2000.iwpt-1.23,J93-2003,0,0.00425822,"guage. We are given a source string If = Ji . . . Ji . . . /J, which is to be translated into a target string e{ = e 1 . . . ei . . . e1. Among all possible target strings, . we will choose the string with the highest probability : arg m ax {Pr( e{ 1 ft ) } e l1 arg m ax { Pr( e{) · Pr(ff l e{)} ( 1) e l1 The argmax operation denotes the search problem, i.e. the generation of the output sentence in the target l anguage. Pr( e{) is the language model (LM) of the target language, which will be investigated in this paper, whereas P r ( ff le{) is the translation m odel that is the m ain topic in [1, 9, 11, 12, 13, 14]. In this work the alignment templ ate approach as described in [11] is used. 231 2 Language Models for SMT Especially for the task of translation, the need of more restriction in the LM prove to be necessary. Restriction of the LM of the target language intuitively should improve translation quality in that way that the translation model should allow many alignment possibilities that are then restricted by the language model. Some heuristics help SMT systems to perform better, for example by re-ordering the source sentence as in (13] or by producing permutations in the search that are scored"
2000.iwpt-1.23,P98-2158,0,0.0282283,"guage. We are given a source string If = Ji . . . Ji . . . /J, which is to be translated into a target string e{ = e 1 . . . ei . . . e1. Among all possible target strings, . we will choose the string with the highest probability : arg m ax {Pr( e{ 1 ft ) } e l1 arg m ax { Pr( e{) · Pr(ff l e{)} ( 1) e l1 The argmax operation denotes the search problem, i.e. the generation of the output sentence in the target l anguage. Pr( e{) is the language model (LM) of the target language, which will be investigated in this paper, whereas P r ( ff le{) is the translation m odel that is the m ain topic in [1, 9, 11, 12, 13, 14]. In this work the alignment templ ate approach as described in [11] is used. 231 2 Language Models for SMT Especially for the task of translation, the need of more restriction in the LM prove to be necessary. Restriction of the LM of the target language intuitively should improve translation quality in that way that the translation model should allow many alignment possibilities that are then restricted by the language model. Some heuristics help SMT systems to perform better, for example by re-ordering the source sentence as in (13] or by producing permutations in the search that are scored"
2000.iwpt-1.23,niessen-etal-2000-evaluation,1,0.837329,"Missing"
2000.iwpt-1.23,W99-0604,1,0.783921,"guage. We are given a source string If = Ji . . . Ji . . . /J, which is to be translated into a target string e{ = e 1 . . . ei . . . e1. Among all possible target strings, . we will choose the string with the highest probability : arg m ax {Pr( e{ 1 ft ) } e l1 arg m ax { Pr( e{) · Pr(ff l e{)} ( 1) e l1 The argmax operation denotes the search problem, i.e. the generation of the output sentence in the target l anguage. Pr( e{) is the language model (LM) of the target language, which will be investigated in this paper, whereas P r ( ff le{) is the translation m odel that is the m ain topic in [1, 9, 11, 12, 13, 14]. In this work the alignment templ ate approach as described in [11] is used. 231 2 Language Models for SMT Especially for the task of translation, the need of more restriction in the LM prove to be necessary. Restriction of the LM of the target language intuitively should improve translation quality in that way that the translation model should allow many alignment possibilities that are then restricted by the language model. Some heuristics help SMT systems to perform better, for example by re-ordering the source sentence as in (13] or by producing permutations in the search that are scored"
2000.iwpt-1.23,P97-1037,1,0.889467,"guage. We are given a source string If = Ji . . . Ji . . . /J, which is to be translated into a target string e{ = e 1 . . . ei . . . e1. Among all possible target strings, . we will choose the string with the highest probability : arg m ax {Pr( e{ 1 ft ) } e l1 arg m ax { Pr( e{) · Pr(ff l e{)} ( 1) e l1 The argmax operation denotes the search problem, i.e. the generation of the output sentence in the target l anguage. Pr( e{) is the language model (LM) of the target language, which will be investigated in this paper, whereas P r ( ff le{) is the translation m odel that is the m ain topic in [1, 9, 11, 12, 13, 14]. In this work the alignment templ ate approach as described in [11] is used. 231 2 Language Models for SMT Especially for the task of translation, the need of more restriction in the LM prove to be necessary. Restriction of the LM of the target language intuitively should improve translation quality in that way that the translation model should allow many alignment possibilities that are then restricted by the language model. Some heuristics help SMT systems to perform better, for example by re-ordering the source sentence as in (13] or by producing permutations in the search that are scored"
2000.iwpt-1.23,1993.mtsummit-1.11,0,0.057905,"sentence incrementally. 2.4 Linear Interpolation of Language Models Experiments show that every LM ty pe has some advantages compared to the other LMs, but also bears some weakness so that it would be best to use all LMs at the same time. An m-gram LM for instance has its strength in robustness and we expect the grammar based LM to model long range dependencies better. A very easy method to combine two LMs p 1 ( ·) and p 2 ( ·) is to use linear interpolation full-sentence level: Pr( e { ) 3 = ( 1 - a) · P1 (e{ ) + a · p2 (e{ ) [8] at the with O < a < 1 Parsing Performance The &quot;VERBMOBIL Task&quot; [15] is a speech translation task in the domain of appointment scheduling, travel planning and hotel reservation. The translation direction is from German to English which poses special problems due to the big difference in the word order of the two languages. To perform experiments with the SCYK parser, we used the English part of the VERBMOBIL tree bank [5] . Table 3 shows some statistics about the investigated corpora. For the performance tests of the parser, we used the standard training and test set that consist of about 9000 and 500 trees, respec tively, where every tree corresponds to one"
2000.iwpt-1.23,P96-1021,0,0.0607216,"Missing"
2000.iwpt-1.23,P98-2230,0,0.0367155,"Missing"
2001.mtsummit-papers.45,1992.tmi-1.8,0,0.946097,"ections on a German-English corpus. Keywords Statistical Machine Translation, Reordering, Morpho-Syntactic Information, Question Inversion, Seperable Prefixes 1 Introduction In this paper, we address the question of how morphological and syntactic analysis can help statistical machine translation (SMT). Although there has been a number of publications dealing with morphological and syntactic analysis in general and its application to machine translation in particular, there have only been a few which incorporate information from this analysis in the process of statistical machine translation (Brown et al., 1992; Nießen and Ney, 2000). In our approach, we introduce transformations to both the source and target string. In our experiments the considered languages are German and English. Systematic evaluations demonstrate that linguistic knowledge can improve translation results. We concentrate on transformations which aim at “harmonizing” the word order in corresponding sentences. Our experiences with various tasks and language pairs show that difference in word order is one of the main sources of errors in machine translation, if not the most dominant problem in this field. The presentation focusses o"
2001.mtsummit-papers.45,J93-2003,0,0.00837682,"ess in statistical machine translation can be formulated as follows: Every target language string         is assigned a probability      to be an admissible translation for the given source language string         . According to Bayes’ decision rule, we have to choose the target string that maximizes the product of the target language model     and the string translation model    . Many existing systems for SMT (Wang and Waibel, 1997; Nießen et al., 1998; Och et al., 1999) make use of a special way of structuring the string translation model (Brown et al., 1993): The correspondence between the words in the source and the target string is described by alignments that assign target word positions to each source word position. The probability of a certain target language word to occur in the target string is assumed to depend basically only on the source words aligned to it. The overall architecture of the statistical translation approach is depicted in Figure 1. In this figure we already anticipate the fact that we will transform the source strings in a certain manner. If necessary we also apply the inverse of these transformations on the produced outp"
2001.mtsummit-papers.45,C90-3030,0,0.0225624,"ecessary we also apply the inverse of these transformations on the produced output strings. Source Language Text Transformation lemma wir wollen nach das Essen nach Essen Esse Essen Essen auf|brechen tags pers pron pl 1st nom V ind present pl 1st prep art sg dat neutr N neutr sg dat prep N name sg dat N fem pl dat N neutr pl dat N neutr sg dat V seperable inf Table 1: Sample analysis of a German sentence. Input: ‘‘Wir wollen nach dem Essen nach Essen aufbrechen’’. J f1 J I Pr(f 1 |e 1 ) Global Search: maximize Pr( e 1I ) a description of the constraint grammar approach we refer the reader to (Karlsson, 1990). Tables 1 and 2 give examples of the information provided by these tools. These examples demonstrate that the tools can quite reliably disambiguate between different readings: For instance, they infer that the word “wollen” is a verb in the indicative present first person plural form. Without any context taken into account, “wollen” has other readings. It can even be interpreted as derived not from a verb, but from an adjective with the meaning “made of wool”. In the cases where the tools returns more than one reading simple heuristics based on domain specific preference rules are applied. Th"
2001.mtsummit-papers.45,C00-2162,1,0.448716,"English corpus. Keywords Statistical Machine Translation, Reordering, Morpho-Syntactic Information, Question Inversion, Seperable Prefixes 1 Introduction In this paper, we address the question of how morphological and syntactic analysis can help statistical machine translation (SMT). Although there has been a number of publications dealing with morphological and syntactic analysis in general and its application to machine translation in particular, there have only been a few which incorporate information from this analysis in the process of statistical machine translation (Brown et al., 1992; Nießen and Ney, 2000). In our approach, we introduce transformations to both the source and target string. In our experiments the considered languages are German and English. Systematic evaluations demonstrate that linguistic knowledge can improve translation results. We concentrate on transformations which aim at “harmonizing” the word order in corresponding sentences. Our experiences with various tasks and language pairs show that difference in word order is one of the main sources of errors in machine translation, if not the most dominant problem in this field. The presentation focusses on the following aspects"
2001.mtsummit-papers.45,P98-2158,0,0.0580824,"Missing"
2001.mtsummit-papers.45,niessen-etal-2000-evaluation,1,0.830173,"Missing"
2001.mtsummit-papers.45,W99-0604,1,0.921952,"ok on our future work. 2 Statistical Machine Translation The goal of the translation process in statistical machine translation can be formulated as follows: Every target language string         is assigned a probability      to be an admissible translation for the given source language string         . According to Bayes’ decision rule, we have to choose the target string that maximizes the product of the target language model     and the string translation model    . Many existing systems for SMT (Wang and Waibel, 1997; Nießen et al., 1998; Och et al., 1999) make use of a special way of structuring the string translation model (Brown et al., 1993): The correspondence between the words in the source and the target string is described by alignments that assign target word positions to each source word position. The probability of a certain target language word to occur in the target string is assumed to depend basically only on the source words aligned to it. The overall architecture of the statistical translation approach is depicted in Figure 1. In this figure we already anticipate the fact that we will transform the source strings in a certain m"
2001.mtsummit-papers.45,P97-1047,0,0.0350657,"be reported. Finally, we will give an outlook on our future work. 2 Statistical Machine Translation The goal of the translation process in statistical machine translation can be formulated as follows: Every target language string         is assigned a probability      to be an admissible translation for the given source language string         . According to Bayes’ decision rule, we have to choose the target string that maximizes the product of the target language model     and the string translation model    . Many existing systems for SMT (Wang and Waibel, 1997; Nießen et al., 1998; Och et al., 1999) make use of a special way of structuring the string translation model (Brown et al., 1993): The correspondence between the words in the source and the target string is described by alignments that assign target word positions to each source word position. The probability of a certain target language word to occur in the target string is assumed to depend basically only on the source words aligned to it. The overall architecture of the statistical translation approach is depicted in Figure 1. In this figure we already anticipate the fact that we will tra"
2001.mtsummit-papers.45,C98-2153,0,\N,Missing
2003.mtsummit-papers.32,niessen-etal-2000-evaluation,1,0.882677,"an MT system are eventually intended to be used by humans. Consequently, manually assigned scores are considered as gold standard for evaluation. In order to evaluate an MT system, a set {Tk }nk=1 of translations generated by the system, called candidate sentence set, is evaluated by human experts. Unfortunately, manual evaluation is very expensive in time and money. Several suggestions have been made to simplify and accelerate this task, while at the same time reproducibility and reliability are improved. But manual evaluation still requires 30 to 60 seconds per sentence even for easy tasks (Nießen et al., 2000). Thus, the manual evaluation of a candidate sentence set, which usually contains hundreds or even thousands of sentences, takes several hours. For this reason, a number of automatic evaluation measures have been proposed, which provide cheap and reproducible results. To evaluate a candidate sentence set using an automatic evaluation measure, each sentence is compared to a set of reference translations Rk . Usually, there is more than one reference translation for a sentence, since there is more than one way to translate it correctly. The automatic evaluation measure either pools these referen"
2003.mtsummit-papers.32,J91-1004,0,0.0534179,"le. Since there is only a single nonterminal A, the two-dimensional parsing table Q(·) does not to be dependent on any nonterminal. 3.5 Complexity of the Algorithm Analogously to the original CYK algorithm, the Q(·) table can be filled using dynamic programming. A table of size O(I 2 J 2 ) has to be filled; O(IJ) pairs of split points (i0 , j 0 ) must be taken into account for each table entry. This yields a time complexity of O(I 3 J 3 ) for this approach. We found that in most cases it is not necessary to calculate all values of Q(i0 , i0 ; j0 , j 0 ). We implemented a memoization approach (Norvig, 1991), i. e. caching of all previously calculated table entries of Q(·). This algorithm has the same worst case complexity O(I 3 J 3 ), but performs much better in the average case. This is due to the fact that we can prune many subtrees of the search tree after having estimated or calculated the first term in the sum. 4 An Application to MT Evaluation 0 0 i j τ 0 ∈T (si10 +1 ,tj10 +1 ) and for inversion, we obtain dinv (sii10 , tjj10 ) = min 0 0 i ,j min 0 j 0 0 i τ 0 ∈T (si10 +1 ,tjj ) 0 τ ∈T (sii ,tj10 +1 ) ª © c(τ ) + c(τ 0 ) + cinv 3.4 Dynamic Programming Recursion We define an auxiliary quant"
2003.mtsummit-papers.32,P02-1040,0,0.0860627,"way to translate it correctly. The automatic evaluation measure either pools these reference translations, or it is calculated against the most similar reference sentence. Evidently, automatic evaluation measures depend heavily on the choice of reference translations. At present, automatic evaluation measures can only decide on words and phrases, and not whether the meaning of sentences is captured or not. From these considerations, it is clear that MT research would benefit from an automatic evaluation measure which strongly correlates with human judgment. 4.2 Automatic Measures 4.2.1 BLEU (Papineni et al., 2002) introduced an MT evaluation measure which they called BLEU (BiLingual Evaluation Understudy). For each candidate sentence Tk , a modified n-gram precision is calculated with respect to its pooled reference sentences Rk . The n-gram lengths range from 1 to 4. To penalize overgeneration of common n-grams in a candidate sentence, the n-gram count is limited to the corresponding maximum n-gram count in its reference sentences. Then, the geometric mean of these four precisions is calculated. The precision alone would favor systems that produce short and simple sentences, even if parts of the trans"
2003.mtsummit-papers.32,P95-1033,0,0.0746778,"del , and cins are parameters of the edit distance; usually we set all of them to 1. α and β are parse subtrees, x and y are terminal symbols. We define the inversion edit distance between a source sentence sI1 and a target sentence tJ1 to be the minimum cost of the set T (sI1 , tJ1 ) of all parse trees generated by the BTG for this sentence pair: dinv (sI1 , tJ1 ) := The Extended Distance Measure A concise definition of the edit operations introduced in Section 2 can be given using bracketing transduction grammars. 3.1 Bracketing Transduction Grammars A bracketing transduction grammar (BTG) (Wu, 1995) is a pair-of-string model that generates two output strings s and t. It consists of one common set of production rules for both output strings. A BTG always generates a pair of sentences. Terminals are pairs of symbols, where each may be the empty word . Concatenation of the terminals and nonterminals on the right hand side of a production rule is either straight, denoted by [·], or inverted, denoted by h·i. In the former case, the parse subtree is to be read left-to-right in both s and t, and in the latter case it is to be read left-to-right in s and right-to-left in t. A BTG contains only"
2003.mtsummit-papers.52,J93-2003,0,0.0371876,"get language string e1 . . . eI . We choose the string that has maximum probability given the source string, P r(eI1 |f1J ). Applying Bayes’ decision rule yields the following criterion: eˆI1 = arg max P r(eI1 |f1J ) = (1) eI1 = arg max{P r(eI1 ) · P r(f1J |eI1 )} . eI1 The correspondence between the words in the source and the target string is described by alignments which can be viewed as mappings B : i → Bi ⊂ {1, . . . , J} assigning a set Bi of source positions to each target position i (including the empty position zero). Note that this conception is different from the one introduced in (Brown et al., 1993) where the alignment assigns (exactly) one target position to each source position. The search (denoted by the arg max operation in Eq. 1) explores the space of all possible target language strings eI1 and all possible alignments B0I between the source and the target language string to find the one with maximum probability. Applying the maximum approximation, this yields ˆ I ) = arg max P r(eI , B I |f J ) . (2) (ˆ eI , B 1 0 eI1 , B0I 1 0 1 This decision criterion aims at the minimization of the expected number of sentence errors. For descriptions of SMT systems see for example (Och and Ney,"
2003.mtsummit-papers.52,P02-1038,1,0.506572,"et al., 1993) where the alignment assigns (exactly) one target position to each source position. The search (denoted by the arg max operation in Eq. 1) explores the space of all possible target language strings eI1 and all possible alignments B0I between the source and the target language string to find the one with maximum probability. Applying the maximum approximation, this yields ˆ I ) = arg max P r(eI , B I |f J ) . (2) (ˆ eI , B 1 0 eI1 , B0I 1 0 1 This decision criterion aims at the minimization of the expected number of sentence errors. For descriptions of SMT systems see for example (Och and Ney, 2002; Vogel et al., 2000; Takezawa et al., 1998; Yamada and Knight, 2002). 3 Confidence Measures For a given translation produced by an MT system, we want to measure the confidence of being correct for each generated word. That is, for each word in the target hypothesis, the confidence is to be calculated and compared to a tagging threshold which has been optimized on a development corpus. All words whose confidence is above this threshold are tagged as correct and all others are tagged as false. Unlike the criterion given in Eq. 2, this approach aims at the minimization of the expected number of"
2003.mtsummit-papers.52,E03-1032,1,0.517274,"ranslations that are likely to be correct. Confidence measures are widely used in speech recognition (see e.g. (Weintraub et al., 1997; Wessel et al., 2001)), but until recently they have not been applied in the area of MT. (Gandrabur and Foster, 2003) introduced confidence measures for a translation prediction task in an interactive environment. They estimate confidence for up to four predicted words. Unlike this, our approach allows for the calculation of confidence for each word in a sentence generated by the system. Thus, it can be applied to interactive systems like the one described in (Och et al., 2003), e. g. to mark words with a low confidence for correction. We present methods for the calculation of confidence measures for MT that rely only on information contained in the output of an MT system. They are based on word graphs and N best lists. For each word in a target sentence, the posterior probability is computed and employed as confidence measure. Furthermore, alternative confidence measures computed on N best lists are introduced and compared to the word posterior probabilities. The remainder of the paper is organized as follows: A short introduction to Statistical Machine Translation"
2003.mtsummit-papers.52,J03-1005,1,0.527981,"of appointment scheduling and travel arrangements. The second task we worked on is the TransType2 corpus. It consists of technical manuals like user guides, operating guides, and system administration guides for different devices. It comprises three language pairs, each of which contains English (E). The other three languages are French (F), Spanish (S), and German (G). The corpus statistics can be seen in Table 3. 4.2 Experimental Setup We performed translation experiments with an implementation of the IBM-4 translation model (Brown et al., 1993). A description of the system can be found in (Tillmann and Ney, 2003). The experimental setup for the two corpora is described in Table 4. It shows the baseline word error rate (WER), the graph error rate (GER), and the word graph density (WGD) for the different language pairs. The WER is based on the Levenshtein distance and computes the minimum number of substitution, insertion, and deletion operations that have to be performed to convert the generated string into the reference string. The GER is computed by determining the sentence in the word graph that has the minimum Levenshtein distance to a given reference. Thus, it is a lower bound for the word error r"
2003.mtsummit-papers.52,W02-1021,1,0.442083,"t only information which is contained in the output of an SMT system. Table 1: Illustration of Eqs. 3 and 4: Sentences taken into account for the calculation of the word posterior probability of the word ’?’ in Translation 1 are marked with a ’+’. Source was hast du gesagt ? target (criterion 1) source (criterion 2) Translation 1 what1 did2 you3 say4 ?5 + + Translation 2 what1 have2 you3 said4 ?5 + + Translation 3 what1 did2 you3 just0 say4 ?5 + Translation 4 what1 you3 did2 say4 .5 3.2 Word Posterior Probabilities on Word Graphs Using an SMT system, we construct a word graph as described in (Ueffing et al., 2002): The nodes represent sets of covered source sentence positions and differentiate between different language model histories. An edge is labeled with the target word generated as a translation of the covered source position(s). The edges are also annotated with the probabilities of the different translation submodels. Each path from the source of the graph (i.e. the node with zero covered source sentence positions) to the sink (i.e. the node where all source sentence positions are covered) is an alternative target sentence hypothesis. Thus, the word graph contains the most probable sentence hy"
2003.mtsummit-papers.52,2000.eamt-1.5,1,0.598696,"the alignment assigns (exactly) one target position to each source position. The search (denoted by the arg max operation in Eq. 1) explores the space of all possible target language strings eI1 and all possible alignments B0I between the source and the target language string to find the one with maximum probability. Applying the maximum approximation, this yields ˆ I ) = arg max P r(eI , B I |f J ) . (2) (ˆ eI , B 1 0 eI1 , B0I 1 0 1 This decision criterion aims at the minimization of the expected number of sentence errors. For descriptions of SMT systems see for example (Och and Ney, 2002; Vogel et al., 2000; Takezawa et al., 1998; Yamada and Knight, 2002). 3 Confidence Measures For a given translation produced by an MT system, we want to measure the confidence of being correct for each generated word. That is, for each word in the target hypothesis, the confidence is to be calculated and compared to a tagging threshold which has been optimized on a development corpus. All words whose confidence is above this threshold are tagged as correct and all others are tagged as false. Unlike the criterion given in Eq. 2, this approach aims at the minimization of the expected number of word errors instead"
2003.mtsummit-papers.52,P02-1039,0,0.012299,"position to each source position. The search (denoted by the arg max operation in Eq. 1) explores the space of all possible target language strings eI1 and all possible alignments B0I between the source and the target language string to find the one with maximum probability. Applying the maximum approximation, this yields ˆ I ) = arg max P r(eI , B I |f J ) . (2) (ˆ eI , B 1 0 eI1 , B0I 1 0 1 This decision criterion aims at the minimization of the expected number of sentence errors. For descriptions of SMT systems see for example (Och and Ney, 2002; Vogel et al., 2000; Takezawa et al., 1998; Yamada and Knight, 2002). 3 Confidence Measures For a given translation produced by an MT system, we want to measure the confidence of being correct for each generated word. That is, for each word in the target hypothesis, the confidence is to be calculated and compared to a tagging threshold which has been optimized on a development corpus. All words whose confidence is above this threshold are tagged as correct and all others are tagged as false. Unlike the criterion given in Eq. 2, this approach aims at the minimization of the expected number of word errors instead of sentence errors. 3.1 Word Posterior Probabilit"
2004.iwslt-evaluation.13,J90-2002,0,0.494047,"Missing"
2004.iwslt-evaluation.13,W99-0604,1,0.657673,"Missing"
2004.iwslt-evaluation.13,E99-1010,0,0.0439985,"Missing"
2004.iwslt-evaluation.13,W02-1021,1,0.117557,"Missing"
2004.iwslt-evaluation.13,N04-1021,0,0.0547991,"Missing"
2004.iwslt-evaluation.13,C04-1030,1,0.594268,"Missing"
2004.iwslt-evaluation.13,J97-3002,0,0.0526216,"Missing"
2004.iwslt-evaluation.13,takezawa-etal-2002-toward,0,0.0402389,"Missing"
2004.iwslt-evaluation.13,2003.mtsummit-papers.51,0,0.0619504,"Missing"
2004.iwslt-evaluation.13,P02-1040,0,\N,Missing
2004.iwslt-evaluation.13,P02-1038,1,\N,Missing
2004.iwslt-evaluation.13,P03-1021,0,\N,Missing
2004.iwslt-papers.7,J90-2002,0,0.250978,"some of the presented techniques. 2. Statistical Machine Translation 2.1. Word Alignment In statistical machine translation, we are given a source language sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language sentence eI1 = e1 . . . ei . . . eI . Among all possible target language sentences, we choose the sentence with the highest probability:  eˆI1 = argmax P r(eI1 |f1J ) (1) eI1 = argmax eI1  P r(eI1 ) · P r(f1J |eI1 ) (2) The decomposition into two knowledge sources in Equation 2 is known as the source-channel approach to statistical machine translation [3]. It allows an independent modeling of the target language model P r(eI1 ) and translation model P r(f1J |eI1 ). The target language model describes the wellformedness of the target language sentence. The translation model links the source language sentence to the target language sentence. The word alignment A is introduced into the translation model as a hidden variable: X P r(f1J |eI1 ) = P r(f1J , A|eI1 ) (3) A Usually, restricted alignments are used in the sense that each source word is aligned to at most one target word. Thus, an alignment A is a mapping from source sentence positions to"
2004.iwslt-papers.7,J93-2003,0,0.0389305,"ment A is introduced into the translation model as a hidden variable: X P r(f1J |eI1 ) = P r(f1J , A|eI1 ) (3) A Usually, restricted alignments are used in the sense that each source word is aligned to at most one target word. Thus, an alignment A is a mapping from source sentence positions to target sentence positions A = a1 ...aj ...aJ , (aj ∈ {0, . . . , I}). The alignment aJ1 may contain alignments aj = 0 with the ‘empty’ word e0 to account for source sentence words that are not aligned to any target word at all. A detailed comparison of the commonly used translation models IBM-1 to IBM-5 [4], as well as the Hidden-Markov alignment model (HMM) [5] can be found in [6]. All these models include parameters p(f |e) for the single-word based lexicon. They differ in the alignment model. All of the model parameters are trained iteratively with the EM-Algorithm. We follow the alignment template translation approach of [9], where a phrase tranlation model is used as one of the main features. The key elements of this translation approach are the alignment templates. These are pairs of source and target language phrases together with an alignment within the phrases. The phrases are extracted"
2004.iwslt-papers.7,C96-2141,1,0.642373,"den variable: X P r(f1J |eI1 ) = P r(f1J , A|eI1 ) (3) A Usually, restricted alignments are used in the sense that each source word is aligned to at most one target word. Thus, an alignment A is a mapping from source sentence positions to target sentence positions A = a1 ...aj ...aJ , (aj ∈ {0, . . . , I}). The alignment aJ1 may contain alignments aj = 0 with the ‘empty’ word e0 to account for source sentence words that are not aligned to any target word at all. A detailed comparison of the commonly used translation models IBM-1 to IBM-5 [4], as well as the Hidden-Markov alignment model (HMM) [5] can be found in [6]. All these models include parameters p(f |e) for the single-word based lexicon. They differ in the alignment model. All of the model parameters are trained iteratively with the EM-Algorithm. We follow the alignment template translation approach of [9], where a phrase tranlation model is used as one of the main features. The key elements of this translation approach are the alignment templates. These are pairs of source and target language phrases together with an alignment within the phrases. The phrases are extracted from the automatically estimated word alignments. The a"
2004.iwslt-papers.7,J03-1002,1,0.143593,"f1J |eI1 ) = P r(f1J , A|eI1 ) (3) A Usually, restricted alignments are used in the sense that each source word is aligned to at most one target word. Thus, an alignment A is a mapping from source sentence positions to target sentence positions A = a1 ...aj ...aJ , (aj ∈ {0, . . . , I}). The alignment aJ1 may contain alignments aj = 0 with the ‘empty’ word e0 to account for source sentence words that are not aligned to any target word at all. A detailed comparison of the commonly used translation models IBM-1 to IBM-5 [4], as well as the Hidden-Markov alignment model (HMM) [5] can be found in [6]. All these models include parameters p(f |e) for the single-word based lexicon. They differ in the alignment model. All of the model parameters are trained iteratively with the EM-Algorithm. We follow the alignment template translation approach of [9], where a phrase tranlation model is used as one of the main features. The key elements of this translation approach are the alignment templates. These are pairs of source and target language phrases together with an alignment within the phrases. The phrases are extracted from the automatically estimated word alignments. The alignment templates a"
2004.iwslt-papers.7,P02-1038,1,0.627781,"word penalty and alignment template penalty feature functions. To model the alignment template reorderings, we use a feature function that penalizes reorderings linear in the jump width. We use a dynamic programming beam search algorithm to generate the translation hypothesis with maximum probability. This search algorithm allows for arbitrary reorderings at the level of alignment templates. Within the alignment templates, the word order is learned in training and kept fix during the search process. This is only a brief description of the alignment template approach. For further details, see [9, 7]. 3. Acquiring Additional Training Data 2.2. Translation: Alignment Template Approach The argmax operation in Eq. 2 denotes the search problem, i.e. the generation of the output sentence in the target language. We have to maximize over all possible target language sentences. For the search, we choose an alternative to the classical source-channel approach and model the posterior probability P r(eI1 |f1J ) directly. Using a log-linear model [7], we obtain: ! M X I J J I J P r(e1 |f1 ) = Z(f1 ) · exp λm hm (e1 , f1 ) m=1 Here, Z(f1J ) denotes the appropriate normalization constant, hm are the fe"
2004.iwslt-papers.7,P03-1021,0,0.0274503,"h and model the posterior probability P r(eI1 |f1J ) directly. Using a log-linear model [7], we obtain: ! M X I J J I J P r(e1 |f1 ) = Z(f1 ) · exp λm hm (e1 , f1 ) m=1 Here, Z(f1J ) denotes the appropriate normalization constant, hm are the feature functions and λm are the corresponding scaling factors. We thus arrive at the decision rule: ( M ) X I I J eˆ1 = argmax λm hm (e1 , f1 ) eI1 to the maximum entropy principle, e.g. using the Generalized Iterative Scaling (GIS) algorithm. Alternatively, one can train them with respect to the final translation quality measured by some error criterion [8]. m=1 This approach has the advantage that additional models or feature functions can be easily integrated into the overall system. The model scaling factors λM 1 are trained according 140 When only a small corpus of sentence pairs is available for training of the statistical translation models, it may be reasonable to include additional bilingual training data from other sources. Since this additional data may come from another domain and substantially differ from the original training corpus, a method for selecting relevant sentences is desirable. In our experiments, we use a relevance measu"
2004.iwslt-papers.7,W99-0604,1,0.944144,"...aj ...aJ , (aj ∈ {0, . . . , I}). The alignment aJ1 may contain alignments aj = 0 with the ‘empty’ word e0 to account for source sentence words that are not aligned to any target word at all. A detailed comparison of the commonly used translation models IBM-1 to IBM-5 [4], as well as the Hidden-Markov alignment model (HMM) [5] can be found in [6]. All these models include parameters p(f |e) for the single-word based lexicon. They differ in the alignment model. All of the model parameters are trained iteratively with the EM-Algorithm. We follow the alignment template translation approach of [9], where a phrase tranlation model is used as one of the main features. The key elements of this translation approach are the alignment templates. These are pairs of source and target language phrases together with an alignment within the phrases. The phrases are extracted from the automatically estimated word alignments. The alignment templates are build at the level of word classes, which improves their generalization capability. Besides the alignment template translation model probabilities, we use additional feature functions. These are the word translation model and two language models: a"
2004.iwslt-papers.7,2001.mtsummit-papers.68,0,0.0231131,"and substantially differ from the original training corpus, a method for selecting relevant sentences is desirable. In our experiments, we use a relevance measure of ngram coverage. To this end, we compute the set C of ngrams occurring in the source part of the initial training corpus (n = 1, 2, 3, 4). Then, for each candidate source sentence in the additional corpus, we compute a score based on the occurrence of the n-grams from C in that sentence. The score is defined as the geometric mean of n-gram precisions and is therefore similar to the BLEU score used in machine translation evaluation [10]. Such score provides a quantitative measure of how “out-of-domain” or “in-domain” the additional training data may be. We add only those sentence pairs to the initial training corpus, for which this score is sufficiently high. 4. Morphological Information for Word Alignments 4.1. Lexicon Smoothing Existing statistical translation systems usually treat different derivations of the same base form as they were independent of each other. In our approach, the dependencies between such derivations are taken into account during the EM training of the statistical alignment models. Typically, the stat"
2004.iwslt-papers.7,P00-1056,1,0.650352,"word alignment quality on the Verbmobil task. The German– English Verbmobil task [13] is a speech translation task in the domain of appointment scheduling, travel planning and hotel reservation. The corpus statistics are shown in Table 1. The number of running words and the vocabularies are based on full-form words including punctuation marks. As in [6], the first 100 sentences of the alignment test corpus are used as a development corpus to optimize model parameters that are not trained via the EM algorithm, e.g. the smoothing parameters. We use the same evaluation criterion as described in [14]. The generated word alignment is compared to a reference alignment which is produced by human experts. The obtained reference alignment may contain many-to-one and one-to-many relationships and includes sure (S) and possible (P) alignment points. The quality of an alignment A is computed as appropriately redefined precision and recall measures. We also use the alignment error rate (AER), which is derived from the well-known F-measure. |A ∩ S| |A ∩ P | , precision = |S| |A| |A ∩ S |+ |A ∩ P | AER(S, P ; A) = 1 − |A |+ |S| recall = With these definitions a recall error can only occur if a S(ure"
2004.iwslt-papers.7,W01-1407,1,\N,Missing
2004.iwslt-papers.7,P02-1040,0,\N,Missing
2005.eamt-1.17,2004.iwslt-evaluation.13,1,0.824945,"Missing"
2005.eamt-1.25,W00-0508,0,0.0457912,"Missing"
2005.eamt-1.25,P04-1065,1,0.890111,"Missing"
2005.eamt-1.25,knight-al-onaizan-1998-translation,0,0.0852462,"Missing"
2005.eamt-1.25,N03-1019,0,0.113584,"Missing"
2005.eamt-1.25,C04-1032,1,0.835675,"ed with one target word (e. g. translating an English noun phrase into a German compound). The second case usually involves non-literal phrase-to-phrase translations, when translating individual source words does not convey the meaning of the source phrase. An example of the source sentence reordering, as well as of the three described bilingual corpus representations, labeled with (A),(B), and (C), respectively, is given in Figure 1. In our approach, we can avoid various heuristics and learn these and other types of corpus representations by using a flexible alignment framework presented in (Matusov et al., 2004). Following this work, we efficiently compute optimal, minimumcost alignments which satisfy certain constraints. The constraints may include the requirement for each word to be aligned at least once, functional form or full monotonicity. Local alignment costs between a source word fj and a target word ei are estimated statistically using state occupation probabilities of the HMM and IBM-4 models as trained by the GIZA++ toolkit (Och et al., 2003). 2.3 Optimization Criterion Using one of the corpus representations (f˜, e˜) via a certain (constrained) alignment A, we rewrite the joint translatio"
2005.eamt-1.25,J03-1002,1,0.01143,"Missing"
2005.eamt-1.25,J04-4002,1,0.719465,"Missing"
2005.eamt-1.25,P02-1040,0,0.0940792,"r the BTEC corpus are given in Table 1. We evaluate the impact of the proposed reordering restrictions on the CSTAR 2003 test set with 506 Chinese sentences and 16 reference translations. We also present results on the Verbmobil task (Wahlster, 2000). The domain of this corpus is appointment scheduling, travel planning, and hotel reservation. It consists of transcriptions of spontaneous speech. Table 2 shows the statistics of this corpus. 5.2 Evaluation Criteria For the automatic evaluation, we used the word error rate (WER), position-independent word error 186 rate (PER), and the BLEU score (Papineni et al., 2002). This score measures accuracy, i. e. larger scores are better. The three measures were computed with respect to multiple reference translations, when they were available. To indicate this, we will label the error rate acronyms with an m. On the Chinese-to-English BTEC task, both training and evaluation were performed using corpora and references in lowercase and without punctuation marks. 5.3 Experiments As described in Sec. 2.2, we reordered the source sentences in training. We then created a bilingual corpus of tuples (fj , e˜j ) (i. e. representation (B) in Figure 1) based on a fully monot"
2005.eamt-1.29,H93-1039,0,0.0227916,"slation (SMT) is to translate an input word sequence f1J = f1 . . . fj . . . fJ into a target word sequence eI1 = e1 . . . ei . . . eI by maximising the probability P (eI1 |f1J ). This probability can be factorised into the translation model probability P (f1J |eI1 ), which describes the correspondence between the words in the source and the target sequence and the language model probability P (eJ1 ), which describes the wellformedness of the produced target sequence. These two probabilities can be modelled independently of each other. For detailed descriptions of SMT models, see for example (Brown et al., 1993). Translation probabilities are extracted from a bilingual parallel text corpus, whereas language model probabilities are learnt from a monolingual text corpus in the target language. Usually, the larger the available training corpus, the better the performance of a translation system. However, acquisition of a large high-quality bilingual parallel text for the desired domain and language pair requires lot of time and effort, and, for many language pairs, is not even possible. Therefore, the strategies for exploiting limited amounts of bilingual data are receiving more and more attention (Al-O"
2005.eamt-1.29,J04-2003,1,0.834265,"lities are extracted from a bilingual parallel text corpus, whereas language model probabilities are learnt from a monolingual text corpus in the target language. Usually, the larger the available training corpus, the better the performance of a translation system. However, acquisition of a large high-quality bilingual parallel text for the desired domain and language pair requires lot of time and effort, and, for many language pairs, is not even possible. Therefore, the strategies for exploiting limited amounts of bilingual data are receiving more and more attention (Al-Onaizan et al., 2000; Nießen and Ney, 2004; Matusov et al., 2004). 212 Conventional dictionaries (one word and its translation(s) per entry) have been proposed in (Brown et al., 1993) and are shown to be valuable resources for SMT systems. They can be used to augment and also to replace the training corpus. Nevertheless, the main draw-back is that they typically contain only base forms of the words and not inflections. The use of morpho-syntactic information for overcoming this problem is investigated in (Nießen and Ney, 2004) for translation from German into English and in (Vogel and Monson, 2004) for translation from Chinese into En"
2005.eamt-1.29,P02-1040,0,0.0709516,"Missing"
2005.eamt-1.29,vogel-monson-2004-augmenting,0,0.0159583,"ore attention (Al-Onaizan et al., 2000; Nießen and Ney, 2004; Matusov et al., 2004). 212 Conventional dictionaries (one word and its translation(s) per entry) have been proposed in (Brown et al., 1993) and are shown to be valuable resources for SMT systems. They can be used to augment and also to replace the training corpus. Nevertheless, the main draw-back is that they typically contain only base forms of the words and not inflections. The use of morpho-syntactic information for overcoming this problem is investigated in (Nießen and Ney, 2004) for translation from German into English and in (Vogel and Monson, 2004) for translation from Chinese into English. Still, the dictionaries normally contain one word per entry and do not take into account phrases, idioms and similar complex expressions. In our work, we have exploited a phrasal lexicon (one short phrase and its translation(s) per entry) as a bilingual knowledge source for SMT which has not been examined so far. A phrasal lexicon is expected to be especially helpful to overcome some difficulties which cannot be handled well with standard dictionaries. We have used the phrasal lexicon to increase the existing training corpus as well as to replace it."
2005.eamt-1.29,J93-2003,0,\N,Missing
2005.eamt-1.29,2004.iwslt-papers.7,1,\N,Missing
2005.eamt-1.35,2004.iwslt-evaluation.13,1,0.361636,"and Ney, 2004). For the application in an interactive environment, we need conﬁdence measures that operate on the word level (instead of the sentence level) and that can be computed very efﬁciently. (Gandrabur and Foster, 2003) studies the application of word-level conﬁdence measures for translation prediction in an interactive SMT system. The SMT system applied there is a rather simple model that combines a trigram language model and the IBM translation model 2 (Brown et al., 1993). In contrast to this, we apply a fully-ﬂedged SMT system on the basis of bilingual phrases (Och and Ney, 2004; Bender et al., 2004), taking a large number of different submodels into account. Moreover, the EAMT 2005 Conference Proceedings system described in (Gandrabur and Foster, 2003) predicts extensions of up to four words, whereas our system translates the whole input sentence. In addition to the prediction of words based on the conﬁdence as proposed in (Gandrabur and Foster, 2003), we also study a new approach of rejecting words with low conﬁdence. Furthermore, we will introduce a method to make use of a given preﬁx (which is known to be correct) in the conﬁdence estimation. 4 Application in Interactive MT If the hum"
2005.eamt-1.35,J04-4002,1,0.497271,"uirk, 2004; Ueffing and Ney, 2004). For the application in an interactive environment, we need conﬁdence measures that operate on the word level (instead of the sentence level) and that can be computed very efﬁciently. (Gandrabur and Foster, 2003) studies the application of word-level conﬁdence measures for translation prediction in an interactive SMT system. The SMT system applied there is a rather simple model that combines a trigram language model and the IBM translation model 2 (Brown et al., 1993). In contrast to this, we apply a fully-ﬂedged SMT system on the basis of bilingual phrases (Och and Ney, 2004; Bender et al., 2004), taking a large number of different submodels into account. Moreover, the EAMT 2005 Conference Proceedings system described in (Gandrabur and Foster, 2003) predicts extensions of up to four words, whereas our system translates the whole input sentence. In addition to the prediction of words based on the conﬁdence as proposed in (Gandrabur and Foster, 2003), we also study a new approach of rejecting words with low conﬁdence. Furthermore, we will introduce a method to make use of a given preﬁx (which is known to be correct) in the conﬁdence estimation. 4 Application in Int"
2005.eamt-1.35,E03-1032,1,0.844721,"eystroke of the human translator. Note that this decision can be taken on the word or character level even though the translation system makes use of bilingual phrases. This approach requires a highly efﬁcient search, because human users will only accept response times of fractions of a second. To achieve this, the SMT system computes a word graph representing a subset of the possible translations of the input sentence (Uefﬁng et al., 2002). This representation of the search space is then used for the efﬁcient computation of the extension. For a description of the interactive SMT system, see (Och et al., 2003). The concept of interactive machine translation was ﬁrst suggested by (Foster et al., 1996). The basic idea is to provide an environment to a human translator that interactively reacts upon the input as the user writes or corrects the translation. In such an approach, the system suggests an extension of a sentence that the human user either accepts or ignores. An implementation of such a tool was performed in the TransType project (Foster et al., 1996; Foster et al., 1997; Langlais et al., 2000) and further improved within TransType2 (Atos Origin Spain et al., 2002; Civera et al., 2004). 3 Co"
2005.eamt-1.35,W02-1021,1,0.848341,"search for the extension is perEAMT 2005 Conference Proceedings Application of word-level confidence measures in interactive statistical machine translation formed after each keystroke of the human translator. Note that this decision can be taken on the word or character level even though the translation system makes use of bilingual phrases. This approach requires a highly efﬁcient search, because human users will only accept response times of fractions of a second. To achieve this, the SMT system computes a word graph representing a subset of the possible translations of the input sentence (Uefﬁng et al., 2002). This representation of the search space is then used for the efﬁcient computation of the extension. For a description of the interactive SMT system, see (Och et al., 2003). The concept of interactive machine translation was ﬁrst suggested by (Foster et al., 1996). The basic idea is to provide an environment to a human translator that interactively reacts upon the input as the user writes or corrects the translation. In such an approach, the system suggests an extension of a sentence that the human user either accepts or ignores. An implementation of such a tool was performed in the TransType"
2005.eamt-1.35,C04-1046,1,0.885186,"ggests an extension of a sentence that the human user either accepts or ignores. An implementation of such a tool was performed in the TransType project (Foster et al., 1996; Foster et al., 1997; Langlais et al., 2000) and further improved within TransType2 (Atos Origin Spain et al., 2002; Civera et al., 2004). 3 Conﬁdence Measures for SMT Conﬁdence measures have been extensively studied for speech recognition, but are not well known in other areas. Only recently have researchers started to investigate conﬁdence measures for machine translation (Blatz et al., 2003; Gandrabur and Foster, 2003; Blatz et al., 2004; Quirk, 2004; Ueffing and Ney, 2004). For the application in an interactive environment, we need conﬁdence measures that operate on the word level (instead of the sentence level) and that can be computed very efﬁciently. (Gandrabur and Foster, 2003) studies the application of word-level conﬁdence measures for translation prediction in an interactive SMT system. The SMT system applied there is a rather simple model that combines a trigram language model and the IBM translation model 2 (Brown et al., 1993). In contrast to this, we apply a fully-ﬂedged SMT system on the basis of bilingual phrase"
2005.eamt-1.35,J93-2003,0,0.0368871,"onﬁdence measures for machine translation (Blatz et al., 2003; Gandrabur and Foster, 2003; Blatz et al., 2004; Quirk, 2004; Ueffing and Ney, 2004). For the application in an interactive environment, we need conﬁdence measures that operate on the word level (instead of the sentence level) and that can be computed very efﬁciently. (Gandrabur and Foster, 2003) studies the application of word-level conﬁdence measures for translation prediction in an interactive SMT system. The SMT system applied there is a rather simple model that combines a trigram language model and the IBM translation model 2 (Brown et al., 1993). In contrast to this, we apply a fully-ﬂedged SMT system on the basis of bilingual phrases (Och and Ney, 2004; Bender et al., 2004), taking a large number of different submodels into account. Moreover, the EAMT 2005 Conference Proceedings system described in (Gandrabur and Foster, 2003) predicts extensions of up to four words, whereas our system translates the whole input sentence. In addition to the prediction of words based on the conﬁdence as proposed in (Gandrabur and Foster, 2003), we also study a new approach of rejecting words with low conﬁdence. Furthermore, we will introduce a method"
2005.eamt-1.35,W04-3245,0,0.121434,"Missing"
2005.eamt-1.35,C96-1067,0,0.0310517,"racter level even though the translation system makes use of bilingual phrases. This approach requires a highly efﬁcient search, because human users will only accept response times of fractions of a second. To achieve this, the SMT system computes a word graph representing a subset of the possible translations of the input sentence (Uefﬁng et al., 2002). This representation of the search space is then used for the efﬁcient computation of the extension. For a description of the interactive SMT system, see (Och et al., 2003). The concept of interactive machine translation was ﬁrst suggested by (Foster et al., 1996). The basic idea is to provide an environment to a human translator that interactively reacts upon the input as the user writes or corrects the translation. In such an approach, the system suggests an extension of a sentence that the human user either accepts or ignores. An implementation of such a tool was performed in the TransType project (Foster et al., 1996; Foster et al., 1997; Langlais et al., 2000) and further improved within TransType2 (Atos Origin Spain et al., 2002; Civera et al., 2004). 3 Conﬁdence Measures for SMT Conﬁdence measures have been extensively studied for speech recogni"
2005.eamt-1.35,1997.mtsummit-papers.1,0,0.524776,"arch space is then used for the efﬁcient computation of the extension. For a description of the interactive SMT system, see (Och et al., 2003). The concept of interactive machine translation was ﬁrst suggested by (Foster et al., 1996). The basic idea is to provide an environment to a human translator that interactively reacts upon the input as the user writes or corrects the translation. In such an approach, the system suggests an extension of a sentence that the human user either accepts or ignores. An implementation of such a tool was performed in the TransType project (Foster et al., 1996; Foster et al., 1997; Langlais et al., 2000) and further improved within TransType2 (Atos Origin Spain et al., 2002; Civera et al., 2004). 3 Conﬁdence Measures for SMT Conﬁdence measures have been extensively studied for speech recognition, but are not well known in other areas. Only recently have researchers started to investigate conﬁdence measures for machine translation (Blatz et al., 2003; Gandrabur and Foster, 2003; Blatz et al., 2004; Quirk, 2004; Ueffing and Ney, 2004). For the application in an interactive environment, we need conﬁdence measures that operate on the word level (instead of the sentence lev"
2005.eamt-1.35,W00-0507,0,0.0393828,"ed for the efﬁcient computation of the extension. For a description of the interactive SMT system, see (Och et al., 2003). The concept of interactive machine translation was ﬁrst suggested by (Foster et al., 1996). The basic idea is to provide an environment to a human translator that interactively reacts upon the input as the user writes or corrects the translation. In such an approach, the system suggests an extension of a sentence that the human user either accepts or ignores. An implementation of such a tool was performed in the TransType project (Foster et al., 1996; Foster et al., 1997; Langlais et al., 2000) and further improved within TransType2 (Atos Origin Spain et al., 2002; Civera et al., 2004). 3 Conﬁdence Measures for SMT Conﬁdence measures have been extensively studied for speech recognition, but are not well known in other areas. Only recently have researchers started to investigate conﬁdence measures for machine translation (Blatz et al., 2003; Gandrabur and Foster, 2003; Blatz et al., 2004; Quirk, 2004; Ueffing and Ney, 2004). For the application in an interactive environment, we need conﬁdence measures that operate on the word level (instead of the sentence level) and that can be comp"
2005.eamt-1.37,P91-1022,0,0.147266,"arameters. In practice, many sentences in the training corpora are long. Some translation applications cannot handle a sentence whose length is larger than a predetermined value. The reasons are memory limits and the computational complexity of the algorithms. Therefore, long sentences are usually removed during the preprocessing. But even if long sentences are included, the resulting quality is usually not as good as it is for short sentences. 1.2 Comparison with Sentence Alignment The problem of sentence segmentation is similar to the problem of sentence alignment which was investigated by (Brown et al., 1991; Chen, 1993; Moore, 2002). In the case of the sentence segmentation, we assume that the sentence pairs are aligned correctly. The tasks are to find appropriate split points and to align the subsentences. In the case of the sentence alignment, the corpus is aligned at the document level only. Here, we have to align the sentences of two documents rather than having to 280 1.3 State of the Art Previous research on the sentence segmentation problem can be found in (Nevado et al., 2003), who searches for the segmentation boundaries using a dynamic programming algorithm. This technique is based on"
2005.eamt-1.37,J93-2003,0,0.0217239,"In statistical machine translation, we are given a source language (‘French’) sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language (‘English’) sentence eI1 = e1 . . . ei . . . eI . Among all possible target language sentences, we will choose the sentence with the highest probability: eˆI1 = argmax eI1 = argmax eI1  P r(eI1 |f1J )    P r(eI1 ) · P r(f1J |eI1 ) (1) The decomposition into two knowledge sources in Equation 1 allows an independent modeling of target language model P r(eI1 ) and translation model P r(f1J |eI1 )1 , known as source-channel model (Brown et al., 1993). The target language model describes the well-formedness of the target language sentence. The translation model links the source language sentence to the target language sentence. The argmax operation denotes the search problem, i.e. the generation of the output sentence into the target language. We have to maximize over all possible target language sentences. The translation model P r(f1J |eI1 ) can be further extended to a statistical alignment model with the following equation: P r(f1J |eI1 ) =  P r(f1J , aJ1 |eI1 ) 2.2 Alignment Models There are different decompositions of the alignment"
2005.eamt-1.37,P93-1002,0,0.0633879,"ce, many sentences in the training corpora are long. Some translation applications cannot handle a sentence whose length is larger than a predetermined value. The reasons are memory limits and the computational complexity of the algorithms. Therefore, long sentences are usually removed during the preprocessing. But even if long sentences are included, the resulting quality is usually not as good as it is for short sentences. 1.2 Comparison with Sentence Alignment The problem of sentence segmentation is similar to the problem of sentence alignment which was investigated by (Brown et al., 1991; Chen, 1993; Moore, 2002). In the case of the sentence segmentation, we assume that the sentence pairs are aligned correctly. The tasks are to find appropriate split points and to align the subsentences. In the case of the sentence alignment, the corpus is aligned at the document level only. Here, we have to align the sentences of two documents rather than having to 280 1.3 State of the Art Previous research on the sentence segmentation problem can be found in (Nevado et al., 2003), who searches for the segmentation boundaries using a dynamic programming algorithm. This technique is based on the lexicon"
2005.eamt-1.37,moore-2002-fast,0,0.0152406,"tences in the training corpora are long. Some translation applications cannot handle a sentence whose length is larger than a predetermined value. The reasons are memory limits and the computational complexity of the algorithms. Therefore, long sentences are usually removed during the preprocessing. But even if long sentences are included, the resulting quality is usually not as good as it is for short sentences. 1.2 Comparison with Sentence Alignment The problem of sentence segmentation is similar to the problem of sentence alignment which was investigated by (Brown et al., 1991; Chen, 1993; Moore, 2002). In the case of the sentence segmentation, we assume that the sentence pairs are aligned correctly. The tasks are to find appropriate split points and to align the subsentences. In the case of the sentence alignment, the corpus is aligned at the document level only. Here, we have to align the sentences of two documents rather than having to 280 1.3 State of the Art Previous research on the sentence segmentation problem can be found in (Nevado et al., 2003), who searches for the segmentation boundaries using a dynamic programming algorithm. This technique is based on the lexicon information. H"
2005.eamt-1.37,W03-2205,0,0.018661,"nt The problem of sentence segmentation is similar to the problem of sentence alignment which was investigated by (Brown et al., 1991; Chen, 1993; Moore, 2002). In the case of the sentence segmentation, we assume that the sentence pairs are aligned correctly. The tasks are to find appropriate split points and to align the subsentences. In the case of the sentence alignment, the corpus is aligned at the document level only. Here, we have to align the sentences of two documents rather than having to 280 1.3 State of the Art Previous research on the sentence segmentation problem can be found in (Nevado et al., 2003), who searches for the segmentation boundaries using a dynamic programming algorithm. This technique is based on the lexicon information. However, it only allows a monotone alignment of the bilingual segmented sentences and it requires a list of manually defined anchor words. 1.4 Idea of the Method Inspired by the phrase extraction approach (Vogel et al., 2004), we introduce a new sentence segmentation method which does not need anchor words and allows for nonmonotone alignments of the subsentences. Here we separate a sentence pair into two subpairs with the so-called “IBM Word Alignment Model"
2005.eamt-1.37,J03-1002,1,0.0133802,"f the alignment probability P r(f1J , aJ1 |eI1 ). The IBM-1 model (Brown et al., 1993) assumes that all alignments have the same probability by using a uniform distribution:   I J   1 p(fj |ei ) p(f1J |eI1 ) = I j=1 Hence, the word order does not affect the alignment probability. We use the IBM-1 model and the higher-order models IBM-4 (Brown et al., 1993) and HiddenMarkov model (HMM) (Vogel et al., 1996) to train the lexicon parameters p(fj |ei ). The resulting probability distribution is more concentrated than the one trained unsing the IBM-1 model only. The training software is GIZA++ (Och and Ney, 2003). To incorporate the context into the translation model, the alignment template translation approach (Och and Ney, 2004) is applied. A dynamic programming beam search algorithm is used to generate the translation hypothesis with maximum probability. 3 Segmentation Methods In this section, we describe the sentence segmentation algorithm in detail. The main idea is that we use the word alignment information to find the optimal split point in a sentence pair and separate it into two pairs. To calculate the alignment probability of a segment pair, we indicate (j1 , i1 ) and (j2 , i2 ) as the start"
2005.eamt-1.37,J04-4002,1,0.654087,"the same probability by using a uniform distribution:   I J   1 p(fj |ei ) p(f1J |eI1 ) = I j=1 Hence, the word order does not affect the alignment probability. We use the IBM-1 model and the higher-order models IBM-4 (Brown et al., 1993) and HiddenMarkov model (HMM) (Vogel et al., 1996) to train the lexicon parameters p(fj |ei ). The resulting probability distribution is more concentrated than the one trained unsing the IBM-1 model only. The training software is GIZA++ (Och and Ney, 2003). To incorporate the context into the translation model, the alignment template translation approach (Och and Ney, 2004) is applied. A dynamic programming beam search algorithm is used to generate the translation hypothesis with maximum probability. 3 Segmentation Methods In this section, we describe the sentence segmentation algorithm in detail. The main idea is that we use the word alignment information to find the optimal split point in a sentence pair and separate it into two pairs. To calculate the alignment probability of a segment pair, we indicate (j1 , i1 ) and (j2 , i2 ) as the start and end point of a segment, respectively. aJ 1 The alignment model P r(f1J , aJ1 |eI1 ) introduces a ‘hidden’ word alig"
2005.eamt-1.37,P02-1040,0,0.0750529,"substitution, insertion and deletion operations that have to be performed to convert the generated sentence into the reference sentence. • PER (position-independent word error rate): A shortcoming of the WER is that it requires a perfect word order. The word order of an acceptable sentence can be different from that of the target sentence, so that the WER measure alone could be misleading. The PER compares the words in the two sentences ignoring the word order. • BLEU score: This score measures the precision of unigrams, bigrams, trigrams and fourgrams with a penalty for too short sentences. (Papineni et al., 2002). • NIST score: This score is similar to BLEU, but it uses an arithmetic average of N-gram counts rather than a geometric average, and it weights more heavily those N-grams that are more informative. (Doddington, 2002). The BLEU and NIST scores measure accuracy, i.e. larger scores are better. In our evaluation the scores are measured as case insensitive and with respect to multiple references. 4.5 Translation Results The evaluation is done on two tasks described in Section 4.1. In the NIST Chinese-English evaluations, the BLEU score is used as evaluation criterion. Therefore, we optimize the p"
2005.eamt-1.37,C96-2141,1,0.716387,"on model P r(f1J |eI1 ) can be further extended to a statistical alignment model with the following equation: P r(f1J |eI1 ) =  P r(f1J , aJ1 |eI1 ) 2.2 Alignment Models There are different decompositions of the alignment probability P r(f1J , aJ1 |eI1 ). The IBM-1 model (Brown et al., 1993) assumes that all alignments have the same probability by using a uniform distribution:   I J   1 p(fj |ei ) p(f1J |eI1 ) = I j=1 Hence, the word order does not affect the alignment probability. We use the IBM-1 model and the higher-order models IBM-4 (Brown et al., 1993) and HiddenMarkov model (HMM) (Vogel et al., 1996) to train the lexicon parameters p(fj |ei ). The resulting probability distribution is more concentrated than the one trained unsing the IBM-1 model only. The training software is GIZA++ (Och and Ney, 2003). To incorporate the context into the translation model, the alignment template translation approach (Och and Ney, 2004) is applied. A dynamic programming beam search algorithm is used to generate the translation hypothesis with maximum probability. 3 Segmentation Methods In this section, we describe the sentence segmentation algorithm in detail. The main idea is that we use the word alignme"
2005.eamt-1.37,2004.iwslt-evaluation.11,0,0.0288695,"Missing"
2005.eamt-1.37,J97-3002,0,0.0918773,"ed as the split point. 3.4 Recursive Segmentation We introduce the maximum sentence lengths for the source language Jmax and for the target language Imax . If a sentence is longer than the maximum length, the sentence pair is split into two subsentence pairs. In most cases, these sub-sentences are still too long. Therefore, the splitting is applied recursively until the length of each new sentence is less than the predefined value. The recursive algorithm is shown in Figure 4 for a bilingual sentence segmentation S(f1J , eI1 ). The algorithm is similar to the bracketing transduction grammars (Wu, 1997). Here, we take the local decision after each recursion. The full parsing with BTG is not feasible for long sentences because of its cubic complexity. 3.5 Segmentation Example We take the sentence pair in Figure 1 as an example. The maximum lengths in both languages is defined as three. In practice, the segmented sentences contain from 25 to hundreds of words. Using the algorithm in Figure 4, this sentence pair is segmented as follows: First, the lengths of the two sentences are larger than the maximum lengths, the sentences will be segmented. After the calculation with Equation 5, we find the"
2005.eamt-1.6,2004.iwslt-evaluation.13,1,0.857242,"till has to be determined is if the response time of the system, increased by the overhead of regenerating the word graphs, remains acceptable for interactive use under real-life conditions. Off-line experiments seem to indicate that this is the case (see next section). 6 6.1 Experimental Results Experimental Setup The experiments were performed on the SpanishEnglish and English-German Xerox corpora, which consist of the translation of technical manuals. The corpora allocations are summarized in Table 1 and Table 2. After training and optimization of the model scaling factors, the SMT engine (Bender et al., 2004) was used to translate the test corpus. The results using the standard evaluation measures for machine translation (word error rate, positionindependent word error rate, BLEU score and NIST score) are shown in Table 3. Using the same parameter settings, a simulation of the interactive mode was carried out. This simulation mode is described in (Och et al., 2003). The system with the same parameter settings was also successfully used by human translators to evaluate it under real-life conditions. Due to the high effort that human evaluations require, only the wordgraph based generation strategy"
2005.eamt-1.6,C96-1067,0,0.580617,"ife applications. The produced sentences often contain grammatical errors and the preservation of the meaning is not even always achieved. Therefore a manual post-processing of the texts has to be done. The concept of interactive machine translation already has a long history, and the first systems appeared in the end of the 1960’s. However in most of these systems the user doesn’t have a direct control over the translation process, and most of the user interaction is reduced to performing source language disambiguation on demand. The approach we center on in this work was first suggested by (Foster et al., 1996) and an implementation was carried out in the TransType project (Langlais et al., 2000). In such an environment, human translators interact with a translation system that acts as an assistance tool and dynamically provides a list of translations that best complete the part of the source senEAMT 2005 Conference Proceedings tence already translated. Further refinements were presented in the TransType2 project (SchlumbergerSema S.A. et al., 2001). The work presented in this paper deals with generation strategies for interactive (statistical) machine translation systems. Clearly, the best approach"
2005.eamt-1.6,W00-0507,0,0.366059,"servation of the meaning is not even always achieved. Therefore a manual post-processing of the texts has to be done. The concept of interactive machine translation already has a long history, and the first systems appeared in the end of the 1960’s. However in most of these systems the user doesn’t have a direct control over the translation process, and most of the user interaction is reduced to performing source language disambiguation on demand. The approach we center on in this work was first suggested by (Foster et al., 1996) and an implementation was carried out in the TransType project (Langlais et al., 2000). In such an environment, human translators interact with a translation system that acts as an assistance tool and dynamically provides a list of translations that best complete the part of the source senEAMT 2005 Conference Proceedings tence already translated. Further refinements were presented in the TransType2 project (SchlumbergerSema S.A. et al., 2001). The work presented in this paper deals with generation strategies for interactive (statistical) machine translation systems. Clearly, the best approach would be to start a new search for every given prefix. However, in these kind of syste"
2005.eamt-1.6,E03-1032,1,0.906128,"rent way, as it itself can be a prefix of the next word. To ensure the extensions start with this word prefix, the comparison must be done at the character level. One might think about different costs for the mismatch of words within the prefix and for extensions which do not start with the given word prefix. If a word within the prefix can not be produced by the search algorithm, then it will obviously not be produced by any further search call. This kind of substitution error is less harmful for producing good hypotheses than unfitting extensions, and should therefore be penalized less. In (Och et al., 2003), an efficient algorithm for interactive generation using word graphs was presented. A word graph is a weighted directed acyclic graph, in which each node represents a partial translation hypothesis and each edge is labeled with a word of the target sentence and is weighted according to the language and translation model scores. (Ueffing et al., 2002) give a more detailed description of word graphs and show how they can be easily produced as a sub-product of the search process. An example of a word graph is shown in Figure 2. It is clear that each node in the word graph defines a prefix of a p"
2005.eamt-1.6,W02-1021,1,0.904238,"that have the same word prefix. In the actual implementation, the method is applied on the character level, and the search for an extension is performed after each keystroke of the human translator. The crucial factor is an efficient maximization of Eq. 3, because human translators will only accept response times of fractions of a second. Using state-of-the-art search algorithms this is not 34 achievable without putting up with an unacceptable amount of search errors. To overcome this problem, we can compute a word graph which represents a subset of possible extensions (Ney and Aubert, 1994; Ueffing et al., 2002). The generation is then constrained to this set of extensions. 3 Phrase-based Approach The base method we use in our translation system is the alignment template approach as described in (Och et al., 1999; Och and Ney, 2004). This approach uses the so-called alignment templates, which are pairs of source and target language phrases1 together with the word alignment within the phrases. The alignment templates are introduced as hidden variables z1K when modelling the conditional translation probability Pr(f1J |eI1 ): Pr(f1J |eI1 ) =  I K K I Pr(aK 1 |e1 ) · Pr(z1 |a1 , e1 )· z1K ,aK 1 I Pr(f1J"
2005.eamt-1.6,J04-4002,1,0.629855,"icient maximization of Eq. 3, because human translators will only accept response times of fractions of a second. Using state-of-the-art search algorithms this is not 34 achievable without putting up with an unacceptable amount of search errors. To overcome this problem, we can compute a word graph which represents a subset of possible extensions (Ney and Aubert, 1994; Ueffing et al., 2002). The generation is then constrained to this set of extensions. 3 Phrase-based Approach The base method we use in our translation system is the alignment template approach as described in (Och et al., 1999; Och and Ney, 2004). This approach uses the so-called alignment templates, which are pairs of source and target language phrases1 together with the word alignment within the phrases. The alignment templates are introduced as hidden variables z1K when modelling the conditional translation probability Pr(f1J |eI1 ): Pr(f1J |eI1 ) =  I K K I Pr(aK 1 |e1 ) · Pr(z1 |a1 , e1 )· z1K ,aK 1 I Pr(f1J |z1K , aK 1 , e1 ) . (4) In Equation (4), we introduce the additional hidden variables aK 1 that model the alignment of the alignment templates themselves. As smoothing, automatically trained word classes can be used, and ad"
2005.eamt-1.6,W99-0604,1,0.787605,"l factor is an efficient maximization of Eq. 3, because human translators will only accept response times of fractions of a second. Using state-of-the-art search algorithms this is not 34 achievable without putting up with an unacceptable amount of search errors. To overcome this problem, we can compute a word graph which represents a subset of possible extensions (Ney and Aubert, 1994; Ueffing et al., 2002). The generation is then constrained to this set of extensions. 3 Phrase-based Approach The base method we use in our translation system is the alignment template approach as described in (Och et al., 1999; Och and Ney, 2004). This approach uses the so-called alignment templates, which are pairs of source and target language phrases1 together with the word alignment within the phrases. The alignment templates are introduced as hidden variables z1K when modelling the conditional translation probability Pr(f1J |eI1 ): Pr(f1J |eI1 ) =  I K K I Pr(aK 1 |e1 ) · Pr(z1 |a1 , e1 )· z1K ,aK 1 I Pr(f1J |z1K , aK 1 , e1 ) . (4) In Equation (4), we introduce the additional hidden variables aK 1 that model the alignment of the alignment templates themselves. As smoothing, automatically trained word classes"
2005.iwslt-1.18,P03-1021,0,0.0418797,"0]. A phrase is a contiguous sequence of words. The pairs of source and target phrases are extracted from the training corpus and used in the translation. The phrase translation probability P r(eI1 |f1J ) is modeled directly using a weighted log-linear combination of a trigram language model and various translation models: a phrase translation model and a word-based lexicon model. These translation models are used for both directions: p(f |e) and p(e|f ). Additionally, we use a word penalty and a phrase penalty. The model scaling factors are optimized with respect to some evaluation criterion [11]. 1 The notational convention will be as follows: we use the symbol P r(·) to denote general probability distributions with (nearly) no specific assumptions. In contrast, for model-based probability distributions, we use the generic symbol p(·). 3. Segmentation methods 3.1. Conventional segmentation methods In this section, we give a short overview of the current Chinese word segmentation methods in statistical machine translation, most of these methods can be classified into three categories: • The training and test texts are segmented with an automatic segmentation tool. Many segmentation to"
2005.iwslt-1.18,W04-1118,1,0.652012,"may contain some errors, and we also found that a much more accurate word segmentation does not always lead to a large improvement in the translation performance. • The training and test texts are segmented manually. Manual segmentation avoids segmentation errors but requires a human effort. Moreover, the correct segmentation will not result in the best translation result, if the segmentations in the test and training sets are inconsistent. • Each Chinese character is treated as a word Training and translation at the Chinese character level do not require additional tool or human effort. But [1] showed that the translation results are not so good as the results obtained when translation is at the word level. To minimize the number of lexicon entries and to ensure the consistency of the segmentations in the training and in the translation, we developed a new segmentation method, which uses the training text at the word level and translate the test text at the character level. 3.2. Idea Figure 1 shows the translation procedures. With the conventional method, only a single-best word segmentation is transferred to the search for the best translation. This approach is not ideal because th"
2005.iwslt-1.18,P02-1040,0,0.101372,"ed word segmentation in the translation, we only need to read segmentation lattice in Figure 3 instead of the manual segmented sentence. 4.2. Evaluation criteria ?:? xu:xu shou:shou ji:ji deng:deng li:li na:nali ban:ban li:eps li:li na:na ban:banli zai:zai li:eps 0 deng:dengji ji:eps shou:shouxu xu:eps 1 2 3 4 Figure 5: Segmentation transducer. So far, in machine translation research, a single generally accepted criterion for the evaluation of the experimental results does not exist. Therefore, we used different criteria: WER (word error rate), PER (position-independent word error rate), BLEU [12] and NIST [13]. For the evaluation corpus, we have sixteen references available. The four criteria are computed with respect to multiple references. The evaluation was case-insensitive. The BLEU and NIST scores measure accuracy, i.e. larger scores are better. 4.3. Evaluation results We present the translation results on the IWSLT 2005 task [4] described in Section 4.1. The experiments are based on two translation systems: • Finite-state transducer-based translation 3.5. Weighting with language model costs A problem of translation with the lattice in Figure 3 is that shorter paths are usually p"
2005.iwslt-1.18,P96-1019,0,0.0862748,"Missing"
2005.iwslt-1.18,J90-2002,0,0.555513,"on 4. 2. Statistical machine translation system 2.1. Bayes decision rule In statistical machine translation, we are given a source language sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language sentence eI1 = e1 . . . ei . . . eI . Among all possible target language sentences, we will choose the sentence with the highest probability: © ª ˆ eˆI1 = argmax P r(eI1 |f1J ) (1) eI1 ,I = argmax eI1 ,I © P r(eI1 ) · P r(f1J |eI1 ) ª (2) The decomposition into two knowledge sources in Equation 2 is known as the source-channel approach to statistical machine translation [5]. It allows an independent modelSingle-best segmentation: T ext / Segmentation: Equation 3 Segmentation lattice: T ext / Global decision: Equation 6 / Decision: Equation 5 / T ranslation / T ranslation Figure 1: Segmentation methods ing of the target language model P r(eI1 ) and the translation model P r(f1J |eI1 )1 . In our system, the translation model is trained on a bilingual corpus using GIZA++ [6], and the language model is trained with the SRILM toolkit [7]. 2.2. Weighted finite-state transducer-based translation We use the weighted finite-state tool by [8]. A weighted finite-state tran"
2005.iwslt-1.18,J03-1002,1,0.011191,") eI1 ,I = argmax eI1 ,I © P r(eI1 ) · P r(f1J |eI1 ) ª (2) The decomposition into two knowledge sources in Equation 2 is known as the source-channel approach to statistical machine translation [5]. It allows an independent modelSingle-best segmentation: T ext / Segmentation: Equation 3 Segmentation lattice: T ext / Global decision: Equation 6 / Decision: Equation 5 / T ranslation / T ranslation Figure 1: Segmentation methods ing of the target language model P r(eI1 ) and the translation model P r(f1J |eI1 )1 . In our system, the translation model is trained on a bilingual corpus using GIZA++ [6], and the language model is trained with the SRILM toolkit [7]. 2.2. Weighted finite-state transducer-based translation We use the weighted finite-state tool by [8]. A weighted finite-state transducer (Q, Σ ∪ {}, Ω ∪ {}, K, E, i, F, λ, ρ) is a structure with a set of states Q, an alphabet of input symbols Σ, an alphabet of output symbols Ω, a weight semiring K, a set of arcs E, a single initial state i with weight λ and a set of final states F weighted by the function ρ : F → K. A weighted finite-state acceptor is a weighted finite-state transducer without the output alphabet. A composition"
2005.iwslt-1.18,P04-1065,1,0.420284,"atistical machine translation [5]. It allows an independent modelSingle-best segmentation: T ext / Segmentation: Equation 3 Segmentation lattice: T ext / Global decision: Equation 6 / Decision: Equation 5 / T ranslation / T ranslation Figure 1: Segmentation methods ing of the target language model P r(eI1 ) and the translation model P r(f1J |eI1 )1 . In our system, the translation model is trained on a bilingual corpus using GIZA++ [6], and the language model is trained with the SRILM toolkit [7]. 2.2. Weighted finite-state transducer-based translation We use the weighted finite-state tool by [8]. A weighted finite-state transducer (Q, Σ ∪ {}, Ω ∪ {}, K, E, i, F, λ, ρ) is a structure with a set of states Q, an alphabet of input symbols Σ, an alphabet of output symbols Ω, a weight semiring K, a set of arcs E, a single initial state i with weight λ and a set of final states F weighted by the function ρ : F → K. A weighted finite-state acceptor is a weighted finite-state transducer without the output alphabet. A composition algorithm is defined as: Let T1 : Σ∗ × Ω → K and T2 : Ω∗ × Γ∗ → K be two transducers defined over the same semiring K. Their composition T1 ◦T2 realizes the functio"
2005.iwslt-1.18,N04-1033,1,0.737334,"by the function ρ : F → K. A weighted finite-state acceptor is a weighted finite-state transducer without the output alphabet. A composition algorithm is defined as: Let T1 : Σ∗ × Ω → K and T2 : Ω∗ × Γ∗ → K be two transducers defined over the same semiring K. Their composition T1 ◦T2 realizes the function T : Σ∗ × Γ∗ → K. ∗ By using the structure of the weighted finite-state transducers, the translation model is simply estimated as the language model on a bilanguage of source phrase/target phrase tuples, see [9]. 2.3. Phrase-based translation The phrase-based translation model is described in [10]. A phrase is a contiguous sequence of words. The pairs of source and target phrases are extracted from the training corpus and used in the translation. The phrase translation probability P r(eI1 |f1J ) is modeled directly using a weighted log-linear combination of a trigram language model and various translation models: a phrase translation model and a word-based lexicon model. These translation models are used for both directions: p(f |e) and p(e|f ). Additionally, we use a word penalty and a phrase penalty. The model scaling factors are optimized with respect to some evaluation criterion [1"
2005.iwslt-1.19,2001.mtsummit-papers.68,0,0.136167,"h the human judgement at least as well as the evaluation measures which are based on manual sentence boundaries. 1. Introduction Evaluation of the produced results is crucial for natural language processing (NLP) research in general and, in particular for machine translation (MT). Human evaluation of MT system output is a time consuming and expensive task. This is why automatic evaluation is preferred to human evaluation in the research community. A variety of automatic evaluation measures have been proposed and studied over the last years. All of the wide-spread evaluation measures like BLEU [1], NIST [2], and word error rate compare translation hypotheses with human reference translations. Since a human translator usually translates one sentence of a source language text at a time, all of these measures include the concept of sentences, or more generally, segments1 . Each evaluation algorithm expects that a machine translation system will produce exactly one target language segment for each source language segment. Thus, the total number of segments in the automatically translated document must be equal to the number of reference segments in the manually translated document. In case"
2005.iwslt-1.19,W05-0903,1,0.810929,"same number of segments, where each segment is a translation of the “correct” segmentation of the manually transcribed speech input2 . If the segmentation of the MT output corresponds to the segmentation of the manual reference translations, then for each candidate segerk . Let Ik denote ment Ek , we have R reference sentences E the length of a candidate segment Ek , and Nrk the reference erk . From the reference lengths of each reference segment E lengths, an optimal reference segment length Nk∗ is selected as the length of the reference with the lowest segment-level error rate or best score [4]. With this, we write P the total candidate length over the document as I := k Ik , and the total reference length as P N ∗ := k Nk∗ . 2.1. W ER The segment-level word error rate is defined as the Levenerk ) between a candidate segment shtein distance dL (Ek , E erk , divided by the reference Ek and a reference segment E length Nk∗ for normalization. For a whole candidate corpus with multiple references, the segment-level scores are combined, and the W ER is defined to be: ¡ ¢ 1 X erk W ER := ∗ min dL Ek , E r N (1) k In this paper, we also evaluate MT output at document level. When evaluating"
2005.iwslt-1.19,2004.iwslt-evaluation.1,0,0.0265168,"ndaries from the candidate translations and determined the segmentation automatically using the Levenshtein distance based algorithm as described in Section 3. As a consequence of the alignment procedure we obtained the AS-WER. In addition, using the resulting automatic segmentation which corresponds to the segmentation of the reference documents, we recomputed the other evaluation measures. In the following, we denote these measures by AS-PER, AS-BLEU, and AS-NIST. We calculated the evaluation measures on two different tasks. The first task is the IWSLT BTEC 2004 Chinese-toEnglish evaluation [8]. Here, we evaluated translation output of twenty MT systems which had participated in this public evaluation. The evaluation was case-insensitive, and the translation hypotheses and references did not include punctuation marks. Additionally, we scored the translations of four MT systems from different research groups which took part in the first MT evaluation in the framework of the European research project TC-STAR [9]. We addressed only the condition of translating verbatim (exactly transcribed) speech from Spanish to English. Here, the evaluation was case-sensitive, but again without consi"
2005.iwslt-1.19,P02-1040,0,\N,Missing
2005.iwslt-1.20,1998.amta-tutorials.6,0,0.566661,"Missing"
2005.iwslt-1.20,J90-2002,0,0.695619,". Additionally, we translated Chinese ASR lattices. 1.1. Source-channel approach to SMT In statistical machine translation, we are given a source language sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language sentence eI1 = e1 . . . ei . . . eI . Among all possible target language sentences, we will choose the sentence with the highest probability: © ª ˆ eˆI1 = argmax P r(eI1 |f1J ) (1) I,eI1 = argmax I,eI1 © P r(eI1 ) · P r(f1J |eI1 ) ª (2) This decomposition into two knowledge sources is known as the source-channel approach to statistical machine translation [1]. It allows an independent modeling of the target language model P r(eI1 ) and the translation model P r(f1J |eI1 )1 . The target language model describes the well-formedness of the target language sentence. The translation model links the source language sentence to the target language sentence. The argmax operation denotes the search problem, i.e., the generation of the output sentence in the target language. 1.2. Log-linear model 1. Introduction We give an overview of the RWTH phrase-based statistical machine translation system that was used in the evaluation campaign of the International W"
2005.iwslt-1.20,P02-1038,1,0.79314,"ll review the statistical approach to machine translation and introduce the notation that we will use in the later sections. Then, we will describe the models and algorithms that are used for generating the N -best lists, i.e., the first pass. In Section 4, we will describe the models that are used to rescore and rerank this N -best list, i.e., the second pass. Afterward, we will give an overview of the tasks and discuss the experimental results. An alternative to the classical source-channel approach is the direct modeling of the posterior probability P r(eI1 |f1J ). Using a log-linear model [2], we obtain: ´ P M J I ) , f exp λ h (e m m 1 1 m=1 P ´ P r(eI1 |f1J ) = P (3) M J 0I0 exp m=1 λm hm (e 1 , f1 ) e0 I1 0 The denominator represents a normalization factor that depends only on the source sentence f1J . Therefore, we can omit it during the search process. As a decision rule, we obtain: ( M ) X ˆ eˆI1 = argmax λm hm (eI1 , f1J ) (4) I,eI1 1 The m=1 notational convention will be as follows: we use the symbol P r(·) to denote general probability distributions with (nearly) no specific assumptions. In contrast, for model-based probability distributions, we use the generic symbol p"
2005.iwslt-1.20,P03-1021,0,0.0758006,"follows: we use the symbol P r(·) to denote general probability distributions with (nearly) no specific assumptions. In contrast, for model-based probability distributions, we use the generic symbol p(·). This approach is a generalization of the source-channel approach. It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM 1 are trained according to the maximum entropy principle, e.g., using the GIS algorithm. Alternatively, one can train them with respect to the final translation quality measured by an error criterion [3]. For the IWSLT evaluation campaign, we optimized the scaling factors with respect to a linear interpolation of WER, PER, BLEU and NIST using the Downhill Simplex algorithm from [4]. 1.3. Phrase-based approach The basic idea of phrase-based translation is to segment the given source sentence into phrases, then translate each phrase and finally compose the target sentence from these phrase translations. This idea is illustrated in Figure 1. Formally, we define a segmentation of a given sentence pair (f1J , eI1 ) into K blocks: k → sk := (ik ; bk , jk ), for k = 1 . . . K. (5) Here, ik denotes t"
2005.iwslt-1.20,2002.tmi-tutorials.2,0,0.161904,"get sentence are covered by exactly one phrase. Thus, there are no gaps and there is no overlap. For a given sentence pair (f1J , eI1 ) and a given segmentation sK 1 , we define the bilingual phrases as: e˜k f˜k := eik−1 +1 . . . eik (6) := fbk . . . fjk (7) target positions I = i4 i3 2. Search algorithms The RWTH phrase-based system supports two alternative search strategies that will be described in this section. Translating a source language word graph. The first search strategy that our system supports takes a source language word graph as input and translates this graph in a monotone way [5]. The input graph can represent different reorderings of the input sentence so that the overall search can generate nonmonotone translations. Using this approach, it is very simple to experiment with various reordering constraints, e.g., the constraints proposed in [6]. Alternatively, we can use ASR lattices as input and translate them without changing the search algorithm, cf. [7]. A disadvantage when translating lattices with this method is that the search is monotone. To overcome this problem, we extended the monotone search algorithm from [5, 7] so that it is possible to reorder the target"
2005.iwslt-1.20,W05-0831,1,0.219539,"itions I = i4 i3 2. Search algorithms The RWTH phrase-based system supports two alternative search strategies that will be described in this section. Translating a source language word graph. The first search strategy that our system supports takes a source language word graph as input and translates this graph in a monotone way [5]. The input graph can represent different reorderings of the input sentence so that the overall search can generate nonmonotone translations. Using this approach, it is very simple to experiment with various reordering constraints, e.g., the constraints proposed in [6]. Alternatively, we can use ASR lattices as input and translate them without changing the search algorithm, cf. [7]. A disadvantage when translating lattices with this method is that the search is monotone. To overcome this problem, we extended the monotone search algorithm from [5, 7] so that it is possible to reorder the target phrases. We implemented the following idea: while traversing the input graph, a phrase can be skipped and processed later. Source cardinality synchronous search. For singleword based models, this search strategy is described in [8]. The idea is that the search proceed"
2005.iwslt-1.20,J03-1005,1,0.786355,"s, e.g., the constraints proposed in [6]. Alternatively, we can use ASR lattices as input and translate them without changing the search algorithm, cf. [7]. A disadvantage when translating lattices with this method is that the search is monotone. To overcome this problem, we extended the monotone search algorithm from [5, 7] so that it is possible to reorder the target phrases. We implemented the following idea: while traversing the input graph, a phrase can be skipped and processed later. Source cardinality synchronous search. For singleword based models, this search strategy is described in [8]. The idea is that the search proceeds synchronously with the cardinality of the already translated source positions. Here, we use a phrase-based version of this idea. To make the search problem feasible, the reorderings are constrained as in [9]. Word graphs and N -best lists. The two described search algorithms generate a word graph containing the most likely translation hypotheses. Out of this word graph we extract N -best lists. For more details on word graphs and N best list extraction, see [10, 11]. 3. Models used during search i2 i1 0 = i0 0 = j 0 j2 b2 b1 only on the sentence pair (f1J"
2005.iwslt-1.20,C04-1030,1,0.855321,"To overcome this problem, we extended the monotone search algorithm from [5, 7] so that it is possible to reorder the target phrases. We implemented the following idea: while traversing the input graph, a phrase can be skipped and processed later. Source cardinality synchronous search. For singleword based models, this search strategy is described in [8]. The idea is that the search proceeds synchronously with the cardinality of the already translated source positions. Here, we use a phrase-based version of this idea. To make the search problem feasible, the reorderings are constrained as in [9]. Word graphs and N -best lists. The two described search algorithms generate a word graph containing the most likely translation hypotheses. Out of this word graph we extract N -best lists. For more details on word graphs and N best list extraction, see [10, 11]. 3. Models used during search i2 i1 0 = i0 0 = j 0 j2 b2 b1 only on the sentence pair (f1J , eI1 ), but also on the segmentaJ I K tion sK 1 , i.e., we have models h(f1 , e1 , s1 ). j1 j3 j4 = J b3 b4 source positions Figure 1: Illustration of the phrase segmentation. Note that the segmentation sK 1 contains the information on the phra"
2005.iwslt-1.20,W05-0834,1,0.835929,"rdinality synchronous search. For singleword based models, this search strategy is described in [8]. The idea is that the search proceeds synchronously with the cardinality of the already translated source positions. Here, we use a phrase-based version of this idea. To make the search problem feasible, the reorderings are constrained as in [9]. Word graphs and N -best lists. The two described search algorithms generate a word graph containing the most likely translation hypotheses. Out of this word graph we extract N -best lists. For more details on word graphs and N best list extraction, see [10, 11]. 3. Models used during search i2 i1 0 = i0 0 = j 0 j2 b2 b1 only on the sentence pair (f1J , eI1 ), but also on the segmentaJ I K tion sK 1 , i.e., we have models h(f1 , e1 , s1 ). j1 j3 j4 = J b3 b4 source positions Figure 1: Illustration of the phrase segmentation. Note that the segmentation sK 1 contains the information on the phrase-level reordering. The segmentation sK 1 is introduced as a hidden variable in the translation model. Therefore, it would be theoretically correct to sum over all possible segmentations. In practice, we use the maximum approximation for this sum. As a result, t"
2005.iwslt-1.20,W02-1021,1,0.799925,"rdinality synchronous search. For singleword based models, this search strategy is described in [8]. The idea is that the search proceeds synchronously with the cardinality of the already translated source positions. Here, we use a phrase-based version of this idea. To make the search problem feasible, the reorderings are constrained as in [9]. Word graphs and N -best lists. The two described search algorithms generate a word graph containing the most likely translation hypotheses. Out of this word graph we extract N -best lists. For more details on word graphs and N best list extraction, see [10, 11]. 3. Models used during search i2 i1 0 = i0 0 = j 0 j2 b2 b1 only on the sentence pair (f1J , eI1 ), but also on the segmentaJ I K tion sK 1 , i.e., we have models h(f1 , e1 , s1 ). j1 j3 j4 = J b3 b4 source positions Figure 1: Illustration of the phrase segmentation. Note that the segmentation sK 1 contains the information on the phrase-level reordering. The segmentation sK 1 is introduced as a hidden variable in the translation model. Therefore, it would be theoretically correct to sum over all possible segmentations. In practice, we use the maximum approximation for this sum. As a result, t"
2005.iwslt-1.20,N04-1033,1,0.843447,"tion. Note that the segmentation sK 1 contains the information on the phrase-level reordering. The segmentation sK 1 is introduced as a hidden variable in the translation model. Therefore, it would be theoretically correct to sum over all possible segmentations. In practice, we use the maximum approximation for this sum. As a result, the models h(·) depend not We use a log-linear combination of several models (also called feature functions). In this section, we will describe the models that are used in the first pass, i.e., during search. This is an improved version of the system described in [12]. More specifically the models are: a phrase translation model, a word-based translation model, a deletion model, word and phrase penalty, a target language model and a reordering model. 3.1. Phrase-based model The phrase-based translation model is the main component of our translation system. The hypotheses are generated by concatenating target language phrases. The pairs of source and corresponding target phrases are extracted from the wordaligned bilingual training corpus. The phrase extraction algorithm is described in detail in [5]. The main idea is to extract phrase pairs that are consis"
2005.iwslt-1.20,W99-0604,1,0.92093,"del The phrase-based translation model is the main component of our translation system. The hypotheses are generated by concatenating target language phrases. The pairs of source and corresponding target phrases are extracted from the wordaligned bilingual training corpus. The phrase extraction algorithm is described in detail in [5]. The main idea is to extract phrase pairs that are consistent with the word alignment. Thus, the words of the source phrase are aligned only to words in the target phrase and vice versa. This criterion is identical to the alignment template criterion described in [13]. We use relative frequencies to estimate the phrase translation probabilities: p(f˜|˜ e) = N (f˜, e˜) N (˜ e) (8) Here, the number of co-occurrences of a phrase pair (f˜, e˜) that are consistent with the word alignment is denoted as N (f˜, e˜). If one occurrence of a target phrase e˜ has N &gt; 1 possible translations, each of them contributes to N (f˜, e˜) with 1/N . The marginal count N (˜ e) is the number of occurrences of the target phrase e˜ in the training corpus. The resulting feature function is: hPhr (f1J , eI1 , sK 1 ) = log K Y p(f˜k |˜ ek ) (9) The word translation probabilities p(f"
2005.iwslt-1.20,2004.iwslt-evaluation.13,1,0.873901,", eI1 , sK 1 ) = log jk K Y Y ik X p(fj |ei ) (10) k=1 j=bk i=ik−1 +1 The word translation probabilities p(f |e) are estimated as relative frequencies from the word-aligned training corpus. The word-based lexicon model is also used in both directions p(f |e) and p(e|f ). 3.3. Deletion model The deletion model [14] is designed to penalize hypotheses that miss the translation of a word. For each source word, we check if a target word with a probability higher than a given threshold τ exists. If not, this word is considered a deletion. The feature simply counts the number of deletions. Last year [15], we used this model during rescoring only, whereas this year, we integrated a within-phrase variant of the deletion model into the search: hDel (f1J , eI1 , sK 1 )= jk K X X ik Y k=1 j=bk i=ik−1 +1 [ p(fj |ei ) &lt; τ ] (11) 3.5. Target language model We use the SRI language modeling toolkit [17] to train a standard n-gram language model. The smoothing technique we apply is the modified Kneser-Ney discounting with interpolation. The order of the language model depends on the translation direction. For most tasks, we use a trigram model, except for Chinese-English, where we use a fivegram languag"
2005.iwslt-1.20,2005.eamt-1.17,1,0.801958,"techniques need specialized tools which traverse the graph appropriately. Additionally, because a node within a word graph allows for many histories, one can only apply local rescoring techniques, whereas for N -best lists, techniques can be used that consider properties of the whole target sentence. In the next sections, we will present several rescoring techniques. 4.1. Clustered language models One of the first ideas in rescoring is to use additional language models that were not used in the generation procedure. In our system, we use clustered language models based on regular expressions [18]. Each hypothesis is classified by matching it to regular expressions that identify the type of the sentence. Then, a cluster-specific (or sentence-type-specific) language model is interpolated into a global language model to compute the score of the sentence: hCLM (f1J , eI1 ) = (17) X£ ¤¡ ¢ I I I log Rc (e1 ) αc pc (e1 ) + (1 − αc )pg (e1 ) , c pg (eI1 ) I where is the global language ¤ pc (e1 ) the £ model, I cluster-specific language model, and Rc (e1 ) denotes the true-or-false statement (cf. Equation 12) which is 1 if the cth regular expression Rc (·) matches the target sentence eI1 and"
2005.iwslt-1.20,J03-1002,1,0.116578,"τ . In the experiments, τ was chosen between 10−1 and 10−4 . 4.4. Hidden Markov alignment model The next step after IBM model 1 rescoring is HMM rescoring. We use the HMM to compute the log-likelihood of a 2 The clusters are disjunct, thus only one regular expression matches. sentence pair (f1J , eI1 ): hHMM (f1J , eI1 ) = log J XY ¡ p(aj |aj−1 , I) · p(fj |eaj ) ¢ j=1 aJ 1 (20) In our experiments, we use a refined alignment probability p(aj − aj−1 |G(eaj ), I) that conditions the jump widths of the alignment positions aj − aj−1 on the word class G(eaj ). This is the so-called homogeneous HMM [19]. 4.5. Word penalties Several word penalties are used in the rescoring step:  (a)  I I/J (b) hWP (f1J , eI1 ) =  2|I − J|/(I + J) (c) (21) The word penalties are heuristics that affect the generated hypothesis length. In general, sentences that are too short should be avoided. 5. Integrating ASR and MT In the experiments on coupling speech recognition and machine translation, we used the phrase-based MT system described in Section 2 to translate ASR lattices. In addition to the models described in Section 3, we use the acoustic model and the source language model of the ASR system in the lo"
2005.iwslt-1.20,takezawa-etal-2002-toward,0,0.0815201,"g speech recognition and translation is the mismatch between the vocabularies of the ASR and MT system. For the Chinese-English task, the number of out-of-vocabulary (OOV) words was rather high. Ideally, the vocabulary of the recognition system should be a subset of the translation system source vocabulary. In the IWSLT evaluation, we had no control over the recognition experiments. For this reason, the reported improvements might have been larger with a proper handling of the vocabularies. 6. Tasks and corpora The experiments were carried out on the Basic Travel Expression Corpus (BTEC) task [20]. This is a multilingual speech corpus which contains tourism-related sentences similar to those that are found in phrase books. The corpus statistics are shown in Table 1. For the supplied data track, 20 000 sentences training corpus and two test sets (C-Star’03 and IWSLT’04) were made available for each language pair. As additional training resources for the C-Star track, we used the full BTEC for Japanese-English and the Spoken Language DataBase (SLDB) [21], which consists of transcriptions of spoken dialogs in the domain of hotel reservations3 . 3 The Japanese-English training corpora (BTE"
2005.iwslt-1.20,P02-1040,0,0.119193,"Missing"
2005.iwslt-1.20,W05-0909,0,0.0806623,"Missing"
2005.iwslt-1.20,2003.mtsummit-papers.51,0,0.106807,"Missing"
2005.mtsummit-invited.5,H94-1028,0,0.0449536,"o manually design rules and knowledge sources for these operations. There are two open problems with this concept: i - 12 1. How can we get hold of all the rules and make sure that we know all the rules that the system needs? 2. How can we achieve a coherent and consistent interaction of all these rules when generating the target sentence? Both problems are elegantly addressed in the statistical approach. Instead of using hard rules, we make use of probability distributions that serve as probabilistic knowledge sources. In the baseline version of the statistical approach as introduced by IBM (Berger et al. 1994; Brown et al. 1993), the translation task can be expressed as follows. We are given a sentence F in the source language and we want to generate the corresponding target sentence E. For this purpose, we consider the associated posterior distribution p(F |E) of all possible ˆ ) pairs (F, E) and select the target sentence E(F with the highest posterior probability: ˆ ) = arg max{p(E|F )} F → E(F E = arg max{p(E) · p(F |E)} E which is referred to as Bayes decision rule. In the second equation, the posterior probability p(F |E) has been replaced by the joint probability p(E, F ) which is written a"
2005.mtsummit-invited.5,J93-2003,0,0.155176,"les and knowledge sources for these operations. There are two open problems with this concept: i - 12 1. How can we get hold of all the rules and make sure that we know all the rules that the system needs? 2. How can we achieve a coherent and consistent interaction of all these rules when generating the target sentence? Both problems are elegantly addressed in the statistical approach. Instead of using hard rules, we make use of probability distributions that serve as probabilistic knowledge sources. In the baseline version of the statistical approach as introduced by IBM (Berger et al. 1994; Brown et al. 1993), the translation task can be expressed as follows. We are given a sentence F in the source language and we want to generate the corresponding target sentence E. For this purpose, we consider the associated posterior distribution p(F |E) of all possible ˆ ) pairs (F, E) and select the target sentence E(F with the highest posterior probability: ˆ ) = arg max{p(E|F )} F → E(F E = arg max{p(E) · p(F |E)} E which is referred to as Bayes decision rule. In the second equation, the posterior probability p(F |E) has been replaced by the joint probability p(E, F ) which is written as the product of the"
2005.mtsummit-invited.5,J04-2004,0,0.0149759,"hm) Testing Output Figure 2: Tasks in statistical MT. at some national levels, the European level and the international level (C-Star, ATR, Verbmobil, Eutrans, LC-Star, PF-Star, TCStar, ...). Apart from the project TCStar, which started only recently, all these projects addressed translation tasks with rather limited domains (like traveling and tourism) and medium-sized vocabularies (about 10 000 words). The best performing translation systems are based on various types of statistical approaches (Och and Ney 2002) including example-based methods (Sumita et al. 2003), finite-state transducers (Casacuberta and Vidal 2004) and other data driven approaches. This is the characteristic and most striking result of the various projects. A similar experience was made for written language translation. Within the US Tides program, the goal of the MT project was to translate news articles from Chinese to English and from Arabic to English, which implied large vocabularies (80 000 and more words) and rather unrestricted domains. In the evaluations, it was found that, due to the recent improvements, the statistical approach was able to produce competitive or superior results in comparison with conventional translation sys"
2005.mtsummit-invited.5,koen-2004-pharaoh,0,0.0232396,"e extraction of bilingual phrases after the alignment-lexicon models (like IBM and HMM) have been trained. i - 15 In other words, the phrase-based models are not yet incorporated into the iterative training procedure. It is interesting to note that this extraction of phrase pairs shows a certain similarity to memory-based translation. The important difference, however, is that in statistical MT these pairs are extracted automatically. • efficient algorithms for generation: To generate the target sentence, various strategies have been studied like A∗ search and dynamic programming beam search (Koehn 2004; Tillmann and Ney 2003). In the experimental tests, dynamic programming beam search has been found to be much more efficient than a (pure) A∗ strategy. Typically, this beam search strategy works by processing the source positions in a left-to-right fashion and allowing word re-orderings to a certain degree. Furthermore, these search strategies have been extended to produce word lattices and N-best lists rather than only the single best sentence. • log-linear model combinations and rescoring: The baseline models in statistical translation are the lexicon model, the alignment model and the lang"
2005.mtsummit-invited.5,N03-1017,0,0.0136105,"anged in order to improve the quality of the final word alignments. • context dependent or phrase-based lexicon models: The original alignment-lexicon models (Brown et al. 1993) do not take into account the context in which both the source and the target words appear. There is an evident need to introduce more context dependencies into these models, e.g. by handling word groups and phrases rather than single words. There have been a number of successful extensions that move away from single words and handle word groups in both the source and target language (Och et al. 1999; Zens et al. 2002; Koehn et al. 2003; Och and Ney 2004). Typically, these extensions seem to be limited to the extraction of bilingual phrases after the alignment-lexicon models (like IBM and HMM) have been trained. i - 15 In other words, the phrase-based models are not yet incorporated into the iterative training procedure. It is interesting to note that this extraction of phrase pairs shows a certain similarity to memory-based translation. The important difference, however, is that in statistical MT these pairs are extracted automatically. • efficient algorithms for generation: To generate the target sentence, various strategi"
2005.mtsummit-invited.5,N04-1022,0,0.0334773,"neral point of view, there are four tasks to be addressed in the statistical approach as illustrated in Fig. 2: • error measure and decision rule: Bayes decision rule is based on minimizing the so-called posterior risk which requires a quantitative error measure or cost function. In statistical MT (as in speech recognition), the traditional error measure is the 0/1loss function that minimizes the sentence error rate but not necessarily the error measures used in translation like WER, PER and BLEU (see later). This type of inconsistency is not addressed in the literature with the exception of (Kumar and Byrne 2004). Furthermore, some applications of machine translation require criteria at the word level (like confidence Data measures (Ueffing et al. 2003)) rather than at the sentence level. • probability models: The probability models are used to replace the true but unknown probability distributions in Bayes decision rule. Their ultimate goal is to provide the link between the input data (source sentence) and the output data (target sentence) that have to be produced by the translation system. It is exactly here where linguistic knowledge will be helpful to come up with better models in the future. • t"
2005.mtsummit-invited.5,J04-2003,1,0.828752,"slation Models. While the alignment approach introduced in (Brown et al. 1993) does not make use of any syntactic concepts, there were attempts at introducing explicit syntactic structures into the statistical translation models (Alshawi et al. 2000; Wu 1997; Yamada and Knight 2001). In such a way, it is expected that the difference in the word order between target and source sentences can be better taken into account. At present, these syntax-based extensions do not (yet) seem to pay off in terms of performance. In addition, the syntactic approach could also include a morphological analysis (Nießen and Ney 2004) so that the statistical approach could go beyond the usual full forms of words. Speech Translation. The translation of spoken language requires the combination of two operations, namely the recognition of the spoken source sentence and its translation into the target sentence. Thus, we are faced with the additional problem of finding a suitable integration of recognition and translation. While the principles of this integration are more or less well known (Ney 1999), in practice most systems only make use of N-best lists, which however do not seem to improve performance. Interactive MT. What"
2005.mtsummit-invited.5,P02-1038,1,0.825846,"n (+ eff. algorithm) Training parameter estimates Probability Models Decision Rule (+ eff. algorithm) Testing Output Figure 2: Tasks in statistical MT. at some national levels, the European level and the international level (C-Star, ATR, Verbmobil, Eutrans, LC-Star, PF-Star, TCStar, ...). Apart from the project TCStar, which started only recently, all these projects addressed translation tasks with rather limited domains (like traveling and tourism) and medium-sized vocabularies (about 10 000 words). The best performing translation systems are based on various types of statistical approaches (Och and Ney 2002) including example-based methods (Sumita et al. 2003), finite-state transducers (Casacuberta and Vidal 2004) and other data driven approaches. This is the characteristic and most striking result of the various projects. A similar experience was made for written language translation. Within the US Tides program, the goal of the MT project was to translate news articles from Chinese to English and from Arabic to English, which implied large vocabularies (80 000 and more words) and rather unrestricted domains. In the evaluations, it was found that, due to the recent improvements, the statistical"
2005.mtsummit-invited.5,J03-1002,1,0.0167893,"seem to correlate well with MT quality when measured in terms of adequacy and fluency. At the present level of MT performance, most researchers consider them to be adequate to assess the progress in the field. Such automatic measures are very important to allow for fast train/test cycles in research. • efficient algorithms for training: The alignment-lexicon models are trained on large sets of source-target sentence pairs. Although its principle was already introduced in 1993 (Brown et al. 1993), the training procedure is fairly complex and its details were studied experimentally only later (Och and Ney 2003). This work resulted in a public software package GIZA++ that is used by most researchers in the field. Furthermore, a couple of refinements were introduced beyond the original alignment-lexicon models like the so-called HMM approach (Vogel et al. 1996). Another refinement is the symmetrization of the training procedure, where the role of target and source sentences is exchanged in order to improve the quality of the final word alignments. • context dependent or phrase-based lexicon models: The original alignment-lexicon models (Brown et al. 1993) do not take into account the context in which"
2005.mtsummit-invited.5,W99-0604,1,0.765037,"target and source sentences is exchanged in order to improve the quality of the final word alignments. • context dependent or phrase-based lexicon models: The original alignment-lexicon models (Brown et al. 1993) do not take into account the context in which both the source and the target words appear. There is an evident need to introduce more context dependencies into these models, e.g. by handling word groups and phrases rather than single words. There have been a number of successful extensions that move away from single words and handle word groups in both the source and target language (Och et al. 1999; Zens et al. 2002; Koehn et al. 2003; Och and Ney 2004). Typically, these extensions seem to be limited to the extraction of bilingual phrases after the alignment-lexicon models (like IBM and HMM) have been trained. i - 15 In other words, the phrase-based models are not yet incorporated into the iterative training procedure. It is interesting to note that this extraction of phrase pairs shows a certain similarity to memory-based translation. The important difference, however, is that in statistical MT these pairs are extracted automatically. • efficient algorithms for generation: To generate"
2005.mtsummit-invited.5,P02-1040,0,0.0730815,"Missing"
2005.mtsummit-invited.5,E03-1048,0,0.0215257,"robability Models Decision Rule (+ eff. algorithm) Testing Output Figure 2: Tasks in statistical MT. at some national levels, the European level and the international level (C-Star, ATR, Verbmobil, Eutrans, LC-Star, PF-Star, TCStar, ...). Apart from the project TCStar, which started only recently, all these projects addressed translation tasks with rather limited domains (like traveling and tourism) and medium-sized vocabularies (about 10 000 words). The best performing translation systems are based on various types of statistical approaches (Och and Ney 2002) including example-based methods (Sumita et al. 2003), finite-state transducers (Casacuberta and Vidal 2004) and other data driven approaches. This is the characteristic and most striking result of the various projects. A similar experience was made for written language translation. Within the US Tides program, the goal of the MT project was to translate news articles from Chinese to English and from Arabic to English, which implied large vocabularies (80 000 and more words) and rather unrestricted domains. In the evaluations, it was found that, due to the recent improvements, the statistical approach was able to produce competitive or superior"
2005.mtsummit-invited.5,J03-1005,1,0.840953,"of bilingual phrases after the alignment-lexicon models (like IBM and HMM) have been trained. i - 15 In other words, the phrase-based models are not yet incorporated into the iterative training procedure. It is interesting to note that this extraction of phrase pairs shows a certain similarity to memory-based translation. The important difference, however, is that in statistical MT these pairs are extracted automatically. • efficient algorithms for generation: To generate the target sentence, various strategies have been studied like A∗ search and dynamic programming beam search (Koehn 2004; Tillmann and Ney 2003). In the experimental tests, dynamic programming beam search has been found to be much more efficient than a (pure) A∗ strategy. Typically, this beam search strategy works by processing the source positions in a left-to-right fashion and allowing word re-orderings to a certain degree. Furthermore, these search strategies have been extended to produce word lattices and N-best lists rather than only the single best sentence. • log-linear model combinations and rescoring: The baseline models in statistical translation are the lexicon model, the alignment model and the language model. Due to model"
2005.mtsummit-invited.5,2003.mtsummit-papers.52,1,0.846965,"e: Bayes decision rule is based on minimizing the so-called posterior risk which requires a quantitative error measure or cost function. In statistical MT (as in speech recognition), the traditional error measure is the 0/1loss function that minimizes the sentence error rate but not necessarily the error measures used in translation like WER, PER and BLEU (see later). This type of inconsistency is not addressed in the literature with the exception of (Kumar and Byrne 2004). Furthermore, some applications of machine translation require criteria at the word level (like confidence Data measures (Ueffing et al. 2003)) rather than at the sentence level. • probability models: The probability models are used to replace the true but unknown probability distributions in Bayes decision rule. Their ultimate goal is to provide the link between the input data (source sentence) and the output data (target sentence) that have to be produced by the translation system. It is exactly here where linguistic knowledge will be helpful to come up with better models in the future. • training criterion: The training criterion is used to learn the free parameters of the probability models from the training data. As in speech r"
2005.mtsummit-invited.5,C96-2141,1,0.649643,"t to allow for fast train/test cycles in research. • efficient algorithms for training: The alignment-lexicon models are trained on large sets of source-target sentence pairs. Although its principle was already introduced in 1993 (Brown et al. 1993), the training procedure is fairly complex and its details were studied experimentally only later (Och and Ney 2003). This work resulted in a public software package GIZA++ that is used by most researchers in the field. Furthermore, a couple of refinements were introduced beyond the original alignment-lexicon models like the so-called HMM approach (Vogel et al. 1996). Another refinement is the symmetrization of the training procedure, where the role of target and source sentences is exchanged in order to improve the quality of the final word alignments. • context dependent or phrase-based lexicon models: The original alignment-lexicon models (Brown et al. 1993) do not take into account the context in which both the source and the target words appear. There is an evident need to introduce more context dependencies into these models, e.g. by handling word groups and phrases rather than single words. There have been a number of successful extensions that mov"
2005.mtsummit-invited.5,J97-3002,0,0.0237365,"d easily. • more powerful computers and more parallel corpora: Both the training and the generation algorithms in statistical MT require a huge computing power, in particular the memory requirements tend to be very demanding. Furthermore, the bilingual corpora have been steadily growing in size. 3.3 Additional Research Directions Syntax-based Translation Models. While the alignment approach introduced in (Brown et al. 1993) does not make use of any syntactic concepts, there were attempts at introducing explicit syntactic structures into the statistical translation models (Alshawi et al. 2000; Wu 1997; Yamada and Knight 2001). In such a way, it is expected that the difference in the word order between target and source sentences can be better taken into account. At present, these syntax-based extensions do not (yet) seem to pay off in terms of performance. In addition, the syntactic approach could also include a morphological analysis (Nießen and Ney 2004) so that the statistical approach could go beyond the usual full forms of words. Speech Translation. The translation of spoken language requires the combination of two operations, namely the recognition of the spoken source sentence and i"
2005.mtsummit-invited.5,2002.tmi-tutorials.2,0,0.0189726,"sentences is exchanged in order to improve the quality of the final word alignments. • context dependent or phrase-based lexicon models: The original alignment-lexicon models (Brown et al. 1993) do not take into account the context in which both the source and the target words appear. There is an evident need to introduce more context dependencies into these models, e.g. by handling word groups and phrases rather than single words. There have been a number of successful extensions that move away from single words and handle word groups in both the source and target language (Och et al. 1999; Zens et al. 2002; Koehn et al. 2003; Och and Ney 2004). Typically, these extensions seem to be limited to the extraction of bilingual phrases after the alignment-lexicon models (like IBM and HMM) have been trained. i - 15 In other words, the phrase-based models are not yet incorporated into the iterative training procedure. It is interesting to note that this extraction of phrase pairs shows a certain similarity to memory-based translation. The important difference, however, is that in statistical MT these pairs are extracted automatically. • efficient algorithms for generation: To generate the target sentenc"
2005.mtsummit-invited.5,E03-1032,1,\N,Missing
2005.mtsummit-invited.5,P01-1067,0,\N,Missing
2005.mtsummit-invited.5,J04-4002,1,\N,Missing
2005.mtsummit-papers.34,J93-2003,0,0.0128844,"uation results. 1 The structure of the paper is as follows: In Section 2 we will describe the statistical approach to machine translation and in Section 3 further methods used in our translation system. The EPPS databases and experimental results will be presented in Section 4. We will draw conclusions in the last Section. 2 Statistical Machine Translation In a machine translation framework we are given a sentence f1J = f1 . . . fJ in a source language that is to be translated as sentence eI1 = e1 . . . eI into a target language (f and e stand for ‘French’ and ‘English’ in the original paper (Brown et al., 1993)). For the statistical approach, we use Bayes decision rule which states that we should choose the sentence that maximizes the posterior probability eˆI1 = argmax p(eI1 |f1J ) (1) eI1 = argmax p(eI1 )p(f1J |eI1 ) , (2) eI1 Introduction Speech-to-speech translation is an outstanding reasearch goal in the machine translation community. Up to now, most of the projects dealing with this issue have dealt only with artiﬁcial or very limited tasks (Wahlster, 2000; EuTransProject, 2000; Lavie et al., 2001; Ueﬃng and Ney, 2005). The goal of the TC-Star project is to build a speech-to-speech translation"
2005.mtsummit-papers.34,2005.eamt-1.17,1,0.776963,"IBM1 Rescoring Although the IBM1 model is the easiest one of the single-word based translation models and the phrase based models clearly outperform this approach, the inclusion of the scores of this 261 model, i.e. hIBM1 (f1J |eI1 ) = I J   1 p(fj |ei ) (I + 1)J (6) j=1 i=0 has been shown experimentally to improve the performance of a machine translation system (Och et al., 2003). 3.5 LM Rescoring During the generation process, a single language model is used. However, additional language models speciﬁc to each sentence to be translated can help to improve the machine translation quality (Hasan and Ney, 2005). The motivation behind this lies in the following observation: the syntactic structure of a sentence is inﬂuenced by its type. It is obvious that an interrogative sentence has a diﬀerent structure from a declarative one due to non-local dependencies arising e.g. from wh-extraction. As an example, let us consider the syntax of the following sentences: “Is the commissioner ready to give an undertaking?” and “The commissioner is ready to give an undertaking.” If we look closer at the ﬁrst four words of each sentence (is, the, commissioner and ready), the trigrams observed are quite diﬀerent, lea"
2005.mtsummit-papers.34,H01-1007,0,0.0254038,". . . eI into a target language (f and e stand for ‘French’ and ‘English’ in the original paper (Brown et al., 1993)). For the statistical approach, we use Bayes decision rule which states that we should choose the sentence that maximizes the posterior probability eˆI1 = argmax p(eI1 |f1J ) (1) eI1 = argmax p(eI1 )p(f1J |eI1 ) , (2) eI1 Introduction Speech-to-speech translation is an outstanding reasearch goal in the machine translation community. Up to now, most of the projects dealing with this issue have dealt only with artiﬁcial or very limited tasks (Wahlster, 2000; EuTransProject, 2000; Lavie et al., 2001; Ueﬃng and Ney, 2005). The goal of the TC-Star project is to build a speech-to-speech translation system that can deal with real life data. For this purpose we have collected data from parliamentary speeches held in the European Parliament Plenary Sessions (EPPS) to build an open domain corpus. There are three different versions of the data, the oﬃcial version of the speeches as available on the web page of the European Parliament, the actual exact transcription of the speeches produced by human transcribers and the output of an automatic speech recognition system. We evaluate our system unde"
2005.mtsummit-papers.34,P02-1038,1,0.542956,"ord based models2 in both directions (source-totarget and target-to-source) and combining the two obtained alignments (Och and Ney, 2003). Given this alignment an extraction of contiguous phrases is carried out and their probabilities are computed by mean of relative frequencies (Zens and Ney, 2004). An example of an alignment between two sentences and a (possible) set of phrases to be extracted is shown in Figure 2. 3.2 Log-linear Model As an alternative to the traditional sourcechannel approach given in Equation (2) we can model the translation probability directly using a log-linear model (Och and Ney, 2002):   M I, fJ) exp λ h (e m m 1 1 m=1  , p(eI1 |f1J ) =  M I, fJ) exp λ h (˜ e m=1 m m 1 1 I e˜1 (5) 2 Usually the used models are IBM-1, HMM and IBM-4. with hm diﬀerent models, λm scaling factors and the denominator a normalization factor that can be ignored in the maximization process. We choose the λm by optimizing a performance measure over a development corpus using the downhill simplex algorithm as presented in (Press et al., 2002). The source-channel model (2) is a special case of (5) with appropriate feature functions. The log-linear model, however, has the advantage that addition"
2005.mtsummit-papers.34,J03-1002,1,0.010911,"context into the translation model is to learn translations for whole phrases instead of single words. Here, a phrase is simply a sequence of words, no other linguistic meaning is required. So, the basic idea of phrase-based translation is to segment the given source sentence into phrases, then translate each phrase and ﬁnally compose the target sentence from these phrase translations. First an alignment between source and target sentence is found by using a chain of single-word based models2 in both directions (source-totarget and target-to-source) and combining the two obtained alignments (Och and Ney, 2003). Given this alignment an extraction of contiguous phrases is carried out and their probabilities are computed by mean of relative frequencies (Zens and Ney, 2004). An example of an alignment between two sentences and a (possible) set of phrases to be extracted is shown in Figure 2. 3.2 Log-linear Model As an alternative to the traditional sourcechannel approach given in Equation (2) we can model the translation probability directly using a log-linear model (Och and Ney, 2002):   M I, fJ) exp λ h (e m m 1 1 m=1  , p(eI1 |f1J ) =  M I, fJ) exp λ h (˜ e m=1 m m 1 1 I e˜1 (5) 2 Usually the"
2005.mtsummit-papers.34,P02-1040,0,0.0715923,"ion. Sentence pairs Running Words Running Words without Punct. Marks Vocabulary Singletons Spanish English 1 207 740 34 851 423 33 335 048 31 360 260 30 049 355 139 587 93 995 48 631 33 891 Table 2: Statistics of the EPPS training corpus. order of an acceptable sentence can be different from that of the target sentence, so that the WER measure alone could be misleading. The PER compares the words in the two sentences ignoring the word order. • BLEU and NIST scores: These scores are a weighted n-gram precision in combination with a penalty for sentences which are too short, and were deﬁned in (Papineni et al., 2002) and (Doddington, 2002). Both measure accuracy, i.e. large scores are better. All of these metrics can be extended to the case where we have multiple references by calculating the value for each of the reference translations and choosing the best one among them. In our case we had two references per sentence. 4.4 Results The results for the FTE corpus are given in Table 4. The baseline results refer to the output of the translation system, as described in Section 3.1, without any of the further improvements discussed in Section 3. It can be seen that the log-linear combination of models signiﬁ"
2005.mtsummit-papers.34,W02-1021,1,0.821509,"rom being perfect. For eﬃciency reasons in most tasks, the whole search space can not be treated directly. So some pruning has to be carried out in the search process, which can lead to the rejection of valid translations (socalled search errors). The state-of-the-art algorithms used in current systems, however, allow to minimize these kinds of errors, so the main source of errors still lies in the probability models, i.e. sentences which are better translations do not get a better score (a higher probability). In order to alleviate this eﬀect, we can make use of word graphs and n-best lists (Ueﬃng et al., 2002). These are representations of diﬀerent possible translations for a given sentence. Once we have this representation we can use further models in order to compute an additional score for each of the possible candidates and then choose the one with the best score. Ideally these additional models would be integrated into the generation algorithm, but most of them are too costly to include in the search procedure or do not have a structure which allows this kind of coupling. How to eﬃciently compute n-best lists and word graphs for the phrase-based approach is presented in (Zens and Ney, 2005). 3"
2005.mtsummit-papers.34,C96-2141,1,0.629724,"the output of an automatic speech recognition system. We evaluate our system under these three conditions. 259 where the argmax operator denotes the search process. The transformation from (1) to (2) using Bayes rule allows us to use two sources of information, the translation model p(f1J |eI1 ) and the target language model p(eI1 ). The translation model can be further decomposed into a lexicon model, which gives the probability for word translations, and an alignment model, which connects the words in the source and target sentences. Let us consider the HMM Alignment model as presented in (Vogel et al., 1996) in order to illustrate this decomposition. This model decomposes the translation probability as follows: J  pϑ (f1J |eI1 ) = [pϑ (aj |aj−1 , I, J)pϑ (fj |eaj )] , j=1 aJ 1 (3) where the term pϑ (aj |aj−1 , I, J) is a ﬁrstorder model for the alignment, and the term Source Language Text Transformation f1J Pr(f1J |eI1 ) Global Search: maximize Pr(eI1 ) · Pr(f1J |eI1 ) over eI1 Lexicon model Alignment model Pr(eI1 ) Language model Transformation Target Language Text Figure 1: Architecture of the translation approach based on Bayes decision rule. pϑ (fj |eaj ) is the lexicon model1 , both depend"
2005.mtsummit-papers.34,N04-1033,1,0.844315,"guistic meaning is required. So, the basic idea of phrase-based translation is to segment the given source sentence into phrases, then translate each phrase and ﬁnally compose the target sentence from these phrase translations. First an alignment between source and target sentence is found by using a chain of single-word based models2 in both directions (source-totarget and target-to-source) and combining the two obtained alignments (Och and Ney, 2003). Given this alignment an extraction of contiguous phrases is carried out and their probabilities are computed by mean of relative frequencies (Zens and Ney, 2004). An example of an alignment between two sentences and a (possible) set of phrases to be extracted is shown in Figure 2. 3.2 Log-linear Model As an alternative to the traditional sourcechannel approach given in Equation (2) we can model the translation probability directly using a log-linear model (Och and Ney, 2002):   M I, fJ) exp λ h (e m m 1 1 m=1  , p(eI1 |f1J ) =  M I, fJ) exp λ h (˜ e m=1 m m 1 1 I e˜1 (5) 2 Usually the used models are IBM-1, HMM and IBM-4. with hm diﬀerent models, λm scaling factors and the denominator a normalization factor that can be ignored in the maximizati"
2005.mtsummit-papers.34,W05-0834,1,0.828788,"s (Ueﬃng et al., 2002). These are representations of diﬀerent possible translations for a given sentence. Once we have this representation we can use further models in order to compute an additional score for each of the possible candidates and then choose the one with the best score. Ideally these additional models would be integrated into the generation algorithm, but most of them are too costly to include in the search procedure or do not have a structure which allows this kind of coupling. How to eﬃciently compute n-best lists and word graphs for the phrase-based approach is presented in (Zens and Ney, 2005). 3.4 IBM1 Rescoring Although the IBM1 model is the easiest one of the single-word based translation models and the phrase based models clearly outperform this approach, the inclusion of the scores of this 261 model, i.e. hIBM1 (f1J |eI1 ) = I J   1 p(fj |ei ) (I + 1)J (6) j=1 i=0 has been shown experimentally to improve the performance of a machine translation system (Och et al., 2003). 3.5 LM Rescoring During the generation process, a single language model is used. However, additional language models speciﬁc to each sentence to be translated can help to improve the machine translation qual"
2006.eamt-1.11,2005.eamt-1.6,1,0.88575,"Esteban, Lorenzo, Valderr´abanos, & Lapalme, 2004). Furthermore, an earlier prototype demonstrating this concept was already presented in (Isabelle et al., 1993). In this paper, we enhance a phrase-based SMT system with interactive search capabilities. Another phrase-based approach using alignment templates was presented in (Och et al., 2003). It uses a word-graph as a compact representation of the search space and locates nodes that correspond to word sequences with minimum edit distance to a given prefix. An investigation on different search strategies based on this approach is reported in (Bender, Hasan, Vilar, Zens, & Ney, 2005). Other approaches use stochastic finitestate transducers that represent weighted graphs and, thus, efficiently code possible source-target sentence pairs in a compact manner (Civera et al., 2004). 3 Machine translation engine In this section, we shortly summarize the theoretical background of an interactive statistical machine translation system. First, we review the underlying non-interactive SMT part. Then, we describe the translation model for interactive machine translation from a statistical viewpoint. We also present an extension that allows for arbitrary text as input, without limitat"
2006.eamt-1.11,J90-2002,0,0.21354,"bability: ˆ eˆI1 = argmax  I,eI1 P r(eI1 |f1J ) (1) The posterior probability P r(eI1 |f1J ) is modeled directly using a log-linear combination of several models (Och & Ney, 2002): P r(eI1 |f1J ) = (2)  M I J exp m=1 λm hm (e1 , f1 )  P P M 0I0 , f J ) exp λ h (e m m 1 1 m=1 P I 0 ,e0 I1 0 The denominator represents a normalization factor that depends only on the source sentence f1J . Therefore, we can omit it during the search process. As a decision rule, we obtain: ( M ) X ˆ eˆI1 = argmax λm hm (eI1 , f1J ) (3) I,eI1 m=1 This approach is a generalization of the source-channel approach (Brown et al., 1990). It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM 1 are trained with respect to the final translation quality measured by an error criterion (Och, 2003). We use a state-of-the-art phrase-based translation system including the following models: an n-gram language model, a phrase translation model and a word-based lexicon model. The latter two models are used for both directions: p(f |e) and p(e|f ). Additionally, we use a word penalty and a phrase penalty. The reordering model of the baseline system is distance-base"
2006.eamt-1.11,W04-3245,0,0.0356611,"Missing"
2006.eamt-1.11,P04-3001,0,0.0231145,"Missing"
2006.eamt-1.11,A83-1029,0,0.159087,"system based on alignment templates. Related work in the CAT domain is referred to in the next section. In Section 3, we review the theoretical framework for interactive machine translation being derived from a statistical MT viewpoint. In Section 4, we present a detailed overview on the technical architecture, whereas Section 5 addresses some preliminary experiments using a stateof-the-art phrase-based machine translation system within the presented framework. We conclude the paper in Section 6. 2 Related work A multi-level design of interactive machine translation was already suggested by (Melby, 1983) based on work presented in (Kay, 1980). The main idea is to provide an environment with interactive capabilities to a human translator that suggests extensions of a partly translated sentence. The user can either accept or reject these completions. A recent implementation of such a tool was performed within the TransType project (Foster, Isabelle, & Plamondon, 1996, 1997; Langlais, Foster, & Lapalme, 2000). The assistance tool was then refined for the TransType2 project (Esteban, Lorenzo, Valderr´abanos, & Lapalme, 2004). Furthermore, an earlier prototype demonstrating this concept was alread"
2006.eamt-1.11,P03-1021,0,0.00740553,"P M 0I0 , f J ) exp λ h (e m m 1 1 m=1 P I 0 ,e0 I1 0 The denominator represents a normalization factor that depends only on the source sentence f1J . Therefore, we can omit it during the search process. As a decision rule, we obtain: ( M ) X ˆ eˆI1 = argmax λm hm (eI1 , f1J ) (3) I,eI1 m=1 This approach is a generalization of the source-channel approach (Brown et al., 1990). It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM 1 are trained with respect to the final translation quality measured by an error criterion (Och, 2003). We use a state-of-the-art phrase-based translation system including the following models: an n-gram language model, a phrase translation model and a word-based lexicon model. The latter two models are used for both directions: p(f |e) and p(e|f ). Additionally, we use a word penalty and a phrase penalty. The reordering model of the baseline system is distance-based, i.e. it assigns costs based on the distance from the end position of a phrase to the start position of the next phrase. 3.2 Interactive machine translation In interactive machine translation, we have to find an extension eIi+1 fo"
2006.eamt-1.11,P02-1038,1,0.54339,"st corpus. Thus, the system is capable of being employed in a real-world translation environment. 3.1 Baseline statistical translation system machine In statistical machine translation, we are given a source language sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language sentence eI1 = e1 . . . ei . . . eI . Among all possible target language sentences, we will choose the sentence with the highest probability: ˆ eˆI1 = argmax  I,eI1 P r(eI1 |f1J ) (1) The posterior probability P r(eI1 |f1J ) is modeled directly using a log-linear combination of several models (Och & Ney, 2002): P r(eI1 |f1J ) = (2)  M I J exp m=1 λm hm (e1 , f1 )  P P M 0I0 , f J ) exp λ h (e m m 1 1 m=1 P I 0 ,e0 I1 0 The denominator represents a normalization factor that depends only on the source sentence f1J . Therefore, we can omit it during the search process. As a decision rule, we obtain: ( M ) X ˆ eˆI1 = argmax λm hm (eI1 , f1J ) (3) I,eI1 m=1 This approach is a generalization of the source-channel approach (Brown et al., 1990). It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM 1 are trained with respect to t"
2006.eamt-1.11,C96-1067,0,0.0208176,"e preliminary experiments using a stateof-the-art phrase-based machine translation system within the presented framework. We conclude the paper in Section 6. 2 Related work A multi-level design of interactive machine translation was already suggested by (Melby, 1983) based on work presented in (Kay, 1980). The main idea is to provide an environment with interactive capabilities to a human translator that suggests extensions of a partly translated sentence. The user can either accept or reject these completions. A recent implementation of such a tool was performed within the TransType project (Foster, Isabelle, & Plamondon, 1996, 1997; Langlais, Foster, & Lapalme, 2000). The assistance tool was then refined for the TransType2 project (Esteban, Lorenzo, Valderr´abanos, & Lapalme, 2004). Furthermore, an earlier prototype demonstrating this concept was already presented in (Isabelle et al., 1993). In this paper, we enhance a phrase-based SMT system with interactive search capabilities. Another phrase-based approach using alignment templates was presented in (Och et al., 2003). It uses a word-graph as a compact representation of the search space and locates nodes that correspond to word sequences with minimum edit distan"
2006.eamt-1.11,E03-1032,1,0.872017,"totype on different language pairs. 1 Introduction Computer Assisted Translation (CAT) aims at helping professional translators to faster translate texts from one language into another. The broad term covers many aspects, reaching from electronic dictionaries, terminology databases, automatic translation systems and other modules, such as translation memories. A crucial component is the machine translation system, as it imposes most of the computation and memory requirement constraints. Obviously, a separation of the translator’s environment and a dedicated translation server is intelligible (Och, Zens, & Ney, 2003). Generally, there might be additional components involved in the overall translation process, such as preprocessing, on-the-fly reranking and eventual postprocessing (e.g. truecasing). We present a straightforward framework that allows for several modules to be connected in series, employing a common interface and defined data structures as input and output. Thus, the overall maintenance effort is facilitated. The idea is to use translation objects that hold all necessary information and pass them from one application to another. For flexibility reasons and ease of use, we choose TCP/IP sock"
2006.eamt-1.11,1997.mtsummit-papers.1,0,0.152906,"Missing"
2006.eamt-1.11,P02-1040,0,0.0729848,"on and deletion operations that have to be performed to convert the generated sentence into the reference sentence. • PER (position-independent word error rate): A shortcoming of the WER is that it requires a perfect word order. The word order of an acceptable sentence can be different from that of the target sentence, so that the WER measure alone could be misleading. The PER compares the words in the two sentences ignoring the word order. • BLEU and NIST scores: These scores are a weighted n-gram precision in combination with a penalty for sentences which are too short, and were defined in (Papineni, Roukos, Ward, & Zhu, 2002) and (Doddington, 2002), respectively. Both measure accuracy, i.e. higher scores are better. In order to determine the effort a human translator would need to produce a reference translation, we use the following measure: • KSMR (keystroke and mouse action ratio): This is the overall number of interactions of the user with the CAT system divided by the number of running characters for each sentence. As an interaction, we count keystrokes when typing in characters for parts where the system does not offer appropriate extensions as well as mouse actions (i.e. mouse clicks) that are needed to ac"
2006.eamt-1.11,1993.tmi-1.17,0,0.030612,"resented in (Kay, 1980). The main idea is to provide an environment with interactive capabilities to a human translator that suggests extensions of a partly translated sentence. The user can either accept or reject these completions. A recent implementation of such a tool was performed within the TransType project (Foster, Isabelle, & Plamondon, 1996, 1997; Langlais, Foster, & Lapalme, 2000). The assistance tool was then refined for the TransType2 project (Esteban, Lorenzo, Valderr´abanos, & Lapalme, 2004). Furthermore, an earlier prototype demonstrating this concept was already presented in (Isabelle et al., 1993). In this paper, we enhance a phrase-based SMT system with interactive search capabilities. Another phrase-based approach using alignment templates was presented in (Och et al., 2003). It uses a word-graph as a compact representation of the search space and locates nodes that correspond to word sequences with minimum edit distance to a given prefix. An investigation on different search strategies based on this approach is reported in (Bender, Hasan, Vilar, Zens, & Ney, 2005). Other approaches use stochastic finitestate transducers that represent weighted graphs and, thus, efficiently code poss"
2006.eamt-1.11,W00-0507,0,0.0796508,"Missing"
2006.eamt-1.11,2005.iwslt-1.20,1,0.821969,"am therefore has to incorporate only a small set of basic capabilities, i.e. receiving, parsing and sending the object, in order to be usable in the application chain. One major advantage is that many such modules can be provided by different research groups and easily set up for experimentation. By using TCP/IP, the servers even do not need to be in one intranet but can be located anywhere on the internet instead. Furthermore, to test our basic framework, we incorporated server-like capabilities and an interactive search mode in a state-of-theart phrase-based machine translation (MT) system (Zens et al., 2005). The current performance is similar to an interactive machine translation (IMT) system based on alignment templates. Related work in the CAT domain is referred to in the next section. In Section 3, we review the theoretical framework for interactive machine translation being derived from a statistical MT viewpoint. In Section 4, we present a detailed overview on the technical architecture, whereas Section 5 addresses some preliminary experiments using a stateof-the-art phrase-based machine translation system within the presented framework. We conclude the paper in Section 6. 2 Related work A"
2006.eamt-1.21,bungeroth-etal-2006-german,1,0.852479,"kets, e.g. ‘(mehr)’, ‘-hn’ means that the signer is nodding during signing. Figure 4: Minimal pair for the hand configuration in DGS: ‘SAY’ and ‘ASK’ 4 Experiments The corpus used in this work was manually transcribed by language experts. On the German television channel Phoenix, the German weather forecast is translated into DGS. The videos, i.e. the German sentences spoken by the announcer and the signs from the interpreter, were transcribed, and their quality were checked on a regular basis. The corpus statistics are listed in Table 1. For a detailed description, the reader is referred to (Bungeroth, Stein, Dreuw, & Zahedi, 2006). 4.1 Morpho-Syntax Processing Based PreWe try to enhance the translation by either omitting redundant sentence information or by transforming parts that do not change the meaning of the sentence in the pre-processing phase. These measurements are especially important on smaller corpora. In our work, we employ the gerCG parser2 for various pre-processing steps. gerCG delivers all vital parts-of-speech information (POS). We also employed a parser that reads the gerCG tags as well a a simple rule file which lists actions for the specific POS. In informal experiments on the development corpus, s"
2006.eamt-1.21,N04-2005,0,0.0204705,"statistical methods have not been used in translation from written text to sign language yet. Moreover, the other approaches did not present quantitative results. Thus, performance comparison is not possible. (Morrissey & Way, 2005) investigate corpus-based methods for example-based sign language translation from English to the sign language of the Netherlands. With the small corpus and no available lexicon, the system is robust for sentences already encountered in the training set, but has problems with unseen combinations of corpus chunks as well as corpus parts that it is unable to align. (Huenerfauth, 2004) explores the challenges of machine translation techniques from written text to sign languages. He proposed methods concerning the theoretical issues arising during translation, for example a notation for signs which use the 3D space around the signer to form complex expressions. (S´af´ar & Marshall, 2001) propose a decompensation of the translation process into two steps: first they translate from written text into a semantic representation of the signs. Afterwards a second translation into a graphically oriented representation is done. Both steps use rule-based techniques for a specific doma"
2006.eamt-1.21,2005.mtsummit-ebmt.14,0,0.153987,"ssing can enhance the translation results. We also investigate the specific demands for sign language translation. Finally, we present detailed results based on both automatic and manual evaluation of the translation output. 1 Deutsche Geb¨ ardensprache 1.1 State-of-the-Art Several researchers deal with the challenges of automatic sign language translation. To the best of our knowledge, statistical methods have not been used in translation from written text to sign language yet. Moreover, the other approaches did not present quantitative results. Thus, performance comparison is not possible. (Morrissey & Way, 2005) investigate corpus-based methods for example-based sign language translation from English to the sign language of the Netherlands. With the small corpus and no available lexicon, the system is robust for sentences already encountered in the training set, but has problems with unseen combinations of corpus chunks as well as corpus parts that it is unable to align. (Huenerfauth, 2004) explores the challenges of machine translation techniques from written text to sign languages. He proposed methods concerning the theoretical issues arising during translation, for example a notation for signs whi"
2006.eamt-1.21,2005.iwslt-1.20,1,0.422782,"sentation is done. Both steps use rule-based techniques for a specific domain in British Sign Language. However, no quantitative results were published. (Bauer, Nießen, & Hienz, 1999) propose the recognition of captured sign language videos into manual sign parameters. They argue that these parameters can be transformed into written text by statistical machine translation. However, no detailed results are given. 2 Phrase-Based Translation Machine We use a statistical machine translation system to automatically transfer the meaning of a source language sentence into a target language sentence (Zens et al., 2005). Following the notation convention, we denote the source language with J words as f1J = f1 . . . fJ , a target language sentence as eI1 = e1 . . . eI and their correspondence as the a-posteriori probability Pr(eI1 |f1J ). The sentence eˆI1 that maximizes this probability is chosen as the translation sentence as shown in Equation 1.  eˆI1 = argmax Pr(eI1 |f1J ) (1) eI1  = argmax Pr(eI1 ) · Pr(f1J |eJ1 ) (2) eI1 The estimation of the a-posteriori probability is divided into three subproblems: 1. the language model, for which we employ trigrams smoothed with KneserNey discounting (Chen & Goodm"
2006.eamt-1.21,W05-0831,1,\N,Missing
2006.iwslt-evaluation.15,P02-1038,1,0.675938,"tion [2]. It allows for an independent modeling of the target language model P r(eI1 ) and the translation model P r(f1J |eI1 )1 . The target language model describes the well-formedness of the target language sentence. The translation model links the source language sentence to the target language sentence. The argmax operation denotes the search problem, i.e., the generation of the output sentence in the target language. 1.2. Log-linear model A generalization of the classical source-channel approach is the direct modeling of the posterior probability P r(eI1 |f1J ). Using a log-linear model [3], we obtain: P ´ M exp λm hm (eI1 , f1J ) m=1 P ´ P r(eI1 |f1J ) = P (3) M J 0I0 exp m=1 λm hm (e 1 , f1 ) e0 I1 0 1 The notational convention will be as follows: we use the symbol P r(·) to denote general probability distributions with (nearly) no specific assumptions. In contrast, for model-based probability distributions, we use the generic symbol p(·). 103 The denominator represents a normalization factor that depends only on the source sentence f1J . Therefore, we can omit it during the search process. As a decision rule, we obtain: ( M ) X Iˆ I J eˆ1 = argmax λm hm (e1 , f1 ) (4) targe"
2006.iwslt-evaluation.15,P03-1021,0,0.0724362,"that depends only on the source sentence f1J . Therefore, we can omit it during the search process. As a decision rule, we obtain: ( M ) X Iˆ I J eˆ1 = argmax λm hm (e1 , f1 ) (4) target positions I,eI1 I = i4 m=1 This is a generalization of the source-channel approach. It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM 1 are trained according to the maximum entropy principle, e.g., using the GIS algorithm. Alternatively, one can train them with respect to the final translation quality measured by an error criterion [4]. For the IWSLT evaluation campaign, we optimized the scaling factors with respect to the BLEU measure, using the Downhill Simplex algorithm from [5]. i3 i2 i1 0 = i0 0 = j0 j2 b2 b1 j4 = J j3 j1 b4 b3 source positions Figure 1: Illustration of the phrase segmentation. 1.3. Phrase-based approach The basic idea of phrase-based translation is to segment the given source sentence into phrases, then translate each phrase and finally compose the target sentence from these phrase translations. This idea is illustrated in Figure 1. Formally, we define a segmentation of a given sentence pair (f1J , eI"
2006.iwslt-evaluation.15,2005.iwslt-1.20,1,0.136382,"ation and introduce the notation that we will use in the later sections. Then, we will describe the models and algorithms that are used for generating the N -best list, i.e., the first pass. In Section 3, we will describe the models that are used to rescore and rerank this N -best list, i.e., the second pass. Afterwards, we will give an overview of the tasks and discuss the experimental results. This paper will also include a section describing the method used for the system combination of the TC-Star project partners. The overall system is similar to the one used in the 2005 IWSLT evaluation [1]. However, it contains novel features for the first pass, as well as for the second pass. In the first pass, we use phrase count features (cf. 2.2) to smooth the phrase probabiliies. In the second pass, we used sentence mixture language models 3.2 as a new model for rescoring. 1.1. Source-channel approach to SMT In statistical machine translation, we are given a source language sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language sentence eI1 = e1 . . . ei . . . eI . Among all possible target language sentences, we will choose the sentence with the highest pro"
2006.iwslt-evaluation.15,J03-1005,1,0.669481,". . fjk (7) Note that the segmentation sK 1 contains the information on the phrase-level reordering. The segmentation sK 1 is introduced as a hidden variable in the translation model. Therefore, it would be theoretically correct to sum over all possible segmentations. In practice, we use the maximum approximation for this sum. As a result, the models h(·) depend not only on the sentence pair (f1J , eI1 ), but also on the segmentaJ I K tion sK 1 , i.e., we have models h(f1 , e1 , s1 ). 1.4. Source cardinality synchronous search For single-word based models, this search strategy is described in [6]. The idea is that the search proceeds synchronously with the cardinality of the already translated source positions. Here, we use a phrase-based version of this idea. To make the search problem feasible, the reorderings are constrained as in [7]. 2. Models used during search When searching for the best translation for a given input sentence, we use a log-linear combination of several models (also called feature functions) as decision criterion. In this section, we will describe the models that are used in the first pass, i.e., during N best list generation. More specifically the models are: a"
2006.iwslt-evaluation.15,C04-1030,1,0.839059,"ossible segmentations. In practice, we use the maximum approximation for this sum. As a result, the models h(·) depend not only on the sentence pair (f1J , eI1 ), but also on the segmentaJ I K tion sK 1 , i.e., we have models h(f1 , e1 , s1 ). 1.4. Source cardinality synchronous search For single-word based models, this search strategy is described in [6]. The idea is that the search proceeds synchronously with the cardinality of the already translated source positions. Here, we use a phrase-based version of this idea. To make the search problem feasible, the reorderings are constrained as in [7]. 2. Models used during search When searching for the best translation for a given input sentence, we use a log-linear combination of several models (also called feature functions) as decision criterion. In this section, we will describe the models that are used in the first pass, i.e., during N best list generation. More specifically the models are: a phrase translation model, a word-based translation model, word and phrase penalty, a target language model and a reordering model. We will now describe the models in detail. 2.1. Phrase-based model The phrase-based translation model is the main"
2006.iwslt-evaluation.15,2002.tmi-tutorials.2,0,0.0348216,", i.e., during N best list generation. More specifically the models are: a phrase translation model, a word-based translation model, word and phrase penalty, a target language model and a reordering model. We will now describe the models in detail. 2.1. Phrase-based model The phrase-based translation model is the main component of our translation system. The hypotheses are generated by concatenating target language phrases. The pairs of source and corresponding target phrases are extracted from the wordaligned bilingual training corpus by the phrase extraction algorithm described in detail in [8]. The main idea is to extract phrase pairs that are consistent with the word alignment, meaning that the words of the source phrase are aligned only to words in the target phrase and vice versa. This criterion is identical to the alignment template criterion described in [9]. We use relative frequencies to estimate the phrase translation probabilities: p(f˜|˜ e) = N (f˜, e˜) N (˜ e) (8) Here, the number of co-occurrences of a phrase pair (f˜, e˜) that are consistent with the word alignment is denoted as N (f˜, e˜). If one occurrence of a target phrase e˜ has N > 1 possible translations, each o"
2006.iwslt-evaluation.15,W99-0604,1,0.875186,"e phrase-based translation model is the main component of our translation system. The hypotheses are generated by concatenating target language phrases. The pairs of source and corresponding target phrases are extracted from the wordaligned bilingual training corpus by the phrase extraction algorithm described in detail in [8]. The main idea is to extract phrase pairs that are consistent with the word alignment, meaning that the words of the source phrase are aligned only to words in the target phrase and vice versa. This criterion is identical to the alignment template criterion described in [9]. We use relative frequencies to estimate the phrase translation probabilities: p(f˜|˜ e) = N (f˜, e˜) N (˜ e) (8) Here, the number of co-occurrences of a phrase pair (f˜, e˜) that are consistent with the word alignment is denoted as N (f˜, e˜). If one occurrence of a target phrase e˜ has N > 1 possible translations, each of them contributes to N (f˜, e˜) 104 with 1/N . The marginal count N (˜ e) is the number of occurrences of the target phrase e˜ in the training corpus. The resulting feature function is: hPhr (f1J , eI1 , sK 1 ) = log K Y p(f˜k |˜ ek ) 2.4. Word and phrase penalty model In a"
2006.iwslt-evaluation.15,2004.iwslt-evaluation.13,1,0.815761,"sentence and phrase lengths. The model scaling factors can be adjusted to prefer longer sentences and longer phrases. 2.5. Target language model We use the SRI language modeling toolkit [11] to train a standard n-gram language model. The resulting feature function is: I Y hLM (f1J , eI1 , sK p(ei |ei−1 (14) 1 ) = log i−n+1 ) i=1 The smoothing technique we apply is the modified KneserNey discounting with interpolation. We used a 6-gram language model for all tasks. [N (f˜k , e˜k ) ≤ τ ] jk K Y Y I K 2.6. Reordering model We use a very simple reordering model that is also used in, for instance, [9, 12]. It assigns costs based on the jump width: hRM (f1J , eI1 , sK 1 )= K X |bk − jk−1 − 1 |+ J − jK (15) k=1 3. Rescoring models In this section, we describe the second pass of our system, the rescoring of N -best lists. N -best lists are suitable for easily applying several rescoring techniques because the hypotheses are already fully generated. In comparison, word graph rescoring techniques need specialized tools which traverse the graph appropriately. Additionally, because a node within a word graph allows for many histories, one can only apply local rescoring techniques, whereas for N -best"
2006.iwslt-evaluation.15,2005.eamt-1.17,1,0.888573,"Missing"
2006.iwslt-evaluation.15,W06-3110,1,0.184162,"se of another rescoring technique that benefits from the IBM model 1 lexical probabilities: hDel (f1J , eI1 ) = J Y I X [ p(fj |ei ) < τ ] (19) j=1 i=0 We call this the IBM1 deletion model. It counts all source words whose lexical probability given each target word is below a threshold τ . In the experiments, τ was chosen between 10−1 and 10−4 . 3.5. Sentence length model Sentence length is crucial for the evaluation of machine translation output, especially when using automatic evalua106 tion measures. Therefore we explicitly modeled the target sentence length I using the method described in [16]: X hSL (f1J , eI1 ) = log p(eI1 |f1J ) Table 2: Progress over time: comparison of the RWTH systems of the years 2004 to 2006 for the supplied data track on the IWSLT 2005 test set. eI1 Translation Direction Chin.-Engl. The sum is carried out only over those target hypotheses that have length I. 4. Tasks and corpora The experiments were carried out on the Basic Travel Expression Corpus (BTEC) task [17]. This is a multilingual speech corpus which contains tourism-related sentences similar to those that are found in phrase books. The corpus statistics are shown in Table 1. For the open data trac"
2006.iwslt-evaluation.15,takezawa-etal-2002-toward,0,0.0460057,"the evaluation of machine translation output, especially when using automatic evalua106 tion measures. Therefore we explicitly modeled the target sentence length I using the method described in [16]: X hSL (f1J , eI1 ) = log p(eI1 |f1J ) Table 2: Progress over time: comparison of the RWTH systems of the years 2004 to 2006 for the supplied data track on the IWSLT 2005 test set. eI1 Translation Direction Chin.-Engl. The sum is carried out only over those target hypotheses that have length I. 4. Tasks and corpora The experiments were carried out on the Basic Travel Expression Corpus (BTEC) task [17]. This is a multilingual speech corpus which contains tourism-related sentences similar to those that are found in phrase books. The corpus statistics are shown in Table 1. For the open data track a 40 000 sentences training corpus and four test sets were made available for each language pair. Other resources, despite proprietary data were permitted, but were not used in this system. As the BTEC is a rather clean corpus, the preprocessing consisted mainly of tokenization, i.e., separating punctuation marks from words. Additionally, we expanded contractions such as it’s or I’m in the English co"
2006.iwslt-evaluation.15,J03-1002,1,0.094442,"Missing"
2006.iwslt-evaluation.15,P02-1040,0,0.123176,"Missing"
2006.iwslt-evaluation.15,W05-0909,0,0.0606975,"Missing"
2006.iwslt-evaluation.15,E06-1005,1,0.51274,"Missing"
2006.iwslt-evaluation.15,W02-1021,1,\N,Missing
2006.iwslt-evaluation.15,J90-2002,0,\N,Missing
2006.iwslt-evaluation.15,W05-0834,1,\N,Missing
2006.iwslt-evaluation.15,W05-0831,1,\N,Missing
2006.iwslt-papers.1,P02-1038,1,0.362963,"y of a comma given the context exceeds a certain threshold. We are not aware of any other published work dealing with the detection of SU boundaries and punctuation in the context of machine translation. 158 3. Phrase-based MT system of RWTH speech In this section we will briefly present the statistical MT system which we use in the experiments for this work. We will denote the (given) source sentence with f1J = f1 . . . fJ , which is to be translated into a target language sentence eI1 = e1 . . . eI . Our baseline system maximizes the translation probability directly using a log-linear model [9]: P ´ M exp λm hm (eI1 , f1J ) m=1 P ´ , (1) p(eI1 |f1J ) = X M I, fJ) exp λ h (˜ e m m 1 1 m=1 I SUs e˜1 with a set of different features hm , scaling factors λm and the denominator a normalization factor that can be ignored in the maximization process. We choose the λm by optimizing an MT performance measure on a development corpus using the downhill simplex algorithm. The most important models in equation (1) are phrasebased models in both source to target and target to source directions. In order to extract these models, an alignment between a source sentence and its target language tran"
2006.iwslt-papers.1,J03-1002,1,0.00605234,"λm and the denominator a normalization factor that can be ignored in the maximization process. We choose the λm by optimizing an MT performance measure on a development corpus using the downhill simplex algorithm. The most important models in equation (1) are phrasebased models in both source to target and target to source directions. In order to extract these models, an alignment between a source sentence and its target language translation is found for all sentence pairs in the training corpus using the IBM-1, HMM and IBM-4 models in both directions and combining the two obtained alignments [10]. Given this alignment, an extraction of contiguous phrases is carried out and their probabilities are computed by means of relative frequencies [13]. Additionally we use single word based lexica in source to target and target to source direction. This has the effect of smoothing the relative frequencies used as estimates of the phrase probabilities. The phrase-based and single word based probabilities thus yield 4 features of the log-linear model. Another important feature in the log-linear model is the language model, an n-gram language model with KneserNey smoothing. A length and a phrase p"
2006.iwslt-papers.1,P02-1040,0,0.111881,"Missing"
2006.iwslt-papers.1,N04-1033,1,0.84139,"re on a development corpus using the downhill simplex algorithm. The most important models in equation (1) are phrasebased models in both source to target and target to source directions. In order to extract these models, an alignment between a source sentence and its target language translation is found for all sentence pairs in the training corpus using the IBM-1, HMM and IBM-4 models in both directions and combining the two obtained alignments [10]. Given this alignment, an extraction of contiguous phrases is carried out and their probabilities are computed by means of relative frequencies [13]. Additionally we use single word based lexica in source to target and target to source direction. This has the effect of smoothing the relative frequencies used as estimates of the phrase probabilities. The phrase-based and single word based probabilities thus yield 4 features of the log-linear model. Another important feature in the log-linear model is the language model, an n-gram language model with KneserNey smoothing. A length and a phrase penalty are the last models in the set of the seven basic models which are used in the system. 4. Sentence Segmentation and Punctuation Prediction in"
2006.iwslt-papers.1,2005.iwslt-1.19,1,0.886348,"Missing"
2006.iwslt-papers.7,2005.iwslt-1.20,1,0.362873,"the original single-word-based models to phrase-based-models, in order to better capture the context dependencies of the words in the translation process. The starting point for the training of these models was however the Viterbi alignment produced as a byproduct of the training of the original IBM models, that is, the alignment with the highest probability given the final parameter estimations. Most state-of-the-art machine translation systems, normally based on a phrase-based translation scheme or variations of it, make use of this Viterbi alignment as a first step in the training process [2, 3, 4]. Other translation approaches also benefit from the use of alignments [5]. It is then to expect that an increase in quality of the alignment should lead to an increase in translation quality. At least, it is expected that an improvement in the alignments does not hurt translation performance. In [6] the “Alignment Error Rate” (AER) is introduced as a measure of alignment quality. Given a reference alignment, consisting of a set S of “Sure”, unambiguous alignment points and a set P of “Possible”, ambiguous alignment points, with S ⊆ P , the AER of an alignment A = {(j, aj )} is defined to be |"
2006.iwslt-papers.7,P05-1033,0,0.0502601,"the original single-word-based models to phrase-based-models, in order to better capture the context dependencies of the words in the translation process. The starting point for the training of these models was however the Viterbi alignment produced as a byproduct of the training of the original IBM models, that is, the alignment with the highest probability given the final parameter estimations. Most state-of-the-art machine translation systems, normally based on a phrase-based translation scheme or variations of it, make use of this Viterbi alignment as a first step in the training process [2, 3, 4]. Other translation approaches also benefit from the use of alignments [5]. It is then to expect that an increase in quality of the alignment should lead to an increase in translation quality. At least, it is expected that an improvement in the alignments does not hurt translation performance. In [6] the “Alignment Error Rate” (AER) is introduced as a measure of alignment quality. Given a reference alignment, consisting of a set S of “Sure”, unambiguous alignment points and a set P of “Possible”, ambiguous alignment points, with S ⊆ P , the AER of an alignment A = {(j, aj )} is defined to be |"
2006.iwslt-papers.7,J04-2004,0,0.0975736,"the original single-word-based models to phrase-based-models, in order to better capture the context dependencies of the words in the translation process. The starting point for the training of these models was however the Viterbi alignment produced as a byproduct of the training of the original IBM models, that is, the alignment with the highest probability given the final parameter estimations. Most state-of-the-art machine translation systems, normally based on a phrase-based translation scheme or variations of it, make use of this Viterbi alignment as a first step in the training process [2, 3, 4]. Other translation approaches also benefit from the use of alignments [5]. It is then to expect that an increase in quality of the alignment should lead to an increase in translation quality. At least, it is expected that an improvement in the alignments does not hurt translation performance. In [6] the “Alignment Error Rate” (AER) is introduced as a measure of alignment quality. Given a reference alignment, consisting of a set S of “Sure”, unambiguous alignment points and a set P of “Possible”, ambiguous alignment points, with S ⊆ P , the AER of an alignment A = {(j, aj )} is defined to be |"
2006.iwslt-papers.7,J03-1002,1,0.0610827,"s, that is, the alignment with the highest probability given the final parameter estimations. Most state-of-the-art machine translation systems, normally based on a phrase-based translation scheme or variations of it, make use of this Viterbi alignment as a first step in the training process [2, 3, 4]. Other translation approaches also benefit from the use of alignments [5]. It is then to expect that an increase in quality of the alignment should lead to an increase in translation quality. At least, it is expected that an improvement in the alignments does not hurt translation performance. In [6] the “Alignment Error Rate” (AER) is introduced as a measure of alignment quality. Given a reference alignment, consisting of a set S of “Sure”, unambiguous alignment points and a set P of “Possible”, ambiguous alignment points, with S ⊆ P , the AER of an alignment A = {(j, aj )} is defined to be |A ∩ S |+ |A ∩ P | . AER(S, P ; A) = 1 − |A |+ |S| cision using the possible alignments. In the same paper, an exhaustive study of different alignment models is carried out. Following this work, numerous new alignment methods or refinements to existing ones have appeared in the literature, which incre"
2006.iwslt-papers.7,2005.mtsummit-papers.34,1,0.760218,"owever many of them do not report translation results, and the implicit assumption is made that the improvements on alignment quality will influence the translation process in a positive way. In this paper we will present two counter-examples to this assumption, that is, we will present (review in one of the cases) two relatively simple refinements of the standard alignment process using the IBM models that actually deteriorate the alignment quality. However, they improve the translation performance. We will show this on two translation models, a phrase based system similar to the one used in [7] and a finite state transducer based system as presented in [8]. The key point is that these methods adapt the alignments to the translation models that will make further use of them. 2. Related Work In [9] the authors conduct an experimental study on the correlation of AER as defined above and the actual translation performance. To our knowledge this is the first work that carries out such a detailed study. The conclusion of their work is that the alignment error rate is not a good measure for predicting translation performance. The main reason given is that AER does not penalize an unbalance"
2006.iwslt-papers.7,W02-1018,0,0.0657364,"Missing"
2006.iwslt-papers.7,W05-0831,1,0.906414,"implicit assumption is made that the improvements on alignment quality will influence the translation process in a positive way. In this paper we will present two counter-examples to this assumption, that is, we will present (review in one of the cases) two relatively simple refinements of the standard alignment process using the IBM models that actually deteriorate the alignment quality. However, they improve the translation performance. We will show this on two translation models, a phrase based system similar to the one used in [7] and a finite state transducer based system as presented in [8]. The key point is that these methods adapt the alignments to the translation models that will make further use of them. 2. Related Work In [9] the authors conduct an experimental study on the correlation of AER as defined above and the actual translation performance. To our knowledge this is the first work that carries out such a detailed study. The conclusion of their work is that the alignment error rate is not a good measure for predicting translation performance. The main reason given is that AER does not penalize an unbalanced precision and recall. They propose to use the “standard” F-me"
2006.iwslt-papers.7,P02-1038,1,0.544429,"n flaw found in both of these measures is that they do not take the structure of the translation model into account. 3. Phrase-Based Translation In this section we will briefly discuss the standard phrase based approach to machine translation, and we will pay special attention to the phrase extraction method. As usual, we will denote the (given) source sentence with f1J = f1 . . . fJ , which is to be translated into a target language sentence eI1 = e1 . . . eI . The usual approach in most state-of-the-art translation systems models the translation probability directly using a log-linear model [10]: P  M J I exp ) , f λ h (e m=1 m m 1 1  , (5) P p(eI1 |f1J ) = X M eI1 , f1J ) exp m=1 λm hm (˜ I e˜1 with a set of different models hm , scaling factors λm and the denominator a normalization factor that can be ignored in the maximization process. The most important models in equation (5) normally are phrase-based models in both source-totarget and target-to-source directions. In order to extract these phrase-based models, an alignment between the source and target training sentences is found by using the standard IBM models in both directions (source-to-target and target-to-source) and"
2006.iwslt-papers.7,2005.mtsummit-papers.36,0,0.0388298,"89 2 000 54 247 57 945 ∼ = argmax max P r(A) · P r(f1J , e˜J1 |A) e˜J 1 A∈A ∼ = argmax max e˜J 1 P r(fj , e˜j |f1j−1 , e˜j−1 1 , A) A∈A fj :j=1...J = argmax max e˜J 1 Table 1: Statistics of the Europarl corpus. Y A∈A Y j−1 p(fj , e˜j |fj−m , e˜j−1 j−m , A) . fj :j=1...J In other words: if we assume a uniform distribution for P r(A), the translation problem can be mapped to the problem of estimating an m-gram language model over a learned set of bilingual tuples (fj , e˜j ). In our case we represent this language model as a weighted finite state transducer, but this is not the only possibility [11]. Assume that the alignment is a function of the target words A′ : {1, . . . , I} → {1, . . . , J}, then the bilingual tuples (fj , e˜j ) can be inferred with e. g. the GIATI method of [4]. Each source word will be mapped to a target phrase of one or more words or an “empty” phrase ε. In particular, the source words which will remain non-aligned due to the alignment functionality restriction are paired with the empty phrase. However the alignments produced by the standard alignment generation procedure do not have this functionlike property. Furthermore, assuming that we could have such an ali"
2006.iwslt-papers.7,C04-1032,1,0.845511,"imates may be poor. 4.1. Alignment Adaptation This problem can be solved by reordering either the source or the target training sentences (both in training and test phases) in a way such that alignments become monotonic for all sentences. In [8] a method is presented to obtain an alignment that fulfill both requirements. Here we will give an overview of it. First, we estimate a cost matrix C for each sentence pair (f1J , eI1 ). The elements of this matrix cij are the local costs of aligning a source word fj to a target word ei . This cost matrix is estimated using the original IBM models, see [12] for more detail. For a given alignment A ⊆ I × J, define the costs of this alignment, c(A), as the sum of the local costs of all aligned word pairs: X c(A) = cij (7) (i,j)∈A The goal is to find an alignment with the minimum costs which fulfills the given constraints. In a first step, we require the alignment to be a function of source words A1 : {1, . . . , J} → {1, . . . , I} in order to uniquely define a reordering of the source sentence. This is easily computed from the cost matrix C as: A1 (j) = argmin cij . (8) i Non-aligned source words are not allowed. A1 naturally defines a new order"
2006.iwslt-papers.7,W05-0820,0,0.0126352,"ment (using a “reordered” cost matrix) with a dynamic programming algorithm similar to the Levenshtein string edit distance algorithm. An example of this method is shown in Figure 2. Because of the special constraints we require for this model, the alignment quality is expected to be relatively poor. 5. Experimental Results In this section we will analyze the impact the alignment methods described in Sections 3.1 and 4.1 have on both alignment and translation quality. For this, experiments will be reported on the Europarl corpus as used in the ACL 2005 Machine Translation Workshop Shared Task [13], for the German-English language pair. The corpus consists of the proceedings of the European Parliament, which are published on the web. Statistics are shown in Table 1. This corpus was chosen because of the different structure of the German and the English languages, that allows to better observe the effect of the alignments than for other language pairs, where the alignment is quasi-monotonic (e.g. English-Spanish). In order to have a reference alignment, we randomly selected a subset of the training corpus, consisting of 508 sentences, and manually annotated the alignments. Contrary to th"
2006.iwslt-papers.7,P06-1002,0,0.117678,"the translation process. If we had perfect statistical translation models that could generate a completely correct translation given a perfect alignment, it could perfectly be that a direct relation between alignment quality and translation quality would exist. However we do not have such perfect models and the training procedure can be “confused” when it finds structures it does not expect, although they may be completely correct. Therefore it can be of advantage to sacrifice some alignment quality in order to better guide the training process and have more robust estimations. A recent work [14] actually presents a new measure called “consistent phrase error rate” which tries to extend the AER to the concept of phrases. The authors show how this measure correlates better with translation performance, but it is however to much oriented to a phrase-based system and we expect it to perform poorly for other translation approaches5 . But one can take a step further. The alignment concept was first introduced as a hidden variable for the training of the single-word based models. Let them remain hidden then. When switching to phrase-based models the given data is assumed to be not only the"
2006.iwslt-papers.7,P03-1041,0,0.0397145,"Missing"
2006.iwslt-papers.7,J93-2003,0,\N,Missing
2006.iwslt-papers.7,J07-3002,0,\N,Missing
2007.iwslt-1.25,J90-2002,0,0.51512,"translation , we are given a source language sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language sentence eI1 = e1 . . . ei . . . eI . Among all possible target language sentences, we will choose the sentence with the highest translation probability: ˆ eˆI1 = argmax I,eI1  P r(eI1 |f1J ) (1) We model this probability directly using a log-linear model: P  M I J exp λ h (e , f ) m m 1 1 m=1 P  P r(eI1 |f1J ) = P (2) M ′I′ , f J ) exp λ h (e 1 1 m=1 m m e′ I1 ′ This equation can be considered as a generalization of the source-channel approach presented in [1]. The hm (·) represent feature functions which can be bilingual, and thus represent the correspondence between source and target language, or monolingual, which represent additional features like grammaticality of the output. Typically, the features are statistical models or simple heuristics. This approach has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM 1 are trained according to the maximum entropy principle, e.g., using the GIS algorithm. Alternatively, one can train them with respect to the final translation quali"
2007.iwslt-1.25,P03-1021,0,0.040284,"ctions which can be bilingual, and thus represent the correspondence between source and target language, or monolingual, which represent additional features like grammaticality of the output. Typically, the features are statistical models or simple heuristics. This approach has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM 1 are trained according to the maximum entropy principle, e.g., using the GIS algorithm. Alternatively, one can train them with respect to the final translation quality measured by an error criterion [2]. For the IWSLT evaluation campaign, we optimized the scaling factors with respect to the BLEU measure, using the Downhill Simplex algorithm from [3]. The denominator in Equation 2 represents a normalization factor that depends only on the source sentence f1J . Therefore, we can omit it in the search process. As a decision rule, we obtain: ( M ) X Iˆ I J eˆ1 = argmax λm hm (e1 , f1 ) (3) I,eI1 m=1 Current state-of-the-art machine translation systems have a clearly dominating bilingual model guiding the translation process (i.e. a phrase-based model) and additional submodels. The systems develo"
2007.iwslt-1.25,2002.tmi-tutorials.2,0,0.0469304,"re are no gaps and there is no overlap. For a given sentence pair (f1J , eI1 ) and a given segmentation sK 1 , we define the bilingual phrases as: e˜k f˜k := eik−1 +1 . . . eik (5) := fbk . . . fjk (6) segmentations. In practice, we use the maximum approximation for this sum. As a result, the models h(·) depend not only on the sentence pair (f1J , eI1 ), but also on the segmentaJ I K tion sK 1 , i.e. we have models h(f1 , e1 , s1 ). The pairs of source and corresponding target phrases are extracted from the word-aligned bilingual training corpus by the phrase extraction algorithm described in [4]. The main idea is to extract phrase pairs that are consistent with the word alignment, meaning that the words of the source phrase are aligned only to words in the target phrase and vice versa. We use relative frequencies to estimate the phrase translation probabilities: p(f˜|˜ e) = hPhr (f1J , eI1 , sK 1 ) = log K Y p(f˜k |˜ ek ) (8) k=1 To obtain a more symmetric model, we use the phrase-based model in both directions p(f˜|˜ e) and p(˜ e|f˜). Depending on the language pair, we used one of three different types of reordering models. Jump Reordering. We use a very simple reordering model that"
2007.iwslt-1.25,W99-0604,1,0.717155,"rase pairs that are consistent with the word alignment, meaning that the words of the source phrase are aligned only to words in the target phrase and vice versa. We use relative frequencies to estimate the phrase translation probabilities: p(f˜|˜ e) = hPhr (f1J , eI1 , sK 1 ) = log K Y p(f˜k |˜ ek ) (8) k=1 To obtain a more symmetric model, we use the phrase-based model in both directions p(f˜|˜ e) and p(˜ e|f˜). Depending on the language pair, we used one of three different types of reordering models. Jump Reordering. We use a very simple reordering model that is also used in, for instance, [5, 6]. It assigns costs based on the jump width: K X |bk − jk−1 − 1 |+ J − jK (9) k=1 I = i4 target positions (7) Here, the number of co-occurrences of a phrase pair (f˜, e˜) that are consistent with the word alignment is denoted as N (f˜, e˜). If one occurrence of a target phrase e˜ has N > 1 possible translations, each of them contributes to N (f˜, e˜) with 1/N . The marginal count N (˜ e) is the number of occurrences of the target phrase e˜ in the training corpus. The resulting feature function is: hRM (f1J , eI1 , sK 1 )= i3 i2 i1 0 = i0 0 = j0 j2 b2 b1 N (f˜, e˜) N (˜ e) j1 j3 j4 = J b3 b4 sou"
2007.iwslt-1.25,2004.iwslt-evaluation.13,1,0.89106,"rase pairs that are consistent with the word alignment, meaning that the words of the source phrase are aligned only to words in the target phrase and vice versa. We use relative frequencies to estimate the phrase translation probabilities: p(f˜|˜ e) = hPhr (f1J , eI1 , sK 1 ) = log K Y p(f˜k |˜ ek ) (8) k=1 To obtain a more symmetric model, we use the phrase-based model in both directions p(f˜|˜ e) and p(˜ e|f˜). Depending on the language pair, we used one of three different types of reordering models. Jump Reordering. We use a very simple reordering model that is also used in, for instance, [5, 6]. It assigns costs based on the jump width: K X |bk − jk−1 − 1 |+ J − jK (9) k=1 I = i4 target positions (7) Here, the number of co-occurrences of a phrase pair (f˜, e˜) that are consistent with the word alignment is denoted as N (f˜, e˜). If one occurrence of a target phrase e˜ has N > 1 possible translations, each of them contributes to N (f˜, e˜) with 1/N . The marginal count N (˜ e) is the number of occurrences of the target phrase e˜ in the training corpus. The resulting feature function is: hRM (f1J , eI1 , sK 1 )= i3 i2 i1 0 = i0 0 = j0 j2 b2 b1 N (f˜, e˜) N (˜ e) j1 j3 j4 = J b3 b4 sou"
2007.iwslt-1.25,W05-0831,1,0.948835,"el reordering. The segmentation sK 1 is introduced as a hidden variable in the translation model. Therefore, it would be theoretically correct to sum over all possible Local Reordering. For closely related languages like Italian and English reordering within a local context forms the majority of all non-monotonicity. Common example are the change of the position of a preposition or the position of the adjective with respect to the noun it refers to. For local reordering, we allow words of the source sentence to be arbitrarily reordered within a restricted window of n positions as described in [7]. At each position, we give a fixed probability to the monotone word order and distribute the remaining probability mass among the other reordering possibilities. Syntactic Reordering for Chinese. For Chinese-toEnglish translation, reordering is a difficult task. Often, word order depends on the syntactic context. This is not handled well with the standard reordering approaches as presented above. Therefore we apply a rule-based reordering model at the level of syntactic chunks. The reordering is generated by a set of rules learned from word-aligned training data. These rules are obtained by p"
2007.iwslt-1.25,W07-0401,1,0.834617,"de X2 , the X2 that X1 i today games baseball any there are ci sono partite di baseball oggi training corpus and then reordering the obtained chunks to match target word order. For a test sentence to be translated, we generate every reordering that complies with the extracted rules. Reordering alternatives are weighted using the relative frequency of the rule in the training data. Additionally, we use a source language model that was trained on the reordered Chinese training sentences for weighting the transformed source word sequence. A more detailed description of the model can be found in [8]. (11) (12) where the bold subindices in the non-terminals represent the correspondence between source and target “gaps”. This model has as additional advantage that reordering is integrated as part of the model itself. The first step in the hierarchical phrase extraction is the same as for the phrased-based model presented in Section 3.1. Having a set of initial phrases, we search for phrases which contain other smaller sub-phrases and produce a new phrase with gaps. In our system, we restricted the number of non-terminals for each hierarchical phrase to a maximum of two, which were also not"
2007.iwslt-1.25,J07-2003,0,0.188396,"level of syntactic chunks. The reordering is generated by a set of rules learned from word-aligned training data. These rules are obtained by parsing the Chinese source language sentences of a bilingual 3.2. Hierarchical Phrase-Based Model The hierarchical phrase-based approach can be considered as an extension of the standard phrase-based model. In this model we allow the phrases to have “gaps”, i.e. we allow non-contiguous parts of the source sentence to be translated into possibly non-contiguous parts of the target sentence. The model can be formalized as a synchronous context-free grammar [9]. The bilingual rules are of the form X → hγ, α, ∼i , Figure 2: Example for the tuple based system. The bilingual sentence extracted is ci sono|are there partite di baseball|any baseball games oggi|today (10) where X is a non-terminal, γ and α are strings of terminals and non-terminals, and ∼ is a one-to-one correspondence between the non-terminals of α and γ. Two examples of this kind of rules for the Chinese-to-English translation direction are (borrowed from [9]) X → hyu X1 you X2 , have X2 with X1 i X → hX1 de X2 , the X2 that X1 i today games baseball any there are ci sono partite di base"
2007.iwslt-1.25,P06-1098,0,0.0258556,"h contain other smaller sub-phrases and produce a new phrase with gaps. In our system, we restricted the number of non-terminals for each hierarchical phrase to a maximum of two, which were also not allowed to be adjacent. In the original work [9], the search is organized as a parsing process, forming an extension of the CYK algorithm. This method is further augmented to include language model scores directly in the search, rather than as a preprocessing steps. Our implementation differs from this approach. We generate the target sentences in a strictly left-to-right fashion, in the spirit of [10]. In latter paper, rules are restricted to have a non-terminal symol only at the end of the rule. In our implementation we are able to handle all rules without restriction. We achieve this by transforming the target side of the grammar rules similar into a structure similar to a Greibach normal form. This allows a better integration in our existing decoder architecture (see Section 3.5) and a straightforward inclusion of language model scores into the translation process. 3.3. Bilingual N-Gram Model In this model, the main feature function in the log-linear model combination corresponds to the"
2007.iwslt-1.25,J04-2004,0,0.0245592,"tion is monotonic, i.e. we only use multiword source phrases if the alignment points cross, in a manner similar to [11]. Figure 2 shows an example of this segmentation. Each token in the bilanguage represents the event of the source words f˜k and the target words e˜k being aligned in the training data. For these events, we want to model the joint probability P r(fj , ei ). The transformation of the whole training corpus in such a way results in a bilanguage representation of the training corpus. On this new corpus, we apply standard language modeling techniques to train smoothed m-gram models [12]. In experimental trials a 4-gram model resulted in the best performance for most translation tasks. For better generalization we applied absolute discounting with leaving-one-out parameter estimation. Although reordering techniques can be applied for this kind of model [7], the performance of the model is normally significantly worse than the phrase-based models for language pairs with different word order. Therefore this system was only used for the Italian-to-English translation direction. 3.4. Common Models 3.4.4. Phrase penalty model 3.4.1. Word-based lexicon model In phrase-based MT, we"
2007.iwslt-1.25,patry-etal-2006-mood,0,0.0186379,"and normal phrases allows us to better control the contribution of each type of phrases. 3.4.5. Word penalty We also use another simple heuristic, the word penalty, to control the length of the produced translation: hWP (f1J , eI1 , sK 1 ) = I (16) These last two models affect the average sentence length. The model scaling factors can be adjusted to prefer longer sentences and longer phrases. 3.5. Implementation All models are implemented in a common software framework, called Xastur1 . They use the same decoder and common features modules. The architecture is similar to the one presented in [15]. 4. System combination To make use of the strenghts of the different models, we generated a consensus translation out of five different MT setups using an enhanced version of the system combination approach description in [16]. For each input test sentence, the first-best hypothesis of one contributing MT system is selected as primary hypothesis, and all other n-best (“secondary”; here: n = 10) translations of all systems are aligned to it, allowing for word reordering. The iterative alignment procedure is based on a GIZA++ training. During the alignment step, the whole test corpus of transla"
2007.iwslt-1.25,E06-1005,1,0.848336,"eI1 , sK 1 ) = I (16) These last two models affect the average sentence length. The model scaling factors can be adjusted to prefer longer sentences and longer phrases. 3.5. Implementation All models are implemented in a common software framework, called Xastur1 . They use the same decoder and common features modules. The architecture is similar to the one presented in [15]. 4. System combination To make use of the strenghts of the different models, we generated a consensus translation out of five different MT setups using an enhanced version of the system combination approach description in [16]. For each input test sentence, the first-best hypothesis of one contributing MT system is selected as primary hypothesis, and all other n-best (“secondary”; here: n = 10) translations of all systems are aligned to it, allowing for word reordering. The iterative alignment procedure is based on a GIZA++ training. During the alignment step, the whole test corpus of translations is taken into account. When the mutual word alignment of all the hypotheses for one sentence is obtained, the secondary hypotheses are then reordered to match the word order of the primary hypothesis based on the alignmen"
2007.iwslt-1.25,N07-1029,0,0.0577419,"rk is constructed. Since it is not known in advance which hypothesis has the best word order, we let each hypothesis play the role of the primary translation once for each sentence, and thus construct M confusion networks 1 Xastur is A Statistical Translator Under Research. (where M is the number of systems used; here M = 5) and unite them in a single lattice. All arcs in the path through the confusion network representing a hypothesis of a particular MT system are weighted with a system-specific factor; the different n-best hypotheses of each systems are weighted similarly to the approach of [17]. The lattice is then rescored using a Trigram LM which is trained on the MT hypotheses. This is to give a bonus to phrases that have been hypothesized by the systems, instead of single words only. Form the resulting lattice, the best hypothesis is extracted as the result of the system combination. The factors for the individual systems, as well as a LM factor and a Word Penalty are optimized using Condor [18]. We used the the IWSLT 2005 set for the Chinese-to-English tuning and the IWSLT 2007 dev5a set for Italian-to-English. For the Italian-to-English translation, the system combination proc"
2007.iwslt-1.25,takezawa-etal-2002-toward,0,0.0364178,"re optimized using Condor [18]. We used the the IWSLT 2005 set for the Chinese-to-English tuning and the IWSLT 2007 dev5a set for Italian-to-English. For the Italian-to-English translation, the system combination process worked on true case input, but gave bonus to pairs of words upper case/lower case words aligned to each other. For the Chinese-to-English system combination, all input hypotheses were in lower case, and a separate true casing step was performed on the consensus translation. 5. Tasks and corpora The experiments were carried out on the Basic Travel Expression Corpus (BTEC) task [19]. This is a multilingual speech corpus which contains tourism-related sentences similar to those that are found in phrase books. For the Chineseto-English track, a 40 000 sentence pair training corpus and five test sets were made available. For the Italian-to-English track, only 20 000 sentence pairs, but 6 development sets were provided. Other resources, despite proprietary data were permitted, but were not used in this system. 6. Italian-to-English Results For the Italian-to-English translation direction all the models described in this paper were used in the model combination. The preproces"
2007.iwslt-1.25,2006.iwslt-papers.1,1,0.808741,"ystem. 6. Italian-to-English Results For the Italian-to-English translation direction all the models described in this paper were used in the model combination. The preprocessing of the Italian side consisted mainly in the splitting of contractions like “dell’albergo” or “un’altra” into “dell’ albergo” and “un’ altra” respectively. No corresponding transformation was used in the English side. For the phrase-based model and the hierarchical model punctuations were removed in the source side of the corpus, but not on the target side. This has shown in past evaluations to obtain the best results [20]. However the tuple model does not seem to be able to generate the correct punctuations. In this case the model was trained without punctuations in the target side, and punctuation was restored used the tools of the SRI LM toolkit [13]. The input text was lowercased, but the target text was kept in “true case”. For each word at the beginning of a sentence, the most frequent case was determined and substituted. The case for words at the beginning of sentences was then restored as a postprocessing step. For the Italian-to-English condition 6 different developTable 1: Results for the different sy"
2007.iwslt-1.25,W03-1709,0,0.301982,"Missing"
2007.iwslt-1.25,C04-1006,1,0.900684,"Missing"
2007.iwslt-1.25,P02-1040,0,0.0762194,"age of the IWSLT 2004 test data is already high for the 20k sentences and the 16 references allow for a large tolerance in the MT output. The large improvement in this year can be attributed to the extensive evaluation of different aspects of the system like like word segmentations, alignment parameters and alignment combinations. The large improvements on the development and blind test set used in the preparation seem to be due to an increasing amount of overfitting on the small and specific BTEC dataset. 8. Evaluation Results For all the experiments, we report the two accuracy measures BLEU [24] and NIST [25] as well as the two error rates WER and PER. All those criteria are computed with respect to multiple references. 8.1. Primary submissions The translation results of the RWTH primary submissions are summarized in Table 4. For Chinese-to-English, we also report the results of the best contrastive submissions, as it performed better than the primary submission and only differs slightly in the optimization criterion. For the primary submission we used the average sentence length as reference length for the BLEU measure, the best submission used the “minimum nearest” method, taking t"
2007.iwslt-1.3,J96-1002,0,0.0137253,"Missing"
2007.iwslt-1.3,W05-0831,1,0.886998,"Missing"
2007.iwslt-1.3,N03-1017,0,0.0103966,"Missing"
2007.iwslt-1.3,2001.mtsummit-papers.45,1,0.810172,"since different languages have different word order requirements. In current phrasebased Statistical Machine Translation (SMT) systems, distance-based reordering constraints are widely used, such as IBM constraints [1], local constraints [2] and distortion limit [3]. With these models phrase-based SMT is powerful in word reordering within short distance. However, longdistance reordering is still problematic. In order to solve the long-distance reordering problem, it has been realized that syntactic information should be used. Some approaches have applied at the word-level, such as morphology [4], POS tags [5] and word classes [6]. They are particularly useful for the language with rich morphology for reducing the data sparseness. Another kinds of syntax reordering methods require parse trees, such as the work in [7], [8], [9], [10]. The parse tree is more powerful to capture the sentence structures. However, it is expensive to create tree structures and building a good quality parser is also a hard task. What we are interested in here is to use an intermediate syntax between POS tag and parse tree: chunks, as the basic unit for reordering. It is not only because chunks are with more"
2007.iwslt-1.3,popovic-ney-2006-pos,1,0.238747,"nt languages have different word order requirements. In current phrasebased Statistical Machine Translation (SMT) systems, distance-based reordering constraints are widely used, such as IBM constraints [1], local constraints [2] and distortion limit [3]. With these models phrase-based SMT is powerful in word reordering within short distance. However, longdistance reordering is still problematic. In order to solve the long-distance reordering problem, it has been realized that syntactic information should be used. Some approaches have applied at the word-level, such as morphology [4], POS tags [5] and word classes [6]. They are particularly useful for the language with rich morphology for reducing the data sparseness. Another kinds of syntax reordering methods require parse trees, such as the work in [7], [8], [9], [10]. The parse tree is more powerful to capture the sentence structures. However, it is expensive to create tree structures and building a good quality parser is also a hard task. What we are interested in here is to use an intermediate syntax between POS tag and parse tree: chunks, as the basic unit for reordering. It is not only because chunks are with more syntax than PO"
2007.iwslt-1.3,W06-1609,0,0.0922268,"ferent word order requirements. In current phrasebased Statistical Machine Translation (SMT) systems, distance-based reordering constraints are widely used, such as IBM constraints [1], local constraints [2] and distortion limit [3]. With these models phrase-based SMT is powerful in word reordering within short distance. However, longdistance reordering is still problematic. In order to solve the long-distance reordering problem, it has been realized that syntactic information should be used. Some approaches have applied at the word-level, such as morphology [4], POS tags [5] and word classes [6]. They are particularly useful for the language with rich morphology for reducing the data sparseness. Another kinds of syntax reordering methods require parse trees, such as the work in [7], [8], [9], [10]. The parse tree is more powerful to capture the sentence structures. However, it is expensive to create tree structures and building a good quality parser is also a hard task. What we are interested in here is to use an intermediate syntax between POS tag and parse tree: chunks, as the basic unit for reordering. It is not only because chunks are with more syntax than POS tags, but also they"
2007.iwslt-1.3,P05-1066,0,0.396938,"l constraints [2] and distortion limit [3]. With these models phrase-based SMT is powerful in word reordering within short distance. However, longdistance reordering is still problematic. In order to solve the long-distance reordering problem, it has been realized that syntactic information should be used. Some approaches have applied at the word-level, such as morphology [4], POS tags [5] and word classes [6]. They are particularly useful for the language with rich morphology for reducing the data sparseness. Another kinds of syntax reordering methods require parse trees, such as the work in [7], [8], [9], [10]. The parse tree is more powerful to capture the sentence structures. However, it is expensive to create tree structures and building a good quality parser is also a hard task. What we are interested in here is to use an intermediate syntax between POS tag and parse tree: chunks, as the basic unit for reordering. It is not only because chunks are with more syntax than POS tags, but also they are closer to the definition of a “phrase” in phrase-based SMT and easy to use. We have not found much work to do reordering at the chunk level. Schafer [11] has developed a word-chunk two"
2007.iwslt-1.3,D07-1077,0,0.154608,"straints [2] and distortion limit [3]. With these models phrase-based SMT is powerful in word reordering within short distance. However, longdistance reordering is still problematic. In order to solve the long-distance reordering problem, it has been realized that syntactic information should be used. Some approaches have applied at the word-level, such as morphology [4], POS tags [5] and word classes [6]. They are particularly useful for the language with rich morphology for reducing the data sparseness. Another kinds of syntax reordering methods require parse trees, such as the work in [7], [8], [9], [10]. The parse tree is more powerful to capture the sentence structures. However, it is expensive to create tree structures and building a good quality parser is also a hard task. What we are interested in here is to use an intermediate syntax between POS tag and parse tree: chunks, as the basic unit for reordering. It is not only because chunks are with more syntax than POS tags, but also they are closer to the definition of a “phrase” in phrase-based SMT and easy to use. We have not found much work to do reordering at the chunk level. Schafer [11] has developed a word-chunk two level"
2007.iwslt-1.3,P07-1091,0,0.399,"nts [2] and distortion limit [3]. With these models phrase-based SMT is powerful in word reordering within short distance. However, longdistance reordering is still problematic. In order to solve the long-distance reordering problem, it has been realized that syntactic information should be used. Some approaches have applied at the word-level, such as morphology [4], POS tags [5] and word classes [6]. They are particularly useful for the language with rich morphology for reducing the data sparseness. Another kinds of syntax reordering methods require parse trees, such as the work in [7], [8], [9], [10]. The parse tree is more powerful to capture the sentence structures. However, it is expensive to create tree structures and building a good quality parser is also a hard task. What we are interested in here is to use an intermediate syntax between POS tag and parse tree: chunks, as the basic unit for reordering. It is not only because chunks are with more syntax than POS tags, but also they are closer to the definition of a “phrase” in phrase-based SMT and easy to use. We have not found much work to do reordering at the chunk level. Schafer [11] has developed a word-chunk two levels syn"
2007.iwslt-1.3,D07-1056,0,0.0538963,"2] and distortion limit [3]. With these models phrase-based SMT is powerful in word reordering within short distance. However, longdistance reordering is still problematic. In order to solve the long-distance reordering problem, it has been realized that syntactic information should be used. Some approaches have applied at the word-level, such as morphology [4], POS tags [5] and word classes [6]. They are particularly useful for the language with rich morphology for reducing the data sparseness. Another kinds of syntax reordering methods require parse trees, such as the work in [7], [8], [9], [10]. The parse tree is more powerful to capture the sentence structures. However, it is expensive to create tree structures and building a good quality parser is also a hard task. What we are interested in here is to use an intermediate syntax between POS tag and parse tree: chunks, as the basic unit for reordering. It is not only because chunks are with more syntax than POS tags, but also they are closer to the definition of a “phrase” in phrase-based SMT and easy to use. We have not found much work to do reordering at the chunk level. Schafer [11] has developed a word-chunk two levels syntactic"
2007.iwslt-1.3,W03-1002,0,0.0524565,"parse trees, such as the work in [7], [8], [9], [10]. The parse tree is more powerful to capture the sentence structures. However, it is expensive to create tree structures and building a good quality parser is also a hard task. What we are interested in here is to use an intermediate syntax between POS tag and parse tree: chunks, as the basic unit for reordering. It is not only because chunks are with more syntax than POS tags, but also they are closer to the definition of a “phrase” in phrase-based SMT and easy to use. We have not found much work to do reordering at the chunk level. Schafer [11] has developed a word-chunk two levels syntactic transduction which uses chunks on both language sides. It is a whole translation system. Here, we only apply chunks on source language and are more interested in using chunk knowledge in the phrasebased translation framework. In this paper, we will improve the approach described in [12] by adding a weight model using the rules probability and repeating training on the reordered sentence pairs. In Section 3, the baseline systems are introduced. Section 4 is the main part of the paper, where the new methods to improve the baseline model are presen"
2007.iwslt-1.3,W07-0401,1,0.649895,"the basic unit for reordering. It is not only because chunks are with more syntax than POS tags, but also they are closer to the definition of a “phrase” in phrase-based SMT and easy to use. We have not found much work to do reordering at the chunk level. Schafer [11] has developed a word-chunk two levels syntactic transduction which uses chunks on both language sides. It is a whole translation system. Here, we only apply chunks on source language and are more interested in using chunk knowledge in the phrasebased translation framework. In this paper, we will improve the approach described in [12] by adding a weight model using the rules probability and repeating training on the reordered sentence pairs. In Section 3, the baseline systems are introduced. Section 4 is the main part of the paper, where the new methods to improve the baseline model are presented. Section 5 describes the experiments and the analysis. Finally, Section 6 is the conclusion. 2. Related work In the previous chunk level reordering work, [12] has represented the reorderings generated with some rules in a weighted lattice. The lattice is weighted with language model trained on reordered source data. The informatio"
2007.iwslt-1.3,W03-1709,0,0.0619507,"is POS tagged and chunked. Five chunks are generated from seven words. The English gloss is also shown at the last row for each chunks. The three rules for reordering the chunks are listed in the second table. Then the corresponding lattice with the three rules is generated. Note that when building the lattice, the monotone word sequence without any reordering is guaranteed to be included. The chunk parser is the maximum entropy tool YASMET 1 . The F-measure is 63.3 for chunk tagging. Since the chunking requires POS tags, “Inst. of Computing Tech., Chinese Lexical Analysis System. (ICTCLAS)” [19] is used. It does word segmentation and Part-Of-Speech tagging in one pass. The lattice is weighted with a trigram reordered http://www-i6.informatik.rwth-aachen.de/web/Software /index.html bu 8 duo wo men 9 chu zu 7 10 bu 11 1 4 duo 12 source language model. Each path of the lattice is a permutation fππ1J = fπ1 , ..., fπJ for a given source sentence f1J . πj is the permutation position of word fj . The weight model used in the decoder is: hslm (fππ1J , f1J ) = log p(fππ1J |f1J ) = J X (5) log p(fπj |fπj−1 , fπj−2 )(6) j=1 4. Improved chunk reordering system Two methods will be reported to imp"
2007.iwslt-1.3,2002.tmi-tutorials.2,0,0.274077,"pairs. In Section 3, the baseline systems are introduced. Section 4 is the main part of the paper, where the new methods to improve the baseline model are presented. Section 5 describes the experiments and the analysis. Finally, Section 6 is the conclusion. 2. Related work In the previous chunk level reordering work, [12] has represented the reorderings generated with some rules in a weighted lattice. The lattice is weighted with language model trained on reordered source data. The information from the reordering rules is not used. The previous work to input a graph to SMT system was done by [13]. Another work with weighted graph is done by [14]. In their N-grambased SMT system, reordering is handled by a statistical machine reordering (SMR) system, which translate an original source language to a reordered source language. The output of the SMR system is a weighted graph. Their reordering is done at word class level. Another work is to use multiple reordered inputs instead of single input to the SMT system. [9] represents reordered sentences in a N-best list. 3. Baseline system 3.1. The baseline phrase-based SMT system In statistical machine translation, we are given a source languag"
2007.iwslt-1.3,W07-0720,0,0.0495149,"roduced. Section 4 is the main part of the paper, where the new methods to improve the baseline model are presented. Section 5 describes the experiments and the analysis. Finally, Section 6 is the conclusion. 2. Related work In the previous chunk level reordering work, [12] has represented the reorderings generated with some rules in a weighted lattice. The lattice is weighted with language model trained on reordered source data. The information from the reordering rules is not used. The previous work to input a graph to SMT system was done by [13]. Another work with weighted graph is done by [14]. In their N-grambased SMT system, reordering is handled by a statistical machine reordering (SMR) system, which translate an original source language to a reordered source language. The output of the SMR system is a weighted graph. Their reordering is done at word class level. Another work is to use multiple reordered inputs instead of single input to the SMT system. [9] represents reordered sentences in a N-best list. 3. Baseline system 3.1. The baseline phrase-based SMT system In statistical machine translation, we are given a source language sentence f1J = f1 . . . fj . . . fJ , which is t"
2007.iwslt-1.3,J90-2002,0,0.420238,"ed sentences in a N-best list. 3. Baseline system 3.1. The baseline phrase-based SMT system In statistical machine translation, we are given a source language sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language sentence eI1 = e1 . . . ei . . . eI . Among all possible target language sentences, we will choose the sentence with the highest probability:  ˆ eˆI1 = argmax P r(eI1 |f1J ) (1) I,eI1 = argmax I,eI1  P r(eI1 ) · P r(f1J |eI1 ) (2) This decomposition into two knowledge sources is known as the source-channel approach to statistical machine translation [15]. It allows an independent modeling of the target language model P r(eI1 ) and the translation model P r(f1J |eI1 ). The target language model describes the well-formedness of the target language sentence. The translation model links the source language sentence to the target language sentence. The argmax operation denotes the search problem, i.e., the generation of the output sentence in the target language. An alternative to the classical source-channel approach is the direct modeling of the posterior probability P r(eI1 |f1J ). Using a log-linear model [16], we obtain:  P M I J exp m=1 λm"
2007.iwslt-1.3,P02-1038,1,0.109097,"o statistical machine translation [15]. It allows an independent modeling of the target language model P r(eI1 ) and the translation model P r(f1J |eI1 ). The target language model describes the well-formedness of the target language sentence. The translation model links the source language sentence to the target language sentence. The argmax operation denotes the search problem, i.e., the generation of the output sentence in the target language. An alternative to the classical source-channel approach is the direct modeling of the posterior probability P r(eI1 |f1J ). Using a log-linear model [16], we obtain:  P M I J exp m=1 λm hm (e1 , f1 )  P P r(eI1 |f1J ) = P M 0I0 , f J ) exp λ h (e m m 1 1 m=1 e0 I1 0 (3) The denominator represents a normalization factor that depends only on the source sentence f1J . Therefore, we can omit it during the search process. As a decision rule, we obtain: (M ) X ˆ eˆI1 = argmax λm hm (eI1 , f1J ) (4) I,eI1 m=1 This approach is a generalization of the sourcechannel approach. It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM 1 are trained according to the maximum entropy p"
2007.iwslt-1.3,P03-1021,0,0.0659479,"ormalization factor that depends only on the source sentence f1J . Therefore, we can omit it during the search process. As a decision rule, we obtain: (M ) X ˆ eˆI1 = argmax λm hm (eI1 , f1J ) (4) I,eI1 m=1 This approach is a generalization of the sourcechannel approach. It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM 1 are trained according to the maximum entropy principle, e.g., using the GIS algorithm. Alternatively, one can train them with respect to the final translation quality measured by an error criterion [17]. The log linear model is a natural framework to integrate many models. During the search of the baseline system we are using the following models: • phrase translation models (including phrase count features) • word-based translation models • word and phrase penalty • target language model (6-gram) • jump reordering model (assigning costs based on the jump width) All the experiments in the paper are evaluated without rescoring. More details about the baseline system can be found in [18]. Figure 1: An example of source reordering. source ke yi dan shi wo men chu zu che bu duo POS v c r v n d m"
2007.iwslt-1.3,2000.eamt-1.5,1,0.801713,"ernatively, one can train them with respect to the final translation quality measured by an error criterion [17]. The log linear model is a natural framework to integrate many models. During the search of the baseline system we are using the following models: • phrase translation models (including phrase count features) • word-based translation models • word and phrase penalty • target language model (6-gram) • jump reordering model (assigning costs based on the jump width) All the experiments in the paper are evaluated without rescoring. More details about the baseline system can be found in [18]. Figure 1: An example of source reordering. source ke yi dan shi wo men chu zu che bu duo POS v c r v n d m chunks v c r NP VP English gloss yes but we taxi not many used reordering rules NP VP → VP NP r NP VP → r VP NP r NP VP → VP r NP Reordering Lattice: chu zu che 5 bu 6 duo che wo men 0 ke yi 1 dan shi 2 3 3.2. Chunking reordering system The baseline reordering system we use was described in [12]. The reordering is done in preprocessing stage on the source language side. A source sentence is firstly parsed into chunks. These chunks will be reordered by some rules which are automatically"
2007.iwslt-1.3,2006.amta-papers.25,0,0.0378225,"ing data as bilingual corpora. The corpus statistics are shown in Table 1. The scaling factors are optimized for the BLEU score. The translation is evaluated case-insensitive and with punctuation marks. 5.2. Evaluation criteria WER (word error rate). The WER is computed as the minimum number of substitution, insertion and deletion operations that have to be performed to convert the generated sentence into the reference sentence. PER (position-independent word error rate). The PER compares the words in the hypothesis and references ignoring the word order. TER (translation error rate). The TER [20] is computed as the number of edits needed to change a system output so that it exactly matches a given reference. The edits include insertions, deletions, substitutions and shifts. BLEU. This score measures the precision of unigrams, bigrams, trigrams and fourgrams with respect to a reference translation with a penalty for too short sentences [21]. The BLEU score measures accuracy. 5.3. Results In Table 2, the translation results for the IWSLT05 eval data are reported. The experiments are run comparing to the baseline which is the source reordering weighed only by the source language model. T"
2007.iwslt-1.3,P02-1040,0,0.104406,"Missing"
2007.iwslt-1.3,2006.iwslt-evaluation.15,1,\N,Missing
2007.mtsummit-papers.44,2004.tmi-1.11,1,0.827162,"ure is proposed. • A complete system setup was discussed by Stein (Stein et al., 2006) for German and German sign language on the domain weather reports. Further, they describe how to improve the results with sign language specific pre- and postprocessing methods. 4 Data-Driven MT in DCU and RWTH University Over the last 10 years, the National Centre for Language Technology at DCU has developed a successful track record in research on Data-Driven MT. This is evident from the work of (Veale & Way, 1997) involving a template-driven approach to EBMT, to the Marker-Based segmentation research of (Gough & Way, 2004b) and more recently the work of (Stroppa & Way, 2006) on the development of the MaTrEx MT system (cf. section 4.1) which has performed well in international evaluations such as IWSLT.2 For over a decade, the RWTH University has been focussing research on SMT. The system has achieved very competitive results in all international evaluations in which it has participated (TC-STAR3 ,IWSLT, NIST4 ). In light of these developments, we have chosen to combine the approaches of these two prominent data-driven MT research centres and apply their approaches to the area of SL translation. These systems a"
2007.mtsummit-papers.44,W05-0833,1,0.847614,"algorithm is employed to align the chunks created in the chunking module. Rather than using the Expectation-Maximization algorithm for parameter estimation, instead these are directly computed according to the information within the chunks. This information is obtained from three sources: word-to-word translation probabilities, word-to-word cognates and chunk labels. The resulting aligned chunks are then combined with the SMT phrasal alignments. The two alignment styles Figure 1: MaTrEx Architecture are merged to help produce translations of a higher quality following the recent research of (Groves & Way, 2005; Groves & Way, 2006) 4.1.4 Decoder The MaTrEx decoder is a wrapper around Moses (Koehn et al., 2007), a phrase-based SMT decoder. Minimum-Error-Rate training (Och, 2003) is implemented within a log-linear framework (Och & Ney, 2002) and the BLEU metric (Papineni et al., 2002) is optimized using the development set. 4.2 The RWTH MT System We use a SMT system to automatically transfer the meaning of a source language sentence into a target language sentence. Our baseline system maximizes the translation probability directly using a log-linear model (Och & Ney, 2002) shown in below: P  M J I e"
2007.mtsummit-papers.44,H90-1021,0,0.0235709,"n language (EN–DE, DE–EN) (iv) and the novel translation pairings of SL to SL (DGS–ISL, ISL–DGS). Figure 2: Permutation graph of a source sentence f1 f2 f3 f4 using a window size w = 2 for a) local constraints, b) IBM constraints and c) inverse IBM constraints evident from the work of (Morrissey & Way, 2006), whose SL research made use of data from the ECHO project data. For the most part, that which is available is so small in terms of sentence quantity that it is unusable for data-driven MT. For these reason we chose to create our own corpora. We found a suitable dataset in the ATIS corpus (Hemphill et al., 1990). The ATIS (Air Travel Information System) corpus is a dataset of transcriptions from speech containing information on flights, aircraft, cities and similar related information. This corpus is particularly suited to our MT needs as it is within a closed domain and has a small vocabulary. The domain itself has a potentially practical use for Deaf people. The ATIS corpus consists of 595 English sentences. Although this is a significantly smaller dataset than that used in mainstream data-driven MT, it is sufficient to feed our systems, as demonstrated in section 6. We had this dataset translated"
2007.mtsummit-papers.44,N03-1017,0,0.00343872,"ew language pairs. An overview of the translation process is in Figure 1. The decoder is fed by different example databases to translate new sentences. These chunk and lexical example databases are created using the the Word Alignment, Chunking and Chunk Alignment Modules that are themselves fed by aligned source-target sentences. 4.1.1 Word Alignment Module Word alignment for the system is performed using Giza++ (Och, 2003), a statistical word alignment toolkit. A set of high-quality word alignments are extracted from the original uni-directional alignment sets using the “refined” method of (Koehn et al., 2003). 4.1.2 Chunking Module The primary chunking strategy employed for our language pairs in this system is based on the Marker Hypothesis (Green, 1979). This method is based on the universal psycholinguistic constraint that languages are marked for syntactic structure at their surface level by closed sets of lexemes or morphemes. Lists of closed-class “marker” words ( i.e. prepositions, conjunctions, determiners etc.) are used to segment the sentences and derive a new data source: a set of marker chunks. Each chunk consists of one or more marker words and at least one non-marker word to ensure co"
2007.mtsummit-papers.44,2005.mtsummit-papers.11,0,0.0151008,"Missing"
2007.mtsummit-papers.44,2002.tmi-papers.12,0,0.070933,"Missing"
2007.mtsummit-papers.44,2005.mtsummit-ebmt.14,1,0.834326,"he generation of ASL. There have also been interlingual approaches adopted by (Veale et al., 1998) and (Zhao et al., 2000), the latter employing synchronised tree– adjoining grammars. A second generation hybrid approach has been developed by (Huenerfauth, 2005) where interlingual, transfer and direct approaches are integrated. 1 http://www.let.kun.nl/sign-lang/echo/data.html 3.2 Current Developments More recently, SLMT has followed the more mainstream MT trend away from rule-based approaches toward data-driven methods. The following groups are active in their ‘third generation’ approaches: • (Morrissey & Way, 2005; Morrissey & Way, 2006) investigate corpus-based methods for example-based sign language translation from English to the sign language of the Netherlands. • (Chiu et al., 2007) present a system for the language pair Chinese and Taiwanese sign language. They show that their optimizing method surpasses IBM model 2. • Basic work on Spanish and Spanish sign language was done by (San-Segundo et al., 2006). Here, a speech to gesture architecture is proposed. • A complete system setup was discussed by Stein (Stein et al., 2006) for German and German sign language on the domain weather reports. Furth"
2007.mtsummit-papers.44,P03-1021,0,0.0654225,"(EBMT) and SMT approaches. The system is modular in design consisting of a number of extendible and reimplementable modules. This modular design makes it particularly adaptable to new language pairs. An overview of the translation process is in Figure 1. The decoder is fed by different example databases to translate new sentences. These chunk and lexical example databases are created using the the Word Alignment, Chunking and Chunk Alignment Modules that are themselves fed by aligned source-target sentences. 4.1.1 Word Alignment Module Word alignment for the system is performed using Giza++ (Och, 2003), a statistical word alignment toolkit. A set of high-quality word alignments are extracted from the original uni-directional alignment sets using the “refined” method of (Koehn et al., 2003). 4.1.2 Chunking Module The primary chunking strategy employed for our language pairs in this system is based on the Marker Hypothesis (Green, 1979). This method is based on the universal psycholinguistic constraint that languages are marked for syntactic structure at their surface level by closed sets of lexemes or morphemes. Lists of closed-class “marker” words ( i.e. prepositions, conjunctions, determin"
2007.mtsummit-papers.44,P02-1038,1,0.446131,"hunks. This information is obtained from three sources: word-to-word translation probabilities, word-to-word cognates and chunk labels. The resulting aligned chunks are then combined with the SMT phrasal alignments. The two alignment styles Figure 1: MaTrEx Architecture are merged to help produce translations of a higher quality following the recent research of (Groves & Way, 2005; Groves & Way, 2006) 4.1.4 Decoder The MaTrEx decoder is a wrapper around Moses (Koehn et al., 2007), a phrase-based SMT decoder. Minimum-Error-Rate training (Och, 2003) is implemented within a log-linear framework (Och & Ney, 2002) and the BLEU metric (Papineni et al., 2002) is optimized using the development set. 4.2 The RWTH MT System We use a SMT system to automatically transfer the meaning of a source language sentence into a target language sentence. Our baseline system maximizes the translation probability directly using a log-linear model (Och & Ney, 2002) shown in below: P  M J I exp ) , f λ h (e m=1 m m 1 1 P  p(eI1 |f1J ) = X M exp eI1 , f1J ) m=1 λm hm (˜ I e˜1 with a set of different features hm , scaling factors λm and the denominator a normalization factor that can be ignored in the maximization proces"
2007.mtsummit-papers.44,P02-1040,0,0.0742212,"om three sources: word-to-word translation probabilities, word-to-word cognates and chunk labels. The resulting aligned chunks are then combined with the SMT phrasal alignments. The two alignment styles Figure 1: MaTrEx Architecture are merged to help produce translations of a higher quality following the recent research of (Groves & Way, 2005; Groves & Way, 2006) 4.1.4 Decoder The MaTrEx decoder is a wrapper around Moses (Koehn et al., 2007), a phrase-based SMT decoder. Minimum-Error-Rate training (Och, 2003) is implemented within a log-linear framework (Och & Ney, 2002) and the BLEU metric (Papineni et al., 2002) is optimized using the development set. 4.2 The RWTH MT System We use a SMT system to automatically transfer the meaning of a source language sentence into a target language sentence. Our baseline system maximizes the translation probability directly using a log-linear model (Och & Ney, 2002) shown in below: P  M J I exp ) , f λ h (e m=1 m m 1 1 P  p(eI1 |f1J ) = X M exp eI1 , f1J ) m=1 λm hm (˜ I e˜1 with a set of different features hm , scaling factors λm and the denominator a normalization factor that can be ignored in the maximization process. We choose the λm by optimizing an MT perf"
2007.mtsummit-papers.44,2006.eamt-1.21,1,0.823333,"following groups are active in their ‘third generation’ approaches: • (Morrissey & Way, 2005; Morrissey & Way, 2006) investigate corpus-based methods for example-based sign language translation from English to the sign language of the Netherlands. • (Chiu et al., 2007) present a system for the language pair Chinese and Taiwanese sign language. They show that their optimizing method surpasses IBM model 2. • Basic work on Spanish and Spanish sign language was done by (San-Segundo et al., 2006). Here, a speech to gesture architecture is proposed. • A complete system setup was discussed by Stein (Stein et al., 2006) for German and German sign language on the domain weather reports. Further, they describe how to improve the results with sign language specific pre- and postprocessing methods. 4 Data-Driven MT in DCU and RWTH University Over the last 10 years, the National Centre for Language Technology at DCU has developed a successful track record in research on Data-Driven MT. This is evident from the work of (Veale & Way, 1997) involving a template-driven approach to EBMT, to the Marker-Based segmentation research of (Gough & Way, 2004b) and more recently the work of (Stroppa & Way, 2006) on the develop"
2007.mtsummit-papers.44,2007.tmi-papers.26,1,0.823492,"promising results for the addition of EBMT-style chunks, increasing distortion limits and reordering constraints. This shows some potential for producing improved translations if incorporated together in a data-driven system. Our research has also highlighted the need for MT to be applied to SLs to aid communication with the Deaf and hearing communities and have outlined current developments in this area. With this in mind, we have begun to take our work further by adding an SL recognition tool to the front end of our current system to develop a fully automatic SL-tospoken language MT system (Stein et al., 2007). For the ATIS corpus and its available video recordings in ISL, some preliminary but promising experiments have been carried out to connect the recognition and MT processes. At a later stage, to facilitate a more practical use for the Deaf we hope to reverse the language direction and produce SL translations of spoken language through the medium of an avatar, thereby allowing Deaf people to translate and access information in their natural language. The development of both these language directions leads naturally to the merging of both systems to allow for translation from SL-to-SL, a novel"
2007.mtsummit-papers.44,2006.iwslt-evaluation.4,1,0.827273,"ussed by Stein (Stein et al., 2006) for German and German sign language on the domain weather reports. Further, they describe how to improve the results with sign language specific pre- and postprocessing methods. 4 Data-Driven MT in DCU and RWTH University Over the last 10 years, the National Centre for Language Technology at DCU has developed a successful track record in research on Data-Driven MT. This is evident from the work of (Veale & Way, 1997) involving a template-driven approach to EBMT, to the Marker-Based segmentation research of (Gough & Way, 2004b) and more recently the work of (Stroppa & Way, 2006) on the development of the MaTrEx MT system (cf. section 4.1) which has performed well in international evaluations such as IWSLT.2 For over a decade, the RWTH University has been focussing research on SMT. The system has achieved very competitive results in all international evaluations in which it has participated (TC-STAR3 ,IWSLT, NIST4 ). In light of these developments, we have chosen to combine the approaches of these two prominent data-driven MT research centres and apply their approaches to the area of SL translation. These systems are described in more detail in sections 4.1 and 4.2. 2"
2007.mtsummit-papers.44,zhao-etal-2000-machine,0,0.512048,"d generation’ approaches. Transfer-based approaches have included the work of (Grieve-Smith, 1999) who translated English weather reports into American Sign Language (ASL) by mapping syntactic structures. (Van Zijl & Barker, 2003) also used a syntactic approach in their work on South African Sign Language with most of their focus on avatar production. (Marshall & S´af´ar, 2002; S´af´ar & Marshall, 2002) employ discourse representation structures and use HPSG semantic feature structures for the generation of ASL. There have also been interlingual approaches adopted by (Veale et al., 1998) and (Zhao et al., 2000), the latter employing synchronised tree– adjoining grammars. A second generation hybrid approach has been developed by (Huenerfauth, 2005) where interlingual, transfer and direct approaches are integrated. 1 http://www.let.kun.nl/sign-lang/echo/data.html 3.2 Current Developments More recently, SLMT has followed the more mainstream MT trend away from rule-based approaches toward data-driven methods. The following groups are active in their ‘third generation’ approaches: • (Morrissey & Way, 2005; Morrissey & Way, 2006) investigate corpus-based methods for example-based sign language translation"
2007.mtsummit-papers.44,P05-2007,0,\N,Missing
2007.mtsummit-papers.44,W05-0831,1,\N,Missing
2007.mtsummit-papers.44,2006.iwslt-evaluation.15,1,\N,Missing
2007.mtsummit-papers.68,J90-2002,0,0.239252,"Missing"
2007.mtsummit-papers.68,N03-1017,0,0.0174378,"gine in section 2.2. Usually the scaling factors λm are estimated iteratively to maximize the likelihood of the training data under the log-linear model using, i.e., GIS algorithm. Alternatively, they can be trained discriminatively on a development set to directly maximize the translation performance measured by an error criterion (Och, 2003). 2.2. Decoding Process and Active Features In SMT, translation is implemented as a statistical decision making process to search for the best target sentence within all possibilities. We use phrase-based translation (Och et al., 1999; Och and Ney, 2004; Koehn et al., 2003), which takes phrases as basic translation units rather than words. A phrase is a consecutive sequence of words, which captures word context naturally. In a typical phrasebased SMT system, the translation process begins with the segmentation of the source sentence into phrases, and then translates each source phrase into a target phrase, and finally reorders the target phrases to generate the output hypothesis. Our translation system employs the phrase-based loglinear model. The decoder generates target sentences from left to right by covering source phrases in a certain order under the heuris"
2007.mtsummit-papers.68,J03-1002,1,0.0240924,"wn et al., 1990). It allows an independent modeling of the target language model P r(eI1 ) and the translation model P r(f1J |eI1 ). The argmax operation denotes the search problem, i.e. the generation of the output sentence in the target language. The notational convention will be as follows: we use the symbol P r(·) to denote general probability distributions with (nearly) no specific assumptions. In contrast, for model-based probability distributions, we use the generic symbol p(·). 2.1. Log-linear Model for SMT As an alternative to the classical source-channel model, the log-linear model (Och and Ney, 2003) has become popular and proved to be effective in directly modeling the distribution of a target sentence when given a source sentence: P r(eI1 |f1J ) = M X  1 exp λm hm (eI1 , f1J ) Zf1J m=1 The denominator is a normalization factor, which guarantees a proper probability distribution over all possible target sentences conditioned on the source sentence. Since f1J is given during the decoding process, the denominator can be ignored, and the searching criterion is simplified as ˆ eˆJ1 = argmax I,eI1 M nX o λm hm (eI1 , f1J ) (2) m=1 The log-linear model is a generalization of the sourcechannel"
2007.mtsummit-papers.68,J04-4002,1,0.617509,"the translation engine in section 2.2. Usually the scaling factors λm are estimated iteratively to maximize the likelihood of the training data under the log-linear model using, i.e., GIS algorithm. Alternatively, they can be trained discriminatively on a development set to directly maximize the translation performance measured by an error criterion (Och, 2003). 2.2. Decoding Process and Active Features In SMT, translation is implemented as a statistical decision making process to search for the best target sentence within all possibilities. We use phrase-based translation (Och et al., 1999; Och and Ney, 2004; Koehn et al., 2003), which takes phrases as basic translation units rather than words. A phrase is a consecutive sequence of words, which captures word context naturally. In a typical phrasebased SMT system, the translation process begins with the segmentation of the source sentence into phrases, and then translates each source phrase into a target phrase, and finally reorders the target phrases to generate the output hypothesis. Our translation system employs the phrase-based loglinear model. The decoder generates target sentences from left to right by covering source phrases in a certain o"
2007.mtsummit-papers.68,W99-0604,1,0.334037,"e features used in the translation engine in section 2.2. Usually the scaling factors λm are estimated iteratively to maximize the likelihood of the training data under the log-linear model using, i.e., GIS algorithm. Alternatively, they can be trained discriminatively on a development set to directly maximize the translation performance measured by an error criterion (Och, 2003). 2.2. Decoding Process and Active Features In SMT, translation is implemented as a statistical decision making process to search for the best target sentence within all possibilities. We use phrase-based translation (Och et al., 1999; Och and Ney, 2004; Koehn et al., 2003), which takes phrases as basic translation units rather than words. A phrase is a consecutive sequence of words, which captures word context naturally. In a typical phrasebased SMT system, the translation process begins with the segmentation of the source sentence into phrases, and then translates each source phrase into a target phrase, and finally reorders the target phrases to generate the output hypothesis. Our translation system employs the phrase-based loglinear model. The decoder generates target sentences from left to right by covering source phr"
2007.mtsummit-papers.68,P03-1021,0,0.0277658,"nel model. One advantage of the log-linear model is easy integration of multiple feature functions hm , which guarantees a direct statistical decision during decoding for an accurate output and fast search. We will discuss active features used in the translation engine in section 2.2. Usually the scaling factors λm are estimated iteratively to maximize the likelihood of the training data under the log-linear model using, i.e., GIS algorithm. Alternatively, they can be trained discriminatively on a development set to directly maximize the translation performance measured by an error criterion (Och, 2003). 2.2. Decoding Process and Active Features In SMT, translation is implemented as a statistical decision making process to search for the best target sentence within all possibilities. We use phrase-based translation (Och et al., 1999; Och and Ney, 2004; Koehn et al., 2003), which takes phrases as basic translation units rather than words. A phrase is a consecutive sequence of words, which captures word context naturally. In a typical phrasebased SMT system, the translation process begins with the segmentation of the source sentence into phrases, and then translates each source phrase into a t"
2007.mtsummit-papers.68,P02-1040,0,0.0948367,"trained on the English part of the bilingual training corpus and on the monolingual data from the LDC GigaWord corpus. The total amount of the language model training data is more than 1.5 billion running words. In task II, using the method described in Section 3., we mix this general language model with a domain specific language model trained with speech transcription domain corpora containing over 100 million running words. The language model mixture weights are optimized using Powell algorithm with the respect of the PPL measured on the development corpus for each domain. We use the BLEU (Papineni et al., 2002) score as the primary evaluation criterion. Model scaling factors (feature weights) are optimized with the respect of the BLEU score using the Downhill Simplex algorithm. In task I, we use the NIST 2002 evaluation set as the newswire and the GALE 2006 dryrun development corpus as the newsgroup development set. The evaluation set is the GALE 2006 evaluation data. The sentences in some Chinese test sets are segmented but not in the English references. Our purpose is to show that the system optimized on the domain specific development corpus outperforms the one optimized on the general or out of"
2007.mtsummit-papers.68,2006.amta-papers.25,0,0.0266402,"dent word error rate): The PER is defined as the WER ignoring the word order. • BLEU score: This score measures the precision of unigrams, bigrams, trigrams and fourgrams with respect to reference translations with a penalty for too short sentences (Papineni et al., 2002). The BLEU score measures the accuracy, i.e. larger BLEU scores are better. • NIST score: NIST score (Doddington, 2002) is similar to BLEU, but it uses an arithmetic average of N-gram counts rather than a geometric average, and it weights more heavily those N-grams that are more informative. • TER Translation Edit Rate (TER) (Snover et al., 2006) measures the amount of editing which a human being would have to perform to change a system output so it exactly matches a reference translation. 5.3.2. Translation Results In task I, we distinguish the systems with different settings of the scaling factors of the log-linear model in the decoder. In Table 2, in the baseline systems the scaling factors are optimized on the newswire development corpus. If all the newsgroup documents are translated with the feature weights optimized on the newsgroup development corpus, we receive oracle best (O.B.) translation results. Here we show the oracle be"
2007.mtsummit-papers.68,W06-3111,1,0.825796,"n, so we performed the domain adaptation methods described in Section 4. In task II, there are four domains in the test data, newswire, broadcast news, broadcast conversation and web text. The domain boundaries are provided already, so there is no need to perform the domain classification any more. 5.1. Task and Corpus The corpus statistics of the bilingual training data and the test sets are shown in Table 1. The preprocessing step includes the tokenization and the categorization on the numbers and dates. Long sentences are segmented into short sentences using the binary segmentation method (Xu et al., 2006) to reduce the training time. After the preprocessing and segmentation, the parallel training data contains more than 20 million sentences and approximately 250 million words in each language. The six-gram language model was trained on the English part of the bilingual training corpus and on the monolingual data from the LDC GigaWord corpus. The total amount of the language model training data is more than 1.5 billion running words. In task II, using the method described in Section 3., we mix this general language model with a domain specific language model trained with speech transcription do"
2007.mtsummit-papers.68,2002.tmi-tutorials.2,0,0.023027,"fly describe some of them: Phrase Translation Model: The phrase translation model is the most crucial component, sometimes it is referred as phrase translation table, which specifies alternative translation candidates and their probabilities for each source phrase. To build a phrase translation model, we start from a collection of parallel sentences and word alignments between sentence pair. We use IBM Model-4 word alignments (Brown et al., 1990) trained with the GIZA++ toolkit (Och and Ney, 2003). All phrase pairs with respect to word alignment boundaries are identified (more details are in (Zens et al., 2002)) and pooled to estimate a phrase translation table by their relative frequency. For better performance, we use phrase translation models in both translation directions. Word-based lexicon Model: To alleviate the data sparseness problem, a word-based lexicon model (Zens et al., 2005) is usually introduced to smooth the phrase translation probabilities. We assume all words in the source phrase generate all words in the phrase equally as in IBM Model-1. The lexicon probability is estimated as relative frequency from the word-aligned training corpora. Like a phrase translation model, we also appl"
2007.mtsummit-papers.68,2005.iwslt-1.20,1,0.830959,"translation model, we start from a collection of parallel sentences and word alignments between sentence pair. We use IBM Model-4 word alignments (Brown et al., 1990) trained with the GIZA++ toolkit (Och and Ney, 2003). All phrase pairs with respect to word alignment boundaries are identified (more details are in (Zens et al., 2002)) and pooled to estimate a phrase translation table by their relative frequency. For better performance, we use phrase translation models in both translation directions. Word-based lexicon Model: To alleviate the data sparseness problem, a word-based lexicon model (Zens et al., 2005) is usually introduced to smooth the phrase translation probabilities. We assume all words in the source phrase generate all words in the phrase equally as in IBM Model-1. The lexicon probability is estimated as relative frequency from the word-aligned training corpora. Like a phrase translation model, we also apply a word-based lexicon model in both directions. Target Language Model: A target language model helps to discriminate alternative target hypothesis by assigning, ideally, higher probability to a sentence which is more likely to be spoken/written. In our system, we use a statistical n"
2007.tmi-papers.26,2006.iwslt-evaluation.15,1,0.871056,"Missing"
2007.tmi-papers.26,2005.mtsummit-ebmt.14,1,0.803034,"Missing"
2007.tmi-papers.26,2006.eamt-1.21,1,0.889231,"Missing"
2008.iwslt-evaluation.16,2002.tmi-tutorials.2,0,0.032515,"Model The basic idea of phrase-based translation is to segment the given source sentence into phrases, then translate each phrase and finally compose the target sentence from these phrase translations. Phrases are defined as nonempty contiguous sequences of words. We constrain the segmentations so that all words in the source and the target sentence are covered by exactly one phrase. Thus, there are no gaps and there is no overlap. The pairs of source and corresponding target phrases are extracted from the word-aligned bilingual training corpus by the phrase extraction algorithm described in [2]. The main idea is to extract phrase pairs that are consistent with the word alignment, meaning that the words of the source phrase are aligned only to words in the target phrase and vice versa. Proceedings of IWSLT 2008, Hawaii - U.S.A. We use relative frequencies to estimate the phrase translation probabilities: p(f˜|˜ e) = N (f˜, e˜) N (˜ e) (2) Here, the number of co-occurrences of a phrase pair (f˜, e˜) that are consistent with the word alignment is denoted as N (f˜, e˜). If one occurrence of a target phrase e˜ has N &gt; 1 possible translations, each of them contributes to N (f˜, e˜) with 1"
2008.iwslt-evaluation.16,W99-0604,1,0.584043,"3.3.1. Word-based Lexicon Model hPhr (f1J , eI1 , sK 1 ) = log K Y p(f˜k |˜ ek ) (3) k=1 To obtain a more symmetric model, we use the phrase-based model in both directions p(f˜|˜ e) and p(˜ e|f˜). Depending on the language pair, we used a different type of reordering model: • IBM Reordering For the Arabic-to-English language pair a word-based reordering constrained by the IBM restrictions [3] is often enough and obtains the best results. • Jump Reordering For the Chinese-to-English translation direction we use a very simple reordering model at phrase level that is also used in, for instance, [4, 5]. It assigns costs based only on the jump width. The phrase translation models estimate their probabilities by relative frequencies. Most of the longer phrases or translation units however occur only once in the training corpus. Therefore, pure relative frequencies overestimate the probability of those phrases. To overcome this problem, we use a word-based lexicon model to smooth the phrase translation probabilities. The score of a phrase pair is computed similar to the IBM model 1, but here, we are summing only within a phrase pair and not over the whole target language sentence. In the case"
2008.iwslt-evaluation.16,2004.iwslt-evaluation.13,1,0.818237,"3.3.1. Word-based Lexicon Model hPhr (f1J , eI1 , sK 1 ) = log K Y p(f˜k |˜ ek ) (3) k=1 To obtain a more symmetric model, we use the phrase-based model in both directions p(f˜|˜ e) and p(˜ e|f˜). Depending on the language pair, we used a different type of reordering model: • IBM Reordering For the Arabic-to-English language pair a word-based reordering constrained by the IBM restrictions [3] is often enough and obtains the best results. • Jump Reordering For the Chinese-to-English translation direction we use a very simple reordering model at phrase level that is also used in, for instance, [4, 5]. It assigns costs based only on the jump width. The phrase translation models estimate their probabilities by relative frequencies. Most of the longer phrases or translation units however occur only once in the training corpus. Therefore, pure relative frequencies overestimate the probability of those phrases. To overcome this problem, we use a word-based lexicon model to smooth the phrase translation probabilities. The score of a phrase pair is computed similar to the IBM model 1, but here, we are summing only within a phrase pair and not over the whole target language sentence. In the case"
2008.iwslt-evaluation.16,J07-2003,0,0.0522557,"ation probabilities p(f |e) are estimated as relative frequencies from the word-aligned training corpus. The word-based lexicon model is also used in both directions p(f |e) and p(e|f ). 3.3.2. Target Language Model 3.2. Hierarchical Model The hierarchical phrase-based approach can be considered as an extension of the standard phrase-based model. In this model we allow the phrases to have “gaps”, i.e. we allow non-contiguous parts of the source sentence to be translated into possibly non-contiguous parts of the target sentence. The model can be formalized as a synchronous context-free grammar [6]. The bilingual rules are of the form X → hγ, α, ∼i , (4) where X is a non-terminal, γ and α are strings of terminals and non-terminals, and ∼ is a one-to-one correspondence between the non-terminals of α and γ. Two examples of this kind of rules for the Chinese-to-English translation direction are X→h We use the SRI language modeling toolkit [7] to train a standard n-gram language model. The smoothing technique we apply is the modified Kneser-Ney discounting with interpolation. In our case we used a 6-gram language model. 3.3.3. Phrase Count Features The reliability of the phrase probability"
2008.iwslt-evaluation.16,2008.iwslt-papers.7,1,0.828609,"and NP, respectively), therefore the corresponding hierarchical rule gets a count of 1 for the syntax feature in the target part. Similarly for the source part. These counts are added up for all occurrences of a hierarchical rule (which may be extracted from different sentences and perhaps with different syntactic properties) and normalized with the total count of the phrase. We tried different ways of smoothing the counts, for the case where the phrases do not correspond to the yield of a node completely, but a binary count seemed to work best for the IWSLT data. More details can be found in [9]. 4.2. Chunk-based Reordering for Chinese For the standard phrase-based model we also tried and improved reordering model based on an extended version of the method described in [10]. The Chinese input sentence is reordered by a set of syntactic chunk-level rules, which are automatically learned from the training data. The method is described in [11]. In contrast to previous work, the reordered sentences are represented as an n-best list instead of a lattice. The size of the n-best list is kept small. This method has two advantages. On the one hand, not all reorderings are translated, which im"
2008.iwslt-evaluation.16,2007.iwslt-1.3,1,0.793315,"ed up for all occurrences of a hierarchical rule (which may be extracted from different sentences and perhaps with different syntactic properties) and normalized with the total count of the phrase. We tried different ways of smoothing the counts, for the case where the phrases do not correspond to the yield of a node completely, but a binary count seemed to work best for the IWSLT data. More details can be found in [9]. 4.2. Chunk-based Reordering for Chinese For the standard phrase-based model we also tried and improved reordering model based on an extended version of the method described in [10]. The Chinese input sentence is reordered by a set of syntactic chunk-level rules, which are automatically learned from the training data. The method is described in [11]. In contrast to previous work, the reordered sentences are represented as an n-best list instead of a lattice. The size of the n-best list is kept small. This method has two advantages. On the one hand, not all reorderings are translated, which improves system performance. The concept is similar to performing an aggressive pruning on the reordering lattice, where only the most promising reorderings alternatives are kept. On t"
2008.iwslt-evaluation.16,W07-0401,1,0.828669,"total count of the phrase. We tried different ways of smoothing the counts, for the case where the phrases do not correspond to the yield of a node completely, but a binary count seemed to work best for the IWSLT data. More details can be found in [9]. 4.2. Chunk-based Reordering for Chinese For the standard phrase-based model we also tried and improved reordering model based on an extended version of the method described in [10]. The Chinese input sentence is reordered by a set of syntactic chunk-level rules, which are automatically learned from the training data. The method is described in [11]. In contrast to previous work, the reordered sentences are represented as an n-best list instead of a lattice. The size of the n-best list is kept small. This method has two advantages. On the one hand, not all reorderings are translated, which improves system performance. The concept is similar to performing an aggressive pruning on the reordering lattice, where only the most promising reorderings alternatives are kept. On the other hand, there is not need for a translation system that can handle lattice based input, and thus this reordering method can be easily adapted to any translation sy"
2008.iwslt-evaluation.16,C08-1128,1,0.831022,"le used in the translation process is the composed from the standard phrase table expanded with the new phrases extracted from the reordered training sentences. The training data was parsed by the tree parser from Purdue University [12], extracting the basic chunks from the tree structure. Each chunk has 1.7 words on average. The size of the source reordered n-best list is 5. We additionally use the jump reordering model. 4.3. Source Preprocessing 4.3.1. Chinese Chinese word segmentation is one of the crucial steps in the Chinese text preprocessing. We compared various segmentation methods in [13] and found out that the unigram segmenter performs better translation results in many cases than the ictclas tool [14], which we use as baseline. Our unigram segmentation is an LDC-like segmentation without text Proceedings of IWSLT 2008, Hawaii - U.S.A. S S VP WHADVP WRB Where VP P NP 洗手间 PP PN VV AUX NP is DT JJ NN the public toilet 在 哪里 X → h X ∼0 在 哪里 , Where is X ∼0 i Figure 1: Example of a syntax-enhanced hierarchical rule. normalization. Given a manually compiled lexicon, i.e. an LDC lexicon that contains words and their relative frequencies Ps (f 0 j ), the best segmentation is the one"
2008.iwslt-evaluation.16,W03-1730,0,0.0114191,"ted from the reordered training sentences. The training data was parsed by the tree parser from Purdue University [12], extracting the basic chunks from the tree structure. Each chunk has 1.7 words on average. The size of the source reordered n-best list is 5. We additionally use the jump reordering model. 4.3. Source Preprocessing 4.3.1. Chinese Chinese word segmentation is one of the crucial steps in the Chinese text preprocessing. We compared various segmentation methods in [13] and found out that the unigram segmenter performs better translation results in many cases than the ictclas tool [14], which we use as baseline. Our unigram segmentation is an LDC-like segmentation without text Proceedings of IWSLT 2008, Hawaii - U.S.A. S S VP WHADVP WRB Where VP P NP 洗手间 PP PN VV AUX NP is DT JJ NN the public toilet 在 哪里 X → h X ∼0 在 哪里 , Where is X ∼0 i Figure 1: Example of a syntax-enhanced hierarchical rule. normalization. Given a manually compiled lexicon, i.e. an LDC lexicon that contains words and their relative frequencies Ps (f 0 j ), the best segmentation is the one that maximizes the joint probability of all words in the sentence, with the assumption that words are independent of"
2008.iwslt-evaluation.16,2005.eamt-1.37,1,0.896906,"Missing"
2008.iwslt-evaluation.16,W06-3111,1,0.903734,"Missing"
2008.iwslt-evaluation.16,P06-1001,0,0.0484133,"Missing"
2008.iwslt-evaluation.16,P05-1071,0,0.1017,"Missing"
2008.iwslt-evaluation.16,W07-0813,0,0.0393414,"Missing"
2008.iwslt-evaluation.16,E06-1005,1,0.776328,"del trained only on 20K sentence pairs was to weak to differentiate between good and bad ASR hypotheses. The expansion of the lattices using alternative word segmentations introduces additional ambiguity: so far we have not used probabilities for the segmentation alternatives. Nevertheless, examples show that in many cases the ASR errors can be avoided when word lattices are translated (see Table 1). 4.5. System Combination For system combination we used our approach from last year’s evaluation campaign [8], which is based on an enhanced version of the system combination approach described in [24]. The method is based on the generation of - 112 - Table 1: Examples of improved speech translation quality when ASR word lattices are used as input for translation. single-best lattice reference single-best lattice reference single-best lattice reference Hurry up. Can you. Some? It is too expensive. Can you make it cheaper? Too expensive. Can you make it cheaper? Where is the bus stop? The bus stop here, please. Here is the bus stop. How long time? How long will it take to get there? How much time will it take? a consensus translation out of the output of different translation systems. The co"
2008.iwslt-evaluation.16,N07-1029,0,0.0278975,"systems. The core of the method consists in building a confusion network for each sentence by aligning and combining the (single-best) translation hypothesis from one MT system with the translations produced by the other MT systems (and the other translations from the same system, if n-best lists are used in combination). For each sentence, each MT system is selected once as “primary” system, and the other hypotheses are aligned to this hypothesis. The resulting confusing networks are combined into one word graph, which is then weighted with system-specific factors, similar to the approach of [25], and a trigram LM trained on the MT hypotheses. The translation with the best total score within this word graph is selected as consensus translation. The scaling factors of these models are optimized using the Condor toolkit [26] to achieve optimal BLEU score on the dev set. 5. Experimental Results In this year’s evaluation RWTH participated in the Arabic-toEnglish and Chinese-to-English translation directions. For this last language pair, we participated in both evaluation tasks, BTEC and Challenge. As training data we used the provided training data and additionally a part of the HITcorpus"
2008.iwslt-papers.7,W06-1606,0,0.00705261,"nements to the extraction process and including syntax information. Section 6 presents experimental results, which are analyzed in Section 7. Section 8 concludes the paper. 2. Related Work The hierarchical phrase based approach was first presented by David Chiang in [3] and further detailed in [2]. Already in [3], Chiang proposes the use of syntactic information together with his new hierarchical approach, but without success. Some recent publications have shown that the use of syntax for translation achieves significant improvements. One prominent example are the works by the ISI group (e.g. [4, 5]). These works go apart from the standard phrase-based approach by defining new translation units and extraction procedures, but they try to still keep the advantages of phrase-based translation [6]. There have also been some previous efforts in combining syntactic information together with a hierarchical phrase-based approach, see for example Zollmann Proceedings of IWSLT 2008, Hawaii - U.S.A. 中 X ∼0 那个 X ∼1 # It’s the X ∼1 in the X ∼0 也 要 X ∼0 一些 X ∼1 # like to X ∼0 some X ∼1 too Figure 1: Example of hierarchical rules. et al. [7] or more recently Marton et al. [8]. Our work differs from the"
2008.iwslt-papers.7,W06-3119,0,0.0192306,"One prominent example are the works by the ISI group (e.g. [4, 5]). These works go apart from the standard phrase-based approach by defining new translation units and extraction procedures, but they try to still keep the advantages of phrase-based translation [6]. There have also been some previous efforts in combining syntactic information together with a hierarchical phrase-based approach, see for example Zollmann Proceedings of IWSLT 2008, Hawaii - U.S.A. 中 X ∼0 那个 X ∼1 # It’s the X ∼1 in the X ∼0 也 要 X ∼0 一些 X ∼1 # like to X ∼0 some X ∼1 too Figure 1: Example of hierarchical rules. et al. [7] or more recently Marton et al. [8]. Our work differs from the above mentioned mainly in that we extract the syntactic information already at the training phrase, and it gets integrated in the search process as an additional model in the base log-linear combination that underlies most state-of-the-art statistical machine translation systems. Therefore, no modification of the search algorithms is needed and we can also make use of syntactic information for both languages, source and target (see also Section 5). Most of the previous work limit themselves only to the target language side, as the"
2008.iwslt-papers.7,P08-1114,0,0.0401196,"by the ISI group (e.g. [4, 5]). These works go apart from the standard phrase-based approach by defining new translation units and extraction procedures, but they try to still keep the advantages of phrase-based translation [6]. There have also been some previous efforts in combining syntactic information together with a hierarchical phrase-based approach, see for example Zollmann Proceedings of IWSLT 2008, Hawaii - U.S.A. 中 X ∼0 那个 X ∼1 # It’s the X ∼1 in the X ∼0 也 要 X ∼0 一些 X ∼1 # like to X ∼0 some X ∼1 too Figure 1: Example of hierarchical rules. et al. [7] or more recently Marton et al. [8]. Our work differs from the above mentioned mainly in that we extract the syntactic information already at the training phrase, and it gets integrated in the search process as an additional model in the base log-linear combination that underlies most state-of-the-art statistical machine translation systems. Therefore, no modification of the search algorithms is needed and we can also make use of syntactic information for both languages, source and target (see also Section 5). Most of the previous work limit themselves only to the target language side, as the correspondences between the syntact"
2008.iwslt-papers.7,2002.tmi-tutorials.2,0,0.0351574,"on systems. Therefore, no modification of the search algorithms is needed and we can also make use of syntactic information for both languages, source and target (see also Section 5). Most of the previous work limit themselves only to the target language side, as the correspondences between the syntactic structures of both languages are hard to define. 3. Hierarchical Phrase Based Translation The baseline system we use is an in-house implementation of a hierarchical phrase-based system, similar to the one presented in [2]. This approach can be seen as an extension of the phrase-based approach [9, 10], where we allow for “gaps” in the extracted phrases. In this way, longer range dependencies in the translation process can be modelled and the reordering is directly integrated in the decoding process. The translation model can be formalized as a synchronous context free grammar, where the rules are of the form X → hγ, α, ∼i where X is a non-terminal, γ and α are strings of terminals (respectively in the source and target languages) and non-terminals, and ∼ is a one-to-one correspondence between the non-terminals of α and γ, which shows corresponding “elided” parts in the source and target se"
2008.iwslt-papers.7,N03-1017,0,0.00596269,"on systems. Therefore, no modification of the search algorithms is needed and we can also make use of syntactic information for both languages, source and target (see also Section 5). Most of the previous work limit themselves only to the target language side, as the correspondences between the syntactic structures of both languages are hard to define. 3. Hierarchical Phrase Based Translation The baseline system we use is an in-house implementation of a hierarchical phrase-based system, similar to the one presented in [2]. This approach can be seen as an extension of the phrase-based approach [9, 10], where we allow for “gaps” in the extracted phrases. In this way, longer range dependencies in the translation process can be modelled and the reordering is directly integrated in the decoding process. The translation model can be formalized as a synchronous context free grammar, where the rules are of the form X → hγ, α, ∼i where X is a non-terminal, γ and α are strings of terminals (respectively in the source and target languages) and non-terminals, and ∼ is a one-to-one correspondence between the non-terminals of α and γ, which shows corresponding “elided” parts in the source and target se"
2008.iwslt-papers.7,P07-1019,0,0.0207936,"directions source-to-target and target-to-source, which get combined log-lineally with additional IBM1-like word level scores at the phrase level, word and phrase penalty scores at generation time. The decoding process is basically a parsing of the source sentence according to the defined grammar, keeping track of the target language translation contexts in order to compute language model scores during the translation process. In order to deal with the high computational effort of the search process, early pruning is carried out in the form of “cube pruning” or its lazy version “cube growing” [11]. 4. Refinement of Extraction Heuristics In standard phrase-based translation, the extraction of additional phrase pairs by including non-aligned words adjacent to the standard phrases, both in the source and target language, has proven to be beneficial in the translation process. However, in [2] they are not included in the extraction process, probably for efficiency reasons. Proceedings of IWSLT 2008, Hawaii - U.S.A. We however, found it beneficial to include them in the translation process. Although difficult to justify from a practical point of view, practice has shown that simple heuristi"
2008.iwslt-papers.7,P03-1054,0,0.0114961,"les and thus the system is able to make a better usage of bilingual correspondences between syntactic structures. Furthermore, the inclusion of this information as additional scores in the phrases does not have any impact on computation time. Our goal is to determine if the bilingual phrase pair corresponds to some syntactic structures, or not. We stress again that we do not limit the amount of phrases we extract, as non-syntactical phrases are necessary to achieve good translation performance [6]. We parse the English part with Charniak’s parser1 and the Chinese part with the Stanford parser [12]. Given an initial phrase pair we analyze both parts (source and target) independently. In order to weight a phrase ranging from position i to j, we check whether this sequence corresponds to the yield of some node in the parse tree. If not, we first determine the minimum number of words that we have to delete or add to the phrase so that it can be associated with such a node. In order to compute this number we search in the tree in a bottom-up manner, looking for the lowest node that does not cover all words, or in a top-down manner, looking for the highest node that covers all the words of t"
2008.iwslt-papers.7,P03-1021,0,0.0333238,"Missing"
2008.iwslt-papers.7,W03-1709,0,0.0119376,"Missing"
2008.iwslt-papers.7,2006.iwslt-papers.5,0,0.0141788,"yntax information improves the translation performance in some cases. 7. Discussion We believe that the results presented in the previous section must be interpreted cautiously. Table 2 also shows the performance of the different systems on the test04 data which we used as development set for parameter tuning. In this corpus the variability of the results is much greater and no clear conclusions can be drawn. This can partly be due to the relatively small size of the data used and also due to instabilities in the optimization algorithm used (downhill simplex), as pointed out in Lambert et al. [16]. The consistent results obtained on the blind test data set, however, give a reasonable indication that the proposed methods improve translation quality. 10. References [1] P. F. Brown, S. A. Della Pietra, V. J. Della Pietra, and R. L. Mercer, “The mathematics of statistical machine translation: Parameter estimation,” Computational Linguistics, vol. 19, no. 2, pp. 263–311, June 1993. [2] D. Chiang, “Hierarchical Phrase-Based Translation,” Computational Linguistics, vol. 33, no. 2, pp. 201–228, 2007. [3] ——, “A Hierarchical Phrase-Based Model for Statistical Machine Translation,” in Proc. of t"
2008.iwslt-papers.7,N04-1035,0,\N,Missing
2008.iwslt-papers.7,J93-2003,0,\N,Missing
2008.iwslt-papers.7,P05-1033,0,\N,Missing
2008.iwslt-papers.7,D07-1079,0,\N,Missing
2008.iwslt-papers.7,2007.iwslt-1.25,1,\N,Missing
2008.iwslt-papers.7,J07-2003,0,\N,Missing
2008.iwslt-papers.7,2007.iwslt-1.10,0,\N,Missing
2008.iwslt-papers.8,W99-0604,1,0.531725,"Missing"
2008.iwslt-papers.8,2002.tmi-tutorials.2,0,0.085219,"Missing"
2008.iwslt-papers.8,N03-1017,0,0.0338709,"Missing"
2008.iwslt-papers.8,J99-4005,0,0.179726,"Missing"
2008.iwslt-papers.8,J03-1005,1,0.615064,"Missing"
2008.iwslt-papers.8,P07-2045,1,0.0120572,"Missing"
2008.iwslt-papers.8,J04-4002,1,0.39413,"Missing"
2008.iwslt-papers.8,2007.mtsummit-papers.43,0,0.0219142,"Missing"
2008.iwslt-papers.8,W06-3602,0,0.0295213,"Missing"
2008.iwslt-papers.8,P05-1033,0,0.0294416,"Missing"
2008.iwslt-papers.8,P07-1019,0,0.292006,"Missing"
2009.eamt-1.31,J90-2002,0,0.756696,"Missing"
2009.eamt-1.31,J93-2003,0,0.0364369,"226–233, Barcelona, May 2009 226 aJ1 := a1 , . . . , aj , . . . , aJ is introduced for aligning the source sentence f1J to the target sentence eI1 . The source word at position j is aligned to the target word at position i = aj . The alignment aJ1 may contain special alignment aj = 0, which means that the source word at index j is not aligned to any target word. Because a word in the source sentence cannot be aligned to multiple words in the target sentence, the alignment is trained in both translation directions: source to target and target to source. For each direction, a Viterbi alignment (Brown et al., 1993) is computed: A1 = {(aj , j)|aj ≥ 0} and A2 = {(i, bi )|bi ≥ 0}. Here, aJ1 is the alignment from the source language to the target language and bI1 is the alignment from the target language to the source language. To obtain more symmetrized alignments, A1 and A2 can be combined into one alignment matrix A with the following combination methods. More details are described in (Och and Ney, 2004): Figure 1: An alignment example with unaligned words. ? that is why w  • union: A = A1 ∪ A2 • ref ined: extend from the intersection. intersect ⊆ ref ined ⊆ union 1 LDC2006E93: LDC GALE Y1 Q4 Release -"
2009.eamt-1.31,N03-1017,0,0.0415861,"Missing"
2009.eamt-1.31,P07-1039,0,0.0127158,") and implemented by e. g. (Koehn et al., 2003). Since this widely used phrase extraction method depends on word alignments, it is often assumed that the quality c 2009 European Association for Machine Translation. of word alignment is critical to the success of translation. However, some research have shown that the large gains in alignment accuracy often lead to, at best, minor gains in translation performance (Lopez and Resnik, 2006). They concluded that it could be more useful to directly investigate ways to reduce the noise in phrase extraction than improving word alignment. The work by (Ma et al., 2007) shows that a good phrase segmentation is important for translation result. Encouraged by the work, this paper explores the influence of the unaligned words on the phrase extraction and machine translation results. We show that the presence of unaligned words causes extraction of “noisy” phrases which can lead to insertion and deletion errors in the translation output. Furthermore, we propose approaches for “hard” and “soft” deletion of the unaligned words on the source language side. We then show that better way to deal with unaligned words can substantially improve translation quality, on bo"
2009.eamt-1.31,W99-0604,1,0.705124,"ngs of words between each source sentence and its target language translation. Because of the difference in the structure of the involved languages, not all words in the source language have a corresponding word in the target language. So in the alignments, no matter manually created or automatically learned, some words are aligned, some are not. Current state-of-the-art statistical machine translation is based on phrases. First the word alignments for the training corpus are generated. Then phrase alignments are inferred heuristically from the word alignments. This approach was presented by (Och et al., 1999) and implemented by e. g. (Koehn et al., 2003). Since this widely used phrase extraction method depends on word alignments, it is often assumed that the quality c 2009 European Association for Machine Translation. of word alignment is critical to the success of translation. However, some research have shown that the large gains in alignment accuracy often lead to, at best, minor gains in translation performance (Lopez and Resnik, 2006). They concluded that it could be more useful to directly investigate ways to reduce the noise in phrase extraction than improving word alignment. The work by (M"
2009.eamt-1.31,J03-1002,1,0.0135217,"a. The large vocabulary GALE data were all provided by LDC. The test data has four genres: broadcast news (BN), broadcast conversations (BC), newswire (NW) and webtext (WT). The first two genres are for speech translation and the last two are for text translation. Here, we only carried out experiments on NW. The sentences of the GALE task are longer (around 30 words per sentence) and more difficult to translate. The corpus statistics for both tasks are shown in Table 4: 5.2 Baseline System Our baseline system is a standard phrase-based SMT system. Word alignments are obtained by using GIZA++ (Och and Ney, 2003) with IBM model 4 3 . We symmetrized bidirectional alignments using the refined heuristic (Och and Ney, 2004). The phrase-based translation model is a log-linear model that include phrase translation probabilities and word-based translation probabilities in both translation directions, phrase count models, word and phrase penalty, target language model (LM) and a distortion model. Language models were built using the SRI language mod3 Specifically, on GALE data we performed 5 iterations of Model 1, 5 iterations of HMM, 2 iterations of Model 4. On BTEC data we performed 4 iterations of Model 1,"
2009.eamt-1.31,P07-1090,0,0.0155861,"unction words and content words, we could find that the correct unaligned words are roughly function words, while the wrong unaligned words are usually content words. The function words have little lexical meaning, but instead serve to express grammatical relationships with other words within a sentence On the contrary, the content words usually carry meaning, which are “natural units” of translation between languages. If we just focus on the disambiguation of multiple phrases and not consider applying grammatical information in function words to the translation system, like the work done by (Setiawan et al., 2007), the simplest way of reducing the multiple phrases is to delete the ’correct’ unaligned words: the function words. The function words at the target side should not be touched, since they are necessary to complete a good sentence. However, the function words at the source side could be removed, when they have no corresponding translations. 4.1 Deletion Candidates Not all unaligned words should be removed. Besides the content words, a source function word could also have correct mappings to the target words in some sentences. We have used two constraints to filter out the words which can be del"
2009.eamt-1.31,takezawa-etal-2002-toward,0,0.0198983,"nments by merging the phrase counts and rewhich means that they were deleted wrongly. compute the phrase probabilities. 229 5 Experimental Setup BTEC Train: Sentences Running words Dev: Sentences Running words Test: Sentences Running words GALE Train: Sentences Running words Dev08: Sentences Running words Test08: Sentences Running words 5.1 Data We carried out MT experiments for translation from Chinese to English on two data sets: BTEC08 and GALE08. The BTEC08 data was provided within the IWSLT 2008 evaluation campaign (Paul, 2008), extracted from the Basic Traveling Expression Corpus(BTEC) (Takezawa et al., 2002). The data is a multilingual speech corpus which contains sentences which are usually found in books for tourists. The sentences are short, with less than 10 words on average. The parallel training data is relatively small. We added the official IWSLT08 training data, the IWSLT06 dev data and IWSLT06 evaluation data and their references to the training data. The development and test sets in the experiments below are from the IWSLT04 and IWSLT05 evaluation data. We found that the two data sets are not similar, so we took the first half of each and combine them as dev data. The remaining two hal"
2009.eamt-1.31,J04-4002,1,\N,Missing
2009.eamt-1.31,2008.iwslt-evaluation.1,0,\N,Missing
2009.eamt-1.31,2006.amta-papers.11,0,\N,Missing
2009.eamt-1.33,P05-1033,0,0.0279192,"l itself is also relatively simple and allows for efficient generation algorithms like for example beam search (see e.g. (Koehn, 2004)). This allowed the approach to scale to bigger tasks and it is still one of the most widely used models nowadays. The current trend in SMT, however, is to bring more c 2009 European Association for Machine Translation. information in the form of grammatical structures. There are mainly two possibilities, in the form of linguistically motivated grammars (e.g. (Marcu et al., 2006)) or just formal grammars, which do not need to have a linguistic equivalent (e.g. (Chiang, 2005)). These more expressive models have associated a more difficult search problem, which normally involves a parsing process (usually a variation of the CYK algorithm) while incorporating the translation information. The inclusion of language model (LM) information replicates nodes in the parsing tree, which increases the cost of the generation process. And not to be underestimated, the number of rules the system has to deal with can be of one order of magnitude bigger than the standard phrase-based approach, depending on the model1 . Therefore, new, efficient algorithms for translation with the"
2009.eamt-1.33,J07-2003,0,0.810445,"g process (usually a variation of the CYK algorithm) while incorporating the translation information. The inclusion of language model (LM) information replicates nodes in the parsing tree, which increases the cost of the generation process. And not to be underestimated, the number of rules the system has to deal with can be of one order of magnitude bigger than the standard phrase-based approach, depending on the model1 . Therefore, new, efficient algorithms for translation with these richer models had to be developed. In this paper we will concentrate on the cube growing algorithm (Huang and Chiang, 2007), a lazy version of the cube pruning algorithm (Chiang, 2007). These algorithms represent the search space as an hypergraph and add language model scores as necessary. The most time-consuming operation in the translation process is the LM score computation, especially when huge LMs are used. The cube growing algorithm follows an on-demand computation strategy and tries to minimize the number of LM scores that need to be computed. In order to minimize the number of search errors, while still maintaining computational efficiency, the algorithm depends on an (efficient) heuristic for these LM cos"
2009.eamt-1.33,P07-1019,0,0.44229,"s a parsing process (usually a variation of the CYK algorithm) while incorporating the translation information. The inclusion of language model (LM) information replicates nodes in the parsing tree, which increases the cost of the generation process. And not to be underestimated, the number of rules the system has to deal with can be of one order of magnitude bigger than the standard phrase-based approach, depending on the model1 . Therefore, new, efficient algorithms for translation with these richer models had to be developed. In this paper we will concentrate on the cube growing algorithm (Huang and Chiang, 2007), a lazy version of the cube pruning algorithm (Chiang, 2007). These algorithms represent the search space as an hypergraph and add language model scores as necessary. The most time-consuming operation in the translation process is the LM score computation, especially when huge LMs are used. The cube growing algorithm follows an on-demand computation strategy and tries to minimize the number of LM scores that need to be computed. In order to minimize the number of search errors, while still maintaining computational efficiency, the algorithm depends on an (efficient) heuristic for these LM cos"
2009.eamt-1.33,koen-2004-pharaoh,0,0.0772177,"ion performance and efficiency and propose a new heuristic which efficiently decreases memory requirements and computation time, while maintaining translation performance. 1 Introduction In the last decade, the phrase-based approach to machine translation has been the de-facto standard for statistical machine translation (SMT) systems. The main reason was that it offered a great improvement in translation quality over its predecessors, the single-word based models. The model itself is also relatively simple and allows for efficient generation algorithms like for example beam search (see e.g. (Koehn, 2004)). This allowed the approach to scale to bigger tasks and it is still one of the most widely used models nowadays. The current trend in SMT, however, is to bring more c 2009 European Association for Machine Translation. information in the form of grammatical structures. There are mainly two possibilities, in the form of linguistically motivated grammars (e.g. (Marcu et al., 2006)) or just formal grammars, which do not need to have a linguistic equivalent (e.g. (Chiang, 2005)). These more expressive models have associated a more difficult search problem, which normally involves a parsing proces"
2009.eamt-1.33,W06-1606,0,0.01255,"great improvement in translation quality over its predecessors, the single-word based models. The model itself is also relatively simple and allows for efficient generation algorithms like for example beam search (see e.g. (Koehn, 2004)). This allowed the approach to scale to bigger tasks and it is still one of the most widely used models nowadays. The current trend in SMT, however, is to bring more c 2009 European Association for Machine Translation. information in the form of grammatical structures. There are mainly two possibilities, in the form of linguistically motivated grammars (e.g. (Marcu et al., 2006)) or just formal grammars, which do not need to have a linguistic equivalent (e.g. (Chiang, 2005)). These more expressive models have associated a more difficult search problem, which normally involves a parsing process (usually a variation of the CYK algorithm) while incorporating the translation information. The inclusion of language model (LM) information replicates nodes in the parsing tree, which increases the cost of the generation process. And not to be underestimated, the number of rules the system has to deal with can be of one order of magnitude bigger than the standard phrase-based"
2009.eamt-1.33,J03-1002,1,0.00761933,"tional LM computations is small. On the other side, when compared with the original heuristic, we eliminate the need of the -LM pass altogether. 5.2 Choosing the Classes There is still the open question of how to choose the word-to-class mapping C. In our case we investigated two alternatives. The first one is to use automatically generated classes. We used the mkcls tool (Och, 1999), which uses a maximum likelihood approach on a corpus by using a class bigram decomposition. This tool is widely used as part of the preprocessing steps when training statistical alignments using the GIZA++ tool (Och and Ney, 2003). This criterion seems to be adequate for our task, as both the words themselves and the context are taken into account. Another possibility would be to use Part-ofSpeech tags as word classes. The tagging itself can, however, be an expensive process, involving a new search in itself. We applied a simplifying assumption, in which we remove the ambiguity of the tagging. We applied a full POS-tagger (Brants, 2000) to the training corpora and then we simply selected the most frequent POS tag for each word. In this way we defined our mapping C. 6 Experimental Results Experiments are reported using"
2009.eamt-1.33,E99-1010,0,0.0154992,"c introduces a new language model into the translation process. However, the size of this language model is quite small, especially when compared with the full language model used in search, and thus the overhead of the additional LM computations is small. On the other side, when compared with the original heuristic, we eliminate the need of the -LM pass altogether. 5.2 Choosing the Classes There is still the open question of how to choose the word-to-class mapping C. In our case we investigated two alternatives. The first one is to use automatically generated classes. We used the mkcls tool (Och, 1999), which uses a maximum likelihood approach on a corpus by using a class bigram decomposition. This tool is widely used as part of the preprocessing steps when training statistical alignments using the GIZA++ tool (Och and Ney, 2003). This criterion seems to be adequate for our task, as both the words themselves and the context are taken into account. Another possibility would be to use Part-ofSpeech tags as word classes. The tagging itself can, however, be an expensive process, involving a new search in itself. We applied a simplifying assumption, in which we remove the ambiguity of the taggin"
2009.eamt-1.33,D08-1012,0,0.0427386,"Missing"
2009.eamt-1.33,A00-1031,0,0.00859756,"approach on a corpus by using a class bigram decomposition. This tool is widely used as part of the preprocessing steps when training statistical alignments using the GIZA++ tool (Och and Ney, 2003). This criterion seems to be adequate for our task, as both the words themselves and the context are taken into account. Another possibility would be to use Part-ofSpeech tags as word classes. The tagging itself can, however, be an expensive process, involving a new search in itself. We applied a simplifying assumption, in which we remove the ambiguity of the tagging. We applied a full POS-tagger (Brants, 2000) to the training corpora and then we simply selected the most frequent POS tag for each word. In this way we defined our mapping C. 6 Experimental Results Experiments are reported using the 2008 WMT evaluation data (Callison-Burch et al., 2008), for the German-to-English translation direction. This corpus consists of the speeches held in the plenary session of the European Parliament. The test data was the in-domain data used in the evaluation. The statistics of the corpus can be seen in Table 1. Figure 2 shows the results for the -LM heuristic3 . The BLEU score is shown in Figure 2(a). The be"
2009.eamt-1.33,W08-0309,0,0.0121553,"dequate for our task, as both the words themselves and the context are taken into account. Another possibility would be to use Part-ofSpeech tags as word classes. The tagging itself can, however, be an expensive process, involving a new search in itself. We applied a simplifying assumption, in which we remove the ambiguity of the tagging. We applied a full POS-tagger (Brants, 2000) to the training corpora and then we simply selected the most frequent POS tag for each word. In this way we defined our mapping C. 6 Experimental Results Experiments are reported using the 2008 WMT evaluation data (Callison-Burch et al., 2008), for the German-to-English translation direction. This corpus consists of the speeches held in the plenary session of the European Parliament. The test data was the in-domain data used in the evaluation. The statistics of the corpus can be seen in Table 1. Figure 2 shows the results for the -LM heuristic3 . The BLEU score is shown in Figure 2(a). The best results are achieved with a -LM n-best size of 200. The difference in performance, however is not too big and nearly optimal results can already be achieved with a -LM n-best size of 50. When looking into the computational resources the diff"
2010.amta-papers.32,W09-0437,0,0.0133723,"rget generation has proven very successful and robust by relying on statistics learned purely on surface forms from huge corpora. Such systems still outperform hierarchical setups in many evaluations. (Galley and Manning, 2010) even show that conventional systems can be extended in a way that they are able to make use of phrases with gaps similar to the rule set of hierarchical systems. In their experiments, a conventional system with gappy phrases and lexicalized reordering produces a significantly better output for Chinese-English than a hierarchical one without any syntactic enhancements. (Auli et al., 2009) challenge the common assumption that there are structural differences in the types of outputs the two translation approaches can produce. Analyzing the search spaces of conventional phrase-based and hierarchical systems, they find a high overlap. They argue that the main difference is in the parameterization, not in the expressiveness of the translation models. Recent research has demonstrated how two types of extended lexicon models called triplet lexicon model (we will abbreviate this simply as triplets in many cases) and discriminative word lexicon (DWL) can improve the translation results"
2010.amta-papers.32,J93-2003,0,0.0129456,"ir computational demands in training, and their final size. The experimental evaluation is presented in Section 5. We first give a characterization of the experimental setup and the main details of our systems. We then report on the different extended lexicon models we trained and proceed with a comparison of the translation results using these models in standard phrase-based and hierarchical translation. 3 Previous Work (Hasan et al., 2008) proposed triplet lexicon models for statistical machine translation for the first time. Triplet lexicon models are related to the well-known IBM-1 model (Brown et al., 1993) but extend it with a second trigger. (Hasan et al., 2008) also introduced the restrictions that are applied to triplets in this work, they did however apply the models only in an n-best list reranking framework. They evaluated their methods on a small Chinese-English and on a Spanish-English/English-Spanish task. (Hasan and Ney, 2009) investigated triplet lexicon scoring in a conventional phrase-based decoder and compared translation performance of the so-called path-constrained (or path-aligned) triplet models applied in reranking to an integrated application in search on a large-scale Chine"
2010.amta-papers.32,P05-1033,0,0.343261,"y within a local context and give reliable results as long as only information from a limited window is required. But reordering in translation between different languages, recursive embedding of subphrases, as it is common in natural language, and distant lexical interconnections are hard to model and difficult to handle in a computationally efficient way. 1 1 (Knight, 1999) proofs that the decoding problem with unrestricted reorderings is NP-complete. The hierarchical phrase-based approach to SMT promises to be able to capture translations whose scope is larger than a few consecutive words (Chiang, 2005; Chiang, 2007). By allowing gaps within bilingual phrases that are indicated by corresponding place-holders (i.e. co-indexed non-terminals), the phrase table of a hierarchical phrase-based translation (HPBT) system can be considered to be the production set of a synchronous context-free grammar. This formal grammar usually does not comply with a linguistically motivated grammar, but as the search procedure is realized as a probabilistic parser, the hierarchical phrase-based paradigm connects somewhat closer to more linguistics-related work in natural language processing than conventional phra"
2010.amta-papers.32,J07-2003,0,0.281662,"al context and give reliable results as long as only information from a limited window is required. But reordering in translation between different languages, recursive embedding of subphrases, as it is common in natural language, and distant lexical interconnections are hard to model and difficult to handle in a computationally efficient way. 1 1 (Knight, 1999) proofs that the decoding problem with unrestricted reorderings is NP-complete. The hierarchical phrase-based approach to SMT promises to be able to capture translations whose scope is larger than a few consecutive words (Chiang, 2005; Chiang, 2007). By allowing gaps within bilingual phrases that are indicated by corresponding place-holders (i.e. co-indexed non-terminals), the phrase table of a hierarchical phrase-based translation (HPBT) system can be considered to be the production set of a synchronous context-free grammar. This formal grammar usually does not comply with a linguistically motivated grammar, but as the search procedure is realized as a probabilistic parser, the hierarchical phrase-based paradigm connects somewhat closer to more linguistics-related work in natural language processing than conventional phrase-based transl"
2010.amta-papers.32,N10-1140,0,0.0226689,"02) without having to impose any hard contraints on the translation process. Bringing different lines of research together in a natural way by augmenting hierarchical translation with syntactic knowledge has primarily been done with the intent to be able to produce better structured outputs with the resulting systems. On the other hand, conventional phrase-based translation with left-to-right target generation has proven very successful and robust by relying on statistics learned purely on surface forms from huge corpora. Such systems still outperform hierarchical setups in many evaluations. (Galley and Manning, 2010) even show that conventional systems can be extended in a way that they are able to make use of phrases with gaps similar to the rule set of hierarchical systems. In their experiments, a conventional system with gappy phrases and lexicalized reordering produces a significantly better output for Chinese-English than a hierarchical one without any syntactic enhancements. (Auli et al., 2009) challenge the common assumption that there are structural differences in the types of outputs the two translation approaches can produce. Analyzing the search spaces of conventional phrase-based and hierarchi"
2010.amta-papers.32,N09-2005,1,0.784137,"sing these models in standard phrase-based and hierarchical translation. 3 Previous Work (Hasan et al., 2008) proposed triplet lexicon models for statistical machine translation for the first time. Triplet lexicon models are related to the well-known IBM-1 model (Brown et al., 1993) but extend it with a second trigger. (Hasan et al., 2008) also introduced the restrictions that are applied to triplets in this work, they did however apply the models only in an n-best list reranking framework. They evaluated their methods on a small Chinese-English and on a Spanish-English/English-Spanish task. (Hasan and Ney, 2009) investigated triplet lexicon scoring in a conventional phrase-based decoder and compared translation performance of the so-called path-constrained (or path-aligned) triplet models applied in reranking to an integrated application in search on a large-scale Chinese-English task. They did not evaluate different variants of the model. The DWL model in a variant that is trained using seen features as well as unseen features was presented by (Mauser et al., 2009). We will compare our new variant of DWL models to the model as described by them. (Mauser et al., 2009) also compared the effect of a tr"
2010.amta-papers.32,D08-1039,1,0.869383,"Missing"
2010.amta-papers.32,P07-1019,0,0.0346242,"e parallel corpus and the LDC Gigaword v4 corpus. We measured a perplexity of 96.9 on the four reference translations of MT06. 5.1.1 Hierarchical Systems The hierarchical translation system we utilize has been developed at RWTH and has recently been released as open source software (Vilar et al., 2010). It implements the hierarchical phrase-based paradigm that has been introduced by (Chiang, 2005). We performed shallow search as defined in (Iglesias et al., 2009), i.e. we did not allow substitutions of non-terminals by strings containing nonterminals again, and ran the cube pruning algorithm (Huang and Chiang, 2007) with 500-best generation. Furthermore, we configured observation histogram pruning at a value of 50. Apart from the hierarchical phrase translation model, the language model and the extended lexicon models, the log-linear model combination of our systems comprises source-to-target and targetto-source phrase translation probabilities, IBM-1 source-to-target and target-to-source lexical translation probabilities, two features that account for some control about the application of hierarchical rules as opposed to initial rules, length penalties on word and phrase level and four binary features,"
2010.amta-papers.32,E09-1044,0,0.0310373,"Missing"
2010.amta-papers.32,J99-4005,0,0.0414614,"e dependencies into account is still one of the main problems in today’s statistical machine translation (SMT). State-of-the-art systems comprise components like a phrase translation model and n-gram language models that act effectively within a local context and give reliable results as long as only information from a limited window is required. But reordering in translation between different languages, recursive embedding of subphrases, as it is common in natural language, and distant lexical interconnections are hard to model and difficult to handle in a computationally efficient way. 1 1 (Knight, 1999) proofs that the decoding problem with unrestricted reorderings is NP-complete. The hierarchical phrase-based approach to SMT promises to be able to capture translations whose scope is larger than a few consecutive words (Chiang, 2005; Chiang, 2007). By allowing gaps within bilingual phrases that are indicated by corresponding place-holders (i.e. co-indexed non-terminals), the phrase table of a hierarchical phrase-based translation (HPBT) system can be considered to be the production set of a synchronous context-free grammar. This formal grammar usually does not comply with a linguistically mo"
2010.amta-papers.32,D09-1022,1,0.908847,"translation approaches can produce. Analyzing the search spaces of conventional phrase-based and hierarchical systems, they find a high overlap. They argue that the main difference is in the parameterization, not in the expressiveness of the translation models. Recent research has demonstrated how two types of extended lexicon models called triplet lexicon model (we will abbreviate this simply as triplets in many cases) and discriminative word lexicon (DWL) can improve the translation results of conventional phrase-based systems in n-best reranking as well as directly in beam-search decoding (Mauser et al., 2009). Both of them account for global source sentence context to predict context-specific target words. Their main advantage is that they promote a better lexical selection than the baseline models alone are able to achieve. With the availability of DWL and triplet model scoring implementations in a state-of-the-art hierarchical phrase-based translation system (Vilar et al., 2010), we are now in a position to compare conventional and hierarchical phrase-based setups — either of them enriched with extended lexicon models — against each other. On the large-scale NIST Arabic-English translation task,"
2010.amta-papers.32,P02-1038,1,0.503195,"stem can be considered to be the production set of a synchronous context-free grammar. This formal grammar usually does not comply with a linguistically motivated grammar, but as the search procedure is realized as a probabilistic parser, the hierarchical phrase-based paradigm connects somewhat closer to more linguistics-related work in natural language processing than conventional phrase-based translation (PBT). Several efforts have been made recently to engineer syntactically more informed SMT systems. Appropriate models can be introduced into the log-linear framework of modern SMT systems (Och and Ney, 2002) without having to impose any hard contraints on the translation process. Bringing different lines of research together in a natural way by augmenting hierarchical translation with syntactic knowledge has primarily been done with the intent to be able to produce better structured outputs with the resulting systems. On the other hand, conventional phrase-based translation with left-to-right target generation has proven very successful and robust by relying on statistics learned purely on surface forms from huge corpora. Such systems still outperform hierarchical setups in many evaluations. (Gal"
2010.amta-papers.32,J03-1002,1,0.0125958,"gain   Nefˆ 1 ∆Gefˆ ≥ Nefˆ log − 1 (9) Nfˆ NNe Ne ). N can be calculated simply by using the counts Nefˆ, Ne and Nf computed from the corpus. It should be mentioned that this criterion can be applied only to seen pairs. In the case of unseen pairs the logarithm is undefined. + N log(1 + 5 5.1 Experiments Experimental Setup We used a training corpus of 2.5M Arabic-English sentence pairs to set up the hierarchical as well as the conventional phrase-based systems. Word alignments in both directions were produced with GIZA++ and symmetrized according to the refined method that was proposed by (Och and Ney, 2003). Arabic Sentences English 2 514 413 Running words 54 324 372 55 348 390 Vocabulary 264 528 207 780 Singletons 115 171 91 390 Table 1: Data statistics for the preprocessed ArabicEnglish parallel training corpus. Numbers have been replaced by a special category symbol. The scaling factors of the log-linear model combination have been optimized on the MT06 NIST test corpus. MT08 was employed as held-out test data. Detailed statistics about the parallel data are given in Table 1, the characteristics of the development and the test corpus are reported in Table 2. All of the configurations use the"
2010.amta-papers.32,W10-1738,1,0.909202,"iate this simply as triplets in many cases) and discriminative word lexicon (DWL) can improve the translation results of conventional phrase-based systems in n-best reranking as well as directly in beam-search decoding (Mauser et al., 2009). Both of them account for global source sentence context to predict context-specific target words. Their main advantage is that they promote a better lexical selection than the baseline models alone are able to achieve. With the availability of DWL and triplet model scoring implementations in a state-of-the-art hierarchical phrase-based translation system (Vilar et al., 2010), we are now in a position to compare conventional and hierarchical phrase-based setups — either of them enriched with extended lexicon models — against each other. On the large-scale NIST Arabic-English translation task, we show that though a gap between the BLEU scores of the baseline systems can be observed, the two paradigms perform exactly the same if triplet and DWL models are added to the setups. Hierarchical and standard phrase-based statistical machine translation currently seem to operate at a comparable level, with advantages in some points for each of them. A good parameterization"
2010.amta-papers.32,2008.iwslt-papers.8,1,0.873322,"model, the language model and the extended lexicon models, the log-linear model combination of our systems comprises source-to-target and targetto-source phrase translation probabilities, IBM-1 source-to-target and target-to-source lexical translation probabilities, two features that account for some control about the application of hierarchical rules as opposed to initial rules, length penalties on word and phrase level and four binary features, essentially simple count features. 5.1.2 Phrase-Based Systems Our standard phrase-based machine translation system operates in the way described by (Zens and Ney, 2008). Phrase translation and word lexicon models in both directions, phrase and word penalties, a binary model that indicates a source phrase Extended Lexicon Models Triplet models. We prepared several triplet models of the variant denoted as path-constrained in Section 4.1 as well as of the variant denoted as uncontrained. The number of EM iterations has been 6 in all cases. Four different path-constrained triplet models are considered, one without any count cutoff and three with cutoffs of 2, 3, and 4, respectively. Like for the word alignments used for the phrase extraction, we used symmetrized"
2010.amta-papers.32,C04-1030,1,0.893716,"Missing"
2010.amta-papers.8,N09-1025,0,0.0562958,"Missing"
2010.amta-papers.8,J07-2003,0,0.189032,"our comparison, since the risk of converging to poor local optima during the optimization procedure increases when too many features are available, thus making it difficult to draw clear conclusions. 2 Hierarchical Machine Translation The hierarchical phrase-based approach can be considered to be an extension of the standard phrase-based model. In this model, we allow the phrases to have “gaps”, i.e. we allow noncontiguous parts of the source sentence to be translated into possibly non-contiguous parts of the target sentence. The model can be formalized as a synchronous context-free grammar (Chiang, 2007). The bilingual rules are of the form X → hγ, α, ∼i , (1) where X is a non-terminal, γ and α are strings of terminals and non-terminals, and ∼ is a one-toone correspondence between the non-terminals of α and γ. Two examples of this kind of rules for the German-to-English translation direction are X → hich habe X ∼0 gesehen, I have seen X ∼0 i X → hum X ∼0 zu X ∼1 , in order to X ∼1 X ∼0 i where the indices in the non-terminals represent the correspondence between source and target “gaps”. This model has the additional advantage that reordering is integrated as part of the model itself, as can"
2010.amta-papers.8,W08-1301,0,0.0230466,"al integrity during the extraction process. Instead we produce additional information for each phrase. We mark those phrases that do not fit in the model with a binary feature. In this way we allow the corresponding scaling factors to decide whether the phrase can still be used during decoding. This also means that a scaling factor of zero allows the decoder to fall back to the baseline system during the minimum error rate training. We parse the English target sentences with the Stanford parser1 , which is able to produce deep syntactic parses as well as dependency structures (de Marneffe and Manning, 2008). In the following we will present the three syntactic models that we analyze in this work. 1 http://nlp.stanford.edu/software/lex-parser.shtml 3.1 Parse Matching The first model that we employ is also the simplest one. Given a monolingual sentence (be it in the source or the target language) and the associated parse tree, we will say that a lexical phrase extracted from this sentence is syntactically valid if it corresponds to the yield of one of the nodes in the syntax tree. With this model, we hope that we can guide the decoder to prefer phrases that are syntactically sound rather than usin"
2010.amta-papers.8,D07-1079,0,0.0601923,"l phrase-based model for machine translation in Section 2. We then describe the additional syntactical models used in this paper in Section 3. Results and detailed analysis on the NIST Chinese-English task are presented in Section 4. We conclude the paper in Section 5. 1.1 Related Work One of the first papers to incorporate syntactic knowledge in a statistical machine translation model was (Yamada and Knight, 2001), although the performance was not on par with other state-of-the-art approaches at that time. Further development in this direction achieved competitive results, as can be seen in (DeNeefe et al., 2007) and later publications by the same group. In contrast to these studies, which propose new models centered around the syntactic information, we focus mainly on methods that can be easily incorporated into an existing hierarchical system. In this work, we employ soft syntactic features comparable to (Vilar et al., 2008). These features measure how much a phrase corresponds to a valid syntactic structure of a given parse tree. Further, we include a dependency language model in a string-to-dependency model in the spirit of (Shen et al., 2008). We also derive soft syntactic labels as in (Venugopal"
2010.amta-papers.8,N04-1035,0,0.0693091,"s and produce additional initial phrases, also with a low probability. An example is shown in Figure 1(d). The additional phrases that are generated when applying these heuristics are not considered for the later extraction of hierarchical phrases. This is due to the large number of phrases that could be extracted when considering the whole set of initial phrases, which would pose efficiency problems for the translation process. In our experiments, the heuristic methods already increased the number of initial phrases roughly by a factor of 2. 3 Syntactic Features Unlike other work, like e.g. (Galley et al., 2004), we are not enforcing any syntactical integrity during the extraction process. Instead we produce additional information for each phrase. We mark those phrases that do not fit in the model with a binary feature. In this way we allow the corresponding scaling factors to decide whether the phrase can still be used during decoding. This also means that a scaling factor of zero allows the decoder to fall back to the baseline system during the minimum error rate training. We parse the English target sentences with the Stanford parser1 , which is able to produce deep syntactic parses as well as dep"
2010.amta-papers.8,P08-1114,0,0.081536,"t can be easily incorporated into an existing hierarchical system. In this work, we employ soft syntactic features comparable to (Vilar et al., 2008). These features measure how much a phrase corresponds to a valid syntactic structure of a given parse tree. Further, we include a dependency language model in a string-to-dependency model in the spirit of (Shen et al., 2008). We also derive soft syntactic labels as in (Venugopal et al., 2009), where the generic non-terminal of the hierarchical system is replaced by a syntactic label. Other approaches in this field like (Chiang et al., 2009) and (Marton and Resnik, 2008) go into similar directions, but create a rather large quantity of features. We chose not to include their approaches into our comparison, since the risk of converging to poor local optima during the optimization procedure increases when too many features are available, thus making it difficult to draw clear conclusions. 2 Hierarchical Machine Translation The hierarchical phrase-based approach can be considered to be an extension of the standard phrase-based model. In this model, we allow the phrases to have “gaps”, i.e. we allow noncontiguous parts of the source sentence to be translated into"
2010.amta-papers.8,P02-1038,1,0.747643,"Missing"
2010.amta-papers.8,P03-1021,0,0.0297927,"ords Vocabulary OOVs Sentences # Words Vocabulary OOVs Chinese English 3 030 696 77 456 152 81 002 954 83 128 213 076 21 059 95 544 1 664 42 930 172 324 6 387 17 202 1 871 50 353 1 357 36 114 149 057 6 418 17 877 1 375 43 724 Table 1: Statistics for the Chinese-English corpus 4 Experimental Results We used the Chinese-English NIST 2006 evaluation set as a development corpus and the NIST 2008 evaluation set as the blind test corpus. The systems were trained on a medium-sized training set. Statistics can be found in Table 1. All systems were optimized for the BLEU score using Och’s MERT method (Och, 2003), with all scaling factors initialized with a value of 0.1. For rescoring with trigram dependency language models we generated 100-best lists after the optimization process. Translation results obtained applying the methods discussed in Section 3 are shown in Table 2. All three methods yield improvements over the baseline system. The string-todependency method has very strong improvements in TER, while the soft syntactic labels perform very good in terms of BLEU. The parsematch approach is somewhat in between. The combination of the methods also leads to nice synergies. With the exception of t"
2010.amta-papers.8,P08-1066,0,0.396344,"on achieved competitive results, as can be seen in (DeNeefe et al., 2007) and later publications by the same group. In contrast to these studies, which propose new models centered around the syntactic information, we focus mainly on methods that can be easily incorporated into an existing hierarchical system. In this work, we employ soft syntactic features comparable to (Vilar et al., 2008). These features measure how much a phrase corresponds to a valid syntactic structure of a given parse tree. Further, we include a dependency language model in a string-to-dependency model in the spirit of (Shen et al., 2008). We also derive soft syntactic labels as in (Venugopal et al., 2009), where the generic non-terminal of the hierarchical system is replaced by a syntactic label. Other approaches in this field like (Chiang et al., 2009) and (Marton and Resnik, 2008) go into similar directions, but create a rather large quantity of features. We chose not to include their approaches into our comparison, since the risk of converging to poor local optima during the optimization procedure increases when too many features are available, thus making it difficult to draw clear conclusions. 2 Hierarchical Machine Tran"
2010.amta-papers.8,N09-1027,0,0.297999,"Missing"
2010.amta-papers.8,2008.iwslt-papers.7,1,0.938414,"ate syntactic knowledge in a statistical machine translation model was (Yamada and Knight, 2001), although the performance was not on par with other state-of-the-art approaches at that time. Further development in this direction achieved competitive results, as can be seen in (DeNeefe et al., 2007) and later publications by the same group. In contrast to these studies, which propose new models centered around the syntactic information, we focus mainly on methods that can be easily incorporated into an existing hierarchical system. In this work, we employ soft syntactic features comparable to (Vilar et al., 2008). These features measure how much a phrase corresponds to a valid syntactic structure of a given parse tree. Further, we include a dependency language model in a string-to-dependency model in the spirit of (Shen et al., 2008). We also derive soft syntactic labels as in (Venugopal et al., 2009), where the generic non-terminal of the hierarchical system is replaced by a syntactic label. Other approaches in this field like (Chiang et al., 2009) and (Marton and Resnik, 2008) go into similar directions, but create a rather large quantity of features. We chose not to include their approaches into ou"
2010.amta-papers.8,W10-1738,1,0.846637,"rious groups report improvement over their baseline systems with different approaches, but it is not clear whether the benefits of the different methods are complementary or if they rather address the same issues. In this work, we compare three recent syntactic methods that enhance the translation quality. We measure their performance individually and in combination with each other on a medium sized NIST Chinese-English task, and offer some analysis of typical translation examples. All the presented methods are released as part of the open source hierarchical machine translation toolkit Jane (Vilar et al., 2010). This paper is organized as follows: We briefly recapitulate the hierarchical phrase-based model for machine translation in Section 2. We then describe the additional syntactical models used in this paper in Section 3. Results and detailed analysis on the NIST Chinese-English task are presented in Section 4. We conclude the paper in Section 5. 1.1 Related Work One of the first papers to incorporate syntactic knowledge in a statistical machine translation model was (Yamada and Knight, 2001), although the performance was not on par with other state-of-the-art approaches at that time. Further de"
2010.amta-papers.8,P01-1067,0,0.0755085,"the presented methods are released as part of the open source hierarchical machine translation toolkit Jane (Vilar et al., 2010). This paper is organized as follows: We briefly recapitulate the hierarchical phrase-based model for machine translation in Section 2. We then describe the additional syntactical models used in this paper in Section 3. Results and detailed analysis on the NIST Chinese-English task are presented in Section 4. We conclude the paper in Section 5. 1.1 Related Work One of the first papers to incorporate syntactic knowledge in a statistical machine translation model was (Yamada and Knight, 2001), although the performance was not on par with other state-of-the-art approaches at that time. Further development in this direction achieved competitive results, as can be seen in (DeNeefe et al., 2007) and later publications by the same group. In contrast to these studies, which propose new models centered around the syntactic information, we focus mainly on methods that can be easily incorporated into an existing hierarchical system. In this work, we employ soft syntactic features comparable to (Vilar et al., 2008). These features measure how much a phrase corresponds to a valid syntactic s"
2010.iwslt-evaluation.22,W06-3103,1,0.835479,"Workshop on Spoken Language Translation (IWSLT 2010). We used it as an opportunity to incorporate novel methods which have been investigated at RWTH over the last year and which have proven to be successful in other evaluations. We participated in the Arabic-English BTEC task, and used standard alignment and training tools as well as our inhouse phrase-based and open-source hierarchical SMT decoders. We explored and implemented different segmentation tools for Arabic. The methods used to implement those tools vary from rule-based methods (typically encoded as finite state transducers) such as [1], to methods which are statistically-based such as [2] and [3]. All these works have shown that segmentation improves MT quality significantly for both small and large scale tasks. Due to the different methodologies that we apply for segmentation, we expect that there will be complimentary variation in the results achieved by each method. The next step would be to exploit those variations and achieve better results by combining the systems. This paper is organized as follows. In Section 2, we present the data and resources that will be used to build our segmenters and the SMT system. In Sectio"
2010.iwslt-evaluation.22,N04-4015,0,0.0675793,"We used it as an opportunity to incorporate novel methods which have been investigated at RWTH over the last year and which have proven to be successful in other evaluations. We participated in the Arabic-English BTEC task, and used standard alignment and training tools as well as our inhouse phrase-based and open-source hierarchical SMT decoders. We explored and implemented different segmentation tools for Arabic. The methods used to implement those tools vary from rule-based methods (typically encoded as finite state transducers) such as [1], to methods which are statistically-based such as [2] and [3]. All these works have shown that segmentation improves MT quality significantly for both small and large scale tasks. Due to the different methodologies that we apply for segmentation, we expect that there will be complimentary variation in the results achieved by each method. The next step would be to exploit those variations and achieve better results by combining the systems. This paper is organized as follows. In Section 2, we present the data and resources that will be used to build our segmenters and the SMT system. In Section 3, we discuss the problems of Arabic SMT and present"
2010.iwslt-evaluation.22,N06-2013,0,0.0454777,"it as an opportunity to incorporate novel methods which have been investigated at RWTH over the last year and which have proven to be successful in other evaluations. We participated in the Arabic-English BTEC task, and used standard alignment and training tools as well as our inhouse phrase-based and open-source hierarchical SMT decoders. We explored and implemented different segmentation tools for Arabic. The methods used to implement those tools vary from rule-based methods (typically encoded as finite state transducers) such as [1], to methods which are statistically-based such as [2] and [3]. All these works have shown that segmentation improves MT quality significantly for both small and large scale tasks. Due to the different methodologies that we apply for segmentation, we expect that there will be complimentary variation in the results achieved by each method. The next step would be to exploit those variations and achieve better results by combining the systems. This paper is organized as follows. In Section 2, we present the data and resources that will be used to build our segmenters and the SMT system. In Section 3, we discuss the problems of Arabic SMT and present the sol"
2010.iwslt-evaluation.22,N04-4038,0,0.0482616,"asily captured by the IBM alignment models. In this work, we experimented with the following segmenters: • FST - A Finite State Transducer-based approach introduced and implemented by [1]. The FST is used as a framework to implement a set of rules for segmentation of Arabic. The prefixes that are split include w,f,k,l,b,Al and s. Suffixes which are segmented are pronouns (objective and possessive). The method is characterized by fast processing speed but suffers from the lack of context in the decision procedure leading to erroneous output. • SVM - we reimplemented the classifier suggested by [4]. In their method, each character is classified by its segment rule (prefix, stem and suffix) and position (beginning and inside segment). Arabic words are segmented according to the ATB scheme. Additionally, feminine marker normalization (tX→p+X) using an SVM model is applied on top of the segmenter output, which proved to be significant for the performance of MT in our experiments. • CRF - we implemented a CRF classifier for segmentation using similar setup of classifiers and classes as in the SVM model. The software we use as an implementation of conditional random fields is named CRF++4 ."
2010.iwslt-evaluation.22,W07-0813,0,0.052985,"eme. Additionally, feminine marker normalization (tX→p+X) using an SVM model is applied on top of the segmenter output, which proved to be significant for the performance of MT in our experiments. • CRF - we implemented a CRF classifier for segmentation using similar setup of classifiers and classes as in the SVM model. The software we use as an implementation of conditional random fields is named CRF++4 . • MorphTagger - is a general architecture for Part-OfSpeech (POS) tagging of natural languages. The architecture was first proposed in [5] and applied for the task of POS tagging of Hebrew. [6] adapted the architecture to the Arabic language. MorphTagger is implemented using Buckwalter Arabic Morphological Analyzer v1.0 (BAMA) as a morphological analyzer and a Hidden-Markov-Model (HMM) (using the SRIML5 toolkit) as the disambiguator component. • MADA - The Morphological Analysis and Disambiguation of Arabic (MADA) system, developed in [7], can be seen as an extension of an SVM-based system with the incorporation of a morphological analyzer. As in [8], we experiment with different segmentation schemes for each chosen analysis. We use the schemes directly implemented in the MADA versi"
2010.iwslt-evaluation.22,P05-1071,0,0.0466539,"lementation of conditional random fields is named CRF++4 . • MorphTagger - is a general architecture for Part-OfSpeech (POS) tagging of natural languages. The architecture was first proposed in [5] and applied for the task of POS tagging of Hebrew. [6] adapted the architecture to the Arabic language. MorphTagger is implemented using Buckwalter Arabic Morphological Analyzer v1.0 (BAMA) as a morphological analyzer and a Hidden-Markov-Model (HMM) (using the SRIML5 toolkit) as the disambiguator component. • MADA - The Morphological Analysis and Disambiguation of Arabic (MADA) system, developed in [7], can be seen as an extension of an SVM-based system with the incorporation of a morphological analyzer. As in [8], we experiment with different segmentation schemes for each chosen analysis. We use the schemes directly implemented in the MADA version we are using, namely: D1,D2,D3 and the ATB (TB) schemes. 4. Phrase-based system 4.1. Standard phrase-based system (PBT) The phrase-based SMT system used in this work is an inhouse implementation of state-of-the-art phrase-based MT system as described in [9]. We use the standard set of models with phrase translation probabilities for source-to-tar"
2010.iwslt-evaluation.22,2010.amta-papers.8,1,0.836307,"WTH and free for non-commercial use [12]. This approach is an extension of the phrase-based approach, where the phrases are allowed to have gaps [13]. In this way long-range dependencies and reorderings can be modelled in a consistent statistical framework. The system labelled as JANE represents a fairly standard setup of the system and constitutes a baseline upon which the two next systems are built. 5.2. Soft syntax labels (SYN) To extend the hierarchical system with syntax information of the English target side, we derive soft syntactic labels as in [14] with the modifications described in [15]. In this model, instead of considering only a single, generic non-terminal in the underlying grammar, we extend the set of labels to include syntactic categories as found in syntactic parse trees. To extract the syntax information, we parse the English target sentences with the Stanford parser6 . It is important to note that the new non-terminals are considered in a probabilistic way. In this way, the parsing process itself continues to use the generic non-terminal as in the baseline model and the parsing space is unaltered. The extended set of non-terminals is then used to compute a new prob"
2010.iwslt-evaluation.22,2010.iwslt-papers.18,1,0.874946,"h respect to the syntactic constructs. 5.3. Poor-man syntax (POMS) In this approach we apply the same model as described in the previous section, but the method for producing the new 6 http://nlp.stanford.edu/software/lex-parser.shtml JANE BLEU TER 55.4 30.6 55.3 30.2 55.2 29.4 53.9 31.2 54.6 30.2 56.6 28.8| 57.1| 29.4 56.6− 28.9− 53.0 32.4 SYN BLEU TER 55.7 30.8 54.4 31.2 55.7 29.4 54.5 30.9 54.8 31.2 56.5 28.5+ 56.6| 29.2 55.4 30.3 52.7 32.5 POMS BLEU TER 56.1 30.2 56.0− 29.4− 55.2 29.9 54.8 30.8 55.5− 29.7− 56.8− 28.7 57.5∗ 28.5∗ 54.9 29.5 53.4 32.3 non-terminals is altered as described in [16]. Instead of relying on parse trees based on linguistic knowledge we rely on automatic clustering methods. This makes this approach applicable also for underresourced languages for which no linguistic tools may be available. 6. Results The results of the different segmentation methods and schemes are summarized in Table 1. In this table, the best result in a column is marked with |, thus comparing different segmentations for the same decoder setup. We mark with − the best (in a row) performing decoder over a specific segmentation method. ∗ marks the best result overall in the table. For compar"
2010.iwslt-evaluation.22,W10-1747,1,0.898303,"Missing"
2010.iwslt-evaluation.22,2008.iwslt-papers.8,1,0.0907932,"MADA - The Morphological Analysis and Disambiguation of Arabic (MADA) system, developed in [7], can be seen as an extension of an SVM-based system with the incorporation of a morphological analyzer. As in [8], we experiment with different segmentation schemes for each chosen analysis. We use the schemes directly implemented in the MADA version we are using, namely: D1,D2,D3 and the ATB (TB) schemes. 4. Phrase-based system 4.1. Standard phrase-based system (PBT) The phrase-based SMT system used in this work is an inhouse implementation of state-of-the-art phrase-based MT system as described in [9]. We use the standard set of models with phrase translation probabilities for source-to-target and target-to-source direction, smoothing with lexical weights, a word and phrase penalty, distance-based and lexicalized reordering and an n-gram target language model. 4.2. Phrase training (Forced Alignment-FA) To estimate the phrase translation probabilities we experimented with both standard heuristic phrase extraction ([10]) and a forced alignment training procedure as described in [11]. The latter estimates the probabilities as relative frequencies from the phrase-aligned training data, which i"
2010.iwslt-evaluation.22,W99-0604,1,0.294484,"m 4.1. Standard phrase-based system (PBT) The phrase-based SMT system used in this work is an inhouse implementation of state-of-the-art phrase-based MT system as described in [9]. We use the standard set of models with phrase translation probabilities for source-to-target and target-to-source direction, smoothing with lexical weights, a word and phrase penalty, distance-based and lexicalized reordering and an n-gram target language model. 4.2. Phrase training (Forced Alignment-FA) To estimate the phrase translation probabilities we experimented with both standard heuristic phrase extraction ([10]) and a forced alignment training procedure as described in [11]. The latter estimates the probabilities as relative frequencies from the phrase-aligned training data, which is computed by a modified version of the translation decoder. To do this, the translation decoder is constrained to produce the reference translation for each bilingual sentence pair. In order to counteract overfitting, leaving-one-out is applied in training. In addition to providing a statistically well-founded 4 http://crfpp.sourceforge.net/ 5 http://www-speech.sri.com/projects/srilm/ 164 Proceedings of the 7th Internati"
2010.iwslt-evaluation.22,P10-1049,1,0.304281,"ystem used in this work is an inhouse implementation of state-of-the-art phrase-based MT system as described in [9]. We use the standard set of models with phrase translation probabilities for source-to-target and target-to-source direction, smoothing with lexical weights, a word and phrase penalty, distance-based and lexicalized reordering and an n-gram target language model. 4.2. Phrase training (Forced Alignment-FA) To estimate the phrase translation probabilities we experimented with both standard heuristic phrase extraction ([10]) and a forced alignment training procedure as described in [11]. The latter estimates the probabilities as relative frequencies from the phrase-aligned training data, which is computed by a modified version of the translation decoder. To do this, the translation decoder is constrained to produce the reference translation for each bilingual sentence pair. In order to counteract overfitting, leaving-one-out is applied in training. In addition to providing a statistically well-founded 4 http://crfpp.sourceforge.net/ 5 http://www-speech.sri.com/projects/srilm/ 164 Proceedings of the 7th International Workshop on Spoken Language Translation Paris, December 2nd"
2010.iwslt-evaluation.22,W10-1738,1,0.0939642,"010: IWSLT08 results summary (nocase+punc) System CRF FST MADA ATB MADA D1 MADA D2 MADA D3 MorphTagger SVM TOK PBT BLEU TER 55.5 29.8− 54.5 30.7 55.1 29.5 54.8 30.8 55.4 29.9 55.4 29.6 56.5| 29.2| 56.1 29.7 55.5− 30.1− FA BLEU TER 56.4− 30.7 55.9 30.3 57.1+ 29.2+ 55.2− 30.6− 55.5 30.1 56.5 30.1 55.8 30.1 55.9 30.0 54.8 30.3 phrase model, the forced alignment procedure has the benefit of producing smaller phrase tables. 5. Hierarchical system 5.1. Standard hierarchical system (JANE) We used the open source hierarchical phrase-based system Jane, developed at RWTH and free for non-commercial use [12]. This approach is an extension of the phrase-based approach, where the phrases are allowed to have gaps [13]. In this way long-range dependencies and reorderings can be modelled in a consistent statistical framework. The system labelled as JANE represents a fairly standard setup of the system and constitutes a baseline upon which the two next systems are built. 5.2. Soft syntax labels (SYN) To extend the hierarchical system with syntax information of the English target side, we derive soft syntactic labels as in [14] with the modifications described in [15]. In this model, instead of consider"
2010.iwslt-evaluation.22,J07-2003,0,0.142759,"K PBT BLEU TER 55.5 29.8− 54.5 30.7 55.1 29.5 54.8 30.8 55.4 29.9 55.4 29.6 56.5| 29.2| 56.1 29.7 55.5− 30.1− FA BLEU TER 56.4− 30.7 55.9 30.3 57.1+ 29.2+ 55.2− 30.6− 55.5 30.1 56.5 30.1 55.8 30.1 55.9 30.0 54.8 30.3 phrase model, the forced alignment procedure has the benefit of producing smaller phrase tables. 5. Hierarchical system 5.1. Standard hierarchical system (JANE) We used the open source hierarchical phrase-based system Jane, developed at RWTH and free for non-commercial use [12]. This approach is an extension of the phrase-based approach, where the phrases are allowed to have gaps [13]. In this way long-range dependencies and reorderings can be modelled in a consistent statistical framework. The system labelled as JANE represents a fairly standard setup of the system and constitutes a baseline upon which the two next systems are built. 5.2. Soft syntax labels (SYN) To extend the hierarchical system with syntax information of the English target side, we derive soft syntactic labels as in [14] with the modifications described in [15]. In this model, instead of considering only a single, generic non-terminal in the underlying grammar, we extend the set of labels to include syn"
2010.iwslt-evaluation.22,N09-1027,0,0.0119972,"phrase-based system Jane, developed at RWTH and free for non-commercial use [12]. This approach is an extension of the phrase-based approach, where the phrases are allowed to have gaps [13]. In this way long-range dependencies and reorderings can be modelled in a consistent statistical framework. The system labelled as JANE represents a fairly standard setup of the system and constitutes a baseline upon which the two next systems are built. 5.2. Soft syntax labels (SYN) To extend the hierarchical system with syntax information of the English target side, we derive soft syntactic labels as in [14] with the modifications described in [15]. In this model, instead of considering only a single, generic non-terminal in the underlying grammar, we extend the set of labels to include syntactic categories as found in syntactic parse trees. To extract the syntax information, we parse the English target sentences with the Stanford parser6 . It is important to note that the new non-terminals are considered in a probabilistic way. In this way, the parsing process itself continues to use the generic non-terminal as in the baseline model and the parsing space is unaltered. The extended set of non-ter"
2010.iwslt-evaluation.22,popovic-ney-2006-pos,1,\N,Missing
2010.iwslt-evaluation.22,D11-1033,0,\N,Missing
2010.iwslt-evaluation.22,E09-1044,0,\N,Missing
2010.iwslt-evaluation.22,D09-1022,1,\N,Missing
2010.iwslt-evaluation.22,J93-2003,0,\N,Missing
2010.iwslt-evaluation.22,E06-1005,1,\N,Missing
2010.iwslt-evaluation.22,E03-1076,0,\N,Missing
2010.iwslt-evaluation.22,D08-1089,0,\N,Missing
2010.iwslt-evaluation.22,P03-1054,0,\N,Missing
2010.iwslt-evaluation.22,P02-1040,0,\N,Missing
2010.iwslt-evaluation.22,W06-3110,1,\N,Missing
2010.iwslt-evaluation.22,J10-3008,0,\N,Missing
2010.iwslt-evaluation.22,2010.iwslt-keynotes.2,0,\N,Missing
2010.iwslt-evaluation.22,P10-2041,0,\N,Missing
2010.iwslt-evaluation.22,P08-2030,0,\N,Missing
2010.iwslt-evaluation.22,W07-0734,0,\N,Missing
2010.iwslt-evaluation.22,W06-3105,0,\N,Missing
2010.iwslt-evaluation.22,N03-1017,0,\N,Missing
2010.iwslt-evaluation.22,2008.iwslt-papers.7,1,\N,Missing
2010.iwslt-evaluation.22,J03-1002,1,\N,Missing
2010.iwslt-evaluation.22,W06-3108,1,\N,Missing
2010.iwslt-evaluation.22,P07-1019,0,\N,Missing
2010.iwslt-evaluation.22,D08-1039,1,\N,Missing
2010.iwslt-evaluation.22,P08-1066,0,\N,Missing
2010.iwslt-evaluation.22,2009.mtsummit-posters.17,0,\N,Missing
2010.iwslt-evaluation.22,2010.iwslt-papers.15,1,\N,Missing
2010.iwslt-evaluation.22,2006.iwslt-papers.1,1,\N,Missing
2010.iwslt-evaluation.22,2011.iwslt-papers.1,1,\N,Missing
2010.iwslt-evaluation.22,2011.iwslt-papers.7,1,\N,Missing
2010.iwslt-evaluation.22,2011.iwslt-papers.8,1,\N,Missing
2010.iwslt-evaluation.22,N04-1033,1,\N,Missing
2010.iwslt-evaluation.22,2011.iwslt-evaluation.1,0,\N,Missing
2010.iwslt-evaluation.22,D08-1076,0,\N,Missing
2010.iwslt-evaluation.22,P03-1021,0,\N,Missing
2010.iwslt-evaluation.22,2011.iwslt-papers.5,1,\N,Missing
2010.iwslt-evaluation.22,P08-1000,0,\N,Missing
2010.iwslt-papers.11,W06-3105,0,0.0618427,"rase extraction procedure defined in Equation 1 requires a word alignment to be provided. Normally this alignment is computed using probabilistic models, usually the word-based IBM translation models [11] as implemented in the GIZA++ toolkit [12], which are different to the ones later used in the translation process. This produces a mismatch between the phrase extraction procedure and the translation procedure, as they are based on different stochastic models, which are applied independently of each other. Other approaches have tried to bridge this mismatch between training and decoding, e.g. [1, 2, 3]. Recently, consistent improvements in translation quality could be achieved [4]. In this work we investigate a first approach to incorporate the techniques proposed in [4] in the hierarchical phrasebased approach. In this section we describe the training procedure and the model by which the phrase counts are computed, which we will later incorporate into the hierarchical translation system. 3.1. Forced Alignment for Phrase-Based Models An illustration of the basic idea of the forced alignment training can be seen in Figure 1. The forced alignment procedure performs a phrase segmentation and a"
2010.iwslt-papers.11,P06-1096,0,0.0221215,"rase extraction procedure defined in Equation 1 requires a word alignment to be provided. Normally this alignment is computed using probabilistic models, usually the word-based IBM translation models [11] as implemented in the GIZA++ toolkit [12], which are different to the ones later used in the translation process. This produces a mismatch between the phrase extraction procedure and the translation procedure, as they are based on different stochastic models, which are applied independently of each other. Other approaches have tried to bridge this mismatch between training and decoding, e.g. [1, 2, 3]. Recently, consistent improvements in translation quality could be achieved [4]. In this work we investigate a first approach to incorporate the techniques proposed in [4] in the hierarchical phrasebased approach. In this section we describe the training procedure and the model by which the phrase counts are computed, which we will later incorporate into the hierarchical translation system. 3.1. Forced Alignment for Phrase-Based Models An illustration of the basic idea of the forced alignment training can be seen in Figure 1. The forced alignment procedure performs a phrase segmentation and a"
2010.iwslt-papers.11,2009.eamt-1.23,0,0.0260374,"rase extraction procedure defined in Equation 1 requires a word alignment to be provided. Normally this alignment is computed using probabilistic models, usually the word-based IBM translation models [11] as implemented in the GIZA++ toolkit [12], which are different to the ones later used in the translation process. This produces a mismatch between the phrase extraction procedure and the translation procedure, as they are based on different stochastic models, which are applied independently of each other. Other approaches have tried to bridge this mismatch between training and decoding, e.g. [1, 2, 3]. Recently, consistent improvements in translation quality could be achieved [4]. In this work we investigate a first approach to incorporate the techniques proposed in [4] in the hierarchical phrasebased approach. In this section we describe the training procedure and the model by which the phrase counts are computed, which we will later incorporate into the hierarchical translation system. 3.1. Forced Alignment for Phrase-Based Models An illustration of the basic idea of the forced alignment training can be seen in Figure 1. The forced alignment procedure performs a phrase segmentation and a"
2010.iwslt-papers.11,P10-1049,1,0.931056,"ed. Normally this alignment is computed using probabilistic models, usually the word-based IBM translation models [11] as implemented in the GIZA++ toolkit [12], which are different to the ones later used in the translation process. This produces a mismatch between the phrase extraction procedure and the translation procedure, as they are based on different stochastic models, which are applied independently of each other. Other approaches have tried to bridge this mismatch between training and decoding, e.g. [1, 2, 3]. Recently, consistent improvements in translation quality could be achieved [4]. In this work we investigate a first approach to incorporate the techniques proposed in [4] in the hierarchical phrasebased approach. In this section we describe the training procedure and the model by which the phrase counts are computed, which we will later incorporate into the hierarchical translation system. 3.1. Forced Alignment for Phrase-Based Models An illustration of the basic idea of the forced alignment training can be seen in Figure 1. The forced alignment procedure performs a phrase segmentation and alignment of each sentence pair of the training data using a modification of the"
2010.iwslt-papers.11,P08-1024,0,0.0416513,"phrase alignment between source and target sentences. Phrase translation probabilities are then updated based on this alignment. By applying leaving-one-out in the training procedure, overfitting effects can be diminished. The phrase table which is learnt from forced alignments can be used as phrase table itself in the translation system or can be combined with the original phrase-based system. Experiments in [4] show that the latter gives better results. In recent years, conventional phrase-based systems have been outerperformed by hierarchical phrase-based or syntaxbased systems. The papers [5, 6] describe first training approaches with forced alignment techniques with hierarchical translation systems. However, they report difficulties when aligning training sentences because of the restrictions in the phrase extraction process. Our work is intended to neither solve this problem nor propose any forced alignment training method on hierarchical systems. Instead, we want to see the effects of combining a hierarchical system with forced alignments from a phrase-based decoder. The next section will recall phrase-based and hierarchical phrase-based translation models. In Section 3 we describ"
2010.iwslt-papers.11,2008.iwslt-papers.7,1,0.851625,"forced alignments as described in Section 3. The hierarchical system is used as baseline and combined with the retrained phrase table from the forced alignment training using the phrase-based system. 5.1. Results First, we present our results on the IWSLT 2010 BTEC task for Arabic-to-English for which corpus statistics are given in Table 1. We give BLEU scores in Table 2 as well as TER scores in Table 3. We chose test04 as development set and test08 and test05 as blind test sets. We experimented with a hierarchical baseline system and a hierarchical system enriched with soft syntactic labels [15]. The second will be simply denoted by the label syntax in our tables of results. The filtering method from Section 4 improves both the baseline and the system with syntax information, though improvements can be found only on one of the test sets each. The intersection method was only tested on the simple baseline and performed worse on all test sets. In order to investigate our method on a larger corpus, we experimented on the English-to-German Quaero project corpus from 2010. This corpus mainly contains the data from the Workshop of Machine Translation (WMT) 2010, namely Europarl and news-co"
2010.iwslt-papers.11,2009.iwslt-papers.2,0,0.123072,"phrase alignment between source and target sentences. Phrase translation probabilities are then updated based on this alignment. By applying leaving-one-out in the training procedure, overfitting effects can be diminished. The phrase table which is learnt from forced alignments can be used as phrase table itself in the translation system or can be combined with the original phrase-based system. Experiments in [4] show that the latter gives better results. In recent years, conventional phrase-based systems have been outerperformed by hierarchical phrase-based or syntaxbased systems. The papers [5, 6] describe first training approaches with forced alignment techniques with hierarchical translation systems. However, they report difficulties when aligning training sentences because of the restrictions in the phrase extraction process. Our work is intended to neither solve this problem nor propose any forced alignment training method on hierarchical systems. Instead, we want to see the effects of combining a hierarchical system with forced alignments from a phrase-based decoder. The next section will recall phrase-based and hierarchical phrase-based translation models. In Section 3 we describ"
2010.iwslt-papers.11,W99-0604,1,0.633447,"how we combine these forced alignments with hierarchical translation models. An empirical evaluation on two different tasks is done in Section 5. Finally, Section 6 concludes the paper. 2. Translation Models In this work we will study the combination of two widely used approaches to statistical machine translation. The main difference between the two models lies in the basic units that are used for the translation. 2.1. Phrase-based Translation Model The phrase based translation model is based on the concept of phrase, a bilingual pair of sequences of words that are translations of each other [7]. Given a word-aligned training corpus, we extract those phrases for which the source words are aligned only to target words within the phrase and vice-versa. This set can be formalized for a sentence pair (f1J , eI1 ) as P(f1J ,eI1 , A) =  hfjj12 , eii21 i |j1 , j2 , i1 , i2 s.t. ∀(j, i) ∈ A : j1 ≤ j ≤ j2 ⇔ i1 ≤ i ≤ i2 ∧ ∃(j, i) ∈ A : (j1 ≤ j ≤ j2 ∧ i1 ≤ i ≤ i2 ) , (1) where A is the alignment between the source and target sentences expressed as a set of position pairs. 291 Proceedings of the 7th International Workshop on Spoken Language Translation Paris, December 2nd and 3rd, 2010 2.2. Hie"
2010.iwslt-papers.11,P05-1033,0,0.169168,"re aligned only to target words within the phrase and vice-versa. This set can be formalized for a sentence pair (f1J , eI1 ) as P(f1J ,eI1 , A) =  hfjj12 , eii21 i |j1 , j2 , i1 , i2 s.t. ∀(j, i) ∈ A : j1 ≤ j ≤ j2 ⇔ i1 ≤ i ≤ i2 ∧ ∃(j, i) ∈ A : (j1 ≤ j ≤ j2 ∧ i1 ≤ i ≤ i2 ) , (1) where A is the alignment between the source and target sentences expressed as a set of position pairs. 291 Proceedings of the 7th International Workshop on Spoken Language Translation Paris, December 2nd and 3rd, 2010 2.2. Hierarchical Phrase-based Translation Model set of hierarchical rules The hierarchical approach [8] to machine translation is a generalization of the above model where the phrases are allowed to have “gaps”. Those gaps are linked in the source and target language such that a translation rule specifies the location of the translation of the text filling a gap in the source side. The model is formalized as a synchronous context-free grammar. The set of rules extracted from an aligned bilingual sentence pair is best described in a recursive way. Given a source sentence f1J , a target sentence eI1 , an alignment A between them and N the maximum number of gaps allowed (usually N = 2), we can def"
2010.iwslt-papers.11,W06-3119,0,0.0206708,"s relative frequencies. In this work we will study alternative ways to compute these probabilities. α, β ∈ (F ∪ N )? , δ, γ ∈ (E ∪ N )? ∧ ∃j1 , j2 , i1 , i2 : j1 < j2 , i1 < i2 :  2 X → hαfjj12 β, δeii1 γ i ∈ Hn−1 (f1J , eI1 , A)  ∧X → hfjj12 , eii21 i ∈ H0 (f1J , eI1 , A) , The total set of hierarchical phrases extracted from a parallel corpus is the union of the hierarchical phrases extracted from each of its sentences. As can be seen from Equation 4, in the standard approach only one generic non-terminal is used. There are works which propose to extend the set of non-terminals, see e.g. [9]. It is common practice to include two additional rules to the • IBM1-like word-based probabilities computed at the phrase level, also in source-to-target and target-tosource directions. These probabilities can be seen as a smoothing of the afore mentioned phrase-based probabilities. In the case of the hierarchical model, the nonterminals in the rules are simply ignored in the computation. 292 Proceedings of the 7th International Workshop on Spoken Language Translation Paris, December 2nd and 3rd, 2010 • Language model probabilities of the produced translation. • Different penalties. These heu"
2010.iwslt-papers.11,P03-1021,0,0.00786503,"s help in controlling different aspects of the translation. A word penalty can guide the translation process into choosing longer or shorter translations, a penalty for rules not in the set H0 can favour hierarchical rules over lexical phrases, etc. The set of chosen features is dependent of the model used, but they are similar in spirit. • Phrase count features which penalize phrases with low counts. The values for the scaling factors λm are estimated by minimum error rate training, a numerical method that optimizes a measure of translation quality (usually BLEU) on a heldout development set [10]. 3. Forced Alignments The standard phrase extraction procedure defined in Equation 1 requires a word alignment to be provided. Normally this alignment is computed using probabilistic models, usually the word-based IBM translation models [11] as implemented in the GIZA++ toolkit [12], which are different to the ones later used in the translation process. This produces a mismatch between the phrase extraction procedure and the translation procedure, as they are based on different stochastic models, which are applied independently of each other. Other approaches have tried to bridge this mismatc"
2010.iwslt-papers.11,J93-2003,0,0.02008,"s, etc. The set of chosen features is dependent of the model used, but they are similar in spirit. • Phrase count features which penalize phrases with low counts. The values for the scaling factors λm are estimated by minimum error rate training, a numerical method that optimizes a measure of translation quality (usually BLEU) on a heldout development set [10]. 3. Forced Alignments The standard phrase extraction procedure defined in Equation 1 requires a word alignment to be provided. Normally this alignment is computed using probabilistic models, usually the word-based IBM translation models [11] as implemented in the GIZA++ toolkit [12], which are different to the ones later used in the translation process. This produces a mismatch between the phrase extraction procedure and the translation procedure, as they are based on different stochastic models, which are applied independently of each other. Other approaches have tried to bridge this mismatch between training and decoding, e.g. [1, 2, 3]. Recently, consistent improvements in translation quality could be achieved [4]. In this work we investigate a first approach to incorporate the techniques proposed in [4] in the hierarchical ph"
2010.iwslt-papers.11,2008.iwslt-papers.8,1,0.904736,"Missing"
2010.iwslt-papers.11,W10-1738,1,0.892031,"Missing"
2010.iwslt-papers.11,J03-1002,1,\N,Missing
2010.iwslt-papers.11,D08-1076,0,\N,Missing
2010.iwslt-papers.12,E06-1005,1,0.922753,"arget language pair. The disadvantage of this approach is that both the translation into the pivot language, and the translation into the target language are error-prone – and typically, these errors add up. As a result, on comparable training resources, we can expect the translation quality of a pivot system to be significantly lower that the quality of a “direct” system1 . Since Kay [2] has first predicted the usefulness of multilingual resources, several approaches have been proposed to utilize resources and data available in more than two languages for MT. Multi-source machine translation [3, 4, 5] denotes techniques to translate documents which are available in two or more source languages. One approach that has recently been shown to be very effective [4, 6] is to use individual bilingual MT systems to translate the source documents independently of each other into one document each in the target language, and then to use MT system combination (ibid.) to generate a consensus translation out of these different target translations. In this paper, we will investigate to what extent 1 Within this paper, we use the term “direct system” to denote a (statistical) MT system that has been trai"
2010.iwslt-papers.12,E09-1082,0,0.0772212,"arget language pair. The disadvantage of this approach is that both the translation into the pivot language, and the translation into the target language are error-prone – and typically, these errors add up. As a result, on comparable training resources, we can expect the translation quality of a pivot system to be significantly lower that the quality of a “direct” system1 . Since Kay [2] has first predicted the usefulness of multilingual resources, several approaches have been proposed to utilize resources and data available in more than two languages for MT. Multi-source machine translation [3, 4, 5] denotes techniques to translate documents which are available in two or more source languages. One approach that has recently been shown to be very effective [4, 6] is to use individual bilingual MT systems to translate the source documents independently of each other into one document each in the target language, and then to use MT system combination (ibid.) to generate a consensus translation out of these different target translations. In this paper, we will investigate to what extent 1 Within this paper, we use the term “direct system” to denote a (statistical) MT system that has been trai"
2010.iwslt-papers.12,W09-0407,1,0.812949,"e – and typically, these errors add up. As a result, on comparable training resources, we can expect the translation quality of a pivot system to be significantly lower that the quality of a “direct” system1 . Since Kay [2] has first predicted the usefulness of multilingual resources, several approaches have been proposed to utilize resources and data available in more than two languages for MT. Multi-source machine translation [3, 4, 5] denotes techniques to translate documents which are available in two or more source languages. One approach that has recently been shown to be very effective [4, 6] is to use individual bilingual MT systems to translate the source documents independently of each other into one document each in the target language, and then to use MT system combination (ibid.) to generate a consensus translation out of these different target translations. In this paper, we will investigate to what extent 1 Within this paper, we use the term “direct system” to denote a (statistical) MT system that has been trained on a bilingual corpus between source and target language, and does not utilize any pivot or bridge languages. 299 Proceedings of the 7th International Workshop o"
2010.iwslt-papers.12,D07-1005,0,0.143443,"Missing"
2010.iwslt-papers.12,N06-1003,0,0.0986054,"Missing"
2010.iwslt-papers.12,N07-1061,0,0.498978,"ta are available. Unfortunately, if one wants to be able to translate from many possible source languages into many possible target languages, separate MT systems for each possible pair of source and target language have to be trained, on bilingual data in this specific language pair. Quite often this is not possible, especially where rare or unrelated languages are involved. Significant amounts of bilingual in-domain training data may be unavailable; the number of systems to train and to tune may be too high. One approach to overcome this problem has been proposed e.g. by Utiyama and Isahara [1]: A third, more frequent language is utilized as a pivot or bridge language. Ideally, sufficient bilingual language resources are available for both the pair of source and pivot language, and for the pair of pivot and target language. The final translation is then obtained by going via the bridge language, either by generating full translations of the source sentence in this bridge language, or by using the bilingual data to build translation models for the source–target language pair. The disadvantage of this approach is that both the translation into the pivot language, and the translation i"
2010.iwslt-papers.12,2001.mtsummit-papers.46,1,0.565201,"arget language pair. The disadvantage of this approach is that both the translation into the pivot language, and the translation into the target language are error-prone – and typically, these errors add up. As a result, on comparable training resources, we can expect the translation quality of a pivot system to be significantly lower that the quality of a “direct” system1 . Since Kay [2] has first predicted the usefulness of multilingual resources, several approaches have been proposed to utilize resources and data available in more than two languages for MT. Multi-source machine translation [3, 4, 5] denotes techniques to translate documents which are available in two or more source languages. One approach that has recently been shown to be very effective [4, 6] is to use individual bilingual MT systems to translate the source documents independently of each other into one document each in the target language, and then to use MT system combination (ibid.) to generate a consensus translation out of these different target translations. In this paper, we will investigate to what extent 1 Within this paper, we use the term “direct system” to denote a (statistical) MT system that has been trai"
2010.iwslt-papers.12,W09-2503,1,0.895966,"Missing"
2010.iwslt-papers.12,D10-1064,1,0.878502,"Missing"
2010.iwslt-papers.12,P07-1092,0,0.267577,"Missing"
2010.iwslt-papers.12,J06-4004,1,0.89411,"1000 sentences from the common subset (same sentences for all languages). 301 Proceedings of the 7th International Workshop on Spoken Language Translation Paris, December 2nd and 3rd, 2010 MT Sys 1' Src ... MT Sys m' Piv 1 ... MT Sys 1'' Piv m MT Sys m'' ... Direct MT Sys Hyp 1 ... GIZA++alignment Hyp m Reordering Network generation, weighting, rescoring Consensus Translation Hyp m+1 Figure 1: Structure of the multipivot system 5.2. Translation engines The translation engine for these experiments implements the n-gram-based approach to statistical machine translation detailed by Marino et al. [21]. The overall translation accuracy is comparable to state-of-the-art phrase-based translation engines such as the MOSES system [22]. In a nutshell, the translation model is implemented as a stochastic finite-state transducer trained using a n-gram language model of (source,target) pairs [23]. Training such a model requires to reorder source sentences so as to match the target word order. Reordering hypotheses are computed before decoding takes place via a stochastic finite-state automaton that builds a lattice with the most promising hypotheses according to a set of rewrite rules previously co"
2010.iwslt-papers.12,P09-1018,0,0.147907,"Missing"
2010.iwslt-papers.12,P07-2045,0,0.00550476,"en Language Translation Paris, December 2nd and 3rd, 2010 MT Sys 1' Src ... MT Sys m' Piv 1 ... MT Sys 1'' Piv m MT Sys m'' ... Direct MT Sys Hyp 1 ... GIZA++alignment Hyp m Reordering Network generation, weighting, rescoring Consensus Translation Hyp m+1 Figure 1: Structure of the multipivot system 5.2. Translation engines The translation engine for these experiments implements the n-gram-based approach to statistical machine translation detailed by Marino et al. [21]. The overall translation accuracy is comparable to state-of-the-art phrase-based translation engines such as the MOSES system [22]. In a nutshell, the translation model is implemented as a stochastic finite-state transducer trained using a n-gram language model of (source,target) pairs [23]. Training such a model requires to reorder source sentences so as to match the target word order. Reordering hypotheses are computed before decoding takes place via a stochastic finite-state automaton that builds a lattice with the most promising hypotheses according to a set of rewrite rules previously collected from the training bi-texts using the word alignments. In addition to the bilingual n-gram model, our SMT system implements"
2010.iwslt-papers.12,2008.amta-srw.6,0,0.0340832,"Missing"
2010.iwslt-papers.12,eisele-2006-parallel,0,0.0566411,"Missing"
2010.iwslt-papers.12,J03-1002,1,0.0201737,"puts from different systems was first shown to produce superior results in automatic speech recognition (ASR). Voting schemes like the ROVER approach of Fiscus [16] create confusion networks (CNs) from the output of different ASR systems for the same audio input. The consensus recognition hypothesis is generated by weighted majority voting. This approach has later been adapted to MT as well [17]. In this paper, we follow the approach of Matusov et al [4, 18]: An unsupervised monolingual word alignment is trained between all pairs of hypotheses for each source sentence using the GIZA++ toolkit [19]. These alignments are then used to reorder all individual hypotheses to one selected (“primary”) hypothesis, which defines the word order in the consensus translation. A CN is then generated from these reordered hypotheses. As there is no obvious way to determine the best primary hypothesis, separate CNs are generated for all possible primary hypotheses, which are then combined 300 Proceedings of the 7th International Workshop on Spoken Language Translation Paris, December 2nd and 3rd, 2010 Table 1: Corpus statistics for the experimental setup. to a single word lattice. This lattice is then r"
2010.iwslt-papers.12,2005.mtsummit-papers.11,0,0.0506804,"k Words 13.4k 13.5k 14.0k 14.6k 10.1k 16.1k 14.1k 14.3k 14.2k 14.5k 12.7k Dev Test Voc. OOV Words Voc. OOV 3.2k 104 25.9k 5.1k 226 3.5k 120 26.0k 5.5k 245 2.8k 39 27.2k 4.0k 63 3.3k 56 28.6k 5.0k 88 4.3k 244 19.6k 7.1k 407 3.2k 47 31.5k 4.8k 87 3.9k 72 27.2k 6.2k 159 3.4k 61 28.1k 5.1k 99 3.1k 76 27.5k 4.8k 162 3.4k 49 28.3k 5.2k 118 3.3k 116 24.5k 5.2k 226 5. Experimental setup 5.1. Training and Development data For experimenting with our approach, we built translation systems to serve as direct or pivot systems using a phrase-based MT engine for several language pairs of the Europarl corpus [20], which is available in 11 languages: Danish (da), German (de), English (en) , Spanish (es), Finnish (fi), French (fr), Greek (el), Italian (it), Dutch (nl), Portuguese (pt) and Swedish (sv). We also decided to study three source–target language pairs, two for which translation accuracy, as measured by automatic metrics, is moderate, (de–en) and (fr–de), and one for which translation accuracy, is much higher. (fr–en). This allowed us to check whether the improvements provided by our method carry over even in situations where the baseline is high; conversely, it also allows us to assess whether"
2010.iwslt-papers.12,J04-2004,0,0.0336595,"gnment Hyp m Reordering Network generation, weighting, rescoring Consensus Translation Hyp m+1 Figure 1: Structure of the multipivot system 5.2. Translation engines The translation engine for these experiments implements the n-gram-based approach to statistical machine translation detailed by Marino et al. [21]. The overall translation accuracy is comparable to state-of-the-art phrase-based translation engines such as the MOSES system [22]. In a nutshell, the translation model is implemented as a stochastic finite-state transducer trained using a n-gram language model of (source,target) pairs [23]. Training such a model requires to reorder source sentences so as to match the target word order. Reordering hypotheses are computed before decoding takes place via a stochastic finite-state automaton that builds a lattice with the most promising hypotheses according to a set of rewrite rules previously collected from the training bi-texts using the word alignments. In addition to the bilingual n-gram model, our SMT system implements eight additional models which are linearly combined following a discriminative modeling framework [24]: two lexicalized reordering models [25], which attempt to"
2010.iwslt-papers.12,P02-1038,1,0.508083,"ned using a n-gram language model of (source,target) pairs [23]. Training such a model requires to reorder source sentences so as to match the target word order. Reordering hypotheses are computed before decoding takes place via a stochastic finite-state automaton that builds a lattice with the most promising hypotheses according to a set of rewrite rules previously collected from the training bi-texts using the word alignments. In addition to the bilingual n-gram model, our SMT system implements eight additional models which are linearly combined following a discriminative modeling framework [24]: two lexicalized reordering models [25], which attempt to model the orientation of the current translation unit according to the previous as well as the ordering of the next unit with respect to the current unit, a target-language model which provides information about the target language structure and fluency; two lexicon models, which constitute complementary translation models computed for each given tuple; a ‘weak’ distance-based distortion model; and finally a word-bonus model and a tuple-bonus model which are used in order to compensate for the system preference for short translations."
2010.iwslt-papers.12,N04-4026,0,0.0237976,"urce,target) pairs [23]. Training such a model requires to reorder source sentences so as to match the target word order. Reordering hypotheses are computed before decoding takes place via a stochastic finite-state automaton that builds a lattice with the most promising hypotheses according to a set of rewrite rules previously collected from the training bi-texts using the word alignments. In addition to the bilingual n-gram model, our SMT system implements eight additional models which are linearly combined following a discriminative modeling framework [24]: two lexicalized reordering models [25], which attempt to model the orientation of the current translation unit according to the previous as well as the ordering of the next unit with respect to the current unit, a target-language model which provides information about the target language structure and fluency; two lexicon models, which constitute complementary translation models computed for each given tuple; a ‘weak’ distance-based distortion model; and finally a word-bonus model and a tuple-bonus model which are used in order to compensate for the system preference for short translations. For this study, we used 3-gram bilingual"
2010.iwslt-papers.12,P96-1041,0,0.0557653,"ccording to the previous as well as the ordering of the next unit with respect to the current unit, a target-language model which provides information about the target language structure and fluency; two lexicon models, which constitute complementary translation models computed for each given tuple; a ‘weak’ distance-based distortion model; and finally a word-bonus model and a tuple-bonus model which are used in order to compensate for the system preference for short translations. For this study, we used 3-gram bilingual tuple and 3-gram target language models built using Kneser-Ney smoothing [26]; training was performed with the SRI language modeling toolkit [27]. After preprocessing the corpora with standard tokenization tools, word-to-word GIZA++ [19] alignments are performed in both directions, followed by the growdiag-final-and heuristic [28]. 5.3. Experiments The two principal research questions we wanted to answer with the experiments for this paper were: Can we use the multi-pivot approach instead of a direct source– target system, with comparable translation scores? And secondly, can we use the multi-pivot approach to improve the output of an existing direct system? The former"
2010.iwslt-papers.12,2005.iwslt-1.8,0,0.0213956,"slation models computed for each given tuple; a ‘weak’ distance-based distortion model; and finally a word-bonus model and a tuple-bonus model which are used in order to compensate for the system preference for short translations. For this study, we used 3-gram bilingual tuple and 3-gram target language models built using Kneser-Ney smoothing [26]; training was performed with the SRI language modeling toolkit [27]. After preprocessing the corpora with standard tokenization tools, word-to-word GIZA++ [19] alignments are performed in both directions, followed by the growdiag-final-and heuristic [28]. 5.3. Experiments The two principal research questions we wanted to answer with the experiments for this paper were: Can we use the multi-pivot approach instead of a direct source– target system, with comparable translation scores? And secondly, can we use the multi-pivot approach to improve the output of an existing direct system? The former question is most relevant for the “matrix” scenario sketched in Section 3, where we have a large number of possible source and target languages, and do not want to build separate translation systems for each individual pair – either because we want to sa"
2010.iwslt-papers.12,2009.mtsummit-papers.7,0,\N,Missing
2010.iwslt-papers.17,P02-1040,0,0.0845164,"lso want to offer new solutions that are tailored to scarce resources. More specifically, we examine how to optimize the scaling factors when holding back a development set would already take away a large portion of the precious training data. We also look at the performance of different alignment merging strategies and propose new methods on how to apply them to small-sized data. In addition, we conduct experiments with different decoders and employ state-of-the-art techniques like soft syntactic labels as well as trigger-based and discriminative word lexica. All results are reported on BLEU [1] and TER [2], and their improvements over the baseline are checked for statistical significance. 1.1. Paper Structure and Related Work After some preliminaries in Section 2, we begin our experiments with a sanity check in Section 3 to analyze whether a translation process is really necessary. In a recent paper [3], the authors work on the translation of an intermediate, signed form of the Czech language and obtain translation results of up to 81 BLEU, which probably is due to the similarity between this hybrid language and written Czech. We examine whether such a similarity is also true in the"
2010.iwslt-papers.17,2006.amta-papers.25,0,0.0123023,"offer new solutions that are tailored to scarce resources. More specifically, we examine how to optimize the scaling factors when holding back a development set would already take away a large portion of the precious training data. We also look at the performance of different alignment merging strategies and propose new methods on how to apply them to small-sized data. In addition, we conduct experiments with different decoders and employ state-of-the-art techniques like soft syntactic labels as well as trigger-based and discriminative word lexica. All results are reported on BLEU [1] and TER [2], and their improvements over the baseline are checked for statistical significance. 1.1. Paper Structure and Related Work After some preliminaries in Section 2, we begin our experiments with a sanity check in Section 3 to analyze whether a translation process is really necessary. In a recent paper [3], the authors work on the translation of an intermediate, signed form of the Czech language and obtain translation results of up to 81 BLEU, which probably is due to the similarity between this hybrid language and written Czech. We examine whether such a similarity is also true in the case of Ger"
2010.iwslt-papers.17,D09-1022,1,0.845503,"point out that for small test sets and for unstable data, BLEU is a bad choice as an optimization metric, since e.g. sometimes no correct four-gram can be found. The same authors report in [6] that in more recent experiments the BLEU scores are on reasonable levels again, but leave the question open whether this is due to better data or better machine translation systems. In Section 9, we will examine the impact of extended 337 Proceedings of the 7th International Workshop on Spoken Language Translation Paris, December 2nd and 3rd, 2010 lexicon models on sign language machine translation. In [8], the authors report remarkable improvements by applying extended lexicon models to large-scale machine translation tasks, and we examine whether we can transfer this improvement to sign language translation. After presenting the final system in Section 10, we conclude our paper in Section 11. 2. Preliminaries We use the RWTH-PHOENIX-v3.0 corpus, which consists of parallel sentences in German Sign Language and written German, taken from the domain of weather forecast news. These forecasts are part of the main evening news program, which is broadcast on the public television channel “PHOENIX” a"
2010.iwslt-papers.17,2008.iwslt-papers.8,1,0.824562,"ughout the paper. In this paper, we use a phrase-based and a hierarchical phrase-based decoder and also apply system combination to some hypotheses. In the following, we will describe the systems that we used. Figure 1: Snapshot of the PHOENIX broadcast news Glosses German Train: Sentences Running Words Vocabulary Singletons 2565 31 208 41 306 1 027 1 763 371 641 Test: Sentences Running Words Vocabulary OOVs 6 115 570 86 512 8 230 915 133 Table 1: Corpus statistics for the weather forecast corpus 2.1. Phrase-based Translation We used an in-house phrase-based translation system as described in [9]. The training corpus is word-aligned using GIZA++2 , and phrase pairs consistent with this alignment are extracted. Different models which capture particular aspects of a translation, such as fluency of the output or the accurate translation of individual words, are integrated into a log-linear framework: For a given source sentence f , the system chooses that translation eˆ which maximizes the sum over the m different models hm , weighted by some scaling factors λm : eˆ(f ) := argmax e ( X ) λm hm (e, f ) m . (1) The models hm used in the phrase-based translation system are phrase- and word"
2010.iwslt-papers.17,W10-1738,1,0.811827,"rk: For a given source sentence f , the system chooses that translation eˆ which maximizes the sum over the m different models hm , weighted by some scaling factors λm : eˆ(f ) := argmax e ( X ) λm hm (e, f ) m . (1) The models hm used in the phrase-based translation system are phrase- and word translation probabilities in both directions, a standard n-gram language model, word-, phrase- and distortion penalties and a discriminative reordering model. 2.2. Hierarchical Phrase-based Translation We also employ our open-source hierarchical translation system JANE, which was officially released in [10]. It is able 1 http://www-speech.sri.com/projects/srilm/ 2 http://www.htlpr.rwth-aachen.de/˜och/software/GIZA++.html 338 Proceedings of the 7th International Workshop on Spoken Language Translation Paris, December 2nd and 3rd, 2010 MT system simple lower casing 4-letter stems BLEU TER PER 18.1 71.0 63.0 2.1 2.6 85.7 81.1 81.5 74.8 baseline training on training Table 2: Results for the sanity check (Section 3) to translate hierarchical phrases and is based on a log-linear model as described in the previous section. Its standard models consist of translation probabilities, IBM-like word lexica,"
2010.iwslt-papers.17,N03-1017,0,0.00999241,"e errors made at the phrase extraction level are likely to propagate into the translation. We compute alignments based on the IBM Models with GIZA++. Since the IBM Models are not symmetric, the resulting alignment differs depending on the translation direction. Usually, one alignment is produced for each direction, and the two alignments are merged. We compared the following merging strategies: intersection Here, we only take alignment points that appear in both alignments. union We take every alignment point that appears in either alignment. grow-diag-final-and This algorithm as presented in [12] is probably most widely used. Starting from the intersection alignment, it iteratively extends every alignment point whenever there is a direct neighbor, i.e. when a vertically, horizontally or diagonally adjacent alignment point is part of the union alignment but not yet of the merged alignment. In a finalizing step called finaland, we ignore the adjacency and add points from the unification alignment when both source and target row are unaligned. unify intersect grow-diag-final-and grow-mono-final-and precision recall F AER 40.9 80.1 44.2 47.6 62.0 28.8 55.2 45.4 49.3 42.0 49.1 46.5 50.6 57"
2010.iwslt-papers.17,N09-1027,0,0.0213498,"some small improvement in TER. The best system is the one produced by the system combination, which not only has the best performance on the test set but is actually significantly better than the single grow-diag-final-and system. 6. Linguistically Motivated Experiments In [5], we applied a syntactic analysis to the target language by extracting additional information with the freely available Stanford parser3 . We first penalized phrases that did not match the yield of a syntax tree-node, as in [14]. We denote these experiments as parse-match. Second, we employed soft syntactic labels as in [15]. With this, we introduce new non-terminal labels into an additional feature function and penalize phrases that do not match the syntactic labels of the non-terminal that they are replacing. This is denoted as softsyntax. As stated earlier, the corpus is no longer identical to the 3 http://nlp.stanford.edu/software/lex-parser.shtml one used in the old experiments, since the sentence length and the grammar complexity is now higher, which is why we repeat the experiments. See Table 6 for an overview of the results. Based on the results we can conclude that the proposed methods still do not help"
2010.iwslt-papers.17,E99-1010,0,0.0517534,"-parser.shtml one used in the old experiments, since the sentence length and the grammar complexity is now higher, which is why we repeat the experiments. See Table 6 for an overview of the results. Based on the results we can conclude that the proposed methods still do not help for this small corpus. In the outlook of the paper, we wrote that the methods probably did not help because of the rather large number of labels, and that automatic clustering techniques could help in this matter. For this, we now cluster the words and phrases into only a few classes by making use of the tools makecls [16] and CLUTO [17]. The results can be found in Table 7. While the results are not as deteriorated as the pure syntactic approaches, the methods still do not improve over the baseline. We therefore draw the conclusion that on this small corpus, the methods do not help in a single system and could only be used as an additional system in a system combination approach. 7. Phrase-based translation As stated in the beginning, we want to employ different decoders in this work and use them in a final system combination. We therefore trained our in-house phrase-based translation system, as described in S"
2010.iwslt-papers.17,J93-2003,0,\N,Missing
2010.iwslt-papers.17,2008.iwslt-papers.7,1,\N,Missing
2010.iwslt-papers.17,J03-1002,1,\N,Missing
2010.iwslt-papers.18,N04-1035,0,\N,Missing
2010.iwslt-papers.18,E99-1010,0,\N,Missing
2010.iwslt-papers.18,P01-1067,0,\N,Missing
2010.iwslt-papers.18,N09-1027,0,\N,Missing
2010.iwslt-papers.18,N09-1025,0,\N,Missing
2010.iwslt-papers.18,P08-1114,0,\N,Missing
2010.iwslt-papers.18,P05-1033,0,\N,Missing
2010.iwslt-papers.18,N03-1017,0,\N,Missing
2010.iwslt-papers.18,P02-1038,1,\N,Missing
2010.iwslt-papers.18,2008.iwslt-papers.7,1,\N,Missing
2010.iwslt-papers.18,D07-1079,0,\N,Missing
2010.iwslt-papers.18,P08-1066,0,\N,Missing
2010.iwslt-papers.18,W06-3119,0,\N,Missing
2010.iwslt-papers.18,J07-2003,0,\N,Missing
2010.iwslt-papers.18,D08-1076,0,\N,Missing
2011.eamt-1.37,2010.amta-papers.7,0,\N,Missing
2011.eamt-1.37,W10-1761,0,\N,Missing
2011.eamt-1.37,E09-1044,0,\N,Missing
2011.eamt-1.37,D09-1022,1,\N,Missing
2011.eamt-1.37,C04-1030,1,\N,Missing
2011.eamt-1.37,P10-1146,0,\N,Missing
2011.eamt-1.37,W10-1738,1,\N,Missing
2011.eamt-1.37,2008.iwslt-papers.6,0,\N,Missing
2011.eamt-1.37,J10-3008,0,\N,Missing
2011.eamt-1.37,2010.iwslt-keynotes.2,0,\N,Missing
2011.eamt-1.37,N09-1027,0,\N,Missing
2011.eamt-1.37,P07-2045,0,\N,Missing
2011.eamt-1.37,P06-1055,0,\N,Missing
2011.eamt-1.37,P05-1033,0,\N,Missing
2011.eamt-1.37,J03-1002,1,\N,Missing
2011.eamt-1.37,W09-0434,0,\N,Missing
2011.eamt-1.37,2009.mtsummit-posters.17,0,\N,Missing
2011.eamt-1.37,2010.amta-papers.33,0,\N,Missing
2011.iwslt-evaluation.15,2011.iwslt-evaluation.16,1,0.746987,"led in the Quaero program is 1 http://www.quaero.org spoken language translation (SLT). In this work, the 2011 project-internal evaluation campaign on SLT is described. The campaign focuses on the language pair German-French in both directions, and both human and automatic transcripts of the spoken text are considered as input data. The automatic transcripts were produced by the Rover combination of single-best output of the best submission from each of the three sites participating in the internal 2010 automatic speech recognition (ASR) evaluation, which is described in an accompanying paper [1]. The campaign was designed and conducted by DGA and compares the different approaches taken by the four participating partners RWTH, KIT, LIMSI and SYSTRAN. In addition to publicly available data, monolingual and bilingual corpora collected in the Quaero program were used for training and evaluating the systems. The approaches to machine translation taken by the partners differ substantially. KIT, LIMSI and RWTH apply statistical techniques to perform the task, whereas SYSTRAN uses their commercial rule-based translation engine. KIT makes use of a phrase-based decoder augmented with partof-sp"
2011.iwslt-evaluation.15,P02-1040,0,0.0815552,"s been built from the test sets of the previous years. • arte.tv 2.3. Metrics and Scoring The corpora used to evaluate this task have been built from French and German (manual) transcriptions extracted from the test set used in the previous year’s Quaero evaluation campaign of ASR [1]. These transcriptions come from recordings of broadcast shows. The transcriptions were resegmented manually by the human translators into sentences. Indeed the time-based segmentation, traditionally used for ASR purposes, induced translation issues in the previous 2 http://www.statmt.org/wmt10/ The B LEU-4 score [3] and the Translation Edit Rate (T ER) [4] were chosen as the evaluation metrics for machine translation in Quaero program. B LEU measures the closeness of a candidate translation to one or several reference translations by counting the number of n-grams in the system output that also occur in the reference translation. T ER is an error measure for machine translation that measures the number of edits required to change a system output into one of the references. T ER is defined as the minimum number of 115 edits needed to change a hypothesis so that it matches one of the references, normalized"
2011.iwslt-evaluation.15,2006.amta-papers.25,0,0.0225424,"evious years. • arte.tv 2.3. Metrics and Scoring The corpora used to evaluate this task have been built from French and German (manual) transcriptions extracted from the test set used in the previous year’s Quaero evaluation campaign of ASR [1]. These transcriptions come from recordings of broadcast shows. The transcriptions were resegmented manually by the human translators into sentences. Indeed the time-based segmentation, traditionally used for ASR purposes, induced translation issues in the previous 2 http://www.statmt.org/wmt10/ The B LEU-4 score [3] and the Translation Edit Rate (T ER) [4] were chosen as the evaluation metrics for machine translation in Quaero program. B LEU measures the closeness of a candidate translation to one or several reference translations by counting the number of n-grams in the system output that also occur in the reference translation. T ER is an error measure for machine translation that measures the number of edits required to change a system output into one of the references. T ER is defined as the minimum number of 115 edits needed to change a hypothesis so that it matches one of the references, normalized by the average length of the references."
2011.iwslt-evaluation.15,J05-4003,0,0.0172208,"asing variant and change the case as required to be able to translate it. Some of the available data contains a lot of noise. The Giga corpus, for example, includes a large amount of noise such as non-standardized HTML characters. Also, the Bookshop and Presseurop corpora contain truncated lines, which do not match its aligned translation sentence. These noisy pairs potentially degrade the quality of the translation model. The special filtering was applied to the Giga corpus and some of the Quaero data. We used a Support Vector Machines classifier to filter the corpus, inspired by the work of [5] on comparable data. To generate the translation model, we used the MGIZA++ Toolkit to calculate the word alignment for the training corpus. Afterwards, the alignments were combined using the grow-diag-final-and heuristic. Word reordering is addressed using the POS-based reordering model as described in [6] to account for the different word orders in the languages. To cover long-range reorderings, we apply a modified reordering model with non-continuous rules [7]. The part-of-speech tags for the reordering model are obtained using the TreeTagger [8]. The phrase table and the phrases were built"
2011.iwslt-evaluation.15,2007.tmi-papers.21,0,0.0128424,"ot match its aligned translation sentence. These noisy pairs potentially degrade the quality of the translation model. The special filtering was applied to the Giga corpus and some of the Quaero data. We used a Support Vector Machines classifier to filter the corpus, inspired by the work of [5] on comparable data. To generate the translation model, we used the MGIZA++ Toolkit to calculate the word alignment for the training corpus. Afterwards, the alignments were combined using the grow-diag-final-and heuristic. Word reordering is addressed using the POS-based reordering model as described in [6] to account for the different word orders in the languages. To cover long-range reorderings, we apply a modified reordering model with non-continuous rules [7]. The part-of-speech tags for the reordering model are obtained using the TreeTagger [8]. The phrase table and the phrases were built with the Moses Toolkit [9] and scored by our inhouse parallel phrase scorer [10]. We used 4-gram language models with Kneser-Ney smoothing, which are generated by using the SRILM toolkit [11]. The system applied a bilingual language model as described in [12] to extend the context of source language words"
2011.iwslt-evaluation.15,W09-0435,1,0.688116,"Giga corpus and some of the Quaero data. We used a Support Vector Machines classifier to filter the corpus, inspired by the work of [5] on comparable data. To generate the translation model, we used the MGIZA++ Toolkit to calculate the word alignment for the training corpus. Afterwards, the alignments were combined using the grow-diag-final-and heuristic. Word reordering is addressed using the POS-based reordering model as described in [6] to account for the different word orders in the languages. To cover long-range reorderings, we apply a modified reordering model with non-continuous rules [7]. The part-of-speech tags for the reordering model are obtained using the TreeTagger [8]. The phrase table and the phrases were built with the Moses Toolkit [9] and scored by our inhouse parallel phrase scorer [10]. We used 4-gram language models with Kneser-Ney smoothing, which are generated by using the SRILM toolkit [11]. The system applied a bilingual language model as described in [12] to extend the context of source language words available for translation. Tuning is performed using minimum error rate training against the B LEU score as described in [13]. Translations are generated using"
2011.iwslt-evaluation.15,P07-2045,0,0.00836467,"generate the translation model, we used the MGIZA++ Toolkit to calculate the word alignment for the training corpus. Afterwards, the alignments were combined using the grow-diag-final-and heuristic. Word reordering is addressed using the POS-based reordering model as described in [6] to account for the different word orders in the languages. To cover long-range reorderings, we apply a modified reordering model with non-continuous rules [7]. The part-of-speech tags for the reordering model are obtained using the TreeTagger [8]. The phrase table and the phrases were built with the Moses Toolkit [9] and scored by our inhouse parallel phrase scorer [10]. We used 4-gram language models with Kneser-Ney smoothing, which are generated by using the SRILM toolkit [11]. The system applied a bilingual language model as described in [12] to extend the context of source language words available for translation. Tuning is performed using minimum error rate training against the B LEU score as described in [13]. Translations are generated using our in-house phrase-based decoder [14]. German-French For German to French we applied longrange POS-based reordering rules and lattice phrase extraction. We ad"
2011.iwslt-evaluation.15,W11-2145,1,0.808022,"oolkit to calculate the word alignment for the training corpus. Afterwards, the alignments were combined using the grow-diag-final-and heuristic. Word reordering is addressed using the POS-based reordering model as described in [6] to account for the different word orders in the languages. To cover long-range reorderings, we apply a modified reordering model with non-continuous rules [7]. The part-of-speech tags for the reordering model are obtained using the TreeTagger [8]. The phrase table and the phrases were built with the Moses Toolkit [9] and scored by our inhouse parallel phrase scorer [10]. We used 4-gram language models with Kneser-Ney smoothing, which are generated by using the SRILM toolkit [11]. The system applied a bilingual language model as described in [12] to extend the context of source language words available for translation. Tuning is performed using minimum error rate training against the B LEU score as described in [13]. Translations are generated using our in-house phrase-based decoder [14]. German-French For German to French we applied longrange POS-based reordering rules and lattice phrase extraction. We added a bilingual language model and a POSbased bilingua"
2011.iwslt-evaluation.15,W11-2124,1,0.82441,"g the POS-based reordering model as described in [6] to account for the different word orders in the languages. To cover long-range reorderings, we apply a modified reordering model with non-continuous rules [7]. The part-of-speech tags for the reordering model are obtained using the TreeTagger [8]. The phrase table and the phrases were built with the Moses Toolkit [9] and scored by our inhouse parallel phrase scorer [10]. We used 4-gram language models with Kneser-Ney smoothing, which are generated by using the SRILM toolkit [11]. The system applied a bilingual language model as described in [12] to extend the context of source language words available for translation. Tuning is performed using minimum error rate training against the B LEU score as described in [13]. Translations are generated using our in-house phrase-based decoder [14]. German-French For German to French we applied longrange POS-based reordering rules and lattice phrase extraction. We added a bilingual language model and a POSbased bilingual language model. The part-of-speeches for this model were generated by using the RF tagger for German [15] and the LIA Tagger for French 3 . These taggers produce more fine-grain"
2011.iwslt-evaluation.15,W05-0836,1,0.88503,"ng model with non-continuous rules [7]. The part-of-speech tags for the reordering model are obtained using the TreeTagger [8]. The phrase table and the phrases were built with the Moses Toolkit [9] and scored by our inhouse parallel phrase scorer [10]. We used 4-gram language models with Kneser-Ney smoothing, which are generated by using the SRILM toolkit [11]. The system applied a bilingual language model as described in [12] to extend the context of source language words available for translation. Tuning is performed using minimum error rate training against the B LEU score as described in [13]. Translations are generated using our in-house phrase-based decoder [14]. German-French For German to French we applied longrange POS-based reordering rules and lattice phrase extraction. We added a bilingual language model and a POSbased bilingual language model. The part-of-speeches for this model were generated by using the RF tagger for German [15] and the LIA Tagger for French 3 . These taggers produce more fine-grained linguistic information than the TreeTagger, whose output is used for POS-based reordering. French-German For French to German we also used long-range POS based reordering"
2011.iwslt-evaluation.15,C08-1098,0,0.0239782,"kit [11]. The system applied a bilingual language model as described in [12] to extend the context of source language words available for translation. Tuning is performed using minimum error rate training against the B LEU score as described in [13]. Translations are generated using our in-house phrase-based decoder [14]. German-French For German to French we applied longrange POS-based reordering rules and lattice phrase extraction. We added a bilingual language model and a POSbased bilingual language model. The part-of-speeches for this model were generated by using the RF tagger for German [15] and the LIA Tagger for French 3 . These taggers produce more fine-grained linguistic information than the TreeTagger, whose output is used for POS-based reordering. French-German For French to German we also used long-range POS based reordering rules and lattice phrase extraction. Using the POS-based language model led to a big improvement. 3.2. LIMSI LIMSI’s participation in Quaero 2011 evaluation campaign was focused on the translation of German from and into French. The adaptation of our text translation system to speech inputs is mostly performed in preprocessing, aimed at removing dysflu"
2011.iwslt-evaluation.15,N04-4026,0,0.0164881,"slation system based on bilingual n-grams. N-code overview N-code’s translation model implements a stochastic finite-state transducer (FST) trained using an n-gram model (source,target) pairs. The training requires source-side sentence reorderings to match the target word order, also performed by a stochastic FST reordering model, which uses POS information to generalize reordering patterns beyond lexical regularities. Complementary to the translation model, ten more features are used in a linear scoring function: a target-language model; four lexicon models; two lexicalized reordering models [16] to predict the orientation of the next translation unit; a weak distancebased distortion model; and finally a word-bonus model and a tuple-bonus model which compensate for the system preference for short translations. The four lexicon models are similar to the standard ones in phrase-based systems: two scores correspond to the relative frequencies of the tuples and two lexical weights, estimated from the automatically generated word alignments. The weights associated to features are found using the minimum error rate training procedure [17] on the development set. The decoding is beam-search-"
2011.iwslt-evaluation.15,P03-1021,0,0.0157097,"ur lexicon models; two lexicalized reordering models [16] to predict the orientation of the next translation unit; a weak distancebased distortion model; and finally a word-bonus model and a tuple-bonus model which compensate for the system preference for short translations. The four lexicon models are similar to the standard ones in phrase-based systems: two scores correspond to the relative frequencies of the tuples and two lexical weights, estimated from the automatically generated word alignments. The weights associated to features are found using the minimum error rate training procedure [17] on the development set. The decoding is beam-search-based on top of a dynamic programming algorithm. Reordering hypotheses are computed in a preprocessing step, making use of reordering rules built from the word reorderings introduced in the tuple extraction process. The resulting reordering hypotheses are passed to the decoder as word lattices [18]. German-French Part-of-speech information for German 3 http://lia.univ-avignon.fr/fileadmin/documents/ Users/Intranet/chercheurs/bechet/download_fred. html 4 http://www.limsi.fr/Individu/jmcrego/n-code 116 is computed using in-house CRF-based tagg"
2011.iwslt-evaluation.15,P10-1052,1,0.744516,"the development set. The decoding is beam-search-based on top of a dynamic programming algorithm. Reordering hypotheses are computed in a preprocessing step, making use of reordering rules built from the word reorderings introduced in the tuple extraction process. The resulting reordering hypotheses are passed to the decoder as word lattices [18]. German-French Part-of-speech information for German 3 http://lia.univ-avignon.fr/fileadmin/documents/ Users/Intranet/chercheurs/bechet/download_fred. html 4 http://www.limsi.fr/Individu/jmcrego/n-code 116 is computed using in-house CRF-based tagger [19]. All the available data has been preprocessed and word aligned using MGIZA++; these alignments were then used in a standard Ncode pipeline. As development set we used the WMT 2010 newstest set; internal tests were conducted on the test data of 2009 and 2011. LIMSI used the best available text translation system and the preprocessing with tools initially developed and used for our German to English systems [20]. These tools have also been augmented so as to perform a restricted form of longrange reorderings, notably to move separable particles closer to the verbs they depend on [21]. For the r"
2011.iwslt-evaluation.15,D09-1022,1,0.784658,"al machine translation system (pbt) used in this work is an inhouse implementation of the state-of-the-art machine translation decoder described in [25]. For our hierarchical setups, we employed the open source translation toolkit Jane [26], which has been developed at RWTH and is freely available for non-commercial use. The basic concept of RWTH’s approach to machine translation system combination is described in [27, 28]. With both decoders, we did several setups with different amounts of models. Optional additional models are discriminative word lexicon (dwl) models, triplet lexicon models [29] and additionally binary count features. Unless stated otherwise, we optimized the model weights with standard minimum error rate training [17] on 100-best lists on B LEU. • pbt with additional models dwl and triplets • pbt with additional model triplets With the system combination of all different systems, we got an improvement in B LEU and in T ER compared to the best single system of both tasks. 3.4. SYSTRAN The German and French data submitted by SYSTRAN were obtained by the SYSTRAN baseline engine, being traditionally classified as a rule-based system. However, over the decades, its devel"
2011.iwslt-evaluation.15,2010.iwslt-papers.6,0,0.0142765,"a.univ-avignon.fr/fileadmin/documents/ Users/Intranet/chercheurs/bechet/download_fred. html 4 http://www.limsi.fr/Individu/jmcrego/n-code 116 is computed using in-house CRF-based tagger [19]. All the available data has been preprocessed and word aligned using MGIZA++; these alignments were then used in a standard Ncode pipeline. As development set we used the WMT 2010 newstest set; internal tests were conducted on the test data of 2009 and 2011. LIMSI used the best available text translation system and the preprocessing with tools initially developed and used for our German to English systems [20]. These tools have also been augmented so as to perform a restricted form of longrange reorderings, notably to move separable particles closer to the verbs they depend on [21]. For the reordering models we selected the monotone-swap-discontinuous (MSD) model. Language models Large 4-gram language models were trained on all the available data as described in [22]. Additionally, SOUL, a neuronal language model was used to rescore the n-best hypotheses. These models were trained following the methodology of [23] and used for rescoring n-best lists. We used 10-gram history size (differences with 6"
2011.iwslt-evaluation.15,C00-2162,1,0.678983,"sed tagger [19]. All the available data has been preprocessed and word aligned using MGIZA++; these alignments were then used in a standard Ncode pipeline. As development set we used the WMT 2010 newstest set; internal tests were conducted on the test data of 2009 and 2011. LIMSI used the best available text translation system and the preprocessing with tools initially developed and used for our German to English systems [20]. These tools have also been augmented so as to perform a restricted form of longrange reorderings, notably to move separable particles closer to the verbs they depend on [21]. For the reordering models we selected the monotone-swap-discontinuous (MSD) model. Language models Large 4-gram language models were trained on all the available data as described in [22]. Additionally, SOUL, a neuronal language model was used to rescore the n-best hypotheses. These models were trained following the methodology of [23] and used for rescoring n-best lists. We used 10-gram history size (differences with 6-gram were insignificant). Using the neural language model led to (small but consistent) improvements in all tasks. With the help of system combination, we combined the hypoth"
2011.iwslt-evaluation.15,2008.iwslt-papers.8,1,0.818685,"the pipeline was unchanged as compared to text translations. For the Quaero 2011 evaluation RWTH utilized state-ofthe-art phrase-based and hierarchical translation systems as well as our in-house system combination framework. GIZA [24] was employed to train word alignments, all language models were created with the SRILM toolkit [11] and are standard 4-gram language models with interpolated modified Kneser-Ney smoothing. The phrase-based statistical machine translation system (pbt) used in this work is an inhouse implementation of the state-of-the-art machine translation decoder described in [25]. For our hierarchical setups, we employed the open source translation toolkit Jane [26], which has been developed at RWTH and is freely available for non-commercial use. The basic concept of RWTH’s approach to machine translation system combination is described in [27, 28]. With both decoders, we did several setups with different amounts of models. Optional additional models are discriminative word lexicon (dwl) models, triplet lexicon models [29] and additionally binary count features. Unless stated otherwise, we optimized the model weights with standard minimum error rate training [17] on 1"
2011.iwslt-evaluation.15,E06-1005,1,0.810679,"ents, all language models were created with the SRILM toolkit [11] and are standard 4-gram language models with interpolated modified Kneser-Ney smoothing. The phrase-based statistical machine translation system (pbt) used in this work is an inhouse implementation of the state-of-the-art machine translation decoder described in [25]. For our hierarchical setups, we employed the open source translation toolkit Jane [26], which has been developed at RWTH and is freely available for non-commercial use. The basic concept of RWTH’s approach to machine translation system combination is described in [27, 28]. With both decoders, we did several setups with different amounts of models. Optional additional models are discriminative word lexicon (dwl) models, triplet lexicon models [29] and additionally binary count features. Unless stated otherwise, we optimized the model weights with standard minimum error rate training [17] on 100-best lists on B LEU. • pbt with additional models dwl and triplets • pbt with additional model triplets With the system combination of all different systems, we got an improvement in B LEU and in T ER compared to the best single system of both tasks. 3.4. SYSTRAN The Ger"
2011.iwslt-evaluation.15,J03-1002,1,\N,Missing
2011.iwslt-evaluation.15,W11-2135,1,\N,Missing
2011.iwslt-evaluation.16,2011.iwslt-evaluation.15,1,\N,Missing
2011.iwslt-evaluation.16,H05-1026,1,\N,Missing
2011.iwslt-papers.1,E09-1044,0,\N,Missing
2011.iwslt-papers.1,D09-1022,1,\N,Missing
2011.iwslt-papers.1,J93-2003,0,\N,Missing
2011.iwslt-papers.1,W10-1738,1,\N,Missing
2011.iwslt-papers.1,P11-2080,0,\N,Missing
2011.iwslt-papers.1,N09-2005,1,\N,Missing
2011.iwslt-papers.1,W06-1607,0,\N,Missing
2011.iwslt-papers.1,P07-2045,0,\N,Missing
2011.iwslt-papers.1,P07-1020,0,\N,Missing
2011.iwslt-papers.1,N03-1017,0,\N,Missing
2011.iwslt-papers.1,P02-1038,1,\N,Missing
2011.iwslt-papers.1,J03-1002,1,\N,Missing
2011.iwslt-papers.1,P07-1019,0,\N,Missing
2011.iwslt-papers.1,D08-1039,1,\N,Missing
2011.iwslt-papers.1,N04-1021,0,\N,Missing
2011.iwslt-papers.1,N04-1033,1,\N,Missing
2011.iwslt-papers.1,J07-2003,0,\N,Missing
2011.iwslt-papers.1,2010.amta-papers.33,0,\N,Missing
2011.iwslt-papers.1,2006.iwslt-evaluation.15,1,\N,Missing
2011.iwslt-papers.1,D08-1076,0,\N,Missing
2011.iwslt-papers.1,P11-2081,0,\N,Missing
2011.iwslt-papers.1,P04-1066,0,\N,Missing
2011.iwslt-papers.5,D10-1044,0,\N,Missing
2011.iwslt-papers.5,D11-1033,0,\N,Missing
2011.iwslt-papers.5,J93-2003,0,\N,Missing
2011.iwslt-papers.5,P02-1040,0,\N,Missing
2011.iwslt-papers.5,D09-1074,0,\N,Missing
2011.iwslt-papers.5,P10-2041,0,\N,Missing
2011.iwslt-papers.5,P07-1004,0,\N,Missing
2011.iwslt-papers.5,P07-2045,0,\N,Missing
2011.iwslt-papers.5,P08-2030,0,\N,Missing
2011.iwslt-papers.5,D07-1036,0,\N,Missing
2011.iwslt-papers.5,W07-0733,0,\N,Missing
2011.iwslt-papers.5,P03-1021,0,\N,Missing
2011.iwslt-papers.5,J03-1002,1,\N,Missing
2011.iwslt-papers.5,W04-3250,0,\N,Missing
2011.iwslt-papers.5,N04-1021,0,\N,Missing
2011.iwslt-papers.7,2006.iwslt-papers.1,1,0.409395,"d by the accuracy of the predicted punctuation as well as by the quality of the final translation output. The paper is organized as follows. In Section 2, a short overview of the published research on punctuation prediction is given. In Section 3, we recapitulate different approaches for punctuation prediction. We present our approach using a statistical phrase-based machine translation system in Section 4, followed by Section 5 describing the system combination. Finally, Section 6 describes the experimental results, followed by a conclusion. 2. Related Work This paper is based on the work of [1]. Amongst others they presented three different approaches to restore punctuation in already segmented ASR output. In addition to implicit punctuation generation in the translation process, punc238 tuation was predicted as pre- and postprocessing step. For punctuation prediction they used the HIDDEN - NGRAM tool from the SRI toolkit [2]. The implicit punctuation generation worked best on IWSLT 2006 corpus, but on TC-STAR 2006 corpus they achieved better results with punctuation prediction on source and target. They pointed out that on small corpora like IWSLT 2006 falsely inserted punctuation"
2011.iwslt-papers.7,2007.iwslt-1.10,0,0.130195,"ed best on IWSLT 2006 corpus, but on TC-STAR 2006 corpus they achieved better results with punctuation prediction on source and target. They pointed out that on small corpora like IWSLT 2006 falsely inserted punctuation marks in the source side deteriorated the performance of the translation system. However, the IWSLT corpus became larger in the last years and therefore we verify the results within IWSLT 2011 SLT task. Furthermore, we use in addition for the punctuation prediction a phrase-based statistical machine translation system. Using MT for punctuation prediction was first described in [3]. In this work, a phrase-based statistical machine translation system was trained on a pseudo-’bilingual’ corpus. The case-sensitive target language text with punctuation was considered as the target language and the text without case information and punctuation was used as source language. They applied this approach as postprocessing step in evaluation campaign of IWSLT 2007 and achieved a significant improvement over the baseline. In [4] the same approach was employed as preprocessing step and compared with the HIDDEN - NGRAM tool within the evaluation campaign of IWSLT 2008. The HIDDEN NGRA"
2011.iwslt-papers.7,D10-1018,0,0.317837,"DDEN NGRAM tool outperformed the MT-based punctuation prediction. Moreover, they achieved further improvements by combining these two methods using a majority voting procedure. In our work, we further investigate this approach and compare it with the HIDDEN - NGRAM tool at different stages at which the prediction is done. In our analysis we consider translation quality at the end of the translation pipeline as well as the accuracy of the punctuation prediction. In contrast to the majority vote, we do a system combination of the hypotheses of all different approaches. The approach described in [5] is based on conditional random fields (CRF). They extended the linear-chain CRF model to a factorial CRF model using two layers with different sets of tags for punctuation marks respectively sentence types. They compared their novel approach with linear-chain CRF model and the HIDDEN - NGRAM tool on the IWSLT 2009 corpus. Besides the comparison of the translation quality in terms of B LEU, they also compared the CRF models with the hidden event language model regarding precision, recall and F1-measure. Both in terms of B LEU and in terms of precision, recall and F1-measure the CRF models outp"
2011.iwslt-papers.7,2008.iwslt-papers.8,1,0.342239,"s in the source sentences become non-aligned. In Figure 3 and Figure 4 is one example for deleting the punctuation marks in the source sentence. Now, we are able to train a monolingual MT system for unpunctuated to punctuated text. The tuning set for the parameter tuning is constructed by removing the punctuation marks from the regular development set source text. As reference we use the original source text with the punctuation left intact. The phrase-based MT system used in this work for the punctuation prediction is an in-house implementation of the state-of-the-art MT decoder described in [6]. We use the standard set of models with phrase translation probabilities and lexical smoothing in both directions, word and phrase penalty, an 9-gram source language model and three binary count features. Due to the fact, that we use a monotone alignment, the reordering model is dropped. We also allow longer phrases to capture punctuation dependencies. The optimization is done with standard MERT [7] on 200-best lists with FullPunct Implicit NoPunct system combination Figure 5: System combination of the translation result coming from different punctuation prediction methods. B LEU as optimizat"
2011.iwslt-papers.7,P03-1021,0,0.0466025,"rce text with the punctuation left intact. The phrase-based MT system used in this work for the punctuation prediction is an in-house implementation of the state-of-the-art MT decoder described in [6]. We use the standard set of models with phrase translation probabilities and lexical smoothing in both directions, word and phrase penalty, an 9-gram source language model and three binary count features. Due to the fact, that we use a monotone alignment, the reordering model is dropped. We also allow longer phrases to capture punctuation dependencies. The optimization is done with standard MERT [7] on 200-best lists with FullPunct Implicit NoPunct system combination Figure 5: System combination of the translation result coming from different punctuation prediction methods. B LEU as optimization criterion. 200-best lists are chosen to get more different hypotheses. 5. System Combination System combination is used to produce consensus translations from multiple translation hypotheses generated with different systems. We follow an approach similar to the one described in [8, 9]. The basic procedure is, that hypotheses from different translations systems are aligned on the word level to fin"
2011.iwslt-papers.7,E06-1005,1,0.319416,"opped. We also allow longer phrases to capture punctuation dependencies. The optimization is done with standard MERT [7] on 200-best lists with FullPunct Implicit NoPunct system combination Figure 5: System combination of the translation result coming from different punctuation prediction methods. B LEU as optimization criterion. 200-best lists are chosen to get more different hypotheses. 5. System Combination System combination is used to produce consensus translations from multiple translation hypotheses generated with different systems. We follow an approach similar to the one described in [8, 9]. The basic procedure is, that hypotheses from different translations systems are aligned on the word level to find corresponding parts. Based on these alignments, a weighted majority voting on aligned words and additional models are used to produce the consensus translation. In the scope of this work, we will combine translation output from multiple punctuation prediction schemes. Figure 5 shows the basic idea how to use system combination in this task. 6. Experimental Evaluation The methods presented in this paper were evaluated on the IWSLT 2011 English-to-French translation track [10]. IWS"
2011.iwslt-papers.7,J07-2003,0,0.0641623,"able 3). We use a modified development set as described in Section 4. We remove the punctuation of the development and test sets which are available in the MT task of IWSLT 2011 (Table 2). MT SLT English French English French 934 20131 20280 17735 20280 17795 3209 3717 3132 3717 1664 31975 33814 27427 33814 27653 3711 4678 3670 4678 6.2. Hierarchical phrase-based decoder for translation The following MT system is given to compare all punctuation prediction strategies. We use the open source hierarchical phrase-based system Jane [11], which implements the hierarchical approach as introduced by [12]. The search is carried out using the cube pruning algorithm [13]. The models integrated into our Jane systems are: phrase translation probabilities in both translation directions, word and phrase penalty, binary features marking hierarchical phrases, glue rule, and rules with non-terminals at the boundaries, four binary count features and an 4-gram language model. For a robust baseline we add a sparse discriminative word lexicon (DWL) model for lexical smoothing and triplets similar to [14]. The model weights are optimized with standard MERT [7] on 100-best lists. 6.3. Comparison of the punct"
2011.iwslt-papers.7,P07-1019,0,0.0607338,"n 4. We remove the punctuation of the development and test sets which are available in the MT task of IWSLT 2011 (Table 2). MT SLT English French English French 934 20131 20280 17735 20280 17795 3209 3717 3132 3717 1664 31975 33814 27427 33814 27653 3711 4678 3670 4678 6.2. Hierarchical phrase-based decoder for translation The following MT system is given to compare all punctuation prediction strategies. We use the open source hierarchical phrase-based system Jane [11], which implements the hierarchical approach as introduced by [12]. The search is carried out using the cube pruning algorithm [13]. The models integrated into our Jane systems are: phrase translation probabilities in both translation directions, word and phrase penalty, binary features marking hierarchical phrases, glue rule, and rules with non-terminals at the boundaries, four binary count features and an 4-gram language model. For a robust baseline we add a sparse discriminative word lexicon (DWL) model for lexical smoothing and triplets similar to [14]. The model weights are optimized with standard MERT [7] on 100-best lists. 6.3. Comparison of the punctuation prediction accuracy To assess and compare the punctuation"
2011.iwslt-papers.7,2010.amta-papers.32,1,0.838696,"hierarchical phrase-based system Jane [11], which implements the hierarchical approach as introduced by [12]. The search is carried out using the cube pruning algorithm [13]. The models integrated into our Jane systems are: phrase translation probabilities in both translation directions, word and phrase penalty, binary features marking hierarchical phrases, glue rule, and rules with non-terminals at the boundaries, four binary count features and an 4-gram language model. For a robust baseline we add a sparse discriminative word lexicon (DWL) model for lexical smoothing and triplets similar to [14]. The model weights are optimized with standard MERT [7] on 100-best lists. 6.3. Comparison of the punctuation prediction accuracy To assess and compare the punctuation prediction performance of the approaches presented in Section 3, we remove all punctuation from test set of the correct manual transcription, and restore the punctuation marks with the HIDDEN NGRAM as well as with our phrase-based decoder for punctuation prediction (PPMT). We use the original test set as reference. We verify the methods before the translation, because the translation process causes too many errors for measuring"
2011.iwslt-papers.7,2006.amta-papers.25,0,0.0866157,". shown in Table 6. When we consider all punctuation, the precision of the prediction with the HIDDEN - NGRAM is slightly higher then PPMT . However, the recall of the prediction with the PPMT is better and this results in a higher F-measure. 6.4. Comparison of the translation quality While a comparison of the punctuation prediction performance might be a good indicator of the overall accuracy of the method, we ultimately want to improve the quality of the translation output. In order to compare the different strategies, we measure the translation quality of all systems in B LEU [15] and T ER [16]. B LEU measures the accuracy of the translation, so higher values in B LEU are better. T ER is an error measure, with lower values indicating better quality. We built five different experimental setups with regards to the description in Subsection 6.2. To compare our new method, we use the HIDDEN - NGRAM tool with the same language model as applied in our phrase-based decoder for punctuation prediction. Thus, we get two systems for F ULL P UNCT and two systems for N O P UNCT. The fifth system is I MPLICIT. Table 7 shows the comparison between the different translation system and both predicti"
2011.iwslt-papers.7,2011.iwslt-evaluation.1,0,0.0685004,"in [8, 9]. The basic procedure is, that hypotheses from different translations systems are aligned on the word level to find corresponding parts. Based on these alignments, a weighted majority voting on aligned words and additional models are used to produce the consensus translation. In the scope of this work, we will combine translation output from multiple punctuation prediction schemes. Figure 5 shows the basic idea how to use system combination in this task. 6. Experimental Evaluation The methods presented in this paper were evaluated on the IWSLT 2011 English-to-French translation track [10]. IWSLT is an annual public evaluation campaign focused on speech translation. The domain of the 2011 translation task is lecture-type talks presented at TED conferences which are also available online2 . Two different conditions were evaluated: Automatic and manual transcription of lectures. While the correct manual transcription also contained punctuation marks, the automatic transcription did not. The automatic transcription used in this work was the 1-best hypothesis from the speech recognition system. The in-domain training data (Table 1) also consisted of transcribed TED lectures as well"
2011.iwslt-papers.7,2008.iwslt-evaluation.3,0,\N,Missing
2011.iwslt-papers.7,P02-1040,0,\N,Missing
2011.iwslt-papers.8,P02-1040,0,0.0794142,"he feature set of the loglinear model of the baseline hierarchical system is augmented with additional dependency-based features that can be categorized in two groups: those associated with the tree building process and those related to the dependency LM. We study how dependency tree building features and dependency LM each perform in isolation. • Usually trigrams are used for the dependency language model. We analyze the typical dependency tree structures found in our data and, based on the findings, explore which dependency language model order is appropriate. Results are presented in B LEU [6] and T ER [7] on a NIST Chinese–English subset and on a German–French corpus. 246 submitted were Bills submitted by Brownback Bills Senator on submitted Bills were ports and immigration on on ports ports Figure 1: Dependency tree of an English sentence. 2. Related Work Besides the authors mentioned in the previous section, several other groups have introduced dependency-based extensions to their machine translation frameworks in recent years. Among them, Galley & Manning [8] perform dependency parsing during decoding by lowering the parsing time to quadratic complexity. The authors work on the"
2011.iwslt-papers.8,2006.amta-papers.25,0,0.0321392,"t of the loglinear model of the baseline hierarchical system is augmented with additional dependency-based features that can be categorized in two groups: those associated with the tree building process and those related to the dependency LM. We study how dependency tree building features and dependency LM each perform in isolation. • Usually trigrams are used for the dependency language model. We analyze the typical dependency tree structures found in our data and, based on the findings, explore which dependency language model order is appropriate. Results are presented in B LEU [6] and T ER [7] on a NIST Chinese–English subset and on a German–French corpus. 246 submitted were Bills submitted by Brownback Bills Senator on submitted Bills were ports and immigration on on ports ports Figure 1: Dependency tree of an English sentence. 2. Related Work Besides the authors mentioned in the previous section, several other groups have introduced dependency-based extensions to their machine translation frameworks in recent years. Among them, Galley & Manning [8] perform dependency parsing during decoding by lowering the parsing time to quadratic complexity. The authors work on the NIST Chinese"
2011.iwslt-papers.8,P09-1087,0,0.122997,"and, based on the findings, explore which dependency language model order is appropriate. Results are presented in B LEU [6] and T ER [7] on a NIST Chinese–English subset and on a German–French corpus. 246 submitted were Bills submitted by Brownback Bills Senator on submitted Bills were ports and immigration on on ports ports Figure 1: Dependency tree of an English sentence. 2. Related Work Besides the authors mentioned in the previous section, several other groups have introduced dependency-based extensions to their machine translation frameworks in recent years. Among them, Galley & Manning [8] perform dependency parsing during decoding by lowering the parsing time to quadratic complexity. The authors work on the NIST Chinese–English corpus and show significant improvements over the baseline. Bach et al. [9] rely on source-side dependency information for reordering information on the tree structure. Similar to lexicalized reordering models, the tree sub-structure is used to employ features in a phrase-based system, for English–Spanish and English–Iraqi. Gao et al. [10] propose soft reordering constraints based on the source-side dependency structure in a hierarchical setting with im"
2011.iwslt-papers.8,2009.mtsummit-papers.1,0,0.0788533,"re Bills submitted by Brownback Bills Senator on submitted Bills were ports and immigration on on ports ports Figure 1: Dependency tree of an English sentence. 2. Related Work Besides the authors mentioned in the previous section, several other groups have introduced dependency-based extensions to their machine translation frameworks in recent years. Among them, Galley & Manning [8] perform dependency parsing during decoding by lowering the parsing time to quadratic complexity. The authors work on the NIST Chinese–English corpus and show significant improvements over the baseline. Bach et al. [9] rely on source-side dependency information for reordering information on the tree structure. Similar to lexicalized reordering models, the tree sub-structure is used to employ features in a phrase-based system, for English–Spanish and English–Iraqi. Gao et al. [10] propose soft reordering constraints based on the source-side dependency structure in a hierarchical setting with improvements on the NIST Chinese–English task. Xie et al. [11] also work with source-side dependencies and store the reordering information for each head-dependent. They employ a dependency-to-string translation model an"
2011.iwslt-papers.8,D11-1079,0,0.0588772,"ed dependency-based extensions to their machine translation frameworks in recent years. Among them, Galley & Manning [8] perform dependency parsing during decoding by lowering the parsing time to quadratic complexity. The authors work on the NIST Chinese–English corpus and show significant improvements over the baseline. Bach et al. [9] rely on source-side dependency information for reordering information on the tree structure. Similar to lexicalized reordering models, the tree sub-structure is used to employ features in a phrase-based system, for English–Spanish and English–Iraqi. Gao et al. [10] propose soft reordering constraints based on the source-side dependency structure in a hierarchical setting with improvements on the NIST Chinese–English task. Xie et al. [11] also work with source-side dependencies and store the reordering information for each head-dependent. They employ a dependency-to-string translation model and compare its performance to a state-of-the-art hierarchical system, on the NIST Chinese–English task. Quirk & Menezes [12] present a treelet translation system with dependency projection from source to target and tree-based decoding. ? X˜1 X˜1 and immigration and w"
2011.iwslt-papers.8,D11-1020,0,0.0556656,"the parsing time to quadratic complexity. The authors work on the NIST Chinese–English corpus and show significant improvements over the baseline. Bach et al. [9] rely on source-side dependency information for reordering information on the tree structure. Similar to lexicalized reordering models, the tree sub-structure is used to employ features in a phrase-based system, for English–Spanish and English–Iraqi. Gao et al. [10] propose soft reordering constraints based on the source-side dependency structure in a hierarchical setting with improvements on the NIST Chinese–English task. Xie et al. [11] also work with source-side dependencies and store the reordering information for each head-dependent. They employ a dependency-to-string translation model and compare its performance to a state-of-the-art hierarchical system, on the NIST Chinese–English task. Quirk & Menezes [12] present a treelet translation system with dependency projection from source to target and tree-based decoding. ? X˜1 X˜1 and immigration and were immigration Figure 2: Example of a well-defined merge (left) and an illdefined merge (right). A different method is to parse the (hopefully grammatically sound) training ma"
2011.iwslt-papers.8,J07-2003,0,0.202423,"earch space, and the information to be gained from dependency tree building during decoding. The application of a non-restrictive approach together with an integrated dependency LM scoring is a novel contribution which yields significant improvements for two large-scale translation tasks for the language pairs Chinese–English and German–French. 1. Introduction String-to-dependency hierarchical machine translation employs target-side dependency features to capture syntactically motivated relations between words even across longer distances. It is based on the hierarchical phrase-based paradigm [1] and implements enhancements that allow for an integration of knowledge obtained from dependency parses of the training material. Dependency trees over translation hypotheses are built on-the-fly during the decoding process from information gathered in the training phase and stored in the phrase table. A dependency language model can be applied to rate the quality of the constructed tree structures. In initial publications on the topic [2, 3], a restriction of the phrase inventory to a subset of phrases which meet certain validity conditions concerning the dependency relations is proposed. Phr"
2011.iwslt-papers.8,P08-1066,0,0.0718468,"ency features to capture syntactically motivated relations between words even across longer distances. It is based on the hierarchical phrase-based paradigm [1] and implements enhancements that allow for an integration of knowledge obtained from dependency parses of the training material. Dependency trees over translation hypotheses are built on-the-fly during the decoding process from information gathered in the training phase and stored in the phrase table. A dependency language model can be applied to rate the quality of the constructed tree structures. In initial publications on the topic [2, 3], a restriction of the phrase inventory to a subset of phrases which meet certain validity conditions concerning the dependency relations is proposed. Phrases with dependency structures that are not suitable for the construction of a well-formed dependency tree are excluded beforehand. Additional merging constraints apply during decoding. In later works [4, 5], heuristics are proposed that enable assembling of malformed dependency structures as well, thus permitting the utilization of the full phrase inventory of the standard hierarchical approach. Validity and tree well-formedness conditions"
2011.iwslt-papers.8,2010.amta-papers.8,1,0.923934,"the decoding process from information gathered in the training phase and stored in the phrase table. A dependency language model can be applied to rate the quality of the constructed tree structures. In initial publications on the topic [2, 3], a restriction of the phrase inventory to a subset of phrases which meet certain validity conditions concerning the dependency relations is proposed. Phrases with dependency structures that are not suitable for the construction of a well-formed dependency tree are excluded beforehand. Additional merging constraints apply during decoding. In later works [4, 5], heuristics are proposed that enable assembling of malformed dependency structures as well, thus permitting the utilization of the full phrase inventory of the standard hierarchical approach. Validity and tree well-formedness conditions are modeled in a soft way as features in the log-linear model. Here, the dependency language model is however included in an n-best reranking framework only. This paper aims at filling the gap by investigating stringto-dependency hierarchical translation with and without restrictions, and by comparing dependency LM reranking methods with dependency LM scoring"
2011.iwslt-papers.8,W10-1738,1,0.889266,"the n-best hypotheses industry merging ∼2 A in the textile Constructed Tree dependency language model features based on a dependency tree built during decoding China in the textile China Figure 6: Merging two phrases with one left and two right merging errors. The dependency pointers point into other directions as the parent-dependencies. pendency language model order, and the influence of features created during the dependency tree construction. Significance levels are annotated with (*) for p &lt; .1 and with (**) for p &lt; .05. We employ RWTH’s freely available machine translation toolkit Jane [14], a hierarchical phrase-based translation system comparable to David Chiang’s Hiero [1]. The baseline setup, which is kept constant for all experiments with the same language pair, consists of the following features: 4gram language model, phrase translation probabilities (target to source and source to target), word translation lexicons, word penalty, phrase penalty, binary markers for hierarchical phrases and generic glue rules. The word alignments have been computed based on the IBM Models with GIZA++ [15]. 5.1. Chinese–English Large parts of our experiments are carried out on the NIST Chine"
2011.iwslt-papers.8,P03-1054,0,0.00837328,"se penalty, binary markers for hierarchical phrases and generic glue rules. The word alignments have been computed based on the IBM Models with GIZA++ [15]. 5.1. Chinese–English Large parts of our experiments are carried out on the NIST Chinese–English task with around 3 million parallel training sentences and 81 million running words on the target side. The NIST 2006 evaluation set (nist06) is used as a development corpus, the NIST 2008 and 2005 sets (nist08, nist05) and a concatenation of the NIST 2002 and 2004 sets (nist0204) are used as test sets. We rely on the Stanford Dependency Parser [16] to create the dependency trees during training and reranking. The parser model was trained on the Wall Street Journal corpus. 5.1.1. Parsing Dependency Tree vs. Building During Decoding First, we wanted to check whether dependency tree construction during decoding is more reliable than obtaining depenTree Features penalty features for construction errors of the dependency tree built during decoding Combinations of these are inspected, too. The results in Table 2 suggest that both the dependency tree derived from parsing the n-best lists as well as the tree built during decoding comparably imp"
2011.iwslt-papers.8,P06-1055,0,0.0162674,"task since the grammar structure is quite different and additional linguistic knowledge often helps the system to improve over the baseline. To examine if we can also obtain improvements on other language pairs, we tested the setup that proved best on the NIST Chinese–English task also on the German–French language pair. We work on the German–French translation task as defined within the Quaero project. Our parallel training corpus consists of 2 million sentences. Since the Stanford dependency parser does not provide a pre-trained model to parse French, we used the Berkeley dependency parser [17] in251 stead. The translation results are presented in Table 7. While the methods show little impact on the eval set of 2010, the translation quality on the other test set significantly improves in both B LEU and T ER when applying tree building features and dependency LM directly in decoding. Even though the performance is not improved on all test sets for the German– French task, we still consider string-to-dependency extensions to be a valuable addition to hierarchical systems even for closer-related language pairs. 6. Conclusion We have shown that information derived from dependencies can"
2012.amta-papers.8,N06-1003,0,0.0296517,"two topics: pivot translation and lightly-supervised training. Many pivot translation approaches have been proposed in the past. The vast literature on pivot translation cannot be discussed in detail here due to space contraints. Wu and Wang (2009) and Utiyama and Isahara (2007) provide good overviews of the field. More recent publications are e.g. (Cettolo et al., 2011), (Leusch et al., 2010) and (Koehn et al., 2009), to mention some. The synthetic method (Wu and Wang, 2009) comes closest to what is done by us. We would like to particularly point to the work by Cohn and Lapata (2007) and by Callison-Burch et al. (2006). Cohn et al. adopt the pivot translation by triangulation method to improve existing baselines. This idea is quite similar to our pivot lightlysupervised training approach, which employs synthetic data. Callison-Burch et al. suggest an interesting paraphrasing technique for SMT that rests upon parallel data with a pivot language. The effect should de facto be comparable. Ueffing et al. (2007) introduced semi-supervised learning methods for the effective use of monolingual data in order to improve translation quality of SMT systems. Large-scale lightly-supervised training for SMT as we define"
2012.amta-papers.8,2011.eamt-1.34,0,0.0159469,"this translation step and the French side of the EnglishFrench parallel corpus constitute an unsupervised bitext which can be used as supplementary training material for our German→French system. 2 Related Work Our method combines techniques from two topics: pivot translation and lightly-supervised training. Many pivot translation approaches have been proposed in the past. The vast literature on pivot translation cannot be discussed in detail here due to space contraints. Wu and Wang (2009) and Utiyama and Isahara (2007) provide good overviews of the field. More recent publications are e.g. (Cettolo et al., 2011), (Leusch et al., 2010) and (Koehn et al., 2009), to mention some. The synthetic method (Wu and Wang, 2009) comes closest to what is done by us. We would like to particularly point to the work by Cohn and Lapata (2007) and by Callison-Burch et al. (2006). Cohn et al. adopt the pivot translation by triangulation method to improve existing baselines. This idea is quite similar to our pivot lightlysupervised training approach, which employs synthetic data. Callison-Burch et al. suggest an interesting paraphrasing technique for SMT that rests upon parallel data with a pivot language. The effect sh"
2012.amta-papers.8,P07-1092,0,0.0464944,"ethod combines techniques from two topics: pivot translation and lightly-supervised training. Many pivot translation approaches have been proposed in the past. The vast literature on pivot translation cannot be discussed in detail here due to space contraints. Wu and Wang (2009) and Utiyama and Isahara (2007) provide good overviews of the field. More recent publications are e.g. (Cettolo et al., 2011), (Leusch et al., 2010) and (Koehn et al., 2009), to mention some. The synthetic method (Wu and Wang, 2009) comes closest to what is done by us. We would like to particularly point to the work by Cohn and Lapata (2007) and by Callison-Burch et al. (2006). Cohn et al. adopt the pivot translation by triangulation method to improve existing baselines. This idea is quite similar to our pivot lightlysupervised training approach, which employs synthetic data. Callison-Burch et al. suggest an interesting paraphrasing technique for SMT that rests upon parallel data with a pivot language. The effect should de facto be comparable. Ueffing et al. (2007) introduced semi-supervised learning methods for the effective use of monolingual data in order to improve translation quality of SMT systems. Large-scale lightly-super"
2012.amta-papers.8,W07-0717,0,0.0244497,"ing the word alignments that are produced by the decoder during the generation of the unsupervised data and using GIZA++ (Och and Ney, 2003) word alignments performs roughly equally well. Lambert et al. also propose to make use of an automatically contructed dictionary which provides unobserved morphological forms of nouns, verbs or adjectives. They achieve a gain of about 0.5 points B LEU over a competitive baseline. Another technique we employ in our experiments is the combination of multiple phrase tables. Combining multiple phrase tables has e.g. been investigated for domain adaptation by Foster and Kuhn (2007) and Koehn and Schroeder (2007) before. Huck et al. (2011) combine phrase tables from human-generated data and from unsupervised data in the context of lightly-supervised training. 3 Lightly-Supervised Training In previous lightly-supervised training scenarios, the baseline source-to-target SMT system is being augmented with additional unsupervised parallel data that is produced by automatically translating either source language monolingual data to the target language or target language monolingual data to the source language. The former is typically done with the baseline system itself, the"
2012.amta-papers.8,W11-2145,0,0.0191725,"ith the frequency-based method described in (Koehn and Knight, 2003). We apply compound splitting to German text whenever German is the source language, but not for setups where German is the target language. The unsupervised data is produced by translating the English side of the English-French 109 corpus as provided for the translation task of the Workshop on Statistical Machine Translation (WMT).4 Data statistics are given in Table 2. Some noisy parts of the raw corpus have been removed beforehand by means of an SVM classifier in a fashion comparable to the filtering technique described by Herrmann et al. (2011). The English→German SMT system with which we translate the English side of the 109 corpus to German is trained with the English-German parallel resources that have been provided for the 2011 WMT shared translation task (constrained track). Statistics of the preprocessed corpus are given in Table 3. 6 Phrase-Based Translation System We apply a phrase-based translation (PBT) system which is an in-house implementation of the stateof-the-art decoder as described by Zens and Ney (2008). A standard set of models is used, comprising phrase translation probabilities and lexical translation probabilit"
2012.amta-papers.8,W11-2211,1,0.799755,"g the generation of the unsupervised data and using GIZA++ (Och and Ney, 2003) word alignments performs roughly equally well. Lambert et al. also propose to make use of an automatically contructed dictionary which provides unobserved morphological forms of nouns, verbs or adjectives. They achieve a gain of about 0.5 points B LEU over a competitive baseline. Another technique we employ in our experiments is the combination of multiple phrase tables. Combining multiple phrase tables has e.g. been investigated for domain adaptation by Foster and Kuhn (2007) and Koehn and Schroeder (2007) before. Huck et al. (2011) combine phrase tables from human-generated data and from unsupervised data in the context of lightly-supervised training. 3 Lightly-Supervised Training In previous lightly-supervised training scenarios, the baseline source-to-target SMT system is being augmented with additional unsupervised parallel data that is produced by automatically translating either source language monolingual data to the target language or target language monolingual data to the source language. The former is typically done with the baseline system itself, the latter with a reverse (”target-to-source”) system. The rev"
2012.amta-papers.8,E03-1076,0,0.130666,"llel training corpora we utilize for an empirical evaluation of pivot lightlysupervised training on a German→French translation task. The pivot language is English. To train the German→French baseline system, we use 2.0M sentence pairs that are partly taken from the Europarl corpus (Koehn, 2005) and have partly tried in our experiments. been collected within the Quaero project.3 Statistics of the preprocessed data can be found in the direct entry of Table 6 (first three lines). The preprocessing pipeline includes splitting of German compound words with the frequency-based method described in (Koehn and Knight, 2003). We apply compound splitting to German text whenever German is the source language, but not for setups where German is the target language. The unsupervised data is produced by translating the English side of the English-French 109 corpus as provided for the translation task of the Workshop on Statistical Machine Translation (WMT).4 Data statistics are given in Table 2. Some noisy parts of the raw corpus have been removed beforehand by means of an SVM classifier in a fashion comparable to the filtering technique described by Herrmann et al. (2011). The English→German SMT system with which we"
2012.amta-papers.8,W07-0733,0,0.0322016,"t are produced by the decoder during the generation of the unsupervised data and using GIZA++ (Och and Ney, 2003) word alignments performs roughly equally well. Lambert et al. also propose to make use of an automatically contructed dictionary which provides unobserved morphological forms of nouns, verbs or adjectives. They achieve a gain of about 0.5 points B LEU over a competitive baseline. Another technique we employ in our experiments is the combination of multiple phrase tables. Combining multiple phrase tables has e.g. been investigated for domain adaptation by Foster and Kuhn (2007) and Koehn and Schroeder (2007) before. Huck et al. (2011) combine phrase tables from human-generated data and from unsupervised data in the context of lightly-supervised training. 3 Lightly-Supervised Training In previous lightly-supervised training scenarios, the baseline source-to-target SMT system is being augmented with additional unsupervised parallel data that is produced by automatically translating either source language monolingual data to the target language or target language monolingual data to the source language. The former is typically done with the baseline system itself, the latter with a reverse (”target-"
2012.amta-papers.8,P07-2045,0,0.00569146,"ervised training approach, which employs synthetic data. Callison-Burch et al. suggest an interesting paraphrasing technique for SMT that rests upon parallel data with a pivot language. The effect should de facto be comparable. Ueffing et al. (2007) introduced semi-supervised learning methods for the effective use of monolingual data in order to improve translation quality of SMT systems. Large-scale lightly-supervised training for SMT as we define it in this paper has been first carried out by Schwenk (2008). Schwenk translates a large amount of monolingual French data with an initial Moses (Koehn et al., 2007) baseline system into English. He uses the resulting unsupervised bitexts as additional training corpora to improve the baseline French→English system. With lightly-supervised training, Schwenk achieves improvements of around one point B LEU over the baseline. In a later work (Schwenk and Senellart, 2009) he applies the same method for translation model adaptation on an Arabic→French task with gains of up to 3.5 points B LEU. Li et al. (2011) present an approach that is very similar to lightly-supervised training. They conduct their experiments with a hierarchical phrase-based system and trans"
2012.amta-papers.8,2009.mtsummit-papers.7,0,0.125307,"nguage and the target language. Pivot translation employs such bitext to bridge from source to target across the pivot language, thus effectively providing source-totarget translation (Utiyama and Isahara, 2007; Wu and Wang, 2009). The method may also be advantageous in cases where many translation systems between a large number of languages are to be built. To save time and cost, it may be convenient to resort to a pivot approach and to set up 2(n − 1) systems between each of n − 1 languages and a common pivot language, instead of setting up n(n − 1) systems between all pairs of n languages (Koehn et al., 2009). We utilize the pivot translation paradigm with a different motivation in this work. We investigate a source-target language combination—German and French—that does not suffer from a lack of resources. A noticeable amount of parallel training data and monolingual target language data exists for this language pair, from which we build a well-performing German→French baseline SMT system. We however argue that our system could be improved if we were able to also deploy the extensive amount of parallel resources of both of these languages with third languages, in particular with English. English-"
2012.amta-papers.8,2005.mtsummit-papers.11,0,0.0705455,"applied to the German target-side data. texts, the source→target system does not only learn from the contents of the corpus the unsupervised data originates from, but also from bilingual information that is represented in the translation model of the pivot→source system. 5 Parallel Resources We now specify the parallel training corpora we utilize for an empirical evaluation of pivot lightlysupervised training on a German→French translation task. The pivot language is English. To train the German→French baseline system, we use 2.0M sentence pairs that are partly taken from the Europarl corpus (Koehn, 2005) and have partly tried in our experiments. been collected within the Quaero project.3 Statistics of the preprocessed data can be found in the direct entry of Table 6 (first three lines). The preprocessing pipeline includes splitting of German compound words with the frequency-based method described in (Koehn and Knight, 2003). We apply compound splitting to German text whenever German is the source language, but not for setups where German is the target language. The unsupervised data is produced by translating the English side of the English-French 109 corpus as provided for the translation t"
2012.amta-papers.8,W11-2132,0,0.126494,"d bitexts as additional training corpora to improve the baseline French→English system. With lightly-supervised training, Schwenk achieves improvements of around one point B LEU over the baseline. In a later work (Schwenk and Senellart, 2009) he applies the same method for translation model adaptation on an Arabic→French task with gains of up to 3.5 points B LEU. Li et al. (2011) present an approach that is very similar to lightly-supervised training. They conduct their experiments with a hierarchical phrase-based system and translate monolingual target language data into the source language. Lambert et al. (2011) investigate a large variety of lightly-supervised training settings on the French-English language pair in both directions. They draw some interesting conclusions, in particular that it is better to add automatically translated texts to the translation model training data which have been translated from the target to the source language (instead of from the source to the target language), and that using the word alignments that are produced by the decoder during the generation of the unsupervised data and using GIZA++ (Och and Ney, 2003) word alignments performs roughly equally well. Lambert"
2012.amta-papers.8,2010.iwslt-papers.12,1,0.812991,"nd the French side of the EnglishFrench parallel corpus constitute an unsupervised bitext which can be used as supplementary training material for our German→French system. 2 Related Work Our method combines techniques from two topics: pivot translation and lightly-supervised training. Many pivot translation approaches have been proposed in the past. The vast literature on pivot translation cannot be discussed in detail here due to space contraints. Wu and Wang (2009) and Utiyama and Isahara (2007) provide good overviews of the field. More recent publications are e.g. (Cettolo et al., 2011), (Leusch et al., 2010) and (Koehn et al., 2009), to mention some. The synthetic method (Wu and Wang, 2009) comes closest to what is done by us. We would like to particularly point to the work by Cohn and Lapata (2007) and by Callison-Burch et al. (2006). Cohn et al. adopt the pivot translation by triangulation method to improve existing baselines. This idea is quite similar to our pivot lightlysupervised training approach, which employs synthetic data. Callison-Burch et al. suggest an interesting paraphrasing technique for SMT that rests upon parallel data with a pivot language. The effect should de facto be compar"
2012.amta-papers.8,D11-1085,0,0.0185183,"ine it in this paper has been first carried out by Schwenk (2008). Schwenk translates a large amount of monolingual French data with an initial Moses (Koehn et al., 2007) baseline system into English. He uses the resulting unsupervised bitexts as additional training corpora to improve the baseline French→English system. With lightly-supervised training, Schwenk achieves improvements of around one point B LEU over the baseline. In a later work (Schwenk and Senellart, 2009) he applies the same method for translation model adaptation on an Arabic→French task with gains of up to 3.5 points B LEU. Li et al. (2011) present an approach that is very similar to lightly-supervised training. They conduct their experiments with a hierarchical phrase-based system and translate monolingual target language data into the source language. Lambert et al. (2011) investigate a large variety of lightly-supervised training settings on the French-English language pair in both directions. They draw some interesting conclusions, in particular that it is better to add automatically translated texts to the translation model training data which have been translated from the target to the source language (instead of from the"
2012.amta-papers.8,J03-1002,1,0.0180522,"ngual target language data into the source language. Lambert et al. (2011) investigate a large variety of lightly-supervised training settings on the French-English language pair in both directions. They draw some interesting conclusions, in particular that it is better to add automatically translated texts to the translation model training data which have been translated from the target to the source language (instead of from the source to the target language), and that using the word alignments that are produced by the decoder during the generation of the unsupervised data and using GIZA++ (Och and Ney, 2003) word alignments performs roughly equally well. Lambert et al. also propose to make use of an automatically contructed dictionary which provides unobserved morphological forms of nouns, verbs or adjectives. They achieve a gain of about 0.5 points B LEU over a competitive baseline. Another technique we employ in our experiments is the combination of multiple phrase tables. Combining multiple phrase tables has e.g. been investigated for domain adaptation by Foster and Kuhn (2007) and Koehn and Schroeder (2007) before. Huck et al. (2011) combine phrase tables from human-generated data and from un"
2012.amta-papers.8,P02-1040,0,0.0905698,"t set. B LEU and T ER are given in percentage. We train alignments in both directions and symmetrize them according to the refined method that was suggested by Och and Ney (2003). 7 Experiments In our experiments, we work with the standard WMT newstest sets. These sets are multi-parallel corpora. Each of the sets exists in a version in each of the three languages that are of relevance to us: German, French, English. We employ newstest2009 as development set in all setups; newstest2008, newstest2010 and newstest2011 are heldout sets and used for testing. We evaluate in truecase with the B LEU (Papineni et al., 2002) and T ER (Snover et al., 2006) measures on a single reference translation. 7.1 Systems for Producing Unsupervised Data We first measure the translation performance of two direct translation systems, a French→German system that we run on the French 109 data to produce pivot unsupervised data, and an English→German system that we run on the English 109 data to produce data for lightly-supervised training without pivot language for comparison with the pivot approach. French→German The French→German system is based on the parallel data from Table 1. Translation results are shown in Table 4. Engli"
2012.amta-papers.8,2009.mtsummit-posters.17,0,0.0630298,"the effective use of monolingual data in order to improve translation quality of SMT systems. Large-scale lightly-supervised training for SMT as we define it in this paper has been first carried out by Schwenk (2008). Schwenk translates a large amount of monolingual French data with an initial Moses (Koehn et al., 2007) baseline system into English. He uses the resulting unsupervised bitexts as additional training corpora to improve the baseline French→English system. With lightly-supervised training, Schwenk achieves improvements of around one point B LEU over the baseline. In a later work (Schwenk and Senellart, 2009) he applies the same method for translation model adaptation on an Arabic→French task with gains of up to 3.5 points B LEU. Li et al. (2011) present an approach that is very similar to lightly-supervised training. They conduct their experiments with a hierarchical phrase-based system and translate monolingual target language data into the source language. Lambert et al. (2011) investigate a large variety of lightly-supervised training settings on the French-English language pair in both directions. They draw some interesting conclusions, in particular that it is better to add automatically tra"
2012.amta-papers.8,2008.iwslt-papers.6,0,0.246176,"iangulation method to improve existing baselines. This idea is quite similar to our pivot lightlysupervised training approach, which employs synthetic data. Callison-Burch et al. suggest an interesting paraphrasing technique for SMT that rests upon parallel data with a pivot language. The effect should de facto be comparable. Ueffing et al. (2007) introduced semi-supervised learning methods for the effective use of monolingual data in order to improve translation quality of SMT systems. Large-scale lightly-supervised training for SMT as we define it in this paper has been first carried out by Schwenk (2008). Schwenk translates a large amount of monolingual French data with an initial Moses (Koehn et al., 2007) baseline system into English. He uses the resulting unsupervised bitexts as additional training corpora to improve the baseline French→English system. With lightly-supervised training, Schwenk achieves improvements of around one point B LEU over the baseline. In a later work (Schwenk and Senellart, 2009) he applies the same method for translation model adaptation on an Arabic→French task with gains of up to 3.5 points B LEU. Li et al. (2011) present an approach that is very similar to ligh"
2012.amta-papers.8,2006.amta-papers.25,0,0.0168824,"n percentage. We train alignments in both directions and symmetrize them according to the refined method that was suggested by Och and Ney (2003). 7 Experiments In our experiments, we work with the standard WMT newstest sets. These sets are multi-parallel corpora. Each of the sets exists in a version in each of the three languages that are of relevance to us: German, French, English. We employ newstest2009 as development set in all setups; newstest2008, newstest2010 and newstest2011 are heldout sets and used for testing. We evaluate in truecase with the B LEU (Papineni et al., 2002) and T ER (Snover et al., 2006) measures on a single reference translation. 7.1 Systems for Producing Unsupervised Data We first measure the translation performance of two direct translation systems, a French→German system that we run on the French 109 data to produce pivot unsupervised data, and an English→German system that we run on the English 109 data to produce data for lightly-supervised training without pivot language for comparison with the pivot approach. French→German The French→German system is based on the parallel data from Table 1. Translation results are shown in Table 4. English→German The English→German sy"
2012.amta-papers.8,P07-1004,0,0.0220326,"Koehn et al., 2009), to mention some. The synthetic method (Wu and Wang, 2009) comes closest to what is done by us. We would like to particularly point to the work by Cohn and Lapata (2007) and by Callison-Burch et al. (2006). Cohn et al. adopt the pivot translation by triangulation method to improve existing baselines. This idea is quite similar to our pivot lightlysupervised training approach, which employs synthetic data. Callison-Burch et al. suggest an interesting paraphrasing technique for SMT that rests upon parallel data with a pivot language. The effect should de facto be comparable. Ueffing et al. (2007) introduced semi-supervised learning methods for the effective use of monolingual data in order to improve translation quality of SMT systems. Large-scale lightly-supervised training for SMT as we define it in this paper has been first carried out by Schwenk (2008). Schwenk translates a large amount of monolingual French data with an initial Moses (Koehn et al., 2007) baseline system into English. He uses the resulting unsupervised bitexts as additional training corpora to improve the baseline French→English system. With lightly-supervised training, Schwenk achieves improvements of around one"
2012.amta-papers.8,N07-1061,0,0.121205,"atistical machine translation are typically applied in scenarios where no bilingual resources to build a translation system between a source and a target language exist. For many under-resourced language pairs, no humangenerated parallel data of source and target texts is available. There may however still be bitexts at hand between both the source language and a third pivot language as well as the same pivot language and the target language. Pivot translation employs such bitext to bridge from source to target across the pivot language, thus effectively providing source-totarget translation (Utiyama and Isahara, 2007; Wu and Wang, 2009). The method may also be advantageous in cases where many translation systems between a large number of languages are to be built. To save time and cost, it may be convenient to resort to a pivot approach and to set up 2(n − 1) systems between each of n − 1 languages and a common pivot language, instead of setting up n(n − 1) systems between all pairs of n languages (Koehn et al., 2009). We utilize the pivot translation paradigm with a different motivation in this work. We investigate a source-target language combination—German and French—that does not suffer from a lack of"
2012.amta-papers.8,P09-1018,0,0.336882,"on are typically applied in scenarios where no bilingual resources to build a translation system between a source and a target language exist. For many under-resourced language pairs, no humangenerated parallel data of source and target texts is available. There may however still be bitexts at hand between both the source language and a third pivot language as well as the same pivot language and the target language. Pivot translation employs such bitext to bridge from source to target across the pivot language, thus effectively providing source-totarget translation (Utiyama and Isahara, 2007; Wu and Wang, 2009). The method may also be advantageous in cases where many translation systems between a large number of languages are to be built. To save time and cost, it may be convenient to resort to a pivot approach and to set up 2(n − 1) systems between each of n − 1 languages and a common pivot language, instead of setting up n(n − 1) systems between all pairs of n languages (Koehn et al., 2009). We utilize the pivot translation paradigm with a different motivation in this work. We investigate a source-target language combination—German and French—that does not suffer from a lack of resources. A notice"
2012.amta-papers.8,2008.iwslt-papers.8,1,0.779267,"moved beforehand by means of an SVM classifier in a fashion comparable to the filtering technique described by Herrmann et al. (2011). The English→German SMT system with which we translate the English side of the 109 corpus to German is trained with the English-German parallel resources that have been provided for the 2011 WMT shared translation task (constrained track). Statistics of the preprocessed corpus are given in Table 3. 6 Phrase-Based Translation System We apply a phrase-based translation (PBT) system which is an in-house implementation of the stateof-the-art decoder as described by Zens and Ney (2008). A standard set of models is used, comprising phrase translation probabilities and lexical translation probabilities in both directions, word and phrase penalty, a distance-based distortion model, an ngram target language model and three simple countbased binary features. Parameter weights are optimized with the downhill simplex algorithm (Nelder and Mead, 1965) on the word graph. The language models in all our setups are 4grams with modified Kneser-Ney smoothing and are trained with the SRILM toolkit (Stolcke, 2002) on large collections of monolingual data. Word alignments are produced with"
2012.eamt-1.66,D10-1054,0,\N,Missing
2012.eamt-1.66,D11-1079,0,\N,Missing
2012.eamt-1.66,E09-1044,0,\N,Missing
2012.eamt-1.66,N04-4026,0,\N,Missing
2012.eamt-1.66,C04-1030,1,\N,Missing
2012.eamt-1.66,D08-1089,0,\N,Missing
2012.eamt-1.66,W10-1738,1,\N,Missing
2012.eamt-1.66,J10-3008,0,\N,Missing
2012.eamt-1.66,P07-2045,0,\N,Missing
2012.eamt-1.66,N09-1049,0,\N,Missing
2012.eamt-1.66,P05-1033,0,\N,Missing
2012.eamt-1.66,J03-1002,1,\N,Missing
2012.eamt-1.66,W06-3108,1,\N,Missing
2012.eamt-1.66,P07-1019,0,\N,Missing
2012.eamt-1.66,2011.eamt-1.37,1,\N,Missing
2012.iwslt-evaluation.7,popovic-ney-2006-pos,1,\N,Missing
2012.iwslt-evaluation.7,N04-4026,0,\N,Missing
2012.iwslt-evaluation.7,D09-1022,1,\N,Missing
2012.iwslt-evaluation.7,J93-2003,0,\N,Missing
2012.iwslt-evaluation.7,E03-1076,0,\N,Missing
2012.iwslt-evaluation.7,N04-4038,0,\N,Missing
2012.iwslt-evaluation.7,C02-1050,0,\N,Missing
2012.iwslt-evaluation.7,P02-1040,0,\N,Missing
2012.iwslt-evaluation.7,W10-1738,1,\N,Missing
2012.iwslt-evaluation.7,P12-3029,0,\N,Missing
2012.iwslt-evaluation.7,J10-3008,0,\N,Missing
2012.iwslt-evaluation.7,2010.iwslt-keynotes.2,0,\N,Missing
2012.iwslt-evaluation.7,P10-2041,0,\N,Missing
2012.iwslt-evaluation.7,P10-1049,1,\N,Missing
2012.iwslt-evaluation.7,P07-2045,0,\N,Missing
2012.iwslt-evaluation.7,P08-2030,0,\N,Missing
2012.iwslt-evaluation.7,W07-0734,0,\N,Missing
2012.iwslt-evaluation.7,2008.iwslt-papers.8,1,\N,Missing
2012.iwslt-evaluation.7,J03-1002,1,\N,Missing
2012.iwslt-evaluation.7,W06-3108,1,\N,Missing
2012.iwslt-evaluation.7,D09-1117,0,\N,Missing
2012.iwslt-evaluation.7,P07-1019,0,\N,Missing
2012.iwslt-evaluation.7,C12-3061,1,\N,Missing
2012.iwslt-evaluation.7,W06-3103,1,\N,Missing
2012.iwslt-evaluation.7,2012.iwslt-papers.18,1,\N,Missing
2012.iwslt-evaluation.7,C12-2091,1,\N,Missing
2012.iwslt-evaluation.7,2010.iwslt-papers.15,1,\N,Missing
2012.iwslt-evaluation.7,2006.iwslt-papers.1,1,\N,Missing
2012.iwslt-evaluation.7,J07-2003,0,\N,Missing
2012.iwslt-evaluation.7,2002.tmi-tutorials.2,0,\N,Missing
2012.iwslt-evaluation.7,P03-1021,0,\N,Missing
2012.iwslt-evaluation.7,2012.eamt-1.60,0,\N,Missing
2012.iwslt-papers.16,W99-0604,1,\N,Missing
2012.iwslt-papers.16,J99-4005,0,\N,Missing
2012.iwslt-papers.16,P02-1040,0,\N,Missing
2012.iwslt-papers.16,P08-1009,0,\N,Missing
2012.iwslt-papers.16,W07-0401,1,\N,Missing
2012.iwslt-papers.16,J06-4004,0,\N,Missing
2012.iwslt-papers.16,N03-1017,0,\N,Missing
2012.iwslt-papers.16,P02-1038,1,\N,Missing
2012.iwslt-papers.16,W06-3108,1,\N,Missing
2012.iwslt-papers.16,W04-3250,0,\N,Missing
2012.iwslt-papers.16,D07-1077,0,\N,Missing
2012.iwslt-papers.16,N04-1021,0,\N,Missing
2012.iwslt-papers.16,P10-1052,0,\N,Missing
2012.iwslt-papers.18,2012.eamt-1.60,0,0.0324683,"postprocessed ASR output. 3. Automatically Transcribed Text in Training The starting point of this work is a data source which provides audio recordings, the corresponding manual transcriptions and the translation of these transcriptions. The onlineavailable TED talks are such a kind of source 1 . This website provides manually transcribed and translated lecturetype talks presented at TED conferences. Furthermore, WIT3 (Web Inventory of Transcribed and Translated Talks) redistributes the original content published by the TED website 1 http://www.ted.com/ for the machine translation community [6]. The transcriptions and the translations are processed as parallel bilingual corpus to be able to train an SMT system. Further, development and test sets are provided. In an SLT application, the development and test sets are automatically transcribed speech, which have to be translated into a target language. We assume in this work that the recognitions of the development and test sets do not contain punctuation and casing and the segmentation is given and corresponds to sentence-like units. With an SMT system, the automatically recognized speech is translated. Furthermore, the punctuation an"
2012.iwslt-papers.18,2006.iwslt-papers.1,1,0.952728,"s to be able to train an SMT system. Further, development and test sets are provided. In an SLT application, the development and test sets are automatically transcribed speech, which have to be translated into a target language. We assume in this work that the recognitions of the development and test sets do not contain punctuation and casing and the segmentation is given and corresponds to sentence-like units. With an SMT system, the automatically recognized speech is translated. Furthermore, the punctuation and the case information are restored during the translation process as described in [7]. In order to train such an SMT system, the punctuation and the case information of source language data in the bilingual training corpus are deleted to create a pseudo ASR output. In our work, we train an SMT system on a bilingual corpus with real ASR output instead of pseudo ASR output as source language data. Due to the fact that WIT3 also speciﬁes the talks which were used to create the provided bilingual corpora, we are able to recognize the relevant audio recordings with our ASR system. About 1028 relevant talks are available on the web. In sum, roughly 250 hours of speech have to be rec"
2012.iwslt-papers.18,2005.iwslt-1.19,1,0.891421,"levant talks are available on the web. In sum, roughly 250 hours of speech have to be recognized. Using the automatically transcribed recordings as source language data, we build a new bilingual corpus to train an SMT system for an SLT task. 3.1. Sentence Alignment In general, an ASR system does not provide sentence-wise segmentation. However, a bilingual corpus, which is used to train an SMT system, consists of parallel sentences. In order to align automatic transcriptions sentence-wise to a given segmented manual transcription, we employ an automatic resegmentation algorithm as described in [8]. The re-segmentation algorithm calculates the Levenshtein alignment between the recognition and its manual transcription. By backtracing the decisions of the edit distance algorithm, an alignment between a given sequence of words and an already sentence-wise segmented manual transcription as reference can be found. Thus, the sentence segmentation of the reference is transferred to the recognition. The re-segmentation algorithm is solved by dynamic programming. As mentioned, WIT3 provides manually transcribed text as well as the corresponding translation. First, we align our recognized trainin"
2012.iwslt-papers.18,P12-2006,1,0.818664,"me tool. The recognition is structured in three passes, In the ﬁrst pass, a speaker independent model is used. The recognition result of the ﬁrst pass is used for estimating feature transformations for speaker adaptation (CMLLR). The second pass uses the CMLLR transformed features. Finally, a confusion network decoding is performed on the word lattices obtained from the second pass. and a small amount of in-domain data (ted), see Table 3. The recognition lexicon consists of 150k words. 4.2. MT System The decoder of the phrase-based translation system which is used in this work is described in [10] and is part of RWTH’s open-source SMT toolkit Jane 2.1 2 . We use the standard set of models with phrase translation probabilities and lexical smoothing in both directions, word and phrase penalty, distance-based distortion model, a 4-gram target language model and three binary count features. The features hm ( f1J , eJ1 ) are combined in a weighted log-linear model to ˆ ﬁnd the best translation eˆI1 ˆ eˆI1 = arg max Table 2: Acoustic training data of ASR system Corpus Amount of data [hours] quaero-2011 268h hub4+tdt4 393h epps 102h Table 3: Language model training data of ASR system Corpus G"
2012.iwslt-papers.18,P03-1021,0,0.0859037,"transcribed acoustic data in total, see Table 2. The acoustic training data consists of American broadcast news data (hub4+tdt4), European parliament speeches (epps), and British broadcast conversations (quaero). The MLP is trained on the 268 hours of the quaero corpus only. We use 4500 triphone states and perform eight EM splits, resulting in a GMM with roughly 1.1 million mixture components. The language model is trained on a large amount of news data (Gigaword), the transcriptions of the audio training data, eI1 M ∑ λm hm ( f1J , eJ1 ). (2) m=1 The weights are optimized using standard MERT [11] on 200-best lists with B LEU as optimization criterion. 5. Experimental Evaluation The proposed approach was evaluated on the IWSLT 2012 English-to-French spoken language translation task based on the already mentioned TED talks. For the evaluation, WIT3 provides in-domain bilingual training data based on manually transcribed text and its translation. The 1028 talks (around 250 hours of speech), which corresponds to the bilingual training data, were recognized with the described ASR system. For the baseline model, we removed punctuation and case information of the source language to create ps"
2012.iwslt-papers.18,2006.amta-papers.25,0,0.0328718,"bles are marked as AUTOMATIC - TRANSCRIPTION ◦ MANUAL TRANSCRIPTION . 5.1.3. Training Data Concatenation In contrast to the other two methods, the training corpora MANUAL - TRANSCRIPTION and AUTOMATIC TRANSCRIPTION were combined before the phrase extraction. In particular, MANUAL - TRANSCRIPTION and AUTOMATIC - TRANSCRIPTION were concatenated and the translation model was re-trained. This setup is named AUTOMATIC - TRANSCRIPTION + MANUAL TRANSCRIPTION . 5.2. Results Table 9 shows the comparison between different setups. We measured the translation quality of all systems in B LEU [14] and T ER [15] on the development set as well as on the test set. First, we ran two baseline experiments. Both systems were trained on MANUAL - TRANSCRIPTION. The ﬁrst setup was tuned and tested on the provided development and test sets (IWSLT 2012) and the second one on our own recognitions. It seems that a better W ER results in a higher translation quality. Using AUTOMATIC - TRANSCRIPTION (cn-decoding) performs only slightly better then the baseline. The biggest improvement was achieved by AUTOMATIC - TRANSCRIPTION (cn-decoding) ◦ MANUAL - TRANSCRIPTION in comparison to MANUAL - TRANSCRIPTION (baseline,"
2012.iwslt-papers.18,P02-1040,0,\N,Missing
2012.iwslt-papers.18,J03-1002,1,\N,Missing
2012.iwslt-papers.18,2011.iwslt-papers.7,1,\N,Missing
2012.iwslt-papers.7,N12-1006,0,0.0128186,"y, we experiment with mixture modeling, where additional improvements are reported when using weighted phrase extraction over a variety of baselines. 1. Introduction Over the last years, large amounts of monolingual and bilingual training corpora were collected for statistical machine translation (SMT). Early years focused on structured data translation such as newswire and parliamentary discussions. Nowadays, due to the success of SMT, new domains of translation are being explored, such as talk translation in the IWSLT TED evaluation [1] and dialects translation within the DARPA BOLT project [2]. The introduction of the BOLT project marks a shift in the Arabic NLP community, changing the focus from handling Modern Standard Arabic (MSA) structured data (e.g. news) to dialectal Arabic user generated noisy data (e.g. emails, weblogs). Dialectal Arabic is mainly spoken and scarcely written, even when it is written, the lack of common orthography causes signiﬁcant variety and ambiguity in lexicon and morphology. The challenge is even greater due to the domain of informal communication, which is noisy by its nature. In this work, we perform experiments on both the BOLT and the IWSLT TED se"
2012.iwslt-papers.7,P07-1004,0,0.0751221,"recaps brieﬂy mixture modeling methods that will be used in the paper. Experimental setup including corpora statistics and the SMT system are described in Section 5. The results of the described methods are summarized in Section 6. Last, we conclude with few suggestions for future work. 2. Related work A broad range of methods and techniques have been suggested in the past for domain adaptation for SMT. The techniques include, among others: (i) semi-supervised training where one translates in-domain monolingual data and utilizes the automatic translations for retraining the LM and/or the TM ([3],[4]), (ii) different methods of interpolating indomain and out-of-domain models ([5], [6], [7]) (iii) and sample weighting on the sentence or even the phrase level for LM training ([8],[9]) and TM training ([10],[11],[12]). Note that ﬁltering is a special case of the sample weighting method where a threshold is assigned to discard unwanted samples. Weighted phrase extraction can be done at several levels of granularity. [6] perform TM adaptation using mixture modeling at the corpus level. Each corpus in their setting gets a weight using various methods including language model (LM) perplexity"
2012.iwslt-papers.7,2008.iwslt-papers.6,0,0.0369171,"aps brieﬂy mixture modeling methods that will be used in the paper. Experimental setup including corpora statistics and the SMT system are described in Section 5. The results of the described methods are summarized in Section 6. Last, we conclude with few suggestions for future work. 2. Related work A broad range of methods and techniques have been suggested in the past for domain adaptation for SMT. The techniques include, among others: (i) semi-supervised training where one translates in-domain monolingual data and utilizes the automatic translations for retraining the LM and/or the TM ([3],[4]), (ii) different methods of interpolating indomain and out-of-domain models ([5], [6], [7]) (iii) and sample weighting on the sentence or even the phrase level for LM training ([8],[9]) and TM training ([10],[11],[12]). Note that ﬁltering is a special case of the sample weighting method where a threshold is assigned to discard unwanted samples. Weighted phrase extraction can be done at several levels of granularity. [6] perform TM adaptation using mixture modeling at the corpus level. Each corpus in their setting gets a weight using various methods including language model (LM) perplexity and"
2012.iwslt-papers.7,D07-1036,0,0.0733458,"setup including corpora statistics and the SMT system are described in Section 5. The results of the described methods are summarized in Section 6. Last, we conclude with few suggestions for future work. 2. Related work A broad range of methods and techniques have been suggested in the past for domain adaptation for SMT. The techniques include, among others: (i) semi-supervised training where one translates in-domain monolingual data and utilizes the automatic translations for retraining the LM and/or the TM ([3],[4]), (ii) different methods of interpolating indomain and out-of-domain models ([5], [6], [7]) (iii) and sample weighting on the sentence or even the phrase level for LM training ([8],[9]) and TM training ([10],[11],[12]). Note that ﬁltering is a special case of the sample weighting method where a threshold is assigned to discard unwanted samples. Weighted phrase extraction can be done at several levels of granularity. [6] perform TM adaptation using mixture modeling at the corpus level. Each corpus in their setting gets a weight using various methods including language model (LM) perplexity and information retrieval methods. Interpolation is then done linearly or log-linear"
2012.iwslt-papers.7,W07-0717,0,0.766722,"including corpora statistics and the SMT system are described in Section 5. The results of the described methods are summarized in Section 6. Last, we conclude with few suggestions for future work. 2. Related work A broad range of methods and techniques have been suggested in the past for domain adaptation for SMT. The techniques include, among others: (i) semi-supervised training where one translates in-domain monolingual data and utilizes the automatic translations for retraining the LM and/or the TM ([3],[4]), (ii) different methods of interpolating indomain and out-of-domain models ([5], [6], [7]) (iii) and sample weighting on the sentence or even the phrase level for LM training ([8],[9]) and TM training ([10],[11],[12]). Note that ﬁltering is a special case of the sample weighting method where a threshold is assigned to discard unwanted samples. Weighted phrase extraction can be done at several levels of granularity. [6] perform TM adaptation using mixture modeling at the corpus level. Each corpus in their setting gets a weight using various methods including language model (LM) perplexity and information retrieval methods. Interpolation is then done linearly or log-linearly. T"
2012.iwslt-papers.7,W07-0733,0,0.269671,"uding corpora statistics and the SMT system are described in Section 5. The results of the described methods are summarized in Section 6. Last, we conclude with few suggestions for future work. 2. Related work A broad range of methods and techniques have been suggested in the past for domain adaptation for SMT. The techniques include, among others: (i) semi-supervised training where one translates in-domain monolingual data and utilizes the automatic translations for retraining the LM and/or the TM ([3],[4]), (ii) different methods of interpolating indomain and out-of-domain models ([5], [6], [7]) (iii) and sample weighting on the sentence or even the phrase level for LM training ([8],[9]) and TM training ([10],[11],[12]). Note that ﬁltering is a special case of the sample weighting method where a threshold is assigned to discard unwanted samples. Weighted phrase extraction can be done at several levels of granularity. [6] perform TM adaptation using mixture modeling at the corpus level. Each corpus in their setting gets a weight using various methods including language model (LM) perplexity and information retrieval methods. Interpolation is then done linearly or log-linearly. The we"
2012.iwslt-papers.7,P10-2041,0,0.625833,"cribed methods are summarized in Section 6. Last, we conclude with few suggestions for future work. 2. Related work A broad range of methods and techniques have been suggested in the past for domain adaptation for SMT. The techniques include, among others: (i) semi-supervised training where one translates in-domain monolingual data and utilizes the automatic translations for retraining the LM and/or the TM ([3],[4]), (ii) different methods of interpolating indomain and out-of-domain models ([5], [6], [7]) (iii) and sample weighting on the sentence or even the phrase level for LM training ([8],[9]) and TM training ([10],[11],[12]). Note that ﬁltering is a special case of the sample weighting method where a threshold is assigned to discard unwanted samples. Weighted phrase extraction can be done at several levels of granularity. [6] perform TM adaptation using mixture modeling at the corpus level. Each corpus in their setting gets a weight using various methods including language model (LM) perplexity and information retrieval methods. Interpolation is then done linearly or log-linearly. The weights are calculated using the development set therefore expressing adaptation to the domain b"
2012.iwslt-papers.7,D09-1074,0,0.57478,"marized in Section 6. Last, we conclude with few suggestions for future work. 2. Related work A broad range of methods and techniques have been suggested in the past for domain adaptation for SMT. The techniques include, among others: (i) semi-supervised training where one translates in-domain monolingual data and utilizes the automatic translations for retraining the LM and/or the TM ([3],[4]), (ii) different methods of interpolating indomain and out-of-domain models ([5], [6], [7]) (iii) and sample weighting on the sentence or even the phrase level for LM training ([8],[9]) and TM training ([10],[11],[12]). Note that ﬁltering is a special case of the sample weighting method where a threshold is assigned to discard unwanted samples. Weighted phrase extraction can be done at several levels of granularity. [6] perform TM adaptation using mixture modeling at the corpus level. Each corpus in their setting gets a weight using various methods including language model (LM) perplexity and information retrieval methods. Interpolation is then done linearly or log-linearly. The weights are calculated using the development set therefore expressing adaptation to the domain being translated. [13] a"
2012.iwslt-papers.7,D10-1044,0,0.0761371,"ed in Section 6. Last, we conclude with few suggestions for future work. 2. Related work A broad range of methods and techniques have been suggested in the past for domain adaptation for SMT. The techniques include, among others: (i) semi-supervised training where one translates in-domain monolingual data and utilizes the automatic translations for retraining the LM and/or the TM ([3],[4]), (ii) different methods of interpolating indomain and out-of-domain models ([5], [6], [7]) (iii) and sample weighting on the sentence or even the phrase level for LM training ([8],[9]) and TM training ([10],[11],[12]). Note that ﬁltering is a special case of the sample weighting method where a threshold is assigned to discard unwanted samples. Weighted phrase extraction can be done at several levels of granularity. [6] perform TM adaptation using mixture modeling at the corpus level. Each corpus in their setting gets a weight using various methods including language model (LM) perplexity and information retrieval methods. Interpolation is then done linearly or log-linearly. The weights are calculated using the development set therefore expressing adaptation to the domain being translated. [13] also p"
2012.iwslt-papers.7,D11-1033,0,0.714182,"Section 6. Last, we conclude with few suggestions for future work. 2. Related work A broad range of methods and techniques have been suggested in the past for domain adaptation for SMT. The techniques include, among others: (i) semi-supervised training where one translates in-domain monolingual data and utilizes the automatic translations for retraining the LM and/or the TM ([3],[4]), (ii) different methods of interpolating indomain and out-of-domain models ([5], [6], [7]) (iii) and sample weighting on the sentence or even the phrase level for LM training ([8],[9]) and TM training ([10],[11],[12]). Note that ﬁltering is a special case of the sample weighting method where a threshold is assigned to discard unwanted samples. Weighted phrase extraction can be done at several levels of granularity. [6] perform TM adaptation using mixture modeling at the corpus level. Each corpus in their setting gets a weight using various methods including language model (LM) perplexity and information retrieval methods. Interpolation is then done linearly or log-linearly. The weights are calculated using the development set therefore expressing adaptation to the domain being translated. [13] also perfor"
2012.iwslt-papers.7,E12-1055,0,0.0672497,"([10],[11],[12]). Note that ﬁltering is a special case of the sample weighting method where a threshold is assigned to discard unwanted samples. Weighted phrase extraction can be done at several levels of granularity. [6] perform TM adaptation using mixture modeling at the corpus level. Each corpus in their setting gets a weight using various methods including language model (LM) perplexity and information retrieval methods. Interpolation is then done linearly or log-linearly. The weights are calculated using the development set therefore expressing adaptation to the domain being translated. [13] also performs weighting at the corpus level, but the weights are integrated into the phrase model estimation procedure. His method does not show an advantage over linear interpolation. A ﬁner grained weighting is that of [10], who assign each sentence in the bitexts a weight using features of metainformation and optimizing a mapping from feature vectors to weights using a translation quality measure over the development set. [11] perform weighting at the phrase level, using a maximum likelihood term limited to the development set as an objective function to optimize. They compare the phrase l"
2012.iwslt-papers.7,W12-3154,0,0.287022,"n removing phrase pairs completely when ﬁltering. We compare our weighting method to ﬁltering and show superior results. In some cases, one might be interested in reducing the size of the TM for efﬁciency reasons. We combine ﬁltering with weighting, and show that this leads to better performance than ﬁltering alone. Last, as done in some of the previous work mentioned above, we experiment with mixture modeling over the weighted phrase models. We use linear and log-linear interpolation similar to [6]. We differ from [13] by showing improved results over linear interpolation of baseline models. [14] analyze the effect of adding a general-domain corpus at different parts of the SMT training pipeline. A method denoted as “x+yE” performed best in their experiments. This method extracts all phrases from a concatenation of in-domain and general corpora, then, if a phrase pair exists in the in-domain phrase table it is assigned the indomain probability, otherwise it is assigned the probability from the concatenation phrase table. We call this method an ifelse combination and test it in our experiments. 3. Weighted phrase extraction The classical phrase model is trained using a “simple” maximum"
2012.iwslt-papers.7,P07-2045,0,0.00718144,"incipled way is by weighting the sentences of the corpora differently, such that sentences which are more related to the domain will have higher weights and therefore have a stronger impact on the phrase probabilities. For language model training purposes, we use an additional 8 billion words for BOLT (4B words from the LDC gigaword corpus and 4B words collected from web resources) and 1.4 billion words for IWSLT (supplied as part of the campaign monolingual training data 3 ). 5.2. Translation system The baseline system is built using a state-of-the art phrasebased SMT system similar to Moses [15]. We use the standard set of models with phrase translation probabilities for source-to-target and target-to-source directions, smoothing with lexical weights, a word and phrase penalty, distancebased reordering and an n-gram target language model. The lexical models are trained on the in-domain portion of the data and kept constant throughout the experiments. This way we achieve more control on the variability of the experiments. In the experiments, we update the phrase probability features in both directions of translation. The SMT systems are tuned on the dev development set with minimum er"
2012.iwslt-papers.7,P03-1021,0,0.0151574,"ard set of models with phrase translation probabilities for source-to-target and target-to-source directions, smoothing with lexical weights, a word and phrase penalty, distancebased reordering and an n-gram target language model. The lexical models are trained on the in-domain portion of the data and kept constant throughout the experiments. This way we achieve more control on the variability of the experiments. In the experiments, we update the phrase probability features in both directions of translation. The SMT systems are tuned on the dev development set with minimum error rate training [16] using B LEU [17] accuracy measure as the optimization criterion. We test the performance of our system on the test set using the B LEU and translation edit rate (TER) [18] measures. We use T ER as an additional measure to verify the consistency of our improvements and avoid over-tuning. The BOLT results are case insensitive while the IWSLT results are case sensitive. In addition to the raw automatic results, we perform signiﬁcance testing over the test 3 For a list of the IWSLT TED 2011 training corpora, see http://www. iwslt2011.org/doku.php?id=06_evaluation 196 The 9th International Worksho"
2012.iwslt-papers.7,P02-1040,0,0.0876515,"with phrase translation probabilities for source-to-target and target-to-source directions, smoothing with lexical weights, a word and phrase penalty, distancebased reordering and an n-gram target language model. The lexical models are trained on the in-domain portion of the data and kept constant throughout the experiments. This way we achieve more control on the variability of the experiments. In the experiments, we update the phrase probability features in both directions of translation. The SMT systems are tuned on the dev development set with minimum error rate training [16] using B LEU [17] accuracy measure as the optimization criterion. We test the performance of our system on the test set using the B LEU and translation edit rate (TER) [18] measures. We use T ER as an additional measure to verify the consistency of our improvements and avoid over-tuning. The BOLT results are case insensitive while the IWSLT results are case sensitive. In addition to the raw automatic results, we perform signiﬁcance testing over the test 3 For a list of the IWSLT TED 2011 training corpora, see http://www. iwslt2011.org/doku.php?id=06_evaluation 196 The 9th International Workshop on Spoken Langu"
2012.iwslt-papers.7,2006.amta-papers.25,0,0.0188416,"tancebased reordering and an n-gram target language model. The lexical models are trained on the in-domain portion of the data and kept constant throughout the experiments. This way we achieve more control on the variability of the experiments. In the experiments, we update the phrase probability features in both directions of translation. The SMT systems are tuned on the dev development set with minimum error rate training [16] using B LEU [17] accuracy measure as the optimization criterion. We test the performance of our system on the test set using the B LEU and translation edit rate (TER) [18] measures. We use T ER as an additional measure to verify the consistency of our improvements and avoid over-tuning. The BOLT results are case insensitive while the IWSLT results are case sensitive. In addition to the raw automatic results, we perform signiﬁcance testing over the test 3 For a list of the IWSLT TED 2011 training corpora, see http://www. iwslt2011.org/doku.php?id=06_evaluation 196 The 9th International Workshop on Spoken Language Translation Hong Kong, December 6th-7th, 2012 Translation model Unﬁltered EGY EGY+GEN Filtered EGY+GEN-1Mbest EGY+GEN-1Mrand Weighted phrase extr. 10EG"
2012.iwslt-papers.7,W04-3250,0,0.175582,"Missing"
2012.iwslt-papers.7,2011.iwslt-evaluation.1,0,\N,Missing
2013.iwslt-evaluation.15,2012.iwslt-evaluation.7,1,\N,Missing
2013.iwslt-evaluation.16,2012.eamt-1.60,1,0.8976,"neous speech and heterogeneous topics and styles. The 1 http://www.eu-bridge.eu task is open domain, with a wide range of heavily dissimilar subjects and jargons across talks. IWSLT subdivides the task and separately evaluates automatic transcription of talks from audio to text, speech translation of talks from audio, and text translation of talks as three different tracks [3, 4]. The training data is constrained to the corpora specified by the organizers. The supplied list of corpora comprises a large amount of publicly available monolingual and parallel training data, though, including WIT3 [5], Europarl [6], MultiUN [7], the English and French Gigaword corpora as provided by the Linguistic Data Consortium [8], and the News Crawl, 109 and News Commentary corpora from the WMT shared task training data [9]. For the two “official” language pairs [1] for translation at IWSLT 2013, English→French and German→English, these resources allow for building of systems with state-of-the-art performance by participants. The EU-BRIDGE project is funded by the European Union under the Seventh Framework Programme (FP7) [10] and brings together several project partners who have each previously been v"
2013.iwslt-evaluation.16,2005.mtsummit-papers.11,1,0.078384,"nd heterogeneous topics and styles. The 1 http://www.eu-bridge.eu task is open domain, with a wide range of heavily dissimilar subjects and jargons across talks. IWSLT subdivides the task and separately evaluates automatic transcription of talks from audio to text, speech translation of talks from audio, and text translation of talks as three different tracks [3, 4]. The training data is constrained to the corpora specified by the organizers. The supplied list of corpora comprises a large amount of publicly available monolingual and parallel training data, though, including WIT3 [5], Europarl [6], MultiUN [7], the English and French Gigaword corpora as provided by the Linguistic Data Consortium [8], and the News Crawl, 109 and News Commentary corpora from the WMT shared task training data [9]. For the two “official” language pairs [1] for translation at IWSLT 2013, English→French and German→English, these resources allow for building of systems with state-of-the-art performance by participants. The EU-BRIDGE project is funded by the European Union under the Seventh Framework Programme (FP7) [10] and brings together several project partners who have each previously been very successful"
2013.iwslt-evaluation.16,eisele-chen-2010-multiun,0,0.0452925,"ous topics and styles. The 1 http://www.eu-bridge.eu task is open domain, with a wide range of heavily dissimilar subjects and jargons across talks. IWSLT subdivides the task and separately evaluates automatic transcription of talks from audio to text, speech translation of talks from audio, and text translation of talks as three different tracks [3, 4]. The training data is constrained to the corpora specified by the organizers. The supplied list of corpora comprises a large amount of publicly available monolingual and parallel training data, though, including WIT3 [5], Europarl [6], MultiUN [7], the English and French Gigaword corpora as provided by the Linguistic Data Consortium [8], and the News Crawl, 109 and News Commentary corpora from the WMT shared task training data [9]. For the two “official” language pairs [1] for translation at IWSLT 2013, English→French and German→English, these resources allow for building of systems with state-of-the-art performance by participants. The EU-BRIDGE project is funded by the European Union under the Seventh Framework Programme (FP7) [10] and brings together several project partners who have each previously been very successful in contribut"
2013.iwslt-evaluation.16,E06-1005,1,0.921596,"e-scale evaluation campaigns like IWSLT and WMT in recent years, thereby demonstrating their ability to continuously enhance their systems and promoting progress in machine translation. Machine translation research within EU-BRIDGE has a strong focus on translation of spoken language. The IWSLT TED talks task constitutes an interesting framework for empirical testing of some of the systems for spoken language translation which are developed as part of the project. The work described here is an attempt to attain translation quality beyond strong single system performance via system combination [11]. Similar cooperative approaches based on system combination have proven to be valuable for machine translation in other projects, e.g. in the Quaero programme [12, 13]. Within EU-BRIDGE, we built combined system setups for text translation of talks from English to French as well as from German to English. We found that the combined translation engines of RWTH, UEDIN, KIT, and FBK systems are very effective. In the rest of the paper we will give some insight into the technology behind the combined engines which have been used to produce the joint EU-BRIDGE submission to the IWSLT 2013 MT track"
2013.iwslt-evaluation.16,P02-1040,0,0.0892795,"-BRIDGE submission to the IWSLT 2013 MT track. The remainder of the paper is structured as follows: We first describe the individual English→French and German→English systems by RWTH Aachen University (Section 2), the University of Edinburgh (Section 3), Karlsruhe Institute of Technology (Section 4), and Fondazione Bruno Kessler (Section 5), respectively. We then present the techniques for machine translation system combination which have been employed to obtain consensus translations from the outputs of the individual systems of the project partners (Section 6). Experimental results in B LEU [14] and T ER [15] are given in Section 7. A brief error analysis on selected examples from the test data has been conducted which we discuss in Section 8. We finally conclude the paper with Section 9. 2. RWTH Aachen University RWTH applied both the phrase-based (RWTH scss) and the hierarchical (RWTH hiero) decoder implemented in RWTH’s publicly available translation toolkit Jane [16, 17, 18, 19]. The model weights of all systems were tuned with standard Minimum Error Rate Training [20] on the provided dev2010 set. RWTH used B LEU as optimization objective. Language models were created with the SR"
2013.iwslt-evaluation.16,2006.amta-papers.25,0,0.15922,"sion to the IWSLT 2013 MT track. The remainder of the paper is structured as follows: We first describe the individual English→French and German→English systems by RWTH Aachen University (Section 2), the University of Edinburgh (Section 3), Karlsruhe Institute of Technology (Section 4), and Fondazione Bruno Kessler (Section 5), respectively. We then present the techniques for machine translation system combination which have been employed to obtain consensus translations from the outputs of the individual systems of the project partners (Section 6). Experimental results in B LEU [14] and T ER [15] are given in Section 7. A brief error analysis on selected examples from the test data has been conducted which we discuss in Section 8. We finally conclude the paper with Section 9. 2. RWTH Aachen University RWTH applied both the phrase-based (RWTH scss) and the hierarchical (RWTH hiero) decoder implemented in RWTH’s publicly available translation toolkit Jane [16, 17, 18, 19]. The model weights of all systems were tuned with standard Minimum Error Rate Training [20] on the provided dev2010 set. RWTH used B LEU as optimization objective. Language models were created with the SRILM toolkit [2"
2013.iwslt-evaluation.16,W10-1738,1,0.880309,"iques for machine translation system combination which have been employed to obtain consensus translations from the outputs of the individual systems of the project partners (Section 6). Experimental results in B LEU [14] and T ER [15] are given in Section 7. A brief error analysis on selected examples from the test data has been conducted which we discuss in Section 8. We finally conclude the paper with Section 9. 2. RWTH Aachen University RWTH applied both the phrase-based (RWTH scss) and the hierarchical (RWTH hiero) decoder implemented in RWTH’s publicly available translation toolkit Jane [16, 17, 18, 19]. The model weights of all systems were tuned with standard Minimum Error Rate Training [20] on the provided dev2010 set. RWTH used B LEU as optimization objective. Language models were created with the SRILM toolkit [21]. All RWTH systems include the standard set of models provided by Jane. For English→French, the final setups for RWTH scss and RWTH hiero differ in the amount of training data and in the choice of models. For the English→French hierarchical setup the bilingual data was limited to the in-domain WIT3 data, News Commentary, Europarl, and Common Crawl corpora. The word alignment w"
2013.iwslt-evaluation.16,popovic-ney-2006-pos,1,0.929216,"ll available parallel data and trained a word alignment with GIZA++ [24]. The same language model as in the hierarchical setup was used. RWTH applied the following supplementary features for the phrase-based system: a lexicalized reordering model [25], a discriminative word lexicon [26], a 7-gram word class language model [27], a continuous space language model [28], and a second translation model from the WIT3 portion of the training data only. For German→English, RWTH decompounded the German source in a preprocessing step [29] and applied partof-speech-based long-range verb reordering rules [30]. Both systems RWTH scss and RWTH hiero rest upon all available bilingual data and word alignment obtained with GIZA++. A language model was trained on the target side of all available bilingual data plus 12 of the Shuffled News corpus and 1 4 of the English Gigaword v3 corpus, resulting in a total of 1.7 billion running words. In both German→English systems, RWTH applied a more sophisticated discriminative phrase training method. Similar to [31], a gradient-based method is used to optimize a maximum expected B LEU objective, for which we define B LEU on the sentence level with smoothed 3-gram"
2013.iwslt-evaluation.16,P03-1021,0,0.129032,"ns from the outputs of the individual systems of the project partners (Section 6). Experimental results in B LEU [14] and T ER [15] are given in Section 7. A brief error analysis on selected examples from the test data has been conducted which we discuss in Section 8. We finally conclude the paper with Section 9. 2. RWTH Aachen University RWTH applied both the phrase-based (RWTH scss) and the hierarchical (RWTH hiero) decoder implemented in RWTH’s publicly available translation toolkit Jane [16, 17, 18, 19]. The model weights of all systems were tuned with standard Minimum Error Rate Training [20] on the provided dev2010 set. RWTH used B LEU as optimization objective. Language models were created with the SRILM toolkit [21]. All RWTH systems include the standard set of models provided by Jane. For English→French, the final setups for RWTH scss and RWTH hiero differ in the amount of training data and in the choice of models. For the English→French hierarchical setup the bilingual data was limited to the in-domain WIT3 data, News Commentary, Europarl, and Common Crawl corpora. The word alignment was created with fast align [22]. A language model was trained on the target side of all avai"
2013.iwslt-evaluation.16,P12-1031,0,0.10415,"For German→English, RWTH decompounded the German source in a preprocessing step [29] and applied partof-speech-based long-range verb reordering rules [30]. Both systems RWTH scss and RWTH hiero rest upon all available bilingual data and word alignment obtained with GIZA++. A language model was trained on the target side of all available bilingual data plus 12 of the Shuffled News corpus and 1 4 of the English Gigaword v3 corpus, resulting in a total of 1.7 billion running words. In both German→English systems, RWTH applied a more sophisticated discriminative phrase training method. Similar to [31], a gradient-based method is used to optimize a maximum expected B LEU objective, for which we define B LEU on the sentence level with smoothed 3-gram and 4gram precisions. RWTH performed discriminative training on the WIT3 portion of the training data. The German→English phrase-based system was furthermore improved by a lexicalized reordering model and 7-gram word class language model. RWTH finally applied domain adaptation by adding a second translation model to the decoder which was trained on the WIT3 portion of the data only. This second translation model was likewise improved with discri"
2013.iwslt-evaluation.16,P10-2041,0,0.0805135,"setups for RWTH scss and RWTH hiero differ in the amount of training data and in the choice of models. For the English→French hierarchical setup the bilingual data was limited to the in-domain WIT3 data, News Commentary, Europarl, and Common Crawl corpora. The word alignment was created with fast align [22]. A language model was trained on the target side of all available bilingual data plus 12 of the Shuffled News corpus and 41 of the French Gigaword Second Edition corpus. The monolingual data selection for using only parts of the corpora is based on cross-entropy difference as described in [23]. The hierarchical system was extended with a second translation model. The additional translation model was trained on the WIT3 portion of the training data only. For the English→French phrase-based setup, RWTH utilized all available parallel data and trained a word alignment with GIZA++ [24]. The same language model as in the hierarchical setup was used. RWTH applied the following supplementary features for the phrase-based system: a lexicalized reordering model [25], a discriminative word lexicon [26], a 7-gram word class language model [27], a continuous space language model [28], and a se"
2013.iwslt-evaluation.16,D08-1089,0,0.117877,"orpus. The monolingual data selection for using only parts of the corpora is based on cross-entropy difference as described in [23]. The hierarchical system was extended with a second translation model. The additional translation model was trained on the WIT3 portion of the training data only. For the English→French phrase-based setup, RWTH utilized all available parallel data and trained a word alignment with GIZA++ [24]. The same language model as in the hierarchical setup was used. RWTH applied the following supplementary features for the phrase-based system: a lexicalized reordering model [25], a discriminative word lexicon [26], a 7-gram word class language model [27], a continuous space language model [28], and a second translation model from the WIT3 portion of the training data only. For German→English, RWTH decompounded the German source in a preprocessing step [29] and applied partof-speech-based long-range verb reordering rules [30]. Both systems RWTH scss and RWTH hiero rest upon all available bilingual data and word alignment obtained with GIZA++. A language model was trained on the target side of all available bilingual data plus 12 of the Shuffled News corpus and 1 4 of"
2013.iwslt-evaluation.16,P07-2045,1,0.0125349,"EU on the sentence level with smoothed 3-gram and 4gram precisions. RWTH performed discriminative training on the WIT3 portion of the training data. The German→English phrase-based system was furthermore improved by a lexicalized reordering model and 7-gram word class language model. RWTH finally applied domain adaptation by adding a second translation model to the decoder which was trained on the WIT3 portion of the data only. This second translation model was likewise improved with discriminative phrase training. 3. University of Edinburgh UEDIN’s systems were trained using the Moses system [32], replicating the settings described in [33] developed for the 2013 Workshop on Statistical Machine Translation. The characteristics of the system include: a maximum sentence length of 80, grow-diag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM [34] used at runtime, a lexically-driven 5-gram operation sequence model [35] with four additional supportive features (two gap-based penalties, one distance-based feature and one deletion penalty), msdbidirectional-fe lexicalized reordering, sparse lexical and domain features [36], a"
2013.iwslt-evaluation.16,W13-2212,1,0.868834,"m and 4gram precisions. RWTH performed discriminative training on the WIT3 portion of the training data. The German→English phrase-based system was furthermore improved by a lexicalized reordering model and 7-gram word class language model. RWTH finally applied domain adaptation by adding a second translation model to the decoder which was trained on the WIT3 portion of the data only. This second translation model was likewise improved with discriminative phrase training. 3. University of Edinburgh UEDIN’s systems were trained using the Moses system [32], replicating the settings described in [33] developed for the 2013 Workshop on Statistical Machine Translation. The characteristics of the system include: a maximum sentence length of 80, grow-diag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM [34] used at runtime, a lexically-driven 5-gram operation sequence model [35] with four additional supportive features (two gap-based penalties, one distance-based feature and one deletion penalty), msdbidirectional-fe lexicalized reordering, sparse lexical and domain features [36], a distortion limit of 6, 100-best translation"
2013.iwslt-evaluation.16,W11-2123,0,0.0545914,"tion by adding a second translation model to the decoder which was trained on the WIT3 portion of the data only. This second translation model was likewise improved with discriminative phrase training. 3. University of Edinburgh UEDIN’s systems were trained using the Moses system [32], replicating the settings described in [33] developed for the 2013 Workshop on Statistical Machine Translation. The characteristics of the system include: a maximum sentence length of 80, grow-diag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM [34] used at runtime, a lexically-driven 5-gram operation sequence model [35] with four additional supportive features (two gap-based penalties, one distance-based feature and one deletion penalty), msdbidirectional-fe lexicalized reordering, sparse lexical and domain features [36], a distortion limit of 6, 100-best translation options, minimum Bayes risk decoding [37], cube pruning [38] with a stack size of 1000 during tuning and 5000 during testing and the no-reordering-over-punctuation heuristic. UEDIN used the compact phrase table representation by [39]. For English→German, UEDIN used a sequen"
2013.iwslt-evaluation.16,P11-1105,1,0.916011,"d on the WIT3 portion of the data only. This second translation model was likewise improved with discriminative phrase training. 3. University of Edinburgh UEDIN’s systems were trained using the Moses system [32], replicating the settings described in [33] developed for the 2013 Workshop on Statistical Machine Translation. The characteristics of the system include: a maximum sentence length of 80, grow-diag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM [34] used at runtime, a lexically-driven 5-gram operation sequence model [35] with four additional supportive features (two gap-based penalties, one distance-based feature and one deletion penalty), msdbidirectional-fe lexicalized reordering, sparse lexical and domain features [36], a distortion limit of 6, 100-best translation options, minimum Bayes risk decoding [37], cube pruning [38] with a stack size of 1000 during tuning and 5000 during testing and the no-reordering-over-punctuation heuristic. UEDIN used the compact phrase table representation by [39]. For English→German, UEDIN used a sequence model over morphological tags. The UEDIN systems were tuned on the dev"
2013.iwslt-evaluation.16,D09-1022,1,0.892821,"n for using only parts of the corpora is based on cross-entropy difference as described in [23]. The hierarchical system was extended with a second translation model. The additional translation model was trained on the WIT3 portion of the training data only. For the English→French phrase-based setup, RWTH utilized all available parallel data and trained a word alignment with GIZA++ [24]. The same language model as in the hierarchical setup was used. RWTH applied the following supplementary features for the phrase-based system: a lexicalized reordering model [25], a discriminative word lexicon [26], a 7-gram word class language model [27], a continuous space language model [28], and a second translation model from the WIT3 portion of the training data only. For German→English, RWTH decompounded the German source in a preprocessing step [29] and applied partof-speech-based long-range verb reordering rules [30]. Both systems RWTH scss and RWTH hiero rest upon all available bilingual data and word alignment obtained with GIZA++. A language model was trained on the target side of all available bilingual data plus 12 of the Shuffled News corpus and 1 4 of the English Gigaword v3 corpus, resu"
2013.iwslt-evaluation.16,2012.iwslt-papers.17,1,0.860668,"em [32], replicating the settings described in [33] developed for the 2013 Workshop on Statistical Machine Translation. The characteristics of the system include: a maximum sentence length of 80, grow-diag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM [34] used at runtime, a lexically-driven 5-gram operation sequence model [35] with four additional supportive features (two gap-based penalties, one distance-based feature and one deletion penalty), msdbidirectional-fe lexicalized reordering, sparse lexical and domain features [36], a distortion limit of 6, 100-best translation options, minimum Bayes risk decoding [37], cube pruning [38] with a stack size of 1000 during tuning and 5000 during testing and the no-reordering-over-punctuation heuristic. UEDIN used the compact phrase table representation by [39]. For English→German, UEDIN used a sequence model over morphological tags. The UEDIN systems were tuned on the dev2010 set made available for the IWSLT 2013 workshop. Tuning was performed using the k-best batch MIRA algorithm [40] with a maximum number of iterations of 25. B LEU was used as the metric to evaluate resu"
2013.iwslt-evaluation.16,D13-1138,1,0.815085,"based on cross-entropy difference as described in [23]. The hierarchical system was extended with a second translation model. The additional translation model was trained on the WIT3 portion of the training data only. For the English→French phrase-based setup, RWTH utilized all available parallel data and trained a word alignment with GIZA++ [24]. The same language model as in the hierarchical setup was used. RWTH applied the following supplementary features for the phrase-based system: a lexicalized reordering model [25], a discriminative word lexicon [26], a 7-gram word class language model [27], a continuous space language model [28], and a second translation model from the WIT3 portion of the training data only. For German→English, RWTH decompounded the German source in a preprocessing step [29] and applied partof-speech-based long-range verb reordering rules [30]. Both systems RWTH scss and RWTH hiero rest upon all available bilingual data and word alignment obtained with GIZA++. A language model was trained on the target side of all available bilingual data plus 12 of the Shuffled News corpus and 1 4 of the English Gigaword v3 corpus, resulting in a total of 1.7 billion running w"
2013.iwslt-evaluation.16,N04-1022,0,0.487773,"atistical Machine Translation. The characteristics of the system include: a maximum sentence length of 80, grow-diag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM [34] used at runtime, a lexically-driven 5-gram operation sequence model [35] with four additional supportive features (two gap-based penalties, one distance-based feature and one deletion penalty), msdbidirectional-fe lexicalized reordering, sparse lexical and domain features [36], a distortion limit of 6, 100-best translation options, minimum Bayes risk decoding [37], cube pruning [38] with a stack size of 1000 during tuning and 5000 during testing and the no-reordering-over-punctuation heuristic. UEDIN used the compact phrase table representation by [39]. For English→German, UEDIN used a sequence model over morphological tags. The UEDIN systems were tuned on the dev2010 set made available for the IWSLT 2013 workshop. Tuning was performed using the k-best batch MIRA algorithm [40] with a maximum number of iterations of 25. B LEU was used as the metric to evaluate results. While UEDIN’s main submission also includes sequence models and operation sequence m"
2013.iwslt-evaluation.16,W12-2702,0,0.051709,"cribed in [23]. The hierarchical system was extended with a second translation model. The additional translation model was trained on the WIT3 portion of the training data only. For the English→French phrase-based setup, RWTH utilized all available parallel data and trained a word alignment with GIZA++ [24]. The same language model as in the hierarchical setup was used. RWTH applied the following supplementary features for the phrase-based system: a lexicalized reordering model [25], a discriminative word lexicon [26], a 7-gram word class language model [27], a continuous space language model [28], and a second translation model from the WIT3 portion of the training data only. For German→English, RWTH decompounded the German source in a preprocessing step [29] and applied partof-speech-based long-range verb reordering rules [30]. Both systems RWTH scss and RWTH hiero rest upon all available bilingual data and word alignment obtained with GIZA++. A language model was trained on the target side of all available bilingual data plus 12 of the Shuffled News corpus and 1 4 of the English Gigaword v3 corpus, resulting in a total of 1.7 billion running words. In both German→English systems, RW"
2013.iwslt-evaluation.16,P07-1019,0,0.222647,"ranslation. The characteristics of the system include: a maximum sentence length of 80, grow-diag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM [34] used at runtime, a lexically-driven 5-gram operation sequence model [35] with four additional supportive features (two gap-based penalties, one distance-based feature and one deletion penalty), msdbidirectional-fe lexicalized reordering, sparse lexical and domain features [36], a distortion limit of 6, 100-best translation options, minimum Bayes risk decoding [37], cube pruning [38] with a stack size of 1000 during tuning and 5000 during testing and the no-reordering-over-punctuation heuristic. UEDIN used the compact phrase table representation by [39]. For English→German, UEDIN used a sequence model over morphological tags. The UEDIN systems were tuned on the dev2010 set made available for the IWSLT 2013 workshop. Tuning was performed using the k-best batch MIRA algorithm [40] with a maximum number of iterations of 25. B LEU was used as the metric to evaluate results. While UEDIN’s main submission also includes sequence models and operation sequence models over Brown wo"
2013.iwslt-evaluation.16,E03-1076,1,0.900834,"data only. For the English→French phrase-based setup, RWTH utilized all available parallel data and trained a word alignment with GIZA++ [24]. The same language model as in the hierarchical setup was used. RWTH applied the following supplementary features for the phrase-based system: a lexicalized reordering model [25], a discriminative word lexicon [26], a 7-gram word class language model [27], a continuous space language model [28], and a second translation model from the WIT3 portion of the training data only. For German→English, RWTH decompounded the German source in a preprocessing step [29] and applied partof-speech-based long-range verb reordering rules [30]. Both systems RWTH scss and RWTH hiero rest upon all available bilingual data and word alignment obtained with GIZA++. A language model was trained on the target side of all available bilingual data plus 12 of the Shuffled News corpus and 1 4 of the English Gigaword v3 corpus, resulting in a total of 1.7 billion running words. In both German→English systems, RWTH applied a more sophisticated discriminative phrase training method. Similar to [31], a gradient-based method is used to optimize a maximum expected B LEU objective"
2013.iwslt-evaluation.16,N12-1047,0,0.148125,"penalty), msdbidirectional-fe lexicalized reordering, sparse lexical and domain features [36], a distortion limit of 6, 100-best translation options, minimum Bayes risk decoding [37], cube pruning [38] with a stack size of 1000 during tuning and 5000 during testing and the no-reordering-over-punctuation heuristic. UEDIN used the compact phrase table representation by [39]. For English→German, UEDIN used a sequence model over morphological tags. The UEDIN systems were tuned on the dev2010 set made available for the IWSLT 2013 workshop. Tuning was performed using the k-best batch MIRA algorithm [40] with a maximum number of iterations of 25. B LEU was used as the metric to evaluate results. While UEDIN’s main submission also includes sequence models and operation sequence models over Brown word clusters, these setups were not finished in time for the contribution to the EU-BRIDGE system combination. language models trained on WIT3 , Europarl, News Commentary, 109 , and Common Crawl by minimizing the perplexity on the development data. For the class-based language model, KIT utilized in-domain WIT3 data with 4grams and 50 clusters. In addition, a 9-gram POS-based language model derived fr"
2013.iwslt-evaluation.16,2011.iwslt-evaluation.9,1,0.925869,"ge model derived from LIA POS tags [55] on all monolingual data was applied. KIT optimized the log-linear combination of all these models on the provided development data using Minimum Error Rate Training [20]. 4. Karlsruhe Institute of Technology The KIT translations have been generated by an in-house phrase-based translations system [41]. The models were trained on the Europarl, News Commentary, WIT3 , Common Crawl corpora for both directions and WMT 109 for English→French and the additional monolingual training data. The big noisy 109 and Crawl corpora were filtered using an SVM classifier [42]. In addition to the standard preprocessing, KIT used compound splitting [29] for the German text. In both translation directions, KIT performed reordering using two models. KIT encoded different reorderings of the source sentences in a word lattice. For the English→French system, only short-range rules [43] were used to generate these lattices. For German→English, long-range rules [44] and tree-based reordering rules [45] were used as well. The part-of-speech (POS) tags needed for these rules were generated by the TreeTagger [46] and the parse trees by the Stanford Parser [47]. In addition, K"
2013.iwslt-evaluation.16,2007.tmi-papers.21,0,0.422618,"e-based translations system [41]. The models were trained on the Europarl, News Commentary, WIT3 , Common Crawl corpora for both directions and WMT 109 for English→French and the additional monolingual training data. The big noisy 109 and Crawl corpora were filtered using an SVM classifier [42]. In addition to the standard preprocessing, KIT used compound splitting [29] for the German text. In both translation directions, KIT performed reordering using two models. KIT encoded different reorderings of the source sentences in a word lattice. For the English→French system, only short-range rules [43] were used to generate these lattices. For German→English, long-range rules [44] and tree-based reordering rules [45] were used as well. The part-of-speech (POS) tags needed for these rules were generated by the TreeTagger [46] and the parse trees by the Stanford Parser [47]. In addition, KIT scored the different reorderings of both language pairs using a lexicalized reordering model [48]. The phrase tables of the systems were trained using GIZA++ alignment for the English→French task and using a discriminative alignment [49] for the German→English task. KIT adapted the phrase table to the TED"
2013.iwslt-evaluation.16,W09-0435,1,0.918776,"Commentary, WIT3 , Common Crawl corpora for both directions and WMT 109 for English→French and the additional monolingual training data. The big noisy 109 and Crawl corpora were filtered using an SVM classifier [42]. In addition to the standard preprocessing, KIT used compound splitting [29] for the German text. In both translation directions, KIT performed reordering using two models. KIT encoded different reorderings of the source sentences in a word lattice. For the English→French system, only short-range rules [43] were used to generate these lattices. For German→English, long-range rules [44] and tree-based reordering rules [45] were used as well. The part-of-speech (POS) tags needed for these rules were generated by the TreeTagger [46] and the parse trees by the Stanford Parser [47]. In addition, KIT scored the different reorderings of both language pairs using a lexicalized reordering model [48]. The phrase tables of the systems were trained using GIZA++ alignment for the English→French task and using a discriminative alignment [49] for the German→English task. KIT adapted the phrase table to the TED domain using the back off approach and by also adapting the candidate selection"
2013.iwslt-evaluation.16,W13-0805,1,0.889592,"ra for both directions and WMT 109 for English→French and the additional monolingual training data. The big noisy 109 and Crawl corpora were filtered using an SVM classifier [42]. In addition to the standard preprocessing, KIT used compound splitting [29] for the German text. In both translation directions, KIT performed reordering using two models. KIT encoded different reorderings of the source sentences in a word lattice. For the English→French system, only short-range rules [43] were used to generate these lattices. For German→English, long-range rules [44] and tree-based reordering rules [45] were used as well. The part-of-speech (POS) tags needed for these rules were generated by the TreeTagger [46] and the parse trees by the Stanford Parser [47]. In addition, KIT scored the different reorderings of both language pairs using a lexicalized reordering model [48]. The phrase tables of the systems were trained using GIZA++ alignment for the English→French task and using a discriminative alignment [49] for the German→English task. KIT adapted the phrase table to the TED domain using the back off approach and by also adapting the candidate selection [50]. In addition to the phrase tabl"
2013.iwslt-evaluation.16,W08-1006,0,0.169177,"SVM classifier [42]. In addition to the standard preprocessing, KIT used compound splitting [29] for the German text. In both translation directions, KIT performed reordering using two models. KIT encoded different reorderings of the source sentences in a word lattice. For the English→French system, only short-range rules [43] were used to generate these lattices. For German→English, long-range rules [44] and tree-based reordering rules [45] were used as well. The part-of-speech (POS) tags needed for these rules were generated by the TreeTagger [46] and the parse trees by the Stanford Parser [47]. In addition, KIT scored the different reorderings of both language pairs using a lexicalized reordering model [48]. The phrase tables of the systems were trained using GIZA++ alignment for the English→French task and using a discriminative alignment [49] for the German→English task. KIT adapted the phrase table to the TED domain using the back off approach and by also adapting the candidate selection [50]. In addition to the phrase table probabilities, KIT modeled the translation process by a bilingual language model [51] and a discriminative word lexicon [52]. For the German→English task, a"
2013.iwslt-evaluation.16,2005.iwslt-1.8,1,0.888473,"t. In both translation directions, KIT performed reordering using two models. KIT encoded different reorderings of the source sentences in a word lattice. For the English→French system, only short-range rules [43] were used to generate these lattices. For German→English, long-range rules [44] and tree-based reordering rules [45] were used as well. The part-of-speech (POS) tags needed for these rules were generated by the TreeTagger [46] and the parse trees by the Stanford Parser [47]. In addition, KIT scored the different reorderings of both language pairs using a lexicalized reordering model [48]. The phrase tables of the systems were trained using GIZA++ alignment for the English→French task and using a discriminative alignment [49] for the German→English task. KIT adapted the phrase table to the TED domain using the back off approach and by also adapting the candidate selection [50]. In addition to the phrase table probabilities, KIT modeled the translation process by a bilingual language model [51] and a discriminative word lexicon [52]. For the German→English task, a discriminative word lexicon with source and target context features was applied, while only the source context feat"
2013.iwslt-evaluation.16,W08-0303,1,0.796238,"word lattice. For the English→French system, only short-range rules [43] were used to generate these lattices. For German→English, long-range rules [44] and tree-based reordering rules [45] were used as well. The part-of-speech (POS) tags needed for these rules were generated by the TreeTagger [46] and the parse trees by the Stanford Parser [47]. In addition, KIT scored the different reorderings of both language pairs using a lexicalized reordering model [48]. The phrase tables of the systems were trained using GIZA++ alignment for the English→French task and using a discriminative alignment [49] for the German→English task. KIT adapted the phrase table to the TED domain using the back off approach and by also adapting the candidate selection [50]. In addition to the phrase table probabilities, KIT modeled the translation process by a bilingual language model [51] and a discriminative word lexicon [52]. For the German→English task, a discriminative word lexicon with source and target context features was applied, while only the source context features were employed for the English→French task. During decoding, KIT used several language models to adapt the system to the task and to bet"
2013.iwslt-evaluation.16,2012.amta-papers.19,1,0.890564,"and tree-based reordering rules [45] were used as well. The part-of-speech (POS) tags needed for these rules were generated by the TreeTagger [46] and the parse trees by the Stanford Parser [47]. In addition, KIT scored the different reorderings of both language pairs using a lexicalized reordering model [48]. The phrase tables of the systems were trained using GIZA++ alignment for the English→French task and using a discriminative alignment [49] for the German→English task. KIT adapted the phrase table to the TED domain using the back off approach and by also adapting the candidate selection [50]. In addition to the phrase table probabilities, KIT modeled the translation process by a bilingual language model [51] and a discriminative word lexicon [52]. For the German→English task, a discriminative word lexicon with source and target context features was applied, while only the source context features were employed for the English→French task. During decoding, KIT used several language models to adapt the system to the task and to better model the sentence structure by means of class-based n-grams. For the German→English task, KIT used one language model trained on all data, an in-doma"
2013.iwslt-evaluation.16,W11-2124,1,0.885306,"ated by the TreeTagger [46] and the parse trees by the Stanford Parser [47]. In addition, KIT scored the different reorderings of both language pairs using a lexicalized reordering model [48]. The phrase tables of the systems were trained using GIZA++ alignment for the English→French task and using a discriminative alignment [49] for the German→English task. KIT adapted the phrase table to the TED domain using the back off approach and by also adapting the candidate selection [50]. In addition to the phrase table probabilities, KIT modeled the translation process by a bilingual language model [51] and a discriminative word lexicon [52]. For the German→English task, a discriminative word lexicon with source and target context features was applied, while only the source context features were employed for the English→French task. During decoding, KIT used several language models to adapt the system to the task and to better model the sentence structure by means of class-based n-grams. For the German→English task, KIT used one language model trained on all data, an in-domain language model trained only on the WIT3 corpus and one language model trained on 5 M sentences selected using cross-"
2013.iwslt-evaluation.16,W13-2264,1,0.887808,"se trees by the Stanford Parser [47]. In addition, KIT scored the different reorderings of both language pairs using a lexicalized reordering model [48]. The phrase tables of the systems were trained using GIZA++ alignment for the English→French task and using a discriminative alignment [49] for the German→English task. KIT adapted the phrase table to the TED domain using the back off approach and by also adapting the candidate selection [50]. In addition to the phrase table probabilities, KIT modeled the translation process by a bilingual language model [51] and a discriminative word lexicon [52]. For the German→English task, a discriminative word lexicon with source and target context features was applied, while only the source context features were employed for the English→French task. During decoding, KIT used several language models to adapt the system to the task and to better model the sentence structure by means of class-based n-grams. For the German→English task, KIT used one language model trained on all data, an in-domain language model trained only on the WIT3 corpus and one language model trained on 5 M sentences selected using cross-entropy difference [23]. Furthermore, K"
2013.iwslt-evaluation.16,2012.iwslt-papers.3,1,0.886049,"criminative word lexicon with source and target context features was applied, while only the source context features were employed for the English→French task. During decoding, KIT used several language models to adapt the system to the task and to better model the sentence structure by means of class-based n-grams. For the German→English task, KIT used one language model trained on all data, an in-domain language model trained only on the WIT3 corpus and one language model trained on 5 M sentences selected using cross-entropy difference [23]. Furthermore, KIT used an RBM-based language model [53] trained on the WIT3 corpus. Finally, KIT also used a classbased language model, trained on the WIT3 corpus using the MKCLS [54] algorithm to cluster the words. For the English→French translation task, KIT linearly combined the 5. Fondazione Bruno Kessler The FBK component of the system combination corresponds to the “contrastive 1” system of the official FBK submission. The FBK system was built upon a standard phrasebased system using the Moses toolkit [32], and exploited the huge amount of parallel English→French and monolingual French training data, provided by the organizers. It featured a"
2013.iwslt-evaluation.16,E99-1010,0,0.0594124,"ed for the English→French task. During decoding, KIT used several language models to adapt the system to the task and to better model the sentence structure by means of class-based n-grams. For the German→English task, KIT used one language model trained on all data, an in-domain language model trained only on the WIT3 corpus and one language model trained on 5 M sentences selected using cross-entropy difference [23]. Furthermore, KIT used an RBM-based language model [53] trained on the WIT3 corpus. Finally, KIT also used a classbased language model, trained on the WIT3 corpus using the MKCLS [54] algorithm to cluster the words. For the English→French translation task, KIT linearly combined the 5. Fondazione Bruno Kessler The FBK component of the system combination corresponds to the “contrastive 1” system of the official FBK submission. The FBK system was built upon a standard phrasebased system using the Moses toolkit [32], and exploited the huge amount of parallel English→French and monolingual French training data, provided by the organizers. It featured a statistical log-linear model including a filled-up phrase translation model [56] and lexicalized reordering models (RMs), two F"
2013.iwslt-evaluation.16,2011.iwslt-evaluation.18,1,0.928081,"el, trained on the WIT3 corpus using the MKCLS [54] algorithm to cluster the words. For the English→French translation task, KIT linearly combined the 5. Fondazione Bruno Kessler The FBK component of the system combination corresponds to the “contrastive 1” system of the official FBK submission. The FBK system was built upon a standard phrasebased system using the Moses toolkit [32], and exploited the huge amount of parallel English→French and monolingual French training data, provided by the organizers. It featured a statistical log-linear model including a filled-up phrase translation model [56] and lexicalized reordering models (RMs), two French language models (LMs), as well as distortion, word, and phrase penalties. In order to focus it on TED specific domain and genre, and to reduce the size of the system, data selection by means of IRSTLM toolkit [57] was performed on the whole parallel English→French corpus, using the WIT3 training data as in-domain data. Different amount of data are selected from each available corpora but the WIT3 data, for a total of 66 M English running words. Two TMs and two RMs were trained on WIT3 and selected data, separately, and combined using the fil"
2013.iwslt-evaluation.16,W05-0909,0,0.0593782,"es which are outputs of different translation engines. The consensus translations can be better in terms of translation quality than any of the individual hypotheses. To combine the engines of the project partners for the EU-BRIDGE joint setups, we applied a system combination implementation that has been developed at RWTH Aachen University. The basic concept of RWTH’s approach to machine translation system combination has been described by Matusov et al. [60]. This approach includes an enhanced alignment and reordering framework. Alignments between the system outputs are learned using METEOR [61]. A confusion network is then built using one of the hypotheses as “primary” hypothesis. We do not make a hard decision on which of the hypotheses to use for that, but instead combine all possible confusion networks into a single lattice. Majority voting on the generated lattice is performed using the prior probabilities for each system as well as other statistical models, e.g. a special n-gram language model which is learned on the input hypotheses. Scaling factors of the models are optimized using the Minimum Error Rate Training algorithm. The translation with the best total score within the"
2013.iwslt-evaluation.16,W12-3140,1,\N,Missing
2013.iwslt-evaluation.16,J03-1002,1,\N,Missing
2013.iwslt-evaluation.16,C12-3061,1,\N,Missing
2013.iwslt-evaluation.16,federico-etal-2012-iwslt,1,\N,Missing
2013.iwslt-evaluation.16,2011.iwslt-evaluation.1,1,\N,Missing
2013.iwslt-evaluation.16,W13-2223,1,\N,Missing
2013.iwslt-evaluation.16,N13-1073,0,\N,Missing
2013.iwslt-papers.1,forster-etal-2012-rwth,1,0.502687,"ey could not be distinguished by the hand features used at the time. In addition to the annotation of the ID-glosses, the RWTH-Phoenix-Weather corpus has been marked with time boundaries on the sentence as well as the gloss level. The spoken German weather forecast has been transcribed semi-automatically using a state-of-the-art automatic speech recognition system. To train active appearance models on this corpus, facial landmarks have been manually labeled on a small set of images. In the following, we will briefly describe the corpus setup and statistics. For a more thorough description see [8]. Note that in this setup, we use only the portions of RWTHPhoenix-Weather for which time boundaries for individual glosses are annotated. These are necessary to extract the features for the viseme recognizer. DGS # signers # editions duration[h] # frames # sentences # running glosses vocabulary size # singletons German 7 190 3.25 293,077 2,552 14,771 30,860 911 1,452 120 337 Table 1: Statistics of the RWTH-Phoenix-Weather corpus for DGS and announcements in spoken German Figure 3: Visualization of facial annotations The corpus statistics for the RWTH-Phoenix-Weather corpus with time boundarie"
2013.iwslt-papers.1,W10-1738,1,0.773609,"ecognizer measured on 640 manual annotations. tered by comparing them to the original GIZA++ alignment and estimating the relative error for a given gloss and viseme sequence. Viseme sequences that cause a high mismatch to the GIZA++ alignment are less likely to support the following translation step. We tested different error thresholds on the development set and obtained best results for a threshold of 30. Translation variants with a relative error higher were removed, that is, no gloss variant was generated. 6. Experiments For our experiments, We use the open-source translation system JANE [17]. The training corpus is word-aligned using GIZA++, and phrase pairs consistent with this alignment are extracted. Previous experiments on this corpus ([9]) have shown that phrase-based systems outperform hierarchical systems, and consequently we choose a phrase-based system for machine translation. Since the corpus is very small, regular MERT training on a held-out development set leads to unstable optimization parameters. We therefore apply a technique similar to cross-validation where we train five different systems, each with a different portion of the training data used as the development"
2013.mtsummit-papers.19,P06-1009,0,0.0179529,"very large, and an alignment is seldom provided with the corpora. As CRFs include a summation over all possible target sequences (equation 1), the computational complexity of CRFs can be expressed by a polynomial of the target vocabulary size |Y |with a degree equal to the size of the feature describing the largest tuple in the target sequence (n-gram in language modeling (LM)). Authors have published approaches to move computation time to the lower degree parts of the polynomial, e.g. (Lavergne et al., 2010). However, this only changes constants in the complexity, not the overall complexity. Blunsom and Cohn (2006) and Niehues and Vogel (2008) avoid this problem by improving the alignment A used for the phrase extraction of a phrase based translation (PBT) system. In this case the source and target sequences are given, and the effective target vocabulary are either active or non-active alignments points p(A|y1I , xJ1 ), which is faster to compute than a sequence from Y, but reference alignments are needed, which are usually not provided with a machine translation corpus. Another approach is to manually constrain the summation to a reduced set of target sequences. Blunsom et al. (2008) propose to extend"
2013.mtsummit-papers.19,P08-1024,0,0.0237398,"rall complexity. Blunsom and Cohn (2006) and Niehues and Vogel (2008) avoid this problem by improving the alignment A used for the phrase extraction of a phrase based translation (PBT) system. In this case the source and target sequences are given, and the effective target vocabulary are either active or non-active alignments points p(A|y1I , xJ1 ), which is faster to compute than a sequence from Y, but reference alignments are needed, which are usually not provided with a machine translation corpus. Another approach is to manually constrain the summation to a reduced set of target sequences. Blunsom et al. (2008) propose to extend a hierarchical machine translation system and constrain the summation to the derivations given by this system, while (Lavergne et al., 2011) use a PBT system and use the phrase table to Sima’an, K., Forcada, M.L., Grasmick, D., Depraetere, H., Way, A. (eds.) Proceedings of the XIV Machine Translation Summit (Nice, September 2–6, 2013), p. 151–158. c 2013 The authors. This article is licensed under a Creative Commons 3.0 licence, no derivative works, attribution, CC-BY-ND. constrain the summation. Unfortunately, both approaches could only improve constrained systems. In (He a"
2013.mtsummit-papers.19,P12-1031,0,0.013349,"008) propose to extend a hierarchical machine translation system and constrain the summation to the derivations given by this system, while (Lavergne et al., 2011) use a PBT system and use the phrase table to Sima’an, K., Forcada, M.L., Grasmick, D., Depraetere, H., Way, A. (eds.) Proceedings of the XIV Machine Translation Summit (Nice, September 2–6, 2013), p. 151–158. c 2013 The authors. This article is licensed under a Creative Commons 3.0 licence, no derivative works, attribution, CC-BY-ND. constrain the summation. Unfortunately, both approaches could only improve constrained systems. In (He and Deng, 2012) the authors propose to constrain the summation to 100-best lists produced by a generative machine translation system for the training corpus. Up to our knowledge He and Deng (2012) reports the first improvements over a strong baseline with a system similar to CRFs. Over the last years at the same time a different approach to speed up ME model estimation became popular for neural network (NN) language modeling (LM). In (Goodman, 2001) the usage of an intermediate variable c is proposed, called classes. They model the translation problem as a product of first translating the source sequence int"
2013.mtsummit-papers.19,H05-1064,0,0.0272766,", yi , xJ1 ) = PL J l=1 λl hl (yi−1 , yi , x1 ): p(y1I |xJ1 ) PI e =P y˜1I H(yi−1 ,yi ,xJ 1) PI i yi−1 ,xJ i=1 H(˜ 1) i=1 e (1) The feature weights λL 1 are estimated by maximization of the conditional log-likelihood L, which is commonly extended by prior distributions n − cnn |λL 1 |n , e.g. L1 c and L2 c regularpn (λL 1 2 1) ∝ e ization: L= K X k=1 log p({y I1 }k |{xJ1 }k ) − 2 X n=1 n cn ||λL 1 ||n (2) with k = 1, . . . , K summing over the training corpus and {y I1 }k the k-th reference translation. To support a latent variable, e.g. an alignment A, various authors (Quattoni et al., 2007; Koo and Collins, 2005; Yu and Lam, 2008) suggested a summation in the numerator and the denominator of equation 1: p(y1I |xJ1 ) P =P P ˜ A Ae PI H(A,yi−1 ,yi ,xJ 1) PI J ˜ e i=1 H(A,˜yi−1 ,˜yi ,x1 ) i=1 y˜1I ,I(A) (3) Three types of features were used to support the conditional probability, first source-n-gram features depending only on one target symbol yi and a combination of source symA(j)+γ bols xA(j)+γ21 relative to the currently aligned source word xA(j) (with γ1 ≤ γ2 ), with γ1 , γ2 = −5, . . . , 5, γ1 + γ2 + 1 ≤ 3, second target-n-gram features describing the relation of a consecutive set of target symbols"
2013.mtsummit-papers.19,P10-1052,0,0.0687668,"Missing"
2013.mtsummit-papers.19,W11-2168,0,0.0147825,"se based translation (PBT) system. In this case the source and target sequences are given, and the effective target vocabulary are either active or non-active alignments points p(A|y1I , xJ1 ), which is faster to compute than a sequence from Y, but reference alignments are needed, which are usually not provided with a machine translation corpus. Another approach is to manually constrain the summation to a reduced set of target sequences. Blunsom et al. (2008) propose to extend a hierarchical machine translation system and constrain the summation to the derivations given by this system, while (Lavergne et al., 2011) use a PBT system and use the phrase table to Sima’an, K., Forcada, M.L., Grasmick, D., Depraetere, H., Way, A. (eds.) Proceedings of the XIV Machine Translation Summit (Nice, September 2–6, 2013), p. 151–158. c 2013 The authors. This article is licensed under a Creative Commons 3.0 licence, no derivative works, attribution, CC-BY-ND. constrain the summation. Unfortunately, both approaches could only improve constrained systems. In (He and Deng, 2012) the authors propose to constrain the summation to 100-best lists produced by a generative machine translation system for the training corpus. Up"
2013.mtsummit-papers.19,P10-2041,0,0.0111708,"e package. However, it was trained solely on the TED portion of the training data with the generative training scheme presented in (Wuebker et al., 2010) applying forced alignment. Models include translation probabilities and lexical smoothing in both directions, word and phrase penalty, distancebased reordering model, an n-gram target language model and three binary count features, and a 4gram language model trained on the TED, Europarl, News-Commentary and Shuffled News corpora from the workshop. From the Shuffled News data 1/8 of the sentences were selected with the technique presented in (Moore and Lewis, 2010). 5.1 SSSD search within CRF framework Table 3 contrasts the results of the two PBT systems (line 1 and line 2) with an independent CRF translation tandem p(cI1 |xJ1 ) / p(y1I |cI1 , xJ1 ). Line 3 to 6 replaced the bigram features in model p(cI1 |xJ1 ) with a LM estimated on all available monolingual training data in IWSLT projected to classes, while line 7 and line 8 used bigram features instead of a LM, and line 9 and line 10 used both. Results were very less affected by the choice of features in p(y1I |cI1 , xJ1 ). A LM or bigram features in p(y1I |cI1 , xJ1 ) did not result in a change in"
2013.mtsummit-papers.19,2012.iwslt-evaluation.16,0,0.0207637,"Missing"
2013.mtsummit-papers.19,W95-0107,0,0.0580499,"features were used to support the conditional probability, first source-n-gram features depending only on one target symbol yi and a combination of source symA(j)+γ bols xA(j)+γ21 relative to the currently aligned source word xA(j) (with γ1 ≤ γ2 ), with γ1 , γ2 = −5, . . . , 5, γ1 + γ2 + 1 ≤ 3, second target-n-gram features describing the relation of a consecutive set of target symbols yi , yi−1 , and third word stem features, including prefixes and suffixes up to length 4 and capitalization. Lehnen et al. (2012) described the use of begin (b), continue (c), and skip (s) labels (inspired by (Ramshaw and Marcus, 1995)) for each target vocabulary word to support monotonous HCRFs (equation 3). At each source symbol the last target symbol is continued, a new one begins, or two target symbols begin. Each target symbol is labeled to make this mapping bijective. At each source symbol all aligned target words are known and at each target symbol all aligned source symbols are known. Features are applied to all combinations of source and target symbols. This modeling restricts the summation over I to I &lt; 2J. The applied CRF software was realized with weighted finite state transducers (Mohri, 2009). A chain represen"
2013.mtsummit-papers.19,P04-1007,0,0.0363719,"g will be presented. To design the tandem of CRF translation model and a phrase based baseline we will evaluate two different ways of n-best list integrations. 1 Introduction Over the last decade a variant of Maximum Entropy (ME) models for sequences, Conditional Random Fields (CRFs) (Lafferty et al., 2001) and Hidden CRFs (HCRFs) (Quattoni et al., 2007) have shown high accuracies in various fields including part-of-speech tagging (Lafferty et al., 2001), semantic tagging (Hahn et al., 2010), chunking (Sha and Pereira, 2003), speech recognition (Zweig and Nguyen, 2009), and language modeling (Roark et al., 2004). But designing (H)CRFs for Statistical Machine Translation (SMT) seems to be a serious challenge. In SMT a sequence xJ1 = x1 , . . . , xJ composed of symbols from a large vocabulary X (of size 10k-100k) is mapped to a sequence y1I = y1 , . . . , yI composed of symbols which are from a large vocabulary Y (10k-100k). The critical points are that the vocabularies are both very large, and an alignment is seldom provided with the corpora. As CRFs include a summation over all possible target sequences (equation 1), the computational complexity of CRFs can be expressed by a polynomial of the target"
2013.mtsummit-papers.19,N03-1028,0,0.0166282,"strong baseline. Results with an independent CRF translation system and n-best list rescoring will be presented. To design the tandem of CRF translation model and a phrase based baseline we will evaluate two different ways of n-best list integrations. 1 Introduction Over the last decade a variant of Maximum Entropy (ME) models for sequences, Conditional Random Fields (CRFs) (Lafferty et al., 2001) and Hidden CRFs (HCRFs) (Quattoni et al., 2007) have shown high accuracies in various fields including part-of-speech tagging (Lafferty et al., 2001), semantic tagging (Hahn et al., 2010), chunking (Sha and Pereira, 2003), speech recognition (Zweig and Nguyen, 2009), and language modeling (Roark et al., 2004). But designing (H)CRFs for Statistical Machine Translation (SMT) seems to be a serious challenge. In SMT a sequence xJ1 = x1 , . . . , xJ composed of symbols from a large vocabulary X (of size 10k-100k) is mapped to a sequence y1I = y1 , . . . , yI composed of symbols which are from a large vocabulary Y (10k-100k). The critical points are that the vocabularies are both very large, and an alignment is seldom provided with the corpora. As CRFs include a summation over all possible target sequences (equation"
2013.mtsummit-papers.19,P10-1049,1,0.840941,"em with forced alignments only trained on the TED training data. The first phrase-based system used the SCSS software variant of the Jane software package (Wuebker et al., 2012) and made use of all available in-domain and out-domain data, part-of-speech-based adjective reordering as preprocessing step, a LM with all available monolingual training data, and a 7-gram word class language model. The second system also uses the SCSS software variant of the Jane software package. However, it was trained solely on the TED portion of the training data with the generative training scheme presented in (Wuebker et al., 2010) applying forced alignment. Models include translation probabilities and lexical smoothing in both directions, word and phrase penalty, distancebased reordering model, an n-gram target language model and three binary count features, and a 4gram language model trained on the TED, Europarl, News-Commentary and Shuffled News corpora from the workshop. From the Shuffled News data 1/8 of the sentences were selected with the technique presented in (Moore and Lewis, 2010). 5.1 SSSD search within CRF framework Table 3 contrasts the results of the two PBT systems (line 1 and line 2) with an independent"
2013.mtsummit-papers.19,C12-3061,1,0.833458,"no 21.6 250 yes 21.5 60.5 62.3 24.6 25.4 55.1 55.4 9 10 bigram, with LM 250 no 21.8 250 yes 21.7 61.3 61.5 25.2 25.1 55.6 55.3 Table 3: Results with SSSD search within the CRF framework, and without using a PBT system. Language model scales and word penalty were selected to optimize BLEU on the dev set. uation. As baseline system we were provided with the best single PBT system from (Peitz et al., 2012) for English to French and a PBT system with forced alignments only trained on the TED training data. The first phrase-based system used the SCSS software variant of the Jane software package (Wuebker et al., 2012) and made use of all available in-domain and out-domain data, part-of-speech-based adjective reordering as preprocessing step, a LM with all available monolingual training data, and a 7-gram word class language model. The second system also uses the SCSS software variant of the Jane software package. However, it was trained solely on the TED portion of the training data with the generative training scheme presented in (Wuebker et al., 2010) applying forced alignment. Models include translation probabilities and lexical smoothing in both directions, word and phrase penalty, distancebased reorde"
2013.mtsummit-papers.19,W08-0303,0,0.0117087,"is seldom provided with the corpora. As CRFs include a summation over all possible target sequences (equation 1), the computational complexity of CRFs can be expressed by a polynomial of the target vocabulary size |Y |with a degree equal to the size of the feature describing the largest tuple in the target sequence (n-gram in language modeling (LM)). Authors have published approaches to move computation time to the lower degree parts of the polynomial, e.g. (Lavergne et al., 2010). However, this only changes constants in the complexity, not the overall complexity. Blunsom and Cohn (2006) and Niehues and Vogel (2008) avoid this problem by improving the alignment A used for the phrase extraction of a phrase based translation (PBT) system. In this case the source and target sequences are given, and the effective target vocabulary are either active or non-active alignments points p(A|y1I , xJ1 ), which is faster to compute than a sequence from Y, but reference alignments are needed, which are usually not provided with a machine translation corpus. Another approach is to manually constrain the summation to a reduced set of target sequences. Blunsom et al. (2008) propose to extend a hierarchical machine transl"
2013.mtsummit-papers.19,J04-4002,1,0.36621,"1 reord. PBT 2 + Nsum (including target bigram) 250 no 26.4 57.7 29.4 51.9 250 yes 27.1 56.9 30.1 51.2 Table 4: Results of N-best rescoring adding the (H)CRF scores on top of the scores in the n-best lists of the second PBT system trained on TED data. Line 1 indicates the result of the baseline system. Bold face numbers mark the best result with respect to the dev set. scores Nsum , and Nmax . Using fully normalized probabilities did not change the translation quality. On the final augmented n-best lists the weights for n-best list scores were retrained via Minimum Error Rate Training (MERT) (Och and Ney, 2004), initialized with the best weights of the n-best list generating SCSS system. Experiments have shown that the second model p(y1I |cI1 , xJ1 ) did not change the translation quality, and got a zero weight by the MERT training. The results with only the first model p(cI1 |xJ1 ) are shown in table 4 and table 5. To have a fair comparison the parameters of the baseline system (line 1) were reoptimized, too. We have marked the systems giving the best results with respect to the development set. The best systems on the development set produce the best results on the test set, but in some cases the"
2014.amta-researchers.15,D11-1033,0,0.235668,"om itself. Now, Al-Onaizan & Simard (Eds.) Proceedings of AMTA 2014, vol. 1: MT Researchers Vancouver, BC © The Authors 195 sentences of the generic corpus are sorted regarding the computation of the difference between domain-specific score and generic score. At last, the best amount of the sorted data has to be determined. This best point is found by minimizing the perplexity of a development set on growing percentages of the sorted corpus. Moore and Lewis (2010) reported that the perplexity decreases when less, but more appropriate data is used. Recent works expand this approach to bitexts (Axelrod et al., 2011; Mansour et al., 2011). Approaches like corpus weighting (Shah et al., 2010) or sentence weighting (Matsoukas et al., 2009; Mansour and Ney, 2012) are not suitable to our translation task because these approaches can produce huge models by considering the whole data. 3 Cross-entropy based Data Selection versus Infrequent n-gram Recovery In this section we detail the different approaches experimented with for data selection. On one hand we process the data selection for both LM and translation model (TM) using cross-entropy. On the other hand, the infrequent n-gram recovery (Gascó et al., 2012"
2014.amta-researchers.15,2011.iwslt-evaluation.18,0,0.0595347,"og-linear or a linear approach (Foster and Kuhn, 2007; Civera and Juan, 2007). The standard log-linear model may be used to combine some domainspecific models (Koehn and Schroeder, 2007). In the same way target language models may be combined using a log-linear or a linear combination (Schwenk and Koehn, 2008). Sennrich et al. (2013) proposed to combine different specific parts of the phrase-table during translation leading to a multi-domain adaptation approach. Niehues and Waibel (2012) compared several incremental approaches, namely the backoff, the factored, the log-linear and the fill-up (Bisazza et al., 2011) techniques. These approaches aim at adapting an MT system towards a target domain using small amounts of parallel in-domain data. The main outcome of this paper is that all the approaches successfully improve the generic model and none of them is better than the others. The performances of the approaches mainly depend on their match to the specific data. 2.3 Data selection The main idea of data selection is to try to take advantage of a generic corpus by picking out a subset of training data that is most relevant to the domain of interest. Two main approaches are used to perform domain adapta"
2014.amta-researchers.15,J93-2003,0,0.0861508,"both source and target side: ¯ LM (s, t) = HLM (s) − HLM H (s) + HLMItrg (t) − HLMOˆ Isrc ˆ src O Al-Onaizan & Simard (Eds.) Proceedings of AMTA 2014, vol. 1: MT Researchers Vancouver, BC trg (t) (3) © The Authors 196 Note that since the scores in Equation 3 are computed for the source and target separately, any target sentence t0 whose cross-entropy score is similar to that of t can exchange t and have a similar score assigned to it by this method. As a result, poorly aligned data can not be detected by LM cross-entropy scoring only. 3.2 Translation Model Cross-entropy The IBM-Model 1 (M1) (Brown et al., 1993) is a model used in state-of-the-art SMT systems for a variety of applications. In this work, we apply M1 scores to achieve adaptation to some domain specific data. Mansour et al. (2011) extend the formulation by Axelrod et al. (2011), which is described in Equation (3), by adding the M1 cross-entropy score to the LM cross entropy score. The M1 cross-entropy for a sentence pair (s, t) = s1 , ..., s|s |, t1 , ..., t|t |is defined as: where ¯ M 1 (s, t) = HM 1 (t|s) − HM 1 (t|s) + HM 1 (s|t) − HM 1 (s|t) H I I ˆ ˆ O O (4)   |s| |t| X X 1 1 log  pM 1 (ti |sj ) HM 1 (t|s) = − |t| |s| j=1 i="
2014.amta-researchers.15,W07-0722,1,0.799684,"e amounts of monolingual training data translated using a completely new model. Lambert et al. (2011) enhanced this approach by using the translations of monolingual data in the target language. 2.2 Model combination and update One way to adapt MT models is to combine translation models. Models can be combined using the mixture-model approach, a log-linear combination or through incremental learning approaches. To obtain a mixture of domain-specific models trained on several different domain-specific corpora, they can be combined using a log-linear or a linear approach (Foster and Kuhn, 2007; Civera and Juan, 2007). The standard log-linear model may be used to combine some domainspecific models (Koehn and Schroeder, 2007). In the same way target language models may be combined using a log-linear or a linear combination (Schwenk and Koehn, 2008). Sennrich et al. (2013) proposed to combine different specific parts of the phrase-table during translation leading to a multi-domain adaptation approach. Niehues and Waibel (2012) compared several incremental approaches, namely the backoff, the factored, the log-linear and the fill-up (Bisazza et al., 2011) techniques. These approaches aim at adapting an MT syst"
2014.amta-researchers.15,W07-0717,0,0.0282688,"it proposes to add large amounts of monolingual training data translated using a completely new model. Lambert et al. (2011) enhanced this approach by using the translations of monolingual data in the target language. 2.2 Model combination and update One way to adapt MT models is to combine translation models. Models can be combined using the mixture-model approach, a log-linear combination or through incremental learning approaches. To obtain a mixture of domain-specific models trained on several different domain-specific corpora, they can be combined using a log-linear or a linear approach (Foster and Kuhn, 2007; Civera and Juan, 2007). The standard log-linear model may be used to combine some domainspecific models (Koehn and Schroeder, 2007). In the same way target language models may be combined using a log-linear or a linear combination (Schwenk and Koehn, 2008). Sennrich et al. (2013) proposed to combine different specific parts of the phrase-table during translation leading to a multi-domain adaptation approach. Niehues and Waibel (2012) compared several incremental approaches, namely the backoff, the factored, the log-linear and the fill-up (Bisazza et al., 2011) techniques. These approaches ai"
2014.amta-researchers.15,D08-1089,0,0.0143253,"searches for the best translation eˆI1 as defined by the I K J models hm (e1 , s1 , f1 ). It can be written as (Och and Ney, 2004) ( ˆ eˆI1 = arg max I,eI1 M X ) J λm hm (eI1 , sK 1 , f1 ) , (9) m=1 where f1J = f1 . . . fJ is the source sentence, eI1 = e1 . . . eI the target sentence and sK 1 = s1 . . . sK their phrase segmentation and alignment. The feature functions hm include translation channel models in both directions, lexical smoothing models in both directions, an n-gram language model, phrase and word penalty, a jump-distance-based distortion model, a hierarchical orientation model (Galley and Manning, 2008) and an n-gram cluster language model (Wuebker et al., 2013). The log-linear feature weights λm are optimized on a development data set with minimum error rate training (MERT) (Och, 2003). As optimization criterion we use B LEU (Papineni et al., 2001). Al-Onaizan & Simard (Eds.) Proceedings of AMTA 2014, vol. 1: MT Researchers Vancouver, BC © The Authors 199 5 Experiments In this section we describe the different experiments we made in order to compare between the approaches. 5.1 The VideoLectures.NET Repository VideoLectures.NET1 is a free and open access repository of video lectures mostly f"
2014.amta-researchers.15,P02-1023,0,0.656356,"nd, such approaches use information retrieval techniques and similarity scores. On the other hand, language models are used associated to perplexity and cross-entropy. Intuitively, seeking the data closest to the test set is related to information retrieval techniques. Lü et al. (2007) present this approach using the standard measure T F.IDF (Term Frequency – Inverse Document Frequency) to measure the similarity between the test sentences and the training sentences. This approach is based on a bag-of-words scheme. The second approach, based on language models (LMs), was originally proposed by Gao and Zhang (2002). Here, the generic corpus is scored against an LM trained on a seed of domain-specific data, and the cross-entropy is computed for each sentence. Then, the same generic corpus is scored against an LM trained on a random sample taken from itself. Now, Al-Onaizan & Simard (Eds.) Proceedings of AMTA 2014, vol. 1: MT Researchers Vancouver, BC © The Authors 195 sentences of the generic corpus are sorted regarding the computation of the difference between domain-specific score and generic score. At last, the best amount of the sorted data has to be determined. This best point is found by minimizing"
2014.amta-researchers.15,E12-1016,0,0.540022,"elrod et al., 2011; Mansour et al., 2011). Approaches like corpus weighting (Shah et al., 2010) or sentence weighting (Matsoukas et al., 2009; Mansour and Ney, 2012) are not suitable to our translation task because these approaches can produce huge models by considering the whole data. 3 Cross-entropy based Data Selection versus Infrequent n-gram Recovery In this section we detail the different approaches experimented with for data selection. On one hand we process the data selection for both LM and translation model (TM) using cross-entropy. On the other hand, the infrequent n-gram recovery (Gascó et al., 2012), is explored. 3.1 Language Model Cross-entropy The LM cross-entropy difference can be used for both monolingual data selection for LM training as described by Moore and Lewis (2010), or bilingual selection for translation model training (Axelrod et al., 2011). Given an in-domain corpus I and an out-of-domain or general-domain corpus O, first we ˆ ⊆ O of approximately the same size as I, and train the LMs LMI generate a random subset O and LMOˆ using the corresponding training data. Afterwards, each sentence o ∈ O is scored according to: HLMI (o) − HLMOˆ (o) (1) where H is the length-normalise"
2014.amta-researchers.15,N03-1017,0,0.0353971,"cross-entropy achieves the most stable results. As another important criterion for measuring translation quality in our application, we identify the number of out-ofvocabulary words. Here, infrequent n-gram recovery shows superior performance. Finally, we combine the two selection techniques in order to benefit from both their strengths. 1 Introduction With the continuous growth of available bitexts and research advances of the underlying technology, statistical machine translation (SMT) has become popular for many real world tasks. The most common approach is still the phrase-based paradigm (Koehn et al., 2003), that provides an efficient framework with good translation quality for many language pairs. This work focuses on the application of SMT to the task of translating scientific video lectures. Online scientific video lectures are becoming increasingly popular, e.g. in the context of massive open online courses (MOOCs). Being able to provide high quality automatic translations for this kind of technical talks could, e.g., prove beneficial to education at universities, Al-Onaizan & Simard (Eds.) Proceedings of AMTA 2014, vol. 1: MT Researchers Vancouver, BC © The Authors 193 sharing technical kno"
2014.amta-researchers.15,W07-0733,0,0.0273928,"anced this approach by using the translations of monolingual data in the target language. 2.2 Model combination and update One way to adapt MT models is to combine translation models. Models can be combined using the mixture-model approach, a log-linear combination or through incremental learning approaches. To obtain a mixture of domain-specific models trained on several different domain-specific corpora, they can be combined using a log-linear or a linear approach (Foster and Kuhn, 2007; Civera and Juan, 2007). The standard log-linear model may be used to combine some domainspecific models (Koehn and Schroeder, 2007). In the same way target language models may be combined using a log-linear or a linear combination (Schwenk and Koehn, 2008). Sennrich et al. (2013) proposed to combine different specific parts of the phrase-table during translation leading to a multi-domain adaptation approach. Niehues and Waibel (2012) compared several incremental approaches, namely the backoff, the factored, the log-linear and the fill-up (Bisazza et al., 2011) techniques. These approaches aim at adapting an MT system towards a target domain using small amounts of parallel in-domain data. The main outcome of this paper is"
2014.amta-researchers.15,W11-2132,1,0.895614,"involves a confidence measure in order to select the Al-Onaizan & Simard (Eds.) Proceedings of AMTA 2014, vol. 1: MT Researchers Vancouver, BC © The Authors 194 most reliable data to train a small additional phrase table (PT). The generic and the new phrase tables are used jointly for translation, which can be seen as a mixture model with one specific PT built for each test set. The lightly-supervised training approach proposed by Schwenk (2008) does not adapt the model to the test data, but it proposes to add large amounts of monolingual training data translated using a completely new model. Lambert et al. (2011) enhanced this approach by using the translations of monolingual data in the target language. 2.2 Model combination and update One way to adapt MT models is to combine translation models. Models can be combined using the mixture-model approach, a log-linear combination or through incremental learning approaches. To obtain a mixture of domain-specific models trained on several different domain-specific corpora, they can be combined using a log-linear or a linear approach (Foster and Kuhn, 2007; Civera and Juan, 2007). The standard log-linear model may be used to combine some domainspecific mode"
2014.amta-researchers.15,E12-2003,0,0.0201164,"lly transcribed and translated into several languages. In particular, 23 of these 27 lectures (16 hours) were translated into French by professional translators. 5.2 Data Our experiments are performed on the task of translating manually transcribed English video lectures into French. In addition to around 5000 sentence pairs from VideoLectures.NET, we use the parallel TED talk data provided for the shared translation task of the International Workshop on Spoken Language Translation4 as in-domain data. The general domain data consists of several corpora. The COSMAT scientific thesis abstracts (Lambert et al., 2012) and the news-commentary-v8 corpus, provided by the ACL 2013 8th Workshop on Statistical Machine Translation5 (WMT), are directly added to the baseline without instance selection due to their small size. The large corpora on which data selection is performed, are the Europarl-v7 corpus (also provided by WMT), the JRC-Acquis corpus (Steinberger et al., 2006) and the Open Subtitles corpus6 (Tiedemann, 2012). Data statistics for the complete in-domain and out-of-domain data are given in Table 1. For the development and test sets we selected four video lectures each, that were manually transcribed"
2014.amta-researchers.15,D07-1036,0,0.650913,"Missing"
2014.amta-researchers.15,2012.iwslt-papers.7,1,0.80783,"ric corpus are sorted regarding the computation of the difference between domain-specific score and generic score. At last, the best amount of the sorted data has to be determined. This best point is found by minimizing the perplexity of a development set on growing percentages of the sorted corpus. Moore and Lewis (2010) reported that the perplexity decreases when less, but more appropriate data is used. Recent works expand this approach to bitexts (Axelrod et al., 2011; Mansour et al., 2011). Approaches like corpus weighting (Shah et al., 2010) or sentence weighting (Matsoukas et al., 2009; Mansour and Ney, 2012) are not suitable to our translation task because these approaches can produce huge models by considering the whole data. 3 Cross-entropy based Data Selection versus Infrequent n-gram Recovery In this section we detail the different approaches experimented with for data selection. On one hand we process the data selection for both LM and translation model (TM) using cross-entropy. On the other hand, the infrequent n-gram recovery (Gascó et al., 2012), is explored. 3.1 Language Model Cross-entropy The LM cross-entropy difference can be used for both monolingual data selection for LM training as"
2014.amta-researchers.15,2011.iwslt-papers.5,1,0.90042,"izan & Simard (Eds.) Proceedings of AMTA 2014, vol. 1: MT Researchers Vancouver, BC © The Authors 195 sentences of the generic corpus are sorted regarding the computation of the difference between domain-specific score and generic score. At last, the best amount of the sorted data has to be determined. This best point is found by minimizing the perplexity of a development set on growing percentages of the sorted corpus. Moore and Lewis (2010) reported that the perplexity decreases when less, but more appropriate data is used. Recent works expand this approach to bitexts (Axelrod et al., 2011; Mansour et al., 2011). Approaches like corpus weighting (Shah et al., 2010) or sentence weighting (Matsoukas et al., 2009; Mansour and Ney, 2012) are not suitable to our translation task because these approaches can produce huge models by considering the whole data. 3 Cross-entropy based Data Selection versus Infrequent n-gram Recovery In this section we detail the different approaches experimented with for data selection. On one hand we process the data selection for both LM and translation model (TM) using cross-entropy. On the other hand, the infrequent n-gram recovery (Gascó et al., 2012), is explored. 3.1 Lan"
2014.amta-researchers.15,D09-1074,0,0.0228901,"95 sentences of the generic corpus are sorted regarding the computation of the difference between domain-specific score and generic score. At last, the best amount of the sorted data has to be determined. This best point is found by minimizing the perplexity of a development set on growing percentages of the sorted corpus. Moore and Lewis (2010) reported that the perplexity decreases when less, but more appropriate data is used. Recent works expand this approach to bitexts (Axelrod et al., 2011; Mansour et al., 2011). Approaches like corpus weighting (Shah et al., 2010) or sentence weighting (Matsoukas et al., 2009; Mansour and Ney, 2012) are not suitable to our translation task because these approaches can produce huge models by considering the whole data. 3 Cross-entropy based Data Selection versus Infrequent n-gram Recovery In this section we detail the different approaches experimented with for data selection. On one hand we process the data selection for both LM and translation model (TM) using cross-entropy. On the other hand, the infrequent n-gram recovery (Gascó et al., 2012), is explored. 3.1 Language Model Cross-entropy The LM cross-entropy difference can be used for both monolingual data sele"
2014.amta-researchers.15,P10-2041,0,0.494601,"cific data, and the cross-entropy is computed for each sentence. Then, the same generic corpus is scored against an LM trained on a random sample taken from itself. Now, Al-Onaizan & Simard (Eds.) Proceedings of AMTA 2014, vol. 1: MT Researchers Vancouver, BC © The Authors 195 sentences of the generic corpus are sorted regarding the computation of the difference between domain-specific score and generic score. At last, the best amount of the sorted data has to be determined. This best point is found by minimizing the perplexity of a development set on growing percentages of the sorted corpus. Moore and Lewis (2010) reported that the perplexity decreases when less, but more appropriate data is used. Recent works expand this approach to bitexts (Axelrod et al., 2011; Mansour et al., 2011). Approaches like corpus weighting (Shah et al., 2010) or sentence weighting (Matsoukas et al., 2009; Mansour and Ney, 2012) are not suitable to our translation task because these approaches can produce huge models by considering the whole data. 3 Cross-entropy based Data Selection versus Infrequent n-gram Recovery In this section we detail the different approaches experimented with for data selection. On one hand we proc"
2014.amta-researchers.15,2012.amta-papers.19,0,0.0272372,"s. To obtain a mixture of domain-specific models trained on several different domain-specific corpora, they can be combined using a log-linear or a linear approach (Foster and Kuhn, 2007; Civera and Juan, 2007). The standard log-linear model may be used to combine some domainspecific models (Koehn and Schroeder, 2007). In the same way target language models may be combined using a log-linear or a linear combination (Schwenk and Koehn, 2008). Sennrich et al. (2013) proposed to combine different specific parts of the phrase-table during translation leading to a multi-domain adaptation approach. Niehues and Waibel (2012) compared several incremental approaches, namely the backoff, the factored, the log-linear and the fill-up (Bisazza et al., 2011) techniques. These approaches aim at adapting an MT system towards a target domain using small amounts of parallel in-domain data. The main outcome of this paper is that all the approaches successfully improve the generic model and none of them is better than the others. The performances of the approaches mainly depend on their match to the specific data. 2.3 Data selection The main idea of data selection is to try to take advantage of a generic corpus by picking out"
2014.amta-researchers.15,P03-1021,0,0.035916,"ere f1J = f1 . . . fJ is the source sentence, eI1 = e1 . . . eI the target sentence and sK 1 = s1 . . . sK their phrase segmentation and alignment. The feature functions hm include translation channel models in both directions, lexical smoothing models in both directions, an n-gram language model, phrase and word penalty, a jump-distance-based distortion model, a hierarchical orientation model (Galley and Manning, 2008) and an n-gram cluster language model (Wuebker et al., 2013). The log-linear feature weights λm are optimized on a development data set with minimum error rate training (MERT) (Och, 2003). As optimization criterion we use B LEU (Papineni et al., 2001). Al-Onaizan & Simard (Eds.) Proceedings of AMTA 2014, vol. 1: MT Researchers Vancouver, BC © The Authors 199 5 Experiments In this section we describe the different experiments we made in order to compare between the approaches. 5.1 The VideoLectures.NET Repository VideoLectures.NET1 is a free and open access repository of video lectures mostly filmed by people from the Jožef Stefan Institute (JSI, Slovenia) at major conferences, summer schools, workshops and science promotional events from many fields of science. VideoLectures.N"
2014.amta-researchers.15,J04-4002,1,0.68254,"Missing"
2014.amta-researchers.15,2001.mtsummit-papers.68,0,0.0282297,"e1 . . . eI the target sentence and sK 1 = s1 . . . sK their phrase segmentation and alignment. The feature functions hm include translation channel models in both directions, lexical smoothing models in both directions, an n-gram language model, phrase and word penalty, a jump-distance-based distortion model, a hierarchical orientation model (Galley and Manning, 2008) and an n-gram cluster language model (Wuebker et al., 2013). The log-linear feature weights λm are optimized on a development data set with minimum error rate training (MERT) (Och, 2003). As optimization criterion we use B LEU (Papineni et al., 2001). Al-Onaizan & Simard (Eds.) Proceedings of AMTA 2014, vol. 1: MT Researchers Vancouver, BC © The Authors 199 5 Experiments In this section we describe the different experiments we made in order to compare between the approaches. 5.1 The VideoLectures.NET Repository VideoLectures.NET1 is a free and open access repository of video lectures mostly filmed by people from the Jožef Stefan Institute (JSI, Slovenia) at major conferences, summer schools, workshops and science promotional events from many fields of science. VideoLectures.NET has so far published more than 15K lectures, all of them reco"
2014.amta-researchers.15,2008.iwslt-papers.6,0,0.0272986,"s was first proposed by Ueffing (2006) and refined by Ueffing et al. (2007). The main idea is to filter the translations with the translated test data. This process involves a confidence measure in order to select the Al-Onaizan & Simard (Eds.) Proceedings of AMTA 2014, vol. 1: MT Researchers Vancouver, BC © The Authors 194 most reliable data to train a small additional phrase table (PT). The generic and the new phrase tables are used jointly for translation, which can be seen as a mixture model with one specific PT built for each test set. The lightly-supervised training approach proposed by Schwenk (2008) does not adapt the model to the test data, but it proposes to add large amounts of monolingual training data translated using a completely new model. Lambert et al. (2011) enhanced this approach by using the translations of monolingual data in the target language. 2.2 Model combination and update One way to adapt MT models is to combine translation models. Models can be combined using the mixture-model approach, a log-linear combination or through incremental learning approaches. To obtain a mixture of domain-specific models trained on several different domain-specific corpora, they can be co"
2014.amta-researchers.15,I08-2089,0,0.0254036,"way to adapt MT models is to combine translation models. Models can be combined using the mixture-model approach, a log-linear combination or through incremental learning approaches. To obtain a mixture of domain-specific models trained on several different domain-specific corpora, they can be combined using a log-linear or a linear approach (Foster and Kuhn, 2007; Civera and Juan, 2007). The standard log-linear model may be used to combine some domainspecific models (Koehn and Schroeder, 2007). In the same way target language models may be combined using a log-linear or a linear combination (Schwenk and Koehn, 2008). Sennrich et al. (2013) proposed to combine different specific parts of the phrase-table during translation leading to a multi-domain adaptation approach. Niehues and Waibel (2012) compared several incremental approaches, namely the backoff, the factored, the log-linear and the fill-up (Bisazza et al., 2011) techniques. These approaches aim at adapting an MT system towards a target domain using small amounts of parallel in-domain data. The main outcome of this paper is that all the approaches successfully improve the generic model and none of them is better than the others. The performances o"
2014.amta-researchers.15,P13-1082,0,0.0129827,"to combine translation models. Models can be combined using the mixture-model approach, a log-linear combination or through incremental learning approaches. To obtain a mixture of domain-specific models trained on several different domain-specific corpora, they can be combined using a log-linear or a linear approach (Foster and Kuhn, 2007; Civera and Juan, 2007). The standard log-linear model may be used to combine some domainspecific models (Koehn and Schroeder, 2007). In the same way target language models may be combined using a log-linear or a linear combination (Schwenk and Koehn, 2008). Sennrich et al. (2013) proposed to combine different specific parts of the phrase-table during translation leading to a multi-domain adaptation approach. Niehues and Waibel (2012) compared several incremental approaches, namely the backoff, the factored, the log-linear and the fill-up (Bisazza et al., 2011) techniques. These approaches aim at adapting an MT system towards a target domain using small amounts of parallel in-domain data. The main outcome of this paper is that all the approaches successfully improve the generic model and none of them is better than the others. The performances of the approaches mainly"
2014.amta-researchers.15,W10-1759,0,0.335217,"Researchers Vancouver, BC © The Authors 195 sentences of the generic corpus are sorted regarding the computation of the difference between domain-specific score and generic score. At last, the best amount of the sorted data has to be determined. This best point is found by minimizing the perplexity of a development set on growing percentages of the sorted corpus. Moore and Lewis (2010) reported that the perplexity decreases when less, but more appropriate data is used. Recent works expand this approach to bitexts (Axelrod et al., 2011; Mansour et al., 2011). Approaches like corpus weighting (Shah et al., 2010) or sentence weighting (Matsoukas et al., 2009; Mansour and Ney, 2012) are not suitable to our translation task because these approaches can produce huge models by considering the whole data. 3 Cross-entropy based Data Selection versus Infrequent n-gram Recovery In this section we detail the different approaches experimented with for data selection. On one hand we process the data selection for both LM and translation model (TM) using cross-entropy. On the other hand, the infrequent n-gram recovery (Gascó et al., 2012), is explored. 3.1 Language Model Cross-entropy The LM cross-entropy differe"
2014.amta-researchers.15,steinberger-etal-2006-jrc,0,0.286062,"Missing"
2014.amta-researchers.15,tiedemann-2012-parallel,0,0.0508334,"slation task of the International Workshop on Spoken Language Translation4 as in-domain data. The general domain data consists of several corpora. The COSMAT scientific thesis abstracts (Lambert et al., 2012) and the news-commentary-v8 corpus, provided by the ACL 2013 8th Workshop on Statistical Machine Translation5 (WMT), are directly added to the baseline without instance selection due to their small size. The large corpora on which data selection is performed, are the Europarl-v7 corpus (also provided by WMT), the JRC-Acquis corpus (Steinberger et al., 2006) and the Open Subtitles corpus6 (Tiedemann, 2012). Data statistics for the complete in-domain and out-of-domain data are given in Table 1. For the development and test sets we selected four video lectures each, that were manually transcribed and professionally translated, resulting in a total of 1013 and 1360 sentences for development and test, respectively. In addition to the target side of the bilingual data, we leverage large amounts of monolingual resources for language model training. These include the Common Crawl Corpus, the 109 French-English corpus, the UN corpus and the News Crawl articles, available from the WMT 1 http://videolect"
2014.amta-researchers.15,2006.iwslt-papers.3,0,0.0243411,"on techniques in Section 3. Section 4 gives an account of the statistical translation system used in our experiments. Finally, the experimental setup and results are discussed in Section 5 and we conclude with Section 6. 2 Domain Adaptation Domain adaptation can be performed in different ways: using lightly-supervised approaches, model combination/update or data selection. 2.1 Lightly-supervised approaches A common way to adapt a statistical machine translation model is to use lightly-supervised approaches. These approaches aim to self-enhance the translation model. This was first proposed by Ueffing (2006) and refined by Ueffing et al. (2007). The main idea is to filter the translations with the translated test data. This process involves a confidence measure in order to select the Al-Onaizan & Simard (Eds.) Proceedings of AMTA 2014, vol. 1: MT Researchers Vancouver, BC © The Authors 194 most reliable data to train a small additional phrase table (PT). The generic and the new phrase tables are used jointly for translation, which can be seen as a mixture model with one specific PT built for each test set. The lightly-supervised training approach proposed by Schwenk (2008) does not adapt the mode"
2014.amta-researchers.15,P07-1004,0,0.0256273,"ction 4 gives an account of the statistical translation system used in our experiments. Finally, the experimental setup and results are discussed in Section 5 and we conclude with Section 6. 2 Domain Adaptation Domain adaptation can be performed in different ways: using lightly-supervised approaches, model combination/update or data selection. 2.1 Lightly-supervised approaches A common way to adapt a statistical machine translation model is to use lightly-supervised approaches. These approaches aim to self-enhance the translation model. This was first proposed by Ueffing (2006) and refined by Ueffing et al. (2007). The main idea is to filter the translations with the translated test data. This process involves a confidence measure in order to select the Al-Onaizan & Simard (Eds.) Proceedings of AMTA 2014, vol. 1: MT Researchers Vancouver, BC © The Authors 194 most reliable data to train a small additional phrase table (PT). The generic and the new phrase tables are used jointly for translation, which can be seen as a mixture model with one specific PT built for each test set. The lightly-supervised training approach proposed by Schwenk (2008) does not adapt the model to the test data, but it proposes t"
2014.amta-researchers.15,C12-3061,1,0.813971,"a is selected based on infrequent n-gram recovery and part is selected with TM model cross-entropy. This way, we hope to benefit from the new information introduced by the first while reinforcing a domain-specific distribution at the same time. In practice we start with the maximum amount of data selected by infrequent n-gram recovery. On top of this, we now add increasing amounts of data selected by TM model cross-entropy, until the full general domain data has been added. 4 Statistical Translation System We use the standard phrase-based translation decoder from the open source toolkit Jane (Wuebker et al., 2012) for all translation experiments. The translation process is framed as a loglinear combination of models, which is a generalization of the source-channel paradigm introˆ duced by Brown et al. (1993). The decoder searches for the best translation eˆI1 as defined by the I K J models hm (e1 , s1 , f1 ). It can be written as (Och and Ney, 2004) ( ˆ eˆI1 = arg max I,eI1 M X ) J λm hm (eI1 , sK 1 , f1 ) , (9) m=1 where f1J = f1 . . . fJ is the source sentence, eI1 = e1 . . . eI the target sentence and sK 1 = s1 . . . sK their phrase segmentation and alignment. The feature functions hm include transl"
2014.amta-researchers.15,D13-1138,1,0.836368,"models hm (e1 , s1 , f1 ). It can be written as (Och and Ney, 2004) ( ˆ eˆI1 = arg max I,eI1 M X ) J λm hm (eI1 , sK 1 , f1 ) , (9) m=1 where f1J = f1 . . . fJ is the source sentence, eI1 = e1 . . . eI the target sentence and sK 1 = s1 . . . sK their phrase segmentation and alignment. The feature functions hm include translation channel models in both directions, lexical smoothing models in both directions, an n-gram language model, phrase and word penalty, a jump-distance-based distortion model, a hierarchical orientation model (Galley and Manning, 2008) and an n-gram cluster language model (Wuebker et al., 2013). The log-linear feature weights λm are optimized on a development data set with minimum error rate training (MERT) (Och, 2003). As optimization criterion we use B LEU (Papineni et al., 2001). Al-Onaizan & Simard (Eds.) Proceedings of AMTA 2014, vol. 1: MT Researchers Vancouver, BC © The Authors 199 5 Experiments In this section we describe the different experiments we made in order to compare between the approaches. 5.1 The VideoLectures.NET Repository VideoLectures.NET1 is a free and open access repository of video lectures mostly filmed by people from the Jožef Stefan Institute (JSI, Sloven"
2014.amta-researchers.15,P02-1040,0,\N,Missing
2014.amta-researchers.15,D08-1076,0,\N,Missing
2014.iwslt-evaluation.7,D14-1003,1,0.921764,"slation of spoken language. The IWSLT TED talks task constitutes an interesting framework for empirical testing of some of the systems for spoken language translation which are developed as part of the project. In this work, we describe the EU-BRIDGE submissions to the 2014 IWSLT translation task. This year, we combined several single systems of RWTH, UEDIN, KIT, and FBK for the German→English SLT, German→English MT, English→German MT, and English→French MT tasks. Additionally to the standard system combination pipeline presented in [1, 2], we applied a recurrent neural network rescoring step [3] for the English→French MT task. Similar cooperative approaches based on system combination have proven to be valuable for machine translation in previous joint submissions, e.g. [4, 5]. 2. RWTH Aachen University RWTH applied the identical training pipeline and models on both language pairs: The state-of-the-art phrase-based baseline systems were augmented with a hierarchical reordering model, several additional language models (LMs) and maximum expected B LEU training for phrasal, lexical and reordering models. Further, RWTH employed rescoring with novel recurrent neural language and translat"
2014.iwslt-evaluation.7,W10-1738,1,0.885248,"and maximum expected B LEU training for phrasal, lexical and reordering models. Further, RWTH employed rescoring with novel recurrent neural language and translation models. The same systems were used for the SLT track, where RWTH ad57 Proceedings of the 11th International Workshop on Spoken Language Translation Lake Tahoe, December 4th and 5th, 2014 ditionally performed punctuation prediction on the automatic transcriptions employing hierarchical phrase-based translation. Both the phrase-based and the hierarchical decoder are implemented in RWTH’s publicly available translation toolkit Jane [6, 7]. The model weights of all systems were tuned with standard Minimum Error Rate Training [8] on the provided dev2012 set. RWTH used B LEU as optimization objective. For the German→English translation direction, in a preprocessing step the German source was decompounded [9] and part-of-speech-based long-range verb reordering rules [10] were applied. RWTH’s translation systems are described in more detail in [11]. Backoff Language Models Each translation system used three backoff LMs that were estimated with the KenLM toolkit [12]: A large general domain 5-gram LM, an in-domain 5-gram LM and a 7-"
2014.iwslt-evaluation.7,P03-1021,0,0.488353,"employed rescoring with novel recurrent neural language and translation models. The same systems were used for the SLT track, where RWTH ad57 Proceedings of the 11th International Workshop on Spoken Language Translation Lake Tahoe, December 4th and 5th, 2014 ditionally performed punctuation prediction on the automatic transcriptions employing hierarchical phrase-based translation. Both the phrase-based and the hierarchical decoder are implemented in RWTH’s publicly available translation toolkit Jane [6, 7]. The model weights of all systems were tuned with standard Minimum Error Rate Training [8] on the provided dev2012 set. RWTH used B LEU as optimization objective. For the German→English translation direction, in a preprocessing step the German source was decompounded [9] and part-of-speech-based long-range verb reordering rules [10] were applied. RWTH’s translation systems are described in more detail in [11]. Backoff Language Models Each translation system used three backoff LMs that were estimated with the KenLM toolkit [12]: A large general domain 5-gram LM, an in-domain 5-gram LM and a 7-gram word class language model (wcLM). All of them used interpolated Kneser-Ney smoothing."
2014.iwslt-evaluation.7,popovic-ney-2006-pos,1,0.798687,"th and 5th, 2014 ditionally performed punctuation prediction on the automatic transcriptions employing hierarchical phrase-based translation. Both the phrase-based and the hierarchical decoder are implemented in RWTH’s publicly available translation toolkit Jane [6, 7]. The model weights of all systems were tuned with standard Minimum Error Rate Training [8] on the provided dev2012 set. RWTH used B LEU as optimization objective. For the German→English translation direction, in a preprocessing step the German source was decompounded [9] and part-of-speech-based long-range verb reordering rules [10] were applied. RWTH’s translation systems are described in more detail in [11]. Backoff Language Models Each translation system used three backoff LMs that were estimated with the KenLM toolkit [12]: A large general domain 5-gram LM, an in-domain 5-gram LM and a 7-gram word class language model (wcLM). All of them used interpolated Kneser-Ney smoothing. For the general domain LM, RWTH first selected 12 of the English Shuffled News, and 41 of the French Shuffled News as well as both the English and French Gigaword corpora by the cross-entropy difference criterion described in [13]. The selectio"
2014.iwslt-evaluation.7,P13-2121,1,0.819366,"mplemented in RWTH’s publicly available translation toolkit Jane [6, 7]. The model weights of all systems were tuned with standard Minimum Error Rate Training [8] on the provided dev2012 set. RWTH used B LEU as optimization objective. For the German→English translation direction, in a preprocessing step the German source was decompounded [9] and part-of-speech-based long-range verb reordering rules [10] were applied. RWTH’s translation systems are described in more detail in [11]. Backoff Language Models Each translation system used three backoff LMs that were estimated with the KenLM toolkit [12]: A large general domain 5-gram LM, an in-domain 5-gram LM and a 7-gram word class language model (wcLM). All of them used interpolated Kneser-Ney smoothing. For the general domain LM, RWTH first selected 12 of the English Shuffled News, and 41 of the French Shuffled News as well as both the English and French Gigaword corpora by the cross-entropy difference criterion described in [13]. The selection was then concatenated with all available remaining monolingual data and used to build and unpruned LM. The in-domain language models were estimated on the TED data only. For the word class LM, RWT"
2014.iwslt-evaluation.7,P10-2041,0,0.0916594,"rdering rules [10] were applied. RWTH’s translation systems are described in more detail in [11]. Backoff Language Models Each translation system used three backoff LMs that were estimated with the KenLM toolkit [12]: A large general domain 5-gram LM, an in-domain 5-gram LM and a 7-gram word class language model (wcLM). All of them used interpolated Kneser-Ney smoothing. For the general domain LM, RWTH first selected 12 of the English Shuffled News, and 41 of the French Shuffled News as well as both the English and French Gigaword corpora by the cross-entropy difference criterion described in [13]. The selection was then concatenated with all available remaining monolingual data and used to build and unpruned LM. The in-domain language models were estimated on the TED data only. For the word class LM, RWTH trained 200 classes on the target side of the bilingual training data using an in-house tool similar to mkcls [14]. With these class definitions, RWTH applied the technique shown in [15] to compute the wcLM on the same data as the general-domain LM. Maximum Expected B LEU Training RWTH applied discriminative training, learning three types of features under a maximum expected B LEU ob"
2014.iwslt-evaluation.7,E99-1010,0,0.0737032,"them used interpolated Kneser-Ney smoothing. For the general domain LM, RWTH first selected 12 of the English Shuffled News, and 41 of the French Shuffled News as well as both the English and French Gigaword corpora by the cross-entropy difference criterion described in [13]. The selection was then concatenated with all available remaining monolingual data and used to build and unpruned LM. The in-domain language models were estimated on the TED data only. For the word class LM, RWTH trained 200 classes on the target side of the bilingual training data using an in-house tool similar to mkcls [14]. With these class definitions, RWTH applied the technique shown in [15] to compute the wcLM on the same data as the general-domain LM. Maximum Expected B LEU Training RWTH applied discriminative training, learning three types of features under a maximum expected B LEU objective [16]. It was performed on the TED portion of the data, which is high quality in-domain data of reasonable size. This makes training feasible while at the same time providing an implicit domain adaptation effect. Similar to [16], RWTH generated 100-best lists on the training data which were used as training samples for"
2014.iwslt-evaluation.7,D13-1138,1,0.85854,"RWTH first selected 12 of the English Shuffled News, and 41 of the French Shuffled News as well as both the English and French Gigaword corpora by the cross-entropy difference criterion described in [13]. The selection was then concatenated with all available remaining monolingual data and used to build and unpruned LM. The in-domain language models were estimated on the TED data only. For the word class LM, RWTH trained 200 classes on the target side of the bilingual training data using an in-house tool similar to mkcls [14]. With these class definitions, RWTH applied the technique shown in [15] to compute the wcLM on the same data as the general-domain LM. Maximum Expected B LEU Training RWTH applied discriminative training, learning three types of features under a maximum expected B LEU objective [16]. It was performed on the TED portion of the data, which is high quality in-domain data of reasonable size. This makes training feasible while at the same time providing an implicit domain adaptation effect. Similar to [16], RWTH generated 100-best lists on the training data which were used as training samples for a gradient based update method. Leave-oneout [17] was applied to circumv"
2014.iwslt-evaluation.7,P12-1031,0,0.0125863,"lection was then concatenated with all available remaining monolingual data and used to build and unpruned LM. The in-domain language models were estimated on the TED data only. For the word class LM, RWTH trained 200 classes on the target side of the bilingual training data using an in-house tool similar to mkcls [14]. With these class definitions, RWTH applied the technique shown in [15] to compute the wcLM on the same data as the general-domain LM. Maximum Expected B LEU Training RWTH applied discriminative training, learning three types of features under a maximum expected B LEU objective [16]. It was performed on the TED portion of the data, which is high quality in-domain data of reasonable size. This makes training feasible while at the same time providing an implicit domain adaptation effect. Similar to [16], RWTH generated 100-best lists on the training data which were used as training samples for a gradient based update method. Leave-oneout [17] was applied to circumvent over-fitting. Here, RWTH followed an approach similar to [18], where each feature type was condensed into a single feature for the log-linear model combination. In the first pass, RWTH trained phrase pair and"
2014.iwslt-evaluation.7,P10-1049,1,0.833909,"the technique shown in [15] to compute the wcLM on the same data as the general-domain LM. Maximum Expected B LEU Training RWTH applied discriminative training, learning three types of features under a maximum expected B LEU objective [16]. It was performed on the TED portion of the data, which is high quality in-domain data of reasonable size. This makes training feasible while at the same time providing an implicit domain adaptation effect. Similar to [16], RWTH generated 100-best lists on the training data which were used as training samples for a gradient based update method. Leave-oneout [17] was applied to circumvent over-fitting. Here, RWTH followed an approach similar to [18], where each feature type was condensed into a single feature for the log-linear model combination. In the first pass, RWTH trained phrase pair and phrase-internal word pair features, and in the second pass a hierarchical reordering model, resulting altogether in an additional eight models for log-linear combination. Recurrent Neural Network Models All systems applied rescoring on 1000-best lists using recurrent language and translation models. The recurrency was handled with the long short-term memory (LST"
2014.iwslt-evaluation.7,D14-1132,0,0.157332,"M. Maximum Expected B LEU Training RWTH applied discriminative training, learning three types of features under a maximum expected B LEU objective [16]. It was performed on the TED portion of the data, which is high quality in-domain data of reasonable size. This makes training feasible while at the same time providing an implicit domain adaptation effect. Similar to [16], RWTH generated 100-best lists on the training data which were used as training samples for a gradient based update method. Leave-oneout [17] was applied to circumvent over-fitting. Here, RWTH followed an approach similar to [18], where each feature type was condensed into a single feature for the log-linear model combination. In the first pass, RWTH trained phrase pair and phrase-internal word pair features, and in the second pass a hierarchical reordering model, resulting altogether in an additional eight models for log-linear combination. Recurrent Neural Network Models All systems applied rescoring on 1000-best lists using recurrent language and translation models. The recurrency was handled with the long short-term memory (LSTM) architecture [19] and RWTH used a class-factored output layer for increased efficienc"
2014.iwslt-evaluation.7,2011.iwslt-papers.7,1,0.944851,"ort-term memory (LSTM) architecture [19] and RWTH used a class-factored output layer for increased efficiency as described in [20]. All neural networks were trained on the TED portion of the data with 2000 word classes. In addition to the recurrent language model (RNN-LM), RWTH applied the deep bidirectional word-based translation model (RNN-BTM) described in [3], which is capable of taking the full source context into account for each translation decision. Spoken Language Translation For the SLT task, RWTH reintroduced punctuation and case information before the actual translation similar to [21]. However, RWTH employed a hierarchical phrase-based system with a maximum of one nonterminal symbol per rule in place of a phrase-based system. A punctuation prediction system based on hierarchical translation is able to capture long-range dependencies between words and punctuation marks and is more robust for unseen word sequences. The model weights are tuned with standard MERT on 100best lists. As optimization criterion RWTH used F2 -Score rather than B LEU or W ER. More details can be found in [22]. Since punctuation predicting and recasing were applied before the actual translation, the f"
2014.iwslt-evaluation.7,2014.iwslt-papers.17,1,0.734908,"RWTH reintroduced punctuation and case information before the actual translation similar to [21]. However, RWTH employed a hierarchical phrase-based system with a maximum of one nonterminal symbol per rule in place of a phrase-based system. A punctuation prediction system based on hierarchical translation is able to capture long-range dependencies between words and punctuation marks and is more robust for unseen word sequences. The model weights are tuned with standard MERT on 100best lists. As optimization criterion RWTH used F2 -Score rather than B LEU or W ER. More details can be found in [22]. Since punctuation predicting and recasing were applied before the actual translation, the final translation systems from the MT track could be kept completely unchanged. 3. University of Edinburgh The UEDIN translation engines [23] are based on the open source Moses toolkit [24]. UEDIN set up phrase-based systems for all SLT and MT tasks covered in this paper, and additionally a string-to-tree syntax-based system [25] for the English→German MT task. The systems were trained using monolingual and parallel data from WIT3 , Europarl, MultiUN, the English and French Gigaword corpora as provided"
2014.iwslt-evaluation.7,P07-2045,1,0.0190208,"n hierarchical translation is able to capture long-range dependencies between words and punctuation marks and is more robust for unseen word sequences. The model weights are tuned with standard MERT on 100best lists. As optimization criterion RWTH used F2 -Score rather than B LEU or W ER. More details can be found in [22]. Since punctuation predicting and recasing were applied before the actual translation, the final translation systems from the MT track could be kept completely unchanged. 3. University of Edinburgh The UEDIN translation engines [23] are based on the open source Moses toolkit [24]. UEDIN set up phrase-based systems for all SLT and MT tasks covered in this paper, and additionally a string-to-tree syntax-based system [25] for the English→German MT task. The systems were trained using monolingual and parallel data from WIT3 , Europarl, MultiUN, the English and French Gigaword corpora as provided by the Linguistic Data Consortium, the German Political Speeches Corpus, and the Common Crawl, 109 , and News Commentary corpora from the WMT shared task training data. Word alignments for the MT track systems were created by aligning the data in both directions with MGIZA++ [26]"
2014.iwslt-evaluation.7,N04-1035,0,0.0565459,"equences. The model weights are tuned with standard MERT on 100best lists. As optimization criterion RWTH used F2 -Score rather than B LEU or W ER. More details can be found in [22]. Since punctuation predicting and recasing were applied before the actual translation, the final translation systems from the MT track could be kept completely unchanged. 3. University of Edinburgh The UEDIN translation engines [23] are based on the open source Moses toolkit [24]. UEDIN set up phrase-based systems for all SLT and MT tasks covered in this paper, and additionally a string-to-tree syntax-based system [25] for the English→German MT task. The systems were trained using monolingual and parallel data from WIT3 , Europarl, MultiUN, the English and French Gigaword corpora as provided by the Linguistic Data Consortium, the German Political Speeches Corpus, and the Common Crawl, 109 , and News Commentary corpora from the WMT shared task training data. Word alignments for the MT track systems were created by aligning the data in both directions with MGIZA++ [26] and symmetrizing the two trained alignments. Word alignments for the SLT track system were created using fast align [27]. The SRILM toolkit [2"
2014.iwslt-evaluation.7,W08-0509,0,0.192359,"[24]. UEDIN set up phrase-based systems for all SLT and MT tasks covered in this paper, and additionally a string-to-tree syntax-based system [25] for the English→German MT task. The systems were trained using monolingual and parallel data from WIT3 , Europarl, MultiUN, the English and French Gigaword corpora as provided by the Linguistic Data Consortium, the German Political Speeches Corpus, and the Common Crawl, 109 , and News Commentary corpora from the WMT shared task training data. Word alignments for the MT track systems were created by aligning the data in both directions with MGIZA++ [26] and symmetrizing the two trained alignments. Word alignments for the SLT track system were created using fast align [27]. The SRILM toolkit [28] was employed to train 5-gram LMs with modified Kneser-Ney smoothing [29]. UEDIN trained individual LMs on each corpus and then interpolated them using weights tuned to minimize perplexity on a development set. Common features included in the UEDIN phrase-based systems are the language model, phrase translation scores in both directions smoothed with Good-Turing discounting, lexical translation scores in both directions, word and phrase penalties, six"
2014.iwslt-evaluation.7,N13-1073,0,0.0453396,"e syntax-based system [25] for the English→German MT task. The systems were trained using monolingual and parallel data from WIT3 , Europarl, MultiUN, the English and French Gigaword corpora as provided by the Linguistic Data Consortium, the German Political Speeches Corpus, and the Common Crawl, 109 , and News Commentary corpora from the WMT shared task training data. Word alignments for the MT track systems were created by aligning the data in both directions with MGIZA++ [26] and symmetrizing the two trained alignments. Word alignments for the SLT track system were created using fast align [27]. The SRILM toolkit [28] was employed to train 5-gram LMs with modified Kneser-Ney smoothing [29]. UEDIN trained individual LMs on each corpus and then interpolated them using weights tuned to minimize perplexity on a development set. Common features included in the UEDIN phrase-based systems are the language model, phrase translation scores in both directions smoothed with Good-Turing discounting, lexical translation scores in both directions, word and phrase penalties, six simple count-based binary features, distancebased distortion costs, a hierarchical lexicalized reordering model [30], sp"
2014.iwslt-evaluation.7,C14-1041,1,0.839592,"ndividual LMs on each corpus and then interpolated them using weights tuned to minimize perplexity on a development set. Common features included in the UEDIN phrase-based systems are the language model, phrase translation scores in both directions smoothed with Good-Turing discounting, lexical translation scores in both directions, word and phrase penalties, six simple count-based binary features, distancebased distortion costs, a hierarchical lexicalized reordering model [30], sparse lexical and domain indicator features [31] and operation sequence models over different word representations [32]. Model weights were optimized with batch MIRA [33] to maximize B LEU [34]. Spoken Language Translation One of the main challenges of spoken language translation is to overcome the mismatch in the style of data that the 58 Proceedings of the 11th International Workshop on Spoken Language Translation Lake Tahoe, December 4th and 5th, 2014 speech recognition systems output, and the written text that is used to train the translation model. ASR system output lacks punctuation and capitalization, which is the main stylistic differences. Previous research [35, 21, 36] suggests that it is preferrable"
2014.iwslt-evaluation.7,N12-1047,0,0.0681194,"them using weights tuned to minimize perplexity on a development set. Common features included in the UEDIN phrase-based systems are the language model, phrase translation scores in both directions smoothed with Good-Turing discounting, lexical translation scores in both directions, word and phrase penalties, six simple count-based binary features, distancebased distortion costs, a hierarchical lexicalized reordering model [30], sparse lexical and domain indicator features [31] and operation sequence models over different word representations [32]. Model weights were optimized with batch MIRA [33] to maximize B LEU [34]. Spoken Language Translation One of the main challenges of spoken language translation is to overcome the mismatch in the style of data that the 58 Proceedings of the 11th International Workshop on Spoken Language Translation Lake Tahoe, December 4th and 5th, 2014 speech recognition systems output, and the written text that is used to train the translation model. ASR system output lacks punctuation and capitalization, which is the main stylistic differences. Previous research [35, 21, 36] suggests that it is preferrable to punctuate the text before translation, which is"
2014.iwslt-evaluation.7,P02-1040,0,0.0918061,"d to minimize perplexity on a development set. Common features included in the UEDIN phrase-based systems are the language model, phrase translation scores in both directions smoothed with Good-Turing discounting, lexical translation scores in both directions, word and phrase penalties, six simple count-based binary features, distancebased distortion costs, a hierarchical lexicalized reordering model [30], sparse lexical and domain indicator features [31] and operation sequence models over different word representations [32]. Model weights were optimized with batch MIRA [33] to maximize B LEU [34]. Spoken Language Translation One of the main challenges of spoken language translation is to overcome the mismatch in the style of data that the 58 Proceedings of the 11th International Workshop on Spoken Language Translation Lake Tahoe, December 4th and 5th, 2014 speech recognition systems output, and the written text that is used to train the translation model. ASR system output lacks punctuation and capitalization, which is the main stylistic differences. Previous research [35, 21, 36] suggests that it is preferrable to punctuate the text before translation, which is what UEDIN did by trai"
2014.iwslt-evaluation.7,2006.iwslt-papers.1,1,0.862433,"els over different word representations [32]. Model weights were optimized with batch MIRA [33] to maximize B LEU [34]. Spoken Language Translation One of the main challenges of spoken language translation is to overcome the mismatch in the style of data that the 58 Proceedings of the 11th International Workshop on Spoken Language Translation Lake Tahoe, December 4th and 5th, 2014 speech recognition systems output, and the written text that is used to train the translation model. ASR system output lacks punctuation and capitalization, which is the main stylistic differences. Previous research [35, 21, 36] suggests that it is preferrable to punctuate the text before translation, which is what UEDIN did by training a translation system on the German side of the parallel data. The “source language” of the system had punctuation and capitalization stripped, and the “target language” was the standard German parallel text. The handling of punctuation is similar to the other groups in this paper, however UEDIN used a phrase-based model with no distortion or reordering, and tuned the model to the ASR input text using batch MIRA and the B LEU score. German→English MT For the UEDIN German→English MT tas"
2014.iwslt-evaluation.7,2012.iwslt-papers.15,1,0.927241,"els over different word representations [32]. Model weights were optimized with batch MIRA [33] to maximize B LEU [34]. Spoken Language Translation One of the main challenges of spoken language translation is to overcome the mismatch in the style of data that the 58 Proceedings of the 11th International Workshop on Spoken Language Translation Lake Tahoe, December 4th and 5th, 2014 speech recognition systems output, and the written text that is used to train the translation model. ASR system output lacks punctuation and capitalization, which is the main stylistic differences. Previous research [35, 21, 36] suggests that it is preferrable to punctuate the text before translation, which is what UEDIN did by training a translation system on the German side of the parallel data. The “source language” of the system had punctuation and capitalization stripped, and the “target language” was the standard German parallel text. The handling of punctuation is similar to the other groups in this paper, however UEDIN used a phrase-based model with no distortion or reordering, and tuned the model to the ASR input text using batch MIRA and the B LEU score. German→English MT For the UEDIN German→English MT tas"
2014.iwslt-evaluation.7,P05-1066,1,0.733044,"ferrable to punctuate the text before translation, which is what UEDIN did by training a translation system on the German side of the parallel data. The “source language” of the system had punctuation and capitalization stripped, and the “target language” was the standard German parallel text. The handling of punctuation is similar to the other groups in this paper, however UEDIN used a phrase-based model with no distortion or reordering, and tuned the model to the ASR input text using batch MIRA and the B LEU score. German→English MT For the UEDIN German→English MT task system, prereordering [37] and compound splitting [38] were applied to the German source language side in a preprocessing step. A factored translation model [39] was employed. Source side factors are word, lemma, part-of-speech (POS) tag, and morphological tag. Target side factors are word, lemma, and POS tag. UEDIN incorporated two additional LMs into the German→English MT system: a 7-gram LM over POS tags (trained on WIT3 only) and a 7-gram LM over lemmas (trained on WIT3 only). Model weights were optimized on a concatenation of dev2010 and dev2012. English→French MT UEDIN contributed two phrase-based systems for the"
2014.iwslt-evaluation.7,E03-1076,1,0.858704,"xt before translation, which is what UEDIN did by training a translation system on the German side of the parallel data. The “source language” of the system had punctuation and capitalization stripped, and the “target language” was the standard German parallel text. The handling of punctuation is similar to the other groups in this paper, however UEDIN used a phrase-based model with no distortion or reordering, and tuned the model to the ASR input text using batch MIRA and the B LEU score. German→English MT For the UEDIN German→English MT task system, prereordering [37] and compound splitting [38] were applied to the German source language side in a preprocessing step. A factored translation model [39] was employed. Source side factors are word, lemma, part-of-speech (POS) tag, and morphological tag. Target side factors are word, lemma, and POS tag. UEDIN incorporated two additional LMs into the German→English MT system: a 7-gram LM over POS tags (trained on WIT3 only) and a 7-gram LM over lemmas (trained on WIT3 only). Model weights were optimized on a concatenation of dev2010 and dev2012. English→French MT UEDIN contributed two phrase-based systems for the English→French EU-BRIDGE sy"
2014.iwslt-evaluation.7,2012.amta-papers.9,1,0.84942,"arallel data. The “source language” of the system had punctuation and capitalization stripped, and the “target language” was the standard German parallel text. The handling of punctuation is similar to the other groups in this paper, however UEDIN used a phrase-based model with no distortion or reordering, and tuned the model to the ASR input text using batch MIRA and the B LEU score. German→English MT For the UEDIN German→English MT task system, prereordering [37] and compound splitting [38] were applied to the German source language side in a preprocessing step. A factored translation model [39] was employed. Source side factors are word, lemma, part-of-speech (POS) tag, and morphological tag. Target side factors are word, lemma, and POS tag. UEDIN incorporated two additional LMs into the German→English MT system: a 7-gram LM over POS tags (trained on WIT3 only) and a 7-gram LM over lemmas (trained on WIT3 only). Model weights were optimized on a concatenation of dev2010 and dev2012. English→French MT UEDIN contributed two phrase-based systems for the English→French EU-BRIDGE system combination. Both comprise Brown clusters with 200 classes as additional factors on source and target"
2014.iwslt-evaluation.7,D08-1089,0,0.176922,"ign [27]. The SRILM toolkit [28] was employed to train 5-gram LMs with modified Kneser-Ney smoothing [29]. UEDIN trained individual LMs on each corpus and then interpolated them using weights tuned to minimize perplexity on a development set. Common features included in the UEDIN phrase-based systems are the language model, phrase translation scores in both directions smoothed with Good-Turing discounting, lexical translation scores in both directions, word and phrase penalties, six simple count-based binary features, distancebased distortion costs, a hierarchical lexicalized reordering model [30], sparse lexical and domain indicator features [31] and operation sequence models over different word representations [32]. Model weights were optimized with batch MIRA [33] to maximize B LEU [34]. Spoken Language Translation One of the main challenges of spoken language translation is to overcome the mismatch in the style of data that the 58 Proceedings of the 11th International Workshop on Spoken Language Translation Lake Tahoe, December 4th and 5th, 2014 speech recognition systems output, and the written text that is used to train the translation model. ASR system output lacks punctuation a"
2014.iwslt-evaluation.7,W14-3324,1,0.784121,"ical tag. UEDIN-A was trained with all corpora, whereas for UEDIN-B the parallel training data was restricted to the indomain WIT3 corpus. Additional features of the systems are: a 5-gram LM over Brown clusters, a 7-gram LM over morphological tags (UEDIN-A: trained on all data, UEDIN-B: trained on WIT3 only), and a 7-gram LM over POS tags (UEDIN-A, not UEDIN-B). Model weights of UEDIN-B were optimized on dev2010, model weights of UEDIN-A on a concatenation of dev2010 and dev2012. Syntax-based system. UEDIN-C is a string-to-tree translation system with similar features as the ones described in [40]. The target-side data was parsed with BitPar [41], and right binarization was applied to the parse trees. The system was adapted to the TED domain by extracting separate rule tables (from the WIT3 corpus and from the rest of the parallel data) and merging them with a fill-up technique [42]. Augmenting the system with non-syntactic phrases [43] and adding soft source syntactic constraints [44] yielded further improvements. Model weights of UEDIN-C were optimized on a concatenation of dev2010 and dev2012. 4. Karlsruhe Institute of Technology The KIT translations were generated by an in-house ph"
2014.iwslt-evaluation.7,2012.iwslt-papers.17,1,0.881764,"ain 5-gram LMs with modified Kneser-Ney smoothing [29]. UEDIN trained individual LMs on each corpus and then interpolated them using weights tuned to minimize perplexity on a development set. Common features included in the UEDIN phrase-based systems are the language model, phrase translation scores in both directions smoothed with Good-Turing discounting, lexical translation scores in both directions, word and phrase penalties, six simple count-based binary features, distancebased distortion costs, a hierarchical lexicalized reordering model [30], sparse lexical and domain indicator features [31] and operation sequence models over different word representations [32]. Model weights were optimized with batch MIRA [33] to maximize B LEU [34]. Spoken Language Translation One of the main challenges of spoken language translation is to overcome the mismatch in the style of data that the 58 Proceedings of the 11th International Workshop on Spoken Language Translation Lake Tahoe, December 4th and 5th, 2014 speech recognition systems output, and the written text that is used to train the translation model. ASR system output lacks punctuation and capitalization, which is the main stylistic diff"
2014.iwslt-evaluation.7,C04-1024,0,0.0400394,"ereas for UEDIN-B the parallel training data was restricted to the indomain WIT3 corpus. Additional features of the systems are: a 5-gram LM over Brown clusters, a 7-gram LM over morphological tags (UEDIN-A: trained on all data, UEDIN-B: trained on WIT3 only), and a 7-gram LM over POS tags (UEDIN-A, not UEDIN-B). Model weights of UEDIN-B were optimized on dev2010, model weights of UEDIN-A on a concatenation of dev2010 and dev2012. Syntax-based system. UEDIN-C is a string-to-tree translation system with similar features as the ones described in [40]. The target-side data was parsed with BitPar [41], and right binarization was applied to the parse trees. The system was adapted to the TED domain by extracting separate rule tables (from the WIT3 corpus and from the rest of the parallel data) and merging them with a fill-up technique [42]. Augmenting the system with non-syntactic phrases [43] and adding soft source syntactic constraints [44] yielded further improvements. Model weights of UEDIN-C were optimized on a concatenation of dev2010 and dev2012. 4. Karlsruhe Institute of Technology The KIT translations were generated by an in-house phrasebased translations system [45]. The models wer"
2014.iwslt-evaluation.7,2011.iwslt-evaluation.18,1,0.873679,"ined on WIT3 only), and a 7-gram LM over POS tags (UEDIN-A, not UEDIN-B). Model weights of UEDIN-B were optimized on dev2010, model weights of UEDIN-A on a concatenation of dev2010 and dev2012. Syntax-based system. UEDIN-C is a string-to-tree translation system with similar features as the ones described in [40]. The target-side data was parsed with BitPar [41], and right binarization was applied to the parse trees. The system was adapted to the TED domain by extracting separate rule tables (from the WIT3 corpus and from the rest of the parallel data) and merging them with a fill-up technique [42]. Augmenting the system with non-syntactic phrases [43] and adding soft source syntactic constraints [44] yielded further improvements. Model weights of UEDIN-C were optimized on a concatenation of dev2010 and dev2012. 4. Karlsruhe Institute of Technology The KIT translations were generated by an in-house phrasebased translations system [45]. The models were trained on the Europarl, News Commentary, WIT3 , Common Crawl corpora for all directions, as well as on the additional monolingual training data. The noisy Crawl corpora were filtered using an SVM classifier [46]. In addition to the standa"
2014.iwslt-evaluation.7,W14-3362,1,0.610881,"N-A, not UEDIN-B). Model weights of UEDIN-B were optimized on dev2010, model weights of UEDIN-A on a concatenation of dev2010 and dev2012. Syntax-based system. UEDIN-C is a string-to-tree translation system with similar features as the ones described in [40]. The target-side data was parsed with BitPar [41], and right binarization was applied to the parse trees. The system was adapted to the TED domain by extracting separate rule tables (from the WIT3 corpus and from the rest of the parallel data) and merging them with a fill-up technique [42]. Augmenting the system with non-syntactic phrases [43] and adding soft source syntactic constraints [44] yielded further improvements. Model weights of UEDIN-C were optimized on a concatenation of dev2010 and dev2012. 4. Karlsruhe Institute of Technology The KIT translations were generated by an in-house phrasebased translations system [45]. The models were trained on the Europarl, News Commentary, WIT3 , Common Crawl corpora for all directions, as well as on the additional monolingual training data. The noisy Crawl corpora were filtered using an SVM classifier [46]. In addition to the standard preprocessing, KIT used compound splitting [38] for"
2014.iwslt-evaluation.7,W14-4018,1,0.774295,"ptimized on dev2010, model weights of UEDIN-A on a concatenation of dev2010 and dev2012. Syntax-based system. UEDIN-C is a string-to-tree translation system with similar features as the ones described in [40]. The target-side data was parsed with BitPar [41], and right binarization was applied to the parse trees. The system was adapted to the TED domain by extracting separate rule tables (from the WIT3 corpus and from the rest of the parallel data) and merging them with a fill-up technique [42]. Augmenting the system with non-syntactic phrases [43] and adding soft source syntactic constraints [44] yielded further improvements. Model weights of UEDIN-C were optimized on a concatenation of dev2010 and dev2012. 4. Karlsruhe Institute of Technology The KIT translations were generated by an in-house phrasebased translations system [45]. The models were trained on the Europarl, News Commentary, WIT3 , Common Crawl corpora for all directions, as well as on the additional monolingual training data. The noisy Crawl corpora were filtered using an SVM classifier [46]. In addition to the standard preprocessing, KIT used compound splitting [38] for the German text when translating from German. In t"
2014.iwslt-evaluation.7,2011.iwslt-evaluation.9,1,0.861968,"m with a fill-up technique [42]. Augmenting the system with non-syntactic phrases [43] and adding soft source syntactic constraints [44] yielded further improvements. Model weights of UEDIN-C were optimized on a concatenation of dev2010 and dev2012. 4. Karlsruhe Institute of Technology The KIT translations were generated by an in-house phrasebased translations system [45]. The models were trained on the Europarl, News Commentary, WIT3 , Common Crawl corpora for all directions, as well as on the additional monolingual training data. The noisy Crawl corpora were filtered using an SVM classifier [46]. In addition to the standard preprocessing, KIT used compound splitting [38] for the German text when translating from German. In the SLT task, KIT first recased the input and added punctuation marks to the ASR hypotheses. This was done with a monolingual translation system as shown in [36]. In all translation directions, KIT used a pre-reordering approach. Different reorderings of the source sentences were encoded in a word lattice. For the English→French system, only short-range rules were used to generate these lattices [47]. Long-range rules [48] and tree-based reordering rules [49] were"
2014.iwslt-evaluation.7,2007.tmi-papers.21,0,0.0614729,"ta. The noisy Crawl corpora were filtered using an SVM classifier [46]. In addition to the standard preprocessing, KIT used compound splitting [38] for the German text when translating from German. In the SLT task, KIT first recased the input and added punctuation marks to the ASR hypotheses. This was done with a monolingual translation system as shown in [36]. In all translation directions, KIT used a pre-reordering approach. Different reorderings of the source sentences were encoded in a word lattice. For the English→French system, only short-range rules were used to generate these lattices [47]. Long-range rules [48] and tree-based reordering rules [49] were used for German→English. The POS tags needed for these rules were generated by the TreeTagger [50] and the parse trees by the Stanford Parser [51]. In addition, for the language pairs involving German KIT applied the different reorderings of both language pairs using a lexicalized reordering model. The phrase tables of the systems were trained using GIZA++ alignment [52]. KIT adapted the phrase table to the TED domain using the backoff approach and by means of candidate selection [53]. In addition to the phrase table probabiliti"
2014.iwslt-evaluation.7,W09-0413,1,0.842557,"pora were filtered using an SVM classifier [46]. In addition to the standard preprocessing, KIT used compound splitting [38] for the German text when translating from German. In the SLT task, KIT first recased the input and added punctuation marks to the ASR hypotheses. This was done with a monolingual translation system as shown in [36]. In all translation directions, KIT used a pre-reordering approach. Different reorderings of the source sentences were encoded in a word lattice. For the English→French system, only short-range rules were used to generate these lattices [47]. Long-range rules [48] and tree-based reordering rules [49] were used for German→English. The POS tags needed for these rules were generated by the TreeTagger [50] and the parse trees by the Stanford Parser [51]. In addition, for the language pairs involving German KIT applied the different reorderings of both language pairs using a lexicalized reordering model. The phrase tables of the systems were trained using GIZA++ alignment [52]. KIT adapted the phrase table to the TED domain using the backoff approach and by means of candidate selection [53]. In addition to the phrase table probabilities, KIT modeled the tra"
2014.iwslt-evaluation.7,W13-0805,1,0.85195,"ifier [46]. In addition to the standard preprocessing, KIT used compound splitting [38] for the German text when translating from German. In the SLT task, KIT first recased the input and added punctuation marks to the ASR hypotheses. This was done with a monolingual translation system as shown in [36]. In all translation directions, KIT used a pre-reordering approach. Different reorderings of the source sentences were encoded in a word lattice. For the English→French system, only short-range rules were used to generate these lattices [47]. Long-range rules [48] and tree-based reordering rules [49] were used for German→English. The POS tags needed for these rules were generated by the TreeTagger [50] and the parse trees by the Stanford Parser [51]. In addition, for the language pairs involving German KIT applied the different reorderings of both language pairs using a lexicalized reordering model. The phrase tables of the systems were trained using GIZA++ alignment [52]. KIT adapted the phrase table to the TED domain using the backoff approach and by means of candidate selection [53]. In addition to the phrase table probabilities, KIT modeled the translation process by a bilingual langu"
2014.iwslt-evaluation.7,W08-1006,0,0.0150981,"k, KIT first recased the input and added punctuation marks to the ASR hypotheses. This was done with a monolingual translation system as shown in [36]. In all translation directions, KIT used a pre-reordering approach. Different reorderings of the source sentences were encoded in a word lattice. For the English→French system, only short-range rules were used to generate these lattices [47]. Long-range rules [48] and tree-based reordering rules [49] were used for German→English. The POS tags needed for these rules were generated by the TreeTagger [50] and the parse trees by the Stanford Parser [51]. In addition, for the language pairs involving German KIT applied the different reorderings of both language pairs using a lexicalized reordering model. The phrase tables of the systems were trained using GIZA++ alignment [52]. KIT adapted the phrase table to the TED domain using the backoff approach and by means of candidate selection [53]. In addition to the phrase table probabilities, KIT modeled the translation process by a bilingual language model [54] and a discriminative word lexicon using source context features [55]. During decoding, KIT used several LMs to adapt the system to the ta"
2014.iwslt-evaluation.7,2012.amta-papers.19,1,0.839901,"e rules were used to generate these lattices [47]. Long-range rules [48] and tree-based reordering rules [49] were used for German→English. The POS tags needed for these rules were generated by the TreeTagger [50] and the parse trees by the Stanford Parser [51]. In addition, for the language pairs involving German KIT applied the different reorderings of both language pairs using a lexicalized reordering model. The phrase tables of the systems were trained using GIZA++ alignment [52]. KIT adapted the phrase table to the TED domain using the backoff approach and by means of candidate selection [53]. In addition to the phrase table probabilities, KIT modeled the translation process by a bilingual language model [54] and a discriminative word lexicon using source context features [55]. During decoding, KIT used several LMs to adapt the system to the task and to better model the sentence structure using a class-based LM. For the German→English task, KIT used one LM trained on all data, an in-domain LM trained only on the WIT3 corpus, and one LM trained on 5M sentences selected using cross-entropy difference [13]. As classes KIT used the clusters obtained using the mkcls algorithm on the WI"
2014.iwslt-evaluation.7,W11-2124,1,0.902739,"for German→English. The POS tags needed for these rules were generated by the TreeTagger [50] and the parse trees by the Stanford Parser [51]. In addition, for the language pairs involving German KIT applied the different reorderings of both language pairs using a lexicalized reordering model. The phrase tables of the systems were trained using GIZA++ alignment [52]. KIT adapted the phrase table to the TED domain using the backoff approach and by means of candidate selection [53]. In addition to the phrase table probabilities, KIT modeled the translation process by a bilingual language model [54] and a discriminative word lexicon using source context features [55]. During decoding, KIT used several LMs to adapt the system to the task and to better model the sentence structure using a class-based LM. For the German→English task, KIT used one LM trained on all data, an in-domain LM trained only on the WIT3 corpus, and one LM trained on 5M sentences selected using cross-entropy difference [13]. As classes KIT used the clusters obtained using the mkcls algorithm on the WIT3 corpus. For German↔ English, KIT used a 9-gram LM with 100 or 1000 clusters and for the English→French MT task, a cl"
2014.iwslt-evaluation.7,W13-2264,1,0.835602,"ed by the TreeTagger [50] and the parse trees by the Stanford Parser [51]. In addition, for the language pairs involving German KIT applied the different reorderings of both language pairs using a lexicalized reordering model. The phrase tables of the systems were trained using GIZA++ alignment [52]. KIT adapted the phrase table to the TED domain using the backoff approach and by means of candidate selection [53]. In addition to the phrase table probabilities, KIT modeled the translation process by a bilingual language model [54] and a discriminative word lexicon using source context features [55]. During decoding, KIT used several LMs to adapt the system to the task and to better model the sentence structure using a class-based LM. For the German→English task, KIT used one LM trained on all data, an in-domain LM trained only on the WIT3 corpus, and one LM trained on 5M sentences selected using cross-entropy difference [13]. As classes KIT used the clusters obtained using the mkcls algorithm on the WIT3 corpus. For German↔ English, KIT used a 9-gram LM with 100 or 1000 clusters and for the English→French MT task, a cluster-based 4-gram LM was trained on 500 clusters. For English→German"
2014.iwslt-evaluation.7,2012.eamt-1.60,1,0.892622,"Missing"
2014.iwslt-evaluation.7,D11-1033,0,0.167316,"Missing"
2014.iwslt-evaluation.7,W05-0909,0,0.085167,"m multiple hypotheses which are outputs of different translation engines. The consensus translations can be better in terms of translation quality than any of the individual hypotheses. To combine the engines of the project partners for the EU-BRIDGE joint setups, we applied a system combination implementation that has been developed at RWTH Aachen University [1]. In Fig. 1 an overview is illustrated. We first address the generation of a confusion network (CN) from I input translations. For that we need a pairwise alignment between all input hypotheses. This alignment is calculated via METEOR [60]. The hypotheses are then reordered to match the word order of a selected skeleton hypothesis. Instead of using only one of the input hypothesis as skeleton, we generate I different CNs, each having one of the input systems as skeleton. The final lattice is the union of all I previous generated CNs. In Fig. 2 an example confusion network of I = 4 input translations with one skeleton translation is illustrated. Between two adjacent nodes, we always have a choice between the I different system output words. The confusion network decoding step involves determining the shortest path through the ne"
2014.iwslt-evaluation.7,2006.amta-papers.25,0,0.0356913,"andard set of models is a word penalty, a 3-gram language model trained on the input hypotheses, and for each system one binary voting feature. During decoding the binary voting feature for system i (1 ≤ i ≤ I) is 1 iff the word is from system i, otherwise 0. The M different model weights λm are trained with MERT [8]. the red cab the a a red blue green train car car Figure 2: System A: the red cab ; System B: the red train ; System C: a blue car ; System D: a green car ; Reference: the blue car . 7. Results In this section, we present our experimental results. All reported B LEU [34] and T ER [61] scores are case-sensitive with one reference. All system combination results have been generated with RWTH’s open source system combination implementation Jane [1]. German→English SLT For the German→English SLT task, we combined three different individual systems generated by UEDIN, KIT, and RWTH. Experimental results are given in Table 1. The final system combination yields improvements of 1.5 points in B LEU and 1.2 points in T ER compared to the best single system (KIT). All single systems as well as the system combination parameters were tuned on dev2012. For this year’s IWSLT SLT track,"
2014.iwslt-evaluation.7,E06-1005,1,\N,Missing
2014.iwslt-evaluation.7,P11-1105,1,\N,Missing
2014.iwslt-evaluation.7,W10-1711,1,\N,Missing
2014.iwslt-evaluation.7,2010.iwslt-evaluation.22,1,\N,Missing
2014.iwslt-evaluation.7,E14-2008,1,\N,Missing
2014.iwslt-evaluation.7,2014.iwslt-evaluation.6,1,\N,Missing
2014.iwslt-evaluation.7,J03-1002,1,\N,Missing
2014.iwslt-evaluation.7,C12-3061,1,\N,Missing
2014.iwslt-evaluation.7,2013.iwslt-evaluation.16,1,\N,Missing
2014.iwslt-evaluation.7,W14-3310,1,\N,Missing
2020.aacl-main.25,D19-1079,0,0.535586,"l confidence penalty, and we leave it for future work. STN CFD (3) 3.1 Generalized Formula In an effort to obtain a unified view, we propose a simple generalized formula and make two major changes. First, we separate the outer summation over the tokens and divide it into two summations, namely “not to smooth” and “to smooth”. Second, we modify the prior distribution to allow it to depend on the position, current token and model output. In this case, r could be the posterior from some helper model (e.g. an LM), and during training, obtaining it on-the-fly is not expensive, as previously shown (Bi et al., 2019; Wang et al., 2019). The generalized label smoothing (GNR) loss can be expressed as: 214 GNR L =− V XX pv log qv − n∈A v=1 V XX n∈B v=1 ((1 − m)pv + mrv,qv ) log qv (5) where LGNR denotes the generalized cross entropy, A is the set of tokens not to smooth, B is the set of tokens to smooth, rv,qv is an arbitrary prior distribution for smoothing and again we drop the dependencies of pv , qv and rv,qv on n for simplicity. A natural question when explicitly writing out A and B, s.t. A ∩ B = ∅ and |A ∪ B |= N , is which tokens to include in B. Here, we consider two simple ideas: uniform random sam"
2020.aacl-main.25,P96-1041,0,0.619097,"e field of NMT. Since the introduction of BERT (Devlin et al., 2019), the Transformer model (Vaswani et al., 2017) becomes the de facto architectural choice for many competitive NLP systems. Among the numerous ingredients that make Transformer networks successful, label smoothing is one that must not be overlooked and shall be the focus of this work. The idea of smoothing is not new in itself. For instance, many smoothing heuristics and functions are investigated in the context of count-based language modeling (Jelinek and Mercer, 1980; Katz, 1987; Church and Gale, 1991; Kneser and Ney, 1995; Chen and Goodman, 1996). Interestingly, when training NNs, the idea of smoothing comes in a new form and is applied on the empirical one-hot target distributions. Proposed to counteract overfitting and pursue better generalization, label smoothing (Szegedy et al., 2016) finds its first applications in NNs in the field of computer vision. Later, the method is shown to be effective in MT (Vaswani et al., 2017). Furthermore, it is also helpful when applied in other scenarios, e.g. Generative Adversarial Networks (GANs) (Salimans et al., 2016), automatic speech recognition (Chiu et al., 2018), and person re-identificati"
2020.aacl-main.25,D18-1045,0,0.0289223,"tention mechanism (Bahdanau et al., 2015; Luong et al., 2015), end-to-end sequence learning with attention becomes the dominant design choice for Neural Machine Translation (NMT) models. From the study of convolutional sequence to sequence learning (Gehring et al., 2017a,b), to the prosperity of self-attention networks (Vaswani et al., 2017; Devlin et al., 2019), modern NMT systems, especially Transformer-based ones (Vaswani et al., 2017), often deliver state-of-the-art performances (Bojar et al., 2018; Barrault et al., 2019), even under the condition of large-scale corpora (Ott et al., 2018; Edunov et al., 2018). In Transformer-based models, label smoothing is a widely applied method to improve model performance. Szegedy et al. (2016) initially introduce the method when making refinements to the Inception (Szegedy et al., 2015) model, with the motivation to combat overfitting and improve adaptability. In principle, label smoothing discounts a certain probability mass from the true label and redistributes it uniformly across all the class labels. This lowers the difference between the largest probability output and the others, effectively discouraging the model to generate overly confident predictions"
2020.aacl-main.25,P19-1555,0,0.0207422,"a, as pointed out in Xie et al. (2016). Interestingly, label smoothing can also be understood as estimating the marginalized label dropout during training (Pereyra et al., 2017). In this paper, we propose two straightforward extensions to label smoothing, examining token selection and prior distribution. Salimans et al. (2016) and Zhou et al. (2017) investigate a similar issue to the former. In the context of GANs, they select only those positive examples to smooth while we consider the task of MT, discussing how many tokens to smooth and how they should be selected. Pereyra et al. (2017) and Gao et al. (2019) talk about ideas similar to the latter. In their respective contexts, one experiments with unigram probabilities for label smoothing and the other uses Language Model (LM) posteriors to softly augment the source and target side of MT training data. dependencies of qv and pv on n are omitted for simplicity. Additionally for Equation 1, authors of both papers (Vaswani et al., 2017; Pereyra et al., 2017) point out that the uniform prior can be replaced with alternative distributions over the target vocabulary. One more thing to notice is the negative sign in front of the non-negative term m0 in"
2020.aacl-main.25,P17-1012,0,0.134338,"ical performance of strong neural machine translation systems can be further improved. 1 Introduction In recent years, Neural Network (NN) models bring steady and concrete improvements on the task of Machine Translation (MT). From the introduction of sequence-to-sequence models (Cho et al., 2014; Sutskever et al., 2014a), to the invention of the attention mechanism (Bahdanau et al., 2015; Luong et al., 2015), end-to-end sequence learning with attention becomes the dominant design choice for Neural Machine Translation (NMT) models. From the study of convolutional sequence to sequence learning (Gehring et al., 2017a,b), to the prosperity of self-attention networks (Vaswani et al., 2017; Devlin et al., 2019), modern NMT systems, especially Transformer-based ones (Vaswani et al., 2017), often deliver state-of-the-art performances (Bojar et al., 2018; Barrault et al., 2019), even under the condition of large-scale corpora (Ott et al., 2018; Edunov et al., 2018). In Transformer-based models, label smoothing is a widely applied method to improve model performance. Szegedy et al. (2016) initially introduce the method when making refinements to the Inception (Szegedy et al., 2015) model, with the motivation to"
2020.aacl-main.25,N19-4009,0,0.0278026,"ibuted to each token in the vocabulary. The graph of GRN2 is similar to STD, only changing the limit from V1 to rv as m approaches one, and not included here for brevity. One last thing to notice is that the outer summation over the tokens is ignored. If it is taken into consideration, q˜ is dragged towards the empirical distribution given by the corpus3 . ture (Vaswani et al., 2017), we apply the base setup for IWSLT and the big setup for WMT. For all language pairs, we share all three embedding matrices. All helper models are also Transformer-based. We conduct all experiments using fairseq (Ott et al., 2019), monitor development set perplexity during training, and report BLEU (Papineni et al., 2002) scores on test sets after beam search. 4.1 Finding a Good Recipe In this section, we describe our results and insights towards a good recipe to successfully apply label smoothing. We experiment with six IWSLT2014 datasets: German (de), Spanish (es), Italian (it), Dutch (nl), Romanian (ro), Russian (ru) to English (en), and one WMT2014 dataset: English to German. The statistics of these datasets are summarized in Table 1. To prepare the subword tokens, we adopt joint byte pair encoding (Sennrich et al."
2020.aacl-main.25,W18-6301,0,0.0343454,"nvention of the attention mechanism (Bahdanau et al., 2015; Luong et al., 2015), end-to-end sequence learning with attention becomes the dominant design choice for Neural Machine Translation (NMT) models. From the study of convolutional sequence to sequence learning (Gehring et al., 2017a,b), to the prosperity of self-attention networks (Vaswani et al., 2017; Devlin et al., 2019), modern NMT systems, especially Transformer-based ones (Vaswani et al., 2017), often deliver state-of-the-art performances (Bojar et al., 2018; Barrault et al., 2019), even under the condition of large-scale corpora (Ott et al., 2018; Edunov et al., 2018). In Transformer-based models, label smoothing is a widely applied method to improve model performance. Szegedy et al. (2016) initially introduce the method when making refinements to the Inception (Szegedy et al., 2015) model, with the motivation to combat overfitting and improve adaptability. In principle, label smoothing discounts a certain probability mass from the true label and redistributes it uniformly across all the class labels. This lowers the difference between the largest probability output and the others, effectively discouraging the model to generate overly"
2020.aacl-main.25,D16-1139,0,0.0201295,"39 38.5 38 LM cheating LM normal no smoothing uniform unigram 37.5 37 36.5 1.0 31.0 52.9 100.2 model smoothed with it performs. This is loosely the case for LM, with cheating LMs giving better performances than uniform and unigram, and normal LMs lacking behind. As for MT, improvement over the no smoothing case is seen in Figure 6b. However, neither the downhill trend nor the competence over other priors in terms of BLEU, is seen. This suggests that the model is probably not utilizing the information in the soft distribution effectively. Related to knowledge distillation (Hinton et al., 2015; Kim and Rush, 2016), a trainable teacher (the helper model in our case) might be further beneficial (Bi et al., 2019; Wang et al., 2018). One important thing to mention is that, while neither LM nor MT outperforms uniform or unigram in terms of test BLEU score in our experiments, we see significant drops in development set perplexities when smoothing with LM or MT. This signals a mismatch between training and testing, and suggests that smoothing with LM or MT indeed works well for the optimization criterion, but not as much for the final metric, the calculation of which involves beam search and scoring of the di"
2020.aacl-main.25,P02-1040,0,0.106991,"ng the limit from V1 to rv as m approaches one, and not included here for brevity. One last thing to notice is that the outer summation over the tokens is ignored. If it is taken into consideration, q˜ is dragged towards the empirical distribution given by the corpus3 . ture (Vaswani et al., 2017), we apply the base setup for IWSLT and the big setup for WMT. For all language pairs, we share all three embedding matrices. All helper models are also Transformer-based. We conduct all experiments using fairseq (Ott et al., 2019), monitor development set perplexity during training, and report BLEU (Papineni et al., 2002) scores on test sets after beam search. 4.1 Finding a Good Recipe In this section, we describe our results and insights towards a good recipe to successfully apply label smoothing. We experiment with six IWSLT2014 datasets: German (de), Spanish (es), Italian (it), Dutch (nl), Romanian (ro), Russian (ru) to English (en), and one WMT2014 dataset: English to German. The statistics of these datasets are summarized in Table 1. To prepare the subword tokens, we adopt joint byte pair encoding (Sennrich et al., 2016), and use 10K and 32K merge operations on IWSLT and WMT, respectively. When preprocess"
2020.aacl-main.25,P06-2093,0,0.0736035,"rocess and show an empirically good recipe to apply label smoothing. • Finally, we examine the implications in search and scoring and motivate further research into the mismatch between training and testing. 2 Related Work The extensive use of NNs in MT (Bojar et al., 2016, 2017, 2018; Barrault et al., 2019) is a result of many pioneering and inspiring works. Continuousvalued word vectors lay the foundation of modern Natural Language Processing (NLP) NNs, capturing semantic and syntactic relations and providing numerical ways to calculate meaningful distances among words (Bengio et al., 2001; Schwenk et al., 2006; Schwenk, 2007; Sundermeyer et al., 2012; Mikolov et al., 2013a,b). The investigations of sequence-to-sequence learning (Cho et al., 2014; Sutskever et al., 2014b), the studies of attention mechanism (Bahdanau et al., 2015; Luong et al., 2015) and the explorations into convolutional and self-attention NNs (Gehring et al., 2017a,b; Vaswani et al., 2017) mark steady and important steps in the field of NMT. Since the introduction of BERT (Devlin et al., 2019), the Transformer model (Vaswani et al., 2017) becomes the de facto architectural choice for many competitive NLP systems. Among the numero"
2020.aacl-main.25,P16-1162,0,0.166899,"Missing"
2020.aacl-main.25,D19-1331,0,0.0218287,"f numbers corresponds to using only the cross entropy criterion for training. The second row of numbers corresponds to the Transformer baselines. The last row contains scores obtained with our best hyperparameters. 35 41.5 test BLEU BLEU 41 34 no smoothing uniform, m = 0.1 unigram, m = 0.3 LM, m = 0.3 33 32 1 2 3 4 5 6 7 40.5 40 39.5 8 9 39 41 10 data fitted curve 41.5 42 beam size 42.5 43 (a) Dev BLEU is a good proxy for test BLEU. Figure 7: BLEU versus beam size on de-en. 41.5 data fitted curve in Zhou et al. (2019)). However, the solid curve for LM drops quickly as beam size increases (see Stahlberg and Byrne (2019) for more insight). A possible explanation is that models smoothed with LMs generate search spaces that are richer in probability variations and more diversified, compared to e.g. uniform label smoothing. As search becomes stronger, hypotheses that have higher probabilities, but not necessarily closer to the true targets, are found. This suggests that the mismatch in development set perplexity and test BLEU is a complex phenomenon and calls for more analysis. test BLEU 41 5.2 43.5 dev BLEU We further examine test BLEU with respect to development (dev) BLEU and dev perplexity. As shown in Figur"
2020.aacl-main.25,D19-1073,0,0.0200757,"lty, and we leave it for future work. STN CFD (3) 3.1 Generalized Formula In an effort to obtain a unified view, we propose a simple generalized formula and make two major changes. First, we separate the outer summation over the tokens and divide it into two summations, namely “not to smooth” and “to smooth”. Second, we modify the prior distribution to allow it to depend on the position, current token and model output. In this case, r could be the posterior from some helper model (e.g. an LM), and during training, obtaining it on-the-fly is not expensive, as previously shown (Bi et al., 2019; Wang et al., 2019). The generalized label smoothing (GNR) loss can be expressed as: 214 GNR L =− V XX pv log qv − n∈A v=1 V XX n∈B v=1 ((1 − m)pv + mrv,qv ) log qv (5) where LGNR denotes the generalized cross entropy, A is the set of tokens not to smooth, B is the set of tokens to smooth, rv,qv is an arbitrary prior distribution for smoothing and again we drop the dependencies of pv , qv and rv,qv on n for simplicity. A natural question when explicitly writing out A and B, s.t. A ∩ B = ∅ and |A ∪ B |= N , is which tokens to include in B. Here, we consider two simple ideas: uniform random sampling (RND) and an e"
2020.aacl-main.25,Q19-1006,0,0.0200286,"2: BLEU scores can be significantly improved with good label smoothing recipes. The first row of numbers corresponds to using only the cross entropy criterion for training. The second row of numbers corresponds to the Transformer baselines. The last row contains scores obtained with our best hyperparameters. 35 41.5 test BLEU BLEU 41 34 no smoothing uniform, m = 0.1 unigram, m = 0.3 LM, m = 0.3 33 32 1 2 3 4 5 6 7 40.5 40 39.5 8 9 39 41 10 data fitted curve 41.5 42 beam size 42.5 43 (a) Dev BLEU is a good proxy for test BLEU. Figure 7: BLEU versus beam size on de-en. 41.5 data fitted curve in Zhou et al. (2019)). However, the solid curve for LM drops quickly as beam size increases (see Stahlberg and Byrne (2019) for more insight). A possible explanation is that models smoothed with LMs generate search spaces that are richer in probability variations and more diversified, compared to e.g. uniform label smoothing. As search becomes stronger, hypotheses that have higher probabilities, but not necessarily closer to the true targets, are found. This suggests that the mismatch in development set perplexity and test BLEU is a complex phenomenon and calls for more analysis. test BLEU 41 5.2 43.5 dev BLEU We"
2020.aacl-main.41,W19-5301,0,0.0386389,"Missing"
2020.aacl-main.41,2014.iwslt-evaluation.1,0,0.118611,"Missing"
2020.aacl-main.41,W17-4123,0,0.0252752,"as an alternative to the length normalization as described in Section 3.3. “len. ratio” gives the length ratio between the hypothesis length and the reference length: the closer to 1, the better. predict target length well and further improve translation quality. In addition, the predicted length can be used to replace the length normalization with a better and more mathematically explainable control of the output length. For future work, the use of length prediction in positional encoding (Lakew et al., 2019; Takase and Okazaki, 2019) and nonautoregressive (or partially autoregressive) NMT (Gu et al., 2017; Lee et al., 2018; Stern et al., 2019) could be further investigated. Acknowledgements Figure 3: Length prediction model outperforms the baseline model in length prediction test accuracy. Figure 3 shows the relationship between the length prediction accuracy of the baseline model and the length prediction model, and the threshold T for calculating accuracy. Since the transformer baseline model does not predict the target length, the length prediction of baseline is obtained from the average ratio of source sentence length to target sentence length. For the length prediction task, the accuracy"
2020.aacl-main.41,E17-1005,0,0.0291165,"timated length information can either be implicitly included in the network to “guide” translation, or it can be used explicitly as an alternative to length normalization during decoding. The experimental results on various datasets show that the proposed system achieves improvements compared to the baseline model and the predicted length can easily be used to replace the length normalization. (1) 2 Related Work Multi-task learning is an important training strategy that aims to improve the generalization performance of the main task with some other related tasks (Luong et al., 2016; Mart´ınez Alonso and Plank, 2017). With regard to deep learning, multitask learning is applied successfully in many areas, such as natural language processing (Liu et al., 2015), computer vision (Donahue et al., 2014), and speech processing (Heigold et al., 2013). In this work, the prediction of the target length while generating translation hypotheses can be seen as a 389 Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing, pages 389–395 c December 4 - 7, 2020. 2020 Association for Computation"
2020.aacl-main.41,W18-6322,0,0.0141653,"ng is applied successfully in many areas, such as natural language processing (Liu et al., 2015), computer vision (Donahue et al., 2014), and speech processing (Heigold et al., 2013). In this work, the prediction of the target length while generating translation hypotheses can be seen as a 389 Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing, pages 389–395 c December 4 - 7, 2020. 2020 Association for Computational Linguistics multi-task learning application. Murray and Chiang (2018) and Stahlberg and Byrne (2019) attribute the fact that beam search prefers shorter candidates due to the local normalization of NMT. To address this problem, in addition to the standard length normalization technique, Wu et al. (2016) propose a more complicated correction with a hyperparameter that can be adjusted for different language pairs. In He et al. (2016), a word reward function is proposed that simulates the coverage vector in statistical machine translation so that the decoder prefers a long translation. Huang et al. (2017) and Yang et al. (2018) suggest variations of this reward th"
2020.aacl-main.41,D17-1227,0,0.028288,"utational Linguistics multi-task learning application. Murray and Chiang (2018) and Stahlberg and Byrne (2019) attribute the fact that beam search prefers shorter candidates due to the local normalization of NMT. To address this problem, in addition to the standard length normalization technique, Wu et al. (2016) propose a more complicated correction with a hyperparameter that can be adjusted for different language pairs. In He et al. (2016), a word reward function is proposed that simulates the coverage vector in statistical machine translation so that the decoder prefers a long translation. Huang et al. (2017) and Yang et al. (2018) suggest variations of this reward that provide better guarantees during search. There are also works on target vocabulary prediction in the encoder-decoder model that implicitly predicts the target length (Weng et al., 2017; Suzuki and Nagata, 2017). In our work, the target length is explicitly modeled by the neural network itself, which indicates that the entire system relies more on statistics rather than heuristics. 3 Neural Length Model To predict the target length based on the standard transformer architecture (Vaswani et al., 2017), we build a multi-layer sub-netw"
2020.aacl-main.41,N19-4009,0,0.0736513,"Missing"
2020.aacl-main.41,P02-1040,0,0.106117,"Missing"
2020.aacl-main.41,W18-6319,0,0.0334368,"Missing"
2020.aacl-main.41,D18-1149,0,0.0226979,"e to the length normalization as described in Section 3.3. “len. ratio” gives the length ratio between the hypothesis length and the reference length: the closer to 1, the better. predict target length well and further improve translation quality. In addition, the predicted length can be used to replace the length normalization with a better and more mathematically explainable control of the output length. For future work, the use of length prediction in positional encoding (Lakew et al., 2019; Takase and Okazaki, 2019) and nonautoregressive (or partially autoregressive) NMT (Gu et al., 2017; Lee et al., 2018; Stern et al., 2019) could be further investigated. Acknowledgements Figure 3: Length prediction model outperforms the baseline model in length prediction test accuracy. Figure 3 shows the relationship between the length prediction accuracy of the baseline model and the length prediction model, and the threshold T for calculating accuracy. Since the transformer baseline model does not predict the target length, the length prediction of baseline is obtained from the average ratio of source sentence length to target sentence length. For the length prediction task, the accuracy of our model is a"
2020.aacl-main.41,D19-1331,0,0.199604,"many areas, such as natural language processing (Liu et al., 2015), computer vision (Donahue et al., 2014), and speech processing (Heigold et al., 2013). In this work, the prediction of the target length while generating translation hypotheses can be seen as a 389 Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing, pages 389–395 c December 4 - 7, 2020. 2020 Association for Computational Linguistics multi-task learning application. Murray and Chiang (2018) and Stahlberg and Byrne (2019) attribute the fact that beam search prefers shorter candidates due to the local normalization of NMT. To address this problem, in addition to the standard length normalization technique, Wu et al. (2016) propose a more complicated correction with a hyperparameter that can be adjusted for different language pairs. In He et al. (2016), a word reward function is proposed that simulates the coverage vector in statistical machine translation so that the decoder prefers a long translation. Huang et al. (2017) and Yang et al. (2018) suggest variations of this reward that provide better guarantees du"
2020.aacl-main.41,N15-1092,0,0.0263353,"length normalization during decoding. The experimental results on various datasets show that the proposed system achieves improvements compared to the baseline model and the predicted length can easily be used to replace the length normalization. (1) 2 Related Work Multi-task learning is an important training strategy that aims to improve the generalization performance of the main task with some other related tasks (Luong et al., 2016; Mart´ınez Alonso and Plank, 2017). With regard to deep learning, multitask learning is applied successfully in many areas, such as natural language processing (Liu et al., 2015), computer vision (Donahue et al., 2014), and speech processing (Heigold et al., 2013). In this work, the prediction of the target length while generating translation hypotheses can be seen as a 389 Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing, pages 389–395 c December 4 - 7, 2020. 2020 Association for Computational Linguistics multi-task learning application. Murray and Chiang (2018) and Stahlberg and Byrne (2019) attribute the fact that beam search pref"
2020.aacl-main.41,E17-2047,0,0.0282066,"ngth normalization technique, Wu et al. (2016) propose a more complicated correction with a hyperparameter that can be adjusted for different language pairs. In He et al. (2016), a word reward function is proposed that simulates the coverage vector in statistical machine translation so that the decoder prefers a long translation. Huang et al. (2017) and Yang et al. (2018) suggest variations of this reward that provide better guarantees during search. There are also works on target vocabulary prediction in the encoder-decoder model that implicitly predicts the target length (Weng et al., 2017; Suzuki and Nagata, 2017). In our work, the target length is explicitly modeled by the neural network itself, which indicates that the entire system relies more on statistics rather than heuristics. 3 Neural Length Model To predict the target length based on the standard transformer architecture (Vaswani et al., 2017), we build a multi-layer sub-network that only requires information from the source sequence (or the encoder). In this work the length prediction task is considered as a classification task for different lengths. Other methods, such as directly generating a real number, binarizing the length, or performin"
2020.aacl-main.41,N19-1401,0,0.0184609,"e. “- len. normalization” denotes that the predicted length is used during decoding as an alternative to the length normalization as described in Section 3.3. “len. ratio” gives the length ratio between the hypothesis length and the reference length: the closer to 1, the better. predict target length well and further improve translation quality. In addition, the predicted length can be used to replace the length normalization with a better and more mathematically explainable control of the output length. For future work, the use of length prediction in positional encoding (Lakew et al., 2019; Takase and Okazaki, 2019) and nonautoregressive (or partially autoregressive) NMT (Gu et al., 2017; Lee et al., 2018; Stern et al., 2019) could be further investigated. Acknowledgements Figure 3: Length prediction model outperforms the baseline model in length prediction test accuracy. Figure 3 shows the relationship between the length prediction accuracy of the baseline model and the length prediction model, and the threshold T for calculating accuracy. Since the transformer baseline model does not predict the target length, the length prediction of baseline is obtained from the average ratio of source sentence lengt"
2020.aacl-main.41,W16-2342,1,0.676687,"Missing"
2020.aacl-main.41,D17-1013,0,0.0191499,"to the standard length normalization technique, Wu et al. (2016) propose a more complicated correction with a hyperparameter that can be adjusted for different language pairs. In He et al. (2016), a word reward function is proposed that simulates the coverage vector in statistical machine translation so that the decoder prefers a long translation. Huang et al. (2017) and Yang et al. (2018) suggest variations of this reward that provide better guarantees during search. There are also works on target vocabulary prediction in the encoder-decoder model that implicitly predicts the target length (Weng et al., 2017; Suzuki and Nagata, 2017). In our work, the target length is explicitly modeled by the neural network itself, which indicates that the entire system relies more on statistics rather than heuristics. 3 Neural Length Model To predict the target length based on the standard transformer architecture (Vaswani et al., 2017), we build a multi-layer sub-network that only requires information from the source sequence (or the encoder). In this work the length prediction task is considered as a classification task for different lengths. Other methods, such as directly generating a real number, binarizin"
2020.aacl-main.41,D18-1342,0,0.365533,"Missing"
2020.amta-research.2,W18-6318,1,0.834794,"et al. (2016) apply explicit hard alignments to generate a translation using a maximum approximation. Alkhouli and Ney (2017) compute attention weights using pre-defined alignments to bias soft attention toward hard alignments. Yang et al. (2013) use lexical and alignment models, where alignments have no dependence on the lexical context. Tamura et al. (2014) also introduce a lexicalized neural alignment model to generate word alignments for the phrase-based translation system. In this work, we use neither pre-computed alignments nor a phrase table. As an extension to neural alignment models, Alkhouli et al. (2018) use the transformer architecture to train both alignment and lexicon models while augmenting the multi-head attention component with additional hard alignment information. In their work, they train two separate networks and combine them in decoding with a maximum approximation. In contrast, we train a single network and sum over source positions. Inspired by the success of statistical alignment models, Tu et al. (2016); Cohn et al. (2016) propose fertility and coverage concepts by including dependence on previous attention weights. Zenkel et al. (2019) try to gain high quality alignments by r"
2020.amta-research.2,W16-2206,1,0.910877,"incorporate it as a key interpretation component into our work. From the statistical perspective, we revisit the formulation of the posterior probability of a given sentence by computing a separate translation score for every target-source word pair. Since marginalization is exponential in the order of the model, we only explore a zero-order assumption, i.e. there is no dependence between subsequent alignments. The marginalization over the latent variable becomes simple and efficient for zero-order models and can be easily applied in both training and decoding. Unlike higher order dependence (Alkhouli et al., 2016, 2018; Wang et al., 2018), no dynamic programming and no search for the alignment path is required, thus a simple beam search decoder is used. We also address the theoretical connection between our approach and IBM model 2 (Brown et al., 1993). Tackling the costly computation of the softmax for all source positions, we employ an approximation by taking the topK relevant positions. To the best of our knowledge, this work explores the first instance of a zero-order latent variable alignments using the transformer architecture in an end-to-end fashion for machine translation. 2 Related Works Sim"
2020.amta-research.2,W17-4711,1,0.88366,"mely the alignment and lexicon models. Unlike (Wang et al., 2018, 2017) where they use two separate networks, one for the alignment and one for the lexicon model and they need to jointly train two networks batch-wise, our work is still a single network trained end-to-end similar to the transformer model. Due to first-order dependence, Wang et al. (2018) also apply the forward-backward algorithm to compute the posterior probabilities as true labels, which is not required in our model. Alkhouli et al. (2016) apply explicit hard alignments to generate a translation using a maximum approximation. Alkhouli and Ney (2017) compute attention weights using pre-defined alignments to bias soft attention toward hard alignments. Yang et al. (2013) use lexical and alignment models, where alignments have no dependence on the lexical context. Tamura et al. (2014) also introduce a lexicalized neural alignment model to generate word alignments for the phrase-based translation system. In this work, we use neither pre-computed alignments nor a phrase table. As an extension to neural alignment models, Alkhouli et al. (2018) use the transformer architecture to train both alignment and lexicon models while augmenting the multi"
2020.amta-research.2,J93-2003,0,0.113184,"air. Since marginalization is exponential in the order of the model, we only explore a zero-order assumption, i.e. there is no dependence between subsequent alignments. The marginalization over the latent variable becomes simple and efficient for zero-order models and can be easily applied in both training and decoding. Unlike higher order dependence (Alkhouli et al., 2016, 2018; Wang et al., 2018), no dynamic programming and no search for the alignment path is required, thus a simple beam search decoder is used. We also address the theoretical connection between our approach and IBM model 2 (Brown et al., 1993). Tackling the costly computation of the softmax for all source positions, we employ an approximation by taking the topK relevant positions. To the best of our knowledge, this work explores the first instance of a zero-order latent variable alignments using the transformer architecture in an end-to-end fashion for machine translation. 2 Related Works Similar to IBM and HMM alignments (Brown et al., 1993; Vogel et al., 1996), there are standalone neural approaches based on introducing word alignments as hidden variables, such that either a full sum over the alignment path or a maximum approxima"
2020.amta-research.2,2016.amta-researchers.10,0,0.0136906,"statistical alignment models, Tu et al. (2016); Cohn et al. (2016) propose fertility and coverage concepts by including dependence on previous attention weights. Zenkel et al. (2019) try to gain high quality alignments by recomputing the attention heads after each target word prediction. Peter et al. (2017); Li et al. (2018) employ the full target context to improve alignment accuracy. Given statistical alignments obtained from Giza++ toolkit (Och and Ney, 2003), there are some methods in which the soft attention weights are supervised to behave similarly to the conventional hard alignments. Chen et al. (2016); Mi et al. (2016); Liu et al. (2016); Garg et al. (2019) add an additional training objective term that is dependent on the pre-computed alignments like Giza++ to guide neural models in training. Instead of an objective function, Alkhouli and Ney (2017) modify the attention energy Proceedings of the 14th Conference of the Association for Machine Translation in the Americas October 6 - 9, 2020, Volume 1: MT Research Track Page 8 computation directly to have dependence on the Giza++ alignment and perform beam search over both the lexical and alignment hypotheses. Unlike the aforementioned metho"
2020.amta-research.2,N16-1102,0,0.0170411,"he phrase-based translation system. In this work, we use neither pre-computed alignments nor a phrase table. As an extension to neural alignment models, Alkhouli et al. (2018) use the transformer architecture to train both alignment and lexicon models while augmenting the multi-head attention component with additional hard alignment information. In their work, they train two separate networks and combine them in decoding with a maximum approximation. In contrast, we train a single network and sum over source positions. Inspired by the success of statistical alignment models, Tu et al. (2016); Cohn et al. (2016) propose fertility and coverage concepts by including dependence on previous attention weights. Zenkel et al. (2019) try to gain high quality alignments by recomputing the attention heads after each target word prediction. Peter et al. (2017); Li et al. (2018) employ the full target context to improve alignment accuracy. Given statistical alignments obtained from Giza++ toolkit (Och and Ney, 2003), there are some methods in which the soft attention weights are supervised to behave similarly to the conventional hard alignments. Chen et al. (2016); Mi et al. (2016); Liu et al. (2016); Garg et al"
2020.amta-research.2,D19-1453,0,0.0857352,"n the transformer architecture such that the translation posterior distribution has a direct dependency on the source positions. • as to the interest in alignment based approaches, we intend to investigate whether the latent-based models are able to tackle the explainability problem of alignments especially Proceedings of the 14th Conference of the Association for Machine Translation in the Americas October 6 - 9, 2020, Volume 1: MT Research Track Page 7 for the transformer model. Similar to how some approaches in explainable NMT use the attention (Stahlberg et al., 2018; Zenkel et al., 2019; Garg et al., 2019), we also incorporate it as a key interpretation component into our work. From the statistical perspective, we revisit the formulation of the posterior probability of a given sentence by computing a separate translation score for every target-source word pair. Since marginalization is exponential in the order of the model, we only explore a zero-order assumption, i.e. there is no dependence between subsequent alignments. The marginalization over the latent variable becomes simple and efficient for zero-order models and can be easily applied in both training and decoding. Unlike higher order de"
2020.amta-research.2,P07-2045,0,0.0110399,"n (10) Once we compute the lexicon and alignment probabilities, we sum over j positions as stated in Equation 6 with topK approximation. The model has almost the same number of parameters as our transformer baseline. A visualization of model architecture can be seen in Figure 1. 6 Experiments We carry out the experiments on four WMT 2018 translation tasks1 : German↔English and Chinese↔English. The corpora statistics are shown in Table 1. We do not employ any kind of synthetic or back-translated data in this work. For German↔English, after tokenization and true-casing using the Moses toolkit (Koehn et al., 2007), we apply byte pair encoding (BPE) (Sennrich et al., 2016) with 50k merge operations. We use the original parallel data consisting of 5.9M sentence pairs (see Table 1). For Chinese↔English, we apply sentence pieces model (SPM) (Kudo, 2018) with an n-best size of 30 and 32k merge operations. The original bilingual data consists of almost 26M samples. We filter out the noisy data by removing illegal characters and duplication, hence we end up with 14M pairs. For De↔En and Zh↔En, we use the newstest2015 and the newsdev2017 as the development set respectively and the newstest2017 and newstest2018"
2020.amta-research.2,W17-3204,0,0.116247,"r interpretability. 1 Introduction Current state-of-the-art neural machine translation (NMT) systems are based on attention models (Bahdanau et al., 2015; Luong et al., 2015; Gehring et al., 2017; Vaswani et al., 2017), where “soft attention” is used to focus on the most relevant parts of the source sequence while generating target words. This distribution can be considered as an implicit probabilistic notion of alignment as an intermediate step of the translation model. However, it does not work in the same way as its analogous alignment in conventional statistical machine translation (SMT) (Koehn and Knowles, 2017). Contrary to SMT, where a “hard alignment” is a transparent process that defines the correspondence between source and target words, it is often challenging for the fuzzy attention mechanism to extract a comprehensible alignment. Although the context vector, a weighted sum of the input states, includes the alignment information implicitly, the alignment model does not directly influence the final translation probability of a sentence. Hence, it is often hard to determine the contribution of the attention on the output. In this work, • we incorporate the attention model into the direct hidden"
2020.amta-research.2,P18-1007,0,0.0183471,"tecture can be seen in Figure 1. 6 Experiments We carry out the experiments on four WMT 2018 translation tasks1 : German↔English and Chinese↔English. The corpora statistics are shown in Table 1. We do not employ any kind of synthetic or back-translated data in this work. For German↔English, after tokenization and true-casing using the Moses toolkit (Koehn et al., 2007), we apply byte pair encoding (BPE) (Sennrich et al., 2016) with 50k merge operations. We use the original parallel data consisting of 5.9M sentence pairs (see Table 1). For Chinese↔English, we apply sentence pieces model (SPM) (Kudo, 2018) with an n-best size of 30 and 32k merge operations. The original bilingual data consists of almost 26M samples. We filter out the noisy data by removing illegal characters and duplication, hence we end up with 14M pairs. For De↔En and Zh↔En, we use the newstest2015 and the newsdev2017 as the development set respectively and the newstest2017 and newstest2018 as our test sets. The models are evaluated using case-sensitive B LEU (Papineni et al., 2002) computed by the official scripts of WMT campaign, i.e. mteval-v13a2 and case-sensitive normalized T ER (Snover et al., 2006) computed by tercom3"
2020.amta-research.2,N18-1125,0,0.0203177,"enting the multi-head attention component with additional hard alignment information. In their work, they train two separate networks and combine them in decoding with a maximum approximation. In contrast, we train a single network and sum over source positions. Inspired by the success of statistical alignment models, Tu et al. (2016); Cohn et al. (2016) propose fertility and coverage concepts by including dependence on previous attention weights. Zenkel et al. (2019) try to gain high quality alignments by recomputing the attention heads after each target word prediction. Peter et al. (2017); Li et al. (2018) employ the full target context to improve alignment accuracy. Given statistical alignments obtained from Giza++ toolkit (Och and Ney, 2003), there are some methods in which the soft attention weights are supervised to behave similarly to the conventional hard alignments. Chen et al. (2016); Mi et al. (2016); Liu et al. (2016); Garg et al. (2019) add an additional training objective term that is dependent on the pre-computed alignments like Giza++ to guide neural models in training. Instead of an objective function, Alkhouli and Ney (2017) modify the attention energy Proceedings of the 14th Co"
2020.amta-research.2,C16-1291,0,0.0214592,"l. (2016); Cohn et al. (2016) propose fertility and coverage concepts by including dependence on previous attention weights. Zenkel et al. (2019) try to gain high quality alignments by recomputing the attention heads after each target word prediction. Peter et al. (2017); Li et al. (2018) employ the full target context to improve alignment accuracy. Given statistical alignments obtained from Giza++ toolkit (Och and Ney, 2003), there are some methods in which the soft attention weights are supervised to behave similarly to the conventional hard alignments. Chen et al. (2016); Mi et al. (2016); Liu et al. (2016); Garg et al. (2019) add an additional training objective term that is dependent on the pre-computed alignments like Giza++ to guide neural models in training. Instead of an objective function, Alkhouli and Ney (2017) modify the attention energy Proceedings of the 14th Conference of the Association for Machine Translation in the Americas October 6 - 9, 2020, Volume 1: MT Research Track Page 8 computation directly to have dependence on the Giza++ alignment and perform beam search over both the lexical and alignment hypotheses. Unlike the aforementioned methods, our approach does not require any"
2020.amta-research.2,D15-1166,0,0.04796,"ignments. We show that the alignment quality in transformer models can be improved by introducing a latent variable for the alignments. To study the effect of the latent model, we quantitatively and qualitatively analyze the extracted alignments from the multi-head attention. We demonstrate that this method slightly improves translation quality on four WMT 2018 shared translation tasks, as well as generating more focused alignments for better interpretability. 1 Introduction Current state-of-the-art neural machine translation (NMT) systems are based on attention models (Bahdanau et al., 2015; Luong et al., 2015; Gehring et al., 2017; Vaswani et al., 2017), where “soft attention” is used to focus on the most relevant parts of the source sequence while generating target words. This distribution can be considered as an implicit probabilistic notion of alignment as an intermediate step of the translation model. However, it does not work in the same way as its analogous alignment in conventional statistical machine translation (SMT) (Koehn and Knowles, 2017). Contrary to SMT, where a “hard alignment” is a transparent process that defines the correspondence between source and target words, it is often cha"
2020.amta-research.2,J03-1002,1,0.0473408,"combine them in decoding with a maximum approximation. In contrast, we train a single network and sum over source positions. Inspired by the success of statistical alignment models, Tu et al. (2016); Cohn et al. (2016) propose fertility and coverage concepts by including dependence on previous attention weights. Zenkel et al. (2019) try to gain high quality alignments by recomputing the attention heads after each target word prediction. Peter et al. (2017); Li et al. (2018) employ the full target context to improve alignment accuracy. Given statistical alignments obtained from Giza++ toolkit (Och and Ney, 2003), there are some methods in which the soft attention weights are supervised to behave similarly to the conventional hard alignments. Chen et al. (2016); Mi et al. (2016); Liu et al. (2016); Garg et al. (2019) add an additional training objective term that is dependent on the pre-computed alignments like Giza++ to guide neural models in training. Instead of an objective function, Alkhouli and Ney (2017) modify the attention energy Proceedings of the 14th Conference of the Association for Machine Translation in the Americas October 6 - 9, 2020, Volume 1: MT Research Track Page 8 computation dire"
2020.amta-research.2,P02-1040,0,0.107464,"ge operations. We use the original parallel data consisting of 5.9M sentence pairs (see Table 1). For Chinese↔English, we apply sentence pieces model (SPM) (Kudo, 2018) with an n-best size of 30 and 32k merge operations. The original bilingual data consists of almost 26M samples. We filter out the noisy data by removing illegal characters and duplication, hence we end up with 14M pairs. For De↔En and Zh↔En, we use the newstest2015 and the newsdev2017 as the development set respectively and the newstest2017 and newstest2018 as our test sets. The models are evaluated using case-sensitive B LEU (Papineni et al., 2002) computed by the official scripts of WMT campaign, i.e. mteval-v13a2 and case-sensitive normalized T ER (Snover et al., 2006) computed by tercom3 . For our experiments, we train both the transformer and the RNN attention models. We follow a base transformer similar to (Vaswani et al., 2017) where we use 6 layers in both the 1 http://statmt.org/wmt18/ 2 ftp://jaguar.ncsl.nist.gov/mt/resources/mteval-v13a.pl 3 http://www.cs.umd.edu/ snover/tercom/ Proceedings of the 14th Conference of the Association for Machine Translation in the Americas October 6 - 9, 2020, Volume 1: MT Research Track Page 12"
2020.amta-research.2,P16-1162,0,0.0546904,"ilities, we sum over j positions as stated in Equation 6 with topK approximation. The model has almost the same number of parameters as our transformer baseline. A visualization of model architecture can be seen in Figure 1. 6 Experiments We carry out the experiments on four WMT 2018 translation tasks1 : German↔English and Chinese↔English. The corpora statistics are shown in Table 1. We do not employ any kind of synthetic or back-translated data in this work. For German↔English, after tokenization and true-casing using the Moses toolkit (Koehn et al., 2007), we apply byte pair encoding (BPE) (Sennrich et al., 2016) with 50k merge operations. We use the original parallel data consisting of 5.9M sentence pairs (see Table 1). For Chinese↔English, we apply sentence pieces model (SPM) (Kudo, 2018) with an n-best size of 30 and 32k merge operations. The original bilingual data consists of almost 26M samples. We filter out the noisy data by removing illegal characters and duplication, hence we end up with 14M pairs. For De↔En and Zh↔En, we use the newstest2015 and the newsdev2017 as the development set respectively and the newstest2017 and newstest2018 as our test sets. The models are evaluated using case-sens"
2020.amta-research.2,D18-1065,0,0.0623313,"2020, Volume 1: MT Research Track Page 8 computation directly to have dependence on the Giza++ alignment and perform beam search over both the lexical and alignment hypotheses. Unlike the aforementioned methods, our approach does not require any pre-computed alignments, and we do not need to search for the alignment path. It means our zero-order model can be easily applied in both training and decoding. There are also a number of recent works in which attention is used as a latent alignment by decomposing the joint distribution between an alignment model and a lexicon model (Wu et al., 2018; Shankar et al., 2018; Bahar et al., 2020). They mainly use a recurrent neural network (RNN) parameterization. The main difference of our work, is that we explore the use of transformer models. They either use character-level output or conduct the experiments on a small training set where the vocabularies appear to be small, whilst we evaluate our experiments using relatively large vocabularies. Shankar and Sarawagi (2019) extend the prior into an explicit posterior attention distribution. Deng et al. (2018) propose a non-differentiable approach, “hard attention”, where an explicit dependence of a single input to"
2020.amta-research.2,2006.amta-papers.25,0,0.0414635,"sentence pieces model (SPM) (Kudo, 2018) with an n-best size of 30 and 32k merge operations. The original bilingual data consists of almost 26M samples. We filter out the noisy data by removing illegal characters and duplication, hence we end up with 14M pairs. For De↔En and Zh↔En, we use the newstest2015 and the newsdev2017 as the development set respectively and the newstest2017 and newstest2018 as our test sets. The models are evaluated using case-sensitive B LEU (Papineni et al., 2002) computed by the official scripts of WMT campaign, i.e. mteval-v13a2 and case-sensitive normalized T ER (Snover et al., 2006) computed by tercom3 . For our experiments, we train both the transformer and the RNN attention models. We follow a base transformer similar to (Vaswani et al., 2017) where we use 6 layers in both the 1 http://statmt.org/wmt18/ 2 ftp://jaguar.ncsl.nist.gov/mt/resources/mteval-v13a.pl 3 http://www.cs.umd.edu/ snover/tercom/ Proceedings of the 14th Conference of the Association for Machine Translation in the Americas October 6 - 9, 2020, Volume 1: MT Research Track Page 12 encoder and the decoder with an internal dimension size of 512. We set the number of heads in the multi-head attention to 8."
2020.amta-research.2,W18-5420,0,0.0150911,"irect hidden Markov model (HMM) formulation in the transformer architecture such that the translation posterior distribution has a direct dependency on the source positions. • as to the interest in alignment based approaches, we intend to investigate whether the latent-based models are able to tackle the explainability problem of alignments especially Proceedings of the 14th Conference of the Association for Machine Translation in the Americas October 6 - 9, 2020, Volume 1: MT Research Track Page 7 for the transformer model. Similar to how some approaches in explainable NMT use the attention (Stahlberg et al., 2018; Zenkel et al., 2019; Garg et al., 2019), we also incorporate it as a key interpretation component into our work. From the statistical perspective, we revisit the formulation of the posterior probability of a given sentence by computing a separate translation score for every target-source word pair. Since marginalization is exponential in the order of the model, we only explore a zero-order assumption, i.e. there is no dependence between subsequent alignments. The marginalization over the latent variable becomes simple and efficient for zero-order models and can be easily applied in both trai"
2020.amta-research.2,P14-1138,0,0.0189799,"ingle network trained end-to-end similar to the transformer model. Due to first-order dependence, Wang et al. (2018) also apply the forward-backward algorithm to compute the posterior probabilities as true labels, which is not required in our model. Alkhouli et al. (2016) apply explicit hard alignments to generate a translation using a maximum approximation. Alkhouli and Ney (2017) compute attention weights using pre-defined alignments to bias soft attention toward hard alignments. Yang et al. (2013) use lexical and alignment models, where alignments have no dependence on the lexical context. Tamura et al. (2014) also introduce a lexicalized neural alignment model to generate word alignments for the phrase-based translation system. In this work, we use neither pre-computed alignments nor a phrase table. As an extension to neural alignment models, Alkhouli et al. (2018) use the transformer architecture to train both alignment and lexicon models while augmenting the multi-head attention component with additional hard alignment information. In their work, they train two separate networks and combine them in decoding with a maximum approximation. In contrast, we train a single network and sum over source"
2020.amta-research.2,P16-1008,0,0.0175292,"d alignments for the phrase-based translation system. In this work, we use neither pre-computed alignments nor a phrase table. As an extension to neural alignment models, Alkhouli et al. (2018) use the transformer architecture to train both alignment and lexicon models while augmenting the multi-head attention component with additional hard alignment information. In their work, they train two separate networks and combine them in decoding with a maximum approximation. In contrast, we train a single network and sum over source positions. Inspired by the success of statistical alignment models, Tu et al. (2016); Cohn et al. (2016) propose fertility and coverage concepts by including dependence on previous attention weights. Zenkel et al. (2019) try to gain high quality alignments by recomputing the attention heads after each target word prediction. Peter et al. (2017); Li et al. (2018) employ the full target context to improve alignment accuracy. Given statistical alignments obtained from Giza++ toolkit (Och and Ney, 2003), there are some methods in which the soft attention weights are supervised to behave similarly to the conventional hard alignments. Chen et al. (2016); Mi et al. (2016); Liu et al"
2020.amta-research.2,2006.iwslt-papers.7,1,0.757991,"Missing"
2020.amta-research.2,C96-2141,1,0.483917,"nd no search for the alignment path is required, thus a simple beam search decoder is used. We also address the theoretical connection between our approach and IBM model 2 (Brown et al., 1993). Tackling the costly computation of the softmax for all source positions, we employ an approximation by taking the topK relevant positions. To the best of our knowledge, this work explores the first instance of a zero-order latent variable alignments using the transformer architecture in an end-to-end fashion for machine translation. 2 Related Works Similar to IBM and HMM alignments (Brown et al., 1993; Vogel et al., 1996), there are standalone neural approaches based on introducing word alignments as hidden variables, such that either a full sum over the alignment path or a maximum approximation (Viterbi word alignment) is used. These models decompose the translation process into two parts, namely the alignment and lexicon models. Unlike (Wang et al., 2018, 2017) where they use two separate networks, one for the alignment and one for the lexicon model and they need to jointly train two networks batch-wise, our work is still a single network trained end-to-end similar to the transformer model. Due to first-orde"
2020.amta-research.2,P19-1580,0,0.0493323,"Missing"
2020.amta-research.2,P17-2020,1,0.894215,"Missing"
2020.amta-research.2,P18-2060,1,0.747071,"pretation component into our work. From the statistical perspective, we revisit the formulation of the posterior probability of a given sentence by computing a separate translation score for every target-source word pair. Since marginalization is exponential in the order of the model, we only explore a zero-order assumption, i.e. there is no dependence between subsequent alignments. The marginalization over the latent variable becomes simple and efficient for zero-order models and can be easily applied in both training and decoding. Unlike higher order dependence (Alkhouli et al., 2016, 2018; Wang et al., 2018), no dynamic programming and no search for the alignment path is required, thus a simple beam search decoder is used. We also address the theoretical connection between our approach and IBM model 2 (Brown et al., 1993). Tackling the costly computation of the softmax for all source positions, we employ an approximation by taking the topK relevant positions. To the best of our knowledge, this work explores the first instance of a zero-order latent variable alignments using the transformer architecture in an end-to-end fashion for machine translation. 2 Related Works Similar to IBM and HMM alignm"
2020.amta-research.2,D18-1473,0,0.0904553,"as October 6 - 9, 2020, Volume 1: MT Research Track Page 8 computation directly to have dependence on the Giza++ alignment and perform beam search over both the lexical and alignment hypotheses. Unlike the aforementioned methods, our approach does not require any pre-computed alignments, and we do not need to search for the alignment path. It means our zero-order model can be easily applied in both training and decoding. There are also a number of recent works in which attention is used as a latent alignment by decomposing the joint distribution between an alignment model and a lexicon model (Wu et al., 2018; Shankar et al., 2018; Bahar et al., 2020). They mainly use a recurrent neural network (RNN) parameterization. The main difference of our work, is that we explore the use of transformer models. They either use character-level output or conduct the experiments on a small training set where the vocabularies appear to be small, whilst we evaluate our experiments using relatively large vocabularies. Shankar and Sarawagi (2019) extend the prior into an explicit posterior attention distribution. Deng et al. (2018) propose a non-differentiable approach, “hard attention”, where an explicit dependence"
2020.amta-research.2,P13-1017,0,0.0262682,"nment and one for the lexicon model and they need to jointly train two networks batch-wise, our work is still a single network trained end-to-end similar to the transformer model. Due to first-order dependence, Wang et al. (2018) also apply the forward-backward algorithm to compute the posterior probabilities as true labels, which is not required in our model. Alkhouli et al. (2016) apply explicit hard alignments to generate a translation using a maximum approximation. Alkhouli and Ney (2017) compute attention weights using pre-defined alignments to bias soft attention toward hard alignments. Yang et al. (2013) use lexical and alignment models, where alignments have no dependence on the lexical context. Tamura et al. (2014) also introduce a lexicalized neural alignment model to generate word alignments for the phrase-based translation system. In this work, we use neither pre-computed alignments nor a phrase table. As an extension to neural alignment models, Alkhouli et al. (2018) use the transformer architecture to train both alignment and lexicon models while augmenting the multi-head attention component with additional hard alignment information. In their work, they train two separate networks and"
2020.amta-research.2,P18-4022,1,0.901115,"Missing"
2020.coling-main.386,D18-1549,0,0.0180567,"urther give our interpretations why the smoothing methods work in practice. 2 Related Work In the recent work by Gao et al. (2019), input smoothing is motivated and introduced. Conceptually, the parallel data used to train neural machine translation models is only a sampled subset of the total “true” translation data. Under the name of “soft contextualized data augmentation”, the authors use an additional LM to give soft distributions across the vocabulary for randomly selected positions. Compared to previous data augmentaion methods (Iyyer et al., 2015; Xie et al., 2017; Fadaee et al., 2017; Artetxe et al., 2018; Lample et al., 2018), the soft smoothing method achieves more significant improvements. The method is quickly adopted and motivates many interesting work, e.g. selecting words to “smooth” with dependency parsing (Duan et al., 2020), automatic repairing noisy synthetic parallel data (Cheng et al., 2020), and distilling knowledge from BERT (Devlin et al., 2019) via “text smoothing” (Wu et al., 2020). On the other hand, output smoothing enjoys a slightly longer history. In this era where neural network are extensively used for modeling, Szegedy et al. (2016) initially introduce the method of “l"
2020.coling-main.386,P96-1041,0,0.643663,"back-translation model is commonly used, how exactly the artificial source-side texts should be generated largely remains a yet-to-resolve research question. The sampling vs. search comparisons are already made in several works (Edunov et al., 2018; Imamura et al., 2018; Grac¸a et al., 2019), while Wang et al. (2019) being a most recent work introducing uncertainty-based confidence estimation as an alternative. 4362 The term “smoothing” is also traditionally used in the context of count-based language modeling (Jelinek and Mercer, 1980; Katz, 1987; Church and Gale, 1991; Kneser and Ney, 1995; Chen and Goodman, 1996). In a broader sense, one-hot vectors commonly used at the input-side and output-side of neural networks serve as empirical counts to the model. In this interpretation, both input smoothing and output smoothing are similar in that they both discount certain probability masses from the what is observed in data, to those rare events (rare combinations of input and output words / tokens). In other words, the smoothing methods discussed in this paper should have an overall effect of combating over-fitting and boosting generalization. Closely related, the standing investigations into knowledge dist"
2020.coling-main.386,N19-1423,0,0.129722,"augmentation”, the authors use an additional LM to give soft distributions across the vocabulary for randomly selected positions. Compared to previous data augmentaion methods (Iyyer et al., 2015; Xie et al., 2017; Fadaee et al., 2017; Artetxe et al., 2018; Lample et al., 2018), the soft smoothing method achieves more significant improvements. The method is quickly adopted and motivates many interesting work, e.g. selecting words to “smooth” with dependency parsing (Duan et al., 2020), automatic repairing noisy synthetic parallel data (Cheng et al., 2020), and distilling knowledge from BERT (Devlin et al., 2019) via “text smoothing” (Wu et al., 2020). On the other hand, output smoothing enjoys a slightly longer history. In this era where neural network are extensively used for modeling, Szegedy et al. (2016) initially introduce the method of “label smoothing” and Vaswani et al. (2017) include it by default into the Transformer setup. Discounting a certain probability mass from to one-hot true target distribution, and redistributing uniformly across the vocabulary, label smoothing wishes to solve the problem of over-fitting and boost adaptability. Relatedly, Pereyra et al. (2017) introduces a confiden"
2020.coling-main.386,D18-1045,0,0.413875,"oothing are used in combination, giving up to +1.9 BLEU scores on standard machine translation tasks and reveal reasons why these smoothing methods should be preferred. 1 Introduction Nowadays, neural network models are commonly used for the task of machine translation. The Transformer (Vaswani et al., 2017) architecture is the default choice for many competitive systems (Bojar et al., 2018; Barrault et al., 2019; Ott et al., 2018). In order to make use of large amount of available data in the target language, among others, back-translation is a frequently used method (Sennrich et al., 2016a; Edunov et al., 2018; Grac¸a et al., 2019). Recently, a method under the name “soft contextualized data augmentation” (Gao et al., 2019) is introduced and focus on the input side of neural machine translation models. Intuitively, the method smoothes both the source input and the target input to the model. While one-hot vectors are traditionally used to feed the word / token information to the network, this method instead uses an external language model (LM) trained on the parallel data without additional monolingual data, and achieve a “smoother” input where a “linear interpolation” operation is done on the word"
2020.coling-main.386,P17-2090,0,0.016578,"ack-translation, we further give our interpretations why the smoothing methods work in practice. 2 Related Work In the recent work by Gao et al. (2019), input smoothing is motivated and introduced. Conceptually, the parallel data used to train neural machine translation models is only a sampled subset of the total “true” translation data. Under the name of “soft contextualized data augmentation”, the authors use an additional LM to give soft distributions across the vocabulary for randomly selected positions. Compared to previous data augmentaion methods (Iyyer et al., 2015; Xie et al., 2017; Fadaee et al., 2017; Artetxe et al., 2018; Lample et al., 2018), the soft smoothing method achieves more significant improvements. The method is quickly adopted and motivates many interesting work, e.g. selecting words to “smooth” with dependency parsing (Duan et al., 2020), automatic repairing noisy synthetic parallel data (Cheng et al., 2020), and distilling knowledge from BERT (Devlin et al., 2019) via “text smoothing” (Wu et al., 2020). On the other hand, output smoothing enjoys a slightly longer history. In this era where neural network are extensively used for modeling, Szegedy et al. (2016) initially intr"
2020.coling-main.386,P19-1555,0,0.104217,"s why these smoothing methods should be preferred. 1 Introduction Nowadays, neural network models are commonly used for the task of machine translation. The Transformer (Vaswani et al., 2017) architecture is the default choice for many competitive systems (Bojar et al., 2018; Barrault et al., 2019; Ott et al., 2018). In order to make use of large amount of available data in the target language, among others, back-translation is a frequently used method (Sennrich et al., 2016a; Edunov et al., 2018; Grac¸a et al., 2019). Recently, a method under the name “soft contextualized data augmentation” (Gao et al., 2019) is introduced and focus on the input side of neural machine translation models. Intuitively, the method smoothes both the source input and the target input to the model. While one-hot vectors are traditionally used to feed the word / token information to the network, this method instead uses an external language model (LM) trained on the parallel data without additional monolingual data, and achieve a “smoother” input where a “linear interpolation” operation is done on the word embedding matrices, instead of the usual “table lookup”. Conceptually, the “input smoothing” method above largely re"
2020.coling-main.386,P17-1012,0,0.0253454,"more small datasets, IWSLT2014 Dutch→English (nl-en) and IWSLT2014 Spanish→English (es-en), plus a larger dataset, WMT2014 English→German (en-de). For the latter, we look at both the base and big model from the original Transformer paper and evaluate on newstest2014, newstest2015 and newstest2016. We implement the various smoothing methods in the fairseq toolkit (Ott et al., 2019) and conduct experiments with it. For the vocabulary, we use 10,000 and 32,000 merge operations with joint byte pair encoding from Sennrich et al. (2016b) for IWSLT and WMT respectively. For IWSLT, we largely follow Gehring et al. (2017), lowercase all sentences, remove extremely long sentence pairs, subsample sentence pairs from training data as our development set, and concatenate all available development and test sets. For WMT, we adopt the preprocessing steps in Ott et al. (2018). For all of our experiments, the three embedding matrices are tied, similar to that in Vaswani et al. (2017). For more details about preprocessing, we refer the readers to the fairseq source, where the preprocessing scripts are available and easy to adapt. During training, we monitor the development set perplexity. After convergence, we further"
2020.coling-main.386,W19-5205,1,0.878405,"Missing"
2020.coling-main.386,W18-2707,0,0.0862589,"y sees some use (Huck, 2018). For neural machine translation, Sennrich et al. (2016a) formally introduces the method of back-translation, which marks an important improvement in the training pipelines. Edunov et al. (2018) extends the method to the data scenario where huge amounts of monolingual data is available. While a separate target-to-source back-translation model is commonly used, how exactly the artificial source-side texts should be generated largely remains a yet-to-resolve research question. The sampling vs. search comparisons are already made in several works (Edunov et al., 2018; Imamura et al., 2018; Grac¸a et al., 2019), while Wang et al. (2019) being a most recent work introducing uncertainty-based confidence estimation as an alternative. 4362 The term “smoothing” is also traditionally used in the context of count-based language modeling (Jelinek and Mercer, 1980; Katz, 1987; Church and Gale, 1991; Kneser and Ney, 1995; Chen and Goodman, 1996). In a broader sense, one-hot vectors commonly used at the input-side and output-side of neural networks serve as empirical counts to the model. In this interpretation, both input smoothing and output smoothing are similar in that they both discou"
2020.coling-main.386,P15-1162,0,0.072042,"Missing"
2020.coling-main.386,D16-1139,0,0.0205181,"ectors commonly used at the input-side and output-side of neural networks serve as empirical counts to the model. In this interpretation, both input smoothing and output smoothing are similar in that they both discount certain probability masses from the what is observed in data, to those rare events (rare combinations of input and output words / tokens). In other words, the smoothing methods discussed in this paper should have an overall effect of combating over-fitting and boosting generalization. Closely related, the standing investigations into knowledge distillation (Hinton et al., 2015; Kim and Rush, 2016; Freitag et al., 2017; Tan et al., 2019) are also connected works and may be further referred to. 3 Methodology In this section, we define the translation models and training criterions using different combinations of smoothing at the input side and output side. The distinction among these models is necessarily made in order to draw a fair conclusion if the improvements from input and output smoothing can stack. Consider parallel training data f1J = f1 ...fj ...fJ , f ∈ F and eI1 = e1 ...ei ...eI , e ∈ E used to train machine translation models, where f and e denote tokens in the source and t"
2020.coling-main.386,W18-6301,0,0.0896128,"Missing"
2020.coling-main.386,N19-4009,0,0.0234324,"ments For fast iterations of experiments, we first conduct experiments on a smaller dataset, namely IWSLT2014 German→English (de-en). After obtaining meaningful and conclusive results, we repeat the core experiments and extend to two more small datasets, IWSLT2014 Dutch→English (nl-en) and IWSLT2014 Spanish→English (es-en), plus a larger dataset, WMT2014 English→German (en-de). For the latter, we look at both the base and big model from the original Transformer paper and evaluate on newstest2014, newstest2015 and newstest2016. We implement the various smoothing methods in the fairseq toolkit (Ott et al., 2019) and conduct experiments with it. For the vocabulary, we use 10,000 and 32,000 merge operations with joint byte pair encoding from Sennrich et al. (2016b) for IWSLT and WMT respectively. For IWSLT, we largely follow Gehring et al. (2017), lowercase all sentences, remove extremely long sentence pairs, subsample sentence pairs from training data as our development set, and concatenate all available development and test sets. For WMT, we adopt the preprocessing steps in Ott et al. (2018). For all of our experiments, the three embedding matrices are tied, similar to that in Vaswani et al. (2017)."
2020.coling-main.386,P02-1040,0,0.107419,"cessing scripts are available and easy to adapt. During training, we monitor the development set perplexity. After convergence, we further average the most recent checkpoints for a small performance boost. Note that this checkpoint averaging step is done for all of the models mentioned in this paper, so it is fair to compare the results to draw conclusions about smoothing. During beam search, we consistently use a beam size of five for IWSLT and four for 4365 WMT for fair comparisons to literature. Finally, we report case-insensitive BLEU scores on IWSLT and case-sensitive BLEU scores on WMT (Papineni et al., 2002) on the test sets. 4.1 Tuning on a Small Dataset Output smoothing with a zero-gram LM (Vaswani et al., 2017) is known to consistently give performance improvements. Therefore, our first step is to replicate the results from Gao et al. (2019) about input smoothing. The original authors tune the γ parameter, which controls the probability of each token to be selected for input smoothing. In our case, we follow their setup and additionally vary λ in order to determine the optimal strength of smoothing. Furthermore, we look at alternative smoothing helper models to be used as qsrc and qtgt , and e"
2020.coling-main.386,D19-5616,0,0.0160155,"ei |f1J , e1i−1 ; qsrc , qtgt , Φ I  1 XX L=− (1 − m)δ(ei , e) + mqout log p I i=1 e∈E 4364 (6) Compared to using one-hot vectors everywhere, using smoothed representations have the benefit of combining potentially all word vectors in each update step. It is important to mention that, all smoothing methods mentioned in this paper are only used during training, while during testing, the one-hot vectors are again used, following the idea that a model trained with smoothed representation of words should better generalize during testing. This can be further related to the topic of exposure bias (Schmidt, 2019), where the training-testing mismatch may lead to unseen or corrupted context during search. Although we do not conduct experiments to further validate the point, qualitatively we think input smoothing effectively lets the model see more unique contexts during training, mitigating the exposure bias problem. A general note about the input smoothing helpers qsrc and qtgt is that, during training, the context for a certain position is not limited only to the left. In other words, one does not have to use a leftto-right LM to obtain the posterior distribution as in Gao et al. (2019). For example,"
2020.coling-main.386,P16-1009,0,0.566944,"when input and output smoothing are used in combination, giving up to +1.9 BLEU scores on standard machine translation tasks and reveal reasons why these smoothing methods should be preferred. 1 Introduction Nowadays, neural network models are commonly used for the task of machine translation. The Transformer (Vaswani et al., 2017) architecture is the default choice for many competitive systems (Bojar et al., 2018; Barrault et al., 2019; Ott et al., 2018). In order to make use of large amount of available data in the target language, among others, back-translation is a frequently used method (Sennrich et al., 2016a; Edunov et al., 2018; Grac¸a et al., 2019). Recently, a method under the name “soft contextualized data augmentation” (Gao et al., 2019) is introduced and focus on the input side of neural machine translation models. Intuitively, the method smoothes both the source input and the target input to the model. While one-hot vectors are traditionally used to feed the word / token information to the network, this method instead uses an external language model (LM) trained on the parallel data without additional monolingual data, and achieve a “smoother” input where a “linear interpolation” operatio"
2020.coling-main.386,P16-1162,0,0.727876,"when input and output smoothing are used in combination, giving up to +1.9 BLEU scores on standard machine translation tasks and reveal reasons why these smoothing methods should be preferred. 1 Introduction Nowadays, neural network models are commonly used for the task of machine translation. The Transformer (Vaswani et al., 2017) architecture is the default choice for many competitive systems (Bojar et al., 2018; Barrault et al., 2019; Ott et al., 2018). In order to make use of large amount of available data in the target language, among others, back-translation is a frequently used method (Sennrich et al., 2016a; Edunov et al., 2018; Grac¸a et al., 2019). Recently, a method under the name “soft contextualized data augmentation” (Gao et al., 2019) is introduced and focus on the input side of neural machine translation models. Intuitively, the method smoothes both the source input and the target input to the model. While one-hot vectors are traditionally used to feed the word / token information to the network, this method instead uses an external language model (LM) trained on the parallel data without additional monolingual data, and achieve a “smoother” input where a “linear interpolation” operatio"
2020.coling-main.386,D19-1073,0,0.0159338,"ranslation, Sennrich et al. (2016a) formally introduces the method of back-translation, which marks an important improvement in the training pipelines. Edunov et al. (2018) extends the method to the data scenario where huge amounts of monolingual data is available. While a separate target-to-source back-translation model is commonly used, how exactly the artificial source-side texts should be generated largely remains a yet-to-resolve research question. The sampling vs. search comparisons are already made in several works (Edunov et al., 2018; Imamura et al., 2018; Grac¸a et al., 2019), while Wang et al. (2019) being a most recent work introducing uncertainty-based confidence estimation as an alternative. 4362 The term “smoothing” is also traditionally used in the context of count-based language modeling (Jelinek and Mercer, 1980; Katz, 1987; Church and Gale, 1991; Kneser and Ney, 1995; Chen and Goodman, 1996). In a broader sense, one-hot vectors commonly used at the input-side and output-side of neural networks serve as empirical counts to the model. In this interpretation, both input smoothing and output smoothing are similar in that they both discount certain probability masses from the what is o"
2020.coling-main.612,C18-1139,0,0.134851,"he neural architectures that are used in named entity recognition, a conditional random field layer is commonly used for the output. This work proposes to use a neural language model as an alternative to the conditional random field layer, which is more flexible for the size of the corpus. Experimental results show that the proposed system has a significant advantage in terms of training speed. 1 Introduction With the help of various neural network architectures, named entity recognition (NER) systems nowadays achieve very promising performance for tasks with a limited number of entity types (Akbik et al., 2018; Devlin et al., 2019; Jiang et al., 2019). Besides various types of embedding techniques and long shortterm memory (LSTM) (Hochreiter and Schmidhuber, 1997) recurrent neural networks (RNN), another important component of those systems is the conditional random field (CRF) layer (Lafferty et al., 2001). The CRF layer is very effective for tasks such as NER and part-of-speech (POS) tagging. However, the training time of such a model increases quadratically with the vocabulary size, which is the number of different entity types in the case of NER. To tackle this problem, we use LSTM-based neural"
2020.coling-main.612,N19-4010,0,0.0119325,"m the beam. Therefore, we want the best scored hypotheses to stay on the beam. To address this issue, we refer to Wiseman and Rush (2016), in which subsequent candidates are generated from the true token when it falls off the beam. We adopt this idea and develop our simplified method: for each time step, we replace the K-th candidate with the true tag if it is not included in the K-best list. 4 Experiments We experiment on four benchmark NER tasks in three languages: CoNLL 2003 English/Dutch, OntoNotes English and GermEval 2014 German. 4.1 Models As we conduct all our experiments using Flair (Akbik et al., 2019a), we adopt the recommended setup for the baseline BLSTM-CRF models. We use GloVe word embeddings (Pennington et al., 2014) for the CoNLL03 English task, while FastText embeddings (Mikolov et al., 2018) for CoNLL03 Dutch and GermEval, and FastText web crawl embeddings for OntoNotes are used. Pooled Flair embeddings (Akbik et al., 2019b) are used for all experiments except for OntoNotes, for which the non-pooled version (Akbik et al., 2018) is used. The BLSTM has a single 256-unit forward and backward LSTM layer followed by a CRF layer. For non-CRF baseline models, the CRF layers are simply re"
2020.coling-main.612,N19-1078,0,0.0109102,"m the beam. Therefore, we want the best scored hypotheses to stay on the beam. To address this issue, we refer to Wiseman and Rush (2016), in which subsequent candidates are generated from the true token when it falls off the beam. We adopt this idea and develop our simplified method: for each time step, we replace the K-th candidate with the true tag if it is not included in the K-best list. 4 Experiments We experiment on four benchmark NER tasks in three languages: CoNLL 2003 English/Dutch, OntoNotes English and GermEval 2014 German. 4.1 Models As we conduct all our experiments using Flair (Akbik et al., 2019a), we adopt the recommended setup for the baseline BLSTM-CRF models. We use GloVe word embeddings (Pennington et al., 2014) for the CoNLL03 English task, while FastText embeddings (Mikolov et al., 2018) for CoNLL03 Dutch and GermEval, and FastText web crawl embeddings for OntoNotes are used. Pooled Flair embeddings (Akbik et al., 2019b) are used for all experiments except for OntoNotes, for which the non-pooled version (Akbik et al., 2018) is used. The BLSTM has a single 256-unit forward and backward LSTM layer followed by a CRF layer. For non-CRF baseline models, the CRF layers are simply re"
2020.coling-main.612,N19-1423,0,0.0757573,"Missing"
2020.coling-main.612,D19-1367,0,0.0211585,"Missing"
2020.coling-main.612,L18-1008,0,0.0297302,"ken when it falls off the beam. We adopt this idea and develop our simplified method: for each time step, we replace the K-th candidate with the true tag if it is not included in the K-best list. 4 Experiments We experiment on four benchmark NER tasks in three languages: CoNLL 2003 English/Dutch, OntoNotes English and GermEval 2014 German. 4.1 Models As we conduct all our experiments using Flair (Akbik et al., 2019a), we adopt the recommended setup for the baseline BLSTM-CRF models. We use GloVe word embeddings (Pennington et al., 2014) for the CoNLL03 English task, while FastText embeddings (Mikolov et al., 2018) for CoNLL03 Dutch and GermEval, and FastText web crawl embeddings for OntoNotes are used. Pooled Flair embeddings (Akbik et al., 2019b) are used for all experiments except for OntoNotes, for which the non-pooled version (Akbik et al., 2018) is used. The BLSTM has a single 256-unit forward and backward LSTM layer followed by a CRF layer. For non-CRF baseline models, the CRF layers are simply removed leaving all other parameters unchanged. For each task, we train four CRF and non-CRF models respectively. In all our hybrid model experiments, the BLSTM tagger component has the same configuration"
2020.coling-main.612,D14-1162,0,0.102963,"man and Rush (2016), in which subsequent candidates are generated from the true token when it falls off the beam. We adopt this idea and develop our simplified method: for each time step, we replace the K-th candidate with the true tag if it is not included in the K-best list. 4 Experiments We experiment on four benchmark NER tasks in three languages: CoNLL 2003 English/Dutch, OntoNotes English and GermEval 2014 German. 4.1 Models As we conduct all our experiments using Flair (Akbik et al., 2019a), we adopt the recommended setup for the baseline BLSTM-CRF models. We use GloVe word embeddings (Pennington et al., 2014) for the CoNLL03 English task, while FastText embeddings (Mikolov et al., 2018) for CoNLL03 Dutch and GermEval, and FastText web crawl embeddings for OntoNotes are used. Pooled Flair embeddings (Akbik et al., 2019b) are used for all experiments except for OntoNotes, for which the non-pooled version (Akbik et al., 2018) is used. The BLSTM has a single 256-unit forward and backward LSTM layer followed by a CRF layer. For non-CRF baseline models, the CRF layers are simply removed leaving all other parameters unchanged. For each task, we train four CRF and non-CRF models respectively. In all our h"
2020.coling-main.612,D16-1137,0,0.0266391,"ning approach, the LSTM-based LM can also be trained jointly with the tagging model. In this case, a single training loss is computed and back-propagated to both LM and BLSTM-based tagging model. To jointly train the hybrid model at the sequence level, theoretically the scores for all possible tag sequences must be calculated. The dynamic programming algorithm used for the first-order transition model is infeasible for our joint training with the LSTM-based LM. A number of publications dealt with issues related to sequence training, particularly those related to optimizing the search process (Wiseman and Rush, 2016; Daum´e III and Marcu, 2005). Inspired by them we develop a straightforward training method. Looking at the denominator in Equation 2, although it is not feasible to go through all tag sequences, we can estimate the denominator by considering only those hypotheses with the highest score and that can be generated from the beam search. The log likelihood of the true tags can be approximated by X  exp sθ (xT1 , yˆ1T ) log Pθ0 (y1T |xT1 ) = sθ (xT1 , y1T ) − log (8) |{z } T yˆ ∈beam gold score |t=1 {z } beam score and it can be written as the difference between the gold score and the beam score."
2020.eamt-1.5,N19-1388,0,0.127614,"ervised learning for NMT in various data settings. 3 Unsupervised NMT This section reviews the core concepts of the recent unsupervised NMT framework and describes to which points they are potentially vulnerable. 3.1 Bidirectional Modeling Most of the unsupervised NMT methods share the model parameters between source→target and target→source directions. They also often share a joint subword vocabulary across the two languages (Sennrich et al., 2016b). Sharing a model among different translation tasks has been shown to be effective in multilingual NMT (Firat et al., 2016; Johnson et al., 2017; Aharoni et al., 2019), especially in improving performance on low-resource language pairs. This is due to the commonality of natural languages; learning to represent a language is helpful to represent other languages, e.g. by transferring knowledge of general sentence structures. It also provides good regularization for the model. Unsupervised learning is an extreme scenario of MT, where bilingual information is very weak. To supplement the weak and noisy training signal, knowledge transfer and regularization are crucial, which can be achieved by the bidirectional sharing. It is based on the fact that a translatio"
2020.eamt-1.5,P17-1042,0,0.044072,"erative training, the model should be able to generate meaningful translations already in the first iteration. We cannot expect the training to progress from a randomly initialized network and the synthetic data generated by it. Cross-lingual embeddings give a good starting point for the model by defining a joint continuous space shared by multiple languages. Ideally, in such a space, close embedding vectors are semantically related to each other regardless of their languages; they can be possible candidates for translation pairs (Mikolov et al., 2013). It can be learned either in word level (Artetxe et al., 2017; Conneau et al., 2018) or in sentence level (Conneau and Lample, 2019) using only monolingual corpora. In the word level, we can initialize the embedding layers with cross-lingual word embedding vectors (Artetxe et al., 2018b; Lample et al., 2018a; Yang et al., 2018; Lample et al., 2018b; Artetxe et al., 2019; Sun et al., 2019). On the other hand, the whole encoder/decoder parameters can be initialized with cross-lingual sequence training (Conneau and Lample, 2019; Ren et al., 2019a; Song et al., 2019). Cross-lingual word embedding has limited performance among distant languages (Søgaard et a"
2020.eamt-1.5,D18-1399,0,0.0860189,"Missing"
2020.eamt-1.5,J82-2005,0,0.67529,"Missing"
2020.eamt-1.5,P19-1019,0,0.540583,"ly with monolingual corpora, was † The author is now at DeepL GmbH. c 2020 The authors. This article is licensed under a Creative Commons 3.0 licence, no derivative works, attribution, CCBY-ND. proposed for those scenarios which lack bilingual data (Artetxe et al., 2018b; Lample et al., 2018a). Despite its progress in research, the performance of the unsupervised methods has been evaluated mostly on high-resource language pairs, e.g. German↔English or French↔English (Artetxe et al., 2018b; Lample et al., 2018a; Yang et al., 2018; Artetxe et al., 2018a; Lample et al., 2018b; Ren et al., 2019b; Artetxe et al., 2019; Sun et al., 2019; Sen et al., 2019). For these language pairs, huge bilingual corpora are already available, so there is no need for unsupervised learning in practice. Empirical results in these tasks do not carry over to low-resource language pairs; they simply fail to produce any meaningful translations (Neubig and Hu, 2018; Guzmán et al., 2019). This paper aims for a more comprehensive and pragmatic study on the performance of unsupervised NMT. Our experiments span ten translation tasks in the following five language pairs: • German↔English: similar languages, abundant bilingual/monolingu"
2020.eamt-1.5,Q17-1010,0,0.0324421,"vised systems have particular problems in the outputs other than limited adequacy/fluency? Another problem is that the model cannot distinguish words that appear in the same context. In the second example, the model knows that Vier in German (Four in English) is a number, but it generates a wrong number in English (Eight). The initial LM is trained to predict either Four or Eight given the same surrounding words (e.g. 1856, things) and has no clue to map Four to Vier. The model cannot learn these mappings by itself with back-translations. This problem can be partly solved by subword modeling (Bojanowski et al., 2017) or orthographic features (Riley and Gildea, 2018; Artetxe et al., 2019), which are however not effective for language pairs with disjoint alphabets. 5 Conclusion and Outlook In this paper, we examine the state-of-the-art unsupervised NMT in a wide range of tasks and data settings. We find that the performance of unsupervised NMT is seriously affected by these factors: • Linguistic similarity of source and target languages • Domain similarity of training data between source and target languages It is very hard to fulfill these in low-/zero-resource language pairs, which makes the current unsup"
2020.eamt-1.5,C18-1111,0,0.0171655,"g works poorly. In all of our experiments, supervised and semi-supervised baselines with 50k-sentence bilingual data outperform the best unsupervised results. Our analyses pinpoint the limits of the current unsupervised NMT and also suggest immediate research directions. 1 Introduction Statistical methods for machine translation (MT) require a large set of sentence pairs in two languages to build a decent translation system (Resnik and Smith, 2003; Koehn, 2005). Such bilingual data is scarce for most language pairs and its quality varies largely over different domains (AlOnaizan et al., 2002; Chu and Wang, 2018). Neural machine translation (NMT) (Bahdanau et al., 2015; Vaswani et al., 2017), the standard paradigm of MT these days, has been claimed to suffer from the data scarcity more severely than phrase-based MT (Koehn and Knowles, 2017). Unsupervised NMT, which trains a neural translation model only with monolingual corpora, was † The author is now at DeepL GmbH. c 2020 The authors. This article is licensed under a Creative Commons 3.0 licence, no derivative works, attribution, CCBY-ND. proposed for those scenarios which lack bilingual data (Artetxe et al., 2018b; Lample et al., 2018a). Despite it"
2020.eamt-1.5,D19-5610,0,0.0207224,"d NMT useless in practice. We also find that the performance is not improved by using massive monolingual data on one or both sides. In practice, a simple, non-tuned semi-supervised baseline with only less than 50k bilingual sentence pairs is sufficient to outperform our best large-scale unsupervised system. At this moment, we cannot recommend unsupervised learning for building MT products if there are at least small bilingual data. For the cases where there is no bilingual data available at all, we plan to systematically compare the unsupervised NMT to pivot-based methods (Kim et al., 2019b; Currey and Heafield, 2019) or multilingual zero-shot translation (Johnson et al., 2017; Aharoni et al., 2019). To make unsupervised NMT useful in the future, we suggest the following research directions: Language-/Domain-agnostic LM We show in Section 4.5 that the initial cross-lingual LM actually determines the performance of unsupervised NMT. In Section 4.6, we argue that the poor performance is due to input copying, for which we blame a poor cross-lingual LM. The LM pre-training must therefore handle dissimilar languages and domains equally well. This might be done by careful data selection or better regularization"
2020.eamt-1.5,D14-1061,0,0.0262232,"te-of-the-art unsupervised NMT in numerous real and artificial translation tasks. • We provide guidelines on whether to employ unsupervised NMT in practice, by showing how much bilingual data is sufficient to outperform the unsupervised results. • We clarify which factors make unsupervised NMT weak and which points must be improved, by analyzing the results both quantitatively and qualitatively. 2 Related Work The idea of unsupervised MT dates back to wordbased decipherment methods (Knight et al., 2006; Ravi and Knight, 2011). They learn only lexicon models at first, but add alignment models (Dou et al., 2014; Nuhn, 2019) or heuristic features (Naim et al., 2018) later. Finally, Artetxe et al. (2018a) and Lample et al. (2018b) train a fully-fledged phrase-based MT system in an unsupervised way. With neural networks, unsupervised learning of a sequence-to-sequence NMT model has been proposed by Lample et al. (2018a) and Artetxe et al. (2018b). Though having slight variations (Yang et al., 2018; Sun et al., 2019; Sen et al., 2019), unsupervised NMT approaches commonly 1) learn a shared model for both source→target and target→source 2) using iterative back-translation, along with 3) a denoising autoe"
2020.eamt-1.5,N16-1101,0,0.0311551,"systematically evaluate and analyze unsupervised learning for NMT in various data settings. 3 Unsupervised NMT This section reviews the core concepts of the recent unsupervised NMT framework and describes to which points they are potentially vulnerable. 3.1 Bidirectional Modeling Most of the unsupervised NMT methods share the model parameters between source→target and target→source directions. They also often share a joint subword vocabulary across the two languages (Sennrich et al., 2016b). Sharing a model among different translation tasks has been shown to be effective in multilingual NMT (Firat et al., 2016; Johnson et al., 2017; Aharoni et al., 2019), especially in improving performance on low-resource language pairs. This is due to the commonality of natural languages; learning to represent a language is helpful to represent other languages, e.g. by transferring knowledge of general sentence structures. It also provides good regularization for the model. Unsupervised learning is an extreme scenario of MT, where bilingual information is very weak. To supplement the weak and noisy training signal, knowledge transfer and regularization are crucial, which can be achieved by the bidirectional shari"
2020.eamt-1.5,W18-6409,1,0.728618,"ermutation of words, to make a corrupted input. The denoising objective trains the model to reorder the noisy input to the correct syntax, which is essential for generating fluent outputs. This is done for each language individually with monolingual data, as shown in Figure 2. source sentence target sentence source/target joint vocabulary decoder encoder source/target joint vocabulary noisy source noisy target Figure 2: Denoising autoencoder training for source or target language. Once the model is sufficiently trained for denoising, it is helpful to remove the objective or reduce its weight (Graça et al., 2018). At the later stages of training, the model gets improved in reordering and translates better; learning to denoise might hurt the performance in clean test sets. 4 Experiments and Analysis Data Our experiments were conducted on WMT 2018 German↔English and Russian↔ English, WMT 2019 Chinese↔English, Kazakh↔ English, and Gujarati↔English (Table 1). We preprocessed the data using the M OSES1 tokenizer and a frequent caser. For Chinese, we used the JIEBA segmenter2 . Lastly, byte pair encoding (BPE) (Sennrich et al., 2016b) was learned jointly over source and target languages with 32k merges and"
2020.eamt-1.5,D19-1632,0,0.172312,"e unsupervised methods has been evaluated mostly on high-resource language pairs, e.g. German↔English or French↔English (Artetxe et al., 2018b; Lample et al., 2018a; Yang et al., 2018; Artetxe et al., 2018a; Lample et al., 2018b; Ren et al., 2019b; Artetxe et al., 2019; Sun et al., 2019; Sen et al., 2019). For these language pairs, huge bilingual corpora are already available, so there is no need for unsupervised learning in practice. Empirical results in these tasks do not carry over to low-resource language pairs; they simply fail to produce any meaningful translations (Neubig and Hu, 2018; Guzmán et al., 2019). This paper aims for a more comprehensive and pragmatic study on the performance of unsupervised NMT. Our experiments span ten translation tasks in the following five language pairs: • German↔English: similar languages, abundant bilingual/monolingual data • Russian↔English: distant languages, abundant bilingual/monolingual data, similar sizes of the alphabet • Chinese↔English: distant languages, abundant bilingual/monolingual data, very different sizes of the alphabet • Kazakh↔English: distant languages, scarce bilingual data, abundant monolingual data • Gujarati↔English: distant languages, s"
2020.eamt-1.5,N16-1162,0,0.0296657,"unsupervised NMT employs an de-en Language family Alphabet Size Monolingual Sentences Words Bilingual Sentences Words ru-en zh-en kk-en gu-en German English Russian English Chinese English Kazakh English Gujarati English Germanic 60 Germanic 52 Slavic 66 Germanic 52 Sinitic 8,105 Germanic 52 Turkic 42 Germanic 52 Indic 91 Germanic 52 100M 1.8B 2.3B 5.9M 137.4M 144.9M 1.1B 71.6M 2.0B 1.4B 25.4M 618.6M 790M 30.8M 699M 18.9M 440.3M 482.9M 18.5M 278.5M 421.5M 4.1M 121.5M 93.8M 222k 1.6M 156k 1.9M 2.3M 1.5M Table 1: Training data statistics. additional training objective of denoising autoencoding (Hill et al., 2016). Given a clean sentence, artificial noises are injected, e.g. deletion or permutation of words, to make a corrupted input. The denoising objective trains the model to reorder the noisy input to the correct syntax, which is essential for generating fluent outputs. This is done for each language individually with monolingual data, as shown in Figure 2. source sentence target sentence source/target joint vocabulary decoder encoder source/target joint vocabulary noisy source noisy target Figure 2: Denoising autoencoder training for source or target language. Once the model is sufficiently trained"
2020.eamt-1.5,W18-2703,0,0.0302077,"et and source language, respectively. In unsupervised learning, the synthetic data should be created not only once at the beginning but also repeatedly throughout the training. At the early stages of training, the model might be too weak to generate good translations. Hence, most methods update the training data as the model gets improved during training. The improved model for source→target direction back-translates source monolingual data, which improves the model for target→source direction, and vice versa. This cycle is called dual learning (He et al., 2016) or iterative back-translation (Hoang et al., 2018). Figure 1 shows the case when it is applied to a fully shared bidirectional model. target translation source sentence source translation target sentence source/target joint vocabulary source/target joint vocabulary decoder decoder 1) 2) 1) 2) encoder encoder source/target joint vocabulary source/target joint vocabulary source sentence (a) target translation target sentence source translation (b) Figure 1: Iterative back-translation for training a bidirectional sequence-to-sequence model. The model first translates monolingual sentences (solid arrows), and then gets trained with the translatio"
2020.eamt-1.5,D18-1101,1,0.854159,"del for both source→target and target→source 2) using iterative back-translation, along with 3) a denoising autoencoder objective. They are initialized with either cross-lingual word embeddings or a cross-lingual language model (LM). To further improve the performance at the cost of efficiency, Lample et al. (2018b), Ren et al. (2019b) and Artetxe et al. (2019) combine unsupervised NMT with unsupervised phrase-based MT. On the other hand, one can also avoid the long iterative training by applying a separate denoiser directly to the word-by-word translations from cross-lingual word embeddings (Kim et al., 2018; Pourdamghani et al., 2019). Unsupervised NMT approaches have been so far evaluated mostly on high-resource language pairs, e.g. French→English, for academic purposes. In terms of practicality, they tend to underperform in low-resource language pairs, e.g. Azerbaijani→English (Neubig and Hu, 2018) or Nepali→English (Guzmán et al., 2019). To the best of our knowledge, this work is the first to systematically evaluate and analyze unsupervised learning for NMT in various data settings. 3 Unsupervised NMT This section reviews the core concepts of the recent unsupervised NMT framework and describe"
2020.eamt-1.5,P19-1120,1,0.885134,"Missing"
2020.eamt-1.5,D19-1080,1,0.927555,"achieved by the bidirectional sharing. It is based on the fact that a translation problem is dual in nature; source→target and target→source tasks are conceptually related to each other. Previous works on unsupervised NMT vary in the degree of sharing: the whole encoder (Artetxe et al., 2018b; Sen et al., 2019), the middle layers (Yang et al., 2018; Sun et al., 2019), or the whole model (Lample et al., 2018a; Lample et al., 2018b; Ren et al., 2019a; Conneau and Lample, 2019). Note that the network sharing is less effective among linguistically distinct languages in NMT (Kocmi and Bojar, 2018; Kim et al., 2019a). It still works as a regularizer, but transferring knowledge is harder if the morphology or word order is quite different. We show how well unsupervised NMT performs on such language pairs in Section 4.1. 3.2 Iterative Back-Translation Unsupervised learning for MT assumes no bilingual data for training. A traditional remedy for the data scarcity is generating synthetic bilingual data from monolingual text (Koehn, 2005; Schwenk, 2008; Sennrich et al., 2016a). To train a bidirectional model of Section 3.1, we need bilingual data of both translation directions. Therefore, most unsupervised NMT"
2020.eamt-1.5,P06-2065,0,0.0792703,"rvised NMT works poorly. Here is a summary of our contributions: • We thoroughly evaluate the performance of state-of-the-art unsupervised NMT in numerous real and artificial translation tasks. • We provide guidelines on whether to employ unsupervised NMT in practice, by showing how much bilingual data is sufficient to outperform the unsupervised results. • We clarify which factors make unsupervised NMT weak and which points must be improved, by analyzing the results both quantitatively and qualitatively. 2 Related Work The idea of unsupervised MT dates back to wordbased decipherment methods (Knight et al., 2006; Ravi and Knight, 2011). They learn only lexicon models at first, but add alignment models (Dou et al., 2014; Nuhn, 2019) or heuristic features (Naim et al., 2018) later. Finally, Artetxe et al. (2018a) and Lample et al. (2018b) train a fully-fledged phrase-based MT system in an unsupervised way. With neural networks, unsupervised learning of a sequence-to-sequence NMT model has been proposed by Lample et al. (2018a) and Artetxe et al. (2018b). Though having slight variations (Yang et al., 2018; Sun et al., 2019; Sen et al., 2019), unsupervised NMT approaches commonly 1) learn a shared model"
2020.eamt-1.5,W18-6325,0,0.019897,"crucial, which can be achieved by the bidirectional sharing. It is based on the fact that a translation problem is dual in nature; source→target and target→source tasks are conceptually related to each other. Previous works on unsupervised NMT vary in the degree of sharing: the whole encoder (Artetxe et al., 2018b; Sen et al., 2019), the middle layers (Yang et al., 2018; Sun et al., 2019), or the whole model (Lample et al., 2018a; Lample et al., 2018b; Ren et al., 2019a; Conneau and Lample, 2019). Note that the network sharing is less effective among linguistically distinct languages in NMT (Kocmi and Bojar, 2018; Kim et al., 2019a). It still works as a regularizer, but transferring knowledge is harder if the morphology or word order is quite different. We show how well unsupervised NMT performs on such language pairs in Section 4.1. 3.2 Iterative Back-Translation Unsupervised learning for MT assumes no bilingual data for training. A traditional remedy for the data scarcity is generating synthetic bilingual data from monolingual text (Koehn, 2005; Schwenk, 2008; Sennrich et al., 2016a). To train a bidirectional model of Section 3.1, we need bilingual data of both translation directions. Therefore, mos"
2020.eamt-1.5,W17-3204,0,0.0406114,"also suggest immediate research directions. 1 Introduction Statistical methods for machine translation (MT) require a large set of sentence pairs in two languages to build a decent translation system (Resnik and Smith, 2003; Koehn, 2005). Such bilingual data is scarce for most language pairs and its quality varies largely over different domains (AlOnaizan et al., 2002; Chu and Wang, 2018). Neural machine translation (NMT) (Bahdanau et al., 2015; Vaswani et al., 2017), the standard paradigm of MT these days, has been claimed to suffer from the data scarcity more severely than phrase-based MT (Koehn and Knowles, 2017). Unsupervised NMT, which trains a neural translation model only with monolingual corpora, was † The author is now at DeepL GmbH. c 2020 The authors. This article is licensed under a Creative Commons 3.0 licence, no derivative works, attribution, CCBY-ND. proposed for those scenarios which lack bilingual data (Artetxe et al., 2018b; Lample et al., 2018a). Despite its progress in research, the performance of the unsupervised methods has been evaluated mostly on high-resource language pairs, e.g. German↔English or French↔English (Artetxe et al., 2018b; Lample et al., 2018a; Yang et al., 2018; Ar"
2020.eamt-1.5,2005.mtsummit-papers.11,0,0.592593,"domain mismatch between source and target monolingual data. Such conditions are common for low-resource language pairs, where unsupervised learning works poorly. In all of our experiments, supervised and semi-supervised baselines with 50k-sentence bilingual data outperform the best unsupervised results. Our analyses pinpoint the limits of the current unsupervised NMT and also suggest immediate research directions. 1 Introduction Statistical methods for machine translation (MT) require a large set of sentence pairs in two languages to build a decent translation system (Resnik and Smith, 2003; Koehn, 2005). Such bilingual data is scarce for most language pairs and its quality varies largely over different domains (AlOnaizan et al., 2002; Chu and Wang, 2018). Neural machine translation (NMT) (Bahdanau et al., 2015; Vaswani et al., 2017), the standard paradigm of MT these days, has been claimed to suffer from the data scarcity more severely than phrase-based MT (Koehn and Knowles, 2017). Unsupervised NMT, which trains a neural translation model only with monolingual corpora, was † The author is now at DeepL GmbH. c 2020 The authors. This article is licensed under a Creative Commons 3.0 licence, n"
2020.eamt-1.5,J18-3006,0,0.0220743,"rtificial translation tasks. • We provide guidelines on whether to employ unsupervised NMT in practice, by showing how much bilingual data is sufficient to outperform the unsupervised results. • We clarify which factors make unsupervised NMT weak and which points must be improved, by analyzing the results both quantitatively and qualitatively. 2 Related Work The idea of unsupervised MT dates back to wordbased decipherment methods (Knight et al., 2006; Ravi and Knight, 2011). They learn only lexicon models at first, but add alignment models (Dou et al., 2014; Nuhn, 2019) or heuristic features (Naim et al., 2018) later. Finally, Artetxe et al. (2018a) and Lample et al. (2018b) train a fully-fledged phrase-based MT system in an unsupervised way. With neural networks, unsupervised learning of a sequence-to-sequence NMT model has been proposed by Lample et al. (2018a) and Artetxe et al. (2018b). Though having slight variations (Yang et al., 2018; Sun et al., 2019; Sen et al., 2019), unsupervised NMT approaches commonly 1) learn a shared model for both source→target and target→source 2) using iterative back-translation, along with 3) a denoising autoencoder objective. They are initialized with either cros"
2020.eamt-1.5,P18-2036,0,0.050339,"et al., 2018) or in sentence level (Conneau and Lample, 2019) using only monolingual corpora. In the word level, we can initialize the embedding layers with cross-lingual word embedding vectors (Artetxe et al., 2018b; Lample et al., 2018a; Yang et al., 2018; Lample et al., 2018b; Artetxe et al., 2019; Sun et al., 2019). On the other hand, the whole encoder/decoder parameters can be initialized with cross-lingual sequence training (Conneau and Lample, 2019; Ren et al., 2019a; Song et al., 2019). Cross-lingual word embedding has limited performance among distant languages (Søgaard et al., 2018; Nakashole and Flauger, 2018) and so does cross-lingual LM (Pires et al., 2019). Section 4.5 shows the impact of a poor initialization. 3.4 Denoising Autoencoder Initializing the word embedding layers furnishes the model with cross-lingual matching in the lexical embedding space, but does not provide any information on word orders or generation of text. Cross-lingual LMs encode word sequences in different languages, but they are not explicitly trained to reorder source words to the target language syntax. Both ways do not initialize the crucial parameters for reordering: the encoder-decoder attention and the recurrence on"
2020.eamt-1.5,D18-1103,0,0.103415,"the performance of the unsupervised methods has been evaluated mostly on high-resource language pairs, e.g. German↔English or French↔English (Artetxe et al., 2018b; Lample et al., 2018a; Yang et al., 2018; Artetxe et al., 2018a; Lample et al., 2018b; Ren et al., 2019b; Artetxe et al., 2019; Sun et al., 2019; Sen et al., 2019). For these language pairs, huge bilingual corpora are already available, so there is no need for unsupervised learning in practice. Empirical results in these tasks do not carry over to low-resource language pairs; they simply fail to produce any meaningful translations (Neubig and Hu, 2018; Guzmán et al., 2019). This paper aims for a more comprehensive and pragmatic study on the performance of unsupervised NMT. Our experiments span ten translation tasks in the following five language pairs: • German↔English: similar languages, abundant bilingual/monolingual data • Russian↔English: distant languages, abundant bilingual/monolingual data, similar sizes of the alphabet • Chinese↔English: distant languages, abundant bilingual/monolingual data, very different sizes of the alphabet • Kazakh↔English: distant languages, scarce bilingual data, abundant monolingual data • Gujarati↔English"
2020.eamt-1.5,P19-1493,0,0.030047,"9) using only monolingual corpora. In the word level, we can initialize the embedding layers with cross-lingual word embedding vectors (Artetxe et al., 2018b; Lample et al., 2018a; Yang et al., 2018; Lample et al., 2018b; Artetxe et al., 2019; Sun et al., 2019). On the other hand, the whole encoder/decoder parameters can be initialized with cross-lingual sequence training (Conneau and Lample, 2019; Ren et al., 2019a; Song et al., 2019). Cross-lingual word embedding has limited performance among distant languages (Søgaard et al., 2018; Nakashole and Flauger, 2018) and so does cross-lingual LM (Pires et al., 2019). Section 4.5 shows the impact of a poor initialization. 3.4 Denoising Autoencoder Initializing the word embedding layers furnishes the model with cross-lingual matching in the lexical embedding space, but does not provide any information on word orders or generation of text. Cross-lingual LMs encode word sequences in different languages, but they are not explicitly trained to reorder source words to the target language syntax. Both ways do not initialize the crucial parameters for reordering: the encoder-decoder attention and the recurrence on decoder states. As a result, an initial model for"
2020.eamt-1.5,W18-6319,0,0.0207698,"ati↔English (Table 1). We preprocessed the data using the M OSES1 tokenizer and a frequent caser. For Chinese, we used the JIEBA segmenter2 . Lastly, byte pair encoding (BPE) (Sennrich et al., 2016b) was learned jointly over source and target languages with 32k merges and applied without vocabulary threshold. Model We used 6-layer Transformer base architecture (Vaswani et al., 2017) by default: 512-dimension embedding/hidden layers, 2048dimension feedforward sublayers, and 8 heads. Decoding and Evaluation Decoding was done with beam size 5. We evaluated the test performance with S ACRE B LEU (Post, 2018). Unsupervised Learning We ran X LM3 by Conneau and Lample (2019) for the unsupervised experiments. The back-translations were done with beam search for each mini-batch of 16k tokens. The weight of the denoising objective started with 1 and linearly decreased to 0.1 until 100k updates, and then decreased to 0 until 300k updates. The model’s encoder and decoder were both initialized with the same pre-trained cross-lingual LM. We removed the language embeddings from the encoder for better cross-linguality (see Section 4.6). Unless otherwise specified, we used the same monolingual training data f"
2020.eamt-1.5,P19-1293,0,0.0213078,"e→target and target→source 2) using iterative back-translation, along with 3) a denoising autoencoder objective. They are initialized with either cross-lingual word embeddings or a cross-lingual language model (LM). To further improve the performance at the cost of efficiency, Lample et al. (2018b), Ren et al. (2019b) and Artetxe et al. (2019) combine unsupervised NMT with unsupervised phrase-based MT. On the other hand, one can also avoid the long iterative training by applying a separate denoiser directly to the word-by-word translations from cross-lingual word embeddings (Kim et al., 2018; Pourdamghani et al., 2019). Unsupervised NMT approaches have been so far evaluated mostly on high-resource language pairs, e.g. French→English, for academic purposes. In terms of practicality, they tend to underperform in low-resource language pairs, e.g. Azerbaijani→English (Neubig and Hu, 2018) or Nepali→English (Guzmán et al., 2019). To the best of our knowledge, this work is the first to systematically evaluate and analyze unsupervised learning for NMT in various data settings. 3 Unsupervised NMT This section reviews the core concepts of the recent unsupervised NMT framework and describes to which points they are p"
2020.eamt-1.5,P11-1002,0,0.0631102,"ly. Here is a summary of our contributions: • We thoroughly evaluate the performance of state-of-the-art unsupervised NMT in numerous real and artificial translation tasks. • We provide guidelines on whether to employ unsupervised NMT in practice, by showing how much bilingual data is sufficient to outperform the unsupervised results. • We clarify which factors make unsupervised NMT weak and which points must be improved, by analyzing the results both quantitatively and qualitatively. 2 Related Work The idea of unsupervised MT dates back to wordbased decipherment methods (Knight et al., 2006; Ravi and Knight, 2011). They learn only lexicon models at first, but add alignment models (Dou et al., 2014; Nuhn, 2019) or heuristic features (Naim et al., 2018) later. Finally, Artetxe et al. (2018a) and Lample et al. (2018b) train a fully-fledged phrase-based MT system in an unsupervised way. With neural networks, unsupervised learning of a sequence-to-sequence NMT model has been proposed by Lample et al. (2018a) and Artetxe et al. (2018b). Though having slight variations (Yang et al., 2018; Sun et al., 2019; Sen et al., 2019), unsupervised NMT approaches commonly 1) learn a shared model for both source→target a"
2020.eamt-1.5,D19-1071,0,0.330321,"ranslation model only with monolingual corpora, was † The author is now at DeepL GmbH. c 2020 The authors. This article is licensed under a Creative Commons 3.0 licence, no derivative works, attribution, CCBY-ND. proposed for those scenarios which lack bilingual data (Artetxe et al., 2018b; Lample et al., 2018a). Despite its progress in research, the performance of the unsupervised methods has been evaluated mostly on high-resource language pairs, e.g. German↔English or French↔English (Artetxe et al., 2018b; Lample et al., 2018a; Yang et al., 2018; Artetxe et al., 2018a; Lample et al., 2018b; Ren et al., 2019b; Artetxe et al., 2019; Sun et al., 2019; Sen et al., 2019). For these language pairs, huge bilingual corpora are already available, so there is no need for unsupervised learning in practice. Empirical results in these tasks do not carry over to low-resource language pairs; they simply fail to produce any meaningful translations (Neubig and Hu, 2018; Guzmán et al., 2019). This paper aims for a more comprehensive and pragmatic study on the performance of unsupervised NMT. Our experiments span ten translation tasks in the following five language pairs: • German↔English: similar languages, abund"
2020.eamt-1.5,J03-3002,0,0.317443,"uistic dissimilarity and domain mismatch between source and target monolingual data. Such conditions are common for low-resource language pairs, where unsupervised learning works poorly. In all of our experiments, supervised and semi-supervised baselines with 50k-sentence bilingual data outperform the best unsupervised results. Our analyses pinpoint the limits of the current unsupervised NMT and also suggest immediate research directions. 1 Introduction Statistical methods for machine translation (MT) require a large set of sentence pairs in two languages to build a decent translation system (Resnik and Smith, 2003; Koehn, 2005). Such bilingual data is scarce for most language pairs and its quality varies largely over different domains (AlOnaizan et al., 2002; Chu and Wang, 2018). Neural machine translation (NMT) (Bahdanau et al., 2015; Vaswani et al., 2017), the standard paradigm of MT these days, has been claimed to suffer from the data scarcity more severely than phrase-based MT (Koehn and Knowles, 2017). Unsupervised NMT, which trains a neural translation model only with monolingual corpora, was † The author is now at DeepL GmbH. c 2020 The authors. This article is licensed under a Creative Commons"
2020.eamt-1.5,P18-2062,0,0.0217554,"ts other than limited adequacy/fluency? Another problem is that the model cannot distinguish words that appear in the same context. In the second example, the model knows that Vier in German (Four in English) is a number, but it generates a wrong number in English (Eight). The initial LM is trained to predict either Four or Eight given the same surrounding words (e.g. 1856, things) and has no clue to map Four to Vier. The model cannot learn these mappings by itself with back-translations. This problem can be partly solved by subword modeling (Bojanowski et al., 2017) or orthographic features (Riley and Gildea, 2018; Artetxe et al., 2019), which are however not effective for language pairs with disjoint alphabets. 5 Conclusion and Outlook In this paper, we examine the state-of-the-art unsupervised NMT in a wide range of tasks and data settings. We find that the performance of unsupervised NMT is seriously affected by these factors: • Linguistic similarity of source and target languages • Domain similarity of training data between source and target languages It is very hard to fulfill these in low-/zero-resource language pairs, which makes the current unsupervised NMT useless in practice. We also find tha"
2020.eamt-1.5,2008.iwslt-papers.6,0,0.0382316,"al., 2019a; Conneau and Lample, 2019). Note that the network sharing is less effective among linguistically distinct languages in NMT (Kocmi and Bojar, 2018; Kim et al., 2019a). It still works as a regularizer, but transferring knowledge is harder if the morphology or word order is quite different. We show how well unsupervised NMT performs on such language pairs in Section 4.1. 3.2 Iterative Back-Translation Unsupervised learning for MT assumes no bilingual data for training. A traditional remedy for the data scarcity is generating synthetic bilingual data from monolingual text (Koehn, 2005; Schwenk, 2008; Sennrich et al., 2016a). To train a bidirectional model of Section 3.1, we need bilingual data of both translation directions. Therefore, most unsupervised NMT methods back-translate in both directions, i.e. source and target monolingual data to target and source language, respectively. In unsupervised learning, the synthetic data should be created not only once at the beginning but also repeatedly throughout the training. At the early stages of training, the model might be too weak to generate good translations. Hence, most methods update the training data as the model gets improved during"
2020.eamt-1.5,P19-1297,0,0.392459,"uthor is now at DeepL GmbH. c 2020 The authors. This article is licensed under a Creative Commons 3.0 licence, no derivative works, attribution, CCBY-ND. proposed for those scenarios which lack bilingual data (Artetxe et al., 2018b; Lample et al., 2018a). Despite its progress in research, the performance of the unsupervised methods has been evaluated mostly on high-resource language pairs, e.g. German↔English or French↔English (Artetxe et al., 2018b; Lample et al., 2018a; Yang et al., 2018; Artetxe et al., 2018a; Lample et al., 2018b; Ren et al., 2019b; Artetxe et al., 2019; Sun et al., 2019; Sen et al., 2019). For these language pairs, huge bilingual corpora are already available, so there is no need for unsupervised learning in practice. Empirical results in these tasks do not carry over to low-resource language pairs; they simply fail to produce any meaningful translations (Neubig and Hu, 2018; Guzmán et al., 2019). This paper aims for a more comprehensive and pragmatic study on the performance of unsupervised NMT. Our experiments span ten translation tasks in the following five language pairs: • German↔English: similar languages, abundant bilingual/monolingual data • Russian↔English: distant la"
2020.eamt-1.5,P19-1021,0,0.0332722,"Missing"
2020.eamt-1.5,P16-1009,0,0.571234,"→English (Neubig and Hu, 2018) or Nepali→English (Guzmán et al., 2019). To the best of our knowledge, this work is the first to systematically evaluate and analyze unsupervised learning for NMT in various data settings. 3 Unsupervised NMT This section reviews the core concepts of the recent unsupervised NMT framework and describes to which points they are potentially vulnerable. 3.1 Bidirectional Modeling Most of the unsupervised NMT methods share the model parameters between source→target and target→source directions. They also often share a joint subword vocabulary across the two languages (Sennrich et al., 2016b). Sharing a model among different translation tasks has been shown to be effective in multilingual NMT (Firat et al., 2016; Johnson et al., 2017; Aharoni et al., 2019), especially in improving performance on low-resource language pairs. This is due to the commonality of natural languages; learning to represent a language is helpful to represent other languages, e.g. by transferring knowledge of general sentence structures. It also provides good regularization for the model. Unsupervised learning is an extreme scenario of MT, where bilingual information is very weak. To supplement the weak an"
2020.eamt-1.5,P16-1162,0,0.850984,"→English (Neubig and Hu, 2018) or Nepali→English (Guzmán et al., 2019). To the best of our knowledge, this work is the first to systematically evaluate and analyze unsupervised learning for NMT in various data settings. 3 Unsupervised NMT This section reviews the core concepts of the recent unsupervised NMT framework and describes to which points they are potentially vulnerable. 3.1 Bidirectional Modeling Most of the unsupervised NMT methods share the model parameters between source→target and target→source directions. They also often share a joint subword vocabulary across the two languages (Sennrich et al., 2016b). Sharing a model among different translation tasks has been shown to be effective in multilingual NMT (Firat et al., 2016; Johnson et al., 2017; Aharoni et al., 2019), especially in improving performance on low-resource language pairs. This is due to the commonality of natural languages; learning to represent a language is helpful to represent other languages, e.g. by transferring knowledge of general sentence structures. It also provides good regularization for the model. Unsupervised learning is an extreme scenario of MT, where bilingual information is very weak. To supplement the weak an"
2020.eamt-1.5,P18-1072,0,0.0515918,"Missing"
2020.eamt-1.5,P19-1119,0,0.299043,"rpora, was † The author is now at DeepL GmbH. c 2020 The authors. This article is licensed under a Creative Commons 3.0 licence, no derivative works, attribution, CCBY-ND. proposed for those scenarios which lack bilingual data (Artetxe et al., 2018b; Lample et al., 2018a). Despite its progress in research, the performance of the unsupervised methods has been evaluated mostly on high-resource language pairs, e.g. German↔English or French↔English (Artetxe et al., 2018b; Lample et al., 2018a; Yang et al., 2018; Artetxe et al., 2018a; Lample et al., 2018b; Ren et al., 2019b; Artetxe et al., 2019; Sun et al., 2019; Sen et al., 2019). For these language pairs, huge bilingual corpora are already available, so there is no need for unsupervised learning in practice. Empirical results in these tasks do not carry over to low-resource language pairs; they simply fail to produce any meaningful translations (Neubig and Hu, 2018; Guzmán et al., 2019). This paper aims for a more comprehensive and pragmatic study on the performance of unsupervised NMT. Our experiments span ten translation tasks in the following five language pairs: • German↔English: similar languages, abundant bilingual/monolingual data • Russian↔"
2020.eamt-1.5,P18-1005,0,0.431053,"hn and Knowles, 2017). Unsupervised NMT, which trains a neural translation model only with monolingual corpora, was † The author is now at DeepL GmbH. c 2020 The authors. This article is licensed under a Creative Commons 3.0 licence, no derivative works, attribution, CCBY-ND. proposed for those scenarios which lack bilingual data (Artetxe et al., 2018b; Lample et al., 2018a). Despite its progress in research, the performance of the unsupervised methods has been evaluated mostly on high-resource language pairs, e.g. German↔English or French↔English (Artetxe et al., 2018b; Lample et al., 2018a; Yang et al., 2018; Artetxe et al., 2018a; Lample et al., 2018b; Ren et al., 2019b; Artetxe et al., 2019; Sun et al., 2019; Sen et al., 2019). For these language pairs, huge bilingual corpora are already available, so there is no need for unsupervised learning in practice. Empirical results in these tasks do not carry over to low-resource language pairs; they simply fail to produce any meaningful translations (Neubig and Hu, 2018; Guzmán et al., 2019). This paper aims for a more comprehensive and pragmatic study on the performance of unsupervised NMT. Our experiments span ten translation tasks in the following"
2020.eamt-1.5,Q17-1024,0,\N,Missing
2020.eamt-1.5,2020.tacl-1.47,0,\N,Missing
2020.findings-emnlp.155,D19-1079,0,0.297248,"roved significantly and consistently on various MT tasks. • We compare our method with the similar training method, i.e. T/S learning and conditional T/S learning (Meng et al., 2019), and provide Related Work T/S Learning Knowledge distillation is first introduced by Buciluˇa et al. (2006) and re-gains popularity due to Li et al. (2014) and Hinton et al. (2015). Currently, T/S learning and its variants can be roughly divided into two paradigms: a fixed pre-trained teacher model (Li et al., 2014; Hinton et al., 2015; Meng et al., 2019) and a dynamic cotrained teacher model (Zhang et al., 2018; Bi et al., 2019). For the former, the student learns from both hard targets and soft posteriors generated by a fixed teacher. For the latter, multiple co-trained students are considered as a teacher to one another, also known as mutual learning (Zhang et al., 2018). Alternatively, an ensemble integrated by multiple co-trained agents can also be treated as a teacher to all agents (Bi et al., 2019). Dual Learning Dual learning (He et al., 2016) or multi-agent dual learning (Wang et al., 2018) is to leverage the duality between the primal task and the dual task. The source and target domains for these two tasks"
2020.findings-emnlp.155,P17-1176,0,0.143195,"i et al., 2017; Edunov et al., 2018). Conventional training of the NMT models with hard targets limits the models’ generalization ability (Szegedy et al., 2016; Pereyra et al., 2017). This has led to a rapid growth of research in developing more regularized models. Teacher-student (T/S) learning (Li et al., 2014; Hinton et al., 2015; Meng et al., 2019) is an effective method to handle this problem. It has been widely applied in many cases, e.g. model compression (Li et al., 2014; Hinton et al., 2015), domain adaptation (Li et al., 2017; Meng et al., 2018) and low-resource machine translation (Chen et al., 2017). T/S learning is a strategy that trains a student model with both hard targets and soft posteriors produced by a pre-trained teacher model (Li et al., 2014). Because training with soft targets provides smoother output distribution, T/S learning could outperform the single model training (Li et al., 2014; Hinton et al., 2015; Meng et al., 2018). However, does a teacher always outperform a student? In order to evaluate the pros and cons of different models, we conduct experiments on two different architectures. Table 1 shows the translation quality from various models. Arch1 outperforms Arch2 f"
2020.findings-emnlp.155,D18-1045,0,0.0198293,"orithm. Our experiments show that sequential mutual learning at the sentence-level and the token-level improves the results cumulatively. Absolute improvements compared to strong baselines are obtained on various translation tasks. On the IWSLT’14 German-English task, we get a new state-of-the-art BLEU score of 37.0. We also report a competitive result, 29.9 BLEU score, on the WMT’14 English-German task. 1 Introduction Neural machine translation (NMT) has achieved significant progress over recent years (Sutskever et al., 2014; Bahdanau et al., 2015; Gehring et al., 2017; Vaswani et al., 2017; Edunov et al., 2018). Conventional training of the NMT models with hard targets limits the models’ generalization ability (Szegedy et al., 2016; Pereyra et al., 2017). This has led to a rapid growth of research in developing more regularized models. Teacher-student (T/S) learning (Li et al., 2014; Hinton et al., 2015; Meng et al., 2019) is an effective method to handle this problem. It has been widely applied in many cases, e.g. model compression (Li et al., 2014; Hinton et al., 2015), domain adaptation (Li et al., 2017; Meng et al., 2018) and low-resource machine translation (Chen et al., 2017). T/S learning is"
2020.findings-emnlp.155,P17-1138,0,0.0655091,"Missing"
2020.findings-emnlp.155,2020.coling-main.386,1,0.712715,"loss between the empirical distribution and the model distribution p, which can be written as: L=− I X V X ✶{ei = v}logp(ˆei = v) (2) i=1 v=1 where ✶{·} is the indicator function. The objective function only takes care of the probabilities of target tokens and omit the probabilities of rival tokens according to Equation (2), where no explicit regularization is introduced. One could make the model generalize better by discounting a certain probability mass from the one-hot target distribution and interpolate with a uniform prior over the vocabulary (Szegedy et al., 2016; Pereyra et al., 2017; Gao et al., 2020a,b), which is also known as label smoothing. Then the loss function is: L=− I X V X pr(ei )logp(ˆ ei = v) (3) i=1 v=1 with: pr(ei ) =  1 − α , if ei = v α , otherwise V −1 (4) with the discounted probability mass α, where 0 ≤ α ≤ 1. Empirically, we choose α = 0.1. Compared to using hard targets, label smoothing assigns some probability mass to the rival labels. Apart from label smoothing, mutual learning (ML) (Zhang et al., 2018) is another method to regularize the models. Multi-agent ML with three agents is illustrated in Figure 1a. Some studies have shown that one agent could perform bette"
2020.findings-emnlp.155,2020.aacl-main.25,1,0.695055,"loss between the empirical distribution and the model distribution p, which can be written as: L=− I X V X ✶{ei = v}logp(ˆei = v) (2) i=1 v=1 where ✶{·} is the indicator function. The objective function only takes care of the probabilities of target tokens and omit the probabilities of rival tokens according to Equation (2), where no explicit regularization is introduced. One could make the model generalize better by discounting a certain probability mass from the one-hot target distribution and interpolate with a uniform prior over the vocabulary (Szegedy et al., 2016; Pereyra et al., 2017; Gao et al., 2020a,b), which is also known as label smoothing. Then the loss function is: L=− I X V X pr(ei )logp(ˆ ei = v) (3) i=1 v=1 with: pr(ei ) =  1 − α , if ei = v α , otherwise V −1 (4) with the discounted probability mass α, where 0 ≤ α ≤ 1. Empirically, we choose α = 0.1. Compared to using hard targets, label smoothing assigns some probability mass to the rival labels. Apart from label smoothing, mutual learning (ML) (Zhang et al., 2018) is another method to regularize the models. Multi-agent ML with three agents is illustrated in Figure 1a. Some studies have shown that one agent could perform bette"
2020.findings-emnlp.155,P84-1044,0,0.482808,"Missing"
2020.findings-emnlp.155,N19-4009,0,0.0186863,"ounts of parallel sentence pairs for training, validation and testing. On WMT’14 En-De, we choose the WMT’16 training set and sample 4.5M parallel sentence pairs for training (Ott et al., 2018), employ newstest 2013 as the validation set and use newstest 2014 as the testing set (Vaswani et al., 2017). For all language pairs, we use byte-pair encoding (Sennrich et al., 2015) with shared vocabularies. Model Architecture We mainly employ three types of the Transformer model (Vaswani et al., 2017), i.e. Transformer small, Transformer base and Transformer big, implemented in the fairseqpy toolkit (Ott et al., 2019). Transformer base and Transformer big stay the same as Vaswani et al. (2017). The difference between Transformer small and Transformer base is that each encoder and decoder layer in Transformer small employs a word representation size of 512, a feed-forward layer dimension of 1024 and 4 attention heads. Transformer small is used for the small-scale IWSLT’14 De-En and IWSLT’14 Nl-En datasets with a dropout rate of 0.3. Transformer base is applied for the middle-scale WMT’16 Ro-En and large-scale WMT’14 En-De with a dropout rate of 0.1. Transformer big is also employed for the largescale WMT’14"
2020.findings-emnlp.155,W18-6301,0,0.0267372,"on multiple benchmark MT datasets to evaluate the effectiveness of the proposed method, including IWSLT’14 German-English (De-En), IWSLT’14 Dutch-English (Nl-En), WMT’16 RomanianEnglish (Ro-En) and WMT’14 English-German (En-De). The amount of parallel sentence pairs for different MT tasks is shown in Table 2. Following Edunov et al. (2017), we split IWSLT’14 De-En, IWSLT’14 Nl-En and WMT’16 Ro-En datasets into various amounts of parallel sentence pairs for training, validation and testing. On WMT’14 En-De, we choose the WMT’16 training set and sample 4.5M parallel sentence pairs for training (Ott et al., 2018), employ newstest 2013 as the validation set and use newstest 2014 as the testing set (Vaswani et al., 2017). For all language pairs, we use byte-pair encoding (Sennrich et al., 2015) with shared vocabularies. Model Architecture We mainly employ three types of the Transformer model (Vaswani et al., 2017), i.e. Transformer small, Transformer base and Transformer big, implemented in the fairseqpy toolkit (Ott et al., 2019). Transformer base and Transformer big stay the same as Vaswani et al. (2017). The difference between Transformer small and Transformer base is that each encoder and decoder la"
2020.findings-emnlp.155,P02-1040,0,0.107067,"ansformer big with an initial learning rate of 5e-4. We use a batch size (the number of tokens) of 4K for Transformer small and Transformer small7, a batch size of 25K for Transformer base and Transformer big. If the batch size can not be set as the number above because of memory limit, we accumulate gradients to match it. We use the same settings for the optimization and learning rate as Gehring et al. (2017) for ConvS2S with a batch size of 4K. We use beam search with a beam size of five and length penalty of 0.6 to generate translations for all of the models. The evaluation metric is BLEU (Papineni et al., 2002). For IWSLT’14 De-En and IWSLT’14 Nl-En, we use a single Nvidia GTX 1080Ti GPU to train 2, 3 and 4 co-trained Transformer small for 1.5, 2 and 3 days, respectively. For WMT’16 Ro-En, we use a single GPU to train 2, 3 and 4 co-trained Transformer base for 2, 3.5 and 4.5 days, respectively. For WMT’14 En-De, we use four GPUs to train 2, 3 and 4 Transformer base for 10, 13 and 18 days, respectively. For WMT’14 En-De, we also use four GPUs to train 2, 3 and 4 Transformer big for 12, 18 and 21 days, respectively. 1719 Method Transformer small T/S Conditional T/S Asymmetric SML Symmetric SML IWSLT’1"
2020.wmt-1.71,N18-1118,0,0.603811,"u et al., 2015) and more recently the Transformer architecture (Vaswani et al., 2017), there remain challenges which can not be solved by using sentence-level NMT systems. Among other issues, this includes the problem of inter-sentential anaphora resolution (Guillou et al., 2018) or the consistent translation across a document (L¨aubli et al., 2018), for which the system inevitably needs document-level context information. In recent years, many works have focused on changing existing NMT architectures to incorporate context information in the translation process (Tiedemann and Scherrer, 2017; Bawden et al., 2018; Voita et al., 2018). However, often times results are reported only on very specific tasks (most commonly subtitle translation), making it difficult to assess the potential of the different methods in a more general setting. This, together with the fact that big improvements are typically reported on low resource tasks, gives the impression that documentlevel NMT mostly improves due to regularization rather than from leveraging the additional context information. In this work we want to give a more complete overview of the current state of documentlevel NMT by comparing various approaches on"
2020.wmt-1.71,W18-6315,0,0.0211658,"main data. 3.3 Document-level Back-translation While there exist many works showing the improvements of context-aware systems, some major aspects are typically not covered - one of them being back-translation (Sennrich et al., 2016a). Backtranslation is an integral part when building the strongest possible systems and is currently the best way to include monolingual data in the training of a NMT system. It uses an inverse, target-to-source, MT model to generate synthetic source sentences given target-side monolingual sentences. There exists a series of works on this topic (Hoang et al., 2018; Burlot and Yvon, 2018; Grac¸a et al., 2019). However, the underlying inverse MT model used so far is mostly on the sentence level. In this work, we argue that back-translation could be even more crucial when training document-level NMT systems, since even for common language pairs like German-English we have very limited amounts of parallel document-level data while having an abundance of monolingual document-level data. In addition, except for using a sentence-level inverse NMT model, we also introduce a document-level inverse MT model to generate pseudo source documents given monolingual target-side documents. T"
2020.wmt-1.71,W09-2404,0,0.0325295,"ext. Similarly, Tu et al. (2018) augment their NMT system with an external cache to memorize the translation history. Werlen et al. (2018) integrate two hierarchical attention networks (HAN) (Yang et al., 2016) in the NMT model to take account for source and target context. Maruf et al. (2019) apply a hierarchical attention module on sentences and words in the context to select contextual information that is more relevant to the current sentence. Related Works The discourse- or document-level translation is a long-standing and unsolved topic in the machine translation community (Mitkov, 1999; Carpuat, 2009; Hardmeier, 2014). Although neural machine translation (Sutskever et al., 2014; Bahdanau et al., 2015; Vaswani et al., 2017) has recently become the dominant translation paradigm that provides superior performance, the independence between sentences is still the fundamental assumption taken for granted by most NMT systems. This means, that discourse-level phenomena between sentences such as pronominal reference, consistent lexical choice, and verbal tenses, etc. can not be addressed by these sentence-level NMT systems (L¨aubli et al., 2018; Guillou et al., 2018). The current NMT approaches ta"
2020.wmt-1.71,2020.autosimtrans-1.5,0,0.124097,"e context, Tiedemann and Scherrer (2017) concatenate consecutive sentences as input to the NMT system, while Jean et al. (2017); Bawden et al. (2018); Zhang et al. (2018) use an additional encoder to extract contextual information from a few previous source-side sentences. These works only consider a local context, including a few previous sentences. Some researches seek to capture the global document context; Wang et al. (2017) summarize the global context from all previous sentences in a document with a pre-trained hierarchical RNN and then use it for updating decoder states. Very recently, Chen et al. (2020) proposed a discourse structure-based encoder that takes account of the discourse structure information of the input document. For adding additional target-side context, Tiedemann and Scherrer (2017); Agrawal et al. (2018) conduct multi-sentences decoding and observe only a minor improvement. Maruf and Haffari (2018) For incorporating document-level monolingual data from the source language, Zhu et al. (2020) use BERT (Devlin et al., 2019) to model the sourceside context and integrate it with the encoder and decoder of the NMT model. Junczys-Dowmunt (2019) share the parameters of a BERT-style"
2020.wmt-1.71,N19-1423,0,0.422571,"e the global context from all previous sentences in a document with a pre-trained hierarchical RNN and then use it for updating decoder states. Very recently, Chen et al. (2020) proposed a discourse structure-based encoder that takes account of the discourse structure information of the input document. For adding additional target-side context, Tiedemann and Scherrer (2017); Agrawal et al. (2018) conduct multi-sentences decoding and observe only a minor improvement. Maruf and Haffari (2018) For incorporating document-level monolingual data from the source language, Zhu et al. (2020) use BERT (Devlin et al., 2019) to model the sourceside context and integrate it with the encoder and decoder of the NMT model. Junczys-Dowmunt (2019) share the parameters of a BERT-style encoder trained on monolingual documents with the MT model. To utilize the document-level monolingual data from the target language, Junczys-Dowmunt (2019) also submit a system that trained on the combination of real and synthetic document-parallel data obtained by back-translation. However, they do not consider document-level back-translation. Voita et al. (2019a) proposed a document-level postediting system which is trained only using th"
2020.wmt-1.71,W19-5205,1,0.893218,"Missing"
2020.wmt-1.71,W18-6435,0,0.238792,"nomena like pronoun resolution or headline translation to give 604 Proceedings of the 5th Conference on Machine Translation (WMT), pages 604–616 c Online, November 19–20, 2020. 2020 Association for Computational Linguistics an interpretation of the potential improvements from leveraging context information. • We study the effects of utilizing documentlevel monolingual data via back-translation and report significant improvements particularly for document-level NMT systems. 2 apply cache-based models to store vector representations for both source- and target-side context. Similarly, Tu et al. (2018) augment their NMT system with an external cache to memorize the translation history. Werlen et al. (2018) integrate two hierarchical attention networks (HAN) (Yang et al., 2016) in the NMT model to take account for source and target context. Maruf et al. (2019) apply a hierarchical attention module on sentences and words in the context to select contextual information that is more relevant to the current sentence. Related Works The discourse- or document-level translation is a long-standing and unsolved topic in the machine translation community (Mitkov, 1999; Carpuat, 2009; Hardmeier, 2014)."
2020.wmt-1.71,P14-6007,0,0.0207077,"Tu et al. (2018) augment their NMT system with an external cache to memorize the translation history. Werlen et al. (2018) integrate two hierarchical attention networks (HAN) (Yang et al., 2016) in the NMT model to take account for source and target context. Maruf et al. (2019) apply a hierarchical attention module on sentences and words in the context to select contextual information that is more relevant to the current sentence. Related Works The discourse- or document-level translation is a long-standing and unsolved topic in the machine translation community (Mitkov, 1999; Carpuat, 2009; Hardmeier, 2014). Although neural machine translation (Sutskever et al., 2014; Bahdanau et al., 2015; Vaswani et al., 2017) has recently become the dominant translation paradigm that provides superior performance, the independence between sentences is still the fundamental assumption taken for granted by most NMT systems. This means, that discourse-level phenomena between sentences such as pronominal reference, consistent lexical choice, and verbal tenses, etc. can not be addressed by these sentence-level NMT systems (L¨aubli et al., 2018; Guillou et al., 2018). The current NMT approaches tackling inter-sente"
2020.wmt-1.71,2010.iwslt-papers.10,0,0.0958999,"Missing"
2020.wmt-1.71,W15-2501,0,0.0243703,", although relevant, there is doubt if the metrics like BLEU score (Papineni et al., 2002) can capture these complex rep(e i |ei1− 1 , f pre BREAK f cur ) ¯ ¯ lationships (Le Nagard and Koehn, 2010; Hardmeier and Federico, 2010). To get more insights into the capacities dealing with discourse-level phenomena of their MT models, some researchers use more targeted evaluation scores (Wong et al., 2020), like the Accuracy of Pronoun Translation (APT) Werlen and Popescu-Belis (2017), or they evaluate their systems on some specific test suites that contain more and more complex discourse phenomena (Hardmeier et al., 2015; Guillou et al., 2018; M¨uller et al., 2018; Voita et al., 2019b). 3 Feed Forward L× encoder Add & Norm Add & Norm Src-trg Attention Feed Forward Add & Norm Add & Norm Document-level NMT In this section, we first describe several commonly used context-aware NMT architectures and highlight the differences among them, largely following the work by Kim et al. (2019). Afterwards, we describe one radical attempt to represent the document-level context in one single embedding vector using BERT (Devlin et al., 2019). Finally, we explain our proposed paradigm to use documentlevel back-translation in"
2020.wmt-1.71,W18-2703,0,0.0183797,"as supplement in-domain data. 3.3 Document-level Back-translation While there exist many works showing the improvements of context-aware systems, some major aspects are typically not covered - one of them being back-translation (Sennrich et al., 2016a). Backtranslation is an integral part when building the strongest possible systems and is currently the best way to include monolingual data in the training of a NMT system. It uses an inverse, target-to-source, MT model to generate synthetic source sentences given target-side monolingual sentences. There exists a series of works on this topic (Hoang et al., 2018; Burlot and Yvon, 2018; Grac¸a et al., 2019). However, the underlying inverse MT model used so far is mostly on the sentence level. In this work, we argue that back-translation could be even more crucial when training document-level NMT systems, since even for common language pairs like German-English we have very limited amounts of parallel document-level data while having an abundance of monolingual document-level data. In addition, except for using a sentence-level inverse NMT model, we also introduce a document-level inverse MT model to generate pseudo source documents given monolingual t"
2020.wmt-1.71,W19-5321,0,0.027266,"r updating decoder states. Very recently, Chen et al. (2020) proposed a discourse structure-based encoder that takes account of the discourse structure information of the input document. For adding additional target-side context, Tiedemann and Scherrer (2017); Agrawal et al. (2018) conduct multi-sentences decoding and observe only a minor improvement. Maruf and Haffari (2018) For incorporating document-level monolingual data from the source language, Zhu et al. (2020) use BERT (Devlin et al., 2019) to model the sourceside context and integrate it with the encoder and decoder of the NMT model. Junczys-Dowmunt (2019) share the parameters of a BERT-style encoder trained on monolingual documents with the MT model. To utilize the document-level monolingual data from the target language, Junczys-Dowmunt (2019) also submit a system that trained on the combination of real and synthetic document-parallel data obtained by back-translation. However, they do not consider document-level back-translation. Voita et al. (2019a) proposed a document-level postediting system which is trained only using the monolingual document-level corpus. Recently, there has been a tendency in the community to conclude that the context"
2020.wmt-1.71,D19-6503,1,0.838167,"Missing"
2020.wmt-1.71,P17-4012,0,0.0398556,"sentences where the coreference is resolved intersententially. This results in a targeted test set containing more inter-sentential discourse phenomena. The detailed statistics of these two targeted test sets are given in Table 2. All language pairs are preprocessed with the Moses tokenizer7 except for the Chinese corpus which is preprocessed with the chinese text segmentation tool “jieba”8 . We apply byte pair encoding (Sennrich et al., 2016b) with 32k merge operations jointly for source and target languages. 4.2 Experimental setting All models are implemented in open-source toolkit OpenNMT (Klein et al., 2017). For the sentencelevel baseline system, we follow a 6-layer base Transformer model (Vaswani et al., 2017) and set the hidden size and embedding size as 512 and the dimension of the feed-forward layer as 2048. We use 8 heads for multi-head attention. For our context-aware models, we extend baseline system to include additional encoder with the same setting. In training, we use Adam optimizer (Kingma and Ba, 2014) or its variant Lazy Adam Optimizer for optimization and follow the learning rate schedule described in (Vaswani et al., 2017). The learning rate scale factor and warm-up steps are dif"
2020.wmt-1.71,D18-1512,0,0.0573294,"Missing"
2020.wmt-1.71,W10-1737,0,0.100641,"Missing"
2020.wmt-1.71,2020.acl-main.322,0,0.203444,"Missing"
2020.wmt-1.71,L16-1147,0,0.0223124,"am size 5 and concatenate the resulting bilingual synthetic data with the real documents in the newscommentary v14 dataset (En-De). Finally, we compare the performance of a sentence-level baseline (En-De) and a context-aware model, Single Encoder (2to2), on both concatenated corpora. To our knowledge, this is the first attempt to explore the document-level back-translation data systematically (see Section 4.3.5). 4 4.1 Experiments Datasets We experiment with various parallel documentlevel datasets including IWSLT TED talk EnglishItalian,2 WMT news-commentary v14 EnglishGerman,3 OpenSubtitles (Lison and Tiedemann, 2016) v2018 English-German4 and an additional inhouse e-commerce English-Chinese dataset. The test sets for the former two are the IWSLT 2017 test set and WMT newstest2018, respectively; for the latter two, we have created the dev and test sets ourselves by doing appropriate splits to the complete dataset.5 The data statistics of bilingual corpora used for fine-tuning context-aware models are summarized in Table 1. In the IWSLT, WMT and OpenSubtitles datasets, there exists a boundary between documents. We first take them as sentence-level corpora to train the baseline and further fine-tune the cont"
2020.wmt-1.71,P18-1118,0,0.0483478,"ext, including a few previous sentences. Some researches seek to capture the global document context; Wang et al. (2017) summarize the global context from all previous sentences in a document with a pre-trained hierarchical RNN and then use it for updating decoder states. Very recently, Chen et al. (2020) proposed a discourse structure-based encoder that takes account of the discourse structure information of the input document. For adding additional target-side context, Tiedemann and Scherrer (2017); Agrawal et al. (2018) conduct multi-sentences decoding and observe only a minor improvement. Maruf and Haffari (2018) For incorporating document-level monolingual data from the source language, Zhu et al. (2020) use BERT (Devlin et al., 2019) to model the sourceside context and integrate it with the encoder and decoder of the NMT model. Junczys-Dowmunt (2019) share the parameters of a BERT-style encoder trained on monolingual documents with the MT model. To utilize the document-level monolingual data from the target language, Junczys-Dowmunt (2019) also submit a system that trained on the combination of real and synthetic document-parallel data obtained by back-translation. However, they do not consider docu"
2020.wmt-1.71,N19-1313,0,0.124575,"potential improvements from leveraging context information. • We study the effects of utilizing documentlevel monolingual data via back-translation and report significant improvements particularly for document-level NMT systems. 2 apply cache-based models to store vector representations for both source- and target-side context. Similarly, Tu et al. (2018) augment their NMT system with an external cache to memorize the translation history. Werlen et al. (2018) integrate two hierarchical attention networks (HAN) (Yang et al., 2016) in the NMT model to take account for source and target context. Maruf et al. (2019) apply a hierarchical attention module on sentences and words in the context to select contextual information that is more relevant to the current sentence. Related Works The discourse- or document-level translation is a long-standing and unsolved topic in the machine translation community (Mitkov, 1999; Carpuat, 2009; Hardmeier, 2014). Although neural machine translation (Sutskever et al., 2014; Bahdanau et al., 2015; Vaswani et al., 2017) has recently become the dominant translation paradigm that provides superior performance, the independence between sentences is still the fundamental assum"
2020.wmt-1.71,W18-6307,0,0.0473732,"Missing"
2020.wmt-1.71,P02-1040,0,0.106859,"ntext with some random signal and show that random signals can achieve the same level improvement as the real context. However, it should be taken with a grain of salt since solving this task, along with the analysis, is quite challenging. There are many impact factors from the architecture, the data at hand, to the metric being used for evaluation. 605 One issue that can not be ignored in all discourserelated researches is the problem of evaluation. Since some discourse-level phenomena between sentences appear less frequently, although relevant, there is doubt if the metrics like BLEU score (Papineni et al., 2002) can capture these complex rep(e i |ei1− 1 , f pre BREAK f cur ) ¯ ¯ lationships (Le Nagard and Koehn, 2010; Hardmeier and Federico, 2010). To get more insights into the capacities dealing with discourse-level phenomena of their MT models, some researchers use more targeted evaluation scores (Wong et al., 2020), like the Accuracy of Pronoun Translation (APT) Werlen and Popescu-Belis (2017), or they evaluate their systems on some specific test suites that contain more and more complex discourse phenomena (Hardmeier et al., 2015; Guillou et al., 2018; M¨uller et al., 2018; Voita et al., 2019b)."
2020.wmt-1.71,N18-1202,0,0.0283269,"& Norm Masked Self Attention Output Embedding ei1− 1 Figure 2: Multi-Encoders Out-side of decoder approach (Out.). Another way to do the integration is to keep the representation of the current source sentence and the representation of the contexts separate and allow the decoder to have access to the context representations. Figure 3 shows a sequential integration inside of the decoder, where the decoder firstly attends to the current source representation, p( ei |ei1− 1 , f cur , f pre ) L× integrate it following the Multi-Encoders (In. Par.). Considering that a pre-trained model like ELMo (Peters et al., 2018) or BERT (Devlin et al., 2019) can capture rich representations of the input, it is apparent that one can also use it to model contextual information. Figure 5 shows the BERT-fused model proposed in Zhu et al. (2020), which uses a BERT encoder to obtain the BERT hidden representations HB on the concatenation of the context sentence fpre and the current source sentence fcur . HB is further fused into each layer of the encoder decoder layer Add & Norm Feed Forward Gated sum Add & Norm L× Context-trg Attention L× encoder Add & Norm encoder Add & Norm Feed Forward Feed Forward Add & Norm Src-trg A"
2020.wmt-1.71,W18-6319,0,0.0205505,"are models, we extend baseline system to include additional encoder with the same setting. In training, we use Adam optimizer (Kingma and Ba, 2014) or its variant Lazy Adam Optimizer for optimization and follow the learning rate schedule described in (Vaswani et al., 2017). The learning rate scale factor and warm-up steps are different for different datasets. In all our experiments, we share word embeddings over the source and the context. The context encoders are also initialized by the encoder of the sentence-level baseline. For automatic evaluation, we report casesensitive sacreBLEU score (Post, 2018) for all corpora except for e-commerce, on which the evaluation is done in Chinese character-level with caseinsensitive sacreBLEU. 4.3 Analysis 4.3.1 Performance in Terms of BLEU Table 3 shows the corpus-level BLEU-scores of all architectures on different tasks. For the baseline as well as the “source-side-only” systems we get similar results to Kim et al. (2019) on the IWSLT 7 6 https://github.com/huggingface/ neuralcoref 8 609 http://www.statmt.org/moses https://github.com/fxsjy/jieba System Baseline Single Encoder (2to1) Single Encoder (3to1) Multi-Encoders (Out.) Multi-Encoders (In. Seq.)"
2020.wmt-1.71,P16-1009,0,0.630009,"m leveraging the additional context information. In this work we want to give a more complete overview of the current state of documentlevel NMT by comparing various approaches on a variety of different tasks including an applicationoriented E-commerce setting. We discuss both, widely used performance metrics, as well as highly task-specific observations. Another important aspect when talking about document-level NMT is the applicability in “real life” settings. There, when faced with a low resource data scenario, back-translation is an established way of greatly improving system performance (Sennrich et al., 2016a). However, to the best of our knowledge, the effect of backtranslation data obtained and used by context-aware models has never been explored before. The main contributions of this paper are summarized below: • We explore several existing context-aware architectures on four diverse machine translation tasks, consisting of different domains and data quantities. • We examine the usage of context aware embeddings created by pre-trained monolingual models and study to what extent these embeddings can be simplified. • We conduct corpus studies and extensive analysis on corpus specific phenomena l"
2020.wmt-1.71,P16-1162,0,0.837774,"m leveraging the additional context information. In this work we want to give a more complete overview of the current state of documentlevel NMT by comparing various approaches on a variety of different tasks including an applicationoriented E-commerce setting. We discuss both, widely used performance metrics, as well as highly task-specific observations. Another important aspect when talking about document-level NMT is the applicability in “real life” settings. There, when faced with a low resource data scenario, back-translation is an established way of greatly improving system performance (Sennrich et al., 2016a). However, to the best of our knowledge, the effect of backtranslation data obtained and used by context-aware models has never been explored before. The main contributions of this paper are summarized below: • We explore several existing context-aware architectures on four diverse machine translation tasks, consisting of different domains and data quantities. • We examine the usage of context aware embeddings created by pre-trained monolingual models and study to what extent these embeddings can be simplified. • We conduct corpus studies and extensive analysis on corpus specific phenomena l"
2020.wmt-1.71,W17-4811,0,0.546353,"utskever et al., 2014; Bahdanau et al., 2015) and more recently the Transformer architecture (Vaswani et al., 2017), there remain challenges which can not be solved by using sentence-level NMT systems. Among other issues, this includes the problem of inter-sentential anaphora resolution (Guillou et al., 2018) or the consistent translation across a document (L¨aubli et al., 2018), for which the system inevitably needs document-level context information. In recent years, many works have focused on changing existing NMT architectures to incorporate context information in the translation process (Tiedemann and Scherrer, 2017; Bawden et al., 2018; Voita et al., 2018). However, often times results are reported only on very specific tasks (most commonly subtitle translation), making it difficult to assess the potential of the different methods in a more general setting. This, together with the fact that big improvements are typically reported on low resource tasks, gives the impression that documentlevel NMT mostly improves due to regularization rather than from leveraging the additional context information. In this work we want to give a more complete overview of the current state of documentlevel NMT by comparing"
2020.wmt-1.71,Q18-1029,0,0.0809472,"ecific phenomena like pronoun resolution or headline translation to give 604 Proceedings of the 5th Conference on Machine Translation (WMT), pages 604–616 c Online, November 19–20, 2020. 2020 Association for Computational Linguistics an interpretation of the potential improvements from leveraging context information. • We study the effects of utilizing documentlevel monolingual data via back-translation and report significant improvements particularly for document-level NMT systems. 2 apply cache-based models to store vector representations for both source- and target-side context. Similarly, Tu et al. (2018) augment their NMT system with an external cache to memorize the translation history. Werlen et al. (2018) integrate two hierarchical attention networks (HAN) (Yang et al., 2016) in the NMT model to take account for source and target context. Maruf et al. (2019) apply a hierarchical attention module on sentences and words in the context to select contextual information that is more relevant to the current sentence. Related Works The discourse- or document-level translation is a long-standing and unsolved topic in the machine translation community (Mitkov, 1999; Carpuat, 2009; Hardmeier, 2014)."
2020.wmt-1.71,D19-1081,0,0.224261,"Missing"
2020.wmt-1.71,P19-1116,0,0.126607,"Missing"
2020.wmt-1.71,P18-1117,0,0.299376,"ore recently the Transformer architecture (Vaswani et al., 2017), there remain challenges which can not be solved by using sentence-level NMT systems. Among other issues, this includes the problem of inter-sentential anaphora resolution (Guillou et al., 2018) or the consistent translation across a document (L¨aubli et al., 2018), for which the system inevitably needs document-level context information. In recent years, many works have focused on changing existing NMT architectures to incorporate context information in the translation process (Tiedemann and Scherrer, 2017; Bawden et al., 2018; Voita et al., 2018). However, often times results are reported only on very specific tasks (most commonly subtitle translation), making it difficult to assess the potential of the different methods in a more general setting. This, together with the fact that big improvements are typically reported on low resource tasks, gives the impression that documentlevel NMT mostly improves due to regularization rather than from leveraging the additional context information. In this work we want to give a more complete overview of the current state of documentlevel NMT by comparing various approaches on a variety of differe"
2020.wmt-1.71,D17-1301,0,0.038647,"nting NMT by • adding source-side context • including both source- and target-side context • utilizing source- and/or target-side documentlevel monolingual data To include the source-side context, Tiedemann and Scherrer (2017) concatenate consecutive sentences as input to the NMT system, while Jean et al. (2017); Bawden et al. (2018); Zhang et al. (2018) use an additional encoder to extract contextual information from a few previous source-side sentences. These works only consider a local context, including a few previous sentences. Some researches seek to capture the global document context; Wang et al. (2017) summarize the global context from all previous sentences in a document with a pre-trained hierarchical RNN and then use it for updating decoder states. Very recently, Chen et al. (2020) proposed a discourse structure-based encoder that takes account of the discourse structure information of the input document. For adding additional target-side context, Tiedemann and Scherrer (2017); Agrawal et al. (2018) conduct multi-sentences decoding and observe only a minor improvement. Maruf and Haffari (2018) For incorporating document-level monolingual data from the source language, Zhu et al. (2020) u"
2020.wmt-1.71,W17-4802,0,0.310281,"gnored in all discourserelated researches is the problem of evaluation. Since some discourse-level phenomena between sentences appear less frequently, although relevant, there is doubt if the metrics like BLEU score (Papineni et al., 2002) can capture these complex rep(e i |ei1− 1 , f pre BREAK f cur ) ¯ ¯ lationships (Le Nagard and Koehn, 2010; Hardmeier and Federico, 2010). To get more insights into the capacities dealing with discourse-level phenomena of their MT models, some researchers use more targeted evaluation scores (Wong et al., 2020), like the Accuracy of Pronoun Translation (APT) Werlen and Popescu-Belis (2017), or they evaluate their systems on some specific test suites that contain more and more complex discourse phenomena (Hardmeier et al., 2015; Guillou et al., 2018; M¨uller et al., 2018; Voita et al., 2019b). 3 Feed Forward L× encoder Add & Norm Add & Norm Src-trg Attention Feed Forward Add & Norm Add & Norm Document-level NMT In this section, we first describe several commonly used context-aware NMT architectures and highlight the differences among them, largely following the work by Kim et al. (2019). Afterwards, we describe one radical attempt to represent the document-level context in one s"
2020.wmt-1.71,D18-1325,0,0.0798507,"nference on Machine Translation (WMT), pages 604–616 c Online, November 19–20, 2020. 2020 Association for Computational Linguistics an interpretation of the potential improvements from leveraging context information. • We study the effects of utilizing documentlevel monolingual data via back-translation and report significant improvements particularly for document-level NMT systems. 2 apply cache-based models to store vector representations for both source- and target-side context. Similarly, Tu et al. (2018) augment their NMT system with an external cache to memorize the translation history. Werlen et al. (2018) integrate two hierarchical attention networks (HAN) (Yang et al., 2016) in the NMT model to take account for source and target context. Maruf et al. (2019) apply a hierarchical attention module on sentences and words in the context to select contextual information that is more relevant to the current sentence. Related Works The discourse- or document-level translation is a long-standing and unsolved topic in the machine translation community (Mitkov, 1999; Carpuat, 2009; Hardmeier, 2014). Although neural machine translation (Sutskever et al., 2014; Bahdanau et al., 2015; Vaswani et al., 2017)"
2020.wmt-1.71,2020.acl-main.530,0,0.0468302,"e metric being used for evaluation. 605 One issue that can not be ignored in all discourserelated researches is the problem of evaluation. Since some discourse-level phenomena between sentences appear less frequently, although relevant, there is doubt if the metrics like BLEU score (Papineni et al., 2002) can capture these complex rep(e i |ei1− 1 , f pre BREAK f cur ) ¯ ¯ lationships (Le Nagard and Koehn, 2010; Hardmeier and Federico, 2010). To get more insights into the capacities dealing with discourse-level phenomena of their MT models, some researchers use more targeted evaluation scores (Wong et al., 2020), like the Accuracy of Pronoun Translation (APT) Werlen and Popescu-Belis (2017), or they evaluate their systems on some specific test suites that contain more and more complex discourse phenomena (Hardmeier et al., 2015; Guillou et al., 2018; M¨uller et al., 2018; Voita et al., 2019b). 3 Feed Forward L× encoder Add & Norm Add & Norm Src-trg Attention Feed Forward Add & Norm Add & Norm Document-level NMT In this section, we first describe several commonly used context-aware NMT architectures and highlight the differences among them, largely following the work by Kim et al. (2019). Afterwards,"
2020.wmt-1.71,N16-1174,0,0.0213651,"–20, 2020. 2020 Association for Computational Linguistics an interpretation of the potential improvements from leveraging context information. • We study the effects of utilizing documentlevel monolingual data via back-translation and report significant improvements particularly for document-level NMT systems. 2 apply cache-based models to store vector representations for both source- and target-side context. Similarly, Tu et al. (2018) augment their NMT system with an external cache to memorize the translation history. Werlen et al. (2018) integrate two hierarchical attention networks (HAN) (Yang et al., 2016) in the NMT model to take account for source and target context. Maruf et al. (2019) apply a hierarchical attention module on sentences and words in the context to select contextual information that is more relevant to the current sentence. Related Works The discourse- or document-level translation is a long-standing and unsolved topic in the machine translation community (Mitkov, 1999; Carpuat, 2009; Hardmeier, 2014). Although neural machine translation (Sutskever et al., 2014; Bahdanau et al., 2015; Vaswani et al., 2017) has recently become the dominant translation paradigm that provides sup"
2020.wmt-1.71,N16-1000,0,0.213262,"Missing"
2020.wmt-1.71,D18-1049,0,0.133465,"Missing"
2021.acl-srw.1,C18-1139,0,0.0868,"the Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: Student Research Workshop, pages 1–15 August 5–6, 2021. ©2021 Association for Computational Linguistics with additional bidirectional LSTM or CNN encoders. In other related work, Mesnil et al. (2013) have pioneered the use of recurrent neural networks (RNN) to decode tags. Recently, various pre-trained word embedding techniques have offered further improvements over the strong baseline achieved by the neural architectures. Akbik et al. (2018) suggest using pre-trained character-level language models from which to extract hidden states at the start and end character positions of each word to embed any string in a sentence-level context. In addition, the embedding generated by unsupervised representation learning (Peters et al., 2018; Devlin et al., 2019; Liu et al., 2019; Taill´e et al., 2020) has been used successfully for NER, as well as other NLP tasks. In this work, the strongest model for each task is used as the baseline model. 2.2 ding that is successfully used for various NLP tasks, the masked language modeling (MLM) can al"
2021.acl-srw.1,Q16-1026,0,0.0191487,"ttings. In addition, semisupervised approaches using self-training techniques (Blum and Mitchell, 1998) have shown 2 2.1 Related Work State-of-the-art Techniques in NER Collobert et al. (2011) advance the use of neural networks (NN) for NER, who propose an architecture based on temporal convolutional neural networks (CNN) over the sequence of words. Since then, many articles have suggested improvements to this architecture. Huang et al. (2015) propose replacing the CNN encoder in Collobert et al. (2011) with a bidirectional long short-term memory (LSTM) encoder, while Lample et al. (2016) and Chiu and Nichols (2016) introduce a hierarchy into the architecture by replacing artificially designed features ∗ Work completed while studying at RWTH Aachen University. 1 From here on, for the sake of simplicity, we omit the annual information of the datasets. 1 Proceedings of the Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: Student Research Workshop, pages 1–15 August 5–6, 2021. ©2021 Association for Computational Linguistics with additional bidirectional LSTM or CNN encoders. In other relat"
2021.acl-srw.1,D18-1217,0,0.0994051,"ssification tasks. And for neural MT, Gao et al. (2019) suggest replacing randomly selected words in a sentence with a mixture of several related words based on a distribution representation. In this work, we explore the use of MLM-based contextual augmentation approaches for various NER tasks. 3 Self-training Though, the amount of annotated training data is limited for many NLP tasks, additional unlabeled data is available in most situations. Semisupervised learning approaches make use of this additional data. A common way to do this is selftraining (Kozareva et al., 2005; T¨ackstr¨om, 2012; Clark et al., 2018). At a high level, it consists of the following steps: Data Adaptation in NLP In NLP, generating synthetic data using forward or backward inference is a commonly used approach to increase the amount of training data. In strong MT systems, synthetic data that is generated by back-translation is often used as additional training data to improve translation quality (Sennrich et al., 2016). A similar approach using backward inference is also successfully used for end-to-end ASR (Hayashi et al., 2018). In addition, back-translation, as observed by Yu et al. (2018), can create various paraphrases wh"
2021.acl-srw.1,C18-1105,0,0.0204685,"et al., 2016). In addition to providing significant performance improvements, neural models often require high hardware conditions and a large amount of clean training data. However, there is usually only a limited amount of cleanly labeled data available, so techniques such as data augmentation and selftraining are commonly used to generate additional synthetic data. Significant progress has been made in recent years in designing data augmentations for computer vision (CV) (Krizhevsky et al., 2012), automatic speech recognition (ASR) (Park et al., 2019), natural language understanding (NLU) (Hou et al., 2018) and machine translation (MT) (Wang et al., 2018) in supervised settings. In addition, semisupervised approaches using self-training techniques (Blum and Mitchell, 1998) have shown 2 2.1 Related Work State-of-the-art Techniques in NER Collobert et al. (2011) advance the use of neural networks (NN) for NER, who propose an architecture based on temporal convolutional neural networks (CNN) over the sequence of words. Since then, many articles have suggested improvements to this architecture. Huang et al. (2015) propose replacing the CNN encoder in Collobert et al. (2011) with a bidirectional long"
2021.acl-srw.1,N18-2072,0,0.0275317,"er-level language models from which to extract hidden states at the start and end character positions of each word to embed any string in a sentence-level context. In addition, the embedding generated by unsupervised representation learning (Peters et al., 2018; Devlin et al., 2019; Liu et al., 2019; Taill´e et al., 2020) has been used successfully for NER, as well as other NLP tasks. In this work, the strongest model for each task is used as the baseline model. 2.2 ding that is successfully used for various NLP tasks, the masked language modeling (MLM) can also be used for data augmentation. Kobayashi (2018) and Wu et al. (2019) propose to replace words with other words that are predicted using the language model at the corresponding position, which shows promising performance on text classification tasks. Recently, Kumar et al. (2020) discussed the effectiveness of such different pre-trained transformerbased models for data augmentation on text classification tasks. And for neural MT, Gao et al. (2019) suggest replacing randomly selected words in a sentence with a mixture of several related words based on a distribution representation. In this work, we explore the use of MLM-based contextual aug"
2021.acl-srw.1,D08-1071,0,0.142588,"Missing"
2021.acl-srw.1,2021.ccl-1.108,0,0.033533,"Missing"
2021.acl-srw.1,D14-1162,0,0.0906284,"Missing"
2021.acl-srw.1,D18-1100,0,0.0196985,"ant performance improvements, neural models often require high hardware conditions and a large amount of clean training data. However, there is usually only a limited amount of cleanly labeled data available, so techniques such as data augmentation and selftraining are commonly used to generate additional synthetic data. Significant progress has been made in recent years in designing data augmentations for computer vision (CV) (Krizhevsky et al., 2012), automatic speech recognition (ASR) (Park et al., 2019), natural language understanding (NLU) (Hou et al., 2018) and machine translation (MT) (Wang et al., 2018) in supervised settings. In addition, semisupervised approaches using self-training techniques (Blum and Mitchell, 1998) have shown 2 2.1 Related Work State-of-the-art Techniques in NER Collobert et al. (2011) advance the use of neural networks (NN) for NER, who propose an architecture based on temporal convolutional neural networks (CNN) over the sequence of words. Since then, many articles have suggested improvements to this architecture. Huang et al. (2015) propose replacing the CNN encoder in Collobert et al. (2011) with a bidirectional long short-term memory (LSTM) encoder, while Lample e"
2021.acl-srw.1,N18-1202,0,0.00863183,"directional LSTM or CNN encoders. In other related work, Mesnil et al. (2013) have pioneered the use of recurrent neural networks (RNN) to decode tags. Recently, various pre-trained word embedding techniques have offered further improvements over the strong baseline achieved by the neural architectures. Akbik et al. (2018) suggest using pre-trained character-level language models from which to extract hidden states at the start and end character positions of each word to embed any string in a sentence-level context. In addition, the embedding generated by unsupervised representation learning (Peters et al., 2018; Devlin et al., 2019; Liu et al., 2019; Taill´e et al., 2020) has been used successfully for NER, as well as other NLP tasks. In this work, the strongest model for each task is used as the baseline model. 2.2 ding that is successfully used for various NLP tasks, the masked language modeling (MLM) can also be used for data augmentation. Kobayashi (2018) and Wu et al. (2019) propose to replace words with other words that are predicted using the language model at the corresponding position, which shows promising performance on text classification tasks. Recently, Kumar et al. (2020) discussed th"
2021.acl-srw.3,W18-6318,1,0.845982,"source and target sentence, which leads to significant improvements compared to the pure sequence-to-sequence model (Sutskever et al., 2014). Wang et al. (2018) present a LSTM-RNNbased HMM that does not employ an attention mechanism. This work aims to build a similar model with the transformer architecture. While they perform comparable to the LSTM-RNN-based attention baseline with a much slower model, our model outperforms the transformer baseline in terms of T ER scores. The derivation of neural models for translation on the basis of the HMM framework is also studied in Yu et al. (2017) and Alkhouli et al. (2018). In Yu et al. (2017), alignment-based neural models are used to model alignment and translation from the target to the source side (inverse direction), and 23 Proceedings of the Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: Student Research Workshop, pages 23–32 August 5–6, 2021. ©2021 Association for Computational Linguistics a language model is included in addition. And Alkhouli et al. (2018) rely on alignments generated by statistical systems that serve as supervision"
2021.acl-srw.3,2005.iwslt-1.8,0,0.026575,"Missing"
2021.acl-srw.3,D16-1162,0,0.0122221,"omputational Linguistics a language model is included in addition. And Alkhouli et al. (2018) rely on alignments generated by statistical systems that serve as supervision for the training of the neural systems. By contrast, the model proposed in this work does not require any additional language model or alignment information and thus keeps the entire system monolithic. Several works have been carried out to change attention models to capture more complex dependencies. Cohn et al. (2016) introduce structural biases from word-based alignment concepts such as fertility and Markov conditioning. Arthur et al. (2016) incorporate lexical probabilities to influence attention. These changes are based on the LSTMRNN-based attention model. Garg et al. (2019) and Zenkel et al. (2020) try to generate translation and high-quality alignment jointly using an end-to-end neural training pipeline. By contrast, our work focuses more on improving the translation quality using the alignment information generated by the self-contained model. 3 the lexicon probability can be generated. While the lexicon model in the direct HMM has a zero-order dependency on the current alignment position bi : i−1 J J Pr(ei |bi0 , ei−1 0 ,"
2021.acl-srw.3,P00-1056,1,0.613676,"ell as the approaches proposed in Garg et al. (2019) and Zenkel et al. (2020). Note, however, that our zero-order model does not include the future target word information in estimating alignments, and we do not use additional loss for alignment training, since the original goal of this work is to improve translation quality by applying HMM factorization. Alignment Quality In addition to improvements in the T ER scores, we believe that the direct HMM also provides better alignment quality than the standard cross-attention. To verify this assumption, we compute the alignment error rate (A ER) (Och and Ney, 2000) on the RWTH German-English Golden Alignments corpus (Vilar et al., 2006), which provides 505 manually word-aligned sentence pairs extracted from the Europarl corpus. We take the argmax of the alignment probability output of our model as an estimated alignment. In addition, as with the conventional HMM, the argmax of the posterior probability can also be used as an estimated alignment, which explicitly includes the lexicon information and should lead to a better quality. As baselines, we take the argmax of the average of the attention heads in the fifth and sixth decoder layers, since Garg et"
2021.acl-srw.3,D18-1335,1,0.835117,"ignificant improvements have been made to neural machine translations (NMT). Regardless of whether a recurrent neural network with long short-term memory (Hochreiter and Schmidhuber, 1997) (LSTM-RNN) (Bahdanau et al., 2015) or a convolutional neural network (CNN) (Gehring et al., 2017) or a self-attentive transformer network (Vaswani et al., 2017) is used, the attention mechanism is always one of the key components that all state-of-the-art NMT systems contain. Several attempts have been made to explore alternative architectures that do not use an attention mechanism (Wang et al., 2017, 2018; Bahar et al., 2018; Press and Smith, 2018). However, either the performance of those systems is significantly worse than that of the LSTM-RNN-based approaches, or the time and memory complexity is much higher. Since the transformer architecture has upgraded the state-of-the-art to an even higher standard, fewer studies are being carried out in this direction. Despite the promising translation performance of the transformer architecture, recent studies have found that the quality of the word alignments produced by the multi-head cross-attention weights is 2 Related Work The attention component is introduced by B"
2021.acl-srw.3,J03-1002,1,0.0471566,"the inevitable loop over the target position i, the decoding speed of the zero-order model is only slightly slower than that of the transformer baseline. Details of time usage are given in Appendix B. 5.2 extracted directly from the transformer attention weights. The posterior probability that contains the lexicon information indeed provides better alignments, which can be seen as a further advantage of the direct HMM, since it cannot be calculated in the standard transformer architecture without an explicit alignment probability. In terms of A ER performance, our model stands behind GIZA++ (Och and Ney, 2003) as well as the approaches proposed in Garg et al. (2019) and Zenkel et al. (2020). Note, however, that our zero-order model does not include the future target word information in estimating alignments, and we do not use additional loss for alignment training, since the original goal of this work is to improve translation quality by applying HMM factorization. Alignment Quality In addition to improvements in the T ER scores, we believe that the direct HMM also provides better alignment quality than the standard cross-attention. To verify this assumption, we compute the alignment error rate (A"
2021.acl-srw.3,2006.iwslt-papers.7,1,0.727188,"Missing"
2021.acl-srw.3,C96-2141,1,0.578164,"o i−1 i−1 J (2) = Pr(bi , ei |b0 , e0 , f1 ) the context vector, which can also be considered as bI1 i=1 a substitution for the residual layer in the standard I XY transformer architecture. As the outputs of the last i−1 i−1 J J = Pr(ei |bi0 , ei−1 0 , f1 ) · Pr(bi |b0 , e0 , f1 ) decoder layer (and the entire network) we have a | | {z } {z } bI1 i=1 lexicon probability alignment probability lexicon probability: (3) J p(ei |j, ei−1 0 , f1 )    The term “direct” refers to the modeling of p(e|f ) (L) = softmax W · max 0, W · h + W · s 4 5 j 6 i instead of p(f |e) as in the conventional HMM (Vogel et al., 1996). In Wang et al. (2018), two (7) LSTM-RNN based neural networks are used to and an alignment probability: model the lexicon and the alignment probability J (L) p(j|ei−1 (j|i) (8) 0 , f1 ) = α separately. In this work they are modeled with a The output probability for the current word is: single transformer-based network. J p(ei |ei−1 0 , f1 ) 4 Direct HMM in Transformer = This section describes in detail how we modify the transformer model so that both the alignment and J X j=1 24 i−1 J J p(j|ei−1 0 , f1 ) · p(ei |j, e0 , f1 ) (9) next block layer norm lexicon probability add softmax linear pr"
2021.acl-srw.3,P17-2020,1,0.778588,"Introduction Recently, significant improvements have been made to neural machine translations (NMT). Regardless of whether a recurrent neural network with long short-term memory (Hochreiter and Schmidhuber, 1997) (LSTM-RNN) (Bahdanau et al., 2015) or a convolutional neural network (CNN) (Gehring et al., 2017) or a self-attentive transformer network (Vaswani et al., 2017) is used, the attention mechanism is always one of the key components that all state-of-the-art NMT systems contain. Several attempts have been made to explore alternative architectures that do not use an attention mechanism (Wang et al., 2017, 2018; Bahar et al., 2018; Press and Smith, 2018). However, either the performance of those systems is significantly worse than that of the LSTM-RNN-based approaches, or the time and memory complexity is much higher. Since the transformer architecture has upgraded the state-of-the-art to an even higher standard, fewer studies are being carried out in this direction. Despite the promising translation performance of the transformer architecture, recent studies have found that the quality of the word alignments produced by the multi-head cross-attention weights is 2 Related Work The attention co"
2021.acl-srw.3,P18-2060,1,0.889665,"rmer architecture has upgraded the state-of-the-art to an even higher standard, fewer studies are being carried out in this direction. Despite the promising translation performance of the transformer architecture, recent studies have found that the quality of the word alignments produced by the multi-head cross-attention weights is 2 Related Work The attention component is introduced by Bahdanau et al. (2015) in NMT to simulate the alignment between the source and target sentence, which leads to significant improvements compared to the pure sequence-to-sequence model (Sutskever et al., 2014). Wang et al. (2018) present a LSTM-RNNbased HMM that does not employ an attention mechanism. This work aims to build a similar model with the transformer architecture. While they perform comparable to the LSTM-RNN-based attention baseline with a much slower model, our model outperforms the transformer baseline in terms of T ER scores. The derivation of neural models for translation on the basis of the HMM framework is also studied in Yu et al. (2017) and Alkhouli et al. (2018). In Yu et al. (2017), alignment-based neural models are used to model alignment and translation from the target to the source side (inver"
2021.acl-srw.3,2020.acl-main.146,0,0.0504812,"rvision for the training of the neural systems. By contrast, the model proposed in this work does not require any additional language model or alignment information and thus keeps the entire system monolithic. Several works have been carried out to change attention models to capture more complex dependencies. Cohn et al. (2016) introduce structural biases from word-based alignment concepts such as fertility and Markov conditioning. Arthur et al. (2016) incorporate lexical probabilities to influence attention. These changes are based on the LSTMRNN-based attention model. Garg et al. (2019) and Zenkel et al. (2020) try to generate translation and high-quality alignment jointly using an end-to-end neural training pipeline. By contrast, our work focuses more on improving the translation quality using the alignment information generated by the self-contained model. 3 the lexicon probability can be generated. While the lexicon model in the direct HMM has a zero-order dependency on the current alignment position bi : i−1 J J Pr(ei |bi0 , ei−1 0 , f1 ) := p(ei |bi , e0 , f1 ) (4) we implement zero- and first-order dependencies for the alignment model. 4.1 Zero-order Architecture In the zero-order architecture"
2021.dialdoc-1.8,D19-5602,0,0.0411876,"Missing"
2021.dialdoc-1.8,N19-1423,0,0.0098043,"gent Response Grounding Prediction Methods Baselines Span-based objective The training objective for QA assumes that the probability of the start and end position are conditionally independent. Previous work (Fajcik et al., 2020) indicates that directly modeling the joint probability of start and end position can improve performance. Hence, to model this joint probability, we use a biaffine classifier as proposed by Dozat and Manning (2017) for dependency parsing. Agent Response Grounding Prediction For the first subtask, Feng et al. (2020) fine-tune BERT for question answering as proposed by Devlin et al. (2019). Therefore, a start and end score for each token is calculated by a linear projection from the last hidden states of the model. These scores are normalized using a softmax over all tokens to obtain probabilities for the start and end positions. In 58 spans S. We model the response generation as: Ensembling In our submission, we use an ensemble of multiple models for the prediction of spans to capture their uncertainty. More precisely, we use Bayesian Model Averaging (Hoeting et al., 1999), where the probability of a span a = (as , ae ) is obtained by marginalizing the joint probability of spa"
2021.dialdoc-1.8,D18-2015,1,0.815251,"ncertainty of the span selection model into account. Similar to Lewis et al. (2020b) and Thulke et al. (2021) we propose to marginalize over all 59 Subtask 1 model baseline RoBERTa ensemble Subtask 2 F1 67.9 73.2 75.9 test EM 51.5 58.3 63.5 F1 70.8 77.3 78.8 val EM 56.3 65.6 68.4 test model baseline (ours) cascaded (RoBERTa) cascaded (ensemble) val BLEU 28.1 32.9 39.1 39.6 40.4 41.5 Table 1: Results of our best system on test and validation set. 6 Experiments 6.1 We base our implementation1 on the provided baseline code of the shared task 2 . Furthermore, we use the workflow manager Sisyphus (Peter et al., 2018) to organize our experiments. For the first subtask, we use the base and large variants of RoBERTa (Liu et al., 2019) and ELECTRA (Clark et al., 2020) instead of BERT large uncased. In the second subtask, we use BART base instead of the large variant, which was used in the baseline code, since even after reducing the batch size to one, we were not able to run the baseline with a maximum sequence length of 1024 on our Nvidia GTX 1080 Ti and RTX 2080 Ti GPUs due to memory constraints. All models are fine-tuned with an initial learning rate of 3e-5. Base variants are trained for 10 epochs and lar"
2021.dialdoc-1.8,2020.emnlp-main.652,0,0.0623183,"Missing"
2021.dialdoc-1.8,W18-6319,0,0.012074,"d with their grounding span and can be used as additional samples in both tasks. In the baseline implementation, these are excluded from training and evaluation. To maintain comparability, we do not include them in the validation or test data. For evaluation, we use the same evaluation metrics as proposed in the baseline. In the first subtask, exact match (EM), i.e. the percentage of exact matches between the predicted and reference span (after lowercasing and removing punctuation, articles, and whitespace) and the token-level F1 score is used. The second subtask is evaluated using SacreBLEU (Post, 2018). Results Table 1 summarizes our main results and submission to the shared task. The first line shows the results obtained by reproducing the baseline provided by the organizers (using BART base for Subtask 2). We note that these results differ from the ones reported in Feng et al. (2020) due to slightly different data conditions in the shared task and their paper. The second line shows the results of our best single model. In Subtask 1, we obtained our best results by using RoBERTa large, trained additionally on agent follow-up turns, and by restricting the model to phrases occurring in the d"
2021.dialdoc-1.8,2020.acl-main.54,0,0.0275609,"he form of FAQ documents, where snippets are much shorter than those considered in this work. Pre-trained trained language models such as BART (Lewis et al., 2020a) or RoBERTa (Liu et al., 2019) have recently become a successful tool for different kinds of natural language understanding tasks, such as question answering (QA), where they obtain state-of-the-art results (Liu et al., 2019; Clark et al., 2020). Naturally, they have recently also found their way into task-oriented dialog systems (Lewis et al., 2020a), where they are either used as end-to-end systems (Budzianowski and Vuli´c, 2019; Ham et al., 2020) or as components for a specific subtask (He et al., 2021). Introduction Unstructured documents contain a vast amount of knowledge that can be useful information for responding to users in goal-oriented dialog systems. The shared task at the first DialDoc Workshop focuses on grounding and generating agent responses in such systems. Therefore, two subtasks are proposed: given a dialog extract the relevant information for the next agent turn from a document and generate a natural language agent response based on dialog context and grounding document. In this paper, we present our submissions to"
2021.dialdoc-1.8,Q19-1016,0,0.0268309,"nd subtask, we use a cascaded model which grounds the response prediction on the predicted span instead of the full document. With these approaches, we obtain significant improvements in both subtasks compared to the baseline. 1 2 Related Work Recently, multiple datasets and challenges concerning conversational question answering have been proposed. For example, Saeidi et al. (2018) introduced ShARC, a dataset containing ca. 32k utterances which include follow-up questions on user requests which can not be answered directly based on the given dialog and grounding. Similarly, the CoQA dataset (Reddy et al., 2019) provides 127k questions with answers and grounding obtained from human conversations. Closer related to the DialDoc shared task, the task in the first track of DSTC 9 (Kim et al., 2020) was to generate agent responses based on relevant knowledge in task-oriented dialog. However, the considered knowledge has the form of FAQ documents, where snippets are much shorter than those considered in this work. Pre-trained trained language models such as BART (Lewis et al., 2020a) or RoBERTa (Liu et al., 2019) have recently become a successful tool for different kinds of natural language understanding t"
2021.dialdoc-1.8,D18-1233,0,0.0400438,"Missing"
2021.dialdoc-1.8,2020.sigdial-1.35,0,0.0208512,"oth subtasks compared to the baseline. 1 2 Related Work Recently, multiple datasets and challenges concerning conversational question answering have been proposed. For example, Saeidi et al. (2018) introduced ShARC, a dataset containing ca. 32k utterances which include follow-up questions on user requests which can not be answered directly based on the given dialog and grounding. Similarly, the CoQA dataset (Reddy et al., 2019) provides 127k questions with answers and grounding obtained from human conversations. Closer related to the DialDoc shared task, the task in the first track of DSTC 9 (Kim et al., 2020) was to generate agent responses based on relevant knowledge in task-oriented dialog. However, the considered knowledge has the form of FAQ documents, where snippets are much shorter than those considered in this work. Pre-trained trained language models such as BART (Lewis et al., 2020a) or RoBERTa (Liu et al., 2019) have recently become a successful tool for different kinds of natural language understanding tasks, such as question answering (QA), where they obtain state-of-the-art results (Liu et al., 2019; Clark et al., 2020). Naturally, they have recently also found their way into task-ori"
2021.insights-1.10,W18-6301,0,0.0204802,"nism by a recurrent connection, allowing direct access to previous attention/alignment decisions. We propose several ways to include such a recurrency into the attention mechanism. Verifying their performance across different translation tasks we conclude that these extensions and dependencies are not beneficial for the translation performance of the Transformer architecture. 1 Introduction 2 Since its introduction by Vaswani et al. (2017), the Transformer architecture has enabled state of the art results on nearly all machine translation (MT) tasks (Bojar et al., 2018; Barrault et al., 2019; Ott et al., 2018). Compared to previous neural machine translation (NMT) approaches (Sutskever et al., 2014; Bahdanau et al., 2015), it introduces many new concepts like self-attention, positional encoding and multi-head attention. However, the Transformer still relies on the encoder-decoder attention mechanism introduced by Bahdanau et al. (2015) to translate a source sentence into the target language. While for earlier NMT models, this attention mechanism was thoroughly investigated and many different variants were proposed (Feng et al., 2016; Cohn et al., 2016; Sankaran et al., 2016; Tu et al., 2016), the s"
2021.insights-1.10,W18-6319,0,0.0532491,"Missing"
2021.insights-1.10,W19-5301,0,0.0654849,"Missing"
2021.insights-1.10,2006.amta-papers.25,0,0.152527,"Missing"
2021.insights-1.10,W18-6401,0,0.0264887,"ents, we extend the (cross-)attention mechanism by a recurrent connection, allowing direct access to previous attention/alignment decisions. We propose several ways to include such a recurrency into the attention mechanism. Verifying their performance across different translation tasks we conclude that these extensions and dependencies are not beneficial for the translation performance of the Transformer architecture. 1 Introduction 2 Since its introduction by Vaswani et al. (2017), the Transformer architecture has enabled state of the art results on nearly all machine translation (MT) tasks (Bojar et al., 2018; Barrault et al., 2019; Ott et al., 2018). Compared to previous neural machine translation (NMT) approaches (Sutskever et al., 2014; Bahdanau et al., 2015), it introduces many new concepts like self-attention, positional encoding and multi-head attention. However, the Transformer still relies on the encoder-decoder attention mechanism introduced by Bahdanau et al. (2015) to translate a source sentence into the target language. While for earlier NMT models, this attention mechanism was thoroughly investigated and many different variants were proposed (Feng et al., 2016; Cohn et al., 2016; Sank"
2021.insights-1.10,P16-1008,0,0.0289303,"2019; Ott et al., 2018). Compared to previous neural machine translation (NMT) approaches (Sutskever et al., 2014; Bahdanau et al., 2015), it introduces many new concepts like self-attention, positional encoding and multi-head attention. However, the Transformer still relies on the encoder-decoder attention mechanism introduced by Bahdanau et al. (2015) to translate a source sentence into the target language. While for earlier NMT models, this attention mechanism was thoroughly investigated and many different variants were proposed (Feng et al., 2016; Cohn et al., 2016; Sankaran et al., 2016; Tu et al., 2016), the same can not be said for the Transformer. In the present work, we discuss the Transformer encoder-decoder attention mechanism, propose different ways to enhance its capabilities and analyze the resulting systems. One particular design decision in the Transformer attention mechanism catches the eye: When calculating the context vector in the current decoding step, there is no direct information flow coming Related Work In recurrent network architectures (Bahdanau et al., 2015) the decoder state recurrently depends on the previous decoding step. Many works have extended this by additionall"
2021.insights-1.10,C16-1290,0,0.0126668,"translation (MT) tasks (Bojar et al., 2018; Barrault et al., 2019; Ott et al., 2018). Compared to previous neural machine translation (NMT) approaches (Sutskever et al., 2014; Bahdanau et al., 2015), it introduces many new concepts like self-attention, positional encoding and multi-head attention. However, the Transformer still relies on the encoder-decoder attention mechanism introduced by Bahdanau et al. (2015) to translate a source sentence into the target language. While for earlier NMT models, this attention mechanism was thoroughly investigated and many different variants were proposed (Feng et al., 2016; Cohn et al., 2016; Sankaran et al., 2016; Tu et al., 2016), the same can not be said for the Transformer. In the present work, we discuss the Transformer encoder-decoder attention mechanism, propose different ways to enhance its capabilities and analyze the resulting systems. One particular design decision in the Transformer attention mechanism catches the eye: When calculating the context vector in the current decoding step, there is no direct information flow coming Related Work In recurrent network architectures (Bahdanau et al., 2015) the decoder state recurrently depends on the previous"
2021.insights-1.10,P18-4022,1,0.847531,"2 34.3 53.2 Tr→En newstest2018 B LEU T ER 20.22 19.6 70.2 19.5 70.3 19.8 70.2 19.7 70.3 19.8 70.5 19.6 70.2 19.5 71.2 En→It TED tst2010 B LEU T ER 28.53 28.9 58.5 28.9 58.3 29.1 58.0 29.1 58.3 28.9 58.5 28.7 58.7 28.7 58.8 Train Time 1.0x 5.6x 6.0x 6.1x 7.5x 5.4x 7.9x Table 2: Performance comparison of the approaches using additional context information from the previous time steps as described in Section 3.1. Train time refers to the average GPU time per training checkpoint measured on Ro→En. We show the best results reported in literature for each task: 1 Kasai et al. (2020), 2 Marie et al. (2018) and 3 Lakew et al. (2017) in the way in which the context vector is transformed before being used as an additional keyvalue pair. The performance of each variant in terms of B LEU and T ER is shown in Table 1. The variants 1 (Equation 5) and 2 (Equation 6) perform the strongest, being both slightly better than our baseline system. Re-using the transformation matrices from the other key-value pairs does not seem to hurt the system. Limiting the additional context information to the same attention head (variant 3, Equation 7) results in a slight performance loss. Additionally, omitting the tran"
2021.insights-1.10,W18-6419,0,0.0281088,"53.6 34.2 53.2 34.3 53.2 Tr→En newstest2018 B LEU T ER 20.22 19.6 70.2 19.5 70.3 19.8 70.2 19.7 70.3 19.8 70.5 19.6 70.2 19.5 71.2 En→It TED tst2010 B LEU T ER 28.53 28.9 58.5 28.9 58.3 29.1 58.0 29.1 58.3 28.9 58.5 28.7 58.7 28.7 58.8 Train Time 1.0x 5.6x 6.0x 6.1x 7.5x 5.4x 7.9x Table 2: Performance comparison of the approaches using additional context information from the previous time steps as described in Section 3.1. Train time refers to the average GPU time per training checkpoint measured on Ro→En. We show the best results reported in literature for each task: 1 Kasai et al. (2020), 2 Marie et al. (2018) and 3 Lakew et al. (2017) in the way in which the context vector is transformed before being used as an additional keyvalue pair. The performance of each variant in terms of B LEU and T ER is shown in Table 1. The variants 1 (Equation 5) and 2 (Equation 6) perform the strongest, being both slightly better than our baseline system. Re-using the transformation matrices from the other key-value pairs does not seem to hurt the system. Limiting the additional context information to the same attention head (variant 3, Equation 7) results in a slight performance loss. Additionally, omitting the tran"
2021.iwslt-1.32,N19-1388,0,0.0207814,"in autoregressive models. This new architecture (i) avoids unnecessary early decisions that can cause errors which are then propagated throughout the cascaded models (ii) utilizes the src→trg, src→piv and piv→trg training data and (iii) communicates the full information from the src→piv model downstream by providing a natural interface between the src→piv and piv→trg models. 2 fine-tuned on src→trg corpus through the trainable adapter. Pivot-based NMT is typically used in a low-resource src→trg setup, and multilingual NMT systems proved to be successful in this scenario (Johnson et al., 2017; Aharoni et al., 2019; Zhang et al., 2020). To tackle a low-resource NMT problem, (Kim et al., 2019) also explore different ways to extend the back-translation idea (Sennrich et al., 2016a) for src→piv→trg scenarios. However, since this work aims to provide the general framework for the integrated training of cascaded sequence-to-sequence models, we do not aim for comprehensive comparisons with multilingual NMT systems and various data augmentation strategies. We refer to (Kim et al., 2019) for in-depth comparison studies. In speech translation, the tight model integration for the cascaded models also attracted at"
2021.iwslt-1.32,N18-1008,0,0.0218143,"kle a low-resource NMT problem, (Kim et al., 2019) also explore different ways to extend the back-translation idea (Sennrich et al., 2016a) for src→piv→trg scenarios. However, since this work aims to provide the general framework for the integrated training of cascaded sequence-to-sequence models, we do not aim for comprehensive comparisons with multilingual NMT systems and various data augmentation strategies. We refer to (Kim et al., 2019) for in-depth comparison studies. In speech translation, the tight model integration for the cascaded models also attracted attention from the community. (Anastasopoulos and Chiang, 2018; Wang et al., 2019; Sperber et al., 2019) discussed either use of attention or hidden state vectors as a connection interface for the tight model integration in cascaded systems. Recently, (Bahar et al., 2021) proposed to use posterior distribution as an input to the encoder of the second model. Related Work Several approaches were proposed in recent years to address the weaknesses of the traditional cascaded models. Early works investigated the applications of the N-best list decoding both in speech translation and pivot-based translation (Woszczyna et al., 1993; Lavie et al., 1996; Och and"
2021.iwslt-1.32,D19-1633,0,0.176681,"erated and optimized in parallel. However, current approaches also need an explicit length model as additional input to the decoder. Gu et al. (2018) utilize the standard Transformer architecture and provide several modifications in order to obtain a non-autoregessive machine translation system. Recent works proposed to relax the independence constraints during training and use iterative decoding for the NAT, meaning that instead of only one decoding pass, the model relies on the multiple passes, and conditional dependence might be used on the consecutive passes to achieve better performance (Ghazvininejad et al., 2019; Gu et al., 2019; Lee et al., 2018; Stern et al., 2019). Such decoding procedure allows shrinking the gap between the performance of the autoregressive and non-autoregressive models. 3.3 = argmax K,z1K ˆ eˆI1 = argmax I,eI1 K Y k=1 I Y ps2p (zk |z1k−1 , f1J ) ˆ pp2t (ei |ei−1 ˆ1K ). 1 ,z (2) (3) i=1 We investigate the stability and potential for improvement of this interface in the Section 6.1. Pivot-based Machine Translation A cascading system ps2t for pivot-based machine translation consists of a src→piv model ps2p and a piv→trg model pp2t , which typically have a disjoint parameter set. Wh"
2021.iwslt-1.32,D16-1139,0,0.025475,"ssive than a softmax layer and b) is trained on the single-iteration output. This mismatch between training and decoding could be the reason why decoder iterations are not beneficial for the integrated model. Additionally, we experimented with decoder iterations during training of the integrated model, but it breaks the gradient propagation. Although our initial experiments with the iterations have been unsuccessful, we think that they can be applied for training using such approaches as Gumbel-Softmax (Jang et al., 2017). 6.6 Knowledge Distillation Sequence-level knowledge distillation (KD) (Kim and Rush, 2016) proved to be useful for the training of non-autoregressive models (Zhou et al., 2020). Although it improves the src→piv model performance, our initial experiments show that KD results in a 0.1-0.3 B LEU degradation on the integrated model. 7 Acknowledgments Authors affiliated with RWTH Aachen University have partially received funding from the European Research Council (ERC) (under the European Union’s Horizon 2020 research and innovation programme, grant agreement No 694537, project “SEQCLAS”) and eBay Inc. The work reflects only the authors’ views, and none of the funding agencies is respon"
2021.iwslt-1.32,D19-1080,1,0.92991,"ions that can cause errors which are then propagated throughout the cascaded models (ii) utilizes the src→trg, src→piv and piv→trg training data and (iii) communicates the full information from the src→piv model downstream by providing a natural interface between the src→piv and piv→trg models. 2 fine-tuned on src→trg corpus through the trainable adapter. Pivot-based NMT is typically used in a low-resource src→trg setup, and multilingual NMT systems proved to be successful in this scenario (Johnson et al., 2017; Aharoni et al., 2019; Zhang et al., 2020). To tackle a low-resource NMT problem, (Kim et al., 2019) also explore different ways to extend the back-translation idea (Sennrich et al., 2016a) for src→piv→trg scenarios. However, since this work aims to provide the general framework for the integrated training of cascaded sequence-to-sequence models, we do not aim for comprehensive comparisons with multilingual NMT systems and various data augmentation strategies. We refer to (Kim et al., 2019) for in-depth comparison studies. In speech translation, the tight model integration for the cascaded models also attracted attention from the community. (Anastasopoulos and Chiang, 2018; Wang et al., 2019"
2021.iwslt-1.32,2005.mtsummit-papers.11,0,0.0308664,"easily adapted to any Transformer-based cascaded model. 5 Experimental Results To test and verify the proposed cascaded model, we conduct experiments on French→German and German→Czech data from the WMT 2019 news translation task1 . – Train src→piv model on src→piv cor279 1 http://www.statmt.org/wmt19/ (a) AR-based integrated model. (b) NAT-based integrated model. (c) Three-components NAT-based integrated model. Figure 2: Different variants of the encoder-decoder model integration through the connection interface. 5.1 5.2 Data Training data for French→German includes Europarl corpus version 7 (Koehn, 2005), CommonCrawl2 corpus and the newstest2008-2010. The total number of parallel sentences is 2.3M. The original German→Czech task was constrained to unsupervised translation, but we utilized the available parallel data to relax these constraints. The corpus consists of NewsCommentary version 14 (Tiedemann, 2012) and we extended it by including newssyscomb20093 and the concatenation of previous years test sets newstest2008-2010 from the news translation task. The total amount of parallel sentences is 230K. For both tasks we use newstest2011 as the development set and newstest2012 as the test sets"
2021.iwslt-1.32,C96-1075,0,0.621544,"stasopoulos and Chiang, 2018; Wang et al., 2019; Sperber et al., 2019) discussed either use of attention or hidden state vectors as a connection interface for the tight model integration in cascaded systems. Recently, (Bahar et al., 2021) proposed to use posterior distribution as an input to the encoder of the second model. Related Work Several approaches were proposed in recent years to address the weaknesses of the traditional cascaded models. Early works investigated the applications of the N-best list decoding both in speech translation and pivot-based translation (Woszczyna et al., 1993; Lavie et al., 1996; Och and Ney, 2004; Utiyama and Isahara, 2007). The N-best list decoding allows to pass multiple intermediate hypotheses and avoid unnecessary early decisions. An efficient alternative to the n-best list is lattices, which replaced the n-best list for the speech translation models (Zhang et al., 2005; Schultz et al., 2004; Matusov et al., 2008). However, the usage of the discrete decisions does not allow to train cascaded model jointly on src→trg data. Most recent works are focusing instead on the joint or integrated training for sequence-tosequence cascaded models. Thus, (Cheng et al., 2017)"
2021.iwslt-1.32,D18-1149,0,0.0181152,"rrent approaches also need an explicit length model as additional input to the decoder. Gu et al. (2018) utilize the standard Transformer architecture and provide several modifications in order to obtain a non-autoregessive machine translation system. Recent works proposed to relax the independence constraints during training and use iterative decoding for the NAT, meaning that instead of only one decoding pass, the model relies on the multiple passes, and conditional dependence might be used on the consecutive passes to achieve better performance (Ghazvininejad et al., 2019; Gu et al., 2019; Lee et al., 2018; Stern et al., 2019). Such decoding procedure allows shrinking the gap between the performance of the autoregressive and non-autoregressive models. 3.3 = argmax K,z1K ˆ eˆI1 = argmax I,eI1 K Y k=1 I Y ps2p (zk |z1k−1 , f1J ) ˆ pp2t (ei |ei−1 ˆ1K ). 1 ,z (2) (3) i=1 We investigate the stability and potential for improvement of this interface in the Section 6.1. Pivot-based Machine Translation A cascading system ps2t for pivot-based machine translation consists of a src→piv model ps2p and a piv→trg model pp2t , which typically have a disjoint parameter set. While both models are trained indepen"
2021.iwslt-1.32,J04-4002,1,0.58056,"ng, 2018; Wang et al., 2019; Sperber et al., 2019) discussed either use of attention or hidden state vectors as a connection interface for the tight model integration in cascaded systems. Recently, (Bahar et al., 2021) proposed to use posterior distribution as an input to the encoder of the second model. Related Work Several approaches were proposed in recent years to address the weaknesses of the traditional cascaded models. Early works investigated the applications of the N-best list decoding both in speech translation and pivot-based translation (Woszczyna et al., 1993; Lavie et al., 1996; Och and Ney, 2004; Utiyama and Isahara, 2007). The N-best list decoding allows to pass multiple intermediate hypotheses and avoid unnecessary early decisions. An efficient alternative to the n-best list is lattices, which replaced the n-best list for the speech translation models (Zhang et al., 2005; Schultz et al., 2004; Matusov et al., 2008). However, the usage of the discrete decisions does not allow to train cascaded model jointly on src→trg data. Most recent works are focusing instead on the joint or integrated training for sequence-tosequence cascaded models. Thus, (Cheng et al., 2017) suggested a joint"
2021.iwslt-1.32,N19-4009,0,0.0232689,"w.statmt.org/wmt09/ system-combination-task.html Preprocessing For each parallel corpus, we apply a standard preprocessing procedure: First, we tokenize each corpus using the Moses4 tokenizer. Then a true-casing model is trained on all training data and applied to both training and test data. In the final step, we train byte-pair encoding (BPE) (Sennrich et al., 2016b) with 32000 merge operations. In order to enable model integration, we train BPE jointly on all available data for the respective language. 5.3 Model and Training We implement the models described in Section 4 using the fairseq (Ott et al., 2019) sequence-to-sequence extendable framework. As non-autoregressive src→piv model, we choose the Conditional Masked Language Model (CMLM) (Ghazvininejad et al., 2019) with 6 layers for both encoder and decoder, and a standard 6 layer ‘base’ Transformer for the piv→trg system (Vaswani et al., 2017). For each interface, the length of the pivot sequence is set to the length of the source sequence by default. More on the length modeling is discussed in the Section 6.4. For the decoder states interface, the last decoder is used for all the experiments. For model fine-tuning, the Adam optimizer (Kingm"
2021.iwslt-1.32,P02-1040,0,0.109277,"have been used for French→German and German→Czech accordingly. The dropout is set to 0.1 for French→German and 0.3 for German→Czech. We set the effective batch size to 65,536 following the fairseq recommendations for the non-autoregressive models. Although CMLM provides the Mask-Predict decoding algorithm (Ghazvininejad et al., 2019), in our work we only use one iteration and obtain probability distribution and hidden states from the fully masked sequence, which means that each token is only conditioned on the source tokens. Results are reported using the sacreBLEU 5 implementation of B LEU (Papineni et al., 2002). We compare our models against three baselines: • direct baseline: The direct baseline is the Transformer base model, which is trained only on src→trg (direct) parallel data. • AR pivot baseline: A baseline system composed of cascading a src→piv and a piv→trg autoregressive (AR) models. These two models are autoregressive Transformer ‘base’ models with six layers of encoder and decoder, respectively. The individual models are trained on either src→piv or piv→trg data. There is no fine-tuning on the src→trg data, and results are reported based on the inference only. • NA pivot baseline: Simila"
2021.iwslt-1.32,P16-1009,0,0.272009,"(ii) utilizes the src→trg, src→piv and piv→trg training data and (iii) communicates the full information from the src→piv model downstream by providing a natural interface between the src→piv and piv→trg models. 2 fine-tuned on src→trg corpus through the trainable adapter. Pivot-based NMT is typically used in a low-resource src→trg setup, and multilingual NMT systems proved to be successful in this scenario (Johnson et al., 2017; Aharoni et al., 2019; Zhang et al., 2020). To tackle a low-resource NMT problem, (Kim et al., 2019) also explore different ways to extend the back-translation idea (Sennrich et al., 2016a) for src→piv→trg scenarios. However, since this work aims to provide the general framework for the integrated training of cascaded sequence-to-sequence models, we do not aim for comprehensive comparisons with multilingual NMT systems and various data augmentation strategies. We refer to (Kim et al., 2019) for in-depth comparison studies. In speech translation, the tight model integration for the cascaded models also attracted attention from the community. (Anastasopoulos and Chiang, 2018; Wang et al., 2019; Sperber et al., 2019) discussed either use of attention or hidden state vectors as a"
2021.iwslt-1.32,P16-1162,0,0.37851,"(ii) utilizes the src→trg, src→piv and piv→trg training data and (iii) communicates the full information from the src→piv model downstream by providing a natural interface between the src→piv and piv→trg models. 2 fine-tuned on src→trg corpus through the trainable adapter. Pivot-based NMT is typically used in a low-resource src→trg setup, and multilingual NMT systems proved to be successful in this scenario (Johnson et al., 2017; Aharoni et al., 2019; Zhang et al., 2020). To tackle a low-resource NMT problem, (Kim et al., 2019) also explore different ways to extend the back-translation idea (Sennrich et al., 2016a) for src→piv→trg scenarios. However, since this work aims to provide the general framework for the integrated training of cascaded sequence-to-sequence models, we do not aim for comprehensive comparisons with multilingual NMT systems and various data augmentation strategies. We refer to (Kim et al., 2019) for in-depth comparison studies. In speech translation, the tight model integration for the cascaded models also attracted attention from the community. (Anastasopoulos and Chiang, 2018; Wang et al., 2019; Sperber et al., 2019) discussed either use of attention or hidden state vectors as a"
2021.iwslt-1.32,Q19-1020,0,0.060305,"uires each model to output a discrete decision. This means that the deeper knowledge that the model may encode in its representation of the output is reduced to a ‘surface form’ of a particular prediction, which is passed on to the following model. Lastly, in conventional cascaded system there is no possibility to make use of end-to-end training data, meaning that the training data most suited for the task cannot be used. To tackle these problems, several approaches for integrated end-to-end training of cascaded models have been proposed and applied to different NLP tasks (Bahar et al., 2021; Sperber et al., 2019; Sung et al., 2019). Integrated end-to-end training is usually achieved by merging the consecutive models and fine-tuning the resulting system on the endto-end training data. Although the idea of this approach is simple, it remains an open challenge how to choose the interface between the models in such a way that they can be trained, e.g. by gradient propagation. Furthermore, most of these approaches rely on synthetic or natural multi-way 276 Proceedings of the 18th International Conference on Spoken Language Translation, pages 276–286 Bangkok, Thailand (Online), August 5–6, 2021. ©2021 Asso"
2021.iwslt-1.32,2020.acl-main.661,0,0.0182692,"ut the need for an explicit intermediate representation. This new architecture (i) avoids unnecessary early decisions that can cause errors which are then propagated throughout the cascaded models and (ii) utilizes the end-to-end training data directly. We conduct an evaluation on two pivot-based machine translation tasks, namely French→German and German→Czech. Our experimental results show that the proposed architecture yields an improvement of more than 2 B LEU for French→German over the cascaded baseline. 1 Introduction Many complex natural language applications such as speech translation (Sperber and Paulik, 2020) or pivot translation (Utiyama and Isahara, 2007; De Gispert and Marino, 2006) traditionally rely on cascaded models. The technique of model cascading is commonly used to solve problems that can be divided into a sequence of sub-problems where the solution to the first problem is used as an input to the second and so on. Typically cascaded systems include several consecutive and independently trained models, each of which aims to solve a particular sub-task. For example in a cascaded speech translation system an automatic speech recognition model receives the audio signal as an input and gener"
2021.iwslt-1.32,tiedemann-2012-parallel,0,0.0351732,"Missing"
2021.iwslt-1.32,N07-1061,0,0.313882,"ntation. This new architecture (i) avoids unnecessary early decisions that can cause errors which are then propagated throughout the cascaded models and (ii) utilizes the end-to-end training data directly. We conduct an evaluation on two pivot-based machine translation tasks, namely French→German and German→Czech. Our experimental results show that the proposed architecture yields an improvement of more than 2 B LEU for French→German over the cascaded baseline. 1 Introduction Many complex natural language applications such as speech translation (Sperber and Paulik, 2020) or pivot translation (Utiyama and Isahara, 2007; De Gispert and Marino, 2006) traditionally rely on cascaded models. The technique of model cascading is commonly used to solve problems that can be divided into a sequence of sub-problems where the solution to the first problem is used as an input to the second and so on. Typically cascaded systems include several consecutive and independently trained models, each of which aims to solve a particular sub-task. For example in a cascaded speech translation system an automatic speech recognition model receives the audio signal as an input and generates a transcription as an output of the first s"
2021.iwslt-1.32,W19-5803,0,0.0126258,"Kim et al., 2019) also explore different ways to extend the back-translation idea (Sennrich et al., 2016a) for src→piv→trg scenarios. However, since this work aims to provide the general framework for the integrated training of cascaded sequence-to-sequence models, we do not aim for comprehensive comparisons with multilingual NMT systems and various data augmentation strategies. We refer to (Kim et al., 2019) for in-depth comparison studies. In speech translation, the tight model integration for the cascaded models also attracted attention from the community. (Anastasopoulos and Chiang, 2018; Wang et al., 2019; Sperber et al., 2019) discussed either use of attention or hidden state vectors as a connection interface for the tight model integration in cascaded systems. Recently, (Bahar et al., 2021) proposed to use posterior distribution as an input to the encoder of the second model. Related Work Several approaches were proposed in recent years to address the weaknesses of the traditional cascaded models. Early works investigated the applications of the N-best list decoding both in speech translation and pivot-based translation (Woszczyna et al., 1993; Lavie et al., 1996; Och and Ney, 2004; Utiyama"
2021.iwslt-1.32,H93-1041,0,0.393095,"from the community. (Anastasopoulos and Chiang, 2018; Wang et al., 2019; Sperber et al., 2019) discussed either use of attention or hidden state vectors as a connection interface for the tight model integration in cascaded systems. Recently, (Bahar et al., 2021) proposed to use posterior distribution as an input to the encoder of the second model. Related Work Several approaches were proposed in recent years to address the weaknesses of the traditional cascaded models. Early works investigated the applications of the N-best list decoding both in speech translation and pivot-based translation (Woszczyna et al., 1993; Lavie et al., 1996; Och and Ney, 2004; Utiyama and Isahara, 2007). The N-best list decoding allows to pass multiple intermediate hypotheses and avoid unnecessary early decisions. An efficient alternative to the n-best list is lattices, which replaced the n-best list for the speech translation models (Zhang et al., 2005; Schultz et al., 2004; Matusov et al., 2008). However, the usage of the discrete decisions does not allow to train cascaded model jointly on src→trg data. Most recent works are focusing instead on the joint or integrated training for sequence-tosequence cascaded models. Thus,"
2021.iwslt-1.32,2020.acl-main.148,0,0.0150879,"ls. This new architecture (i) avoids unnecessary early decisions that can cause errors which are then propagated throughout the cascaded models (ii) utilizes the src→trg, src→piv and piv→trg training data and (iii) communicates the full information from the src→piv model downstream by providing a natural interface between the src→piv and piv→trg models. 2 fine-tuned on src→trg corpus through the trainable adapter. Pivot-based NMT is typically used in a low-resource src→trg setup, and multilingual NMT systems proved to be successful in this scenario (Johnson et al., 2017; Aharoni et al., 2019; Zhang et al., 2020). To tackle a low-resource NMT problem, (Kim et al., 2019) also explore different ways to extend the back-translation idea (Sennrich et al., 2016a) for src→piv→trg scenarios. However, since this work aims to provide the general framework for the integrated training of cascaded sequence-to-sequence models, we do not aim for comprehensive comparisons with multilingual NMT systems and various data augmentation strategies. We refer to (Kim et al., 2019) for in-depth comparison studies. In speech translation, the tight model integration for the cascaded models also attracted attention from the comm"
2021.iwslt-1.32,2005.iwslt-1.2,0,0.0430405,"er of the second model. Related Work Several approaches were proposed in recent years to address the weaknesses of the traditional cascaded models. Early works investigated the applications of the N-best list decoding both in speech translation and pivot-based translation (Woszczyna et al., 1993; Lavie et al., 1996; Och and Ney, 2004; Utiyama and Isahara, 2007). The N-best list decoding allows to pass multiple intermediate hypotheses and avoid unnecessary early decisions. An efficient alternative to the n-best list is lattices, which replaced the n-best list for the speech translation models (Zhang et al., 2005; Schultz et al., 2004; Matusov et al., 2008). However, the usage of the discrete decisions does not allow to train cascaded model jointly on src→trg data. Most recent works are focusing instead on the joint or integrated training for sequence-tosequence cascaded models. Thus, (Cheng et al., 2017) suggested a joint training approach for the pivot-based neural machine translation. In their work, two attention-based RNN models (Bahdanau et al., 2015) are trained jointly with different connection terms in the objective function and the src→trg as a bridging corpus. Another approach is to apply th"
2021.naacl-main.15,W18-6318,1,0.852766,"edding space. The standard approach for creating such embeddings is to first train embeddings for each language pair separately (Mikolov et al., 2013; Pennington et al., 2014) and then projecting them into the same vector space (Conneau et al., 2017; Artetxe et al., 2018), which is possible with or without the help of parallel data. Word alignments between a source and a target sentence were an integral part in count-based statistical machine translation systems (Brown et al., 1993; Koehn et al., 2007) and it has been shown that they can be used to help certain aspects of NMT systems as well (Alkhouli et al., 2018). For a long time, IBM-model-based frameworks like GIZA++ (Och and Ney, 2003) or fastalign (Dyer et al., 2013) produced the best word alignments. However, recently Sabet et al. (2020) report equally good results by using a word similarity matrix calculated from cross-lingual word embeddings. Recently, a number of shared tasks for data filtering have been held, giving a good overview of current state-of-the-art methods. Best known is the WMT shared task for parallel corpus filtering, which was held in 2018 (Koehn et al., 2018), 2019 (Koehn et al., 2019) and 2020 (Koehn et al., 2020) respectivel"
2021.naacl-main.15,P18-1073,0,0.15603,"a noisy corpus. Afterwards, a fixed amount of sentence pairs is selected according to that score. The best performing submissions from past years use language identification tools as the first part of 3 Detecting Different Types of Noise their setup (Junczys-Dowmunt, 2018; Chaudhary Applying language identification (language ID) is et al., 2019; Lu et al., 2020), removing sentence a well established first step in most high performpairs where the language of either source or target sentence does not match the expectation. Rossen- ing data filtering approaches. During this step, all bach et al. (2018) and Junczys-Dowmunt (2018) sentence pairs for which either the source or taruse a combination of language model and trans- get sentence is not mapped to the correct language are discarded. It can be argued that this step does lation model scores to sort the sentence pairs by quality. Chaudhary et al. (2019) use the cosine dis- not only remove sentence pairs in the wrong language, but also that language-agnostic noise, e.g. tance between cross-lingual sentence embeddings of source and target sentence as score. Wang et al. sequences of numbers, is almost completely re(2017) estimate the quality"
2021.naacl-main.15,W18-2709,0,0.0148543,"T tasks. We find that said method, which was performing very strong in the WMT shared task, does not perform well within our more realistic task conditions. While we find that our approaches come out at the top on all three tasks, different variants perform best on different tasks. Further experiments on the WMT 2020 shared task for parallel corpus filtering show that our methods achieve comparable results to the strongest submissions of this campaign. 1 Introduction training, which often comes from web-crawling1 and is quite ‘noisy’, the task of data filtering becomes increasingly important (Khayrallah and Koehn, 2018). Data filtering in the context of machine translation (MT) describes a collection of approaches which select a subset of a given, possibly noisy corpus with the aim to maximize the performance of an MT system trained on this data. There exist very simple approaches, the most prominent being based on language identification tools, to detect certain types of noise, e.g. sentences that are from a wrong language. However, other types of noise are much harder to detect, for example when both source and target sentence are well formulated and in the correct language but are not translations of one"
2021.naacl-main.15,J93-2003,0,0.156749,"sentations should be aligned in such a way that the embeddings of the same word in different languages are close together in the embedding space. The standard approach for creating such embeddings is to first train embeddings for each language pair separately (Mikolov et al., 2013; Pennington et al., 2014) and then projecting them into the same vector space (Conneau et al., 2017; Artetxe et al., 2018), which is possible with or without the help of parallel data. Word alignments between a source and a target sentence were an integral part in count-based statistical machine translation systems (Brown et al., 1993; Koehn et al., 2007) and it has been shown that they can be used to help certain aspects of NMT systems as well (Alkhouli et al., 2018). For a long time, IBM-model-based frameworks like GIZA++ (Och and Ney, 2003) or fastalign (Dyer et al., 2013) produced the best word alignments. However, recently Sabet et al. (2020) report equally good results by using a word similarity matrix calculated from cross-lingual word embeddings. Recently, a number of shared tasks for data filtering have been held, giving a good overview of current state-of-the-art methods. Best known is the WMT shared task for par"
2021.naacl-main.15,W19-5404,0,0.0183982,"ertain aspects of NMT systems as well (Alkhouli et al., 2018). For a long time, IBM-model-based frameworks like GIZA++ (Och and Ney, 2003) or fastalign (Dyer et al., 2013) produced the best word alignments. However, recently Sabet et al. (2020) report equally good results by using a word similarity matrix calculated from cross-lingual word embeddings. Recently, a number of shared tasks for data filtering have been held, giving a good overview of current state-of-the-art methods. Best known is the WMT shared task for parallel corpus filtering, which was held in 2018 (Koehn et al., 2018), 2019 (Koehn et al., 2019) and 2020 (Koehn et al., 2020) respectively. In these tasks, the participants are asked to provide scores for every sentence pair in a noisy corpus. Afterwards, a fixed amount of sentence pairs is selected according to that score. The best performing submissions from past years use language identification tools as the first part of 3 Detecting Different Types of Noise their setup (Junczys-Dowmunt, 2018; Chaudhary Applying language identification (language ID) is et al., 2019; Lu et al., 2020), removing sentence a well established first step in most high performpairs where the language of eithe"
2021.naacl-main.15,W19-5435,0,0.0727532,"language identification (language ID) is et al., 2019; Lu et al., 2020), removing sentence a well established first step in most high performpairs where the language of either source or target sentence does not match the expectation. Rossen- ing data filtering approaches. During this step, all bach et al. (2018) and Junczys-Dowmunt (2018) sentence pairs for which either the source or taruse a combination of language model and trans- get sentence is not mapped to the correct language are discarded. It can be argued that this step does lation model scores to sort the sentence pairs by quality. Chaudhary et al. (2019) use the cosine dis- not only remove sentence pairs in the wrong language, but also that language-agnostic noise, e.g. tance between cross-lingual sentence embeddings of source and target sentence as score. Wang et al. sequences of numbers, is almost completely re(2017) estimate the quality of a sentence pair us- moved. ing the euclidean distance between each sentence In order to evaluate the effectiveness of the filvector and two vectors representing in-domain and tering by language ID approach, we decide to test out-domain data. Hangya and Fraser (2018) score the method on the popular De→En"
2021.naacl-main.15,N13-1073,0,0.0270496,"ir separately (Mikolov et al., 2013; Pennington et al., 2014) and then projecting them into the same vector space (Conneau et al., 2017; Artetxe et al., 2018), which is possible with or without the help of parallel data. Word alignments between a source and a target sentence were an integral part in count-based statistical machine translation systems (Brown et al., 1993; Koehn et al., 2007) and it has been shown that they can be used to help certain aspects of NMT systems as well (Alkhouli et al., 2018). For a long time, IBM-model-based frameworks like GIZA++ (Och and Ney, 2003) or fastalign (Dyer et al., 2013) produced the best word alignments. However, recently Sabet et al. (2020) report equally good results by using a word similarity matrix calculated from cross-lingual word embeddings. Recently, a number of shared tasks for data filtering have been held, giving a good overview of current state-of-the-art methods. Best known is the WMT shared task for parallel corpus filtering, which was held in 2018 (Koehn et al., 2018), 2019 (Koehn et al., 2019) and 2020 (Koehn et al., 2020) respectively. In these tasks, the participants are asked to provide scores for every sentence pair in a noisy corpus. Aft"
2021.naacl-main.15,W18-6477,0,0.0278364,"to sort the sentence pairs by quality. Chaudhary et al. (2019) use the cosine dis- not only remove sentence pairs in the wrong language, but also that language-agnostic noise, e.g. tance between cross-lingual sentence embeddings of source and target sentence as score. Wang et al. sequences of numbers, is almost completely re(2017) estimate the quality of a sentence pair us- moved. ing the euclidean distance between each sentence In order to evaluate the effectiveness of the filvector and two vectors representing in-domain and tering by language ID approach, we decide to test out-domain data. Hangya and Fraser (2018) score the method on the popular De→En data filtering the similarity between source and target sentence task. By manually checking the noisy corpus (see by averaging the word-pair similarity, which is cal- Section 5.1 for details) we find different types of culated from cross-lingual word embeddings. ‘noise patterns’. For each of these ‘noise patterns’, Since the above mentioned methods are eval- we create a synthetic corpus (50k lines each), only uated on different tasks with very different data consisting of sentence pairs with this specific noise. 163 We find/create the following ‘noise pat"
2021.naacl-main.15,W18-6478,0,0.107517,"ring have been held, giving a good overview of current state-of-the-art methods. Best known is the WMT shared task for parallel corpus filtering, which was held in 2018 (Koehn et al., 2018), 2019 (Koehn et al., 2019) and 2020 (Koehn et al., 2020) respectively. In these tasks, the participants are asked to provide scores for every sentence pair in a noisy corpus. Afterwards, a fixed amount of sentence pairs is selected according to that score. The best performing submissions from past years use language identification tools as the first part of 3 Detecting Different Types of Noise their setup (Junczys-Dowmunt, 2018; Chaudhary Applying language identification (language ID) is et al., 2019; Lu et al., 2020), removing sentence a well established first step in most high performpairs where the language of either source or target sentence does not match the expectation. Rossen- ing data filtering approaches. During this step, all bach et al. (2018) and Junczys-Dowmunt (2018) sentence pairs for which either the source or taruse a combination of language model and trans- get sentence is not mapped to the correct language are discarded. It can be argued that this step does lation model scores to sort the sentenc"
2021.naacl-main.15,2020.wmt-1.111,0,0.0803367,"e WMT shared task for parallel corpus filtering, which was held in 2018 (Koehn et al., 2018), 2019 (Koehn et al., 2019) and 2020 (Koehn et al., 2020) respectively. In these tasks, the participants are asked to provide scores for every sentence pair in a noisy corpus. Afterwards, a fixed amount of sentence pairs is selected according to that score. The best performing submissions from past years use language identification tools as the first part of 3 Detecting Different Types of Noise their setup (Junczys-Dowmunt, 2018; Chaudhary Applying language identification (language ID) is et al., 2019; Lu et al., 2020), removing sentence a well established first step in most high performpairs where the language of either source or target sentence does not match the expectation. Rossen- ing data filtering approaches. During this step, all bach et al. (2018) and Junczys-Dowmunt (2018) sentence pairs for which either the source or taruse a combination of language model and trans- get sentence is not mapped to the correct language are discarded. It can be argued that this step does lation model scores to sort the sentence pairs by quality. Chaudhary et al. (2019) use the cosine dis- not only remove sentence pai"
2021.naacl-main.15,P12-3005,0,0.0457528,"very different sources and, hence, should express rather different data biases and noise patterns. We choose to test the proposed methods in two settings of the WMT news translation task and not in the conditions defined by the WMT parallel corpus filtering task because we experienced in the past, that performance gains from data filtering on the very noisy corpora of the data filtering task do not carry over to the news translation task. For the corpus data statistics, please refer to Table 2. Following state of the art filtering systems (Junczys-Dowmunt, 2018), we use the langid.py toolkit (Lui and Baldwin, 2012) as the first step in our filtering pipeline by removing source and target sentences where at least one side is not classified to be the correct language. In order to obtain cross-lingual word embeddings we follow the method proposed by Artetxe et al. (2018). In particular we first train GloVe Word Embeddings (Pennington et al., 2014) with a fixed vector size of 300 on the respective monolingual corpora after applying langid.py. From these we select the embeddings of the 200k most common words in each language. They form the base We introduce Variants (2) and (3) since we observe that often th"
2021.naacl-main.15,J03-1002,1,0.0594595,"n embeddings for each language pair separately (Mikolov et al., 2013; Pennington et al., 2014) and then projecting them into the same vector space (Conneau et al., 2017; Artetxe et al., 2018), which is possible with or without the help of parallel data. Word alignments between a source and a target sentence were an integral part in count-based statistical machine translation systems (Brown et al., 1993; Koehn et al., 2007) and it has been shown that they can be used to help certain aspects of NMT systems as well (Alkhouli et al., 2018). For a long time, IBM-model-based frameworks like GIZA++ (Och and Ney, 2003) or fastalign (Dyer et al., 2013) produced the best word alignments. However, recently Sabet et al. (2020) report equally good results by using a word similarity matrix calculated from cross-lingual word embeddings. Recently, a number of shared tasks for data filtering have been held, giving a good overview of current state-of-the-art methods. Best known is the WMT shared task for parallel corpus filtering, which was held in 2018 (Koehn et al., 2018), 2019 (Koehn et al., 2019) and 2020 (Koehn et al., 2020) respectively. In these tasks, the participants are asked to provide scores for every sen"
2021.naacl-main.15,N19-4009,0,0.031744,"Missing"
2021.naacl-main.15,P02-1040,0,0.115643,"Missing"
2021.naacl-main.15,D14-1162,0,0.0856302,"that they use ‘known-tobe-clean’ parallel data in order to train the models of their filtering pipeline. Creating cross-lingual word embeddings from parallel and/or monolingual data is an active field of research (Ruder et al., 2019). In addition to capturing semantic relationships within each language, these representations should be aligned in such a way that the embeddings of the same word in different languages are close together in the embedding space. The standard approach for creating such embeddings is to first train embeddings for each language pair separately (Mikolov et al., 2013; Pennington et al., 2014) and then projecting them into the same vector space (Conneau et al., 2017; Artetxe et al., 2018), which is possible with or without the help of parallel data. Word alignments between a source and a target sentence were an integral part in count-based statistical machine translation systems (Brown et al., 1993; Koehn et al., 2007) and it has been shown that they can be used to help certain aspects of NMT systems as well (Alkhouli et al., 2018). For a long time, IBM-model-based frameworks like GIZA++ (Och and Ney, 2003) or fastalign (Dyer et al., 2013) produced the best word alignments. However"
2021.naacl-main.15,W18-6487,1,0.841784,"Missing"
2021.naacl-main.15,2020.findings-emnlp.147,0,0.0934716,"rojecting them into the same vector space (Conneau et al., 2017; Artetxe et al., 2018), which is possible with or without the help of parallel data. Word alignments between a source and a target sentence were an integral part in count-based statistical machine translation systems (Brown et al., 1993; Koehn et al., 2007) and it has been shown that they can be used to help certain aspects of NMT systems as well (Alkhouli et al., 2018). For a long time, IBM-model-based frameworks like GIZA++ (Och and Ney, 2003) or fastalign (Dyer et al., 2013) produced the best word alignments. However, recently Sabet et al. (2020) report equally good results by using a word similarity matrix calculated from cross-lingual word embeddings. Recently, a number of shared tasks for data filtering have been held, giving a good overview of current state-of-the-art methods. Best known is the WMT shared task for parallel corpus filtering, which was held in 2018 (Koehn et al., 2018), 2019 (Koehn et al., 2019) and 2020 (Koehn et al., 2020) respectively. In these tasks, the participants are asked to provide scores for every sentence pair in a noisy corpus. Afterwards, a fixed amount of sentence pairs is selected according to that s"
2021.naacl-main.15,2006.amta-papers.25,0,0.199329,"Missing"
2021.naacl-main.15,P17-2089,0,0.0546806,"Missing"
2021.naacl-main.15,P18-4022,1,0.83975,"Missing"
bungeroth-etal-2006-german,2005.mtsummit-ebmt.14,0,\N,Missing
bungeroth-etal-2008-atis,H90-1021,0,\N,Missing
bungeroth-etal-2008-atis,bungeroth-etal-2006-german,1,\N,Missing
C00-2123,W99-0604,1,0.821331,"nd Ney, 2000). The sentence length probability p(J jI ) is omitted without any loss in performance. For the inverted alignment probability p(bi jbi 1 ; I; J ), we drop the dependence on the target sentence length I . 2.2 Word Joining The baseline alignment model does not permit that a source word is aligned to two or more target words, e.g. for the translation direction from German to English, the German compound noun 'Zahnarzttermin' causes problems, because it must be translated by the two target words dentist's appointment. We use a solution to this problem similar to the one presented in (Och et al., 1999), where target words are joined during training. The word joining is done on the basis of a likelihood criterion. An extended lexicon model is de ned, and its likelihood is compared to a baseline lexicon model, which takes only single-word dependencies into account. E.g. when 'Zahnarzttermin' is aligned to dentist's, the extended lexicon model might learn that 'Zahnarzttermin' actually has to be aligned to both dentist's and appointment. In the following, we assume that this word joining has been carried out. 3 DP Algorithm for Statistical Machine Translation In order to handle the necessary w"
C00-2123,C00-2163,1,0.764311,"= max I I Y i=1 [p(bi jbi j  max eI ;bI p(J I ) 1 p(bi jbi p( i=1 1 1  j ei eii 12 May ) of  )) j 1 ; I; J ) p(fbi ei )] ( I Y  i=1 j j fourth =  the on you p(ei eii 12 ) visit )) not 1 ; I; J ) p(fbi ei )] ; can colleague my where the two products over i have been merged into a single product over i. p(ei jeii 12 ) is the trigram language model probability. The inverted alignment probability p(bi jbi 1 ; I; J ) and the lexicon probability p(fbi jei ) are obtained by relative frequency estimates from the Viterbi alignment path after the nal training iteration. The details are given in (Och and Ney, 2000). The sentence length probability p(J jI ) is omitted without any loss in performance. For the inverted alignment probability p(bi jbi 1 ; I; J ), we drop the dependence on the target sentence length I . 2.2 Word Joining The baseline alignment model does not permit that a source word is aligned to two or more target words, e.g. for the translation direction from German to English, the German compound noun 'Zahnarzttermin' causes problems, because it must be translated by the two target words dentist's appointment. We use a solution to this problem similar to the one presented in (Och et al., 1"
C00-2123,P97-1037,1,0.918764,"Missing"
C00-2123,1993.mtsummit-1.11,0,0.0518831,"Missing"
C00-2123,J93-2003,0,\N,Missing
C00-2162,C90-3030,0,0.0187675,"kinds of transformations we apply. Source Language Text Transformation J I Pr(f 1 |e 1 ) Global Search: J Lexicon Model Alignment Model I Pr(f 1 |e 1 ) over e 1I I Pr( e 1 ) Language Model Transformation Target Language Text Figure 1: Architecture of the translation approach based on Bayes&apos; decision rule. 3 3.1 Analysis We used GERTWOL, a German Morphological Analyser (Haapalainen and Majorin, 1995) and the Constraint Grammar Parser for German GERCG for lexical analysis and morphological and syntactic disambiguation. For a description of the Constraint Grammar approach we refer the reader to (Karlsson, 1990). Some preprocessing was necessary to meet the input format requirements of the tools. In the cases where the tools returned more than one reading, either simple heuristics based on domain speci c preference rules where applied or a more general, non-ambiguous analysis was used. In the following subsections we list some transformations we have tested. 3.2 Separated German Verbpre xes J f1 maximize Pr( e 1I ) The transformation method however is more adequate for the preliminary identi cation of those phenomena relevant for improving the translation results. Analysis and Transformation of the I"
C00-2162,P98-2158,0,0.0878528,"Missing"
C00-2162,niessen-etal-2000-evaluation,1,0.292932,"Missing"
C00-2162,P98-2162,0,0.0903341,"Missing"
C00-2162,W99-0604,1,0.80879,"Missing"
C00-2162,1993.mtsummit-1.11,0,0.0903116,"Missing"
C00-2162,P97-1047,0,0.0211324,"Missing"
C00-2162,J93-2003,0,\N,Missing
C00-2162,C98-2153,0,\N,Missing
C00-2162,C98-2157,0,\N,Missing
C00-2163,J93-2003,0,0.283447,"ine translation. We propose to measure the quality of an alignment model using the quality of the Viterbi alignment compared to a manually-produced alignment and describe a re ned annotation scheme to produce suitable reference alignments. We also compare the impact of di erent alignment models on the translation quality of a statistical machine translation system. 1 Introduction In statistical machine translation (SMT) it is necessary to model the translation probability P r(f1J jeI1 ). Here f1J = f denotes the (French) source and eI1 = e denotes the (English) target string. Most SMT models (Brown et al., 1993; Vogel et al., 1996) try to model word-to-word correspondences between source and target words using an alignment mapping from source position j to target position i = aj . We can rewrite the probability P r(f1J jeI1 ) by introducing the `hidden&apos; alignments aJ1 := a1 :::aj :::aJ (aj 2 f0; : : : ; I g): P r(f1 je1 ) = J I X aJ P r(f1 ; a1 je1 ) J J I 1 = J XY P r(f ; a jf1 1 ; a1 1 ; e1 ) j j J a 1 j j I j =1 To allow for French words which do not directly correspond to any English word an arti cial &apos;empty&apos; word e0 is added to the target sentence at position i = 0. The di erent alignment model"
C00-2163,niessen-etal-2000-evaluation,1,0.45998,"Missing"
C00-2163,W99-0604,1,0.676963,"or words which are in the dictionary but indirectly also for other words. The additional sentences in the training corpus are weighted with a factor Flex during the EM-training of the lexicon probabilities. We assign the dictionary entries which really cooccur in the training corpus a high weight Flex and the remaining entries a very low weight. In our experiments we use Flex = 10 for the co-occurring dictionary entries which is equivalent to adding every dictionary entry ten times to the training corpus. 6 The Alignment Template System The statistical machine-translation method described in (Och et al., 1999) is based on a word aligned training corpus and thereby makes use of singleword based alignment models. The key element of this approach are the alignment templates which are pairs of phrases together with an alignment between the words within the phrases. The advantage of the alignment template approach over word based statistical translation models is that word context and local re-orderings are explicitly taken into account. We typically observe that this approach produces better translations than the single-word based models. The alignment templates are automatically trained using a parall"
C00-2163,C96-2141,1,0.953355,"propose to measure the quality of an alignment model using the quality of the Viterbi alignment compared to a manually-produced alignment and describe a re ned annotation scheme to produce suitable reference alignments. We also compare the impact of di erent alignment models on the translation quality of a statistical machine translation system. 1 Introduction In statistical machine translation (SMT) it is necessary to model the translation probability P r(f1J jeI1 ). Here f1J = f denotes the (French) source and eI1 = e denotes the (English) target string. Most SMT models (Brown et al., 1993; Vogel et al., 1996) try to model word-to-word correspondences between source and target words using an alignment mapping from source position j to target position i = aj . We can rewrite the probability P r(f1J jeI1 ) by introducing the `hidden&apos; alignments aJ1 := a1 :::aj :::aJ (aj 2 f0; : : : ; I g): P r(f1 je1 ) = J I X aJ P r(f1 ; a1 je1 ) J J I 1 = J XY P r(f ; a jf1 1 ; a1 1 ; e1 ) j j J a 1 j j I j =1 To allow for French words which do not directly correspond to any English word an arti cial &apos;empty&apos; word e0 is added to the target sentence at position i = 0. The di erent alignment models we present provide"
C00-2163,1993.mtsummit-1.11,0,0.0746119,"of the alignment template approach over word based statistical translation models is that word context and local re-orderings are explicitly taken into account. We typically observe that this approach produces better translations than the single-word based models. The alignment templates are automatically trained using a parallel training corpus. For more information about the alignment template approach see (Och et al., 1999). 7 Results We present results on the Verbmobil Task which is a speech translation task in the domain of appointment scheduling, travel planning, and hotel reservation (Wahlster, 1993). We measure the quality of the above mentioned alignment models with respect to alignment quality and translation quality. To obtain a reference alignment for evaluating alignment quality, we manually aligned about 1.4 percent of our training corpus. We allowed the humans who performed the alignment to specify two di erent kinds of alignments: an S (sure) alignment which is used for alignments which are unambiguously and a P (possible) alignment which is used for alignments which might or might not exist. The P relation is used especially to align words within idiomatic expressions, free tran"
C02-1032,C00-2163,1,\N,Missing
C02-1032,J93-2003,0,\N,Missing
C02-1032,E99-1010,1,\N,Missing
C02-1032,J96-1002,0,\N,Missing
C02-1032,P01-1027,1,\N,Missing
C02-1032,W00-0707,0,\N,Missing
C04-1006,J93-2003,0,0.0180943,"Missing"
C04-1006,P03-1012,0,0.0604065,"Missing"
C04-1006,P03-1011,0,0.0257173,"Missing"
C04-1006,J00-2004,0,0.217992,"Missing"
C04-1006,P00-1056,1,0.699934,"hereas in language modeling typically integer counts are used. Additionally, we want to allow for discounting values d greater than one. The backing-off distribution β(f, e¯) is estimated using relative frequencies: β(f, e¯) = N (f, e¯) P N (f˜, e¯) f˜ Here, N (f, e¯) denotes the count of the event that the source language word f and the target language base form e¯ occur together. These counts are computed by summing the lexicon counts N (f, e) over all full-form words e which share the same base form e¯. 5 Results 5.1 Evaluation Criteria We use the same evaluation criterion as described in (Och and Ney, 2000). The generated word alignment is compared to a reference alignment which is produced by human experts. The annotation scheme explicitly takes the ambiguity of the word alignment into account. There are two different kinds of alignments: sure alignments (S) which are used for alignments that are unambiguous and possible alignments (P ) which are used for alignments that might or might not exist. The P relation is used especially to align words within idiomatic expressions, free translations, and missing function words. It is guaranteed that the sure alignments are a subset of the possible alig"
C04-1006,J03-1002,1,0.114909,"l language processing. Obvious applications are the extraction of bilingual word or phrase lexica (Melamed, 2000; Och and Ney, 2000). These applications depend heavily on the quality of the word alignment (Och and Ney, 2000). Word alignment models were first introduced in statistical machine translation (Brown et al., 1993). The alignment describes the mapping from source sentence words to target sentence words. Using the IBM translation models IBM-1 to IBM-5 (Brown et al., 1993), as well as the Hidden-Markov alignment model (Vogel et al., 1996), we can produce alignments of good quality. In (Och and Ney, 2003), it is shown that the statistical approach performs very well compared to alternative approaches, e.g. based on the Dice coefficient or the competitive linking algorithm (Melamed, 2000). A central component of the statistical translation models is the lexicon. It models the word translation probabilities. The standard training procedure of the statistical models uses the EM algorithm. Typically, the models are trained for one translation direction only. Here, we will perform a simultaneous training of both translation directions, source-to-target and target-to-source. After each iteration of"
C04-1006,W02-1012,0,0.215898,"Missing"
C04-1006,C96-2141,1,0.951397,"l corpora are an important knowledge source for many tasks in natural language processing. Obvious applications are the extraction of bilingual word or phrase lexica (Melamed, 2000; Och and Ney, 2000). These applications depend heavily on the quality of the word alignment (Och and Ney, 2000). Word alignment models were first introduced in statistical machine translation (Brown et al., 1993). The alignment describes the mapping from source sentence words to target sentence words. Using the IBM translation models IBM-1 to IBM-5 (Brown et al., 1993), as well as the Hidden-Markov alignment model (Vogel et al., 1996), we can produce alignments of good quality. In (Och and Ney, 2003), it is shown that the statistical approach performs very well compared to alternative approaches, e.g. based on the Dice coefficient or the competitive linking algorithm (Melamed, 2000). A central component of the statistical translation models is the lexicon. It models the word translation probabilities. The standard training procedure of the statistical models uses the EM algorithm. Typically, the models are trained for one translation direction only. Here, we will perform a simultaneous training of both translation directio"
C04-1006,J97-3002,0,0.190502,"Missing"
C04-1030,J90-2002,0,0.427447,"significant improvements compared to the unconstrained search. 1 Introduction In statistical machine translation, we are given a source language (‘French’) sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language (‘English’) sentence eI1 = e1 . . . ei . . . eI . Among all possible target language sentences, we will choose the sentence with the highest probability: © ª eˆI1 = argmax P r(eI1 |f1J ) eI1 = argmax eI1 © ª P r(eI1 ) · P r(f1J |eI1 ) This decomposition into two knowledge sources is known as the source-channel approach to statistical machine translation (Brown et al., 1990). It allows an independent modeling of target language model P r(eI1 ) and translation model P r(f1J |eI1 ). The target language model describes the well-formedness of the target language sentence. The translation model links the source language sentence to the target language sentence. It can be further decomposed into alignment and lexicon model. The argmax operation denotes the search problem, i.e. the generation of the output sentence in the target language. We have to maximize over all possible target language sentences. An alternative to the classical sourcechannel approach is the direct"
C04-1030,J99-4005,0,0.599269,"ls or feature functions can be easily integrated into the overall system. The model scaling factors λM 1 are trained according to the maximum entropy principle, e.g. using the GIS algorithm. Alternatively, one can train them with respect to the final translation quality measured by some error criterion (Och, 2003). In this paper, we will investigate the reordering problem for phrase-based translation approaches. As the word order in source and target language may differ, the search algorithm has to allow certain reorderings. If arbitrary reorderings are allowed, the search problem is NP-hard (Knight, 1999). To obtain an efficient search algorithm, we can either restrict the possible reorderings or we have to use an approximation algorithm. Note that in the latter case we cannot guarantee to find an optimal solution. The remaining part of this work is structured as follows: in the next section, we will review the baseline translation system, namely the alignment template approach. Afterward, we will describe different reordering constraints. We will begin with the IBM constraints for phrase-based translation. Then, we will describe constraints based on inversion transduction grammars (ITG). In t"
C04-1030,N03-1017,0,0.32893,"Missing"
C04-1030,W02-1018,0,0.0915666,"Missing"
C04-1030,P02-1038,1,0.858868,"lation model P r(f1J |eI1 ). The target language model describes the well-formedness of the target language sentence. The translation model links the source language sentence to the target language sentence. It can be further decomposed into alignment and lexicon model. The argmax operation denotes the search problem, i.e. the generation of the output sentence in the target language. We have to maximize over all possible target language sentences. An alternative to the classical sourcechannel approach is the direct modeling of the posterior probability P r(eI1 |f1J ). Using a loglinear model (Och and Ney, 2002), we obtain: Ã P r(eI1 |f1J ) = exp ! M X λm hm (eI1 , f1J ) · Z(f1J ) m=1 Here, Z(f1J ) denotes the appropriate normalization constant. As a decision rule, we obtain: ( eˆI1 = argmax eI1 M X ) λm hm (eI1 , f1J ) m=1 This approach is a generalization of the source-channel approach. It has the advantage that additional models or feature functions can be easily integrated into the overall system. The model scaling factors λM 1 are trained according to the maximum entropy principle, e.g. using the GIS algorithm. Alternatively, one can train them with respect to the final translation quality measu"
C04-1030,W99-0604,1,0.401442,"nslation system, namely the alignment template approach. Afterward, we will describe different reordering constraints. We will begin with the IBM constraints for phrase-based translation. Then, we will describe constraints based on inversion transduction grammars (ITG). In the following, we will call these the ITG constraints. In Section 4, we will present results for two Japanese–English translation tasks. 2 Alignment Template Approach In this section, we give a brief description of the translation system, namely the alignment template approach. The key elements of this translation approach (Och et al., 1999) are the alignment templates. These are pairs of source and target language phrases with an alignment within the phrases. The alignment templates are build at the level of word classes. This improves the generalization capability of the alignment templates. We use maximum entropy to train the model scaling factors (Och and Ney, 2002). As feature functions we use a phrase translation model as well as a word translation model. Additionally, we use two language model feature functions: a word-based trigram model and a class-based five-gram model. Furthermore, we use two heuristics, namely the wor"
C04-1030,P03-1021,0,0.209602,"= exp ! M X λm hm (eI1 , f1J ) · Z(f1J ) m=1 Here, Z(f1J ) denotes the appropriate normalization constant. As a decision rule, we obtain: ( eˆI1 = argmax eI1 M X ) λm hm (eI1 , f1J ) m=1 This approach is a generalization of the source-channel approach. It has the advantage that additional models or feature functions can be easily integrated into the overall system. The model scaling factors λM 1 are trained according to the maximum entropy principle, e.g. using the GIS algorithm. Alternatively, one can train them with respect to the final translation quality measured by some error criterion (Och, 2003). In this paper, we will investigate the reordering problem for phrase-based translation approaches. As the word order in source and target language may differ, the search algorithm has to allow certain reorderings. If arbitrary reorderings are allowed, the search problem is NP-hard (Knight, 1999). To obtain an efficient search algorithm, we can either restrict the possible reorderings or we have to use an approximation algorithm. Note that in the latter case we cannot guarantee to find an optimal solution. The remaining part of this work is structured as follows: in the next section, we will"
C04-1030,P02-1040,0,0.113983,"eletion operations that have to be performed to convert the generated sentence into the reference sentence. PER (position-independent word error rate). A shortcoming of the WER is that it requires a perfect word order. The word order of an acceptable sentence can be different from that of the target sentence, so that the WER measure alone could be misleading. The PER compares the words in the two sentences ignoring the word order. BLEU. This score measures the precision of unigrams, bigrams, trigrams and fourgrams with respect to a reference translation with a penalty for too short sentences (Papineni et al., 2002). The BLEU score measures accuracy, i.e. large BLEU scores are better. NIST. This score is similar to BLEU. It is a weighted n-gram precision in combination with a penalty for too short sentences (Doddington, 2002). The NIST score measures accuracy, i.e. large NIST scores are better. Note that for each source sentence, we have as many as 16 references available. We compute all the preceding criteria with respect to multiple references. 4.3 System Comparison In Table 3 and Table 4, we show the translation results for the BTEC task. First, we observe that the overall quality is rather high on th"
C04-1030,takezawa-etal-2002-toward,1,0.296878,"to the left of the current position jc , e.g. positions (a) and (d). Somewhere in between there has to be an covered position j whose successor position j + 1 is uncovered, e.g. (b) and (c). Therefore, any reordering that violates Equation 1 generates the pattern on the left-hand side in Figure 4, thus it violates the ITG constraints. 4 Results 4.1 Corpus Statistics To investigate the effect of reordering constraints, we have chosen two Japanese–English tasks, because the word order in Japanese and English is rather different. The first task is the Basic Travel Expression Corpus (BTEC) task (Takezawa et al., 2002). The corpus statistics are shown in Table 1. This corpus consists of phrasebook entries. The second task is the Spoken Language DataBase (SLDB) task (Morimoto et al., 1994). This task consists of transcription of spoken dialogs in the domain of hotel reservation. Here, we use domain-specific training data in addition to the BTEC corpus. The corpus statistics of this additional corpus are shown in Table 2. The development corpus is the same for both tasks. 4.2 Evaluation Criteria WER (word error rate). The WER is computed as the minimum number of substitution, insertion and deletion operations"
C04-1030,J03-1005,1,0.779472,"a sequence of word classes as used in the alignment templates. 3.1 IBM Constraints In this section, we describe restrictions on the phrase reordering in spirit of the IBM constraints (Berger et al., 1996). First, we briefly review the IBM constraints at the word level. The target sentence is produced word by word. We keep a coverage vector to mark the already translated (covered) source positions. The next target word has to be the translation of one of the first k uncovered, i.e. not translated, source positions. The IBM constraints are illustrated in Figure 1. For further details see e.g. (Tillmann and Ney, 2003). For the phrase-based translation approach, we use the same idea. The target sentence is produced phrase by phrase. Now, we allow skipping of up to k phrases. If we set k = 0, we obtain a search that is monotone at the phrase level as a special case. Q(1, ∅, $) = 1  with inversion target positions without inversion target positions The search problem can be solved using dynamic programming. We define a auxiliary function Q(j, S, e). Here, the source position j is the first unprocessed source position; with unprocessed, we mean this source position is neither translated nor skipped. We use th"
C04-1030,J97-3002,0,0.799973,"the language model history. The symbol $ is used to mark the sentence start and the sentence end. The extension to higher-order n-gram language models is straightforward. We use M to denote the maximum phrase length in the source language. We obtain the following dynamic programming equations: source positions source positions Figure 2: Illustration of monotone and inverted concatenation of two consecutive blocks. setting k = 0 results in a search algorithm that is monotone at the phrase level. 3.2 ITG Constraints Q(j, S, e) = max In this section, we describe the ITG conn straints (Wu, 1995; Wu, 1997). Here, we interj−1 max max Q(j 0 , S, e0 ) · p(fj 0 |˜ e) · p(˜ e|e0 ), pret the input sentence as a sequence of blocks. e0 ,˜ e j−M ≤j 0 <j o 0 0 , e0 ) · p(f j +l−1 |˜ 0 ) , In the beginning, each alignment template is a max Q(j, S e ) · p(˜ e |e j0 block of its own. Then, the reordering process (j 0 ,l)∈S 0 S=S 0 {(j 0 ,l)}  can be interpreted as follows: we select two consecutive blocks and merge them to a single max0 Q(j 0 , S 0 , e) j−M ≤j <j block by choosing between two options: either S 0 :S=S 0 ∪{(j 0 ,j−j 0 )}∧|S 0 |<k keep the target phrases in monotone order or Q(J + 2, ∅, $) ="
C04-1030,P03-1019,1,0.776962,"entence word by word or phrase the position to be translated next jn . Then, by phrase. The idea is to start with the beam it is not allowed to move from an uncovered search decoder for unconstrained search and position to a covered one. modify it in such a way that it will produce Now, we sketch the proof that these cononly reorderings that do not violate the ITG straints are equivalent to the ITG constraints. constraints. Now, we describe one way to obIt is easy to see that the constraint in Equatain such a decoder. It has been pointed out tion 1 avoids the pattern on the left-hand side in (Zens and Ney, 2003) that the ITG conin Figure 4. To be precise: after placing the straints can be characterized as follows: a refirst two phrases at (b,1) and (d,2), it avoids ordering violates the ITG constraints if and the placement of the third phrase at (a,3). only if it contains (3, 1, 4, 2) or (2, 4, 1, 3) as Similarly, the constraint in Equation 2 avoid a subsequence. This means, if we select four the pattern on the right-hand side in Figcolumns and the corresponding rows from the ure 4. Therefore, if we enforce the constraints alignment matrix and we obtain one of the two in Equation 1 and Equation 2, we"
C04-1032,J93-2003,0,0.0320223,"particular the state occupation probabilities, will be used to determine the costs of aligning a specific source word to a target word. We will evaluate the suggested alignment methods on the German–English Verbmobil task and the French–English Canadian Hansards task. We will show statistically significant improvements compared to state-ofthe-art results in (Och and Ney, 2003). 2 Statistical Word Alignment Models In this section, we will give an overview of the commonly used statistical word alignment techniques. They are based on the sourcechannel approach to statistical machine translation (Brown et al., 1993). We are given a source language sentence f1J := f1 ...fj ...fJ which has to be translated into a target language sentence eI1 := e1 ...ei ...eI . Among all possible target language sentences, we will choose the sentence with the highest probability: © ª eˆI1 = argmax P r(eI1 |f1J ) eI1 = argmax eI1 © ª P r(eI1 ) · P r(f1J |eI1 ) This decomposition into two knowledge sources allows for an independent modeling of target language model P r(eI1 ) and translation model P r(f1J |eI1 ). Into the translation model, the word alignment A is introduced as a hidden variable: X P r(f1J |eI1 ) = P r(f1J ,"
C04-1032,P03-1012,0,0.0477676,"Missing"
C04-1032,P03-1011,0,0.0400771,"Missing"
C04-1032,J00-2004,0,0.0627208,"Missing"
C04-1032,P00-1056,1,0.805812,"the alignment are minimal. Using state occupation probabilities for word alignment modeling results in a number of advantages. First of all, in calculation of these probabilities with the models IBM-1, IBM-2 and HMM the EM-algorithm is performed exact, i.e. the summation over all alignments is efficiently performed in the Estep. For the HMM this is done using the Baum-Welch algorithm (Baum, 1972). So far, an efficient algorithm to compute the sum over all alignments in the fertility models IBM-3 to IBM-5 is not known. Therefore, this sum is approximated using a subset of promising alignments (Och and Ney, 2000). In both cases, the resulting estimates are more precise than the ones obtained by the maximum approximation, i. e. by considering only the Viterbi alignment. Instead of using the state occupation probabilities from only one training direction as costs (Equation 1), we can interpolate the state occupation probabilities from the sourceto-target and the target-to-source training for each pair (i,j) of positions in a sentence pair (f1J , eI1 ). This will improve the estimation of the local alignment costs. Having such symmetrized costs, we can employ the graph alignment algorithms (cf. Section 4"
C04-1032,J03-1002,1,0.261441,"which avoids this constraint and produces symmetric word alignments. This algorithm considers the alignment problem as a task of finding the edge cover with minimal costs in a bipartite graph. The parameters of the IBM models and HMM, in particular the state occupation probabilities, will be used to determine the costs of aligning a specific source word to a target word. We will evaluate the suggested alignment methods on the German–English Verbmobil task and the French–English Canadian Hansards task. We will show statistically significant improvements compared to state-ofthe-art results in (Och and Ney, 2003). 2 Statistical Word Alignment Models In this section, we will give an overview of the commonly used statistical word alignment techniques. They are based on the sourcechannel approach to statistical machine translation (Brown et al., 1993). We are given a source language sentence f1J := f1 ...fj ...fJ which has to be translated into a target language sentence eI1 := e1 ...ei ...eI . Among all possible target language sentences, we will choose the sentence with the highest probability: © ª eˆI1 = argmax P r(eI1 |f1J ) eI1 = argmax eI1 © ª P r(eI1 ) · P r(f1J |eI1 ) This decomposition into two"
C04-1032,C96-2141,1,0.935974,"aligned bilingual corpora provide important knowledge for many natural language processing tasks, such as the extraction of bilingual word or phrase lexica (Melamed, 2000; Och and Ney, 2000). The solutions of these problems depend heavily on the quality of the word alignment (Och and Ney, 2000). Word alignment models were first introduced in statistical machine translation (Brown et al., 1993). An alignment describes a mapping from source sentence words to target sentence words. Using the IBM translation models IBM-1 to IBM-5 (Brown et al., 1993), as well as the Hidden-Markov alignment model (Vogel et al., 1996), we can produce alignments of good quality. However, all these models constrain the alignments so that a source word can be aligned to at most one target word. This constraint is useful to reduce the computational complexity of the model training, but makes it hard to align phrases in the target language (English) such as ‘the day after tomorrow’ to one word in the source language (German) ‘¨ ubermorgen’. We will present a word alignment algorithm which avoids this constraint and produces symmetric word alignments. This algorithm considers the alignment problem as a task of finding the edge c"
C04-1032,J97-3002,0,0.0795518,"Missing"
C04-1045,J93-2003,0,0.0132705,"ty compared to the, to our knowledge, best system are reported on the German-English Verbmobil corpus. 1 Introduction In statistical machine translation, a translation model P r(f1J |eI1 ) describes the correspondences between the words in the source language sentence f1J and the words in the target language sentence eI1 . Statistical alignment models are created by introducing a hidden variable aJ1 representing a mapping from the source word fj into the target word eaj . So far, most of the statistical machine translation systems are based on the single-word alignment models as described in (Brown et al., 1993) as well as the Hidden Markov alignment model (Vogel et al., 1996). The lexicon models used in these systems typically do not include any linguistic or contextual information which often results in inadequate alignments between the sentence pairs. In this work, we propose an approach to improve the quality of the statistical alignments by taking into account the interdependencies of different derivations of the words. We are getting use of the hierarchical representation of the statistical lexicon model as proposed in (Nießen and Ney, 2001) for the conventional EM training procedure. Experimen"
C04-1045,C02-1032,1,0.704972,"Missing"
C04-1045,2001.mtsummit-papers.45,1,0.949885,"ed on the single-word alignment models as described in (Brown et al., 1993) as well as the Hidden Markov alignment model (Vogel et al., 1996). The lexicon models used in these systems typically do not include any linguistic or contextual information which often results in inadequate alignments between the sentence pairs. In this work, we propose an approach to improve the quality of the statistical alignments by taking into account the interdependencies of different derivations of the words. We are getting use of the hierarchical representation of the statistical lexicon model as proposed in (Nießen and Ney, 2001) for the conventional EM training procedure. Experimental results are reported for the German-English Verbmobil corpus and the evaluation is done by comparing the obtained Viterbi alignments after the training of conventional models and models which are using morpho-syntactic information with a manually annotated reference alignment. 2 Related Work The popular IBM models for statistical machine translation are described in (Brown et al., 1993) and the HMM-based alignment model was introduced in (Vogel et al., 1996). A good overview of all these models is given in (Och and Ney, 2003) where the"
C04-1045,W01-1407,1,0.909123,"ed on the single-word alignment models as described in (Brown et al., 1993) as well as the Hidden Markov alignment model (Vogel et al., 1996). The lexicon models used in these systems typically do not include any linguistic or contextual information which often results in inadequate alignments between the sentence pairs. In this work, we propose an approach to improve the quality of the statistical alignments by taking into account the interdependencies of different derivations of the words. We are getting use of the hierarchical representation of the statistical lexicon model as proposed in (Nießen and Ney, 2001) for the conventional EM training procedure. Experimental results are reported for the German-English Verbmobil corpus and the evaluation is done by comparing the obtained Viterbi alignments after the training of conventional models and models which are using morpho-syntactic information with a manually annotated reference alignment. 2 Related Work The popular IBM models for statistical machine translation are described in (Brown et al., 1993) and the HMM-based alignment model was introduced in (Vogel et al., 1996). A good overview of all these models is given in (Och and Ney, 2003) where the"
C04-1045,P00-1056,1,0.739818,"e initial models. Train where f bt represents the base form of the word f with sequence of corresponding tags, e.g. “gehen-V-IND-PRES”; s and the M-step is then performed using hierarchical counts: δ(f bt, f btjs )δ(e, eis ) i,j C(f b, e) = For each full form, refined hierarchical counts are obtained in the following way: Test Sentences Words Vocabulary Singletons Sentences Words S relations P relations German English 34446 329625 343076 5936 3505 2600 1305 354 3233 3109 2559 4596 Table 1: Corpus statistics for Verbmobil task 6.1 Evaluation Method We use the evaluation criterion described in (Och and Ney, 2000). The obtained word alignment is compared to a reference alignment produced by human experts. The annotation scheme explicitly takes into account the ambiguity of the word alignment. The unambiguous alignments are annotated as sure alignments (S) and the ambiguous ones as possible alignments (P ). The set of possible alignments P is used especially for idiomatic expressions, free translations and missing function words. The set S is subset of the set P (S ⊆ P ). The quality of an alignment A is computed as appropriately redefined precision and recall measures. Additionally, we use the alignmen"
C04-1045,J03-1002,1,0.111339,"sed in (Nießen and Ney, 2001) for the conventional EM training procedure. Experimental results are reported for the German-English Verbmobil corpus and the evaluation is done by comparing the obtained Viterbi alignments after the training of conventional models and models which are using morpho-syntactic information with a manually annotated reference alignment. 2 Related Work The popular IBM models for statistical machine translation are described in (Brown et al., 1993) and the HMM-based alignment model was introduced in (Vogel et al., 1996). A good overview of all these models is given in (Och and Ney, 2003) where the model IBM-6 is also introduced as the log-linear interpolation of the other models. Context dependencies have been introduced into the training of alignments in (Varea et al., 2002), but they do not take any linguistic information into account. Some recent publications have proposed the use of morpho-syntactic knowledge for statistical machine translation, but mostly only for the preprocessing step whereas training procedure of the statistical models remains the same (e.g. (Nießen and Ney, 2001a)). Incorporation of the morpho-syntactic knowlegde into statistical models has been deal"
C04-1045,C96-2141,1,0.9073,"the German-English Verbmobil corpus. 1 Introduction In statistical machine translation, a translation model P r(f1J |eI1 ) describes the correspondences between the words in the source language sentence f1J and the words in the target language sentence eI1 . Statistical alignment models are created by introducing a hidden variable aJ1 representing a mapping from the source word fj into the target word eaj . So far, most of the statistical machine translation systems are based on the single-word alignment models as described in (Brown et al., 1993) as well as the Hidden Markov alignment model (Vogel et al., 1996). The lexicon models used in these systems typically do not include any linguistic or contextual information which often results in inadequate alignments between the sentence pairs. In this work, we propose an approach to improve the quality of the statistical alignments by taking into account the interdependencies of different derivations of the words. We are getting use of the hierarchical representation of the statistical lexicon model as proposed in (Nießen and Ney, 2001) for the conventional EM training procedure. Experimental results are reported for the German-English Verbmobil corpus a"
C04-1045,W02-1012,0,\N,Missing
C08-1128,W06-1655,0,0.0211706,"e 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. Microsoft Corporation∗ One Microsoft Way Redmond, WA 98052, USA {jfgao,kristout}@microsoft.com frequencies are obtained using manually annotated data. This method is sub-optimal for MT. For example, d(paper) and d(card) can be two words or composed into one word dd(cards). Since d ddoes not exist in the manual lexicon, it cannot be generated by this method. In addition to unigram segmentation, other methods have been proposed. For example, (Gao et al., 2005) described an adaptive CWS system, and (Andrew, 2006) employed a conditional random field model for sequence segmentation. However, these methods are not specifically developed for the MT application, and significant improvements in translation performance need to be shown. In (Xu et al., 2004) and (Xu et al., 2005), word segmentations are integrated into MT systems during model training and translation. We refine the method in training using a Bayesian semisupervised CWS approach motivated by (Goldwater et al., 2006). We describe a generative model which consists of a word model and two alignment models, representing the monolingual and bilingu"
C08-1128,J93-2003,0,0.0237847,"ach table with infinite number of seats (approximately corresponding to Chinese word frequencies). The Dirichlet Process model can be viewed intuitively as a cache model (Goldwater et al., 2006). Each word fj in the corpus is either retrieved from a cache or generated anew given the previously observed words f−j : where the maximization is taken over Chinese word sequences whose character sequence is cK 1 . 2.2 Translation system Once we have segmented the Chinese sentences into words, we train standard alignment models in both directions with GIZA++ (Och and Ney, 2002) using models of IBM-1 (Brown et al., 1993), HMM (Vogel et al., 1996) and IBM-4 (Brown et al., 1993). Our MT system uses a phrase-based decoder and the log-linear model described in (Zens and Ney, 2004). Features in the log-linear model include translation models in two directions, a language model, a distortion model and a sentence length penalty. The feature weights are tuned on the development set using a downhill simplex algorithm (Press et al., 2002). The language model is a statistical ngram model estimated using modified Kneser-Ney smoothing. 3 Unigram Dirichlet Process Model for CWS The simplest version of our model is based on"
C08-1128,P02-1038,1,0.192261,"ly corresponding to Chinese word types), each table with infinite number of seats (approximately corresponding to Chinese word frequencies). The Dirichlet Process model can be viewed intuitively as a cache model (Goldwater et al., 2006). Each word fj in the corpus is either retrieved from a cache or generated anew given the previously observed words f−j : where the maximization is taken over Chinese word sequences whose character sequence is cK 1 . 2.2 Translation system Once we have segmented the Chinese sentences into words, we train standard alignment models in both directions with GIZA++ (Och and Ney, 2002) using models of IBM-1 (Brown et al., 1993), HMM (Vogel et al., 1996) and IBM-4 (Brown et al., 1993). Our MT system uses a phrase-based decoder and the log-linear model described in (Zens and Ney, 2004). Features in the log-linear model include translation models in two directions, a language model, a distortion model and a sentence length penalty. The feature weights are tuned on the development set using a downhill simplex algorithm (Press et al., 2002). The language model is a statistical ngram model estimated using modified Kneser-Ney smoothing. 3 Unigram Dirichlet Process Model for CWS Th"
C08-1128,P02-1040,0,0.110305,"step is done according to the algorithm in Table 1. Using this algorithm, we obtain a new segmentation of the Chinese data and train the translation models using this segmentation as in the baseline MT system. To segment the test data for translation, we use a unigram model, trained with maximum likelihood estimation off of the final segmentation of the training corpus FT . 6 Translation Experiments We performed experiments using our models for CWS on a large and a small data track. We evaluated performance by measuring WER (word error rate), PER (position-independent word error rate), BLEU (Papineni et al., 2002) and TER (translation error rate) (Snover et al., 2006) using multiple references. 6.1 Translation Task: Large Track NIST We first report the experiments using our monolingual unigram Dirichlet Process model for word segmentation on the NIST machine translation task (NIST, 2005). Because of the computational requirements, we only employed the monolingual word model for this large data track, i.e. the feature weights were λ1 = 1, λ2 = 0, λ3 = 0. Therefore, no alignment information needs to be maintained in this case. The bilingual training corpus is a superset of corpora in the news domain coll"
C08-1128,2006.amta-papers.25,0,0.0127207,"g this algorithm, we obtain a new segmentation of the Chinese data and train the translation models using this segmentation as in the baseline MT system. To segment the test data for translation, we use a unigram model, trained with maximum likelihood estimation off of the final segmentation of the training corpus FT . 6 Translation Experiments We performed experiments using our models for CWS on a large and a small data track. We evaluated performance by measuring WER (word error rate), PER (position-independent word error rate), BLEU (Papineni et al., 2002) and TER (translation error rate) (Snover et al., 2006) using multiple references. 6.1 Translation Task: Large Track NIST We first report the experiments using our monolingual unigram Dirichlet Process model for word segmentation on the NIST machine translation task (NIST, 2005). Because of the computational requirements, we only employed the monolingual word model for this large data track, i.e. the feature weights were λ1 = 1, λ2 = 0, λ3 = 0. Therefore, no alignment information needs to be maintained in this case. The bilingual training corpus is a superset of corpora in the news domain collected from different sources. We took LDC (LDC, 2003) a"
C08-1128,C96-2141,1,0.472239,"mber of seats (approximately corresponding to Chinese word frequencies). The Dirichlet Process model can be viewed intuitively as a cache model (Goldwater et al., 2006). Each word fj in the corpus is either retrieved from a cache or generated anew given the previously observed words f−j : where the maximization is taken over Chinese word sequences whose character sequence is cK 1 . 2.2 Translation system Once we have segmented the Chinese sentences into words, we train standard alignment models in both directions with GIZA++ (Och and Ney, 2002) using models of IBM-1 (Brown et al., 1993), HMM (Vogel et al., 1996) and IBM-4 (Brown et al., 1993). Our MT system uses a phrase-based decoder and the log-linear model described in (Zens and Ney, 2004). Features in the log-linear model include translation models in two directions, a language model, a distortion model and a sentence length penalty. The feature weights are tuned on the development set using a downhill simplex algorithm (Press et al., 2002). The language model is a statistical ngram model estimated using modified Kneser-Ney smoothing. 3 Unigram Dirichlet Process Model for CWS The simplest version of our model is based on a unigram Dirichlet Proce"
C08-1128,W04-1118,1,0.723099,"ted data. This method is sub-optimal for MT. For example, d(paper) and d(card) can be two words or composed into one word dd(cards). Since d ddoes not exist in the manual lexicon, it cannot be generated by this method. In addition to unigram segmentation, other methods have been proposed. For example, (Gao et al., 2005) described an adaptive CWS system, and (Andrew, 2006) employed a conditional random field model for sequence segmentation. However, these methods are not specifically developed for the MT application, and significant improvements in translation performance need to be shown. In (Xu et al., 2004) and (Xu et al., 2005), word segmentations are integrated into MT systems during model training and translation. We refine the method in training using a Bayesian semisupervised CWS approach motivated by (Goldwater et al., 2006). We describe a generative model which consists of a word model and two alignment models, representing the monolingual and bilingual information, respectively. In our methods, we first segment Chinese text using a unigram segmenter, and then learn new word types and word distributions, which are suitable for MT. Our experiments on both large (NIST) and small (IWSLT) dat"
C08-1128,2005.iwslt-1.18,1,0.694023,"is sub-optimal for MT. For example, d(paper) and d(card) can be two words or composed into one word dd(cards). Since d ddoes not exist in the manual lexicon, it cannot be generated by this method. In addition to unigram segmentation, other methods have been proposed. For example, (Gao et al., 2005) described an adaptive CWS system, and (Andrew, 2006) employed a conditional random field model for sequence segmentation. However, these methods are not specifically developed for the MT application, and significant improvements in translation performance need to be shown. In (Xu et al., 2004) and (Xu et al., 2005), word segmentations are integrated into MT systems during model training and translation. We refine the method in training using a Bayesian semisupervised CWS approach motivated by (Goldwater et al., 2006). We describe a generative model which consists of a word model and two alignment models, representing the monolingual and bilingual information, respectively. In our methods, we first segment Chinese text using a unigram segmenter, and then learn new word types and word distributions, which are suitable for MT. Our experiments on both large (NIST) and small (IWSLT) data tracks of Chinese-to"
C08-1128,N04-1033,1,0.749729,"ache model (Goldwater et al., 2006). Each word fj in the corpus is either retrieved from a cache or generated anew given the previously observed words f−j : where the maximization is taken over Chinese word sequences whose character sequence is cK 1 . 2.2 Translation system Once we have segmented the Chinese sentences into words, we train standard alignment models in both directions with GIZA++ (Och and Ney, 2002) using models of IBM-1 (Brown et al., 1993), HMM (Vogel et al., 1996) and IBM-4 (Brown et al., 1993). Our MT system uses a phrase-based decoder and the log-linear model described in (Zens and Ney, 2004). Features in the log-linear model include translation models in two directions, a language model, a distortion model and a sentence length penalty. The feature weights are tuned on the development set using a downhill simplex algorithm (Press et al., 2002). The language model is a statistical ngram model estimated using modified Kneser-Ney smoothing. 3 Unigram Dirichlet Process Model for CWS The simplest version of our model is based on a unigram Dirichlet Process (DP) model, using only monolingual information. Different from a standard unigram model for CWS, our model can introduce new Chine"
C08-1128,W03-1730,0,0.127363,"Missing"
C08-1128,J05-4005,1,0.845047,"the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. Microsoft Corporation∗ One Microsoft Way Redmond, WA 98052, USA {jfgao,kristout}@microsoft.com frequencies are obtained using manually annotated data. This method is sub-optimal for MT. For example, d(paper) and d(card) can be two words or composed into one word dd(cards). Since d ddoes not exist in the manual lexicon, it cannot be generated by this method. In addition to unigram segmentation, other methods have been proposed. For example, (Gao et al., 2005) described an adaptive CWS system, and (Andrew, 2006) employed a conditional random field model for sequence segmentation. However, these methods are not specifically developed for the MT application, and significant improvements in translation performance need to be shown. In (Xu et al., 2004) and (Xu et al., 2005), word segmentations are integrated into MT systems during model training and translation. We refine the method in training using a Bayesian semisupervised CWS approach motivated by (Goldwater et al., 2006). We describe a generative model which consists of a word model and two align"
C08-1128,P06-1085,0,\N,Missing
C08-1128,P02-1017,0,\N,Missing
C12-1053,J12-2006,0,0.0807906,"that our model improves the baseline system by 0.93 BLEU 0.98 TER on average. We also compare our method with a syntax-augmented model (Cherry, 2008), and demonstrate the importance of predicate-argument semantics in machine translation. KEYWORDS: statistical machine translation, semantic role labeling. Proceedings of COLING 2012: Technical Papers, pages 867–878, COLING 2012, Mumbai, December 2012. 867 1 Introduction In recent years, there are growing interests in incorporating semantics into statistical machine translation (SMT) (Wu and Fung, 2009; Liu and Gildea, 2010; Gao and Vogel, 2011; Baker et al., 2012). Among all existing semantic representations, semantic role labeling (SRL) aims at automatically analyzing predicate-argument structures and can capture essential meaning of sentences. Since the seminal work of (Gildea and Jurafsky, 2002), quite a few researchers concentrate on resolving SRL with different machine learning methods. Nowadays, good SRL systems can be built based on accurate syntactic parsers for English, as well as many other languages. In this paper, we explore predicate-argument analysis of source sentences to improve phrasebased SMT systems. On one hand, the predicate-argume"
C12-1053,P08-1009,0,0.520845,"ity, Beijing, China feng@cs.rwth-aachen.de, ws@pku.edu.cn, ney@cs.rwth-aachen.de ABSTRACT In this paper, we propose a novel semantic cohesion model. Our model utilizes the predicateargument structures as soft constraints and plays the role as a reordering model in the phrasebased statistical machine translation system. We build a translation system with GALE data. Experimental results on the NIST02, NIST03, NIST04, NIST05 and NIST08 Chinese-English tasks show that our model improves the baseline system by 0.93 BLEU 0.98 TER on average. We also compare our method with a syntax-augmented model (Cherry, 2008), and demonstrate the importance of predicate-argument semantics in machine translation. KEYWORDS: statistical machine translation, semantic role labeling. Proceedings of COLING 2012: Technical Papers, pages 867–878, COLING 2012, Mumbai, December 2012. 867 1 Introduction In recent years, there are growing interests in incorporating semantics into statistical machine translation (SMT) (Wu and Fung, 2009; Liu and Gildea, 2010; Gao and Vogel, 2011; Baker et al., 2012). Among all existing semantic representations, semantic role labeling (SRL) aims at automatically analyzing predicate-argument stru"
C12-1053,W02-1001,0,0.059381,"ition of semantic chunks is described below. • Constituent outside an argument receive the tag O. • For a sequence of constituents forming a semantic role of Ax, the first constituent receives the semantic chunk label B(egin)-Ax, • and the remaining ones receive the label I(nside)-Ax. Developing features has been shown crucial to advancing the state-of-the-art in SRL. To achieve good Chinese SRL results, we utilize rich syntactic features introduced in (Sun, 2010). For sequential tagging, we use a first order linear-chain global linear model and estimate parameters with structured preceptron (Collins, 2002). Our semantic chunking method can tolerate two types of parsing errors that are shown in Figure 3. Assume tree structures (1 and 4) on the left hand side are the correct syntactic analysis, while tree structures (2, 3, 5 and 6) on the right hand side are some wrong analysis. Though a constituent classification system, the arguments Ax and A y can not be recovered since there is no node to express them. In our constituent chunking system, however, when these errors occur, the arguments can still be found, if XP1 is assigned a label B-Ax or B-A y and XP2 is assigned a label I-Ax or I-A y. 1 C-c"
C12-1053,W11-1012,0,0.104881,"se-English tasks show that our model improves the baseline system by 0.93 BLEU 0.98 TER on average. We also compare our method with a syntax-augmented model (Cherry, 2008), and demonstrate the importance of predicate-argument semantics in machine translation. KEYWORDS: statistical machine translation, semantic role labeling. Proceedings of COLING 2012: Technical Papers, pages 867–878, COLING 2012, Mumbai, December 2012. 867 1 Introduction In recent years, there are growing interests in incorporating semantics into statistical machine translation (SMT) (Wu and Fung, 2009; Liu and Gildea, 2010; Gao and Vogel, 2011; Baker et al., 2012). Among all existing semantic representations, semantic role labeling (SRL) aims at automatically analyzing predicate-argument structures and can capture essential meaning of sentences. Since the seminal work of (Gildea and Jurafsky, 2002), quite a few researchers concentrate on resolving SRL with different machine learning methods. Nowadays, good SRL systems can be built based on accurate syntactic parsers for English, as well as many other languages. In this paper, we explore predicate-argument analysis of source sentences to improve phrasebased SMT systems. On one hand,"
C12-1053,J02-3001,0,0.0536937,"ation. KEYWORDS: statistical machine translation, semantic role labeling. Proceedings of COLING 2012: Technical Papers, pages 867–878, COLING 2012, Mumbai, December 2012. 867 1 Introduction In recent years, there are growing interests in incorporating semantics into statistical machine translation (SMT) (Wu and Fung, 2009; Liu and Gildea, 2010; Gao and Vogel, 2011; Baker et al., 2012). Among all existing semantic representations, semantic role labeling (SRL) aims at automatically analyzing predicate-argument structures and can capture essential meaning of sentences. Since the seminal work of (Gildea and Jurafsky, 2002), quite a few researchers concentrate on resolving SRL with different machine learning methods. Nowadays, good SRL systems can be built based on accurate syntactic parsers for English, as well as many other languages. In this paper, we explore predicate-argument analysis of source sentences to improve phrasebased SMT systems. On one hand, the predicate-argument event layer of SRL captures global dependencies which is crucial for the MT output quality. On the other hand, the semantic role information contained in SRL also provide a good clue to the appropriateness of a phrase segment chosen by"
C12-1053,N03-1017,0,0.053277,"irectly using a log-linear combination of several models (Och and Ney, 2002): P  M exp λm hm (e1I , f1J ) P r(e1I |f1J ) = m=1 P 0 I ,e exp P M m=1 0 0I 1  0 0I λm hm (e 1 , f1J ) (2) The denominator is to make the P r(e1I |f1J ) to be a probability distribution and it depends only on the source sentence f1J . For search, the decision rule is simply: ˆeiI = arg max ˆ M nX m=1 o λm hm (e1I , f1J ) (3) The model scaling factors λ1M are trained with Minimum Error Rate Training (MERT). In this paper, the phrase-based machine translation system is utilized (Och et al., 1999; Zens et al., 2002; Koehn et al., 2003). The translation process consists in segmentation of the source sentence according to the phrase table which is built from the word alignment. The translation of each of these segments is then just extracting the target side from the phrase pair. With the corresponding target side, the final translation is the composition of these translated segments. In this last step, reordering is allowed. 2.2 Semantic Role Labeling In the last decade, there has been an increasing interest in SRL on several languages, which consists of recognizing arguments involved by predicates in a given sentence and la"
C12-1053,P03-1056,0,0.019061,"model does not have hard limit. We list the important information regarding the experimental setup below. All those conditions have been kept same in this work. • lowercased training data (Table 1) from GALE task alignment trained with GIZA++ • tuning corpus: NIST06 test corpora: NIST02 03 04 05 and 08 • 5-gram LM (1 694 412 027 running words) trained by SRILM toolkit (Stolcke, 2002) with modified Kneser-Ney smoothing LM training data: target side of bilingual data. • BLEU (Papineni et al., 2001) and TER (Snover et al., 2005) reported all scores calculated in lowercase way. • Stanford Parser (Levy and Manning, 2003) used to get the Chinese constituent tree for the SRL and the dependency tree for the syntactic cohesion model Chinese Sentences Running Words Vocabulary English 5 384 856 115 172 748 129 820 318 1 125 437 739 251 Table 1: training data statistics 4.2 A Full Parsing Based Chinese SRL System 4.2.1 Background SRL methods that are successful on English are adopted to resolve Chinese SRL (Xue, 2008; Sun, 2010). Previous work indicates that syntactic information is very important for SRL and full parsing based approaches are considerably better than shallow parsing based ones. Based on a phrase-str"
C12-1053,C10-1081,0,0.133761,"IST05 and NIST08 Chinese-English tasks show that our model improves the baseline system by 0.93 BLEU 0.98 TER on average. We also compare our method with a syntax-augmented model (Cherry, 2008), and demonstrate the importance of predicate-argument semantics in machine translation. KEYWORDS: statistical machine translation, semantic role labeling. Proceedings of COLING 2012: Technical Papers, pages 867–878, COLING 2012, Mumbai, December 2012. 867 1 Introduction In recent years, there are growing interests in incorporating semantics into statistical machine translation (SMT) (Wu and Fung, 2009; Liu and Gildea, 2010; Gao and Vogel, 2011; Baker et al., 2012). Among all existing semantic representations, semantic role labeling (SRL) aims at automatically analyzing predicate-argument structures and can capture essential meaning of sentences. Since the seminal work of (Gildea and Jurafsky, 2002), quite a few researchers concentrate on resolving SRL with different machine learning methods. Nowadays, good SRL systems can be built based on accurate syntactic parsers for English, as well as many other languages. In this paper, we explore predicate-argument analysis of source sentences to improve phrasebased SMT"
C12-1053,P02-1038,1,0.614626,"Secondly, the SRL framework will be given. Thirdly, we demonstrate how the semantic role information can be used for translation. 2.1 Principle In statistical machine translation, we are given a source language sentence f1J = f1 . . . f j . . . f J . The objective is to translate the source into a target language sentence e1I = e1 . . . ei . . . e I . The strategy is among all possible target language sentences, we will choose the one with the highest probability: ˆeiI = arg max{P r(e1I |f1J )} ˆ I,e1I 868 (1) We model P r(e1I |f1J ) directly using a log-linear combination of several models (Och and Ney, 2002): P  M exp λm hm (e1I , f1J ) P r(e1I |f1J ) = m=1 P 0 I ,e exp P M m=1 0 0I 1  0 0I λm hm (e 1 , f1J ) (2) The denominator is to make the P r(e1I |f1J ) to be a probability distribution and it depends only on the source sentence f1J . For search, the decision rule is simply: ˆeiI = arg max ˆ M nX m=1 o λm hm (e1I , f1J ) (3) The model scaling factors λ1M are trained with Minimum Error Rate Training (MERT). In this paper, the phrase-based machine translation system is utilized (Och et al., 1999; Zens et al., 2002; Koehn et al., 2003). The translation process consists in segmentation of the"
C12-1053,W99-0604,1,0.565703,"e1I 868 (1) We model P r(e1I |f1J ) directly using a log-linear combination of several models (Och and Ney, 2002): P  M exp λm hm (e1I , f1J ) P r(e1I |f1J ) = m=1 P 0 I ,e exp P M m=1 0 0I 1  0 0I λm hm (e 1 , f1J ) (2) The denominator is to make the P r(e1I |f1J ) to be a probability distribution and it depends only on the source sentence f1J . For search, the decision rule is simply: ˆeiI = arg max ˆ M nX m=1 o λm hm (e1I , f1J ) (3) The model scaling factors λ1M are trained with Minimum Error Rate Training (MERT). In this paper, the phrase-based machine translation system is utilized (Och et al., 1999; Zens et al., 2002; Koehn et al., 2003). The translation process consists in segmentation of the source sentence according to the phrase table which is built from the word alignment. The translation of each of these segments is then just extracting the target side from the phrase pair. With the corresponding target side, the final translation is the composition of these translated segments. In this last step, reordering is allowed. 2.2 Semantic Role Labeling In the last decade, there has been an increasing interest in SRL on several languages, which consists of recognizing arguments involved"
C12-1053,2001.mtsummit-papers.68,0,0.0299556,"penalty. The reordering model for the baseline system is the distance-based jump model which uses linear distance. This model does not have hard limit. We list the important information regarding the experimental setup below. All those conditions have been kept same in this work. • lowercased training data (Table 1) from GALE task alignment trained with GIZA++ • tuning corpus: NIST06 test corpora: NIST02 03 04 05 and 08 • 5-gram LM (1 694 412 027 running words) trained by SRILM toolkit (Stolcke, 2002) with modified Kneser-Ney smoothing LM training data: target side of bilingual data. • BLEU (Papineni et al., 2001) and TER (Snover et al., 2005) reported all scores calculated in lowercase way. • Stanford Parser (Levy and Manning, 2003) used to get the Chinese constituent tree for the SRL and the dependency tree for the syntactic cohesion model Chinese Sentences Running Words Vocabulary English 5 384 856 115 172 748 129 820 318 1 125 437 739 251 Table 1: training data statistics 4.2 A Full Parsing Based Chinese SRL System 4.2.1 Background SRL methods that are successful on English are adopted to resolve Chinese SRL (Xue, 2008; Sun, 2010). Previous work indicates that syntactic information is very importan"
C12-1053,W95-0107,0,0.00786778,"can tolerate some syntactic parsing errors. First, our system collects all c-commanders1 and puts them in order. Because c-commanders of a predicate are not overlapped with each other and compose the whole sentence, we can take this step as a sequentialization procedure. Sun et al. (2008) present a theoretical analysis about argument positions and suggest that an argument should c-command a predicate. Therefore, our sequentialization precedure keeps most semantic roles. On basis of sequentialized constituents, we define semantic chunks which do not overlap nor embed using IOB2 representation (Ramshaw and Marcus, 1995) and transfer the SRL problem as a constituent tagging problem. Our definition of semantic chunks is described below. • Constituent outside an argument receive the tag O. • For a sequence of constituents forming a semantic role of Ax, the first constituent receives the semantic chunk label B(egin)-Ax, • and the remaining ones receive the label I(nside)-Ax. Developing features has been shown crucial to advancing the state-of-the-art in SRL. To achieve good Chinese SRL results, we utilize rich syntactic features introduced in (Sun, 2010). For sequential tagging, we use a first order linear-chain"
C12-1053,P10-2031,1,0.934056,"LM training data: target side of bilingual data. • BLEU (Papineni et al., 2001) and TER (Snover et al., 2005) reported all scores calculated in lowercase way. • Stanford Parser (Levy and Manning, 2003) used to get the Chinese constituent tree for the SRL and the dependency tree for the syntactic cohesion model Chinese Sentences Running Words Vocabulary English 5 384 856 115 172 748 129 820 318 1 125 437 739 251 Table 1: training data statistics 4.2 A Full Parsing Based Chinese SRL System 4.2.1 Background SRL methods that are successful on English are adopted to resolve Chinese SRL (Xue, 2008; Sun, 2010). Previous work indicates that syntactic information is very important for SRL and full parsing based approaches are considerably better than shallow parsing based ones. Based on a phrase-structure parsing, SRL is usually formulated as a constituent classification problem. In particular, SRL is divided into three sub-tasks: 1) pruning with a heuristic rule, 2) argument identification (AI) to recognize arguments, and 3) semantic role classification (SRC) to predict semantic types. To efficiently excluded non-arguments, a pruning procedure is executed to filter out constituents that are highly u"
C12-1053,C08-1105,1,0.856819,"ll parsing based constituent chunking. span with an argument in the manual annotation, the system cannot possibly get a correct prediction. In other words, the best the system can do is to correctly label all arguments that have a counterpart node in the parse tree. In this paper, we implement a semantic chunking method which can tolerate some syntactic parsing errors. First, our system collects all c-commanders1 and puts them in order. Because c-commanders of a predicate are not overlapped with each other and compose the whole sentence, we can take this step as a sequentialization procedure. Sun et al. (2008) present a theoretical analysis about argument positions and suggest that an argument should c-command a predicate. Therefore, our sequentialization precedure keeps most semantic roles. On basis of sequentialized constituents, we define semantic chunks which do not overlap nor embed using IOB2 representation (Ramshaw and Marcus, 1995) and transfer the SRL problem as a constituent tagging problem. Our definition of semantic chunks is described below. • Constituent outside an argument receive the tag O. • For a sequence of constituents forming a semantic role of Ax, the first constituent receive"
C12-1053,N09-2004,0,0.154278,", NIST03, NIST04, NIST05 and NIST08 Chinese-English tasks show that our model improves the baseline system by 0.93 BLEU 0.98 TER on average. We also compare our method with a syntax-augmented model (Cherry, 2008), and demonstrate the importance of predicate-argument semantics in machine translation. KEYWORDS: statistical machine translation, semantic role labeling. Proceedings of COLING 2012: Technical Papers, pages 867–878, COLING 2012, Mumbai, December 2012. 867 1 Introduction In recent years, there are growing interests in incorporating semantics into statistical machine translation (SMT) (Wu and Fung, 2009; Liu and Gildea, 2010; Gao and Vogel, 2011; Baker et al., 2012). Among all existing semantic representations, semantic role labeling (SRL) aims at automatically analyzing predicate-argument structures and can capture essential meaning of sentences. Since the seminal work of (Gildea and Jurafsky, 2002), quite a few researchers concentrate on resolving SRL with different machine learning methods. Nowadays, good SRL systems can be built based on accurate syntactic parsers for English, as well as many other languages. In this paper, we explore predicate-argument analysis of source sentences to im"
C12-1053,J08-2004,0,0.0386738,"smoothing LM training data: target side of bilingual data. • BLEU (Papineni et al., 2001) and TER (Snover et al., 2005) reported all scores calculated in lowercase way. • Stanford Parser (Levy and Manning, 2003) used to get the Chinese constituent tree for the SRL and the dependency tree for the syntactic cohesion model Chinese Sentences Running Words Vocabulary English 5 384 856 115 172 748 129 820 318 1 125 437 739 251 Table 1: training data statistics 4.2 A Full Parsing Based Chinese SRL System 4.2.1 Background SRL methods that are successful on English are adopted to resolve Chinese SRL (Xue, 2008; Sun, 2010). Previous work indicates that syntactic information is very important for SRL and full parsing based approaches are considerably better than shallow parsing based ones. Based on a phrase-structure parsing, SRL is usually formulated as a constituent classification problem. In particular, SRL is divided into three sub-tasks: 1) pruning with a heuristic rule, 2) argument identification (AI) to recognize arguments, and 3) semantic role classification (SRC) to predict semantic types. To efficiently excluded non-arguments, a pruning procedure is executed to filter out constituents that"
C12-1053,2002.tmi-tutorials.2,0,0.0769249,"el P r(e1I |f1J ) directly using a log-linear combination of several models (Och and Ney, 2002): P  M exp λm hm (e1I , f1J ) P r(e1I |f1J ) = m=1 P 0 I ,e exp P M m=1 0 0I 1  0 0I λm hm (e 1 , f1J ) (2) The denominator is to make the P r(e1I |f1J ) to be a probability distribution and it depends only on the source sentence f1J . For search, the decision rule is simply: ˆeiI = arg max ˆ M nX m=1 o λm hm (e1I , f1J ) (3) The model scaling factors λ1M are trained with Minimum Error Rate Training (MERT). In this paper, the phrase-based machine translation system is utilized (Och et al., 1999; Zens et al., 2002; Koehn et al., 2003). The translation process consists in segmentation of the source sentence according to the phrase table which is built from the word alignment. The translation of each of these segments is then just extracting the target side from the phrase pair. With the corresponding target side, the final translation is the composition of these translated segments. In this last step, reordering is allowed. 2.2 Semantic Role Labeling In the last decade, there has been an increasing interest in SRL on several languages, which consists of recognizing arguments involved by predicates in a"
C12-1053,P02-1040,0,\N,Missing
C12-2091,N10-1033,0,\N,Missing
C12-2091,D12-1041,0,\N,Missing
C12-2091,E03-1076,0,\N,Missing
C12-2091,C08-1064,0,\N,Missing
C12-2091,P02-1040,0,\N,Missing
C12-2091,W10-1738,1,\N,Missing
C12-2091,P10-1049,1,\N,Missing
C12-2091,W06-3123,0,\N,Missing
C12-2091,2006.amta-papers.2,0,\N,Missing
C12-2091,D12-1089,0,\N,Missing
C12-2091,C10-2021,0,\N,Missing
C12-2091,W06-3105,0,\N,Missing
C12-2091,P05-1033,0,\N,Missing
C12-2091,J03-1002,1,\N,Missing
C12-2091,2009.iwslt-papers.2,0,\N,Missing
C12-2091,P07-1019,0,\N,Missing
C12-2091,2010.iwslt-papers.11,1,\N,Missing
C12-2091,D08-1076,0,\N,Missing
C12-2091,P08-1024,0,\N,Missing
C12-3061,J99-4005,0,\N,Missing
C12-3061,N10-1140,0,\N,Missing
C12-3061,D09-1022,1,\N,Missing
C12-3061,C04-1030,1,\N,Missing
C12-3061,W10-1738,1,\N,Missing
C12-3061,D08-1024,0,\N,Missing
C12-3061,P12-3004,0,\N,Missing
C12-3061,N09-1027,0,\N,Missing
C12-3061,P10-1049,1,\N,Missing
C12-3061,P07-2045,0,\N,Missing
C12-3061,N09-1025,0,\N,Missing
C12-3061,J06-4004,0,\N,Missing
C12-3061,N03-1017,0,\N,Missing
C12-3061,P02-1038,1,\N,Missing
C12-3061,2008.iwslt-papers.8,1,\N,Missing
C12-3061,P10-4002,0,\N,Missing
C12-3061,2008.iwslt-papers.7,1,\N,Missing
C12-3061,P07-1019,0,\N,Missing
C12-3061,P12-2006,1,\N,Missing
C12-3061,W06-3119,0,\N,Missing
C12-3061,2010.iwslt-papers.18,1,\N,Missing
C12-3061,2011.iwslt-papers.8,1,\N,Missing
C12-3061,J07-2003,0,\N,Missing
C12-3061,N10-2003,0,\N,Missing
C12-3061,D07-1080,0,\N,Missing
C12-3061,2009.eamt-1.33,1,\N,Missing
C12-3061,P03-1021,0,\N,Missing
C12-3061,2012.eamt-1.66,1,\N,Missing
C96-2141,1993.mtsummit-1.11,0,\N,Missing
C96-2141,J93-2003,0,\N,Missing
C96-2141,C94-2178,0,\N,Missing
D07-1055,W05-0909,0,0.0366622,"ation of the Bleu score as some of the training criteria are motivated by this. The Bleu score is a combination of the geometric mean of n-gram precisions and a brevity penalty for too short translation hypotheses. The Bleu score for a translation hypothˆ esis eI1 and a reference translation eˆI1 is computed as: Evaluation Metrics The automatic evaluation of machine translation is currently an active research area. There exists a variety of different metrics, e.g., word error rate, position-independent word error rate, BLEU score (Papineni et al., 2002), NIST score (Doddington, 2002), METEOR (Banerjee and Lavie, 2005), GTM (Turian et al., 2003). Each of them has advantages and shortcomings. A popular metric for evaluating machine translation quality is the Bleu score (Papineni et al., 2002). It has certain shortcomings for comparing different machine translation systems, especially if comparing conceptually different systems, e.g. phrase-based versus rule-based systems, as shown in (Callison-Burch et al., 2006). On the other hand, Callison-Burch concluded that the Bleu score is reliable for comparing variants of the same machine translation system. As this is exactly what we will need in our experiments an"
D07-1055,J90-2002,0,0.168761,"Hence, the MAP decision rule is optimal for the sentence or string error rate. It is not necessarily optimal for other evaluation metrics such as the Bleu score. One reason for the popularity of the MAP decision rule might be that, compared to the MBR rule, its computation is simpler. The posterior probability P r(eI1 |f1J ) is modeled directly using a log-linear combination of several models (Och and Ney, 2002): P  M I, fJ) exp λ h (e m m 1 1 m=1 P  pλM (eI1 |f1J ) = P 1 M 0I0 , f J ) exp λ h (e 1 1 m=1 m m I 0 ,e0 I1 0 (1) This approach is a generalization of the sourcechannel approach (Brown et al., 1990). It has the advantage that additional models h(·) can be easily integrated into the overall system. The denominator represents a normalization factor that depends only on the source sentence f1J . Therefore, we can omit it in case of the MAP decision rule during the search process and obtain: 0 ( 0 Here, L(eI1 , e0 I1 ) denotes the loss function under consideration. It measures the loss (or errors) of a candidate translation eI1 assuming the correct trans0 lation is e0 I1 . In the following, we will call this decision rule the MBR rule (Kumar and Byrne, 2004). This decision rule is optimal in"
D07-1055,E06-1032,0,0.00743824,"ctive research area. There exists a variety of different metrics, e.g., word error rate, position-independent word error rate, BLEU score (Papineni et al., 2002), NIST score (Doddington, 2002), METEOR (Banerjee and Lavie, 2005), GTM (Turian et al., 2003). Each of them has advantages and shortcomings. A popular metric for evaluating machine translation quality is the Bleu score (Papineni et al., 2002). It has certain shortcomings for comparing different machine translation systems, especially if comparing conceptually different systems, e.g. phrase-based versus rule-based systems, as shown in (Callison-Burch et al., 2006). On the other hand, Callison-Burch concluded that the Bleu score is reliable for comparing variants of the same machine translation system. As this is exactly what we will need in our experiments and as Bleu is currently the most popular metric, we have chosen it as our primary evaluation metric. Nevertheless, most of the 526 ˆ = BP(I, I)  1 ˆ exp (1 − I/I) P ˆ Precn (eI1 , eˆI1 ) = w1n if I ≥ Iˆ if I &lt; Iˆ ˆ min{C(w1n |eI1 ), C(w1n |ˆ eI1 )} P w1n C(w1n |eI1 ) Here, C(w1n |eI1 ) denotes the number of occurrences of an n-gram w1n in a sentence eI1 . The denominators of the n-gram precisions e"
D07-1055,P07-2026,1,0.773732,"meters with respect to the final evaluation criterion; this is the so-called minimum error rate training (Och, 2003). Minimum Bayes risk decoding for machine trans524 Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational c Natural Language Learning, pp. 524–532, Prague, June 2007. 2007 Association for Computational Linguistics lation was introduced in (Kumar and Byrne, 2004). It was shown that MBR outperforms MAP decoding for different evaluation criteria. Further experiments using MBR for Bleu were performed in (Venugopal et al., 2005; Ehling et al., 2007). Here, we will present additional evidence that MBR decoding is preferable over MAP decoding. Tillmann and Zhang (2006) describe a perceptron style algorithm for training millions of features. Here, we focus on the comparison of different training criteria. Shen et al. (2004) compared different algorithms for tuning the log-linear weights in a reranking framework and achieved results comparable to the standard minimum error rate training. An annealed minimum risk approach is presented in (Smith and Eisner, 2006) which outperforms both maximum likelihood and minimum error rate training. The pa"
D07-1055,koen-2004-pharaoh,0,0.0375308,"rule is optimal in the sense that any other decision rule will result (on average) in at least as many errors as the MBR rule. Despite this, most SMT systems do not use the MBR decision rule. The most common approach is to use the maximum aposteriori (MAP) decision rule. Thus, we select the hypothesis which maximizes the posterior probability P r(eI1 |f1J ): 525 ˆ eˆI1 = argmax I,eI1 M X ) λm hm (eI1 , f1J ) m=1 Note that the denominator affects the results of the MBR decision rule and, thus, cannot be omitted in that case. We use a state-of-the-art phrase-based translation system similar to (Koehn, 2004; Mauser et al., 2006) including the following models: an n-gram language model, a phrase translation model and a wordbased lexicon model. The latter two models are used for both directions: p(f |e) and p(e|f ). Additionally, we use a word penalty, phrase penalty and a distortion penalty. In the following, we will discuss the so-called training problem (Ney, 2001): how do we train the free parameters λM 1 of the model? The current state-of-the-art is to use minimum error rate training (MERT) as described in (Och, 2003). The free parameters are tuned to directly optimize the evaluation criterio"
D07-1055,N04-1022,0,0.613871,"focus is on the training problem. We will compare a variety of training criteria for statistical machine translation. In particular, we are considering criteria for the log-linear parameters or model scaling factors. We will introduce new training criteria based on maximum likelihood estimation and expected loss computation. We will show that some achieve significantly better results than the standard minimum error rate training of (Och, 2003). Additionally, we will compare two decision rules, the common maximum a-posteriori (MAP) decision rule and the minimum Bayes risk (MBR) decision rule (Kumar and Byrne, 2004). We will show that the minimum Bayes risk decision rule results in better translation quality than the maximum aposteriori decision rule for several training criteria. The remaining part of this paper is structured as follows: first, we will describe related work in Sec. 2. Then, we will briefly review the baseline system, Bayes decision rule for statistical machine translation and automatic evaluation metrics for machine translation in Sec. 3 and Sec. 4, respectively. The novel training criteria are described in Sec. 5 and Sec. 6. Experimental results are reported in Sec. 7 and conclusions a"
D07-1055,C04-1072,0,0.0616683,"n |ˆ eI1 )} P w1n C(w1n |eI1 ) Here, C(w1n |eI1 ) denotes the number of occurrences of an n-gram w1n in a sentence eI1 . The denominators of the n-gram precisions evaluate to the number of n-grams in the hypothesis, i.e. I − n + 1. The n-gram counts for the Bleu score computation are usually collected over a whole document. For our purposes, a sentence-level computation is preferable. A problem with the sentence-level Bleu score is that the score is zero if not at least one fourgram matches. As we would like to avoid this problem, we use the smoothed sentence-level Bleu score as suggested in (Lin and Och, 2004). Thus, we increase the nominator and denominator of Precn (·, ·) by one for n &gt; 1. Note that we will use the sentence-level Bleu score only during training. The evaluation on the development and test sets will be carried out using the standard Bleu score, i.e. at the corpus level. As the MERT baseline does not require the use of the sentence-level Bleu score, we use the standard Bleu score for training the baseline system. In the following, we will describe several criteria for training the log-linear parameters λM 1 of our model. For notational convenience, we assume that there is just one r"
D07-1055,2006.iwslt-evaluation.15,1,0.721706,"al in the sense that any other decision rule will result (on average) in at least as many errors as the MBR rule. Despite this, most SMT systems do not use the MBR decision rule. The most common approach is to use the maximum aposteriori (MAP) decision rule. Thus, we select the hypothesis which maximizes the posterior probability P r(eI1 |f1J ): 525 ˆ eˆI1 = argmax I,eI1 M X ) λm hm (eI1 , f1J ) m=1 Note that the denominator affects the results of the MBR decision rule and, thus, cannot be omitted in that case. We use a state-of-the-art phrase-based translation system similar to (Koehn, 2004; Mauser et al., 2006) including the following models: an n-gram language model, a phrase translation model and a wordbased lexicon model. The latter two models are used for both directions: p(f |e) and p(e|f ). Additionally, we use a word penalty, phrase penalty and a distortion penalty. In the following, we will discuss the so-called training problem (Ney, 2001): how do we train the free parameters λM 1 of the model? The current state-of-the-art is to use minimum error rate training (MERT) as described in (Och, 2003). The free parameters are tuned to directly optimize the evaluation criterion. Except for the MERT"
D07-1055,W01-1405,1,0.91741,"ents over a state-of-the-art minimum error rate training baseline on a large ChineseEnglish translation task. We present novel training criteria based on maximum likelihood estimation and expected loss computation. Additionally, we compare the maximum a-posteriori decision rule and the minimum Bayes risk decision rule. We show that, not only from a theoretical point of view but also in terms of translation quality, the minimum Bayes risk decision rule is preferable. 1 Introduction Once we specified the Bayes decision rule for statistical machine translation, we have to address three problems (Ney, 2001): • the search problem, i.e. how to find the best translation candidate among all possible target language sentences; • the modeling problem, i.e. how to structure the dependencies of source and target language sentences; • the training problem, i.e. how to estimate the free parameters of the models from the training data. Here, the main focus is on the training problem. We will compare a variety of training criteria for statistical machine translation. In particular, we are considering criteria for the log-linear parameters or model scaling factors. We will introduce new training criteria bas"
D07-1055,P02-1038,1,0.703222,"teria. The remaining part of this paper is structured as follows: first, we will describe related work in Sec. 2. Then, we will briefly review the baseline system, Bayes decision rule for statistical machine translation and automatic evaluation metrics for machine translation in Sec. 3 and Sec. 4, respectively. The novel training criteria are described in Sec. 5 and Sec. 6. Experimental results are reported in Sec. 7 and conclusions are given in Sec. 8. 2 Related Work The most common modeling approach in statistical machine translation is to use a log-linear combination of several sub-models (Och and Ney, 2002). In (Och and Ney, 2002), the log-linear weights were tuned to maximize the mutual information criterion (MMI). The current state-of-the-art is to optimize these parameters with respect to the final evaluation criterion; this is the so-called minimum error rate training (Och, 2003). Minimum Bayes risk decoding for machine trans524 Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational c Natural Language Learning, pp. 524–532, Prague, June 2007. 2007 Association for Computational Linguistics lation was introduced in (Kumar and Byrne, 2004)"
D07-1055,P03-1021,0,0.637155,"ies of source and target language sentences; • the training problem, i.e. how to estimate the free parameters of the models from the training data. Here, the main focus is on the training problem. We will compare a variety of training criteria for statistical machine translation. In particular, we are considering criteria for the log-linear parameters or model scaling factors. We will introduce new training criteria based on maximum likelihood estimation and expected loss computation. We will show that some achieve significantly better results than the standard minimum error rate training of (Och, 2003). Additionally, we will compare two decision rules, the common maximum a-posteriori (MAP) decision rule and the minimum Bayes risk (MBR) decision rule (Kumar and Byrne, 2004). We will show that the minimum Bayes risk decision rule results in better translation quality than the maximum aposteriori decision rule for several training criteria. The remaining part of this paper is structured as follows: first, we will describe related work in Sec. 2. Then, we will briefly review the baseline system, Bayes decision rule for statistical machine translation and automatic evaluation metrics for machine"
D07-1055,P02-1040,0,0.109912,"on metrics. In the following, we will briefly review the computation of the Bleu score as some of the training criteria are motivated by this. The Bleu score is a combination of the geometric mean of n-gram precisions and a brevity penalty for too short translation hypotheses. The Bleu score for a translation hypothˆ esis eI1 and a reference translation eˆI1 is computed as: Evaluation Metrics The automatic evaluation of machine translation is currently an active research area. There exists a variety of different metrics, e.g., word error rate, position-independent word error rate, BLEU score (Papineni et al., 2002), NIST score (Doddington, 2002), METEOR (Banerjee and Lavie, 2005), GTM (Turian et al., 2003). Each of them has advantages and shortcomings. A popular metric for evaluating machine translation quality is the Bleu score (Papineni et al., 2002). It has certain shortcomings for comparing different machine translation systems, especially if comparing conceptually different systems, e.g. phrase-based versus rule-based systems, as shown in (Callison-Burch et al., 2006). On the other hand, Callison-Burch concluded that the Bleu score is reliable for comparing variants of the same machine translation"
D07-1055,N04-1023,0,0.0454727,"Natural Language Learning, pp. 524–532, Prague, June 2007. 2007 Association for Computational Linguistics lation was introduced in (Kumar and Byrne, 2004). It was shown that MBR outperforms MAP decoding for different evaluation criteria. Further experiments using MBR for Bleu were performed in (Venugopal et al., 2005; Ehling et al., 2007). Here, we will present additional evidence that MBR decoding is preferable over MAP decoding. Tillmann and Zhang (2006) describe a perceptron style algorithm for training millions of features. Here, we focus on the comparison of different training criteria. Shen et al. (2004) compared different algorithms for tuning the log-linear weights in a reranking framework and achieved results comparable to the standard minimum error rate training. An annealed minimum risk approach is presented in (Smith and Eisner, 2006) which outperforms both maximum likelihood and minimum error rate training. The parameters are estimated iteratively using an annealing technique that minimizes the risk of an expected-BLEU approximation, which is similar to the one presented in this paper. 3 Baseline System In statistical machine translation, we are given a source language sentence f1J = f"
D07-1055,P06-2101,0,0.397507,"a. Further experiments using MBR for Bleu were performed in (Venugopal et al., 2005; Ehling et al., 2007). Here, we will present additional evidence that MBR decoding is preferable over MAP decoding. Tillmann and Zhang (2006) describe a perceptron style algorithm for training millions of features. Here, we focus on the comparison of different training criteria. Shen et al. (2004) compared different algorithms for tuning the log-linear weights in a reranking framework and achieved results comparable to the standard minimum error rate training. An annealed minimum risk approach is presented in (Smith and Eisner, 2006) which outperforms both maximum likelihood and minimum error rate training. The parameters are estimated iteratively using an annealing technique that minimizes the risk of an expected-BLEU approximation, which is similar to the one presented in this paper. 3 Baseline System In statistical machine translation, we are given a source language sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language sentence eI1 = e1 . . . ei . . . eI . Statistical decision theory tells us that among all possible target language sentences, we should choose the sentence which minimize"
D07-1055,P06-1091,0,0.0247565,"). Minimum Bayes risk decoding for machine trans524 Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational c Natural Language Learning, pp. 524–532, Prague, June 2007. 2007 Association for Computational Linguistics lation was introduced in (Kumar and Byrne, 2004). It was shown that MBR outperforms MAP decoding for different evaluation criteria. Further experiments using MBR for Bleu were performed in (Venugopal et al., 2005; Ehling et al., 2007). Here, we will present additional evidence that MBR decoding is preferable over MAP decoding. Tillmann and Zhang (2006) describe a perceptron style algorithm for training millions of features. Here, we focus on the comparison of different training criteria. Shen et al. (2004) compared different algorithms for tuning the log-linear weights in a reranking framework and achieved results comparable to the standard minimum error rate training. An annealed minimum risk approach is presented in (Smith and Eisner, 2006) which outperforms both maximum likelihood and minimum error rate training. The parameters are estimated iteratively using an annealing technique that minimizes the risk of an expected-BLEU approximatio"
D07-1055,2003.mtsummit-papers.51,0,0.0386609,"of the training criteria are motivated by this. The Bleu score is a combination of the geometric mean of n-gram precisions and a brevity penalty for too short translation hypotheses. The Bleu score for a translation hypothˆ esis eI1 and a reference translation eˆI1 is computed as: Evaluation Metrics The automatic evaluation of machine translation is currently an active research area. There exists a variety of different metrics, e.g., word error rate, position-independent word error rate, BLEU score (Papineni et al., 2002), NIST score (Doddington, 2002), METEOR (Banerjee and Lavie, 2005), GTM (Turian et al., 2003). Each of them has advantages and shortcomings. A popular metric for evaluating machine translation quality is the Bleu score (Papineni et al., 2002). It has certain shortcomings for comparing different machine translation systems, especially if comparing conceptually different systems, e.g. phrase-based versus rule-based systems, as shown in (Callison-Burch et al., 2006). On the other hand, Callison-Burch concluded that the Bleu score is reliable for comparing variants of the same machine translation system. As this is exactly what we will need in our experiments and as Bleu is currently the"
D07-1055,W05-0836,0,0.0251486,"s to optimize these parameters with respect to the final evaluation criterion; this is the so-called minimum error rate training (Och, 2003). Minimum Bayes risk decoding for machine trans524 Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational c Natural Language Learning, pp. 524–532, Prague, June 2007. 2007 Association for Computational Linguistics lation was introduced in (Kumar and Byrne, 2004). It was shown that MBR outperforms MAP decoding for different evaluation criteria. Further experiments using MBR for Bleu were performed in (Venugopal et al., 2005; Ehling et al., 2007). Here, we will present additional evidence that MBR decoding is preferable over MAP decoding. Tillmann and Zhang (2006) describe a perceptron style algorithm for training millions of features. Here, we focus on the comparison of different training criteria. Shen et al. (2004) compared different algorithms for tuning the log-linear weights in a reranking framework and achieved results comparable to the standard minimum error rate training. An annealed minimum risk approach is presented in (Smith and Eisner, 2006) which outperforms both maximum likelihood and minimum error"
D07-1055,W06-3110,1,0.937433,"to the case of multiple references. (3) 5 5.1 Maximum Likelihood Sentence-Level Computation A popular approach for training parameters is maximum likelihood estimation (MLE). Here, the goal is to maximize the joint likelihood of the parameters and the training data. For log-linear models, this results in a nice optimization criterion which is convex and has a single optimum. It is equivalent to the maximum mutual information (MMI) criterion. We obtain the following training criterion: I J FM L−N (λM 1 , (e1 , f1 )) = Here, we use the n-gram posterior probability pλM (w1n |f1J ) as defined in (Zens and Ney, 2006). 1 The n-gram posterior distribution is smoothed using a uniform distribution over all possible n-grams. 1 As an alternative to the sentence-level MLE, we performed experiments with an n-gram level MLE. Here, we limit the order of the n-grams and assume conditional independence among the n-gram probabilities. We define the log-likelihood (LLH) of a target language sentence eI1 given a source language sentence f1J as: 527 1 1 1 I J I J FM L−S (λM 1 , (e1 , f1 )) = log pλM (e1 |f1 ) 5.2 N -gram Level Computation log pλM (w1n |f1J ) n=1 wn ∈eI pλM (w1n |f1J ) 1 A problem that we often face in pr"
D08-1039,D07-1007,0,0.166582,"Missing"
D08-1039,P07-1005,0,0.107311,"Missing"
D08-1039,W03-1003,0,0.0576906,"Missing"
D08-1039,J01-2004,0,0.0245636,"ithm, as will be shown later in more detail. 2 Related Work In the past, a significant number of methods has been presented that try to capture long-distance dependencies, i.e. use dependencies in the data that reach beyond the local context of n-grams or phrase pairs. In language modeling, monolingual trigger approaches have been presented (Rosenfeld, 1996; Tillmann and Ney, 1997) as well as syntactical methods that parse the input and model long-range dependencies on the syntactic level by conditioning on the predecessing words and their corresponding parent nodes (Chelba and Jelinek, 2000; Roark, 2001). The latter approach was shown to reduce perplexities and improve the WER in speech recognition systems. One drawback is that the parsing process might slow down the system significantly and the approach is complicated to be integrated directly in the search process. Thus, the effect is often shown offline in reranking experiments using n-best lists. One of the simplest models that can be seen in the context of lexical triggers is the IBM model 1 (Brown et al., 1993) which captures lexical dependencies between source and target words. It can be seen as a lexicon containing correspondents of t"
D08-1039,W97-1014,1,0.918763,"n for the scoring. The motivation behind this approach is to get nonlocal information outside the current context (i.e. the currently considered bilingual phrase pair) into the translation process. The triplets are trained via the EM algorithm, as will be shown later in more detail. 2 Related Work In the past, a significant number of methods has been presented that try to capture long-distance dependencies, i.e. use dependencies in the data that reach beyond the local context of n-grams or phrase pairs. In language modeling, monolingual trigger approaches have been presented (Rosenfeld, 1996; Tillmann and Ney, 1997) as well as syntactical methods that parse the input and model long-range dependencies on the syntactic level by conditioning on the predecessing words and their corresponding parent nodes (Chelba and Jelinek, 2000; Roark, 2001). The latter approach was shown to reduce perplexities and improve the WER in speech recognition systems. One drawback is that the parsing process might slow down the system significantly and the approach is complicated to be integrated directly in the search process. Thus, the effect is often shown offline in reranking experiments using n-best lists. One of the simples"
D08-1039,hasan-ney-2008-multi,1,\N,Missing
D08-1039,koen-2004-pharaoh,0,\N,Missing
D08-1039,mauser-etal-2008-automatic,1,\N,Missing
D08-1039,W99-0604,1,\N,Missing
D08-1039,J99-2004,0,\N,Missing
D08-1039,W04-3245,0,\N,Missing
D08-1039,1993.tmi-1.17,0,\N,Missing
D08-1039,A83-1029,0,\N,Missing
D08-1039,W06-1626,0,\N,Missing
D08-1039,D09-1022,1,\N,Missing
D08-1039,C04-1030,1,\N,Missing
D08-1039,J93-2003,0,\N,Missing
D08-1039,W02-1021,1,\N,Missing
D08-1039,E03-1032,1,\N,Missing
D08-1039,C96-2141,1,\N,Missing
D08-1039,W00-0507,0,\N,Missing
D08-1039,C96-1067,0,\N,Missing
D08-1039,J96-1002,0,\N,Missing
D08-1039,W00-0726,0,\N,Missing
D08-1039,J09-4009,0,\N,Missing
D08-1039,P05-1071,0,\N,Missing
D08-1039,P02-1040,0,\N,Missing
D08-1039,P04-3001,0,\N,Missing
D08-1039,H05-1097,0,\N,Missing
D08-1039,2008.iwslt-papers.6,0,\N,Missing
D08-1039,P01-1027,1,\N,Missing
D08-1039,W06-3110,1,\N,Missing
D08-1039,W09-0401,0,\N,Missing
D08-1039,N09-2005,1,\N,Missing
D08-1039,N07-1062,1,\N,Missing
D08-1039,D09-1008,0,\N,Missing
D08-1039,P07-2045,0,\N,Missing
D08-1039,W09-0438,1,\N,Missing
D08-1039,N09-1025,0,\N,Missing
D08-1039,W05-0834,1,\N,Missing
D08-1039,P07-1020,0,\N,Missing
D08-1039,N03-1017,0,\N,Missing
D08-1039,P02-1038,1,\N,Missing
D08-1039,2008.iwslt-papers.8,1,\N,Missing
D08-1039,2008.iwslt-papers.7,1,\N,Missing
D08-1039,J03-1002,1,\N,Missing
D08-1039,P04-1007,0,\N,Missing
D08-1039,H05-1096,1,\N,Missing
D08-1039,P07-1019,0,\N,Missing
D08-1039,2005.eamt-1.17,1,\N,Missing
D08-1039,W06-3103,1,\N,Missing
D08-1039,J03-1005,1,\N,Missing
D08-1039,2005.eamt-1.6,1,\N,Missing
D08-1039,2005.mtsummit-papers.11,0,\N,Missing
D08-1039,takezawa-etal-2002-toward,0,\N,Missing
D08-1039,2005.iwslt-1.20,1,\N,Missing
D08-1039,N04-1021,0,\N,Missing
D08-1039,2004.iwslt-evaluation.13,1,\N,Missing
D08-1039,N04-1033,1,\N,Missing
D08-1039,J07-2003,0,\N,Missing
D08-1039,hasan-etal-2006-creating,1,\N,Missing
D08-1039,W06-2606,1,\N,Missing
D08-1039,2007.mtsummit-papers.31,0,\N,Missing
D08-1039,2006.iwslt-evaluation.15,1,\N,Missing
D08-1039,carpuat-wu-2008-evaluation,0,\N,Missing
D08-1039,D07-1055,1,\N,Missing
D08-1039,P03-1021,0,\N,Missing
D08-1088,P08-2007,0,0.0303576,"rror rate (PER) on a slightly augmented variant of CNs which allows for edges to carry multiple symbols. The concatenation of symbols corresponds to the interdependency of decisions in the case of bigram matches above. NP-hard problems are quite common in machine 839 Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 839–847, c Honolulu, October 2008. 2008 Association for Computational Linguistics translation; for example, Knight (1999) has shown that even for a simple form of statistical MT models, the decoding problem is NP-complete. More recently, DeNero and Klein (2008) have proven the NP-completeness of the phrase alignment problem. But even a simple, common procedure as BLEU scoring, which can be performed in linear time on single sentences, becomes a potentially intractable problem as soon as it has to be performed on a slightly more powerful representation, such as confusion networks. This rather surprising result is the motivation of this paper. The problem of finding the best unigram BLEU score in an unaugmented variant of CNs is not NPcomplete, as we show in Section 4. We present an algorithm that finds such a unigram BLEU-best path in polynomial time"
D08-1088,W07-0414,0,0.182865,"rsity, Germany {leusch,matusov,ney}@cs.rwth-aachen.de Abstract (2002), current research in MT uses more sophisticated measures, like the BLEU score (Papineni et al., 2001). Zens and Ney (2005) first described this task on general word graphs, and sketched a complete algorithm for calculating the maximum BLEU score in a word graph. While they do not give an estimate on the complexity of their algorithm, they note that already a simpler algorithm for calculating the Position independent Error Rate (PER) has an exponential worst-case complexity. The same can be expected for their BLEU algorithm. Dreyer et al (2007) examined a special class of word graphs, namely those that denote constrained reorderings of single sentences. These word graphs have some properties which simplify the calculation; for example, no edge is labeled with the empty word, and all paths have the same length and end in the same node. Even then, their decoder does not optimize the true BLEU score, but an approximate version which uses a language-model-like unmodified precision. We give a very short introduction to CNs and the BLEU score in Section 2. Confusion networks are a simple representation of multiple speech recognition or tr"
D08-1088,N07-2017,1,0.79118,"Missing"
D08-1088,J99-4005,0,0.050177,"h itself can influence the decisions after that. We also show that this also holds for unigram BLEU and the position independent error rate (PER) on a slightly augmented variant of CNs which allows for edges to carry multiple symbols. The concatenation of symbols corresponds to the interdependency of decisions in the case of bigram matches above. NP-hard problems are quite common in machine 839 Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 839–847, c Honolulu, October 2008. 2008 Association for Computational Linguistics translation; for example, Knight (1999) has shown that even for a simple form of statistical MT models, the decoding problem is NP-complete. More recently, DeNero and Klein (2008) have proven the NP-completeness of the phrase alignment problem. But even a simple, common procedure as BLEU scoring, which can be performed in linear time on single sentences, becomes a potentially intractable problem as soon as it has to be performed on a slightly more powerful representation, such as confusion networks. This rather surprising result is the motivation of this paper. The problem of finding the best unigram BLEU score in an unaugmented va"
D08-1088,C04-1072,0,0.202386,"path hypotheses with the same number of empty edges, and ending in the same position in the confusion network. This idea is illustrated in Figure 6: We compare only the partial precision of path hypotheses ending in the same node. Due to the simple nature of this search graph, it can easily be traversed in a left-to-right, top-to-bottom manner. With regard to a node currently being expanded, only the next node in the same row, and the corresponding columns in the next row need to be kept active. When implementing this algorithm, Hypotheses should be compared on the modified BLEUS precision by Lin and Och (2004) because the original BLEU precision equals zero as long as there are no higher n-gram matches in the partial hypotheses, which renders meaningful comparison hard or impossible. In the rightmost column, all path hypotheses within a node have the same hypothesis length. Consequently, we can select the hypothesis with the best (brevity-penalized) BLEU score by multiplying the appropriate brevity penalty to the precision of the best path ending in each of these nodes. If we always expand all possible path hypotheses within the nodes, and basically run a full search, we will always find the BLEU-b"
D08-1088,E06-1005,1,0.855334,"how that even small generalizations of this data structure render the problem to be NP-hard again. Since finding the optimal solution is thus not always feasible, we introduce an approximating algorithm based on a multi-stack decoder, which finds a (not necessarily optimal) solution for n-gram BLEU in polynomial time. 1 Introduction In machine translation (MT), confusion networks (CNs) are commonly used to represent alternative versions of sentences. Typical applications include translation of different speech recognition hypotheses (Bertoldi et al., 2007) or system combination (Fiscus, 1997; Matusov et al., 2006). A typical operation on a given CN is to find the path which minimizes or maximizes a certain evaluation metric. This operation can be used in applications like Minimum Error Rate Training (Och, 2003), or optimizing system combination as described by Hillard et al. (2007). Whereas this is easily achievable for simple metrics like the Word Error Rate (WER) as described by Mohri and Riley In Section 3 we show that finding the best BLEU score is an NP-hard problem, even for a simplified variant of BLEU which only scores unigrams and bigrams. The main reason for this problem to become NP-hard is"
D08-1088,P03-1021,0,0.0891499,"a multi-stack decoder, which finds a (not necessarily optimal) solution for n-gram BLEU in polynomial time. 1 Introduction In machine translation (MT), confusion networks (CNs) are commonly used to represent alternative versions of sentences. Typical applications include translation of different speech recognition hypotheses (Bertoldi et al., 2007) or system combination (Fiscus, 1997; Matusov et al., 2006). A typical operation on a given CN is to find the path which minimizes or maximizes a certain evaluation metric. This operation can be used in applications like Minimum Error Rate Training (Och, 2003), or optimizing system combination as described by Hillard et al. (2007). Whereas this is easily achievable for simple metrics like the Word Error Rate (WER) as described by Mohri and Riley In Section 3 we show that finding the best BLEU score is an NP-hard problem, even for a simplified variant of BLEU which only scores unigrams and bigrams. The main reason for this problem to become NP-hard is that by looking at bigrams, we allow for one decision to also influence the following decision, which itself can influence the decisions after that. We also show that this also holds for unigram BLEU a"
D08-1088,2001.mtsummit-papers.68,0,0.0364375,"th from the start node to the end node visits each node of the graph in canonical order. Usually, we represent unlabeled edges by labeling them with the empty word ε. Within this paper, we represent a CN by a list of lists of words {wi,j }, where each wi,j corresponds to a symbol on an edge between nodes i and i + 1. A path in this CN can be written as a string of integers, an1 = a1 , . . . , an , such that the path is labeled w1,a1 w2,a2 . . . wn,an . Note that there can be a different number of possible words, j, for different positions i. 2.1 BLEU and variants The BLEU score, as defined by Papineni et al. (2001), is the modified n-gram precision of a hy840 pothesis, with 1 ≤ n ≤ N , given a set of reference translations R. “Modified precision” here means that for each n-gram, its maximum number of occurrences within the reference sentences is counted, and only up to that many occurrences in the hypothesis are considered to be correct. The geometric mean over the precisions for all n is calculated, and multiplied by a brevity penalty bp. This brevity penalty is 1.0 if the hypothesis sentence is at least as long as the reference sentence (special cases occur if multiple reference sentences with differe"
D08-1088,W05-0834,1,0.932221,"– in many cases, having a good, but not necessarily optimum path is preferable to having no good path at all. A simple approach would be to walk the CN from the start node to the end node, keeping track of ngrams visited so far, and choosing the word next which maximizes the n-gram precision up to this word. Track is kept by keeping n-gram count vectors for the hypothesis path and the reference sentences, and update those in each step. The main problem with this approach is that often the local optimum is suboptimal on the global scale, for example if a word occurs on a later position again. Zens and Ney (2005) on the other hand propose to keep all n-gram count vectors instead, and only recombine path hypotheses with identical count vectors. As they suspect, the search space can become exponentially large. In this paper, we suggest a compromise between these two extremes, namely keeping active a sufficiently large number of “path hypotheses” in terms of n-gram precision, instead of only the first best, or of all. But even then, edges with empty words pose a problem, as stepping along an empty edge will never decrease the precision of the local path. In certain cases, steps along empty edges may affe"
D08-1088,P02-1040,0,\N,Missing
D09-1022,N07-1008,0,\N,Missing
D09-1022,J93-2003,0,\N,Missing
D09-1022,P01-1027,1,\N,Missing
D09-1022,N09-2005,1,\N,Missing
D09-1022,W07-0413,0,\N,Missing
D09-1022,D07-1007,0,\N,Missing
D09-1022,J00-2004,0,\N,Missing
D09-1022,P07-1005,0,\N,Missing
D09-1022,P07-1020,0,\N,Missing
D09-1022,2008.iwslt-papers.8,1,\N,Missing
D09-1022,D08-1039,1,\N,Missing
D09-1022,N04-1021,0,\N,Missing
D09-1022,W97-1014,1,\N,Missing
D13-1138,E99-1010,0,\N,Missing
D13-1138,D08-1089,0,\N,Missing
D13-1138,P02-1040,0,\N,Missing
D13-1138,W10-1738,1,\N,Missing
D13-1138,D07-1091,0,\N,Missing
D13-1138,W12-3125,0,\N,Missing
D13-1138,J04-4002,1,\N,Missing
D13-1138,N03-1017,0,\N,Missing
D13-1138,J03-1002,1,\N,Missing
D13-1138,C12-3061,1,\N,Missing
D13-1138,2010.iwslt-evaluation.11,0,\N,Missing
D13-1138,W04-3250,0,\N,Missing
D13-1138,P03-1021,0,\N,Missing
D13-1138,N13-1003,0,\N,Missing
D14-1003,D13-1106,0,0.319897,"ks. They compare between word-factored and tuple-factored n-gram models, obtaining their best results using the word-factored approach, which is less amenable to data sparsity issues. Both of our word-based and phrase-based models eventually work on the word level. Kalchbrenner and Blunsom (2013) use recurrent neural networks with full source sentence representations. The continuous representations are obtained by applying a sequence of convolutions, and the result is fed into the hidden layer of a recurrent language model. Rescoring results indicate no improvements over the state of the art. Auli et al. (2013) also include source sentence representations built either using Latent Semantic Analysis or by concatenating word embeddings. This approach produced no notable gain over systems using a recurrent language model. On the other hand, our proposed bidirectional models include the full source sentence relying on recurrency, yielding improvements over competitive baselines already including a recurrent language model. RNNs were also used with minimum translation units (Hu et al., 2014), which are phrase pairs undergoing certain constraints. At the input layer, each of the source and target phrases"
D14-1003,1997.mtsummit-plenaries.5,0,0.404519,"Missing"
D14-1003,E14-1003,0,0.631886,"Translation Modeling with Bidirectional Recurrent Neural Networks Martin Sundermeyer1 , Tamer Alkhouli1 , Joern Wuebker1 , and Hermann Ney1,2 1 Human Language Technology and Pattern Recognition Group RWTH Aachen University, Aachen, Germany 2 Spoken Language Processing Group Univ. Paris-Sud, France and LIMSI/CNRS, Orsay, France {surname}@cs.rwth-aachen.de Abstract on translation modeling with recurrent neural networks shows its effectiveness on standard baselines, so far no notable gains have been presented on top of recurrent language models (Auli et al., 2013; Kalchbrenner and Blunsom, 2013; Hu et al., 2014). In this work, we present two novel approaches to recurrent neural translation modeling: wordbased and phrase-based. The word-based approach assumes one-to-one aligned source and target sentences. We evaluate different ways of resolving alignment ambiguities to obtain such alignments. The phrase-based RNN approach is more closely tied to the underlying translation paradigm. It models actual phrasal translation probabilities while avoiding sparsity issues by using single words as input and output units. Furthermore, in addition to the unidirectional formulation, we are the first to propose a b"
D14-1003,1997.tmi-1.19,0,0.186958,"Missing"
D14-1003,W13-2258,1,0.865603,"Missing"
D14-1003,D13-1176,0,0.131366,"al networks in machine translation (MT) are presented in (Casta˜no et al., 1997; Casta˜no and Casacuberta, 1997; Casta˜no and Casacuberta, 1999), where they were used for example-based MT. Recently, Le et al. (2012) presented translation models using an output layer with classes and a shortlist for rescoring using feedforward networks. They compare between word-factored and tuple-factored n-gram models, obtaining their best results using the word-factored approach, which is less amenable to data sparsity issues. Both of our word-based and phrase-based models eventually work on the word level. Kalchbrenner and Blunsom (2013) use recurrent neural networks with full source sentence representations. The continuous representations are obtained by applying a sequence of convolutions, and the result is fed into the hidden layer of a recurrent language model. Rescoring results indicate no improvements over the state of the art. Auli et al. (2013) also include source sentence representations built either using Latent Semantic Analysis or by concatenating word embeddings. This approach produced no notable gain over systems using a recurrent language model. On the other hand, our proposed bidirectional models include the f"
D14-1003,P14-1129,0,0.656153,"−1 1 , f1 class layer  I p ei |c(ei ), ei−1 1 , f1  data sources for the LM we selected parts of the Shuffled News and LDC English Gigaword corpora based on cross-entropy difference (Moore and Lewis, 2010), resulting in a total of 1.7 billion running words for LM training. The state-ofthe-art baseline is a standard phrase-based SMT system (Koehn et al., 2003) tuned with MERT (Och, 2003). It contains a hierarchical reordering model (Galley and Manning, 2008) and a 7gram word cluster language model (Wuebker et al., 2013). Here, we also compare against a feedforward joint model as described by Devlin et al. (2014), with a source window of 11 words and a target history of three words, which we denote as BBN-JM. Instead of POS tags, we predict word classes trained with mkcls. We use a shortlist of size 16K and 1000 classes for the remaining words. All neural networks are trained on the TED portion of the data (138K segments) and are applied in a rescoring step on 1000-best lists. To confirm our results, we run additional experiments on the Arabic→English and Chinese→English tasks of the DARPA BOLT project. In both cases, the neural network models are added on top of our most competitive evaluation system"
D14-1003,N03-1017,0,0.150988,"Missing"
D14-1003,D08-1089,0,0.200815,"Missing"
D14-1003,N12-1005,0,0.204244,"large speedups. They report major improvements over strong baselines. The speedups achieved by both works allowed to integrate feedforward neural networks into the decoder. In this Section we contrast previous work to ours, where we design RNNs to model bilingual dependencies, which are applied to rerank n-best lists after decoding. To the best of our knowledge, the earliest attempts to apply neural networks in machine translation (MT) are presented in (Casta˜no et al., 1997; Casta˜no and Casacuberta, 1997; Casta˜no and Casacuberta, 1999), where they were used for example-based MT. Recently, Le et al. (2012) presented translation models using an output layer with classes and a shortlist for rescoring using feedforward networks. They compare between word-factored and tuple-factored n-gram models, obtaining their best results using the word-factored approach, which is less amenable to data sparsity issues. Both of our word-based and phrase-based models eventually work on the word level. Kalchbrenner and Blunsom (2013) use recurrent neural networks with full source sentence representations. The continuous representations are obtained by applying a sequence of convolutions, and the result is fed into"
D14-1003,P10-2041,0,0.188549,"Missing"
D14-1003,D13-1140,0,0.138454,"Missing"
D14-1003,P03-1021,0,0.552689,"Missing"
D14-1003,W10-1738,1,0.474078,"Missing"
D14-1003,P02-1040,0,0.0930684,"Missing"
D14-1003,P10-1049,1,0.701202,"from the example sentence. For brevity, we omit the precise handling of sentence begin and end tokens. the last word of the source phrase “Beispiel” being presented to the network, the full source phrase is stored in the hidden layer, and the neural network is then trained to predict the target phrase words at the output layer. Subsequently, the source input is ε, and the target input is the most recent target side history word. To obtain a phrase-aligned training sequence for the phrase-based RNN models, we force-align the training data with the application of leave-one-out as described in (Wuebker et al., 2010). presentation of the source side is finished we start estimating probabilities for the target side. Therefore, we do not let the neural network learn a target distribution until the very last source word is considered. In this way, we break up the conventional RNN training scheme where an input sample is directly followed by its corresponding teacher signal. Similarly, the presentation of the source side of the next phrase only starts after the prediction of the current target side is completed. To this end, we introduce a no-operation token, denoted by ε, which is not part of the vocabulary"
D14-1003,P06-2093,0,0.0838438,"Missing"
D14-1003,C12-3061,1,0.409628,"Missing"
D14-1003,C12-2104,0,0.155737,"n units (Hu et al., 2014), which are phrase pairs undergoing certain constraints. At the input layer, each of the source and target phrases are modeled as a bag of words, while the output phrase is predicted word-by-word assuming conditional independence. The approach seeks to alleviate data sparsity problems that would arise if phrases were to be uniquely distinguished. Our proposed phrase-based models maintain word order within phrases, but the phrases are processed in a wordpair manner, while the phrase boundaries remain implicitly encoded in the way the words are presented to the network. Schwenk (2012) proposed a feedforward network that predicts phrases of a 3 LSTM Recurrent Neural Networks Our work is based on recurrent neural networks. In related fields like e. g. language modeling, this type of neural network has been shown to perform considerably better than standard feedforward architectures (Mikolov et al., 2011; Arisoy et al., 2012; Sundermeyer et al., 2013; Liu et al., 2014). Most commonly, recurrent neural networks are trained with stochastic gradient descent (SGD), where the gradient of the training criterion is computed with the backpropagation through time algorithm (Rumelhart"
D14-1003,D13-1138,1,0.896862,"Missing"
D14-1003,2006.amta-papers.25,0,0.176983,"Missing"
D14-1003,W12-2703,0,\N,Missing
D14-1003,P04-1013,0,\N,Missing
D14-1184,P10-1106,0,\N,Missing
D14-1184,D08-1085,0,\N,Missing
D14-1184,P11-1025,0,\N,Missing
D14-1184,P12-1017,1,\N,Missing
D14-1184,P13-1154,1,\N,Missing
D15-1165,W15-3034,1,0.842973,"rd reordering. In addition, the JTR RNN models do not require the use of IBM-1 lexica to resolve multiply-aligned words. As discussed in Section 3, these cases are resolved by aligning the multiply-aligned word to the first word on the opposite side. The integration of the NNs into the decoder is not trivial, due to the dependence on the target context. In the case of RNNs, the context is unbounded, which would affect state recombination, and lead to less variety in the beam used to prune the search space. Therefore, the RNN scores are computed using approximations instead (Auli et al., 2013; Alkhouli et al., 2015). In (Alkhouli et al., 2015), it is shown that approximate RNN integration into the phrase-based decoder has a slight advantage over n-best rescoring. Therefore, we apply RNNs in rescoring in this work, and to allow for a direct comparison between FFNNs and RNNs, we apply FFNNs in rescoring as well. 5 Evaluation We perform experiments on the largescale IWSLT 20132 (Cettolo et al., 2014) German→English, WMT 20153 German→English and the DARPA BOLT Chinese→English tasks. The statistics for the bilingual corpora are shown in Table 2. Word alignments are generated with the GIZA++ toolkit 1406 2 htt"
D15-1165,D13-1106,0,0.268023,"ot have any explicit treatment of alignments. Bahdanau et al. (2015) introduced soft alignments as part of the network architecture. In this work, we make use of hard alignments instead, where we encode the alignments in the source and target sequences, requiring no modifications of existing feed-forward and recurrent NN architectures. Our feed-forward models are based on the architectures proposed in (Devlin et al., 2014), while the recurrent models are based on (Sundermeyer et al., 2014). Further recent research on applying NN models for extended context was carried out in (Le et al., 2012; Auli et al., 2013; Hu et al., 2014). All of these works focus on lexical context and ignore the reordering aspect covered in our work. 3 JTR Sequences The core idea of this work is the interpretation of a bilingual sentence pair and its word alignment as a linear sequence of K joint translation and reordering (JTR) tokens gK1 . Formally, the sequence gK1 ( f1J , eI1 , bI1 ) is a uniquely defined interpretation of a given source sentence f1J , its translation eI1 and the inverted alignment bI1 , where bi denotes the ordered sequence of source positions j aligned to target position i. We drop the explicit mentio"
D15-1165,J90-2002,0,0.838221,"Missing"
D15-1165,J93-2003,0,0.0526068,"Missing"
D15-1165,2014.iwslt-evaluation.1,0,0.154546,"Missing"
D15-1165,2011.mtsummit-papers.30,0,0.0297545,"T German English BOLT Chinese English 4.32M 108M 109M 836K 792K 4.22M 106M 108M 814K 773K 4.08M 78M 86M 384K 817K Table 2: Statistics for the bilingual training data of the IWSLT 2013 German→English, WMT 2015 German→English, and the DARPA BOLT Chinese→English translation tasks. (Och and Ney, 2003). We use a standard phrasebased translation system (Koehn et al., 2003). The decoding process is implemented as a beam search. All baselines contain phrasal and lexical smoothing models for both directions, word and phrase penalties, a distance-based reordering model, enhanced low frequency features (Chen et al., 2011), a hierarchical reordering model (HRM) (Galley and Manning, 2008), a word class LM (Wuebker et al., 2013) and an n-gram LM. The lexical and phrase translation models of all baseline systems are trained on all provided bilingual data. The log-linear feature weights are tuned with minimum error rate training (MERT) (Och, 2003) on B LEU (Papineni et al., 2001). All systems are evaluated with MultEval (Clark et al., 2011). The reported B LEU scores are averaged over three MERT optimization runs. All LMs, OSMs and count-based JTR models are estimated with the KenLM toolkit (Heafield et al., 2013)."
D15-1165,P11-2031,0,0.0703101,"ch. All baselines contain phrasal and lexical smoothing models for both directions, word and phrase penalties, a distance-based reordering model, enhanced low frequency features (Chen et al., 2011), a hierarchical reordering model (HRM) (Galley and Manning, 2008), a word class LM (Wuebker et al., 2013) and an n-gram LM. The lexical and phrase translation models of all baseline systems are trained on all provided bilingual data. The log-linear feature weights are tuned with minimum error rate training (MERT) (Och, 2003) on B LEU (Papineni et al., 2001). All systems are evaluated with MultEval (Clark et al., 2011). The reported B LEU scores are averaged over three MERT optimization runs. All LMs, OSMs and count-based JTR models are estimated with the KenLM toolkit (Heafield et al., 2013). The OSM and the count-based JTR model are implemented in the phrasal decoder. NNs are used only in rescoring. The 9-gram FFNNs are trained with two hidden layers. The short lists contain the 10k most frequent words, and all remaining words are clusterd into 1000 word classes. The projecton layer has 17 × 100 nodes, the first hidden layer 1000 and the second 500. The RNNs have LSTM architectures. The URNN has 2 hidden"
D15-1165,C10-2023,0,0.0197048,"gnments and the models, similar to the training of IBM models (Brown et al., 1990; Brown et al., 1993). In the long run, we intend to achieve a consistency between decoding and training using the introduced JTR models. 2 Previous Work In order to address the downsides of the phrase translation model, various approaches have been taken. Mari˜no et al. (2006) proposed a bilingual language model (BILM) that operates on bilingual n-grams, with an own n-gram decoder requiring monotone alignments. The lexical reordering model introduced in (Tillmann, 2004) was integrated into phrase-based decoding. Crego and Yvon (2010) adapted the approach to BILMs. The bilingual n-grams are further advanced in (Niehues et al., 2011), where they operate on nonmonotone alignments within a phrase-based translation framework. Compared to our JTR models, their BILMs treat jointly aligned source words as minimal translation units, ignore unaligned source words and do not include reordering information. Durrani et al. (2011) developed the OSM which combined dependencies on bilingual word pairs and reordering information into a single framework. It used an own decoder that was based on ngrams of MTUs and predicted single translati"
D15-1165,H05-1022,0,0.145439,"this work can be seen as an extension of the ETM. Nevertheless, JTR models utilize linear sequences of dependencies and combine the translation of bilingual word pairs and reoderings into a single model. The ETM, however, features separate models for the translation of individual words and reorderings and provides an explicit treatment of multiple alignments. As they operate on linear sequences, JTR count models can be implemented using existing toolkits for n-gram language models, e.g. the KenLM toolkit (Heafield et al., 2013). An HMM approach for word-to-phrase alignments was presented in (Deng and Byrne, 2005), showing performance similar to IBM Model 4 on the task of bitext alignment. Feng et al. (2013) propose several models which rely only on the information provided by the source side and predict reorderings. Contrastingly, JTR models incorporate target information as well and predict both translations and reorderings jointly in a single framework. Zhang et al. (2013) explore different Markov chain orderings for an n-gram model on MTUs in rescoring. Feng and Cohn (2013) present another generative word-based Markov chain translation model which exploits a hierarchical PitmanYor process for smoot"
D15-1165,P14-1129,0,0.170502,"Missing"
D15-1165,P11-1105,0,0.0493314,"odel (BILM) that operates on bilingual n-grams, with an own n-gram decoder requiring monotone alignments. The lexical reordering model introduced in (Tillmann, 2004) was integrated into phrase-based decoding. Crego and Yvon (2010) adapted the approach to BILMs. The bilingual n-grams are further advanced in (Niehues et al., 2011), where they operate on nonmonotone alignments within a phrase-based translation framework. Compared to our JTR models, their BILMs treat jointly aligned source words as minimal translation units, ignore unaligned source words and do not include reordering information. Durrani et al. (2011) developed the OSM which combined dependencies on bilingual word pairs and reordering information into a single framework. It used an own decoder that was based on ngrams of MTUs and predicted single translation or reordering operations. This was further advanced in (Durrani et al., 2013a) by a decoder that was capable of predicting whole sequences of MTUs, similar to a phrase-based decoder. In (Durrani et al., 2013b), a slightly enhanced version of OSM was integrated into the log-linear framework of the Moses system (Koehn et al., 2007). Both the BILM (Stewart et al., 2014) and the OSM (Durra"
D15-1165,N13-1001,0,0.427665,"ng word alignments into novel linear sequences. These are joint translation and reordering (JTR) uniquely defined sequences, combining interdepending lexical and alignment dependencies on the word level into a single framework. They are constructed in a simple manner while capturing multiple alignments and empty words. JTR sequences can be used to train a variety of models. We investigate the performances of ngram models with modified Kneser-Ney smoothing, feed-forward and recurrent neural network architectures when estimated on JTR sequences, and compare them to the operation sequence model (Durrani et al., 2013b). Evaluations on the IWSLT German→English, WMT German→English and BOLT Chinese→English tasks show that JTR models improve state-of-the-art phrasebased systems by up to 2.2 BLEU. 1 Introduction Standard phrase-based machine translation (Och et al., 1999; Zens et al., 2002; Koehn et al., 2003) uses relative frequencies of phrase pairs to estimate a translation model. The phrase table is extracted from a bilingual text aligned on the word level, using e.g. GIZA++ (Och and Ney, 2003). Although the phrase pairs capture internal dependencies between the source and target phrases aligned to each ot"
D15-1165,P13-2071,0,0.556345,"ng word alignments into novel linear sequences. These are joint translation and reordering (JTR) uniquely defined sequences, combining interdepending lexical and alignment dependencies on the word level into a single framework. They are constructed in a simple manner while capturing multiple alignments and empty words. JTR sequences can be used to train a variety of models. We investigate the performances of ngram models with modified Kneser-Ney smoothing, feed-forward and recurrent neural network architectures when estimated on JTR sequences, and compare them to the operation sequence model (Durrani et al., 2013b). Evaluations on the IWSLT German→English, WMT German→English and BOLT Chinese→English tasks show that JTR models improve state-of-the-art phrasebased systems by up to 2.2 BLEU. 1 Introduction Standard phrase-based machine translation (Och et al., 1999; Zens et al., 2002; Koehn et al., 2003) uses relative frequencies of phrase pairs to estimate a translation model. The phrase table is extracted from a bilingual text aligned on the word level, using e.g. GIZA++ (Och and Ney, 2003). Although the phrase pairs capture internal dependencies between the source and target phrases aligned to each ot"
D15-1165,C14-1041,0,0.116443,"2011) developed the OSM which combined dependencies on bilingual word pairs and reordering information into a single framework. It used an own decoder that was based on ngrams of MTUs and predicted single translation or reordering operations. This was further advanced in (Durrani et al., 2013a) by a decoder that was capable of predicting whole sequences of MTUs, similar to a phrase-based decoder. In (Durrani et al., 2013b), a slightly enhanced version of OSM was integrated into the log-linear framework of the Moses system (Koehn et al., 2007). Both the BILM (Stewart et al., 2014) and the OSM (Durrani et al., 2014) can be smoothed using word classes. Guta et al. (2015) introduced the extended translation model (ETM), which operates on the word level and augments the IBM models by an additional bilingual word pair and a reordering operation. It is implemented into the log-linear framework of a phrase-based decoder and shown to be competitive with a 7-gram OSM. The JTR n-gram models proposed within this work can be seen as an extension of the ETM. Nevertheless, JTR models utilize linear sequences of dependencies and combine the translation of bilingual word pairs and reoderings into a single model. The ET"
D15-1165,P13-1033,0,0.509592,"guage models, e.g. the KenLM toolkit (Heafield et al., 2013). An HMM approach for word-to-phrase alignments was presented in (Deng and Byrne, 2005), showing performance similar to IBM Model 4 on the task of bitext alignment. Feng et al. (2013) propose several models which rely only on the information provided by the source side and predict reorderings. Contrastingly, JTR models incorporate target information as well and predict both translations and reorderings jointly in a single framework. Zhang et al. (2013) explore different Markov chain orderings for an n-gram model on MTUs in rescoring. Feng and Cohn (2013) present another generative word-based Markov chain translation model which exploits a hierarchical PitmanYor process for smoothing, but it is only applied to induce word alignments. Their follow-up work (Feng et al., 2014) introduces a Markov-model on 1402 MTUs, similar to the OSM described above. Recently, neural machine translation has emerged as an alternative to phrase-based decoding, where NNs are used as standalone models to decode source input. In (Sutskever et al., 2014), a recurrent NN was used to encode a source sequence, and output a target sentence once the source sentence was ful"
D15-1165,P13-1032,1,0.767593,"s of dependencies and combine the translation of bilingual word pairs and reoderings into a single model. The ETM, however, features separate models for the translation of individual words and reorderings and provides an explicit treatment of multiple alignments. As they operate on linear sequences, JTR count models can be implemented using existing toolkits for n-gram language models, e.g. the KenLM toolkit (Heafield et al., 2013). An HMM approach for word-to-phrase alignments was presented in (Deng and Byrne, 2005), showing performance similar to IBM Model 4 on the task of bitext alignment. Feng et al. (2013) propose several models which rely only on the information provided by the source side and predict reorderings. Contrastingly, JTR models incorporate target information as well and predict both translations and reorderings jointly in a single framework. Zhang et al. (2013) explore different Markov chain orderings for an n-gram model on MTUs in rescoring. Feng and Cohn (2013) present another generative word-based Markov chain translation model which exploits a hierarchical PitmanYor process for smoothing, but it is only applied to induce word alignments. Their follow-up work (Feng et al., 2014)"
D15-1165,W14-1616,0,0.324511,"Feng et al. (2013) propose several models which rely only on the information provided by the source side and predict reorderings. Contrastingly, JTR models incorporate target information as well and predict both translations and reorderings jointly in a single framework. Zhang et al. (2013) explore different Markov chain orderings for an n-gram model on MTUs in rescoring. Feng and Cohn (2013) present another generative word-based Markov chain translation model which exploits a hierarchical PitmanYor process for smoothing, but it is only applied to induce word alignments. Their follow-up work (Feng et al., 2014) introduces a Markov-model on 1402 MTUs, similar to the OSM described above. Recently, neural machine translation has emerged as an alternative to phrase-based decoding, where NNs are used as standalone models to decode source input. In (Sutskever et al., 2014), a recurrent NN was used to encode a source sequence, and output a target sentence once the source sentence was fully encoded in the network. The network did not have any explicit treatment of alignments. Bahdanau et al. (2015) introduced soft alignments as part of the network architecture. In this work, we make use of hard alignments i"
D15-1165,D08-1089,0,0.193694,"792K 4.22M 106M 108M 814K 773K 4.08M 78M 86M 384K 817K Table 2: Statistics for the bilingual training data of the IWSLT 2013 German→English, WMT 2015 German→English, and the DARPA BOLT Chinese→English translation tasks. (Och and Ney, 2003). We use a standard phrasebased translation system (Koehn et al., 2003). The decoding process is implemented as a beam search. All baselines contain phrasal and lexical smoothing models for both directions, word and phrase penalties, a distance-based reordering model, enhanced low frequency features (Chen et al., 2011), a hierarchical reordering model (HRM) (Galley and Manning, 2008), a word class LM (Wuebker et al., 2013) and an n-gram LM. The lexical and phrase translation models of all baseline systems are trained on all provided bilingual data. The log-linear feature weights are tuned with minimum error rate training (MERT) (Och, 2003) on B LEU (Papineni et al., 2001). All systems are evaluated with MultEval (Clark et al., 2011). The reported B LEU scores are averaged over three MERT optimization runs. All LMs, OSMs and count-based JTR models are estimated with the KenLM toolkit (Heafield et al., 2013). The OSM and the count-based JTR model are implemented in the phra"
D15-1165,W15-3033,1,0.349271,"Missing"
D15-1165,P13-2121,0,0.0813648,"Missing"
D15-1165,E14-1003,0,0.300348,"t treatment of alignments. Bahdanau et al. (2015) introduced soft alignments as part of the network architecture. In this work, we make use of hard alignments instead, where we encode the alignments in the source and target sequences, requiring no modifications of existing feed-forward and recurrent NN architectures. Our feed-forward models are based on the architectures proposed in (Devlin et al., 2014), while the recurrent models are based on (Sundermeyer et al., 2014). Further recent research on applying NN models for extended context was carried out in (Le et al., 2012; Auli et al., 2013; Hu et al., 2014). All of these works focus on lexical context and ignore the reordering aspect covered in our work. 3 JTR Sequences The core idea of this work is the interpretation of a bilingual sentence pair and its word alignment as a linear sequence of K joint translation and reordering (JTR) tokens gK1 . Formally, the sequence gK1 ( f1J , eI1 , bI1 ) is a uniquely defined interpretation of a given source sentence f1J , its translation eI1 and the inverted alignment bI1 , where bi denotes the ordered sequence of source positions j aligned to target position i. We drop the explicit mention of ( f1J , eI1 ,"
D15-1165,N03-1017,0,0.353414,"ignments and empty words. JTR sequences can be used to train a variety of models. We investigate the performances of ngram models with modified Kneser-Ney smoothing, feed-forward and recurrent neural network architectures when estimated on JTR sequences, and compare them to the operation sequence model (Durrani et al., 2013b). Evaluations on the IWSLT German→English, WMT German→English and BOLT Chinese→English tasks show that JTR models improve state-of-the-art phrasebased systems by up to 2.2 BLEU. 1 Introduction Standard phrase-based machine translation (Och et al., 1999; Zens et al., 2002; Koehn et al., 2003) uses relative frequencies of phrase pairs to estimate a translation model. The phrase table is extracted from a bilingual text aligned on the word level, using e.g. GIZA++ (Och and Ney, 2003). Although the phrase pairs capture internal dependencies between the source and target phrases aligned to each other, they fail to model dependencies that extend beyond phrase boundaries. Phrase-based decoding involves concatenating target phrases. The burden of ensuring that the result is linguistically consistent falls on the language model (LM). Although JTR n-gram models are closely related to the op"
D15-1165,P07-2045,0,0.00776249,"ource words and do not include reordering information. Durrani et al. (2011) developed the OSM which combined dependencies on bilingual word pairs and reordering information into a single framework. It used an own decoder that was based on ngrams of MTUs and predicted single translation or reordering operations. This was further advanced in (Durrani et al., 2013a) by a decoder that was capable of predicting whole sequences of MTUs, similar to a phrase-based decoder. In (Durrani et al., 2013b), a slightly enhanced version of OSM was integrated into the log-linear framework of the Moses system (Koehn et al., 2007). Both the BILM (Stewart et al., 2014) and the OSM (Durrani et al., 2014) can be smoothed using word classes. Guta et al. (2015) introduced the extended translation model (ETM), which operates on the word level and augments the IBM models by an additional bilingual word pair and a reordering operation. It is implemented into the log-linear framework of a phrase-based decoder and shown to be competitive with a 7-gram OSM. The JTR n-gram models proposed within this work can be seen as an extension of the ETM. Nevertheless, JTR models utilize linear sequences of dependencies and combine the trans"
D15-1165,N12-1005,0,0.109906,"The network did not have any explicit treatment of alignments. Bahdanau et al. (2015) introduced soft alignments as part of the network architecture. In this work, we make use of hard alignments instead, where we encode the alignments in the source and target sequences, requiring no modifications of existing feed-forward and recurrent NN architectures. Our feed-forward models are based on the architectures proposed in (Devlin et al., 2014), while the recurrent models are based on (Sundermeyer et al., 2014). Further recent research on applying NN models for extended context was carried out in (Le et al., 2012; Auli et al., 2013; Hu et al., 2014). All of these works focus on lexical context and ignore the reordering aspect covered in our work. 3 JTR Sequences The core idea of this work is the interpretation of a bilingual sentence pair and its word alignment as a linear sequence of K joint translation and reordering (JTR) tokens gK1 . Formally, the sequence gK1 ( f1J , eI1 , bI1 ) is a uniquely defined interpretation of a given source sentence f1J , its translation eI1 and the inverted alignment bI1 , where bi denotes the ordered sequence of source positions j aligned to target position i. We drop"
D15-1165,J06-4004,0,0.152922,"Missing"
D15-1165,P10-2041,0,0.053486,"ain data, smaller n-gram sizes were used. All rescoring experiments used 1000best lists without duplicates. 5.1 Tasks description The domain of IWSLT consists of lecture-type talks presented at TED conferences which are also available online4 . All systems are optimized on the dev2010 corpus, named dev here. Some of the OSM and JTR systems are trained on the TED portions of the data containing 138K sentences. To estimate the 4-gram LM, we additionally make use of parts of the Shuffled News, LDC English Gigaword and 109 -French-English corpora, selected by a cross-entropy difference criterion (Moore and Lewis, 2010). In total, 1.7 billion running words are taken for LM training. The BOLT Chinese→English task is evaluated on the “discussion forum” domain. The 5-gram LM is trained on 2.9 billion running words in total. The in-domain data consists of a subset of 67.8K sentences and we used a set of 1845 sentences for tuning. The evaluation set test1 contains 1844 and test2 1124 sentences. For the WMT task, we used the target side of the bilingual data and all monolingual data to train a pruned 5-gram LM on a total of 4.4 billion running words. We concatenated the newstest2011 and newstest2012 corpora for tu"
D15-1165,J03-1002,1,0.0842537,"neural network architectures when estimated on JTR sequences, and compare them to the operation sequence model (Durrani et al., 2013b). Evaluations on the IWSLT German→English, WMT German→English and BOLT Chinese→English tasks show that JTR models improve state-of-the-art phrasebased systems by up to 2.2 BLEU. 1 Introduction Standard phrase-based machine translation (Och et al., 1999; Zens et al., 2002; Koehn et al., 2003) uses relative frequencies of phrase pairs to estimate a translation model. The phrase table is extracted from a bilingual text aligned on the word level, using e.g. GIZA++ (Och and Ney, 2003). Although the phrase pairs capture internal dependencies between the source and target phrases aligned to each other, they fail to model dependencies that extend beyond phrase boundaries. Phrase-based decoding involves concatenating target phrases. The burden of ensuring that the result is linguistically consistent falls on the language model (LM). Although JTR n-gram models are closely related to the operation sequence model (OSM) (Durrani et al., 2013b), there are three main differences. To begin with, the OSM employs minimal translation units (MTUs), which are essentially atomic phrases. A"
D15-1165,W99-0604,1,0.577079,"le manner while capturing multiple alignments and empty words. JTR sequences can be used to train a variety of models. We investigate the performances of ngram models with modified Kneser-Ney smoothing, feed-forward and recurrent neural network architectures when estimated on JTR sequences, and compare them to the operation sequence model (Durrani et al., 2013b). Evaluations on the IWSLT German→English, WMT German→English and BOLT Chinese→English tasks show that JTR models improve state-of-the-art phrasebased systems by up to 2.2 BLEU. 1 Introduction Standard phrase-based machine translation (Och et al., 1999; Zens et al., 2002; Koehn et al., 2003) uses relative frequencies of phrase pairs to estimate a translation model. The phrase table is extracted from a bilingual text aligned on the word level, using e.g. GIZA++ (Och and Ney, 2003). Although the phrase pairs capture internal dependencies between the source and target phrases aligned to each other, they fail to model dependencies that extend beyond phrase boundaries. Phrase-based decoding involves concatenating target phrases. The burden of ensuring that the result is linguistically consistent falls on the language model (LM). Although JTR n-g"
D15-1165,P03-1021,0,0.0614101,"lation system (Koehn et al., 2003). The decoding process is implemented as a beam search. All baselines contain phrasal and lexical smoothing models for both directions, word and phrase penalties, a distance-based reordering model, enhanced low frequency features (Chen et al., 2011), a hierarchical reordering model (HRM) (Galley and Manning, 2008), a word class LM (Wuebker et al., 2013) and an n-gram LM. The lexical and phrase translation models of all baseline systems are trained on all provided bilingual data. The log-linear feature weights are tuned with minimum error rate training (MERT) (Och, 2003) on B LEU (Papineni et al., 2001). All systems are evaluated with MultEval (Clark et al., 2011). The reported B LEU scores are averaged over three MERT optimization runs. All LMs, OSMs and count-based JTR models are estimated with the KenLM toolkit (Heafield et al., 2013). The OSM and the count-based JTR model are implemented in the phrasal decoder. NNs are used only in rescoring. The 9-gram FFNNs are trained with two hidden layers. The short lists contain the 10k most frequent words, and all remaining words are clusterd into 1000 word classes. The projecton layer has 17 × 100 nodes, the first"
D15-1165,2001.mtsummit-papers.68,0,0.0140599,"et al., 2003). The decoding process is implemented as a beam search. All baselines contain phrasal and lexical smoothing models for both directions, word and phrase penalties, a distance-based reordering model, enhanced low frequency features (Chen et al., 2011), a hierarchical reordering model (HRM) (Galley and Manning, 2008), a word class LM (Wuebker et al., 2013) and an n-gram LM. The lexical and phrase translation models of all baseline systems are trained on all provided bilingual data. The log-linear feature weights are tuned with minimum error rate training (MERT) (Och, 2003) on B LEU (Papineni et al., 2001). All systems are evaluated with MultEval (Clark et al., 2011). The reported B LEU scores are averaged over three MERT optimization runs. All LMs, OSMs and count-based JTR models are estimated with the KenLM toolkit (Heafield et al., 2013). The OSM and the count-based JTR model are implemented in the phrasal decoder. NNs are used only in rescoring. The 9-gram FFNNs are trained with two hidden layers. The short lists contain the 10k most frequent words, and all remaining words are clusterd into 1000 word classes. The projecton layer has 17 × 100 nodes, the first hidden layer 1000 and the second"
D15-1165,2014.amta-researchers.3,0,0.222678,"ering information. Durrani et al. (2011) developed the OSM which combined dependencies on bilingual word pairs and reordering information into a single framework. It used an own decoder that was based on ngrams of MTUs and predicted single translation or reordering operations. This was further advanced in (Durrani et al., 2013a) by a decoder that was capable of predicting whole sequences of MTUs, similar to a phrase-based decoder. In (Durrani et al., 2013b), a slightly enhanced version of OSM was integrated into the log-linear framework of the Moses system (Koehn et al., 2007). Both the BILM (Stewart et al., 2014) and the OSM (Durrani et al., 2014) can be smoothed using word classes. Guta et al. (2015) introduced the extended translation model (ETM), which operates on the word level and augments the IBM models by an additional bilingual word pair and a reordering operation. It is implemented into the log-linear framework of a phrase-based decoder and shown to be competitive with a 7-gram OSM. The JTR n-gram models proposed within this work can be seen as an extension of the ETM. Nevertheless, JTR models utilize linear sequences of dependencies and combine the translation of bilingual word pairs and reo"
D15-1165,D14-1003,1,0.862777,"rrani et al., 2013b). Experimental results confirm that this simplification does not make JTR models less expressive, as their performance is on par with the OSM. Due to data sparsity, increasing the n-gram order of count-based models beyond a certain point becomes useless. To address this, we resort to neu1401 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1401–1411, c Lisbon, Portugal, 17-21 September 2015. 2015 Association for Computational Linguistics. ral networks (NNs), as they have been successfully applied to machine translation recently (Sundermeyer et al., 2014; Devlin et al., 2014). They are able to score any word combination without requiring additional smoothing techniques. We experiment with feed-forward and recurrent translation networks, benefiting from their smoothing capabilities. To this end, we split the linear sequence into two sequences for the neural translation models to operate on. This is possible due to the simplicity of the JTR sequence. We show that the count and NN models perform well on their own, and that combining them yields even better results. In this work, we apply n-gram models with modified Kneser-Ney smoothing during ph"
D15-1165,N04-4026,0,0.0982156,"ved word alignments by a joint optimization of both the alignments and the models, similar to the training of IBM models (Brown et al., 1990; Brown et al., 1993). In the long run, we intend to achieve a consistency between decoding and training using the introduced JTR models. 2 Previous Work In order to address the downsides of the phrase translation model, various approaches have been taken. Mari˜no et al. (2006) proposed a bilingual language model (BILM) that operates on bilingual n-grams, with an own n-gram decoder requiring monotone alignments. The lexical reordering model introduced in (Tillmann, 2004) was integrated into phrase-based decoding. Crego and Yvon (2010) adapted the approach to BILMs. The bilingual n-grams are further advanced in (Niehues et al., 2011), where they operate on nonmonotone alignments within a phrase-based translation framework. Compared to our JTR models, their BILMs treat jointly aligned source words as minimal translation units, ignore unaligned source words and do not include reordering information. Durrani et al. (2011) developed the OSM which combined dependencies on bilingual word pairs and reordering information into a single framework. It used an own decode"
D15-1165,D13-1138,1,0.861827,"384K 817K Table 2: Statistics for the bilingual training data of the IWSLT 2013 German→English, WMT 2015 German→English, and the DARPA BOLT Chinese→English translation tasks. (Och and Ney, 2003). We use a standard phrasebased translation system (Koehn et al., 2003). The decoding process is implemented as a beam search. All baselines contain phrasal and lexical smoothing models for both directions, word and phrase penalties, a distance-based reordering model, enhanced low frequency features (Chen et al., 2011), a hierarchical reordering model (HRM) (Galley and Manning, 2008), a word class LM (Wuebker et al., 2013) and an n-gram LM. The lexical and phrase translation models of all baseline systems are trained on all provided bilingual data. The log-linear feature weights are tuned with minimum error rate training (MERT) (Och, 2003) on B LEU (Papineni et al., 2001). All systems are evaluated with MultEval (Clark et al., 2011). The reported B LEU scores are averaged over three MERT optimization runs. All LMs, OSMs and count-based JTR models are estimated with the KenLM toolkit (Heafield et al., 2013). The OSM and the count-based JTR model are implemented in the phrasal decoder. NNs are used only in rescor"
D15-1165,2002.tmi-tutorials.2,0,0.0611081,"pturing multiple alignments and empty words. JTR sequences can be used to train a variety of models. We investigate the performances of ngram models with modified Kneser-Ney smoothing, feed-forward and recurrent neural network architectures when estimated on JTR sequences, and compare them to the operation sequence model (Durrani et al., 2013b). Evaluations on the IWSLT German→English, WMT German→English and BOLT Chinese→English tasks show that JTR models improve state-of-the-art phrasebased systems by up to 2.2 BLEU. 1 Introduction Standard phrase-based machine translation (Och et al., 1999; Zens et al., 2002; Koehn et al., 2003) uses relative frequencies of phrase pairs to estimate a translation model. The phrase table is extracted from a bilingual text aligned on the word level, using e.g. GIZA++ (Och and Ney, 2003). Although the phrase pairs capture internal dependencies between the source and target phrases aligned to each other, they fail to model dependencies that extend beyond phrase boundaries. Phrase-based decoding involves concatenating target phrases. The burden of ensuring that the result is linguistically consistent falls on the language model (LM). Although JTR n-gram models are clos"
D15-1165,N13-1002,0,0.0782986,"operate on linear sequences, JTR count models can be implemented using existing toolkits for n-gram language models, e.g. the KenLM toolkit (Heafield et al., 2013). An HMM approach for word-to-phrase alignments was presented in (Deng and Byrne, 2005), showing performance similar to IBM Model 4 on the task of bitext alignment. Feng et al. (2013) propose several models which rely only on the information provided by the source side and predict reorderings. Contrastingly, JTR models incorporate target information as well and predict both translations and reorderings jointly in a single framework. Zhang et al. (2013) explore different Markov chain orderings for an n-gram model on MTUs in rescoring. Feng and Cohn (2013) present another generative word-based Markov chain translation model which exploits a hierarchical PitmanYor process for smoothing, but it is only applied to induce word alignments. Their follow-up work (Feng et al., 2014) introduces a Markov-model on 1402 MTUs, similar to the OSM described above. Recently, neural machine translation has emerged as an alternative to phrase-based decoding, where NNs are used as standalone models to decode source input. In (Sutskever et al., 2014), a recurren"
D15-1165,P02-1040,0,\N,Missing
D18-1101,E17-3017,0,0.0611533,"Missing"
D18-1101,N16-1162,0,0.187982,"theses. Once we have the cross-lingual mapping, we can transform the embedding of a given source word and find a target word with the closest embedding, i.e. nearest neighbor search. Here, we apply cross-domain similarity local scaling (Conneau et al., 2018) to penalize the word similarities in dense areas of the embedding distribution. We further refine the mapping obtained from Step 2 as follows (Artetxe et al., 2017): 3.2 Denoising Even when we have correctly translated words for each position, the output is still far from an acceptable translation. We adopt sequence denoising autoencoder (Hill et al., 2016) to improve the translation output of Section 3.1. The main idea is to train a sequence-to-sequence neural network model that takes a noisy sentence as input and produces a (denoised) clean sentence as output, both of which are of the same (target) language. The model was originally proposed to learn sentence embeddings, but here we use it directly to actually remove noise in a sentence. Training label sequences for the denoising network would be target monolingual sentences, but 3. Build a synthetic dictionary by finding mutual nearest neighbors for both translation directions in vocabularies"
D18-1101,E17-2103,1,0.890323,"Missing"
D18-1101,E17-1088,0,0.0905667,"Missing"
D18-1101,P17-1042,0,0.139558,"Missing"
D18-1101,W17-3204,0,0.0231401,"ingual word embedding and its usage in translation. 1 • We formulate a straightforward way to combine a language model with cross-lingual word similarities, effectively considering context in lexical choices. • We develop a postprocessing method for word-by-word translation outputs using a denoising autoencoder, handling local reordering and multi-aligned words. Introduction Building a machine translation (MT) system requires lots of bilingual data. Neural MT models (Bahdanau et al., 2015), which become the current standard, are even more difficult to train without huge bilingual supervision (Koehn and Knowles, 2017). However, bilingual resources are still limited to some of the selected language pairs—mostly from or to English. A workaround for zero-resource language pairs is translating via an intermediate (pivot) language. To do so, we need to collect parallel data and train MT models for source-to-pivot and pivot-to-target individually; it takes a double effort and the decoding is twice as slow. Unsupervised learning is another alternative, where we can train an MT system with only monolingual corpora. Decipherment methods (Ravi and Knight, 2011; Nuhn et al., 2013) are the first work in this direction"
D18-1101,D18-1549,0,0.0536268,"do not involve any decoding steps to generate pseudo-parallel training data, but still perform This is a generalized version of swapping two neighboring words (Hill et al., 2016). Reordering is highly dependent of each language, but we found that this noise is generally close to wordby-word translation outputs. Insertion, deletion, and reordering noises were applied to each mini-batch with different random seeds, allowing the model to see various noisy versions of the same clean sentence over the epochs. Note that the deletion and permutation noises are integrated in the neural MT training of Artetxe et al. (2018) and Lample et al. (2018) as additional training objectives. Whereas we optimize an independent model solely for denoising without architecture change. It allows us to easily train a larger network with a larger data. Insertion noise is of our original design, which we found to be the most effective (Section 4.1). 4 Experiments We applied the proposed methods on WMT 2016 German↔English task and WMT 2014 French↔English task. For German/English, we trained word embeddings with 100M sentences sampled from News Crawl 2014-2017 monolingual corpora. For French, we used News Crawl 2007-2014 (around 4"
D18-1101,N03-1017,0,0.111813,"Missing"
D18-1101,Q17-1010,0,0.11113,"edding for word-by-word translation, which is state-of-the-art in terms of type translation quality (Artetxe et al., 2017; Conneau et al., 2018). Cross-lingual word embedding is a continuous representation of words whose vector space is shared across multiple languages. This enables distance calculation between word embeddings across languages, which is actually finding translation candidates. We train cross-lingual word embedding in a fully unsupervised manner: 1. Learn monolingual source and target embeddings independently. For this, we run skipgram algorithm augmented with character ngram (Bojanowski et al., 2017). 2. Find a linear mapping from source embedding space to target embedding space by adversarial training (Conneau et al., 2018). We do not pre-train the discriminator with a seed dictionary, and consider only the top Vcross-train words of each language as input to the discriminator. L(e; f, h) = λemb log q(f, e) + λLM log p(e|h) Here, q(f, e) is a lexical score defined as: q(f, e) = d(f, e) + 1 2 where d(f, e) ∈ [−1, 1] is a cosine similarity between f and e. It is transformed to the range [0, 1] to make it similar in scale with the LM probability. In our experiments, we found that this simple"
D18-1101,P13-1154,1,0.884165,"ut huge bilingual supervision (Koehn and Knowles, 2017). However, bilingual resources are still limited to some of the selected language pairs—mostly from or to English. A workaround for zero-resource language pairs is translating via an intermediate (pivot) language. To do so, we need to collect parallel data and train MT models for source-to-pivot and pivot-to-target individually; it takes a double effort and the decoding is twice as slow. Unsupervised learning is another alternative, where we can train an MT system with only monolingual corpora. Decipherment methods (Ravi and Knight, 2011; Nuhn et al., 2013) are the first work in this direction, but they often suffer from a huge latent hypothesis space (Kim et al., 2017). • We analyze the effect of different artificial noises for the denoising model and propose a novel noise type. • We verify that cross-lingual embedding on subword units performs poorly in translation. • We empirically show that cross-lingual mapping can be learned using a small vocabulary without losing the translation performance. The proposed models can be efficiently trained with off-the-shelf softwares with little or no changes in the implementation, using only monolingual d"
D18-1101,P08-1088,0,0.10246,"Missing"
D18-1101,P11-1002,0,0.136147,"ifficult to train without huge bilingual supervision (Koehn and Knowles, 2017). However, bilingual resources are still limited to some of the selected language pairs—mostly from or to English. A workaround for zero-resource language pairs is translating via an intermediate (pivot) language. To do so, we need to collect parallel data and train MT models for source-to-pivot and pivot-to-target individually; it takes a double effort and the decoding is twice as slow. Unsupervised learning is another alternative, where we can train an MT system with only monolingual corpora. Decipherment methods (Ravi and Knight, 2011; Nuhn et al., 2013) are the first work in this direction, but they often suffer from a huge latent hypothesis space (Kim et al., 2017). • We analyze the effect of different artificial noises for the denoising model and propose a novel noise type. • We verify that cross-lingual embedding on subword units performs poorly in translation. • We empirically show that cross-lingual mapping can be learned using a small vocabulary without losing the translation performance. The proposed models can be efficiently trained with off-the-shelf softwares with little or no changes in the implementation, usin"
D18-1101,P16-1009,0,0.126776,"Missing"
D18-1101,P16-1162,0,0.169097,"Missing"
D18-1101,P17-1179,0,0.0685862,"Missing"
D18-1335,P02-1040,0,\N,Missing
D18-1335,P07-2045,0,\N,Missing
D18-1335,W16-2316,0,\N,Missing
D18-1335,P16-1162,0,\N,Missing
D19-1080,N19-1388,0,0.093095,"Missing"
D19-1080,2008.iwslt-papers.1,0,0.0145814,"ng algorithm is adopted from bilingual word embedding mapping (Xing et al., 2015). Our cross-lingual encoder (Section 3.3) is inspired by cross-lingual sentence embedding algorithms using NMT (Schwenk and Douze, 2017; Schwenk, 2018). Transfer learning was first introduced to NMT by Zoph et al. (2016), where only the source language is switched before/after the transfer. Nguyen and Chiang (2017) and Kocmi and Bojar (2018) use shared subword vocabularies to work 2. Pivot-based synthetic parallel data. We may translate the pivot side of given pivottarget parallel data using a pivot→source model (Bertoldi et al., 2008), or the other way around translating source-pivot data using a pivot→target model (De Gispert and Marino, 2006). For NMT, the former is extended by Zheng et al. (2017) to compute the expectation over synthetic source sentences. The latter is also called teacher-student approach (Chen et al., 2017), where the pivot→target model (teacher) produces target hypotheses for training the source→target model (student). 3. Pivot-based model training. In phrasebased MT, there have been many efforts to combine phrase/word level features of source-pivot and pivot-target into 867 Pre-train Final Model Pivo"
D19-1080,P17-1176,0,0.0765059,"where only the source language is switched before/after the transfer. Nguyen and Chiang (2017) and Kocmi and Bojar (2018) use shared subword vocabularies to work 2. Pivot-based synthetic parallel data. We may translate the pivot side of given pivottarget parallel data using a pivot→source model (Bertoldi et al., 2008), or the other way around translating source-pivot data using a pivot→target model (De Gispert and Marino, 2006). For NMT, the former is extended by Zheng et al. (2017) to compute the expectation over synthetic source sentences. The latter is also called teacher-student approach (Chen et al., 2017), where the pivot→target model (teacher) produces target hypotheses for training the source→target model (student). 3. Pivot-based model training. In phrasebased MT, there have been many efforts to combine phrase/word level features of source-pivot and pivot-target into 867 Pre-train Final Model Pivot Decoder Target Decoder Source Encoder Copy Parameters Copy Parameters Source Encoder Pre-train Pre-train 1 Pre-train 2 Target Decoder Pivot Decoder Target Decoder Copy Parameters Target Decoder Pivot Encoder Source Encoder Pivot Encoder (Frozen) Copy Parameters Source Encoder Copy Parameters Fina"
D19-1080,P19-1120,1,0.898025,"Missing"
D19-1080,P17-4012,0,0.0430853,"odel and Training The 6-layer base Transformer architecture (Vaswani et al., 2017) was used for all of our experiments. Batch size was set to 4,096 tokens. Each checkpoint amounts to 10k updates for pre-training and 20k updates for fine-tuning. Each model was optimized with Adam (Kingma and Ba, 2014) with an initial learning rate of 0.0001, which was multiplied by 0.7 whenever perplexity on the validation set was not improved for three checkpoints. When it was not improved for eight checkpoints, we stopped the training. The NMT model training and transfer were done with the O PEN NMT toolkit (Klein et al., 2017). Pivot adapter was trained using the M USE toolkit (Conneau et al., 2018), which was originally developed for bilingual word embeddings but we adjusted for matching sentence representations. Data We used the News Commentary v14 parallel corpus and newstest2008-2010 test sets as the source-target training data for both tasks. The newstest sets were oversampled four times. The German→Czech task was originally limited to unsupervised learning (using only monolingual corpora) in WMT 2019, but we relaxed this constraint by the available parallel data. We used newstest2011 as a validation set and n"
D19-1080,I11-1154,0,0.0344258,"Missing"
D19-1080,W18-6325,0,0.13117,"(Section 3.2) shares the same motivation with the interlingua component of Lu et al. (2018), but is much compact, independent of variable input length, and easy to train offline. The adapter training algorithm is adopted from bilingual word embedding mapping (Xing et al., 2015). Our cross-lingual encoder (Section 3.3) is inspired by cross-lingual sentence embedding algorithms using NMT (Schwenk and Douze, 2017; Schwenk, 2018). Transfer learning was first introduced to NMT by Zoph et al. (2016), where only the source language is switched before/after the transfer. Nguyen and Chiang (2017) and Kocmi and Bojar (2018) use shared subword vocabularies to work 2. Pivot-based synthetic parallel data. We may translate the pivot side of given pivottarget parallel data using a pivot→source model (Bertoldi et al., 2008), or the other way around translating source-pivot data using a pivot→target model (De Gispert and Marino, 2006). For NMT, the former is extended by Zheng et al. (2017) to compute the expectation over synthetic source sentences. The latter is also called teacher-student approach (Chen et al., 2017), where the pivot→target model (teacher) produces target hypotheses for training the source→target mode"
D19-1080,D18-1045,0,0.0493626,"Missing"
D19-1080,W18-6309,0,0.0738123,"tural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 866–876, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics a source→target system (Utiyama and Isahara, 2007; Wu and Wang, 2007; Bakhshaei et al., 2010; Zahabi et al., 2013; Zhu et al., 2014; Miura et al., 2015). In NMT, Cheng et al. (2017) jointly train for three translation directions of source-pivot-target by sharing network components, where Ren et al. (2018) use the expectation-maximization algorithm with the target sentence as a latent variable. Lu et al. (2018) deploy intermediate recurrent layers which are common for multiple encoders and decoders, while Johnson et al. (2017) share all components of a single multilingual model. Both methods train the model for language pairs involving English but enable zero-shot translation for unseen non-English language pairs. For this, Ha et al. (2017) encode the target language as an additional embedding and filter out non-target tokens in the output. Lakew et al. (2017) combine the multilingual training with synthetic data generation to improve the zero-shot performance iteratively, where Sestorain et al. (20"
D19-1080,D16-1026,0,0.0479785,"Missing"
D19-1080,W19-5330,0,0.048134,"Missing"
D19-1080,N16-1162,0,0.0221518,"ivot language in low-resource/zeroresource MT. They can be divided into three categories: 1. Pivot translation (pivoting). The most naive approach is reusing (already trained) source→pivot and pivot→target models directly, decoding twice via the pivot language (Kauers et al., 2002; De Gispert and Marino, 2006). One can keep N -best hypotheses in the pivot language to reduce the prediction bias (Utiyama and Isahara, 2007) and improve the final translation by system combination (Costa-Juss`a et al., 2011), which however increases the translation time even more. In multilingual NMT, Firat et al. (2016) modify the second translation step (pivot→target) to use source and pivot language sentences together as the input. Our work is based on transfer learning (Zoph et al., 2016) and belongs to the third category: model training. On the contrary to the multilingual joint training, we suggest two distinct steps: pretraining (with source-pivot and pivot-target data) and fine-tuning (with source-target data). With our proposed methods, we prevent the model from losing its capacity to other languages while utilizing the information from related language pairs well, as shown in the experiments (Sectio"
D19-1080,P15-2094,0,0.0199207,"ta condition, we consistently outperform strong baselines, e.g., multilingual, pivoting, or teacher-student, showing the universal effectiveness of our transfer learning schemes. Equal contribution. 866 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 866–876, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics a source→target system (Utiyama and Isahara, 2007; Wu and Wang, 2007; Bakhshaei et al., 2010; Zahabi et al., 2013; Zhu et al., 2014; Miura et al., 2015). In NMT, Cheng et al. (2017) jointly train for three translation directions of source-pivot-target by sharing network components, where Ren et al. (2018) use the expectation-maximization algorithm with the target sentence as a latent variable. Lu et al. (2018) deploy intermediate recurrent layers which are common for multiple encoders and decoders, while Johnson et al. (2017) share all components of a single multilingual model. Both methods train the model for language pairs involving English but enable zero-shot translation for unseen non-English language pairs. For this, Ha et al. (2017) en"
D19-1080,Q17-1024,0,0.0835146,"Missing"
D19-1080,I17-2050,0,0.0775749,"Section 4). Our pivot adapter (Section 3.2) shares the same motivation with the interlingua component of Lu et al. (2018), but is much compact, independent of variable input length, and easy to train offline. The adapter training algorithm is adopted from bilingual word embedding mapping (Xing et al., 2015). Our cross-lingual encoder (Section 3.3) is inspired by cross-lingual sentence embedding algorithms using NMT (Schwenk and Douze, 2017; Schwenk, 2018). Transfer learning was first introduced to NMT by Zoph et al. (2016), where only the source language is switched before/after the transfer. Nguyen and Chiang (2017) and Kocmi and Bojar (2018) use shared subword vocabularies to work 2. Pivot-based synthetic parallel data. We may translate the pivot side of given pivottarget parallel data using a pivot→source model (Bertoldi et al., 2008), or the other way around translating source-pivot data using a pivot→target model (De Gispert and Marino, 2006). For NMT, the former is extended by Zheng et al. (2017) to compute the expectation over synthetic source sentences. The latter is also called teacher-student approach (Chen et al., 2017), where the pivot→target model (teacher) produces target hypotheses for trai"
D19-1080,P18-1006,0,0.019865,"sfer learning schemes. Equal contribution. 866 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 866–876, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics a source→target system (Utiyama and Isahara, 2007; Wu and Wang, 2007; Bakhshaei et al., 2010; Zahabi et al., 2013; Zhu et al., 2014; Miura et al., 2015). In NMT, Cheng et al. (2017) jointly train for three translation directions of source-pivot-target by sharing network components, where Ren et al. (2018) use the expectation-maximization algorithm with the target sentence as a latent variable. Lu et al. (2018) deploy intermediate recurrent layers which are common for multiple encoders and decoders, while Johnson et al. (2017) share all components of a single multilingual model. Both methods train the model for language pairs involving English but enable zero-shot translation for unseen non-English language pairs. For this, Ha et al. (2017) encode the target language as an additional embedding and filter out non-target tokens in the output. Lakew et al. (2017) combine the multilingual training"
D19-1080,P13-2057,1,0.808612,"esource) • None (zero-shot) For each data condition, we consistently outperform strong baselines, e.g., multilingual, pivoting, or teacher-student, showing the universal effectiveness of our transfer learning schemes. Equal contribution. 866 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 866–876, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics a source→target system (Utiyama and Isahara, 2007; Wu and Wang, 2007; Bakhshaei et al., 2010; Zahabi et al., 2013; Zhu et al., 2014; Miura et al., 2015). In NMT, Cheng et al. (2017) jointly train for three translation directions of source-pivot-target by sharing network components, where Ren et al. (2018) use the expectation-maximization algorithm with the target sentence as a latent variable. Lu et al. (2018) deploy intermediate recurrent layers which are common for multiple encoders and decoders, while Johnson et al. (2017) share all components of a single multilingual model. Both methods train the model for language pairs involving English but enable zero-shot translation for unseen non-English langua"
D19-1080,P18-2037,0,0.0171481,"event the model from losing its capacity to other languages while utilizing the information from related language pairs well, as shown in the experiments (Section 4). Our pivot adapter (Section 3.2) shares the same motivation with the interlingua component of Lu et al. (2018), but is much compact, independent of variable input length, and easy to train offline. The adapter training algorithm is adopted from bilingual word embedding mapping (Xing et al., 2015). Our cross-lingual encoder (Section 3.3) is inspired by cross-lingual sentence embedding algorithms using NMT (Schwenk and Douze, 2017; Schwenk, 2018). Transfer learning was first introduced to NMT by Zoph et al. (2016), where only the source language is switched before/after the transfer. Nguyen and Chiang (2017) and Kocmi and Bojar (2018) use shared subword vocabularies to work 2. Pivot-based synthetic parallel data. We may translate the pivot side of given pivottarget parallel data using a pivot→source model (Bertoldi et al., 2008), or the other way around translating source-pivot data using a pivot→target model (De Gispert and Marino, 2006). For NMT, the former is extended by Zheng et al. (2017) to compute the expectation over synthetic"
D19-1080,W17-2619,0,0.0206206,"r proposed methods, we prevent the model from losing its capacity to other languages while utilizing the information from related language pairs well, as shown in the experiments (Section 4). Our pivot adapter (Section 3.2) shares the same motivation with the interlingua component of Lu et al. (2018), but is much compact, independent of variable input length, and easy to train offline. The adapter training algorithm is adopted from bilingual word embedding mapping (Xing et al., 2015). Our cross-lingual encoder (Section 3.3) is inspired by cross-lingual sentence embedding algorithms using NMT (Schwenk and Douze, 2017; Schwenk, 2018). Transfer learning was first introduced to NMT by Zoph et al. (2016), where only the source language is switched before/after the transfer. Nguyen and Chiang (2017) and Kocmi and Bojar (2018) use shared subword vocabularies to work 2. Pivot-based synthetic parallel data. We may translate the pivot side of given pivottarget parallel data using a pivot→source model (Bertoldi et al., 2008), or the other way around translating source-pivot data using a pivot→target model (De Gispert and Marino, 2006). For NMT, the former is extended by Zheng et al. (2017) to compute the expectatio"
D19-1080,D14-1174,0,0.0190445,"-shot) For each data condition, we consistently outperform strong baselines, e.g., multilingual, pivoting, or teacher-student, showing the universal effectiveness of our transfer learning schemes. Equal contribution. 866 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 866–876, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics a source→target system (Utiyama and Isahara, 2007; Wu and Wang, 2007; Bakhshaei et al., 2010; Zahabi et al., 2013; Zhu et al., 2014; Miura et al., 2015). In NMT, Cheng et al. (2017) jointly train for three translation directions of source-pivot-target by sharing network components, where Ren et al. (2018) use the expectation-maximization algorithm with the target sentence as a latent variable. Lu et al. (2018) deploy intermediate recurrent layers which are common for multiple encoders and decoders, while Johnson et al. (2017) share all components of a single multilingual model. Both methods train the model for language pairs involving English but enable zero-shot translation for unseen non-English language pairs. For this"
D19-1080,P16-1162,0,0.21095,"Missing"
D19-1080,D16-1163,0,0.0646029,"ady trained) source→pivot and pivot→target models directly, decoding twice via the pivot language (Kauers et al., 2002; De Gispert and Marino, 2006). One can keep N -best hypotheses in the pivot language to reduce the prediction bias (Utiyama and Isahara, 2007) and improve the final translation by system combination (Costa-Juss`a et al., 2011), which however increases the translation time even more. In multilingual NMT, Firat et al. (2016) modify the second translation step (pivot→target) to use source and pivot language sentences together as the input. Our work is based on transfer learning (Zoph et al., 2016) and belongs to the third category: model training. On the contrary to the multilingual joint training, we suggest two distinct steps: pretraining (with source-pivot and pivot-target data) and fine-tuning (with source-target data). With our proposed methods, we prevent the model from losing its capacity to other languages while utilizing the information from related language pairs well, as shown in the experiments (Section 4). Our pivot adapter (Section 3.2) shares the same motivation with the interlingua component of Lu et al. (2018), but is much compact, independent of variable input length,"
D19-1080,N07-1061,0,0.583488,"the pre-trained decoder with the outputs of the pre-trained encoder. Introduction • Cross-lingual encoder pre-training with autoencoding of the pivot language. Machine translation (MT) research is biased towards language pairs including English due to the ease of collecting parallel corpora. Translation between non-English languages, e.g., French→German, is usually done with pivoting through English, i.e., translating French (source) input to English (pivot) first with a French→English model which is later translated to German (target) with a English→German model (De Gispert and Marino, 2006; Utiyama and Isahara, 2007; Wu and Wang, 2007). However, pivoting requires doubled decoding time and the translation errors are propagated or expanded via the two-step process. Therefore, it is more beneficial to build a single source→target model directly for both efficiency and adequacy. Since non-English language ∗ Our methods are evaluated in two non-English language pairs of WMT 2019 news translation tasks: high-resource (French→German) and lowresource (German→Czech). We show that NMT models pre-trained with our methods are highly effective in various data conditions, when fine-tuned for source→target with: • Real"
D19-1080,P07-1108,0,0.456952,"h the outputs of the pre-trained encoder. Introduction • Cross-lingual encoder pre-training with autoencoding of the pivot language. Machine translation (MT) research is biased towards language pairs including English due to the ease of collecting parallel corpora. Translation between non-English languages, e.g., French→German, is usually done with pivoting through English, i.e., translating French (source) input to English (pivot) first with a French→English model which is later translated to German (target) with a English→German model (De Gispert and Marino, 2006; Utiyama and Isahara, 2007; Wu and Wang, 2007). However, pivoting requires doubled decoding time and the translation errors are propagated or expanded via the two-step process. Therefore, it is more beneficial to build a single source→target model directly for both efficiency and adequacy. Since non-English language ∗ Our methods are evaluated in two non-English language pairs of WMT 2019 news translation tasks: high-resource (French→German) and lowresource (German→Czech). We show that NMT models pre-trained with our methods are highly effective in various data conditions, when fine-tuned for source→target with: • Real parallel corpus • P"
D19-1080,N15-1104,0,0.0611583,"Missing"
D19-1133,P02-1040,0,\N,Missing
D19-1133,D17-1319,0,\N,Missing
D19-1133,D18-2012,0,\N,Missing
D19-1133,W18-6478,0,\N,Missing
D19-1133,W18-6475,0,\N,Missing
D19-1133,W18-6453,0,\N,Missing
D19-1133,E17-2068,0,\N,Missing
D19-1133,W19-5301,0,\N,Missing
D19-1133,P18-4022,1,\N,Missing
D19-1133,W18-6479,0,\N,Missing
D19-1133,W18-6487,1,\N,Missing
D19-1133,W18-6472,0,\N,Missing
D19-1133,W18-6484,0,\N,Missing
D19-1133,W18-6482,0,\N,Missing
D19-6503,C18-1139,0,0.0247555,"correctly foresaw absence stronger fiscal stimulus forthcoming either States recovery Great Recession 2008 slow Retain named entities recent years Europe the United States the Great Recession 2008 Retain specific POS years I foresaw the absence stimulus was forthcoming either Europe or the United States recovery the Great Recession 2008 would be Table 1: Examples for filtering of words in the context (News Commentary v14 English→German). are domain-specific or containing gender information. We empirically found that n = 150 works reasonably well. For the last two methods, we use the F LAIR2 (Akbik et al., 2018) toolkit. We exclude the tags that are irrelevant to syntax/semantics of the current sentence. The detailed lists of retained tags can be found in the appendix. The filtering is performed on word level in the preprocessing. When a sentence is completely pruned, we use a special token to denote an empty sentence (e.g. EMPTY ). Table 1 gives examples of the filtering. We can observe that the original sentence is shortened greatly by removing redundant tokens, but the topic information and the important subjects still remain. 3 S OCKEYE (Hieber et al., 2018). We used Adam optimizer (Kingma and Ba"
D19-6503,W17-3204,0,0.0324567,"est method to include context in NMT is to just modify the input, i.e. concatenate surrounding sentences to the current one and put the extended sentence in a normal sentence-to-sentence model (Tiedemann and Scherrer, 2017; Agrawal et al., 2018). A special token is inserted between context and current sentences to mark sentence boundaries (e.g. BREAK ). Figure 1 depicts this approach. Here, a single encoder processes the context and current sentences together as one long input. This requires no change in the model architecture but worsens a fundamental problem of NMT: translating long inputs (Koehn and Knowles, 2017). Apart from the data scarcity of a higher-dimensional input space, it is difficult to optimize the attention component to the long spans (Sukhbaatar et al., 2019). p ei|ei−1 1 , fcur , fpre Integration Outside the Decoder The first method combines encoder representation of all input sentences before being fed to the decoder (Maruf and Haffari, 2018; Voita et al., 2018; Miculicich et al., 2018; Zhang et al., 2018; Maruf et al., 2019). It attends from the representations of the current sentence (Hcur ) to those of the previous ¯ Afterwards, a linear sentence (Hpre ), yielding H. interpolation w"
D19-6503,C18-1051,0,0.0494335,"nts may be switched. To block signals of potentially unimportant context information, a gating mechanism can be employed between the regular and context attention outputs like Section 2.2.1. p ei|ei−1 1 , fcur , fpre  Decoder ei−1 1 Figure 3: Multi-encoder approach integrating context inside the decoder with sequential attentions. • Remove stopwords using a pre-defined list1 • Remove n ∈ N most frequent words Parallel Attentions Figure 4 shows the case when performing the two attention operations in parallel and combining them with a gating afterwards (Jean et al., 2017; Cao and Xiong, 2018; Kuang and Xiong, 2018; Bawden et al., 2018; Stojanovski and Fraser, 2018). This method relates document-level context to the target history independently of the current source sentence, and lets the decoding computation faster. • Retain only named entities • Retain only the words with specific parts-ofspeech (POS) tags The first method has the same motivation as Kuang et al. (2018) to ignore function words. The second method aims to keep infrequent words that 1 26 https://github.com/explosion/spaCy Original source in recent years, I correctly foresaw that, in the absence of stronger fiscal stimulus (which was not"
D19-6503,C18-1050,0,0.0612588,"defined list1 • Remove n ∈ N most frequent words Parallel Attentions Figure 4 shows the case when performing the two attention operations in parallel and combining them with a gating afterwards (Jean et al., 2017; Cao and Xiong, 2018; Kuang and Xiong, 2018; Bawden et al., 2018; Stojanovski and Fraser, 2018). This method relates document-level context to the target history independently of the current source sentence, and lets the decoding computation faster. • Retain only named entities • Retain only the words with specific parts-ofspeech (POS) tags The first method has the same motivation as Kuang et al. (2018) to ignore function words. The second method aims to keep infrequent words that 1 26 https://github.com/explosion/spaCy Original source in recent years, I correctly foresaw that, in the absence of stronger fiscal stimulus (which was not forthcoming in either Europe or the United States), recovery from the Great Recession of 2008 would be slow. Remove stopwords recent years, I correctly foresaw absence stronger fiscal stimulus (forthcoming Europe United States), recovery Great Recession 2008 slow. Remove most frequent words recent correctly foresaw absence stronger fiscal stimulus forthcoming e"
D19-6503,N18-1118,0,0.308314,"(NMT) (Bahdanau et al., 2015; Vaswani et al., 2017) has been originally developed to work sentence by sentence. Recently, it has been claimed that sentence-level NMT generates document-level errors, e.g. wrong coreference of pronouns/articles or inconsistent translations throughout a document (Guillou et al., 2018; L¨aubli et al., 2018). A lot of research addresses these problems by feeding surrounding context sentences as additional inputs to an NMT model. Modeling of the context is usually done with fully-fledged NMT encoders with extensions to consider complex relations between sentences (Bawden et al., 2018; Voita et al., 2018; Zhang et al., 2018; Miculicich et al., 2018; Maruf et al., 2019). Despite the high overhead in modeling, translation metric scores (e.g. B LEU) are often only marginally improved, leaving the evaluation to artificial tests targeted for pronoun resolution (Jean et al., 2017; Tiedemann and Scherrer, 2017; Bawden et al., 2018; Voita To answer these questions, we conduct an extensive qualitative analysis on non-targeted test sets. According to the analysis, we use only the important parts of the surrounding sentences to facilitate the integration of long-range contexts. We al"
D19-6503,D18-1512,0,0.158615,"Missing"
D19-6503,D18-1340,0,0.0236329,"the attention components may be switched. To block signals of potentially unimportant context information, a gating mechanism can be employed between the regular and context attention outputs like Section 2.2.1. p ei|ei−1 1 , fcur , fpre  Decoder ei−1 1 Figure 3: Multi-encoder approach integrating context inside the decoder with sequential attentions. • Remove stopwords using a pre-defined list1 • Remove n ∈ N most frequent words Parallel Attentions Figure 4 shows the case when performing the two attention operations in parallel and combining them with a gating afterwards (Jean et al., 2017; Cao and Xiong, 2018; Kuang and Xiong, 2018; Bawden et al., 2018; Stojanovski and Fraser, 2018). This method relates document-level context to the target history independently of the current source sentence, and lets the decoding computation faster. • Retain only named entities • Retain only the words with specific parts-ofspeech (POS) tags The first method has the same motivation as Kuang et al. (2018) to ignore function words. The second method aims to keep infrequent words that 1 26 https://github.com/explosion/spaCy Original source in recent years, I correctly foresaw that, in the absence of stronger fiscal s"
D19-6503,P18-1118,0,0.156777,"ng documentlevel approaches for NMT and describe our strategies to filter out uninteresting words in the context 24 Proceedings of the Fourth Workshop on Discourse in Machine Translation (DiscoMT 2019), pages 24–34 c Hong Kong, China, November 3, 2019. 2019 Association for Computational Linguistics 2.2 input. We illustrate with an example of including one previous source sentence as the documentlevel context, which can be easily generalized also to other context inputs such as target hypotheses (Agrawal et al., 2018; Bawden et al., 2018; Voita et al., 2019) or decoder states (Tu et al., 2018; Maruf and Haffari, 2018; Miculicich et al., 2018). For the notations, we denote a source sentence by f and its encoded representations by H. A subscript distinguishes the previous (pre) and current (cur) sentences. ei indicates a target token to be predicted at position i, and ei−1 are already pre1 dicted tokens in previous positions. Z denotes encoded representations of a partial target sequence. 2.1 Multi-Encoder Approach Alternatively, multi-encoder approaches encode each additional sentence separately. The model learns representations solely of the context sentences which are then integrated into the baseline mo"
D19-6503,W17-4702,0,0.0381908,"evel NMT, the English word “said” is translated to a correct conjugation of “sagen” (= say) for the third person noun “der Pr¨asident” (= the President). This can be explained by the high attention energy on “Trump” (Figure 7a) in the context sentence. Another interpretable cause is topic-aware lexical choice (Table 6b). The document-level model actively attends to “seized” and “cocaine” in the context sentence (Figure 7b), and does not miss the source word “raids” in the translation (“Razzien”). When it corrects the translation of polysemous words, it is related to word sense disambiguation (Gonzales et al., 2017; Marvin and Koehn, 2018; Pu et al., 2018). This category includes also a coherence of text style in the translation outputs, depending on the context topic. 700 600 Number of Sentences 500 400 300 200 100 0 0.20 0.25 0.30 0.35 0.40 Avg. Gate Activation 0.45 0.50 Figure 6: Gating activation for all T ER-improved cases of the English→German task, averaged over all layers and target positions. 30 Previous src inside the White House, Trump addressed Sikorsky representatives, joking with the media about his own fleet of company products. “I know Sikorsky very well,” the President said, “I have thr"
D19-6503,N19-1313,0,0.34384,"work sentence by sentence. Recently, it has been claimed that sentence-level NMT generates document-level errors, e.g. wrong coreference of pronouns/articles or inconsistent translations throughout a document (Guillou et al., 2018; L¨aubli et al., 2018). A lot of research addresses these problems by feeding surrounding context sentences as additional inputs to an NMT model. Modeling of the context is usually done with fully-fledged NMT encoders with extensions to consider complex relations between sentences (Bawden et al., 2018; Voita et al., 2018; Zhang et al., 2018; Miculicich et al., 2018; Maruf et al., 2019). Despite the high overhead in modeling, translation metric scores (e.g. B LEU) are often only marginally improved, leaving the evaluation to artificial tests targeted for pronoun resolution (Jean et al., 2017; Tiedemann and Scherrer, 2017; Bawden et al., 2018; Voita To answer these questions, we conduct an extensive qualitative analysis on non-targeted test sets. According to the analysis, we use only the important parts of the surrounding sentences to facilitate the integration of long-range contexts. We also compare different architectures for the context modeling and check sufficient model"
D19-6503,W18-6435,0,0.175008,"Missing"
D19-6503,W18-1812,0,0.0209385,"ord “said” is translated to a correct conjugation of “sagen” (= say) for the third person noun “der Pr¨asident” (= the President). This can be explained by the high attention energy on “Trump” (Figure 7a) in the context sentence. Another interpretable cause is topic-aware lexical choice (Table 6b). The document-level model actively attends to “seized” and “cocaine” in the context sentence (Figure 7b), and does not miss the source word “raids” in the translation (“Razzien”). When it corrects the translation of polysemous words, it is related to word sense disambiguation (Gonzales et al., 2017; Marvin and Koehn, 2018; Pu et al., 2018). This category includes also a coherence of text style in the translation outputs, depending on the context topic. 700 600 Number of Sentences 500 400 300 200 100 0 0.20 0.25 0.30 0.35 0.40 Avg. Gate Activation 0.45 0.50 Figure 6: Gating activation for all T ER-improved cases of the English→German task, averaged over all layers and target positions. 30 Previous src inside the White House, Trump addressed Sikorsky representatives, joking with the media about his own fleet of company products. “I know Sikorsky very well,” the President said, “I have three of them.” Current src"
D19-6503,W18-1820,0,0.0611328,"Missing"
D19-6503,D18-1325,0,0.438625,"originally developed to work sentence by sentence. Recently, it has been claimed that sentence-level NMT generates document-level errors, e.g. wrong coreference of pronouns/articles or inconsistent translations throughout a document (Guillou et al., 2018; L¨aubli et al., 2018). A lot of research addresses these problems by feeding surrounding context sentences as additional inputs to an NMT model. Modeling of the context is usually done with fully-fledged NMT encoders with extensions to consider complex relations between sentences (Bawden et al., 2018; Voita et al., 2018; Zhang et al., 2018; Miculicich et al., 2018; Maruf et al., 2019). Despite the high overhead in modeling, translation metric scores (e.g. B LEU) are often only marginally improved, leaving the evaluation to artificial tests targeted for pronoun resolution (Jean et al., 2017; Tiedemann and Scherrer, 2017; Bawden et al., 2018; Voita To answer these questions, we conduct an extensive qualitative analysis on non-targeted test sets. According to the analysis, we use only the important parts of the surrounding sentences to facilitate the integration of long-range contexts. We also compare different architectures for the context modeling and c"
D19-6503,Q18-1044,0,0.0271652,"to a correct conjugation of “sagen” (= say) for the third person noun “der Pr¨asident” (= the President). This can be explained by the high attention energy on “Trump” (Figure 7a) in the context sentence. Another interpretable cause is topic-aware lexical choice (Table 6b). The document-level model actively attends to “seized” and “cocaine” in the context sentence (Figure 7b), and does not miss the source word “raids” in the translation (“Razzien”). When it corrects the translation of polysemous words, it is related to word sense disambiguation (Gonzales et al., 2017; Marvin and Koehn, 2018; Pu et al., 2018). This category includes also a coherence of text style in the translation outputs, depending on the context topic. 700 600 Number of Sentences 500 400 300 200 100 0 0.20 0.25 0.30 0.35 0.40 Avg. Gate Activation 0.45 0.50 Figure 6: Gating activation for all T ER-improved cases of the English→German task, averaged over all layers and target positions. 30 Previous src inside the White House, Trump addressed Sikorsky representatives, joking with the media about his own fleet of company products. “I know Sikorsky very well,” the President said, “I have three of them.” Current src Reference Sent-le"
D19-6503,W19-5321,0,0.084016,"Missing"
D19-6503,W18-6306,0,0.01944,"entially unimportant context information, a gating mechanism can be employed between the regular and context attention outputs like Section 2.2.1. p ei|ei−1 1 , fcur , fpre  Decoder ei−1 1 Figure 3: Multi-encoder approach integrating context inside the decoder with sequential attentions. • Remove stopwords using a pre-defined list1 • Remove n ∈ N most frequent words Parallel Attentions Figure 4 shows the case when performing the two attention operations in parallel and combining them with a gating afterwards (Jean et al., 2017; Cao and Xiong, 2018; Kuang and Xiong, 2018; Bawden et al., 2018; Stojanovski and Fraser, 2018). This method relates document-level context to the target history independently of the current source sentence, and lets the decoding computation faster. • Retain only named entities • Retain only the words with specific parts-ofspeech (POS) tags The first method has the same motivation as Kuang et al. (2018) to ignore function words. The second method aims to keep infrequent words that 1 26 https://github.com/explosion/spaCy Original source in recent years, I correctly foresaw that, in the absence of stronger fiscal stimulus (which was not forthcoming in either Europe or the United States),"
D19-6503,P19-1032,0,0.0249058,"al sentence-to-sentence model (Tiedemann and Scherrer, 2017; Agrawal et al., 2018). A special token is inserted between context and current sentences to mark sentence boundaries (e.g. BREAK ). Figure 1 depicts this approach. Here, a single encoder processes the context and current sentences together as one long input. This requires no change in the model architecture but worsens a fundamental problem of NMT: translating long inputs (Koehn and Knowles, 2017). Apart from the data scarcity of a higher-dimensional input space, it is difficult to optimize the attention component to the long spans (Sukhbaatar et al., 2019). p ei|ei−1 1 , fcur , fpre Integration Outside the Decoder The first method combines encoder representation of all input sentences before being fed to the decoder (Maruf and Haffari, 2018; Voita et al., 2018; Miculicich et al., 2018; Zhang et al., 2018; Maruf et al., 2019). It attends from the representations of the current sentence (Hcur ) to those of the previous ¯ Afterwards, a linear sentence (Hpre ), yielding H. interpolation with gating is applied: ¯ + (1 − g)Hcur gH (1)    ¯ Hcur + bg is gating actiwhere g = σ Wg H; vation and Wg , bg are learnable parameters. This type of integrati"
D19-6503,W17-4811,0,0.082685,"; L¨aubli et al., 2018). A lot of research addresses these problems by feeding surrounding context sentences as additional inputs to an NMT model. Modeling of the context is usually done with fully-fledged NMT encoders with extensions to consider complex relations between sentences (Bawden et al., 2018; Voita et al., 2018; Zhang et al., 2018; Miculicich et al., 2018; Maruf et al., 2019). Despite the high overhead in modeling, translation metric scores (e.g. B LEU) are often only marginally improved, leaving the evaluation to artificial tests targeted for pronoun resolution (Jean et al., 2017; Tiedemann and Scherrer, 2017; Bawden et al., 2018; Voita To answer these questions, we conduct an extensive qualitative analysis on non-targeted test sets. According to the analysis, we use only the important parts of the surrounding sentences to facilitate the integration of long-range contexts. We also compare different architectures for the context modeling and check sufficient model complexity for a significant improvement. Our results show that the improvement in B LEU is mostly from a non-linguistic factor: regularization by reserving parameters for context inputs. We also verify that very long context is indeed no"
D19-6503,Q18-1029,0,0.318699,"review the existing documentlevel approaches for NMT and describe our strategies to filter out uninteresting words in the context 24 Proceedings of the Fourth Workshop on Discourse in Machine Translation (DiscoMT 2019), pages 24–34 c Hong Kong, China, November 3, 2019. 2019 Association for Computational Linguistics 2.2 input. We illustrate with an example of including one previous source sentence as the documentlevel context, which can be easily generalized also to other context inputs such as target hypotheses (Agrawal et al., 2018; Bawden et al., 2018; Voita et al., 2019) or decoder states (Tu et al., 2018; Maruf and Haffari, 2018; Miculicich et al., 2018). For the notations, we denote a source sentence by f and its encoded representations by H. A subscript distinguishes the previous (pre) and current (cur) sentences. ei indicates a target token to be predicted at position i, and ei−1 are already pre1 dicted tokens in previous positions. Z denotes encoded representations of a partial target sequence. 2.1 Multi-Encoder Approach Alternatively, multi-encoder approaches encode each additional sentence separately. The model learns representations solely of the context sentences which are then integr"
D19-6503,P19-1116,0,0.136213,"Missing"
D19-6503,P18-1117,0,0.127722,"l., 2015; Vaswani et al., 2017) has been originally developed to work sentence by sentence. Recently, it has been claimed that sentence-level NMT generates document-level errors, e.g. wrong coreference of pronouns/articles or inconsistent translations throughout a document (Guillou et al., 2018; L¨aubli et al., 2018). A lot of research addresses these problems by feeding surrounding context sentences as additional inputs to an NMT model. Modeling of the context is usually done with fully-fledged NMT encoders with extensions to consider complex relations between sentences (Bawden et al., 2018; Voita et al., 2018; Zhang et al., 2018; Miculicich et al., 2018; Maruf et al., 2019). Despite the high overhead in modeling, translation metric scores (e.g. B LEU) are often only marginally improved, leaving the evaluation to artificial tests targeted for pronoun resolution (Jean et al., 2017; Tiedemann and Scherrer, 2017; Bawden et al., 2018; Voita To answer these questions, we conduct an extensive qualitative analysis on non-targeted test sets. According to the analysis, we use only the important parts of the surrounding sentences to facilitate the integration of long-range contexts. We also compare different"
D19-6503,D18-1049,0,0.178938,"Missing"
D19-6503,P16-1162,0,\N,Missing
dreuw-etal-2010-signspeak,2005.mtsummit-ebmt.14,0,\N,Missing
dreuw-etal-2010-signspeak,dreuw-etal-2008-benchmark,1,\N,Missing
dreuw-etal-2010-signspeak,bungeroth-etal-2008-atis,1,\N,Missing
dreuw-etal-2010-signspeak,2006.eamt-1.21,1,\N,Missing
dreuw-etal-2010-signspeak,2006.iwslt-evaluation.15,1,\N,Missing
E03-1007,J96-1002,0,0.0761314,"ent Catalan Sentence Spanish Sentence did you say the eighteenth ? you did say the eighteenth ? you_did say the eighteenth ? has dit el divuit ? i, has dicho el dieciocho ? ing operation. This makes it impossible to translate the verb itself, because it is then unknown to the system. The same holds for combinations of pronouns and verbs that are unseen in training, e. g. the training corpus contains the bigram &apos;I went&apos;, but not the one &apos;she went&apos;. In order to overcome this problem, we train our lexicon model using maximum entropy. 5.1 The Maximum Entropy Approach The maximum entropy approach (Berger et al., 1996) presents a powerful framework for the combination of several knowledge sources. This principle recommends to choose the distribution which preserves as much uncertainty as possible in terms of maximizing the entropy. The distribution is required to satisfy constraints, which represent facts known from the data. These constraints are expressed on the basis of feature functions h u,(s,t), 350 where (s, t) is a pair of source and target word. The lexicon probability of a source word given the target word has the following functional form P (s 1 t) Z(t) exP L_, A m h„,(s,t) Y.‘ with the normaliza"
E03-1007,1992.tmi-1.8,0,0.0656806,"hen, we introduce the transformations that we apply to the less inflected language of the two under consideration (namely English) in Section 4. After describing the maximum entropy approach and the training procedure we use for the statistical lexicon in Section 5, we present results on the trilingual LC-STAR corpus in Section 6. Then, we conclude and present ideas about future work in Section 7. 347 2 Related Work Publications dealing with the integration of linguistic information into the process of statistical machine translation are rather few although this had already been suggested in (Brown et al., 1992). (NieBen and Ney, 2001b) introduce hierarchical lexicon models including baseform and POS information for translation from German into English. Information contained in the German entries that are not relevant for the generation of the English translation are omitted. Unlike this, we investigate methods for enriching English with knowledge to help selecting the correct fullform in a morphologically richer language. (Niefien and Ney, 2001a) propose reordering operations for the language pair German—English that help SMT by harmonizing word order between source and target. The question inversio"
E03-1007,J93-2003,0,0.00499747,"Missing"
E03-1007,P01-1027,1,0.850187,"that are not relevant for the generation of the English translation are omitted. Unlike this, we investigate methods for enriching English with knowledge to help selecting the correct fullform in a morphologically richer language. (Niefien and Ney, 2001a) propose reordering operations for the language pair German—English that help SMT by harmonizing word order between source and target. The question inversion we apply was inspired by this; nevertheless, we do not perform a full morpho-syntactic analysis, but make use only of POS information which can be obtained from freely available tools. (Garcia-Varea et al., 2001) apply a maximum entropy approach for training the statistical lexicon, but do not take any linguistic information into account. The use of POS information for improving statistical alignment quality is described in (Toutanova et al., 2002), but no translation results are presented. 3 Statistical Machine Translation The goal of machine translation is the translation of an input string Si,. . . , s j in the source language into a target language string ti tI. We choose the string that has maximal probability given the source string, Pr(tils1). Applying Bayes&apos; decision rule yields the following"
E03-1007,P01-1030,0,0.0405992,"Missing"
E03-1007,2001.mtsummit-papers.45,1,0.857719,"transformations that we apply to the less inflected language of the two under consideration (namely English) in Section 4. After describing the maximum entropy approach and the training procedure we use for the statistical lexicon in Section 5, we present results on the trilingual LC-STAR corpus in Section 6. Then, we conclude and present ideas about future work in Section 7. 347 2 Related Work Publications dealing with the integration of linguistic information into the process of statistical machine translation are rather few although this had already been suggested in (Brown et al., 1992). (NieBen and Ney, 2001b) introduce hierarchical lexicon models including baseform and POS information for translation from German into English. Information contained in the German entries that are not relevant for the generation of the English translation are omitted. Unlike this, we investigate methods for enriching English with knowledge to help selecting the correct fullform in a morphologically richer language. (Niefien and Ney, 2001a) propose reordering operations for the language pair German—English that help SMT by harmonizing word order between source and target. The question inversion we apply was inspired"
E03-1007,W01-1407,1,0.884734,"Missing"
E03-1007,W02-1012,0,0.0402907,"d Ney, 2001a) propose reordering operations for the language pair German—English that help SMT by harmonizing word order between source and target. The question inversion we apply was inspired by this; nevertheless, we do not perform a full morpho-syntactic analysis, but make use only of POS information which can be obtained from freely available tools. (Garcia-Varea et al., 2001) apply a maximum entropy approach for training the statistical lexicon, but do not take any linguistic information into account. The use of POS information for improving statistical alignment quality is described in (Toutanova et al., 2002), but no translation results are presented. 3 Statistical Machine Translation The goal of machine translation is the translation of an input string Si,. . . , s j in the source language into a target language string ti tI. We choose the string that has maximal probability given the source string, Pr(tils1). Applying Bayes&apos; decision rule yields the following criterion: arg max Pr(t i s i ) tf = arg max{Pr(t1) • Pr(s1 tf 4)1 (1) Through this decomposition of the probability, we obtain two knowledge sources: the translation and the language model. Those two can be modelled independently of each o"
E03-1007,niessen-etal-2000-evaluation,1,0.875159,"Missing"
E03-1007,2000.eamt-1.5,1,0.653927,"Missing"
E03-1007,W99-0604,1,0.806405,"Missing"
E03-1007,P97-1047,0,0.0450311,"Missing"
E03-1032,J90-2002,0,0.139099,"will present some results. Finally, we will describe the implemented prototype system. 2 Statistical Machine Translation We are given a source language ('French') sentence = f3 . . . ff, which is to be translated into a target language ( 'English') sentence ef = e l ... 6, ... el-. Among all possible target language sentences, we will choose the sentence of unknown length / with the highest probability: = argmax {Pr (ei f )} (1) argmax {Pr (e)) • Pr(fil lef)} (2) The decomposition into two knowledge sources in Eq. 2 is the so-called source-channel approach to statistical machine translation (Brown et al., 1990). It allows an independent modeling of target language model Pr (ef ) and translation model Pr(filef)- The target language model describes the well-formedness of the target language sentence. The translation model links the source language sentence to the target language sentence. The argmax operation denotes the search problem, i.e. the generation of the output sentence in the target language. Here, we maximize over all possible target language sentences. 3 Interactive Machine Translation In a statistical approach, the problem of finding an extension ef+1 of a given prefix 61 can be described"
E03-1032,C96-1067,0,0.600538,"n such an environment, the main goal of the machine translation system is not to produce translations that are understandable for an inexperienced recipient but to support a professional human posteditor. Typically, a better quality of the produced machine translation text yields a reduced post-editing effort. From an application point of view, many additional aspects have to be considered: the user interface, the used formats and the additional support tools such as lexicons, terminological databases or translation memories. The concept of interactive machine translation, first suggested by (Foster et al., 1996), finds a very natural implementation in the framework of statistical machine translation. In interactive machine translation, the basic idea is to provide an environment to a human translator that interactively reacts upon the input as the user writes or corrects the translation. In such an approach, the system suggests an extension of a sentence that the human user either accepts or ignores. An implementation of such a tool was performed in the TransType project (Foster et al., 1996; Foster et al., 1997; Langlais et al., 2000). The user interface of the TransType system combines a machine tr"
E03-1032,1997.mtsummit-papers.1,0,0.757582,"ranslation memories. The concept of interactive machine translation, first suggested by (Foster et al., 1996), finds a very natural implementation in the framework of statistical machine translation. In interactive machine translation, the basic idea is to provide an environment to a human translator that interactively reacts upon the input as the user writes or corrects the translation. In such an approach, the system suggests an extension of a sentence that the human user either accepts or ignores. An implementation of such a tool was performed in the TransType project (Foster et al., 1996; Foster et al., 1997; Langlais et al., 2000). The user interface of the TransType system combines a machine translation system and a text editor into a single application. The human translator types the translation of a given source text. For each prefix of a word, the machine translation system computes the most probable extension of this word and presents this to the user. The human translator either accepts this translation by press387 ing a certain key or ignores the suggestion and continues typing. Rather than single-word predictions, as in the TransType approach, it is preferable that the suggested extensio"
E03-1032,W02-1020,0,0.173018,"n. The server performs the actual translations as well as all time-consuming operations such as computing the extensions. The client includes only the user interface and can therefore run on a small computer. Client and server are connected via Internet or Intranet. There is ongoing research to experimentally study the productivity gain of such a system for professional human translators. 9 Related Work As already mentioned, previous work towards interactive machine translation has been carried out in the TransType project (Foster et al., 1996; Foster et al., 1997; Langlais et al., 2000). In (Foster et al., 2002) a so-called ""user model"" has been introduced to maximize the expected benefit of the human translator. This user model consists of two components. The first component models the benefit of a certain extension. The second component models the acceptance probability of this extension. The user model is used to determine the length of the proposed extension measured in characters. The resulting decision rule is more centered on the human user than the one in Eq. 3. It takes into account, e.g., the time the user needs to read the extension (at least approximatively). In principle, the decision ru"
E03-1032,W00-0507,0,0.482506,"The concept of interactive machine translation, first suggested by (Foster et al., 1996), finds a very natural implementation in the framework of statistical machine translation. In interactive machine translation, the basic idea is to provide an environment to a human translator that interactively reacts upon the input as the user writes or corrects the translation. In such an approach, the system suggests an extension of a sentence that the human user either accepts or ignores. An implementation of such a tool was performed in the TransType project (Foster et al., 1996; Foster et al., 1997; Langlais et al., 2000). The user interface of the TransType system combines a machine translation system and a text editor into a single application. The human translator types the translation of a given source text. For each prefix of a word, the machine translation system computes the most probable extension of this word and presents this to the user. The human translator either accepts this translation by press387 ing a certain key or ignores the suggestion and continues typing. Rather than single-word predictions, as in the TransType approach, it is preferable that the suggested extension consists of multiple w"
E03-1032,W99-0604,1,0.231989,"ciency without an unacceptable amount of search errors. The one we will use usually takes a few seconds per sentence. Hence, we have to perform certain simplifications making the search problem feasible. Our solution is to precompute a subset of possible word sequences. The search in Eq. 3 is then constrained to this set of hypotheses. As data structure for efficiently representing the set of possible word sequences, we use word hypotheses graphs (Ney and Aubert, 1994; Ueffing et al., 2002) . 4 Alignment Templates As specific machine translation method, we use the alignment template approach (Och et al., 1999). The key elements of this approach are the alignment templates, which are pairs of source and target language phrases together with an alignment between the words within the phrases. The advantage of the alignment template approach compared to single word-based statistical translation models is that word context and local changes in word order are explicitly considered. The alignment template model refines the translation probability Pr Cf by introducing two hidden variables z and a fc for the K alignment templates and the alignment of the alignment temnode S (n): plates: Pr(fiilef) = E Pr(af"
E03-1032,W02-1021,1,0.618849,"larger than a fraction of a second is not acceptable. The search algorithms developed so far are not able to achieve this efficiency without an unacceptable amount of search errors. The one we will use usually takes a few seconds per sentence. Hence, we have to perform certain simplifications making the search problem feasible. Our solution is to precompute a subset of possible word sequences. The search in Eq. 3 is then constrained to this set of hypotheses. As data structure for efficiently representing the set of possible word sequences, we use word hypotheses graphs (Ney and Aubert, 1994; Ueffing et al., 2002) . 4 Alignment Templates As specific machine translation method, we use the alignment template approach (Och et al., 1999). The key elements of this approach are the alignment templates, which are pairs of source and target language phrases together with an alignment between the words within the phrases. The advantage of the alignment template approach compared to single word-based statistical translation models is that word context and local changes in word order are explicitly considered. The alignment template model refines the translation probability Pr Cf by introducing two hidden variabl"
E03-1055,J96-1002,0,0.0308739,"ation systems (Zhou et al., 2002). In this paper we present two approaches for analyzing the semantics of natural language inputs and discuss their advantages and drawbacks. The first approach is derived from the field of statistical machine translation (MT) and is based on the source-channel paradigm (Brown et al., 1993). Here, we apply a method called alignment templates (Och et al., 1999). The alternative apich warde gerne von KOln nach MUnchen fahren @want question V V @origin @destination @going Figure 1: Example of a word! concept mapping. proach uses the maximum entropy (ME) framework (Berger et al., 1996). For both frameworks, the objective can be described as follows. Given a natural source sentence fiJ = fj...f./ we choose the formal target language sentence ef = el •••e,...ei with the highest probability among all possible target sentences: argmax { Pr (ej ei fi&apos; ) (1) argmax r(ge,)•pr(ef) Pr (f&apos;) el argmax { Pr(fief) • Pr(ef) • (2) e Using Bayes&apos; theorem, Eq. 1 can be rewritten to Eq. 2, where the denominator can be neglected. The argmax operation denotes the search problem, i.e. the generation of the sequence of formal semantic concepts in the target language. An example is depicted in Fi"
E03-1055,M98-1018,0,0.0382589,"hold K, we only include those features that E p4i(en fTh)} n=1 where u p(Ai )=H 2, , a2 . 7ra exp [ 2A7 m 15 4.3 Search In the test phase, the search is performed using the so called maximum approximation, i.e. the most likely sequence of concepts ef is chosen among all possible sequences ef : Table 1: Training and testing conditions for the TABA corpus. Natural Language Train argmax {Pr(ei fij )} C&apos; argma,x EA rrt h,„,(e -1, fiJ )} . Test rrt=1 Therefore, the time-consuming renormalization in Eq. 5 is not needed during search. We run a Viterbi search to find the highest probability sequence (Borthwick et al., 1998). 5 Results Experiments were performed on the German inhouse Philips TABA corpus l and the German inhouse TELDIR corpus 2 . The TABA corpus is a text corpus in the domain of a train timetable information system (Aust et al., 1995). The TELDIR corpus is derived from the domain of a telephone directory assistance. Along with the bilingual annotation consisting of the source and target sentences, the corpora also provide the affiliated alignments between source words and concepts. The corpora allocations are summarized in table 1 and table 2. For the TABA corpus, the target language consists of 2"
E03-1055,J93-2003,0,0.00932534,"uction The objective of natural language understanding (NLU) is to extract all the information from a natural language based input which are relevant for a specific task. Typical applications using NLU components are spoken dialogue systems (Levin and Pieraccini, 1995) or speech-to-speech translation systems (Zhou et al., 2002). In this paper we present two approaches for analyzing the semantics of natural language inputs and discuss their advantages and drawbacks. The first approach is derived from the field of statistical machine translation (MT) and is based on the source-channel paradigm (Brown et al., 1993). Here, we apply a method called alignment templates (Och et al., 1999). The alternative apich warde gerne von KOln nach MUnchen fahren @want question V V @origin @destination @going Figure 1: Example of a word! concept mapping. proach uses the maximum entropy (ME) framework (Berger et al., 1996). For both frameworks, the objective can be described as follows. Given a natural source sentence fiJ = fj...f./ we choose the formal target language sentence ef = el •••e,...ei with the highest probability among all possible target sentences: argmax { Pr (ej ei fi&apos; ) (1) argmax r(ge,)•pr(ef) Pr (f&apos;) e"
E03-1055,P94-1004,0,0.0151305,"ts results for both the alignment templates approach and the ME framework. For both approaches, experiments were carried out on two different German NLU tasks. 2 Concept based semantic representation - A crucial decision, when designing an NLU system, is the choice of a suitable semantic representation, since interpreting a user&apos;s request requires an appropriate formalism to represent the meaning of an utterance. Different semantic representations have been proposed. Among them, case frames (Issar and Ward, 1993), semantic frames (Bennacef et al., 1994), and variants of hierarchical concepts (Miller et al., 1994) as well as flat concepts (Levin and Pieraccini, 1995) are the most prominent. Since we regard NLU as a special case of a translation problem, we have chosen a flat 12 concept-based target language as meaning representation. A semantic concept (in the following briefly termed as concept) is defined as the smallest unit of meaning that is relevant to a specific task (Levin and Pieraccini, 1995). Figure 1 depicts an example of a concept-based meaning representation for the input utterance &apos;I would like to go from Munich to Cologne&apos; from the domain of a German traintimetable information system. T"
E03-1055,W99-0604,1,0.919994,"t all the information from a natural language based input which are relevant for a specific task. Typical applications using NLU components are spoken dialogue systems (Levin and Pieraccini, 1995) or speech-to-speech translation systems (Zhou et al., 2002). In this paper we present two approaches for analyzing the semantics of natural language inputs and discuss their advantages and drawbacks. The first approach is derived from the field of statistical machine translation (MT) and is based on the source-channel paradigm (Brown et al., 1993). Here, we apply a method called alignment templates (Och et al., 1999). The alternative apich warde gerne von KOln nach MUnchen fahren @want question V V @origin @destination @going Figure 1: Example of a word! concept mapping. proach uses the maximum entropy (ME) framework (Berger et al., 1996). For both frameworks, the objective can be described as follows. Given a natural source sentence fiJ = fj...f./ we choose the formal target language sentence ef = el •••e,...ei with the highest probability among all possible target sentences: argmax { Pr (ej ei fi&apos; ) (1) argmax r(ge,)•pr(ef) Pr (f&apos;) el argmax { Pr(fief) • Pr(ef) • (2) e Using Bayes&apos; theorem, Eq. 1 can be"
E03-1055,C96-2141,1,0.64461,"ranslation approach decomposes Pr(eflg) into two probability distributions, the language model probability and the translation probability. The architecture of this method is depicted in figure 2. For the translation approach, we use the same training procedure as for the automatic translation of natural languages. When rewriting the translation probability Pr(fiJ 4) by introducing a &apos;hidden&apos; alignment al = with a j C {1,...,1}, we obtain: 611) = E Pr(fi&apos;,aPef) (3) a = Efl a = Pr(fi,aj 1.3-1 , a13 -1 • ei) • The IBM models as proposed by (Brown et al., 1993) and the HMM model as suggested by (Vogel et al., 1996) result from different decompositions of Pr(fif ,a .i! 4). For training the alignment model, we train a sequence of models of increasing complexity. Starting from the first model IBM1, we proceed over the HMM model, IBM3 up to IBMS. Using the model IBMS as a result of the last training step, we use the alignment template approach to model whole word groups. Source Language Text ( Preprocessing ) Pr(fij leD Global Search H H Lexicon Model Alignment Model @destination @origin @train determination @want_guestion @hello @yes U. 0 = argmax {Pr(eI) • Pr(fiT Pr(e) Language Model 0 0 Target Language T"
E06-1005,A94-1016,0,0.788909,"speech recognition (ASR). Voting schemes like the ROVER approach of (Fiscus, 1997) use edit distance alignment and time information to create confusion networks from the output of several ASR systems. Some research on multi-engine machine translation has also been performed in recent years. The most straightforward approaches simply select, for each sentence, one of the provided hypotheses. The selection is made based on the scores of translation, language, and other models (Nomoto, 2004; Paul et al., 2005). Other approaches combine lattices or N -best lists from several different MT systems (Frederking and Nirenburg, 1994). To be successful, such approaches require compatible lattices and comparable scores of the (word) hypotheses in the lattices. However, the scores of most statistical machine translation (SMT) systems are not normalized and therefore not directly comparable. For some other MT systems (e.g. knowledge-based systems), the lattices and/or scores of hypotheses may not be even available. (Bangalore et al., 2001) used the edit distance alignment extended to multiple sequences to construct a confusion network from several translation hypotheses. This algorithm produces monotone alignments only (i. e."
E06-1005,C04-1032,1,0.483303,"n, we add a fraction of a count for words with identical prefixes. The initialization could be furthermore improved by using word classes, part-of-speech tags, or a list of synonyms. The model parameters are trained iteratively in an unsupervised manner with the EM algorithm using the GIZA++ toolkit (Och and Ney, 2003). The training is performed in the directions En → Em and Em → En . The updated lexicon tables from the two directions are interpolated after each iteration. The final alignments are determined using cost matrices defined by the state occupation probabilities of the trained HMM (Matusov et al., 2004). The alignments are used for reordering each secondary translation En and for computing the confusion network. 34 Figure 1: Example of creating a confusion network from monotone one-to-one word alignments (denoted with symbol |). The words of the primary hypothesis are printed in bold. The symbol $ denotes a null alignment or an ε-arc in the corresponding part of the confusion network. original hypotheses alignment and reordering confusion network 1. would you like coffee or tea 2. would you have tea or coffee 3. would you like your coffee or 4. I have some coffee tea would you like would|wou"
E06-1005,P04-1063,0,0.507184,"ple machine translation systems. Combining outputs from different systems was shown to be quite successful in automatic speech recognition (ASR). Voting schemes like the ROVER approach of (Fiscus, 1997) use edit distance alignment and time information to create confusion networks from the output of several ASR systems. Some research on multi-engine machine translation has also been performed in recent years. The most straightforward approaches simply select, for each sentence, one of the provided hypotheses. The selection is made based on the scores of translation, language, and other models (Nomoto, 2004; Paul et al., 2005). Other approaches combine lattices or N -best lists from several different MT systems (Frederking and Nirenburg, 1994). To be successful, such approaches require compatible lattices and comparable scores of the (word) hypotheses in the lattices. However, the scores of most statistical machine translation (SMT) systems are not normalized and therefore not directly comparable. For some other MT systems (e.g. knowledge-based systems), the lattices and/or scores of hypotheses may not be even available. (Bangalore et al., 2001) used the edit distance alignment extended to multi"
E06-1005,2001.mtsummit-papers.46,1,0.82518,"Missing"
E06-1005,J03-1002,1,0.0266526,"he single-word based lexicon probabilities p(en |em ) are initialized with normalized lexicon counts collected over the sentence pairs (En , Em ) on this corpus. Since all of the hypotheses are in the same language, we count co-occurring equal words, i. e. if en is the same word as em . In addition, we add a fraction of a count for words with identical prefixes. The initialization could be furthermore improved by using word classes, part-of-speech tags, or a list of synonyms. The model parameters are trained iteratively in an unsupervised manner with the EM algorithm using the GIZA++ toolkit (Och and Ney, 2003). The training is performed in the directions En → Em and Em → En . The updated lexicon tables from the two directions are interpolated after each iteration. The final alignments are determined using cost matrices defined by the state occupation probabilities of the trained HMM (Matusov et al., 2004). The alignments are used for reordering each secondary translation En and for computing the confusion network. 34 Figure 1: Example of creating a confusion network from monotone one-to-one word alignments (denoted with symbol |). The words of the primary hypothesis are printed in bold. The symbol"
E06-1005,P02-1040,0,0.115404,"TC-STAR evaluation (verbatim condition) was used for the EPPS task. In Table 1, the number of running words in English is the average number of running words in the hypotheses, from which the consensus translation was computed; the vocabulary of English is the merged vocabulary of these hypotheses. For the BTEC IWSLT04 corpus, the statistics for English is given for the experiments described in Sections 3.3 and 3.5, respectively. 3.2 Evaluation Criteria Well-established objective evaluation measures like the word error rate (WER), positionindependent word error rate (PER), and the BLEU score (Papineni et al., 2002) were used to assess the translation quality. All measures were computed with respect to multiple reference translations. The evaluation (as well as the alignment training) was case-insensitive, without considering the punctuation marks. 36 3.3 Chinese-English Translation Different applications of the proposed combination method have been evaluated. First, we focused on combining different MT systems which have the same source and target language. The initial experiments were performed on the BTEC Chinese-English task. We combined translations produced by 5 different MT systems. Table 2 shows"
E06-1005,2005.iwslt-1.5,0,0.0435604,"anslation systems. Combining outputs from different systems was shown to be quite successful in automatic speech recognition (ASR). Voting schemes like the ROVER approach of (Fiscus, 1997) use edit distance alignment and time information to create confusion networks from the output of several ASR systems. Some research on multi-engine machine translation has also been performed in recent years. The most straightforward approaches simply select, for each sentence, one of the provided hypotheses. The selection is made based on the scores of translation, language, and other models (Nomoto, 2004; Paul et al., 2005). Other approaches combine lattices or N -best lists from several different MT systems (Frederking and Nirenburg, 1994). To be successful, such approaches require compatible lattices and comparable scores of the (word) hypotheses in the lattices. However, the scores of most statistical machine translation (SMT) systems are not normalized and therefore not directly comparable. For some other MT systems (e.g. knowledge-based systems), the lattices and/or scores of hypotheses may not be even available. (Bangalore et al., 2001) used the edit distance alignment extended to multiple sequences to con"
E06-1005,C96-2141,1,\N,Missing
E06-1005,2004.iwslt-evaluation.1,0,\N,Missing
E06-1031,W05-0909,0,0.118315,"common prefix length into costs, this fraction is then subtracted from 1. Table 1 gives an example of these two worddependent substitution costs. 245 e Table 1: Example of word-dependent substitution costs. Levenshtein prefix e˜ distance substitution cost similarity substitution cost usual understanding talk unusual misunderstanding talks 4.4 Perspectives More sophisticated methods could be considered for word-dependent substitution costs as well. Examples of such methods are the introduction of information weights as in the N IST measure or the comparison of stems or synonyms, as in M ETEOR (Banerjee and Lavie, 2005). 5 2 7 3 16 1 5 2 3 1 Experimental Results 5.1 Experimental Setting The different evaluation measures were assessed experimentally on data from the Chinese–English and the Arabic–English task of the N IST 2004 evaluation workshop (Przybocki, 2004). In this evaluation campaign, 4460 and 1735 candidate translations, respectively, generated by different research MT systems were evaluated by human judges with regard to fluency and adequacy. Four reference translations are provided for each candidate translation. Detailed corpus statistics are listed in Table 2. For the experiments in this study,"
E06-1031,2003.mtsummit-papers.32,1,0.808455,"ong jump distances becomes impractical for sentences longer than 20 words. 242 . o’clock seven at airport the reference at met we . t or rp ai e th on k oc cl o’ n ve se at t me ve ha we candidate deletion identity best path insertion long jump substitution block start/ end node Figure 1: Example of a long jump alignment grid. All possible deletion, insertion, identity and substitution operations are depicted. Only long jump edges from the best path are drawn. A possible way to achieve polynomial runtime is to restrict the number of admissible block permutations. This has been implemented by (Leusch et al., 2003) in the inversion word error rate. Alternatively, a heuristic or approximative distance can be calculated, as in G TM by (Turian et al., 2003). An implementation of both approaches at the same time can be found in T ER by (Snover et al., 2005). In this paper, we will present another approach which has a suitable run-time, while still maintaining completeness of the calculated measure. The idea of the proposed method is to drop some restrictions on the alignment path. The long jump distance as well as the Levenshtein distance require both reference and candidate translation to be covered comple"
E06-1031,W05-0903,1,0.797605,"ation campaigns. Furthermore, we included T ER (Snover et al., 2005) as a recent heuristic block movement measure in some of our experiments for comparison with our measure. As the B LEU score is unsuitable for sentence level evaluation in its original definition, B LEU -S smoothing as described by (Lin and Och, 2004) is performed. Additionally, we added sentence boundary symbols for B LEU, and a different reference length calculation scheme for T ER, because these changes improved the correlation between human evaluation and the two automatic measures. Details on this have been described in (Leusch et al., 2005). 5.2 CD ER Table 3 presents the correlation of B LEU, W ER, and CD ER with human assessment. It can be seen that CD ER shows better correlation than B LEU and W ER on both corpora. On the Chinese–English task, the smoothed B LEU score has a higher sentence-level correlation than W ER. However, this is not the case for the Arabic– 246 Table 3: Correlation (r) between human evaluation (adequacy + fluency) and automatic evaluation with B LEU, W ER, and CD ER (N IST 2004 evaluation; sentence level). Automatic measure B LEU W ER CD ER CD ER reverseda CD ER maximumb a b Chin.–E. 0.615 0.559 0.625 0"
E06-1031,C04-1072,0,0.0495503,"Missing"
E06-1031,P02-1040,0,0.116387,"put. Such a measure will help analyze the strengths and weaknesses of different translation systems or different versions of the same system by comparing output at the sentence level. In most applications of MT, understandability for humans in terms of readability as well as semantical correctness should be the evaluation criterion. But as human evaluation is tedious and cost-intensive, automatic evaluation measures are used in most MT research tasks. A high correlation between these automatic evaluation measures and human evaluation is thus desirable. State-of-the-art measures such as B LEU (Papineni et al., 2002) or N IST (Doddington, 2002) aim at measuring the translation quality rather on the document level1 than on the level of single sentences. They are thus not well-suited for sentence-level evaluation. The introduction of smoothing (Lin and Och, 2004) solves this problem only partially. In this paper, we will present a new automatic error measure for MT – the CD ER – which is designed for assessing MT quality on the sentence level. It is based on edit distance – such as the well-known word error rate (W ER) – but allows for reordering of blocks. Nevertheless, by defining reordering costs, the or"
E06-1031,2003.mtsummit-papers.51,0,0.121429,"e th on k oc cl o’ n ve se at t me ve ha we candidate deletion identity best path insertion long jump substitution block start/ end node Figure 1: Example of a long jump alignment grid. All possible deletion, insertion, identity and substitution operations are depicted. Only long jump edges from the best path are drawn. A possible way to achieve polynomial runtime is to restrict the number of admissible block permutations. This has been implemented by (Leusch et al., 2003) in the inversion word error rate. Alternatively, a heuristic or approximative distance can be calculated, as in G TM by (Turian et al., 2003). An implementation of both approaches at the same time can be found in T ER by (Snover et al., 2005). In this paper, we will present another approach which has a suitable run-time, while still maintaining completeness of the calculated measure. The idea of the proposed method is to drop some restrictions on the alignment path. The long jump distance as well as the Levenshtein distance require both reference and candidate translation to be covered completely and disjointly. When extending the metric by block movements, we drop this constraint for the candidate translation. That is, only the wo"
E14-2008,W11-2107,0,0.0891332,"Missing"
E14-2008,D08-1011,0,0.0544777,"S*:*EPS*/-0.7 2 the:the/-0.6 comprising:comprising/-0.1 3 *EPS*:*EPS*/-0.9 an:an/-0.1 4 isolated:isolated/-0.8 *EPS*:*EPS*/-0.2 5 cdna:cdna/-1 6 *EPS*:*EPS*/-0.4 library:library/-0.6 7 Figure 1: Scored confusion network. *EPS* denotes the empty word, red arcs highlight the shortest path. ing and an additional language model. Matusov et al. (2006) proposed an alignment based on the GIZA++ toolkit which introduced word reordering not present in MSA, and Sim et al. (2007) used alignments produced by T ER scoring (Snover et al., 2006). Extensions of the last two are based on hidden Markov models (He et al., 2008), inversion transduction grammars (Karakos et al., 2008), or METEOR (Heafield and Lavie, 2010). 3 and Lavie, 2011) was originally designed to reorder a translation for scoring and has a high precision. The recall is lower because synonyms which are not in the METEOR database or punctuation marks like “!” and “?” are not aligned to each other. For our purposes, we augment the METEOR paraphrase table with entries like “.|!”, “.|?”, or “the|a”. Figure 2 shows an example METEOR hypothesis alignment. The primary hypothesis “isolated cdna lib” determines the word order. An entry “a|b” means that wor"
E14-2008,P08-2021,0,0.0487936,"-0.1 3 *EPS*:*EPS*/-0.9 an:an/-0.1 4 isolated:isolated/-0.8 *EPS*:*EPS*/-0.2 5 cdna:cdna/-1 6 *EPS*:*EPS*/-0.4 library:library/-0.6 7 Figure 1: Scored confusion network. *EPS* denotes the empty word, red arcs highlight the shortest path. ing and an additional language model. Matusov et al. (2006) proposed an alignment based on the GIZA++ toolkit which introduced word reordering not present in MSA, and Sim et al. (2007) used alignments produced by T ER scoring (Snover et al., 2006). Extensions of the last two are based on hidden Markov models (He et al., 2008), inversion transduction grammars (Karakos et al., 2008), or METEOR (Heafield and Lavie, 2010). 3 and Lavie, 2011) was originally designed to reorder a translation for scoring and has a high precision. The recall is lower because synonyms which are not in the METEOR database or punctuation marks like “!” and “?” are not aligned to each other. For our purposes, we augment the METEOR paraphrase table with entries like “.|!”, “.|?”, or “the|a”. Figure 2 shows an example METEOR hypothesis alignment. The primary hypothesis “isolated cdna lib” determines the word order. An entry “a|b” means that word “a” from a secondary hypothesis has been aligned to wo"
E14-2008,E06-1005,1,0.845972,"f the European Chapter of the Association for Computational Linguistics, pages 29–32, c Gothenburg, Sweden, April 26-30 2014. 2014 Association for Computational Linguistics *EPS*:*EPS*/-0.3 contain:contain/-0.2 will:will/-0.3 *EPS*:*EPS*/-0.7 0 1 comprise:comprise/-0.1 *EPS*:*EPS*/-0.7 2 the:the/-0.6 comprising:comprising/-0.1 3 *EPS*:*EPS*/-0.9 an:an/-0.1 4 isolated:isolated/-0.8 *EPS*:*EPS*/-0.2 5 cdna:cdna/-1 6 *EPS*:*EPS*/-0.4 library:library/-0.6 7 Figure 1: Scored confusion network. *EPS* denotes the empty word, red arcs highlight the shortest path. ing and an additional language model. Matusov et al. (2006) proposed an alignment based on the GIZA++ toolkit which introduced word reordering not present in MSA, and Sim et al. (2007) used alignments produced by T ER scoring (Snover et al., 2006). Extensions of the last two are based on hidden Markov models (He et al., 2008), inversion transduction grammars (Karakos et al., 2008), or METEOR (Heafield and Lavie, 2010). 3 and Lavie, 2011) was originally designed to reorder a translation for scoring and has a high precision. The recall is lower because synonyms which are not in the METEOR database or punctuation marks like “!” and “?” are not aligned to"
E14-2008,P03-1021,0,0.134095,"with the sentence from the primary system. During the generation of the confusion network we align the hypotheses consecutively into the confusion network via the following procedure: 4 Experimental Results All experiments are conducted on the latest official WMT system combination shared task.4 We exclusively employ resources which were permitted for the constrained track of the task in all our setups. The big LM was trained on News Commentary and Europarl data. As tuning set we used newssyscombtune2011, as test set we used newssyscombtest2011. Feature weights have been optimized with MERT (Och, 2003). Table 1 contains the empirical results (truecase). For all four language pairs we achieve improvements over the best 2011 evaluation system combination submission either in B LEU or T ER. We get the highest improvement of 0.7 points in B LEU for es→en when adding both the big LM and IBM-1 features. Adding the big LM over the baseline enhances the translation quality for all four language pairs. Adding IBM-1 lexicon models on top of the big LM is of marginal or no benefit for most language • If a word wi from hypothesis A has a relation to a word v j of the primary hypothesis, we insert it as"
E14-2008,J93-2003,0,0.0349938,"Missing"
E14-2008,2006.amta-papers.25,0,0.0233343,"contain:contain/-0.2 will:will/-0.3 *EPS*:*EPS*/-0.7 0 1 comprise:comprise/-0.1 *EPS*:*EPS*/-0.7 2 the:the/-0.6 comprising:comprising/-0.1 3 *EPS*:*EPS*/-0.9 an:an/-0.1 4 isolated:isolated/-0.8 *EPS*:*EPS*/-0.2 5 cdna:cdna/-1 6 *EPS*:*EPS*/-0.4 library:library/-0.6 7 Figure 1: Scored confusion network. *EPS* denotes the empty word, red arcs highlight the shortest path. ing and an additional language model. Matusov et al. (2006) proposed an alignment based on the GIZA++ toolkit which introduced word reordering not present in MSA, and Sim et al. (2007) used alignments produced by T ER scoring (Snover et al., 2006). Extensions of the last two are based on hidden Markov models (He et al., 2008), inversion transduction grammars (Karakos et al., 2008), or METEOR (Heafield and Lavie, 2010). 3 and Lavie, 2011) was originally designed to reorder a translation for scoring and has a high precision. The recall is lower because synonyms which are not in the METEOR database or punctuation marks like “!” and “?” are not aligned to each other. For our purposes, we augment the METEOR paraphrase table with entries like “.|!”, “.|?”, or “the|a”. Figure 2 shows an example METEOR hypothesis alignment. The primary hypothe"
E14-2008,2013.iwslt-evaluation.16,1,\N,Missing
E14-2008,W13-2223,1,\N,Missing
E14-2008,D08-1076,0,\N,Missing
E14-4034,2013.iwslt-evaluation.1,0,0.0314032,"Missing"
E14-4034,N03-1017,0,0.062816,"lities based on collected rule counts. We show the effectiveness of our procedure on the IWSLT German→English and English→French translation tasks. Our results show improvements of up to 1.6 points B LEU. 1 Introduction In state of the art statistical machine translation systems, the translation model is estimated by following heuristic: Given bilingual training data, a word alignment is trained with tools such as GIZA++ (Och and Ney, 2003) or fast align (Dyer et al., 2013). Then, all valid translation pairs are extracted and the translation probabilities are computed as relative frequencies (Koehn et al., 2003). However, this extraction method causes several problems. First, this approach does not consider, whether a translation pair is extracted from a likely alignment or not. Further, during the extraction process, models employed in decoding are not considered. For phrase-based translation, a successful approach addressing these issues is presented in (Wuebker et al., 2010). By applying a phrasebased decoder on the source sentences of the training data and constraining the translations to the corresponding target sentences, k-best segmentations are produced. Then, the phrases used for 2 Hierarchi"
E14-4034,P10-2041,0,0.0570292,"Missing"
E14-4034,W05-1506,0,0.0458876,"cess as we do not have to employ the cube pruning algorithm as described in the previous section. Consequently, forced decoding for hierarchical phrase-based translation is equivalent to synchronous parsing of the training data. Dyer (2010) has described an approach to reduce the average-case run-time of synchronous parsing by splitting one bilingual parse into two successive monolingual parses. We adopt this method and first parse the source sentence and then the target sentence with CYK+. If the given sentence pair has been parsed successfully, we employ a top-down k-best parsing algorithm (Chiang and Huang, 2005) on the resulting hypergraph to find the k-best derivations between the given source and target sentence. In this step, all models of the translation process are The translation probabilities are computed in source-to-target as well as in target-to-source direction. In the translation processes, these probabilities are integrated in the log-linear combination among other models such as a language model, word lexicon models, word and phrase penalty and binary features marking hierarchical phrases, glue rule and rules with non-terminals at the boundaries. The translation process of hierarchical"
E14-4034,J03-1002,1,0.0201937,"he source and target sentences. This is done by synchronous parsing the given sentence pairs. After extracting k-best derivations, we reestimate the translation model probabilities based on collected rule counts. We show the effectiveness of our procedure on the IWSLT German→English and English→French translation tasks. Our results show improvements of up to 1.6 points B LEU. 1 Introduction In state of the art statistical machine translation systems, the translation model is estimated by following heuristic: Given bilingual training data, a word alignment is trained with tools such as GIZA++ (Och and Ney, 2003) or fast align (Dyer et al., 2013). Then, all valid translation pairs are extracted and the translation probabilities are computed as relative frequencies (Koehn et al., 2003). However, this extraction method causes several problems. First, this approach does not consider, whether a translation pair is extracted from a likely alignment or not. Further, during the extraction process, models employed in decoding are not considered. For phrase-based translation, a successful approach addressing these issues is presented in (Wuebker et al., 2010). By applying a phrasebased decoder on the source se"
E14-4034,P05-1033,0,0.105325,"approach does not consider, whether a translation pair is extracted from a likely alignment or not. Further, during the extraction process, models employed in decoding are not considered. For phrase-based translation, a successful approach addressing these issues is presented in (Wuebker et al., 2010). By applying a phrasebased decoder on the source sentences of the training data and constraining the translations to the corresponding target sentences, k-best segmentations are produced. Then, the phrases used for 2 Hierarchical Phrase-based Translation In hierarchical phrase-based translation (Chiang, 2005), discontinuous phrases with “gaps” are allowed. The translation model is formalized as a synchronous context-free grammar (SCFG) 174 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 174–179, c Gothenburg, Sweden, April 26-30 2014. 2014 Association for Computational Linguistics and consists of bilingual rules, which are based on bilingual standard phrases and discontinuous phrases. Each bilingual rule rewrites a generic non-terminal X into a pair of strings f˜ and e˜ with both terminals and non-terminals in both languages X → hf"
E14-4034,P03-1021,0,0.108177,"al X. With these hierarchical phrases we can define the hierarchical rules in the SCFG. The rule probabilities which are in general defined as relative frequencies are computed based on the joint counts C(X → hf˜, e˜i) of a bilingual rule X → hf˜, e˜i C(X → hf˜, e˜i) pH (f˜|˜ e) = P . ˜0 ˜i) f˜0 C(X → hf , e 3 Translation Model Training We propose following pipeline for consistent hierarchical phrase-based training: First we train a word alignment, from which the baseline translation model is extracted as described in the previous section. The log-linear parameter weights are tuned with MERT (Och, 2003) on a development set to produce the baseline system. Next, we perform decoding on the training data. As the translations are constrained to the given target sentences, we name this step forced decoding in the following. Details are given in the next subsection. Given the counts CF D (X → hf˜, e˜i) of the rules, which have been applied in the forced decoding step, the translation probabilities pF D (f˜|˜ e) for the translation model are recomputed: CF D (X → hf˜, e˜i) pF D (f˜|˜ e) = P . ˜0 ˜i) f˜0 CF D (X → hf , e (3) Finally, using the translation model with the reestimated probabilities, we"
E14-4034,J07-2003,0,0.0709671,"ge part of the SCFG. In this work, we perform this step with a modified version of the CYK+ algorithm (Chappelier and Rajman, 1998). The output of this algorithm is a hypergraph, which represents all possible derivations of the input sentence. A derivation represents an application of rules from the grammar to generate the given input sentence. Using the the associated target part of the applied rule, for each derivation a translation can be constructed. In a second step, the language model score is incorporated. Given the hypergraph, this is done with the cube pruning algorithm presented in (Chiang, 2007). 175 included (except for the language model). Further, leave-one-out is applied to counteract overfitting. Note, that the model weights of the baseline system are used to perform forced decoding. Finally, we extract and count the rules which have been applied in the derivations. These counts are used to recompute the translation probabilities. 3.2 Sentences Run. Words Vocabulary It is focusing the translation of TED talks. Bilingual data statistics are given in Table 1. The baseline system was trained on all available bilingual data and used a 4-gram LM with modified KneserNey smoothing (Kne"
E14-4034,2001.mtsummit-papers.68,0,0.0327359,"Missing"
E14-4034,P11-2031,0,0.0541754,"Missing"
E14-4034,2006.amta-papers.25,0,0.0429498,"Missing"
E14-4034,N13-1073,0,0.0282672,"is is done by synchronous parsing the given sentence pairs. After extracting k-best derivations, we reestimate the translation model probabilities based on collected rule counts. We show the effectiveness of our procedure on the IWSLT German→English and English→French translation tasks. Our results show improvements of up to 1.6 points B LEU. 1 Introduction In state of the art statistical machine translation systems, the translation model is estimated by following heuristic: Given bilingual training data, a word alignment is trained with tools such as GIZA++ (Och and Ney, 2003) or fast align (Dyer et al., 2013). Then, all valid translation pairs are extracted and the translation probabilities are computed as relative frequencies (Koehn et al., 2003). However, this extraction method causes several problems. First, this approach does not consider, whether a translation pair is extracted from a likely alignment or not. Further, during the extraction process, models employed in decoding are not considered. For phrase-based translation, a successful approach addressing these issues is presented in (Wuebker et al., 2010). By applying a phrasebased decoder on the source sentences of the training data and c"
E14-4034,N10-1033,0,0.0224717,"detail. Given a sentence pair of the training data, we constrain the translation of the source sentence to produce the corresponding target sentence. For this constrained decoding process, the language model score is constant as the translation is fixed. Hence, the incorporation of the a language model is not needed. This results in a simplification of the decoding process as we do not have to employ the cube pruning algorithm as described in the previous section. Consequently, forced decoding for hierarchical phrase-based translation is equivalent to synchronous parsing of the training data. Dyer (2010) has described an approach to reduce the average-case run-time of synchronous parsing by splitting one bilingual parse into two successive monolingual parses. We adopt this method and first parse the source sentence and then the target sentence with CYK+. If the given sentence pair has been parsed successfully, we employ a top-down k-best parsing algorithm (Chiang and Huang, 2005) on the resulting hypergraph to find the k-best derivations between the given source and target sentence. In this step, all models of the translation process are The translation probabilities are computed in source-to"
E14-4034,E14-2008,1,0.882213,"Missing"
E14-4034,W10-1738,1,0.904678,"Missing"
E14-4034,P02-1040,0,\N,Missing
E14-4034,P10-1049,1,\N,Missing
E14-4034,W13-0804,1,\N,Missing
E14-4034,C12-3061,1,\N,Missing
E17-2103,D12-1025,0,0.0191459,"2013). Probabilistic decipherment relaxes this assumption to allow many-to-many mapping, while the vocabulary is usually limited to a few thousand types (Nuhn et al., 2012; Dou and Knight, 2013; Nuhn and Ney, 2014; Dou et al., 2015). There has been several attempts to improve the scalability of decipherment methods, which are however not applicable to 100k-vocabulary translation scenarios. For EM-based decipherment, Nuhn et al. (2012) and Nuhn and Ney (2014) accelerate hypothesis expansions but do not explicitly solve the memory issue for a large lexicon table. Count-based Bayesian inference (Dou and Knight, 2012; Dou and Knight, 2013; Dou et al., 2015) loses all context information beyond bigrams for the sake of efficiency; it is therefore particularly effective in contextless deterministic ciphers or in inducing an auxiliary lexicon for supervised SMT. Ravi (2013) uses binary hashing to quicken the Bayesian sampling procedure, which Introduction Statistical machine translation (SMT) heavily relies on parallel text to train translation models with supervised learning. Unfortunately, parallel training data is scarce for most language pairs, where an alternative learning formalism is highly in need. In"
E17-2103,D13-1173,0,0.0159646,"the lexicon training with word classes, which efficiently boosts the performance. Our methods produced promising results on two large-scale unsupervised translation tasks. 1 2 Related Work Early work on unsupervised sequence learning was mainly for deterministic decipherment, a combinatorial problem of matching input-output symbols with 1:1 or homophonic assumption (Knight et al., 2006; Ravi and Knight, 2011a; Nuhn et al., 2013). Probabilistic decipherment relaxes this assumption to allow many-to-many mapping, while the vocabulary is usually limited to a few thousand types (Nuhn et al., 2012; Dou and Knight, 2013; Nuhn and Ney, 2014; Dou et al., 2015). There has been several attempts to improve the scalability of decipherment methods, which are however not applicable to 100k-vocabulary translation scenarios. For EM-based decipherment, Nuhn et al. (2012) and Nuhn and Ney (2014) accelerate hypothesis expansions but do not explicitly solve the memory issue for a large lexicon table. Count-based Bayesian inference (Dou and Knight, 2012; Dou and Knight, 2013; Dou et al., 2015) loses all context information beyond bigrams for the sake of efficiency; it is therefore particularly effective in contextless dete"
E17-2103,P15-1081,0,0.0245931,"Missing"
E17-2103,W06-1607,0,0.0823512,"Missing"
E17-2103,P14-2123,1,0.818906,"ith word classes, which efficiently boosts the performance. Our methods produced promising results on two large-scale unsupervised translation tasks. 1 2 Related Work Early work on unsupervised sequence learning was mainly for deterministic decipherment, a combinatorial problem of matching input-output symbols with 1:1 or homophonic assumption (Knight et al., 2006; Ravi and Knight, 2011a; Nuhn et al., 2013). Probabilistic decipherment relaxes this assumption to allow many-to-many mapping, while the vocabulary is usually limited to a few thousand types (Nuhn et al., 2012; Dou and Knight, 2013; Nuhn and Ney, 2014; Dou et al., 2015). There has been several attempts to improve the scalability of decipherment methods, which are however not applicable to 100k-vocabulary translation scenarios. For EM-based decipherment, Nuhn et al. (2012) and Nuhn and Ney (2014) accelerate hypothesis expansions but do not explicitly solve the memory issue for a large lexicon table. Count-based Bayesian inference (Dou and Knight, 2012; Dou and Knight, 2013; Dou et al., 2015) loses all context information beyond bigrams for the sake of efficiency; it is therefore particularly effective in contextless deterministic ciphers or"
E17-2103,P12-1017,1,0.903626,"Missing"
E17-2103,P07-1094,0,0.12142,"Missing"
E17-2103,P13-1154,1,0.873023,"table without any parallel text or seed lexicon. First, we solve the memory bottleneck and enforce the sparsity with a simple thresholding scheme for the lexicon. Second, we initialize the lexicon training with word classes, which efficiently boosts the performance. Our methods produced promising results on two large-scale unsupervised translation tasks. 1 2 Related Work Early work on unsupervised sequence learning was mainly for deterministic decipherment, a combinatorial problem of matching input-output symbols with 1:1 or homophonic assumption (Knight et al., 2006; Ravi and Knight, 2011a; Nuhn et al., 2013). Probabilistic decipherment relaxes this assumption to allow many-to-many mapping, while the vocabulary is usually limited to a few thousand types (Nuhn et al., 2012; Dou and Knight, 2013; Nuhn and Ney, 2014; Dou et al., 2015). There has been several attempts to improve the scalability of decipherment methods, which are however not applicable to 100k-vocabulary translation scenarios. For EM-based decipherment, Nuhn et al. (2012) and Nuhn and Ney (2014) accelerate hypothesis expansions but do not explicitly solve the memory issue for a large lexicon table. Count-based Bayesian inference (Dou a"
E17-2103,D07-1031,0,0.0262189,"r the forward-backward step explode. 650 Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, pages 650–656, c Valencia, Spain, April 3-7, 2017. 2017 Association for Computational Linguistics yet shows poor performance in large-scale experiments. Our problem is also related to unsupervised tagging with hidden Markov model (HMM). To the best of our knowledge, there is no published work on HMM training for a 100k-size discrete space. HMM taggers are often integrated with sparse priors (Goldwater and Griffiths, 2007; Johnson, 2007), which is not readily possible in a large vocabulary setting due to the memory bottleneck. Learning a good initialization on a smaller model is inspired by Och and Ney (2003) and Knight et al. (2006). Word classes have been widely used in SMT literature as factors in translation (Koehn and Hoang, 2007; Rishøj and Søgaard, 2011) or smoothing space of model components (Wuebker et al., 2013; Kim et al., 2016). To evaluate a translation output eˆN 1 , we use token-level accuracy (Acc.): 3 3.1 N P Acc. = Target (LM) E U T RANS es-en Run. Words Vocab. 85k 677 4.2M 505 E UROPARL es-en Run. Words Voc"
E17-2103,P15-2090,1,0.845897,"Missing"
E17-2103,W16-2212,1,0.853159,"M). To the best of our knowledge, there is no published work on HMM training for a 100k-size discrete space. HMM taggers are often integrated with sparse priors (Goldwater and Griffiths, 2007; Johnson, 2007), which is not readily possible in a large vocabulary setting due to the memory bottleneck. Learning a good initialization on a smaller model is inspired by Och and Ney (2003) and Knight et al. (2006). Word classes have been widely used in SMT literature as factors in translation (Koehn and Hoang, 2007; Rishøj and Søgaard, 2011) or smoothing space of model components (Wuebker et al., 2013; Kim et al., 2016). To evaluate a translation output eˆN 1 , we use token-level accuracy (Acc.): 3 3.1 N P Acc. = Target (LM) E U T RANS es-en Run. Words Vocab. 85k 677 4.2M 505 E UROPARL es-en Run. Words Vocab. 2.7M 32k 42.9M 96k IWSLT ro-en Run. Words Vocab. 2.8M 99k 13.7M 114k (1) Model We adopt a noisy-channel approach to define a joint probability of f1N and eN 1 as follows: Unsupervised learning is yet computationally demanding to solve general translation tasks including reordering or phrase translation. Instead, we take a simpler task which assumes 1:1 monotone alignment between source and target words."
E17-2103,J03-1002,1,0.0142983,"s, pages 650–656, c Valencia, Spain, April 3-7, 2017. 2017 Association for Computational Linguistics yet shows poor performance in large-scale experiments. Our problem is also related to unsupervised tagging with hidden Markov model (HMM). To the best of our knowledge, there is no published work on HMM training for a 100k-size discrete space. HMM taggers are often integrated with sparse priors (Goldwater and Griffiths, 2007; Johnson, 2007), which is not readily possible in a large vocabulary setting due to the memory bottleneck. Learning a good initialization on a smaller model is inspired by Och and Ney (2003) and Knight et al. (2006). Word classes have been widely used in SMT literature as factors in translation (Koehn and Hoang, 2007; Rishøj and Søgaard, 2011) or smoothing space of model components (Wuebker et al., 2013; Kim et al., 2016). To evaluate a translation output eˆN 1 , we use token-level accuracy (Acc.): 3 3.1 N P Acc. = Target (LM) E U T RANS es-en Run. Words Vocab. 85k 677 4.2M 505 E UROPARL es-en Run. Words Vocab. 2.7M 32k 42.9M 96k IWSLT ro-en Run. Words Vocab. 2.8M 99k 13.7M 114k (1) Model We adopt a noisy-channel approach to define a joint probability of f1N and eN 1 as follows:"
E17-2103,P11-1025,0,0.0181302,"earn a large translation table without any parallel text or seed lexicon. First, we solve the memory bottleneck and enforce the sparsity with a simple thresholding scheme for the lexicon. Second, we initialize the lexicon training with word classes, which efficiently boosts the performance. Our methods produced promising results on two large-scale unsupervised translation tasks. 1 2 Related Work Early work on unsupervised sequence learning was mainly for deterministic decipherment, a combinatorial problem of matching input-output symbols with 1:1 or homophonic assumption (Knight et al., 2006; Ravi and Knight, 2011a; Nuhn et al., 2013). Probabilistic decipherment relaxes this assumption to allow many-to-many mapping, while the vocabulary is usually limited to a few thousand types (Nuhn et al., 2012; Dou and Knight, 2013; Nuhn and Ney, 2014; Dou et al., 2015). There has been several attempts to improve the scalability of decipherment methods, which are however not applicable to 100k-vocabulary translation scenarios. For EM-based decipherment, Nuhn et al. (2012) and Nuhn and Ney (2014) accelerate hypothesis expansions but do not explicitly solve the memory issue for a large lexicon table. Count-based Baye"
E17-2103,P06-2065,0,0.231879,"n (EM) algorithm to learn a large translation table without any parallel text or seed lexicon. First, we solve the memory bottleneck and enforce the sparsity with a simple thresholding scheme for the lexicon. Second, we initialize the lexicon training with word classes, which efficiently boosts the performance. Our methods produced promising results on two large-scale unsupervised translation tasks. 1 2 Related Work Early work on unsupervised sequence learning was mainly for deterministic decipherment, a combinatorial problem of matching input-output symbols with 1:1 or homophonic assumption (Knight et al., 2006; Ravi and Knight, 2011a; Nuhn et al., 2013). Probabilistic decipherment relaxes this assumption to allow many-to-many mapping, while the vocabulary is usually limited to a few thousand types (Nuhn et al., 2012; Dou and Knight, 2013; Nuhn and Ney, 2014; Dou et al., 2015). There has been several attempts to improve the scalability of decipherment methods, which are however not applicable to 100k-vocabulary translation scenarios. For EM-based decipherment, Nuhn et al. (2012) and Nuhn and Ney (2014) accelerate hypothesis expansions but do not explicitly solve the memory issue for a large lexicon"
E17-2103,P11-1002,0,0.0814717,"earn a large translation table without any parallel text or seed lexicon. First, we solve the memory bottleneck and enforce the sparsity with a simple thresholding scheme for the lexicon. Second, we initialize the lexicon training with word classes, which efficiently boosts the performance. Our methods produced promising results on two large-scale unsupervised translation tasks. 1 2 Related Work Early work on unsupervised sequence learning was mainly for deterministic decipherment, a combinatorial problem of matching input-output symbols with 1:1 or homophonic assumption (Knight et al., 2006; Ravi and Knight, 2011a; Nuhn et al., 2013). Probabilistic decipherment relaxes this assumption to allow many-to-many mapping, while the vocabulary is usually limited to a few thousand types (Nuhn et al., 2012; Dou and Knight, 2013; Nuhn and Ney, 2014; Dou et al., 2015). There has been several attempts to improve the scalability of decipherment methods, which are however not applicable to 100k-vocabulary translation scenarios. For EM-based decipherment, Nuhn et al. (2012) and Nuhn and Ney (2014) accelerate hypothesis expansions but do not explicitly solve the memory issue for a large lexicon table. Count-based Baye"
E17-2103,D07-1091,0,0.0628003,"ce in large-scale experiments. Our problem is also related to unsupervised tagging with hidden Markov model (HMM). To the best of our knowledge, there is no published work on HMM training for a 100k-size discrete space. HMM taggers are often integrated with sparse priors (Goldwater and Griffiths, 2007; Johnson, 2007), which is not readily possible in a large vocabulary setting due to the memory bottleneck. Learning a good initialization on a smaller model is inspired by Och and Ney (2003) and Knight et al. (2006). Word classes have been widely used in SMT literature as factors in translation (Koehn and Hoang, 2007; Rishøj and Søgaard, 2011) or smoothing space of model components (Wuebker et al., 2013; Kim et al., 2016). To evaluate a translation output eˆN 1 , we use token-level accuracy (Acc.): 3 3.1 N P Acc. = Target (LM) E U T RANS es-en Run. Words Vocab. 85k 677 4.2M 505 E UROPARL es-en Run. Words Vocab. 2.7M 32k 42.9M 96k IWSLT ro-en Run. Words Vocab. 2.8M 99k 13.7M 114k (1) Model We adopt a noisy-channel approach to define a joint probability of f1N and eN 1 as follows: Unsupervised learning is yet computationally demanding to solve general translation tasks including reordering or phrase transla"
E17-2103,P13-1036,0,0.0184827,"o improve the scalability of decipherment methods, which are however not applicable to 100k-vocabulary translation scenarios. For EM-based decipherment, Nuhn et al. (2012) and Nuhn and Ney (2014) accelerate hypothesis expansions but do not explicitly solve the memory issue for a large lexicon table. Count-based Bayesian inference (Dou and Knight, 2012; Dou and Knight, 2013; Dou et al., 2015) loses all context information beyond bigrams for the sake of efficiency; it is therefore particularly effective in contextless deterministic ciphers or in inducing an auxiliary lexicon for supervised SMT. Ravi (2013) uses binary hashing to quicken the Bayesian sampling procedure, which Introduction Statistical machine translation (SMT) heavily relies on parallel text to train translation models with supervised learning. Unfortunately, parallel training data is scarce for most language pairs, where an alternative learning formalism is highly in need. In contrast, there is a virtually unlimited amount of monolingual data available for most languages. Based on this fact, we define a basic unsupervised learning problem for SMT as follows; given only a source text of arbitrary length and a target side LM, whic"
E17-2103,2005.mtsummit-papers.11,0,0.0381108,"out together from the lexicon. The resulting distribution psp (f |e) is identical for all e’s in the same target class. Word classes group words by syntactic or semantic similarity (Brown et al., 1992), which serve as a reasonable approximation of the original word vocabulary. They are especially suitable for large vocabulary data, because one can arbitrarily choose the number of classes to be very small; learning a class lexicon can thus be much more efficient than learning a word lexicon. 6 Large Vocabulary Experiments We applied two proposed techniques to E U ROPARL Spanish→English corpus (Koehn, 2005) and IWSLT 2014 Romanian→English TED talk corpus (Cettolo et al., 2012). In the E UROPARL data, we left out long sentences with more than 25 words and sentences with singletons. For the IWSLT data, we extended the LM training part with news commentary corpus from WMT 2016 shared tasks. We learned the initial lexicons on 100 classes 653 Knight, 2011b; Nuhn et al., 2012). Note that the idea of thresholding in the sparse lexicon is also applicable to any normalized model components. When the reordering model is lexicalized, the word class initialization may also be helpful for a stable training."
E17-2103,W11-2155,0,0.0315382,"iments. Our problem is also related to unsupervised tagging with hidden Markov model (HMM). To the best of our knowledge, there is no published work on HMM training for a 100k-size discrete space. HMM taggers are often integrated with sparse priors (Goldwater and Griffiths, 2007; Johnson, 2007), which is not readily possible in a large vocabulary setting due to the memory bottleneck. Learning a good initialization on a smaller model is inspired by Och and Ney (2003) and Knight et al. (2006). Word classes have been widely used in SMT literature as factors in translation (Koehn and Hoang, 2007; Rishøj and Søgaard, 2011) or smoothing space of model components (Wuebker et al., 2013; Kim et al., 2016). To evaluate a translation output eˆN 1 , we use token-level accuracy (Acc.): 3 3.1 N P Acc. = Target (LM) E U T RANS es-en Run. Words Vocab. 85k 677 4.2M 505 E UROPARL es-en Run. Words Vocab. 2.7M 32k 42.9M 96k IWSLT ro-en Run. Words Vocab. 2.8M 99k 13.7M 114k (1) Model We adopt a noisy-channel approach to define a joint probability of f1N and eN 1 as follows: Unsupervised learning is yet computationally demanding to solve general translation tasks including reordering or phrase translation. Instead, we take a si"
E17-2103,D13-1138,1,0.68424,"idden Markov model (HMM). To the best of our knowledge, there is no published work on HMM training for a 100k-size discrete space. HMM taggers are often integrated with sparse priors (Goldwater and Griffiths, 2007; Johnson, 2007), which is not readily possible in a large vocabulary setting due to the memory bottleneck. Learning a good initialization on a smaller model is inspired by Och and Ney (2003) and Knight et al. (2006). Word classes have been widely used in SMT literature as factors in translation (Koehn and Hoang, 2007; Rishøj and Søgaard, 2011) or smoothing space of model components (Wuebker et al., 2013; Kim et al., 2016). To evaluate a translation output eˆN 1 , we use token-level accuracy (Acc.): 3 3.1 N P Acc. = Target (LM) E U T RANS es-en Run. Words Vocab. 85k 677 4.2M 505 E UROPARL es-en Run. Words Vocab. 2.7M 32k 42.9M 96k IWSLT ro-en Run. Words Vocab. 2.8M 99k 13.7M 114k (1) Model We adopt a noisy-channel approach to define a joint probability of f1N and eN 1 as follows: Unsupervised learning is yet computationally demanding to solve general translation tasks including reordering or phrase translation. Instead, we take a simpler task which assumes 1:1 monotone alignment between sourc"
forster-etal-2012-rwth,braffort-etal-2010-sign,0,\N,Missing
forster-etal-2012-rwth,dreuw-etal-2008-benchmark,1,\N,Missing
forster-etal-2012-rwth,P02-1040,0,\N,Missing
forster-etal-2012-rwth,2010.iwslt-papers.17,1,\N,Missing
forster-etal-2014-extensions,braffort-etal-2010-sign,0,\N,Missing
forster-etal-2014-extensions,W10-1738,1,\N,Missing
forster-etal-2014-extensions,forster-etal-2012-rwth,1,\N,Missing
forster-etal-2014-extensions,W13-3908,1,\N,Missing
forster-etal-2014-extensions,2013.iwslt-papers.1,1,\N,Missing
garcia-varea-etal-2002-efficient,C00-2163,1,\N,Missing
garcia-varea-etal-2002-efficient,J93-2003,0,\N,Missing
garcia-varea-etal-2002-efficient,E99-1010,1,\N,Missing
garcia-varea-etal-2002-efficient,J96-1002,0,\N,Missing
garcia-varea-etal-2002-efficient,P01-1027,1,\N,Missing
garcia-varea-etal-2002-efficient,W00-0707,0,\N,Missing
H05-1096,C04-1047,0,0.0629713,"reshold are tagged as correct and all others are tagged as incorrect translations. The threshold is optimized on a distinct development set beforehand. Possible applications for confidence measures include • post-editing, where words with low confidence could be marked as potential errors, • improving translation prediction accuracy in trans-type-style interactive machine translation (Gandrabur and Foster, 2003; Ueffing and Ney, 2005), • combining output from different machine translation systems: hypotheses with low confidence can be discarded before selecting one of the system translations (Akiba et al., 2004), or the word confidence scores can be used for generating new hypotheses from the output of different systems (Jayaraman and Lavie, 2005), or the sentence confidence value can be employed for re-ranking (Blatz et al., 2003). In this paper, we will present several approaches to word-level confidence estimation and develop a new phrase-based confidence measure which is independent of the machine translation system which 763 Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language c Processing (HLT/EMNLP), pages 763–770, Vancouver, October 2005."
H05-1096,2004.iwslt-evaluation.8,0,0.0311282,"r(eI1 |f1J ) I,eI1 n (1) o = argmax P r(f1J |eI1 ) · P r(eI1 ) I,eI1 Through this decomposition of the probability, we obtain two knowledge sources: the translation model P r(f1J |eI1 ) and the language model P r(eI1 ). Both of them can be modeled independently of each other. The translation model is responsible for linking the source string f1J and the target string eI1 , i.e. it captures the semantics of the sentence. The target language model captures the well-formedness or the syntax in the target language. Nowadays, most of the state-of-the-art SMT systems are based on bilingual phrases (Bertoldi et al., 2004; Koehn et al., 2003; Och and Ney, 2004; Tillmann, 2003; Vogel et al., 2004; Zens and Ney, 2004). Note that those phrases are sequences of words in the two languages and not necessarily phrases in the linguistic sense. A more detailed description of a phrase-based approach to statistical machine translation will be given in section 2.2. 764 Review of phrase-based translation system Y I h = argmax I j0K ,iK 0 ,I,e1 · K h Y i−1 λ1 c1 · p(ei |ei−2 ) i (2) i=1 c2 · p(f˜k |e˜k )λ2 · p(˜ ek |f˜k )λ3 k=1 · jk Y j=jk−1 +1 p(fj |e˜k )λ4 · ik Y p(ei |f˜k )λ5 i , i=ik−1 +1 where p(f˜k |e˜k ) and p(˜ ek"
H05-1096,C04-1046,1,0.917073,"er deals with confidence estimation for machine translation (MT). Since sentences produced by a machine translation system are often incorrect but may contain correct parts, a method for identifying those correct parts and finding possible errors is desirable. For this purpose, each word in the generated target sentence is assigned a value expressing the confidence that it is correct. Confidence measures have been extensively studied for speech recognition, but are not well known in other areas. Only recently have researchers started to investigate confidence measures for machine translation (Blatz et al., 2004; Gandrabur and Foster, 2003; Quirk, 2004; Ueffing et al., 2003). We apply word confidence measures in MT as follows: For a given translation generated by a machine translation system, we determine a confidence value for each word and compare it to a threshold. All words whose confidence is above this threshold are tagged as correct and all others are tagged as incorrect translations. The threshold is optimized on a distinct development set beforehand. Possible applications for confidence measures include • post-editing, where words with low confidence could be marked as potential errors, • im"
H05-1096,J93-2003,0,0.0054692,"(Press et al., 2002). 6 IBM-1 based approach Another type of confidence measure which does not rely on system output and is thus applicable to any kind of machine translation system is the IBM-1 model based confidence measure which was introduced in (Blatz et al., 2003). We modified this confidence measure because we found that the average lexicon probability used there is dominated by the maximum. Therefore, we determine the maximal translation probability of the target word e over the source sentence words: (9) pIBM−1 (e|f1J ) = max p(e|fj ) , j=0,...,J where f0 is the “empty” source word (Brown et al., 1993). The probabilities p(e|fj ) are word-based lexicon probabilities. Investigations on the use of the IBM-1 model for word confidence measures showed promising results (Blatz et al., 2003; Blatz et al., 2004). Thus, 767 we apply this method here in order to compare it to the other types of confidence measures. 7 Experiments 7.1 Experimental setting The experiments were performed on three different language pairs. All corpora were compiled in the EU project TransType2; they consist of technical manuals. The corpus statistics are given in table 1. The SMT systems that the confidence estimation was"
H05-1096,P05-3026,0,0.032716,"ment set beforehand. Possible applications for confidence measures include • post-editing, where words with low confidence could be marked as potential errors, • improving translation prediction accuracy in trans-type-style interactive machine translation (Gandrabur and Foster, 2003; Ueffing and Ney, 2005), • combining output from different machine translation systems: hypotheses with low confidence can be discarded before selecting one of the system translations (Akiba et al., 2004), or the word confidence scores can be used for generating new hypotheses from the output of different systems (Jayaraman and Lavie, 2005), or the sentence confidence value can be employed for re-ranking (Blatz et al., 2003). In this paper, we will present several approaches to word-level confidence estimation and develop a new phrase-based confidence measure which is independent of the machine translation system which 763 Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language c Processing (HLT/EMNLP), pages 763–770, Vancouver, October 2005. 2005 Association for Computational Linguistics generated the translation. The paper is organized as follows: In section 2, we will briefl"
H05-1096,W05-0831,1,0.819885,"tate-of-the-art SMT systems. We produced single best translations, word graphs and N -best lists on all three language pairs using these systems. The translation quality in terms of WER, PER (position independent word error rate), BLEU and NIST score is given in tables 2 and 3. We see that the best results are obtained on Spanish to English translation, followed by French to English and German to English. Two more translation systems were used for comparative experiments: One is a statistical MT system which is based on a finite state architecture (FSA). For a description of this system, see (Kanthak et al., 2005). Additionally, we used translations generated by Systran2 . Table 3 presents the translation error rates and scores for all systems on the German → English test corpus. These hypotheses were used to investigate whether the phrase-based confidence measures perform well independently of the translation system. All three SMT systems (AT, PBT and FSA) show very similar performance on the German → English test corpus. The fact that Systran generates translations of much lower quality is due to the fact that the technical manuals are very specific in terminology, and the SMT systems have been train"
H05-1096,N03-1017,0,0.00739283,") o = argmax P r(f1J |eI1 ) · P r(eI1 ) I,eI1 Through this decomposition of the probability, we obtain two knowledge sources: the translation model P r(f1J |eI1 ) and the language model P r(eI1 ). Both of them can be modeled independently of each other. The translation model is responsible for linking the source string f1J and the target string eI1 , i.e. it captures the semantics of the sentence. The target language model captures the well-formedness or the syntax in the target language. Nowadays, most of the state-of-the-art SMT systems are based on bilingual phrases (Bertoldi et al., 2004; Koehn et al., 2003; Och and Ney, 2004; Tillmann, 2003; Vogel et al., 2004; Zens and Ney, 2004). Note that those phrases are sequences of words in the two languages and not necessarily phrases in the linguistic sense. A more detailed description of a phrase-based approach to statistical machine translation will be given in section 2.2. 764 Review of phrase-based translation system Y I h = argmax I j0K ,iK 0 ,I,e1 · K h Y i−1 λ1 c1 · p(ei |ei−2 ) i (2) i=1 c2 · p(f˜k |e˜k )λ2 · p(˜ ek |f˜k )λ3 k=1 · jk Y j=jk−1 +1 p(fj |e˜k )λ4 · ik Y p(ei |f˜k )λ5 i , i=ik−1 +1 where p(f˜k |e˜k ) and p(˜ ek |f˜k ) are the phra"
H05-1096,J04-4002,1,0.177352,"|eI1 ) · P r(eI1 ) I,eI1 Through this decomposition of the probability, we obtain two knowledge sources: the translation model P r(f1J |eI1 ) and the language model P r(eI1 ). Both of them can be modeled independently of each other. The translation model is responsible for linking the source string f1J and the target string eI1 , i.e. it captures the semantics of the sentence. The target language model captures the well-formedness or the syntax in the target language. Nowadays, most of the state-of-the-art SMT systems are based on bilingual phrases (Bertoldi et al., 2004; Koehn et al., 2003; Och and Ney, 2004; Tillmann, 2003; Vogel et al., 2004; Zens and Ney, 2004). Note that those phrases are sequences of words in the two languages and not necessarily phrases in the linguistic sense. A more detailed description of a phrase-based approach to statistical machine translation will be given in section 2.2. 764 Review of phrase-based translation system Y I h = argmax I j0K ,iK 0 ,I,e1 · K h Y i−1 λ1 c1 · p(ei |ei−2 ) i (2) i=1 c2 · p(f˜k |e˜k )λ2 · p(˜ ek |f˜k )λ3 k=1 · jk Y j=jk−1 +1 p(fj |e˜k )λ4 · ik Y p(ei |f˜k )λ5 i , i=ik−1 +1 where p(f˜k |e˜k ) and p(˜ ek |f˜k ) are the phrase lexicon models i"
H05-1096,P03-1021,0,0.0458914,"i |f˜k ) is the inverse model, respectively. c1 is the so-called word penalty, and c2 is the phrase penalty, assigning constant costs to each target language word/phrase. The language model is a trigram model with modified Kneser-Ney discounting and interpolation (Stolcke, 2002). The search determines the target sentence and segmentation which maximize the objective function. As equation 2 shows, the sub-models are combined via weighted log-linear interpolation. The model scaling factors λ1 , . . . , λ5 and the word and phrase penalties are optimized with respect to some evaluation criterion (Och, 2003), e.g. BLEU score. 3 Confidence measures for SMT 4 3.1 Related work In this paper, we will present a new approach to word-level confidence estimation which makes explicit use of a phrase-based translation model. Most of the word-level confidence measures which have been presented in the literature so far are either based on relatively simple translation models such as IBM-1 (Blatz et al., 2003) or make use of information provided by the SMT system such as N -best lists or word graphs (Blatz et al., 2003; Gandrabur and Foster, 2003; Ueffing et al., 2003). In contrast to this, our method is base"
H05-1096,quirk-2004-training,0,0.0997186,"translation (MT). Since sentences produced by a machine translation system are often incorrect but may contain correct parts, a method for identifying those correct parts and finding possible errors is desirable. For this purpose, each word in the generated target sentence is assigned a value expressing the confidence that it is correct. Confidence measures have been extensively studied for speech recognition, but are not well known in other areas. Only recently have researchers started to investigate confidence measures for machine translation (Blatz et al., 2004; Gandrabur and Foster, 2003; Quirk, 2004; Ueffing et al., 2003). We apply word confidence measures in MT as follows: For a given translation generated by a machine translation system, we determine a confidence value for each word and compare it to a threshold. All words whose confidence is above this threshold are tagged as correct and all others are tagged as incorrect translations. The threshold is optimized on a distinct development set beforehand. Possible applications for confidence measures include • post-editing, where words with low confidence could be marked as potential errors, • improving translation prediction accuracy i"
H05-1096,W03-1001,0,0.0165206,"I,eI1 Through this decomposition of the probability, we obtain two knowledge sources: the translation model P r(f1J |eI1 ) and the language model P r(eI1 ). Both of them can be modeled independently of each other. The translation model is responsible for linking the source string f1J and the target string eI1 , i.e. it captures the semantics of the sentence. The target language model captures the well-formedness or the syntax in the target language. Nowadays, most of the state-of-the-art SMT systems are based on bilingual phrases (Bertoldi et al., 2004; Koehn et al., 2003; Och and Ney, 2004; Tillmann, 2003; Vogel et al., 2004; Zens and Ney, 2004). Note that those phrases are sequences of words in the two languages and not necessarily phrases in the linguistic sense. A more detailed description of a phrase-based approach to statistical machine translation will be given in section 2.2. 764 Review of phrase-based translation system Y I h = argmax I j0K ,iK 0 ,I,e1 · K h Y i−1 λ1 c1 · p(ei |ei−2 ) i (2) i=1 c2 · p(f˜k |e˜k )λ2 · p(˜ ek |f˜k )λ3 k=1 · jk Y j=jk−1 +1 p(fj |e˜k )λ4 · ik Y p(ei |f˜k )λ5 i , i=ik−1 +1 where p(f˜k |e˜k ) and p(˜ ek |f˜k ) are the phrase lexicon models in both translati"
H05-1096,2005.eamt-1.35,1,0.842328,"a given translation generated by a machine translation system, we determine a confidence value for each word and compare it to a threshold. All words whose confidence is above this threshold are tagged as correct and all others are tagged as incorrect translations. The threshold is optimized on a distinct development set beforehand. Possible applications for confidence measures include • post-editing, where words with low confidence could be marked as potential errors, • improving translation prediction accuracy in trans-type-style interactive machine translation (Gandrabur and Foster, 2003; Ueffing and Ney, 2005), • combining output from different machine translation systems: hypotheses with low confidence can be discarded before selecting one of the system translations (Akiba et al., 2004), or the word confidence scores can be used for generating new hypotheses from the output of different systems (Jayaraman and Lavie, 2005), or the sentence confidence value can be employed for re-ranking (Blatz et al., 2003). In this paper, we will present several approaches to word-level confidence estimation and develop a new phrase-based confidence measure which is independent of the machine translation system wh"
H05-1096,2003.mtsummit-papers.52,1,0.911671,"MT). Since sentences produced by a machine translation system are often incorrect but may contain correct parts, a method for identifying those correct parts and finding possible errors is desirable. For this purpose, each word in the generated target sentence is assigned a value expressing the confidence that it is correct. Confidence measures have been extensively studied for speech recognition, but are not well known in other areas. Only recently have researchers started to investigate confidence measures for machine translation (Blatz et al., 2004; Gandrabur and Foster, 2003; Quirk, 2004; Ueffing et al., 2003). We apply word confidence measures in MT as follows: For a given translation generated by a machine translation system, we determine a confidence value for each word and compare it to a threshold. All words whose confidence is above this threshold are tagged as correct and all others are tagged as incorrect translations. The threshold is optimized on a distinct development set beforehand. Possible applications for confidence measures include • post-editing, where words with low confidence could be marked as potential errors, • improving translation prediction accuracy in trans-type-style inte"
H05-1096,2004.iwslt-evaluation.11,0,0.0322614,"his decomposition of the probability, we obtain two knowledge sources: the translation model P r(f1J |eI1 ) and the language model P r(eI1 ). Both of them can be modeled independently of each other. The translation model is responsible for linking the source string f1J and the target string eI1 , i.e. it captures the semantics of the sentence. The target language model captures the well-formedness or the syntax in the target language. Nowadays, most of the state-of-the-art SMT systems are based on bilingual phrases (Bertoldi et al., 2004; Koehn et al., 2003; Och and Ney, 2004; Tillmann, 2003; Vogel et al., 2004; Zens and Ney, 2004). Note that those phrases are sequences of words in the two languages and not necessarily phrases in the linguistic sense. A more detailed description of a phrase-based approach to statistical machine translation will be given in section 2.2. 764 Review of phrase-based translation system Y I h = argmax I j0K ,iK 0 ,I,e1 · K h Y i−1 λ1 c1 · p(ei |ei−2 ) i (2) i=1 c2 · p(f˜k |e˜k )λ2 · p(˜ ek |f˜k )λ3 k=1 · jk Y j=jk−1 +1 p(fj |e˜k )λ4 · ik Y p(ei |f˜k )λ5 i , i=ik−1 +1 where p(f˜k |e˜k ) and p(˜ ek |f˜k ) are the phrase lexicon models in both translation directions. The p"
H05-1096,N04-1033,1,0.941379,"onfidence estimation which make use of SMT system output such as word graphs and N -best lists. In section 5, we will present the new phrase-based confidence measure. Section 6 contains a short description of an IBM-1 based confidence measure to which we will compare the other measures. Experimental evaluation and comparison of the different confidence measures will be shown in section 7, and section 8 will conclude the paper. 2 Statistical machine translation 2.2 For the confidence measures which will be introduced in section 5, we use a state-of-the-art phrasebased approach as described in (Zens and Ney, 2004). The key elements of this translation approach are bilingual phrases, i.e. pairs of source and target language phrases where a phrase is simply a contiguous sequence of words. These bilingual phrases are extracted from a word-aligned bilingual training corpus. We will present the equations for a monotone search here in order to keep the equations simple. Let (j0K , iK 0 ) be a segmentation of the source sentence into phrases, with the corresponding (bilingual) phrase pairs (f˜k , e˜k ) = ik k The phrase(fjjk−1 +1 , eik−1 +1 ), k = 1, . . . , K. based approach to SMT is then expressed by the f"
H05-1096,C04-1030,1,\N,Missing
H05-1096,2005.eamt-1.20,0,\N,Missing
H05-1096,W03-0413,0,\N,Missing
hahn-etal-2008-comparison,W04-3230,0,\N,Missing
hahn-etal-2008-comparison,devillers-etal-2004-french,0,\N,Missing
hahn-etal-2008-comparison,2006.iwslt-evaluation.15,1,\N,Missing
hahn-etal-2008-comparison,N01-1025,0,\N,Missing
hasan-etal-2006-creating,moore-2002-fast,0,\N,Missing
hasan-etal-2006-creating,J90-2002,0,\N,Missing
hasan-etal-2006-creating,P02-1038,1,\N,Missing
hasan-etal-2006-creating,2005.iwslt-1.20,1,\N,Missing
hasan-etal-2006-creating,N04-1033,1,\N,Missing
hasan-etal-2006-creating,P03-1021,0,\N,Missing
hasan-ney-2008-multi,P07-2045,0,\N,Missing
hasan-ney-2008-multi,W06-3103,1,\N,Missing
hasan-ney-2008-multi,hasan-etal-2006-creating,1,\N,Missing
hasan-ney-2008-multi,2007.mtsummit-papers.31,0,\N,Missing
hasan-ney-2008-multi,P03-1021,0,\N,Missing
J03-1002,P98-1006,0,0.168636,"Missing"
J03-1002,H94-1028,0,0.147099,"nd every learning method suffers from a significant data sparseness problem. 1.2 Applications There are numerous applications for word alignments in natural language processing. These applications crucially depend on the quality of the word alignment (Och and Ney 2000; Yarowsky and Wicentowski 2000). An obvious application for word alignment methods is the automatic extraction of bilingual lexica and terminology from corpora (Smadja, McKeown, and Hatzivassiloglou 1996; Melamed 2000). Statistical alignment models are often the basis of single-word-based statistical machine translation systems (Berger et al. 1994; Wu 1996; Wang and Waibel 1998; Nießen et al. 1998; Garc´ıa-Varea, Casacuberta, and Ney 1998; Och, Ueffing, and Ney 2001; Germann et al. 2001). In addition, these models are the starting point for refined phrase-based statistical (Och and Weber 1998; Och, Tillmann, and Ney 1999) or example-based translation systems (Brown 1997). In such systems, the quality of the machine translation output directly depends on the quality of the initial word alignment (Och and Ney 2000). 21 Computational Linguistics Volume 29, Number 1 Another application of word alignments is in the field of word sense disam"
J03-1002,H93-1039,0,0.176439,"Missing"
J03-1002,J93-2003,0,0.199711,"Missing"
J03-1002,1997.tmi-1.13,0,0.159281,"gnment methods is the automatic extraction of bilingual lexica and terminology from corpora (Smadja, McKeown, and Hatzivassiloglou 1996; Melamed 2000). Statistical alignment models are often the basis of single-word-based statistical machine translation systems (Berger et al. 1994; Wu 1996; Wang and Waibel 1998; Nießen et al. 1998; Garc´ıa-Varea, Casacuberta, and Ney 1998; Och, Ueffing, and Ney 2001; Germann et al. 2001). In addition, these models are the starting point for refined phrase-based statistical (Och and Weber 1998; Och, Tillmann, and Ney 1999) or example-based translation systems (Brown 1997). In such systems, the quality of the machine translation output directly depends on the quality of the initial word alignment (Och and Ney 2000). 21 Computational Linguistics Volume 29, Number 1 Another application of word alignments is in the field of word sense disambiguation (Diab 2000). In Yarowsky, Ngai, and Wicentowski (2001), word alignment is used to transfer text analysis tools such as morphologic analyzers or part-of-speech taggers from a language, such as English, for which many tools already exist to languages for which such resources are scarce. 1.3 Overview In Section 2, we revi"
J03-1002,W93-0301,0,0.165602,"Missing"
J03-1002,W00-0801,0,0.146757,"Wang and Waibel 1998; Nießen et al. 1998; Garc´ıa-Varea, Casacuberta, and Ney 1998; Och, Ueffing, and Ney 2001; Germann et al. 2001). In addition, these models are the starting point for refined phrase-based statistical (Och and Weber 1998; Och, Tillmann, and Ney 1999) or example-based translation systems (Brown 1997). In such systems, the quality of the machine translation output directly depends on the quality of the initial word alignment (Och and Ney 2000). 21 Computational Linguistics Volume 29, Number 1 Another application of word alignments is in the field of word sense disambiguation (Diab 2000). In Yarowsky, Ngai, and Wicentowski (2001), word alignment is used to transfer text analysis tools such as morphologic analyzers or part-of-speech taggers from a language, such as English, for which many tools already exist to languages for which such resources are scarce. 1.3 Overview In Section 2, we review various statistical alignment models and heuristic models. We present a new statistical alignment model, a log-linear combination of the best models of Vogel, Ney, and Tillmann (1996) and Brown, Della Pietra, Della Pietra, and Mercer (1993). In Section 3, we describe the training of the"
J03-1002,P98-2158,0,0.160398,"Missing"
J03-1002,P01-1030,0,0.147953,"ents in natural language processing. These applications crucially depend on the quality of the word alignment (Och and Ney 2000; Yarowsky and Wicentowski 2000). An obvious application for word alignment methods is the automatic extraction of bilingual lexica and terminology from corpora (Smadja, McKeown, and Hatzivassiloglou 1996; Melamed 2000). Statistical alignment models are often the basis of single-word-based statistical machine translation systems (Berger et al. 1994; Wu 1996; Wang and Waibel 1998; Nießen et al. 1998; Garc´ıa-Varea, Casacuberta, and Ney 1998; Och, Ueffing, and Ney 2001; Germann et al. 2001). In addition, these models are the starting point for refined phrase-based statistical (Och and Weber 1998; Och, Tillmann, and Ney 1999) or example-based translation systems (Brown 1997). In such systems, the quality of the machine translation output directly depends on the quality of the initial word alignment (Och and Ney 2000). 21 Computational Linguistics Volume 29, Number 1 Another application of word alignments is in the field of word sense disambiguation (Diab 2000). In Yarowsky, Ngai, and Wicentowski (2001), word alignment is used to transfer text analysis tools such as morphologic an"
J03-1002,P00-1050,0,0.170082,"Missing"
J03-1002,J97-2004,0,0.146953,"chnique do indeed obtain a good alignment quality. In this paper, we use Models 1 through 5 described in Brown, Della Pietra, Della Pietra, and Mercer (1993), the hidden Markov alignment model described in Vogel, Ney, and Tillmann (1996) and Och and Ney (2000), and a new alignment model, which we call Model 6. All these models use a different decomposition of the probability Pr (f1J , aJ1 |eI1 ). 2.1.2 Heuristic Models. Considerably simpler methods for obtaining word alignments use a function of the similarity between the types of the two languages (Smadja, McKeown, and Hatzivassiloglou 1996; Ker and Chang 1997; Melamed 2000). Frequently, variations of the Dice coefficient (Dice 1945) are used as this similarity function. For each sentence pair, a matrix including the association scores between every word at every position is then obtained: dice(i, j) = 2 · C(ei , fj ) C(ei ) · C(fj ) (6) 23 Computational Linguistics Volume 29, Number 1 C(e, f ) denotes the co-occurrence count of e and f in the parallel training corpus. C(e) and C(f ) denote the count of e in the target sentences and the count of f in the source sentences, respectively. From this association score matrix, the word alignment is then"
J03-1002,J99-4005,0,0.185271,"2, we obtain Pr (f1J , aJ1 |eI1 ) = p(J |I) · J  [p(aj |j, I, J) · p(fj |eaj )] (18) j=1 1 δ(i, i ) is the Kronecker function, which is one if i = i and zero otherwise. 25 Computational Linguistics Volume 29, Number 1 To reduce the number of alignment parameters, we ignore the dependence on J in the alignment model and use a distribution p(aj |j, I) instead of p(aj |j, I, J). 2.3 Fertility-Based Alignment Models In the following, we give a short description of the fertility-based alignment models of Brown, Della Pietra, Della Pietra, and Mercer (1993). A gentle introduction can be found in Knight (1999b). The fertility-based alignment models (Models 3, 4, and 5) (Brown, Della Pietra, Della Pietra, and Mercer 1993) have a significantly more complicated structure than the simple Models 1 and 2. The fertility φi of a word ei in position i is defined as the number of aligned source words: φi =  δ(aj , i) (19) j The fertility-based alignment models contain a probability p(φ |e) that the target word e is aligned to φ words. By including this probability, it is possible to explicitly describe the fact that for instance the German word ¨ ubermorgen produces four English words (the day after tomorr"
J03-1002,J00-2004,0,0.18143,"s with a very rich morphology, such as Finnish, a trivial segmentation produces a high number of words that occur only once, and every learning method suffers from a significant data sparseness problem. 1.2 Applications There are numerous applications for word alignments in natural language processing. These applications crucially depend on the quality of the word alignment (Och and Ney 2000; Yarowsky and Wicentowski 2000). An obvious application for word alignment methods is the automatic extraction of bilingual lexica and terminology from corpora (Smadja, McKeown, and Hatzivassiloglou 1996; Melamed 2000). Statistical alignment models are often the basis of single-word-based statistical machine translation systems (Berger et al. 1994; Wu 1996; Wang and Waibel 1998; Nießen et al. 1998; Garc´ıa-Varea, Casacuberta, and Ney 1998; Och, Ueffing, and Ney 2001; Germann et al. 2001). In addition, these models are the starting point for refined phrase-based statistical (Och and Weber 1998; Och, Tillmann, and Ney 1999) or example-based translation systems (Brown 1997). In such systems, the quality of the machine translation output directly depends on the quality of the initial word alignment (Och and Ney"
J03-1002,C00-2163,1,0.155591,"mented into aligned sentences and that the sentences are segmented into words. Obviously, there are additional implicit assumptions in the models that are needed to obtain a good alignment quality. For example, in languages with a very rich morphology, such as Finnish, a trivial segmentation produces a high number of words that occur only once, and every learning method suffers from a significant data sparseness problem. 1.2 Applications There are numerous applications for word alignments in natural language processing. These applications crucially depend on the quality of the word alignment (Och and Ney 2000; Yarowsky and Wicentowski 2000). An obvious application for word alignment methods is the automatic extraction of bilingual lexica and terminology from corpora (Smadja, McKeown, and Hatzivassiloglou 1996; Melamed 2000). Statistical alignment models are often the basis of single-word-based statistical machine translation systems (Berger et al. 1994; Wu 1996; Wang and Waibel 1998; Nießen et al. 1998; Garc´ıa-Varea, Casacuberta, and Ney 1998; Och, Ueffing, and Ney 2001; Germann et al. 2001). In addition, these models are the starting point for refined phrase-based statistical (Och and Weber 1998"
J03-1002,W99-0604,1,0.155797,"Missing"
J03-1002,W01-1408,1,0.150274,"Missing"
J03-1002,P98-2162,1,0.152837,"(Och and Ney 2000; Yarowsky and Wicentowski 2000). An obvious application for word alignment methods is the automatic extraction of bilingual lexica and terminology from corpora (Smadja, McKeown, and Hatzivassiloglou 1996; Melamed 2000). Statistical alignment models are often the basis of single-word-based statistical machine translation systems (Berger et al. 1994; Wu 1996; Wang and Waibel 1998; Nießen et al. 1998; Garc´ıa-Varea, Casacuberta, and Ney 1998; Och, Ueffing, and Ney 2001; Germann et al. 2001). In addition, these models are the starting point for refined phrase-based statistical (Och and Weber 1998; Och, Tillmann, and Ney 1999) or example-based translation systems (Brown 1997). In such systems, the quality of the machine translation output directly depends on the quality of the initial word alignment (Och and Ney 2000). 21 Computational Linguistics Volume 29, Number 1 Another application of word alignments is in the field of word sense disambiguation (Diab 2000). In Yarowsky, Ngai, and Wicentowski (2001), word alignment is used to transfer text analysis tools such as morphologic analyzers or part-of-speech taggers from a language, such as English, for which many tools already exist to l"
J03-1002,1992.tmi-1.7,0,0.173068,"Missing"
J03-1002,J96-1001,0,0.148919,"Missing"
J03-1002,P96-1021,0,0.174327,"thod suffers from a significant data sparseness problem. 1.2 Applications There are numerous applications for word alignments in natural language processing. These applications crucially depend on the quality of the word alignment (Och and Ney 2000; Yarowsky and Wicentowski 2000). An obvious application for word alignment methods is the automatic extraction of bilingual lexica and terminology from corpora (Smadja, McKeown, and Hatzivassiloglou 1996; Melamed 2000). Statistical alignment models are often the basis of single-word-based statistical machine translation systems (Berger et al. 1994; Wu 1996; Wang and Waibel 1998; Nießen et al. 1998; Garc´ıa-Varea, Casacuberta, and Ney 1998; Och, Ueffing, and Ney 2001; Germann et al. 2001). In addition, these models are the starting point for refined phrase-based statistical (Och and Weber 1998; Och, Tillmann, and Ney 1999) or example-based translation systems (Brown 1997). In such systems, the quality of the machine translation output directly depends on the quality of the initial word alignment (Och and Ney 2000). 21 Computational Linguistics Volume 29, Number 1 Another application of word alignments is in the field of word sense disambiguation"
J03-1002,P01-1067,0,0.187275,"nt models dependent on word classes (as in Models 4 and 5). increasing the number of alignments used in the approximation of the EM algorithm for the fertility-based alignment models. Further improvements in alignments are expected to be produced through the adoption of cognates (Simard, Foster, and Isabelle 1992) and from statistical alignment 45 Computational Linguistics Volume 29, Number 1 models based on word groups rather than single words (Och, Tillmann, and Ney 1999). The use of models that explicitly deal with the hierarchical structures of natural language is very promising (Wu 1996; Yamada and Knight 2001). We plan to develop structured models for the lexicon, alignment, and fertility probabilities using maximum-entropy models. This is expected to allow an easy integration of more dependencies, such as in a second-order alignment model, without running into the problem of the number of alignment parameters getting unmanageably large. Furthermore, it will be important to verify the applicability of the statistical alignment models examined in this article to less similar language pairs such as ChineseEnglish and Japanese-English. Appendix: Efficient Training of Fertility-Based Alignment Models I"
J03-1002,H01-1035,0,0.216375,"Missing"
J03-1002,P00-1027,0,0.152889,"d sentences and that the sentences are segmented into words. Obviously, there are additional implicit assumptions in the models that are needed to obtain a good alignment quality. For example, in languages with a very rich morphology, such as Finnish, a trivial segmentation produces a high number of words that occur only once, and every learning method suffers from a significant data sparseness problem. 1.2 Applications There are numerous applications for word alignments in natural language processing. These applications crucially depend on the quality of the word alignment (Och and Ney 2000; Yarowsky and Wicentowski 2000). An obvious application for word alignment methods is the automatic extraction of bilingual lexica and terminology from corpora (Smadja, McKeown, and Hatzivassiloglou 1996; Melamed 2000). Statistical alignment models are often the basis of single-word-based statistical machine translation systems (Berger et al. 1994; Wu 1996; Wang and Waibel 1998; Nießen et al. 1998; Garc´ıa-Varea, Casacuberta, and Ney 1998; Och, Ueffing, and Ney 2001; Germann et al. 2001). In addition, these models are the starting point for refined phrase-based statistical (Och and Weber 1998; Och, Tillmann, and Ney 1999) o"
J03-1002,C96-2141,1,\N,Missing
J03-1002,C98-2153,0,\N,Missing
J03-1002,J04-4002,1,\N,Missing
J03-1002,C98-1006,0,\N,Missing
J03-1002,C98-2157,1,\N,Missing
J03-1005,H94-1028,0,0.0291404,"Missing"
J03-1005,J90-2002,0,0.88804,"help us to focus on the most relevant details of the DP-based search procedure. The simplified set of parameters leads to an unrealistic assumption about the length of the source and target sentence, namely, I = J. During the translation experiments we will, of course, not make this assumption. The implementation details for using the full set of IBM-4 model parameters are given in Section 3.9.2. 100 Tillmann and Ney DP Beam Search for Statistical MT 2.2 Search Algorithms for Statistical Machine Translation In this section, we give a short overview of search procedures used in statistical MT: Brown et al. (1990) and Brown et al. (1993) describe a statistical MT system that is based on the same statistical principles as those used in most speech recognition systems (Jelinek 1976). Berger et al. (1994) describes the French-to-English Candide translation system, which uses the translation model proposed in Brown et al. (1993). A detailed description of the decoder used in that system is given in Berger et al. (1996) but has never been published in a paper: Throughout the search process, partial hypotheses are maintained in a set of priority queues. There is a single priority queue for each subset of cov"
J03-1005,J93-2003,0,0.0671091,"Missing"
J03-1005,J92-4003,0,0.0290371,"ds f aligned to the same target word e (which is called the “head”) is placed, and (2) the remaining source words are placed. Two separate distributions are used for these two cases. For placing the “head” the center function center (i) (Brown et al. [1993] uses the notation i ) is used: the average position of the source words with which the target word ei−1 is aligned. The distortion probabilities are class-based: They depend on the word class F(f ) of a covered source word f as well as on the word class E(e) of the previously generated target word e. The classes are automatically trained (Brown et al. 1992). When the IBM-4 model parameters are used during search, an input sentence can be processed one source position at a time in a certain order primarily determined by the distortion probabilities. We will use the following simplified set of translation model parameters: lexicon probabilities p(f |e) and distortion probabilities p(j |j , J). Here, j is the currently covered input sentence position and j is the previously covered input sentence position. The input sentence length J is included, since we would like to think of the distortion probability as normalized according to J. No fertility"
J03-1005,P98-2158,0,0.110968,"Missing"
J03-1005,P01-1030,0,0.778852,"rkov model alignments as used in speech recognition is presented in Tillmann, Vogel, Ney, and Zubiaga (1997) and Tillmann, Vogel, Ney, Zubiaga, and Sawaf (1997). This approach assumes that source and target language have the same word order, and word order differences are dealt with in a preprocessing stage. The work by Wu (1996) also uses the original IBM model parameters and obtains an efficient search algorithm by restricting the possible word reorderings using the so-called stochastic bracketing transduction grammar. Three different decoders for the IBM-4 translation model are compared in Germann et al. (2001). The first is a reimplementation of the stack-based decoder described in Berger et al. (1996). The second is a greedy decoder that starts with an approximate solution and then iteratively improves this first rough solution. The third converts the decoding problem into an integer program (IP), and a standard software package for solving IP is used. Although the last approach is guaranteed to find the optimal solution, it is tested only for input sentences of length eight or shorter. This article will present a DP-based beam search decoder for the IBM-4 translation model. The decoder is designe"
J03-1005,J99-4005,0,0.666526,"of the algorithm applied in the experiments in this article is not restricted to the IBM translation models or to the simplified translation model used in the description of the algorithm in Section 3. Since the efficiency of the beam search approach is based on restrictions on the allowed coverage vectors C alone, the approach may be used for different types of translation models as well (e.g., for the multiword-based translation model proposed in Och, Tillmann, and Ney [1999]). On the other hand, since the decoding problem for the IBM-4 translation model is provably NP-complete, as shown in Knight (1999) and Germann et al. (2001), word reordering restrictions as introduced in this article are essential for obtaining an efficient search algorithm that guarantees that a solution close to the optimal one will be found. Appendix: Quantification of Reordering Restrictions To quantify the reordering restrictions in Section 3.5, the four non-negative numbers numskip, widthskip, nummove, and widthmove are used (widthskip corresponds to L, widthmove corresponds to R in Section 3.4; here, we use a more intuitive notation). Within the implementation of the DP search, the restrictions are provided to the"
J03-1005,niessen-etal-2000-evaluation,1,0.611565,"own for German-to-English translation, as the most detailed experiments are conducted for that direction. Section 4.2.6 gives translation results for the translation direction English to German. In Section 4.3, translation results for the Canadian Hansards task are reported. 118 Tillmann and Ney DP Beam Search for Statistical MT 4.1 Performance Measures for Translation Experiments To measure the performance of the translation methods, we use three types of automatic and easy-to-use measures of the translation errors. Additionally, a subjective evaluation involving human judges is carried out (Niessen et al. 2000). The following evaluation criteria are employed: • WER (word error rate): The WER is computed as the minimum number of substitution, insertion, and deletion operations that have to be performed to convert the generated string into the reference target string. This performance criterion is widely used in speech recognition. The minimum is computed using a DP algorithm and is typically referred to as edit or Levenshtein distance. • mWER (multireference WER): We use the Levenshtein distance between the automatic translation and several reference translations as a measure of the translation error"
J03-1005,C00-2163,1,0.350573,"e model of the target language, whereas Pr (f1J |eI1 ) is the string translation model. The language model probability is computed using a trigram language model. The string translation probability Pr (f1J |eI1 ) is modeled using a series of five models of increasing complexity in training. Here, the model used for the translation experiments is the IBM-4 model. This model uses the same parameter set as the IBM-5 model, which in preliminary experiments did not yield better translation results. The actual implementation used during the experiments is described in AlOnaizan et al. (1999) and in Och and Ney (2000). The argmax operation denotes the search problem (i.e., the generation of the output sentence in the target language). The overall architecture of the statistical translation approach is summarized in Figure 1. In general, as shown in this figure, there may be additional transformations to make the translation task simpler for the algorithm. The transformations may range from simple word categorization to more complex preprocessing steps that require some parsing of the source string. In this article, however, we will use only word catego99 Computational Linguistics Volume 29, Number 1 rizati"
J03-1005,W99-0604,1,0.541368,"Missing"
J03-1005,W01-1408,1,0.896927,"Missing"
J03-1005,C00-2123,1,0.540335,"on. The third converts the decoding problem into an integer program (IP), and a standard software package for solving IP is used. Although the last approach is guaranteed to find the optimal solution, it is tested only for input sentences of length eight or shorter. This article will present a DP-based beam search decoder for the IBM-4 translation model. The decoder is designed to carry out an almost full search with a small number of search errors and with little performance degradation as measured by the word error criterion. A preliminary version of the work presented here was published in Tillmann and Ney (2000). 3. Beam Search in Statistical Machine Translation 3.1 Inverted Alignment Concept To explicitly describe the word order difference between source and target language, Brown et al. (1993) introduced an alignment concept, in which a source position j is mapped to exactly one target position i: regular alignment: j → i = aj 101 Computational Linguistics Volume 29, Number 1 . May of fourth the on you visit not can colleague my case this In I d F n i a e l s l e m k a n n mK S a v M n b . e o i m i a i e i l e e i c s n l r h u e t t c e g h e n e n Figure 2 Regular alignment example for the trans"
J03-1005,P97-1037,1,0.871533,"Missing"
J03-1005,P97-1047,0,0.545008,"is a single priority queue for each subset of covered positions in the source string. In practice, the priority queues are initialized only on demand; far fewer than the full number of queues possible are actually used. The priority queues are limited in size, and only the 1,000 hypotheses with the highest probability are maintained. Each priority queue is assigned a threshold to select the hypotheses that are going to be extended, and the process of assigning these thresholds is rather complicated. A restriction on the possible word reorderings, which is described in Section 3.6, is applied. Wang and Waibel (1997) presents a search algorithm for the IBM-2 translation model based on the A∗ concept and multiple stacks. An extension of this algorithm is demonstrated in Wang and Waibel (1998). Here, a reshuffling step on top of the original decoder is used to handle more complex translation models (e.g., the IBM-3 model is added). Translation approaches that use the IBM-2 model parameters but are based on DP are presented in Garc´ıa-Varea, Casacuberta, and Ney (1998) and Niessen et al. (1998). An approach based on the hidden Markov model alignments as used in speech recognition is presented in Tillmann, Vo"
J03-1005,P96-1021,0,0.268838,"d to handle more complex translation models (e.g., the IBM-3 model is added). Translation approaches that use the IBM-2 model parameters but are based on DP are presented in Garc´ıa-Varea, Casacuberta, and Ney (1998) and Niessen et al. (1998). An approach based on the hidden Markov model alignments as used in speech recognition is presented in Tillmann, Vogel, Ney, and Zubiaga (1997) and Tillmann, Vogel, Ney, Zubiaga, and Sawaf (1997). This approach assumes that source and target language have the same word order, and word order differences are dealt with in a preprocessing stage. The work by Wu (1996) also uses the original IBM model parameters and obtains an efficient search algorithm by restricting the possible word reorderings using the so-called stochastic bracketing transduction grammar. Three different decoders for the IBM-4 translation model are compared in Germann et al. (2001). The first is a reimplementation of the stack-based decoder described in Berger et al. (1996). The second is a greedy decoder that starts with an approximate solution and then iteratively improves this first rough solution. The third converts the decoding problem into an integer program (IP), and a standard"
J03-1005,C00-2162,1,\N,Missing
J03-1005,H92-1073,0,\N,Missing
J03-1005,C96-2141,1,\N,Missing
J03-1005,C94-2178,0,\N,Missing
J03-1005,P00-1004,1,\N,Missing
J03-1005,J96-1002,0,\N,Missing
J03-1005,C98-2153,0,\N,Missing
J03-1005,J04-4002,1,\N,Missing
J03-1005,J93-1006,0,\N,Missing
J03-1005,P99-1065,1,\N,Missing
J03-1005,P98-2230,0,\N,Missing
J03-1005,C98-2225,0,\N,Missing
J03-1005,P98-2162,0,\N,Missing
J03-1005,C98-2157,0,\N,Missing
J03-1005,P98-2221,0,\N,Missing
J03-1005,C98-2216,0,\N,Missing
J03-1005,P00-1056,1,\N,Missing
J04-2003,H93-1039,0,0.0719574,"article takes a different point of view: Even if full bilingual training data are scarce, monolingual knowledge sources like morphological analyzers and data for training the target language model as well as conventional dictionaries (one word and its translation[s] per entry) may be available and of substantial usefulness for improving the performance of statistical translation systems. This is especially the case for more-inflecting major languages like German. The use of dictionaries to augment or replace parallel corpora has already been examined by Brown, Della Pietra, Della Pietra, and Goldsmith (1993) and Koehn and Knight (2001), for instance. 2. Morpho-syntactic Information A prerequisite for the methods for improving the quality of statistical machine translation described in this article is the availability of various kinds of morphological and syntactic information. This section describes the output resulting from morphosyntactic analysis and explains which parts of the analysis are used and how the output is represented for further processing. 2.1 Description of the Analysis Results For obtaining the required morpho-syntactic information, the following analyzers for German and English"
J04-2003,J90-2002,0,0.188224,"lic machine translation system. For this purpose, the lexicon should contain base forms of words and the grammatical category, 182 Nießen and Ney SMT with Scarce Resources subcategorization features, and semantic information in order to enable the size of the lexicon to be reduced and in order to account for unknown word forms, that is, word forms not present explicitly in the dictionary. Today’s statistical machine translation systems build upon the work of P. F. Brown and his colleagues at IBM. The translation models they presented in various papers between 1988 and 1993 (Brown et al. 1988; Brown et al. 1990; Brown, Della Pietra, Della Pietra, and Mercer 1993) are commonly referred to as IBM models 1–5, based on the numbering in Brown, Della Pietra, Della Pietra, and Mercer (1993). The underlying (probabilistic) lexicon contains only pairs of full forms. On the other hand, Brown et al. (1992) had already suggested word forms be annotated with morpho-syntactic information, but they did not perform any investigation on the effects. 1.3.2 Translation with Scarce Resources. Some recent publications, like Al-Onaizan et al. (2000), have dealt with the problem of translation with scarce resources. AlOna"
J04-2003,C88-1016,0,0.108908,"rtually every symbolic machine translation system. For this purpose, the lexicon should contain base forms of words and the grammatical category, 182 Nießen and Ney SMT with Scarce Resources subcategorization features, and semantic information in order to enable the size of the lexicon to be reduced and in order to account for unknown word forms, that is, word forms not present explicitly in the dictionary. Today’s statistical machine translation systems build upon the work of P. F. Brown and his colleagues at IBM. The translation models they presented in various papers between 1988 and 1993 (Brown et al. 1988; Brown et al. 1990; Brown, Della Pietra, Della Pietra, and Mercer 1993) are commonly referred to as IBM models 1–5, based on the numbering in Brown, Della Pietra, Della Pietra, and Mercer (1993). The underlying (probabilistic) lexicon contains only pairs of full forms. On the other hand, Brown et al. (1992) had already suggested word forms be annotated with morpho-syntactic information, but they did not perform any investigation on the effects. 1.3.2 Translation with Scarce Resources. Some recent publications, like Al-Onaizan et al. (2000), have dealt with the problem of translation with scar"
J04-2003,1992.tmi-1.8,0,0.736083,"order to account for unknown word forms, that is, word forms not present explicitly in the dictionary. Today’s statistical machine translation systems build upon the work of P. F. Brown and his colleagues at IBM. The translation models they presented in various papers between 1988 and 1993 (Brown et al. 1988; Brown et al. 1990; Brown, Della Pietra, Della Pietra, and Mercer 1993) are commonly referred to as IBM models 1–5, based on the numbering in Brown, Della Pietra, Della Pietra, and Mercer (1993). The underlying (probabilistic) lexicon contains only pairs of full forms. On the other hand, Brown et al. (1992) had already suggested word forms be annotated with morpho-syntactic information, but they did not perform any investigation on the effects. 1.3.2 Translation with Scarce Resources. Some recent publications, like Al-Onaizan et al. (2000), have dealt with the problem of translation with scarce resources. AlOnaizan et al. report on an experiment involving Tetun-to-English translation by different groups, including one using statistical machine translation. Al-Onaizan et al. assume the absence of linguistic knowledge sources such as morphological analyzers and dictionaries. Nevertheless, they fou"
J04-2003,J93-2003,0,0.0620828,"f being a valid word sequence in the target language and a probability Pr(eI1 |f1J ) of being a translation for the given source language string f1J = f1 · · · fJ . According to Bayes’ decision rule, the optimal translation for f1J is the target string that maximizes the product of the target language model Pr(eI1 ) and the string translation model Pr(f1J |eI1 ). Many existing systems for statistical machine translation (Garc´ıa-Varea and Casacuberta 2001; Germann et al. 2001; Nießen et al. 1998; Och, Tillmann, and Ney 1999) implement models presented by Brown, Della Pietra, Della Pietra, and Mercer (1993): The correspondence between the words in the source and the target strings is described by alignments that assign target word positions to each source word position. The probability that a certain target language word will occur in the target string is assumed to depend basically only on the source words aligned with it. 1.3 Related Work 1.3.1 Morphology. Some publications have already dealt with the treatment of morphology in the framework of language modeling and speech recognition: Kanevsky, Roukos, and Sedivy (1997) propose a statistical language model for inflected languages. They decomp"
J04-2003,P00-1006,0,0.0144127,"}, with the fully inflected original word form F:  h3F,T,L,˜e (e, f , tn0 ) = 1 0 if (∗∗) and F = f otherwise In terms of the hierarchy introduced in Section 4.1, this means that information at three different levels in the hierarchy is combined. The subsets T of relevant tags mentioned previously fix the intermediate level.2 This choice of the types of features as well as the choice of the subsets T is reasonable but somewhat arbitrary. Alternatively one can think of defining a much more general set of features and applying some method of feature selection, as has been done, for example, by Foster (2000), who compared different methods for feature selection within the task of translation modeling for statistical machine translation. Note that the log-linear model introduced here uses one parameter per feature. For the Verbmobil task, for example, there are approximately 162, 000 parameters: 47,800 for the first-order features, 55,700 for the second-order features, and 58,500 for the third-order features. No feature selection or threshold was applied: All features seen in training were used. 4.2.2 Training Procedure. The overall process of training and testing with hierarchical lexicon models"
J04-2003,2001.mtsummit-papers.22,0,0.0211053,"Missing"
J04-2003,P01-1030,0,0.347324,"ew: Even if full bilingual training data are scarce, monolingual knowledge sources like morphological analyzers and data for training the target language model as well as conventional dictionaries (one word and its translation[s] per entry) may be available and of substantial usefulness for improving the performance of statistical translation systems. This is especially the case for more-inflecting major languages like German. The use of dictionaries to augment or replace parallel corpora has already been examined by Brown, Della Pietra, Della Pietra, and Goldsmith (1993) and Koehn and Knight (2001), for instance. 2. Morpho-syntactic Information A prerequisite for the methods for improving the quality of statistical machine translation described in this article is the availability of various kinds of morphological and syntactic information. This section describes the output resulting from morphosyntactic analysis and explains which parts of the analysis are used and how the output is represented for further processing. 2.1 Description of the Analysis Results For obtaining the required morpho-syntactic information, the following analyzers for German and English were applied: gertwol and e"
J04-2003,C90-3030,0,0.0149877,"the availability of various kinds of morphological and syntactic information. This section describes the output resulting from morphosyntactic analysis and explains which parts of the analysis are used and how the output is represented for further processing. 2.1 Description of the Analysis Results For obtaining the required morpho-syntactic information, the following analyzers for German and English were applied: gertwol and engtwol for lexical analysis and gercg and engcg for morphological and syntactic disambiguation. For a description of the underlying approach, the reader is referred to Karlsson (1990). Tables 1 and 2 give examples of the information provided by these tools. 2.2 Treatment of Ambiguity The examples in Tables 1 and 2 demonstrate the capability of the tools to disambiguate among different readings: For instance, they infer that the word wollen is a verb in the indicative present first-person plural form. Without any context taken into account, 183 Computational Linguistics Volume 30, Number 2 Table 1 Sample analysis of a German sentence. Input: Wir wollen nach dem Abendessen nach Essen aufbrechen. (In English: We want to start for Essen after dinner.) Original Base form Tags W"
J04-2003,W01-0504,0,0.0531451,"Missing"
J04-2003,H01-1007,0,0.00826068,". Number of word forms Number of base forms English German 6,871 3,268 10,157 6,667 Table 8 Statistics for the test sets for German to English translation: Verbmobil Eval-2000 (Test and Develop) and Nespole! Verbmobil Test Develop Number of sentences Number of running word forms in German part Number of word forms in German part Trigram LM perplexity of reference translation 251 2,628 429 30.5 Nespole! 276 3,159 434 28.1 70 456 180 76.9 7.1.2 Nespole!. Nespole! is a research project that ran from January 2000 to June 2002. It aimed to provide multimodel support for negotiation (Nespole! 2000; Lavie et al. 2001). Table 5 summarizes the corpus statistics of the Nespole! training set. Table 8 provides the corresponding figures for the test set used in this work. 7.2 The Translation System For testing we used the alignment template translation system, described in Och, Tillmann, and Ney (1999). Training the parameters for this system entails training of IBM model 4 parameters in both translation directions and combining the resulting alignments into one symmetrized alignment. From this symmetrized alignment, the lexicon probabilities as well as the so-called alignment templates are extracted. The latter"
J04-2003,1983.tc-1.13,0,0.457135,"Missing"
J04-2003,C00-2162,1,0.906429,"Missing"
J04-2003,2001.mtsummit-papers.45,1,0.838327,"Missing"
J04-2003,P98-2158,0,0.0153532,"n statistical machine translation, every target language string eI1 = e1 · · · eI is assigned a probability Pr(eI1 ) of being a valid word sequence in the target language and a probability Pr(eI1 |f1J ) of being a translation for the given source language string f1J = f1 · · · fJ . According to Bayes’ decision rule, the optimal translation for f1J is the target string that maximizes the product of the target language model Pr(eI1 ) and the string translation model Pr(f1J |eI1 ). Many existing systems for statistical machine translation (Garc´ıa-Varea and Casacuberta 2001; Germann et al. 2001; Nießen et al. 1998; Och, Tillmann, and Ney 1999) implement models presented by Brown, Della Pietra, Della Pietra, and Mercer (1993): The correspondence between the words in the source and the target strings is described by alignments that assign target word positions to each source word position. The probability that a certain target language word will occur in the target string is assumed to depend basically only on the source words aligned with it. 1.3 Related Work 1.3.1 Morphology. Some publications have already dealt with the treatment of morphology in the framework of language modeling and speech recogniti"
J04-2003,W99-0604,1,0.344735,"Missing"
J04-2003,P98-2162,0,0.0338401,"Missing"
J04-2003,2001.mtsummit-papers.68,0,0.0243673,"nslation system, described in Och, Tillmann, and Ney (1999). Training the parameters for this system entails training of IBM model 4 parameters in both translation directions and combining the resulting alignments into one symmetrized alignment. From this symmetrized alignment, the lexicon probabilities as well as the so-called alignment templates are extracted. The latter are translation patterns which capture phrase-level translation pairs. 7.3 Performance Measures The following evaluation criteria were used in the experiments: BLEU (Bilingual Evaluation Understudy): This score, proposed by Papineni et al. (2001), is based on the notion of modified n-gram precision, with n ∈ {1, . . . , 4}: All candidate unigram, bigram, trigram, and four-gram counts are collected and clipped against their corresponding maximum reference counts. The reference n-gram counts are calculated on a corpus 197 Computational Linguistics Volume 30, Number 2 of reference translations for each input sentence. The clipped candidate counts are summed and normalized by the total number of candidate ngrams. The geometric mean of the modified precision scores for a test corpus is calculated and multiplied by an exponential brevity pe"
J04-2003,C00-2123,1,0.728066,"ace forms: (‘Zimmer-noun-sg.’| ‘room’) and (‘Zimmer-noun-pl.’|‘rooms’). Note that this augmented dictionary, in the following denoted by D , has more entries than D as a result of the step of generating all readings. The two entries (‘beabsichtigt’|‘intends’) and (‘beabsichtigt’|‘intended’), for example, produce three new entries: (‘beabsichtigt-verb-ind.-pres.-sg.3rd’|‘intends’), (‘beabsichtigt-verb-past-part.’|‘intended’), and (‘beabsichtigtadjective-pos.’|‘intended’). 5.2 Multiword Phrases Some recent publications deal with the automatic detection of multiword phrases (Och and Weber 1998; Tillmann and Ney 2000). These methods are very useful, but they have one drawback: They rely on sufficiently large training corpora, because they detect the phrases from automatically learned word alignments. In this section a method for detecting multiword phrases is suggested which merely requires monolingual syntactic analyzers and a conventional dictionary. Some multiword phrases which jointly fulfill a syntactic function are provided by the analyzers. The phrase irgend etwas (‘anything’), for example, may form either an indefinite determiner or an indefinite pronoun. irgend=etwas is merged by the analyzer in o"
J04-2003,P02-1040,0,\N,Missing
J04-2003,C98-2153,0,\N,Missing
J04-2003,C98-2157,0,\N,Missing
J04-4002,J00-1004,0,0.0526268,"Missing"
J04-4002,H94-1028,0,0.0189479,"Missing"
J04-4002,J96-1002,0,0.113258,"Missing"
J04-4002,J90-2002,0,0.471491,"Computational Linguistics Volume 30, Number 4 Institute of Standards and Technology (NIST)/TIDES MT evaluations 2001 through 20031 obtain the best results. In addition, the field of statistical machine translation is rapidly progressing, and the quality of systems is getting better and better. An important factor in these improvements is definitely the availability of large amounts of data for training statistical models. Yet the modeling, training, and search methods have also improved since the field of statistical machine translation was pioneered by IBM in the late 1980s and early 1990s (Brown et al. 1990; Brown et al. 1993; Berger et al. 1994). This article focuses on an important improvement, namely, the use of (generalized) phrases instead of just single words as the core elements of the statistical translation model. We describe in Section 2 the basics of our statistical translation model. We suggest the use of a log-linear model to incorporate the various knowledge sources into an overall translation system and to perform discriminative training of the free model parameters. This approach can be seen as a generalization of the originally suggested source–channel modeling framework for sta"
J04-4002,J93-2003,0,0.237322,"uistics Volume 30, Number 4 Institute of Standards and Technology (NIST)/TIDES MT evaluations 2001 through 20031 obtain the best results. In addition, the field of statistical machine translation is rapidly progressing, and the quality of systems is getting better and better. An important factor in these improvements is definitely the availability of large amounts of data for training statistical models. Yet the modeling, training, and search methods have also improved since the field of statistical machine translation was pioneered by IBM in the late 1980s and early 1990s (Brown et al. 1990; Brown et al. 1993; Berger et al. 1994). This article focuses on an important improvement, namely, the use of (generalized) phrases instead of just single words as the core elements of the statistical translation model. We describe in Section 2 the basics of our statistical translation model. We suggest the use of a log-linear model to incorporate the various knowledge sources into an overall translation system and to perform discriminative training of the free model parameters. This approach can be seen as a generalization of the originally suggested source–channel modeling framework for statistical machine tr"
J04-4002,2003.mtsummit-papers.6,0,0.0862691,"Missing"
J04-4002,P98-2158,0,0.0628605,"Missing"
J04-4002,P01-1027,1,0.202339,"Missing"
J04-4002,P01-1030,0,0.0237461,"uning: beam search. In pruning, we constrain the set of considered translation candidates (the “beam”) only to the promising ones. We compare in beam search those hypotheses that cover different parts of the input sentence. This makes the comparison of the probabilities problematic. Therefore, we integrate an admissible estimation of the remaining probabilities to arrive at a complete translation (Section 5.6) Many of the other search approaches suggested in the literature do not meet the described aims: • Neither optimal A* search (Och, Ueffing, and Ney 2001) nor optimal integer programming (Germann et al. 2001) for statistical MT allows efficient search for long sentences. • Greedy search algorithms (Wang 1998; Germann et al. 2001) typically commit severe search errors (Germann et al. 2001). • Other approaches to solving the search problem obtain polynomial time algorithms by assuming monotone alignments (Tillmann et al. 1997) or imposing a simplified recombination structure (Nießen et al. 1998). Others make simplifying assumptions about the search space (Garc´ıa-Varea, Casacuberta, and Ney 1998; Garc´ıa-Varea et al. 2001), as does the original IBM stack search decoder (Berger et al. 1994). All thes"
J04-4002,P03-1011,0,0.0521328,"a translation of a new sentence be composed of a set of alignment templates that covers the source sentence and the produced translation. Other feature functions score the well-formedness of the produced target language sentence (i.e., language model feature functions), the number of produced words, or the order of the alignment templates. Note that all components of our statistical machine translation model are purely data-driven and that there is no need for linguistically annotated corpora. This is an important advantage compared to syntax-based translation models (Yamada and Knight 2001; Gildea 2003; Charniak, Knight, and Yamada 2003) that require a parser for source or target language. In Section 5, we describe in detail our search algorithm and discuss an efficient implementation. We use a dynamic-programming-based beam search algorithm that allows a trade-off between efficiency and quality. We also discuss the use of heuristic functions to reduce the number of search errors for a fixed beam size. In Section 6, we describe various results obtained on different tasks. For the German–English Verbmobil task, we analyze the effect of various system compo1 http://www.nist.gov/speech/tests/m"
J04-4002,J99-4005,0,0.506674,"sible translations that can be produced given a certain input sentence. To solve this problem, we define as reference translation for maximum-entropy training each sentence that has the minimal number of word errors with respect to any of the reference translations in the n-best list. More details of the training procedure can be found in Och and Ney (2002). 5. Search In this section, we describe an efficient search architecture for the alignment template model. 5.1 General Concept In general, the search problem for statistical MT even using only Model 1 of Brown et al. (1993) is NP-complete (Knight 1999). Therefore, we cannot expect to develop 431 Computational Linguistics Volume 30, Number 4 efficient search algorithms that are guaranteed to solve the problem without search errors. Yet for practical applications it is acceptable to commit some search errors (Section 6.1.2). Hence, the art of developing a search algorithm lies in finding suitable approximations and heuristics that allow an efficient search without committing too many search errors. In the development of the search algorithm described in this section, our main aim is that the search algorithm should be efficient. It should be"
J04-4002,N03-1017,1,0.234788,"Missing"
J04-4002,W02-1018,0,0.163773,"to be distinguished from the use of the term in a linguistic sense. The learned bilingual phrases are not constrained by linguistic phrase boundaries. Compared to the word-based statistical translation models in Brown et al. (1993), this model is based on a (statistical) phrase lexicon instead of a single-word-based lexicon. Looking at the results of the recent machine translation evaluations, this approach seems currently to give the best results, and an increasing number of researchers are working on different methods for learning phrase translation lexica for machine translation purposes (Marcu and Wong 2002; Venugopal, Vogel, and Waibel 2003; Tillmann 2003; Koehn, Och, and Marcu 2003). Our approach to learning a phrase translation lexicon works in two stages: In the first stage, we compute an alignment between words, and in the second stage, we extract the aligned phrase pairs. In our machine translation system, we then use generalized versions of these phrases, called alignment templates, that also include the word alignment and use word classes instead of the words themselves. In Section 4, we describe the various components of the statistical translation model. The backbone of the translation"
J04-4002,H01-1062,0,0.0651359,"Missing"
J04-4002,niessen-etal-2000-evaluation,1,0.307398,"ults. Therefore, we use various criteria. In the following experiments, we use: • WER (word error rate)/mWER (multireference word error rate): The WER is computed as the minimum number of substitution, insertion, and deletion operations that have to be performed to convert the generated sentence into the target sentence. In the case of the multireference word error rate for each test sentence, not just a single reference translation is used, as for the WER, but a whole set of reference translations. For each translation hypothesis, the edit distance to the most similar sentence is calculated (Nießen et al. 2000). • PER (position-independent WER): A shortcoming of the WER is the fact that it requires a perfect word order. An acceptable sentence can have a word order that is different from that of the target sentence, so the WER measure alone could be misleading. To overcome this problem, we introduce as an additional measure the position-independent word error rate. This measure compares the words in the two sentences, ignoring the word order. • BLEU (bilingual evalutation understudy) score: This score measures the precision of unigrams, bigrams, trigrams, and 4-grams with respect to a whole set of re"
J04-4002,E99-1010,1,0.31818,"onds to a bilingual phrase together with an alignment within this phrase. Figure 4 shows examples of alignment templates. ˜ is represented as a matrix with J · (I + 1) binary elements. A The alignment A matrix element with value 1 means that the words at the corresponding positions are aligned, and the value 0 means that the words are not aligned. If a source word is not aligned with a target word, then it is aligned with the empty word e0 , which is at the imaginary position i = 0.   The classes used in FJ1 and EI1 are automatically trained bilingual classes using the method described in Och (1999) and constitute a partition of the vocabulary of source and target language. In general, we are not limited to disjoint classes as long as each specific instance of a word is disambiguated, that is, uniquely belongs to a specific class. In the following, we use the class function C to map words to their classes. Hence, it would be possible to employ parts-of-speech or semantic categories instead of the automatically trained word classes used here. The use of classes instead of the words themselves has the advantage of better generalization. For example, if there exist classes in source and tar"
J04-4002,P03-1021,1,0.349853,"probability in Bayes’ decision rule is referred to as discriminative training (Ney 1995) because we directly take into account the overlap in the probability distributions. The optimization problem under this criterion has very nice properties: There is one unique global optimum, and there are algorithms (e.g. gradient descent) that are guaranteed to converge to the global optimum. Yet the ultimate goal is to obtain good translation quality on unseen test data. An alternative training criterion therefore directly optimizes translation quality as measured by an automatic evaluation criterion (Och 2003). Typically, the translation probability Pr(eI1 |f1J ) is decomposed via additional hidden variables. To include these dependencies in our log-linear model, we extend the feature functions to include the dependence on the additional hidden variable. Using for example the alignment aJ1 as hidden variable, we obtain M feature functions of the form hm (eI1 , f1J , aJ1 ), m = 1, . . . , M and the following model:   M exp λm hm (eI1 , f1J , aJ1 ) m=1   Pr(eI1 , aJ1 |f1J ) =  M  I , f J , a J ) λ h (e J exp I m m   1 m=1 1 1 e ,a 1 1 Obviously, we can perform the same step for translation"
J04-4002,P02-1038,1,0.743587,"ical Machine Translation We are given a source (French) sentence f = f1J = f1 , . . . , fj , . . . , fJ , which is to be translated into a target (English) sentence e = eI1 = e1 , . . . , ei , . . . , eI . Among all possible target sentences, we will choose the sentence with the highest probability:2 ˆeI1 = argmax {Pr(eI1 |f1J )} (1) eI1 The argmax operation denotes the search problem, that is, the generation of the output sentence in the target language. As an alternative to the often used source–channel approach (Brown et al. 1993), we directly model the posterior probability Pr(eI1 |f1J ) (Och and Ney 2002). An especially well-founded framework for doing this is the maximum-entropy framework (Berger, Della Pietra, and Della Pietra 1996). In this framework, we have a set of M feature functions hm (eI1 , f1J ), m = 1, . . . , M. For each feature function, there exists a model 2 The notational convention employed in this article is as follows. We use the symbol Pr(·) to denote general probability distributions with (nearly) no specific assumptions. In contrast, for model-based probability distributions, we use the generic symbol p(·). 419 Computational Linguistics Volume 30, Number 4 parameter λm ,"
J04-4002,J03-1002,1,0.0920734,"ion model and the alignment model is given by Pr(f1J |eI1 ) =  Pr(f1J , aJ1 |eI1 ) (5) aJ1 The alignment aJ1 may contain alignments aj = 0 with the “empty” word e0 to account for source words that are not aligned with any target word. In general, the statistical model depends on a set of unknown parameters θ that is learned from training data. To express the dependence of the model on the parameter set, we use the following notation: Pr(f1J , aJ1 |eI1 ) = pθ (f1J , aJ1 |eI1 ) (6) A detailed description of different specific statistical alignment models can be found in Brown et al. (1993) and Och and Ney (2003). Here, we use the hidden Markov model (HMM) alignment model (Vogel, Ney, and Tillmann 1996) and Model 4 of Brown et al. (1993) to compute the word alignment for the parallel training corpus. To train the unknown parameters θ, we are given a parallel training corpus consisting of S sentence pairs {(fs , es ): s = 1, . . . , S}. For each sentence pair (fs , es ), the alignment variable is denoted by a = aJ1 . The unknown parameters θ are determined by maximizing the likelihood on the parallel training corpus: θˆ = argmax θ  S  s=1  pθ (fs , a |es ) (7) a This optimization can be performed us"
J04-4002,W01-1408,1,0.0914589,"Missing"
J04-4002,2001.mtsummit-papers.68,0,0.0374077,"s the fact that it requires a perfect word order. An acceptable sentence can have a word order that is different from that of the target sentence, so the WER measure alone could be misleading. To overcome this problem, we introduce as an additional measure the position-independent word error rate. This measure compares the words in the two sentences, ignoring the word order. • BLEU (bilingual evalutation understudy) score: This score measures the precision of unigrams, bigrams, trigrams, and 4-grams with respect to a whole set of reference translations, with a penalty for too-short sentences (Papineni et al. 2001). Unlike all other evaluation criteria used here, BLEU measures accuracy, that is, the opposite of error rate. Hence, the larger BLEU scores, the better. In the following, we analyze the effect of various system components: alignment template length, search pruning, and language model n-gram size. A systematic evaluation of the alignment template system comparing it with other translation approaches (e.g., rule-based) has been performed in the Verbmobil project and is described in Tessiore and von Hahn (2000). There, the alignment-template-based system achieved a significantly larger number of"
J04-4002,W03-1001,0,0.0132657,"istic sense. The learned bilingual phrases are not constrained by linguistic phrase boundaries. Compared to the word-based statistical translation models in Brown et al. (1993), this model is based on a (statistical) phrase lexicon instead of a single-word-based lexicon. Looking at the results of the recent machine translation evaluations, this approach seems currently to give the best results, and an increasing number of researchers are working on different methods for learning phrase translation lexica for machine translation purposes (Marcu and Wong 2002; Venugopal, Vogel, and Waibel 2003; Tillmann 2003; Koehn, Och, and Marcu 2003). Our approach to learning a phrase translation lexicon works in two stages: In the first stage, we compute an alignment between words, and in the second stage, we extract the aligned phrase pairs. In our machine translation system, we then use generalized versions of these phrases, called alignment templates, that also include the word alignment and use word classes instead of the words themselves. In Section 4, we describe the various components of the statistical translation model. The backbone of the translation model is the alignment template feature function,"
J04-4002,C00-2123,1,0.0571653,"A) (27) j 3 Note that here some of the simplifying notation of Section 4 has been used. 433 Computational Linguistics Volume 30, Number 4 If the source sentence contains words that have not been seen in the training data, we introduce a new alignment template that performs a one-to-one translation of each of these words by itself. In the second step, we determine a set of probable target language words for each target word position in the alignment template instantiation. Only these words are then hypothesized in the search. We call this selection of highly probable words observation pruning (Tillmann and Ney 2000). As a criterion for a word e at position i in the alignment template instantiation, we use  δ(Ei , C(e)) · J  j=0 ˜ j) A(i,  ˜  · p(e |fj )  A(i , j) (28) i In our experiments, we hypothesize only the five best-scoring words. A decision is a triple d = (Z, e, l) consisting of an alignment template instantiation Z, the generated word e, and the index l of the generated word in Z. A hypothesis n corresponds to a valid sequence of decisions di1 . The possible decisions are as follows: 1. Start a new alignment template: di = (Zi , ei , 1). In this case, the index l = 1. This decision can be"
J04-4002,J03-1005,1,0.356489,"ch space (Garc´ıa-Varea, Casacuberta, and Ney 1998; Garc´ıa-Varea et al. 2001), as does the original IBM stack search decoder (Berger et al. 1994). All these simplifications ultimately make the search problem simpler but introduce fundamental search errors. In the following, we describe our search algorithm based on the concept of beam search, which allows a trade-off between efficiency and quality by adjusting the size of the beam. The search algorithm can be easily adapted to other phrase-based translation models. For single-word-based search in MT, a similar algorithm has been described in Tillmann and Ney (2003). 5.2 Search Problem Putting everything together and performing search in maximum approximation, we obtain the following decision rule:  M   I I J K K ˆe1 = argmax λm · hm (e1 , f1 , π1 , z1 ) (22) eI1 ,π1K ,zK1 432 m=1 Och and Ney The Alignment Template Approach to Statistical Machine Translation Using the four feature functions AT, AL, WRD, and LM, we obtain the following decision rule:3  ˆeI1 = argmax (23) eI1 ,π1K ,zK1 I  λLM log p(ei |ei−2 , ei−1 ) + λWRD log p(ei |{fj |(i, j) ∈ A}, Ei ) (24) i=1 + K   jπ λAT log p(zk |fjπ k k−1 k=1  ) + λ · |j − j | πk−1 +1 +1 AL πk  +λAL · (J −"
J04-4002,P03-1041,0,0.240823,"Missing"
J04-4002,C96-2141,1,0.565161,"Missing"
J04-4002,P97-1047,0,0.0116127,"f edge probabilities of reaching a goal node is always equal to or smaller than the estimated probability. For an A*-based search algorithm, a good heuristic function is crucial to being able to translate long sentences. For a beam search algorithm, the heuristic function has a different motivation. It is used to improve the scoring of search hypotheses. The goal is to make the probabilities of all hypotheses more comparable, in order to minimize the chance that the hypothesis leading to the optimal translation is pruned away. Heuristic functions for search in statistical MT have been used in Wang and Waibel (1997) and Och, Ueffing, and Ney (2001). Wang and Waibel (1997) have described a simple heuristic function for Model 2 of Brown et al. (1993) that was not admissible. Och, Ueffing, and Ney (2001) have described an admissible heuristic function for Model 4 of Brown et al. (1993) and an almost-admissible heuristic function that is empirically obtained. We have to keep in mind that a heuristic function is helpful only if the overhead introduced in computing the heuristic function is more than compensated for by the gain obtained through a better pruning of search hypotheses. The heuristic functions des"
J04-4002,P98-2230,0,0.174529,"Missing"
J04-4002,P01-1067,0,0.712464,"ion, which requires that a translation of a new sentence be composed of a set of alignment templates that covers the source sentence and the produced translation. Other feature functions score the well-formedness of the produced target language sentence (i.e., language model feature functions), the number of produced words, or the order of the alignment templates. Note that all components of our statistical machine translation model are purely data-driven and that there is no need for linguistically annotated corpora. This is an important advantage compared to syntax-based translation models (Yamada and Knight 2001; Gildea 2003; Charniak, Knight, and Yamada 2003) that require a parser for source or target language. In Section 5, we describe in detail our search algorithm and discuss an efficient implementation. We use a dynamic-programming-based beam search algorithm that allows a trade-off between efficiency and quality. We also discuss the use of heuristic functions to reduce the number of search errors for a fixed beam size. In Section 6, we describe various results obtained on different tasks. For the German–English Verbmobil task, we analyze the effect of various system compo1 http://www.nist.gov/s"
J04-4002,P02-1040,0,\N,Missing
J04-4002,C98-2153,0,\N,Missing
J04-4002,P97-1037,1,\N,Missing
J04-4002,C98-2225,0,\N,Missing
J07-1003,C04-1047,0,0.192817,"n: 3 October 2006. © 2007 Association for Computational Linguistics Computational Linguistics Volume 33, Number 1 calculating and evaluating word confidence measures. Possible applications of confidence measures include: r r r marking words with low confidence as potential errors for post-editing improving translation prediction accuracy in TransType-style interactive machine translation (Gandrabur and Foster 2003; Ueffing and Ney 2005a) combining output from different machine translation systems: Hypotheses with low confidence can be discarded before selecting one of the system translations (Akiba et al. 2004), or the word confidence scores can be used in the generation of new hypotheses from the output of different systems (Jayaraman and Lavie 2005), or the sentence confidence value can be employed for reranking (Blatz et al. 2003). The article is organized as follows: In Section 2, we briefly review the statistical approach to machine translation. The phrase-based translation system, which serves as the basis for one of the direct confidence measures, will be presented. Section 3 gives an overview of related work on confidence estimation for machine translation. Moreover, word posterior probabili"
J07-1003,2004.iwslt-evaluation.8,0,0.00981306,") I,eI1 (1) I,eI1 Through this decomposition of the probability, we obtain two knowledge sources: the translation model Pr( f1J |eI1 ) and the language model Pr(eI1 ). Both can be modeled independently of each other. The translation model is responsible for linking the source string f1J and the target string eI1 . It captures the semantics of the sentence. The target language model captures the well-formedness of the syntax in the target language. Nowadays, most state-of-the-art SMT systems are based on bilingual phrases (Och, Tillmann, and Ney 1999; Koehn, Och, and Marcu 2003; Tillmann 2003; Bertoldi et al. 2004; Vogel et al. 2004; Zens and Ney 2004; Chiang 2005). A more detailed description of 10 Ueffing and Ney Word-Level Confidence Estimation for MT a phrase-based approach to statistical machine translation will be given in the following section. 2.2 Review of the Phrase-Based Translation System For the confidence measures which will be introduced in Section 5.1, we use a stateof-the-art phrase-based translation approach as described in Zens and Ney (2004). The key elements of this translation approach are bilingual phrases. Note that these phrases are sequences of words in the two languages and n"
J07-1003,C04-1046,1,0.894453,"n for machine translation (MT). Because sentences generated by a machine translation system are often incorrect but may contain correct substrings, a method for identifying these correct substrings and finding possible errors is desirable. For this purpose, each word in the generated target sentence is assigned a value expressing the confidence that it is correct. Confidence measures have been extensively studied for speech recognition. Only recently have researchers started to investigate confidence measures for machine translation (Gandrabur and Foster 2003; Ueffing, Macherey, and Ney 2003; Blatz et al. 2004; Quirk 2004). In this article, we will develop a sound theoretical framework for ∗ Now at National Research Council Canada, Interactive Language Technologies Group, Gatineau, Qu´ebec J8P 3G5, Canada. E-mail: nicola.ueffing@nrc.gc.ca. ¨ Informatik VI, Computer Science Department, D-52056 Aachen, Germany. E-mail: † Lehrstuhl fur ney@cs.rwth-aachen.de. Submission received: 7 March 2006; revised submission received: 30 September 2006; accepted for publication: 3 October 2006. © 2007 Association for Computational Linguistics Computational Linguistics Volume 33, Number 1 calculating and evaluating"
J07-1003,J93-2003,0,0.0225959,"Missing"
J07-1003,P05-1033,0,0.00828066,"ity, we obtain two knowledge sources: the translation model Pr( f1J |eI1 ) and the language model Pr(eI1 ). Both can be modeled independently of each other. The translation model is responsible for linking the source string f1J and the target string eI1 . It captures the semantics of the sentence. The target language model captures the well-formedness of the syntax in the target language. Nowadays, most state-of-the-art SMT systems are based on bilingual phrases (Och, Tillmann, and Ney 1999; Koehn, Och, and Marcu 2003; Tillmann 2003; Bertoldi et al. 2004; Vogel et al. 2004; Zens and Ney 2004; Chiang 2005). A more detailed description of 10 Ueffing and Ney Word-Level Confidence Estimation for MT a phrase-based approach to statistical machine translation will be given in the following section. 2.2 Review of the Phrase-Based Translation System For the confidence measures which will be introduced in Section 5.1, we use a stateof-the-art phrase-based translation approach as described in Zens and Ney (2004). The key elements of this translation approach are bilingual phrases. Note that these phrases are sequences of words in the two languages and not necessarily phrases in the linguistic sense. The"
J07-1003,P05-3026,0,0.0317495,"ting word confidence measures. Possible applications of confidence measures include: r r r marking words with low confidence as potential errors for post-editing improving translation prediction accuracy in TransType-style interactive machine translation (Gandrabur and Foster 2003; Ueffing and Ney 2005a) combining output from different machine translation systems: Hypotheses with low confidence can be discarded before selecting one of the system translations (Akiba et al. 2004), or the word confidence scores can be used in the generation of new hypotheses from the output of different systems (Jayaraman and Lavie 2005), or the sentence confidence value can be employed for reranking (Blatz et al. 2003). The article is organized as follows: In Section 2, we briefly review the statistical approach to machine translation. The phrase-based translation system, which serves as the basis for one of the direct confidence measures, will be presented. Section 3 gives an overview of related work on confidence estimation for machine translation. Moreover, word posterior probabilities will be introduced, and we will explain how they can be used as word-level confidence measures. In Section 4, we describe so-called system"
J07-1003,N03-1017,0,0.00469263,"Missing"
J07-1003,niessen-etal-2000-evaluation,1,0.169777,"Missing"
J07-1003,P03-1021,0,0.0367926,"s the so-called word penalty, and c2 is the phrase penalty, assigning constant costs to each target language word/phrase. The language model is a trigram model with modified Kneser–Ney discounting and interpolation (Stolcke 2002). The search determines the target sentence and segmentation that maximize the objective function. 11 Computational Linguistics Volume 33, Number 1 As Equation (2) shows, the sub-models are combined via weighted log-linear interpolation. The model scaling factors λ1 , . . . , λ5 and the word and phrase penalties are optimized with respect to some evaluation criterion (Och 2003) such as BLEU score. The phrase-based translation model will be needed later to define the different confidence measures. We therefore introduce the following notation: Let QPM ( f˜k , e˜k ) be the score of the phrase pair, which consists of the phrase penalty c2 , the phrase lexicon scores, and the two word lexicon model scores (see Equation (2)): QPM ( f˜k , e˜k ) := c2 · p( f˜k |e˜k )λ2 · p(˜ek |f˜k )λ3 · jk  p( fj |e˜k ) j =jk −1 +1 λ4 · ik  p(ei |f˜k )λ5 (3) i =ik −1 +1 3. Confidence Measures for MT 3.1 Related Work In many areas of natural language processing, confidence measures have"
J07-1003,J04-4002,1,0.270118,"ing words 18,896 T EST English 1,652,174 32,554,077 31,147,901 124,192 80,125 2,643 40,396 1,073 37,742 25 Computational Linguistics Volume 33, Number 1 Table 3 Statistics of the training, development, and test corpora for the NIST Chinese–English task. Both development and test corpus are provided with four English references. Chinese T RAIN Sentences Running words Vocabulary Dictionary entries D EV (2002 evaluation set) T EST (2004 evaluation set) r r English 7M 213M 351K 82K 199M 223K Sentences Running words 25K 878 Sentences Running words 1,788 52K 239K 105K The alignment template system (Och and Ney 2004) (denoted as AT in the tables), which is also a state-of-the art phrase-based translation system. The Systran version available at http://babelfish.altavista.com/tr in June 2005. These hypotheses were used to investigate whether the direct confidence measures perform well on translations generated by a structurally different system. The translation quality on the TransType2 task in terms of WER, PER, BLEU score (Papineni et al. 2002), and NIST score (NIST 2002) is given in Table 4. We see that the best results are obtained on Spanish to English translation, followed by French to English and Ge"
J07-1003,W99-0604,1,0.688845,"Missing"
J07-1003,P02-1040,0,0.0998603,"2004 evaluation set) r r English 7M 213M 351K 82K 199M 223K Sentences Running words 25K 878 Sentences Running words 1,788 52K 239K 105K The alignment template system (Och and Ney 2004) (denoted as AT in the tables), which is also a state-of-the art phrase-based translation system. The Systran version available at http://babelfish.altavista.com/tr in June 2005. These hypotheses were used to investigate whether the direct confidence measures perform well on translations generated by a structurally different system. The translation quality on the TransType2 task in terms of WER, PER, BLEU score (Papineni et al. 2002), and NIST score (NIST 2002) is given in Table 4. We see that the best results are obtained on Spanish to English translation, followed by French to English and German to English. The reason that Systran generates translations of much lower quality than the SMT systems is due to the fact that the technical manuals are very specific in terminology. The SMT systems were trained on similar corpora so that they are familiar with the terminology. The table additionally shows the translation quality achieved by the system PBT on the NIST test set. Table 4 Translation quality of different MT systems"
J07-1003,quirk-2004-training,0,0.0917417,"lation (MT). Because sentences generated by a machine translation system are often incorrect but may contain correct substrings, a method for identifying these correct substrings and finding possible errors is desirable. For this purpose, each word in the generated target sentence is assigned a value expressing the confidence that it is correct. Confidence measures have been extensively studied for speech recognition. Only recently have researchers started to investigate confidence measures for machine translation (Gandrabur and Foster 2003; Ueffing, Macherey, and Ney 2003; Blatz et al. 2004; Quirk 2004). In this article, we will develop a sound theoretical framework for ∗ Now at National Research Council Canada, Interactive Language Technologies Group, Gatineau, Qu´ebec J8P 3G5, Canada. E-mail: nicola.ueffing@nrc.gc.ca. ¨ Informatik VI, Computer Science Department, D-52056 Aachen, Germany. E-mail: † Lehrstuhl fur ney@cs.rwth-aachen.de. Submission received: 7 March 2006; revised submission received: 30 September 2006; accepted for publication: 3 October 2006. © 2007 Association for Computational Linguistics Computational Linguistics Volume 33, Number 1 calculating and evaluating word confiden"
J07-1003,W03-1001,0,0.0113053,"eI1 ) · Pr(eI1 ) I,eI1 (1) I,eI1 Through this decomposition of the probability, we obtain two knowledge sources: the translation model Pr( f1J |eI1 ) and the language model Pr(eI1 ). Both can be modeled independently of each other. The translation model is responsible for linking the source string f1J and the target string eI1 . It captures the semantics of the sentence. The target language model captures the well-formedness of the syntax in the target language. Nowadays, most state-of-the-art SMT systems are based on bilingual phrases (Och, Tillmann, and Ney 1999; Koehn, Och, and Marcu 2003; Tillmann 2003; Bertoldi et al. 2004; Vogel et al. 2004; Zens and Ney 2004; Chiang 2005). A more detailed description of 10 Ueffing and Ney Word-Level Confidence Estimation for MT a phrase-based approach to statistical machine translation will be given in the following section. 2.2 Review of the Phrase-Based Translation System For the confidence measures which will be introduced in Section 5.1, we use a stateof-the-art phrase-based translation approach as described in Zens and Ney (2004). The key elements of this translation approach are bilingual phrases. Note that these phrases are sequences of words in t"
J07-1003,2003.mtsummit-papers.52,1,0.859561,"Missing"
J07-1003,2005.eamt-1.35,1,0.904561,"t, D-52056 Aachen, Germany. E-mail: † Lehrstuhl fur ney@cs.rwth-aachen.de. Submission received: 7 March 2006; revised submission received: 30 September 2006; accepted for publication: 3 October 2006. © 2007 Association for Computational Linguistics Computational Linguistics Volume 33, Number 1 calculating and evaluating word confidence measures. Possible applications of confidence measures include: r r r marking words with low confidence as potential errors for post-editing improving translation prediction accuracy in TransType-style interactive machine translation (Gandrabur and Foster 2003; Ueffing and Ney 2005a) combining output from different machine translation systems: Hypotheses with low confidence can be discarded before selecting one of the system translations (Akiba et al. 2004), or the word confidence scores can be used in the generation of new hypotheses from the output of different systems (Jayaraman and Lavie 2005), or the sentence confidence value can be employed for reranking (Blatz et al. 2003). The article is organized as follows: In Section 2, we briefly review the statistical approach to machine translation. The phrase-based translation system, which serves as the basis for one of"
J07-1003,H05-1096,1,0.479872,"t, D-52056 Aachen, Germany. E-mail: † Lehrstuhl fur ney@cs.rwth-aachen.de. Submission received: 7 March 2006; revised submission received: 30 September 2006; accepted for publication: 3 October 2006. © 2007 Association for Computational Linguistics Computational Linguistics Volume 33, Number 1 calculating and evaluating word confidence measures. Possible applications of confidence measures include: r r r marking words with low confidence as potential errors for post-editing improving translation prediction accuracy in TransType-style interactive machine translation (Gandrabur and Foster 2003; Ueffing and Ney 2005a) combining output from different machine translation systems: Hypotheses with low confidence can be discarded before selecting one of the system translations (Akiba et al. 2004), or the word confidence scores can be used in the generation of new hypotheses from the output of different systems (Jayaraman and Lavie 2005), or the sentence confidence value can be employed for reranking (Blatz et al. 2003). The article is organized as follows: In Section 2, we briefly review the statistical approach to machine translation. The phrase-based translation system, which serves as the basis for one of"
J07-1003,W02-1021,1,0.865507,"Missing"
J07-1003,2005.mtsummit-papers.34,1,0.694801,"criptions will be presented. The translations that RWTH submitted to this evaluation were generated by the phrase-based translation system described in Section 2.2. N-best lists were generated for development and test corpus, with a maximum length of 20,000 and 15,000, respectively. These were then rescored with an IBM model 1, a 4-gram language model, and a deletion model based on IBM-1. The weights for all these models and for the sentence probability assigned by the SMT system were optimized with respect to BLEU score on the development corpus. For a detailed description of the system, see Vilar et al. (2005). This system was ranked first in the evaluation round according to all evaluation criteria (Ney et al. 2005). Two different sets of rescoring experiments were performed. They differ only in their starting points: The first one starts from the baseline system without rescoring. The sub-model weights of this system were optimized with respect to BLEU on the development set, but no additional models were used for rescoring the N-best list. This experiment was performed to analyze the maximum improvement that can be achieved through rescoring with confidence measures. The second experiment starts"
J07-1003,2004.iwslt-evaluation.11,0,0.011166,"ugh this decomposition of the probability, we obtain two knowledge sources: the translation model Pr( f1J |eI1 ) and the language model Pr(eI1 ). Both can be modeled independently of each other. The translation model is responsible for linking the source string f1J and the target string eI1 . It captures the semantics of the sentence. The target language model captures the well-formedness of the syntax in the target language. Nowadays, most state-of-the-art SMT systems are based on bilingual phrases (Och, Tillmann, and Ney 1999; Koehn, Och, and Marcu 2003; Tillmann 2003; Bertoldi et al. 2004; Vogel et al. 2004; Zens and Ney 2004; Chiang 2005). A more detailed description of 10 Ueffing and Ney Word-Level Confidence Estimation for MT a phrase-based approach to statistical machine translation will be given in the following section. 2.2 Review of the Phrase-Based Translation System For the confidence measures which will be introduced in Section 5.1, we use a stateof-the-art phrase-based translation approach as described in Zens and Ney (2004). The key elements of this translation approach are bilingual phrases. Note that these phrases are sequences of words in the two languages and not necessarily phra"
J07-1003,N04-1033,1,0.568883,"ion of the probability, we obtain two knowledge sources: the translation model Pr( f1J |eI1 ) and the language model Pr(eI1 ). Both can be modeled independently of each other. The translation model is responsible for linking the source string f1J and the target string eI1 . It captures the semantics of the sentence. The target language model captures the well-formedness of the syntax in the target language. Nowadays, most state-of-the-art SMT systems are based on bilingual phrases (Och, Tillmann, and Ney 1999; Koehn, Och, and Marcu 2003; Tillmann 2003; Bertoldi et al. 2004; Vogel et al. 2004; Zens and Ney 2004; Chiang 2005). A more detailed description of 10 Ueffing and Ney Word-Level Confidence Estimation for MT a phrase-based approach to statistical machine translation will be given in the following section. 2.2 Review of the Phrase-Based Translation System For the confidence measures which will be introduced in Section 5.1, we use a stateof-the-art phrase-based translation approach as described in Zens and Ney (2004). The key elements of this translation approach are bilingual phrases. Note that these phrases are sequences of words in the two languages and not necessarily phrases in the linguist"
J07-1003,W05-0834,1,0.808332,"ather restrictive. In practice, the target position of a word varies between different translation alternatives. The method presented here is a starting point for more flexible approaches that perform summation over a window of target positions. In the following, we will show how the word posterior probabilities based on fixed target positions are calculated over word graphs and over N-best lists. 15 Computational Linguistics Volume 33, Number 1 Calculation using word graphs. A word graph represents the most promising hypotheses generated by the translation system (Ueffing, Och, and Ney 2002; Zens and Ney 2005). It has the advantage of being a compact representation of the translation hypothesis space, which allows for efficient calculation of word posterior probabilities. A word graph is a directed acyclic graph G = (V, E) with vertex set V and edge set E. It has one designated root node n0 ∈ V, representing the beginning of the sentence. Each path through the word graph represents a translation candidate. The nodes of the graph contain information such as the set of covered source positions and the language model history. Two hypotheses can be recombined if their information is identical. Recombin"
J07-1003,W06-3110,1,0.657016,"for training the confidence measures. The author found that using a small amount of manually labeled training data yields better performance than using large quantities of automatically labeled data. Akiba et al. (2004) reported the application of confidence measures to the selection of output on N-best lists produced by different MT systems. Word-level confidence measures, namely the rank-weighted sum as described in Section 4.1 (and first introduced in Ueffing, Macherey and Ney [2003]), are used to discard low-quality system output before selecting a translation from the various MT systems. Zens and Ney (2006) presented an extension of the word posterior probabilities presented in this article: Posterior probabilities are calculated not only on the word level, but also for n-grams, and are successfully applied to the rescoring of MT hypotheses. 3.2 Word Posterior Probabilities The confidence of a target word can be expressed by its posterior probability, that is, the probability of the word occurring in the target sentence, given the source sentence. Word posterior probabilities are the basis of all approaches to confidence estimation presented here. The following explains how they can be determine"
J07-1003,2005.eamt-1.20,0,\N,Missing
J07-1003,W03-0413,0,\N,Missing
J09-1002,2005.eamt-1.6,1,0.85769,"ulty of the selected tasks. The second aim is to assess the interactive MT (IPMT) approach proposed in this article. The results are presented in different subsections. The ﬁrst two subsections present the MT and IPMT results for the 1-best translation obtained by the different techniques in the Xerox and EU tasks, respectively. The third subsection presents further IPMT results for the 5-best translations on a single pair of languages. Some of these results may differ from results presented in previous works (Cubel et al. 2003; Och, Zens, and Ney 2003; Civera et al. 2004a; Cubel et al. 2004; Bender et al. 2005). The differences are due to variations in the pre-/post-processing procedures and/or recent improvements of the search techniques used by the different systems. 6.1 Experiments with the Xerox Corpora In this section, the translation results obtained using ATs, PBMs, and SFSTs for all six language pairs of the Xerox corpus are reported. Word-based trigram and class-based ﬁve-gram target-language models were used for the AT models (the parameters of the log-linear model are tuned so as to minimize WER on a development corpus); wordbased trigram target-language models were used for PBMs and trig"
J09-1002,J90-2002,0,0.670725,"the source sentence. The probability Pr(t) represents the well-formedness of t and it is generally called the language model probability (n-gram models are usually adopted [Jelinek 1998]). On the other hand, Pr(s|t) represents the relationship between the two sentences (the source and its translation). It should be of a high value if the source is a good translation of the target and of a low value otherwise. Note that the translation direction is inverted from what would be normally expected; correspondingly the models built around this equation are often called inverted translation models (Brown et al. 1990, 1993). As we will see in Section 3, these models are based on the notion of alignment. It is interesting to note that if we had perfect models, the use of Equation (1) would sufﬁce. Given that we have only approximations, the use of Equation (2) allows the language model to correct deﬁciencies in the translation model. In practice all of these models (and possibly others) are often combined into a loglinear model for Pr(t |s) (Och and Ney 2004):  ˆt = argmax t N   λi · log fi (t, s) (3) i=1 where fi (t, s) can be a model for Pr(s|t), a model for Pr(t|s), a target language model for Pr(t),"
J09-1002,J93-2003,0,0.0457488,"he situation with respect to ﬁnite-state models is similar. Now, Equation (5) is rewritten as ˆts = argmax Pr(tp , ts , s) (7) ts which allows the use of the same models as in Equation (4) as long as the search procedure is changed appropriately (Cubel et al. 2003, 2004; Civera et al. 2004a, 2004b). 3. Statistical and Finite-State Models The models used are presented in the following subsections: Section 3.1 for the conditional distribution Pr(s|t) in Equation (2) and Section 3.2 for the joint distribution Pr(s, t) in Equation (4). 3.1 Statistical Alignment Models The translation models which Brown et al. (1993) introduced to deal with Pr(s|t) in Equation (2) are based on the concept of alignment between the components of a pair (s, t) (thus they are called statistical alignment models). Formally, if the number of the source words in s is J and the number of target words in t is I, an alignment is a function a : {1, ..., J} → {0, ..., I}. The image of j by a will be denoted as aj , in which the particular case aj = 0 means that the position j in s is not aligned with any position of t. By introducing the alignment as a hidden variable in Pr(s|t), Pr(s|t) =  Pr(s, a|t) (8) a The alignment that maximi"
J09-1002,E06-1032,0,0.0363245,"Missing"
J09-1002,J04-2004,1,0.914,"to complete this preﬁx. We will refer to this process as interactive-predictive machine translation (IPMT). This approach introduces two important requirements: First, the models have to provide adequate completions and, second, this has to happen efﬁciently. Taking these requirements into account, stochastic ﬁnite-state transducers (SFSTs), alignment templates (ATs), and phrase-based models (PBMs) are compared in this work. In previous works these models have proven adequate for conventional MT (Vidal 1997; Amengual et al. 2000; Ney et al. 2000; Tom´as and Casacuberta 2001; Och and Ney 2003; Casacuberta and Vidal 2004; Och and Ney 2004; Vidal and Casacuberta 2004). This article shows that 1 The terms preﬁx and sufﬁx are used here to denote any substring at the beginning and end (respectively) of a string of characters (including spaces and punctuation), with no implication of morphological signiﬁcance as is usually implied by these terms in linguistics. 4 Barrachina et al. Statistical Computer-Assisted Translation existing efﬁcient searching algorithms can be adapted in order to provide completions (rather than full translations) also in a very efﬁcient way. The work presented here has been carried out in"
J09-1002,W04-3245,1,0.805366,"Missing"
J09-1002,2003.eamt-1.6,1,0.848014,"Missing"
J09-1002,W02-1020,0,0.464538,"rs in order to solve different types of (lexical, syntactic, or semantic) ambiguities (Slocum 1985; Whitelock et al. 1986). Other interaction strategies have been considered for updating user dictionaries or for searching through dictionaries (Slocum 1985; Whitelock et al. 1986). Speciﬁc proposals can be found in Tomita (1985), Zajac (1988), Yamron et al. (1993), and Sen, Zhaoxiong, and Heyan (1997), among others. An important contribution to CAT technology, carried out within the TransType project, is worth mentioning (Foster, Isabelle, and Plamondon 1997; Langlais, Foster, and Lapalme 2000; Foster 2002; Langlais, Lapalme, and Loranger 2002). It entailed an interesting focus shift in which interaction is directly aimed at the production of the target text, rather than at the disambiguation of the source text, as in earlier interactive systems. The idea proposed in that work was to embed data-driven MT techniques within the interactive translation environment. The hope was to combine the best of both paradigms: CAT, in which the human translator ensures high-quality output, and MT, in which the machine ensures a signiﬁcant gain in productivity. Following these TransType ideas, the innovative"
J09-1002,1997.mtsummit-papers.1,0,0.474006,"Missing"
J09-1002,W04-3250,0,0.0485459,"Missing"
J09-1002,N03-1017,0,0.0196276,"Missing"
J09-1002,W00-0507,0,0.93842,"Missing"
J09-1002,macklovitch-2006-transtype2,0,0.686113,"complete sentence hypotheses on which the human translator can work. This is an important difference to previous work, in which the use of basic MT techniques only allowed the prediction of single tokens (c.f., Section 2.2). Second, using fully ﬂedged SMT systems, we have performed systematic ofﬂine experiments to simulate the speciﬁc conditions of interactive translation and we report and study the results of these experiments. Thirdly, the IPMT systems presented in this article were successfully used in several ﬁeld trials with professional translators (Macklovitch, Nguyen, and Silva 2005; Macklovitch 2006). We should ﬁnally mention that the work developed in TT2 has gone beyond conventional keyboard-and-mouse interaction, leading to the development of advanced multi-modal interfaces. Speech is the most natural form of human communication and its use as feedback in the IPMT framework has been explored by Vidal et al. (2006). On the other hand, human translators can be faster dictating the translation text rather than typing it, thus it has also been investigated how to improve system performance and usability when the user dictates the translation ﬁrst and then edits the recognized text (Khadivi"
J09-1002,W02-1018,0,0.148046,"onto their 10 Barrachina et al. Statistical Computer-Assisted Translation classes. To reduce the memory requirements, only probabilities for phrases up to a maximal length are estimated, and phrases with a probability estimate below a certain threshold are discarded. The weights λi in Equation (10) are usually estimated using held-out data with respect to the automatic evaluation metric employed using the downhill simplex algorithm from Press et al. (2002). 3.1.2 Phrase-Based Models. A simple alternative to AT has been introduced in recent works: The PBM approach (Tom´as and Casacuberta 2001; Marcu and Wong 2002; Zens, Och, and Ney 2002; Tom´as and Casacuberta 2003; Zens and Ney 2004). These methods learn the probability that a sequence of contiguous words—the source phrase—(as a whole unit) in a source sentence is a translation of another sequence of contiguous words—the target phrase—(as a whole unit) in the target sentence. In this case, the statistical dictionaries of single word pairs are substituted by statistical dictionaries of bilingual phrases or bilingual segments. These models are simpler than ATs, because no alignments are assumed between word positions inside a bilingual segment and wor"
J09-1002,E99-1010,0,0.0131006,"on is used for target words, phrases, and sequences in target sentence t. 3.1.1 Alignment Templates. The ATs are based on the bilingual phrases but they are generalized by replacing words with word classes and by storing the alignment ina ), where S and formation for each phrase pair. Formally, an AT Z is a triple (S, T,  a is an T are a source class sequence and a target class sequence, respectively, and  alignment from the set of positions in S to the set of positions in T.4 Mapping of source and target words to bilingual word classes is automatically trained using the method described by Och (1999). The method is actually an unsupervised clustering method which partitions the source and target vocabularies, so that assigning words to classes is a deterministic operation. It is also possible to employ parts-of-speech or semantic categories instead of the unsupervised clustering method used here. More details can be found in Och (1999) and Och and Ney (2004). However, it should be mentioned that the whole AT approach (and similar PBM approaches as they are now called) is independent of the word clustering concept. In particular, for large training corpora, omitting the word clustering in"
J09-1002,J03-1002,1,0.080838,"lation sufﬁx(es)1 to complete this preﬁx. We will refer to this process as interactive-predictive machine translation (IPMT). This approach introduces two important requirements: First, the models have to provide adequate completions and, second, this has to happen efﬁciently. Taking these requirements into account, stochastic ﬁnite-state transducers (SFSTs), alignment templates (ATs), and phrase-based models (PBMs) are compared in this work. In previous works these models have proven adequate for conventional MT (Vidal 1997; Amengual et al. 2000; Ney et al. 2000; Tom´as and Casacuberta 2001; Och and Ney 2003; Casacuberta and Vidal 2004; Och and Ney 2004; Vidal and Casacuberta 2004). This article shows that 1 The terms preﬁx and sufﬁx are used here to denote any substring at the beginning and end (respectively) of a string of characters (including spaces and punctuation), with no implication of morphological signiﬁcance as is usually implied by these terms in linguistics. 4 Barrachina et al. Statistical Computer-Assisted Translation existing efﬁcient searching algorithms can be adapted in order to provide completions (rather than full translations) also in a very efﬁcient way. The work presented h"
J09-1002,J04-4002,1,0.860643,"ill refer to this process as interactive-predictive machine translation (IPMT). This approach introduces two important requirements: First, the models have to provide adequate completions and, second, this has to happen efﬁciently. Taking these requirements into account, stochastic ﬁnite-state transducers (SFSTs), alignment templates (ATs), and phrase-based models (PBMs) are compared in this work. In previous works these models have proven adequate for conventional MT (Vidal 1997; Amengual et al. 2000; Ney et al. 2000; Tom´as and Casacuberta 2001; Och and Ney 2003; Casacuberta and Vidal 2004; Och and Ney 2004; Vidal and Casacuberta 2004). This article shows that 1 The terms preﬁx and sufﬁx are used here to denote any substring at the beginning and end (respectively) of a string of characters (including spaces and punctuation), with no implication of morphological signiﬁcance as is usually implied by these terms in linguistics. 4 Barrachina et al. Statistical Computer-Assisted Translation existing efﬁcient searching algorithms can be adapted in order to provide completions (rather than full translations) also in a very efﬁcient way. The work presented here has been carried out in the TransType2 (TT"
J09-1002,E03-1032,1,0.925952,"Missing"
J09-1002,2001.mtsummit-papers.68,0,0.042139,"te the test word perplexity. (K and M denote thousands and millions, respectively.) Train Sent. pairs (K) Running words (M) Vocabulary (K) 214 5.2/5.9 84/97 223 5.7/5.4 86/153 215 5.3/6.0 84/91 Test English/Spanish English/German English/French Sentences (K) Running words (K) Running chars. (K) Perplexity 0.8 20/23 119/135 58/46 0.8 20/19 120/134 57/87 0.8 20/23 119/134 58/45 18 Barrachina et al. r Statistical Computer-Assisted Translation Bilingual evaluation understudy (BLEU): This is based on the coverage of n-grams of the hypothesized translation which occur in the reference translations (Papineni et al. 2001). Other assessment ﬁgures are aimed at estimating the effort needed by a human translator to produce correct translations using the interactive system. To this end, the target translations which a real user would have in mind are simulated by the given references. The ﬁrst translation hypothesis for each given source sentence is compared with a single reference translation and the longest common character preﬁx (LCP) is obtained. The ﬁrst non-matching character is replaced by the corresponding reference character and then a new system hypothesis is produced. This process is iterated until a fu"
J09-1002,J85-1001,0,0.718127,"vantage of the existing MT technologies is to use them in collaboration with human translators within a computer-assisted translation (CAT) or interactive framework (Isabelle and Church 1997). Historically, CAT and MT have been considered different but close technologies (Kay 1997) and more so for one of the most popular CAT technologies, namely, translation memories (Bowker 2002; Somers 2003). Interactivity in CAT has been explored for a long time. Systems have been designed to interact with human translators in order to solve different types of (lexical, syntactic, or semantic) ambiguities (Slocum 1985; Whitelock et al. 1986). Other interaction strategies have been considered for updating user dictionaries or for searching through dictionaries (Slocum 1985; Whitelock et al. 1986). Speciﬁc proposals can be found in Tomita (1985), Zajac (1988), Yamron et al. (1993), and Sen, Zhaoxiong, and Heyan (1997), among others. An important contribution to CAT technology, carried out within the TransType project, is worth mentioning (Foster, Isabelle, and Plamondon 1997; Langlais, Foster, and Lapalme 2000; Foster 2002; Langlais, Lapalme, and Loranger 2002). It entailed an interesting focus shift in whic"
J09-1002,2001.mtsummit-papers.64,1,0.270917,"Missing"
J09-1002,P06-2107,1,0.913773,"Missing"
J09-1002,1985.tmi-1.19,0,0.660886,"considered different but close technologies (Kay 1997) and more so for one of the most popular CAT technologies, namely, translation memories (Bowker 2002; Somers 2003). Interactivity in CAT has been explored for a long time. Systems have been designed to interact with human translators in order to solve different types of (lexical, syntactic, or semantic) ambiguities (Slocum 1985; Whitelock et al. 1986). Other interaction strategies have been considered for updating user dictionaries or for searching through dictionaries (Slocum 1985; Whitelock et al. 1986). Speciﬁc proposals can be found in Tomita (1985), Zajac (1988), Yamron et al. (1993), and Sen, Zhaoxiong, and Heyan (1997), among others. An important contribution to CAT technology, carried out within the TransType project, is worth mentioning (Foster, Isabelle, and Plamondon 1997; Langlais, Foster, and Lapalme 2000; Foster 2002; Langlais, Lapalme, and Loranger 2002). It entailed an interesting focus shift in which interaction is directly aimed at the production of the target text, rather than at the disambiguation of the source text, as in earlier interactive systems. The idea proposed in that work was to embed data-driven MT techniques w"
J09-1002,W02-1021,1,0.507109,"Missing"
J09-1002,C86-1077,0,0.329907,"e existing MT technologies is to use them in collaboration with human translators within a computer-assisted translation (CAT) or interactive framework (Isabelle and Church 1997). Historically, CAT and MT have been considered different but close technologies (Kay 1997) and more so for one of the most popular CAT technologies, namely, translation memories (Bowker 2002; Somers 2003). Interactivity in CAT has been explored for a long time. Systems have been designed to interact with human translators in order to solve different types of (lexical, syntactic, or semantic) ambiguities (Slocum 1985; Whitelock et al. 1986). Other interaction strategies have been considered for updating user dictionaries or for searching through dictionaries (Slocum 1985; Whitelock et al. 1986). Speciﬁc proposals can be found in Tomita (1985), Zajac (1988), Yamron et al. (1993), and Sen, Zhaoxiong, and Heyan (1997), among others. An important contribution to CAT technology, carried out within the TransType project, is worth mentioning (Foster, Isabelle, and Plamondon 1997; Langlais, Foster, and Lapalme 2000; Foster 2002; Langlais, Lapalme, and Loranger 2002). It entailed an interesting focus shift in which interaction is directl"
J09-1002,H93-1037,0,0.121423,"e technologies (Kay 1997) and more so for one of the most popular CAT technologies, namely, translation memories (Bowker 2002; Somers 2003). Interactivity in CAT has been explored for a long time. Systems have been designed to interact with human translators in order to solve different types of (lexical, syntactic, or semantic) ambiguities (Slocum 1985; Whitelock et al. 1986). Other interaction strategies have been considered for updating user dictionaries or for searching through dictionaries (Slocum 1985; Whitelock et al. 1986). Speciﬁc proposals can be found in Tomita (1985), Zajac (1988), Yamron et al. (1993), and Sen, Zhaoxiong, and Heyan (1997), among others. An important contribution to CAT technology, carried out within the TransType project, is worth mentioning (Foster, Isabelle, and Plamondon 1997; Langlais, Foster, and Lapalme 2000; Foster 2002; Langlais, Lapalme, and Loranger 2002). It entailed an interesting focus shift in which interaction is directly aimed at the production of the target text, rather than at the disambiguation of the source text, as in earlier interactive systems. The idea proposed in that work was to embed data-driven MT techniques within the interactive translation en"
J09-1002,C88-2160,0,0.52258,"erent but close technologies (Kay 1997) and more so for one of the most popular CAT technologies, namely, translation memories (Bowker 2002; Somers 2003). Interactivity in CAT has been explored for a long time. Systems have been designed to interact with human translators in order to solve different types of (lexical, syntactic, or semantic) ambiguities (Slocum 1985; Whitelock et al. 1986). Other interaction strategies have been considered for updating user dictionaries or for searching through dictionaries (Slocum 1985; Whitelock et al. 1986). Speciﬁc proposals can be found in Tomita (1985), Zajac (1988), Yamron et al. (1993), and Sen, Zhaoxiong, and Heyan (1997), among others. An important contribution to CAT technology, carried out within the TransType project, is worth mentioning (Foster, Isabelle, and Plamondon 1997; Langlais, Foster, and Lapalme 2000; Foster 2002; Langlais, Lapalme, and Loranger 2002). It entailed an interesting focus shift in which interaction is directly aimed at the production of the target text, rather than at the disambiguation of the source text, as in earlier interactive systems. The idea proposed in that work was to embed data-driven MT techniques within the inte"
J09-1002,N04-1033,1,0.604748,"words are taken into account. Moreover, in practice the summation operator is replaced with the maximization operator, which in turn reduces the contribution of each individual source word in generating a target word. On the other hand, modeling word sequences rather than single words in both the alignment and lexicon models cause signiﬁcant improvement in translation quality (Och and Ney 8 Barrachina et al. Statistical Computer-Assisted Translation 2004). In this work, we use two closely related models: ATs (Och and Ney 2004) and PBMs (Tom´as and Casacuberta 2001; Koehn, Och, and Marcu 2003; Zens and Ney 2004). Both models are based on bilingual phrases3 (pairs of segments or word sequences) in which all words within the source-language phrase are aligned only to words of the target-language phrase and vice versa. Note that at least one word in the sourcelanguage phrase must be aligned to one word of the target-language phrase, that is, there are no empty phrases similar to the empty word of the word-based models. In addition, no gaps and no overlaps between phrases are allowed. We introduce some notation to deal with phrases. As before, s denotes a sources denotes a generic phrase in s, and  sk t"
J09-1002,2002.tmi-tutorials.2,0,0.133044,"Missing"
J09-1002,2004.tmi-1.9,0,0.171592,"Missing"
J09-1002,P02-1040,0,\N,Missing
J09-1002,P06-2061,1,\N,Missing
J09-1002,H93-1087,0,\N,Missing
J11-4002,W05-0909,0,0.0279152,"nstraints for the hypothesis: Only the words in the reference have to be covered exactly once, whereas those in the hypothesis can be covered zero, one, or multiple times. Preprocessing and normalization methods for improving the evaluation using the standard measures WER, PER, BLEU , and NIST are investigated by Leusch et al. (2005). The same set of measures is examined by Matusov et al. (2005) in combination with automatic sentence segmentation in order to enable evaluation of translation output without sentence boundaries (e.g., translation of speech recognition output). The METEOR metric (Banerjee and Lavie 2005) ﬁrst counts the number of exact word matches between the output and the reference. In a second step, unmatched words are converted into stems or synonyms and then matched. A method that uses the concept of maximum matching string (MMS) is presented by Turian, Shen, and Melamed (2003). IQ (Gim´enez and Amigo´ 2006) is a framework for automatic evaluation in which evaluation metrics can be combined. Nevertheless, none of these measures or extensions takes into account any details about actual translation errors, for example, what the contribution of verbs is in the overall error rate, how many"
J11-4002,J07-2003,0,0.0194535,"each of the error categories, the basic POS classes are analyzed as well in order to estimate which POS classes of each category are reliable for the comparison of translation outputs. The investigations are carried out on six Spanish-to-English TC- STAR outputs generated by phrase-based systems (Vilar et al. 2005) and three German-to-English WMT 09 outputs produced in the framework of the fourth shared translation task (CallisonBurch et al. 2009). Two of the WMT 09 outputs are generated by standard phrase-based systems (Zens, Och, and Ney 2002) and one by a hierarchical phrase-based system (Chiang 2007). For the TC- STAR outputs two reference translations are available for the automatic error analysis, and for the WMT 09 outputs only a single reference is available. For all texts, the ﬂexible human error analysis is carried out. The following sections summarize all the results along with the Spearman and Pearson correlation coefﬁcients calculated across the different translation outputs. 4.3.1 Results on TC-STAR Corpora. The error analyses were carried out on six Spanishto-English outputs generated by phrase-based translation systems built on different sizes of training corpora in order to e"
J11-4002,gimenez-amigo-2006-iqmt,0,0.0514713,"Missing"
J11-4002,2007.mtsummit-papers.39,0,0.120279,"vie 2005) is presented together with a detailed analysis of the obtained results. Automatic error analysis is still a rather unexplored area. A method for automatic identiﬁcation of patterns in translation output using POS sequences is proposed by Lopez and Resnik (2005) in order to see how well a translation system is capable of capturing systematic reordering patterns. Using relative differences between WER and PER for three POS classes (nouns, adjectives, and verbs) is proposed by Popovi´c et al. (2006) for the estimation of inﬂectional and reordering errors. Semi-automatic error analysis (Kirchhoff et al. 2007) is carried out in order to identify problematic 1 G ALE — Global Autonomous Language Exploitation. http://www.arpa.mil/ipto/programs/gale/ index.htm. 2 TC- STAR — Technology and Corpora for Speech to Speech Translation. http://www.tc-star.org/. 3 EACL 09 Fourth Workshop on Statistical Machine Translation. http://www.statmt.org/wmt09/. 659 Computational Linguistics Volume 37, Number 4 characteristics of source documents such as genre, domain, language, and so on. Zhou et al. (2008) propose a diagnostic evaluation of linguistic check-points obtained automatically by aligning parsed source and t"
J11-4002,E06-1031,1,0.873192,"Missing"
J11-4002,W05-0903,1,0.917898,"e Translation Edit Rate (TER) (Snover et al. 2006) and the CD ER measure (Leusch, Uefﬁng, and Ney 2006) are based on the edit distance (WER) but allow reordering of blocks. TER uses an edit distance with additional costs for shifts of word sequences. The CD ER measure drops certain constraints for the hypothesis: Only the words in the reference have to be covered exactly once, whereas those in the hypothesis can be covered zero, one, or multiple times. Preprocessing and normalization methods for improving the evaluation using the standard measures WER, PER, BLEU , and NIST are investigated by Leusch et al. (2005). The same set of measures is examined by Matusov et al. (2005) in combination with automatic sentence segmentation in order to enable evaluation of translation output without sentence boundaries (e.g., translation of speech recognition output). The METEOR metric (Banerjee and Lavie 2005) ﬁrst counts the number of exact word matches between the output and the reference. In a second step, unmatched words are converted into stems or synonyms and then matched. A method that uses the concept of maximum matching string (MMS) is presented by Turian, Shen, and Melamed (2003). IQ (Gim´enez and Amigo´"
J11-4002,2005.eamt-1.13,0,0.0496164,"Missing"
J11-4002,H05-2007,0,0.0199519,"nslation errors, for example, what the contribution of verbs is in the overall error rate, how many full forms are wrong although their base forms are correct, or how many words are missing. A framework for human error analysis and error classiﬁcation ´ Carbonell, has been proposed by Vilar et al. (2006), where a classiﬁcation scheme (Llitjos, and Lavie 2005) is presented together with a detailed analysis of the obtained results. Automatic error analysis is still a rather unexplored area. A method for automatic identiﬁcation of patterns in translation output using POS sequences is proposed by Lopez and Resnik (2005) in order to see how well a translation system is capable of capturing systematic reordering patterns. Using relative differences between WER and PER for three POS classes (nouns, adjectives, and verbs) is proposed by Popovi´c et al. (2006) for the estimation of inﬂectional and reordering errors. Semi-automatic error analysis (Kirchhoff et al. 2007) is carried out in order to identify problematic 1 G ALE — Global Autonomous Language Exploitation. http://www.arpa.mil/ipto/programs/gale/ index.htm. 2 TC- STAR — Technology and Corpora for Speech to Speech Translation. http://www.tc-star.org/. 3 E"
J11-4002,2005.iwslt-1.19,1,0.739337,"ER measure (Leusch, Uefﬁng, and Ney 2006) are based on the edit distance (WER) but allow reordering of blocks. TER uses an edit distance with additional costs for shifts of word sequences. The CD ER measure drops certain constraints for the hypothesis: Only the words in the reference have to be covered exactly once, whereas those in the hypothesis can be covered zero, one, or multiple times. Preprocessing and normalization methods for improving the evaluation using the standard measures WER, PER, BLEU , and NIST are investigated by Leusch et al. (2005). The same set of measures is examined by Matusov et al. (2005) in combination with automatic sentence segmentation in order to enable evaluation of translation output without sentence boundaries (e.g., translation of speech recognition output). The METEOR metric (Banerjee and Lavie 2005) ﬁrst counts the number of exact word matches between the output and the reference. In a second step, unmatched words are converted into stems or synonyms and then matched. A method that uses the concept of maximum matching string (MMS) is presented by Turian, Shen, and Melamed (2003). IQ (Gim´enez and Amigo´ 2006) is a framework for automatic evaluation in which evaluati"
J11-4002,P02-1040,0,0.092082,"contribution of each error category in a particular translation output, and comparing different translation outputs using these categories. In addition, we show how the new error measures can be used to get more information about the differences between translation systems trained on different source and target languages, between different training set-ups for a same phrase-based translation system, as well as between different translation systems. 1.1 Related Work A number of automatic evaluation measures for machine translation output have been investigated in recent years. The BLEU metric (Papineni et al. 2002) and the closely related NIST metric (Doddington 2002), along with WER and PER, have been widely used by many machine translation researchers. The Translation Edit Rate (TER) (Snover et al. 2006) and the CD ER measure (Leusch, Uefﬁng, and Ney 2006) are based on the edit distance (WER) but allow reordering of blocks. TER uses an edit distance with additional costs for shifts of word sequences. The CD ER measure drops certain constraints for the hypothesis: Only the words in the reference have to be covered exactly once, whereas those in the hypothesis can be covered zero, one, or multiple times"
J11-4002,W06-3101,1,0.868667,"Missing"
J11-4002,popovic-ney-2006-pos,1,0.752492,"Missing"
J11-4002,2006.amta-papers.25,0,0.101284,"ed to get more information about the differences between translation systems trained on different source and target languages, between different training set-ups for a same phrase-based translation system, as well as between different translation systems. 1.1 Related Work A number of automatic evaluation measures for machine translation output have been investigated in recent years. The BLEU metric (Papineni et al. 2002) and the closely related NIST metric (Doddington 2002), along with WER and PER, have been widely used by many machine translation researchers. The Translation Edit Rate (TER) (Snover et al. 2006) and the CD ER measure (Leusch, Uefﬁng, and Ney 2006) are based on the edit distance (WER) but allow reordering of blocks. TER uses an edit distance with additional costs for shifts of word sequences. The CD ER measure drops certain constraints for the hypothesis: Only the words in the reference have to be covered exactly once, whereas those in the hypothesis can be covered zero, one, or multiple times. Preprocessing and normalization methods for improving the evaluation using the standard measures WER, PER, BLEU , and NIST are investigated by Leusch et al. (2005). The same set of measures is"
J11-4002,2003.mtsummit-papers.51,0,0.173097,"Missing"
J11-4002,2005.mtsummit-papers.34,1,0.667368,"FTE EsEn1 VT 0.800 0.800 0.800 0.935 0.552 0.978 1.000 1.000 1.000 0.996 0.983 0.991 EnEs1 FTE EnEs2 FTE EnEs1 VT 0.950 0.600 1.000 0.754 0.572 0.538 1.000 1.000 0.950 0.987 0.998 0.990 The experiments should also show how reliable each error category is for the comparison of translation outputs. For each of the error categories, the basic POS classes are analyzed as well in order to estimate which POS classes of each category are reliable for the comparison of translation outputs. The investigations are carried out on six Spanish-to-English TC- STAR outputs generated by phrase-based systems (Vilar et al. 2005) and three German-to-English WMT 09 outputs produced in the framework of the fourth shared translation task (CallisonBurch et al. 2009). Two of the WMT 09 outputs are generated by standard phrase-based systems (Zens, Och, and Ney 2002) and one by a hierarchical phrase-based system (Chiang 2007). For the TC- STAR outputs two reference translations are available for the automatic error analysis, and for the WMT 09 outputs only a single reference is available. For all texts, the ﬂexible human error analysis is carried out. The following sections summarize all the results along with the Spearman a"
J11-4002,vilar-etal-2006-error,1,0.535776,"Missing"
J11-4002,W09-0415,0,0.0195382,"Missing"
J11-4002,J10-3009,0,0.0103603,"on. http://www.tc-star.org/. 3 EACL 09 Fourth Workshop on Statistical Machine Translation. http://www.statmt.org/wmt09/. 659 Computational Linguistics Volume 37, Number 4 characteristics of source documents such as genre, domain, language, and so on. Zhou et al. (2008) propose a diagnostic evaluation of linguistic check-points obtained automatically by aligning parsed source and target sentences. For each check-point, the number of matched n-grams of the references is then calculated. Linguistically based reordering along with the syntax-based evaluation of reordering patterns is described in Xiong et al. (2010). In this work, we propose a novel framework for automatic error analysis of machine translation output based on WER and PER, and systematically investigate a set of possible methods to carry out an error analysis at the word level. 2. A Framework for Automatic Error Analysis The basic idea for automatic error analysis described in this work is to take into account details from the WER (edit distance) and PER algorithms, namely, to identify all erroneous words which are actually contributing to the error rate, and then to combine these words with different types of linguistic knowledge. The ge"
J11-4002,2002.tmi-tutorials.2,0,0.066437,"Missing"
J11-4002,C08-1141,0,0.1705,"opovi´c et al. (2006) for the estimation of inﬂectional and reordering errors. Semi-automatic error analysis (Kirchhoff et al. 2007) is carried out in order to identify problematic 1 G ALE — Global Autonomous Language Exploitation. http://www.arpa.mil/ipto/programs/gale/ index.htm. 2 TC- STAR — Technology and Corpora for Speech to Speech Translation. http://www.tc-star.org/. 3 EACL 09 Fourth Workshop on Statistical Machine Translation. http://www.statmt.org/wmt09/. 659 Computational Linguistics Volume 37, Number 4 characteristics of source documents such as genre, domain, language, and so on. Zhou et al. (2008) propose a diagnostic evaluation of linguistic check-points obtained automatically by aligning parsed source and target sentences. For each check-point, the number of matched n-grams of the references is then calculated. Linguistically based reordering along with the syntax-based evaluation of reordering patterns is described in Xiong et al. (2010). In this work, we propose a novel framework for automatic error analysis of machine translation output based on WER and PER, and systematically investigate a set of possible methods to carry out an error analysis at the word level. 2. A Framework fo"
J11-4002,W09-0401,0,\N,Missing
J11-4002,W07-0718,0,\N,Missing
mansour-ney-2012-arabic,J93-2003,0,\N,Missing
mansour-ney-2012-arabic,W07-0813,0,\N,Missing
mansour-ney-2012-arabic,C04-1081,0,\N,Missing
mansour-ney-2012-arabic,N04-4038,0,\N,Missing
mansour-ney-2012-arabic,P05-1071,0,\N,Missing
mansour-ney-2012-arabic,P08-2030,0,\N,Missing
mansour-ney-2012-arabic,W08-0336,0,\N,Missing
mansour-ney-2012-arabic,2008.iwslt-papers.8,1,\N,Missing
mansour-ney-2012-arabic,P10-1038,0,\N,Missing
mansour-ney-2012-arabic,W06-3103,1,\N,Missing
mansour-ney-2012-arabic,W04-3250,0,\N,Missing
mansour-ney-2012-arabic,2010.iwslt-papers.15,1,\N,Missing
mansour-ney-2012-arabic,W10-1747,1,\N,Missing
mansour-ney-2012-arabic,2010.iwslt-evaluation.1,0,\N,Missing
mauser-etal-2006-training,J93-2003,0,\N,Missing
mauser-etal-2006-training,C04-1006,1,\N,Missing
mauser-etal-2006-training,knight-al-onaizan-1998-translation,0,\N,Missing
mauser-etal-2006-training,W05-0801,0,\N,Missing
mauser-etal-2006-training,P03-1006,0,\N,Missing
mauser-etal-2006-training,J00-2004,0,\N,Missing
mauser-etal-2006-training,W05-0831,1,\N,Missing
mauser-etal-2006-training,J03-1002,1,\N,Missing
mauser-etal-2006-training,P04-1065,1,\N,Missing
mauser-etal-2008-automatic,P02-1040,0,\N,Missing
mauser-etal-2008-automatic,P02-1038,1,\N,Missing
mauser-etal-2008-automatic,2006.iwslt-evaluation.15,1,\N,Missing
mauser-etal-2008-automatic,P03-1021,0,\N,Missing
N04-1033,J90-2002,0,0.660544,"rforms the alignment template system. 1 m=1 Introduction In statistical machine translation, we are given a source language (‘French’) sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language (‘English’) sentence eI1 = e1 . . . ei . . . eI . Among all possible target language sentences, we will choose the sentence with the highest probability: ª © (1) eˆI1 = argmax P r(eI1 |f1J ) eI1 = argmax eI1 © ª P r(eI1 ) · P r(f1J |eI1 ) (2) The decomposition into two knowledge sources in Equation 2 is known as the source-channel approach to statistical machine translation (Brown et al., 1990). It allows an independent modeling of target language model P r(eI1 ) and translation model P r(f1J |eI1 )1 . The target language 1 The notational convention will be as follows: we use the symbol P r(·) to denote general probability distributions with (nearly) no specific assumptions. In contrast, for model-based probability distributions, we use the generic symbol p(·). Here, Z(f1J ) denotes the appropriate normalization constant. As a decision rule, we obtain: ) ( M X I I J eˆ1 = argmax λm hm (e1 , f1 ) eI1 m=1 This approach is a generalization of the source-channel approach. It has the adv"
N04-1033,N03-1017,0,0.219939,"ven for sentences of thirty words, the translation takes only about 1.5 seconds. Recently, phrase-based translation approaches became more and more popular. Some examples are the alignment template system in (Och et al., 1999; Och and Ney, 2002) that we used for comparison. In (Zens et al., 2002), a simple phrase-based approach is described that served as starting point for the system in this work. (Marcu and Wong, 2002) presents a joint probability model for phrase-based translation. It does not use the word alignment for extracting the phrases, but directly generates a phrase alignment. In (Koehn et al., 2003), various aspects of phrase-based systems are compared, e.g. the phrase extraction method, the underlying word alignment model, or the maximum phrase length. (Tomas and Casacuberta, 2003) describes a linear interpolation of a phrase-based and an alignment template-based approach. 10 Conclusions We described a phrase-based translation approach. The basic idea of this approach is to remember all bilingual phrases that have been seen in the word-aligned training corpus. As refinements of the baseline model, we described two simple heuristics: the word penalty feature and the phrase penalty featur"
N04-1033,W02-1018,0,0.0518119,"sentence as a function of the sentence length. The translation times were measured for the translation of the 5432 test sentences of the Canadian Hansards task. We see a clear linear dependency. Even for sentences of thirty words, the translation takes only about 1.5 seconds. Recently, phrase-based translation approaches became more and more popular. Some examples are the alignment template system in (Och et al., 1999; Och and Ney, 2002) that we used for comparison. In (Zens et al., 2002), a simple phrase-based approach is described that served as starting point for the system in this work. (Marcu and Wong, 2002) presents a joint probability model for phrase-based translation. It does not use the word alignment for extracting the phrases, but directly generates a phrase alignment. In (Koehn et al., 2003), various aspects of phrase-based systems are compared, e.g. the phrase extraction method, the underlying word alignment model, or the maximum phrase length. (Tomas and Casacuberta, 2003) describes a linear interpolation of a phrase-based and an alignment template-based approach. 10 Conclusions We described a phrase-based translation approach. The basic idea of this approach is to remember all bilingua"
N04-1033,P02-1038,1,0.816091,"iversity {zens,ney}@cs.rwth-aachen.de Abstract model describes the well-formedness of the target language sentence. The translation model links the source language sentence to the target language sentence. It can be further decomposed into alignment and lexicon model. The argmax operation denotes the search problem, i.e. the generation of the output sentence in the target language. We have to maximize over all possible target language sentences. An alternative to the classical source-channel approach is the direct modeling of the posterior probability P r(eI1 |f1J ). Using a log-linear model (Och and Ney, 2002), we obtain: Ã M ! X P r(eI1 |f1J ) = exp λm hm (eI1 , f1J ) · Z(f1J ) In statistical machine translation, the currently best performing systems are based in some way on phrases or word groups. We describe the baseline phrase-based translation system and various refinements. We describe a highly efficient monotone search algorithm with a complexity linear in the input sentence length. We present translation results for three tasks: Verbmobil, Xerox and the Canadian Hansards. For the Xerox task, it takes less than 7 seconds to translate the whole test set consisting of more than 10K words. The"
N04-1033,W99-0604,1,0.730051,"anslation approach, this disambiguation is addressed by the language model only, which is often not capable of doing this. One way to incorporate the context into the translation model is to learn translations for whole phrases instead of single words. Here, a phrase is simply a sequence of words. So, the basic idea of phrase-based translation is to segment the given source sentence into phrases, then translate each phrase and finally compose the target sentence from these phrase translations. 2.2 P r(f˜1K |˜ eK 1 ) This criterion is identical to the alignment template criterion described in (Och et al., 1999). It means that two phrases are considered to be translations of each other, if the words are aligned only within the phrase pair and not to words outside. The phrases have to be contiguous. Translation Model To use phrases in the translation model, we introduce the hidden variable S. This is a segmentation of the sentence pair (f1J ; eI1 ) into K phrases (f˜1K ; e˜K 1 ). We use a one-toone phrase alignment, i.e. one source phrase is translated by exactly one target phrase. Thus, we obtain: X P r(f1J |eI1 ) = P r(f1J , S|eI1 ) (3) S = S ≈ P r(S|eI1 ) · P r(f1J |S, eI1 ) (4) n o eK ) (5) max P"
N04-1033,P03-1021,0,0.320919,"ributions, we use the generic symbol p(·). Here, Z(f1J ) denotes the appropriate normalization constant. As a decision rule, we obtain: ) ( M X I I J eˆ1 = argmax λm hm (e1 , f1 ) eI1 m=1 This approach is a generalization of the source-channel approach. It has the advantage that additional models or feature functions can be easily integrated into the overall system. The model scaling factors λM 1 are trained according to the maximum entropy principle, e.g. using the GIS algorithm. Alternatively, one can train them with respect to the final translation quality measured by some error criterion (Och, 2003). The remaining part of this work is structured as follows: in the next section, we will describe the baseline phrase-based translation model and the extraction of bilingual phrases. Then, we will describe refinements of the baseline model. In Section 4, we will describe a monotone search algorithm. Its complexity is linear in the sentence length. The next section contains the statistics of the corpora that were used. Then, we will investigate the degree of monotonicity and present the translation results for three tasks: Verbmobil, Xerox and Canadian Hansards. 2 2.1 Phrase-Based Translation M"
N04-1033,2001.mtsummit-papers.68,0,0.0284051,"erations that have to be performed to convert the generated sentence into the reference sentence. • PER (position-independent word error rate): A shortcoming of the WER is that it requires a perfect word order. The word order of an acceptable sentence can be different from that of the target sentence, so that the WER measure alone could be misleading. The PER compares the words in the two sentences ignoring the word order. • BLEU score: This score measures the precision of unigrams, bigrams, trigrams and fourgrams with respect to a reference translation with a penalty for too short sentences (Papineni et al., 2001). BLEU measures accuracy, i.e. large BLEU scores are better. • NIST score: This score is similar to BLEU. It is a weighted ngram precision in combination with a penalty for too short sentences (Doddington, 2002). NIST measures accuracy, i.e. large NIST scores are better. For the Verbmobil task, we have multiple references available. Therefore on this task, we compute all the preceding criteria with respect to multiple references. To indicate this, we will precede the acronyms with an m (multiple) if multiple references are used. For the other two tasks, only single references are used. 7.2 Tra"
N04-1033,J03-1005,1,0.50875,"from left to right. The second variant allows reordering according to the so-called IBM constraints (Berger et al., 1996). Thus up to three words may be skipped and translated later. This system will be denoted by IBM. The third variant implements special German-English reordering constraints. These constraints are represented by a finite state automaton and optimized to handle the reorderings of the German verb group. The abbreviation for this variant is GE. It is only used for the German-English Verbmobil task. This is just an extremely brief description of these systems. For details, see (Tillmann and Ney, 2003). Phrase-Based System (PB). For the phrase-based system, we use the following feature functions: a trigram language model, the phrase translation model and the word-based lexicon model. The latter two feature functions are used for both directions: p(f |e) and p(e|f ). Additionally, we use the word and phrase penalty feature functions. The model scaling factors are optimized on the development corpus with respect to mWER similar to (Och, 2003). We use the Downhill Simplex algorithm from (Press et al., 2002). We do not perform the optimization on N -best lists but we retranslate the whole devel"
N04-1033,2002.tmi-tutorials.2,0,0.0328015,"large test corpus size for this task also affects the translation speed. In Fig. 1, we see the average translation time per sentence as a function of the sentence length. The translation times were measured for the translation of the 5432 test sentences of the Canadian Hansards task. We see a clear linear dependency. Even for sentences of thirty words, the translation takes only about 1.5 seconds. Recently, phrase-based translation approaches became more and more popular. Some examples are the alignment template system in (Och et al., 1999; Och and Ney, 2002) that we used for comparison. In (Zens et al., 2002), a simple phrase-based approach is described that served as starting point for the system in this work. (Marcu and Wong, 2002) presents a joint probability model for phrase-based translation. It does not use the word alignment for extracting the phrases, but directly generates a phrase alignment. In (Koehn et al., 2003), various aspects of phrase-based systems are compared, e.g. the phrase extraction method, the underlying word alignment model, or the maximum phrase length. (Tomas and Casacuberta, 2003) describes a linear interpolation of a phrase-based and an alignment template-based approac"
N04-1033,P02-1040,0,\N,Missing
N07-1062,P05-1032,0,0.102916,"this combinatorial problem exploiting the prefix tree data structure of the phrase-table. This algorithm enables the use of significantly larger input word graphs in a more efficient way resulting in improved translation quality. The remaining part is structured as follows: we will first discuss related work in Sec. 2. Then, in Sec. 3, we will describe the phrase-table representation. Afterwards, we will present applications in speech translation and online MT in Sec. 4 and 5, respectively. Experimental results will be presented in Sec. 6 followed by the conclusions in Sec. 7. 2 Related Work (Callison-Burch et al., 2005) and (Zhang and Vogel, 2005) presented data structures for a compact representation of the word-aligned bilingual data, such that on-the-fly extraction of long phrases is possible. The motivation in (Callison-Burch et al., 2005) is that there are some long source phrases in the test data that also occur in the training data. However, the more interesting question is if these long phrases really help to improve the translation quality. We have investigated this and our results are in line with (Koehn et al., 2003) showing that the translation quality does not improve if we utilize phrases beyon"
N07-1062,P05-1033,0,0.0186306,"ively expensive beforehand. This results in more efficient decoding and improved translation quality. We have shown that this data structure scales very well to large data tasks like the Chinese-English NIST task. The implementation of the described data structure as well as the phrase-match algorithm for confusion networks is available as open source software in the MOSES toolkit1 . Not only standard phrase-based systems can benefit from this data structure. It should be rather straightforward to apply this data structure as well as the phrase-match algorithm to the hierarchical approach of (Chiang, 2005). As the number of rules in this approach is typically larger than the number of phrases in a standard phrase-based system, the gains should be even larger. The language model is another model with high memory requirements. It would be interesting to investigate if the described techniques and data structures are applicable for reducing the memory requirements of language models. Some aspects of the phrase-match algorithm are similar to the composition of finite-state automata. An efficient implementation of on-demand loading (not only on-demand computation) for a 1 http://www.statmt.org/moses"
N07-1062,N03-1017,0,0.00902819,"esented in Sec. 6 followed by the conclusions in Sec. 7. 2 Related Work (Callison-Burch et al., 2005) and (Zhang and Vogel, 2005) presented data structures for a compact representation of the word-aligned bilingual data, such that on-the-fly extraction of long phrases is possible. The motivation in (Callison-Burch et al., 2005) is that there are some long source phrases in the test data that also occur in the training data. However, the more interesting question is if these long phrases really help to improve the translation quality. We have investigated this and our results are in line with (Koehn et al., 2003) showing that the translation quality does not improve if we utilize phrases beyond a certain length. Furthermore, the suffix array data structure of (Callison-Burch et al., 2005) requires a fair amount of memory, about 2 GB in their example, whereas our implementation will use only a tiny amount of memory, e.g. less than 20 MB for the large Chinese-English NIST task. 3 Efficient Phrase-table Representation In this section, we will describe the proposed representation of the phrase-table. A prefix tree, also called trie, is an ordered tree data structure used to store an associative array wher"
N07-1062,P03-1021,0,0.0164504,"phrase-table is reduced to less than 20 MB using ondemand loading. This makes the MT system usable on devices with limited hardware resources. 6 Experimental Results 6.1 Translation System For the experiments, we use a state-of-the-art phrase-based statistical machine translation system as described in (Zens and Ney, 2004). We use a log-linear combination of several models: a fourgram language model, phrase-based and word-based translation models, word, phrase and distortion penalty and a lexicalized distortion model. The model scaling factors are optimized using minimum error rate training (Och, 2003). 6.2 Empirical Analysis for a Large Data Task In this section, we present an empirical analysis of the described data structure for the large data track of the Chinese-English NIST task. The corpus statistics are shown in Tab. 1. The translation quality is measured using two accuracy measures: the BLEU and the NIST score. Additionally, we use the two error rates: the word error rate (WER) and the position-independent word error rate (PER). These evaluation criteria are computed with respect to four reference translations. In Tab. 2, we present the translation quality as a Table 2: NIST task:"
N07-1062,N04-1033,1,0.83917,"we can avoid the filtering step and directly translate the source sentence. An additional advantage is that we load only small parts of the full phrase-table into memory. This reduces the memory requirements significantly, e.g. for the Chinese– English NIST task, the memory requirement of the phrase-table is reduced to less than 20 MB using ondemand loading. This makes the MT system usable on devices with limited hardware resources. 6 Experimental Results 6.1 Translation System For the experiments, we use a state-of-the-art phrase-based statistical machine translation system as described in (Zens and Ney, 2004). We use a log-linear combination of several models: a fourgram language model, phrase-based and word-based translation models, word, phrase and distortion penalty and a lexicalized distortion model. The model scaling factors are optimized using minimum error rate training (Och, 2003). 6.2 Empirical Analysis for a Large Data Task In this section, we present an empirical analysis of the described data structure for the large data track of the Chinese-English NIST task. The corpus statistics are shown in Tab. 1. The translation quality is measured using two accuracy measures: the BLEU and the NI"
N07-1062,2005.eamt-1.39,0,0.149157,"ing the prefix tree data structure of the phrase-table. This algorithm enables the use of significantly larger input word graphs in a more efficient way resulting in improved translation quality. The remaining part is structured as follows: we will first discuss related work in Sec. 2. Then, in Sec. 3, we will describe the phrase-table representation. Afterwards, we will present applications in speech translation and online MT in Sec. 4 and 5, respectively. Experimental results will be presented in Sec. 6 followed by the conclusions in Sec. 7. 2 Related Work (Callison-Burch et al., 2005) and (Zhang and Vogel, 2005) presented data structures for a compact representation of the word-aligned bilingual data, such that on-the-fly extraction of long phrases is possible. The motivation in (Callison-Burch et al., 2005) is that there are some long source phrases in the test data that also occur in the training data. However, the more interesting question is if these long phrases really help to improve the translation quality. We have investigated this and our results are in line with (Koehn et al., 2003) showing that the translation quality does not improve if we utilize phrases beyond a certain length. Furtherm"
N07-2015,2006.iwslt-evaluation.7,0,0.0281587,"f n-best list extraction from a word graph for SMT was presented in (Ueffing et al., 2002). In (Zens and Ney, 2005), an improved method is reported that overcomes some shortcomings, such as duplicate removal by determinization of the word graph (represented as a weighted finite state automaton) and efficient rest-cost estimation with linear time complexity. There are several research groups that use a twopass approach in their MT systems. First, they generate n-best translation hypotheses with the decoder. Second, they apply additional models to the output and rerank the candidates (see e.g. (Chen et al., 2006)). Syntactic features were investigated in (Och et al., 2004) with moderate success. Although complex models, such as features based on shallow parsing or treebank-based syntactic analyses, were applied to the n-best candidates, the “simpler” ones were more promising (e.g. IBM model 1 on sentence-level). In the following section 2, we describe our SMT system and explain how an improved n-best extraction method is capable of generating a very large number of distinct candidates from the word graph. In section 3, we show our experiments related to n-best list reranking with various sizes and the"
N07-2015,N03-1017,0,0.0040397,"l machine translation (SMT). We present a method that allows for fast extraction of very large n-best lists based on the k shortest paths algorithm by (Eppstein, 1998). We will argue that, despite being able to generate a much larger amount of hypotheses than previously reported in the literature, there is no significant gain of such a method in terms of translation quality. In recent years, phrase-based approaches evolved as the dominating method for feasible machine translation systems. Many research groups use a decoder based on a log-linear approach incorporating phrases as main paradigm (Koehn et al., 2003). As a by-product of the decoding process, one can extract n-best translations from a word graph and use these fully generated hypotheses for additional reranking. In the past, several groups report on using n-best lists with n ranging from 1 000 to 10 000. The advantage of n-best reranking is clear: we can apply Related work The idea of n-best list extraction from a word graph for SMT was presented in (Ueffing et al., 2002). In (Zens and Ney, 2005), an improved method is reported that overcomes some shortcomings, such as duplicate removal by determinization of the word graph (represented as a"
N07-2015,2006.iwslt-evaluation.15,1,0.888483,"Missing"
N07-2015,N04-1021,0,0.0748485,"ed in (Ueffing et al., 2002). In (Zens and Ney, 2005), an improved method is reported that overcomes some shortcomings, such as duplicate removal by determinization of the word graph (represented as a weighted finite state automaton) and efficient rest-cost estimation with linear time complexity. There are several research groups that use a twopass approach in their MT systems. First, they generate n-best translation hypotheses with the decoder. Second, they apply additional models to the output and rerank the candidates (see e.g. (Chen et al., 2006)). Syntactic features were investigated in (Och et al., 2004) with moderate success. Although complex models, such as features based on shallow parsing or treebank-based syntactic analyses, were applied to the n-best candidates, the “simpler” ones were more promising (e.g. IBM model 1 on sentence-level). In the following section 2, we describe our SMT system and explain how an improved n-best extraction method is capable of generating a very large number of distinct candidates from the word graph. In section 3, we show our experiments related to n-best list reranking with various sizes and the corresponding performance in terms of MT evaluation measures"
N07-2015,W02-1021,1,0.842256,"as the dominating method for feasible machine translation systems. Many research groups use a decoder based on a log-linear approach incorporating phrases as main paradigm (Koehn et al., 2003). As a by-product of the decoding process, one can extract n-best translations from a word graph and use these fully generated hypotheses for additional reranking. In the past, several groups report on using n-best lists with n ranging from 1 000 to 10 000. The advantage of n-best reranking is clear: we can apply Related work The idea of n-best list extraction from a word graph for SMT was presented in (Ueffing et al., 2002). In (Zens and Ney, 2005), an improved method is reported that overcomes some shortcomings, such as duplicate removal by determinization of the word graph (represented as a weighted finite state automaton) and efficient rest-cost estimation with linear time complexity. There are several research groups that use a twopass approach in their MT systems. First, they generate n-best translation hypotheses with the decoder. Second, they apply additional models to the output and rerank the candidates (see e.g. (Chen et al., 2006)). Syntactic features were investigated in (Och et al., 2004) with moder"
N07-2015,W05-0834,1,0.945714,"or feasible machine translation systems. Many research groups use a decoder based on a log-linear approach incorporating phrases as main paradigm (Koehn et al., 2003). As a by-product of the decoding process, one can extract n-best translations from a word graph and use these fully generated hypotheses for additional reranking. In the past, several groups report on using n-best lists with n ranging from 1 000 to 10 000. The advantage of n-best reranking is clear: we can apply Related work The idea of n-best list extraction from a word graph for SMT was presented in (Ueffing et al., 2002). In (Zens and Ney, 2005), an improved method is reported that overcomes some shortcomings, such as duplicate removal by determinization of the word graph (represented as a weighted finite state automaton) and efficient rest-cost estimation with linear time complexity. There are several research groups that use a twopass approach in their MT systems. First, they generate n-best translation hypotheses with the decoder. Second, they apply additional models to the output and rerank the candidates (see e.g. (Chen et al., 2006)). Syntactic features were investigated in (Och et al., 2004) with moderate success. Although com"
N07-2035,2006.iwslt-evaluation.18,1,0.890672,"Missing"
N07-2035,2005.iwslt-1.23,1,0.905555,"Missing"
N07-2035,J06-4004,1,0.895476,"Missing"
N07-2035,E06-1005,1,0.799617,"ingual N -gram language model. In the phrase-based model, no monotonicity restriction is imposed on the segmentation and the probabilities are normally estimated simply by relative frequencies. This paper extends the analysis of both systems performed in (Crego et al., 2005a) by additionally performing a manual error analysis of both systems, which were the ones used by UPC and RWTH in the last Tc-Star evaluation. Furthermore, we will propose a way to combine both systems in order to improve the quality of translations. Experiments combining several kinds of MT systems have been presented in (Matusov et al., 2006), based only on the single best output of each system. Recently, a more straightforward approach of both systems has been performed in (Costa-juss` a et al., 2006) which simply selects, for each sentence, one of the provided hypotheses. This paper is organized as follows. In section 2, we briefly describe the phrase and the N -gram-based baseline systems. In the next section we present the evaluation framework. In Section 4 we report a structural comparison performed for both systems and, afterwards, in Section 5, we analyze the errors of both systems. Finally, in the last two sections we resc"
N07-2035,vilar-etal-2006-error,1,0.861806,"Missing"
N07-2035,N04-1033,1,0.812475,"n N -gram-based one. The exhaustive analysis includes a comparison of the translation models in terms of efficiency (number of translation units used in the search and computational time) and an examination of the errors in each system’s output. Additionally, we combine both systems, showing accuracy improvements. 1 Introduction Statistical machine translation (SMT) has evolved from the initial word-based translation models to more advanced models that take the context surrounding the words into account. The so-called phrase-based and N -gram-based models are two examples of these approaches (Zens and Ney, 2004; Mari˜ no et al., 2006). In current state-of-the-art SMT systems, the phrase-based or the N -gram-based models are usually the main features in a log-linear framework, reminiscent of the maximum entropy modeling approach. Two basic issues differentiate the N -gram-based system from the phrase-based one: the training data is sequentially segmented into bilingual units; and the probability of these units is estimated as a bilingual N -gram language model. In the phrase-based model, no monotonicity restriction is imposed on the segmentation and the probabilities are normally estimated simply by"
N07-2035,W06-3120,1,\N,Missing
N09-2005,J93-2003,0,0.0155218,"rea et al., 2001). A logistic regression-based word translation model is investigated by Vickrey et al. (2005) but has not been evaluated on a machine translation task. Another WSD approach incorporating context-dependent phrasal translation lexicons is presented by Carpuat and Wu (2007) and has been evaluated on several translation 17 Proceedings of NAACL HLT 2009: Short Papers, pages 17–20, c Boulder, Colorado, June 2009. 2009 Association for Computational Linguistics tasks. The triplet lexicon model presented in this work can also be interpreted as an extension of the standard IBM model 1 (Brown et al., 1993) with an additional trigger. 2 Setup The main focus of this work investigates an extended lexicon model in search and rescoring. The model that we consider here and its integration in the decoder and setup for rescoring are presented in the following sections. 2.1 Extended lexicon model The triplets of the extended lexicon model p(e|f, f 0 ) are composed of two words in the source language triggering one target word. In order to limit the overall number of triplets, we apply a training constraint that reuses the word alignment information obtained in the GIZA++ step. For source words f , we on"
N09-2005,D07-1007,0,0.0534937,"unigram collocations of words are used to refine phrase pair selection dynamically by incorporating scores from the WSD classifier (Chan et al., 2007). A maximumentropy based approach with different features of surrounding words that are locally bound to a context of three positions to the left and right is reported in (Garc´ıa-Varea et al., 2001). A logistic regression-based word translation model is investigated by Vickrey et al. (2005) but has not been evaluated on a machine translation task. Another WSD approach incorporating context-dependent phrasal translation lexicons is presented by Carpuat and Wu (2007) and has been evaluated on several translation 17 Proceedings of NAACL HLT 2009: Short Papers, pages 17–20, c Boulder, Colorado, June 2009. 2009 Association for Computational Linguistics tasks. The triplet lexicon model presented in this work can also be interpreted as an extension of the standard IBM model 1 (Brown et al., 1993) with an additional trigger. 2 Setup The main focus of this work investigates an extended lexicon model in search and rescoring. The model that we consider here and its integration in the decoder and setup for rescoring are presented in the following sections. 2.1 Exte"
N09-2005,P07-1005,0,0.0411116,"fine-grained lexical choice of the target word depending on the additional source word f 0 . Since the second trigger can move over the whole sentence, we capture global (sentence-level) context that is not modeled in local n-grams of the language model or in bilingual phrase pairs that cover only a limited amount of consecutive words. Related work A similar approach has been tried in the word-sense disambiguation (WSD) domain where local but also across-sentence unigram collocations of words are used to refine phrase pair selection dynamically by incorporating scores from the WSD classifier (Chan et al., 2007). A maximumentropy based approach with different features of surrounding words that are locally bound to a context of three positions to the left and right is reported in (Garc´ıa-Varea et al., 2001). A logistic regression-based word translation model is investigated by Vickrey et al. (2005) but has not been evaluated on a machine translation task. Another WSD approach incorporating context-dependent phrasal translation lexicons is presented by Carpuat and Wu (2007) and has been evaluated on several translation 17 Proceedings of NAACL HLT 2009: Short Papers, pages 17–20, c Boulder, Colorado, J"
N09-2005,P01-1027,1,0.931639,"Missing"
N09-2005,D08-1039,1,0.705907,"Missing"
N09-2005,H05-1097,0,0.0277165,"over only a limited amount of consecutive words. Related work A similar approach has been tried in the word-sense disambiguation (WSD) domain where local but also across-sentence unigram collocations of words are used to refine phrase pair selection dynamically by incorporating scores from the WSD classifier (Chan et al., 2007). A maximumentropy based approach with different features of surrounding words that are locally bound to a context of three positions to the left and right is reported in (Garc´ıa-Varea et al., 2001). A logistic regression-based word translation model is investigated by Vickrey et al. (2005) but has not been evaluated on a machine translation task. Another WSD approach incorporating context-dependent phrasal translation lexicons is presented by Carpuat and Wu (2007) and has been evaluated on several translation 17 Proceedings of NAACL HLT 2009: Short Papers, pages 17–20, c Boulder, Colorado, June 2009. 2009 Association for Computational Linguistics tasks. The triplet lexicon model presented in this work can also be interpreted as an extension of the standard IBM model 1 (Brown et al., 1993) with an additional trigger. 2 Setup The main focus of this work investigates an extended l"
N10-1104,N03-2002,0,0.274618,"inds of prefixes and suffixes are appended to the word stems producing a very large number of inflectional forms. This leads to poor language model (LM) probability estimates, and thus high LM perplexities (PPLs) causing problems in large vocabulary continuous speech recognition (LVCSR). One successful approach to deal with this problem is to consider LMs including morphologically decomposed words. Another approach is to use the factored language models (FLMs) which are powerful models that combine multiple sources of information and efficiently integrate them via a complex backoff mechanism (Bilmes and Kirchhoff, 2003). Morphological decomposition is successfully used for Arabic LMs in several previous works. Some are based on linguistic knowledge, and others are based on unsupervised methods. Some of the linguistic methods are based on the Buckwalter Arabic Morphological Analyzer (BAMA) like in (Lamel et al., 2008). Alternatively, in our previous work (El-Desoky et al., 2009), we use the Morphological Analyzer and Disambiguator for Arabic (MADA) (Habash and Rambow, 2007). On the other side, most of the unsupervised methods are based on the minimum description length principle (MDL) like in (Creutz et al.,"
N10-1104,N07-1048,0,0.0959385,"irchhoff, 2003). Morphological decomposition is successfully used for Arabic LMs in several previous works. Some are based on linguistic knowledge, and others are based on unsupervised methods. Some of the linguistic methods are based on the Buckwalter Arabic Morphological Analyzer (BAMA) like in (Lamel et al., 2008). Alternatively, in our previous work (El-Desoky et al., 2009), we use the Morphological Analyzer and Disambiguator for Arabic (MADA) (Habash and Rambow, 2007). On the other side, most of the unsupervised methods are based on the minimum description length principle (MDL) like in (Creutz et al., 2007). Another type of models is the FLM, in which words are viewed as vectors of K factors, so that wt := {ft1:K }. A factor could be any feature of the word such as morphological class, stem, root or even a semantic feature. An FLM is a model over factors, 1:K , f 1:K , ..., f 1:K ), which could be i.e., p(ft1:K |ft−1 t−2 t−n+1 reformed as a product of probabilities of the form p(f |f1 , f2 , ..., fN ). The main idea of the model is to backoff to other factors when some word n-gram is not observed in the training data, thus improving the probability estimates. In this work we try to combine the s"
N10-1104,W02-0506,0,0.0397692,"th the standard full-word, decomposed word, and factored full-word n-gram approaches. 2 Factorization and Decomposition We use MADA 2.0 in order to perform morphological analysis and attach a complete set of morphological tags to Arabic words in context. From those tags 701 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 701–704, c Los Angeles, California, June 2010. 2010 Association for Computational Linguistics we derive three different features. Moreover, we derive a fourth feature based on the root of the word generated by ”Sebawai” (Darwish, 2002). The list of features is: • ”W” (Word): word surface form. • ”L” (Lexeme): word lexeme. • ”M” (Morph): morphological description. • ”P” (Pattern): word after subtracting root. The LM training corpora are processed so that words are replaced by the factored representation as required by SRILM-FLM extensions (Kirchhoff et al., 2008). Then, word decomposition is performed based on MADA as described in our previous publication (El-Desoky et al., 2009). 3 FLM topologies In order to obtain a good performance via FLMs, we need to optimize the FLM parameters: the combination of the conditioning facto"
N10-1104,N07-2014,0,0.0303617,"which are powerful models that combine multiple sources of information and efficiently integrate them via a complex backoff mechanism (Bilmes and Kirchhoff, 2003). Morphological decomposition is successfully used for Arabic LMs in several previous works. Some are based on linguistic knowledge, and others are based on unsupervised methods. Some of the linguistic methods are based on the Buckwalter Arabic Morphological Analyzer (BAMA) like in (Lamel et al., 2008). Alternatively, in our previous work (El-Desoky et al., 2009), we use the Morphological Analyzer and Disambiguator for Arabic (MADA) (Habash and Rambow, 2007). On the other side, most of the unsupervised methods are based on the minimum description length principle (MDL) like in (Creutz et al., 2007). Another type of models is the FLM, in which words are viewed as vectors of K factors, so that wt := {ft1:K }. A factor could be any feature of the word such as morphological class, stem, root or even a semantic feature. An FLM is a model over factors, 1:K , f 1:K , ..., f 1:K ), which could be i.e., p(ft1:K |ft−1 t−2 t−n+1 reformed as a product of probabilities of the form p(f |f1 , f2 , ..., fN ). The main idea of the model is to backoff to other fac"
N12-1035,J93-2003,0,0.021312,"corpus, we are able to estimate single-word based translation probabilities pRF (e|f ) by relative frequency (Koehn et al., 2003). With N (e, f ) denoting counts of aligned cooccurrences of target word e and source word f , we can compute pRF (e|f ) = P N (e, f ) . 0 e0 N (e , f ) (5) If an occurrence of e has multiple aligned source words, each of the alignment links contributes with a fractional count. We denote this model as relative frequency (RF) word lexicon. 2.2 IBM Model 1 The IBM model 1 lexicon (IBM-1) is the first and most basic one in a sequence of probabilistic generative models (Brown et al., 1993). For IBM-1, several simplifying assumptions are made, so that the probability of a target sentence eI1 given a source sentence f0J (with f0 = NULL) can be modeled as P r(eI1 |f1J ) = I X J Y 1 pibm1 (ei |fj ) . (6) (J + 1)I i=1 j=0 The parameters of IBM-1 are estimated iteratively by means of the Expectation-Maximization algorithm with maximum likelihood as training criterion. 3 Thresholding Methods (4) We introduce thresholding methods for insertion and deletion models which set thresholds based on the characteristics of the lexicon model that is applied. For all the following thresholding m"
N12-1035,P05-1033,0,0.084253,"the phrase. Related techniques have been employed before by Och et al. (2003) in an n-best reranking framework and by Mauser et al. (2006) and Zens (2008) in a standard phrase-based translation system. We propose novel thresholding methods in this work and study insertion and deletion features which are based on two different types of lexicon models. We give an extensive experimental evaluation of all these variants on the NIST Chinese→English translation task. 1 ts2tIns (α, β) = Iβ Jα X Y p(βi |αj ) < ταj  (1) i=1 j=1 Insertion and Deletion Models In hierarchical phrase-based translation (Chiang, 2005), we deal with rules X → hα, β,∼ i where hα, βi is a bilingual phrase pair that may contain symbols from a non-terminal set, i.e. α ∈ (N ∪ VF )+ and β ∈ (N ∪VE )+ , where VF and VE are the source and target vocabulary, respectively, and N is a non-terminal set which is shared by source and target. The left-hand side of the rule is a non-terminal symbol X ∈ N , and the ∼ relation denotes a oneto-one correspondence between the non-terminals in α and in β. Let Jα denote the number of terminal Here, [·] denotes a true or false statement: The result is 1 if the condition is true and 0 if the condit"
N12-1035,P07-1019,0,0.03227,"ven f . 4 Experimental Evaluation We present empirical results obtained with the different insertion and deletion model variants on the Chinese→English 2008 NIST task.2 4.1 4.2 Experimental Setup To set up our systems, we employ the open source statistical machine translation toolkit Jane (Vilar et al., 2010; Vilar et al., 2012), which is freely available for non-commercial use. Jane provides efficient C++ implementations for hierarchical phrase extraction, optimization of log-linear feature weights, and parsing-based decoding algorithms. In our experiments, we use the cube pruning algorithm (Huang and Chiang, 2007) to carry out the search. We work with a parallel training corpus of 3.0M Chinese-English sentence pairs (77.5M Chinese / 81.0M English running words). The counts for the RF lexicon models are computed from a symmetrized word alignment (Och and Ney, 2003), the IBM-1 models are produced with GIZA++. When extracting phrases, we apply several restrictions, in particular a maximum length of 10 on source and target side for lexical phrases, a length limit of five (including non-terminal symbols) for hierarchical phrases, and no more than two gaps per phrase. The models integrated into the baseline"
N12-1035,2011.iwslt-papers.1,1,0.88181,"Missing"
N12-1035,2012.eamt-1.66,1,0.872774,"Missing"
N12-1035,N03-1017,0,0.0474752,"Jα Y X   ts2tDel (α, β) = p(βi |αj ) < ταj (3) j=1 i=1 It considers an occurrence of a source word f a deletion iff no target word e exists within the phrase with p(e|f ) greater than or equal to τf . The target-to-source deletion model tt2sDel (·) correspondingly considers an occurrence of a target word e a deletion iff no source word f exists within the phrase with p(f |e) greater than or equal to τe : 2.1 Word Lexicon from Word-Aligned Data Given a word-aligned parallel training corpus, we are able to estimate single-word based translation probabilities pRF (e|f ) by relative frequency (Koehn et al., 2003). With N (e, f ) denoting counts of aligned cooccurrences of target word e and source word f , we can compute pRF (e|f ) = P N (e, f ) . 0 e0 N (e , f ) (5) If an occurrence of e has multiple aligned source words, each of the alignment links contributes with a fractional count. We denote this model as relative frequency (RF) word lexicon. 2.2 IBM Model 1 The IBM model 1 lexicon (IBM-1) is the first and most basic one in a sequence of probabilistic generative models (Brown et al., 1993). For IBM-1, several simplifying assumptions are made, so that the probability of a target sentence eI1 given"
N12-1035,J03-1002,1,0.00845144,"hine translation toolkit Jane (Vilar et al., 2010; Vilar et al., 2012), which is freely available for non-commercial use. Jane provides efficient C++ implementations for hierarchical phrase extraction, optimization of log-linear feature weights, and parsing-based decoding algorithms. In our experiments, we use the cube pruning algorithm (Huang and Chiang, 2007) to carry out the search. We work with a parallel training corpus of 3.0M Chinese-English sentence pairs (77.5M Chinese / 81.0M English running words). The counts for the RF lexicon models are computed from a symmetrized word alignment (Och and Ney, 2003), the IBM-1 models are produced with GIZA++. When extracting phrases, we apply several restrictions, in particular a maximum length of 10 on source and target side for lexical phrases, a length limit of five (including non-terminal symbols) for hierarchical phrases, and no more than two gaps per phrase. The models integrated into the baseline are: phrase translation probabilities and RF lexical translation probabilities on phrase level, each for both translation directions, length penalties on word and phrase level, binary features marking hierarchical phrases, glue rule, and rules with non-te"
N12-1035,P03-1021,0,0.0317562,"Missing"
N12-1035,P02-1040,0,0.0819074,"Missing"
N12-1035,2006.amta-papers.25,0,0.076777,"Missing"
N12-1035,W10-1738,1,0.850092,"r than the floor value are not thresholded. This variant may be considered as histogram ∞. We only apply it with RF lexicons. median τf is a median-based distinct value for each f , i.e. it is set to the value that separates the higher half of the entries from the lower half of the entries p(e|f ) for the given f . 4 Experimental Evaluation We present empirical results obtained with the different insertion and deletion model variants on the Chinese→English 2008 NIST task.2 4.1 4.2 Experimental Setup To set up our systems, we employ the open source statistical machine translation toolkit Jane (Vilar et al., 2010; Vilar et al., 2012), which is freely available for non-commercial use. Jane provides efficient C++ implementations for hierarchical phrase extraction, optimization of log-linear feature weights, and parsing-based decoding algorithms. In our experiments, we use the cube pruning algorithm (Huang and Chiang, 2007) to carry out the search. We work with a parallel training corpus of 3.0M Chinese-English sentence pairs (77.5M Chinese / 81.0M English running words). The counts for the RF lexicon models are computed from a symmetrized word alignment (Och and Ney, 2003), the IBM-1 models are produced"
N12-1035,2006.iwslt-evaluation.15,1,\N,Missing
N12-1035,D08-1076,0,\N,Missing
N13-1074,W07-0717,0,0.244266,"ctures translation tasks show significant improvements of the adapted systems over the general ones. Additionally, we compare our results to mixture modeling, where we report gains when using the suggested phrase training adaptation method. 1 Introduction The task of domain-adaptation attempts to exploit data mainly drawn from one domain (e.g. news, parliamentary discussion) to maximize the performance on the test domain (e.g. lectures, web forums). In this work, we focus on translation model (TM) adaptation. A prominent approach in recent work is weighting at different levels of granularity. Foster and Kuhn (2007) perform weighting at the corpus level, where different corpora receive different weights and are then combined using mixture modeling. A finer grained weighting is that of Matsoukas et al. (2009), who weight each sentence in the bitexts using features of meta-information and optimize a mapping from the feature vectors to weights using a translation quality measure. In this work, we propose to perform TM adaptation using phrase training. We start from a generaldomain phrase table and adapt the probabilities by training on an in-domain data. Thus, we achieve direct phrase probabilities adaptati"
N13-1074,D10-1044,0,0.47302,"Missing"
N13-1074,E03-1076,0,0.0458295,"Missing"
N13-1074,D09-1074,0,0.259539,"suggested phrase training adaptation method. 1 Introduction The task of domain-adaptation attempts to exploit data mainly drawn from one domain (e.g. news, parliamentary discussion) to maximize the performance on the test domain (e.g. lectures, web forums). In this work, we focus on translation model (TM) adaptation. A prominent approach in recent work is weighting at different levels of granularity. Foster and Kuhn (2007) perform weighting at the corpus level, where different corpora receive different weights and are then combined using mixture modeling. A finer grained weighting is that of Matsoukas et al. (2009), who weight each sentence in the bitexts using features of meta-information and optimize a mapping from the feature vectors to weights using a translation quality measure. In this work, we propose to perform TM adaptation using phrase training. We start from a generaldomain phrase table and adapt the probabilities by training on an in-domain data. Thus, we achieve direct phrase probabilities adaptation as opposed to weighting. Foster et al. (2010) perform weighting at the phrase level, assigning each phrase pair a weight according to its relevance to the test domain. They compare phrase weigh"
N13-1074,P03-1021,0,0.0579044,"pen-source SMT toolkit Jane 2.0, which provides a state-ofthe-art phrase-based SMT system (Wuebker et al., 2012a). In addition to the phrase based decoder, Jane 2.0 implements the forced alignment procedure used in this work for the purpose of adaptation. We use the standard set of models with phrase translation probabilities for source-to-target and target-tosource directions, smoothing with lexical weights, a word and phrase penalty, distance-based reordering and an n-gram target language model. The SMT systems are tuned on the dev (dev2010) development set with minimum error rate training (Och, 2003) us651 ing B LEU (Papineni et al., 2002) accuracy measure as the optimization criterion. We test the performance of our system on the test (tst2010) and eval (tst2011) sets using the B LEU and translation edit rate (T ER) (Snover et al., 2006) measures. We use T ER as an additional measure to verify the consistency of our improvements and avoid over-tuning. The Arabic-English results are case sensitive while the German-English results are case insensitive. 4 Results For TM training, we define three different sets: indomain (IN) which is the TED corpus, other-domain (OD) which consists of the U"
N13-1074,P02-1040,0,0.0856405,"2.0, which provides a state-ofthe-art phrase-based SMT system (Wuebker et al., 2012a). In addition to the phrase based decoder, Jane 2.0 implements the forced alignment procedure used in this work for the purpose of adaptation. We use the standard set of models with phrase translation probabilities for source-to-target and target-tosource directions, smoothing with lexical weights, a word and phrase penalty, distance-based reordering and an n-gram target language model. The SMT systems are tuned on the dev (dev2010) development set with minimum error rate training (Och, 2003) us651 ing B LEU (Papineni et al., 2002) accuracy measure as the optimization criterion. We test the performance of our system on the test (tst2010) and eval (tst2011) sets using the B LEU and translation edit rate (T ER) (Snover et al., 2006) measures. We use T ER as an additional measure to verify the consistency of our improvements and avoid over-tuning. The Arabic-English results are case sensitive while the German-English results are case insensitive. 4 Results For TM training, we define three different sets: indomain (IN) which is the TED corpus, other-domain (OD) which consists of the UN corpus for ArabicEnglish and a concate"
N13-1074,popovic-ney-2006-pos,1,0.92193,"Missing"
N13-1074,P08-2030,0,0.155797,"Missing"
N13-1074,2006.amta-papers.25,0,0.0563959,"purpose of adaptation. We use the standard set of models with phrase translation probabilities for source-to-target and target-tosource directions, smoothing with lexical weights, a word and phrase penalty, distance-based reordering and an n-gram target language model. The SMT systems are tuned on the dev (dev2010) development set with minimum error rate training (Och, 2003) us651 ing B LEU (Papineni et al., 2002) accuracy measure as the optimization criterion. We test the performance of our system on the test (tst2010) and eval (tst2011) sets using the B LEU and translation edit rate (T ER) (Snover et al., 2006) measures. We use T ER as an additional measure to verify the consistency of our improvements and avoid over-tuning. The Arabic-English results are case sensitive while the German-English results are case insensitive. 4 Results For TM training, we define three different sets: indomain (IN) which is the TED corpus, other-domain (OD) which consists of the UN corpus for ArabicEnglish and a concatenation of news-commentary and europarl for German-English, and ALL which consists of the concatenation of IN and OD. We experiment with the following extraction methods: • Heuristics: standard phrase ext"
N13-1074,P10-1049,1,0.630675,"ction 4 summarizes the phrase training adaptation results ending with a comparison to mixture modeling. 649 Proceedings of NAACL-HLT 2013, pages 649–654, c Atlanta, Georgia, 9–14 June 2013. 2013 Association for Computational Linguistics 2 Phrase Training The standard phrase extraction procedure in SMT consists of two phases: (i) word-alignment training (e.g., IBM alignment models), (ii) heuristic phrase extraction and relative frequency based phrase translation probability estimation. In this work, we utilize phrase training for the task of adaptation. We use the forced alignment (FA) method (Wuebker et al., 2010) to perform the phrase alignment training and probability estimation. We perform phrase training by running a normal SMT decoder on the training data and constrain the translation to the given target instance. Using n-best possible phrase segmentation for each training instance, the phrase probabilities are re-estimated over the output. Leaving-one-out is used during the forced alignment procedure phase to avoid over-fitting (Wuebker et al., 2010). In the standard phrase training procedure, we are given a training set y, from which an initial heuristics-based phrase table p0y is generated. FA"
N13-1074,C12-3061,1,0.859338,"the phrase probabilities obtained from the in-domain corpus, causing a deterioration in performance. One way to avoid this contamination is by filtering the general corpus, but this discards phrase translations completely from the phrase model. A more principled way is by adapting the phrase probabilities of the full system to the domain being tackled. We perform this by phrase training the full phrase table over the in-domain training set. 3.2 Translation System The baseline system is built using the open-source SMT toolkit Jane 2.0, which provides a state-ofthe-art phrase-based SMT system (Wuebker et al., 2012a). In addition to the phrase based decoder, Jane 2.0 implements the forced alignment procedure used in this work for the purpose of adaptation. We use the standard set of models with phrase translation probabilities for source-to-target and target-tosource directions, smoothing with lexical weights, a word and phrase penalty, distance-based reordering and an n-gram target language model. The SMT systems are tuned on the dev (dev2010) development set with minimum error rate training (Och, 2003) us651 ing B LEU (Papineni et al., 2002) accuracy measure as the optimization criterion. We test the"
N13-1074,W12-3158,0,0.0197547,"the phrase probabilities obtained from the in-domain corpus, causing a deterioration in performance. One way to avoid this contamination is by filtering the general corpus, but this discards phrase translations completely from the phrase model. A more principled way is by adapting the phrase probabilities of the full system to the domain being tackled. We perform this by phrase training the full phrase table over the in-domain training set. 3.2 Translation System The baseline system is built using the open-source SMT toolkit Jane 2.0, which provides a state-ofthe-art phrase-based SMT system (Wuebker et al., 2012a). In addition to the phrase based decoder, Jane 2.0 implements the forced alignment procedure used in this work for the purpose of adaptation. We use the standard set of models with phrase translation probabilities for source-to-target and target-tosource directions, smoothing with lexical weights, a word and phrase penalty, distance-based reordering and an n-gram target language model. The SMT systems are tuned on the dev (dev2010) development set with minimum error rate training (Och, 2003) us651 ing B LEU (Papineni et al., 2002) accuracy measure as the optimization criterion. We test the"
N15-1175,D14-1132,0,0.555118,"being performed. This stands in contrast to the generative approach, where parameters are chosen to maximize likelihood under a generative story, which often bears little correspondence with the actual application of the model. In statistical machine translation (SMT), extending the generative noisy-channel formulation (Brown et al., 1993) as a discriminative, log-linear 1. We propose to apply the RPROP algorithm for maximum expected B LEU training and perform an experimental comparison with growth transformation (GT) (He and Deng, 2012; Setiawan and Zhou, 2013), stochastic gradient descent (Auli et al., 2014) and AdaGrad (Green et al., 2013). RPROP yields superior performance, reaching a total improvement of 1.2 B LEU points over our IWSLT German→English baseline using 5.22M features. 2. In terms of time and memory efficiency, RPROP clearly outperforms GT. The latter needs to update a much larger number of features due to its renormalization component. On the IWSLT data, RPROP is 6.4 times faster than GT and requires a third of the memory. 3. On the WMT German→English task, we perform discriminative training on 4M sentence 1516 Human Language Technologies: The 2015 Annual Conference of the North A"
N15-1175,P08-1024,0,0.0212667,"all development corpus. Another approach based on the AdaGrad method that scales to large numbers of sparse features is proposed in (Green et al., 2013; Green et al., 2014). Different from our work, the authors use either the tuning sets or a small subsample of the training data (15k sentences) for discriminative training. A notably different idea is pursued by Yu et al. (2013), who present a large-scale training procedure that explicitly minimizes search errors. This is achieved by force-decoding the training data and updating at the point where the correct derivation drops off the beam. In (Blunsom et al., 2008), conditional random fields (CRFs) are trained within a hierarchical phrase-based translation framework. The hierarchical phrase-based paradigm is used to model the search space in model estimation and search, leaving the hypothesis weighting to CRF features. They constrain search by a beam width for gradient estimation and update the model with the help of LBFGS. In a similar way Lavergne et al. (2011) use the n-gram based approach (Casacuberta and Vidal, 2004; Mari˜no et al., 2006) to model the reordering, phrase alignment, and the language model. A CRF is applied to estimate the phrase weig"
N15-1175,J93-2003,0,0.0601724,"performed on the full training data of 4M sentence pairs, which is unsurpassed in the literature. 1 Introduction The main advantage of learning parameters in a discriminative fashion is the possibility to directly optimize towards a quality or error measure on the task that is being performed. This stands in contrast to the generative approach, where parameters are chosen to maximize likelihood under a generative story, which often bears little correspondence with the actual application of the model. In statistical machine translation (SMT), extending the generative noisy-channel formulation (Brown et al., 1993) as a discriminative, log-linear 1. We propose to apply the RPROP algorithm for maximum expected B LEU training and perform an experimental comparison with growth transformation (GT) (He and Deng, 2012; Setiawan and Zhou, 2013), stochastic gradient descent (Auli et al., 2014) and AdaGrad (Green et al., 2013). RPROP yields superior performance, reaching a total improvement of 1.2 B LEU points over our IWSLT German→English baseline using 5.22M features. 2. In terms of time and memory efficiency, RPROP clearly outperforms GT. The latter needs to update a much larger number of features due to its"
N15-1175,J04-2004,0,0.0219315,"errors. This is achieved by force-decoding the training data and updating at the point where the correct derivation drops off the beam. In (Blunsom et al., 2008), conditional random fields (CRFs) are trained within a hierarchical phrase-based translation framework. The hierarchical phrase-based paradigm is used to model the search space in model estimation and search, leaving the hypothesis weighting to CRF features. They constrain search by a beam width for gradient estimation and update the model with the help of LBFGS. In a similar way Lavergne et al. (2011) use the n-gram based approach (Casacuberta and Vidal, 2004; Mari˜no et al., 2006) to model the reordering, phrase alignment, and the language model. A CRF is applied to estimate the phrase weights. Model updates are carried out by the RPROP algorithm (Riedmiller and Braun, 1993). However, both approaches only improve over constrained baselines. Our work is inspired by (He and Deng, 2012; Setiawan and Zhou, 2013), where the authors propose to train the standard phrasal and lexical channel models with the growth transformation (GT) algorithm. They use n-best lists on the training data and optimize a maximum expected B LEU objective, that provides a cle"
N15-1175,D08-1024,0,0.0301702,"m expected B LEU training algorithm. Finally, experimental results are given in Section 6 and we conclude with Section 7. 2 Related Work Discriminative training is one of the most active research areas in SMT and it can be integrated into the pipeline at various stages. Och (2003) proposed to apply minimum error rate training (MERT) to optimize the different feature weights in the log-linear model combination on a small development data set. This is still considered to be the state of the art, but is only capable of optimizing a handful of features. More recently, MIRA (Watanabe et al., 2007; Chiang et al., 2008) and PRO (Hopkins and May, 2011) have been presented as optimization procedures that can replace MERT and scale to thousands of parameters. In a different line of work, Liang et al. (2006) describe a fully discriminative training pipeline, where more than one million features are tuned on the training data using a perceptron-style update algorithm. The Direct Translation Model 2 introduced 1517 by Ittycheriah and Roukos (2007) is similar in that it also trains millions of features on the training data. However, the weights are estimated based on a maximum entropy model and the underlying trans"
N15-1175,P05-1033,0,0.0663444,"training on a data set as large as four million sentence pairs. (iii) We apply a leave-one-out heuristic (Wuebker et al., 2010) to make better use of the training data. (iv) We apply phrasal, lexical, reordering and triplet features. (v) Finally, we do not run MERT after each training iteration, which is expensive for large translation systems. 3 Statistical Translation System Our work can be applied to any statistical machine translation paradigm and we will present results on a standard phrase-based translation system (Koehn et al., 2003) and a hierarchical phrase-based translation system (Chiang, 2005). The translation process is implemented as a weighted log-linear combination of several models hm,Θ (E, F ), where E = e1 , . . . , eI denotes the translation hypothesis, F = f1 , . . . , fJ the source sentence, m a model index, and Θ the model parameters. These models include the phrase translation and lexical smoothing scores in both directions, language model (LM) score, distortion penalty, word penalty and phrase penalty (Och and Ney, 2004). Given a source sentence F , the models hm,Θ (E, F ) and the corresponding loglinear feature weights λm , the translation decoder ˆ searches for the b"
N15-1175,P11-2031,0,0.0801903,"s for the bilingual training data of the IWSLT 2013 German→English, the DARPA BOLT Chinese→English and the WMT 2014 German→English tasks. and LDC English Gigaword corpora. The selection is based on cross-entropy difference (Moore and Lewis, 2010). This makes for a total of 1.7 billion running words for LM training. The baseline further contains a hierarchical reordering model (HRM) (Galley and Manning, 2008) and a 7-gram word class language model (Wuebker et al., 2013). On IWSLT, all results are averages over three independent MERT runs, and we evaluate statistical significance with MultEval (Clark et al., 2011). To confirm our findings, additional experiments are run on two large-scale tasks over strong baselines including recurrent neural language models. On the DARPA BOLT Chinese→English task we use our internal evaluation system as a baseline. It is a powerful hierarchical phrase-based SMT engine with 19 dense features, including an LSTM recurrent neural language model (Sundermeyer et al., 2012) and a hierarchical reordering model (Huck et al., 2013). The 5-gram backoff LM is in total trained on 2.9 billion running words. We use the same data for tuning and testing as Setiawan and Zhou (2013), na"
N15-1175,D08-1089,0,0.444835,"apply leave-one-out with all update strategies. 5.3 Features Maximum expected B LEU training facilitates training of arbitrary features. In this work we apply four types of features. (a) A discriminative phrase table, i.e. one feature for each phrase pair. (b) Lexical features, i.e. one feature for each source-target word pair that appear within the same phrase. (c) Source and target triplet features (Hasan et al., 2008), i.e. triples of one source and two target words or one target and two source words appearing within a single phrase pair. (d) The hierarchical lexicalized reordering model (Galley and Manning, 2008), i.e. one feature for each combination of phrase pair, orientation (monotone (M), swap (S) or discontinuous (D)) and orientation direction (forward or backward). GT is only applied with feature set (a), where we reestimate the two phrasal channel models as was done in (He and Deng, 2012). With the other update algorithms we follow the approach taken in (Auli et al., 2014) and condense each feature type into a small number of models for the log-linear combination, which is afterwards tuned with MERT. (a) and (b) result in a single additional model, (c) in two models (source and target triplets"
N15-1175,N13-1048,0,0.0164076,"ization procedures that can replace MERT and scale to thousands of parameters. In a different line of work, Liang et al. (2006) describe a fully discriminative training pipeline, where more than one million features are tuned on the training data using a perceptron-style update algorithm. The Direct Translation Model 2 introduced 1517 by Ittycheriah and Roukos (2007) is similar in that it also trains millions of features on the training data. However, the weights are estimated based on a maximum entropy model and the underlying translation paradigm differs from the standard phrasebased model. Gao and He (2013) use gradient ascent to train Markov random field models for phrase translation. These models are interpreted as undirected phrase compatibility scores rather than translation probabilities. Thus, as in our work, they are not subject to a sum-to-one constraint. Simianer et al. (2012) propose a distributed setup for large-scale discriminative training with joint feature selection. The training corpus is divided into several shards, on which features are updated via perceptron-style gradient descent. The authors present results showing that training on large data sets improves results over just"
N15-1175,P13-1031,0,0.163139,"contrast to the generative approach, where parameters are chosen to maximize likelihood under a generative story, which often bears little correspondence with the actual application of the model. In statistical machine translation (SMT), extending the generative noisy-channel formulation (Brown et al., 1993) as a discriminative, log-linear 1. We propose to apply the RPROP algorithm for maximum expected B LEU training and perform an experimental comparison with growth transformation (GT) (He and Deng, 2012; Setiawan and Zhou, 2013), stochastic gradient descent (Auli et al., 2014) and AdaGrad (Green et al., 2013). RPROP yields superior performance, reaching a total improvement of 1.2 B LEU points over our IWSLT German→English baseline using 5.22M features. 2. In terms of time and memory efficiency, RPROP clearly outperforms GT. The latter needs to update a much larger number of features due to its renormalization component. On the IWSLT data, RPROP is 6.4 times faster than GT and requires a third of the memory. 3. On the WMT German→English task, we perform discriminative training on 4M sentence 1516 Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages"
N15-1175,W14-3360,0,0.0118293,"translation probabilities. Thus, as in our work, they are not subject to a sum-to-one constraint. Simianer et al. (2012) propose a distributed setup for large-scale discriminative training with joint feature selection. The training corpus is divided into several shards, on which features are updated via perceptron-style gradient descent. The authors present results showing that training on large data sets improves results over just using a small development corpus. Another approach based on the AdaGrad method that scales to large numbers of sparse features is proposed in (Green et al., 2013; Green et al., 2014). Different from our work, the authors use either the tuning sets or a small subsample of the training data (15k sentences) for discriminative training. A notably different idea is pursued by Yu et al. (2013), who present a large-scale training procedure that explicitly minimizes search errors. This is achieved by force-decoding the training data and updating at the point where the correct derivation drops off the beam. In (Blunsom et al., 2008), conditional random fields (CRFs) are trained within a hierarchical phrase-based translation framework. The hierarchical phrase-based paradigm is used"
N15-1175,D08-1039,1,0.869947,"Missing"
N15-1175,P12-1031,0,0.0870934,"o directly optimize towards a quality or error measure on the task that is being performed. This stands in contrast to the generative approach, where parameters are chosen to maximize likelihood under a generative story, which often bears little correspondence with the actual application of the model. In statistical machine translation (SMT), extending the generative noisy-channel formulation (Brown et al., 1993) as a discriminative, log-linear 1. We propose to apply the RPROP algorithm for maximum expected B LEU training and perform an experimental comparison with growth transformation (GT) (He and Deng, 2012; Setiawan and Zhou, 2013), stochastic gradient descent (Auli et al., 2014) and AdaGrad (Green et al., 2013). RPROP yields superior performance, reaching a total improvement of 1.2 B LEU points over our IWSLT German→English baseline using 5.22M features. 2. In terms of time and memory efficiency, RPROP clearly outperforms GT. The latter needs to update a much larger number of features due to its renormalization component. On the IWSLT data, RPROP is 6.4 times faster than GT and requires a third of the memory. 3. On the WMT German→English task, we perform discriminative training on 4M sentence"
N15-1175,P13-2121,0,0.0909589,"Missing"
N15-1175,D11-1125,0,0.0240956,"rithm. Finally, experimental results are given in Section 6 and we conclude with Section 7. 2 Related Work Discriminative training is one of the most active research areas in SMT and it can be integrated into the pipeline at various stages. Och (2003) proposed to apply minimum error rate training (MERT) to optimize the different feature weights in the log-linear model combination on a small development data set. This is still considered to be the state of the art, but is only capable of optimizing a handful of features. More recently, MIRA (Watanabe et al., 2007; Chiang et al., 2008) and PRO (Hopkins and May, 2011) have been presented as optimization procedures that can replace MERT and scale to thousands of parameters. In a different line of work, Liang et al. (2006) describe a fully discriminative training pipeline, where more than one million features are tuned on the training data using a perceptron-style update algorithm. The Direct Translation Model 2 introduced 1517 by Ittycheriah and Roukos (2007) is similar in that it also trains millions of features on the training data. However, the weights are estimated based on a maximum entropy model and the underlying translation paradigm differs from the"
N15-1175,W13-2258,1,0.854976,"Wuebker et al., 2013). On IWSLT, all results are averages over three independent MERT runs, and we evaluate statistical significance with MultEval (Clark et al., 2011). To confirm our findings, additional experiments are run on two large-scale tasks over strong baselines including recurrent neural language models. On the DARPA BOLT Chinese→English task we use our internal evaluation system as a baseline. It is a powerful hierarchical phrase-based SMT engine with 19 dense features, including an LSTM recurrent neural language model (Sundermeyer et al., 2012) and a hierarchical reordering model (Huck et al., 2013). The 5-gram backoff LM is in total trained on 2.9 billion running words. We use the same data for tuning and testing as Setiawan and Zhou (2013), namely 1275 (tune) and 12393 sentences of web data taken from LDC2010E30, the NIST MT06 evaluation set and an additional single-reference test set from the discussion forum (df) domain containing 1124 sentence pairs. Maximum expected B LEU training is performed on the discussion forum portion of the training data, consisting of 67.8K sentence pairs. On the German→English task of the 9th Workshop on Statistical Machine Translation4 , both translation"
N15-1175,N07-1008,0,0.0157828,"ll development data set. This is still considered to be the state of the art, but is only capable of optimizing a handful of features. More recently, MIRA (Watanabe et al., 2007; Chiang et al., 2008) and PRO (Hopkins and May, 2011) have been presented as optimization procedures that can replace MERT and scale to thousands of parameters. In a different line of work, Liang et al. (2006) describe a fully discriminative training pipeline, where more than one million features are tuned on the training data using a perceptron-style update algorithm. The Direct Translation Model 2 introduced 1517 by Ittycheriah and Roukos (2007) is similar in that it also trains millions of features on the training data. However, the weights are estimated based on a maximum entropy model and the underlying translation paradigm differs from the standard phrasebased model. Gao and He (2013) use gradient ascent to train Markov random field models for phrase translation. These models are interpreted as undirected phrase compatibility scores rather than translation probabilities. Thus, as in our work, they are not subject to a sum-to-one constraint. Simianer et al. (2012) propose a distributed setup for large-scale discriminative training"
N15-1175,N03-1017,0,0.0329409,"tal comparison. (ii) For the first time, we apply maximum expected B LEU training on a data set as large as four million sentence pairs. (iii) We apply a leave-one-out heuristic (Wuebker et al., 2010) to make better use of the training data. (iv) We apply phrasal, lexical, reordering and triplet features. (v) Finally, we do not run MERT after each training iteration, which is expensive for large translation systems. 3 Statistical Translation System Our work can be applied to any statistical machine translation paradigm and we will present results on a standard phrase-based translation system (Koehn et al., 2003) and a hierarchical phrase-based translation system (Chiang, 2005). The translation process is implemented as a weighted log-linear combination of several models hm,Θ (E, F ), where E = e1 , . . . , eI denotes the translation hypothesis, F = f1 , . . . , fJ the source sentence, m a model index, and Θ the model parameters. These models include the phrase translation and lexical smoothing scores in both directions, language model (LM) score, distortion penalty, word penalty and phrase penalty (Och and Ney, 2004). Given a source sentence F , the models hm,Θ (E, F ) and the corresponding loglinear"
N15-1175,W11-2168,0,0.073415,"le training procedure that explicitly minimizes search errors. This is achieved by force-decoding the training data and updating at the point where the correct derivation drops off the beam. In (Blunsom et al., 2008), conditional random fields (CRFs) are trained within a hierarchical phrase-based translation framework. The hierarchical phrase-based paradigm is used to model the search space in model estimation and search, leaving the hypothesis weighting to CRF features. They constrain search by a beam width for gradient estimation and update the model with the help of LBFGS. In a similar way Lavergne et al. (2011) use the n-gram based approach (Casacuberta and Vidal, 2004; Mari˜no et al., 2006) to model the reordering, phrase alignment, and the language model. A CRF is applied to estimate the phrase weights. Model updates are carried out by the RPROP algorithm (Riedmiller and Braun, 1993). However, both approaches only improve over constrained baselines. Our work is inspired by (He and Deng, 2012; Setiawan and Zhou, 2013), where the authors propose to train the standard phrasal and lexical channel models with the growth transformation (GT) algorithm. They use n-best lists on the training data and optim"
N15-1175,P06-1096,0,0.0900743,"Missing"
N15-1175,J06-4004,0,0.067937,"Missing"
N15-1175,P10-2041,0,0.0520213,"rpora as well as selected parts of the Shuffled News 1 Note that we keep the λ weights fixed throughout all iterations of maximum expected B LEU training. 2 http://www.iwslt2013.org Sentences Run. Words Vocabulary IWSLT German English BOLT Chinese English WMT German English 138K 2.63M 2.70M 75.4K 50.2K 4.08M 78.3M 85.9M 384K 817K 4.09M 105M 104M 659K 649K Table 1: Statistics for the bilingual training data of the IWSLT 2013 German→English, the DARPA BOLT Chinese→English and the WMT 2014 German→English tasks. and LDC English Gigaword corpora. The selection is based on cross-entropy difference (Moore and Lewis, 2010). This makes for a total of 1.7 billion running words for LM training. The baseline further contains a hierarchical reordering model (HRM) (Galley and Manning, 2008) and a 7-gram word class language model (Wuebker et al., 2013). On IWSLT, all results are averages over three independent MERT runs, and we evaluate statistical significance with MultEval (Clark et al., 2011). To confirm our findings, additional experiments are run on two large-scale tasks over strong baselines including recurrent neural language models. On the DARPA BOLT Chinese→English task we use our internal evaluation system a"
N15-1175,J04-4002,1,0.470015,"paradigm and we will present results on a standard phrase-based translation system (Koehn et al., 2003) and a hierarchical phrase-based translation system (Chiang, 2005). The translation process is implemented as a weighted log-linear combination of several models hm,Θ (E, F ), where E = e1 , . . . , eI denotes the translation hypothesis, F = f1 , . . . , fJ the source sentence, m a model index, and Θ the model parameters. These models include the phrase translation and lexical smoothing scores in both directions, language model (LM) score, distortion penalty, word penalty and phrase penalty (Och and Ney, 2004). Given a source sentence F , the models hm,Θ (E, F ) and the corresponding loglinear feature weights λm , the translation decoder ˆ searches for the best scoring translation E: ˆ = arg max {fΘ (E, F )} E E X fΘ (E, F ) = λm hm,Θ (E, F ) (1) (2) m∈M plied and for simplicity, in the following we will assume the particular derivation for a translation hypothesis to be included in the variable E. The loglinear feature weights are optimized with minimum error rate training (MERT) (Och, 2003). 4 4.1 Update Strategies Previously Proposed Algorithms The Growth Transformation (GT) or Extended Baum-Wel"
N15-1175,P03-1021,0,0.417489,"ur experiments also prove that leave-one-out impacts translation quality. This paper is organized as follows. We review related work in Section 2 and present the translation system in Section 3. In Section 4 we describe the different discriminative update strategies applied in this work and Section 5 derives the complete maximum expected B LEU training algorithm. Finally, experimental results are given in Section 6 and we conclude with Section 7. 2 Related Work Discriminative training is one of the most active research areas in SMT and it can be integrated into the pipeline at various stages. Och (2003) proposed to apply minimum error rate training (MERT) to optimize the different feature weights in the log-linear model combination on a small development data set. This is still considered to be the state of the art, but is only capable of optimizing a handful of features. More recently, MIRA (Watanabe et al., 2007; Chiang et al., 2008) and PRO (Hopkins and May, 2011) have been presented as optimization procedures that can replace MERT and scale to thousands of parameters. In a different line of work, Liang et al. (2006) describe a fully discriminative training pipeline, where more than one m"
N15-1175,P02-1040,0,0.0967528,"Missing"
N15-1175,N13-1034,0,0.194761,"exible and efficient discriminative training approach for statistical machine translation. We propose to use the RPROP algorithm for optimizing a maximum expected B LEU objective and experimentally compare it to several other updating schemes. It proves to be more efficient and effective than the previously proposed growth transformation technique and also yields better results than stochastic gradient descent and AdaGrad. We also report strong empirical results on two large scale tasks, namely BOLT Chinese→English and WMT German→English, where our final systems outperform results reported by Setiawan and Zhou (2013) and on matrix.statmt.org. On the WMT task, discriminative training is performed on the full training data of 4M sentence pairs, which is unsurpassed in the literature. 1 Introduction The main advantage of learning parameters in a discriminative fashion is the possibility to directly optimize towards a quality or error measure on the task that is being performed. This stands in contrast to the generative approach, where parameters are chosen to maximize likelihood under a generative story, which often bears little correspondence with the actual application of the model. In statistical machine"
N15-1175,P12-1002,0,0.078287,"ate a much larger number of features due to its renormalization component. On the IWSLT data, RPROP is 6.4 times faster than GT and requires a third of the memory. 3. On the WMT German→English task, we perform discriminative training on 4M sentence 1516 Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 1516–1526, c Denver, Colorado, May 31 – June 5, 2015. 2015 Association for Computational Linguistics pairs, which, to the best of our knowledge, is 2.4 times the size of the largest training set reported in previous work (1.66M sentences in (Simianer et al., 2012)). This proves the scalability of our approach. 4. On two large scale tasks our experiments show good improvements over strong baselines which include recurrent language modeling components. On the Chinese→English DARPA BOLT task, we achieve nearly twice the improvement reported in (Setiawan and Zhou, 2013) on the same test sets which results in a superior final system. Finally, the best single system reported on matrix.statmt.org is outperformed by 0.8 B LEU points on the WMT German→English newstest2013 set. Our experiments also prove that leave-one-out impacts translation quality. This paper"
N15-1175,W10-1738,1,0.892163,"Missing"
N15-1175,D07-1080,0,0.0269347,"ves the complete maximum expected B LEU training algorithm. Finally, experimental results are given in Section 6 and we conclude with Section 7. 2 Related Work Discriminative training is one of the most active research areas in SMT and it can be integrated into the pipeline at various stages. Och (2003) proposed to apply minimum error rate training (MERT) to optimize the different feature weights in the log-linear model combination on a small development data set. This is still considered to be the state of the art, but is only capable of optimizing a handful of features. More recently, MIRA (Watanabe et al., 2007; Chiang et al., 2008) and PRO (Hopkins and May, 2011) have been presented as optimization procedures that can replace MERT and scale to thousands of parameters. In a different line of work, Liang et al. (2006) describe a fully discriminative training pipeline, where more than one million features are tuned on the training data using a perceptron-style update algorithm. The Direct Translation Model 2 introduced 1517 by Ittycheriah and Roukos (2007) is similar in that it also trains millions of features on the training data. However, the weights are estimated based on a maximum entropy model an"
N15-1175,P10-1049,1,0.953347,"ted B LEU objective, that provides a clear training criterion, which is missing e.g. in MIRA estimation. Auli et al. (2014) report good results by applying the same objective function to reordering features, which are trained with stochastic gradient descent (SGD). Our work differs in several key aspects: (i) We propose to apply the RPROP algorithm, which yields superior results to GT, SGD and AdaGrad in our experimental comparison. (ii) For the first time, we apply maximum expected B LEU training on a data set as large as four million sentence pairs. (iii) We apply a leave-one-out heuristic (Wuebker et al., 2010) to make better use of the training data. (iv) We apply phrasal, lexical, reordering and triplet features. (v) Finally, we do not run MERT after each training iteration, which is expensive for large translation systems. 3 Statistical Translation System Our work can be applied to any statistical machine translation paradigm and we will present results on a standard phrase-based translation system (Koehn et al., 2003) and a hierarchical phrase-based translation system (Chiang, 2005). The translation process is implemented as a weighted log-linear combination of several models hm,Θ (E, F ), where"
N15-1175,C12-3061,1,0.935254,"Missing"
N15-1175,D13-1138,1,0.867616,"nglish BOLT Chinese English WMT German English 138K 2.63M 2.70M 75.4K 50.2K 4.08M 78.3M 85.9M 384K 817K 4.09M 105M 104M 659K 649K Table 1: Statistics for the bilingual training data of the IWSLT 2013 German→English, the DARPA BOLT Chinese→English and the WMT 2014 German→English tasks. and LDC English Gigaword corpora. The selection is based on cross-entropy difference (Moore and Lewis, 2010). This makes for a total of 1.7 billion running words for LM training. The baseline further contains a hierarchical reordering model (HRM) (Galley and Manning, 2008) and a 7-gram word class language model (Wuebker et al., 2013). On IWSLT, all results are averages over three independent MERT runs, and we evaluate statistical significance with MultEval (Clark et al., 2011). To confirm our findings, additional experiments are run on two large-scale tasks over strong baselines including recurrent neural language models. On the DARPA BOLT Chinese→English task we use our internal evaluation system as a baseline. It is a powerful hierarchical phrase-based SMT engine with 19 dense features, including an LSTM recurrent neural language model (Sundermeyer et al., 2012) and a hierarchical reordering model (Huck et al., 2013). T"
N15-1175,D13-1112,0,0.0146615,"lection. The training corpus is divided into several shards, on which features are updated via perceptron-style gradient descent. The authors present results showing that training on large data sets improves results over just using a small development corpus. Another approach based on the AdaGrad method that scales to large numbers of sparse features is proposed in (Green et al., 2013; Green et al., 2014). Different from our work, the authors use either the tuning sets or a small subsample of the training data (15k sentences) for discriminative training. A notably different idea is pursued by Yu et al. (2013), who present a large-scale training procedure that explicitly minimizes search errors. This is achieved by force-decoding the training data and updating at the point where the correct derivation drops off the beam. In (Blunsom et al., 2008), conditional random fields (CRFs) are trained within a hierarchical phrase-based translation framework. The hierarchical phrase-based paradigm is used to model the search space in model estimation and search, leaving the hypothesis weighting to CRF features. They constrain search by a beam width for gradient estimation and update the model with the help of"
niessen-etal-2000-evaluation,1993.mtsummit-1.11,0,\N,Missing
niessen-etal-2000-evaluation,P98-2158,0,\N,Missing
niessen-etal-2000-evaluation,C98-2153,0,\N,Missing
niessen-etal-2000-evaluation,P98-1006,0,\N,Missing
niessen-etal-2000-evaluation,C98-1006,0,\N,Missing
P00-1004,W99-0604,1,\N,Missing
P00-1004,niessen-etal-2000-evaluation,1,\N,Missing
P00-1004,C00-2172,0,\N,Missing
P00-1004,C96-1030,0,\N,Missing
P00-1004,P96-1021,0,\N,Missing
P00-1004,P97-1047,0,\N,Missing
P00-1056,ahrenberg-etal-2000-evaluation,0,\N,Missing
P00-1056,C00-2163,1,\N,Missing
P00-1056,J93-2003,0,\N,Missing
P00-1056,H93-1039,0,\N,Missing
P00-1056,C96-2141,1,\N,Missing
P01-1027,J93-2003,0,\N,Missing
P01-1027,C00-2123,1,\N,Missing
P01-1027,E99-1010,1,\N,Missing
P01-1027,J96-1002,0,\N,Missing
P01-1027,P98-2158,0,\N,Missing
P01-1027,C98-2153,0,\N,Missing
P01-1027,W00-0707,0,\N,Missing
P01-1027,P97-1037,1,\N,Missing
P01-1027,H94-1028,0,\N,Missing
P01-1027,P00-1056,1,\N,Missing
P01-1027,P97-1047,0,\N,Missing
P01-1027,P00-1006,0,\N,Missing
P02-1038,J96-1002,0,0.0948631,"observe that comparable results are obtained by using the following decision rule (6) eI1 Here, we replaced pθˆ(f1J |eI1 ) by pθˆ(eI1 |f1J ). From a theoretical framework of the sourcechannel approach, this approach is hard to justify. Yet, if both decision rules yield the same translation quality, we can use that decision rule which is better suited for efficient search. 1.2 Direct Maximum Entropy Translation Model As alternative to the source-channel approach, we directly model the posterior probability P r(eI1 |f1J ). An especially well-founded framework for doing this is maximum entropy (Berger et al., 1996). In this framework, we have a set of M feature functions hm (eI1 , f1J ), m = 1, . . . , M . For each feature function, there exists a model parameter λm , m = 1, . . . , M . The direct translation probability is given Source Language Text  Preprocessing  o λ1 · h1 (eI1 , f1J ) o λ2 · h2 (eI1 , f1J ) Global Search argmax n P M m=1 eI1 o λm hm (eI1 , f1J ) o ...  Postprocessing  Target Language Text Figure 2: Architecture of the translation approach based on direct maximum entropy models. the following two feature functions: by: P r(eI1 |f1J ) = pλM (eI1 |f1J ) 1 PM exp[ m=1 λm hm (eI1 , f"
P02-1038,J93-2003,0,0.0622118,"(1) eI1 The argmax operation denotes the search problem, i.e. the generation of the output sentence in the target language. 1 (2) eI1 Introduction eˆI1 = argmax {P r(eI1 |f1J )} Source-Channel Model The notational convention will be as follows. We use the symbol P r(·) to denote general probability distributions with (nearly) no specific assumptions. In contrast, for model-based probability distributions, we use the generic symbol p(·). This approach is referred to as source-channel approach to statistical MT. Sometimes, it is also referred to as the ‘fundamental equation of statistical MT’ (Brown et al., 1993). Here, P r(eI1 ) is the language model of the target language, whereas P r(f1J |eI1 ) is the translation model. Typically, Eq. 2 is favored over the direct translation model of Eq. 1 with the argument that it yields a modular approach. Instead of modeling one probability distribution, we obtain two different knowledge sources that are trained independently. The overall architecture of the source-channel approach is summarized in Figure 1. In general, as shown in this figure, there may be additional transformations to make the translation task simpler for the algorithm. Typically, training is"
P02-1038,niessen-etal-2000-evaluation,1,0.314719,"ord order of an acceptable sentence can be different from that of the target sentence, so that the WER measure alone could be misleading. To overcome this problem, we introduce as additional measure the position-independent word error rate (PER). This measure compares the words in the two sentences ignoring the word order. • mWER (multi-reference word error rate): For each test sentence, there is not only used a single reference translation, as for the WER, but a whole set of reference translations. For each translation hypothesis, the edit distance to the most similar sentence is calculated (Nießen et al., 2000). • BLEU score: This score measures the precision of unigrams, bigrams, trigrams and fourgrams with respect to a whole set of reference translations with a penalty for too short sentences (Papineni et al., 2001). Unlike all other evaluation criteria used here, BLEU measures accuracy, i.e. the opposite of error rate. Hence, large BLEU scores are better. • SSER (subjective sentence error rate): For a more detailed analysis, subjective judgments by test persons are necessary. Each translated sentence was judged by a human examiner according to an error scale from 0.0 to 1.0 (Nießen et al., 2000)."
P02-1038,W99-0604,1,0.825262,"nd the translation model P r(f1J |eI1 ) = pθ (f1J |eI1 ) depends on parameters θ, then the optimal parameter values are obtained by maximizing the likelihood on a parallel training corpus f S1 , eS1 (Brown et al., 1993): θˆ = argmax θ γˆ = argmax γ S Y s=1 S Y s=1 pθ (fs |es ) (3) pγ (es ) (4) Source Language Text  Preprocessing  o P r(eI1 ): Language Model Global Search eˆI1 = argmax {P r(eI1 ) · P r(f1J |eI1 )} eI1 o P r(f1J |eI1 ): Translation Model  Postprocessing  Target Language Text Figure 1: Architecture of the translation approach based on source-channel models. instead of Eq. 5 (Och et al., 1999): We obtain the following decision rule: eˆI1 = argmax{pγˆ (eI1 ) · pθˆ(f1J |eI1 )} (5) eˆI1 = argmax{pγˆ (eI1 ) · pθˆ(eI1 |f1J )} eI1 State-of-the-art statistical MT systems are based on this approach. Yet, the use of this decision rule has various problems: 1. The combination of the language model pγˆ (eI1 ) and the translation model pθˆ(f1J |eI1 ) as shown in Eq. 5 can only be shown to be optimal if the true probability distributions pγˆ (eI1 ) = P r(eI1 ) and pθˆ(f1J |eI1 ) = P r(f1J |eI1 ) are used. Yet, we know that the used models and training methods provide only poor approximations of"
P02-1038,2001.mtsummit-papers.68,0,0.0600561,"on-independent word error rate (PER). This measure compares the words in the two sentences ignoring the word order. • mWER (multi-reference word error rate): For each test sentence, there is not only used a single reference translation, as for the WER, but a whole set of reference translations. For each translation hypothesis, the edit distance to the most similar sentence is calculated (Nießen et al., 2000). • BLEU score: This score measures the precision of unigrams, bigrams, trigrams and fourgrams with respect to a whole set of reference translations with a penalty for too short sentences (Papineni et al., 2001). Unlike all other evaluation criteria used here, BLEU measures accuracy, i.e. the opposite of error rate. Hence, large BLEU scores are better. • SSER (subjective sentence error rate): For a more detailed analysis, subjective judgments by test persons are necessary. Each translated sentence was judged by a human examiner according to an error scale from 0.0 to 1.0 (Nießen et al., 2000). • IER (information item error rate): The test sentences are segmented into information items. For each of them, if the intended information is conveyed and there are no syntactic errors, the sentence is counted"
P02-1038,1993.mtsummit-1.11,0,0.0929456,"the problem that no single of the reference translations is part of the nbest list because the search algorithm performs pruning, which in principle limits the possible translations that can be produced given a certain input sentence. To solve this problem, we define for maximum entropy training each sentence as reference translation that has the minimal number of word errors with respect to any of the reference translations. 5 Results We present results on the V ERBMOBIL task, which is a speech translation task in the domain of appointment scheduling, travel planning, and hotel reservation (Wahlster, 1993). Table 1 shows the corpus statistics of this task. We use a training corpus, which is used to train the alignment template model and the language models, a development corpus, which is used to estimate the model scaling factors, and a test corpus. Table 1: Characteristics of training corpus (Train), manual lexicon (Lex), development corpus (Dev), test corpus (Test). Train Lex Dev Test Sentences Words Singletons Vocabulary Entries Ext. Vocab. Sentences Words PP (trigr. LM) Sentences Words PP (trigr. LM) German English 58 073 519 523 549 921 3 453 1 698 7 939 4 672 12 779 11 501 6 867 276 3 159"
P02-1038,C00-2163,1,\N,Missing
P02-1038,P02-1040,0,\N,Missing
P03-1019,J90-2002,0,0.238007,"Missing"
P03-1019,J99-4005,0,0.130616,"Missing"
P03-1019,niessen-etal-2000-evaluation,1,0.15214,"m number of substitution, insertion and deletion operations that have to be performed to convert the generated sentence into the target sentence. • PER (position-independent word error rate): A shortcoming of the WER is the fact that it requires a perfect word order. The PER compares the words in the two sentences ignoring the word order. • mWER (multi-reference word error rate): For each test sentence, not only a single reference translation is used, as for the WER, but a whole set of reference translations. For each translation hypothesis, the WER to the most similar sentence is calculated (Nießen et al., 2000). • BLEU score: This score measures the precision of unigrams, bigrams, trigrams and fourgrams with respect to a whole set of reference translations with a penalty for too short sentences (Papineni et al., 2001). BLEU measures accuracy, i.e. large BLEU scores are better. • SSER (subjective sentence error rate): For a more detailed analysis, subjective judgments by test persons are necessary. Each translated sentence was judged by a human examiner according to an error scale from 0.0 to 1.0 (Nießen et al., 2000). 6.2 Translation Results In this section, we will present the translation results f"
P03-1019,P00-1056,1,0.168114,"Missing"
P03-1019,W02-1021,1,0.213289,"ry size of the target language. 3.2 Pruning Although the described search algorithm has a polynomial-time complexity, even with a bigram language model the search space is very large. A full search is possible but time consuming. The situation gets even worse when a trigram language model is used. Therefore, pruning techniques are obligatory to reduce the translation time. Pruning is applied to hypotheses that translate the same subsequence fjjlr of the source sentence. We Generation of Word Graphs The generation of word graphs for a bottom-top search with the IBM constraints is described in (Ueffing et al., 2002). These methods cannot be applied to the CYK-style search for the ITG constraints. Here, the idea for the generation of word graphs is the following: assuming we already have jr word graphs for the source sequences fjkl and fk+1 , then we can construct a word graph for the sequence fjjlr by concatenating the partial word graphs either in monotone or inverted order. Now, we describe this idea in a more formal way. A word graph is a directed acyclic graph (dag) with one start and one end node. The edges are annotated with target language words or phrases. We also allow -transitions. These are e"
P03-1019,P02-1038,1,0.0852491,"s Statistics In the following sections we will present results on two tasks. Therefore, in this section we will show the corpus statistics for each of these tasks. 4.1 Verbmobil The first task we will present results on is the Verbmobil task (Wahlster, 2000). The domain of this corpus is appointment scheduling, travel planning, and hotel reservation. It consists of transcriptions of spontaneous speech. Table 2 shows the corpus statistics of this corpus. The training corpus (Train) was used to train the IBM model parameters. The remaining free parameters, i.e. pm and the model scaling factors (Och and Ney, 2002), were adjusted on the development corpus (Dev). The resulting system was evaluated on the test corpus (Test). 3.4 Extended ITG constraints In this section, we will extend the ITG constraints described in Sec. 2.1. This extension will go beyond basic reordering constraints. We already mentioned that the use of consecutive phrases within the ITG approach is straightforward. The only thing we have to change is the initialization of the Q-table. Now, we will extend this idea to phrases that are non-consecutive in the source language. For this purpose, we adopt the view of the ITG constraints as a"
P03-1019,2001.mtsummit-papers.68,0,0.0144805,"the WER is the fact that it requires a perfect word order. The PER compares the words in the two sentences ignoring the word order. • mWER (multi-reference word error rate): For each test sentence, not only a single reference translation is used, as for the WER, but a whole set of reference translations. For each translation hypothesis, the WER to the most similar sentence is calculated (Nießen et al., 2000). • BLEU score: This score measures the precision of unigrams, bigrams, trigrams and fourgrams with respect to a whole set of reference translations with a penalty for too short sentences (Papineni et al., 2001). BLEU measures accuracy, i.e. large BLEU scores are better. • SSER (subjective sentence error rate): For a more detailed analysis, subjective judgments by test persons are necessary. Each translated sentence was judged by a human examiner according to an error scale from 0.0 to 1.0 (Nießen et al., 2000). 6.2 Translation Results In this section, we will present the translation results for both the IBM constraints and the baseline ITG constraints. We used a single-word based search with IBM Model 4. The initialization for the ITG constraints was done with monotone IBM Model 4 translations. So,"
P03-1019,P96-1021,0,0.389257,"possible to translate this verb-group correctly, because the distance between the two parts is too large (more than four words). As we see in the second example, in German the verb of a subordinate clause is placed at the end (“¨ubernachten”). The IBM search is not able to perform the necessary long-range reordering, as it is done with the ITG search. 7 Related Work The ITG constraints were introduced in (Wu, 1995). The applications were, for instance, the segmentation of Chinese character sequences into Chinese “words” and the bracketing of the source sentence into sub-sentential chunks. In (Wu, 1996) the baseline ITG constraints were used for statistical machine translation. The resulting algorithm is similar to the one presented in Sect. 3.1, but here, we use monotone translation hypotheses of the full IBM Model 4 as initialization, whereas in (Wu, 1996) a single-word based lexicon model is used. In (Vilar, 1998) a model similar to Wu’s method was considered. 8 Conclusions We have described the ITG constraints in detail and compared them to the IBM constraints. We draw the following conclusions: especially for long sentences the ITG constraints allow for higher flexibility in word-reorde"
P03-1019,J97-3002,0,0.935426,"is method. A permutation derived by the above method can be represented as a binary tree where the inner nodes are colored either black or white. At black nodes the resulting sequences of the children are inverted. At white nodes they are kept in monotone order. This representation is equivalent to without inversion with inversion target positions 1999). Therefore, we have to restrict the possible reorderings in some way to make the search problem feasible. Here, we will discuss two such constraints in detail. The first constraints are based on inversion transduction grammars (ITG) (Wu, 1995; Wu, 1997). In the following, we will call these the ITG constraints. The second constraints are the IBM constraints (Berger et al., 1996). In the next section, we will describe these constraints from a theoretical point of view. Then, we will describe the resulting search algorithm and its extension for word graph generation. Afterwards, we will analyze the Viterbi alignments produced during the training of the alignment models. Then, we will compare the translation results when restricting the search to either of these constraints. source positions Figure 1: Illustration of monotone and inverted conca"
P03-1019,P02-1040,0,\N,Missing
P04-1065,P03-1006,0,0.0687709,"toolkit to rapidly build a fast and accurate statistical machine translation system. Future extensibility of the toolkit is ensured as it will be publically available as open source software. 1 Introduction Finite-state automata (FSA) methods proved to elegantly solve many difficult problems in the field of natural language processing. Among the most recent ones are full and lazy compilation of the search network for speech recognition (Mohri et al., 2000a), integrated speech translation (Vidal, 1997; Bangalore and Riccardi, 2000), speech summarization (Hori et al., 2003), language modelling (Allauzen et al., 2003) and parameter estimation through EM (Eisner, 2001) to mention only a few. From this list of different applications it is clear that there is a high demand for generic tools to create and manipulate FSAs. In the past, a number of toolkits have been published, all with different design principles. Here, we give a short overview of toolkits that offer an almost complete set of algorithms: • The FSM LibraryTM from AT&T (Mohri et al., 2000b) is judged the most efficient implementation, offers various semirings, ondemand computation and many algorithms, but is available only in binary form with a p"
P04-1065,W00-0508,0,0.444859,"mand-line tool for interactive manipulation of FSAs. Furthermore, we show how to utilize the toolkit to rapidly build a fast and accurate statistical machine translation system. Future extensibility of the toolkit is ensured as it will be publically available as open source software. 1 Introduction Finite-state automata (FSA) methods proved to elegantly solve many difficult problems in the field of natural language processing. Among the most recent ones are full and lazy compilation of the search network for speech recognition (Mohri et al., 2000a), integrated speech translation (Vidal, 1997; Bangalore and Riccardi, 2000), speech summarization (Hori et al., 2003), language modelling (Allauzen et al., 2003) and parameter estimation through EM (Eisner, 2001) to mention only a few. From this list of different applications it is clear that there is a high demand for generic tools to create and manipulate FSAs. In the past, a number of toolkits have been published, all with different design principles. Here, we give a short overview of toolkits that offer an almost complete set of algorithms: • The FSM LibraryTM from AT&T (Mohri et al., 2000b) is judged the most efficient implementation, offers various semirings, o"
P04-1065,P00-1056,1,0.487093,"ests to solve the translation problem by estimating a language model on a bilanguage (see also (Bangalore and Riccardi, 2000; Casacuberta et al., 2001)). An example of sentences from this bilanguage is given in Figure 5 for the translation task Vermobil (German → English). For technical reasons, -labels are represented by a $ symbol. Note, that due to the fixed segmentation given by the alignments, phrases in the target language are moved to the last source word of an alignment block. So, given an appropriate alignment which can be obtained by means of the pubically available GIZA++ toolkit (Och and Ney, 2000), the approach is very easy in practice: 1. Transform the training corpus with a given alignment into the corresponding bilingual corpus 2. Train a language model on the bilingual corpus 3. Build an acceptor A from the language model The symbols of the resulting acceptor are still a mixture of words from the source language and phrases from the target language. So, we additionally use two simple transducers to split these bilingual words (C1 maps source words fj to bilingual words that start with fj and C2 maps bilingual words with the target sequence epj to the sequences of target words the p"
P04-1065,2002.tmi-tutorials.2,0,0.0369463,"Italian → English 27.0 21.5 37.7 3-5 22 AT 23.7 18.1 36.0 Verbmobil FSA German → English 48.3 41.6 69.8 65-90 460 AT 40.5 30.1 62.2 PF-Star FSA Italian → English 39.8 34.1 58.4 12-15 35 AT 36.8 29.1 54.3 e0 = project-output(best(f ◦ T )) Translation results using this approach are summarized in Table 4 and are being compared with results obtained using the alignment template approach (Och and Ney, 2000). Results for both approaches were obtaining using the same training corpus alignments. Detailed task descriptions for Eutrans/FUB and Verbmobil can be found in (Casacuberta et al., 2001) and (Zens et al., 2002) respectively. We use the usual definitions for word error rate (WER), position independent word error rate (PER) and BLEU statistics here. For the simpler tasks Eutrans, FUB and PF-Star, the WER, PER and the inverted BLEU statistics are close for both approaches. On the German-toEnglish Verbmobil task the FSA approach suffers from long distance reorderings (captured through the fixed training corpus segmentation), which is not very surprising. Although we do not have comparable numbers of the memory usage and the translation times for the alignment template approach, resource usage of the fin"
P06-2061,E03-1032,1,0.951737,"two works considered two parallel N -best lists, generated by MT and ASR systems, Introduction A desired feature of computer-assisted translation (CAT) systems is the integration of the human speech into the system, as skilled human translators are faster at dictating than typing the translations (Brown et al., 1994). Additionally, incorporation of a statistical prediction engine, i.e. a statistical interactive machine translation system, to the CAT system is another useful feature. A statistical prediction engine provides the completions to what a human translator types (Foster et al., 1997; Och et al., 2003). Then, one possible procedure for skilled human translators is to provide the oral translation of a given source text and then to post-edit the recognized text. In the post-editing step, a prediction engine helps to decrease the amount of human interaction (Och et al., 2003). 467 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 467–474, c Sydney, July 2006. 2006 Association for Computational Linguistics language model P r(eI1 ), the translation model P r(f1J |eI1 ) and the acoustic model P r(xT1 |eI1 ). Another approach for modeling the posterior probability P r(eI1 |"
P06-2061,P03-1021,0,0.00655466,"the argmax operator which denotes the search, no renormalization is considered in Eq. 3. This approach has been suggested by (Papineni et al., 1997; Papineni et al., 1998) for a natural language understanding task, by (Beyerlein, 1998) for an ASR task, and by (Och and Ney, 2002) for an MT task. This approach is a generalization of Eq. 2. The direct modeling has the advantage that additional models can be easily integrated into the overall system. The model scaling factors λM 1 are trained on a development corpus according to the final recognition quality measured by the word error rate (WER)(Och, 2003). Search The search in the MT and the ASR systems is already very complex, therefore a fully integrated search to combine ASR and MT models will considerably increase the complexity. To reduce the complexity of the search, we perform two independent searches with the MT and the ASR systems, the search result of each system will be represented as a large word graph. We consider MT and ASR word graphs as FSA. Then, we are able to use FSA algorithms to integrate MT and ASR word graphs. The FSA implementation of the search allows us to use standard optimized algorithms, e.g. available from an open"
P06-2061,J93-2003,0,0.0146367,"t an appropriate search method for building a real-time prediction engine. In this paper, we study the incorporation of MT models and ASR models using finite-state automata. We also propose some transducers based on MT models for rescoring the ASR word graphs. 1 Related Work The idea of incorporating ASR and MT models was independently initiated by two groups: researchers at IBM (Brown et al., 1994), and researchers involved in the TransTalk project (Dymetman et al., 1994; Brousseau et al., 1995). In (Brown et al., 1994), the authors proposed a method to integrate the IBM translation model 2 (Brown et al., 1993) with an ASR system. The main idea was to design a language model (LM) to combine the trigram language model probability with the translation probability for each target word. They reported a perplexity reduction, but no recognition results. In the TransTalk project, the authors improved the ASR performance by rescoring the ASR N -best lists with a translation model. They also introduced the idea of a dynamic vocabulary for a speech recognition system where translation models were generated for each source language sentence. The better performing of the two is the N -best rescoring. Recently,"
P06-2061,1997.mtsummit-papers.1,0,0.0577533,"est lists. The other two works considered two parallel N -best lists, generated by MT and ASR systems, Introduction A desired feature of computer-assisted translation (CAT) systems is the integration of the human speech into the system, as skilled human translators are faster at dictating than typing the translations (Brown et al., 1994). Additionally, incorporation of a statistical prediction engine, i.e. a statistical interactive machine translation system, to the CAT system is another useful feature. A statistical prediction engine provides the completions to what a human translator types (Foster et al., 1997; Och et al., 2003). Then, one possible procedure for skilled human translators is to provide the oral translation of a given source text and then to post-edit the recognized text. In the post-editing step, a prediction engine helps to decrease the amount of human interaction (Och et al., 2003). 467 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 467–474, c Sydney, July 2006. 2006 Association for Computational Linguistics language model P r(eI1 ), the translation model P r(f1J |eI1 ) and the acoustic model P r(xT1 |eI1 ). Another approach for modeling the posterior pr"
P06-2061,P04-1065,1,0.797963,"ch in the MT and the ASR systems is already very complex, therefore a fully integrated search to combine ASR and MT models will considerably increase the complexity. To reduce the complexity of the search, we perform two independent searches with the MT and the ASR systems, the search result of each system will be represented as a large word graph. We consider MT and ASR word graphs as FSA. Then, we are able to use FSA algorithms to integrate MT and ASR word graphs. The FSA implementation of the search allows us to use standard optimized algorithms, e.g. available from an open source toolkit (Kanthak and Ney, 2004). The recognition process is performed in two steps. First, the baseline ASR system generates a word graph in the FSA format for a given utterance xT1 . Second, the translation models rescore each word graph based on the corresponding source language sentence. For each utterance, the decision about the best sentence is made according to the recognition and the translation models. Speech-Enabled CAT Models In a speech-enabled computer-assisted translation system, we are given a source language sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language sentence eI1 ="
P06-2061,W05-0831,1,0.839149,"icon entry: the input label is a target word e, the output label is a source word f , and the weight is − log p(f |e). The null-emitter transducer, as its name states, emits the null word with a pre-defined probability after each input word. The fertility transducer is also a simple transducer to map zero or several 1. a linear acceptor, i.e. a sequence of nodes with one incoming arc and one outgoing arc, the words of source language text are placed consecutively in the arcs of the acceptor, 2. an acceptor containing possible permutations. To limit the permutations, we used an approach as in (Kanthak et al., 2005). Each of these two acceptors results in different constraints for the generation of the hypotheses. The first acceptor restricts the system to generate exactly the same source language sentence, while the second acceptor forces the system to generate the hypotheses that are a reordered variant of the source language sentence. The experiments conducted do not show any significant difference in the recognition results among the two source language acceptors, except that the second acceptor is much slower than the first acceptor. Therefore, we use the first model in our experiments. Table 4 show"
P06-2061,C96-2141,1,0.674347,"Missing"
P06-2061,N04-1033,1,0.892863,"Missing"
P06-2061,knight-al-onaizan-1998-translation,0,0.021181,"ways: 4.7 Fertility-Based Transducer In (Brown et al., 1993), three alignment models are described that include fertility models, these are IBM Models 3, 4, and 5. The fertility-based alignment models have a more complicated structure than the simple IBM Model 1. The fertility model estimates the probability distribution for aligning multiple source words to a single target word. The fertility model provides the probabilities p(φ|e) for aligning a target word e to φ source words. In this section, we propose a method for rescoring ASR word graphs based on the lexicon and fertility models. In (Knight and Al-Onaizan, 1998), some transducers are described to build a finite-state based translation system. We use the same transducers for rescoring ASR word graphs. Here, we have three transducers: lexicon, null-emitter, and fertility. The lexicon transducer is formed by one node and a number of self loops for each target language word, similar to IBM Model 1 transducer in Section 4.5. On each arc of the lexicon transducer, there is a lexicon entry: the input label is a target word e, the output label is a source word f , and the weight is − log p(f |e). The null-emitter transducer, as its name states, emits the nul"
P06-2061,2005.iwslt-1.20,1,0.88101,"Missing"
P06-2061,P02-1038,1,0.457971,"Each of the terms hm (eI1 , f1J , xT1 ) denotes one of the various models which are involved in the recognition procedure. Each individual model is weighted by its scaling factor λm . As there is no direct dependence between f1J and xT1 , the hm (eI1 , f1J , xT1 ) is in one of these two forms: hm (eI1 , xT1 ) and hm (eI1 , f1J ). Due to the argmax operator which denotes the search, no renormalization is considered in Eq. 3. This approach has been suggested by (Papineni et al., 1997; Papineni et al., 1998) for a natural language understanding task, by (Beyerlein, 1998) for an ASR task, and by (Och and Ney, 2002) for an MT task. This approach is a generalization of Eq. 2. The direct modeling has the advantage that additional models can be easily integrated into the overall system. The model scaling factors λM 1 are trained on a development corpus according to the final recognition quality measured by the word error rate (WER)(Och, 2003). Search The search in the MT and the ASR systems is already very complex, therefore a fully integrated search to combine ASR and MT models will considerably increase the complexity. To reduce the complexity of the search, we perform two independent searches with the MT"
P06-2061,C04-1030,1,\N,Missing
P07-2026,J90-2002,0,0.620324,"if eI1 = else 0 e0 I1 Hence, the MAP decision rule is optimal for the sentence or string error rate. It is not necessarily optimal for other evaluation metrics as for example the BLEU score. One reason for the popularity of the MAP decision rule might be that, compared to the MBR rule, its computation is simpler. 3.2 Baseline System The posterior probability P r(eI1 |f1J ) is modeled directly using a log-linear combination of several models (Och and Ney, 2002): ˆ = BP(I, I)  1 ˆ exp (1 − I/I) P ˆ Precn (eI1 , eˆI1 ) = w1n 0 (1) This approach is a generalization of the sourcechannel approach (Brown et al., 1990). It has the advantage that additional models h(·) can be easily integrated into the overall system. The denominator represents a normalization factor that depends only on the source sentence f1J . Therefore, we can omit it in case of the MAP decision rule during the search process. Note that the denominator affects the results of the MBR decision rule and, thus, cannot be omitted in that case. We use a state-of-the-art phrase-based translation system similar to (Matusov et al., 2006) including the following models: an n-gram language model, a phrase translation model and a word-based lexicon"
P07-2026,N04-1022,0,0.099366,"ike the BLEU and NIST score that measure precision and fluency of a given translation hypothesis. 101 The remaining part of this paper is structured as follows: after a short overview of related work in Sec. 2, we describe the MBR decoder in Sec. 3. We present the experimental results in Sec. 4 and conclude in Sec. 5. 2 Related Work MBR decoder for automatic speech recognition (ASR) have been reported to yield improvement over the widely used maximum a-posteriori probability (MAP) decoder (Goel and Byrne, 2003; Mangu et al., 2000; Stolcke et al., 1997). For MT, MBR decoding was introduced in (Kumar and Byrne, 2004). It was shown that MBR is preferable over MAP decoding for different evaluation criteria. Here, we focus on the performance of MBR decoding for the BLEU score on various translation tasks. 3 Implementation of Minimum Bayes Risk Decoding for the BLEU Score 3.1 Bayes Decision Rule In statistical machine translation, we are given a source language sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language sentence eI1 = e1 . . . ei . . . eI . Statistical decision theory tells us that among all possible target language sentences, we should choose the sentence which min"
P07-2026,P02-1038,1,0.615861,"penalty BP(·, ·) for too short translation hypotheses. ˆ ˆ · BLEU(eI1 , eˆI1 ) = BP(I, I) 4 Y ˆ Precn (eI1 , eˆI1 )1/4 n=1 I0 L0−1 (eI1 , e0 1 ) =  1 0 if eI1 = else 0 e0 I1 Hence, the MAP decision rule is optimal for the sentence or string error rate. It is not necessarily optimal for other evaluation metrics as for example the BLEU score. One reason for the popularity of the MAP decision rule might be that, compared to the MBR rule, its computation is simpler. 3.2 Baseline System The posterior probability P r(eI1 |f1J ) is modeled directly using a log-linear combination of several models (Och and Ney, 2002): ˆ = BP(I, I)  1 ˆ exp (1 − I/I) P ˆ Precn (eI1 , eˆI1 ) = w1n 0 (1) This approach is a generalization of the sourcechannel approach (Brown et al., 1990). It has the advantage that additional models h(·) can be easily integrated into the overall system. The denominator represents a normalization factor that depends only on the source sentence f1J . Therefore, we can omit it in case of the MAP decision rule during the search process. Note that the denominator affects the results of the MBR decision rule and, thus, cannot be omitted in that case. We use a state-of-the-art phrase-based translat"
P07-2026,P03-1021,0,0.119728,"rule during the search process. Note that the denominator affects the results of the MBR decision rule and, thus, cannot be omitted in that case. We use a state-of-the-art phrase-based translation system similar to (Matusov et al., 2006) including the following models: an n-gram language model, a phrase translation model and a word-based lexicon model. The latter two models are used for both directions: p(f |e) and p(e|f ). Additionally, we use a word penalty, phrase penalty and a distortion penalty. The model scaling factors λM 1 are optimized with respect to the BLEU score as described in (Och, 2003). 102 P C(w1n |eI1 ) Here, C(w1n |eI1 ) denotes the number of occurrences of an n-gram w1n in a sentence eI1 . The denominator of the n-gram precisions evaluate to the number of n-grams in the hypothesis, i.e. I − n + 1. As loss function for the MBR decoder, we use: ˆ I 0 ,e0 I1 ˆ min{C(w1n |eI1 ), C(w1n |ˆ eI1 )} w1n ˆ L[eI1 , eˆI1 ] = 1 − BLEU(eI1 , eˆI1 ) . P  M I, fJ) exp λ h (e m=1 m m 1 1 P  P r(eI1 |f1J ) = P M 0I0 , f J ) exp λ h (e m m 1 1 m=1 if Iˆ ≥ I if Iˆ &lt; I While the original BLEU score was intended to be used only for aggregate counts over a whole test set, we use the BLEU"
P07-2026,P02-1040,0,0.0787877,"e will call this decision rule the MBR rule (Kumar and Byrne, 2004). Proceedings of the ACL 2007 Demo and Poster Sessions, pages 101–104, c Prague, June 2007. 2007 Association for Computational Linguistics Although it is well known that this decision rule is optimal, most SMT systems do not use it. The most common approach is to use the MAP decision rule. Thus, we select the hypothesis which maximizes the posterior probability P r(eI1 |f1J ): n o ˆ eˆI1 = argmax P r(eI1 |f1J ) I,eI1 This decision rule is equivalent to the MBR criterion under a 0-1 loss function: 3.3 BLEU Score The BLEU score (Papineni et al., 2002) measures the agreement between a hypothesis eI1 generated by ˆ the MT system and a reference translation eˆI1 . It is the geometric mean of n-gram precisions Precn (·, ·) in combination with a brevity penalty BP(·, ·) for too short translation hypotheses. ˆ ˆ · BLEU(eI1 , eˆI1 ) = BP(I, I) 4 Y ˆ Precn (eI1 , eˆI1 )1/4 n=1 I0 L0−1 (eI1 , e0 1 ) =  1 0 if eI1 = else 0 e0 I1 Hence, the MAP decision rule is optimal for the sentence or string error rate. It is not necessarily optimal for other evaluation metrics as for example the BLEU score. One reason for the popularity of the MAP decision rule"
P10-1049,W99-0604,1,\N,Missing
P10-1049,J93-2003,0,\N,Missing
P10-1049,W02-1021,1,\N,Missing
P10-1049,P02-1040,0,\N,Missing
P10-1049,D08-1033,0,\N,Missing
P10-1049,J04-4002,1,\N,Missing
P10-1049,W06-3123,0,\N,Missing
P10-1049,2006.amta-papers.2,0,\N,Missing
P10-1049,P06-1096,0,\N,Missing
P10-1049,W06-3105,0,\N,Missing
P10-1049,P07-2026,1,\N,Missing
P10-1049,N03-1017,0,\N,Missing
P10-1049,J03-1002,1,\N,Missing
P10-1049,D08-1065,0,\N,Missing
P10-1049,P08-1024,0,\N,Missing
P10-1049,P08-2007,0,\N,Missing
P10-1049,2008.iwslt-evaluation.10,0,\N,Missing
P12-1017,W99-0906,0,\N,Missing
P12-1017,P02-1040,0,\N,Missing
P12-1017,P10-1107,0,\N,Missing
P12-1017,W02-0902,0,\N,Missing
P12-1017,P11-1002,0,\N,Missing
P12-1017,P03-1006,0,\N,Missing
P12-1017,P08-1088,0,\N,Missing
P12-1017,D08-1085,0,\N,Missing
P12-2006,2006.iwslt-papers.6,0,0.0588331,"Missing"
P12-2006,W11-2123,0,0.0949861,"Missing"
P12-2006,N03-1017,0,0.0610843,"Missing"
P12-2006,P07-2045,1,0.0181414,"Missing"
P12-2006,2007.mtsummit-papers.43,0,0.0352097,"Missing"
P12-2006,W06-3109,0,0.267098,"Missing"
P12-2006,P02-1040,0,0.0844948,"Missing"
P12-2006,2006.amta-papers.25,0,0.151541,"Missing"
P12-2006,2008.iwslt-papers.8,1,0.94228,"Missing"
P13-1032,W99-0604,1,\N,Missing
P13-1032,J99-4005,0,\N,Missing
P13-1032,D08-1089,0,\N,Missing
P13-1032,P02-1040,0,\N,Missing
P13-1032,P07-2045,0,\N,Missing
P13-1032,P08-1009,0,\N,Missing
P13-1032,J06-4004,0,\N,Missing
P13-1032,N03-1017,0,\N,Missing
P13-1032,P02-1038,1,\N,Missing
P13-1032,W06-3108,1,\N,Missing
P13-1032,W04-3250,0,\N,Missing
P13-1032,D07-1077,0,\N,Missing
P13-1032,C12-1053,1,\N,Missing
P13-1032,N04-1021,0,\N,Missing
P13-1032,P10-1052,0,\N,Missing
P13-1060,W99-0906,0,\N,Missing
P13-1060,D12-1025,0,\N,Missing
P13-1060,P11-1002,0,\N,Missing
P13-1060,P06-2065,0,\N,Missing
P13-1060,P12-1017,1,\N,Missing
P13-1060,P10-1106,0,\N,Missing
P13-1060,D08-1085,0,\N,Missing
P13-1154,steinberger-etal-2006-jrc,0,\N,Missing
P13-1154,D12-1025,0,\N,Missing
P13-1154,P10-1106,0,\N,Missing
P13-1154,P11-1002,0,\N,Missing
P13-1154,D08-1085,0,\N,Missing
P13-1154,P11-1025,0,\N,Missing
P13-1154,P12-1017,1,\N,Missing
P14-2123,P13-1036,0,\N,Missing
P14-2123,P11-1002,0,\N,Missing
P14-2123,P06-2065,0,\N,Missing
P14-2123,P12-1017,1,\N,Missing
P14-2123,P10-1106,0,\N,Missing
P14-2123,D08-1085,0,\N,Missing
P14-2123,P13-1154,1,\N,Missing
P16-2048,P11-2031,0,0.0315998,"i et al., 2015). We therefore decided to only work in reranking for repeated experimentation. Experiments Setup Experiments are conducted on the IWSLT 2013 German→English, WMT 2015 German→English and DARPA BOLT Chinese→English translation tasks. GIZA++ (Och and Ney, 2003) is applied for aligning the parallel corpus. The translation quality is evaluated by case-insensitive B LEU (Papineni et al., 2002) and T ER (Snover et al., 2006) metric. The scaling factors are tuned with MERT (Och, 2003) with B LEU as optimization criterion on the development sets. The systems are evaluated using MultEval (Clark et al., 2011). In the experiments the maximum size of the n-best lists applied for reranking is 500. For the translation experiments, the averaged scores are presented on the development set from three optimization runs. Experiments are performed using the Jane toolkit (Vilar et al., 2010; Wuebker et al., 2012) with a log-linear framework containing following feature functions: 3.2 Exponentially Decaying Bag-of-Words As shown in Section 2.2, the exponential decay approach is applied to express the distance of contextual words from the current word. Thereby the information of sequence order can be included"
P16-2048,P14-1129,0,0.052825,"Missing"
P16-2048,D08-1089,0,0.0441407,"6 Distance: 5 4 3 3 4 d6 d5 d4 d3 d3 d4 2. Bag-of-words individual decay rate: d = dfish Weights: d6fish d5fish d4fish d3fish d3fish d4fish d ∈ {dfriends , dhad , dbeen , dtalking , dlong , dtime } d6friends d5had d4been d3talking Additionally, a neural network translation model, similar to (Devlin et al., 2014), with following configurations is applied for reranking the n-best lists: • Projection layer size 100 for each word • Two non-linear hidden layers with 1000 and 500 nodes respectively 3. Word individual decay rate: Weights: • Word and phrase penalties • Hierarchical reordering model (Galley and Manning, 2008) 1. Corpus decay rate: d Weights: • 7-gram word class language model (Wuebker et al., 2013) d3long d4time • Short-list size 10000 along with 1000 word classes at the output layer • 5 one-hot input vectors of words 3 3.1 Unless otherwise stated, the investigations on bagof-words input features are based on this neural network model. We also integrated our neural network translation model into the decoder as proposed in (Devlin et al., 2014). The relative improvements provided by integrated decoding and reranking are quite similar, which can also be confirmed by (Alkhouli et al., 2015). We there"
P16-2048,C12-3061,1,0.849273,"the parallel corpus. The translation quality is evaluated by case-insensitive B LEU (Papineni et al., 2002) and T ER (Snover et al., 2006) metric. The scaling factors are tuned with MERT (Och, 2003) with B LEU as optimization criterion on the development sets. The systems are evaluated using MultEval (Clark et al., 2011). In the experiments the maximum size of the n-best lists applied for reranking is 500. For the translation experiments, the averaged scores are presented on the development set from three optimization runs. Experiments are performed using the Jane toolkit (Vilar et al., 2010; Wuebker et al., 2012) with a log-linear framework containing following feature functions: 3.2 Exponentially Decaying Bag-of-Words As shown in Section 2.2, the exponential decay approach is applied to express the distance of contextual words from the current word. Thereby the information of sequence order can be included into bag-of-words models. We demonstrated three different kinds of decay rates for words in the bagof-words input feature, namely the corpus general decay rate, the bag-of-words individual decay rate and the word individual decay rate. Table 1 illustrates the experimental results of the neural netw"
P16-2048,J03-1002,1,0.012343,"herwise stated, the investigations on bagof-words input features are based on this neural network model. We also integrated our neural network translation model into the decoder as proposed in (Devlin et al., 2014). The relative improvements provided by integrated decoding and reranking are quite similar, which can also be confirmed by (Alkhouli et al., 2015). We therefore decided to only work in reranking for repeated experimentation. Experiments Setup Experiments are conducted on the IWSLT 2013 German→English, WMT 2015 German→English and DARPA BOLT Chinese→English translation tasks. GIZA++ (Och and Ney, 2003) is applied for aligning the parallel corpus. The translation quality is evaluated by case-insensitive B LEU (Papineni et al., 2002) and T ER (Snover et al., 2006) metric. The scaling factors are tuned with MERT (Och, 2003) with B LEU as optimization criterion on the development sets. The systems are evaluated using MultEval (Clark et al., 2011). In the experiments the maximum size of the n-best lists applied for reranking is 500. For the translation experiments, the averaged scores are presented on the development set from three optimization runs. Experiments are performed using the Jane tool"
P16-2048,P03-1021,0,0.0679117,"provements provided by integrated decoding and reranking are quite similar, which can also be confirmed by (Alkhouli et al., 2015). We therefore decided to only work in reranking for repeated experimentation. Experiments Setup Experiments are conducted on the IWSLT 2013 German→English, WMT 2015 German→English and DARPA BOLT Chinese→English translation tasks. GIZA++ (Och and Ney, 2003) is applied for aligning the parallel corpus. The translation quality is evaluated by case-insensitive B LEU (Papineni et al., 2002) and T ER (Snover et al., 2006) metric. The scaling factors are tuned with MERT (Och, 2003) with B LEU as optimization criterion on the development sets. The systems are evaluated using MultEval (Clark et al., 2011). In the experiments the maximum size of the n-best lists applied for reranking is 500. For the translation experiments, the averaged scores are presented on the development set from three optimization runs. Experiments are performed using the Jane toolkit (Vilar et al., 2010; Wuebker et al., 2012) with a log-linear framework containing following feature functions: 3.2 Exponentially Decaying Bag-of-Words As shown in Section 2.2, the exponential decay approach is applied t"
P16-2048,D13-1138,1,0.855171,"Missing"
P16-2048,P02-1040,0,0.100842,"neural network translation model into the decoder as proposed in (Devlin et al., 2014). The relative improvements provided by integrated decoding and reranking are quite similar, which can also be confirmed by (Alkhouli et al., 2015). We therefore decided to only work in reranking for repeated experimentation. Experiments Setup Experiments are conducted on the IWSLT 2013 German→English, WMT 2015 German→English and DARPA BOLT Chinese→English translation tasks. GIZA++ (Och and Ney, 2003) is applied for aligning the parallel corpus. The translation quality is evaluated by case-insensitive B LEU (Papineni et al., 2002) and T ER (Snover et al., 2006) metric. The scaling factors are tuned with MERT (Och, 2003) with B LEU as optimization criterion on the development sets. The systems are evaluated using MultEval (Clark et al., 2011). In the experiments the maximum size of the n-best lists applied for reranking is 500. For the translation experiments, the averaged scores are presented on the development set from three optimization runs. Experiments are performed using the Jane toolkit (Vilar et al., 2010; Wuebker et al., 2012) with a log-linear framework containing following feature functions: 3.2 Exponentially"
P16-2048,P06-2093,0,0.0858991,"Missing"
P16-2048,C12-2104,0,0.015952,"sregarding the word order. Bagof-words models are used as additional input features to feed-forward neural networks in addition to the one-hot encoding. Thus, the probability of the feed-forward neural network translation model with an m-word source window can be written as: Neural network models have recently gained much attention in research on statistical machine translation. Several groups have reported strong improvements over state-of-the-art baselines when combining phrase-based translation with feedforward neural network-based models (FFNN) (Schwenk et al., 2006; Vaswani et al., 2013; Schwenk, 2012; Devlin et al., 2014), as well as with recurrent neural network models (RNN) (Sundermeyer et al., 2014). Even in alternative translation systems they showed remarkable performance (Sutskever et al., 2014; Bahdanau et al., 2015). The main drawback of a feed-forward neural network model compared to a recurrent neural network model is that it can only have a limited p(eI1 |f1J ) ≈ I Y i=1 +∆m p(ei |fbbii−∆ , fBoW,i ) m (1) where ∆m = m−1 2 and bi is the index of the single aligned source word to the target word ei . We applied the affiliation technique proposed in (Devlin et al., 2014) for obtai"
P16-2048,2006.amta-papers.25,0,0.0378228,"into the decoder as proposed in (Devlin et al., 2014). The relative improvements provided by integrated decoding and reranking are quite similar, which can also be confirmed by (Alkhouli et al., 2015). We therefore decided to only work in reranking for repeated experimentation. Experiments Setup Experiments are conducted on the IWSLT 2013 German→English, WMT 2015 German→English and DARPA BOLT Chinese→English translation tasks. GIZA++ (Och and Ney, 2003) is applied for aligning the parallel corpus. The translation quality is evaluated by case-insensitive B LEU (Papineni et al., 2002) and T ER (Snover et al., 2006) metric. The scaling factors are tuned with MERT (Och, 2003) with B LEU as optimization criterion on the development sets. The systems are evaluated using MultEval (Clark et al., 2011). In the experiments the maximum size of the n-best lists applied for reranking is 500. For the translation experiments, the averaged scores are presented on the development set from three optimization runs. Experiments are performed using the Jane toolkit (Vilar et al., 2010; Wuebker et al., 2012) with a log-linear framework containing following feature functions: 3.2 Exponentially Decaying Bag-of-Words As shown"
P16-2048,D14-1003,1,0.697109,"forward neural networks in addition to the one-hot encoding. Thus, the probability of the feed-forward neural network translation model with an m-word source window can be written as: Neural network models have recently gained much attention in research on statistical machine translation. Several groups have reported strong improvements over state-of-the-art baselines when combining phrase-based translation with feedforward neural network-based models (FFNN) (Schwenk et al., 2006; Vaswani et al., 2013; Schwenk, 2012; Devlin et al., 2014), as well as with recurrent neural network models (RNN) (Sundermeyer et al., 2014). Even in alternative translation systems they showed remarkable performance (Sutskever et al., 2014; Bahdanau et al., 2015). The main drawback of a feed-forward neural network model compared to a recurrent neural network model is that it can only have a limited p(eI1 |f1J ) ≈ I Y i=1 +∆m p(ei |fbbii−∆ , fBoW,i ) m (1) where ∆m = m−1 2 and bi is the index of the single aligned source word to the target word ei . We applied the affiliation technique proposed in (Devlin et al., 2014) for obtaining the one-to-one align293 Proceedings of the 54th Annual Meeting of the Association for Computational"
P16-2048,D13-1140,0,0.0227704,"he set of its words disregarding the word order. Bagof-words models are used as additional input features to feed-forward neural networks in addition to the one-hot encoding. Thus, the probability of the feed-forward neural network translation model with an m-word source window can be written as: Neural network models have recently gained much attention in research on statistical machine translation. Several groups have reported strong improvements over state-of-the-art baselines when combining phrase-based translation with feedforward neural network-based models (FFNN) (Schwenk et al., 2006; Vaswani et al., 2013; Schwenk, 2012; Devlin et al., 2014), as well as with recurrent neural network models (RNN) (Sundermeyer et al., 2014). Even in alternative translation systems they showed remarkable performance (Sutskever et al., 2014; Bahdanau et al., 2015). The main drawback of a feed-forward neural network model compared to a recurrent neural network model is that it can only have a limited p(eI1 |f1J ) ≈ I Y i=1 +∆m p(ei |fbbii−∆ , fBoW,i ) m (1) where ∆m = m−1 2 and bi is the index of the single aligned source word to the target word ei . We applied the affiliation technique proposed in (Devlin et al.,"
P16-2048,W10-1738,1,0.839952,"pplied for aligning the parallel corpus. The translation quality is evaluated by case-insensitive B LEU (Papineni et al., 2002) and T ER (Snover et al., 2006) metric. The scaling factors are tuned with MERT (Och, 2003) with B LEU as optimization criterion on the development sets. The systems are evaluated using MultEval (Clark et al., 2011). In the experiments the maximum size of the n-best lists applied for reranking is 500. For the translation experiments, the averaged scores are presented on the development set from three optimization runs. Experiments are performed using the Jane toolkit (Vilar et al., 2010; Wuebker et al., 2012) with a log-linear framework containing following feature functions: 3.2 Exponentially Decaying Bag-of-Words As shown in Section 2.2, the exponential decay approach is applied to express the distance of contextual words from the current word. Thereby the information of sequence order can be included into bag-of-words models. We demonstrated three different kinds of decay rates for words in the bagof-words input feature, namely the corpus general decay rate, the bag-of-words individual decay rate and the word individual decay rate. Table 1 illustrates the experimental res"
P16-2048,W15-3034,1,\N,Missing
P17-2020,N10-1083,0,\N,Missing
P17-2020,J93-2003,0,\N,Missing
P17-2020,W16-2206,1,\N,Missing
P17-2020,P06-1009,0,\N,Missing
P18-4022,P17-1138,0,0.047261,"Missing"
P18-4022,E17-3017,0,0.0641631,"Missing"
P18-4022,P16-1008,0,0.0362536,"e downloaded the hypotheses from here.4 The WMT 2017 system hypotheses (lower half) are generated using systems having additional back- translation (bt) data. These hypotheses are downloaded from here.5 nrich et al., 2015). We also use Adam (Kingma and Ba, 2014) in all cases. The learning rate scheduling is also similar. In RETURNN, we use a 6 layer bidirectional encoder, trained with pretraining and label smoothing. It has bidirectional LSTMs in every layer of the encoder, unlike Sockeye, which only has the first layer bidirectional. We use a variant of attention weight / fertility feedback (Tu et al., 2016), which is inverse in our case, to use a multiplication instead of a division, for better numerical stability. Our model was derived from the model presented by (Bahar et al., 2017; Peter et al., 2017) and (Bahdanau et al., 2014). We report the best performing Sockeye model we trained, which has 1 bidirectional and 3 unidirectional encoder layers, 1 pre-attention target recurrent layer, and 1 post-attention decoder layer. We trained with a max sequence length of 75, and used the ‘coverage’ RNN attention type. For Sockeye, the final model is an average of the 4 best runs according to the develo"
P18-4022,W17-4735,1,0.887116,"Missing"
P18-4022,W10-1711,1,\N,Missing
P18-4022,2010.iwslt-evaluation.22,1,\N,Missing
P18-4022,P16-1162,0,\N,Missing
P19-1120,W14-4001,1,0.801777,"2017) and Kocmi and Bojar (2018) use shared vocabularies of BPE tokens to improve the transfer learning, but this requires retraining of the parent model whenever we transfer to a new child language. Multilingual NMT trains a single model with parallel data of various translation directions jointly from scratch (Dong et al., 2015; Johnson et al., 2017; Firat et al., 2016; Gu et al., 2018). Their methods also rely on shared subword vocabularies so it is hard for their model to adapt to a new language. Cross-lingual word embedding is studied for the usages in MT as follows. In phrase-based SMT, Alkhouli et al. (2014) builds translation models with word/phrase embeddings. Kim et al. (2018) uses cross-lingual word embedding as a basic translation model for unsupervised MT and attach other components on top of it. Artetxe et al. (2018c) and Lample et al. (2018a) initialize their unsupervised NMT models with pre-trained crosslingual word embeddings. Qi et al. (2018) do the same initialization for supervised cases, observing only improvements in multilingual setups. Artificial noises for the source sentences are used to counteract word-by-word training data in unsupervised MT (Artetxe et al., 2018c; Lample et"
P19-1120,P17-1042,0,0.0571245,"Missing"
P19-1120,P18-1073,0,0.0242471,"ns a single model with parallel data of various translation directions jointly from scratch (Dong et al., 2015; Johnson et al., 2017; Firat et al., 2016; Gu et al., 2018). Their methods also rely on shared subword vocabularies so it is hard for their model to adapt to a new language. Cross-lingual word embedding is studied for the usages in MT as follows. In phrase-based SMT, Alkhouli et al. (2014) builds translation models with word/phrase embeddings. Kim et al. (2018) uses cross-lingual word embedding as a basic translation model for unsupervised MT and attach other components on top of it. Artetxe et al. (2018c) and Lample et al. (2018a) initialize their unsupervised NMT models with pre-trained crosslingual word embeddings. Qi et al. (2018) do the same initialization for supervised cases, observing only improvements in multilingual setups. Artificial noises for the source sentences are used to counteract word-by-word training data in unsupervised MT (Artetxe et al., 2018c; Lample et al., 2018a; Kim et al., 2018), but in this work, they are used to regularize the NMT. Neubig and Hu (2018) study adapting a multilingual NMT system to a new language. They train for a child language pair with additional"
P19-1120,W17-4715,0,0.047717,"Missing"
P19-1120,D18-1549,0,0.0613492,"Missing"
P19-1120,P15-1166,0,0.084222,"l parameters of the decoder; it is actually better than freezing all but the output layer. 6 Related Work Transfer learning is first introduced for NMT in Zoph et al. (2016), yet with a small RNN architecture and on top frequent words instead of using subword units. Nguyen and Chiang (2017) and Kocmi and Bojar (2018) use shared vocabularies of BPE tokens to improve the transfer learning, but this requires retraining of the parent model whenever we transfer to a new child language. Multilingual NMT trains a single model with parallel data of various translation directions jointly from scratch (Dong et al., 2015; Johnson et al., 2017; Firat et al., 2016; Gu et al., 2018). Their methods also rely on shared subword vocabularies so it is hard for their model to adapt to a new language. Cross-lingual word embedding is studied for the usages in MT as follows. In phrase-based SMT, Alkhouli et al. (2014) builds translation models with word/phrase embeddings. Kim et al. (2018) uses cross-lingual word embedding as a basic translation model for unsupervised MT and attach other components on top of it. Artetxe et al. (2018c) and Lample et al. (2018a) initialize their unsupervised NMT models with pre-trained cro"
P19-1120,2008.iwslt-papers.1,0,0.19856,"Missing"
P19-1120,Q17-1010,0,0.127218,"Missing"
P19-1120,2014.iwslt-evaluation.1,0,0.0343255,"Missing"
P19-1120,P17-1176,0,0.109594,"Missing"
P19-1120,I11-1154,0,0.114386,"Missing"
P19-1120,N16-1101,0,0.113125,"g artificial noises, making it easier for the child model to adapt to. Introduction Despite recent success of neural machine translation (NMT) (Bahdanau et al., 2015; Vaswani et al., 2017), its major improvements and optimizations cannot be easily applied to low-resource language pairs. Basic training procedure of NMT does not function well with only a handful of bilingual data (Koehn and Knowles, 2017), while collecting bilingual resource is arduous for many languages. Multilingual NMT solves the problem of lacking bilingual data by training a shared model along with other related languages (Firat et al., 2016; Johnson et al., 2017). For this to work in practice, however, we need a considerable effort to gather bilingual data over multiple languages and preprocess them jointly before training. This has two critical issues: 1) The languages for training • We generate synthetic data from parallel data of the parent language pair, improving the low-resource transfer where the conventional back-translation (Sennrich et al., 2016b) fails. These techniques give incremental improvements while we keep the transfer unsupervised, i.e. it does not require bilingual information between the transferor and the t"
P19-1120,N18-1032,0,0.0481803,"ing all but the output layer. 6 Related Work Transfer learning is first introduced for NMT in Zoph et al. (2016), yet with a small RNN architecture and on top frequent words instead of using subword units. Nguyen and Chiang (2017) and Kocmi and Bojar (2018) use shared vocabularies of BPE tokens to improve the transfer learning, but this requires retraining of the parent model whenever we transfer to a new child language. Multilingual NMT trains a single model with parallel data of various translation directions jointly from scratch (Dong et al., 2015; Johnson et al., 2017; Firat et al., 2016; Gu et al., 2018). Their methods also rely on shared subword vocabularies so it is hard for their model to adapt to a new language. Cross-lingual word embedding is studied for the usages in MT as follows. In phrase-based SMT, Alkhouli et al. (2014) builds translation models with word/phrase embeddings. Kim et al. (2018) uses cross-lingual word embedding as a basic translation model for unsupervised MT and attach other components on top of it. Artetxe et al. (2018c) and Lample et al. (2018a) initialize their unsupervised NMT models with pre-trained crosslingual word embeddings. Qi et al. (2018) do the same init"
P19-1120,D19-1632,0,0.0383747,"Missing"
P19-1120,E17-3017,0,0.0765755,"Missing"
P19-1120,N16-1162,0,0.0522902,"e information, so it makes sense to freeze those parameters even when the source language is changed. On the contrary, encoder-decoder attention represents the relation between source and target sentences, so it should be redefined for a new source language. The performance deteriorates when freezing feedforward sublayers, since it is directly influenced by the encoder-decoder attention layer. The last row means that we freeze all parameters of the decoder; it is actually better than freezing all but the output layer. 6 Related Work Transfer learning is first introduced for NMT in Zoph et al. (2016), yet with a small RNN architecture and on top frequent words instead of using subword units. Nguyen and Chiang (2017) and Kocmi and Bojar (2018) use shared vocabularies of BPE tokens to improve the transfer learning, but this requires retraining of the parent model whenever we transfer to a new child language. Multilingual NMT trains a single model with parallel data of various translation directions jointly from scratch (Dong et al., 2015; Johnson et al., 2017; Firat et al., 2016; Gu et al., 2018). Their methods also rely on shared subword vocabularies so it is hard for their model to adapt"
P19-1120,Q17-1024,0,0.0833965,"Missing"
P19-1120,D18-1330,0,0.0326094,"Missing"
P19-1120,D18-1101,1,0.938421,"e.g. position of a verb in a clause, structure of an adverb phrase, etc. If the input language is changed, the encoder should adjust itself to unfamiliar word orders. The adaptation gets more difficult for non-related languages. To mitigate this syntactic difference in crosslingual transfer for NMT, we suggest to generalize the parent encoder so that it is not overoptimized to the parent source language. We achieve this by modifying the source side of the parent training data, artificially changing its word orders with random noises (Figure 3). The noise function includes (Hill et al., 2016; Kim et al., 2018): • Inserting a word between original words uniformly with a probability pins at each position, choosing the inserted word uniformly from the top Vins frequent words • Deleting original words uniformly with a probability pdel at each position • Permuting original word positions uniformly within a limited distance dper The noises are injected into every source sentence differently for each epoch. The encoder then sees not only word orders of the parent source language but also other various sentence structures. Since we set limits to the randomness of the noises, the encoder is still able to le"
P19-1120,W18-6325,0,0.31335,"target language is fixed. 3.1 Cross-lingual Word Embedding The biggest challenge of cross-lingual transfer is the vocabulary mismatch. A natural language vocabulary is discrete and unique for each language, while the mapping between two different vocabularies is non-deterministic and arbitrary. Therefore, when we merely replace a source language, the NMT encoder will see totally different input sequences; pre-trained encoder weights do not get along with the source embedding anymore. A popular solution to this is sharing the vocabulary among the languages of concern (Nguyen and Chiang, 2017; Kocmi and Bojar, 2018). This is often implemented with joint learning of subword units (Sennrich et al., 2016c). Despite its effectiveness, it has an intrinsic problem in practice: A parent model must be trained already with a shared vocabulary with child languages. Such a pre-trained parent model can be transferred only to those child languages using the same shared vocabulary. When we adapt to a new language whose words are not included in the shared vocabulary, we should learn a joint subword space again with the new language and retrain the parent model accordingly—very inefficient and not scalable. A shared vo"
P19-1120,W17-3204,0,0.0307102,"a better understanding of NMT transfer. 1 • We alleviate the vocabulary mismatch between parent and child languages via crosslingual word embedding. • We train a more general encoder in the parent training by injecting artificial noises, making it easier for the child model to adapt to. Introduction Despite recent success of neural machine translation (NMT) (Bahdanau et al., 2015; Vaswani et al., 2017), its major improvements and optimizations cannot be easily applied to low-resource language pairs. Basic training procedure of NMT does not function well with only a handful of bilingual data (Koehn and Knowles, 2017), while collecting bilingual resource is arduous for many languages. Multilingual NMT solves the problem of lacking bilingual data by training a shared model along with other related languages (Firat et al., 2016; Johnson et al., 2017). For this to work in practice, however, we need a considerable effort to gather bilingual data over multiple languages and preprocess them jointly before training. This has two critical issues: 1) The languages for training • We generate synthetic data from parallel data of the parent language pair, improving the low-resource transfer where the conventional back"
P19-1120,2015.iwslt-evaluation.11,0,0.0607547,"ion i from its internal state si , which depends on hJ1 , E tgt (ei−1 ), and si−1 . It keeps track of the generated hypothesis up to position i-1 and relates the generation with source representations hJ1 . For shared vocabularies between source and target languages, the target embedding weights can be tied with the source embedding weights, i.e. E src = E tgt . The model is trained on a parallel corpus by optimizing for the cross-entropy loss with the stochastic gradient descent algorithm. Translation is carried out with a beam search. For more details, we refer the reader to Bahdanau et al. (2015) and Vaswani et al. (2017). 3 Transfer Learning for NMT In general, transfer learning is reusing the knowledge from other domains/tasks when facing a new problem (Thrun and Pratt, 2012). It has been of continued interest in machine learning for the past decades, especially when there is not enough training data for the problem at hand. Much attention is given to transfer learning for neural networks, since hidden layers of the network can implicitly learn general representations of data; the knowledge can be readily transferred by copying the hidden layer weights to another network (Caruana, 1"
P19-1120,P14-5010,0,0.00537209,"Missing"
P19-1120,D18-1103,0,0.033532,"ingual word embedding as a basic translation model for unsupervised MT and attach other components on top of it. Artetxe et al. (2018c) and Lample et al. (2018a) initialize their unsupervised NMT models with pre-trained crosslingual word embeddings. Qi et al. (2018) do the same initialization for supervised cases, observing only improvements in multilingual setups. Artificial noises for the source sentences are used to counteract word-by-word training data in unsupervised MT (Artetxe et al., 2018c; Lample et al., 2018a; Kim et al., 2018), but in this work, they are used to regularize the NMT. Neubig and Hu (2018) study adapting a multilingual NMT system to a new language. They train for a child language pair with additional parallel data of its similar language pair. Our synthetic data method does not rely on the relatedness of languages but still shows a good performance. They learn just a separate subword vocabulary for the child language without a further care, which we counteract with cross-lingual word embedding. Sachan and Neubig (2018) show ablation studies on parameter sharing and freezing in one-tomany multilingual setup with shared vocabularies. Our work conduct the similar experiments in th"
P19-1120,I17-2050,0,0.240069,"urce languages, while the target language is fixed. 3.1 Cross-lingual Word Embedding The biggest challenge of cross-lingual transfer is the vocabulary mismatch. A natural language vocabulary is discrete and unique for each language, while the mapping between two different vocabularies is non-deterministic and arbitrary. Therefore, when we merely replace a source language, the NMT encoder will see totally different input sequences; pre-trained encoder weights do not get along with the source embedding anymore. A popular solution to this is sharing the vocabulary among the languages of concern (Nguyen and Chiang, 2017; Kocmi and Bojar, 2018). This is often implemented with joint learning of subword units (Sennrich et al., 2016c). Despite its effectiveness, it has an intrinsic problem in practice: A parent model must be trained already with a shared vocabulary with child languages. Such a pre-trained parent model can be transferred only to those child languages using the same shared vocabulary. When we adapt to a new language whose words are not included in the shared vocabulary, we should learn a joint subword space again with the new language and retrain the parent model accordingly—very inefficient and n"
P19-1120,D18-1039,0,0.0370943,"age. They train for a child language pair with additional parallel data of its similar language pair. Our synthetic data method does not rely on the relatedness of languages but still shows a good performance. They learn just a separate subword vocabulary for the child language without a further care, which we counteract with cross-lingual word embedding. Sachan and Neubig (2018) show ablation studies on parameter sharing and freezing in one-tomany multilingual setup with shared vocabularies. Our work conduct the similar experiments in the transfer learning setting with separate vocabularies. Platanios et al. (2018) augment a multilingual model with language-specific embeddings from which the encoder and decoder parameters are inferred with additional linear transformations. They only mention its potential to transfer to an unseen language without any results on it. Our work focuses on transferring a pre-trained model to a new language without any change in the model architecture but with an explicit guidance for cross-linguality on the word embedding level. Wang et al. (2019) address the vocabulary mismatch in multilingual NMT by using shared embeddings of character n-grams and common semantic concepts."
P19-1120,N18-2084,0,0.120415,"he effect of our techniques in transfer learning setups with five different child source languages: Basque (eu), Slovenian (sl), Belarusian (be), Azerbaijani (az), and Turkish (tr). Target language is fixed to English (en) and we use German→English as the parent language pair. Data: The parent model was trained on parallel data of WMT 2018 news translation task1 and synthetic data released by Sennrich et al. (2016a). For the child language pairs, we used IWSLT 2018 low-resource MT task data (eu-en) (Jan et al., 2018), IWSLT 2014 MT task data (sl-en) (Cettolo et al., 2014), TED talk data from (Qi et al., 2018) (be-en/az-en), and subsampling of WMT 2018 news translation task data (tr-en). Statistics of the parallel corpora are given in Table 1. Note that the child source languages are linguistically far from the parent source. Every training dataset was preprocessed with the Moses tokenizer2 , where the source side was lowercased and the target side was frequent-cased. Transfer learning: All NMT models in our experiments follow the base 6-layer Transformer architecture of Vaswani et al. (2017), except that the source and target embedding weights are not tied. Each source language was encoded with by"
P19-1120,D17-1039,0,0.0611133,"Missing"
P19-1120,W18-6327,0,0.0270526,"word-by-word training data in unsupervised MT (Artetxe et al., 2018c; Lample et al., 2018a; Kim et al., 2018), but in this work, they are used to regularize the NMT. Neubig and Hu (2018) study adapting a multilingual NMT system to a new language. They train for a child language pair with additional parallel data of its similar language pair. Our synthetic data method does not rely on the relatedness of languages but still shows a good performance. They learn just a separate subword vocabulary for the child language without a further care, which we counteract with cross-lingual word embedding. Sachan and Neubig (2018) show ablation studies on parameter sharing and freezing in one-tomany multilingual setup with shared vocabularies. Our work conduct the similar experiments in the transfer learning setting with separate vocabularies. Platanios et al. (2018) augment a multilingual model with language-specific embeddings from which the encoder and decoder parameters are inferred with additional linear transformations. They only mention its potential to transfer to an unseen language without any results on it. Our work focuses on transferring a pre-trained model to a new language without any change in the model"
P19-1120,W18-6426,1,0.874907,"Missing"
P19-1120,W16-2323,0,0.298118,"ss-lingual transfer is the vocabulary mismatch. A natural language vocabulary is discrete and unique for each language, while the mapping between two different vocabularies is non-deterministic and arbitrary. Therefore, when we merely replace a source language, the NMT encoder will see totally different input sequences; pre-trained encoder weights do not get along with the source embedding anymore. A popular solution to this is sharing the vocabulary among the languages of concern (Nguyen and Chiang, 2017; Kocmi and Bojar, 2018). This is often implemented with joint learning of subword units (Sennrich et al., 2016c). Despite its effectiveness, it has an intrinsic problem in practice: A parent model must be trained already with a shared vocabulary with child languages. Such a pre-trained parent model can be transferred only to those child languages using the same shared vocabulary. When we adapt to a new language whose words are not included in the shared vocabulary, we should learn a joint subword space again with the new language and retrain the parent model accordingly—very inefficient and not scalable. A shared vocabulary is also problematic in that it must be divided into language-specific portions"
P19-1120,P16-1009,0,0.675761,"ss-lingual transfer is the vocabulary mismatch. A natural language vocabulary is discrete and unique for each language, while the mapping between two different vocabularies is non-deterministic and arbitrary. Therefore, when we merely replace a source language, the NMT encoder will see totally different input sequences; pre-trained encoder weights do not get along with the source embedding anymore. A popular solution to this is sharing the vocabulary among the languages of concern (Nguyen and Chiang, 2017; Kocmi and Bojar, 2018). This is often implemented with joint learning of subword units (Sennrich et al., 2016c). Despite its effectiveness, it has an intrinsic problem in practice: A parent model must be trained already with a shared vocabulary with child languages. Such a pre-trained parent model can be transferred only to those child languages using the same shared vocabulary. When we adapt to a new language whose words are not included in the shared vocabulary, we should learn a joint subword space again with the new language and retrain the parent model accordingly—very inefficient and not scalable. A shared vocabulary is also problematic in that it must be divided into language-specific portions"
P19-1120,P16-1162,0,0.74092,"ss-lingual transfer is the vocabulary mismatch. A natural language vocabulary is discrete and unique for each language, while the mapping between two different vocabularies is non-deterministic and arbitrary. Therefore, when we merely replace a source language, the NMT encoder will see totally different input sequences; pre-trained encoder weights do not get along with the source embedding anymore. A popular solution to this is sharing the vocabulary among the languages of concern (Nguyen and Chiang, 2017; Kocmi and Bojar, 2018). This is often implemented with joint learning of subword units (Sennrich et al., 2016c). Despite its effectiveness, it has an intrinsic problem in practice: A parent model must be trained already with a shared vocabulary with child languages. Such a pre-trained parent model can be transferred only to those child languages using the same shared vocabulary. When we adapt to a new language whose words are not included in the shared vocabulary, we should learn a joint subword space again with the new language and retrain the parent model accordingly—very inefficient and not scalable. A shared vocabulary is also problematic in that it must be divided into language-specific portions"
P19-1120,N07-1061,0,0.277588,"Missing"
P19-1120,D18-1268,0,0.0610292,"Missing"
P19-1120,D16-1163,0,0.04554,"of the source information, so it makes sense to freeze those parameters even when the source language is changed. On the contrary, encoder-decoder attention represents the relation between source and target sentences, so it should be redefined for a new source language. The performance deteriorates when freezing feedforward sublayers, since it is directly influenced by the encoder-decoder attention layer. The last row means that we freeze all parameters of the decoder; it is actually better than freezing all but the output layer. 6 Related Work Transfer learning is first introduced for NMT in Zoph et al. (2016), yet with a small RNN architecture and on top frequent words instead of using subword units. Nguyen and Chiang (2017) and Kocmi and Bojar (2018) use shared vocabularies of BPE tokens to improve the transfer learning, but this requires retraining of the parent model whenever we transfer to a new child language. Multilingual NMT trains a single model with parallel data of various translation directions jointly from scratch (Dong et al., 2015; Johnson et al., 2017; Firat et al., 2016; Gu et al., 2018). Their methods also rely on shared subword vocabularies so it is hard for their model to adapt"
P19-1120,D18-1399,0,\N,Missing
P97-1037,H94-1028,0,0.380274,"Missing"
P97-1037,J93-2003,0,0.0588627,"Missing"
P97-1037,W93-0301,0,0.126761,"Missing"
P97-1037,C94-2178,0,0.0465429,"Missing"
P97-1037,C96-2141,1,0.821772,"issue in modeling the string translation probability Pr(f(le I) is the question of how we define the correspondence between the words of the target sentence and the words of the source sentence. In typical cases, we can assume a sort of pairwise dependence by considering all word pairs (fj,ei) for a given sentence pair [f(; el]. We further constrain this model by assigning each source word to exactly one target word. Models describing these types of dependencies are referred to as alignrnen.t models (Brown e t al., 1993), (Dagan eta].. 1993). (Kay & R6scheisen, 1993). (Fung & Church. 1994), (Vogel et al., 1996). In this section, we introduce a monotoue HMM based alignment and an associated DP based search algorithm for translation. Another approach to statistical machine translation using DP was presented in (Wu, 1996). The notational convention will be a,s follows. We use the symbol Pr(.) to denote general SourceLanguageText 1 problem in speech recognition, where the so-called Hidden Markov models have been successfully used for a long time (Jelinek. 1976). Using the same basic principles, we can rewrite the probability by introducing the 'hidden&quot; aligmnents a~ := a l...aj...aa for a sentence pair"
P97-1037,P96-1021,0,0.307476,"ssume a sort of pairwise dependence by considering all word pairs (fj,ei) for a given sentence pair [f(; el]. We further constrain this model by assigning each source word to exactly one target word. Models describing these types of dependencies are referred to as alignrnen.t models (Brown e t al., 1993), (Dagan eta].. 1993). (Kay & R6scheisen, 1993). (Fung & Church. 1994), (Vogel et al., 1996). In this section, we introduce a monotoue HMM based alignment and an associated DP based search algorithm for translation. Another approach to statistical machine translation using DP was presented in (Wu, 1996). The notational convention will be a,s follows. We use the symbol Pr(.) to denote general SourceLanguageText 1 problem in speech recognition, where the so-called Hidden Markov models have been successfully used for a long time (Jelinek. 1976). Using the same basic principles, we can rewrite the probability by introducing the 'hidden&quot; aligmnents a~ := a l...aj...aa for a sentence pair [f~; c/]: 1 I Transformation ¢~ GlobalSearch: j~ maximize Pr(el). pr(f~lell} I ovor LexiconModel P,,(s 'lcI = I AllgnmentModel J j. pc(e~) [ MLanguage odel, [;.. .,!. ., on] ~i' j=1 To avoid any confnsion with th"
P97-1037,P93-1001,0,\N,Missing
popovic-ney-2004-towards,J93-2003,0,\N,Missing
popovic-ney-2004-towards,E03-1076,0,\N,Missing
popovic-ney-2004-towards,W01-1407,1,\N,Missing
popovic-ney-2004-towards,P02-1040,0,\N,Missing
popovic-ney-2004-towards,J01-2001,0,\N,Missing
popovic-ney-2004-towards,W02-0603,0,\N,Missing
popovic-ney-2004-towards,P02-1038,1,\N,Missing
popovic-ney-2006-pos,P02-1040,0,\N,Missing
popovic-ney-2006-pos,W05-0820,0,\N,Missing
popovic-ney-2006-pos,W05-0831,1,\N,Missing
popovic-ney-2006-pos,P05-1066,0,\N,Missing
popovic-ney-2006-pos,2005.iwslt-1.20,1,\N,Missing
popovic-ney-2006-pos,2001.mtsummit-papers.45,1,\N,Missing
vilar-etal-2006-error,2005.eamt-1.13,0,\N,Missing
vilar-etal-2006-error,P02-1040,0,\N,Missing
W01-1405,J99-4005,0,0.0363209,"idden alignments. These methods are only the time-honoured methods and successful methods of today. The characteristic property lies in the systematic use of a probabilistic framework for the construction of models, in the statistical training of the free parameters of these models and in the explicit use of a global scoring criterion for the decision making process. 3 Experimental Results Whereas stochastic modelling is widely used in speech recognition, there are so far only a few research groups that apply stochastic modelling to language translation (Berger et al. 1994; Brown et al. 1993; Knight 1999). The presentation here is based on work carried out in the framework of the E UTRANS project (Casacuberta et al. 2001) and the V ERBMOBIL project (Wahlster 2000). We will consider the experimental results obtained in the V ERBMOBIL project. The goal of the V ERBMOBIL project is the translation of spoken dialogues in the domains of appointment scheduling and travel planning. The languages are German and English. Whereas during the progress of the project many offline tests were carried out for the optimization and tuning of the statistical approach, the most important evaluation was the final"
W01-1405,H01-1062,0,0.0365783,"Missing"
W01-1405,W99-0604,1,0.841737,"Missing"
W01-1405,J93-2003,0,\N,Missing
W01-1405,H94-1028,0,\N,Missing
W01-1407,niessen-etal-2000-evaluation,1,\N,Missing
W01-1407,1993.mtsummit-1.11,0,\N,Missing
W01-1407,J93-2003,0,\N,Missing
W01-1407,H93-1039,0,\N,Missing
W01-1407,C90-3030,0,\N,Missing
W01-1407,C00-2123,1,\N,Missing
W01-1407,P98-2158,0,\N,Missing
W01-1407,C98-2153,0,\N,Missing
W01-1407,P98-1117,0,\N,Missing
W01-1407,C98-1113,0,\N,Missing
W01-1407,P98-2162,0,\N,Missing
W01-1407,C98-2157,0,\N,Missing
W01-1407,P00-1056,1,\N,Missing
W01-1407,P97-1047,0,\N,Missing
W01-1408,J93-2003,0,0.117121,"language into a target language. We are given a source string f1J = f1 ...fj ...fJ , which is to be translated into a target string eI1 = e1 ...ei ...eI . Among all possible target strings, we will choose the string with the highest probability: n o eˆI1 = arg max P r(e1J |f1I ) eI1   ( X n o = arg max P r(e1I ) · P r(f1J |eI1 ) eI1 The argmax operation denotes the search problem, i.e. the generation of the output sentence in the target language. P r(eI1 ) is the language model of the target language, whereas P r(f1J |e1I ) denotes the translation model. Many statistical translation models (Brown et al., 1993; Vogel et al., 1996; Och and Ney, 2000b) e1I aJ 1 The search space consists of the set of all possible target language strings e1I and all possible alignments aJ1 . 2 IBM Model 4 Various statistical alignment models of the form P r(f1J , aJ1 |eI1 ) have been introduced in (Brown et al., 1993; Vogel et al., 1996; Och and Ney, 2000a). In this paper we use the so-called Model 4 from (Brown et al., 1993). In Model 4 the statistical alignment model is decomposed into five sub-models: • the lexicon model p(f |e) for the probability that the source word f is a translation of the target word e, • the"
W01-1408,C00-2163,1,0.573158,"given a source string f1J = f1 ...fj ...fJ , which is to be translated into a target string eI1 = e1 ...ei ...eI . Among all possible target strings, we will choose the string with the highest probability: n o eˆI1 = arg max P r(e1J |f1I ) eI1   ( X n o = arg max P r(e1I ) · P r(f1J |eI1 ) eI1 The argmax operation denotes the search problem, i.e. the generation of the output sentence in the target language. P r(eI1 ) is the language model of the target language, whereas P r(f1J |e1I ) denotes the translation model. Many statistical translation models (Brown et al., 1993; Vogel et al., 1996; Och and Ney, 2000b) e1I aJ 1 The search space consists of the set of all possible target language strings e1I and all possible alignments aJ1 . 2 IBM Model 4 Various statistical alignment models of the form P r(f1J , aJ1 |eI1 ) have been introduced in (Brown et al., 1993; Vogel et al., 1996; Och and Ney, 2000a). In this paper we use the so-called Model 4 from (Brown et al., 1993). In Model 4 the statistical alignment model is decomposed into five sub-models: • the lexicon model p(f |e) for the probability that the source word f is a translation of the target word e, • the distortion model p=1 (j−j 0 |C(fj ), E"
W01-1408,P00-1056,1,0.47088,"given a source string f1J = f1 ...fj ...fJ , which is to be translated into a target string eI1 = e1 ...ei ...eI . Among all possible target strings, we will choose the string with the highest probability: n o eˆI1 = arg max P r(e1J |f1I ) eI1   ( X n o = arg max P r(e1I ) · P r(f1J |eI1 ) eI1 The argmax operation denotes the search problem, i.e. the generation of the output sentence in the target language. P r(eI1 ) is the language model of the target language, whereas P r(f1J |e1I ) denotes the translation model. Many statistical translation models (Brown et al., 1993; Vogel et al., 1996; Och and Ney, 2000b) e1I aJ 1 The search space consists of the set of all possible target language strings e1I and all possible alignments aJ1 . 2 IBM Model 4 Various statistical alignment models of the form P r(f1J , aJ1 |eI1 ) have been introduced in (Brown et al., 1993; Vogel et al., 1996; Och and Ney, 2000a). In this paper we use the so-called Model 4 from (Brown et al., 1993). In Model 4 the statistical alignment model is decomposed into five sub-models: • the lexicon model p(f |e) for the probability that the source word f is a translation of the target word e, • the distortion model p=1 (j−j 0 |C(fj ), E"
W01-1408,C00-2123,1,0.825236,"rty that if the count of the bigram N (u, v) = 0, then the probability P (w|u, v) depends only on v. In this case the recombination can be significantly improved by recombining all nodes whose language model state has the property N (u, v) = 0 only with respect to v. Obviously, this could be generalized to other types of language models as well. Experiments have shown that by using this efficient recombination, the number of needed hypotheses can be reduced by about a factor of 4. Search algorithms We evaluate the following two search algorithms: • beam search algorithm (BS): (Tillmann, 2001; Tillmann and Ney, 2000) In this algorithm the search space is explored in a breadth-first manner. The search algorithm is based on a dynamic programming approach and applies various pruning techniques in order to restrict the number of considered hypotheses. For more details see (Tillmann, 2001). • A* search algorithm: In A*, all search hypotheses are managed in a priority queue. The basic A* search (Nilsson, 1971) can be described as follows: 1. initialize priority queue with an empty hypothesis 2. remove the hypothesis with the highest score from the priority queue 3. if this hypothesis is a goal hypothesis: outpu"
W01-1408,C96-2141,1,0.914441,"et language. We are given a source string f1J = f1 ...fj ...fJ , which is to be translated into a target string eI1 = e1 ...ei ...eI . Among all possible target strings, we will choose the string with the highest probability: n o eˆI1 = arg max P r(e1J |f1I ) eI1   ( X n o = arg max P r(e1I ) · P r(f1J |eI1 ) eI1 The argmax operation denotes the search problem, i.e. the generation of the output sentence in the target language. P r(eI1 ) is the language model of the target language, whereas P r(f1J |e1I ) denotes the translation model. Many statistical translation models (Brown et al., 1993; Vogel et al., 1996; Och and Ney, 2000b) e1I aJ 1 The search space consists of the set of all possible target language strings e1I and all possible alignments aJ1 . 2 IBM Model 4 Various statistical alignment models of the form P r(f1J , aJ1 |eI1 ) have been introduced in (Brown et al., 1993; Vogel et al., 1996; Och and Ney, 2000a). In this paper we use the so-called Model 4 from (Brown et al., 1993). In Model 4 the statistical alignment model is decomposed into five sub-models: • the lexicon model p(f |e) for the probability that the source word f is a translation of the target word e, • the distortion model p="
W01-1408,P97-1047,0,0.712311,"extensions of this hypothesis and put the extensions to the queue 5. goto 2 The so-called heuristic function estimates the probability of a completion of a partial hypothesis. This function is called admissible if it never underestimates this probability. Thus, admissible heuristic functions are always optimistic. The A* search algorithm corresponds to the Dijkstra algorithm if the heuristic function is equal to zero. 4 Admissible heuristic function In order to perform an efficient search with the A* search algorithm it is crucial to use a good heuristic function. We only know of the work by (Wang and Waibel, 1997) dealing with heuristic functions for search in statistical machine translation. They developed a simple heuristic function for Model 2 from (Brown et al., 1993) which was non admissible. In the following we develop a guaranteed admissible heuristic function for Model 4 taking into account distortion probabilities and the coupling of lexicon, fertility, and language model probabilities. The basic idea for developing a heuristic function for the alignment models is the fact that all source sentence positions which have not been covered so far still have to be translated in order to complete the"
W01-1408,J03-1005,1,\N,Missing
W02-1021,W98-1426,0,\N,Missing
W02-1021,J93-2003,0,\N,Missing
W02-1021,C00-2123,1,\N,Missing
W02-1021,P95-1034,0,\N,Missing
W02-1021,W01-1408,1,\N,Missing
W03-0420,J96-1002,0,0.00871905,"nizations (ORG), and names of miscellaneous entities (MISC) that do not belong to the previous three groups, e.g. [PER Clinton] ’s [ORG Ballybunion] fans invited to [LOC Chicago] . Additionally, the task requires the processing of two different languages from which only English was specified before the submission deadline. Therefore, the $'&)(   *   , 9 ;*  ) 1  <   , $ ' ) & ( :  9 m=?>A@!B   *  221130 <  2/71600 , (  : DC  A well-founded framework for directly modeling the 21   /70 posterior probability   *  2160 <  2160 , is maximum en( C tropy (Berger et al., 1996). In this framework, we have 21   /70 a set of E feature functions F3G  2160 <   <  2160 , <IH  J < K L < E . For each feature function ( F3G , there exists a model parameter M G . The posterior probability can then be modeled as follows: - Digits and numbers: ASCII digit strings and number expressions activate these features. Input Sequence   Preprocessing Global Search         - Pre- and suffixes: If the prefix (suffix) of 8 equals a given prefix (suffix), these features will fire.  &  -,' 0 2134   #   &(')  ) + &('. - ,' 0 ' 13 '  &"
W03-0420,M98-1018,0,0.0265655,"Missing"
W04-1118,J90-2002,0,0.458153,"Missing"
W04-1118,J93-2003,0,0.01137,"ment Models The alignment model P r(f1J , aJ1 |eI1 ) introduces a ‘hidden’ alignment a = aJ1 , which describes 1 The notational convention will be as follows: we use the symbol P r(·) to denote general probability distributions with (nearly) no specific assumptions. In contrast, for model-based probability distributions, we use the generic symbol p(·). a mapping from a source position j to a target position aj . The relationship between the translation model and the alignment model is given by: X P r(f1J |eI1 ) = P r(f1J , aJ1 |eI1 ) (3) aJ 1 In this paper, we use the models IBM-1, IBM4 from (Brown et al., 1993) and the HiddenMarkov alignment model (HMM) from (Vogel et al., 1996). All these models provide different decompositions of the probability P r(f1J , aJ1 |eI1 ). A detailed description of these models can be found in (Och and Ney, 2003). A Viterbi alignment a ˆJ1 of a specific model is an alignment for which the following equation holds: a ˆJ1 = argmax P r(f1J , aJ1 |eI1 ). (4) aJ 1 The alignment models are trained on a bilingual corpus using GIZA++(Och et al., 1999; Och and Ney, 2003). The training is done iteratively in succession on the same data, where the final parameter estimates of a si"
W04-1118,P02-1038,1,0.242537,"ased on phrases circumvents the problem of word segmentation to a certain degree. This method will be referred to as “translation with no segmentation” (see Section 5.2). visit a for hangzhou to go also will they Figure 2: Example of a word aligned sentence pair and some possible alignment templates. In the Chinese–English DARPA TIDES evaluations in June 2002 and May 2003, carried out by NIST (NIST, 2003), the alignment template approach performed very well and was ranked among the best translation systems. Further details on the alignment template approach are described in (Och et al., 1999; Och and Ney, 2002). 3 Task and Corpus Statistics In Section 5.3, we will present results for a Chinese–English translation task. The domain of this task is news articles. As bilingual training data, we use a corpus composed of the English translations of a Chinese Treebank. This corpus is provided by the Linguistic Data Consortium (LDC), catalog number LDC2002E17. In addition, we use a bilingual dictionary with 10K Chinese word entries provided by Stephan Vogel (LDC, 2003b). Table 1 shows the corpus statistics of this task. We have calculated both the number of words and the number of characters in the corpus."
W04-1118,J03-1002,1,0.0116123,"rly) no specific assumptions. In contrast, for model-based probability distributions, we use the generic symbol p(·). a mapping from a source position j to a target position aj . The relationship between the translation model and the alignment model is given by: X P r(f1J |eI1 ) = P r(f1J , aJ1 |eI1 ) (3) aJ 1 In this paper, we use the models IBM-1, IBM4 from (Brown et al., 1993) and the HiddenMarkov alignment model (HMM) from (Vogel et al., 1996). All these models provide different decompositions of the probability P r(f1J , aJ1 |eI1 ). A detailed description of these models can be found in (Och and Ney, 2003). A Viterbi alignment a ˆJ1 of a specific model is an alignment for which the following equation holds: a ˆJ1 = argmax P r(f1J , aJ1 |eI1 ). (4) aJ 1 The alignment models are trained on a bilingual corpus using GIZA++(Och et al., 1999; Och and Ney, 2003). The training is done iteratively in succession on the same data, where the final parameter estimates of a simpler model serve as starting point for a more complex model. The result of the training procedure is the Viterbi alignment of the final training iteration for the whole training corpus. 2.3 Alignment Template Approach In the translatio"
W04-1118,W99-0604,1,0.924603,"ignment model is given by: X P r(f1J |eI1 ) = P r(f1J , aJ1 |eI1 ) (3) aJ 1 In this paper, we use the models IBM-1, IBM4 from (Brown et al., 1993) and the HiddenMarkov alignment model (HMM) from (Vogel et al., 1996). All these models provide different decompositions of the probability P r(f1J , aJ1 |eI1 ). A detailed description of these models can be found in (Och and Ney, 2003). A Viterbi alignment a ˆJ1 of a specific model is an alignment for which the following equation holds: a ˆJ1 = argmax P r(f1J , aJ1 |eI1 ). (4) aJ 1 The alignment models are trained on a bilingual corpus using GIZA++(Och et al., 1999; Och and Ney, 2003). The training is done iteratively in succession on the same data, where the final parameter estimates of a simpler model serve as starting point for a more complex model. The result of the training procedure is the Viterbi alignment of the final training iteration for the whole training corpus. 2.3 Alignment Template Approach In the translation approach from Section 2.1, one disadvantage is that the contextual information is only taken into account by the language model. The single-word based lexicon model does not consider the surrounding words. One way to incorporate the"
W04-1118,P97-1041,0,0.0175549,"Missing"
W04-1118,2001.mtsummit-papers.68,0,0.0289267,"erations that have to be performed to convert the generated sentence into the reference sentence. • PER (position-independent word error rate): A shortcoming of the WER is that it requires a perfect word order. The word order of an acceptable sentence can be different from that of the target sentence, so that the WER measure alone could be misleading. The PER compares the words in the two sentences ignoring the word order. • BLEU score: This score measures the precision of unigrams, bigrams, trigrams and fourgrams with respect to a reference translation with a penalty for too short sentences (Papineni et al., 2001). The BLEU score measures accuracy, i.e. large BLEU scores are better. 5.2 Summary: Three Translation Methods In the experiments, we compare the following three translation methods: • Translation with no segmentation: Each Chinese character is interpreted as a single word. • Translation with learned segmentation: It uses the self-learned dictionary. • Translation with LDC segmentation: The predefined LDC dictionary is used. The core contribution of this paper is the method we called “translation with learned segmentation”, which consists of three steps: • The input is a sequence of Chinese cha"
W04-1118,P98-2206,0,0.016446,"Missing"
W04-1118,C96-2141,1,0.240752,"dden’ alignment a = aJ1 , which describes 1 The notational convention will be as follows: we use the symbol P r(·) to denote general probability distributions with (nearly) no specific assumptions. In contrast, for model-based probability distributions, we use the generic symbol p(·). a mapping from a source position j to a target position aj . The relationship between the translation model and the alignment model is given by: X P r(f1J |eI1 ) = P r(f1J , aJ1 |eI1 ) (3) aJ 1 In this paper, we use the models IBM-1, IBM4 from (Brown et al., 1993) and the HiddenMarkov alignment model (HMM) from (Vogel et al., 1996). All these models provide different decompositions of the probability P r(f1J , aJ1 |eI1 ). A detailed description of these models can be found in (Och and Ney, 2003). A Viterbi alignment a ˆJ1 of a specific model is an alignment for which the following equation holds: a ˆJ1 = argmax P r(f1J , aJ1 |eI1 ). (4) aJ 1 The alignment models are trained on a bilingual corpus using GIZA++(Och et al., 1999; Och and Ney, 2003). The training is done iteratively in succession on the same data, where the final parameter estimates of a simpler model serve as starting point for a more complex model. The res"
W04-1118,P02-1040,0,\N,Missing
W04-1118,C98-2201,0,\N,Missing
W04-3235,E85-1023,0,0.118461,"Other prominent examples are speech recognition and machine translation. The advantage of the POS tagging task is that it will be easier to handle from the mathematical point of view and will result in closedform solutions for the decision rules. From this point-of-view, the POS tagging task serves as a good opportunity to illustrate the key concepts of the statistical approach to NLP. Related Work: For the task of POS tagging, statistical approaches were proposed already in the 60’s and 70’s (Stolz et al., 1965; Bahl and Mercer, 1976), before they started to find widespread use in the 80’s (Beale, 1985; DeRose, 1989; Church, 1989). To the best of our knowledge, the ’standard’ version of the Bayes decision rule, which minimizes the number of string errors, is used in virtually all approaches to POS tagging and other NLP tasks. There are only two research groups that do not take this type of decision rule for granted: (Merialdo, 1994): In the context of POS tagging, the author introduces a method that he calls maximum likelihood tagging. The spirit of this method is similar to that of this work. However, this method is mentioned as an aside and its implications for the Bayes decision rule and"
W04-3235,J96-1002,0,0.0539595,"ed probability distribution p(g1N |w1N ): P r(g1N |w1N ) → p(g1N |w1N ) and apply the chain rule: p(g1N |w1N ) = = N Y n=1 N Y p(gn |g1n−1 , w1N ) n−1 n+2 p(gn |gn−2 , wn−2 ) n=1 As for the generative model, we have made specific assumptions: There is a second-order dependence for the tags g1n , and the dependence on the words n+2 w1N is limited to a window wn−2 around position n. The resulting model is still rather complex and requires further specifications. The typical procedure is to resort to log-linear modelling, which is also referred to as maximum entropy modelling (Ratnaparkhi, 1996; Berger et al., 1996). 3.2.1 String Error For the minimum string error, we obtain the decision rule: w1N → gˆ1N n o = arg max p(g1N |w1N ) g1N Since this is still a second-order model, we can use dynamic programming to compute the most likely POS string. 3.2.2 Symbol Error For the minimum symbol error, the marginal (and posterior) probability pm (g|w1N ) has to be computed: pm (g|w1N ) = X P r(g1N |w1N ) X Y 5 Experimental Results g1N : gm =g = n−1 n+2 p(gn |gn−2 , wn−2 ) g1N : gm =g n which, due to the specific structure of the model n−1 n+2 p(gn |gn−2 , wn−2 ), can be calculated efficiently using only a forward"
W04-3235,J94-2001,0,0.330196,"ate the key concepts of the statistical approach to NLP. Related Work: For the task of POS tagging, statistical approaches were proposed already in the 60’s and 70’s (Stolz et al., 1965; Bahl and Mercer, 1976), before they started to find widespread use in the 80’s (Beale, 1985; DeRose, 1989; Church, 1989). To the best of our knowledge, the ’standard’ version of the Bayes decision rule, which minimizes the number of string errors, is used in virtually all approaches to POS tagging and other NLP tasks. There are only two research groups that do not take this type of decision rule for granted: (Merialdo, 1994): In the context of POS tagging, the author introduces a method that he calls maximum likelihood tagging. The spirit of this method is similar to that of this work. However, this method is mentioned as an aside and its implications for the Bayes decision rule and the statistical approach are not addressed. Part of this work goes back to (Bahl et al., 1974) who considered a problem in coding theory. (Goel and Byrne, 2003): The error measure considered by the authors is the word error rate in speech recognition, i.e. the edit distance. Due to the mathematical complexity of this error measure, th"
W04-3235,W96-0213,0,0.431369,"1N ) by a model-based probability distribution p(g1N |w1N ): P r(g1N |w1N ) → p(g1N |w1N ) and apply the chain rule: p(g1N |w1N ) = = N Y n=1 N Y p(gn |g1n−1 , w1N ) n−1 n+2 p(gn |gn−2 , wn−2 ) n=1 As for the generative model, we have made specific assumptions: There is a second-order dependence for the tags g1n , and the dependence on the words n+2 w1N is limited to a window wn−2 around position n. The resulting model is still rather complex and requires further specifications. The typical procedure is to resort to log-linear modelling, which is also referred to as maximum entropy modelling (Ratnaparkhi, 1996; Berger et al., 1996). 3.2.1 String Error For the minimum string error, we obtain the decision rule: w1N → gˆ1N n o = arg max p(g1N |w1N ) g1N Since this is still a second-order model, we can use dynamic programming to compute the most likely POS string. 3.2.2 Symbol Error For the minimum symbol error, the marginal (and posterior) probability pm (g|w1N ) has to be computed: pm (g|w1N ) = X P r(g1N |w1N ) X Y 5 Experimental Results g1N : gm =g = n−1 n+2 p(gn |gn−2 , wn−2 ) g1N : gm =g n which, due to the specific structure of the model n−1 n+2 p(gn |gn−2 , wn−2 ), can be calculated efficiently"
W04-3235,J88-1003,0,\N,Missing
W05-0806,J93-2003,0,0.0124716,"Missing"
W05-0806,W01-1407,1,0.882366,"Missing"
W05-0806,J04-2003,1,0.83514,"t language. Usually, the performance of a translation system strongly depends on the size of the available training corpus. However, acquisition of a large high-quality bilingual parallel text for the desired domain and language pair requires lot of time and effort, and, for many language pairs, is even not possible. Besides, small corpora have certain advantages - the acquisition does not require too much effort and also manual creation and correction are possible. Therefore there is an increasing number of publications dealing with limited amounts of bilingual data (Al-Onaizan et al., 2000; Nießen and Ney, 2004). In this work, we examine the quality of several statistical machine translation systems constructed on a small amount of parallel Serbian-English text. The main bilingual parallel corpus consists of about 3k sentences and 20k running words from an unrestricted domain. The translation systems are built on the full corpus as well as on a reduced corpus containing only 200 parallel sentences. A small set of about 350 short phrases from the web is used as additional bilingual knowledge. In addition, we investigate the use of monolingual morpho-syntactic knowledge i.e. base forms and POS tags. 1"
W05-0806,J03-1002,1,0.0207503,"is to translate a source language sequence f1 , . . . , fJ into a target language sequence e1 , . . . , eI by maximising the conditional probability P r(eI1 |f1J ). This probability can be factorised into the translation model probability P (f1J |eI1 ) which describes the correspondence between the words in the source and the target sequence, and the language model probability P (eJ1 ) which describes well-formedness of the produced target sequence. These two probabilities can be modelled independently of each other. For detailed descriptions of SMT models see for example (Brown et al., 1993; Och and Ney, 2003). Translation probabilities are learnt from a bilingual parallel text corpus and language model probabilities are learnt from a monolingual text in the tarFor the Serbian language, as a rather minor and not widely studied language, there are not many language resources available, especially not parallel texts. On the other side, investigations on this language may be quite useful since the majority of principles can be extended to the wider group of Slavic languages (e.g. Czech, Polish, Russian, etc.). In this work, we exploit small Serbian-English parallel texts as a bilingual knowledge sourc"
W05-0806,P02-1040,0,0.078321,"timise the scaling factors, results obtained for this set do not differ from those for the test set. Therefore only the joint error rates (Development+Test) are reported. As for the external test set, results for this text are reported only for the full corpus systems, since for the reduced corpus the error rates are higher but the effects of using phrases and morpho-syntactic information are basically the same. 4.2 Translation Results The evaluation metrics used in our experiments are WER (Word Error Rate), PER (Positionindependent word Error Rate) and BLEU (BiLingual Evaluation Understudy) (Papineni et al., 2002). Since BLEU is an accuracy measure, we use 1BLEU as an error measure. 45 4.2.1 Translation from Serbian into English Error rates for the translation from Serbian into English are shown in Table 3 and some examples are shown in Table 6. It can be seen that there is a significant decrease in all error rates when the full forms are replaced with their base forms. Since the redundant information contained in the inflection is removed, the system can better capture the relevant information and is capable of producing correct or approximatively correct translations even for unseen full forms of the"
W05-0806,popovic-ney-2004-towards,1,0.895064,"Missing"
W05-0806,J82-2005,0,0.563994,"Missing"
W05-0806,W96-0213,0,0.0102235,". The morpho-syntactic annotation of the English part of the corpus has been done by the constraint grammar parser ENGCG for morphological and syntactic analysis of English language. For each word, this tool provides its base form and sequence of morpho-syntactic tags. For the Serbian corpus, to our knowlegde there is no available tool for automatic annotation of this language. Therefore, the base forms have been introduced manually and the POS tags have been provided partly manually and partly automatically using a statistical maximum-entropy based POS tagger similar to the one described in (Ratnaparkhi, 1996). First, the 200 sentences of the reduced training corpus have been annotated completely manually. Then the first 500 sentences of the rest of the training corpus have been tagged automatically and the errors have been manually corrected. Afterwards, the POS tagger has been trained on the extended corpus (700 sentences), the next 500 sentences of the rest are annotated, and the procedure has been repeated until the annotation has been finished for the complete corpus. Table 1: Statistics of the Serbian-English Assimil corpus Serbian English Training: original base forms original no article ful"
W05-0831,W00-0508,0,0.172433,"Missing"
W05-0831,2004.iwslt-evaluation.13,1,0.903041,"the reordering problem from the view of the model. Without reordering both in training and during search, sentences can only be translated properly into a language with similar word order. In (Bangalore et al., 2000) weighted reordering has been applied to target sentences since defining a permutation model on the source side is impractical in combination with speech recognition. In order to reduce the computational complexity, this approach considers only a set of plausible reorderings seen on training data. Most other phrase-based statistical approaches like the Alignment Template system of Bender et al. (2004) rely on (local) reorderings which are implicitly memorized with each pair of source and target phrases in training. Additional reorderings on phrase level are fully integrated into the decoding process, which increases the complexity of the system and makes it hard to modify. Zens et al. (2003) reviewed two types of reordering constraints for this type of translation systems. In our work we follow a phrase-based translation approach, applying source sentence reordering on word level. We compute a reordering graph ondemand and take it as input for monotonic translation. This approach is modula"
W05-0831,P04-1065,1,0.437186,"Missing"
W05-0831,knight-al-onaizan-1998-translation,0,0.507961,"Missing"
W05-0831,N03-1019,0,0.120471,"Missing"
W05-0831,C04-1032,1,0.655504,"he empty phrase. Therefore, for language pairs with big differences in word order, probability estimates may be poor. This problem can be solved by reordering either source or target training sentences such that alignments become monotonic for all sentences. We suggest the following consistent source sentence reordering and alignment monotonization approach in which we compute optimal, minimum-cost alignments. First, we estimate a cost matrix C for each sentence pair (f1J , eI1 ). The elements of this matrix cij are the local costs of aligning a source word fj to a target word ei . Following (Matusov et al., 2004), we compute these local costs by interpolating state occupation probabilities from the source-to-target and target-to-source training of the HMM and IBM-4 models as trained by the GIZA++ toolkit (Och et al., 2003). For a given alignment A ⊆ I × J, we define the costs of this alignment c(A) as the sum of the local costs of all aligned word pairs: X c(A) = cij (1) A∈A ∼ = argmax max e˜J 1 (fj , e˜j ). Mapping the bilingual language model to a WFST T is canonical and it has been shown in (Kanthak et al., 2004) that the search problem can then be rewritten using finite-state terminology: j−1 p(fj"
W05-0831,J03-1002,1,0.0715111,"Missing"
W05-0831,P02-1040,0,0.119703,"Missing"
W05-0831,J97-3002,0,0.168153,"well-known in the field of machine translation and were first described in (Berger et al., 1996). The idea behind these constraints is to deviate from monotonic translation by postponing translations of a limited number of words. More specifically, at each state we can translate any of the first l yet uncovered word positions. The implementation using a bit vector is straightforward. For consistency, we associate window size with the parameter l for all constraints presented here. 4.3 1000 ITG Constraints Another type of reordering can be obtained using Inversion Transduction Grammars (ITG) (Wu, 1997). These constraints are inspired by bilingual bracketing. They proved to be quite useful for machine translation, e.g. see (Bender et al., 2004). Here, we interpret the input sentence as a sequence of segments. In the beginning, each word is a segment of its own. Longer segments are constructed by recursively combining two adjacent segments. At each 1 both covered and uncovered train dev test sentences words singletons vocabulary sentences words sentence length (avg/max) sentences words sentence length (avg/max) Chinese English 20 000 182 904 160 523 3 525 2 948 7 643 6 982 506 3 515 3 595 6.9"
W05-0831,2002.tmi-tutorials.2,0,0.0628056,"ermutations as a finite-state automaton requires at least 2J states. Therefore, we opt for computing the permutation automaton on-demand while applying beam pruning in the search. 4.1 Lazy Permutation Automata For on-demand computation of an automaton in the flavor described in (Kanthak et al., 2004) it is sufficient to specify a state description and an algorithm that calculates all outgoing arcs of a state from the state description. In our case, each state represents a permutation of a subset of the source words f1J , which are already translated. This can be described by a bit vector bJ1 (Zens et al., 2002). Each bit of the state bit vector corresponds to an arc of the linear input automaton and is set to one if the arc has been used on any path from the initial to the current state. The bit vectors of two states connected by an arc differ only in a single bit. Note that bit vectors elegantly solve the problem of recombining paths in the automaton as states with the same bit vectors can be merged. As a result, a fully minimized permutation automaton has only a single initial and final state. Even with on-demand computation, complexity using full permutations is unmanagable for long sentences. We"
W05-0831,P03-1019,1,0.772763,"Missing"
W05-0831,J04-2004,0,\N,Missing
W05-0831,2004.iwslt-evaluation.1,0,\N,Missing
W05-0834,N03-1019,0,0.0563219,"tical machine translation systems are phrase-based. • Their graph pruning method is suboptimal as it considers only partial scores and not full path scores. • The N -best list extraction does not eliminate duplicates, i.e. different paths that represent the same translation candidate. • The rest cost estimation is not efficient. It has an exponential worst-case time complexity. We will describe an algorithm with linear worstcase complexity. Apart from (Ueffing et al., 2002), publications on weighted finite state transducer approaches to machine translation, e.g. (Bangalore and Riccardi, 2001; Kumar and Byrne, 2003), deal with word graphs. But to our knowledge, there are no publications that give a detailed analysis and evaluation of the quality of word graphs for machine translation. We will fill this gap and give a systematic description and an assessment of the quality of word graphs for phrase-based machine translation. We will show that even for hard tasks with very large vocabulary and long sentences the graph error rate drops significantly. The remaining part is structured as follows: first we will give a brief description of the translation system in Section 2. In Section 3, we will give a defini"
W05-0834,P02-1038,1,0.395242,"achine translation system usually produces the single-best translation hypotheses for a source sentence. For some applications, we are also interested in alternative translations. The simplest way to represent these alternatives is a list with the N -best translation candidates. These N -best lists have one major disadvantage: the high redundancy. The translation alternatives may differ only by a single word, but still both are listed completely. Usually, the size of the N -best list is in the range of a few • Discriminative Training. The training of the model scaling factors as described in (Och and Ney, 2002) was done on N -best lists. Using word graphs instead could further improve the results. Also, the phrase translation probabilities could be trained discrimatively, rather than only the scaling factors. • Confidence Measures. Word graphs can be used to derive confidence measures, such as the posterior probability (Ueffing and Ney, 2004). 191 Proceedings of the ACL Workshop on Building and Using Parallel Texts, pages 191–198, c Ann Arbor, June 2005. Association for Computational Linguistics, 2005 • Interactive Machine Translation. Some interactive machine translation systems make use of word gr"
W05-0834,E03-1032,1,0.863799,"N -best lists. Using word graphs instead could further improve the results. Also, the phrase translation probabilities could be trained discrimatively, rather than only the scaling factors. • Confidence Measures. Word graphs can be used to derive confidence measures, such as the posterior probability (Ueffing and Ney, 2004). 191 Proceedings of the ACL Workshop on Building and Using Parallel Texts, pages 191–198, c Ann Arbor, June 2005. Association for Computational Linguistics, 2005 • Interactive Machine Translation. Some interactive machine translation systems make use of word graphs, e.g. (Och et al., 2003). State Of The Art. Although there are these many applications, there are only few publications directly devoted to word graphs. The only publication, we are aware of, is (Ueffing et al., 2002). The shortcomings of (Ueffing et al., 2002) are: • They use single-word based models only. Current state of the art statistical machine translation systems are phrase-based. • Their graph pruning method is suboptimal as it considers only partial scores and not full path scores. • The N -best list extraction does not eliminate duplicates, i.e. different paths that represent the same translation candidate"
W05-0834,P03-1021,0,0.323432,"ity P r(eI1 |f1J ) is modeled directly using a weighted log-linear combination of a trigram language model and various translation models: a phrase translation model and a wordbased lexicon model. These translation models are used for both directions: p(f |e) and p(e|f ). Additionally, we use a word penalty and a phrase penalty. With the exception of the language model, all models can be considered as within-phrase models as they depend only on a single phrase pair, but not on the context outside of the phrase. The model scaling factors are optimized with respect to some evaluation criterion (Och, 2003). We extended the monotone search algorithm from (Zens and Ney, 2004) such that reorderings are possible. In our case, we assume that local reorderings are sufficient. Within a certain window, all possible permutations of the source positions are allowed. These permutations are represented as a reordering graph, similar to (Zens et al., 2002). Once we have this reordering graph, we perform a monotone phrase-based translation of this graph. More details of this reordering approach are described in (Kanthak et al., 2005). 3 Word Graphs 3.1 Definition A word graph is a directed acyclic graph G ="
W05-0834,W02-1021,1,0.69194,". • Confidence Measures. Word graphs can be used to derive confidence measures, such as the posterior probability (Ueffing and Ney, 2004). 191 Proceedings of the ACL Workshop on Building and Using Parallel Texts, pages 191–198, c Ann Arbor, June 2005. Association for Computational Linguistics, 2005 • Interactive Machine Translation. Some interactive machine translation systems make use of word graphs, e.g. (Och et al., 2003). State Of The Art. Although there are these many applications, there are only few publications directly devoted to word graphs. The only publication, we are aware of, is (Ueffing et al., 2002). The shortcomings of (Ueffing et al., 2002) are: • They use single-word based models only. Current state of the art statistical machine translation systems are phrase-based. • Their graph pruning method is suboptimal as it considers only partial scores and not full path scores. • The N -best list extraction does not eliminate duplicates, i.e. different paths that represent the same translation candidate. • The rest cost estimation is not efficient. It has an exponential worst-case time complexity. We will describe an algorithm with linear worstcase complexity. Apart from (Ueffing et al., 2002"
W05-0834,2004.iwslt-evaluation.1,0,0.0279902,"Missing"
W05-0834,N04-1033,1,0.861442,"e translation. We will present experimental results in Section 5 for two Chinese– English tasks: the first one, the IWSLT task, is in the domain of basic travel expression found in phrasebooks. The vocabulary is limited and the sentences are short. The second task is the NIST Chinese– English large data track task. Here, the domain is news and therefore the vocabulary is very large and the sentences are with an average of 30 words quite long. 2 Translation System In this section, we give a brief description of the translation system. We use a phrase-based translation approach as described in (Zens and Ney, 2004). The posterior probability P r(eI1 |f1J ) is modeled directly using a weighted log-linear combination of a trigram language model and various translation models: a phrase translation model and a wordbased lexicon model. These translation models are used for both directions: p(f |e) and p(e|f ). Additionally, we use a word penalty and a phrase penalty. With the exception of the language model, all models can be considered as within-phrase models as they depend only on a single phrase pair, but not on the context outside of the phrase. The model scaling factors are optimized with respect to som"
W05-0834,N01-1018,0,0.0117441,"urrent state of the art statistical machine translation systems are phrase-based. • Their graph pruning method is suboptimal as it considers only partial scores and not full path scores. • The N -best list extraction does not eliminate duplicates, i.e. different paths that represent the same translation candidate. • The rest cost estimation is not efficient. It has an exponential worst-case time complexity. We will describe an algorithm with linear worstcase complexity. Apart from (Ueffing et al., 2002), publications on weighted finite state transducer approaches to machine translation, e.g. (Bangalore and Riccardi, 2001; Kumar and Byrne, 2003), deal with word graphs. But to our knowledge, there are no publications that give a detailed analysis and evaluation of the quality of word graphs for machine translation. We will fill this gap and give a systematic description and an assessment of the quality of word graphs for phrase-based machine translation. We will show that even for hard tasks with very large vocabulary and long sentences the graph error rate drops significantly. The remaining part is structured as follows: first we will give a brief description of the translation system in Section 2. In Section"
W05-0834,2002.tmi-tutorials.2,0,0.168978,"the exception of the language model, all models can be considered as within-phrase models as they depend only on a single phrase pair, but not on the context outside of the phrase. The model scaling factors are optimized with respect to some evaluation criterion (Och, 2003). We extended the monotone search algorithm from (Zens and Ney, 2004) such that reorderings are possible. In our case, we assume that local reorderings are sufficient. Within a certain window, all possible permutations of the source positions are allowed. These permutations are represented as a reordering graph, similar to (Zens et al., 2002). Once we have this reordering graph, we perform a monotone phrase-based translation of this graph. More details of this reordering approach are described in (Kanthak et al., 2005). 3 Word Graphs 3.1 Definition A word graph is a directed acyclic graph G = (V, E) with one designated root node n0 ∈ V . The edges are labeled with words and optionally with scores. We will use (n, n0 , w) to denote an edge from node n to node n0 with word label w. Each path through the word graph represents a translation candidate. If the word graph contains scores, we accumulate the edge scores along a path to get"
W05-0834,W05-0831,1,0.923386,"se. The model scaling factors are optimized with respect to some evaluation criterion (Och, 2003). We extended the monotone search algorithm from (Zens and Ney, 2004) such that reorderings are possible. In our case, we assume that local reorderings are sufficient. Within a certain window, all possible permutations of the source positions are allowed. These permutations are represented as a reordering graph, similar to (Zens et al., 2002). Once we have this reordering graph, we perform a monotone phrase-based translation of this graph. More details of this reordering approach are described in (Kanthak et al., 2005). 3 Word Graphs 3.1 Definition A word graph is a directed acyclic graph G = (V, E) with one designated root node n0 ∈ V . The edges are labeled with words and optionally with scores. We will use (n, n0 , w) to denote an edge from node n to node n0 with word label w. Each path through the word graph represents a translation candidate. If the word graph contains scores, we accumulate the edge scores along a path to get the sentence or string score. The score information the word graph has to contain depends on the application. If we want to use the word graph as a word filter, we do not need any"
W05-0834,knight-al-onaizan-1998-translation,0,0.0184284,".2 Generation In this section, we analyze the search process in detail. Later, in Section 5, we will show the (experimental) complexity of each step. We start with the source language sentence that is represented as a linear graph. Then, we introduce reorderings into this graph as described in (Kanthak et al., 2005). The type of reordering should depend on the language pair. In our case, we assume that only local reorderings are required. Within a certain window, all possible reorderings of the source positions are allowed. These permutations are represented as a reordering graph, similar to (Knight and Al-Onaizan, 1998) and (Zens et al., 2002). Once we have this reordering graph, we perform a monotone phrase-based translation of this graph. This translation process consists of the following steps that will be described afterward: 1. segment into phrase 2. translate the individual phrases 3. split the phrases into words 4. apply the language model Now, we will describe each step. The first step is the segmentation into phrases. This can be imagined as introducing “short-cuts” into the graph. The phrase segmentation does not affect the number of nodes, because only additional edges are added to the graph. In t"
W05-0903,2004.iwslt-evaluation.1,0,0.0310677,"hed out on system level. On the BTEC corpus a high sentence level correlation accompanies a significantly lower system level correlation. Note that due to the much lower number of samples on the system level (e.g. 5 vs. 5500), small changes in the sentence level correlation are more likely to be significant than such changes on system level. We have verified these effects by inspecting the rank correlation on both levels, as well as by experiments on other corpora. Although these experiments support our findings, we have omitted results here 0.0 B BLEUS W P 0.0 4.2 W WER P PER 0.6 evaluation (Akiba et al., 2004). We restricted our experiments to the eleven MT systems that had been trained on a common training corpus. Corpus statistics can be found in table 2. Tokenization and case normalization The impact of case information was analyzed in our next experiment. Figure 4 (again without the N IST measure as it shows a similar behavior to the other measures) indicates that it is advisable to disregard case information when looking into adequacy on sentence level. Surprisingly, this also holds for 0.2 TIDES CE 0.0 0.2 TIDES AE 0.0 TIDES CE P B N TIDES AE 1.0 B N 0.8 ● P B ●●●● ● ●●● ●●●● ● ●●● ●●●● none"
W05-0903,2003.mtsummit-papers.32,1,0.854681,"β := − 2 log2 3 Due to the information weights, the value of the N IST score depends highly on the selection of the reference corpus. This must be taken into account when comparing N IST scores of different evaluation campaigns. 2.2 Other measures Lin and Och (2004) introduce a family of three measures named ROUGE. ROUGE -S is a skipbigram F-measure. ROUGE -L and ROUGE -W are measures based on the length of the longest common subsequence of the sentences. ROUGE -S has a structure similar to the bigram P ER presented here. We expect ROUGE -L and ROUGE -W to have similar properties to W ER. In (Leusch et al., 2003), we have described INV W ER , a word error rate enhanced by block transposition edit operations. As structure and scores of INV W ER are similar to W ER, we have omitted INV W ER experiments in this paper. 3 Preprocessing and normalization Although the general idea is clear, there are still several details to be specified when implementing and using an automatic evaluation measure. We are going to investigate the following problems: The first detail we have to state more precisely is the term “word” in the above formulae. A common approach for western languages is to consider spaces as separa"
W05-0903,C04-1072,0,0.0343591,"er of deletions, insertions, and substitutions to transform the candidate sentence into the reference sentence is calculated. Using the counts ne,r , n ˜ e,r,k of a word e in the candidate er,k , we sentence Ek , and the reference sentence E can calculate this distance as  X   er,k := 1 Ik −I˜k + ne,k −˜ dP ER Ek , E ne,r,k 2 e 18 1 · sm + sm + n ¯m  X X min n em 1 ,k ,n ˜ em 1 ,k   k em 1 ∈Ek with the geometric mean gm and a brevity penalty    I¯∗  lpB LEU := min 1 , exp 1 − ¯ I In the original B LEU definition, the smoothing term sm is zero. To allow for sentence-wise evaluation, Lin and Och (2004) define the B LEU - S measure with s1 := 1 and sm&gt;1 := 0. We have adopted this technique for this study. 2.1.4 N IST The N IST score (Doddington, 2002) extends the B LEU score by taking information weights of the m-grams into account. The N IST information weight is defined as  ¯˜ m−1 Info(em ˜¯ em − log2 n 1 ) := − log2 n 1 ¯˜ em := with n 1 X e1 n ˜ en1 ,k,r . k,r Note that the weight of a phrase occurring in many references sentence for a candidate is considered to be lower than the weight of a phrase occurring only once! The N IST score is the sum over all information counts of the co-occ"
W05-0903,2001.mtsummit-papers.68,0,0.0360213,"denote the count of the m-gram em 1 1 ,k within the candidate sentence Ek ; similarly let n ˜ em denote the same count within the reference 1 ,r,k er,k . The total m-gram count over the sentence E X X corpus is then n ¯ m := nem . 1 ,k k em 1 ∈Ek This distance is then normalized into an error rate, the P ER, as described in section 2.1.1. A promising approach is to compare bigram or arbitrary m-gram count vectors instead of unigram count vectors only. This will take into account the ordering of the words within a sentence implicitly, although not as strong as the W ER does. 2.1.3 B LEU B LEU (Papineni et al., 2001) is a precision measure based on m-gram count vectors. The precision is modified such that multiple references are combined into a single m-gram count vector, n ˜ e,k := maxr n ˜ e,r,k . Multiple occurrences of an m-gram in the candidate sentence are counted as correct only up to the maximum occurrence count within the reference sentences. Typically, m = 1, . . . , 4. To avoid a bias towards short candidate sentences consisting of “safe guesses” only, sentences shorter than the reference length will be penalized with a brevity penalty. B LEU := lpB LEU · gm m  2.1.1 W ER The word error rate i"
W05-0903,P02-1040,0,\N,Missing
W06-2606,J99-2004,0,0.450807,"point of view, illogical. The main purpose of this paper is to investigate a means of identifying ungrammatical hypotheses from the output of a machine translation system by using grammatical knowledge that expresses syntactic dependencies of words or word groups. We introduce several methods that try to establish this kind of linkage between the words of a hypothesis and, thus, determine its well-formedness, or “fluency”. We perform rescoring experiments that rerank n-best lists according to the presented framework. As methodologies deriving well-formedness of a sentence we use supertagging (Bangalore and Joshi, 1999) with lightweight dependency analysis (LDA)1 (Bangalore, 2000), link grammars (Sleator and Temperley, 1993) and a maximumentropy (ME) based chunk parser (Bender et al., 2003). The former two approaches explicitly model the syntactic dependencies between words. Each hypothesis that contains irregularities, such as broken linkages or non-satisfied dependencies, should be penalized or rejected accordingly. For the ME chunker, the idea is to train n-gram models on the chunk or POS sequences and directly use the log-probability as feature score. In general, these concepts and the underlying program"
W06-2606,P02-1038,1,0.576947,"machine translation, the best transˆ lation eˆI1 = eˆ1 . . . eˆi . . . eˆIˆ of source words f1J = f1 . . . fj . . . fJ is obtained by maximizing the conditional probability ˆ eˆI1 = argmax{P r(eI1 |f1J )} I,eI1 = argmax{P r(f1J |eI1 ) · P r(eI1 )} (1) I,eI1 using Bayes decision rule. The first probability on the right-hand side of the equation denotes the translation model whereas the second is the target language model. An alternative to this classical source-channel approach is the direct modeling of the posterior probability P r(eI1 |f1J ) which is utilized here. Using a log-linear model (Och and Ney, 2002), we obtain P  M I, fJ) exp λ h (e m=1 m m 1 1 P , P r(eI1 |f1J ) = P M 0I0 , f J ) exp λ h (e 1 1 m=1 m m e0 I1 0 (2) where λm are the scaling factors of the models denoted by feature functions hm (·). The denominator represents a normalization factor that depends only on the source sentence f1J . Therefore, we can omit it during the search process, leading to the following decision rule: ) ( M X Iˆ I J eˆ1 = argmax λm hm (e1 , f1 ) (3) I,eI1 m=1 This approach is a generalization of the sourcechannel approach. It has the advantage that additional models h(·) can be easily integrated into"
W06-2606,N04-1021,0,0.212401,"Missing"
W06-2606,P03-1021,0,0.0105045,"factor that depends only on the source sentence f1J . Therefore, we can omit it during the search process, leading to the following decision rule: ) ( M X Iˆ I J eˆ1 = argmax λm hm (e1 , f1 ) (3) I,eI1 m=1 This approach is a generalization of the sourcechannel approach. It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM 1 are trained according to the maximum entropy principle, e.g., using the GIS algorithm. Alternatively, one can train them with respect to the final translation quality measured by an error criterion (Och, 2003). For the results reported in this paper, we optimized the scaling factors with respect to a linear interpolation of word error rate (WER), position-independent word error rate (PER), BLEU and NIST score using the Downhill Simplex algorithm (Press et al., 2002). 3.2 Supertagging/LDA Supertagging (Bangalore and Joshi, 1999) uses the Lexicalized Tree Adjoining Grammar formalism (LTAG) (XTAG Research Group, 2001). Tree Adjoining Grammars incorporate a tree-rewriting formalism using elementary trees that can be combined by two operations, namely substitution and adjunction, to derive more complex"
W06-2606,1993.iwpt-1.22,0,0.388877,"atical hypotheses from the output of a machine translation system by using grammatical knowledge that expresses syntactic dependencies of words or word groups. We introduce several methods that try to establish this kind of linkage between the words of a hypothesis and, thus, determine its well-formedness, or “fluency”. We perform rescoring experiments that rerank n-best lists according to the presented framework. As methodologies deriving well-formedness of a sentence we use supertagging (Bangalore and Joshi, 1999) with lightweight dependency analysis (LDA)1 (Bangalore, 2000), link grammars (Sleator and Temperley, 1993) and a maximumentropy (ME) based chunk parser (Bender et al., 2003). The former two approaches explicitly model the syntactic dependencies between words. Each hypothesis that contains irregularities, such as broken linkages or non-satisfied dependencies, should be penalized or rejected accordingly. For the ME chunker, the idea is to train n-gram models on the chunk or POS sequences and directly use the log-probability as feature score. In general, these concepts and the underlying programs should be robust and fast in order to be able to cope with large amounts of data (as it is the case for n"
W06-2606,takezawa-etal-2002-toward,0,0.0139104,"9 3 552 133 3 597 142 Supplied Data Track Chinese Japanese English 20 000 176 199 198 453 189 927 8 687 9 277 6 870 4 006 4 431 2 888 506 3 630 4 130 3 823 114 61 65 500 3 681 4 131 3 837 83 71 58 Table 1: Corpus statistics after preprocessing. representation, we extract n-best lists as described in (Zens and Ney, 2005). These n-best lists serve as a starting point for our experiments. The methods presented in Section 3 produce scores that are used as additional features for the n-best lists. 4.1 Corpora The experiments are carried out on a subset of the Basic Travel Expression Corpus (BTEC) (Takezawa et al., 2002), as it is used for the supplied data track condition of the IWSLT evaluation campaign. BTEC is a multilingual speech corpus which contains tourism-related sentences similar to those that are found in phrase books. For the supplied data track, the training corpus contains 20 000 sentences. Two test sets, C-Star’03 and IWSLT’04, are available for the language pairs Arabic-English, Chinese-English and JapaneseEnglish. The corpus statistics are shown in Table 1. The average source sentence length is between seven and eight words for all languages. So the task is rather limited and very domain-spe"
W06-2606,W00-0726,0,0.0184116,"hould be a strong indicator of a syntactically correct sentence. Additionally, we added a normalized cost of the matching process which turned out not to be very helpful for rescoring, so it was discarded. 3.4 ME chunking Like the methods described in the two preceding sections, text chunking consists of dividing a text into syntactically correlated non-overlapping groups of words. Figure 3 shows again our example sentence illustrating this task. Chunks are represented as groups of words between square brackets. We employ the 11 chunk types as defined for the CoNLL-2000 shared task (Tjong Kim Sang and Buchholz, 2000). For the experiments, we apply a maximumentropy based tagger which has been successfully evaluated on natural language understanding and named entity recognition (Bender et al., 2003). Within this tool, we directly factorize the posterior probability and determine the corresponding chunk tag for each word of an input sequence. We assume that the decisions depend only on a limited window ei+2 i−2 = ei−2 ...ei+2 around the current word ei and on the two predecessor chunk tags I ci−1 i−2 . In addition, part-of-speech (POS) tags g1 are assigned and incorporated into the model (cf. Figure 3). Thus"
W06-2606,W05-0834,1,0.816737,"ntaining the most likely translation hypotheses is generated during the search process. Out of this compact 44 Arabic Train C-Star’03 IWSLT’04 Sentences Running Words Vocabulary Singletons Sentences Running Words OOVs (Running Words) Sentences Running Words OOVs (Running Words) 180 075 15 371 8 319 3 552 133 3 597 142 Supplied Data Track Chinese Japanese English 20 000 176 199 198 453 189 927 8 687 9 277 6 870 4 006 4 431 2 888 506 3 630 4 130 3 823 114 61 65 500 3 681 4 131 3 837 83 71 58 Table 1: Corpus statistics after preprocessing. representation, we extract n-best lists as described in (Zens and Ney, 2005). These n-best lists serve as a starting point for our experiments. The methods presented in Section 3 produce scores that are used as additional features for the n-best lists. 4.1 Corpora The experiments are carried out on a subset of the Basic Travel Expression Corpus (BTEC) (Takezawa et al., 2002), as it is used for the supplied data track condition of the IWSLT evaluation campaign. BTEC is a multilingual speech corpus which contains tourism-related sentences similar to those that are found in phrase books. For the supplied data track, the training corpus contains 20 000 sentences. Two test"
W06-2606,2005.iwslt-1.20,1,0.861553,"score the n-best hypotheses and simply use the log-probabilities as additional features. In order to adapt our system to the characteristics of the data used, we build POS and chunk n-gram models on the training corpus part. These domainspecific models are also added to the n-best lists. The ME chunking approach does not model explicit syntactic linkages of words. Instead, it incorporates a statistical framework to exploit valid and syntactically coherent groups of words by additionally looking at the word classes. 4 Experiments For the experiments, we use the translation system described in (Zens et al., 2005). Our phrasebased decoder uses several models during search that are interpolated in a log-linear way (as expressed in Eq. 3), such as phrase-based translation models, word-based lexicon models, a language, deletion and simple reordering model and word and phrase penalties. A word graph containing the most likely translation hypotheses is generated during the search process. Out of this compact 44 Arabic Train C-Star’03 IWSLT’04 Sentences Running Words Vocabulary Singletons Sentences Running Words OOVs (Running Words) Sentences Running Words OOVs (Running Words) 180 075 15 371 8 319 3 552 133"
W06-3101,P04-1079,0,0.0149782,"sibilities for improvements. 1 Patrik Lambert† Rafael Banchs† 2 Introduction The evaluation of the generated output is an important issue for all natural language processing (NLP) tasks, especially for machine translation (MT). Automatic evaluation is preferred because human evaluation is a time consuming and expensive task. Related Work There is a number of publications dealing with various automatic evaluation measures for machine translation output, some of them proposing new measures, some proposing improvements and extensions of the existing ones (Doddington, 2002; Papineni et al., 2002; Babych and Hartley, 2004; Matusov et al., 2005). Semi-automatic evaluation measures have been also investigated, for example in (Nießen et al., 2000). An automatic metric which uses base forms and synonyms of the words in order to correlate better to human judgements has been 1 Proceedings of the Workshop on Statistical Machine Translation, pages 1–6, c New York City, June 2006. 2006 Association for Computational Linguistics proposed in (Banerjee and Lavie, 2005). However, error analysis is still a rather unexplored area. A framework for human error analysis and error classification has been proposed in (Vilar et al."
W06-3101,W05-0909,0,0.0366343,"lation output, some of them proposing new measures, some proposing improvements and extensions of the existing ones (Doddington, 2002; Papineni et al., 2002; Babych and Hartley, 2004; Matusov et al., 2005). Semi-automatic evaluation measures have been also investigated, for example in (Nießen et al., 2000). An automatic metric which uses base forms and synonyms of the words in order to correlate better to human judgements has been 1 Proceedings of the Workshop on Statistical Machine Translation, pages 1–6, c New York City, June 2006. 2006 Association for Computational Linguistics proposed in (Banerjee and Lavie, 2005). However, error analysis is still a rather unexplored area. A framework for human error analysis and error classification has been proposed in (Vilar et al., 2006) and a detailed analysis of the obtained results has been carried out. Automatic methods for error analysis to our knowledge have not been studied yet. Many publications propose the use of morphosyntactic information for improving the performance of a statistical machine translation system. Various methods for treating morphological and syntactical differences between German and English are investigated in (Nießen and Ney, 2000; Nie"
W06-3101,N04-4015,0,0.00900173,"has been proposed in (Vilar et al., 2006) and a detailed analysis of the obtained results has been carried out. Automatic methods for error analysis to our knowledge have not been studied yet. Many publications propose the use of morphosyntactic information for improving the performance of a statistical machine translation system. Various methods for treating morphological and syntactical differences between German and English are investigated in (Nießen and Ney, 2000; Nießen and Ney, 2001a; Nießen and Ney, 2001b). Morphological analysis has been used for improving Arabic-English translation (Lee, 2004), for SerbianEnglish translation (Popovi´c et al., 2005) as well as for Czech-English translation (Goldwater and McClosky, 2005). Inflectional morphology of Spanish verbs is dealt with in (Popovi´c and Ney, 2004; de Gispert et al., 2005). To the best of our knowledge, the use of morpho-syntactic information for error analysis of translation output has not been investigated so far. 3 Morpho-syntactic Information and Automatic Evaluation We propose the use of morpho-syntactic information in combination with the automatic evaluation measures WER and PER in order to get more details about the tran"
W06-3101,2005.iwslt-1.19,1,0.729357,"s. 1 Patrik Lambert† Rafael Banchs† 2 Introduction The evaluation of the generated output is an important issue for all natural language processing (NLP) tasks, especially for machine translation (MT). Automatic evaluation is preferred because human evaluation is a time consuming and expensive task. Related Work There is a number of publications dealing with various automatic evaluation measures for machine translation output, some of them proposing new measures, some proposing improvements and extensions of the existing ones (Doddington, 2002; Papineni et al., 2002; Babych and Hartley, 2004; Matusov et al., 2005). Semi-automatic evaluation measures have been also investigated, for example in (Nießen et al., 2000). An automatic metric which uses base forms and synonyms of the words in order to correlate better to human judgements has been 1 Proceedings of the Workshop on Statistical Machine Translation, pages 1–6, c New York City, June 2006. 2006 Association for Computational Linguistics proposed in (Banerjee and Lavie, 2005). However, error analysis is still a rather unexplored area. A framework for human error analysis and error classification has been proposed in (Vilar et al., 2006) and a detailed"
W06-3101,C00-2162,1,0.81769,"Banerjee and Lavie, 2005). However, error analysis is still a rather unexplored area. A framework for human error analysis and error classification has been proposed in (Vilar et al., 2006) and a detailed analysis of the obtained results has been carried out. Automatic methods for error analysis to our knowledge have not been studied yet. Many publications propose the use of morphosyntactic information for improving the performance of a statistical machine translation system. Various methods for treating morphological and syntactical differences between German and English are investigated in (Nießen and Ney, 2000; Nießen and Ney, 2001a; Nießen and Ney, 2001b). Morphological analysis has been used for improving Arabic-English translation (Lee, 2004), for SerbianEnglish translation (Popovi´c et al., 2005) as well as for Czech-English translation (Goldwater and McClosky, 2005). Inflectional morphology of Spanish verbs is dealt with in (Popovi´c and Ney, 2004; de Gispert et al., 2005). To the best of our knowledge, the use of morpho-syntactic information for error analysis of translation output has not been investigated so far. 3 Morpho-syntactic Information and Automatic Evaluation We propose the use of"
W06-3101,2001.mtsummit-papers.45,1,0.834325,"05). However, error analysis is still a rather unexplored area. A framework for human error analysis and error classification has been proposed in (Vilar et al., 2006) and a detailed analysis of the obtained results has been carried out. Automatic methods for error analysis to our knowledge have not been studied yet. Many publications propose the use of morphosyntactic information for improving the performance of a statistical machine translation system. Various methods for treating morphological and syntactical differences between German and English are investigated in (Nießen and Ney, 2000; Nießen and Ney, 2001a; Nießen and Ney, 2001b). Morphological analysis has been used for improving Arabic-English translation (Lee, 2004), for SerbianEnglish translation (Popovi´c et al., 2005) as well as for Czech-English translation (Goldwater and McClosky, 2005). Inflectional morphology of Spanish verbs is dealt with in (Popovi´c and Ney, 2004; de Gispert et al., 2005). To the best of our knowledge, the use of morpho-syntactic information for error analysis of translation output has not been investigated so far. 3 Morpho-syntactic Information and Automatic Evaluation We propose the use of morpho-syntactic infor"
W06-3101,W01-1407,1,0.840883,"05). However, error analysis is still a rather unexplored area. A framework for human error analysis and error classification has been proposed in (Vilar et al., 2006) and a detailed analysis of the obtained results has been carried out. Automatic methods for error analysis to our knowledge have not been studied yet. Many publications propose the use of morphosyntactic information for improving the performance of a statistical machine translation system. Various methods for treating morphological and syntactical differences between German and English are investigated in (Nießen and Ney, 2000; Nießen and Ney, 2001a; Nießen and Ney, 2001b). Morphological analysis has been used for improving Arabic-English translation (Lee, 2004), for SerbianEnglish translation (Popovi´c et al., 2005) as well as for Czech-English translation (Goldwater and McClosky, 2005). Inflectional morphology of Spanish verbs is dealt with in (Popovi´c and Ney, 2004; de Gispert et al., 2005). To the best of our knowledge, the use of morpho-syntactic information for error analysis of translation output has not been investigated so far. 3 Morpho-syntactic Information and Automatic Evaluation We propose the use of morpho-syntactic infor"
W06-3101,niessen-etal-2000-evaluation,1,0.397729,"nt issue for all natural language processing (NLP) tasks, especially for machine translation (MT). Automatic evaluation is preferred because human evaluation is a time consuming and expensive task. Related Work There is a number of publications dealing with various automatic evaluation measures for machine translation output, some of them proposing new measures, some proposing improvements and extensions of the existing ones (Doddington, 2002; Papineni et al., 2002; Babych and Hartley, 2004; Matusov et al., 2005). Semi-automatic evaluation measures have been also investigated, for example in (Nießen et al., 2000). An automatic metric which uses base forms and synonyms of the words in order to correlate better to human judgements has been 1 Proceedings of the Workshop on Statistical Machine Translation, pages 1–6, c New York City, June 2006. 2006 Association for Computational Linguistics proposed in (Banerjee and Lavie, 2005). However, error analysis is still a rather unexplored area. A framework for human error analysis and error classification has been proposed in (Vilar et al., 2006) and a detailed analysis of the obtained results has been carried out. Automatic methods for error analysis to our kno"
W06-3101,P02-1040,0,0.115841,"t`ecnica de Catalunya (UPC), Barcelona, Spain ⊥ ITC-irst, Centro per la Ricerca Scientifica e Tecnologica, Trento, Italy {popovic,ney}@informatik.rwth-aachen.de {gupta,federico}@itc.it {agispert,canton}@gps.tsc.upc.es {lambert,banchs}@gps.tsc.upc.es Abstract A variety of automatic evaluation measures have been proposed and studied over the last years, some of them are shown to be a very useful tool for comparing different systems as well as for evaluating improvements within one system. The most widely used are Word Error Rate (WER), Position Independent Word Error Rate (PER), the BLEU score (Papineni et al., 2002) and the NIST score (Doddington, 2002). However, none of these measures give any details about the nature of translation errors. A relationship between these error measures and the actual errors in the translation outputs is not easy to find. Therefore some analysis of the translation errors is necessary in order to define the main problems and to focus the research efforts. A framework for human error analysis and error classification has been proposed in (Vilar et al., 2006), but like human evaluation, this is also a time consuming task. The goal of this work is to present a framework for au"
W06-3101,popovic-ney-2004-towards,1,0.340303,"Missing"
W06-3101,popovic-ney-2006-pos,1,0.738548,"Missing"
W06-3101,2005.mtsummit-papers.34,1,0.721067,"173 0.15 0.09 2.7 1.7 840 1094 22774 26917 4081 3958 0.14 0.25 2.8 2.6 Table 1: Corpus statistics for the Spanish-English EPPS task (running words include punctuation marks) corpus). The statistics of the corpora can be seen in Table 1. The statistical machine translation system used in this work is based on a log-linear combination of seven different models. The most important ones are phrase based models in both directions, additionally IBM1 models at the phrase level in both directions as well as phrase and length penalty are used. A more detailed description of the system can be found in (Vilar et al., 2005; Zens et al., 2005). 4.3 Experiments The translation experiments have been done in both translation directions on both sizes of the corpus. In order to examine improvements of the baseline system, a new system with POS-based word reorderings of nouns and adjectives as proposed in (Popovi´c and Ney, 2006) is also analysed. Adjectives in the Spanish language are usually placed after the corresponding noun, whereas for English it is the other way round. Therefore, local reorderings of nouns and ad3 WER 34.5 33.5 41.8 38.9 PER 25.5 25.2 30.7 29.5 BLEU 54.7 56.4 43.2 48.5 English→Spanish full base"
W06-3101,vilar-etal-2006-error,1,0.542481,"Missing"
W06-3101,2005.iwslt-1.20,1,0.479674,"7 840 1094 22774 26917 4081 3958 0.14 0.25 2.8 2.6 Table 1: Corpus statistics for the Spanish-English EPPS task (running words include punctuation marks) corpus). The statistics of the corpora can be seen in Table 1. The statistical machine translation system used in this work is based on a log-linear combination of seven different models. The most important ones are phrase based models in both directions, additionally IBM1 models at the phrase level in both directions as well as phrase and length penalty are used. A more detailed description of the system can be found in (Vilar et al., 2005; Zens et al., 2005). 4.3 Experiments The translation experiments have been done in both translation directions on both sizes of the corpus. In order to examine improvements of the baseline system, a new system with POS-based word reorderings of nouns and adjectives as proposed in (Popovi´c and Ney, 2006) is also analysed. Adjectives in the Spanish language are usually placed after the corresponding noun, whereas for English it is the other way round. Therefore, local reorderings of nouns and ad3 WER 34.5 33.5 41.8 38.9 PER 25.5 25.2 30.7 29.5 BLEU 54.7 56.4 43.2 48.5 English→Spanish full baseline reorder 13k bas"
W06-3101,H05-1085,0,\N,Missing
W06-3103,J90-2002,0,0.290655,"In this paper we first explain our statistical machine translation (SMT) system used for testing the impact of the different segmentation methods, then we introduce some preprocessing and normalization tools for Arabic and explain the linguistic motivation beyond them. Afterwards, we present three word segmentation methods, a supervised learning approach, a finite state automaton-based segmentation, and a frequency-based method. In Section 5, the experimental results are presented. Finally, the paper is summarized in Section 6 . This approach is a generalization of the sourcechannel approach (Brown et al., 1990). It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM 1 are trained with respect to the final translation quality measured by an error criterion (Och, 2003). We use a state-of-the-art phrase-based translation system including the following models: an n-gram language model, a phrase translation model and a word-based lexicon model. The latter two models are used for both directions: p(f |e) and p(e|f ). Additionally, we use a word penalty and a phrase penalty. More details about the baseline system can be found in (Zens"
W06-3103,N04-4038,0,0.445565,"fficient alignment. In order to deal with this problem and to improve the performance of statistical machine translation, each word must be decomposed into its parts. In (Larkey et al., 2002) it was already shown that word segmentation for Arabic improves information retrieval. In (Lee et al., 2003) a statistical approach for Arabic word segmentation was presented. It decomposes each word into a sequence of morphemes (prefixes-stem-suffixes), where all possible prefixes and suffixes (not only those we described in Table 1 and 2) are split from the original word. A comparable work was done by (Diab et al., 2004), where a POS tagging method for Arabic is also discussed. As we have access to this tool, we test its impact on the performance of our translation system. In 15 Proceedings of the Workshop on Statistical Machine Translation, pages 15–22, c New York City, June 2006. 2006 Association for Computational Linguistics Table 1: Prefixes handled in this work and their meanings. Prefix Transliteration Meaning ð ¬  È w and f and then k as, like l in order to H. b with, in È@ Al the (Habash and Rambow, 2005) a morphology analyzer was used for the segementation and POS tagging. In contrast to the methods"
W06-3103,W00-0801,0,0.0668553,"Missing"
W06-3103,E03-1076,0,0.0557911,"es and suffixes and their possible combinations. Based on this set, we may have different splitting points for a given compound word. We decide whether and where to split the composite word based on the frequency of different resulting stems and on the frequency of the compound word, e.g. if the compound word has a higher frequency than all possible stems, it will not be split. This simple heuristic harmonizes the corpus by reducing the size of vocabulary, singletons and also unseen words from the test corpus. This method is very similar to the method used for splitting German compound words (Koehn and Knight, 2003). 4.3 Finite State Automaton-Based Approach (FSA) To segment Arabic words into prefixes, stem and one suffix, we implemented two finite state automata. One for stripping the prefixes and the other for the suffixes. Then, we append the suffix automaton to the other one for stripping prefixes. Figure 1 shows the finite state automaton for stripping all possible prefix combinations. We add the prefix s ( ), which changes the verb tense to the future, to the set of prefixes which must be stripped (see table 1). This prefix can only be combined with w and f. Our motivation is that the future tense"
W06-3103,P03-1021,0,0.0240731,"stic motivation beyond them. Afterwards, we present three word segmentation methods, a supervised learning approach, a finite state automaton-based segmentation, and a frequency-based method. In Section 5, the experimental results are presented. Finally, the paper is summarized in Section 6 . This approach is a generalization of the sourcechannel approach (Brown et al., 1990). It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM 1 are trained with respect to the final translation quality measured by an error criterion (Och, 2003). We use a state-of-the-art phrase-based translation system including the following models: an n-gram language model, a phrase translation model and a word-based lexicon model. The latter two models are used for both directions: p(f |e) and p(e|f ). Additionally, we use a word penalty and a phrase penalty. More details about the baseline system can be found in (Zens and Ney, 2004; Zens et al., 2005). 2 3 Baseline SMT System In statistical machine translation, we are given a source language sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language sentence eI1 = e1"
W06-3103,P02-1040,0,0.112269,"NIST task, we make use of the NIST 2002 evaluation set as a development set and NIST 2004 evaluation set as a test set. Because the test set contains four references for each senence we decided to use only the first four references of the development set for the optimization and evaluation. In the BTEC task, C-Star’03 and IWSLT’04 copora are considered as development and test sets, respectively. 5.2 Evaluation Metrics The commonly used criteria to evaluate the translation results in the machine translation community are: WER (word error rate), PER (positionindependent word error rate), BLEU (Papineni et al., 2002), and NIST (Doddington, 2002). The four criteria are computed with respect to multiple references. The number of reference translations per source sentence varies from 4 to 16 references. The evaluation is case-insensitive for BTEC and casesensitive for NIST task. As the BLEU and NIST scores measure accuracy, higher scores are better. 5.3 Translation Results To study the impact of different segmentation methods on the translation quality, we apply different word segmentation methods to the Arabic part of the BTEC and NIST corpora. Then, we make use of the 19 phrase-based machine translation sy"
W06-3103,takezawa-etal-2002-toward,0,0.0230295,"above to generate negative properties which avoid the corresponding kind of splitting. If a property and its negation belong to the same word then the property is removed and only the negation is considered. At the end each word is split corresponding to the properties it is marked with. 5 5.1 Experimental Results Corpus Statistics The experiments were carried out on two tasks: the corpora of the Arabic-English NIST task, which contain news articles and UN reports, and the Arabic-English corpus of the Basic Travel Expression Corpus (BTEC) task, which consists of typical travel domain phrases (Takezawa et al., 2002). The corpus statistics of the NIST and BTEC corpora are shown in Table 3 and 5. The statistics of the news part of NIST corpus, consisting of the Ummah, ATB, ANEWS1 and eTIRR corpora, is shown in Table 4. In the NIST task, we make use of the NIST 2002 evaluation set as a development set and NIST 2004 evaluation set as a test set. Because the test set contains four references for each senence we decided to use only the first four references of the development set for the optimization and evaluation. In the BTEC task, C-Star’03 and IWSLT’04 copora are considered as development and test sets, re"
W06-3103,P03-1051,0,0.142211,". The reason why we omit them is that they do not have their own meaning. The impact of Arabic morphology is that the vocabulary size and the number of singletons can be dramatically high, i.e. the Arabic words are not seen often enough to be learned by statistical machine translation models. This can lead to an inefficient alignment. In order to deal with this problem and to improve the performance of statistical machine translation, each word must be decomposed into its parts. In (Larkey et al., 2002) it was already shown that word segmentation for Arabic improves information retrieval. In (Lee et al., 2003) a statistical approach for Arabic word segmentation was presented. It decomposes each word into a sequence of morphemes (prefixes-stem-suffixes), where all possible prefixes and suffixes (not only those we described in Table 1 and 2) are split from the original word. A comparable work was done by (Diab et al., 2004), where a POS tagging method for Arabic is also discussed. As we have access to this tool, we test its impact on the performance of our translation system. In 15 Proceedings of the Workshop on Statistical Machine Translation, pages 15–22, c New York City, June 2006. 2006 Associatio"
W06-3103,N04-1033,1,0.853064,"990). It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM 1 are trained with respect to the final translation quality measured by an error criterion (Och, 2003). We use a state-of-the-art phrase-based translation system including the following models: an n-gram language model, a phrase translation model and a word-based lexicon model. The latter two models are used for both directions: p(f |e) and p(e|f ). Additionally, we use a word penalty and a phrase penalty. More details about the baseline system can be found in (Zens and Ney, 2004; Zens et al., 2005). 2 3 Baseline SMT System In statistical machine translation, we are given a source language sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language sentence eI1 = e1 . . . ei . . . eI . Among all possible target language sentences, we will choose the sentence with the highest probability: ˆ eˆI1 = argmax  I,eI1 P r(eI1 |f1J ) (1) 0 (2) The denominator represents a normalization factor that depends only on the source sentence f1J . Therefore, we can omit it during the search process. As a decision rule, we obtain: ( M ) X Iˆ I J eˆ1 = argmax"
W06-3103,N04-4015,0,0.0587257,"all diacritics. After segmenting the text, the size of the sentences increases rapidly, where the number of the stripped article Al is very high. Not every article in an Arabic sentence matches to an article in the target language. One of the reasons is that the adjective in Arabic gets an article if the word it describes is definite. So, if a word has the prefix Al, then its adjective will also have Al as a prefix. In order to reduce the sentence size we decide to remove all these articles that are supposed to be attached to an adjective. Another way for determiner deletion is described in (Lee, 2004). 4  Supervised Learning Approach (SL) (Diab et al., 2004) propose solutions to word segmentation and POS Tagging of Arabic text. For the purpose of training the Arabic TreeBank is used, which is an Arabic corpus containing news articles of the newswire agency AFP. In the first step the text must be transliterated to the Buckwalter transliteration, which is a one-to-one mapping to ASCII characters. In the second step it will be segmented and tokenized. In the third step a partial lemmatization is done. Finally a POS tagging is performed. We will 17 test the impact of the step 3 (segmentation"
W06-3103,2005.iwslt-1.20,1,0.413015,"antage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM 1 are trained with respect to the final translation quality measured by an error criterion (Och, 2003). We use a state-of-the-art phrase-based translation system including the following models: an n-gram language model, a phrase translation model and a word-based lexicon model. The latter two models are used for both directions: p(f |e) and p(e|f ). Additionally, we use a word penalty and a phrase penalty. More details about the baseline system can be found in (Zens and Ney, 2004; Zens et al., 2005). 2 3 Baseline SMT System In statistical machine translation, we are given a source language sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language sentence eI1 = e1 . . . ei . . . eI . Among all possible target language sentences, we will choose the sentence with the highest probability: ˆ eˆI1 = argmax  I,eI1 P r(eI1 |f1J ) (1) 0 (2) The denominator represents a normalization factor that depends only on the source sentence f1J . Therefore, we can omit it during the search process. As a decision rule, we obtain: ( M ) X Iˆ I J eˆ1 = argmax λm hm (e1 , f1 ) (3)"
W06-3103,P02-1038,1,0.244803,"efore, we can omit it during the search process. As a decision rule, we obtain: ( M ) X Iˆ I J eˆ1 = argmax λm hm (e1 , f1 ) (3) I,eI1 3.1 Tokenizer As for other languages, the corpora must be first tokenized. Here words and punctuations (except abbreviation) must be separated. Another criterion is that Arabic has some characters that appear only at the end of a word. We use this criterion to separate words that are wrongly attached to each other. 3.2 Normalization and Simplification The posterior probability P r(eI1 |f1J ) is modeled directly using a log-linear combination of several models (Och and Ney, 2002): P  M I, fJ) exp λ h (e m=1 m m 1 1 P  P r(eI1 |f1J ) = P M 0I0 , f J ) exp λ h (e m m 1 1 m=1 e0 I1 Preprocessing and Normalization Tools m=1 16 The Arabic written language does not contain vowels, instead diacritics are used to define the pronunciation of a word, where a diacritic is written under or above each character in the word. Usually these diacritics are omitted, which increases the ambiguity of a word. In this case, resolving the ambiguity of a word is only dependent on the context. Sometimes, the authors write a diacritic on a word to help the reader and give him a hint which"
W06-3103,P05-1071,0,\N,Missing
W06-3108,J96-1002,0,0.0212931,"ails of this reordering model. The classes our model predicts will be defined in Section 4.2. Then, the feature functions will be defined right phrase orientation target positions target positions left phrase orientation i j’ i j j source positions j’ source positions Figure 1: Illustration of the phrase orientation. in Section 4.3. The training criterion and the training events of the maximum entropy model will be described in Section 4.4. Then, the reordering model has the form 4.2 A well-founded framework for directly modeling the probability p(cj,j ′ |f1J , eI1 , i, j) is maximum entropy (Berger et al., 1996). In this framework, we have a set of N feature functions hn (f1J , eI1 , i, j, cj,j ′ ), n = 1, . . . , N . Each feature function hn is weighted with a factor λn . The resulting model is: Class Definition Ideally, this model predicts the start position of the next phrase. But as predicting the exact position is rather difficult, we group the possible start positions into classes. In the simplest case, we use only two classes. One class for the positions to the left and one class for the positions to the right. As a refinement, we can use four classes instead of two: 1) one position to the lef"
W06-3108,J90-2002,0,0.432383,". . fj . . . fJ , which is to be translated into a target language sentence eI1 = e1 . . . ei . . . eI . Among all possible target language sentences, we will choose the sentence with the highest probability: ˆ I,eI1  P r(eI1 |f1J ) (1) The posterior probability P r(eI1 |f1J ) is modeled directly using a log-linear combination of several models (Och and Ney, 2002): P  M I, fJ) exp λ h (e m m 1 1 m=1 P  P r(eI1 |f1J ) = P M ′I ′ , f J ) exp λ h (e m m 1 1 m=1 I ′ ,e′ I1 ˆ eˆI1 = argmax I,eI1 M X ) λm hm (eI1 , f1J ) m=1 (3) This approach is a generalization of the sourcechannel approach (Brown et al., 1990). It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM 1 are trained with respect to the final translation quality measured by an error criterion (Och, 2003). We use a state-of-the-art phrase-based translation system (Zens and Ney, 2004; Zens et al., 2005) including the following models: an n-gram language model, a phrase translation model and a word-based lexicon model. The latter two models are used for both directions: p(f |e) and p(e|f ). Additionally, we use a word penalty and a phrase penalty. The reordering model"
W06-3108,P03-1021,0,0.0328867,"e posterior probability P r(eI1 |f1J ) is modeled directly using a log-linear combination of several models (Och and Ney, 2002): P  M I, fJ) exp λ h (e m m 1 1 m=1 P  P r(eI1 |f1J ) = P M ′I ′ , f J ) exp λ h (e m m 1 1 m=1 I ′ ,e′ I1 ˆ eˆI1 = argmax I,eI1 M X ) λm hm (eI1 , f1J ) m=1 (3) This approach is a generalization of the sourcechannel approach (Brown et al., 1990). It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM 1 are trained with respect to the final translation quality measured by an error criterion (Och, 2003). We use a state-of-the-art phrase-based translation system (Zens and Ney, 2004; Zens et al., 2005) including the following models: an n-gram language model, a phrase translation model and a word-based lexicon model. The latter two models are used for both directions: p(f |e) and p(e|f ). Additionally, we use a word penalty and a phrase penalty. The reordering model of the baseline system is distancebased, i.e. it assigns costs based on the distance from the end position of a phrase to the start position of the next phrase. This very simple reordering model is widely used, for instance in (Och"
W06-3108,P02-1040,0,0.1059,"irable properties of an appropriate reordering model. The main point is that these are fulfilled not only on the training data, but on unseen test data. There seems to be no overfitting problem. In Table 5, we present the results for four orientation classes. The final error rates are a factor 2-4 larger than for two orientation classes. Despite that we observe the same tendencies as for two orientation classes. Again, using more features always helps to improve the performance. 5.3 Translation Results For the translation experiments on the BTEC task, we report the two accuracy measures BLEU (Papineni et al., 2002) and NIST (Doddington, 2002) as well as the two error rates: word error rate (WER) and position-independent word error rate (PER). These criteria are computed with respect to 16 references. In Table 6, we show the translation results for the BTEC task. In these experiments, the reordering model uses two orientation classes, i.e. it predicts either a left or a right orientation. The features for the maximum-entropy based reordering model are based on the source and target language words within a window of one. The word-class based features are not used for the translation experiments. The maxim"
W06-3108,2005.iwslt-1.8,0,0.383621,"ed corpus. Additionally, we show improved translation performance using these reordering models compared to a state-of-the-art baseline system. 1 Introduction In recent evaluations, phrase-based statistical machine translation systems have achieved good performance. Still the fluency of the machine translation output leaves much to desire. One reason is that most phrase-based systems use a very simple reordering model. Usually, the costs for phrase movements are linear in the distance, e.g. see (Och et al., 1999; Koehn, 2004; Zens et al., 2005). Recently, in (Tillmann and Zhang, 2005) and in (Koehn et al., 2005), a reordering model has been described that tries to predict the orientation of a phrase, i.e. it answers the question ’should the next phrase be to the left or to the right of the current phrase?’ This phrase orientation probability is conditioned on the current source and target phrase and relative frequencies are used to estimate the probabilities. We adopt the idea of predicting the orientation, but we propose to use a maximum-entropy based model. The relative-frequency based approach may suffer from the data sparseness problem, because most of the phrases occur only once in the training"
W06-3108,koen-2004-pharaoh,0,0.668221,"odels as well as the contribution of the individual feature types on a word-aligned corpus. Additionally, we show improved translation performance using these reordering models compared to a state-of-the-art baseline system. 1 Introduction In recent evaluations, phrase-based statistical machine translation systems have achieved good performance. Still the fluency of the machine translation output leaves much to desire. One reason is that most phrase-based systems use a very simple reordering model. Usually, the costs for phrase movements are linear in the distance, e.g. see (Och et al., 1999; Koehn, 2004; Zens et al., 2005). Recently, in (Tillmann and Zhang, 2005) and in (Koehn et al., 2005), a reordering model has been described that tries to predict the orientation of a phrase, i.e. it answers the question ’should the next phrase be to the left or to the right of the current phrase?’ This phrase orientation probability is conditioned on the current source and target phrase and relative frequencies are used to estimate the probabilities. We adopt the idea of predicting the orientation, but we propose to use a maximum-entropy based model. The relative-frequency based approach may suffer from"
W06-3108,H05-1021,0,0.0974603,"eordering model: the costs 55 Proceedings of the Workshop on Statistical Machine Translation, pages 55–63, c New York City, June 2006. 2006 Association for Computational Linguistics for phrase movements are linear in the distance. This approach is also used in the publicly available Pharaoh decoder (Koehn, 2004). The idea of predicting the orientation is adopted from (Tillmann and Zhang, 2005) and (Koehn et al., 2005). Here, we use the maximum entropy principle to combine a variety of different features. A reordering model in the framework of weighted finite state transducers is described in (Kumar and Byrne, 2005). There, the movements are defined at the phrase level, but the window for reordering is very limited. The parameters are estimated using an EM-style method. None of these methods try to generalize from the words or phrases by using word classes or part-ofspeech information. The approach presented here has some resemblance to the bracketing transduction grammars (BTG) of (Wu, 1997), which have been applied to a phrase-based machine translation system in (Zens et al., 2004). The difference is that, here, we do not constrain the phrase reordering. Nevertheless the inverted/monotone concatenation"
W06-3108,P02-1038,1,0.276814,"the phrase reordering. Nevertheless the inverted/monotone concatenation of phrases in the BTG framework is similar to the left/right phrase orientation used here. In statistical machine translation, we are given a source language sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language sentence eI1 = e1 . . . ei . . . eI . Among all possible target language sentences, we will choose the sentence with the highest probability: ˆ I,eI1  P r(eI1 |f1J ) (1) The posterior probability P r(eI1 |f1J ) is modeled directly using a log-linear combination of several models (Och and Ney, 2002): P  M I, fJ) exp λ h (e m m 1 1 m=1 P  P r(eI1 |f1J ) = P M ′I ′ , f J ) exp λ h (e m m 1 1 m=1 I ′ ,e′ I1 ˆ eˆI1 = argmax I,eI1 M X ) λm hm (eI1 , f1J ) m=1 (3) This approach is a generalization of the sourcechannel approach (Brown et al., 1990). It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM 1 are trained with respect to the final translation quality measured by an error criterion (Och, 2003). We use a state-of-the-art phrase-based translation system (Zens and Ney, 2004; Zens et al., 2005) including the fol"
W06-3108,J03-1002,1,0.00801402,"there is only a single optimum and no convergence problems occur. To train the model parameters λN 1 , we use the Generalized Iterative Scaling (GIS) algorithm (Darroch and Ratcliff, 1972). In practice, the training procedure tends to result in an overfitted model. To avoid overfitting, (Chen and Rosenfeld, 1999) have suggested a smoothing method where a Gaussian prior distribution of the parameters is assumed. This method tried to avoid very large lambda values and prevents features that occur only once for a specific class from getting a value of infinity. We train IBM Model 4 with GIZA++ (Och and Ney, 2003) in both translation directions. Then the alignments are symmetrized using a refined heuristic as described in (Och and Ney, 2003). This wordaligned bilingual corpus is used to train the reordering model parameters, i.e. the feature weights λN 1 . Each alignment link defines an event for the maximum entropy training. An exception are the oneto-many alignments, i.e. one source word is aligned to multiple target words. In this case, only the topmost alignment link is considered because the other ones cannot occur at a phrase boundary. Many-toone and many-to-many alignments are handled in a simil"
W06-3108,W99-0604,1,0.683914,"f the reordering models as well as the contribution of the individual feature types on a word-aligned corpus. Additionally, we show improved translation performance using these reordering models compared to a state-of-the-art baseline system. 1 Introduction In recent evaluations, phrase-based statistical machine translation systems have achieved good performance. Still the fluency of the machine translation output leaves much to desire. One reason is that most phrase-based systems use a very simple reordering model. Usually, the costs for phrase movements are linear in the distance, e.g. see (Och et al., 1999; Koehn, 2004; Zens et al., 2005). Recently, in (Tillmann and Zhang, 2005) and in (Koehn et al., 2005), a reordering model has been described that tries to predict the orientation of a phrase, i.e. it answers the question ’should the next phrase be to the left or to the right of the current phrase?’ This phrase orientation probability is conditioned on the current source and target phrase and relative frequencies are used to estimate the probabilities. We adopt the idea of predicting the orientation, but we propose to use a maximum-entropy based model. The relative-frequency based approach may"
W06-3108,E99-1010,0,0.0739474,"Missing"
W06-3108,takezawa-etal-2002-toward,0,0.0187671,". This wordaligned bilingual corpus is used to train the reordering model parameters, i.e. the feature weights λN 1 . Each alignment link defines an event for the maximum entropy training. An exception are the oneto-many alignments, i.e. one source word is aligned to multiple target words. In this case, only the topmost alignment link is considered because the other ones cannot occur at a phrase boundary. Many-toone and many-to-many alignments are handled in a similar way. 5 Experimental Results 5.1 Statistics The experiments were carried out on the Basic Travel Expression Corpus (BTEC) task (Takezawa et al., 2002). This is a multilingual speech corpus which contains tourism-related sentences similar to those that are found in phrase books. We use the Arabic-English, the Chinese-English and the Japanese-English data. The corpus statistics are shown in Table 1. As the BTEC is a rather clean corpus, the preprocessing consisted mainly of tokenization, i.e., separating punctuation marks from words. Additionally, we replaced contractions such as it’s or I’m in the English corpus and we removed the case information. For Arabic, we removed the diacritics and we split common prefixes: Al, w, f, b, l. There was"
W06-3108,P05-1069,0,0.14547,"dual feature types on a word-aligned corpus. Additionally, we show improved translation performance using these reordering models compared to a state-of-the-art baseline system. 1 Introduction In recent evaluations, phrase-based statistical machine translation systems have achieved good performance. Still the fluency of the machine translation output leaves much to desire. One reason is that most phrase-based systems use a very simple reordering model. Usually, the costs for phrase movements are linear in the distance, e.g. see (Och et al., 1999; Koehn, 2004; Zens et al., 2005). Recently, in (Tillmann and Zhang, 2005) and in (Koehn et al., 2005), a reordering model has been described that tries to predict the orientation of a phrase, i.e. it answers the question ’should the next phrase be to the left or to the right of the current phrase?’ This phrase orientation probability is conditioned on the current source and target phrase and relative frequencies are used to estimate the probabilities. We adopt the idea of predicting the orientation, but we propose to use a maximum-entropy based model. The relative-frequency based approach may suffer from the data sparseness problem, because most of the phrases occu"
W06-3108,J97-3002,0,0.301989,"and (Koehn et al., 2005). Here, we use the maximum entropy principle to combine a variety of different features. A reordering model in the framework of weighted finite state transducers is described in (Kumar and Byrne, 2005). There, the movements are defined at the phrase level, but the window for reordering is very limited. The parameters are estimated using an EM-style method. None of these methods try to generalize from the words or phrases by using word classes or part-ofspeech information. The approach presented here has some resemblance to the bracketing transduction grammars (BTG) of (Wu, 1997), which have been applied to a phrase-based machine translation system in (Zens et al., 2004). The difference is that, here, we do not constrain the phrase reordering. Nevertheless the inverted/monotone concatenation of phrases in the BTG framework is similar to the left/right phrase orientation used here. In statistical machine translation, we are given a source language sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language sentence eI1 = e1 . . . ei . . . eI . Among all possible target language sentences, we will choose the sentence with the highest probabili"
W06-3108,N04-1033,1,0.81184,"linear combination of several models (Och and Ney, 2002): P  M I, fJ) exp λ h (e m m 1 1 m=1 P  P r(eI1 |f1J ) = P M ′I ′ , f J ) exp λ h (e m m 1 1 m=1 I ′ ,e′ I1 ˆ eˆI1 = argmax I,eI1 M X ) λm hm (eI1 , f1J ) m=1 (3) This approach is a generalization of the sourcechannel approach (Brown et al., 1990). It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM 1 are trained with respect to the final translation quality measured by an error criterion (Och, 2003). We use a state-of-the-art phrase-based translation system (Zens and Ney, 2004; Zens et al., 2005) including the following models: an n-gram language model, a phrase translation model and a word-based lexicon model. The latter two models are used for both directions: p(f |e) and p(e|f ). Additionally, we use a word penalty and a phrase penalty. The reordering model of the baseline system is distancebased, i.e. it assigns costs based on the distance from the end position of a phrase to the start position of the next phrase. This very simple reordering model is widely used, for instance in (Och et al., 1999; Koehn, 2004; Zens et al., 2005). 4 The Reordering Model 3 Baseli"
W06-3108,C04-1030,1,0.587047,"riety of different features. A reordering model in the framework of weighted finite state transducers is described in (Kumar and Byrne, 2005). There, the movements are defined at the phrase level, but the window for reordering is very limited. The parameters are estimated using an EM-style method. None of these methods try to generalize from the words or phrases by using word classes or part-ofspeech information. The approach presented here has some resemblance to the bracketing transduction grammars (BTG) of (Wu, 1997), which have been applied to a phrase-based machine translation system in (Zens et al., 2004). The difference is that, here, we do not constrain the phrase reordering. Nevertheless the inverted/monotone concatenation of phrases in the BTG framework is similar to the left/right phrase orientation used here. In statistical machine translation, we are given a source language sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language sentence eI1 = e1 . . . ei . . . eI . Among all possible target language sentences, we will choose the sentence with the highest probability: ˆ I,eI1  P r(eI1 |f1J ) (1) The posterior probability P r(eI1 |f1J ) is modeled directly"
W06-3108,2005.iwslt-1.20,1,0.601289,"as the contribution of the individual feature types on a word-aligned corpus. Additionally, we show improved translation performance using these reordering models compared to a state-of-the-art baseline system. 1 Introduction In recent evaluations, phrase-based statistical machine translation systems have achieved good performance. Still the fluency of the machine translation output leaves much to desire. One reason is that most phrase-based systems use a very simple reordering model. Usually, the costs for phrase movements are linear in the distance, e.g. see (Och et al., 1999; Koehn, 2004; Zens et al., 2005). Recently, in (Tillmann and Zhang, 2005) and in (Koehn et al., 2005), a reordering model has been described that tries to predict the orientation of a phrase, i.e. it answers the question ’should the next phrase be to the left or to the right of the current phrase?’ This phrase orientation probability is conditioned on the current source and target phrase and relative frequencies are used to estimate the probabilities. We adopt the idea of predicting the orientation, but we propose to use a maximum-entropy based model. The relative-frequency based approach may suffer from the data sparseness"
W06-3108,2005.iwslt-1.1,0,\N,Missing
W06-3110,C04-1046,0,0.060751,"Missing"
W06-3110,J90-2002,0,0.360601,"hest probability: ˆ eˆI1 = argmax I,eI1  P r(eI1 |f1J ) (1) The posterior probability P r(eI1 |f1J ) is modeled directly using a log-linear combination of several models (Och and Ney, 2002): P  M I, fJ) exp λ h (e m m 1 1 m=1 P  P r(eI1 |f1J ) = P M J ′I ′ exp m=1 λm hm (e 1 , f1 ) ′ I ′ ,e′ I1 (2) The denominator is a normalization factor that depends only on the source sentence f1J . Therefore, we can omit it during the search process. As a decision rule, we obtain: ) ( M X ˆ λm hm (eI1 , f1J ) (3) eˆI1 = argmax I,eI1 m=1 This approach is a generalization of the sourcechannel approach (Brown et al., 1990). It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM 1 are trained with respect to the final translation quality measured by an error criterion (Och, 2003). We use a state-of-the-art phrase-based translation system as described in (Zens and Ney, 2004; Zens et al., 2005). The baseline system includes the following models: an n-gram language model, a phrase translation model and a word-based lexicon model. The latter two models are used for both directions: p(f |e) and p(e|f ). Additionally, we use a word penalty and a"
W06-3110,koen-2004-pharaoh,0,0.14022,"., 2003). The outcome was that the confidence measures did not result in improvements of the translation quality measured with the BLEU and NIST scores. Here, we focus on how the ideas and methods commonly used for confidence estimation can be adapted and/or extended to improve translation quality. So far, always word-level posterior probabilities were used. Here, we will generalize this idea to ngrams. In addition to the n-gram posterior probabilities, we introduce a sentence-length model based on posterior probabilities. The common phrasebased translation systems, such as (Och et al., 1999; Koehn, 2004), do not use an explicit sentence length model. Only the simple word penalty goes into that direction. It can be adjusted to prefer longer or shorter translations. Here, we will explicitly model the sentence length. The novel contributions of this work are to introduce n-gram posterior probabilities and sentence length posterior probabilities. Using these methods, we achieve significant improvements of translation quality. The remaining part of this paper is structured as follows: first, we will briefly describe the baseline system, which is a state-of-the-art phrase-based statistical machine"
W06-3110,P02-1038,1,0.509641,"orkshop on Statistical Machine Translation, pages 72–77, c New York City, June 2006. 2006 Association for Computational Linguistics 2 Baseline System In statistical machine translation, we are given a source language sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language sentence eI1 = e1 . . . ei . . . eI . Among all possible target language sentences, we will choose the sentence with the highest probability: ˆ eˆI1 = argmax I,eI1  P r(eI1 |f1J ) (1) The posterior probability P r(eI1 |f1J ) is modeled directly using a log-linear combination of several models (Och and Ney, 2002): P  M I, fJ) exp λ h (e m m 1 1 m=1 P  P r(eI1 |f1J ) = P M J ′I ′ exp m=1 λm hm (e 1 , f1 ) ′ I ′ ,e′ I1 (2) The denominator is a normalization factor that depends only on the source sentence f1J . Therefore, we can omit it during the search process. As a decision rule, we obtain: ) ( M X ˆ λm hm (eI1 , f1J ) (3) eˆI1 = argmax I,eI1 m=1 This approach is a generalization of the sourcechannel approach (Brown et al., 1990). It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM 1 are trained with respect to the final t"
W06-3110,W99-0604,1,0.688342,"f, is (Blatz et al., 2003). The outcome was that the confidence measures did not result in improvements of the translation quality measured with the BLEU and NIST scores. Here, we focus on how the ideas and methods commonly used for confidence estimation can be adapted and/or extended to improve translation quality. So far, always word-level posterior probabilities were used. Here, we will generalize this idea to ngrams. In addition to the n-gram posterior probabilities, we introduce a sentence-length model based on posterior probabilities. The common phrasebased translation systems, such as (Och et al., 1999; Koehn, 2004), do not use an explicit sentence length model. Only the simple word penalty goes into that direction. It can be adjusted to prefer longer or shorter translations. Here, we will explicitly model the sentence length. The novel contributions of this work are to introduce n-gram posterior probabilities and sentence length posterior probabilities. Using these methods, we achieve significant improvements of translation quality. The remaining part of this paper is structured as follows: first, we will briefly describe the baseline system, which is a state-of-the-art phrase-based statis"
W06-3110,N04-1021,0,0.0492858,"tence length model. Only the simple word penalty goes into that direction. It can be adjusted to prefer longer or shorter translations. Here, we will use the posterior probability of a specific target sentence length I as length model: X p(I|f1J ) = p(eI1 |f1J ) (6) eI1 Note that the sum is carried out only over target sentences eI1 with the a specific length I. Again, the candidate target language sentences are limited to an N -best list. 5 Rescoring/Reranking A straightforward application of the posterior probabilities is to use them as additional features in a rescoring/reranking approach (Och et al., 2004). The use of N -best lists in machine translation has several advantages. It alleviates the effects of the huge search space which is represented in word graphs by using a compact excerpt of the N best hypotheses generated by the system. N -best lists are suitable for easily applying several rescoring techniques since the hypotheses are already fully generated. In comparison, word graph rescoring techniques need specialized tools which can traverse the graph accordingly. The n-gram posterior probabilities can be used similar to an n-gram language model: We use a linear interpolation with weigh"
W06-3110,P03-1021,0,0.0966035,"|f1J ) = P M J ′I ′ exp m=1 λm hm (e 1 , f1 ) ′ I ′ ,e′ I1 (2) The denominator is a normalization factor that depends only on the source sentence f1J . Therefore, we can omit it during the search process. As a decision rule, we obtain: ) ( M X ˆ λm hm (eI1 , f1J ) (3) eˆI1 = argmax I,eI1 m=1 This approach is a generalization of the sourcechannel approach (Brown et al., 1990). It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM 1 are trained with respect to the final translation quality measured by an error criterion (Och, 2003). We use a state-of-the-art phrase-based translation system as described in (Zens and Ney, 2004; Zens et al., 2005). The baseline system includes the following models: an n-gram language model, a phrase translation model and a word-based lexicon model. The latter two models are used for both directions: p(f |e) and p(e|f ). Additionally, we use a word penalty and a phrase penalty. 3 N-Gram Posterior Probabilities The idea is similar to the word posterior probabilities: we sum the sentence posterior probabilities for each occurrence of an n-gram. 73 Let δ(·, ·) denote the Kronecker function. Th"
W06-3110,P02-1040,0,0.121019,"art of the bilingual training cori J pus and additional monolingual English data from C(ei−n+1 , f1 ) J (8) p(ei |ei−1 the GigaWord corpus. The total amount of lani−n+1 , f1 ) = i−1 C(ei−n+1 , f1J ) guage model training data was about 600M running Note that the models do not require smoothing as words. We use a fourgram language model with long as they are applied to the same N -best list they modified Kneser-Ney smoothing as implemented in the SRILM toolkit (Stolcke, 2002). are trained on. To measure the translation quality, we use the If the models are used for unseen sentences, BLEU score (Papineni et al., 2002) and the NIST smoothing is important to avoid zero probabilities. We use a linear interpolation with weights αn and score (Doddington, 2002). The BLEU score is the the smoothed (n − 1)-gram model as generalized geometric mean of the n-gram precision in combination with a brevity penalty for too short sendistribution. tences. The NIST score is the arithmetic mean of i J) C(e , f a weighted n-gram precision in combination with a i−n+1 1 J pn (ei |ei−1 (9) i−n+1 , f1 ) = αn · i−1 J brevity penalty for too short sentences. Both scores C(ei−n+1 , f1 ) are computed case-sensitive with respect to fou"
W06-3110,2005.eamt-1.35,1,0.757443,"nce length posterior probabilities and do a third search pass, etc.. 7.2 Computer Assisted Translation In the computer assisted translation (CAT) framework, the goal is to improve the productivity of human translators. The machine translation system takes not only the current source language sentence but also the already typed partial translation into account. Based on this information, the system suggest completions of the sentence. Word-level posterior probabilities have been used to select the most appropriate completion of the system, for more details see e.g. (Gandrabur and Foster, 2003; Ueffing and Ney, 2005). The n-gram based posterior probabilities as described in this work, might be better suited for this task as they explicitly model the dependency on the previous words, i.e. the given prefix. 8 Conclusions We introduced n-gram and sentence length posterior probabilities and demonstrated their usefulness for rescoring purposes. We performed systematic experiments on the Chinese-English NIST task and showed significant improvements of the translation quality. The improvements were consistent among several evaluation sets. An interesting property of the introduced methods is that they do not req"
W06-3110,2003.mtsummit-papers.52,1,0.467669,"Missing"
W06-3110,N04-1033,1,0.268558,"rmalization factor that depends only on the source sentence f1J . Therefore, we can omit it during the search process. As a decision rule, we obtain: ) ( M X ˆ λm hm (eI1 , f1J ) (3) eˆI1 = argmax I,eI1 m=1 This approach is a generalization of the sourcechannel approach (Brown et al., 1990). It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM 1 are trained with respect to the final translation quality measured by an error criterion (Och, 2003). We use a state-of-the-art phrase-based translation system as described in (Zens and Ney, 2004; Zens et al., 2005). The baseline system includes the following models: an n-gram language model, a phrase translation model and a word-based lexicon model. The latter two models are used for both directions: p(f |e) and p(e|f ). Additionally, we use a word penalty and a phrase penalty. 3 N-Gram Posterior Probabilities The idea is similar to the word posterior probabilities: we sum the sentence posterior probabilities for each occurrence of an n-gram. 73 Let δ(·, ·) denote the Kronecker function. Then, we define the fractional count C(en1 , f1J ) of an ngram en1 for a source sentence f1J as:"
W06-3110,2005.iwslt-1.20,1,0.725103,"hat depends only on the source sentence f1J . Therefore, we can omit it during the search process. As a decision rule, we obtain: ) ( M X ˆ λm hm (eI1 , f1J ) (3) eˆI1 = argmax I,eI1 m=1 This approach is a generalization of the sourcechannel approach (Brown et al., 1990). It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM 1 are trained with respect to the final translation quality measured by an error criterion (Och, 2003). We use a state-of-the-art phrase-based translation system as described in (Zens and Ney, 2004; Zens et al., 2005). The baseline system includes the following models: an n-gram language model, a phrase translation model and a word-based lexicon model. The latter two models are used for both directions: p(f |e) and p(e|f ). Additionally, we use a word penalty and a phrase penalty. 3 N-Gram Posterior Probabilities The idea is similar to the word posterior probabilities: we sum the sentence posterior probabilities for each occurrence of an n-gram. 73 Let δ(·, ·) denote the Kronecker function. Then, we define the fractional count C(en1 , f1J ) of an ngram en1 for a source sentence f1J as: C(en1 , f1J ) = X X"
W06-3110,W03-0413,0,\N,Missing
W06-3111,1998.amta-tutorials.6,0,0.037147,"Missing"
W06-3111,J93-2003,0,0.0250703,"Missing"
W06-3111,J93-1004,0,0.172538,"a combination of the two approaches leads to better translation performance. 1 Introduction Current statistical machine translation systems use bilingual sentences to train the parameters of the translation models. The exploitation of more bilingual sentences automatically and accurately as well as the use of these data with the limited computational requirements become crucial problems. The conventional method for producing parallel sentences is to break the documents into sentences and to align these sentences using dynamic programming. Previous investigations can be found in works such as (Gale and Church, 1993) and (Ma, 2006). A disadvantage is that only the monotone sentence alignments are allowed. Another approach is the binary segmentation method described in (Simard and Langlais, 2003), (Xu et al., 2005) and (Deng et al., 2006), which separates a long sentence pair into two sub-pairs recursively. The binary reordering in alignment is allowed but the segmentation decision is only optimum in each recursion step. Hence, a combination of both methods is expected to produce a more satisfying result. (Deng et al., 2006) performs a two-stage procedure. The documents are first aligned at level using dyn"
W06-3111,ma-2006-champollion,0,0.0123684,"roaches leads to better translation performance. 1 Introduction Current statistical machine translation systems use bilingual sentences to train the parameters of the translation models. The exploitation of more bilingual sentences automatically and accurately as well as the use of these data with the limited computational requirements become crucial problems. The conventional method for producing parallel sentences is to break the documents into sentences and to align these sentences using dynamic programming. Previous investigations can be found in works such as (Gale and Church, 1993) and (Ma, 2006). A disadvantage is that only the monotone sentence alignments are allowed. Another approach is the binary segmentation method described in (Simard and Langlais, 2003), (Xu et al., 2005) and (Deng et al., 2006), which separates a long sentence pair into two sub-pairs recursively. The binary reordering in alignment is allowed but the segmentation decision is only optimum in each recursion step. Hence, a combination of both methods is expected to produce a more satisfying result. (Deng et al., 2006) performs a two-stage procedure. The documents are first aligned at level using dynamic programmin"
W06-3111,J03-1002,1,0.0102698,"ine translation system in Section 2. Then, in Section 3, we will describe the refined binary segmentation method. In Section 4.1, we will introduce the methods to extract bilingual sentences from document aligned texts. The experimental results will be presented in Section 4. 2 Monotone I,eI1 = argmax I,eI1 (1) Figure 1: Two Types of Alignment The IBM model 1 (IBM-1) (Brown et al., 1993) assumes that all alignments have the same probability by using a uniform distribution: X J I 1 YX · p(fj |ei ) IJ (2) We use the IBM-1 to train the lexicon parameters p(f |e), the training software is GIZA++ (Och and Ney, 2003). To incorporate the context into the translation model, the phrase-based translation approach (Zens et al., 2005) is applied. Pairs of source and target language phrases are extracted from the bilingual training corpus and a beam search algorithm is implemented to generate the translation hypothesis with maximum probability. 3 Binary Segmentation Method 3.1 The decomposition into two knowledge sources in Equation 1 allows independent modeling of target language model P r(eI1 ) and translation model P r(f1J |eI1 )1 . The translation model can be further extended to a statistical alignment mode"
W06-3111,P02-1040,0,0.0718853,"Missing"
W06-3111,W03-0304,0,0.012923,"arameters of the translation models. The exploitation of more bilingual sentences automatically and accurately as well as the use of these data with the limited computational requirements become crucial problems. The conventional method for producing parallel sentences is to break the documents into sentences and to align these sentences using dynamic programming. Previous investigations can be found in works such as (Gale and Church, 1993) and (Ma, 2006). A disadvantage is that only the monotone sentence alignments are allowed. Another approach is the binary segmentation method described in (Simard and Langlais, 2003), (Xu et al., 2005) and (Deng et al., 2006), which separates a long sentence pair into two sub-pairs recursively. The binary reordering in alignment is allowed but the segmentation decision is only optimum in each recursion step. Hence, a combination of both methods is expected to produce a more satisfying result. (Deng et al., 2006) performs a two-stage procedure. The documents are first aligned at level using dynamic programming, the initial alignments are then refined to produce shorter segments using binary segmentation. But on the Chinese-English FBIS training corpus, the alignment accura"
W06-3111,J97-3002,0,0.0854975,"Missing"
W06-3111,2005.eamt-1.37,1,0.927694,"models. The exploitation of more bilingual sentences automatically and accurately as well as the use of these data with the limited computational requirements become crucial problems. The conventional method for producing parallel sentences is to break the documents into sentences and to align these sentences using dynamic programming. Previous investigations can be found in works such as (Gale and Church, 1993) and (Ma, 2006). A disadvantage is that only the monotone sentence alignments are allowed. Another approach is the binary segmentation method described in (Simard and Langlais, 2003), (Xu et al., 2005) and (Deng et al., 2006), which separates a long sentence pair into two sub-pairs recursively. The binary reordering in alignment is allowed but the segmentation decision is only optimum in each recursion step. Hence, a combination of both methods is expected to produce a more satisfying result. (Deng et al., 2006) performs a two-stage procedure. The documents are first aligned at level using dynamic programming, the initial alignments are then refined to produce shorter segments using binary segmentation. But on the Chinese-English FBIS training corpus, the alignment accuracy and recall are l"
W06-3111,2005.iwslt-1.20,1,0.870918,"In Section 4.1, we will introduce the methods to extract bilingual sentences from document aligned texts. The experimental results will be presented in Section 4. 2 Monotone I,eI1 = argmax I,eI1 (1) Figure 1: Two Types of Alignment The IBM model 1 (IBM-1) (Brown et al., 1993) assumes that all alignments have the same probability by using a uniform distribution: X J I 1 YX · p(fj |ei ) IJ (2) We use the IBM-1 to train the lexicon parameters p(f |e), the training software is GIZA++ (Och and Ney, 2003). To incorporate the context into the translation model, the phrase-based translation approach (Zens et al., 2005) is applied. Pairs of source and target language phrases are extracted from the bilingual training corpus and a beam search algorithm is implemented to generate the translation hypothesis with maximum probability. 3 Binary Segmentation Method 3.1 The decomposition into two knowledge sources in Equation 1 allows independent modeling of target language model P r(eI1 ) and translation model P r(f1J |eI1 )1 . The translation model can be further extended to a statistical alignment model with the following equation: P r(f1J |eI1 ) = D j=1 i=1 © ª P r(eI1 |f1J ) © ª P r(eI1 ) · P r(f1J |eI1 ) C p(f1"
W07-0401,J96-1002,0,0.0424164,"Missing"
W07-0401,J90-2002,0,0.442192,"ons with the chunk-level source reordering model. 3.1 The Baseline Phrase-based SMT System In statistical machine translation, we are given a source language sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language sentence eI1 = e1 . . . ei . . . eI . Among all possible target language sentences, we will choose the sentence with the highest probability: ˆ eˆI1 = argmax I,eI1 = argmax I,eI1   P r(eI1 |f1J ) P r(eI1 ) · P r(f1J |eI1 ) (1) (2) This decomposition into two knowledge sources is known as the source-channel approach to statistical machine translation (Brown et al., 1990). It allows an independent modeling of the target language model P r(eI1 ) and the translation model P r(f1J |eI1 ). The target language model describes the well-formedness of the target language sentence. The translation model links the source language sentence to the target language sentence. The argmax operation denotes the search problem, i.e., the generation of the output sentence in the target language. A generalization of the classical source-channel approach is the direct modeling of the posterior probability P r(eI1 |f1J ). Using a log-linear model (Och and Ney, 2002), we obtain: P"
W07-0401,2006.iwslt-papers.4,0,0.41497,"erns can be applied to any input source sentence so that the rewritten source and target sentences have similar word order. Both methods need a parser to generate trees of source sentences and are applied only as a preprocessing step. Another kind of source reordering methods besides full parsing is based on Part-Of-Speech (POS) tags or word classes. (Costa-juss`a and Fonollosa, 2006) view the source reordering as a translation task that translate the source language into a reordered source language. Then, the reordered source sentence is taken as the single input to the standard SMT system. (Chen et al., 2006) automatically extract rules from word alignments. These rules are defined at the POS level and the scores of matching rules are used as additional feature functions during rescor2 ing. (Crego and Mari˜no, 2006) integrate source-side reordering into SMT decoding. They automatically learn rewrite patterns from word alignment and represent the patterns with POS tags. To our knowledge no work is reported on the reordering with shallow parsing. Decoding lattices were already used in (Zens et al., 2002; Kanthak et al., 2005). Those approaches used linguistically uninformed word-level reorderings. 3"
W07-0401,P05-1066,0,0.717146,"ules, how they are defined and how to extract them. In Section 5, we explain how to apply the rules and how to generate reordering lattice. In Section 6, we present some results that show that the chunk-level source reordering is helpful for phrase-based statistical machine translation. Finally, we conclude this paper and discuss future work in Section 7. 2 Related Work Beside the reordering methods during decoding, an alternative approach is to reorder the input source sentence to match the word order of the target sentence. Some reordering methods are carried out on syntactic source trees. (Collins et al., 2005) describe a method for reordering German for German-toEnglish translation, where six transformations are applied to the surface string of the parsed source sentence. (Xia and McCord, 2004) propose an approach for translation from French-to-English. This approach automatically extracts rewrite patterns by parsing the source and target sides of the training corpus. These rewrite patterns can be applied to any input source sentence so that the rewritten source and target sentences have similar word order. Both methods need a parser to generate trees of source sentences and are applied only as a p"
W07-0401,W06-1609,0,0.315258,"Missing"
W07-0401,2006.amta-papers.4,0,0.087248,"Missing"
W07-0401,P06-1121,0,0.00765324,"he POS-level. 1 Introduction In machine translation, reordering is one of the major problems, since different languages have different word order requirements. Many reordering constraints have been used for word reorderings, such as ITG constraints (Wu, 1996), IBM constraints (Berger et al., 1996) and local constraints (Kanthak et al., 2005). These approaches do not make use of any linguistic knowledge. Several methods have been proposed to use syntactic information to handle the reordering problem, e.g. (Wu, 1997; Yamada and Knight, 2001; Gildea, 2003; Melamed, 2004; Graehl and Knight, 2004; Galley et al., 2006). One approach makes use of bitext grammars to parse both the source and target languages. Another approach makes use of syntactic information only in the target language. Note that these models have radically different structures and parameterizations than phrase-based models for SMT. Another kind of approaches is to use syntactic information in rescoring methods. (Koehn and Knight, 2003) apply a reranking approach to the sub-task of noun-phrase translation. (Och et al., 2004) and (Shen et al., 2004) describe the use of syntactic features in reranking the output of a full translation system,"
W07-0401,P03-1011,0,0.0306488,"eordering at the chunk-level performs better than at the POS-level. 1 Introduction In machine translation, reordering is one of the major problems, since different languages have different word order requirements. Many reordering constraints have been used for word reorderings, such as ITG constraints (Wu, 1996), IBM constraints (Berger et al., 1996) and local constraints (Kanthak et al., 2005). These approaches do not make use of any linguistic knowledge. Several methods have been proposed to use syntactic information to handle the reordering problem, e.g. (Wu, 1997; Yamada and Knight, 2001; Gildea, 2003; Melamed, 2004; Graehl and Knight, 2004; Galley et al., 2006). One approach makes use of bitext grammars to parse both the source and target languages. Another approach makes use of syntactic information only in the target language. Note that these models have radically different structures and parameterizations than phrase-based models for SMT. Another kind of approaches is to use syntactic information in rescoring methods. (Koehn and Knight, 2003) apply a reranking approach to the sub-task of noun-phrase translation. (Och et al., 2004) and (Shen et al., 2004) describe the use of syntactic f"
W07-0401,N04-1014,0,0.00604591,"performs better than at the POS-level. 1 Introduction In machine translation, reordering is one of the major problems, since different languages have different word order requirements. Many reordering constraints have been used for word reorderings, such as ITG constraints (Wu, 1996), IBM constraints (Berger et al., 1996) and local constraints (Kanthak et al., 2005). These approaches do not make use of any linguistic knowledge. Several methods have been proposed to use syntactic information to handle the reordering problem, e.g. (Wu, 1997; Yamada and Knight, 2001; Gildea, 2003; Melamed, 2004; Graehl and Knight, 2004; Galley et al., 2006). One approach makes use of bitext grammars to parse both the source and target languages. Another approach makes use of syntactic information only in the target language. Note that these models have radically different structures and parameterizations than phrase-based models for SMT. Another kind of approaches is to use syntactic information in rescoring methods. (Koehn and Knight, 2003) apply a reranking approach to the sub-task of noun-phrase translation. (Och et al., 2004) and (Shen et al., 2004) describe the use of syntactic features in reranking the output of a ful"
W07-0401,W05-0831,1,0.775387,"red source sentence is taken as the single input to the standard SMT system. (Chen et al., 2006) automatically extract rules from word alignments. These rules are defined at the POS level and the scores of matching rules are used as additional feature functions during rescor2 ing. (Crego and Mari˜no, 2006) integrate source-side reordering into SMT decoding. They automatically learn rewrite patterns from word alignment and represent the patterns with POS tags. To our knowledge no work is reported on the reordering with shallow parsing. Decoding lattices were already used in (Zens et al., 2002; Kanthak et al., 2005). Those approaches used linguistically uninformed word-level reorderings. 3 System Overview In this section, we will describe the phrase-based SMT system which we use for the experiments. Then, we will give an outline of the extentions with the chunk-level source reordering model. 3.1 The Baseline Phrase-based SMT System In statistical machine translation, we are given a source language sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language sentence eI1 = e1 . . . ei . . . eI . Among all possible target language sentences, we will choose the sentence with the hi"
W07-0401,E03-1076,0,0.0308904,"uistic knowledge. Several methods have been proposed to use syntactic information to handle the reordering problem, e.g. (Wu, 1997; Yamada and Knight, 2001; Gildea, 2003; Melamed, 2004; Graehl and Knight, 2004; Galley et al., 2006). One approach makes use of bitext grammars to parse both the source and target languages. Another approach makes use of syntactic information only in the target language. Note that these models have radically different structures and parameterizations than phrase-based models for SMT. Another kind of approaches is to use syntactic information in rescoring methods. (Koehn and Knight, 2003) apply a reranking approach to the sub-task of noun-phrase translation. (Och et al., 2004) and (Shen et al., 2004) describe the use of syntactic features in reranking the output of a full translation system, but the syntactic features give very small gains. In this paper, we present a strategy to reorder a source sentence using rules based on syntactic chunks. It is possible to integrate reordering rules directly into the search process, but here, we consider a more modular approach: easy to exchange reordering strategy. To avoid hard decisions before SMT, we generate a source-reordering latti"
W07-0401,N04-1021,0,0.0401596,"reordering problem, e.g. (Wu, 1997; Yamada and Knight, 2001; Gildea, 2003; Melamed, 2004; Graehl and Knight, 2004; Galley et al., 2006). One approach makes use of bitext grammars to parse both the source and target languages. Another approach makes use of syntactic information only in the target language. Note that these models have radically different structures and parameterizations than phrase-based models for SMT. Another kind of approaches is to use syntactic information in rescoring methods. (Koehn and Knight, 2003) apply a reranking approach to the sub-task of noun-phrase translation. (Och et al., 2004) and (Shen et al., 2004) describe the use of syntactic features in reranking the output of a full translation system, but the syntactic features give very small gains. In this paper, we present a strategy to reorder a source sentence using rules based on syntactic chunks. It is possible to integrate reordering rules directly into the search process, but here, we consider a more modular approach: easy to exchange reordering strategy. To avoid hard decisions before SMT, we generate a source-reordering lattice instead of a single reordered source sentence as input to the SMT system. Then, the dec"
W07-0401,P03-1021,0,0.0258214,"tagging ′ (3) The denominator represents a normalization factor that depends only on the source sentence f1J . Therefore, we can omit it during the search process. As a decision rule, we obtain: ) ( M X ˆ λm hm (eI1 , f1J ) (4) eˆI1 = argmax I,eI1 m=1 The log-linear model has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM 1 are trained according to the maximum entropy principle, e.g., using the GIS algorithm. Alternatively, one can train them with respect to the final translation quality measured by an error criterion (Och, 2003). The log-linear model is a natural framework to integrate many models. The baseline system uses the following models: • phrase translation model • phrase count features • word-based translation model • word and phrase penalty • target language model (6-gram) • distortion model (assigning costs based on the jump width) All the experiments in the paper are evaluated without rescoring. More details about the baseline system can be found in (Mauser et al., 2006) 3.2 Standard Translation Process Source Sentence Reordering Framework Encouraged by the work of (Xia and McCord, 2004) and (Crego and Ma"
W07-0401,P02-1040,0,0.108076,"et, the chunker has found 4 414 chunks, of which 2 879 are correct. Following the criteria of CoNLL-2000, the chunker is evaluated using the F-score, which is a combination of precision and recall. The result is shown in Table 3. The accuracy is evaluated at the word level, the other three metrics are evaluated at the chunk level. The results at the chunk level are worse than at the word level, because a chunk is counted as correct only if the chunk tag and the chunk boundaries are both correct. 6.2 Translation Results For the translation experiments, we report the two accuracy measures BLEU (Papineni et al., 2002) and NIST (Doddington, 2002) as well as the two error rates word error rate (WER) and positionindependent word error rate (PER). We perform translation experiments on the Basic Traveling Expression Corpus (BTEC) for the Chinese-English task. It is a speech translation task in the domain of tourism-related information. We report results on the IWSLT 2004, 2005 and 2006 evaluation test sets. There are 16 reference translations for the IWSLT 2004 and 2005 tasks and 7 reference translations for the IWSLT 2006 task. Table 4 shows the corpus statistics of the task. A training corpus is used to train"
W07-0401,popovic-ney-2006-pos,1,0.723734,"Missing"
W07-0401,N04-1023,0,0.0246519,". (Wu, 1997; Yamada and Knight, 2001; Gildea, 2003; Melamed, 2004; Graehl and Knight, 2004; Galley et al., 2006). One approach makes use of bitext grammars to parse both the source and target languages. Another approach makes use of syntactic information only in the target language. Note that these models have radically different structures and parameterizations than phrase-based models for SMT. Another kind of approaches is to use syntactic information in rescoring methods. (Koehn and Knight, 2003) apply a reranking approach to the sub-task of noun-phrase translation. (Och et al., 2004) and (Shen et al., 2004) describe the use of syntactic features in reranking the output of a full translation system, but the syntactic features give very small gains. In this paper, we present a strategy to reorder a source sentence using rules based on syntactic chunks. It is possible to integrate reordering rules directly into the search process, but here, we consider a more modular approach: easy to exchange reordering strategy. To avoid hard decisions before SMT, we generate a source-reordering lattice instead of a single reordered source sentence as input to the SMT system. Then, the decoder uses the reordered"
W07-0401,P97-1037,1,0.748365,"Missing"
W07-0401,P96-1021,0,0.568755,"Missing"
W07-0401,J97-3002,0,0.0884327,"he experiments also show that the reordering at the chunk-level performs better than at the POS-level. 1 Introduction In machine translation, reordering is one of the major problems, since different languages have different word order requirements. Many reordering constraints have been used for word reorderings, such as ITG constraints (Wu, 1996), IBM constraints (Berger et al., 1996) and local constraints (Kanthak et al., 2005). These approaches do not make use of any linguistic knowledge. Several methods have been proposed to use syntactic information to handle the reordering problem, e.g. (Wu, 1997; Yamada and Knight, 2001; Gildea, 2003; Melamed, 2004; Graehl and Knight, 2004; Galley et al., 2006). One approach makes use of bitext grammars to parse both the source and target languages. Another approach makes use of syntactic information only in the target language. Note that these models have radically different structures and parameterizations than phrase-based models for SMT. Another kind of approaches is to use syntactic information in rescoring methods. (Koehn and Knight, 2003) apply a reranking approach to the sub-task of noun-phrase translation. (Och et al., 2004) and (Shen et al."
W07-0401,2006.iwslt-evaluation.15,1,0.872897,"Missing"
W07-0401,C04-1073,0,0.843508,"that the chunk-level source reordering is helpful for phrase-based statistical machine translation. Finally, we conclude this paper and discuss future work in Section 7. 2 Related Work Beside the reordering methods during decoding, an alternative approach is to reorder the input source sentence to match the word order of the target sentence. Some reordering methods are carried out on syntactic source trees. (Collins et al., 2005) describe a method for reordering German for German-toEnglish translation, where six transformations are applied to the surface string of the parsed source sentence. (Xia and McCord, 2004) propose an approach for translation from French-to-English. This approach automatically extracts rewrite patterns by parsing the source and target sides of the training corpus. These rewrite patterns can be applied to any input source sentence so that the rewritten source and target sentences have similar word order. Both methods need a parser to generate trees of source sentences and are applied only as a preprocessing step. Another kind of source reordering methods besides full parsing is based on Part-Of-Speech (POS) tags or word classes. (Costa-juss`a and Fonollosa, 2006) view the source"
W07-0401,P04-1083,0,0.0139731,"he chunk-level performs better than at the POS-level. 1 Introduction In machine translation, reordering is one of the major problems, since different languages have different word order requirements. Many reordering constraints have been used for word reorderings, such as ITG constraints (Wu, 1996), IBM constraints (Berger et al., 1996) and local constraints (Kanthak et al., 2005). These approaches do not make use of any linguistic knowledge. Several methods have been proposed to use syntactic information to handle the reordering problem, e.g. (Wu, 1997; Yamada and Knight, 2001; Gildea, 2003; Melamed, 2004; Graehl and Knight, 2004; Galley et al., 2006). One approach makes use of bitext grammars to parse both the source and target languages. Another approach makes use of syntactic information only in the target language. Note that these models have radically different structures and parameterizations than phrase-based models for SMT. Another kind of approaches is to use syntactic information in rescoring methods. (Koehn and Knight, 2003) apply a reranking approach to the sub-task of noun-phrase translation. (Och et al., 2004) and (Shen et al., 2004) describe the use of syntactic features in rera"
W07-0401,P01-1067,0,0.196377,"ents also show that the reordering at the chunk-level performs better than at the POS-level. 1 Introduction In machine translation, reordering is one of the major problems, since different languages have different word order requirements. Many reordering constraints have been used for word reorderings, such as ITG constraints (Wu, 1996), IBM constraints (Berger et al., 1996) and local constraints (Kanthak et al., 2005). These approaches do not make use of any linguistic knowledge. Several methods have been proposed to use syntactic information to handle the reordering problem, e.g. (Wu, 1997; Yamada and Knight, 2001; Gildea, 2003; Melamed, 2004; Graehl and Knight, 2004; Galley et al., 2006). One approach makes use of bitext grammars to parse both the source and target languages. Another approach makes use of syntactic information only in the target language. Note that these models have radically different structures and parameterizations than phrase-based models for SMT. Another kind of approaches is to use syntactic information in rescoring methods. (Koehn and Knight, 2003) apply a reranking approach to the sub-task of noun-phrase translation. (Och et al., 2004) and (Shen et al., 2004) describe the use"
W07-0401,2001.mtsummit-papers.45,1,0.83032,"l source sentence as the input to the translation system. The use of a lattice avoids hard decisions before translation. To generate the reordering lattice, the source sentence is first POS tagged and chunk parsed. Then, reordering rules are applied to the chunks to generate the reordering lattice. Reordering rules are the key information for source reordering. They are automatically learned from the training data. The details of these two modules will be introduced in Section 5. 4 Reordering Rules There has been much work on learning and applying reordering rules on source language, such as (Nießen and Ney, 2001; Xia and McCord, 2004; Collins et al., 2005; Chen et al., 2006; Crego and Mari˜no, 2006; Popovi´c and Ney, 2006). The reordering rules could be composed of words, POS tags or syntactic tags of phrases. In our work, a rule is composed of chunk tags and POS tags. There is Table 1: Examples of reordering rules. (lhs: chunk and POS tag sequence, rhs: permutation ) no. lhs rhs 1. N P0 P P1 u2 n3 0123 2. N P0 P P1 u2 n3 3012 3. DN P0 N P1 V P2 012 4. DN P0 N P1 V P2 102 5. DN P0 N P1 m2 012 6. DN P0 N P1 m2 ad3 3012 7. DN P0 N P1 m2 ad3 v4 4 3 0 1 2 Figure 2: Illustration of three kinds of phrases:"
W07-0401,2002.tmi-tutorials.2,0,0.375381,"e. Then, the reordered source sentence is taken as the single input to the standard SMT system. (Chen et al., 2006) automatically extract rules from word alignments. These rules are defined at the POS level and the scores of matching rules are used as additional feature functions during rescor2 ing. (Crego and Mari˜no, 2006) integrate source-side reordering into SMT decoding. They automatically learn rewrite patterns from word alignment and represent the patterns with POS tags. To our knowledge no work is reported on the reordering with shallow parsing. Decoding lattices were already used in (Zens et al., 2002; Kanthak et al., 2005). Those approaches used linguistically uninformed word-level reorderings. 3 System Overview In this section, we will describe the phrase-based SMT system which we use for the experiments. Then, we will give an outline of the extentions with the chunk-level source reordering model. 3.1 The Baseline Phrase-based SMT System In statistical machine translation, we are given a source language sentence f1J = f1 . . . fj . . . fJ , which is to be translated into a target language sentence eI1 = e1 . . . ei . . . eI . Among all possible target language sentences, we will choose t"
W07-0401,P02-1038,1,0.173932,"ne translation (Brown et al., 1990). It allows an independent modeling of the target language model P r(eI1 ) and the translation model P r(f1J |eI1 ). The target language model describes the well-formedness of the target language sentence. The translation model links the source language sentence to the target language sentence. The argmax operation denotes the search problem, i.e., the generation of the output sentence in the target language. A generalization of the classical source-channel approach is the direct modeling of the posterior probability P r(eI1 |f1J ). Using a log-linear model (Och and Ney, 2002), we obtain: P  M I, fJ) exp λ h (e m=1 m m 1 1 P  P r(eI1 |f1J ) = P M ′I ′ , f J ) exp λ h (e 1 1 m=1 m m I ′ ,e′ I1 Translation Proces with Source Reordering source text sentences source text sentences POS tagging ′ (3) The denominator represents a normalization factor that depends only on the source sentence f1J . Therefore, we can omit it during the search process. As a decision rule, we obtain: ) ( M X ˆ λm hm (eI1 , f1J ) (4) eˆI1 = argmax I,eI1 m=1 The log-linear model has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling"
W07-0401,J03-1002,1,0.00578346,"xtraction algorithm ˜K (Zens et al., 2002) to (F1K , eI1 , a 1 ). Discarding the cross phrases, we keep the other phrases as rules. In a cross phrase, at least two chunk-word alignments overlap on the target language side. An example of a cross phrase is illustrated in Figure 2(c). Figure 2(a) and (b) illustrate the phrases for reordering rules, which could be monotone phrases or reordering phrases. 5 Reordering Lattice Generation 5.1 The extraction of reordering rules is based on the word alignment and the source sentence chunks. Here, we train word alignments in both directions with GIZA++ (Och and Ney, 2003). To get alignment with high accuracy, we use the intersection alignment here. For a given word-aligned sentence pair J (f1 , eI1 , aJ1 ), the source word sequence f1J is first parsed into a chunk sequence F1K . Accordingly, the word-to-word alignment aJ1 is changed to a chunk-to-word alignment a ˜K 1 which is the combination of the target words aligned to the source words in a chunk. It is defined as: a ˜k = {i|i = aj ∧ j ∈ [jk , jk+1 − 1]} The first step of chunk parsing is word segmentation. Then, a POS tagger is usually needed for further syntactic analysis. In our experiments, we use the"
W07-0401,W03-1709,0,0.0317502,"For a given word-aligned sentence pair J (f1 , eI1 , aJ1 ), the source word sequence f1J is first parsed into a chunk sequence F1K . Accordingly, the word-to-word alignment aJ1 is changed to a chunk-to-word alignment a ˜K 1 which is the combination of the target words aligned to the source words in a chunk. It is defined as: a ˜k = {i|i = aj ∧ j ∈ [jk , jk+1 − 1]} The first step of chunk parsing is word segmentation. Then, a POS tagger is usually needed for further syntactic analysis. In our experiments, we use the tool of “Inst. of Computing Tech., Chinese Lexical Analysis System (ICTCLAS)” (Zhang et al., 2003), which does the two tasks in one pass. Referring to the description of the chunking task in CoNLL-20001 , instead of English, a Chinese chunker is processed and evaluated. Each word is assigned a chunk tag, which contains the name of the chunk type and ”B” for the first word of the chunk and ”I” for each other word in the chunk. The ”O” chunk tag is used for tokens which are not part of any chunk. We use the maximum entropy tool YAS1 4 Parsing the Source Sentence http://www.cnts.ua.ac.be/conll2000/chunking/ Figure 3: Example of applying rules. The left part is the used rules. The right part i"
W07-0705,J93-2003,0,0.0313791,"k is more academical, in Section 4 we discuss possible practical applications for this approach. The paper concludes in Section 5. 2 From Words To Letters In the standard approach to statistical machine translation we are given a sentence (sequence of words) f1J = f1 . . . fJ in a source language which is to be translated into a sentence eˆI1 = eˆ1 . . . eˆI in a target language. Bayes decision rule states that we should choose the sentence which maximizes the posterior probability eˆI1 = argmax p(eI1 |f1J ) , (1) eI1 where the argmax operator denotes the search process. In the original work (Brown et al., 1993) the posterior probability p(eI1 |f1J ) is decomposed following a noisy-channel approach, but current stateof-the-art systems model the translation probability directly using a log-linear model(Och and Ney, 2002):  P M I, fJ) λ h (e exp m=1 m m 1 1 , P p(eI1 |f1J ) = X M I, fJ) λ h (˜ e exp m m 1 1 m=1 I e˜1 (2) with hm different models, λm scaling factors and the denominator a normalization factor that can be 34 ignored in the maximization process. The λm are usually chosen by optimizing a performance measure over a development corpus using a numerical optimization algorithm like the down"
W07-0705,P02-1038,1,0.3409,"n we are given a sentence (sequence of words) f1J = f1 . . . fJ in a source language which is to be translated into a sentence eˆI1 = eˆ1 . . . eˆI in a target language. Bayes decision rule states that we should choose the sentence which maximizes the posterior probability eˆI1 = argmax p(eI1 |f1J ) , (1) eI1 where the argmax operator denotes the search process. In the original work (Brown et al., 1993) the posterior probability p(eI1 |f1J ) is decomposed following a noisy-channel approach, but current stateof-the-art systems model the translation probability directly using a log-linear model(Och and Ney, 2002):  P M I, fJ) λ h (e exp m=1 m m 1 1 , P p(eI1 |f1J ) = X M I, fJ) λ h (˜ e exp m m 1 1 m=1 I e˜1 (2) with hm different models, λm scaling factors and the denominator a normalization factor that can be 34 ignored in the maximization process. The λm are usually chosen by optimizing a performance measure over a development corpus using a numerical optimization algorithm like the downhill simplex algorithm (Press et al., 2002). The most widely used models in the log linear combination are phrase-based models in sourceto-target and target-to-source directions, ibm1-like scores computed at phra"
W07-0705,J03-1002,1,0.013417,"it does not constitute a restriction of the generalization capabilities the model can have in creating “new words”. Somehow surprisingly, an additional word language model did not help. While the vocabulary size is reduced, the average sentence length increases, as we consider each letter to be a unit by itself. This has a negative impact in the running time of the actual implementation of the algorithms, specially for the alignment process. In order to alleviate this, the alignment process was split into two passes. In the first part, a word alignment was computed (using the GIZA++ toolkit (Och and Ney, 2003)). Then the training sentences were split according to this alignment (in a similar way to the standard phrase extraction algorithm), so that the length of the source and target part is around thirty letters. Then, a letter-based alignment is computed. 2.2 Efficiency Issues Somewhat counter-intuitively, the reduced vocabulary size does not necessarily imply a reduced mem1 ory footprint, at least not without a dedicated program optimization. As in a sensible implementations of nearly all natural language processing tools, the words are mapped to integers and handled as such. A typical implement"
W07-0705,popovic-ney-2004-towards,1,0.616151,"Missing"
W07-0705,2005.eamt-1.29,1,0.862329,"Missing"
W07-0705,W02-0505,0,\N,Missing
W07-0705,2006.iwslt-evaluation.15,1,\N,Missing
W07-0705,2006.iwslt-evaluation.8,0,\N,Missing
W07-0707,P04-1079,0,0.0242721,"ork Automatic evaluation measures for machine translation output are receiving more and more attention in the last years. The B LEU metric (Papineni et al., 2002) and the closely related N IST metric (Doddington, 2002) along with W ER and P ER 48 Proceedings of the Second Workshop on Statistical Machine Translation, pages 48–55, c Prague, June 2007. 2007 Association for Computational Linguistics have been widely used by many machine translation researchers. An extended version of B LEU which uses n-grams weighted according to their frequency estimated from a monolingual corpus is proposed in (Babych and Hartley, 2004). (Leusch et al., 2005) investigate preprocessing and normalisation methods for improving the evaluation using the standard measures W ER, P ER, B LEU and N IST. The same set of measures is examined in (Matusov et al., 2005) in combination with automatic sentence segmentation in order to enable evaluation of translation output without sentence boundaries (e.g. translation of speech recognition output). A new automatic metric M ETEOR (Banerjee and Lavie, 2005) uses stems and synonyms of the words. This measure counts the number of exact word matches between the output and the reference. In a se"
W07-0707,W05-0909,0,0.0510415,"n extended version of B LEU which uses n-grams weighted according to their frequency estimated from a monolingual corpus is proposed in (Babych and Hartley, 2004). (Leusch et al., 2005) investigate preprocessing and normalisation methods for improving the evaluation using the standard measures W ER, P ER, B LEU and N IST. The same set of measures is examined in (Matusov et al., 2005) in combination with automatic sentence segmentation in order to enable evaluation of translation output without sentence boundaries (e.g. translation of speech recognition output). A new automatic metric M ETEOR (Banerjee and Lavie, 2005) uses stems and synonyms of the words. This measure counts the number of exact word matches between the output and the reference. In a second step, unmatched words are converted into stems or synonyms and then matched. The T ER metric (Snover et al., 2006) measures the amount of editing that a human would have to perform to change the system output so that it exactly matches the reference. The CD ER measure (Leusch et al., 2006) is based on edit distance, such as the well-known W ER, but allows reordering of blocks. Nevertheless, none of these measures or extensions takes into account linguist"
W07-0707,carreras-etal-2004-freeling,0,0.0157882,"Missing"
W07-0707,W05-0903,1,0.913645,"sures for machine translation output are receiving more and more attention in the last years. The B LEU metric (Papineni et al., 2002) and the closely related N IST metric (Doddington, 2002) along with W ER and P ER 48 Proceedings of the Second Workshop on Statistical Machine Translation, pages 48–55, c Prague, June 2007. 2007 Association for Computational Linguistics have been widely used by many machine translation researchers. An extended version of B LEU which uses n-grams weighted according to their frequency estimated from a monolingual corpus is proposed in (Babych and Hartley, 2004). (Leusch et al., 2005) investigate preprocessing and normalisation methods for improving the evaluation using the standard measures W ER, P ER, B LEU and N IST. The same set of measures is examined in (Matusov et al., 2005) in combination with automatic sentence segmentation in order to enable evaluation of translation output without sentence boundaries (e.g. translation of speech recognition output). A new automatic metric M ETEOR (Banerjee and Lavie, 2005) uses stems and synonyms of the words. This measure counts the number of exact word matches between the output and the reference. In a second step, unmatched wo"
W07-0707,E06-1031,1,0.699498,"n in order to enable evaluation of translation output without sentence boundaries (e.g. translation of speech recognition output). A new automatic metric M ETEOR (Banerjee and Lavie, 2005) uses stems and synonyms of the words. This measure counts the number of exact word matches between the output and the reference. In a second step, unmatched words are converted into stems or synonyms and then matched. The T ER metric (Snover et al., 2006) measures the amount of editing that a human would have to perform to change the system output so that it exactly matches the reference. The CD ER measure (Leusch et al., 2006) is based on edit distance, such as the well-known W ER, but allows reordering of blocks. Nevertheless, none of these measures or extensions takes into account linguistic knowledge about actual translation errors, for example what is the contribution of verbs in the overall error rate, how many full forms are wrong whereas their base forms are correct, etc. A framework for human error analysis has been proposed in (Vilar et al., 2006) and a detailed analysis of the obtained results has been carried out. However, human error analysis, like any human evaluation, is a time consuming task. Whereas"
W07-0707,2005.iwslt-1.19,1,0.644817,"h W ER and P ER 48 Proceedings of the Second Workshop on Statistical Machine Translation, pages 48–55, c Prague, June 2007. 2007 Association for Computational Linguistics have been widely used by many machine translation researchers. An extended version of B LEU which uses n-grams weighted according to their frequency estimated from a monolingual corpus is proposed in (Babych and Hartley, 2004). (Leusch et al., 2005) investigate preprocessing and normalisation methods for improving the evaluation using the standard measures W ER, P ER, B LEU and N IST. The same set of measures is examined in (Matusov et al., 2005) in combination with automatic sentence segmentation in order to enable evaluation of translation output without sentence boundaries (e.g. translation of speech recognition output). A new automatic metric M ETEOR (Banerjee and Lavie, 2005) uses stems and synonyms of the words. This measure counts the number of exact word matches between the output and the reference. In a second step, unmatched words are converted into stems or synonyms and then matched. The T ER metric (Snover et al., 2006) measures the amount of editing that a human would have to perform to change the system output so that it"
W07-0707,C00-2162,1,0.772826,"ual translation errors, for example what is the contribution of verbs in the overall error rate, how many full forms are wrong whereas their base forms are correct, etc. A framework for human error analysis has been proposed in (Vilar et al., 2006) and a detailed analysis of the obtained results has been carried out. However, human error analysis, like any human evaluation, is a time consuming task. Whereas the use of linguistic knowledge for improving the performance of a statistical machine translation system is investigated in many publications for various language pairs (like for example (Nießen and Ney, 2000), (Goldwater and McClosky, 2005)), its use for the analysis of translation errors is still a rather unexplored area. Some automatic methods for error analysis using base forms and P OS tags are proposed in (Popovi´c et al., 2006; Popovi´c and Ney, 2006). These measures are based on differences between W ER and P ER which are calculated separately for each P OS class using subsets extracted from the original texts. Standard overall W ER and P ER of the original texts are not at all 49 taken into account. In this work, the standard W ER and P ER are decomposed and analysed. 3 Decomposition of W"
W07-0707,P02-1040,0,0.079304,"is. The results obtained on the European Parliament Plenary Session corpus in Spanish and English give a better overview of the nature of translation errors as well as ideas of where to put efforts for possible improvements of the translation system. 1 Introduction Evaluation of machine translation output is a very important but difficult task. Human evaluation is expensive and time consuming. Therefore a variety of automatic evaluation measures have been studied over the last years. The most widely used are Word Error Rate (W ER), Position independent word Error Rate (P ER), the B LEU score (Papineni et al., 2002) and the N IST score (Doddington, 2002). These measures have shown to be valuable tools for comparing Hermann Ney Lehrstuhl f¨ur Informatik 6 RWTH Aachen University Aachen, Germany ney@cs.rwth-aachen.de different systems as well as for evaluating improvements within one system. However, these measures do not give any details about the nature of translation errors. Therefore some more detailed analysis of the generated output is needed in order to identify the main problems and to focus the research efforts. A framework for human error analysis has been proposed in (Vilar et al., 2006), but as"
W07-0707,W06-3101,1,0.773222,"Missing"
W07-0707,2006.amta-papers.25,0,0.0313844,"ation using the standard measures W ER, P ER, B LEU and N IST. The same set of measures is examined in (Matusov et al., 2005) in combination with automatic sentence segmentation in order to enable evaluation of translation output without sentence boundaries (e.g. translation of speech recognition output). A new automatic metric M ETEOR (Banerjee and Lavie, 2005) uses stems and synonyms of the words. This measure counts the number of exact word matches between the output and the reference. In a second step, unmatched words are converted into stems or synonyms and then matched. The T ER metric (Snover et al., 2006) measures the amount of editing that a human would have to perform to change the system output so that it exactly matches the reference. The CD ER measure (Leusch et al., 2006) is based on edit distance, such as the well-known W ER, but allows reordering of blocks. Nevertheless, none of these measures or extensions takes into account linguistic knowledge about actual translation errors, for example what is the contribution of verbs in the overall error rate, how many full forms are wrong whereas their base forms are correct, etc. A framework for human error analysis has been proposed in (Vilar"
W07-0707,2005.mtsummit-papers.34,1,0.692141,"od can be easily extended to other types of linguistic information. In addition, two methods for error analysis using the W ER and P ER decompositons together with base forms are proposed: estimation of inflectional errors and distribution of missing words over P OS classes. The translation corpus used for our error analysis is built in the framework of the T C -S TAR project (tcs, 2005) and contains the transcriptions of the European Parliament Plenary Sessions (E PPS) in Spanish and English. The translation system used is the phrase-based statistical machine translation system described in (Vilar et al., 2005; Matusov et al., 2006). 2 Related Work Automatic evaluation measures for machine translation output are receiving more and more attention in the last years. The B LEU metric (Papineni et al., 2002) and the closely related N IST metric (Doddington, 2002) along with W ER and P ER 48 Proceedings of the Second Workshop on Statistical Machine Translation, pages 48–55, c Prague, June 2007. 2007 Association for Computational Linguistics have been widely used by many machine translation researchers. An extended version of B LEU which uses n-grams weighted according to their frequency estimated from a"
W07-0707,vilar-etal-2006-error,1,0.707062,"Missing"
W07-0707,H05-1085,0,\N,Missing
W07-0713,E06-1032,0,0.0191741,"sk, namely the ranking of systems. Furthermore we argue that machine translation evaluations should be regarded as statistical processes, both for human and automatic evaluation. We show how confidence ranges for state-of-the-art evaluation measures such as WER and TER can be computed accurately and efficiently without having to resort to Monte Carlo estimates. We give an example of our new evaluation scheme, as well as a comparison with classical automatic and human evaluation on data from a recent international evaluation campaign. 1 However, automatic measures also have big disadvantages; (Callison-Burch et al., 2006) describes some of them. A major problem is that a given sentence in one language can have several correct translations in another language and thus, the measure of similarity with one or even a small amount of reference translations will never be flexible enough to truly reflect the wide range of correct possibilities of a translation. 1 This holds in particular for long sentences and wide- or open-domain tasks like the ones dealt with in current MT projects and evaluations. Introduction Evaluation of machine translation (MT) output is a difficult and still open problem. As in other natural l"
W07-0713,1993.eamt-1.1,0,0.0573576,"binary comparison experiments, each judge was given hypothesis translations ei,X , ei,Y . She could then judge ei,X to be better than, equal to, or worse than ei,Y . All these judgments were counted over the systems. We define a sentence score ri,X,Y for this evaluation method as follows:   +1 ei,X is better than ei,Y ri,X,Y := 0 . (2) ei,X is equal to ei,Y  −1 e is worse than e i,X i,Y Then, the total evaluation score for a binary comparison of systems X and Y is m RX,Y 1 X ri,X,Y , := m (3) i=1 with m the number of evaluated sentences. For this case, namely R being an arithmetic mean, (Efron and Tibshirani, 1993) gives an explicit formula for the estimated standard error of the score RX,Y . To simplify the notation, we will use R instead of RX,Y from now on, and ri instead of ri,X,Y . v um X 1 u t (ri − R)2 . se[R] = (4) m−1 i=1 With x denoting the number of sentences where ri = 1, and y denoting the number of sentences where ri = −1, x−y m R= Train (5) and with basic algebra 1 se[R] = m−1 Test r (x − y)2 x+y− . m (6) Moreover, we can explicitly give an estimate for E[R0 ]: The null hypothesis is that both systems are “equally good”. Then, we should expect as many sentences where X is better than Y as"
W07-0713,W06-3114,0,0.0339031,", there can be biases among the human judges. Large amounts of sentences must therefore be evaluated and procedures like evaluation normalization must be carried out before significant conclusions from the evaluation can be drawn. Another important drawback, which is also one of the causes of the aforementioned problems, is that it is very difficult to define the meaning of the numerical scores precisely. Even if human judges have explicit evaluation guidelines at hand, they still find it difficult to assign a numerical value which represents the quality of the translation for many sentences (Koehn and Monz, 2006). In this paper we present an alternative to this evaluation scheme. Our method starts from the observation that normally the final objective of a human evaluation is to find a “ranking” of different systems, and the absolute score for each system is not relevant (and it can even not be comparable between different evaluations). We focus on a method that aims to simplify the task of the judges and allows to rank the systems according to their translation quality. 3 Binary System Comparisons The main idea of our method relies in the fact that a human evaluator, when presented two different tran"
W07-0713,W05-0903,1,0.854992,"impossible to eliminate them if humans are involved. If one of the judges prefers one kind of structure, there will a bias for a system producing such output, independently of the evaluation procedure. However, the suppression of explicit numerical scores eliminates an additional bias of evaluators. It has been observed that human judges often give scores within 6 Note however that possible evaluator biases can have a great influence in these statistics. a certain range (e.g. in the mid-range or only extreme values), which constitute an additional difficulty when carrying out the evaluation (Leusch et al., 2005). Our method suppresses this kind of bias. Another advantage of our method is the possibility of assessing improvements within one system. With one evaluation we can decide if some modifications actually improve performance. This evaluation even gives us a confidence interval to weight the significance of an improvement. Carrying out a full adequacy-fluency analysis would require a lot more effort, without giving more useful results. 7 Conclusion We presented a novel human evaluation technique that simplifies the task of the evaluators. Our method relies on two basic observations. The first on"
W07-0713,P03-1021,0,0.0111467,"restricted the number of systems in order to keep the evaluation effort manageable for a first experimental setup to test the feasibility of our method. The ranking of 5 systems can be carried out with as few as 7 comparisons, but the ranking of 9 systems requires 19 comparisons. 5 Evaluation Results i=1 (9) With this Equation, Monte-Carlo-estimates are no longer necessary for examining the significance of WER, PER, TER, etc. Unfortunately, we do not expect such a short explicit formula to exist for the standard BLEU score. Still, a confidence range for BLEU can be estimated by bootstrapping (Och, 2003; Zhang and Vogel, 2004). 100 Seven human bilingual evaluators (6 native speakers and one near-native speaker of Spanish) carried out the evaluation. 100 sentences were randomly chosen and assigned to each of the evaluators for every system comparison, as discussed in Section 3.3. The results can be seen in Table 2 and Figure 2. Counts 4 http://www.tc-star.org/ ● ● ● ● 400 300 B−D E−A ●D−C B−A D−A 0 10 20 ● A−C E−B 200 ● 100 # &quot;Second system better&quot; 70 60 50 40 30 ● 0 # &quot;Second system better&quot; B−A D−C A−C E−A E−B B−D D−A ● 0 10 20 30 40 50 60 70 0 # &quot;First system better&quot; 100 200 300 400 # &quot;Firs"
W07-0713,P02-1040,0,0.0919255,"of correct possibilities of a translation. 1 This holds in particular for long sentences and wide- or open-domain tasks like the ones dealt with in current MT projects and evaluations. Introduction Evaluation of machine translation (MT) output is a difficult and still open problem. As in other natural language processing tasks, automatic measures which try to asses the quality of the translation can be computed. The most widely known are the Word Error Rate (WER), the Position independent word Error Rate (PER), the NIST score (Doddington, 2002) and, especially in recent years, the BLEU score (Papineni et al., 2002) and the Translation ErIf the actual quality of a translation in terms of usefulness for human users is to be evaluated, human evaluation needs to be carried out. This is however a costly and very time-consuming process. In this work we present a novel approach to human evaluation that simplifies the task for human judges. Instead of having to assign numerical scores to each sentence to be evaluated, as is done in current evaluation procedures, human judges choose the best one out of two candidate translations. We show how this method can be used to rank an arbitrary number of systems and pres"
W07-0713,2005.mtsummit-papers.34,1,0.679589,"oject4 . The goal of this project is to build a speech-to-speech translation system that can deal with real life data. Three translation directions are dealt with in the project: Spanish to English, English to Spanish and Chinese to English. For the system comparison we concentrated only in the English to Spanish direction. The corpus for the Spanish–English language pair consists of the official version of the speeches held in the European Parliament Plenary Sessions (EPPS), as available on the web page of the European Parliament. A more detailed description of the EPPS data can be found in (Vilar et al., 2005). Table 1 shows the statistics of the corpus. A total of 9 different MT systems participated in this condition in the evaluation campaign that took place in February 2006. We selected five representative systems for our study. Henceforth we shall refer to these systems as System A through System E. We restricted the number of systems in order to keep the evaluation effort manageable for a first experimental setup to test the feasibility of our method. The ranking of 5 systems can be carried out with as few as 7 comparisons, but the ranking of 9 systems requires 19 comparisons. 5 Evaluation Res"
W07-0713,2004.tmi-1.9,0,0.0207347,"the number of systems in order to keep the evaluation effort manageable for a first experimental setup to test the feasibility of our method. The ranking of 5 systems can be carried out with as few as 7 comparisons, but the ranking of 9 systems requires 19 comparisons. 5 Evaluation Results i=1 (9) With this Equation, Monte-Carlo-estimates are no longer necessary for examining the significance of WER, PER, TER, etc. Unfortunately, we do not expect such a short explicit formula to exist for the standard BLEU score. Still, a confidence range for BLEU can be estimated by bootstrapping (Och, 2003; Zhang and Vogel, 2004). 100 Seven human bilingual evaluators (6 native speakers and one near-native speaker of Spanish) carried out the evaluation. 100 sentences were randomly chosen and assigned to each of the evaluators for every system comparison, as discussed in Section 3.3. The results can be seen in Table 2 and Figure 2. Counts 4 http://www.tc-star.org/ ● ● ● ● 400 300 B−D E−A ●D−C B−A D−A 0 10 20 ● A−C E−B 200 ● 100 # &quot;Second system better&quot; 70 60 50 40 30 ● 0 # &quot;Second system better&quot; B−A D−C A−C E−A E−B B−D D−A ● 0 10 20 30 40 50 60 70 0 # &quot;First system better&quot; 100 200 300 400 # &quot;First system better&quot; (a) Eac"
W09-0402,W07-0718,0,0.0707219,"Missing"
W09-0402,W08-0309,0,0.0494742,"METEOR scores. 2008 BLEU Experiments on 2008 test data M BLEU For the official shared evaluation task in 2008, the human evaluation scores were different – the adequacy and fluency scores were abandoned being rather time consuming and often inconsistent, and the sentence ranking was proposed as one of the human evaluation scores: the manual evaluators were asked to rank translated sentences relative to each other. RWTH participated in this shared task with the two most promising metrics according to the previous experiments, i.e. POS B LEU and POS F, and the detailed results can be found in (Callison-Burch et al., 2008). It was shown that these metrics also correlate very well with the sentence ranking on the document level. However, on the sentence level the performance was much weaker: a percentage of sentence pairs for which the human comparison yields the same result as the comparison using particular automatic metric was not very high. We believe that the main reason for this is the fact that the metrics based only on the POS tags can assign high scores to translations without correct semantic meaning, because they are taking into account only syntactic structure without taking into account the actual w"
W09-0402,carreras-etal-2004-freeling,0,0.0153625,"Missing"
W09-0402,W06-3114,0,0.0935888,"Missing"
W09-0402,P02-1040,0,0.0933923,"Missing"
W09-0402,A00-1031,0,\N,Missing
W09-0407,J03-1002,1,0.0116554,"etween the hypotheses are calculated. The hypotheses are then reordered to match the word order of a selected primary hypothesis. From this, we create a confusion network (CN), which we then rescore using 1 A test corpus can be used directly because the alignment training is unsupervised and only automatically produced translations are considered. Proceedings of the Fourth Workshop on Statistical Machine Translation , pages 51–55, c Athens, Greece, 30 March – 31 March 2009. 2009 Association for Computational Linguistics 51 The model parameters are trained iteratively using the GIZA++ toolkit (Och and Ney, 2003). The training is performed in the directions Em → En and En → Em . After each iteration, the updated lexicon tables from the two directions are interpolated. The final alignments are determined using a cost matrix C for each sentence pair (Em , En ). Elements of this matrix are the local costs C(j, i) of aligning a word em,j from Em to a word en,i from En . Following Matusov et al. (2004), we compute these local costs by interpolating the negated logarithms of the state occupation probabilities from the “source-to-target” and “target-tosource” training of the HMM model. Two different alignmen"
W09-0407,P02-1040,0,0.0861447,"Missing"
W09-0407,P07-1040,0,0.109336,"dd a fraction of a count for words with identical prefixes. Introduction The RWTH approach to MT system combination is a refined version of the ROVER approach in ASR (Fiscus, 1997), with additional steps to cope with reordering between different hypotheses, and to use true casing information from the input hypotheses. The basic concept of the approach has been described by Matusov et al. (2006). Several improvements have been added later (Matusov et al., 2008). This approach includes an enhanced alignment and reordering framework. In contrast to existing approaches (Jayaraman and Lavie, 2005; Rosti et al., 2007), the context of the whole corpus rather than a single sentence is considered in this iterative, unsupervised procedure, yielding a more reliable alignment. Majority voting on the generated lattice is performed using the prior probabilities for each system as well as other statistical models such as a special n-gram language model. 2 System Combination Algorithm In this section we present the details of our system combination method. Figure 1 gives an overview of the system combination architecture described in this section. After preprocessing the MT hypotheses, pairwise alignments between th"
W09-0407,J93-2003,0,0.0100691,"its translations En , n = 1, . . . , M, as the primary hypothesis. Then we align the secondary hypotheses Em (m = 1, . . . , M ; n 6= m) with En to match the word order in En . Since it is not clear which hypothesis should be primary, i. e. has the “best” word order, we let every hypothesis play the role of the primary translation, and align all pairs of hypotheses (En , Em ); n 6= m. The word alignment is trained in analogy to the alignment training procedure in statistical MT. The difference is that the two sentences that have to be aligned are in the same language. We use the IBM Model 1 (Brown et al., 1993) and the Hidden Markov Model (HMM, (Vogel et al., 1996)) to estimate the alignment model. The alignment training corpus is created from a test corpus1 of effectively M · (M − 1) · N sentences translated by the involved MT engines. The single-word based lexicon probabilities p(e|e0 ) are initialized from normalized lexicon counts collected over the sentence pairs (Em , En ) on this corpus. Since all of the hypotheses are in the same language, we count co-occurring identical words, i. e. whether em,j is the same word as en,i for some i and j. In addition, we add a fraction of a count for words w"
W09-0407,2006.amta-papers.25,0,0.222309,"Missing"
W09-0407,C96-2141,1,0.705159,"hypothesis. Then we align the secondary hypotheses Em (m = 1, . . . , M ; n 6= m) with En to match the word order in En . Since it is not clear which hypothesis should be primary, i. e. has the “best” word order, we let every hypothesis play the role of the primary translation, and align all pairs of hypotheses (En , Em ); n 6= m. The word alignment is trained in analogy to the alignment training procedure in statistical MT. The difference is that the two sentences that have to be aligned are in the same language. We use the IBM Model 1 (Brown et al., 1993) and the Hidden Markov Model (HMM, (Vogel et al., 1996)) to estimate the alignment model. The alignment training corpus is created from a test corpus1 of effectively M · (M − 1) · N sentences translated by the involved MT engines. The single-word based lexicon probabilities p(e|e0 ) are initialized from normalized lexicon counts collected over the sentence pairs (Em , En ) on this corpus. Since all of the hypotheses are in the same language, we count co-occurring identical words, i. e. whether em,j is the same word as en,i for some i and j. In addition, we add a fraction of a count for words with identical prefixes. Introduction The RWTH approach"
W09-0407,D08-1011,0,0.0662824,"his matrix are the local costs C(j, i) of aligning a word em,j from Em to a word en,i from En . Following Matusov et al. (2004), we compute these local costs by interpolating the negated logarithms of the state occupation probabilities from the “source-to-target” and “target-tosource” training of the HMM model. Two different alignments are computed using the cost matrix C: the alignment e a used for reordering each secondary translation Em , and the alignment a ¯ used to build the confusion network. In addition to the GIZA++ alignments, we have also conducted preliminary experiments following He et al. (2008) to exploit character-based similarity, as well as estimating p(e|e0 ) := P p(e|f )p(f |e0 ) directly from a bilingual lexif con. But we were not able to find improvements over the GIZA++ alignments so far. al., 2007). Weighted majority voting on a single confusion network is straightforward and analogous to ROVER (Fiscus, 1997). We sum up the probabilities of the arcs which are labeled with the same word and have the same start state and the same end state. To exploit the true casing abilities of the input MT systems, we sum up the scores of arcs bearing the same word but in different cases."
W09-0407,P05-3026,0,0.114538,"i and j. In addition, we add a fraction of a count for words with identical prefixes. Introduction The RWTH approach to MT system combination is a refined version of the ROVER approach in ASR (Fiscus, 1997), with additional steps to cope with reordering between different hypotheses, and to use true casing information from the input hypotheses. The basic concept of the approach has been described by Matusov et al. (2006). Several improvements have been added later (Matusov et al., 2008). This approach includes an enhanced alignment and reordering framework. In contrast to existing approaches (Jayaraman and Lavie, 2005; Rosti et al., 2007), the context of the whole corpus rather than a single sentence is considered in this iterative, unsupervised procedure, yielding a more reliable alignment. Majority voting on the generated lattice is performed using the prior probabilities for each system as well as other statistical models such as a special n-gram language model. 2 System Combination Algorithm In this section we present the details of our system combination method. Figure 1 gives an overview of the system combination architecture described in this section. After preprocessing the MT hypotheses, pairwise"
W09-0407,C04-1032,1,0.895843,"tatistical Machine Translation , pages 51–55, c Athens, Greece, 30 March – 31 March 2009. 2009 Association for Computational Linguistics 51 The model parameters are trained iteratively using the GIZA++ toolkit (Och and Ney, 2003). The training is performed in the directions Em → En and En → Em . After each iteration, the updated lexicon tables from the two directions are interpolated. The final alignments are determined using a cost matrix C for each sentence pair (Em , En ). Elements of this matrix are the local costs C(j, i) of aligning a word em,j from Em to a word en,i from En . Following Matusov et al. (2004), we compute these local costs by interpolating the negated logarithms of the state occupation probabilities from the “source-to-target” and “target-tosource” training of the HMM model. Two different alignments are computed using the cost matrix C: the alignment e a used for reordering each secondary translation Em , and the alignment a ¯ used to build the confusion network. In addition to the GIZA++ alignments, we have also conducted preliminary experiments following He et al. (2008) to exploit character-based similarity, as well as estimating p(e|e0 ) := P p(e|f )p(f |e0 ) directly from a bi"
W09-0407,E06-1005,1,0.896436,"over the sentence pairs (Em , En ) on this corpus. Since all of the hypotheses are in the same language, we count co-occurring identical words, i. e. whether em,j is the same word as en,i for some i and j. In addition, we add a fraction of a count for words with identical prefixes. Introduction The RWTH approach to MT system combination is a refined version of the ROVER approach in ASR (Fiscus, 1997), with additional steps to cope with reordering between different hypotheses, and to use true casing information from the input hypotheses. The basic concept of the approach has been described by Matusov et al. (2006). Several improvements have been added later (Matusov et al., 2008). This approach includes an enhanced alignment and reordering framework. In contrast to existing approaches (Jayaraman and Lavie, 2005; Rosti et al., 2007), the context of the whole corpus rather than a single sentence is considered in this iterative, unsupervised procedure, yielding a more reliable alignment. Majority voting on the generated lattice is performed using the prior probabilities for each system as well as other statistical models such as a special n-gram language model. 2 System Combination Algorithm In this secti"
W09-0407,mauser-etal-2008-automatic,1,0.811005,"as well: Neither in FR→EN nor in ES→EN we were able to achieve an improvement over the Google system. For this reason, we did not submit consensus translations for these two language pairs. On the other hand, we would have achieved significant improvements over all (remaining) systems leaving out Google. publicly available CONDOR optimization toolkit (Berghen and Bersini, 2005). For the WMT 2009 Workshop, we selected a linear combination of B LEU (Papineni et al., 2002) and T ER (Snover et al., 2006) as optimization criterion, ˆ := argmaxΘ {(2 · B LEU) − T ER}, based on Θ previous experience (Mauser et al., 2008). We used the whole dev set as a tuning set. For more stable results, we used the case-insensitive variants for both measures, despite the explicit use of case information in our approach. 4 Experimental results Due to the large number of submissions (71 in total for the language pairs DE→EN, ES→EN, FR→EN), we had to select a reasonable number of systems to be able to tune the parameters in a reliable way. Based on previous experience, we manually selected the systems with the best B LEU/T ER score, and tried different variations of this selection, e.g. by removing systems which had low weight"
W09-0407,D09-1022,1,\N,Missing
W09-0407,W06-3110,1,\N,Missing
W09-0407,2005.eamt-1.20,0,\N,Missing
W09-0407,D08-1039,1,\N,Missing
W09-0410,E06-1005,1,0.803237,"st participles, but there are many cases when other verb forms also occur at the clause end. For the translation from German into English, following verb types were moved towards the beginning of a clause: infinitives, infinitives+zu, finite verbs, past participles and negative particles. For the translation from English to German, infinitives and past participles were moved to the end of a clause, where punctuation marks, subordinate conjunctions and finite verbs are considered as the beginning of the next clause. 4 System combination For system combination we used the approach described in (Matusov et al., 2006). The method is based on the generation of a consensus translation out of the output of different translation systems. The core of the method consists in building a confusion network for each sentence by aligning and combining the (single-best) translation hypothesis from one MT system with the translations produced by the other MT systems (and the other translations from the same system, if n-best lists are used in combination). For each sentence, each MT system is selected once as “primary” system, and the other hypotheses are aligned to this hypothesis. The resulting confusion networks are"
W09-0410,popovic-ney-2006-pos,1,0.894671,"Missing"
W09-0410,N07-1029,0,0.0191149,"s. The core of the method consists in building a confusion network for each sentence by aligning and combining the (single-best) translation hypothesis from one MT system with the translations produced by the other MT systems (and the other translations from the same system, if n-best lists are used in combination). For each sentence, each MT system is selected once as “primary” system, and the other hypotheses are aligned to this hypothesis. The resulting confusion networks are combined into a signle word graph, which is then weighted with system-specific factors, similar to the approach of (Rosti et al., 2007), and a trigram LM trained on the MT hypotheses. The translation with the best total score within this word graph is selected as consensus translation. The scaling factors of these models are optimized using the Condor toolkit (Berghen and Bersini, 2005) to achieve optimal B LEU score on the dev set. 5 5.1 Experimental results Experimental settings For all translation directions, we used the provided EuroParl and News parallel corpora to train the translation models and the News monolingual corpora to train the language models. All systems were optimised for the B LEU score on the development"
W09-0410,2008.iwslt-papers.7,1,0.894714,"Missing"
W09-0410,A00-1031,0,0.0616954,"Missing"
W09-0410,carreras-etal-2004-freeling,0,0.0349781,"Missing"
W09-0410,2005.iwslt-1.18,1,\N,Missing
W09-0410,W99-0604,1,\N,Missing
W09-0410,C04-1006,1,\N,Missing
W09-0410,E03-1076,0,\N,Missing
W09-0410,W07-0813,0,\N,Missing
W09-0410,C08-1128,1,\N,Missing
W09-0410,J90-2002,0,\N,Missing
W09-0410,P05-1071,0,\N,Missing
W09-0410,P02-1040,0,\N,Missing
W09-0410,W03-1709,0,\N,Missing
W09-0410,W06-3111,1,\N,Missing
W09-0410,J04-2004,0,\N,Missing
W09-0410,W07-0401,1,\N,Missing
W09-0410,J06-4004,0,\N,Missing
W09-0410,W05-0831,1,\N,Missing
W09-0410,J03-1002,1,\N,Missing
W09-0410,P06-1001,0,\N,Missing
W09-0410,takezawa-etal-2002-toward,0,\N,Missing
W09-0410,2005.eamt-1.37,1,\N,Missing
W09-0410,2006.iwslt-papers.1,1,\N,Missing
W09-0410,2007.iwslt-1.25,1,\N,Missing
W09-0410,2004.iwslt-evaluation.13,1,\N,Missing
W09-0410,2007.iwslt-1.3,1,\N,Missing
W09-0410,J07-2003,0,\N,Missing
W09-0410,2006.iwslt-evaluation.15,1,\N,Missing
W09-0410,P03-1021,0,\N,Missing
W09-0410,2007.iwslt-1.10,0,\N,Missing
W09-0438,N04-1036,0,\N,Missing
W09-0438,W03-0420,1,\N,Missing
W09-0438,W02-0505,0,\N,Missing
W09-0438,P07-1020,0,\N,Missing
W09-0438,P07-1080,0,\N,Missing
W09-0438,P02-1038,1,\N,Missing
W09-0438,N04-1033,1,\N,Missing
W09-0438,J98-4003,0,\N,Missing
W09-0438,D07-1025,0,\N,Missing
W10-1711,E03-1076,0,0.129532,"Missing"
W10-1711,E06-1005,1,0.838332,"Association for Computational Linguistics Standard FA German→English BLEU # Phrases 19.7 128M 20.0 12M French→English BLEU # Phrases 25.5 225M 25.9 35M English→French BLEU # Phrases 23.7 261M 24.0 33M Table 1: BLEU scores on Test and phrase table sizes with and without forced alignment (FA). For German→English and English→French phrase table interpolation was applied. tains flexibility on the input systems. additional steps to cope with reordering between different hypotheses, and to use true casing information from the input hypotheses. The basic concept of the approach has been described by Matusov et al. (2006). Several improvements have been added later (Matusov et al., 2008). This approach includes an enhanced alignment and reordering framework. Alignments between the systems are learned by GIZA++, a one-to-one alignment is generated from the learned state occupation probabilities. From these alignments, a confusion network (CN) is then built using one of the hypotheses as “skeleton” or “primary” hypothesis. We do not make a hard decision on which of the hypotheses to use for that, but instead combine all possible CNs into a single lattice. Majority voting on the generated lattice is performed usi"
W10-1711,D09-1022,1,0.239401,"Missing"
W10-1711,popovic-ney-2006-pos,1,0.575104,"Missing"
W10-1711,2009.mtsummit-posters.17,0,0.036503,"Missing"
W10-1711,J07-2003,0,0.0508773,"etraining method and additional models were tested and investigated with respect to their effect for the different language pairs. For two of the language pairs we could improve performance by system combination. An overview of the systems and models will follow in Section 2 and 3, which describe the baseline architecture, followed by descriptions of the additional system components. Morpho-syntactic analysis and other preprocessing issues are covered by Section 4. Finally, translation results for 2.2 Hierarchical System Our hierarchical phrase-based system is similar to the one described in (Chiang, 2007). It allows for gaps in the phrases by employing a context-free grammar and a CYK-like parsing during the decoding step. It has similar features as the phrasebased system mentioned above. For some systems, we only allowed the non-terminals in hierarchical phrases to be substituted with initial phrases as in (Iglesias et al., 2009), which gave better results on some language pairs. We will refer to this as “shallow rules”. 2.3 System Combination The RWTH approach to MT system combination of the French→English systems as well as the German→English systems is a refined version of the ROVER approa"
W10-1711,P10-1049,1,0.176425,"Missing"
W10-1711,W06-3105,0,0.0459067,"Missing"
W10-1711,W06-3108,1,0.318609,"with a variant of GIZA++. Target language models are 4-gram language models trained with the SRI toolkit, using Kneser-Ney discounting with interpolation. 2.1 Phrase-Based System Our phrase-based translation system is similar to the one described in (Zens and Ney, 2008). Phrase pairs are extracted from a word-aligned bilingual corpus and their translation probability in both directions is estimated by relative frequencies. Additional models include a standard n-gram language model, phrase-level IBM1, word-, phraseand distortion-penalties and a discriminative reordering model as described in (Zens and Ney, 2006). Introduction This paper describes the statistical MT system used for our participation in the WMT 2010 shared translation task. We used it as an opportunity to incorporate novel methods which have been investigated at RWTH over the last year and which have proven to be successful in other evaluations. For all tasks we used standard alignment and training tools as well as our in-house phrasebased and hierarchical statistical MT decoders. When German was involved, morpho-syntactic preprocessing was applied. An alternative phrasetraining method and additional models were tested and investigated"
W10-1711,2008.iwslt-papers.8,1,0.0627609,"ome tasks, a system combination of the best systems was used to generate a final hypothesis. We participated in the constrained condition of GermanEnglish and French-English in each translation direction. 1 2 Translation Systems For the WMT 2010 Evaluation we used standard phrase-based and hierarchical translation systems. Alignments were trained with a variant of GIZA++. Target language models are 4-gram language models trained with the SRI toolkit, using Kneser-Ney discounting with interpolation. 2.1 Phrase-Based System Our phrase-based translation system is similar to the one described in (Zens and Ney, 2008). Phrase pairs are extracted from a word-aligned bilingual corpus and their translation probability in both directions is estimated by relative frequencies. Additional models include a standard n-gram language model, phrase-level IBM1, word-, phraseand distortion-penalties and a discriminative reordering model as described in (Zens and Ney, 2006). Introduction This paper describes the statistical MT system used for our participation in the WMT 2010 shared translation task. We used it as an opportunity to incorporate novel methods which have been investigated at RWTH over the last year and whic"
W10-1711,D08-1039,1,0.678444,"Missing"
W10-1711,W99-0604,1,\N,Missing
W10-1711,D11-1033,0,\N,Missing
W10-1711,E09-1044,0,\N,Missing
W10-1711,J93-2003,0,\N,Missing
W10-1711,N04-4015,0,\N,Missing
W10-1711,W07-0813,0,\N,Missing
W10-1711,N04-4038,0,\N,Missing
W10-1711,D08-1089,0,\N,Missing
W10-1711,P03-1054,0,\N,Missing
W10-1711,P02-1040,0,\N,Missing
W10-1711,W10-1738,1,\N,Missing
W10-1711,W06-3110,1,\N,Missing
W10-1711,J10-3008,0,\N,Missing
W10-1711,2010.iwslt-keynotes.2,0,\N,Missing
W10-1711,P10-2041,0,\N,Missing
W10-1711,N09-1027,0,\N,Missing
W10-1711,P08-2030,0,\N,Missing
W10-1711,W07-0734,0,\N,Missing
W10-1711,N06-2013,0,\N,Missing
W10-1711,N03-1017,0,\N,Missing
W10-1711,2008.iwslt-papers.7,1,\N,Missing
W10-1711,J03-1002,1,\N,Missing
W10-1711,P07-1019,0,\N,Missing
W10-1711,W06-3103,1,\N,Missing
W10-1711,P08-1066,0,\N,Missing
W10-1711,2010.iwslt-papers.15,1,\N,Missing
W10-1711,2006.iwslt-papers.1,1,\N,Missing
W10-1711,2011.iwslt-papers.1,1,\N,Missing
W10-1711,2011.iwslt-papers.7,1,\N,Missing
W10-1711,2011.iwslt-papers.8,1,\N,Missing
W10-1711,N04-1033,1,\N,Missing
W10-1711,2011.iwslt-evaluation.1,0,\N,Missing
W10-1711,W10-1747,1,\N,Missing
W10-1711,D08-1076,0,\N,Missing
W10-1711,P03-1021,0,\N,Missing
W10-1711,2011.iwslt-papers.5,1,\N,Missing
W10-1711,P08-1000,0,\N,Missing
W10-1738,N09-1025,0,0.0105103,"ly the model in search, Jane has to be run with a phrase table that contains word alignment for each phrase, too, with the exception of phrases which are composed purely of non-terminals. Jane’s phrase extraction can optionally supply this information from the training data. (Hasan et al., 2008) and (Hasan and Ney, 2009) employ similar techniques and provide some more discussion on the path-aligned variant of the model and other possible restrictions. 3.6 community. We use an in-house implementation of the method. The second one is the MIRA algorithm, first applied for machine translation in (Chiang et al., 2009). This algorithm is more adequate when the number of parameters to optimize is large. If the Numerical Recipes library (Press et al., 2002) is available, an additional general purpose optimization tool is also compiled. Using this tool a single-best optimization procedure based on the downhill simplex method (Nelder and Mead, 1965) is included. This method, however, can be considered deprecated in favour of the above mentioned methods. 3.8 If the Sun Grid Engine2 is available, all operations of Jane can be parallelized. For the extraction process, the corpus is split into chunks (the granulari"
W10-1738,J07-2003,0,0.602278,"include We also introduce a novel reordering model for the hierarchical phrase-based approach which further enhances translation performance, and analyze the effect some recent extended lexicon models have on the performance of the system. 1 Related Work • SAMT (Zollmann and Venugopal, 2006): The original version is not maintained any more and we had problems working on big corpora. A new version which requires Hadoop has just been released, however the documentation is still missing. Introduction We present a new open source toolkit for hierarchical phrase-based translation, as described in (Chiang, 2007). The hierarchical phrase model is an extension of the standard phrase model, where the phrases are allowed to have “gaps”. In this way, long-distance dependencies and reorderings can be modelled in a consistent way. As in nearly all current statistical approaches to machine translation, this model is embedded in a log-linear model combination. RWTH has been developing this tool during the last two years and it was used successfully in numerous machine translation evaluations. It is developed in C++ with special attention to clean code, extensibility and efficiency. The toolkit is available un"
W10-1738,2009.iwslt-papers.2,0,0.0337704,"provided, one would only need to implement a corresponding frontend which communicates with the translation server (which may be located on another machine). Forced Alignments Jane has also preliminary support for forced alignments between a given source and target sentence. Given a sentence in the source language and its translation in the target language, we find the best way the source sentence can be translated into the given target sentence, using the available inventory of phrases. This is needed for more advanced training approaches like the ones presented in (Blunsom et al., 2008) or (Cmejrek et al., 2009). As reported in these papers, due to the restrictions in the phrase extraction process, not all sentences in the training corpus can be aligned in this way. 3.7 Parallelized operation 3.9 Extensibility One of the goals when implementing the toolkit was to make it easy to extend it with new features. For this, an abstract class was created which we called secondary model. New models need only to derive from this class and implement the abstract methods for data reading and costs computation. This allows for an encapsulation of the computations, which can be activated and deactivated on demand."
W10-1738,N09-2005,1,0.83495,"nstrained triplets is that the first trigger f is restricted to the aligned target word e. The second trigger f 0 is allowed to move along the whole remaining source sentence. For the training of the model, we use word alignment information obtained by GIZA++ (Och and Ney, 2003). To be able to apply the model in search, Jane has to be run with a phrase table that contains word alignment for each phrase, too, with the exception of phrases which are composed purely of non-terminals. Jane’s phrase extraction can optionally supply this information from the training data. (Hasan et al., 2008) and (Hasan and Ney, 2009) employ similar techniques and provide some more discussion on the path-aligned variant of the model and other possible restrictions. 3.6 community. We use an in-house implementation of the method. The second one is the MIRA algorithm, first applied for machine translation in (Chiang et al., 2009). This algorithm is more adequate when the number of parameters to optimize is large. If the Numerical Recipes library (Press et al., 2002) is available, an additional general purpose optimization tool is also compiled. Using this tool a single-best optimization procedure based on the downhill simplex"
W10-1738,W09-0434,0,0.0264578,"Missing"
W10-1738,D08-1039,1,0.886855,"Missing"
W10-1738,P08-1024,0,0.0230148,"code in this direction is provided, one would only need to implement a corresponding frontend which communicates with the translation server (which may be located on another machine). Forced Alignments Jane has also preliminary support for forced alignments between a given source and target sentence. Given a sentence in the source language and its translation in the target language, we find the best way the source sentence can be translated into the given target sentence, using the available inventory of phrases. This is needed for more advanced training approaches like the ones presented in (Blunsom et al., 2008) or (Cmejrek et al., 2009). As reported in these papers, due to the restrictions in the phrase extraction process, not all sentences in the training corpus can be aligned in this way. 3.7 Parallelized operation 3.9 Extensibility One of the goals when implementing the toolkit was to make it easy to extend it with new features. For this, an abstract class was created which we called secondary model. New models need only to derive from this class and implement the abstract methods for data reading and costs computation. This allows for an encapsulation of the computations, which can be activated"
W10-1738,P07-1019,0,0.279989,"thods, we refer to the given literature. 3.1 Search Algorithms 3.3 The search for the best translation proceeds in two steps. First, a monolingual parsing of the input sentence is carried out using the CYK+ algorithm (Chappelier and Rajman, 1998), a generalization of the CYK algorithm which relaxes the requirement for the grammar to be in Chomsky normal form. From the CYK+ chart we extract a hypergraph representing the parsing space. In a second step the translations are generated, computing the language model scores in an integrated fashion. Both the cube pruning and cube growing algorithms (Huang and Chiang, 2007) are implemented. For the latter case, the extensions concerning the language model heuristics similar to (Vilar and Ney, 2009) have also been included. 3.2 Syntactic Features Soft syntactic features comparable to (Vilar et al., 2008) are implemented in the extraction step of the toolkit. In search, they are considered as additional feature functions of the translation rules. The decoder is able to handle an arbitrary number of non-terminal symbols. The extraction has been extended so that the extraction of SAMTrules is included (Zollmann and Venugopal, 2006) but this approach is not fully sup"
W10-1738,J93-2003,0,0.0162587,"Missing"
W10-1738,W09-0424,0,0.0228497,"stent way. As in nearly all current statistical approaches to machine translation, this model is embedded in a log-linear model combination. RWTH has been developing this tool during the last two years and it was used successfully in numerous machine translation evaluations. It is developed in C++ with special attention to clean code, extensibility and efficiency. The toolkit is available under an open source non-commercial license and downloadable from http://www.hltpr.rwth-aachen.de/jane. In this paper we give an overview of the main features of the toolkit and introduce two new ex• Joshua (Li et al., 2009): A decoder written in Java by the John Hopkins University. This project is the most similar to our own, however both were developed independently and each one has some unique features. A brief comparison between these two systems is included in Section 5.1. • Moses (Koehn et al., 2007): The de-facto standard phrase-based translation decoder has now been extended to support hierarchical translation. This is still in an experimental branch, however. 3 Features In this section we will only give a brief overview of the features implemented in Jane. For detailed explanation of previously published"
W10-1738,J97-3002,0,0.0234206,"tion information into account, i.e. it operates on sets, not on sequences or even trees. The probability of a word being part of the target sentence, given a set of source words, are decomposed into binary features, one for each source vocabulary entry. These binary features are combined in a log-linear fashion with corresponding feature weights. The discriminative word lexicon is trained independently for each target word using the L-BFGS (Byrd et al., 1995) algorithm. For regularization, Gaussian priors are utilized. DWL model probabilities are computed as be to include the ITG-Reorderings (Wu, 1997), by adding following rule S → hS ∼0 S ∼1 , S ∼1 S ∼0 i (2) We can also model other reordering constraints. As an example, phrase-level IBM reordering constraints with a window length of 1 can be included substituting the rules in Equation (1) with following rules S → hM ∼0 , M ∼0 i S → hM ∼0 S ∼1 , M ∼0 S ∼1 i S → hB ∼0 M ∼1 , M ∼1 B ∼0 i M → hX ∼0 , X ∼0 i (3) M → hM ∼0 X ∼1 , M ∼0 X ∼1 i B → hX ∼0 , X ∼0 i B → hB ∼0 X ∼1 , X ∼1 B ∼0 i In these rules we have added two additional nonterminals. The M non-terminal denotes a monotonic block and the B non-terminal a back jump. Actually both of th"
W10-1738,D09-1022,1,0.416911,"(·) of the application of a rule X → hα, βi where (α, β) is a bilingual phrase pair that may contain symbols from the non-terminal set is computed as Extended Lexicon Models We enriched Jane with the ability to score hypotheses with discriminative and trigger-based lexicon models that use global source sentence context and are capable of predicting contextspecific target words. This approach has recently been shown to improve the translation results of conventional phrase-based systems. In this section, we briefly review the basic aspects of these extended lexicon models. They are similar to (Mauser et al., 2009), and we refer there for a more detailed exposition on the training procedures and results in conventional phrase-based decoding. Note that the training for these models is not distributed together with Jane. t(α, β, f0J ) = (5)   X XX 2 − log  p(e|fj , fj 0 ) J · (J + 1) 0 e j 264 j >j with e ranging over all terminal symbols in the target part β of the rule. The second sum selects all words from the source sentence f0J (including the empty word that is denoted as f0 here). The third sum incorporates the rest of the source sentence right of the first triggering word. The order of the trig"
W10-1738,N07-1062,1,0.242945,"n Methods Two method based on n-best for minimum error rate training (MERT) of the parameters of the loglinear model are included in Jane. The first one is the procedure described in (Och, 2003), which has become a standard in the machine translation 2 265 http://www.sun.com/software/sge/ through 3.5 are implemented in this way. We thus try to achieve loose coupling in the implementation. In addition a flexible prefix tree implementation with on-demand loading capabilities is included as part of the code. This class has been used for implementing on-demand loading of phrases in the spirit of (Zens and Ney, 2007) and the on-demand n-gram format described in Section 3.2, in addition to some intermediate steps in the phrase extraction process. The code may also be reused in other, independent projects. 3.10 System Jane baseline + reordering 4.1 24.2 59.5 25.2 58.2 25.4 57.4 26.5 56.1 Europarl Data The first task is the Europarl as defined in the Quaero project. The main part of the corpus in this task consists of the Europarl corpus as used in the WMT evaluation (Callison-Burch et al., 2009), with some additional data collected in the scope of the project. We tried the reordering approach presented in S"
W10-1738,J03-1002,1,0.0139727,"triggers is not relevant because per definition p(e|f, f 0 ) = p(e|f 0 , f ), i.e. the model is symmetric. Non-terminals in β have to be skipped when the rule is scored. In Jane, we also implemented scoring for a variant of the triplet lexicon model called the pathconstrained (or path-aligned) triplet model. The characteristic of path-constrained triplets is that the first trigger f is restricted to the aligned target word e. The second trigger f 0 is allowed to move along the whole remaining source sentence. For the training of the model, we use word alignment information obtained by GIZA++ (Och and Ney, 2003). To be able to apply the model in search, Jane has to be run with a phrase table that contains word alignment for each phrase, too, with the exception of phrases which are composed purely of non-terminals. Jane’s phrase extraction can optionally supply this information from the training data. (Hasan et al., 2008) and (Hasan and Ney, 2009) employ similar techniques and provide some more discussion on the path-aligned variant of the model and other possible restrictions. 3.6 community. We use an in-house implementation of the method. The second one is the MIRA algorithm, first applied for machi"
W10-1738,W06-3119,0,0.106679,"Jane implements many features presented in previous work developed both at RWTH and other groups. As we go over the features of the system we will provide the corresponding references. Jane is not the first system of its kind, although it provides some unique features. There are other open source hierarchical decoders available. These include We also introduce a novel reordering model for the hierarchical phrase-based approach which further enhances translation performance, and analyze the effect some recent extended lexicon models have on the performance of the system. 1 Related Work • SAMT (Zollmann and Venugopal, 2006): The original version is not maintained any more and we had problems working on big corpora. A new version which requires Hadoop has just been released, however the documentation is still missing. Introduction We present a new open source toolkit for hierarchical phrase-based translation, as described in (Chiang, 2007). The hierarchical phrase model is an extension of the standard phrase model, where the phrases are allowed to have “gaps”. In this way, long-distance dependencies and reorderings can be modelled in a consistent way. As in nearly all current statistical approaches to machine tra"
W10-1738,P03-1021,0,0.035126,"ting the toolkit was to make it easy to extend it with new features. For this, an abstract class was created which we called secondary model. New models need only to derive from this class and implement the abstract methods for data reading and costs computation. This allows for an encapsulation of the computations, which can be activated and deactivated on demand. The models described in Sections 3.3 Optimization Methods Two method based on n-best for minimum error rate training (MERT) of the parameters of the loglinear model are included in Jane. The first one is the procedure described in (Och, 2003), which has become a standard in the machine translation 2 265 http://www.sun.com/software/sge/ through 3.5 are implemented in this way. We thus try to achieve loose coupling in the implementation. In addition a flexible prefix tree implementation with on-demand loading capabilities is included as part of the code. This class has been used for implementing on-demand loading of phrases in the spirit of (Zens and Ney, 2007) and the on-demand n-gram format described in Section 3.2, in addition to some intermediate steps in the phrase extraction process. The code may also be reused in other, indep"
W10-1738,P08-1066,0,0.0313191,"al feature functions of the translation rules. The decoder is able to handle an arbitrary number of non-terminal symbols. The extraction has been extended so that the extraction of SAMTrules is included (Zollmann and Venugopal, 2006) but this approach is not fully supported (there may be empty parses due to the extended number of non-terminals). We instead opted to support the generalization presented in (Venugopal et al., 2009), where the information about the new non-terminals is included as an additional feature in the log-linear model. In addition, dependency information in the spirit of (Shen et al., 2008) is included. Jane features models for string-to-dependency language models and computes various scores based on the well-formedness of the resulting dependency tree. Jane supports the Stanford parsing format,1 but can be easily extended to other parsers. Language Models Jane supports four formats for n-gram language models: • The ARPA format for language models. We use the SRI toolkit (Stolcke, 2002) to support this format. 3.4 • The binary language model format supported by the SRI toolkit. This format allows for a more efficient language model storage, which reduces loading times. In order"
W10-1738,D07-1049,0,0.0186097,"Missing"
W10-1738,N09-1027,0,0.0826285,"n included. 3.2 Syntactic Features Soft syntactic features comparable to (Vilar et al., 2008) are implemented in the extraction step of the toolkit. In search, they are considered as additional feature functions of the translation rules. The decoder is able to handle an arbitrary number of non-terminal symbols. The extraction has been extended so that the extraction of SAMTrules is included (Zollmann and Venugopal, 2006) but this approach is not fully supported (there may be empty parses due to the extended number of non-terminals). We instead opted to support the generalization presented in (Venugopal et al., 2009), where the information about the new non-terminals is included as an additional feature in the log-linear model. In addition, dependency information in the spirit of (Shen et al., 2008) is included. Jane features models for string-to-dependency language models and computes various scores based on the well-formedness of the resulting dependency tree. Jane supports the Stanford parsing format,1 but can be easily extended to other parsers. Language Models Jane supports four formats for n-gram language models: • The ARPA format for language models. We use the SRI toolkit (Stolcke, 2002) to suppor"
W10-1738,2009.eamt-1.33,1,0.841467,"t, a monolingual parsing of the input sentence is carried out using the CYK+ algorithm (Chappelier and Rajman, 1998), a generalization of the CYK algorithm which relaxes the requirement for the grammar to be in Chomsky normal form. From the CYK+ chart we extract a hypergraph representing the parsing space. In a second step the translations are generated, computing the language model scores in an integrated fashion. Both the cube pruning and cube growing algorithms (Huang and Chiang, 2007) are implemented. For the latter case, the extensions concerning the language model heuristics similar to (Vilar and Ney, 2009) have also been included. 3.2 Syntactic Features Soft syntactic features comparable to (Vilar et al., 2008) are implemented in the extraction step of the toolkit. In search, they are considered as additional feature functions of the translation rules. The decoder is able to handle an arbitrary number of non-terminal symbols. The extraction has been extended so that the extraction of SAMTrules is included (Zollmann and Venugopal, 2006) but this approach is not fully supported (there may be empty parses due to the extended number of non-terminals). We instead opted to support the generalization"
W10-1738,2008.iwslt-papers.7,1,0.842545,"n, 1998), a generalization of the CYK algorithm which relaxes the requirement for the grammar to be in Chomsky normal form. From the CYK+ chart we extract a hypergraph representing the parsing space. In a second step the translations are generated, computing the language model scores in an integrated fashion. Both the cube pruning and cube growing algorithms (Huang and Chiang, 2007) are implemented. For the latter case, the extensions concerning the language model heuristics similar to (Vilar and Ney, 2009) have also been included. 3.2 Syntactic Features Soft syntactic features comparable to (Vilar et al., 2008) are implemented in the extraction step of the toolkit. In search, they are considered as additional feature functions of the translation rules. The decoder is able to handle an arbitrary number of non-terminal symbols. The extraction has been extended so that the extraction of SAMTrules is included (Zollmann and Venugopal, 2006) but this approach is not fully supported (there may be empty parses due to the extended number of non-terminals). We instead opted to support the generalization presented in (Venugopal et al., 2009), where the information about the new non-terminals is included as an"
W10-1738,W09-0401,0,\N,Missing
W10-1738,P07-2045,0,\N,Missing
W10-1738,D08-1076,0,\N,Missing
W10-1747,E06-1005,1,0.913623,"es by N . The word alignment is trained in analogy to the alignment training procedure in statistical MT. The difference is that the two sentences that have to be aligned are in the same language. We use the IBM Model 1 (Brown et al., 1993) and the Hidden Markov Model (HMM, (Vogel et al., 1996)) The RWTH approach to MT system combination is a refined version of the ROVER approach in ASR (Fiscus, 1997), with additional steps to cope with reordering between different hypotheses, and to use true casing information from the input hypotheses. The basic concept of the approach has been described by Matusov et al. (2006). Several improvements have been added later (Matusov et al., 2008). This approach includes an enhanced alignment and reordering framework. In contrast to existing approaches (Jayaraman and Lavie, 2005; Rosti et al., 2007), the context of the whole corpus rather than a single sentence is considered in this iterative, unsupervised procedure, yielding a more reliable alignment. Majority voting on the generated lattice is performed using prior weights for each system as well as other statistical models such as a special n-gram language model. In addition to lattice rescoring, n-best list rerankin"
W10-1747,mauser-etal-2008-automatic,1,0.849685,"Note that the scores reported for DEV are calculated on the full DEV set, but not on any combination of the one-fifth “cross validation” subcorpora. Tuning Tuning Weights for Lattice and n-best Rescoring For lattice rescoring, we need to tune system weights, LM factor, and word penalty to produce good consensus translations. The same holds for the log-linear weights in n-best reranking. For the WMT 2010 Workshop, we selected a linear combination of BLEU (Papineni et al., 2002) and TER (Snover et al., 2006) as optimizaˆ := argmaxΘ {BLEU − T ER}, tion criterion, Θ based on previous experience (Mauser et al., 2008). For more stable results, we use the caseinsensitive variants for both measures, despite the explicit use of case information in the pipeline. System weights were tuned to this criterion using the Downhill Simplex method. Because we considered the number of segments in the tuning set to be too small to allow for a further split into an actual tuning and a control (dev) part, we went for a method closely related to 5-fold cross validation: We randomly split the tuning set into 5 equalsized parts, and tune parameters on four fifth of the set, measuring progress on the remaining fifth. This was"
W10-1747,D09-1022,1,0.864425,"Missing"
W10-1747,J03-1002,1,0.0181973,"rkshop on Statistical Machine Translation and MetricsMATR, pages 315–320, c Uppsala, Sweden, 15-16 July 2010. 2010 Association for Computational Linguistics Hyp 1 ... Hyp k GIZA++alignment Reordering Network generation Weighting & Rescoring 200-best list nbest rescoring (Triplets, LM, ...) Consensus Translation Figure 1: The system combination architecture. 2.4 to estimate the alignment model. The alignment training corpus is created from a test corpus of effectively N ·(M −1)·K sentences translated by the involved MT engines. Model parameters are trained iteratively using the GIZA++ toolkit (Och and Ney, 2003). The training is performed in the directions Em → En and En → Em . The final alignments are determined using a cost matrix C for each sentence pair (Em , En ). Elements of this matrix are the local costs C(j, i) of aligning a word em,j from Em to a word en,i from En . Following Matusov et al. (2004), we compute these local costs by interpolating the negated logarithms of the state occupation probabilities from the “source-to-target” and “target-tosource” training of the HMM model. 2.2 The lattice representing a union of several confusion networks can then be directly rescored with an n-gram l"
W10-1747,P02-1040,0,0.0874682,"ination output to WMT 2010, we also calculated scores on the test set (TEST), to validate our results, and as a preparation for this report. Note that the scores reported for DEV are calculated on the full DEV set, but not on any combination of the one-fifth “cross validation” subcorpora. Tuning Tuning Weights for Lattice and n-best Rescoring For lattice rescoring, we need to tune system weights, LM factor, and word penalty to produce good consensus translations. The same holds for the log-linear weights in n-best reranking. For the WMT 2010 Workshop, we selected a linear combination of BLEU (Papineni et al., 2002) and TER (Snover et al., 2006) as optimizaˆ := argmaxΘ {BLEU − T ER}, tion criterion, Θ based on previous experience (Mauser et al., 2008). For more stable results, we use the caseinsensitive variants for both measures, despite the explicit use of case information in the pipeline. System weights were tuned to this criterion using the Downhill Simplex method. Because we considered the number of segments in the tuning set to be too small to allow for a further split into an actual tuning and a control (dev) part, we went for a method closely related to 5-fold cross validation: We randomly split"
W10-1747,J93-2003,0,0.0183608,"he secondary hypotheses Em (m = 1, . . . , M ; n 6= m) with En to match the word order in En . Since it is not clear which hypothesis should be primary, i. e. has the “best” word order, we let several or all hypothesis play the role of the primary translation, and align all pairs of hypotheses (En , Em ); n 6= m. In this paper, we denote the number of possible primary hypotheses by N . The word alignment is trained in analogy to the alignment training procedure in statistical MT. The difference is that the two sentences that have to be aligned are in the same language. We use the IBM Model 1 (Brown et al., 1993) and the Hidden Markov Model (HMM, (Vogel et al., 1996)) The RWTH approach to MT system combination is a refined version of the ROVER approach in ASR (Fiscus, 1997), with additional steps to cope with reordering between different hypotheses, and to use true casing information from the input hypotheses. The basic concept of the approach has been described by Matusov et al. (2006). Several improvements have been added later (Matusov et al., 2008). This approach includes an enhanced alignment and reordering framework. In contrast to existing approaches (Jayaraman and Lavie, 2005; Rosti et al., 20"
W10-1747,P07-1040,0,0.349427,"wn et al., 1993) and the Hidden Markov Model (HMM, (Vogel et al., 1996)) The RWTH approach to MT system combination is a refined version of the ROVER approach in ASR (Fiscus, 1997), with additional steps to cope with reordering between different hypotheses, and to use true casing information from the input hypotheses. The basic concept of the approach has been described by Matusov et al. (2006). Several improvements have been added later (Matusov et al., 2008). This approach includes an enhanced alignment and reordering framework. In contrast to existing approaches (Jayaraman and Lavie, 2005; Rosti et al., 2007), the context of the whole corpus rather than a single sentence is considered in this iterative, unsupervised procedure, yielding a more reliable alignment. Majority voting on the generated lattice is performed using prior weights for each system as well as other statistical models such as a special n-gram language model. In addition to lattice rescoring, n-best list reranking techniques can be applied to n best paths of this lattice. True casing is considered a separate step in RWTH’s approach, which also takes the input hypotheses into account. 315 Proceedings of the Joint 5th Workshop on St"
W10-1747,D08-1039,1,0.89414,"Missing"
W10-1747,2006.amta-papers.25,0,0.0416845,"lso calculated scores on the test set (TEST), to validate our results, and as a preparation for this report. Note that the scores reported for DEV are calculated on the full DEV set, but not on any combination of the one-fifth “cross validation” subcorpora. Tuning Tuning Weights for Lattice and n-best Rescoring For lattice rescoring, we need to tune system weights, LM factor, and word penalty to produce good consensus translations. The same holds for the log-linear weights in n-best reranking. For the WMT 2010 Workshop, we selected a linear combination of BLEU (Papineni et al., 2002) and TER (Snover et al., 2006) as optimizaˆ := argmaxΘ {BLEU − T ER}, tion criterion, Θ based on previous experience (Mauser et al., 2008). For more stable results, we use the caseinsensitive variants for both measures, despite the explicit use of case information in the pipeline. System weights were tuned to this criterion using the Downhill Simplex method. Because we considered the number of segments in the tuning set to be too small to allow for a further split into an actual tuning and a control (dev) part, we went for a method closely related to 5-fold cross validation: We randomly split the tuning set into 5 equalsiz"
W10-1747,P05-3026,0,0.0299559,"We use the IBM Model 1 (Brown et al., 1993) and the Hidden Markov Model (HMM, (Vogel et al., 1996)) The RWTH approach to MT system combination is a refined version of the ROVER approach in ASR (Fiscus, 1997), with additional steps to cope with reordering between different hypotheses, and to use true casing information from the input hypotheses. The basic concept of the approach has been described by Matusov et al. (2006). Several improvements have been added later (Matusov et al., 2008). This approach includes an enhanced alignment and reordering framework. In contrast to existing approaches (Jayaraman and Lavie, 2005; Rosti et al., 2007), the context of the whole corpus rather than a single sentence is considered in this iterative, unsupervised procedure, yielding a more reliable alignment. Majority voting on the generated lattice is performed using prior weights for each system as well as other statistical models such as a special n-gram language model. In addition to lattice rescoring, n-best list reranking techniques can be applied to n best paths of this lattice. True casing is considered a separate step in RWTH’s approach, which also takes the input hypotheses into account. 315 Proceedings of the Joi"
W10-1747,C96-2141,1,0.504928,"with En to match the word order in En . Since it is not clear which hypothesis should be primary, i. e. has the “best” word order, we let several or all hypothesis play the role of the primary translation, and align all pairs of hypotheses (En , Em ); n 6= m. In this paper, we denote the number of possible primary hypotheses by N . The word alignment is trained in analogy to the alignment training procedure in statistical MT. The difference is that the two sentences that have to be aligned are in the same language. We use the IBM Model 1 (Brown et al., 1993) and the Hidden Markov Model (HMM, (Vogel et al., 1996)) The RWTH approach to MT system combination is a refined version of the ROVER approach in ASR (Fiscus, 1997), with additional steps to cope with reordering between different hypotheses, and to use true casing information from the input hypotheses. The basic concept of the approach has been described by Matusov et al. (2006). Several improvements have been added later (Matusov et al., 2008). This approach includes an enhanced alignment and reordering framework. In contrast to existing approaches (Jayaraman and Lavie, 2005; Rosti et al., 2007), the context of the whole corpus rather than a sing"
W10-1747,W09-0407,1,0.201857,"ing systems, and ran an exhaustive search on all combinations of those to optimize the LM perplexity on the dev set (LM) or the true case BLEU/TER score on a consensus translation (TC). Further research may include a weighted combination here, followed by an optimization of the weights as described in the previous paragraph. 2.7 Consensus True Casing Previous approaches to achieve true cased output in system combination operated on true-cased lattices, used a separate input-independent true caser, or used a general true-cased LM to differentiate between alternative arcs in the lattice, as in (Leusch et al., 2009). For WMT 2010, we use per-sentence information from the input systems to determine the consensus case of each output word. Lattice generation, rescoring, and reranking are performed on lower-cased input, with a lower-cased consensus hypothesis as their result. For each word in this hypothesis, we count how often each casing variant occurs in the input hypotheses for this sentence. We then use the variant with the highest support for the final consensus output. One advantage is that the set of systems used to determine the consensus case does not have to be identical to those used for building"
W10-1747,W06-3110,1,0.878884,"as primary, and unite them into a single lattice. In our experience, this approach is advantageous in terms of translation quality compared to a minimum Bayes risk primary (Rosti et al., 2007). Weighted majority voting on a single confusion network is straightforward and analogous to ROVER (Fiscus, 1997). We sum up the probabilities of the arcs which are labeled with the same word and have the same start state and the same end state. This can also be regarded as having a binary system feature in a log-linear model. 1. Total score from the lattice rescoring 2. NGram posterior weights on those (Zens and Ney, 2006) 3. Word Penalty 4. HypLM trained on a different set of hypotheses (FR–EN only) 5. Large fourgram model trained on Gigaword (DE–EN) or Europarl (FR–EN) 6. IBM1 scores and deletion counts based on a word lexicon trained on WMT training data 316 7. Discriminative word lexicon score (Mauser et al., 2009) 8. Triplet lexicon score (Hasan et al., 2008) later on the test set. For the actual weights and numerical parameters to be used on the test set, we calculate the median of the five variants, which lowered the risk of outliers and overfitting. Other features were also calculated, but did not seem"
W10-1747,C04-1032,1,0.872746,"us Translation Figure 1: The system combination architecture. 2.4 to estimate the alignment model. The alignment training corpus is created from a test corpus of effectively N ·(M −1)·K sentences translated by the involved MT engines. Model parameters are trained iteratively using the GIZA++ toolkit (Och and Ney, 2003). The training is performed in the directions Em → En and En → Em . The final alignments are determined using a cost matrix C for each sentence pair (Em , En ). Elements of this matrix are the local costs C(j, i) of aligning a word em,j from Em to a word en,i from En . Following Matusov et al. (2004), we compute these local costs by interpolating the negated logarithms of the state occupation probabilities from the “source-to-target” and “target-tosource” training of the HMM model. 2.2 The lattice representing a union of several confusion networks can then be directly rescored with an n-gram language model (LM). A transformation of the lattice is required, since LM history has to be memorized. We train a trigram LM on the outputs of the systems involved in system combination. For LM training, we take the system hypotheses for the same test corpus for which the consensus translations are t"
W10-1747,2005.eamt-1.20,0,\N,Missing
W11-2118,J93-2003,0,0.0273888,"t MT systems E, m = 1, . . . , N, as the primary hypothesis. Then we align the secondary hypotheses En (n = 1, . . . , ; n 6= m) with En to match the word order in En . Since it is not clear which hypothesis should be primary, i. e. has the “best” word order, we let several or all hypothesis play the role of the primary translation, and align all pairs of hypotheses (En , Em ); n 6= m. The word alignment is trained in analogy to the alignment training procedure in statistical MT. The difference is that the two sentences that have to be aligned are in the same language. We use the IBM Model 1 (Brown et al., 1993) and the Hidden Markov Model (HMM, (Vogel et al., 1996)) to estimate the alignment model. The alignment training corpus is created from a test corpus of effectively N · (N − 1) · K sentences translated by the involved MT engines. Model parameters are trained iteratively using the GIZA++ toolkit (Och and Ney, 2003). The training is performed in the directions Em → En and En → Em . The final alignments are determined using a cost matrix C for each sentence pair (Em , En ). Elements of this matrix are the local costs C(j, i) of aligning a word em,j from Em to a word en,i from En . Following Matus"
W11-2118,N07-2017,1,0.896356,"Missing"
W11-2118,P05-3026,0,0.0121174,"ization techniques. 1 Introduction RWTH’s main approach to System Combination (SC) for Machine Translation (MT) is a refined version of the ROVER approach in Automatic Speech Recognition (ASR) (Fiscus, 1997), with additional steps to cope with reordering between different hypotheses, and to use true casing information from the input hypotheses. The basic concept of the approach has been described by Matusov et al. (2006). Several improvements have been added later (Matusov et al., 2008). This approach includes an enhanced alignment and reordering framework. In contrast to existing approaches (Jayaraman and Lavie, 2005; Rosti et al., 2007b), the context of the whole corpus rather than a single sentence is considered in this iterative, unsupervised procedure, yielding a more reliable alignment. Majority voting on the generated lattice is performed using prior weights for each system as well as other statistical models such as a special n-gram language model. True casing is considered a separate step in RWTH’s approach, which also takes the input hypotheses into account. The pipeline, and consequently the description of the main pipeline given in this paper, is based on our pipeline for WMT 2010 (Leusch and N"
W11-2118,W10-1747,1,0.266304,"Lavie, 2005; Rosti et al., 2007b), the context of the whole corpus rather than a single sentence is considered in this iterative, unsupervised procedure, yielding a more reliable alignment. Majority voting on the generated lattice is performed using prior weights for each system as well as other statistical models such as a special n-gram language model. True casing is considered a separate step in RWTH’s approach, which also takes the input hypotheses into account. The pipeline, and consequently the description of the main pipeline given in this paper, is based on our pipeline for WMT 2010 (Leusch and Ney, 2010), with extensions as described. When necessary, we denote this pipeline as Align-toLattice, or A2L . For the French–English task, we used two additional system combination engines for the first time: The first one uses the same alignments as A2L, but generates lattices in the OpenFST framework (Allauzen et al., 2007). The OpenFST decoder (fstshortestpath) is then used to find the best path (consensus translation) in this lattice. Analogously, we call this engine A2FST . The second additional engine, which we call SCUNC, uses a TER-based alignment, similar to the approach by Rosti et al. (2007b"
W11-2118,W09-0407,1,0.524409,"cores. As this approach requires strict CN instead of lattices, a union of CNs for different primary hypotheses was no longer possible. We decided to select a fixed single primary system; other approaches would have been to train an additional classifier for this purpose, or to select a minimum-Bayesrisk (MBR) skeleton. Consensus True Casing Previous approaches to achieve true cased output in system combination operated on true-cased lattices, used a separate input-independent true caser, or used a general true-cased LM to differentiate between alternative arcs in the lattice, as described by Leusch et al. (2009). For WMT 2011, we use per-sentence information from the input systems to determine the consensus case of each output word. Lattice generation, rescoring, and reranking are performed on lower-cased input, with a lower-cased consensus hypothesis as their result. For each word in this hypothesis, we count how often each casing variant occurs in the input hypotheses for this sentence. We then use the variant with the highest support for the final consensus output. combination process. This is especially the case since several of these e.g. 25 systems are often only small variants of each other (c"
W11-2118,C04-1072,0,0.0734446,"Missing"
W11-2118,D08-1076,0,0.0530089,"ation of BLEU (Papineni et al., 2002) and TER (Snover et al., 2006) as optimization criterion, ˆ := argmaxΘ {BLEU − T ER} for the A2L Θ engine, based on previous experience (Mauser et al., 2008). To achieve more stable results, we use the case-insensitive variants for both measures, despite the explicit use of case information in the pipeline. System weights were tuned to this criterion using the Downhill Simplex method. In the A2FST setup, we were able to generate full lattices, with separate costs for each individual feature on all arcs (Power Semiring). This allowed us to run Lattice MERT (Macherey et al., 2008) on the full lattice, with no need for pruning (and thus additional outer iterations for re-generating lattices). We tried different strategies – random lines vs axis-parallel lines, regularization, random restarts, etc, and selected the most stable results on TUNE and DEV for this engine. Optimization criterion here was BLEU. 3.2 Training a classifier for SCUNC In MT system combination, even with given reference translations, there is no simple way to identify the “correct” arc in a slot. This renders a classifier-based approach even more difficult than iROVER in ASR. The problem is even aggr"
W11-2118,C04-1032,1,0.82067,"1993) and the Hidden Markov Model (HMM, (Vogel et al., 1996)) to estimate the alignment model. The alignment training corpus is created from a test corpus of effectively N · (N − 1) · K sentences translated by the involved MT engines. Model parameters are trained iteratively using the GIZA++ toolkit (Och and Ney, 2003). The training is performed in the directions Em → En and En → Em . The final alignments are determined using a cost matrix C for each sentence pair (Em , En ). Elements of this matrix are the local costs C(j, i) of aligning a word em,j from Em to a word en,i from En . Following Matusov et al. (2004), we compute these local costs by interpolating the negated logarithms of the state occupation probabilities from the “source-to-target” and “target-tosource” training of the HMM model. A different approach that has e.g. been proposed by Rosti et al. (2007b) is the utilization of a TER alignment (Snover et al., 2006) for this purpose. Because the original TER is insensitive to small changes in spellings, synonyms etc., it has been proposed to use more complex variants, e.g. 153 2.2 2.3 Word Reordering and Confusion Network Generation Voting in the Confusion Network (A2L, A2FST) Instead of choo"
W11-2118,E06-1005,1,0.89725,"n TER. Novel techniques compared with RWTH’s submission to WMT 2010 include two additional system combination engines, an additional word alignment technique, meta combination, and additional optimization techniques. 1 Introduction RWTH’s main approach to System Combination (SC) for Machine Translation (MT) is a refined version of the ROVER approach in Automatic Speech Recognition (ASR) (Fiscus, 1997), with additional steps to cope with reordering between different hypotheses, and to use true casing information from the input hypotheses. The basic concept of the approach has been described by Matusov et al. (2006). Several improvements have been added later (Matusov et al., 2008). This approach includes an enhanced alignment and reordering framework. In contrast to existing approaches (Jayaraman and Lavie, 2005; Rosti et al., 2007b), the context of the whole corpus rather than a single sentence is considered in this iterative, unsupervised procedure, yielding a more reliable alignment. Majority voting on the generated lattice is performed using prior weights for each system as well as other statistical models such as a special n-gram language model. True casing is considered a separate step in RWTH’s a"
W11-2118,mauser-etal-2008-automatic,1,0.842143,"considering those as primary, adding further systems as additional secondaries. Depending on the engine we were using, we selected between 6 and 14 different systems as input. Table 1: Corpus and Task statistics. FR–EN DE–EN ES–EN # sent 3 3.1 avg. # words TUNE DEV TEST 15670 11410 49832 15508 10878 49395 15989 11234 50612 609 394 2000 #sys 25 24 15 Tuning Feature weights For lattice rescoring, we selected a linear combination of BLEU (Papineni et al., 2002) and TER (Snover et al., 2006) as optimization criterion, ˆ := argmaxΘ {BLEU − T ER} for the A2L Θ engine, based on previous experience (Mauser et al., 2008). To achieve more stable results, we use the case-insensitive variants for both measures, despite the explicit use of case information in the pipeline. System weights were tuned to this criterion using the Downhill Simplex method. In the A2FST setup, we were able to generate full lattices, with separate costs for each individual feature on all arcs (Power Semiring). This allowed us to run Lattice MERT (Macherey et al., 2008) on the full lattice, with no need for pruning (and thus additional outer iterations for re-generating lattices). We tried different strategies – random lines vs axis-paral"
W11-2118,J03-1002,1,0.0137454,"imary translation, and align all pairs of hypotheses (En , Em ); n 6= m. The word alignment is trained in analogy to the alignment training procedure in statistical MT. The difference is that the two sentences that have to be aligned are in the same language. We use the IBM Model 1 (Brown et al., 1993) and the Hidden Markov Model (HMM, (Vogel et al., 1996)) to estimate the alignment model. The alignment training corpus is created from a test corpus of effectively N · (N − 1) · K sentences translated by the involved MT engines. Model parameters are trained iteratively using the GIZA++ toolkit (Och and Ney, 2003). The training is performed in the directions Em → En and En → Em . The final alignments are determined using a cost matrix C for each sentence pair (Em , En ). Elements of this matrix are the local costs C(j, i) of aligning a word em,j from Em to a word en,i from En . Following Matusov et al. (2004), we compute these local costs by interpolating the negated logarithms of the state occupation probabilities from the “source-to-target” and “target-tosource” training of the HMM model. A different approach that has e.g. been proposed by Rosti et al. (2007b) is the utilization of a TER alignment (S"
W11-2118,P02-1040,0,0.0824241,"e set of input systems, often starting from the top, and either replacing some of the systems very similar to others with systems further down the list, or not considering those as primary, adding further systems as additional secondaries. Depending on the engine we were using, we selected between 6 and 14 different systems as input. Table 1: Corpus and Task statistics. FR–EN DE–EN ES–EN # sent 3 3.1 avg. # words TUNE DEV TEST 15670 11410 49832 15508 10878 49395 15989 11234 50612 609 394 2000 #sys 25 24 15 Tuning Feature weights For lattice rescoring, we selected a linear combination of BLEU (Papineni et al., 2002) and TER (Snover et al., 2006) as optimization criterion, ˆ := argmaxΘ {BLEU − T ER} for the A2L Θ engine, based on previous experience (Mauser et al., 2008). To achieve more stable results, we use the case-insensitive variants for both measures, despite the explicit use of case information in the pipeline. System weights were tuned to this criterion using the Downhill Simplex method. In the A2FST setup, we were able to generate full lattices, with separate costs for each individual feature on all arcs (Power Semiring). This allowed us to run Lattice MERT (Macherey et al., 2008) on the full la"
W11-2118,N07-1029,0,0.692594,"duction RWTH’s main approach to System Combination (SC) for Machine Translation (MT) is a refined version of the ROVER approach in Automatic Speech Recognition (ASR) (Fiscus, 1997), with additional steps to cope with reordering between different hypotheses, and to use true casing information from the input hypotheses. The basic concept of the approach has been described by Matusov et al. (2006). Several improvements have been added later (Matusov et al., 2008). This approach includes an enhanced alignment and reordering framework. In contrast to existing approaches (Jayaraman and Lavie, 2005; Rosti et al., 2007b), the context of the whole corpus rather than a single sentence is considered in this iterative, unsupervised procedure, yielding a more reliable alignment. Majority voting on the generated lattice is performed using prior weights for each system as well as other statistical models such as a special n-gram language model. True casing is considered a separate step in RWTH’s approach, which also takes the input hypotheses into account. The pipeline, and consequently the description of the main pipeline given in this paper, is based on our pipeline for WMT 2010 (Leusch and Ney, 2010), with exte"
W11-2118,P07-1040,0,0.676647,"duction RWTH’s main approach to System Combination (SC) for Machine Translation (MT) is a refined version of the ROVER approach in Automatic Speech Recognition (ASR) (Fiscus, 1997), with additional steps to cope with reordering between different hypotheses, and to use true casing information from the input hypotheses. The basic concept of the approach has been described by Matusov et al. (2006). Several improvements have been added later (Matusov et al., 2008). This approach includes an enhanced alignment and reordering framework. In contrast to existing approaches (Jayaraman and Lavie, 2005; Rosti et al., 2007b), the context of the whole corpus rather than a single sentence is considered in this iterative, unsupervised procedure, yielding a more reliable alignment. Majority voting on the generated lattice is performed using prior weights for each system as well as other statistical models such as a special n-gram language model. True casing is considered a separate step in RWTH’s approach, which also takes the input hypotheses into account. The pipeline, and consequently the description of the main pipeline given in this paper, is based on our pipeline for WMT 2010 (Leusch and Ney, 2010), with exte"
W11-2118,2006.amta-papers.25,0,0.402318,"). The training is performed in the directions Em → En and En → Em . The final alignments are determined using a cost matrix C for each sentence pair (Em , En ). Elements of this matrix are the local costs C(j, i) of aligning a word em,j from Em to a word en,i from En . Following Matusov et al. (2004), we compute these local costs by interpolating the negated logarithms of the state occupation probabilities from the “source-to-target” and “target-tosource” training of the HMM model. A different approach that has e.g. been proposed by Rosti et al. (2007b) is the utilization of a TER alignment (Snover et al., 2006) for this purpose. Because the original TER is insensitive to small changes in spellings, synonyms etc., it has been proposed to use more complex variants, e.g. 153 2.2 2.3 Word Reordering and Confusion Network Generation Voting in the Confusion Network (A2L, A2FST) Instead of choosing a fixed sentence to define the word order for the consensus translation, we generate confusion networks for N possible hypotheses as primary, and unite them into a single lattice. In our experience, this approach is advantageous in terms of translation quality compared to a minimum Bayes risk primary (Rosti et a"
W11-2118,C96-2141,1,0.551068,"esis. Then we align the secondary hypotheses En (n = 1, . . . , ; n 6= m) with En to match the word order in En . Since it is not clear which hypothesis should be primary, i. e. has the “best” word order, we let several or all hypothesis play the role of the primary translation, and align all pairs of hypotheses (En , Em ); n 6= m. The word alignment is trained in analogy to the alignment training procedure in statistical MT. The difference is that the two sentences that have to be aligned are in the same language. We use the IBM Model 1 (Brown et al., 1993) and the Hidden Markov Model (HMM, (Vogel et al., 1996)) to estimate the alignment model. The alignment training corpus is created from a test corpus of effectively N · (N − 1) · K sentences translated by the involved MT engines. Model parameters are trained iteratively using the GIZA++ toolkit (Och and Ney, 2003). The training is performed in the directions Em → En and En → Em . The final alignments are determined using a cost matrix C for each sentence pair (Em , En ). Elements of this matrix are the local costs C(j, i) of aligning a word em,j from Em to a word en,i from En . Following Matusov et al. (2004), we compute these local costs by inter"
W11-2118,2005.eamt-1.20,0,\N,Missing
W11-2142,J04-2004,0,0.0163665,"e a bilingual language model, an additional language model in the phrase-based system in which each token consist of a target word and all 360 source words it is aligned to. The bilingual tokens enter the translation process as an additional target factor. 2.3 LIMSI-CNRS Single System 2.3.1 System overview The LIMSI system is built with n-code2 , an open source statistical machine translation system based on bilingual n-grams. 2.3.2 n-code Overview In a nutshell, the translation model is implemented as a stochastic finite-state transducer trained using a n-gram model of (source,target) pairs (Casacuberta and Vidal, 2004). Training this model requires to reorder source sentences so as to match the target word order. This is performed by a stochastic finite-state reordering model, which uses part-of-speech information3 to generalize reordering patterns beyond lexical regularities. In addition to the translation model, eleven feature functions are combined: a target-language model; four lexicon models; two lexicalized reordering models (Tillmann, 2004) aiming at predicting the orientation of the next translation unit; a weak distance-based distortion model; and finally a wordbonus model and a tuple-bonus model w"
W11-2142,J07-2003,0,0.0225833,"and word-, phrase- and distortionpenalties, which are combined in log-linear fashion. Parameters are optimized with the DownhillSimplex algorithm (Nelder and Mead, 1965) on the word graph. 358 Proceedings of the 6th Workshop on Statistical Machine Translation, pages 358–364, c Edinburgh, Scotland, UK, July 30–31, 2011. 2011 Association for Computational Linguistics 2.1.2 Hierarchical System For the hierarchical setups described in this paper, the open source Jane toolkit (Vilar et al., 2010) is employed. Jane has been developed at RWTH and implements the hierarchical approach as introduced by Chiang (2007) with some state-of-the-art extensions. In hierarchical phrase-based translation, a weighted synchronous context-free grammar is induced from parallel text. In addition to contiguous lexical phrases, hierarchical phrases with up to two gaps are extracted. The search is typically carried out using the cube pruning algorithm (Huang and Chiang, 2007). The model weights are optimized with standard MERT (Och, 2003) on 100-best lists. 2.1.3 Phrase Model Training 2.2 Karlsruhe Institute of Technology Single System 2.2.1 For some PBT systems a forced alignment procedure was applied to train the phrase"
W11-2142,W08-0310,1,0.899949,"Missing"
W11-2142,P07-1019,0,0.0206925,"or Computational Linguistics 2.1.2 Hierarchical System For the hierarchical setups described in this paper, the open source Jane toolkit (Vilar et al., 2010) is employed. Jane has been developed at RWTH and implements the hierarchical approach as introduced by Chiang (2007) with some state-of-the-art extensions. In hierarchical phrase-based translation, a weighted synchronous context-free grammar is induced from parallel text. In addition to contiguous lexical phrases, hierarchical phrases with up to two gaps are extracted. The search is typically carried out using the cube pruning algorithm (Huang and Chiang, 2007). The model weights are optimized with standard MERT (Och, 2003) on 100-best lists. 2.1.3 Phrase Model Training 2.2 Karlsruhe Institute of Technology Single System 2.2.1 For some PBT systems a forced alignment procedure was applied to train the phrase translation model as described in Wuebker et al. (2010). A modified version of the translation decoder is used to produce a phrase alignment on the bilingual training data. The phrase translation probabilities are estimated from their relative frequencies in the phrasealigned training data. In addition to providing a statistically well-founded ph"
W11-2142,P02-1040,0,0.102913,"Missing"
W11-2142,E03-1076,0,0.0231201,"l table includes two identical Jane systems which are optimized on different criteria. The one optimized on TER−BLEU yields a much lower TER. Final Systems We preprocess the training data prior to training the system, first by normalizing symbols such as quotes, dashes and apostrophes. Then smart-casing of the first words of each sentence is performed. For the German part of the training corpus we use the hunspell1 lexicon to learn a mapping from old German spelling to new German spelling to obtain a corpus with homogeneous spelling. In addition, we perform compound splitting as described in (Koehn and Knight, 2003). Finally, we remove very long sentences, empty lines, and sentences that probably are not parallel due to length mismatch. 2.2.2 For the German→English task, RWTH conducted experiments comparing the standard phrase extraction with the phrase training technique described in Section 2.1.3. Further experiments included the use of additional language model training data, reranking of n-best lists generated by the phrase-based system, and different optimization criteria. A considerable increase in translation quality can be achieved by application of German compound splitting (Koehn and Knight, 20"
W11-2142,W07-0732,1,0.818478,"a statistical post editing (SPE) component. The SYSTRAN system is traditionally classified as a rule-based system. However, over the decades, its development has always been driven by pragmatic considerations, progressively integrating many of the most efficient MT approaches and techniques. Nowadays, the baseline engine can be considered as a linguistic-oriented system making use of dependency analysis, general transfer rules as well as of large manually encoded dictionaries (100k − 800k entries per language pair). The basic setup of the SPE component is identical to the one described in (L. Dugast and Koehn, 2007). A statistical translation model is trained on the rule-based translation of the source and the target side of the parallel corpus. This is done separately for each parallel corpus. Language models are trained on each target half of the parallel corpora and also on additional in-domain corpora. Moreover, the following measures − limiting unwanted statistical effects − were applied: • Named entities are replaced by special tokens on both sides. This usually improves word alignment, since the vocabulary size is significantly reduced. In addition, entity translation is handled more reliably by t"
W11-2142,E06-1005,1,0.83205,"d 15M phrases from the news/europarl corpora, provided as training data for WMT 2011. Weights for these separate models were tuned by the MERT algorithm provided in the Moses toolkit (P. Koehn et al., 2007), using the provided news development set. 3 RWTH Aachen System Combination System combination is used to produce consensus translations from multiple hypotheses produced with different translation engines that are better in terms of translation quality than any of the individual hypotheses. The basic concept of RWTH’s approach to machine translation system combination has been described by Matusov et al. (2006; 2008). This approach includes an enhanced alignment and reordering framework. A lattice is built from the input hypotheses. The translation with the best score within the lattice according to a couple of statistical models is selected as consensus translation. A deeper description will be also given in the WMT11 system combination paper of RWTH Aachen University. For this task only the A2L framework has been used. 4 Experiments We tried different system combinations with different sets of single systems and different optimization criteria. As RWTH has two different translation systems, we pu"
W11-2142,W09-0435,1,0.836207,"ystem applies a bilingual language model to extend the context of source language words available for translation. The individual models are described briefly in the following. 2.2.3 POS-based Reordering Model We use a reordering model that is based on partsof-speech (POS) and learn probabilistic rules from the POS tags of the words in the training corpus and the alignment information. In addition to continuous reordering rules that model short-range reordering (Rottmann and Vogel, 2007), we apply noncontinuous rules to address long-range reorderings as typical for German-English translation (Niehues and Kolss, 2009). The reordering rules are applied to the source sentences and the reordered sentence variants as well as the original sequence are encoded in a word lattice which is used as input to the decoder. 2.2.4 Lattice Phrase Extraction For the test sentences, the POS-based reordering allows us to change the word order in the source sentence so that the sentence can be translated more easily. If we apply this also to the training sentences, we would be able to extract also phrase pairs for originally discontinuous phrases and could apply them during translation of reordered test sentences. Therefore,"
W11-2142,J03-1002,1,0.00747756,"joint translation by combining the knowledge of the four project partners. Each group develop and maintain their own different machine translation system. These single systems differ not only in their general approach, but also in the preprocessing of training and test data. To take the advantage of these differences of each translation system, we combined all hypotheses of the different systems, using the RWTH system combination approach. RWTH Aachen Single Systems For the WMT 2011 evaluation the RWTH utilized RWTH’s state-of-the-art phrase-based and hierarchical translation systems. GIZA++ (Och and Ney, 2003) was employed to train word alignments, language models have been created with the SRILM toolkit (Stolcke, 2002). 2.1.1 Phrase-Based System The phrase-based translation (PBT) system is similar to the one described in Zens and Ney (2008). After phrase pair extraction from the word-aligned bilingual corpus, the translation probabilities are estimated by relative frequencies. The standard feature set also includes an n-gram language model, phraselevel IBM-1 and word-, phrase- and distortionpenalties, which are combined in log-linear fashion. Parameters are optimized with the DownhillSimplex algor"
W11-2142,P03-1021,0,0.147772,"etups described in this paper, the open source Jane toolkit (Vilar et al., 2010) is employed. Jane has been developed at RWTH and implements the hierarchical approach as introduced by Chiang (2007) with some state-of-the-art extensions. In hierarchical phrase-based translation, a weighted synchronous context-free grammar is induced from parallel text. In addition to contiguous lexical phrases, hierarchical phrases with up to two gaps are extracted. The search is typically carried out using the cube pruning algorithm (Huang and Chiang, 2007). The model weights are optimized with standard MERT (Och, 2003) on 100-best lists. 2.1.3 Phrase Model Training 2.2 Karlsruhe Institute of Technology Single System 2.2.1 For some PBT systems a forced alignment procedure was applied to train the phrase translation model as described in Wuebker et al. (2010). A modified version of the translation decoder is used to produce a phrase alignment on the bilingual training data. The phrase translation probabilities are estimated from their relative frequencies in the phrasealigned training data. In addition to providing a statistically well-founded phrase model, this has the benefit of producing smaller phrase tab"
W11-2142,P07-2045,0,0.0131162,"parallel corpus (whose target is identical to the source). This was added to the parallel text in order to improve word alignment. • Singleton phrase pairs are deleted from the phrase table to avoid overfitting. • Phrase pairs not containing the same number of entities on the source and the target side are also discarded. • Phrase pairs appearing less than 2 times were pruned. The SPE language model was trained 15M phrases from the news/europarl corpora, provided as training data for WMT 2011. Weights for these separate models were tuned by the MERT algorithm provided in the Moses toolkit (P. Koehn et al., 2007), using the provided news development set. 3 RWTH Aachen System Combination System combination is used to produce consensus translations from multiple hypotheses produced with different translation engines that are better in terms of translation quality than any of the individual hypotheses. The basic concept of RWTH’s approach to machine translation system combination has been described by Matusov et al. (2006; 2008). This approach includes an enhanced alignment and reordering framework. A lattice is built from the input hypotheses. The translation with the best score within the lattice accor"
W11-2142,2007.tmi-papers.21,0,0.0203552,"lattices. Part-of-speech tags are obtained using the TreeTag1 http://hunspell.sourceforge.net/ ger (Schmid, 1994). In addition, the system applies a bilingual language model to extend the context of source language words available for translation. The individual models are described briefly in the following. 2.2.3 POS-based Reordering Model We use a reordering model that is based on partsof-speech (POS) and learn probabilistic rules from the POS tags of the words in the training corpus and the alignment information. In addition to continuous reordering rules that model short-range reordering (Rottmann and Vogel, 2007), we apply noncontinuous rules to address long-range reorderings as typical for German-English translation (Niehues and Kolss, 2009). The reordering rules are applied to the source sentences and the reordered sentence variants as well as the original sequence are encoded in a word lattice which is used as input to the decoder. 2.2.4 Lattice Phrase Extraction For the test sentences, the POS-based reordering allows us to change the word order in the source sentence so that the sentence can be translated more easily. If we apply this also to the training sentences, we would be able to extract als"
W11-2142,N04-4026,0,0.0225696,"ew In a nutshell, the translation model is implemented as a stochastic finite-state transducer trained using a n-gram model of (source,target) pairs (Casacuberta and Vidal, 2004). Training this model requires to reorder source sentences so as to match the target word order. This is performed by a stochastic finite-state reordering model, which uses part-of-speech information3 to generalize reordering patterns beyond lexical regularities. In addition to the translation model, eleven feature functions are combined: a target-language model; four lexicon models; two lexicalized reordering models (Tillmann, 2004) aiming at predicting the orientation of the next translation unit; a weak distance-based distortion model; and finally a wordbonus model and a tuple-bonus model which compensate for the system preference for short translations. The four lexicon models are similar to the ones use in a standard phrase based system: two scores correspond to the relative frequencies of the tuples and two lexical weights estimated from the automatically generated word alignments. The weights associated to feature functions are optimally combined using a discriminative training framework (Och, 2003), using the news"
W11-2142,W05-0836,1,0.901096,"rd heuristic phrase extraction techniques, performing force alignment phrase training (FA) gives an improvement in BLEU on newstest2008 and newstest2009, but a degradation in TER. The addition of LDC Gigaword corpora (+GW) to the language model training data shows improvements in both BLEU and TER. Reranking was done on 1000-best lists generated by the the best available 359 Preprocessing System Overview The KIT system uses an in-house phrase-based decoder (Vogel, 2003) to perform translation. Optimization with regard to the BLEU score is done using Minimum Error Rate Training as described by Venugopal et al. (2005). The translation model is trained on the Europarl and News Commentary Corpus and the phrase table is based on a GIZA++ Word Alignment. We use two 4-gram SRI language models, one trained on the News Shuffle corpus and one trained on the Gigaword corpus. Reordering is performed based on continuous and non-continuous POS rules to cover short and long-range reorderings. The long-range reordering rules were also applied to the training corpus and phrase extraction was performed on the resulting reordering lattices. Part-of-speech tags are obtained using the TreeTag1 http://hunspell.sourceforge.net"
W11-2142,W10-1738,1,0.832324,"are estimated by relative frequencies. The standard feature set also includes an n-gram language model, phraselevel IBM-1 and word-, phrase- and distortionpenalties, which are combined in log-linear fashion. Parameters are optimized with the DownhillSimplex algorithm (Nelder and Mead, 1965) on the word graph. 358 Proceedings of the 6th Workshop on Statistical Machine Translation, pages 358–364, c Edinburgh, Scotland, UK, July 30–31, 2011. 2011 Association for Computational Linguistics 2.1.2 Hierarchical System For the hierarchical setups described in this paper, the open source Jane toolkit (Vilar et al., 2010) is employed. Jane has been developed at RWTH and implements the hierarchical approach as introduced by Chiang (2007) with some state-of-the-art extensions. In hierarchical phrase-based translation, a weighted synchronous context-free grammar is induced from parallel text. In addition to contiguous lexical phrases, hierarchical phrases with up to two gaps are extracted. The search is typically carried out using the cube pruning algorithm (Huang and Chiang, 2007). The model weights are optimized with standard MERT (Och, 2003) on 100-best lists. 2.1.3 Phrase Model Training 2.2 Karlsruhe Institut"
W11-2142,P10-1049,1,0.823271,"ons. In hierarchical phrase-based translation, a weighted synchronous context-free grammar is induced from parallel text. In addition to contiguous lexical phrases, hierarchical phrases with up to two gaps are extracted. The search is typically carried out using the cube pruning algorithm (Huang and Chiang, 2007). The model weights are optimized with standard MERT (Och, 2003) on 100-best lists. 2.1.3 Phrase Model Training 2.2 Karlsruhe Institute of Technology Single System 2.2.1 For some PBT systems a forced alignment procedure was applied to train the phrase translation model as described in Wuebker et al. (2010). A modified version of the translation decoder is used to produce a phrase alignment on the bilingual training data. The phrase translation probabilities are estimated from their relative frequencies in the phrasealigned training data. In addition to providing a statistically well-founded phrase model, this has the benefit of producing smaller phrase tables and thus allowing more rapid and less memory consuming experiments with a better translation quality. 2.1.4 system (PBT (FA)+GW). Following models were applied: n-gram posteriors (Zens and Ney, 2006), sentence length model, a 6-gram LM and"
W11-2142,W06-3110,1,0.850765,"ase translation model as described in Wuebker et al. (2010). A modified version of the translation decoder is used to produce a phrase alignment on the bilingual training data. The phrase translation probabilities are estimated from their relative frequencies in the phrasealigned training data. In addition to providing a statistically well-founded phrase model, this has the benefit of producing smaller phrase tables and thus allowing more rapid and less memory consuming experiments with a better translation quality. 2.1.4 system (PBT (FA)+GW). Following models were applied: n-gram posteriors (Zens and Ney, 2006), sentence length model, a 6-gram LM and IBM-1 lexicon models in both normal and inverse direction. These models are combined in a log-linear fashion and the scaling factors are tuned in the same manner as the baseline system (using TER−4BLEU on newstest2009). The final table includes two identical Jane systems which are optimized on different criteria. The one optimized on TER−BLEU yields a much lower TER. Final Systems We preprocess the training data prior to training the system, first by normalizing symbols such as quotes, dashes and apostrophes. Then smart-casing of the first words of each"
W11-2142,2008.iwslt-papers.8,1,0.820865,"preprocessing of training and test data. To take the advantage of these differences of each translation system, we combined all hypotheses of the different systems, using the RWTH system combination approach. RWTH Aachen Single Systems For the WMT 2011 evaluation the RWTH utilized RWTH’s state-of-the-art phrase-based and hierarchical translation systems. GIZA++ (Och and Ney, 2003) was employed to train word alignments, language models have been created with the SRILM toolkit (Stolcke, 2002). 2.1.1 Phrase-Based System The phrase-based translation (PBT) system is similar to the one described in Zens and Ney (2008). After phrase pair extraction from the word-aligned bilingual corpus, the translation probabilities are estimated by relative frequencies. The standard feature set also includes an n-gram language model, phraselevel IBM-1 and word-, phrase- and distortionpenalties, which are combined in log-linear fashion. Parameters are optimized with the DownhillSimplex algorithm (Nelder and Mead, 1965) on the word graph. 358 Proceedings of the 6th Workshop on Statistical Machine Translation, pages 358–364, c Edinburgh, Scotland, UK, July 30–31, 2011. 2011 Association for Computational Linguistics 2.1.2 Hie"
W11-2142,D08-1076,0,\N,Missing
W11-2149,P07-1019,0,0.0299407,"k. GIZA++ (Och and Ney, 2003) 2.2 Hierarchical System For the hierarchical setups described in this paper, the open source Jane toolkit (Vilar et al., 2010) was employed. Jane has been developed at RWTH and implements the hierarchical approach as introduced by Chiang (2007) with some state-of-the-art extensions. In hierarchical phrase-based translation, a weighted synchronous context-free grammar is induced from parallel text. In addition to contiguous lexical phrases, hierarchical phrases with up to two gaps are extracted. The search is typically carried out using the cube pruning algorithm (Huang and Chiang, 2007). The standard models integrated into our Jane systems are: phrase translation probabilities and lexical translation probabilities on phrase level, each for both translation directions, length 405 Proceedings of the 6th Workshop on Statistical Machine Translation, pages 405–412, c Edinburgh, Scotland, UK, July 30–31, 2011. 2011 Association for Computational Linguistics penalties on word and phrase level, three binary features marking hierarchical phrases, glue rule, and rules with non-terminals at the boundaries, sourceto-target and target-to-source phrase length ratios, four binary count feat"
W11-2149,E09-1044,0,0.039482,"Missing"
W11-2149,P03-1054,0,0.00307413,"The phrase alignment is produced by a modified version of the translation decoder. In addition to providing a statistically well-founded phrase model, this has the benefit of producing smaller phrase tables and thus allowing more rapid experiments. A detailed description of the training procedure is given in (Wuebker et al., 2010). 3.3 Soft String-to-Dependency Given a dependency tree of the target language, we are able to introduce language models that span over longer distances than the usual n-grams, as in (Shen et al., 2008). To obtain dependency structures, we apply the Stanford parser (Klein and Manning, 2003) on the target side of the training material. RWTH’s open source hierarchical translation toolkit Jane has been extended to include dependency information in the phrase table and to build dependency trees on the output hypotheses at decoding time from this information. Shen et al. (2008) use only phrases that meet certain restrictions. The first possibility is what the authors call a fixed dependency structure. With the exception of one word within this phrase, called the head, no outside word may have a dependency within this phrase. Also, all inner words may only depend on each other or on t"
W11-2149,E03-1076,0,0.0408333,"pora were used additionally. For the 109 French-English and LDC Gigaword corpora RWTH applied the data selection technique described in Section 3.1. We examined two different language models, one with LDC data and one without. Systems were optimized on the newstest2009 data set, newstest2008 was used as test set. The scores for newstest2010 are included for completeness. 5.1 Morpho-Syntactic Analysis In order to reduce the source vocabulary size for the German→English translation, the source side was preprocessed by splitting German compound words with the frequency-based method described in (Koehn and Knight, 2003). To further reduce translation complexity, we performed the long-range part-of-speech based reordering rules proposed by (Popovi´c et al., 2006). For additional experiments we used the TreeTagger (Schmid, 1995) to produce a lemmatized version of the German source. 5.2 Optimization Criterion We studied the impact of different optimization criteria on tranlsation performance. The usual practice is to optimize the scaling factors to maximize BLEU. We also experimented with two different combinations of BLEU and Translation Edit Rate (TER): TER−BLEU and TER−4BLEU. The first denotes the equally we"
W11-2149,E06-1005,1,0.834047,"rules with non-terminals at the boundaries, sourceto-target and target-to-source phrase length ratios, four binary count features and an n-gram language model. The model weights are optimized with standard MERT (Och, 2003) on 100-best lists. 2.3 System Combination System combination is used to produce consensus translations from multiple hypotheses produced with different translation engines that are better in terms of translation quality than any of the individual hypotheses. The basic concept of RWTH’s approach to machine translation system combination has been described by Matusov et al. (Matusov et al., 2006; Matusov et al., 2008). This approach includes an enhanced alignment and reordering framework. A lattice is built from the input hypotheses. The translation with the best score within the lattice according to a couple of statistical models is selected as consensus translation. 3 Translation Modeling We incorporated several novel methods into our systems for the WMT 2011 evaluation. This section provides a short survey of three of the methods which we suppose to be of particular interest. 3.1 Language Model Data Selection For the English and German language models, we applied the data selectio"
W11-2149,D09-1022,1,0.84817,"on automatically selected English data (cf. Section 3.1) from the provided resources including the 109 corpus and LDC Gigaword. The scaling factors of the log-linear model combination are optimized towards BLEU on newstest2009, newstest2010 is used as an unseen test set. 4.1 Experimental Results French→English The results for the French→English task are given in Table 3. RWTH’s three submissions – one primary and two contrastive – are labeled accordingly in the table. The first contrastive submission is a phrasebased system with a standard feature set plus an additional triplet lexicon model (Mauser et al., 2009). The triplet lexicon model was trained on in-domain news commentary data only. The second contrastive submission is a hierarchical Jane system with three syntax-based extensions: A parse match model (Vilar et al., 2008), soft syntactic labels (Stein et al., 2010), and the soft string-to-dependency extension as described in Section 3.3. The primary submission combines the phrase-based contrastive system, a hierarchical system that is very similar to the Jane contrastive submission but with a slightly worse language model, and an additional PBT system that has been trained with forced alignment"
W11-2149,P10-2041,0,0.0393086,"). This approach includes an enhanced alignment and reordering framework. A lattice is built from the input hypotheses. The translation with the best score within the lattice according to a couple of statistical models is selected as consensus translation. 3 Translation Modeling We incorporated several novel methods into our systems for the WMT 2011 evaluation. This section provides a short survey of three of the methods which we suppose to be of particular interest. 3.1 Language Model Data Selection For the English and German language models, we applied the data selection method proposed in (Moore and Lewis, 2010). Each sentence is scored by the difference in cross-entropy between a language model trained from in-domain data and a language model trained from a similar-sized sample of the out-of-domain data. As in-domain data we used the news-commentary corpus. The out-of-domain data from which the data was selected are the news crawl corpus for both languages and for English the 109 corpus and the LDC Gigaword data. We used a 3-gram trained with the SRI toolkit to compute the cross-entropy. For the news crawl corpus, only 1/8 of the sentences were discarded. Of the 109 corpus we retained 1/2 and of the"
W11-2149,J03-1002,1,0.00864889,"overview of our translation systems in Section 2. In addition to the baseline features, we adopted several novel methods, which will be presented in Section 3. Details on the respective setups and translation results for the French-English and German-English language pairs (in both translation directions) are given in Sections 4 and 5. We finally conclude the paper in Section 6. 2 Phrase-Based System Translation Systems For the WMT 2011 evaluation we utilized RWTH’s state-of-the-art phrase-based and hierarchical translation systems as well as our in-house system combination framework. GIZA++ (Och and Ney, 2003) 2.2 Hierarchical System For the hierarchical setups described in this paper, the open source Jane toolkit (Vilar et al., 2010) was employed. Jane has been developed at RWTH and implements the hierarchical approach as introduced by Chiang (2007) with some state-of-the-art extensions. In hierarchical phrase-based translation, a weighted synchronous context-free grammar is induced from parallel text. In addition to contiguous lexical phrases, hierarchical phrases with up to two gaps are extracted. The search is typically carried out using the cube pruning algorithm (Huang and Chiang, 2007). The"
W11-2149,P03-1021,0,0.00696987,"ities and lexical translation probabilities on phrase level, each for both translation directions, length 405 Proceedings of the 6th Workshop on Statistical Machine Translation, pages 405–412, c Edinburgh, Scotland, UK, July 30–31, 2011. 2011 Association for Computational Linguistics penalties on word and phrase level, three binary features marking hierarchical phrases, glue rule, and rules with non-terminals at the boundaries, sourceto-target and target-to-source phrase length ratios, four binary count features and an n-gram language model. The model weights are optimized with standard MERT (Och, 2003) on 100-best lists. 2.3 System Combination System combination is used to produce consensus translations from multiple hypotheses produced with different translation engines that are better in terms of translation quality than any of the individual hypotheses. The basic concept of RWTH’s approach to machine translation system combination has been described by Matusov et al. (Matusov et al., 2006; Matusov et al., 2008). This approach includes an enhanced alignment and reordering framework. A lattice is built from the input hypotheses. The translation with the best score within the lattice accord"
W11-2149,P08-1066,0,0.0240437,"are estimated from their relative frequencies in the phrase-aligned training data. The phrase alignment is produced by a modified version of the translation decoder. In addition to providing a statistically well-founded phrase model, this has the benefit of producing smaller phrase tables and thus allowing more rapid experiments. A detailed description of the training procedure is given in (Wuebker et al., 2010). 3.3 Soft String-to-Dependency Given a dependency tree of the target language, we are able to introduce language models that span over longer distances than the usual n-grams, as in (Shen et al., 2008). To obtain dependency structures, we apply the Stanford parser (Klein and Manning, 2003) on the target side of the training material. RWTH’s open source hierarchical translation toolkit Jane has been extended to include dependency information in the phrase table and to build dependency trees on the output hypotheses at decoding time from this information. Shen et al. (2008) use only phrases that meet certain restrictions. The first possibility is what the authors call a fixed dependency structure. With the exception of one word within this phrase, called the head, no outside word may have a d"
W11-2149,2010.amta-papers.8,1,0.791938,"t set. 4.1 Experimental Results French→English The results for the French→English task are given in Table 3. RWTH’s three submissions – one primary and two contrastive – are labeled accordingly in the table. The first contrastive submission is a phrasebased system with a standard feature set plus an additional triplet lexicon model (Mauser et al., 2009). The triplet lexicon model was trained on in-domain news commentary data only. The second contrastive submission is a hierarchical Jane system with three syntax-based extensions: A parse match model (Vilar et al., 2008), soft syntactic labels (Stein et al., 2010), and the soft string-to-dependency extension as described in Section 3.3. The primary submission combines the phrase-based contrastive system, a hierarchical system that is very similar to the Jane contrastive submission but with a slightly worse language model, and an additional PBT system that has been trained with forced alignment (Wuebker et al., 408 2010) on WMT 2010 data only. 4.2 Experimental Results English→French The results for the English→French task are given in Table 4. We likewise submitted two contrastive systems for this translation direction. The first contrastive submission"
W11-2149,2008.iwslt-papers.7,1,0.86264,"t2009, newstest2010 is used as an unseen test set. 4.1 Experimental Results French→English The results for the French→English task are given in Table 3. RWTH’s three submissions – one primary and two contrastive – are labeled accordingly in the table. The first contrastive submission is a phrasebased system with a standard feature set plus an additional triplet lexicon model (Mauser et al., 2009). The triplet lexicon model was trained on in-domain news commentary data only. The second contrastive submission is a hierarchical Jane system with three syntax-based extensions: A parse match model (Vilar et al., 2008), soft syntactic labels (Stein et al., 2010), and the soft string-to-dependency extension as described in Section 3.3. The primary submission combines the phrase-based contrastive system, a hierarchical system that is very similar to the Jane contrastive submission but with a slightly worse language model, and an additional PBT system that has been trained with forced alignment (Wuebker et al., 408 2010) on WMT 2010 data only. 4.2 Experimental Results English→French The results for the English→French task are given in Table 4. We likewise submitted two contrastive systems for this translation"
W11-2149,W10-1738,1,0.820443,"h will be presented in Section 3. Details on the respective setups and translation results for the French-English and German-English language pairs (in both translation directions) are given in Sections 4 and 5. We finally conclude the paper in Section 6. 2 Phrase-Based System Translation Systems For the WMT 2011 evaluation we utilized RWTH’s state-of-the-art phrase-based and hierarchical translation systems as well as our in-house system combination framework. GIZA++ (Och and Ney, 2003) 2.2 Hierarchical System For the hierarchical setups described in this paper, the open source Jane toolkit (Vilar et al., 2010) was employed. Jane has been developed at RWTH and implements the hierarchical approach as introduced by Chiang (2007) with some state-of-the-art extensions. In hierarchical phrase-based translation, a weighted synchronous context-free grammar is induced from parallel text. In addition to contiguous lexical phrases, hierarchical phrases with up to two gaps are extracted. The search is typically carried out using the cube pruning algorithm (Huang and Chiang, 2007). The standard models integrated into our Jane systems are: phrase translation probabilities and lexical translation probabilities on"
W11-2149,P10-1049,1,0.92613,"tasks we applied a forced alignment procedure to train the phrase translation model with the EM algorithm, similar to the one described in (DeNero et al., 2006). Here, the phrase translation probabilities are estimated from their relative frequencies in the phrase-aligned training data. The phrase alignment is produced by a modified version of the translation decoder. In addition to providing a statistically well-founded phrase model, this has the benefit of producing smaller phrase tables and thus allowing more rapid experiments. A detailed description of the training procedure is given in (Wuebker et al., 2010). 3.3 Soft String-to-Dependency Given a dependency tree of the target language, we are able to introduce language models that span over longer distances than the usual n-grams, as in (Shen et al., 2008). To obtain dependency structures, we apply the Stanford parser (Klein and Manning, 2003) on the target side of the training material. RWTH’s open source hierarchical translation toolkit Jane has been extended to include dependency information in the phrase table and to build dependency trees on the output hypotheses at decoding time from this information. Shen et al. (2008) use only phrases tha"
W11-2149,W06-3108,1,0.91274,"rdering. Further, we applied a system combination technique to create a consensus hypothesis from several different systems. 1 2.1 We applied a phrase-based translation (PBT) system similar to the one described in (Zens and Ney, 2008). Phrase pairs are extracted from a word-aligned bilingual corpus and their translation probability in both directions is estimated by relative frequencies. The standard feature set moreover includes an n-gram language model, phrase-level single-word lexicons and word-, phrase- and distortion-penalties. To lexicalize reordering, a discriminative reordering model (Zens and Ney, 2006a) is used. Parameters are optimized with the Downhill-Simplex algorithm (Nelder and Mead, 1965) on the word graph. Overview We sketch the baseline architecture of RWTH’s setups for the WMT 2011 shared translation task by providing an overview of our translation systems in Section 2. In addition to the baseline features, we adopted several novel methods, which will be presented in Section 3. Details on the respective setups and translation results for the French-English and German-English language pairs (in both translation directions) are given in Sections 4 and 5. We finally conclude the pap"
W11-2149,W06-3110,1,0.909489,"rdering. Further, we applied a system combination technique to create a consensus hypothesis from several different systems. 1 2.1 We applied a phrase-based translation (PBT) system similar to the one described in (Zens and Ney, 2008). Phrase pairs are extracted from a word-aligned bilingual corpus and their translation probability in both directions is estimated by relative frequencies. The standard feature set moreover includes an n-gram language model, phrase-level single-word lexicons and word-, phrase- and distortion-penalties. To lexicalize reordering, a discriminative reordering model (Zens and Ney, 2006a) is used. Parameters are optimized with the Downhill-Simplex algorithm (Nelder and Mead, 1965) on the word graph. Overview We sketch the baseline architecture of RWTH’s setups for the WMT 2011 shared translation task by providing an overview of our translation systems in Section 2. In addition to the baseline features, we adopted several novel methods, which will be presented in Section 3. Details on the respective setups and translation results for the French-English and German-English language pairs (in both translation directions) are given in Sections 4 and 5. We finally conclude the pap"
W11-2149,2008.iwslt-papers.8,1,0.857725,"f the EMNLP 2011 Sixth Workshop on Statistical Machine Translation. Both phrasebased and hierarchical SMT systems were trained for the constrained German-English and French-English tasks in all directions. Experiments were conducted to compare different training data sets, training methods and optimization criteria, as well as additional models on dependency structure and phrase reordering. Further, we applied a system combination technique to create a consensus hypothesis from several different systems. 1 2.1 We applied a phrase-based translation (PBT) system similar to the one described in (Zens and Ney, 2008). Phrase pairs are extracted from a word-aligned bilingual corpus and their translation probability in both directions is estimated by relative frequencies. The standard feature set moreover includes an n-gram language model, phrase-level single-word lexicons and word-, phrase- and distortion-penalties. To lexicalize reordering, a discriminative reordering model (Zens and Ney, 2006a) is used. Parameters are optimized with the Downhill-Simplex algorithm (Nelder and Mead, 1965) on the word graph. Overview We sketch the baseline architecture of RWTH’s setups for the WMT 2011 shared translation ta"
W11-2149,D07-1103,0,\N,Missing
W11-2149,W10-1723,0,\N,Missing
W11-2149,W08-0509,0,\N,Missing
W11-2149,P07-2045,0,\N,Missing
W11-2149,W10-1713,0,\N,Missing
W11-2149,2005.eamt-1.19,0,\N,Missing
W11-2211,W99-0604,1,\N,Missing
W11-2211,E09-1044,0,\N,Missing
W11-2211,W09-0424,0,\N,Missing
W11-2211,P02-1040,0,\N,Missing
W11-2211,W10-1738,1,\N,Missing
W11-2211,2008.iwslt-papers.6,0,\N,Missing
W11-2211,P10-1049,1,\N,Missing
W11-2211,P07-2045,0,\N,Missing
W11-2211,W07-0733,0,\N,Missing
W11-2211,P05-1033,0,\N,Missing
W11-2211,N03-1017,0,\N,Missing
W11-2211,J03-1002,1,\N,Missing
W11-2211,2009.iwslt-papers.4,0,\N,Missing
W11-2211,P07-1019,0,\N,Missing
W11-2211,2009.mtsummit-posters.17,0,\N,Missing
W11-2211,2010.iwslt-papers.11,1,\N,Missing
W11-2211,J07-2003,0,\N,Missing
W11-2211,D08-1076,0,\N,Missing
W11-2211,W07-0717,0,\N,Missing
W12-3124,C08-1005,0,0.0415003,"hms Two different methods have been proposed for building confusion networks: pairwise and incremental alignment. In pairwise alignment, each hypothesis corresponding to a source sentence is aligned independently with the skeleton hypothesis. This set of alignments is consolidated using the skeleton words as anchors to form the confusion network (Matusov et al., 2006; Sim et al., 2007). The same word in two hypotheses may be aligned with a different word in the skeleton resulting in repetition in the network. A two-pass alignment algorithm to improve pairwise TER alignments was introduced in (Ayan et al., 2008). In incremental alignment (Rosti et al., 2008), the confusion network is initialized by forming a simple graph with one word per link from the skeleton hypothesis. Each remaining hypothesis is aligned with the partial confusion network, which allows words from all previous hypotheses be considered as matches. The order in which the hypotheses are aligned may influence the alignment quality. Rosti et al. (2009) proposed a sentence specific alignment order by choosing the unaligned hypothesis closest to the partial confusion network according to TER. The following five alignment algorithms were"
W12-3124,J93-2003,0,0.0425621,"uence the alignment quality. Rosti et al. (2009) proposed a sentence specific alignment order by choosing the unaligned hypothesis closest to the partial confusion network according to TER. The following five alignment algorithms were used in this study. 3.1 Pairwise GIZA++ Enhanced Hypothesis Alignment Matusov et al. (2006) proposed using the GIZA++ Toolkit (Och and Ney, 2003) to align a set of target language translations. A parallel corpus where each system output acting as a skeleton appears as a translation of all system outputs corresponding to the same source sentence. The IBM Model 1 (Brown et al., 1993) and hidden Markov model (HMM) (Vogel et al., 1996) are used to estimate the alignment. Alignments from both “translation” directions are used to obtain symmetrized alignments by interpolating the HMM occupation statistics (Matusov et al., 2004). The algorithm may benefit from the fact that it considers the entire test set when estimating the alignment model parameters; i.e., word alignment links from all output sentences influence the estimation, whereas other alignment algorithms only consider words within a pair of sentences (pairwise alignment) or all outputs corresponding to a single sour"
W12-3124,W11-2103,0,0.0445044,"based on GIZA++ Toolkit which introduced word reordering not present in MSA, and Sim et al. (2007) used the alignments produced by the translation edit rate (TER) (Snover et al., 2006) scoring. Extensions of the last two are included in this study together with alignments based on hidden Markov model (HMM) (Vogel et al., 1996) and inversion transduction grammars (ITG) (Wu, 1997). System combinations produced via confusion network decoding using different hypothesis alignment algorithms have been entered into open evaluations, most recently in 2011 Workshop on Statistical Machine Translation (Callison-Burch et al., 2011). However, there has not been a comparison of the most popular hypothesis alignment algorithms using the same sets of MT system outputs and otherwise identical combination pipelines. This paper attempts to systematically compare the quality of five hypothesis alignment algorithms. Alignments were produced for the same system outputs from three common test sets used in the 2009 NIST Open MT Evaluation and the 2011 Workshop on Statistical Machine Translation. Identical pre-processing, decoding, and weight tuning algorithms were used to quantitatively evaluate the alignment quality. Case insensit"
W12-3124,W98-1115,0,0.0726946,"used to infer the alignment. The pairwise IHMM was extended to operate incrementally in (Li et al., 2009). Sentence specific alignment order is not used by this aligner, which is referred to as iIHMM later in this paper. 3.3 alignment of system outputs. ITGs form an edit distance, invWER (Leusch et al., 2003), that permits properly nested block movements of substrings. For well-formed sentences, this may be more natural than allowing arbitrary shifts. The ITG algorithm is very expensive due to its O(n6 ) complexity. The search algorithm for the best ITG alignment, a best-first chart parsing (Charniak et al., 1998), was augmented with an A∗ search heuristic of quadratic complexity (Klein and Manning, 2003), resulting in significant reduction in computational complexity. The finite state-machine heuristic computes a lower bound to the alignment cost of two strings by allowing arbitrary word re-orderings. The ITG hypothesis alignment algorithm was extended to operate incrementally in (Karakos et al., 2010) and a novel version where the cost function is computed based on the stem/synonym similarity of (Snover et al., 2009) was used in this work. Also, a sentence specific alignment order was used. This alig"
W12-3124,I11-1075,1,0.871525,"combination. Availability of multiple system outputs within the DARPA GALE program as well as NIST Open MT and Workshop on Statistical Machine Translation evaluations has led to extensive research in combining the strengths of diverse MT systems, resulting in significant gains in translation quality. System combination methods proposed in the literature can be roughly divided into three categories: (i) hypothesis selection (Rosti et al., 2007b; Hildebrand and Vogel, 2008), (ii) re-decoding (Frederking and Nirenburg, 1994; Jayaraman and Lavie, 2005; Rosti et al., 2007b; He and Toutanova, 2009; Devlin et al., 2011), and (iii) confusion network decoding. Confusion network decoding has proven to be the most popular as it does not require deep N best lists1 and operates on the surface strings. It has Confusion network decoding has proven to be one of the most successful approaches to machine translation system combination. The hypothesis alignment algorithm is a crucial part of building the confusion networks and many alternatives have been proposed in the literature. This paper describes a systematic comparison of five well known hypothesis alignment algorithms for MT system combination via confusion netw"
W12-3124,A94-1016,0,0.294452,"ntary. The complementary information in the outputs from multiple MT systems may be exploited by system combination. Availability of multiple system outputs within the DARPA GALE program as well as NIST Open MT and Workshop on Statistical Machine Translation evaluations has led to extensive research in combining the strengths of diverse MT systems, resulting in significant gains in translation quality. System combination methods proposed in the literature can be roughly divided into three categories: (i) hypothesis selection (Rosti et al., 2007b; Hildebrand and Vogel, 2008), (ii) re-decoding (Frederking and Nirenburg, 1994; Jayaraman and Lavie, 2005; Rosti et al., 2007b; He and Toutanova, 2009; Devlin et al., 2011), and (iii) confusion network decoding. Confusion network decoding has proven to be the most popular as it does not require deep N best lists1 and operates on the surface strings. It has Confusion network decoding has proven to be one of the most successful approaches to machine translation system combination. The hypothesis alignment algorithm is a crucial part of building the confusion networks and many alternatives have been proposed in the literature. This paper describes a systematic comparison o"
W12-3124,D09-1125,1,0.91068,"be exploited by system combination. Availability of multiple system outputs within the DARPA GALE program as well as NIST Open MT and Workshop on Statistical Machine Translation evaluations has led to extensive research in combining the strengths of diverse MT systems, resulting in significant gains in translation quality. System combination methods proposed in the literature can be roughly divided into three categories: (i) hypothesis selection (Rosti et al., 2007b; Hildebrand and Vogel, 2008), (ii) re-decoding (Frederking and Nirenburg, 1994; Jayaraman and Lavie, 2005; Rosti et al., 2007b; He and Toutanova, 2009; Devlin et al., 2011), and (iii) confusion network decoding. Confusion network decoding has proven to be the most popular as it does not require deep N best lists1 and operates on the surface strings. It has Confusion network decoding has proven to be one of the most successful approaches to machine translation system combination. The hypothesis alignment algorithm is a crucial part of building the confusion networks and many alternatives have been proposed in the literature. This paper describes a systematic comparison of five well known hypothesis alignment algorithms for MT system combinat"
W12-3124,D08-1011,1,0.923232,"considers the entire test set when estimating the alignment model parameters; i.e., word alignment links from all output sentences influence the estimation, whereas other alignment algorithms only consider words within a pair of sentences (pairwise alignment) or all outputs corresponding to a single source sentence (incremental alignment). However, it does not naturally extend to incremental alignment. The monotone one-to-one alignments are then transformed into a confusion network. This aligner is referred to as GIZA later in this paper. 3.2 Incremental Indirect Hidden Markov Model Alignment He et al. (2008) proposed using an indirect hidden Markov model (IHMM) for pairwise alignment of system outputs. The parameters of the IHMM are estimated indirectly from a variety of sources including semantic word similarity, surface word similarity, and a distance-based distortion penalty. The alignment between two target language outputs are treated as the hidden states. A standard Viterbi algorithm is used to infer the alignment. The pairwise IHMM was extended to operate incrementally in (Li et al., 2009). Sentence specific alignment order is not used by this aligner, which is referred to as iIHMM later i"
W12-3124,2008.amta-srw.3,0,0.130672,"hese assumptions may be suboptimal and complementary. The complementary information in the outputs from multiple MT systems may be exploited by system combination. Availability of multiple system outputs within the DARPA GALE program as well as NIST Open MT and Workshop on Statistical Machine Translation evaluations has led to extensive research in combining the strengths of diverse MT systems, resulting in significant gains in translation quality. System combination methods proposed in the literature can be roughly divided into three categories: (i) hypothesis selection (Rosti et al., 2007b; Hildebrand and Vogel, 2008), (ii) re-decoding (Frederking and Nirenburg, 1994; Jayaraman and Lavie, 2005; Rosti et al., 2007b; He and Toutanova, 2009; Devlin et al., 2011), and (iii) confusion network decoding. Confusion network decoding has proven to be the most popular as it does not require deep N best lists1 and operates on the surface strings. It has Confusion network decoding has proven to be one of the most successful approaches to machine translation system combination. The hypothesis alignment algorithm is a crucial part of building the confusion networks and many alternatives have been proposed in the literatu"
W12-3124,P05-3026,0,0.0671933,"tion in the outputs from multiple MT systems may be exploited by system combination. Availability of multiple system outputs within the DARPA GALE program as well as NIST Open MT and Workshop on Statistical Machine Translation evaluations has led to extensive research in combining the strengths of diverse MT systems, resulting in significant gains in translation quality. System combination methods proposed in the literature can be roughly divided into three categories: (i) hypothesis selection (Rosti et al., 2007b; Hildebrand and Vogel, 2008), (ii) re-decoding (Frederking and Nirenburg, 1994; Jayaraman and Lavie, 2005; Rosti et al., 2007b; He and Toutanova, 2009; Devlin et al., 2011), and (iii) confusion network decoding. Confusion network decoding has proven to be the most popular as it does not require deep N best lists1 and operates on the surface strings. It has Confusion network decoding has proven to be one of the most successful approaches to machine translation system combination. The hypothesis alignment algorithm is a crucial part of building the confusion networks and many alternatives have been proposed in the literature. This paper describes a systematic comparison of five well known hypothesi"
W12-3124,P08-2021,1,0.889809,"Missing"
W12-3124,N03-1016,0,0.0741193,"i et al., 2009). Sentence specific alignment order is not used by this aligner, which is referred to as iIHMM later in this paper. 3.3 alignment of system outputs. ITGs form an edit distance, invWER (Leusch et al., 2003), that permits properly nested block movements of substrings. For well-formed sentences, this may be more natural than allowing arbitrary shifts. The ITG algorithm is very expensive due to its O(n6 ) complexity. The search algorithm for the best ITG alignment, a best-first chart parsing (Charniak et al., 1998), was augmented with an A∗ search heuristic of quadratic complexity (Klein and Manning, 2003), resulting in significant reduction in computational complexity. The finite state-machine heuristic computes a lower bound to the alignment cost of two strings by allowing arbitrary word re-orderings. The ITG hypothesis alignment algorithm was extended to operate incrementally in (Karakos et al., 2010) and a novel version where the cost function is computed based on the stem/synonym similarity of (Snover et al., 2009) was used in this work. Also, a sentence specific alignment order was used. This aligner is referred to as iITGp later in this paper. 3.4 Sim et al. (2007) proposed using transla"
W12-3124,W04-3250,0,0.20963,"ed for the NIST and WMT experiments to minimize perplexity on the English reference translations of the previous evaluations, NIST MT08 and WMT10. The system combination weights, both bi-gram lattice decoding and 5-gram 300-best list re-scoring weights, were tuned separately for lattices build with each hypothesis alignment algorithm. The final re-scoring 4 http://www.itl.nist.gov/iad/mig/tests/ mt/2009/ResultsRelease/indexISC.html 195 outputs were detokenized before computing case insensitive BLEU scores. Statistical significance was computed for each pairwise comparison using bootstrapping (Koehn, 2004). Aligner GIZA iTER iTERp iIHMM iITGp Decode tune test 60.06 57.95 59.74 58.63† 60.18 59.05† 60.51 59.27†‡ 60.65 59.37†‡ Oracle tune test 75.06 74.47 73.84 73.20 76.43 75.58 76.50 76.17 76.53 76.05 Table 2: Case insensitive BLEU scores for NIST MT09 Arabic-English system combination outputs. Note, four reference translations were available. Decode corresponds to results after weight tuning and Oracle corresponds to graph TER oracle. Dagger (†) denotes statistically significant difference compared to GIZA and double dagger (‡) compared to iTERp and the aligners above it. The BLEU scores for Ara"
W12-3124,2003.mtsummit-papers.32,1,0.749201,"Missing"
W12-3124,P09-1107,1,0.925933,"er is referred to as GIZA later in this paper. 3.2 Incremental Indirect Hidden Markov Model Alignment He et al. (2008) proposed using an indirect hidden Markov model (IHMM) for pairwise alignment of system outputs. The parameters of the IHMM are estimated indirectly from a variety of sources including semantic word similarity, surface word similarity, and a distance-based distortion penalty. The alignment between two target language outputs are treated as the hidden states. A standard Viterbi algorithm is used to infer the alignment. The pairwise IHMM was extended to operate incrementally in (Li et al., 2009). Sentence specific alignment order is not used by this aligner, which is referred to as iIHMM later in this paper. 3.3 alignment of system outputs. ITGs form an edit distance, invWER (Leusch et al., 2003), that permits properly nested block movements of substrings. For well-formed sentences, this may be more natural than allowing arbitrary shifts. The ITG algorithm is very expensive due to its O(n6 ) complexity. The search algorithm for the best ITG alignment, a best-first chart parsing (Charniak et al., 1998), was augmented with an A∗ search heuristic of quadratic complexity (Klein and Manni"
W12-3124,C04-1032,1,0.864957,"this study. 3.1 Pairwise GIZA++ Enhanced Hypothesis Alignment Matusov et al. (2006) proposed using the GIZA++ Toolkit (Och and Ney, 2003) to align a set of target language translations. A parallel corpus where each system output acting as a skeleton appears as a translation of all system outputs corresponding to the same source sentence. The IBM Model 1 (Brown et al., 1993) and hidden Markov model (HMM) (Vogel et al., 1996) are used to estimate the alignment. Alignments from both “translation” directions are used to obtain symmetrized alignments by interpolating the HMM occupation statistics (Matusov et al., 2004). The algorithm may benefit from the fact that it considers the entire test set when estimating the alignment model parameters; i.e., word alignment links from all output sentences influence the estimation, whereas other alignment algorithms only consider words within a pair of sentences (pairwise alignment) or all outputs corresponding to a single source sentence (incremental alignment). However, it does not naturally extend to incremental alignment. The monotone one-to-one alignments are then transformed into a confusion network. This aligner is referred to as GIZA later in this paper. 3.2 I"
W12-3124,E06-1005,1,0.924758,"n used in confusion network decoding yielding small gains over using 1-best 191 Proceedings of the 7th Workshop on Statistical Machine Translation, pages 191–199, c Montr´eal, Canada, June 7-8, 2012. 2012 Association for Computational Linguistics also been shown to be very successful in combining speech recognition outputs (Fiscus, 1997; Mangu et al., 2000). The first application of confusion network decoding in MT system combination appeared in (Bangalore et al., 2001) where a multiple string alignment (MSA), made popular in biological sequence analysis, was applied to the MT system outputs. Matusov et al. (2006) proposed an alignment based on GIZA++ Toolkit which introduced word reordering not present in MSA, and Sim et al. (2007) used the alignments produced by the translation edit rate (TER) (Snover et al., 2006) scoring. Extensions of the last two are included in this study together with alignments based on hidden Markov model (HMM) (Vogel et al., 1996) and inversion transduction grammars (ITG) (Wu, 1997). System combinations produced via confusion network decoding using different hypothesis alignment algorithms have been entered into open evaluations, most recently in 2011 Workshop on Statistical"
W12-3124,J03-1002,1,0.0317226,"r link from the skeleton hypothesis. Each remaining hypothesis is aligned with the partial confusion network, which allows words from all previous hypotheses be considered as matches. The order in which the hypotheses are aligned may influence the alignment quality. Rosti et al. (2009) proposed a sentence specific alignment order by choosing the unaligned hypothesis closest to the partial confusion network according to TER. The following five alignment algorithms were used in this study. 3.1 Pairwise GIZA++ Enhanced Hypothesis Alignment Matusov et al. (2006) proposed using the GIZA++ Toolkit (Och and Ney, 2003) to align a set of target language translations. A parallel corpus where each system output acting as a skeleton appears as a translation of all system outputs corresponding to the same source sentence. The IBM Model 1 (Brown et al., 1993) and hidden Markov model (HMM) (Vogel et al., 1996) are used to estimate the alignment. Alignments from both “translation” directions are used to obtain symmetrized alignments by interpolating the HMM occupation statistics (Matusov et al., 2004). The algorithm may benefit from the fact that it considers the entire test set when estimating the alignment model"
W12-3124,P03-1021,0,0.0272462,"sion network structure’s resemblance to a sausage. 193 unique n-gram contexts before LM scores can be assigned the arcs. Using long n-gram context may require pruning to reduce memory usage. Given uniform initial system weights, pruning may remove desirable paths. In this work, the lattices were expanded to bi-gram context and no pruning was performed. A set of bi-gram decoding weights were tuned directly on the expanded lattices using a distributed optimizer (Rosti et al., 2010). Since the score in Equation 2 is not a simple log-linear interpolation, the standard minimum error rate training (Och, 2003) with exact line search cannot be used. Instead, downhill simplex (Press et al., 2007) was used in the optimizer client. After bi-gram decoding weight optimization, another set of 5-gram rescoring weights were tuned on 300-best lists generated from the bi-gram expanded lattices. 3 Hypothesis Alignment Algorithms Two different methods have been proposed for building confusion networks: pairwise and incremental alignment. In pairwise alignment, each hypothesis corresponding to a source sentence is aligned independently with the skeleton hypothesis. This set of alignments is consolidated using th"
W12-3124,P02-1040,0,0.0950013,"has not been a comparison of the most popular hypothesis alignment algorithms using the same sets of MT system outputs and otherwise identical combination pipelines. This paper attempts to systematically compare the quality of five hypothesis alignment algorithms. Alignments were produced for the same system outputs from three common test sets used in the 2009 NIST Open MT Evaluation and the 2011 Workshop on Statistical Machine Translation. Identical pre-processing, decoding, and weight tuning algorithms were used to quantitatively evaluate the alignment quality. Case insensitive BLEU score (Papineni et al., 2002) was used as the translation quality metric. 2 Confusion Network Decoding A confusion network is a linear graph where all paths visit all nodes. Two consecutive nodes may be connected by one or more arcs. Given the arcs represent words in hypotheses, multiple arcs connecting two consecutive nodes can be viewed as alternative words in that position of a set of hypotheses encoded by the network. A special NULL token represents a skipped word and will not appear in the system combination output. For example, three hypotheses outputs (Rosti et al., 2011). 192 “twelve big cars”, “twelve cars”, and"
W12-3124,P07-1040,1,0.88807,"d modeling. Many of these assumptions may be suboptimal and complementary. The complementary information in the outputs from multiple MT systems may be exploited by system combination. Availability of multiple system outputs within the DARPA GALE program as well as NIST Open MT and Workshop on Statistical Machine Translation evaluations has led to extensive research in combining the strengths of diverse MT systems, resulting in significant gains in translation quality. System combination methods proposed in the literature can be roughly divided into three categories: (i) hypothesis selection (Rosti et al., 2007b; Hildebrand and Vogel, 2008), (ii) re-decoding (Frederking and Nirenburg, 1994; Jayaraman and Lavie, 2005; Rosti et al., 2007b; He and Toutanova, 2009; Devlin et al., 2011), and (iii) confusion network decoding. Confusion network decoding has proven to be the most popular as it does not require deep N best lists1 and operates on the surface strings. It has Confusion network decoding has proven to be one of the most successful approaches to machine translation system combination. The hypothesis alignment algorithm is a crucial part of building the confusion networks and many alternatives have"
W12-3124,N07-1029,1,0.875478,"ranslation, pages 191–199, c Montr´eal, Canada, June 7-8, 2012. 2012 Association for Computational Linguistics also been shown to be very successful in combining speech recognition outputs (Fiscus, 1997; Mangu et al., 2000). The first application of confusion network decoding in MT system combination appeared in (Bangalore et al., 2001) where a multiple string alignment (MSA), made popular in biological sequence analysis, was applied to the MT system outputs. Matusov et al. (2006) proposed an alignment based on GIZA++ Toolkit which introduced word reordering not present in MSA, and Sim et al. (2007) used the alignments produced by the translation edit rate (TER) (Snover et al., 2006) scoring. Extensions of the last two are included in this study together with alignments based on hidden Markov model (HMM) (Vogel et al., 1996) and inversion transduction grammars (ITG) (Wu, 1997). System combinations produced via confusion network decoding using different hypothesis alignment algorithms have been entered into open evaluations, most recently in 2011 Workshop on Statistical Machine Translation (Callison-Burch et al., 2011). However, there has not been a comparison of the most popular hypothes"
W12-3124,W08-0329,1,0.848494,"or building confusion networks: pairwise and incremental alignment. In pairwise alignment, each hypothesis corresponding to a source sentence is aligned independently with the skeleton hypothesis. This set of alignments is consolidated using the skeleton words as anchors to form the confusion network (Matusov et al., 2006; Sim et al., 2007). The same word in two hypotheses may be aligned with a different word in the skeleton resulting in repetition in the network. A two-pass alignment algorithm to improve pairwise TER alignments was introduced in (Ayan et al., 2008). In incremental alignment (Rosti et al., 2008), the confusion network is initialized by forming a simple graph with one word per link from the skeleton hypothesis. Each remaining hypothesis is aligned with the partial confusion network, which allows words from all previous hypotheses be considered as matches. The order in which the hypotheses are aligned may influence the alignment quality. Rosti et al. (2009) proposed a sentence specific alignment order by choosing the unaligned hypothesis closest to the partial confusion network according to TER. The following five alignment algorithms were used in this study. 3.1 Pairwise GIZA++ Enhanc"
W12-3124,W09-0409,1,0.870846,"potheses may be aligned with a different word in the skeleton resulting in repetition in the network. A two-pass alignment algorithm to improve pairwise TER alignments was introduced in (Ayan et al., 2008). In incremental alignment (Rosti et al., 2008), the confusion network is initialized by forming a simple graph with one word per link from the skeleton hypothesis. Each remaining hypothesis is aligned with the partial confusion network, which allows words from all previous hypotheses be considered as matches. The order in which the hypotheses are aligned may influence the alignment quality. Rosti et al. (2009) proposed a sentence specific alignment order by choosing the unaligned hypothesis closest to the partial confusion network according to TER. The following five alignment algorithms were used in this study. 3.1 Pairwise GIZA++ Enhanced Hypothesis Alignment Matusov et al. (2006) proposed using the GIZA++ Toolkit (Och and Ney, 2003) to align a set of target language translations. A parallel corpus where each system output acting as a skeleton appears as a translation of all system outputs corresponding to the same source sentence. The IBM Model 1 (Brown et al., 1993) and hidden Markov model (HMM"
W12-3124,W10-1748,1,0.890146,"to distinguish paths with 2 A link is used as a synonym to the set of arcs between two consecutive nodes. The name refers to the confusion network structure’s resemblance to a sausage. 193 unique n-gram contexts before LM scores can be assigned the arcs. Using long n-gram context may require pruning to reduce memory usage. Given uniform initial system weights, pruning may remove desirable paths. In this work, the lattices were expanded to bi-gram context and no pruning was performed. A set of bi-gram decoding weights were tuned directly on the expanded lattices using a distributed optimizer (Rosti et al., 2010). Since the score in Equation 2 is not a simple log-linear interpolation, the standard minimum error rate training (Och, 2003) with exact line search cannot be used. Instead, downhill simplex (Press et al., 2007) was used in the optimizer client. After bi-gram decoding weight optimization, another set of 5-gram rescoring weights were tuned on 300-best lists generated from the bi-gram expanded lattices. 3 Hypothesis Alignment Algorithms Two different methods have been proposed for building confusion networks: pairwise and incremental alignment. In pairwise alignment, each hypothesis correspondi"
W12-3124,2006.amta-papers.25,0,0.0415224,"ociation for Computational Linguistics also been shown to be very successful in combining speech recognition outputs (Fiscus, 1997; Mangu et al., 2000). The first application of confusion network decoding in MT system combination appeared in (Bangalore et al., 2001) where a multiple string alignment (MSA), made popular in biological sequence analysis, was applied to the MT system outputs. Matusov et al. (2006) proposed an alignment based on GIZA++ Toolkit which introduced word reordering not present in MSA, and Sim et al. (2007) used the alignments produced by the translation edit rate (TER) (Snover et al., 2006) scoring. Extensions of the last two are included in this study together with alignments based on hidden Markov model (HMM) (Vogel et al., 1996) and inversion transduction grammars (ITG) (Wu, 1997). System combinations produced via confusion network decoding using different hypothesis alignment algorithms have been entered into open evaluations, most recently in 2011 Workshop on Statistical Machine Translation (Callison-Burch et al., 2011). However, there has not been a comparison of the most popular hypothesis alignment algorithms using the same sets of MT system outputs and otherwise identic"
W12-3124,W09-0441,0,0.0293967,"xity. The search algorithm for the best ITG alignment, a best-first chart parsing (Charniak et al., 1998), was augmented with an A∗ search heuristic of quadratic complexity (Klein and Manning, 2003), resulting in significant reduction in computational complexity. The finite state-machine heuristic computes a lower bound to the alignment cost of two strings by allowing arbitrary word re-orderings. The ITG hypothesis alignment algorithm was extended to operate incrementally in (Karakos et al., 2010) and a novel version where the cost function is computed based on the stem/synonym similarity of (Snover et al., 2009) was used in this work. Also, a sentence specific alignment order was used. This aligner is referred to as iITGp later in this paper. 3.4 Sim et al. (2007) proposed using translation edit rate scorer3 to obtain pairwise alignment of system outputs. The TER scorer tries to find shifts of blocks of words that minimize the edit distance between the shifted reference and a hypothesis. Due to the computational complexity, a set of heuristics is used to reduce the run time (Snover et al., 2006). The pairwise TER hypothesis alignment algorithm was extended to operate incrementally in (Rosti et al., 2"
W12-3124,C96-2141,1,0.668959,"2000). The first application of confusion network decoding in MT system combination appeared in (Bangalore et al., 2001) where a multiple string alignment (MSA), made popular in biological sequence analysis, was applied to the MT system outputs. Matusov et al. (2006) proposed an alignment based on GIZA++ Toolkit which introduced word reordering not present in MSA, and Sim et al. (2007) used the alignments produced by the translation edit rate (TER) (Snover et al., 2006) scoring. Extensions of the last two are included in this study together with alignments based on hidden Markov model (HMM) (Vogel et al., 1996) and inversion transduction grammars (ITG) (Wu, 1997). System combinations produced via confusion network decoding using different hypothesis alignment algorithms have been entered into open evaluations, most recently in 2011 Workshop on Statistical Machine Translation (Callison-Burch et al., 2011). However, there has not been a comparison of the most popular hypothesis alignment algorithms using the same sets of MT system outputs and otherwise identical combination pipelines. This paper attempts to systematically compare the quality of five hypothesis alignment algorithms. Alignments were pro"
W12-3124,J97-3002,0,0.0170128,"MT system combination appeared in (Bangalore et al., 2001) where a multiple string alignment (MSA), made popular in biological sequence analysis, was applied to the MT system outputs. Matusov et al. (2006) proposed an alignment based on GIZA++ Toolkit which introduced word reordering not present in MSA, and Sim et al. (2007) used the alignments produced by the translation edit rate (TER) (Snover et al., 2006) scoring. Extensions of the last two are included in this study together with alignments based on hidden Markov model (HMM) (Vogel et al., 1996) and inversion transduction grammars (ITG) (Wu, 1997). System combinations produced via confusion network decoding using different hypothesis alignment algorithms have been entered into open evaluations, most recently in 2011 Workshop on Statistical Machine Translation (Callison-Burch et al., 2011). However, there has not been a comparison of the most popular hypothesis alignment algorithms using the same sets of MT system outputs and otherwise identical combination pipelines. This paper attempts to systematically compare the quality of five hypothesis alignment algorithms. Alignments were produced for the same system outputs from three common t"
W12-3124,W11-2121,1,0.876089,"proposed using inversion transduction grammars (ITG) (Wu, 1997) for pairwise 194 Incremental Translation Edit Rate Alignment with Flexible Matching Incremental Translation Edit Rate Plus Alignment Snover et al. (2009) extended TER scoring to consider synonyms and paraphrase matches, called 3 http://www.cs.umd.edu/˜snover/tercom/ TER-plus (TERp). The shift heuristics in TERp were also relaxed relative to TER. Shifts are allowed if the words being shifted are: (i) exactly the same, (ii) synonyms, stems or paraphrases of the corresponding reference words, or (iii) any such combination. Xu et al. (2011) proposed using an incremental version of TERp for building consensus networks. A sentence specific alignment order was used by this aligner, which is referred to as iTERp later in this paper. 4 Experimental Evaluation Combination experiments were performed on (i) Arabic-English, from the informal system combination track of the 2009 NIST Open MT Evaluation4 ; (ii) German-English from the system combination evaluation of the 2011 Workshop on Statistical Machine Translation (Callison-Burch et al., 2011) (WMT11) and (iii) Spanish-English, again from WMT11. Eight top-performing systems (as evalua"
W12-3124,2005.eamt-1.20,0,\N,Missing
W12-3140,J04-2004,0,0.0800912,"nslation model relies on a specific decomposition of the joint probability of a sentence pair P(s, t) using the n-gram assumption: a sentence pair is decomposed into a sequence of bilingual units called tuples, defining a joint segmentation of the source and target. In the approach of (Mari˜no et al., 2006), this segmentation is a by-product of source reordering which ultimately derives from initial word and phrase alignments. 2.3.1 An Overview of n-code The baseline translation model is implemented as a stochastic finite-state transducer trained using a n-gram model of (source,target) pairs (Casacuberta and Vidal, 2004). Training this model requires to reorder source sentences so as to match the target word order. This is performed by a stochastic finitestate reordering model, which uses part-of-speech information3 to generalize reordering patterns beyond lexical regularities. In addition to the translation model, eleven feature functions are combined: a target-language model; four lexicon models; two lexicalized reordering models (Tillmann, 2004) aiming at predicting the orientation of the next translation unit; a ’weak’ distance-based distortion model; and finally a wordbonus model and a tuple-bonus model"
W12-3140,J07-2003,0,0.0283293,"322–329, c Montr´eal, Canada, June 7-8, 2012. 2012 Association for Computational Linguistics set also includes an n-gram language model, phraselevel IBM-1 and word-, phrase- and distortionpenalties, which are combined in log-linear fashion. The model weights are optimized with standard Mert (Och, 2003) on 200-best lists. The optimization criterium is B LEU. 2.1.2 Hierarchical System For the hierarchical setups (HPBT) described in this paper, the open source Jane toolkit (Vilar et al., 2010) is employed. Jane has been developed at RWTH and implements the hierarchical approach as introduced by Chiang (2007) with some state-of-theart extensions. In hierarchical phrase-based translation, a weighted synchronous context-free grammar is induced from parallel text. In addition to contiguous lexical phrases, hierarchical phrases with up to two gaps are extracted. The search is typically carried out using the cube pruning algorithm (Huang and Chiang, 2007). The model weights are optimized with standard Mert (Och, 2003) on 100-best lists. The optimization criterium is 4B LEU −T ER. 2.1.3 Preprocessing In order to reduce the source vocabulary size translation, the German text was preprocessed by splitting"
W12-3140,W08-0310,1,0.935329,"Missing"
W12-3140,2010.iwslt-papers.6,0,0.0806631,"as last year5 and thus the same target language model as detailed in (Allauzen et al., 2011). For English, we took advantage of our in-house text processing tools for tokenization and detokenization steps (D´echelotte et al., 2008) and our system was built in ”true-case”. As German is morphologically more complex than English, the default policy which consists in treating each word form independently is plagued with data sparsity, which is detrimental both at training and decoding time. Thus, the German side was normalized using a specific pre-processing scheme (Allauzen et al., 2010; Durgar El-Kahlout and Yvon, 2010), which notably aims at reducing the lexical redundancy by (i) normalizing the orthography, (ii) neutralizing most inflections and (iii) splitting complex compounds. 2.4 SYSTRAN Software, Inc. Single System The data submitted by SYSTRAN were obtained by a system composed of the standard SYSTRAN MT engine in combination with a statistical post editing (SPE) component. 4 http://geek.kyloo.net/software 5 The fifth edition of the English Gigaword (LDC2011T07) was not used. 325 The SYSTRAN system is traditionally classified as a rule-based system. However, over the decades, its development has alwa"
W12-3140,P07-1019,0,0.0343944,"on criterium is B LEU. 2.1.2 Hierarchical System For the hierarchical setups (HPBT) described in this paper, the open source Jane toolkit (Vilar et al., 2010) is employed. Jane has been developed at RWTH and implements the hierarchical approach as introduced by Chiang (2007) with some state-of-theart extensions. In hierarchical phrase-based translation, a weighted synchronous context-free grammar is induced from parallel text. In addition to contiguous lexical phrases, hierarchical phrases with up to two gaps are extracted. The search is typically carried out using the cube pruning algorithm (Huang and Chiang, 2007). The model weights are optimized with standard Mert (Och, 2003) on 100-best lists. The optimization criterium is 4B LEU −T ER. 2.1.3 Preprocessing In order to reduce the source vocabulary size translation, the German text was preprocessed by splitting German compound words with the frequency-based method described in (Koehn and Knight, 2003a). To further reduce translation complexity for the phrase-based approach, we performed the long-range part-of-speech based reordering rules proposed by (Popovi´c et al., 2006). 2.1.4 Language Model For both decoders a 4-gram language model is applied. The"
W12-3140,E03-1076,0,0.55884,"ranslation, a weighted synchronous context-free grammar is induced from parallel text. In addition to contiguous lexical phrases, hierarchical phrases with up to two gaps are extracted. The search is typically carried out using the cube pruning algorithm (Huang and Chiang, 2007). The model weights are optimized with standard Mert (Och, 2003) on 100-best lists. The optimization criterium is 4B LEU −T ER. 2.1.3 Preprocessing In order to reduce the source vocabulary size translation, the German text was preprocessed by splitting German compound words with the frequency-based method described in (Koehn and Knight, 2003a). To further reduce translation complexity for the phrase-based approach, we performed the long-range part-of-speech based reordering rules proposed by (Popovi´c et al., 2006). 2.1.4 Language Model For both decoders a 4-gram language model is applied. The language model is trained on the parallel data as well as the provided News crawl, the 109 French-English, UN and LDC Gigaword Fourth Edition corpora. For the 109 French-English, UN and LDC Gigaword corpora RWTH applied the data selection technique described in (Moore and Lewis, 2010). 2.2 2.2.1 Karlsruhe Institute of Technology Single Syst"
W12-3140,W07-0732,1,0.793396,"rule-based system. However, over the decades, its development has always been driven by pragmatic considerations, progressively integrating many of the most efficient MT approaches and techniques. Nowadays, the baseline engine can be considered as a linguistic-oriented system making use of dependency analysis, general transfer rules as well as of large manually encoded dictionaries (100k 800k entries per language pair). The SYSTRAN phrase-based SPE component views the output of the rule-based system as the source language, and the (human) reference translation as the target language, see (L. Dugast and Koehn, 2007). It performs corrections and adaptions learned from the 5-gram language model trained on the parallel target-to-target corpus. Moreover, the following measures - limiting unwanted statistical effects - were applied: • Named entities, time and numeric expressions are replaced by special tokens on both sides. This usually improves word alignment, since the vocabulary size is significantly reduced. In addition, entity translation is handled more reliably by the rule-based engine. • The intersection of both vocabularies (i.e. vocabularies of the rule-based output and the reference translation) is"
W12-3140,N12-1005,1,0.858653,"bilingual pairs, which means that the underlying vocabulary can be quite large. Unfortunately, the parallel data available to train these models are typically smaller than the corresponding monolingual corpora used to train target language models. It is very likely then, that such models should face severe estimation problems. In such setting, using neural network language 3 Part-of-speech labels for English and German are computed using the TreeTagger (Schmid, 1995). 2 http://ncode.limsi.fr/ 324 model techniques seem all the more appropriate. For this study, we follow the recommendations of Le et al. (2012), who propose to factor the joint probability of a sentence pair by decomposing tuples in two (source and target) parts, and further each part in words. This yields a word factored translation model that can be estimated in a continuous space using the SOUL architecture (Le et al., 2011). The design and integration of a SOUL model for large SMT tasks is far from easy, given the computational cost of computing n-gram probabilities. The solution used here was to resort to a two pass approach: the first pass uses a conventional back-off n-gram model to produce a k-best list; in the second pass, t"
W12-3140,J06-4004,1,0.843277,"Missing"
W12-3140,E06-1005,1,0.849031,"glish LDC Gigaword corpus using KneserNey (Kneser and Ney, 1995) smoothing was added. Weights for these separate models were tuned by the Mert algorithm provided in the Moses toolkit (P. Koehn et al., 2007), using the provided news development set. 3 RWTH Aachen System Combination System combination is used to produce consensus translations from multiple hypotheses produced with different translation engines that are better in terms of translation quality than any of the individual hypotheses. The basic concept of RWTH’s approach to machine translation system combination has been described by Matusov et al. (2006; 2008). This approach includes an enhanced alignment and reordering framework. A lattice is built from the input hypotheses. The translation with the best score within the lattice according to a couple of statistical models is selected as consensus translation. 4 Experiments This year, we tried different sets of single systems for system combination. As RWTH has two different translation systems, we put the output of both systems into system combination. Although both systems have the same preprocessing and language model, their hypotheses differ because of their different decoding approach."
W12-3140,D09-1022,1,0.869178,"done using Minimum Error Rate Training as described in Venugopal et al. (2005). 2.2.3 We preprocess the training data prior to training the system, first by normalizing symbols such as 323 Translation Models The translation model is trained on the Europarl and News Commentary Corpus and the phrase table is based on a discriminative word alignment (Niehues and Vogel, 2008). In addition, the system applies a bilingual language model (Niehues et al., 2011) to extend the context of source language words available for translation. Furthermore, we use a discriminative word lexicon as introduced in (Mauser et al., 2009). The lexicon was trained and integrated into our system as described in (Mediani et al., 2011). At last, we tried to find translations for out-of-vocabulary (OOV) words by using quasimorphological operations as described in Niehues and Waibel (2011). For each OOV word, we try to find a related word that we can translate. We modify the ending letters of the OOV word and learn quasimorphological operations to be performed on the known translation of the related word to synthesize a translation for the OOV word. By this approach we were for example able to translate Kaminen into chimneys using t"
W12-3140,2011.iwslt-evaluation.9,1,0.871665,"ocess the training data prior to training the system, first by normalizing symbols such as 323 Translation Models The translation model is trained on the Europarl and News Commentary Corpus and the phrase table is based on a discriminative word alignment (Niehues and Vogel, 2008). In addition, the system applies a bilingual language model (Niehues et al., 2011) to extend the context of source language words available for translation. Furthermore, we use a discriminative word lexicon as introduced in (Mauser et al., 2009). The lexicon was trained and integrated into our system as described in (Mediani et al., 2011). At last, we tried to find translations for out-of-vocabulary (OOV) words by using quasimorphological operations as described in Niehues and Waibel (2011). For each OOV word, we try to find a related word that we can translate. We modify the ending letters of the OOV word and learn quasimorphological operations to be performed on the known translation of the related word to synthesize a translation for the OOV word. By this approach we were for example able to translate Kaminen into chimneys using the known translation Kamin # chimney. 2.2.4 Preprocessing System Overview Language Models We us"
W12-3140,P10-2041,0,0.0181873,"ound words with the frequency-based method described in (Koehn and Knight, 2003a). To further reduce translation complexity for the phrase-based approach, we performed the long-range part-of-speech based reordering rules proposed by (Popovi´c et al., 2006). 2.1.4 Language Model For both decoders a 4-gram language model is applied. The language model is trained on the parallel data as well as the provided News crawl, the 109 French-English, UN and LDC Gigaword Fourth Edition corpora. For the 109 French-English, UN and LDC Gigaword corpora RWTH applied the data selection technique described in (Moore and Lewis, 2010). 2.2 2.2.1 Karlsruhe Institute of Technology Single System quotes, dashes and apostrophes. Then smart-casing of the first words of each sentence is performed. For the German part of the training corpus we use the hunspell1 lexicon to learn a mapping from old German spelling to new German spelling to obtain a corpus with homogenous spelling. In addition, we perform compound splitting as described in (Koehn and Knight, 2003b). Finally, we remove very long sentences, empty lines, and sentences that probably are not parallel due to length mismatch. 2.2.2 The KIT system uses an in-house phrase-bas"
W12-3140,W09-0435,1,0.860476,"Preprocessing System Overview Language Models We use two 4-gram SRI language models, one trained on the News Shuffle corpus and one trained 1 http://hunspell.sourceforge.net/ on the Gigaword corpus. Furthermore, we use a 5gram cluster-based language model trained on the News Shuffle corpus. The word clusters were created using the MKCLS algorithm. We used 100 word clusters. 2.2.5 Reordering Model Reordering is performed based on part-of-speech tags obtained using the TreeTagger (Schmid, 1994). Based on these tags we learn probabilistic continuous (Rottmann and Vogel, 2007) and discontinuous (Niehues and Kolss, 2009) rules to cover short and long-range reorderings. The rules are learned from the training corpus and the alignment. In addition, we learned tree-based reordering rules. Therefore, the training corpus was parsed by the Stanford parser (Rafferty and Manning, 2008). The tree-based rules consist of the head node of a subtree and all its children as well as the new order and a probability. These rules were applied recursively. The reordering rules are applied to the source sentences and the reordered sentence variants as well as the original sequence are encoded in a word lattice which is used as i"
W12-3140,W08-0303,1,0.84967,"very long sentences, empty lines, and sentences that probably are not parallel due to length mismatch. 2.2.2 The KIT system uses an in-house phrase-based decoder (Vogel, 2003) to perform translation and optimization with regard to the B LEU score is done using Minimum Error Rate Training as described in Venugopal et al. (2005). 2.2.3 We preprocess the training data prior to training the system, first by normalizing symbols such as 323 Translation Models The translation model is trained on the Europarl and News Commentary Corpus and the phrase table is based on a discriminative word alignment (Niehues and Vogel, 2008). In addition, the system applies a bilingual language model (Niehues et al., 2011) to extend the context of source language words available for translation. Furthermore, we use a discriminative word lexicon as introduced in (Mauser et al., 2009). The lexicon was trained and integrated into our system as described in (Mediani et al., 2011). At last, we tried to find translations for out-of-vocabulary (OOV) words by using quasimorphological operations as described in Niehues and Waibel (2011). For each OOV word, we try to find a related word that we can translate. We modify the ending letters o"
W12-3140,2011.iwslt-papers.6,1,0.847434,"he Europarl and News Commentary Corpus and the phrase table is based on a discriminative word alignment (Niehues and Vogel, 2008). In addition, the system applies a bilingual language model (Niehues et al., 2011) to extend the context of source language words available for translation. Furthermore, we use a discriminative word lexicon as introduced in (Mauser et al., 2009). The lexicon was trained and integrated into our system as described in (Mediani et al., 2011). At last, we tried to find translations for out-of-vocabulary (OOV) words by using quasimorphological operations as described in Niehues and Waibel (2011). For each OOV word, we try to find a related word that we can translate. We modify the ending letters of the OOV word and learn quasimorphological operations to be performed on the known translation of the related word to synthesize a translation for the OOV word. By this approach we were for example able to translate Kaminen into chimneys using the known translation Kamin # chimney. 2.2.4 Preprocessing System Overview Language Models We use two 4-gram SRI language models, one trained on the News Shuffle corpus and one trained 1 http://hunspell.sourceforge.net/ on the Gigaword corpus. Further"
W12-3140,W11-2124,1,0.868397,"length mismatch. 2.2.2 The KIT system uses an in-house phrase-based decoder (Vogel, 2003) to perform translation and optimization with regard to the B LEU score is done using Minimum Error Rate Training as described in Venugopal et al. (2005). 2.2.3 We preprocess the training data prior to training the system, first by normalizing symbols such as 323 Translation Models The translation model is trained on the Europarl and News Commentary Corpus and the phrase table is based on a discriminative word alignment (Niehues and Vogel, 2008). In addition, the system applies a bilingual language model (Niehues et al., 2011) to extend the context of source language words available for translation. Furthermore, we use a discriminative word lexicon as introduced in (Mauser et al., 2009). The lexicon was trained and integrated into our system as described in (Mediani et al., 2011). At last, we tried to find translations for out-of-vocabulary (OOV) words by using quasimorphological operations as described in Niehues and Waibel (2011). For each OOV word, we try to find a related word that we can translate. We modify the ending letters of the OOV word and learn quasimorphological operations to be performed on the known"
W12-3140,J03-1002,1,0.00977827,"RO partner trained their systems on the parallel Europarl and News Commentary corpora. All single systems were tuned on the newstest2009 or newstest2010 development set. The newstest2011 dev set was used to train the system combination parameters. Finally, the newstest2008-newstest2010 dev sets were used to compare the results of the different system combination settings. In this Section all four different system engines are presented. 2.1 RWTH Aachen Single Systems For the WMT 2012 evaluation the RWTH utilized RWTH’s state-of-the-art phrase-based and hierarchical translation systems. GIZA++ (Och and Ney, 2003) was employed to train word alignments, language models have been created with the SRILM toolkit (Stolcke, 2002). 2.1.1 Phrase-Based System The phrase-based translation (PBT) system is similar to the one described in Zens and Ney (2008). After phrase pair extraction from the word-aligned parallel corpus, the translation probabilities are estimated by relative frequencies. The standard feature 322 Proceedings of the 7th Workshop on Statistical Machine Translation, pages 322–329, c Montr´eal, Canada, June 7-8, 2012. 2012 Association for Computational Linguistics set also includes an n-gram langu"
W12-3140,P03-1021,0,0.230828,"n (PBT) system is similar to the one described in Zens and Ney (2008). After phrase pair extraction from the word-aligned parallel corpus, the translation probabilities are estimated by relative frequencies. The standard feature 322 Proceedings of the 7th Workshop on Statistical Machine Translation, pages 322–329, c Montr´eal, Canada, June 7-8, 2012. 2012 Association for Computational Linguistics set also includes an n-gram language model, phraselevel IBM-1 and word-, phrase- and distortionpenalties, which are combined in log-linear fashion. The model weights are optimized with standard Mert (Och, 2003) on 200-best lists. The optimization criterium is B LEU. 2.1.2 Hierarchical System For the hierarchical setups (HPBT) described in this paper, the open source Jane toolkit (Vilar et al., 2010) is employed. Jane has been developed at RWTH and implements the hierarchical approach as introduced by Chiang (2007) with some state-of-theart extensions. In hierarchical phrase-based translation, a weighted synchronous context-free grammar is induced from parallel text. In addition to contiguous lexical phrases, hierarchical phrases with up to two gaps are extracted. The search is typically carried out"
W12-3140,P07-2045,0,0.00885526,"to improve word alignment. • Singleton phrase pairs are deleted from the phrase table to avoid overfitting. • Phrase pairs not containing the same number of entities on the source and the target side are also discarded. The SPE language model was trained on 2M bilingual phrases from the news/Europarl corpora, provided as training data for WMT 2012. An additional language model built from 15M phrases of the English LDC Gigaword corpus using KneserNey (Kneser and Ney, 1995) smoothing was added. Weights for these separate models were tuned by the Mert algorithm provided in the Moses toolkit (P. Koehn et al., 2007), using the provided news development set. 3 RWTH Aachen System Combination System combination is used to produce consensus translations from multiple hypotheses produced with different translation engines that are better in terms of translation quality than any of the individual hypotheses. The basic concept of RWTH’s approach to machine translation system combination has been described by Matusov et al. (2006; 2008). This approach includes an enhanced alignment and reordering framework. A lattice is built from the input hypotheses. The translation with the best score within the lattice accor"
W12-3140,W08-1006,0,0.100843,"ained on the News Shuffle corpus. The word clusters were created using the MKCLS algorithm. We used 100 word clusters. 2.2.5 Reordering Model Reordering is performed based on part-of-speech tags obtained using the TreeTagger (Schmid, 1994). Based on these tags we learn probabilistic continuous (Rottmann and Vogel, 2007) and discontinuous (Niehues and Kolss, 2009) rules to cover short and long-range reorderings. The rules are learned from the training corpus and the alignment. In addition, we learned tree-based reordering rules. Therefore, the training corpus was parsed by the Stanford parser (Rafferty and Manning, 2008). The tree-based rules consist of the head node of a subtree and all its children as well as the new order and a probability. These rules were applied recursively. The reordering rules are applied to the source sentences and the reordered sentence variants as well as the original sequence are encoded in a word lattice which is used as input to the decoder. For the test sentences, the reordering based on parts-of-speech and trees allows us to change the word order in the source sentence so that the sentence can be translated more easily. In addition, we build reordering lattices for all trainin"
W12-3140,2007.tmi-papers.21,0,0.266844,"the known translation Kamin # chimney. 2.2.4 Preprocessing System Overview Language Models We use two 4-gram SRI language models, one trained on the News Shuffle corpus and one trained 1 http://hunspell.sourceforge.net/ on the Gigaword corpus. Furthermore, we use a 5gram cluster-based language model trained on the News Shuffle corpus. The word clusters were created using the MKCLS algorithm. We used 100 word clusters. 2.2.5 Reordering Model Reordering is performed based on part-of-speech tags obtained using the TreeTagger (Schmid, 1994). Based on these tags we learn probabilistic continuous (Rottmann and Vogel, 2007) and discontinuous (Niehues and Kolss, 2009) rules to cover short and long-range reorderings. The rules are learned from the training corpus and the alignment. In addition, we learned tree-based reordering rules. Therefore, the training corpus was parsed by the Stanford parser (Rafferty and Manning, 2008). The tree-based rules consist of the head node of a subtree and all its children as well as the new order and a probability. These rules were applied recursively. The reordering rules are applied to the source sentences and the reordered sentence variants as well as the original sequence are"
W12-3140,N04-4026,0,0.0510078,"of n-code The baseline translation model is implemented as a stochastic finite-state transducer trained using a n-gram model of (source,target) pairs (Casacuberta and Vidal, 2004). Training this model requires to reorder source sentences so as to match the target word order. This is performed by a stochastic finitestate reordering model, which uses part-of-speech information3 to generalize reordering patterns beyond lexical regularities. In addition to the translation model, eleven feature functions are combined: a target-language model; four lexicon models; two lexicalized reordering models (Tillmann, 2004) aiming at predicting the orientation of the next translation unit; a ’weak’ distance-based distortion model; and finally a wordbonus model and a tuple-bonus model which compensate for the system preference for short translations. The four lexicon models are similar to the ones used in a standard phrase based system: two scores correspond to the relative frequencies of the tuples and two lexical weights estimated from the automatically generated word alignments. The weights associated to feature functions are optimally combined using a discriminative training framework (Och, 2003), using the n"
W12-3140,W05-0836,1,0.92366,"rmed. For the German part of the training corpus we use the hunspell1 lexicon to learn a mapping from old German spelling to new German spelling to obtain a corpus with homogenous spelling. In addition, we perform compound splitting as described in (Koehn and Knight, 2003b). Finally, we remove very long sentences, empty lines, and sentences that probably are not parallel due to length mismatch. 2.2.2 The KIT system uses an in-house phrase-based decoder (Vogel, 2003) to perform translation and optimization with regard to the B LEU score is done using Minimum Error Rate Training as described in Venugopal et al. (2005). 2.2.3 We preprocess the training data prior to training the system, first by normalizing symbols such as 323 Translation Models The translation model is trained on the Europarl and News Commentary Corpus and the phrase table is based on a discriminative word alignment (Niehues and Vogel, 2008). In addition, the system applies a bilingual language model (Niehues et al., 2011) to extend the context of source language words available for translation. Furthermore, we use a discriminative word lexicon as introduced in (Mauser et al., 2009). The lexicon was trained and integrated into our system a"
W12-3140,W10-1738,1,0.875756,"by relative frequencies. The standard feature 322 Proceedings of the 7th Workshop on Statistical Machine Translation, pages 322–329, c Montr´eal, Canada, June 7-8, 2012. 2012 Association for Computational Linguistics set also includes an n-gram language model, phraselevel IBM-1 and word-, phrase- and distortionpenalties, which are combined in log-linear fashion. The model weights are optimized with standard Mert (Och, 2003) on 200-best lists. The optimization criterium is B LEU. 2.1.2 Hierarchical System For the hierarchical setups (HPBT) described in this paper, the open source Jane toolkit (Vilar et al., 2010) is employed. Jane has been developed at RWTH and implements the hierarchical approach as introduced by Chiang (2007) with some state-of-theart extensions. In hierarchical phrase-based translation, a weighted synchronous context-free grammar is induced from parallel text. In addition to contiguous lexical phrases, hierarchical phrases with up to two gaps are extracted. The search is typically carried out using the cube pruning algorithm (Huang and Chiang, 2007). The model weights are optimized with standard Mert (Och, 2003) on 100-best lists. The optimization criterium is 4B LEU −T ER. 2.1.3 P"
W12-3140,2008.iwslt-papers.8,1,0.841876,"parameters. Finally, the newstest2008-newstest2010 dev sets were used to compare the results of the different system combination settings. In this Section all four different system engines are presented. 2.1 RWTH Aachen Single Systems For the WMT 2012 evaluation the RWTH utilized RWTH’s state-of-the-art phrase-based and hierarchical translation systems. GIZA++ (Och and Ney, 2003) was employed to train word alignments, language models have been created with the SRILM toolkit (Stolcke, 2002). 2.1.1 Phrase-Based System The phrase-based translation (PBT) system is similar to the one described in Zens and Ney (2008). After phrase pair extraction from the word-aligned parallel corpus, the translation probabilities are estimated by relative frequencies. The standard feature 322 Proceedings of the 7th Workshop on Statistical Machine Translation, pages 322–329, c Montr´eal, Canada, June 7-8, 2012. 2012 Association for Computational Linguistics set also includes an n-gram language model, phraselevel IBM-1 and word-, phrase- and distortionpenalties, which are combined in log-linear fashion. The model weights are optimized with standard Mert (Och, 2003) on 200-best lists. The optimization criterium is B LEU. 2."
W12-3140,W11-2135,1,\N,Missing
W12-3140,W10-1704,1,\N,Missing
W12-3140,D08-1076,0,\N,Missing
W12-3157,W06-3123,0,0.0468995,"Missing"
W12-3157,J90-2002,0,0.717089,"v model. In this work we apply the phrase training method introduced by Wuebker et al. (2010), where the phrase translation model of a fully competitive SMT system is trained in a generative way. The key to avoiding the over-fitting effects described by DeNero et al. (2006) is their novel leave-one-out procedure. 3 Decoding 3.1 Phrase-based translation We use a standard phrase-based decoder which ˆ searches for the best translation eˆI1 for a given input 452 sentence f1J by maximizing the posterior probability ˆ eˆI1 = arg max P r(eI1 |f1J ). (1) I,eI1 Generalizing the noisy channel approach (Brown et al., 1990) and making use of the maximum approximation (Viterbi), the decoder directly models the posterior probability by a log-linear combiJ nation of several feature functions hm (eI1 , sK 1 , f1 ) weighted with scaling factors λm , which results in the decision rule (Och and Ney, 2004) ( ˆ eˆI1 = arg max I,eI1 ,K,sK 1 M X ) J λm hm (eI1 , sK 1 , f1 ) . (2) m=1 I J Here, sK 1 denotes the segmentation of e1 and f1 into K phrase-pairs and their alignment. The features used are the language model, phrase translation and lexical smoothing models in both directions, word and phrase penalty and a simple di"
W12-3157,W06-3105,0,0.0588457,"Missing"
W12-3157,D08-1033,0,0.0378588,"Missing"
W12-3157,P08-1115,0,0.574401,"dapted this approach to model ambiguities in representing the source language with lattices and were able to report improvements over their respective baselines. The probabilities for different paths through the lattice are usually modeled by assigning probabilities to arcs as a byproduct of the lattice generation or by defining binary indicator features. Applying the first method only makes sense if the lattice construction is based on a single, comprehensive probabilistic method, like a Chinese word segmentation model as is used by Xu et al. (2005). In applications like the one described by Dyer et al. (2008), where several different segmenters for Chinese are combined to create the lattice, this is not possible. Also, our intuition suggests that simply defining indicator features for each of the segmenters may not be ideal, if we assume that there is not a single best segmenter, but rather that for different data instances a different one works best. In statistical machine translation, word lattices are used to represent the ambiguities in the preprocessing of the source sentence, such as word segmentation for Chinese or morphological analysis for German. Several approaches have been proposed to"
W12-3157,N09-1046,0,0.0824065,"Missing"
W12-3157,2009.eamt-1.23,0,0.0600468,"Missing"
W12-3157,W10-1710,0,0.311321,"Missing"
W12-3157,D07-1091,0,0.352491,"Missing"
W12-3157,E03-1076,0,0.417916,"standard distance-based reordering model needs to be redefined for lattice input. We define the distortion penalty as the difference in slot number. Using the shortest path within the lattice is reported to have better performance in (Dyer et al., 2008), however we did not implement it due to time constraints. 4 Lattice design We construct lattices from three different preprocessing variants of the German source side of the data. The surface form is the standard tokenization of the source sentence. The word compounds are produced by the frequency-based compound splitting method described in (Koehn and Knight, 2003), applied to the tokenized sentence. From the compound split sentence we produce the lemma of the 453 German words by applying the TreeTagger toolkit (Schmid, 1995). Each of the different preprocessing variants is assigned a separate layer within the lattice. For the phrase model, word identities are defined by both the word and its layer. In this way, the phrase model can assign different scores to phrases in different layers, allowing it to guide the search towards a specific layer for each word. In practice, this is done by annotating words with a unique identifier for each layer. For examp"
W12-3157,N03-1017,0,0.0253648,"Missing"
W12-3157,W04-3250,0,0.300902,"Missing"
W12-3157,W02-1018,0,0.0914856,"Missing"
W12-3157,W07-0715,0,0.037709,"Missing"
W12-3157,D08-1066,0,0.0297649,"Missing"
W12-3157,W09-0435,0,0.223241,"Missing"
W12-3157,J03-1002,1,0.00897445,"-gram count on the other. In this way the model learns to prefer lattice paths which are taken more often in training. For example, if the phrase (LEM.Streit LEM.Kraft) is used to align the sentence from Figure 1, Cmon (f˜) will 454 Experimental evaluation 6.1 Experimental setup Our experiments are carried out on the newscommentary portion of the German→English data provided for the EMNLP 2011 Sixth Workshop on Statistical Machine Translation (WMT 2011).∗ We use newstest2008 as development set and newstest2009 and newstest2010 as unseen test sets. The word alignments are produced with GIZA++ (Och and Ney, 2003). To optimize the loglinear parameters, the Downhill-Simplex algorithm (Nelder and Mead, 1965) is applied with B LEU (Papineni et al., 2002) as optimization criterion. The ∗ http://www.statmt.org/wmt11 Surface Train newstest2008 newstest2009 newstest2010 Sentences Running Words Vocabulary Size Sentences Running Words Vocabulary Size OOVs (Running Words) Sentences Running Words Vocabulary Size OOVs (Running Words) Sentences Running Words Vocabulary Size OOVs (Running Words) 3.4M 118K 48K 10.3K 3041 63K 12.2K 4058 62K 12.3K 4357 German Compound Lemma 136K 3.5M 81K 52K 2051 50K 9.7K 7.3K 2092 174"
W12-3157,J04-4002,1,0.652426,"ir novel leave-one-out procedure. 3 Decoding 3.1 Phrase-based translation We use a standard phrase-based decoder which ˆ searches for the best translation eˆI1 for a given input 452 sentence f1J by maximizing the posterior probability ˆ eˆI1 = arg max P r(eI1 |f1J ). (1) I,eI1 Generalizing the noisy channel approach (Brown et al., 1990) and making use of the maximum approximation (Viterbi), the decoder directly models the posterior probability by a log-linear combiJ nation of several feature functions hm (eI1 , sK 1 , f1 ) weighted with scaling factors λm , which results in the decision rule (Och and Ney, 2004) ( ˆ eˆI1 = arg max I,eI1 ,K,sK 1 M X ) J λm hm (eI1 , sK 1 , f1 ) . (2) m=1 I J Here, sK 1 denotes the segmentation of e1 and f1 into K phrase-pairs and their alignment. The features used are the language model, phrase translation and lexical smoothing models in both directions, word and phrase penalty and a simple distancebased reordering penalty. 3.2 Lattice translation For lattice input we generalize Equation 2 to also maximize over the set of sentences F(L) encoded by a given source word lattice L: ˆ eˆI1 = ( arg max J I,eI1 ,K,sK 1 ,f1 ∈F (L) M X ) J λm hm (eI1 , sK 1 , f1 ) (3) m=1 Note"
W12-3157,P10-2001,0,0.0587469,"Missing"
W12-3157,P02-1040,0,0.0833125,"Missing"
W12-3157,popovic-ney-2006-pos,1,0.92095,"Missing"
W12-3157,E09-1082,0,0.0428343,"Missing"
W12-3157,2006.amta-papers.25,0,0.0855428,"Missing"
W12-3157,P10-1049,1,0.853799,"raining data sentence. For each layer, we add two indicator features to the phrase table: One binary feature which is set to 1 if the phrase is taken from this layer, and one feature which is equal to the number of words from this layer. This results in six additional feature functions, whose weights are optimized jointly with the standard features described in Section 3.1. We will denote them as layer features. 5 Phrase translation model training To train the phrase model, we use a modified version of the translation decoder to force-align the training data. We apply the method described in (Wuebker et al., 2010), but with word lattices on the source side. To avoid over-fitting, we use their cross-validation technique, which is described as a low-cost alternative to leave-one-out. For cross-validation we segment the training data into batches containing 5000 sentences. For each batch, the phrase table is updated by reducing the phrase counts by the local counts produced by the current batch in the previous training iteration. For the first iteration, we perform the standard phrase extraction separately for each batch to produce the local counts. Singleton ˜ phrases are assigned the probability β (|f |"
W12-3157,2005.iwslt-1.18,1,0.874249,"Missing"
W12-3157,2006.amta-papers.2,0,\N,Missing
W12-5903,P08-1009,0,0.0159728,"hat the reliability of the rules is often language pair dependent. In the second category, researchers try to inform the decoder on what a good reordering is or what a suitable decoding sequence is. (Zens and Ney, 2006) used a discriminative reordering model to predict the orientation of the next phrase given the previous phrase. (Mariño et al., 2006) presents a translation model that constitutes a language model of a sort of “bilanguage” composed of bilingual units. From the reordering point of view, the idea is that the correct reordering is to find the suitable order of translation units. (Cherry, 2008) puts the syntactic cohesion as a soft constraint in the decoder to guide the decoding process to choose those translations that do not violate the syntactic structure of the source sentence. Adding new 18 features in the log-linear framework has the advantage that the new feature has access to the whole search space. Another advantage of methods in this category is that we let the decoder decide the weights of features, so that even if one model gives wrong estimation sometimes, it can still be corrected by other models. Our work in this paper belongs to this category. In the reranking step,"
W12-5903,J99-4005,0,0.0928807,"data. Results show that our model improves the baseline system by 0.98 BLEU 1.21 TER on average. KEYWORDS: statistical machine translation, reordering, conditional random fields. Proceedings of the Workshop on Reordering for Statistical Machine Translation, pages 17–26, COLING 2012, Mumbai, December 2012. 17 1 Introduction The systematic word order difference between two languages pose a challenge for current statistical machine translation (SMT) systems. The system has to decide in which order to translate the given source words. This problem is known as the reordering problem. As shown in (Knight, 1999), if arbitrary reordering is allowed, the search problem is NP-hard. In this paper, we propose a novel tagging style reordering model. Our model converts the reordering problem into a sequence labeling problem, i.e. a tagging task. For a given source sentence, we assign each source token a label which contains the reordering information for that token. We also design an unaligned word tag so that the unaligned word phenomenon is automatically covered in the proposed model. Our model is conditioned on the whole source sentence. Hence it is able to capture the long dependencies in the source sen"
W12-5903,W04-3250,0,0.0453416,"Missing"
W12-5903,P07-2045,0,0.00779695,"Missing"
W12-5903,N03-1017,0,0.0151071,"y using a log-linear combination of several models (Och and Ney, 2002): P  M exp λm hm (e1I , f1J ) P r(e1I |f1J ) = m=1 P 0 I ,e exp P M m=1 0 0I 1  0 0I λm hm (e 1 , f1J ) (2) The denominator is to make the P r(e1I |f1J ) to be a probability distribution and it depends only on the source sentence f1J . For search, the decision rule is simply: ˆeiI = arg max ˆ M nX I,e1I m=1 o λm hm (e1I , f1J ) (3) The model scaling factors λ1M are trained with Minimum Error Rate Training (MERT). In this paper, the phrase-based machine translation system is utilized (Och et al., 1999; Zens et al., 2002; Koehn et al., 2003). The translation process consists in segmenting of the source sentence according to the phrase table which is built from the word alignment. The translation of each of these segments consists just in extracting the target side from the phrase pair. With the corresponding target side, the final translation is the composition of these translated segments. In this last step, reordering is allowed. 4 Tagging-style Reordering Model In this section, we describe the proposed model. First we will describe the training process. Then we explain how to use the model in the decoder. 19 e1 e2 e3 f1 f2 f3"
W12-5903,P10-1052,0,0.498768,"slated after f j and f j translated before f j+1 Lreorder-Rreorder 1 < j < J and f j−1 translated after f j and f j translated after f j+1 Unalign f j is an unaligned source word Up to this point, we have converted the reordering problem into a tagging problem with nine tags. The transformation in Figure 1 is conducted for all the sentence pairs in the bilingual training corpus. After that, we have built an “annotated” corpus for the training. For this supervised structure learning task, we choose the approach conditional random fields (CRFs) (Lafferty et al., 2001; Sutton and Mccallum, 2006; Lavergne et al., 2010). More specifically, we adopt the linear-chain CRFs. However, even for the simple linear-chain CRFs, the complexity of learning and inference grows quadratically with respect to the number of output labels and the amount of structural features which are with regard to adjacent pairs of labels. Hence, to make the computational cost as low as possible, two measures have been taken. Firstly, as described above we reduce the number of tags to nine. Secondly, we add source sentence part-of-speech (POS) tags to the input. For features with window size one to three, both source words and its POS tags"
W12-5903,J06-4004,0,0.0494111,"Missing"
W12-5903,N04-1021,0,0.0382094,"guide the decoding process to choose those translations that do not violate the syntactic structure of the source sentence. Adding new 18 features in the log-linear framework has the advantage that the new feature has access to the whole search space. Another advantage of methods in this category is that we let the decoder decide the weights of features, so that even if one model gives wrong estimation sometimes, it can still be corrected by other models. Our work in this paper belongs to this category. In the reranking step, the system has the last opportunity to choose a good translation. (Och et al., 2004) describe the use of syntactic features in the rescoring step. They report the most useful feature is IBM Model 1 score. The syntactic features contribute very small gains. Another disadvantage of carrying out reordering in reranking is the representativeness of the N-best list is often a question mark. 3 Translation System Overview In this section, we are going to describe the phrase-based SMT system we used for the experiments. In statistical machine translation, we are given a source language sentence f1J = f1 . . . f j . . . f J . The objective is to translate the source into a target lang"
W12-5903,P02-1038,1,0.579454,"en a question mark. 3 Translation System Overview In this section, we are going to describe the phrase-based SMT system we used for the experiments. In statistical machine translation, we are given a source language sentence f1J = f1 . . . f j . . . f J . The objective is to translate the source into a target language sentence e1I = e1 . . . ei . . . e I . The strategy is among all possible target language sentences, we will choose the one with the highest probability: ˆeiI = arg max{P r(e1I |f1J )} ˆ I,e1I (1) We model P r(e1I |f1J ) directly using a log-linear combination of several models (Och and Ney, 2002): P  M exp λm hm (e1I , f1J ) P r(e1I |f1J ) = m=1 P 0 I ,e exp P M m=1 0 0I 1  0 0I λm hm (e 1 , f1J ) (2) The denominator is to make the P r(e1I |f1J ) to be a probability distribution and it depends only on the source sentence f1J . For search, the decision rule is simply: ˆeiI = arg max ˆ M nX I,e1I m=1 o λm hm (e1I , f1J ) (3) The model scaling factors λ1M are trained with Minimum Error Rate Training (MERT). In this paper, the phrase-based machine translation system is utilized (Och et al., 1999; Zens et al., 2002; Koehn et al., 2003). The translation process consists in segmenting of"
W12-5903,W99-0604,1,0.628824,"I (1) We model P r(e1I |f1J ) directly using a log-linear combination of several models (Och and Ney, 2002): P  M exp λm hm (e1I , f1J ) P r(e1I |f1J ) = m=1 P 0 I ,e exp P M m=1 0 0I 1  0 0I λm hm (e 1 , f1J ) (2) The denominator is to make the P r(e1I |f1J ) to be a probability distribution and it depends only on the source sentence f1J . For search, the decision rule is simply: ˆeiI = arg max ˆ M nX I,e1I m=1 o λm hm (e1I , f1J ) (3) The model scaling factors λ1M are trained with Minimum Error Rate Training (MERT). In this paper, the phrase-based machine translation system is utilized (Och et al., 1999; Zens et al., 2002; Koehn et al., 2003). The translation process consists in segmenting of the source sentence according to the phrase table which is built from the word alignment. The translation of each of these segments consists just in extracting the target side from the phrase pair. With the corresponding target side, the final translation is the composition of these translated segments. In this last step, reordering is allowed. 4 Tagging-style Reordering Model In this section, we describe the proposed model. First we will describe the training process. Then we explain how to use the mod"
W12-5903,2001.mtsummit-papers.68,0,0.0130254,"ty. The reordering model for the baseline system is the distance-based jump model which uses linear distance. This model does not have hard limit. We list the important information regarding the experimental setup below. All those conditions have been kept same in this work. • lowercased training data (Table 1) from the BOLT task alignment trained with GIZA++ • development corpus: NIST06 test corpora: NIST02 03 04 05 and 08 • 5-gram LM (1 694 412 027 running words) trained by SRILM toolkit (Stolcke, 2002) with modified Kneser-Ney smoothing training data: target side of bilingual data. • BLEU (Papineni et al., 2001) and TER (Snover et al., 2005) reported all scores calculated in lowercase way. • Wapiti toolkit (Lavergne et al., 2010) used for CRFs Chinese Sentences Running Words Vocabulary English 5 384 856 115 172 748 129 820 318 1 125 437 739 251 Table 1: training data statistics 5.2 CRFs Training Results Table 1 contains the data statistics used for translation model and LM. For the reordering model, we take two further filtering steps. Firstly, we delete the sentence pairs if the source sentence length is one. When the source sentence has only one word, the translation will be always monotonic and th"
W12-5903,D07-1077,0,0.0263381,"ill be given in Section 6. 2 Related Work Many ideas have been proposed to address the reordering problem. Within the phrase-based SMT framework there are mainly three stages where improved reordering could be integrated: 1. Reorder the source sentence. So that the word order of source and target sentences is similar. Usually it is done as the preprocessing step for both training data and test data. 2. In the decoder, add models in the log-linear framework or constraints in the decoder to reward good reordering options or penalize bad ones. 3. In the reranking framework. For the first point, (Wang et al., 2007) used manually designed rules to reorder parse trees of the source sentences as a preprocessing step. Based on shallow syntax, (Zhang et al., 2007) used rules to reorder the source sentences on the chunk level and provide a source-reordering lattice instead of a single reordered source sentence as input to the SMT system. Designing rules to reorder the source sentence is conceptually clear and usually easy to implement. In this way, syntax information can be incorporated into phrase-based SMT systems. However, one disadvantage is that the reliability of the rules is often language pair depende"
W12-5903,W06-3108,1,0.821695,"al., 2007) used rules to reorder the source sentences on the chunk level and provide a source-reordering lattice instead of a single reordered source sentence as input to the SMT system. Designing rules to reorder the source sentence is conceptually clear and usually easy to implement. In this way, syntax information can be incorporated into phrase-based SMT systems. However, one disadvantage is that the reliability of the rules is often language pair dependent. In the second category, researchers try to inform the decoder on what a good reordering is or what a suitable decoding sequence is. (Zens and Ney, 2006) used a discriminative reordering model to predict the orientation of the next phrase given the previous phrase. (Mariño et al., 2006) presents a translation model that constitutes a language model of a sort of “bilanguage” composed of bilingual units. From the reordering point of view, the idea is that the correct reordering is to find the suitable order of translation units. (Cherry, 2008) puts the syntactic cohesion as a soft constraint in the decoder to guide the decoding process to choose those translations that do not violate the syntactic structure of the source sentence. Adding new 18"
W12-5903,2002.tmi-tutorials.2,0,0.0305461,"(e1I |f1J ) directly using a log-linear combination of several models (Och and Ney, 2002): P  M exp λm hm (e1I , f1J ) P r(e1I |f1J ) = m=1 P 0 I ,e exp P M m=1 0 0I 1  0 0I λm hm (e 1 , f1J ) (2) The denominator is to make the P r(e1I |f1J ) to be a probability distribution and it depends only on the source sentence f1J . For search, the decision rule is simply: ˆeiI = arg max ˆ M nX I,e1I m=1 o λm hm (e1I , f1J ) (3) The model scaling factors λ1M are trained with Minimum Error Rate Training (MERT). In this paper, the phrase-based machine translation system is utilized (Och et al., 1999; Zens et al., 2002; Koehn et al., 2003). The translation process consists in segmenting of the source sentence according to the phrase table which is built from the word alignment. The translation of each of these segments consists just in extracting the target side from the phrase pair. With the corresponding target side, the final translation is the composition of these translated segments. In this last step, reordering is allowed. 4 Tagging-style Reordering Model In this section, we describe the proposed model. First we will describe the training process. Then we explain how to use the model in the decoder."
W12-5903,W07-0401,1,0.852154,"here are mainly three stages where improved reordering could be integrated: 1. Reorder the source sentence. So that the word order of source and target sentences is similar. Usually it is done as the preprocessing step for both training data and test data. 2. In the decoder, add models in the log-linear framework or constraints in the decoder to reward good reordering options or penalize bad ones. 3. In the reranking framework. For the first point, (Wang et al., 2007) used manually designed rules to reorder parse trees of the source sentences as a preprocessing step. Based on shallow syntax, (Zhang et al., 2007) used rules to reorder the source sentences on the chunk level and provide a source-reordering lattice instead of a single reordered source sentence as input to the SMT system. Designing rules to reorder the source sentence is conceptually clear and usually easy to implement. In this way, syntax information can be incorporated into phrase-based SMT systems. However, one disadvantage is that the reliability of the rules is often language pair dependent. In the second category, researchers try to inform the decoder on what a good reordering is or what a suitable decoding sequence is. (Zens and N"
W12-5903,P02-1040,0,\N,Missing
W13-0804,2010.amta-papers.7,0,\N,Missing
W13-0804,W12-3128,0,\N,Missing
W13-0804,E09-1044,0,\N,Missing
W13-0804,W05-1506,0,\N,Missing
W13-0804,J10-4005,0,\N,Missing
W13-0804,W09-0424,0,\N,Missing
W13-0804,D11-1020,0,\N,Missing
W13-0804,P02-1040,0,\N,Missing
W13-0804,W10-1738,1,\N,Missing
W13-0804,P12-3004,0,\N,Missing
W13-0804,N09-1027,0,\N,Missing
W13-0804,P07-2045,0,\N,Missing
W13-0804,D12-1107,0,\N,Missing
W13-0804,N13-1116,0,\N,Missing
W13-0804,W08-0402,0,\N,Missing
W13-0804,P05-1033,0,\N,Missing
W13-0804,P10-4002,0,\N,Missing
W13-0804,J03-1002,1,\N,Missing
W13-0804,2009.iwslt-papers.4,0,\N,Missing
W13-0804,P07-1019,0,\N,Missing
W13-0804,2011.eamt-1.37,1,\N,Missing
W13-0804,2012.eamt-1.44,0,\N,Missing
W13-0804,J07-2003,0,\N,Missing
W13-0804,W12-3150,0,\N,Missing
W13-0804,D08-1076,0,\N,Missing
W13-0804,2011.iwslt-evaluation.24,0,\N,Missing
W13-2223,W13-0805,1,0.848446,"OS) based reordering using probabilistic continuous (Rottmann and Vogel, 2007) and discontinuous (Niehues and Kolss, 2009) rules. This was learned using POS tags generated by the TreeTagger (Schmid, 1994) for short and long range reorderings respectively. In addition to this POS-based reordering, we also used tree-based reordering rules. Syntactic parse trees of the whole training corpus and the word alignment between source and target language are used to learn rules on how to reorder the constituents in a German source sentence to make it match the English target sentence word order better (Herrmann et al., 2013). The training corpus was parsed by the Stanford parser (Rafferty and Manning, 2008). The reordering rules are applied to the source sentences and the reordered sentence variants as well as the original sequence are encoded in a word lattice which is used as input to the decoder. Moreover, our reordering model was extended so that it could include the features of lexicalized reordering model. The reordering probabilities for each phrase pair are stored as well as the original position of each word in the lattice. During the decoding, the reordering origin of the words is checked along with its"
W13-2223,E03-1076,0,0.0855399,"n the parallel data as well as the provided News crawl, the 109 French-English, UN and LDC Gigaword Fourth Edition corpora. 2.2 System Overview Karlsruhe Institute of Technology Single System 2.2.1 Preprocessing The training data was preprocessed prior to the training. Symbols such as quotes, dashes and apostrophes are normalized. Then the first words of each sentence are smart-cased. For the German part of the training corpus, the hunspell2 lexicon was used, in order to learn a mapping from old German spelling to new German writing rules. Compound-splitting was also performed as described in Koehn and Knight (2003). We also removed very long sentences, empty lines, and sentences which show big mismatch on the length. 2.2.2 Filtering The web-crawled corpus was filtered using an SVM classifier as described in (Mediani et al., 2011). The lexica used in this filtering task were obtained from Giza alignments trained on the 2.2.5 Translation Models The translation model uses the parallel data of EPPS, NC, and the filtered web-crawled data. As word alignment, we used the Discriminative Word Alignment (DWA) as shown in (Niehues and Vo2 http://hunspell.sourceforge.net/ 186 gel, 2008). The phrase pairs were extra"
W13-2223,P07-2045,0,0.00527113,"ne Translation. The technique of Statistical Post-Editing (Dugast et al., 2007) is used to automatically edit the output of the rule-based system. A Statistical Post-Editing (SPE) module is generated from a bilingual corpus. It is basically a translation module by itself, however it is trained on rule-based • Phrase pairs appearing less than 2 times were pruned. The SPE language model was trained on 2M phrases from the news/europarl and CommonCrawl corpora, provided as training data for WMT 2013. Weights for these separate models were tuned by the Mert algorithm provided in the Moses toolkit (Koehn et al., 2007), using the provided news development set. 5 http://geek.kyloo.net/software 6 The fifth edition of (LDC2011T07) was not used. the English Gigaword 188 0 5:that/1 7:this/3 1 3:is/3 8:was/1 2 0:*EPS*/3 4:it/1 0:*EPS*/3 2:in/1 3 4 0:*EPS*/3 6:the/1 5 0:*EPS*/1 1:future/3 6 Figure 1: Confusion network of four different hypotheses. 3 RWTH Aachen System Combination Table 1: Comparison of single systems tuned on newstest2009 and newstest2010. The results are reported on newstest2012. System combination is used to produce consensus translations from multiple hypotheses generated with different transla"
W13-2223,J04-2004,0,0.0419685,"d a bilingual language model (Niehues et al., 2011). A Discriminative Word Lexicon (DWL) introduced in (Mauser et al., 2009) was extended so that it could take the source context also into the account. For this, we used a bag-of-ngrams instead of representing the source sentence as a bag-of-words. Filtering based on counts was then applied to the features for higher order n-grams. In addition to this, the training examples were created differently so that we only used the words that occur in the n-best list but not in the reference as negative example. a n-gram model of (source,target) pairs (Casacuberta and Vidal, 2004). Training this model requires to reorder source sentences so as to match the target word order. This is performed by a stochastic finite-state reordering model, which uses part-of-speech information4 to generalize reordering patterns beyond lexical regularities. In addition to the translation model, eleven feature functions are combined: a target-language model; four lexicon models; two lexicalized reordering models (Tillmann, 2004) aiming at predicting the orientation of the next translation unit; a ’weak’ distance-based distortion model; and finally a word-bonus model and a tuple-bonus mode"
W13-2223,W07-0734,0,0.0383886,"results are reported on newstest2012. System combination is used to produce consensus translations from multiple hypotheses generated with different translation engines. First, a word to word alignment for the given single system hypotheses is produced. In a second step a confusion network is constructed. Then, the hypothesis with the highest probability is extracted from this confusion network. For the alignment procedure, each of the given single systems generates one confusion network with its own as primary system. To this primary system all other hypotheses are aligned using the METEOR (Lavie and Agarwal, 2007) alignment and thus the primary system defines the word order. Once the alignment is given, the corresponding confusion network is constructed. An example is given in Figure 1. The final network for one source sentence is the union of all confusion networks generated from the different primary systems. That allows the system combination to select the word order from different system outputs. Before performing system combination, each translation output was normalized by tokenization and lowercasing. The output of the combination was then truecased based on the original truecased output. The mo"
W13-2223,W07-0732,0,0.0965924,"m = 10, and used k = 300. 2.3.4 translations and reference data. It applies corrections and adaptations learned from a phrase-based 5-gram language model. Using this two-step process will implicitly keep long distance relations and other constraints determined by the rule-based system while significantly improving phrasal fluency. It has the advantage that quality improvements can be achieved with very little but targeted bilingual data, thus significantly reducing training time and increasing translation performance. The basic setup of the SPE component is identical to the one described in (Dugast et al., 2007). A statistical translation model is trained on the rule-based translation of the source and the target side of the parallel corpus. Language models are trained on each target half of the parallel corpora and also on additional in-domain corpora. Moreover, the following measures - limiting unwanted statistical effects - were applied: Corpora and data pre-processing All the parallel data allowed in the constrained task are pooled together to create a single parallel corpus. This corpus is word-aligned using MGIZA++5 with default settings. For the English monolingual training data, we used the s"
W13-2223,N12-1005,0,0.0335346,"with standard n-gram translation models is that the elementary units are bilingual pairs, which means that the underlying vocabulary can be quite large, even for small translation tasks. Unfortunately, the parallel data available to train these models are typically order of magnitudes smaller than the corresponding monolingual corpora used to train target language models. It is very likely then, that such models should face severe estimation problems. In such setting, using neural network language model techniques seem all the more appropriate. For this study, we follow the recommendations of Le et al. (2012), who propose to factor the joint probability of a sentence pair by decomposing tuples in two (source and target) parts, and further each part in words. This yields a word factored translation model that LIMSI-CNRS Single System 2.3.1 System overview LIMSI’s system is built with n-code (Crego et al., 2011), an open source statistical machine translation system based on bilingual n-gram3 . In this approach, the translation model relies on a specific decomposition of the joint probability of a sentence pair using the n-gram assumption: a sentence pair is decomposed into a sequence of bilingual u"
W13-2223,2010.iwslt-papers.6,0,0.0342874,"Missing"
W13-2223,2012.iwslt-papers.7,1,0.838536,"an compound words with the frequencybased method described in (Koehn and Knight, 2003). To further reduce translation complexity for the phrase-based approach, we performed the long-range part-of-speech based reordering rules proposed by (Popovi´c et al., 2006). 2.2.3 The in-house phrase-based decoder (Vogel, 2003) is used to perform decoding. Optimization with regard to the BLEU score is done using Minimum Error Rate Training (MERT) as described in Venugopal et al. (2005). 2.1.2 Translation Model We applied filtering and weighting for domainadaptation similarly to (Mansour et al., 2011) and (Mansour and Ney, 2012). For filtering the bilingual data, a combination of LM and IBM Model 1 scores was used. In addition, we performed weighted phrase extraction by using a combined LM and IBM Model 1 weight. 2.2.4 Reordering Model We applied part-of-speech (POS) based reordering using probabilistic continuous (Rottmann and Vogel, 2007) and discontinuous (Niehues and Kolss, 2009) rules. This was learned using POS tags generated by the TreeTagger (Schmid, 1994) for short and long range reorderings respectively. In addition to this POS-based reordering, we also used tree-based reordering rules. Syntactic parse tree"
W13-2223,W08-0310,0,0.0216057,"nal in-domain corpora. Moreover, the following measures - limiting unwanted statistical effects - were applied: Corpora and data pre-processing All the parallel data allowed in the constrained task are pooled together to create a single parallel corpus. This corpus is word-aligned using MGIZA++5 with default settings. For the English monolingual training data, we used the same setup as last year6 and thus the same target language model as detailed in (Allauzen et al., 2011). For English, we also took advantage of our inhouse text processing tools for the tokenization and detokenization steps (Dchelotte et al., 2008) and our system is built in “true-case”. As German is morphologically more complex than English, the default policy which consists in treating each word form independently is plagued with data sparsity, which is detrimental both at training and decoding time. Thus, the German side was normalized using a specific pre-processing scheme (described in (Allauzen et al., 2010; Durgar ElKahlout and Yvon, 2010)), which notably aims at reducing the lexical redundancy by (i) normalizing the orthography, (ii) neutralizing most inflections and (iii) splitting complex compounds. 2.4 • Named entities are re"
W13-2223,2011.iwslt-papers.5,1,0.849659,"processed by splitting German compound words with the frequencybased method described in (Koehn and Knight, 2003). To further reduce translation complexity for the phrase-based approach, we performed the long-range part-of-speech based reordering rules proposed by (Popovi´c et al., 2006). 2.2.3 The in-house phrase-based decoder (Vogel, 2003) is used to perform decoding. Optimization with regard to the BLEU score is done using Minimum Error Rate Training (MERT) as described in Venugopal et al. (2005). 2.1.2 Translation Model We applied filtering and weighting for domainadaptation similarly to (Mansour et al., 2011) and (Mansour and Ney, 2012). For filtering the bilingual data, a combination of LM and IBM Model 1 scores was used. In addition, we performed weighted phrase extraction by using a combined LM and IBM Model 1 weight. 2.2.4 Reordering Model We applied part-of-speech (POS) based reordering using probabilistic continuous (Rottmann and Vogel, 2007) and discontinuous (Niehues and Kolss, 2009) rules. This was learned using POS tags generated by the TreeTagger (Schmid, 1994) for short and long range reorderings respectively. In addition to this POS-based reordering, we also used tree-based reordering"
W13-2223,J06-4004,0,0.0399278,"Missing"
W13-2223,D09-1022,1,0.905747,"Missing"
W13-2223,D08-1089,0,0.0206813,"Wuebker et al., 2012) which is part of RWTH’s open-source SMT toolkit Jane 2.1 1 . GIZA++ (Och and Ney, 2003) was employed to train a word alignment, language models have been created with the SRILM toolkit (Stolcke, 2002). After phrase pair extraction from the wordaligned parallel corpus, the translation probabilities are estimated by relative frequencies. The standard feature set also includes an n-gram language model, phrase-level IBM-1 and word-, phrase- and distortion-penalties, which are combined in log-linear fashion. Furthermore, we used an additional reordering model as described in (Galley and Manning, 2008). By this model six 1 http://www-i6.informatik.rwth-aachen. de/jane/ 185 Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 185–192, c Sofia, Bulgaria, August 8-9, 2013 2013 Association for Computational Linguistics additional feature are added to the log-linear combination. The model weights are optimized with standard Mert (Och, 2003a) on 200-best lists. The optimization criterion is B LEU. cleaner corpora, EPPS and NC. Assuming that this corpus is very noisy, we biased our classifier more towards precision than recall. This was realized by giving higher number of f"
W13-2223,2011.iwslt-evaluation.9,1,0.888245,"ing data was preprocessed prior to the training. Symbols such as quotes, dashes and apostrophes are normalized. Then the first words of each sentence are smart-cased. For the German part of the training corpus, the hunspell2 lexicon was used, in order to learn a mapping from old German spelling to new German writing rules. Compound-splitting was also performed as described in Koehn and Knight (2003). We also removed very long sentences, empty lines, and sentences which show big mismatch on the length. 2.2.2 Filtering The web-crawled corpus was filtered using an SVM classifier as described in (Mediani et al., 2011). The lexica used in this filtering task were obtained from Giza alignments trained on the 2.2.5 Translation Models The translation model uses the parallel data of EPPS, NC, and the filtered web-crawled data. As word alignment, we used the Discriminative Word Alignment (DWA) as shown in (Niehues and Vo2 http://hunspell.sourceforge.net/ 186 gel, 2008). The phrase pairs were extracted using different source word order suggested by the POSbased reordering models presented previously as described in (Niehues et al., 2009). In order to extend the context of source language words, we applied a bilin"
W13-2223,W09-0435,1,0.861514,"ith regard to the BLEU score is done using Minimum Error Rate Training (MERT) as described in Venugopal et al. (2005). 2.1.2 Translation Model We applied filtering and weighting for domainadaptation similarly to (Mansour et al., 2011) and (Mansour and Ney, 2012). For filtering the bilingual data, a combination of LM and IBM Model 1 scores was used. In addition, we performed weighted phrase extraction by using a combined LM and IBM Model 1 weight. 2.2.4 Reordering Model We applied part-of-speech (POS) based reordering using probabilistic continuous (Rottmann and Vogel, 2007) and discontinuous (Niehues and Kolss, 2009) rules. This was learned using POS tags generated by the TreeTagger (Schmid, 1994) for short and long range reorderings respectively. In addition to this POS-based reordering, we also used tree-based reordering rules. Syntactic parse trees of the whole training corpus and the word alignment between source and target language are used to learn rules on how to reorder the constituents in a German source sentence to make it match the English target sentence word order better (Herrmann et al., 2013). The training corpus was parsed by the Stanford parser (Rafferty and Manning, 2008). The reordering"
W13-2223,W08-0303,1,0.903038,"Missing"
W13-2223,N04-4026,0,0.016377,"y so that we only used the words that occur in the n-best list but not in the reference as negative example. a n-gram model of (source,target) pairs (Casacuberta and Vidal, 2004). Training this model requires to reorder source sentences so as to match the target word order. This is performed by a stochastic finite-state reordering model, which uses part-of-speech information4 to generalize reordering patterns beyond lexical regularities. In addition to the translation model, eleven feature functions are combined: a target-language model; four lexicon models; two lexicalized reordering models (Tillmann, 2004) aiming at predicting the orientation of the next translation unit; a ’weak’ distance-based distortion model; and finally a word-bonus model and a tuple-bonus model which compensate for the system preference for short translations. The four lexicon models are similar to the ones use in a standard phrase based system: two scores correspond to the relative frequencies of the tuples and two lexical weights estimated from the automatically generated word alignments. The weights associated to feature functions are optimally combined using a discriminative training framework (Och, 2003b). The overal"
W13-2223,W09-0413,1,0.842391,"The web-crawled corpus was filtered using an SVM classifier as described in (Mediani et al., 2011). The lexica used in this filtering task were obtained from Giza alignments trained on the 2.2.5 Translation Models The translation model uses the parallel data of EPPS, NC, and the filtered web-crawled data. As word alignment, we used the Discriminative Word Alignment (DWA) as shown in (Niehues and Vo2 http://hunspell.sourceforge.net/ 186 gel, 2008). The phrase pairs were extracted using different source word order suggested by the POSbased reordering models presented previously as described in (Niehues et al., 2009). In order to extend the context of source language words, we applied a bilingual language model (Niehues et al., 2011). A Discriminative Word Lexicon (DWL) introduced in (Mauser et al., 2009) was extended so that it could take the source context also into the account. For this, we used a bag-of-ngrams instead of representing the source sentence as a bag-of-words. Filtering based on counts was then applied to the features for higher order n-grams. In addition to this, the training examples were created differently so that we only used the words that occur in the n-best list but not in the refe"
W13-2223,W05-0836,1,0.864882,"filtering task). 2.1.1 Preprocessing In order to reduce the source vocabulary size translation, the German text was preprocessed by splitting German compound words with the frequencybased method described in (Koehn and Knight, 2003). To further reduce translation complexity for the phrase-based approach, we performed the long-range part-of-speech based reordering rules proposed by (Popovi´c et al., 2006). 2.2.3 The in-house phrase-based decoder (Vogel, 2003) is used to perform decoding. Optimization with regard to the BLEU score is done using Minimum Error Rate Training (MERT) as described in Venugopal et al. (2005). 2.1.2 Translation Model We applied filtering and weighting for domainadaptation similarly to (Mansour et al., 2011) and (Mansour and Ney, 2012). For filtering the bilingual data, a combination of LM and IBM Model 1 scores was used. In addition, we performed weighted phrase extraction by using a combined LM and IBM Model 1 weight. 2.2.4 Reordering Model We applied part-of-speech (POS) based reordering using probabilistic continuous (Rottmann and Vogel, 2007) and discontinuous (Niehues and Kolss, 2009) rules. This was learned using POS tags generated by the TreeTagger (Schmid, 1994) for short"
W13-2223,W11-2124,1,0.875547,"this filtering task were obtained from Giza alignments trained on the 2.2.5 Translation Models The translation model uses the parallel data of EPPS, NC, and the filtered web-crawled data. As word alignment, we used the Discriminative Word Alignment (DWA) as shown in (Niehues and Vo2 http://hunspell.sourceforge.net/ 186 gel, 2008). The phrase pairs were extracted using different source word order suggested by the POSbased reordering models presented previously as described in (Niehues et al., 2009). In order to extend the context of source language words, we applied a bilingual language model (Niehues et al., 2011). A Discriminative Word Lexicon (DWL) introduced in (Mauser et al., 2009) was extended so that it could take the source context also into the account. For this, we used a bag-of-ngrams instead of representing the source sentence as a bag-of-words. Filtering based on counts was then applied to the features for higher order n-grams. In addition to this, the training examples were created differently so that we only used the words that occur in the n-best list but not in the reference as negative example. a n-gram model of (source,target) pairs (Casacuberta and Vidal, 2004). Training this model r"
W13-2223,C12-3061,1,0.817205,"e of the four project partners. Each group develop and maintain their own different machine translation system. These single systems differ not only in their general approach, but also in the preprocessing of training and test data. To take advantage of these differences of each translation system, we combined all hypotheses of the different systems, using the RWTH system combination approach. This paper is structured as follows. First, the different engines of all four groups are introduced. RWTH Aachen Single System For the WMT 2013 evaluation, RWTH utilized a phrase-based decoder based on (Wuebker et al., 2012) which is part of RWTH’s open-source SMT toolkit Jane 2.1 1 . GIZA++ (Och and Ney, 2003) was employed to train a word alignment, language models have been created with the SRILM toolkit (Stolcke, 2002). After phrase pair extraction from the wordaligned parallel corpus, the translation probabilities are estimated by relative frequencies. The standard feature set also includes an n-gram language model, phrase-level IBM-1 and word-, phrase- and distortion-penalties, which are combined in log-linear fashion. Furthermore, we used an additional reordering model as described in (Galley and Manning, 2"
W13-2223,J03-1002,1,0.00903936,"translation system. These single systems differ not only in their general approach, but also in the preprocessing of training and test data. To take advantage of these differences of each translation system, we combined all hypotheses of the different systems, using the RWTH system combination approach. This paper is structured as follows. First, the different engines of all four groups are introduced. RWTH Aachen Single System For the WMT 2013 evaluation, RWTH utilized a phrase-based decoder based on (Wuebker et al., 2012) which is part of RWTH’s open-source SMT toolkit Jane 2.1 1 . GIZA++ (Och and Ney, 2003) was employed to train a word alignment, language models have been created with the SRILM toolkit (Stolcke, 2002). After phrase pair extraction from the wordaligned parallel corpus, the translation probabilities are estimated by relative frequencies. The standard feature set also includes an n-gram language model, phrase-level IBM-1 and word-, phrase- and distortion-penalties, which are combined in log-linear fashion. Furthermore, we used an additional reordering model as described in (Galley and Manning, 2008). By this model six 1 http://www-i6.informatik.rwth-aachen. de/jane/ 185 Proceedings"
W13-2223,P03-1021,0,0.694457,"models (Tillmann, 2004) aiming at predicting the orientation of the next translation unit; a ’weak’ distance-based distortion model; and finally a word-bonus model and a tuple-bonus model which compensate for the system preference for short translations. The four lexicon models are similar to the ones use in a standard phrase based system: two scores correspond to the relative frequencies of the tuples and two lexical weights estimated from the automatically generated word alignments. The weights associated to feature functions are optimally combined using a discriminative training framework (Och, 2003b). The overall search is based on a beam-search strategy on top of a dynamic programming algorithm. Reordering hypotheses are computed in a preprocessing step, making use of reordering rules built from the word reorderings introduced in the tuple extraction process. The resulting reordering hypotheses are passed to the decoder in the form of word lattices (Crego and Mario, 2006). 2.2.6 Language Models We build separate language models and combined them prior to decoding. As word-token based language models, one language model is built on EPPS, NC, and giga corpus, while another one is built u"
W13-2223,W08-1006,0,0.0614361,"and discontinuous (Niehues and Kolss, 2009) rules. This was learned using POS tags generated by the TreeTagger (Schmid, 1994) for short and long range reorderings respectively. In addition to this POS-based reordering, we also used tree-based reordering rules. Syntactic parse trees of the whole training corpus and the word alignment between source and target language are used to learn rules on how to reorder the constituents in a German source sentence to make it match the English target sentence word order better (Herrmann et al., 2013). The training corpus was parsed by the Stanford parser (Rafferty and Manning, 2008). The reordering rules are applied to the source sentences and the reordered sentence variants as well as the original sequence are encoded in a word lattice which is used as input to the decoder. Moreover, our reordering model was extended so that it could include the features of lexicalized reordering model. The reordering probabilities for each phrase pair are stored as well as the original position of each word in the lattice. During the decoding, the reordering origin of the words is checked along with its probability added as an additional score. 2.1.3 Language Model During decoding a 4-"
W13-2223,2007.tmi-papers.21,0,0.168794,") is used to perform decoding. Optimization with regard to the BLEU score is done using Minimum Error Rate Training (MERT) as described in Venugopal et al. (2005). 2.1.2 Translation Model We applied filtering and weighting for domainadaptation similarly to (Mansour et al., 2011) and (Mansour and Ney, 2012). For filtering the bilingual data, a combination of LM and IBM Model 1 scores was used. In addition, we performed weighted phrase extraction by using a combined LM and IBM Model 1 weight. 2.2.4 Reordering Model We applied part-of-speech (POS) based reordering using probabilistic continuous (Rottmann and Vogel, 2007) and discontinuous (Niehues and Kolss, 2009) rules. This was learned using POS tags generated by the TreeTagger (Schmid, 1994) for short and long range reorderings respectively. In addition to this POS-based reordering, we also used tree-based reordering rules. Syntactic parse trees of the whole training corpus and the word alignment between source and target language are used to learn rules on how to reorder the constituents in a German source sentence to make it match the English target sentence word order better (Herrmann et al., 2013). The training corpus was parsed by the Stanford parser"
W13-2223,W12-3140,1,\N,Missing
W13-2223,W11-2135,0,\N,Missing
W13-2223,W10-1704,0,\N,Missing
W13-2238,D11-1033,0,0.111872,"Missing"
W13-2238,W06-3123,0,0.0218206,"training procedure in Section 4. The complete algorithm is described in Section 5 and experiments are presented in Section 6. We conclude with Section 7. 2 Related Work Marcu and Wong (2002) present a joint probability model, which is trained with a hill-climbing technique based on break, merge, swap and move operations. Due to the computational complexity they are only able to consider phrases, which appear at least five times in the data. The model is shown to slightly underperform heuristic extraction in (Koehn et al., 2003). For higher efficiency, it is constrained by a word alignment in (Birch et al., 2006). DeNero et al. (2008) introduce a different training procedure for this model based on a Gibbs sampler. They make use of the word alignment for initialization. A generative phrase model trained with the Expectation-Maximization (EM) algorithm is shown in (DeNero et al., 2006). It also does not reach the same top performance as heuristic extraction. The authors identify the hidden segmentation variable, which results in over-fitting, as the main problem. 310 data set with minimum error rate training (MERT) (Och, 2003). As optimization criterion we use B LEU (Papineni et al., 2001). quence mode"
W13-2238,P09-1088,0,0.172033,"Missing"
W13-2238,2007.mtsummit-tutorials.1,0,0.0622985,"Missing"
W13-2238,J93-2003,0,0.03583,"Missing"
W13-2238,W06-3105,0,0.252908,"Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 309–319, c Sofia, Bulgaria, August 8-9, 2013 2013 Association for Computational Linguistics Liang et al. (2006) present a discriminative translation system. One of the proposed strategies for training, which the authors call bold updating, is similar to our training scheme. They use heuristically extracted phrase translation probabilities as blanket features in all setups. Another iteratively-trained phrase model is described by Moore and Quirk (2007). Their model is segmentation-free and, confirming the findings in (DeNero et al., 2006), can close the gap to phrase tables induced from surface heuristics. It relies on word alignment for phrase selection. Mylonakis and Sima’an (2008) present a phrase model, whose training procedure uses prior probabilities based on Inversion Transduction Grammar and smoothing as learning objective to prevent over-fitting. They also rely on the word alignment to select phrase pairs. Blunsom et al. (2009) perform inference over latent synchronous derivation trees under a nonparametric Bayesian model with a Gibbs sampler. Training is also initialized by extracting rules from a word alignment, but"
W13-2238,D08-1066,0,0.0379286,"Missing"
W13-2238,D08-1033,0,0.170076,"Missing"
W13-2238,P11-1064,0,0.117924,"Missing"
W13-2238,D12-1041,0,0.0399692,"Missing"
W13-2238,J03-1002,1,0.0188411,"Missing"
W13-2238,P12-1031,0,0.018182,"generative phrase model trained with the Expectation-Maximization (EM) algorithm is shown in (DeNero et al., 2006). It also does not reach the same top performance as heuristic extraction. The authors identify the hidden segmentation variable, which results in over-fitting, as the main problem. 310 data set with minimum error rate training (MERT) (Och, 2003). As optimization criterion we use B LEU (Papineni et al., 2001). quence model. For inference, they optimize their parameters towards alignment F-score. The forced derivations are initialized with the standard heuristic extraction scheme. He and Deng (2012) describe a discriminative phrase training procedure, where n-best translations are produced by the decoder on the whole training data. The heuristically extracted relative frequencies serve as a prior, and the probabilities are updated with a maximum B LEU criterion based on the n-best lists. 3 4 4.1 We use the standard phrase-based translation decoder from the open source toolkit Jane 2 (Wuebker et al., 2012a) for both the training procedure and the translation experiments. It makes use of the usual features: Translation channel models in both directions, lexical smoothing models in both dir"
W13-2238,J04-4002,1,0.524096,"obabilities are updated with a maximum B LEU criterion based on the n-best lists. 3 4 4.1 We use the standard phrase-based translation decoder from the open source toolkit Jane 2 (Wuebker et al., 2012a) for both the training procedure and the translation experiments. It makes use of the usual features: Translation channel models in both directions, lexical smoothing models in both directions, an n-gram language model (LM), phrase and word penalty and a jump-distancebased distortion model. Formally, the best transˆ J lation eˆI1 as defined by the models hm (eI1 , sK 1 , f1 ) can be written as (Och and Ney, 2004) ) ( M X I K J Iˆ λm hm (e1 , s1 , f1 ) , (1) eˆ1 = arg max ˆ sˆK 1 where f1J = f1 . . . fJ is the source sentence, = e1 . . . eI the target sentence and sK 1 = s1 . . . sK their phrase segmentation and alignment. We define sk := (ik , bk , jk ), where ik is the last position of kth target phrase, and (bk , jk ) are the start and end positions of the source phrase aligned to the kth target phrase. Different from many standard systems, the lexical smoothing scores are not estimated by extracting counts from a word alignment, but with IBM-1 model scores trained on the bilingual data with GIZA++."
W13-2238,P03-1021,0,0.109302,"). For higher efficiency, it is constrained by a word alignment in (Birch et al., 2006). DeNero et al. (2008) introduce a different training procedure for this model based on a Gibbs sampler. They make use of the word alignment for initialization. A generative phrase model trained with the Expectation-Maximization (EM) algorithm is shown in (DeNero et al., 2006). It also does not reach the same top performance as heuristic extraction. The authors identify the hidden segmentation variable, which results in over-fitting, as the main problem. 310 data set with minimum error rate training (MERT) (Och, 2003). As optimization criterion we use B LEU (Papineni et al., 2001). quence model. For inference, they optimize their parameters towards alignment F-score. The forced derivations are initialized with the standard heuristic extraction scheme. He and Deng (2012) describe a discriminative phrase training procedure, where n-best translations are produced by the decoder on the whole training data. The heuristically extracted relative frequencies serve as a prior, and the probabilities are updated with a maximum B LEU criterion based on the n-best lists. 3 4 4.1 We use the standard phrase-based transla"
W13-2238,N03-1017,0,0.0496928,"he decoder and its features are described in Section 3 and we give an overview of the training procedure in Section 4. The complete algorithm is described in Section 5 and experiments are presented in Section 6. We conclude with Section 7. 2 Related Work Marcu and Wong (2002) present a joint probability model, which is trained with a hill-climbing technique based on break, merge, swap and move operations. Due to the computational complexity they are only able to consider phrases, which appear at least five times in the data. The model is shown to slightly underperform heuristic extraction in (Koehn et al., 2003). For higher efficiency, it is constrained by a word alignment in (Birch et al., 2006). DeNero et al. (2008) introduce a different training procedure for this model based on a Gibbs sampler. They make use of the word alignment for initialization. A generative phrase model trained with the Expectation-Maximization (EM) algorithm is shown in (DeNero et al., 2006). It also does not reach the same top performance as heuristic extraction. The authors identify the hidden segmentation variable, which results in over-fitting, as the main problem. 310 data set with minimum error rate training (MERT) (O"
W13-2238,2001.mtsummit-papers.68,0,0.0296618,"d alignment in (Birch et al., 2006). DeNero et al. (2008) introduce a different training procedure for this model based on a Gibbs sampler. They make use of the word alignment for initialization. A generative phrase model trained with the Expectation-Maximization (EM) algorithm is shown in (DeNero et al., 2006). It also does not reach the same top performance as heuristic extraction. The authors identify the hidden segmentation variable, which results in over-fitting, as the main problem. 310 data set with minimum error rate training (MERT) (Och, 2003). As optimization criterion we use B LEU (Papineni et al., 2001). quence model. For inference, they optimize their parameters towards alignment F-score. The forced derivations are initialized with the standard heuristic extraction scheme. He and Deng (2012) describe a discriminative phrase training procedure, where n-best translations are produced by the decoder on the whole training data. The heuristically extracted relative frequencies serve as a prior, and the probabilities are updated with a maximum B LEU criterion based on the n-best lists. 3 4 4.1 We use the standard phrase-based translation decoder from the open source toolkit Jane 2 (Wuebker et al."
W13-2238,W04-3250,0,0.341203,"Missing"
W13-2238,P06-1096,0,0.136883,"Missing"
W13-2238,2011.eamt-1.42,0,0.0452054,"Missing"
W13-2238,2006.amta-papers.25,0,0.141837,"Missing"
W13-2238,W02-1018,0,0.0938968,"a disadvantage for translation quality. Although we use a phrase-based decoder here, the principles of our work can be applied to any statistical machine translation paradigm. The software used for our experiments is available under a non-commercial open source licence. The paper is organized as follows. We review related work in Section 2. The decoder and its features are described in Section 3 and we give an overview of the training procedure in Section 4. The complete algorithm is described in Section 5 and experiments are presented in Section 6. We conclude with Section 7. 2 Related Work Marcu and Wong (2002) present a joint probability model, which is trained with a hill-climbing technique based on break, merge, swap and move operations. Due to the computational complexity they are only able to consider phrases, which appear at least five times in the data. The model is shown to slightly underperform heuristic extraction in (Koehn et al., 2003). For higher efficiency, it is constrained by a word alignment in (Birch et al., 2006). DeNero et al. (2008) introduce a different training procedure for this model based on a Gibbs sampler. They make use of the word alignment for initialization. A generati"
W13-2238,P10-1049,1,0.941268,"unified framework induces the phrases based on the same models as in decoding. We train the phrase table without using a word alignment or the extraction heuristics. Different from previous work, we are able to generate all possible phrase pairs on-the-fly during the training procedure. A further advantage of our proposed algorithm is that we use basically the same beam search as in translation. This makes it easy to re-implement by modifying any translation decoder, and makes sure that training and translation are consistent. In principle, we apply the forced decoding approach described in (Wuebker et al., 2010) with cross-validation to prevent over-fitting, but we initialize the phrase table with IBM-1 lexical probabilities (Brown et al., 1993) instead of heuristically extracted relative frequencies. The algorithm is extended with the concept of backoff phrases, so that new phrase pairs can be generated at training time. The size of the newly generated phrases is incremented over the training iterations. By introducing fallback decoding runs, we are able to successfully align the complete training data. Local language models are used for better phrase pair pre-selection. We present an iterative tech"
W13-2238,C12-3061,1,0.931403,"et al., 2001). quence model. For inference, they optimize their parameters towards alignment F-score. The forced derivations are initialized with the standard heuristic extraction scheme. He and Deng (2012) describe a discriminative phrase training procedure, where n-best translations are produced by the decoder on the whole training data. The heuristically extracted relative frequencies serve as a prior, and the probabilities are updated with a maximum B LEU criterion based on the n-best lists. 3 4 4.1 We use the standard phrase-based translation decoder from the open source toolkit Jane 2 (Wuebker et al., 2012a) for both the training procedure and the translation experiments. It makes use of the usual features: Translation channel models in both directions, lexical smoothing models in both directions, an n-gram language model (LM), phrase and word penalty and a jump-distancebased distortion model. Formally, the best transˆ J lation eˆI1 as defined by the models hm (eI1 , sK 1 , f1 ) can be written as (Och and Ney, 2004) ) ( M X I K J Iˆ λm hm (e1 , s1 , f1 ) , (1) eˆ1 = arg max ˆ sˆK 1 where f1J = f1 . . . fJ is the source sentence, = e1 . . . eI the target sentence and sK 1 = s1 . . . sK their phr"
W13-2238,W12-3158,1,0.874049,"et al., 2001). quence model. For inference, they optimize their parameters towards alignment F-score. The forced derivations are initialized with the standard heuristic extraction scheme. He and Deng (2012) describe a discriminative phrase training procedure, where n-best translations are produced by the decoder on the whole training data. The heuristically extracted relative frequencies serve as a prior, and the probabilities are updated with a maximum B LEU criterion based on the n-best lists. 3 4 4.1 We use the standard phrase-based translation decoder from the open source toolkit Jane 2 (Wuebker et al., 2012a) for both the training procedure and the translation experiments. It makes use of the usual features: Translation channel models in both directions, lexical smoothing models in both directions, an n-gram language model (LM), phrase and word penalty and a jump-distancebased distortion model. Formally, the best transˆ J lation eˆI1 as defined by the models hm (eI1 , sK 1 , f1 ) can be written as (Och and Ney, 2004) ) ( M X I K J Iˆ λm hm (e1 , s1 , f1 ) , (1) eˆ1 = arg max ˆ sˆK 1 where f1J = f1 . . . fJ is the source sentence, = e1 . . . eI the target sentence and sK 1 = s1 . . . sK their phr"
W13-2238,I08-1068,0,0.02792,"(e1 , s1 , f1 ) , (1) eˆ1 = arg max ˆ sˆK 1 where f1J = f1 . . . fJ is the source sentence, = e1 . . . eI the target sentence and sK 1 = s1 . . . sK their phrase segmentation and alignment. We define sk := (ik , bk , jk ), where ik is the last position of kth target phrase, and (bk , jk ) are the start and end positions of the source phrase aligned to the kth target phrase. Different from many standard systems, the lexical smoothing scores are not estimated by extracting counts from a word alignment, but with IBM-1 model scores trained on the bilingual data with GIZA++. They are computed as (Zens, 2008) eI1 k=1 j=bk ik X i=ik−1 +1 = arg max K,sK 1 ( M X ) J λm hm (eI1 , sK 1 , f1 ) m=1 (3) To force-align the training data, the translation decoder is constrained to the given target sentence. The translation candidates applicable for each sentence pair are selected through a bilingual phrase matching before the actual search. In the M-step, we re-estimate the phrase table from the phrase alignments. The translation probability of a phrase pair (f˜, e˜) is estimated as m=1 J hlex (eI1 , sK 1 , f1 ) =  jk K X X log p(fj |e0 ) + Overview In this work we employ a training procedure inspired by t"
W13-2238,P02-1040,0,\N,Missing
W13-2238,P10-2041,0,\N,Missing
W13-2238,2006.amta-papers.2,0,\N,Missing
W13-2238,W07-0715,0,\N,Missing
W13-2238,D08-1076,0,\N,Missing
W13-2258,W12-3125,0,0.0598878,"ases. The only difference is that length constraints are applied to phrases, but not to blocks. Figure 1 illustrates the extraction of monotone, swap, and discontinuous orientation classes in left-to-right direction from word-aligned bilingual training samples. The right-to-left direction works analogously. p(O) = P N (O) O0 ∈{M,S,D} N (O We found that this concept can be neatly plugged into the hierarchical phrase-based translation paradigm, without having to resort to approximations in decoding, which is necessary to determine the right-to-left orientation in a standard phrase-based system (Cherry et al., 2012). To train the orientations, the extraction procedure from the standard phrase-based version of the reordering model can be used with a minor extension. The model is trained on the same word-aligned data from which the translation rules are extracted. For each training sentence, we extract all phrases of unlimited length that are consistent with the word alignment, and store their corners in a matrix. The corners are distinguished by their location: topleft, top-right, bottom-left, and bottom-right. For each bilingual phrase, we determine its left-toright and right-to-left orientation by check"
W13-2258,P05-1033,0,0.878427,"sequence and a distortion cost that is computed from the sourceside jump distances. Though the space of admissible reorderings is in most cases contrained by a maximum jump width or coverage-based restrictions (Zens et al., 2004) for efficiency reasons, the basic approach of arbitrarily jumping to uncovered positions on source side is still very permissive. Lexicalized reordering models assist the decoder in taking a good decision. Phrase-based decoding allows for a straightforward integration of lexicalized reordering models which assign Introduction In hierarchical phrase-based translation (Chiang, 2005), a probabilistic synchronous context-free grammar (SCFG) is induced from bilingual training corpora. In addition to continuous lexical phrases as in standard phrase-based translation, hierarchical phrases with usually up to two nonterminals are extracted from the word-aligned parallel training data. Hierarchical decoding is typically carried out with a parsing-based procedure. The parsing algorithm is extended to handle translation candi452 Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 452–463, c Sofia, Bulgaria, August 8-9, 2013 2013 Association for Computation"
W13-2258,J07-2003,0,0.404938,"(with 1 ≤ j1 ≤ j2 ≤ J and 1 ≤ i1 ≤ i2 ≤ I) is consistent with respect to the word alignment A ⊆ {1, ..., I} × {1, ..., J} iff (1) is engrafted into the hierarchical grammar, as well as a special glue rule S → hS ∼0 X ∼1 , S ∼0 X ∼1 i Modeling Phrase Orientation for Hierarchical Machine Translation (2) that the system can use for serial concatenation of phrases as in monotonic phrase-based translation. The initial symbol S is the start symbol of the grammar. Hierarchical search is conducted with a customized version of the CYK+ parsing algorithm (Chappelier and Rajman, 1998) and cube pruning (Chiang, 2007). A hypergraph which represents the whole parsing space is built employing CYK+. Cube pruning operates in bottom-up topological order on this hypergraph and expands at most k derivations at each hypernode. ∃(i, j) ∈ A : i1 ≤ i ≤ i2 ∧ j1 ≤ j ≤ j2 ∧ ∀(i, j) ∈ A : i1 ≤ i ≤ i2 ↔ j1 ≤ j ≤ j2 . (3) Consistency is based upon two conditions in this definition: (1.) At least one source and target position within the block must be aligned, and (2.) words from inside the source interval may only be aligned to words from inside the target interval and vice versa. These are the same conditions as those tha"
W13-2258,D08-1089,0,0.729017,"archical decoding is typically carried out with a parsing-based procedure. The parsing algorithm is extended to handle translation candi452 Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 452–463, c Sofia, Bulgaria, August 8-9, 2013 2013 Association for Computational Linguistics 2 different scores depending on how a currently translated phrase has been reordered with respect to its context. Popular lexicalized reordering models for phrase-based translation distinguish three orientation classes: monotone, swap, and discontinuous (Tillmann, 2004; Koehn et al., 2007; Galley and Manning, 2008). To obtain such a model, scores for the three classes are calculated from the counts of the respective orientation occurrences in the word-aligned training data for each extracted phrase. The left-to-right orientation of phrases during phrase-based search can be easily determined from the start and end positions of continuous phrases. Approximations may need to be adopted for the right-to-left scoring direction. The utility of phrase orientation models in standard phrase-based translation is plausible and has been empirically established in practice. In hierarchical phrase-based translation,"
W13-2258,D08-1039,1,0.911341,"Missing"
W13-2258,C10-1050,0,0.464037,"urrences in the word-aligned training data for each extracted phrase. The left-to-right orientation of phrases during phrase-based search can be easily determined from the start and end positions of continuous phrases. Approximations may need to be adopted for the right-to-left scoring direction. The utility of phrase orientation models in standard phrase-based translation is plausible and has been empirically established in practice. In hierarchical phrase-based translation, some other types of lexicalized reordering models have been investigated recently (He et al., 2010a; He et al., 2010b; Hayashi et al., 2010; Huck et al., 2012a), but in none of them are the orientation scores conditioned on the lexical identity of each phrase individually. These models are rather word-based and applied on block boundaries. Experimental results obtained with these other types of lexicalized reordering models have been very encouraging, though. There are certain reasons why assessing the adequacy of phrase reordering should be useful in hierarchical search: Outline The remainder of the paper is structured as follows: We briefly outline important related publications in the following section. We subsequently give a"
W13-2258,2007.mtsummit-tutorials.1,0,0.054362,"Missing"
W13-2258,2010.amta-papers.25,0,0.16219,"ts of the respective orientation occurrences in the word-aligned training data for each extracted phrase. The left-to-right orientation of phrases during phrase-based search can be easily determined from the start and end positions of continuous phrases. Approximations may need to be adopted for the right-to-left scoring direction. The utility of phrase orientation models in standard phrase-based translation is plausible and has been empirically established in practice. In hierarchical phrase-based translation, some other types of lexicalized reordering models have been investigated recently (He et al., 2010a; He et al., 2010b; Hayashi et al., 2010; Huck et al., 2012a), but in none of them are the orientation scores conditioned on the lexical identity of each phrase individually. These models are rather word-based and applied on block boundaries. Experimental results obtained with these other types of lexicalized reordering models have been very encouraging, though. There are certain reasons why assessing the adequacy of phrase reordering should be useful in hierarchical search: Outline The remainder of the paper is structured as follows: We briefly outline important related publications in the f"
W13-2258,D10-1054,0,0.0770109,"ts of the respective orientation occurrences in the word-aligned training data for each extracted phrase. The left-to-right orientation of phrases during phrase-based search can be easily determined from the start and end positions of continuous phrases. Approximations may need to be adopted for the right-to-left scoring direction. The utility of phrase orientation models in standard phrase-based translation is plausible and has been empirically established in practice. In hierarchical phrase-based translation, some other types of lexicalized reordering models have been investigated recently (He et al., 2010a; He et al., 2010b; Hayashi et al., 2010; Huck et al., 2012a), but in none of them are the orientation scores conditioned on the lexical identity of each phrase individually. These models are rather word-based and applied on block boundaries. Experimental results obtained with these other types of lexicalized reordering models have been very encouraging, though. There are certain reasons why assessing the adequacy of phrase reordering should be useful in hierarchical search: Outline The remainder of the paper is structured as follows: We briefly outline important related publications in the f"
W13-2258,P02-1038,1,0.659361,"checking for adjacent corners. 0) (4) σ · p(O) + N (O|α, β) . P σ + O0 ∈{M,S,D} N (O0 |f˜, e˜) (5) Here, N (O) denotes the global count and N (O|α, β) the lexicalized count for the orientation O. σ is a smoothing constant. To determine the orientation frequency for a hierarchical phrase with non-terminal symbols, the orientation counts of all those phrases are accumulated from which a sub-phrase is cut out and replaced by a non-terminal symbol to obtain this hierarchical phrase. Figure 2 gives an example. Negative logarithms of the values are used as costs in the log-linear model combination (Och and Ney, 2002). Cost 0 for all orientations is assigned to the special rules which are not extracted from the training data (initial and glue rule). p(O|α, β) = 455 source source source f4 X~0 f3 f2 f1 f4 f3 f2 X~0 f1 f4 f3 X~0 f2 f1 e1 e2 e3 X~0 e4 e1 e2 e3 X~0 e4 e1 e2 X~0 e3 e4 target target target (a) Monotone non-terminal orientation. (b) Swap non-terminal orientation. (c) Discontinuous non-terminal orientation. Figure 3: Scoring with the orientation classes monotone, swap, and discontinuous. Each picture shows exactly one hierarchical phrase. The block which replaces the non-terminal X during decoding"
W13-2258,2011.iwslt-papers.1,1,0.881651,"Missing"
W13-2258,J03-1002,1,0.0154534,"an language pair using the standard WMT3 newstest sets for development and testing. 7.1 Experimental Setup We work with a Chinese–English parallel training corpus of 3.0 M sentence pairs (77.5 M Chinese / 81.0 M English running words). To train the German→French baseline system, we use 2.0 M sentence pairs (53.1 M French / 45.8 M German running words) that are partly taken from the Europarl corpus (Koehn, 2005) and have partly been collected within the Quaero project.4 Word alignments are created by aligning the data in both directions with GIZA++5 and symmetrizing the two trained alignments (Och and Ney, 2003). When extracting phrases, we apply several restrictions, in particular a maximum length of ten on source and target side for lexical phrases, a length limit of five on source and ten on target side for hierarchical phrases (including non-terminal symbols), and no more than two non-terminals per phrase. A standard set of models is used in the baselines, comprising phrase translation probabilities and lexical translation probabilities in both directions, word and phrase penalty, binary features marking hierarchical rules, glue rule, and rules 7.2 Chinese→English Experimental Results Table 1 com"
W13-2258,P03-1021,0,0.319883,"Delayed scoring can lead to search errors; in order to keep them confined, the delayed scoring needs to be done separately for all derivations, not just for the first-best subderivations along the incoming hyperedges. 7 with non-terminals at the boundaries, three simple count-based binary features, phrase length ratios, and a language model. The language models are 4-grams with modified Kneser-Ney smoothing (Kneser and Ney, 1995; Chen and Goodman, 1998) which have been trained with the SRILM toolkit (Stolcke, 2002). Model weights are optimized against B LEU (Papineni et al., 2002) with MERT (Och, 2003) on 100-best lists. For Chinese→English we employ MT06 as development set, MT08 is used as unseen test set. For German→French we employ newstest2009 as development set, newstest2008, newstest2010, and newstest2011 are used as unseen test sets. During decoding, a maximum length constraint of ten is applied to all non-terminals except the initial symbol S . Translation quality is measured in truecase with B LEU and T ER (Snover et al., 2006). The results on MT08 are checked for statistical significance over the baseline. Confidence intervals have been computed using bootstrapping for B LEU and C"
W13-2258,2012.eamt-1.66,1,0.901944,"ligned training data for each extracted phrase. The left-to-right orientation of phrases during phrase-based search can be easily determined from the start and end positions of continuous phrases. Approximations may need to be adopted for the right-to-left scoring direction. The utility of phrase orientation models in standard phrase-based translation is plausible and has been empirically established in practice. In hierarchical phrase-based translation, some other types of lexicalized reordering models have been investigated recently (He et al., 2010a; He et al., 2010b; Hayashi et al., 2010; Huck et al., 2012a), but in none of them are the orientation scores conditioned on the lexical identity of each phrase individually. These models are rather word-based and applied on block boundaries. Experimental results obtained with these other types of lexicalized reordering models have been very encouraging, though. There are certain reasons why assessing the adequacy of phrase reordering should be useful in hierarchical search: Outline The remainder of the paper is structured as follows: We briefly outline important related publications in the following section. We subsequently give a summary of some ess"
W13-2258,P02-1040,0,0.0871338,"nd the correct actual costs added. Delayed scoring can lead to search errors; in order to keep them confined, the delayed scoring needs to be done separately for all derivations, not just for the first-best subderivations along the incoming hyperedges. 7 with non-terminals at the boundaries, three simple count-based binary features, phrase length ratios, and a language model. The language models are 4-grams with modified Kneser-Ney smoothing (Kneser and Ney, 1995; Chen and Goodman, 1998) which have been trained with the SRILM toolkit (Stolcke, 2002). Model weights are optimized against B LEU (Papineni et al., 2002) with MERT (Och, 2003) on 100-best lists. For Chinese→English we employ MT06 as development set, MT08 is used as unseen test set. For German→French we employ newstest2009 as development set, newstest2008, newstest2010, and newstest2011 are used as unseen test sets. During decoding, a maximum length constraint of ten is applied to all non-terminals except the initial symbol S . Translation quality is measured in truecase with B LEU and T ER (Snover et al., 2006). The results on MT08 are checked for statistical significance over the baseline. Confidence intervals have been computed using bootstr"
W13-2258,2006.amta-papers.25,0,0.0243919,"; Chen and Goodman, 1998) which have been trained with the SRILM toolkit (Stolcke, 2002). Model weights are optimized against B LEU (Papineni et al., 2002) with MERT (Och, 2003) on 100-best lists. For Chinese→English we employ MT06 as development set, MT08 is used as unseen test set. For German→French we employ newstest2009 as development set, newstest2008, newstest2010, and newstest2011 are used as unseen test sets. During decoding, a maximum length constraint of ten is applied to all non-terminals except the initial symbol S . Translation quality is measured in truecase with B LEU and T ER (Snover et al., 2006). The results on MT08 are checked for statistical significance over the baseline. Confidence intervals have been computed using bootstrapping for B LEU and Cochran’s approximate ratio variance for T ER (Leusch and Ney, 2009). Experiments We evaluate the effect of phrase orientation scoring in hierarchical translation on the Chinese→English 2008 NIST task2 and on the French→German language pair using the standard WMT3 newstest sets for development and testing. 7.1 Experimental Setup We work with a Chinese–English parallel training corpus of 3.0 M sentence pairs (77.5 M Chinese / 81.0 M English"
W13-2258,2010.amta-papers.8,1,0.873547,"Missing"
W13-2258,N03-1017,0,0.0994991,"Missing"
W13-2258,P07-2045,0,0.0460072,"training data. Hierarchical decoding is typically carried out with a parsing-based procedure. The parsing algorithm is extended to handle translation candi452 Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 452–463, c Sofia, Bulgaria, August 8-9, 2013 2013 Association for Computational Linguistics 2 different scores depending on how a currently translated phrase has been reordered with respect to its context. Popular lexicalized reordering models for phrase-based translation distinguish three orientation classes: monotone, swap, and discontinuous (Tillmann, 2004; Koehn et al., 2007; Galley and Manning, 2008). To obtain such a model, scores for the three classes are calculated from the counts of the respective orientation occurrences in the word-aligned training data for each extracted phrase. The left-to-right orientation of phrases during phrase-based search can be easily determined from the start and end positions of continuous phrases. Approximations may need to be adopted for the right-to-left scoring direction. The utility of phrase orientation models in standard phrase-based translation is plausible and has been empirically established in practice. In hierarchical"
W13-2258,N04-4026,0,0.178256,"aligned parallel training data. Hierarchical decoding is typically carried out with a parsing-based procedure. The parsing algorithm is extended to handle translation candi452 Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 452–463, c Sofia, Bulgaria, August 8-9, 2013 2013 Association for Computational Linguistics 2 different scores depending on how a currently translated phrase has been reordered with respect to its context. Popular lexicalized reordering models for phrase-based translation distinguish three orientation classes: monotone, swap, and discontinuous (Tillmann, 2004; Koehn et al., 2007; Galley and Manning, 2008). To obtain such a model, scores for the three classes are calculated from the counts of the respective orientation occurrences in the word-aligned training data for each extracted phrase. The left-to-right orientation of phrases during phrase-based search can be easily determined from the start and end positions of continuous phrases. Approximations may need to be adopted for the right-to-left scoring direction. The utility of phrase orientation models in standard phrase-based translation is plausible and has been empirically established in pract"
W13-2258,D09-1105,0,0.121503,"ientations. Empirical results are presented in Section 7. We conclude the paper in Section 8. 3 Related Work Hierarchical phrase-based translation was proposed by Chiang (2005). He et al. (2010a) integrated a maximum entropy based lexicalized reordering model with word- and class-based features. Different classifiers for different rule patterns are trained for their model (He et al., 2010b). A comparable discriminatively trained model which applies a single classifier for all types of rules was developed by Huck et al. (2012a). Hayashi et al. (2010) explored the word-based reordering model by Tromble and Eisner (2009) in hierarchical translation. For standard phrase-based translation, Galley and Manning (2008) introduced a hierarchical phrase orientation model. Similar to previous approaches (Tillmann, 2004; Koehn et al., 2007), it distinguishes the three orientation classes monotone, swap, and discontinuous. However, it differs in that it is not limited to model local reordering phenomena, but allows for phrases to be hierarchically combined into blocks in order to determine the orientation class. This has the advantage that probability mass is shifted from the rather uninformative default category discon"
W13-2258,2005.mtsummit-papers.11,0,0.023636,"o variance for T ER (Leusch and Ney, 2009). Experiments We evaluate the effect of phrase orientation scoring in hierarchical translation on the Chinese→English 2008 NIST task2 and on the French→German language pair using the standard WMT3 newstest sets for development and testing. 7.1 Experimental Setup We work with a Chinese–English parallel training corpus of 3.0 M sentence pairs (77.5 M Chinese / 81.0 M English running words). To train the German→French baseline system, we use 2.0 M sentence pairs (53.1 M French / 45.8 M German running words) that are partly taken from the Europarl corpus (Koehn, 2005) and have partly been collected within the Quaero project.4 Word alignments are created by aligning the data in both directions with GIZA++5 and symmetrizing the two trained alignments (Och and Ney, 2003). When extracting phrases, we apply several restrictions, in particular a maximum length of ten on source and target side for lexical phrases, a length limit of five on source and ten on target side for hierarchical phrases (including non-terminal symbols), and no more than two non-terminals per phrase. A standard set of models is used in the baselines, comprising phrase translation probabilit"
W13-2258,N09-1027,0,0.0732795,"Missing"
W13-2258,W10-1738,1,0.928383,"Missing"
W13-2258,2008.iwslt-papers.8,1,0.880264,"Missing"
W13-2258,C04-1030,1,0.828,"model is to assess the adequacy of phrase reordering during search. In standard phrase-based translation with continuous phrases only and left-to-right hypothesis generation (Koehn et al., 2003; Zens and Ney, 2008), phrase reordering is implemented by jumps within the input sentence. The choice of the best order for the target sequence is made based on the language model score of this sequence and a distortion cost that is computed from the sourceside jump distances. Though the space of admissible reorderings is in most cases contrained by a maximum jump width or coverage-based restrictions (Zens et al., 2004) for efficiency reasons, the basic approach of arbitrarily jumping to uncovered positions on source side is still very permissive. Lexicalized reordering models assist the decoder in taking a good decision. Phrase-based decoding allows for a straightforward integration of lexicalized reordering models which assign Introduction In hierarchical phrase-based translation (Chiang, 2005), a probabilistic synchronous context-free grammar (SCFG) is induced from bilingual training corpora. In addition to continuous lexical phrases as in standard phrase-based translation, hierarchical phrases with usual"
W13-2258,D09-1022,1,\N,Missing
W13-2258,D08-1076,0,\N,Missing
W13-3908,forster-etal-2012-rwth,1,0.417063,"s such as HamNoSys[6] or SignWriting [8] cover information about different modalities used within sign languages, they are still a weak labeling scheme for signs because they do not give an annotation of the movement, facial expression, etc. per time frame. Furthermore, using glosses as target classes and annotation scheme allows for faster annotation of large amounts sign language data which is needed for a automatic statistical recognition approach. Finally, the proposed recognition system has been tested on the two publicly available databases SIGNUM [19] and RWTH-PHOENIX-Weather (PHOENIX) [20] for GSL which are among the biggest datasets available for continuous ASLR. 2.3. Manual and non-manual features GSL conveys information through manual and non-manual parameters. Manual parameters comprise both hands’ shape, their orientation and position. There are two-handed, as well as single-handed signs. Single-handed signs are usually signed using the dominant hand which in the databases used in this work corresponds to the right hand for all subjects in PHOENIX and all but two in the SIGNUM database. Manual features: For full coverage of a sign, manual features of both hands are used as"
W14-0808,C02-1096,0,0.0982722,"Missing"
W14-0808,P11-2031,0,0.0667223,"Missing"
W14-0808,N13-1073,0,0.0307287,"Missing"
W14-0808,W10-1734,0,0.0398686,"Missing"
W14-0808,E03-1076,0,0.0530794,"raining environments Taking the normalised version of our corpus as a baseline, different training environments have been tested. We designed ﬁve possible training environments in which German compounds were preprocessed. In our ﬁrst experiment (hereinafter “compList”), the list of manually extracted compounds was appended to the end of the training set and no further preprocessing was carried out. In our second experiment (hereinafter “RWTH”), the state-of-the-art compound splitting approach implemented by Popović et al. (2006) was used to split all possible compounds. As also implemented by Koehn and Knight (2003), this approach uses the corpus itself to create a vocabulary that is then subsequently used to calculate the possible splittings in the corpus. It has the advantage of being a stand-alone approach which does not depend on any external resources. A possible drawback of this approach would be that it relies on a large corpus to be able to compute the splittings. Thus, it may not be as efﬁcient with smaller corpora (i.e. if we were to use only the TRIS corpus, for instance). The third experiment (hereinafter “RWTH+compList”) used the split corpus prepared in our second experiment (“RWTH”) but me"
W14-0808,2005.mtsummit-papers.11,0,0.0333363,"Missing"
W14-0808,P03-1021,0,0.14746,"Missing"
W14-0808,2006.amta-papers.25,0,0.0842276,"Missing"
W14-0808,2001.mtsummit-papers.68,0,0.128211,"Missing"
W14-0808,W10-1738,1,0.847398,"le is rather oral and less technical. As compounds tend to be more frequent in domain speciﬁc texts, the TRIS corpus has been used for testing, while the Europarl Corpus has been used in the training set to avoid data scarcity problems and increase the vocabulary coverage of the SMT system. In the case of Machine Translation (MT), both rule-based MT systems (RBMT systems) and Statistical MT systems (SMT systems) encounter problems when dealing with compounds. For the purposes of this paper, the treatment of compounds in German has been tested within the SMT toolkit Jane (Wuebker et al., 2012; Vilar et al., 2010). We have carried out several experiments translating German specialized texts into Spanish to test to which extent incorporating a linguistic analysis of the corpora and compiling compound lists improves the overall SMT results. At this stage, including further linguistic information such as Partof-Speech tagging (POS tagging) or phrase chunking has been disregarded. Forcing the translation of compounds in the phrase tables produced by Jane has also been disregarded. The overall aim was to test how the SMT system performs using different pre-processing strategies of the training data but with"
W14-0808,escartin-2012-design,1,0.268806,"Missing"
W14-0808,weller-heid-2012-analyzing,0,0.0160098,"tenation of the complete Europarl Corpus German→Spanish and a greater part of the TRIS corpus, while in dev and test only texts from the TRIS corpus were used. the list of splittings to be carried out in the corpus. Thus, after all possible splittings were calculated, those splittings that were present in the manually compiled compound list were deleted to ensure that they were not split in the corpus and remained the same. In the fourth experiment (hereinafter “IMS”) we used another compound splitter developed at the Institut für Maschinelle Sprachverarbeitung of the University of Stuttgart (Weller and Heid, 2012). This splitter was also developed using a frequencybased approach. However, in this case the training data consists of a list of lemmatized wordforms together with their POS tags. A set of rules to model transitional elements is also used. While this splitter might be used by processing our corpus with available tools such as TreeTagger (Schmid, 1994)6 and then computing frequencies, in our experiments we used the CELEX7 database for German (Baayen et al., 1993). This was done so because CELEX is an extensive high quality lexical database which already included all the information we needed t"
W14-0808,2008.iwslt-papers.8,1,0.886999,"Missing"
W14-0808,J09-2003,0,\N,Missing
W14-0808,J13-4009,0,\N,Missing
W14-0808,P02-1040,0,\N,Missing
W14-0808,C12-3061,1,\N,Missing
W14-3310,E14-2008,1,0.50059,"nburgh, Scotland † Karlsruhe Institute of Technology, Karlsruhe, Germany ∗ {freitag,peitz,wuebker,ney}@cs.rwth-aachen.de ‡ {mhuck,ndurrani,pkoehn}@inf.ed.ac.uk ‡ v1rsennr@staffmail.ed.ac.uk ‡ maria.nadejde@gmail.com,p.j.williams-2@sms.ed.ac.uk † {teresa.herrmann,eunah.cho,alex.waibel}@kit.edu ‡ Matthias Abstract joint WMT submission of three EU-BRIDGE project partners. RWTH Aachen University (RWTH), the University of Edinburgh (UEDIN) and Karlsruhe Institute of Technology (KIT) all provided several individual systems which were combined by means of the RWTH Aachen system combination approach (Freitag et al., 2014). As distinguished from our EU-BRIDGE joint submission to the IWSLT 2013 evaluation campaign (Freitag et al., 2013), we particularly focused on translation of news text (instead of talks) for WMT. Besides, we put an emphasis on engineering syntaxbased systems in order to combine them with our more established phrase-based engines. We built combined system setups for translation from German to English as well as from English to German. This paper gives some insight into the technology behind the system combination framework and the combined engines which have been used to produce the joint EU-B"
W14-3310,D08-1089,0,0.0336771,"sequence model over cluster IDs. Furthermore, it learns OSM models over POS, morph and word classes. et al., 2010; Wuebker et al., 2012). The model weights of all systems have been tuned with standard Minimum Error Rate Training (Och, 2003) on a concatenation of the newstest2011 and newstest2012 sets. RWTH used B LEU as optimization objective. Both for language model estimation and querying at decoding, the KenLM toolkit (Heafield et al., 2013) is used. All RWTH systems include the standard set of models provided by Jane. Both systems have been augmented with a hierarchical orientation model (Galley and Manning, 2008; Huck et al., 2013) and a cluster language model (Wuebker et al., 2013). The phrasebased system (RWTH scss) has been further improved by maximum expected B LEU training similar to (He and Deng, 2012). The latter has been performed on a selection from the News Commentary, Europarl and Common Crawl corpora based on language and translation model cross-entropies (Mansour et al., 2011). 3 3.2 UEDIN’s syntax-based systems (Williams et al., 2014) follow the GHKM syntax approach as proposed by Galley, Hopkins, Knight, and Marcu (Galley et al., 2004). The open source Moses implementation has been emp"
W14-3310,N04-1035,0,0.0285873,"gmented with a hierarchical orientation model (Galley and Manning, 2008; Huck et al., 2013) and a cluster language model (Wuebker et al., 2013). The phrasebased system (RWTH scss) has been further improved by maximum expected B LEU training similar to (He and Deng, 2012). The latter has been performed on a selection from the News Commentary, Europarl and Common Crawl corpora based on language and translation model cross-entropies (Mansour et al., 2011). 3 3.2 UEDIN’s syntax-based systems (Williams et al., 2014) follow the GHKM syntax approach as proposed by Galley, Hopkins, Knight, and Marcu (Galley et al., 2004). The open source Moses implementation has been employed to extract GHKM rules (Williams and Koehn, 2012). Composed rules (Galley et al., 2006) are extracted in addition to minimal rules, but only up to the following limits: at most twenty tree nodes per rule, a maximum depth of five, and a maximum size of five. Singleton hierarchical rules are dropped. The features for the syntax-based systems comprise Good-Turing-smoothed phrase translation probabilities, lexical translation probabilities in both directions, word and phrase penalty, a rule rareness penalty, a monolingual PCFG probability, an"
W14-3310,P05-1066,1,0.0515024,"employs both the phrase-based (RWTH scss) and the hierarchical (RWTH hiero) decoder implemented in RWTH’s publicly available translation toolkit Jane (Vilar 1 http://www.eu-bridge.eu 105 Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 105–113, c Baltimore, Maryland USA, June 26–27, 2014. 2014 Association for Computational Linguistics els over POS and morph sequences following Durrani et al. (2013c). The English→German system additionally comprises a target-side LM over automatically built word classes (Birch et al., 2013). UEDIN has applied syntactic prereordering (Collins et al., 2005) and compound splitting (Koehn and Knight, 2003) of the source side for the German→English system. The systems have been tuned on a very large tuning set consisting of the test sets from 2008-2012, with a total of 13,071 sentences. UEDIN used newstest2013 as held-out test set. On top of UEDIN phrase-based 1 system, UEDIN phrase-based 2 augments word classes as additional factor and learns an interpolated target sequence model over cluster IDs. Furthermore, it learns OSM models over POS, morph and word classes. et al., 2010; Wuebker et al., 2012). The model weights of all systems have been tune"
W14-3310,P06-1121,0,0.0128251,". The phrasebased system (RWTH scss) has been further improved by maximum expected B LEU training similar to (He and Deng, 2012). The latter has been performed on a selection from the News Commentary, Europarl and Common Crawl corpora based on language and translation model cross-entropies (Mansour et al., 2011). 3 3.2 UEDIN’s syntax-based systems (Williams et al., 2014) follow the GHKM syntax approach as proposed by Galley, Hopkins, Knight, and Marcu (Galley et al., 2004). The open source Moses implementation has been employed to extract GHKM rules (Williams and Koehn, 2012). Composed rules (Galley et al., 2006) are extracted in addition to minimal rules, but only up to the following limits: at most twenty tree nodes per rule, a maximum depth of five, and a maximum size of five. Singleton hierarchical rules are dropped. The features for the syntax-based systems comprise Good-Turing-smoothed phrase translation probabilities, lexical translation probabilities in both directions, word and phrase penalty, a rule rareness penalty, a monolingual PCFG probability, and a 5-gram language model. UEDIN has used the SRILM toolkit (Stolcke, 2002) to train the language model and relies on KenLM for language model"
W14-3310,P13-2071,1,0.0664637,"ction 2 EU-BRIDGE1 is a European research project which is aimed at developing innovative speech translation technology. This paper describes a RWTH Aachen University RWTH (Peitz et al., 2014) employs both the phrase-based (RWTH scss) and the hierarchical (RWTH hiero) decoder implemented in RWTH’s publicly available translation toolkit Jane (Vilar 1 http://www.eu-bridge.eu 105 Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 105–113, c Baltimore, Maryland USA, June 26–27, 2014. 2014 Association for Computational Linguistics els over POS and morph sequences following Durrani et al. (2013c). The English→German system additionally comprises a target-side LM over automatically built word classes (Birch et al., 2013). UEDIN has applied syntactic prereordering (Collins et al., 2005) and compound splitting (Koehn and Knight, 2003) of the source side for the German→English system. The systems have been tuned on a very large tuning set consisting of the test sets from 2008-2012, with a total of 13,071 sentences. UEDIN used newstest2013 as held-out test set. On top of UEDIN phrase-based 1 system, UEDIN phrase-based 2 augments word classes as additional factor and learns an interpolate"
W14-3310,2012.iwslt-papers.17,1,0.805256,".1 Syntax-based Systems Phrase-based Systems UEDIN’s phrase-based systems (Durrani et al., 2014) have been trained using the Moses toolkit (Koehn et al., 2007), replicating the settings described in (Durrani et al., 2013b). The features include: a maximum sentence length of 80, growdiag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5gram language model with KenLM (Heafield, 2011) used at runtime, a lexically-driven 5-gram operation sequence model (OSM) (Durrani et al., 2013a), msd-bidirectional-fe lexicalized reordering, sparse lexical and domain features (Hasler et al., 2012), a distortion limit of 6, a maximum phrase length of 5, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004), cube pruning (Huang and Chiang, 2007), with a stack size of 1000 during tuning and 5000 during testing and the no-reordering-overpunctuation heuristic. UEDIN uses POS and morphological target sequence models built on the indomain subset of the parallel corpus using KneserNey smoothed 7-gram models as additional factors in phrase translation models (Koehn and Hoang, 2007). UEDIN has furthermore built OSM mod106 model. The monolingual part of those parallel"
W14-3310,W13-2212,1,0.898684,"ction 2 EU-BRIDGE1 is a European research project which is aimed at developing innovative speech translation technology. This paper describes a RWTH Aachen University RWTH (Peitz et al., 2014) employs both the phrase-based (RWTH scss) and the hierarchical (RWTH hiero) decoder implemented in RWTH’s publicly available translation toolkit Jane (Vilar 1 http://www.eu-bridge.eu 105 Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 105–113, c Baltimore, Maryland USA, June 26–27, 2014. 2014 Association for Computational Linguistics els over POS and morph sequences following Durrani et al. (2013c). The English→German system additionally comprises a target-side LM over automatically built word classes (Birch et al., 2013). UEDIN has applied syntactic prereordering (Collins et al., 2005) and compound splitting (Koehn and Knight, 2003) of the source side for the German→English system. The systems have been tuned on a very large tuning set consisting of the test sets from 2008-2012, with a total of 13,071 sentences. UEDIN used newstest2013 as held-out test set. On top of UEDIN phrase-based 1 system, UEDIN phrase-based 2 augments word classes as additional factor and learns an interpolate"
W14-3310,P12-1031,0,0.00714997,"um Error Rate Training (Och, 2003) on a concatenation of the newstest2011 and newstest2012 sets. RWTH used B LEU as optimization objective. Both for language model estimation and querying at decoding, the KenLM toolkit (Heafield et al., 2013) is used. All RWTH systems include the standard set of models provided by Jane. Both systems have been augmented with a hierarchical orientation model (Galley and Manning, 2008; Huck et al., 2013) and a cluster language model (Wuebker et al., 2013). The phrasebased system (RWTH scss) has been further improved by maximum expected B LEU training similar to (He and Deng, 2012). The latter has been performed on a selection from the News Commentary, Europarl and Common Crawl corpora based on language and translation model cross-entropies (Mansour et al., 2011). 3 3.2 UEDIN’s syntax-based systems (Williams et al., 2014) follow the GHKM syntax approach as proposed by Galley, Hopkins, Knight, and Marcu (Galley et al., 2004). The open source Moses implementation has been employed to extract GHKM rules (Williams and Koehn, 2012). Composed rules (Galley et al., 2006) are extracted in addition to minimal rules, but only up to the following limits: at most twenty tree nodes"
W14-3310,P13-2121,1,0.0604984,"Missing"
W14-3310,W14-3309,1,0.840972,"btained high sentence-level B LEU scores when being translated with a baseline phrasebased system, and each contain less than 30 words for more rapid tuning. Decoding for the syntaxbased systems is carried out with cube pruning using Moses’ hierarchical decoder (Hoang et al., 2009). UEDIN’s German→English syntax-based setup is a string-to-tree system with compound splitting University of Edinburgh UEDIN contributed phrase-based and syntaxbased systems to both the German→English and the English→German joint submission. 3.1 Syntax-based Systems Phrase-based Systems UEDIN’s phrase-based systems (Durrani et al., 2014) have been trained using the Moses toolkit (Koehn et al., 2007), replicating the settings described in (Durrani et al., 2013b). The features include: a maximum sentence length of 80, growdiag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5gram language model with KenLM (Heafield, 2011) used at runtime, a lexically-driven 5-gram operation sequence model (OSM) (Durrani et al., 2013a), msd-bidirectional-fe lexicalized reordering, sparse lexical and domain features (Hasler et al., 2012), a distortion limit of 6, a maximum phrase length of 5, 100-best translatio"
W14-3310,W11-2123,0,0.00995075,"a string-to-tree system with compound splitting University of Edinburgh UEDIN contributed phrase-based and syntaxbased systems to both the German→English and the English→German joint submission. 3.1 Syntax-based Systems Phrase-based Systems UEDIN’s phrase-based systems (Durrani et al., 2014) have been trained using the Moses toolkit (Koehn et al., 2007), replicating the settings described in (Durrani et al., 2013b). The features include: a maximum sentence length of 80, growdiag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5gram language model with KenLM (Heafield, 2011) used at runtime, a lexically-driven 5-gram operation sequence model (OSM) (Durrani et al., 2013a), msd-bidirectional-fe lexicalized reordering, sparse lexical and domain features (Hasler et al., 2012), a distortion limit of 6, a maximum phrase length of 5, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004), cube pruning (Huang and Chiang, 2007), with a stack size of 1000 during tuning and 5000 during testing and the no-reordering-overpunctuation heuristic. UEDIN uses POS and morphological target sequence models built on the indomain subset of the parallel corpus"
W14-3310,W06-1607,0,0.0222136,"., 2013). It uses a modified syntactic label set, target-side compound splitting, and additional syntactic constraints. UEDIN GHKM S2T (BitPar): A string-to-tree system trained with target-side syntactic annotation obtained with BitPar (Schmid, 2004). The word alignment for German→English is generated using the GIZA++ toolkit (Och and Ney, 2003). For English→German, KIT uses discriminative word alignment (Niehues and Vogel, 2008). Phrase extraction and scoring is done using the Moses toolkit (Koehn et al., 2007). Phrase pair probabilities are computed using modified KneserNey smoothing as in (Foster et al., 2006). UEDIN GHKM S2T (Stanford): A string-totree system trained with target-side syntactic annotation obtained with the German Stanford Parser (Rafferty and Manning, 2008a). In both systems KIT applies short-range reorderings (Rottmann and Vogel, 2007) and longrange reorderings (Niehues and Kolss, 2009) based on POS tags (Schmid, 1994) to perform source sentence reordering according to the target language word order. The long-range reordering rules are applied to the training corpus to create reordering lattices to extract the phrases for the translation model. In addition, a tree-based reordering"
W14-3310,W13-0805,1,0.0274022,"GHKM S2T (Stanford): A string-totree system trained with target-side syntactic annotation obtained with the German Stanford Parser (Rafferty and Manning, 2008a). In both systems KIT applies short-range reorderings (Rottmann and Vogel, 2007) and longrange reorderings (Niehues and Kolss, 2009) based on POS tags (Schmid, 1994) to perform source sentence reordering according to the target language word order. The long-range reordering rules are applied to the training corpus to create reordering lattices to extract the phrases for the translation model. In addition, a tree-based reordering model (Herrmann et al., 2013) trained on syntactic parse trees (Rafferty and Manning, 2008b; Klein and Manning, 2003) as well as a lexicalized reordering model (Koehn et al., 2005) are applied. UEDIN GHKM S2T (Berkeley): A string-totree system trained with target-side syntactic annotation obtained with the German Berkeley Parser (Petrov and Klein, 2007; Petrov and Klein, 2008). UEDIN GHKM T2S (Berkeley): A tree-tostring system trained with source-side syntactic annotation obtained with the English Berkeley Parser (Petrov et al., 2006). UEDIN GHKM S2S (Berkeley): A string-tostring system. The extraction is GHKMbased with s"
W14-3310,2011.iwslt-papers.5,1,0.681344,"rying at decoding, the KenLM toolkit (Heafield et al., 2013) is used. All RWTH systems include the standard set of models provided by Jane. Both systems have been augmented with a hierarchical orientation model (Galley and Manning, 2008; Huck et al., 2013) and a cluster language model (Wuebker et al., 2013). The phrasebased system (RWTH scss) has been further improved by maximum expected B LEU training similar to (He and Deng, 2012). The latter has been performed on a selection from the News Commentary, Europarl and Common Crawl corpora based on language and translation model cross-entropies (Mansour et al., 2011). 3 3.2 UEDIN’s syntax-based systems (Williams et al., 2014) follow the GHKM syntax approach as proposed by Galley, Hopkins, Knight, and Marcu (Galley et al., 2004). The open source Moses implementation has been employed to extract GHKM rules (Williams and Koehn, 2012). Composed rules (Galley et al., 2006) are extracted in addition to minimal rules, but only up to the following limits: at most twenty tree nodes per rule, a maximum depth of five, and a maximum size of five. Singleton hierarchical rules are dropped. The features for the syntax-based systems comprise Good-Turing-smoothed phrase t"
W14-3310,2009.iwslt-papers.4,1,0.346713,"bility, and a 5-gram language model. UEDIN has used the SRILM toolkit (Stolcke, 2002) to train the language model and relies on KenLM for language model scoring during decoding. Model weights are optimized to maximize B LEU. 2000 sentences from the newstest2008-2012 sets have been selected as a development set. The selected sentences obtained high sentence-level B LEU scores when being translated with a baseline phrasebased system, and each contain less than 30 words for more rapid tuning. Decoding for the syntaxbased systems is carried out with cube pruning using Moses’ hierarchical decoder (Hoang et al., 2009). UEDIN’s German→English syntax-based setup is a string-to-tree system with compound splitting University of Edinburgh UEDIN contributed phrase-based and syntaxbased systems to both the German→English and the English→German joint submission. 3.1 Syntax-based Systems Phrase-based Systems UEDIN’s phrase-based systems (Durrani et al., 2014) have been trained using the Moses toolkit (Koehn et al., 2007), replicating the settings described in (Durrani et al., 2013b). The features include: a maximum sentence length of 80, growdiag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser"
W14-3310,D09-1022,1,0.0473567,"ingle generic nonterminal instead of syntactic ones, plus rules that have been added from plain phrase-based extraction (Huck et al., 2014). 4 Language models are trained with the SRILM toolkit (Stolcke, 2002) and use modified KneserNey smoothing. Both systems utilize a language model based on automatically learned word classes using the MKCLS algorithm (Och, 1999). The English→German system comprises language models based on fine-grained part-ofspeech tags (Schmid and Laws, 2008). In addition, a bilingual language model (Niehues et al., 2011) is used as well as a discriminative word lexicon (Mauser et al., 2009) using source context to guide the word choices in the target sentence. Karlsruhe Institute of Technology The KIT translations (Herrmann et al., 2014) are generated by an in-house phrase-based translations system (Vogel, 2003). The provided News Commentary, Europarl, and Common Crawl parallel corpora are used for training the translation 107 dividual system engines have been optimized on different test sets which partially or fully include newstest2011 or newstest2012. System combination weights are either optimized on newstest2011 or newstest2012. We kept newstest2013 as an unseen test set wh"
W14-3310,P07-1019,0,0.0254758,"he settings described in (Durrani et al., 2013b). The features include: a maximum sentence length of 80, growdiag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5gram language model with KenLM (Heafield, 2011) used at runtime, a lexically-driven 5-gram operation sequence model (OSM) (Durrani et al., 2013a), msd-bidirectional-fe lexicalized reordering, sparse lexical and domain features (Hasler et al., 2012), a distortion limit of 6, a maximum phrase length of 5, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004), cube pruning (Huang and Chiang, 2007), with a stack size of 1000 during tuning and 5000 during testing and the no-reordering-overpunctuation heuristic. UEDIN uses POS and morphological target sequence models built on the indomain subset of the parallel corpus using KneserNey smoothed 7-gram models as additional factors in phrase translation models (Koehn and Hoang, 2007). UEDIN has furthermore built OSM mod106 model. The monolingual part of those parallel corpora, the News Shuffle corpus for both directions and additionally the Gigaword corpus for German→English are used as monolingual training data for the different language mod"
W14-3310,2011.iwslt-evaluation.9,1,0.882056,"n, UEDIN has trained various string-to-tree GHKM syntax systems which differ with respect to the syntactic annotation. A tree-to-string system and a string-to-string system (with rules that are not syntactically decorated) have been trained as well. The English→German UEDIN GHKM system names in Table 3 denote: Compound splitting (Koehn and Knight, 2003) is performed on the source side of the corpus for German→English translation before training. In order to improve the quality of the web-crawled Common Crawl corpus, noisy sentence pairs are filtered out using an SVM classifier as described by Mediani et al. (2011). UEDIN GHKM S2T (ParZu): A string-to-tree system trained with target-side syntactic annotation obtained with ParZu (Sennrich et al., 2013). It uses a modified syntactic label set, target-side compound splitting, and additional syntactic constraints. UEDIN GHKM S2T (BitPar): A string-to-tree system trained with target-side syntactic annotation obtained with BitPar (Schmid, 2004). The word alignment for German→English is generated using the GIZA++ toolkit (Och and Ney, 2003). For English→German, KIT uses discriminative word alignment (Niehues and Vogel, 2008). Phrase extraction and scoring is d"
W14-3310,W13-2258,1,0.0602517,"r IDs. Furthermore, it learns OSM models over POS, morph and word classes. et al., 2010; Wuebker et al., 2012). The model weights of all systems have been tuned with standard Minimum Error Rate Training (Och, 2003) on a concatenation of the newstest2011 and newstest2012 sets. RWTH used B LEU as optimization objective. Both for language model estimation and querying at decoding, the KenLM toolkit (Heafield et al., 2013) is used. All RWTH systems include the standard set of models provided by Jane. Both systems have been augmented with a hierarchical orientation model (Galley and Manning, 2008; Huck et al., 2013) and a cluster language model (Wuebker et al., 2013). The phrasebased system (RWTH scss) has been further improved by maximum expected B LEU training similar to (He and Deng, 2012). The latter has been performed on a selection from the News Commentary, Europarl and Common Crawl corpora based on language and translation model cross-entropies (Mansour et al., 2011). 3 3.2 UEDIN’s syntax-based systems (Williams et al., 2014) follow the GHKM syntax approach as proposed by Galley, Hopkins, Knight, and Marcu (Galley et al., 2004). The open source Moses implementation has been employed to extract GHK"
W14-3310,P10-2041,0,0.0226125,"for tuning the system combination or any of the individual systems. In total, the English→German system uses the following language models: two 4-gram wordbased language models trained on the parallel data and the filtered Common Crawl data separately, two 5-gram POS-based language models trained on the same data as the word-based language models, and a 4-gram cluster-based language model trained on 1,000 MKCLS word classes. The German→English system uses a 4-gram word-based language model trained on all monolingual data and an additional language model trained on automatically selected data (Moore and Lewis, 2010). Again, a 4-gram cluster-based language model trained on 1000 MKCLS word classes is applied. 5 6.1 The automatic scores of all individual systems as well as of our final system combination submission are given in Table 1. KIT, UEDIN and RWTH are each providing one individual phrasebased system output. RWTH (hiero) and UEDIN (GHKM) are providing additional systems based on the hierarchical translation model and a stringto-tree syntax model. The pairwise difference of the single system performances is up to 1.3 points in B LEU and 2.5 points in T ER. For German→English, our system combination p"
W14-3310,W14-3362,1,0.700694,"ned with the German Berkeley Parser (Petrov and Klein, 2007; Petrov and Klein, 2008). UEDIN GHKM T2S (Berkeley): A tree-tostring system trained with source-side syntactic annotation obtained with the English Berkeley Parser (Petrov et al., 2006). UEDIN GHKM S2S (Berkeley): A string-tostring system. The extraction is GHKMbased with syntactic target-side annotation from the German Berkeley Parser, but we strip off the syntactic labels. The final grammar contains rules with a single generic nonterminal instead of syntactic ones, plus rules that have been added from plain phrase-based extraction (Huck et al., 2014). 4 Language models are trained with the SRILM toolkit (Stolcke, 2002) and use modified KneserNey smoothing. Both systems utilize a language model based on automatically learned word classes using the MKCLS algorithm (Och, 1999). The English→German system comprises language models based on fine-grained part-ofspeech tags (Schmid and Laws, 2008). In addition, a bilingual language model (Niehues et al., 2011) is used as well as a discriminative word lexicon (Mauser et al., 2009) using source context to guide the word choices in the target sentence. Karlsruhe Institute of Technology The KIT trans"
W14-3310,W09-0435,0,0.00463497,"erated using the GIZA++ toolkit (Och and Ney, 2003). For English→German, KIT uses discriminative word alignment (Niehues and Vogel, 2008). Phrase extraction and scoring is done using the Moses toolkit (Koehn et al., 2007). Phrase pair probabilities are computed using modified KneserNey smoothing as in (Foster et al., 2006). UEDIN GHKM S2T (Stanford): A string-totree system trained with target-side syntactic annotation obtained with the German Stanford Parser (Rafferty and Manning, 2008a). In both systems KIT applies short-range reorderings (Rottmann and Vogel, 2007) and longrange reorderings (Niehues and Kolss, 2009) based on POS tags (Schmid, 1994) to perform source sentence reordering according to the target language word order. The long-range reordering rules are applied to the training corpus to create reordering lattices to extract the phrases for the translation model. In addition, a tree-based reordering model (Herrmann et al., 2013) trained on syntactic parse trees (Rafferty and Manning, 2008b; Klein and Manning, 2003) as well as a lexicalized reordering model (Koehn et al., 2005) are applied. UEDIN GHKM S2T (Berkeley): A string-totree system trained with target-side syntactic annotation obtained"
W14-3310,P03-1054,0,0.00425242,"ion obtained with the German Stanford Parser (Rafferty and Manning, 2008a). In both systems KIT applies short-range reorderings (Rottmann and Vogel, 2007) and longrange reorderings (Niehues and Kolss, 2009) based on POS tags (Schmid, 1994) to perform source sentence reordering according to the target language word order. The long-range reordering rules are applied to the training corpus to create reordering lattices to extract the phrases for the translation model. In addition, a tree-based reordering model (Herrmann et al., 2013) trained on syntactic parse trees (Rafferty and Manning, 2008b; Klein and Manning, 2003) as well as a lexicalized reordering model (Koehn et al., 2005) are applied. UEDIN GHKM S2T (Berkeley): A string-totree system trained with target-side syntactic annotation obtained with the German Berkeley Parser (Petrov and Klein, 2007; Petrov and Klein, 2008). UEDIN GHKM T2S (Berkeley): A tree-tostring system trained with source-side syntactic annotation obtained with the English Berkeley Parser (Petrov et al., 2006). UEDIN GHKM S2S (Berkeley): A string-tostring system. The extraction is GHKMbased with syntactic target-side annotation from the German Berkeley Parser, but we strip off the sy"
W14-3310,W08-0303,0,0.0192279,"sing an SVM classifier as described by Mediani et al. (2011). UEDIN GHKM S2T (ParZu): A string-to-tree system trained with target-side syntactic annotation obtained with ParZu (Sennrich et al., 2013). It uses a modified syntactic label set, target-side compound splitting, and additional syntactic constraints. UEDIN GHKM S2T (BitPar): A string-to-tree system trained with target-side syntactic annotation obtained with BitPar (Schmid, 2004). The word alignment for German→English is generated using the GIZA++ toolkit (Och and Ney, 2003). For English→German, KIT uses discriminative word alignment (Niehues and Vogel, 2008). Phrase extraction and scoring is done using the Moses toolkit (Koehn et al., 2007). Phrase pair probabilities are computed using modified KneserNey smoothing as in (Foster et al., 2006). UEDIN GHKM S2T (Stanford): A string-totree system trained with target-side syntactic annotation obtained with the German Stanford Parser (Rafferty and Manning, 2008a). In both systems KIT applies short-range reorderings (Rottmann and Vogel, 2007) and longrange reorderings (Niehues and Kolss, 2009) based on POS tags (Schmid, 1994) to perform source sentence reordering according to the target language word ord"
W14-3310,D07-1091,1,0.0290057,"2013a), msd-bidirectional-fe lexicalized reordering, sparse lexical and domain features (Hasler et al., 2012), a distortion limit of 6, a maximum phrase length of 5, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004), cube pruning (Huang and Chiang, 2007), with a stack size of 1000 during tuning and 5000 during testing and the no-reordering-overpunctuation heuristic. UEDIN uses POS and morphological target sequence models built on the indomain subset of the parallel corpus using KneserNey smoothed 7-gram models as additional factors in phrase translation models (Koehn and Hoang, 2007). UEDIN has furthermore built OSM mod106 model. The monolingual part of those parallel corpora, the News Shuffle corpus for both directions and additionally the Gigaword corpus for German→English are used as monolingual training data for the different language models. Optimization is done with Minimum Error Rate Training as described in (Venugopal et al., 2005), using newstest2012 and newstest2013 as development and test data respectively. on the German source-language side and syntactic annotation from the Berkeley Parser (Petrov et al., 2006) on the English target-language side. For English→"
W14-3310,E03-1076,1,0.31096,"the hierarchical (RWTH hiero) decoder implemented in RWTH’s publicly available translation toolkit Jane (Vilar 1 http://www.eu-bridge.eu 105 Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 105–113, c Baltimore, Maryland USA, June 26–27, 2014. 2014 Association for Computational Linguistics els over POS and morph sequences following Durrani et al. (2013c). The English→German system additionally comprises a target-side LM over automatically built word classes (Birch et al., 2013). UEDIN has applied syntactic prereordering (Collins et al., 2005) and compound splitting (Koehn and Knight, 2003) of the source side for the German→English system. The systems have been tuned on a very large tuning set consisting of the test sets from 2008-2012, with a total of 13,071 sentences. UEDIN used newstest2013 as held-out test set. On top of UEDIN phrase-based 1 system, UEDIN phrase-based 2 augments word classes as additional factor and learns an interpolated target sequence model over cluster IDs. Furthermore, it learns OSM models over POS, morph and word classes. et al., 2010; Wuebker et al., 2012). The model weights of all systems have been tuned with standard Minimum Error Rate Training (Och"
W14-3310,W11-2124,1,0.0228284,"trip off the syntactic labels. The final grammar contains rules with a single generic nonterminal instead of syntactic ones, plus rules that have been added from plain phrase-based extraction (Huck et al., 2014). 4 Language models are trained with the SRILM toolkit (Stolcke, 2002) and use modified KneserNey smoothing. Both systems utilize a language model based on automatically learned word classes using the MKCLS algorithm (Och, 1999). The English→German system comprises language models based on fine-grained part-ofspeech tags (Schmid and Laws, 2008). In addition, a bilingual language model (Niehues et al., 2011) is used as well as a discriminative word lexicon (Mauser et al., 2009) using source context to guide the word choices in the target sentence. Karlsruhe Institute of Technology The KIT translations (Herrmann et al., 2014) are generated by an in-house phrase-based translations system (Vogel, 2003). The provided News Commentary, Europarl, and Common Crawl parallel corpora are used for training the translation 107 dividual system engines have been optimized on different test sets which partially or fully include newstest2011 or newstest2012. System combination weights are either optimized on news"
W14-3310,2005.iwslt-1.8,1,0.035532,"2008a). In both systems KIT applies short-range reorderings (Rottmann and Vogel, 2007) and longrange reorderings (Niehues and Kolss, 2009) based on POS tags (Schmid, 1994) to perform source sentence reordering according to the target language word order. The long-range reordering rules are applied to the training corpus to create reordering lattices to extract the phrases for the translation model. In addition, a tree-based reordering model (Herrmann et al., 2013) trained on syntactic parse trees (Rafferty and Manning, 2008b; Klein and Manning, 2003) as well as a lexicalized reordering model (Koehn et al., 2005) are applied. UEDIN GHKM S2T (Berkeley): A string-totree system trained with target-side syntactic annotation obtained with the German Berkeley Parser (Petrov and Klein, 2007; Petrov and Klein, 2008). UEDIN GHKM T2S (Berkeley): A tree-tostring system trained with source-side syntactic annotation obtained with the English Berkeley Parser (Petrov et al., 2006). UEDIN GHKM S2S (Berkeley): A string-tostring system. The extraction is GHKMbased with syntactic target-side annotation from the German Berkeley Parser, but we strip off the syntactic labels. The final grammar contains rules with a single"
W14-3310,J03-1002,1,0.0147027,"of the web-crawled Common Crawl corpus, noisy sentence pairs are filtered out using an SVM classifier as described by Mediani et al. (2011). UEDIN GHKM S2T (ParZu): A string-to-tree system trained with target-side syntactic annotation obtained with ParZu (Sennrich et al., 2013). It uses a modified syntactic label set, target-side compound splitting, and additional syntactic constraints. UEDIN GHKM S2T (BitPar): A string-to-tree system trained with target-side syntactic annotation obtained with BitPar (Schmid, 2004). The word alignment for German→English is generated using the GIZA++ toolkit (Och and Ney, 2003). For English→German, KIT uses discriminative word alignment (Niehues and Vogel, 2008). Phrase extraction and scoring is done using the Moses toolkit (Koehn et al., 2007). Phrase pair probabilities are computed using modified KneserNey smoothing as in (Foster et al., 2006). UEDIN GHKM S2T (Stanford): A string-totree system trained with target-side syntactic annotation obtained with the German Stanford Parser (Rafferty and Manning, 2008a). In both systems KIT applies short-range reorderings (Rottmann and Vogel, 2007) and longrange reorderings (Niehues and Kolss, 2009) based on POS tags (Schmid,"
W14-3310,E99-1010,0,0.0419329,"l., 2006). UEDIN GHKM S2S (Berkeley): A string-tostring system. The extraction is GHKMbased with syntactic target-side annotation from the German Berkeley Parser, but we strip off the syntactic labels. The final grammar contains rules with a single generic nonterminal instead of syntactic ones, plus rules that have been added from plain phrase-based extraction (Huck et al., 2014). 4 Language models are trained with the SRILM toolkit (Stolcke, 2002) and use modified KneserNey smoothing. Both systems utilize a language model based on automatically learned word classes using the MKCLS algorithm (Och, 1999). The English→German system comprises language models based on fine-grained part-ofspeech tags (Schmid and Laws, 2008). In addition, a bilingual language model (Niehues et al., 2011) is used as well as a discriminative word lexicon (Mauser et al., 2009) using source context to guide the word choices in the target sentence. Karlsruhe Institute of Technology The KIT translations (Herrmann et al., 2014) are generated by an in-house phrase-based translations system (Vogel, 2003). The provided News Commentary, Europarl, and Common Crawl parallel corpora are used for training the translation 107 div"
W14-3310,P07-2045,1,0.0154876,"th a baseline phrasebased system, and each contain less than 30 words for more rapid tuning. Decoding for the syntaxbased systems is carried out with cube pruning using Moses’ hierarchical decoder (Hoang et al., 2009). UEDIN’s German→English syntax-based setup is a string-to-tree system with compound splitting University of Edinburgh UEDIN contributed phrase-based and syntaxbased systems to both the German→English and the English→German joint submission. 3.1 Syntax-based Systems Phrase-based Systems UEDIN’s phrase-based systems (Durrani et al., 2014) have been trained using the Moses toolkit (Koehn et al., 2007), replicating the settings described in (Durrani et al., 2013b). The features include: a maximum sentence length of 80, growdiag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5gram language model with KenLM (Heafield, 2011) used at runtime, a lexically-driven 5-gram operation sequence model (OSM) (Durrani et al., 2013a), msd-bidirectional-fe lexicalized reordering, sparse lexical and domain features (Hasler et al., 2012), a distortion limit of 6, a maximum phrase length of 5, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004),"
W14-3310,P03-1021,0,0.0102254,"03) of the source side for the German→English system. The systems have been tuned on a very large tuning set consisting of the test sets from 2008-2012, with a total of 13,071 sentences. UEDIN used newstest2013 as held-out test set. On top of UEDIN phrase-based 1 system, UEDIN phrase-based 2 augments word classes as additional factor and learns an interpolated target sequence model over cluster IDs. Furthermore, it learns OSM models over POS, morph and word classes. et al., 2010; Wuebker et al., 2012). The model weights of all systems have been tuned with standard Minimum Error Rate Training (Och, 2003) on a concatenation of the newstest2011 and newstest2012 sets. RWTH used B LEU as optimization objective. Both for language model estimation and querying at decoding, the KenLM toolkit (Heafield et al., 2013) is used. All RWTH systems include the standard set of models provided by Jane. Both systems have been augmented with a hierarchical orientation model (Galley and Manning, 2008; Huck et al., 2013) and a cluster language model (Wuebker et al., 2013). The phrasebased system (RWTH scss) has been further improved by maximum expected B LEU training similar to (He and Deng, 2012). The latter has"
W14-3310,W14-3317,1,0.820032,"ty, the University of Edinburgh, and Karlsruhe Institute of Technology developed several individual systems which serve as system combination input. We devoted special attention to building syntax-based systems and combining them with the phrasebased ones. The joint setups yield empirical gains of up to 1.6 points in B LEU and 1.0 points in T ER on the WMT newstest2013 test set compared to the best single systems. 1 Introduction 2 EU-BRIDGE1 is a European research project which is aimed at developing innovative speech translation technology. This paper describes a RWTH Aachen University RWTH (Peitz et al., 2014) employs both the phrase-based (RWTH scss) and the hierarchical (RWTH hiero) decoder implemented in RWTH’s publicly available translation toolkit Jane (Vilar 1 http://www.eu-bridge.eu 105 Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 105–113, c Baltimore, Maryland USA, June 26–27, 2014. 2014 Association for Computational Linguistics els over POS and morph sequences following Durrani et al. (2013c). The English→German system additionally comprises a target-side LM over automatically built word classes (Birch et al., 2013). UEDIN has applied syntactic prereordering"
W14-3310,N04-1022,0,0.063305,"it (Koehn et al., 2007), replicating the settings described in (Durrani et al., 2013b). The features include: a maximum sentence length of 80, growdiag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5gram language model with KenLM (Heafield, 2011) used at runtime, a lexically-driven 5-gram operation sequence model (OSM) (Durrani et al., 2013a), msd-bidirectional-fe lexicalized reordering, sparse lexical and domain features (Hasler et al., 2012), a distortion limit of 6, a maximum phrase length of 5, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004), cube pruning (Huang and Chiang, 2007), with a stack size of 1000 during tuning and 5000 during testing and the no-reordering-overpunctuation heuristic. UEDIN uses POS and morphological target sequence models built on the indomain subset of the parallel corpus using KneserNey smoothed 7-gram models as additional factors in phrase translation models (Koehn and Hoang, 2007). UEDIN has furthermore built OSM mod106 model. The monolingual part of those parallel corpora, the News Shuffle corpus for both directions and additionally the Gigaword corpus for German→English are used as monolingual train"
W14-3310,W10-1738,1,0.159493,"Missing"
W14-3310,W08-1005,0,0.0331415,"nce reordering according to the target language word order. The long-range reordering rules are applied to the training corpus to create reordering lattices to extract the phrases for the translation model. In addition, a tree-based reordering model (Herrmann et al., 2013) trained on syntactic parse trees (Rafferty and Manning, 2008b; Klein and Manning, 2003) as well as a lexicalized reordering model (Koehn et al., 2005) are applied. UEDIN GHKM S2T (Berkeley): A string-totree system trained with target-side syntactic annotation obtained with the German Berkeley Parser (Petrov and Klein, 2007; Petrov and Klein, 2008). UEDIN GHKM T2S (Berkeley): A tree-tostring system trained with source-side syntactic annotation obtained with the English Berkeley Parser (Petrov et al., 2006). UEDIN GHKM S2S (Berkeley): A string-tostring system. The extraction is GHKMbased with syntactic target-side annotation from the German Berkeley Parser, but we strip off the syntactic labels. The final grammar contains rules with a single generic nonterminal instead of syntactic ones, plus rules that have been added from plain phrase-based extraction (Huck et al., 2014). 4 Language models are trained with the SRILM toolkit (Stolcke, 2"
W14-3310,P06-1055,0,0.0182004,"dditional factors in phrase translation models (Koehn and Hoang, 2007). UEDIN has furthermore built OSM mod106 model. The monolingual part of those parallel corpora, the News Shuffle corpus for both directions and additionally the Gigaword corpus for German→English are used as monolingual training data for the different language models. Optimization is done with Minimum Error Rate Training as described in (Venugopal et al., 2005), using newstest2012 and newstest2013 as development and test data respectively. on the German source-language side and syntactic annotation from the Berkeley Parser (Petrov et al., 2006) on the English target-language side. For English→German, UEDIN has trained various string-to-tree GHKM syntax systems which differ with respect to the syntactic annotation. A tree-to-string system and a string-to-string system (with rules that are not syntactically decorated) have been trained as well. The English→German UEDIN GHKM system names in Table 3 denote: Compound splitting (Koehn and Knight, 2003) is performed on the source side of the corpus for German→English translation before training. In order to improve the quality of the web-crawled Common Crawl corpus, noisy sentence pairs ar"
W14-3310,W12-3150,1,0.544959,"uster language model (Wuebker et al., 2013). The phrasebased system (RWTH scss) has been further improved by maximum expected B LEU training similar to (He and Deng, 2012). The latter has been performed on a selection from the News Commentary, Europarl and Common Crawl corpora based on language and translation model cross-entropies (Mansour et al., 2011). 3 3.2 UEDIN’s syntax-based systems (Williams et al., 2014) follow the GHKM syntax approach as proposed by Galley, Hopkins, Knight, and Marcu (Galley et al., 2004). The open source Moses implementation has been employed to extract GHKM rules (Williams and Koehn, 2012). Composed rules (Galley et al., 2006) are extracted in addition to minimal rules, but only up to the following limits: at most twenty tree nodes per rule, a maximum depth of five, and a maximum size of five. Singleton hierarchical rules are dropped. The features for the syntax-based systems comprise Good-Turing-smoothed phrase translation probabilities, lexical translation probabilities in both directions, word and phrase penalty, a rule rareness penalty, a monolingual PCFG probability, and a 5-gram language model. UEDIN has used the SRILM toolkit (Stolcke, 2002) to train the language model a"
W14-3310,W08-1006,0,0.0232292,"e system trained with target-side syntactic annotation obtained with BitPar (Schmid, 2004). The word alignment for German→English is generated using the GIZA++ toolkit (Och and Ney, 2003). For English→German, KIT uses discriminative word alignment (Niehues and Vogel, 2008). Phrase extraction and scoring is done using the Moses toolkit (Koehn et al., 2007). Phrase pair probabilities are computed using modified KneserNey smoothing as in (Foster et al., 2006). UEDIN GHKM S2T (Stanford): A string-totree system trained with target-side syntactic annotation obtained with the German Stanford Parser (Rafferty and Manning, 2008a). In both systems KIT applies short-range reorderings (Rottmann and Vogel, 2007) and longrange reorderings (Niehues and Kolss, 2009) based on POS tags (Schmid, 1994) to perform source sentence reordering according to the target language word order. The long-range reordering rules are applied to the training corpus to create reordering lattices to extract the phrases for the translation model. In addition, a tree-based reordering model (Herrmann et al., 2013) trained on syntactic parse trees (Rafferty and Manning, 2008b; Klein and Manning, 2003) as well as a lexicalized reordering model (Koeh"
W14-3310,W14-3324,1,0.0949085,"Missing"
W14-3310,2007.tmi-papers.21,0,0.125992,", 2004). The word alignment for German→English is generated using the GIZA++ toolkit (Och and Ney, 2003). For English→German, KIT uses discriminative word alignment (Niehues and Vogel, 2008). Phrase extraction and scoring is done using the Moses toolkit (Koehn et al., 2007). Phrase pair probabilities are computed using modified KneserNey smoothing as in (Foster et al., 2006). UEDIN GHKM S2T (Stanford): A string-totree system trained with target-side syntactic annotation obtained with the German Stanford Parser (Rafferty and Manning, 2008a). In both systems KIT applies short-range reorderings (Rottmann and Vogel, 2007) and longrange reorderings (Niehues and Kolss, 2009) based on POS tags (Schmid, 1994) to perform source sentence reordering according to the target language word order. The long-range reordering rules are applied to the training corpus to create reordering lattices to extract the phrases for the translation model. In addition, a tree-based reordering model (Herrmann et al., 2013) trained on syntactic parse trees (Rafferty and Manning, 2008b; Klein and Manning, 2003) as well as a lexicalized reordering model (Koehn et al., 2005) are applied. UEDIN GHKM S2T (Berkeley): A string-totree system tra"
W14-3310,C12-3061,1,0.125144,"013). UEDIN has applied syntactic prereordering (Collins et al., 2005) and compound splitting (Koehn and Knight, 2003) of the source side for the German→English system. The systems have been tuned on a very large tuning set consisting of the test sets from 2008-2012, with a total of 13,071 sentences. UEDIN used newstest2013 as held-out test set. On top of UEDIN phrase-based 1 system, UEDIN phrase-based 2 augments word classes as additional factor and learns an interpolated target sequence model over cluster IDs. Furthermore, it learns OSM models over POS, morph and word classes. et al., 2010; Wuebker et al., 2012). The model weights of all systems have been tuned with standard Minimum Error Rate Training (Och, 2003) on a concatenation of the newstest2011 and newstest2012 sets. RWTH used B LEU as optimization objective. Both for language model estimation and querying at decoding, the KenLM toolkit (Heafield et al., 2013) is used. All RWTH systems include the standard set of models provided by Jane. Both systems have been augmented with a hierarchical orientation model (Galley and Manning, 2008; Huck et al., 2013) and a cluster language model (Wuebker et al., 2013). The phrasebased system (RWTH scss) has"
W14-3310,C08-1098,0,0.00933067,"target-side annotation from the German Berkeley Parser, but we strip off the syntactic labels. The final grammar contains rules with a single generic nonterminal instead of syntactic ones, plus rules that have been added from plain phrase-based extraction (Huck et al., 2014). 4 Language models are trained with the SRILM toolkit (Stolcke, 2002) and use modified KneserNey smoothing. Both systems utilize a language model based on automatically learned word classes using the MKCLS algorithm (Och, 1999). The English→German system comprises language models based on fine-grained part-ofspeech tags (Schmid and Laws, 2008). In addition, a bilingual language model (Niehues et al., 2011) is used as well as a discriminative word lexicon (Mauser et al., 2009) using source context to guide the word choices in the target sentence. Karlsruhe Institute of Technology The KIT translations (Herrmann et al., 2014) are generated by an in-house phrase-based translations system (Vogel, 2003). The provided News Commentary, Europarl, and Common Crawl parallel corpora are used for training the translation 107 dividual system engines have been optimized on different test sets which partially or fully include newstest2011 or newst"
W14-3310,D13-1138,1,0.0721313,", morph and word classes. et al., 2010; Wuebker et al., 2012). The model weights of all systems have been tuned with standard Minimum Error Rate Training (Och, 2003) on a concatenation of the newstest2011 and newstest2012 sets. RWTH used B LEU as optimization objective. Both for language model estimation and querying at decoding, the KenLM toolkit (Heafield et al., 2013) is used. All RWTH systems include the standard set of models provided by Jane. Both systems have been augmented with a hierarchical orientation model (Galley and Manning, 2008; Huck et al., 2013) and a cluster language model (Wuebker et al., 2013). The phrasebased system (RWTH scss) has been further improved by maximum expected B LEU training similar to (He and Deng, 2012). The latter has been performed on a selection from the News Commentary, Europarl and Common Crawl corpora based on language and translation model cross-entropies (Mansour et al., 2011). 3 3.2 UEDIN’s syntax-based systems (Williams et al., 2014) follow the GHKM syntax approach as proposed by Galley, Hopkins, Knight, and Marcu (Galley et al., 2004). The open source Moses implementation has been employed to extract GHKM rules (Williams and Koehn, 2012). Composed rules ("
W14-3310,C04-1024,0,0.0194264,"f the corpus for German→English translation before training. In order to improve the quality of the web-crawled Common Crawl corpus, noisy sentence pairs are filtered out using an SVM classifier as described by Mediani et al. (2011). UEDIN GHKM S2T (ParZu): A string-to-tree system trained with target-side syntactic annotation obtained with ParZu (Sennrich et al., 2013). It uses a modified syntactic label set, target-side compound splitting, and additional syntactic constraints. UEDIN GHKM S2T (BitPar): A string-to-tree system trained with target-side syntactic annotation obtained with BitPar (Schmid, 2004). The word alignment for German→English is generated using the GIZA++ toolkit (Och and Ney, 2003). For English→German, KIT uses discriminative word alignment (Niehues and Vogel, 2008). Phrase extraction and scoring is done using the Moses toolkit (Koehn et al., 2007). Phrase pair probabilities are computed using modified KneserNey smoothing as in (Foster et al., 2006). UEDIN GHKM S2T (Stanford): A string-totree system trained with target-side syntactic annotation obtained with the German Stanford Parser (Rafferty and Manning, 2008a). In both systems KIT applies short-range reorderings (Rottman"
W14-3310,R13-1079,1,0.28133,"stem and a string-to-string system (with rules that are not syntactically decorated) have been trained as well. The English→German UEDIN GHKM system names in Table 3 denote: Compound splitting (Koehn and Knight, 2003) is performed on the source side of the corpus for German→English translation before training. In order to improve the quality of the web-crawled Common Crawl corpus, noisy sentence pairs are filtered out using an SVM classifier as described by Mediani et al. (2011). UEDIN GHKM S2T (ParZu): A string-to-tree system trained with target-side syntactic annotation obtained with ParZu (Sennrich et al., 2013). It uses a modified syntactic label set, target-side compound splitting, and additional syntactic constraints. UEDIN GHKM S2T (BitPar): A string-to-tree system trained with target-side syntactic annotation obtained with BitPar (Schmid, 2004). The word alignment for German→English is generated using the GIZA++ toolkit (Och and Ney, 2003). For English→German, KIT uses discriminative word alignment (Niehues and Vogel, 2008). Phrase extraction and scoring is done using the Moses toolkit (Koehn et al., 2007). Phrase pair probabilities are computed using modified KneserNey smoothing as in (Foster e"
W14-3310,N07-1051,0,\N,Missing
W14-3310,W05-0836,1,\N,Missing
W14-3310,W05-0909,0,\N,Missing
W14-3310,N13-1001,1,\N,Missing
W14-3310,2010.iwslt-evaluation.11,1,\N,Missing
W14-3310,2013.iwslt-evaluation.16,1,\N,Missing
W14-3310,W13-2213,1,\N,Missing
W14-3310,W14-3313,1,\N,Missing
W14-3310,W11-2145,1,\N,Missing
W14-3310,2013.iwslt-evaluation.3,1,\N,Missing
W14-3317,popovic-ney-2006-pos,1,\N,Missing
W14-3317,N04-4026,0,\N,Missing
W14-3317,E03-1076,0,\N,Missing
W14-3317,D08-1089,0,\N,Missing
W14-3317,P12-1031,0,\N,Missing
W14-3317,P02-1040,0,\N,Missing
W14-3317,W10-1738,1,\N,Missing
W14-3317,D13-1138,1,\N,Missing
W14-3317,P10-2041,0,\N,Missing
W14-3317,P10-1049,1,\N,Missing
W14-3317,W13-2258,1,\N,Missing
W14-3317,J03-1002,1,\N,Missing
W14-3317,W13-0804,1,\N,Missing
W14-3317,C12-3061,1,\N,Missing
W14-3317,W14-3310,1,\N,Missing
W14-3317,2012.iwslt-papers.7,1,\N,Missing
W14-3317,J07-2003,0,\N,Missing
W14-3317,W11-2123,0,\N,Missing
W14-3317,P13-2121,0,\N,Missing
W14-3317,P03-1021,0,\N,Missing
W14-3317,2011.iwslt-papers.5,1,\N,Missing
W14-3359,D11-1033,0,0.149731,"during the 457 Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 457–465, c Baltimore, Maryland USA, June 26–27, 2014. 2014 Association for Computational Linguistics compare different adaptation sets. Furthermore, we do not use confidence measures to filter the automatic translations as they are only used to adapt the general-domain system and are not augmented to the TM. In this work, we apply cross-entropy scoring for adaptation as done by (Moore and Lewis, 2010). Moore and Lewis (2010) apply adaptation by using an LM-based cross-entropy filtering for LM training. Axelrod et al. (2011) generalized the method for TM adaptation by interpolating the source and target LMs. These two works focused on a scenario where in-domain training data are available for adaptation. In this work, we focus on a scenario where in-domain training data is not labeled, and the main resource for adaptation is the source-language test data. In recent WMT evaluations, the method of (Moore and Lewis, 2010) was utilized by several translation systems (Koehn and Haddow, 2012; Rubino et al., 2013). These systems use pseudo in-domain corpus, i.e., news-commentary, as the target domain (while the test dom"
W14-3359,2012.iwslt-evaluation.1,0,0.0729849,"Missing"
W14-3359,W07-0717,0,0.0272369,"otheses to perform adaptation. We extend their work by using the hypotheses also for TM adaptation. (Hildebrand et al., 2005) perform LM and TM adaptation based on information retrieval methods. They use the sourcelanguage test corpus to filter the bilingual data, and then use the target side of the filtered bilingual data to perform LM adaptation. We differ from their work by using both the in-domain sourcelanguage corpus and its corresponding automatic translation for adaptation, which is shown in our experiments to achieve superior results than when using the source-side information only. (Foster and Kuhn, 2007) perform LM and TM adaptation using mixture modeling. In their setting, the mixture weights are modified to express adaptation. They compare cross-domain (in-domain available) against dynamic adaptation. In the dynamic adaptation scenario, they utilize the source side of the development set to adapt the mixture weights (LM adaptation is possible as they only use parallel training data, which enables filtering based on the source side and then keeping the corresponding target side of the data). For an in-domain test set, the cross-domain setup performs better than the dynamic adaptation method."
W14-3359,D08-1089,0,0.0561976,"Missing"
W14-3359,2006.amta-papers.25,0,0.171092,"Missing"
W14-3359,P07-1004,0,0.0196727,"erform LM and TM adaptation using mixture modeling. In their setting, the mixture weights are modified to express adaptation. They compare cross-domain (in-domain available) against dynamic adaptation. In the dynamic adaptation scenario, they utilize the source side of the development set to adapt the mixture weights (LM adaptation is possible as they only use parallel training data, which enables filtering based on the source side and then keeping the corresponding target side of the data). For an in-domain test set, the cross-domain setup performs better than the dynamic adaptation method. (Ueffing et al., 2007) use the test set translations as additional data to train the TM. One important aspect in their work is confidence measurement to remove noisy translation. In our approach, we use the automatic test set translations to adapt the SMT models rather than augmenting it as additional TM data. We also 3 Cross-Entropy Adaptation In this work, we use sample scoring for the purpose of adaptation. We start by introducing the scoring framework and then show how we utilize it to perform filtering based adaptation and weighted phrase extraction based adaptation. LM cross-entropy scores can be used for bot"
W14-3359,2005.eamt-1.19,0,0.0222024,"LM. When using a strong baseline, no improvements in recognition quality are achieved. We differ from their work by using the unsupervised test data to adapt a generaldomain bilingual corpus. We also performed initial experiments of “self-training” for language modeling, where (artificial) perplexity improvement was achieved but without an impact on the machine translation (MT) quality. (Zhao et al., 2004) tackle LM adaptation for SMT. Similarly to our work, they use automatically generated hypotheses to perform adaptation. We extend their work by using the hypotheses also for TM adaptation. (Hildebrand et al., 2005) perform LM and TM adaptation based on information retrieval methods. They use the sourcelanguage test corpus to filter the bilingual data, and then use the target side of the filtered bilingual data to perform LM adaptation. We differ from their work by using both the in-domain sourcelanguage corpus and its corresponding automatic translation for adaptation, which is shown in our experiments to achieve superior results than when using the source-side information only. (Foster and Kuhn, 2007) perform LM and TM adaptation using mixture modeling. In their setting, the mixture weights are modifie"
W14-3359,C12-3061,1,0.875561,"Missing"
W14-3359,W12-3139,0,0.103864,"by (Moore and Lewis, 2010). Moore and Lewis (2010) apply adaptation by using an LM-based cross-entropy filtering for LM training. Axelrod et al. (2011) generalized the method for TM adaptation by interpolating the source and target LMs. These two works focused on a scenario where in-domain training data are available for adaptation. In this work, we focus on a scenario where in-domain training data is not labeled, and the main resource for adaptation is the source-language test data. In recent WMT evaluations, the method of (Moore and Lewis, 2010) was utilized by several translation systems (Koehn and Haddow, 2012; Rubino et al., 2013). These systems use pseudo in-domain corpus, i.e., news-commentary, as the target domain (while the test domain is newswire). The contribution of this work is two fold: we show that the choice of the target set is crucial for adaptation, in addition, we show that an unsupervised target set performs best in terms of translation quality as well as generalization performance to unseen test sets (in comparison to using pseudo in-domain data or the references as target sets). recognition process. (Bacchiani and Roark, 2003) compare supervised against unsupervised (using automa"
W14-3359,C04-1059,0,0.0411939,"g the supervised in-domain to the training of the LM performs better than the unsupervised in-domain. In addition, they perform “selftraining”, where the test set is automatically transcribed and added to the LM. When using a strong baseline, no improvements in recognition quality are achieved. We differ from their work by using the unsupervised test data to adapt a generaldomain bilingual corpus. We also performed initial experiments of “self-training” for language modeling, where (artificial) perplexity improvement was achieved but without an impact on the machine translation (MT) quality. (Zhao et al., 2004) tackle LM adaptation for SMT. Similarly to our work, they use automatically generated hypotheses to perform adaptation. We extend their work by using the hypotheses also for TM adaptation. (Hildebrand et al., 2005) perform LM and TM adaptation based on information retrieval methods. They use the sourcelanguage test corpus to filter the bilingual data, and then use the target side of the filtered bilingual data to perform LM adaptation. We differ from their work by using both the in-domain sourcelanguage corpus and its corresponding automatic translation for adaptation, which is shown in our e"
W14-3359,W04-3250,0,0.378234,"Missing"
W14-3359,2012.iwslt-papers.7,1,0.824854,"Missing"
W14-3359,P10-2041,0,0.675931,"eneral domain) corpus, and (ii) the data is not available or too small, and then it can be gathered or automatically generated during the 457 Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 457–465, c Baltimore, Maryland USA, June 26–27, 2014. 2014 Association for Computational Linguistics compare different adaptation sets. Furthermore, we do not use confidence measures to filter the automatic translations as they are only used to adapt the general-domain system and are not augmented to the TM. In this work, we apply cross-entropy scoring for adaptation as done by (Moore and Lewis, 2010). Moore and Lewis (2010) apply adaptation by using an LM-based cross-entropy filtering for LM training. Axelrod et al. (2011) generalized the method for TM adaptation by interpolating the source and target LMs. These two works focused on a scenario where in-domain training data are available for adaptation. In this work, we focus on a scenario where in-domain training data is not labeled, and the main resource for adaptation is the source-language test data. In recent WMT evaluations, the method of (Moore and Lewis, 2010) was utilized by several translation systems (Koehn and Haddow, 2012; Rub"
W14-3359,P03-1021,0,0.0161903,"Missing"
W14-3359,P02-1040,0,0.0890595,"Missing"
W14-3359,W13-2227,0,\N,Missing
W14-4001,P14-1129,0,0.0475038,"addition, we present a simple way to learn bilingually-constrained phrase vectors. The phrase vectors are then used to provide additional scoring of phrase pairs, which fits into the standard log-linear framework of phrase-based statistical machine translation. Both methods result in significant improvements over a competitive in-domain baseline applied to the Arabic-to-English task of IWSLT 2013. 1 We make use of continuous vectors learned using simple neural networks. Neural networks have been gaining increasing attention recently, where they have been able to enhance strong SMT baselines (Devlin et al., 2014; Sundermeyer et al., 2014). While neural language and translation modeling make intermediate use of continuous representations, there have been also attempts at explicit learning of continuous representations to improve translation (Zhang et al., 2014; Gao et al., 2013). Introduction This work explores the potential of word semantics based on continuous vector representations to enhance the performance of phrase-based machine translation. We present a greedy algorithm that employs the phrase table to identify phrases in a training corpus. The phrase table serves to bilingually restrict the ph"
W14-4001,E14-1003,0,0.178274,"nd Structure in Statistical Translation, pages 1–10, c October 25, 2014, Doha, Qatar. 2014 Association for Computational Linguistics by applying a sequence of convolutions, starting with word representations. the OOV rate which translates to improved B LEU and and T ER scores. We apply the two methods on the IWSLT 2013 Arabic-to-English task and show significant improvements over a strong in-domain baseline. Another approach for phrase representation considers phrases as atomic units that can not be divided further. The representations are learned directly in this case (Mikolov et al., 2013b; Hu et al., 2014). The rest of the paper is structured as follows. Section 2 presents a background on word and phrase vectors. The construction of the phrase corpus is discussed in Section 3, while Section 4 demonstrates how to use word and phrase vectors in the standard phrase-based SMT pipeline. Experiments are presented in Section 5, followed by an overview of the related word in Section 6, and finally Section 7 concludes the work. 2 In this work, we follow the second approach to obtain phrase vectors. To this end, we apply the same methods that yield word vectors, with the difference that phrases are used"
W14-4001,W14-1617,0,0.079044,"Missing"
W14-4001,D13-1176,0,0.120154,"Missing"
W14-4001,E12-1014,0,0.0543412,"Missing"
W14-4001,D14-1003,1,0.827559,"a simple way to learn bilingually-constrained phrase vectors. The phrase vectors are then used to provide additional scoring of phrase pairs, which fits into the standard log-linear framework of phrase-based statistical machine translation. Both methods result in significant improvements over a competitive in-domain baseline applied to the Arabic-to-English task of IWSLT 2013. 1 We make use of continuous vectors learned using simple neural networks. Neural networks have been gaining increasing attention recently, where they have been able to enhance strong SMT baselines (Devlin et al., 2014; Sundermeyer et al., 2014). While neural language and translation modeling make intermediate use of continuous representations, there have been also attempts at explicit learning of continuous representations to improve translation (Zhang et al., 2014; Gao et al., 2013). Introduction This work explores the potential of word semantics based on continuous vector representations to enhance the performance of phrase-based machine translation. We present a greedy algorithm that employs the phrase table to identify phrases in a training corpus. The phrase table serves to bilingually restrict the phrases spotted in the monoli"
W14-4001,W10-1738,1,0.875857,"nd our OOV reduction method. The experiments are based on vectors trained using the word2vec1 toolkit, setting vector dimensionality to 800 for Arabic and 200 for English vectors. We used the skip-gram model with a maximum skip length of 10. The phrase corpus was constructed using 5 passes, with scores computed according to Eq. 1 using 2 phrasal and 2 lexical features. The phrasal and lexical weights were set to 1 and 0.5 respectively, with all features being negative log-probabilities, and the scoring threshold θ was set to 10. All translation experiments are performed with the Jane toolkit (Vilar et al., 2010; Wuebker et al., 2012). The resulting lexicon is compared to the IBM 1 lexicon2 . Given a source word, we select the the best target word according to the VSM-based score. This is compared to the best translation based on the IBM 1 probability. If both translations coincide, we refer to this as a 1-best match. We also check whether the best translation according to IBM 1 matches any of the top-5 translations based on the VSM model. A match in this case is referred to as a 5-best match. 2 We assume for the purpose of this experiment that the IBM 1 lexicon provides perfect translations, which i"
W14-4001,D09-1040,0,0.0589324,"he rich bilingual knowledge provided by the phrase table to join the corpus instead. Gao et al. (2013) learn shared space mappings using a feed-forward neural network and represent a phrase vector as a bag-of-words vector. The vectors are learned aiming to optimize an expected B LEU criterion. Our work is different in that we learn two separate source and target mappings. 8 References We also do not follow their bag-of-words phrase model approach. Yoshua Bengio, Rejean Ducharme, and Pascal Vincent. 2003. A neural probabilistic language model. Journal of Machine Learning Research, 3:1137–1155. Marton et al. (2009) proposed to eliminate OOVs by looking for similar words using distributional vectors, but they prune the search space limiting it to candidates observed in the same context as that of the OOV. We do not employ such a heuristic. Instead, we perform a k-nearest neighbor search spanning the full phrase table to paraphrase its rules and generate new entries. Boxing Chen, George Foster, and Roland Kuhn. 2010. Bilingual sense similarity for statistical machine translation. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 834–843. Jonathan H. Clark, C"
W14-4001,C12-3061,1,0.879264,"method. The experiments are based on vectors trained using the word2vec1 toolkit, setting vector dimensionality to 800 for Arabic and 200 for English vectors. We used the skip-gram model with a maximum skip length of 10. The phrase corpus was constructed using 5 passes, with scores computed according to Eq. 1 using 2 phrasal and 2 lexical features. The phrasal and lexical weights were set to 1 and 0.5 respectively, with all features being negative log-probabilities, and the scoring threshold θ was set to 10. All translation experiments are performed with the Jane toolkit (Vilar et al., 2010; Wuebker et al., 2012). The resulting lexicon is compared to the IBM 1 lexicon2 . Given a source word, we select the the best target word according to the VSM-based score. This is compared to the best translation based on the IBM 1 probability. If both translations coincide, we refer to this as a 1-best match. We also check whether the best translation according to IBM 1 matches any of the top-5 translations based on the VSM model. A match in this case is referred to as a 5-best match. 2 We assume for the purpose of this experiment that the IBM 1 lexicon provides perfect translations, which is not necessarily the c"
W14-4001,P14-1011,0,0.381409,"nslation. Both methods result in significant improvements over a competitive in-domain baseline applied to the Arabic-to-English task of IWSLT 2013. 1 We make use of continuous vectors learned using simple neural networks. Neural networks have been gaining increasing attention recently, where they have been able to enhance strong SMT baselines (Devlin et al., 2014; Sundermeyer et al., 2014). While neural language and translation modeling make intermediate use of continuous representations, there have been also attempts at explicit learning of continuous representations to improve translation (Zhang et al., 2014; Gao et al., 2013). Introduction This work explores the potential of word semantics based on continuous vector representations to enhance the performance of phrase-based machine translation. We present a greedy algorithm that employs the phrase table to identify phrases in a training corpus. The phrase table serves to bilingually restrict the phrases spotted in the monolingual corpus. The algorithm is applied separately to the source and target sides of the training data, resulting in source and target corpora of phrases (instead of words). The phrase corpus is used to learn phrase vectors us"
W14-4001,D13-1141,0,0.256873,"th paraphrased entries. This leads to a reduction in Categorical word representation has been widely used in many natural language processing (NLP) applications including statistical machine translation (SMT), where words are treated as discrete random variables. Continuous word representations, on the other hand, have been applied successfully in many NLP areas (Manning et al., 2008; Collobert and Weston, 2008). However, their application to machine translation is still an open research question. Several works tried to address the question recently (Mikolov et al., 2013b; Zhang et al., 2014; Zou et al., 2013), and this work is but another step in that direction. While categorical representations do not encode any information about word identities, continuous representations embed words in a vector space, resulting in geometric arrangements that reflect in1 Proceedings of SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 1–10, c October 25, 2014, Doha, Qatar. 2014 Association for Computational Linguistics by applying a sequence of convolutions, starting with word representations. the OOV rate which translates to improved B LEU and and T ER scores. We apply"
W14-4001,P10-2041,0,0.0442098,"ime to generate additional phrase table entries, and does not affect decoding time, except through the increase of the phrase table size. In our experiments, the training time using exact k-NN search was acceptable, therefore no search approximations were made. 5 Baseline System The language model (LM) is a 4-gram mixture LM trained on several data sets using modified Kneser-Ney discounting with interpolation, and combined with weights tuned to achieve the lowest perplexity on a development set using the SRILM toolkit (Stolcke, 2002). Data selection is performed using cross-entropy filtering (Moore and Lewis, 2010). 5.2 Word Vectors Here we analyze the quality of word vectors used in the OOV reduction experiments. The vectors are trained using an unaltered word corpus. We build a lexicon using source and target word vectors together with the projection matrix using the similarity score sim(W x f , ze )), where the projection matrix W is used to project the source word vector x f , corresponding to the source word f , to the target vector space. The similarity between the projection result W x f and the target word vector ze is computed. In the following we will refer to these scores computed using vecto"
W14-4001,P02-1038,1,0.567872,"uch mapping is needed for the training of the projection matrix, we resort to the phrase table to obtain it. A source and a target phrase vectors are paired if there is a corresponding phrase pair entry in the phrase table whose score exceeds a certain threshold. Scoring is computed using Eq. 1. Similarly, word vectors are paired using IBM 1 p(e |f ) and p( f |e) lexica. Noisy entries are assumed to have a probability less than a certain threshold and are not used to pair word vectors. Phrase-based Machine Translation The phrase-based decoder consists of a search using a log-linear framework (Och and Ney, 2002) as follows: ( ) ˆ eˆI1 = arg max max I,eI1 M ∑ λm hm (eI1 , sK1 , f1J ) K,sK 1 m=1 (2) where eI1 = e1 ...eI is the target sentence, f1J = f1 ... fJ is the source sentence, sK1 = s1 ...sK is the hidden alignment or derivation. The models hm (eI1 , sK1 , f1J ) are weighted by the weights λm which are tuned using minimum error rate training (MERT) (Och, 2003). The rest of the section presents two ways to integrate vector representations into the system described above. 4.2 4.3 While the standard phrase table is extracted using parallel training data, we propose to extend it and infer new entries"
W14-4001,J03-1002,1,0.00982394,"if the source paraphrase does not already occur in the phrase table. This ensures that original entries are not interfered with and only OOVs are affected during translation. Reducing OOVs by extending the phrase table has the advantage of exploiting the full decoding capabilities (e.g. LM scoring), as opposed to post-decoding translation of OOVs, which would not exhibit any decoding benefits. Our phrase-based baseline system consists of two phrasal and two lexical translation models, trained using a word-aligned bilingual training corpus. Word alignment is automatically generated by GIZA++ (Och and Ney, 2003) given a sentencealigned bilingual corpus. We also include binary count features and bidirectional hierarchical reordering models (Galley and Manning, 2008), with three orientation classes per direction resulting in six reordering models. The baseline also includes word penalty, phrase penalty and a simple distance-based distortion model. The k-nearest neighbor (k-NN) approach is computationally prohibitive for large phrase tables and large number of vectors. This can be alleviated by resorting to approximate k-NN search (e.g. locality sensitive hashing). Note that this search is performed dur"
W14-4001,P03-1021,0,0.0136458,"exica. Noisy entries are assumed to have a probability less than a certain threshold and are not used to pair word vectors. Phrase-based Machine Translation The phrase-based decoder consists of a search using a log-linear framework (Och and Ney, 2002) as follows: ( ) ˆ eˆI1 = arg max max I,eI1 M ∑ λm hm (eI1 , sK1 , f1J ) K,sK 1 m=1 (2) where eI1 = e1 ...eI is the target sentence, f1J = f1 ... fJ is the source sentence, sK1 = s1 ...sK is the hidden alignment or derivation. The models hm (eI1 , sK1 , f1J ) are weighted by the weights λm which are tuned using minimum error rate training (MERT) (Och, 2003). The rest of the section presents two ways to integrate vector representations into the system described above. 4.2 4.3 While the standard phrase table is extracted using parallel training data, we propose to extend it and infer new entries relying on continuous representations. With a similarity measure (e.g. cosine similarity) that computes the similarity between two phrases, a new phrase pair can be generated by replacing either or both of its constituent phrases by similar phrases. The new phrase is referred to as a paraphrase of the phrase it replaces. This enables a richer use of the bi"
W14-4001,D08-1089,0,\N,Missing
W14-4001,P11-2031,0,\N,Missing
W14-4001,P10-1086,0,\N,Missing
W15-3018,popovic-ney-2006-pos,1,\N,Missing
W15-3018,N04-4026,0,\N,Missing
W15-3018,E03-1076,0,\N,Missing
W15-3018,E99-1010,0,\N,Missing
W15-3018,D08-1089,0,\N,Missing
W15-3018,P12-1031,0,\N,Missing
W15-3018,P02-1040,0,\N,Missing
W15-3018,D13-1138,1,\N,Missing
W15-3018,P10-2041,0,\N,Missing
W15-3018,J92-4003,0,\N,Missing
W15-3018,P10-1049,1,\N,Missing
W15-3018,P11-2031,0,\N,Missing
W15-3018,J03-1002,1,\N,Missing
W15-3018,C12-3061,1,\N,Missing
W15-3018,N12-1005,0,\N,Missing
W15-3018,P03-1021,0,\N,Missing
W15-3018,P14-1129,0,\N,Missing
W15-3018,N15-1175,1,\N,Missing
W15-3033,J93-2003,0,0.079735,"Missing"
W15-3033,2014.iwslt-evaluation.1,0,0.345659,"Missing"
W15-3033,P11-2031,0,0.041135,"d cluster language model (Wuebker et al., 2013) and for comparison, we also experiment with a hierarchical reordering model (HRM) (Galley and Manning, 2008). When integrated into a phrase-based decoder, Durrani et al. (2013b) have shown the OSM to outperform bilingual LMs on MTUs. Therefore, we directly compare ourselves with a 7-gram OSM implemented into our phrasebased decoder as an additional feature. The OSM is trained on the same data as the ETM for all tasks. Bilingual data statistics for all tasks are shown in Table 1. For each system setting we evaluate three MERT runs using multeval (Clark et al., 2011). Results are reported in B LEU (Papineni et al., 2001) and T ER (Snover et al., 2006). The optimization criterion for all experiments is B LEU. 5.1 model # parameters phrase-based translation 57,155,149 EdTM lexicon alignment deletion 35,511,396 19,899,812 15,276,718 334,866 EiTM lexicon alignment deletion 34,994,534 20,153,114 14,791,722 49,698 Table 2: The number of model parameters for the BOLT Arabic→English bilingual training data after filtering. B LEU T ER Baseline + HRM 30.7 49.3 + EiTM Ge↔En none Ge→En Ge↔En 31.4 31.6 31.6 31.8 48.3 48.1 48.2 48.2 + EdTM none Ge↔En Ge→En Ge↔En Table"
W15-3033,H05-1022,0,0.426715,"d version of OSM performs best when integrated into the log-linear framework of a phrase-based decoder. Both the BILM (Stewart et al., 2014) and the OSM (Durrani et al., 2014) can Although our approach is similar, there are the following significant differences: On the one hand, the ETM estimates the probability of single words conditioned on an extended lexical and reordering context, whereas the JTR n-gram model predicts the probability of bilingual word pairs. On the other hand, we do not assume linear sequences of dependencies, but propose and explicit treatment of multiply aligned words. Deng and Byrne (2005) present an HMM approach for word-to-phrase alignments, which performs similar to IBM-4 on the task of bitext alignment and can also be applied for more powerful phrase induction. Feng et al. (2013) introduce an reordering model based on sequence labeling techniques by converting the reordering problem into a a tagging task. Zhang et al. (2013) explore different Markov chain orderings for an n-gram model on MTUs. These are not integrated into decoding, but used in N-best rescoring. Another generative, word-based Markov chain translation model is presented by Feng and Cohn (2013). It exploits 2"
W15-3033,P14-1129,0,0.143344,"Missing"
W15-3033,P11-1105,0,0.074614,"ve been taken to compensate the downside of the phrase translation model. Mari˜no et al. (2006) introduce a translation model based on n-grams of bilingual word pairs, i.e. a bilingual language model (BILM), with an n-gram decoder that requires monotone alignments. In (Niehues et al., 2011), this is further advanced by BILMs operating on non-monotone alignments within a PBT framework. However, this differs from our approach: BILMs treat jointly aligned source words as atomic units, ignore source deletions and do not include reordering context. The Operation Sequence Model (OSM) introduced in (Durrani et al., 2011; Durrani et al., 2013a) includes n-grams of both translation and reordering operations in a consistent framework. It utilizes minimal translation units (MTUs) and is applied in a corresponding OSM decoder. Experiments in (Durrani et al., 2013b) show that a slightly enhanced version of OSM performs best when integrated into the log-linear framework of a phrase-based decoder. Both the BILM (Stewart et al., 2014) and the OSM (Durrani et al., 2014) can Although our approach is similar, there are the following significant differences: On the one hand, the ETM estimates the probability of single wo"
W15-3033,D13-1106,0,0.143354,"k. Zhang et al. (2013) explore different Markov chain orderings for an n-gram model on MTUs. These are not integrated into decoding, but used in N-best rescoring. Another generative, word-based Markov chain translation model is presented by Feng and Cohn (2013). It exploits 283 a hierarchical Pitman-Yor process for smoothing, but is only applied to induce word alignments. Their follow-up work (Feng et al., 2014) introduces a Markov-model on MTUs, similar to the OSM described above. Finally, there has been recent research on applying neural network models for extended context (Le et al., 2012; Auli et al., 2013; Hu et al., 2014; Devlin et al., 2014; Sundermeyer et al., 2014). All of these papers focus on lexical context and ignore the reordering aspect covered in our work. 3 (a) forward Figure 3: Overview of the jump classes ∆ j¯, j . same target position i, there are two possible jump classes: ( → (’step forward’), j = j¯ + 1 ∆ j¯, j = y (’jump forward’), j > j¯ + 1. Extended Translation Models In the following, we depict the derivations of the EiTM and the EdTM. Although they operate in opposite translation directions, both models incorporate the inverted alignment bI1 . Given a source sentence f1"
W15-3033,N13-1001,0,0.401112,"nsate the downside of the phrase translation model. Mari˜no et al. (2006) introduce a translation model based on n-grams of bilingual word pairs, i.e. a bilingual language model (BILM), with an n-gram decoder that requires monotone alignments. In (Niehues et al., 2011), this is further advanced by BILMs operating on non-monotone alignments within a PBT framework. However, this differs from our approach: BILMs treat jointly aligned source words as atomic units, ignore source deletions and do not include reordering context. The Operation Sequence Model (OSM) introduced in (Durrani et al., 2011; Durrani et al., 2013a) includes n-grams of both translation and reordering operations in a consistent framework. It utilizes minimal translation units (MTUs) and is applied in a corresponding OSM decoder. Experiments in (Durrani et al., 2013b) show that a slightly enhanced version of OSM performs best when integrated into the log-linear framework of a phrase-based decoder. Both the BILM (Stewart et al., 2014) and the OSM (Durrani et al., 2014) can Although our approach is similar, there are the following significant differences: On the one hand, the ETM estimates the probability of single words conditioned on an"
W15-3033,J90-2002,0,0.67439,"Missing"
W15-3033,P13-2071,0,0.377167,"nsate the downside of the phrase translation model. Mari˜no et al. (2006) introduce a translation model based on n-grams of bilingual word pairs, i.e. a bilingual language model (BILM), with an n-gram decoder that requires monotone alignments. In (Niehues et al., 2011), this is further advanced by BILMs operating on non-monotone alignments within a PBT framework. However, this differs from our approach: BILMs treat jointly aligned source words as atomic units, ignore source deletions and do not include reordering context. The Operation Sequence Model (OSM) introduced in (Durrani et al., 2011; Durrani et al., 2013a) includes n-grams of both translation and reordering operations in a consistent framework. It utilizes minimal translation units (MTUs) and is applied in a corresponding OSM decoder. Experiments in (Durrani et al., 2013b) show that a slightly enhanced version of OSM performs best when integrated into the log-linear framework of a phrase-based decoder. Both the BILM (Stewart et al., 2014) and the OSM (Durrani et al., 2014) can Although our approach is similar, there are the following significant differences: On the one hand, the ETM estimates the probability of single words conditioned on an"
W15-3033,C14-1041,0,0.108216,"aligned source words as atomic units, ignore source deletions and do not include reordering context. The Operation Sequence Model (OSM) introduced in (Durrani et al., 2011; Durrani et al., 2013a) includes n-grams of both translation and reordering operations in a consistent framework. It utilizes minimal translation units (MTUs) and is applied in a corresponding OSM decoder. Experiments in (Durrani et al., 2013b) show that a slightly enhanced version of OSM performs best when integrated into the log-linear framework of a phrase-based decoder. Both the BILM (Stewart et al., 2014) and the OSM (Durrani et al., 2014) can Although our approach is similar, there are the following significant differences: On the one hand, the ETM estimates the probability of single words conditioned on an extended lexical and reordering context, whereas the JTR n-gram model predicts the probability of bilingual word pairs. On the other hand, we do not assume linear sequences of dependencies, but propose and explicit treatment of multiply aligned words. Deng and Byrne (2005) present an HMM approach for word-to-phrase alignments, which performs similar to IBM-4 on the task of bitext alignment and can also be applied for more p"
W15-3033,J06-4004,0,0.508457,"Missing"
W15-3033,P13-1033,0,0.283899,"ligned words. Deng and Byrne (2005) present an HMM approach for word-to-phrase alignments, which performs similar to IBM-4 on the task of bitext alignment and can also be applied for more powerful phrase induction. Feng et al. (2013) introduce an reordering model based on sequence labeling techniques by converting the reordering problem into a a tagging task. Zhang et al. (2013) explore different Markov chain orderings for an n-gram model on MTUs. These are not integrated into decoding, but used in N-best rescoring. Another generative, word-based Markov chain translation model is presented by Feng and Cohn (2013). It exploits 283 a hierarchical Pitman-Yor process for smoothing, but is only applied to induce word alignments. Their follow-up work (Feng et al., 2014) introduces a Markov-model on MTUs, similar to the OSM described above. Finally, there has been recent research on applying neural network models for extended context (Le et al., 2012; Auli et al., 2013; Hu et al., 2014; Devlin et al., 2014; Sundermeyer et al., 2014). All of these papers focus on lexical context and ignore the reordering aspect covered in our work. 3 (a) forward Figure 3: Overview of the jump classes ∆ j¯, j . same target pos"
W15-3033,P10-2041,0,0.060826,"nt models. The domain of IWSLT consists of lecture-type talks presented at TED conferences which are also available online3 . The baseline systems are trained on all provided bilingual data. All systems are optimized on the dev2010 and evaluated on the test2010 corpus. The ETM is trained on the TED portions of the data: 138K sentences for German→English and 185K sentences for English→French. For German→English, to estimate the 4-gram LM, we additionally make use of parts of the Shuffled News, LDC English Gigaword and 109 French-English corpora, selected by a crossentropy difference criterion (Moore and Lewis, 2010). In total, 1.7 billion running words are taken for LM training. For English→French, we use a large general domain 5-gram LM and an indomain 5-gram LM. Both are estimated with the KenLM toolkit (Heafield et al., 2013) using interpolated Kneser-Ney smoothing. For the general domain LM, we first select 12 of the English Shuffled News, 41 of the French Shuffled News as well as both the English and French Gigaword corpora (10) where sK1 = s1 . . . sK is the hidden phrase alignment. The feature weights λm are tuned with minimum error rate training (MERT) (Och, 2003). The models hm , that are part o"
W15-3033,P13-1032,1,0.751388,"is similar, there are the following significant differences: On the one hand, the ETM estimates the probability of single words conditioned on an extended lexical and reordering context, whereas the JTR n-gram model predicts the probability of bilingual word pairs. On the other hand, we do not assume linear sequences of dependencies, but propose and explicit treatment of multiply aligned words. Deng and Byrne (2005) present an HMM approach for word-to-phrase alignments, which performs similar to IBM-4 on the task of bitext alignment and can also be applied for more powerful phrase induction. Feng et al. (2013) introduce an reordering model based on sequence labeling techniques by converting the reordering problem into a a tagging task. Zhang et al. (2013) explore different Markov chain orderings for an n-gram model on MTUs. These are not integrated into decoding, but used in N-best rescoring. Another generative, word-based Markov chain translation model is presented by Feng and Cohn (2013). It exploits 283 a hierarchical Pitman-Yor process for smoothing, but is only applied to induce word alignments. Their follow-up work (Feng et al., 2014) introduces a Markov-model on MTUs, similar to the OSM desc"
W15-3033,W14-1616,0,0.433103,"nd can also be applied for more powerful phrase induction. Feng et al. (2013) introduce an reordering model based on sequence labeling techniques by converting the reordering problem into a a tagging task. Zhang et al. (2013) explore different Markov chain orderings for an n-gram model on MTUs. These are not integrated into decoding, but used in N-best rescoring. Another generative, word-based Markov chain translation model is presented by Feng and Cohn (2013). It exploits 283 a hierarchical Pitman-Yor process for smoothing, but is only applied to induce word alignments. Their follow-up work (Feng et al., 2014) introduces a Markov-model on MTUs, similar to the OSM described above. Finally, there has been recent research on applying neural network models for extended context (Le et al., 2012; Auli et al., 2013; Hu et al., 2014; Devlin et al., 2014; Sundermeyer et al., 2014). All of these papers focus on lexical context and ignore the reordering aspect covered in our work. 3 (a) forward Figure 3: Overview of the jump classes ∆ j¯, j . same target position i, there are two possible jump classes: ( → (’step forward’), j = j¯ + 1 ∆ j¯, j = y (’jump forward’), j > j¯ + 1. Extended Translation Models In th"
W15-3033,P02-1038,1,0.673185,"Missing"
W15-3033,D08-1089,0,0.113012,"subset of 67.8K sentences and the test set contains 1844 sentences. For the Arabic→English BOLT task, we use only the in-domain data for training the baseline and the ETM. The training and test sets contain text drawn from discussion forums in Egyptian Arabic. The evaluation set contains 1510 bilingual sentence pairs. The baseline systems for all tasks - except the Arabic→English BOLT task, where preliminary experiments showed no improvement - contain a 7-gram word cluster language model (Wuebker et al., 2013) and for comparison, we also experiment with a hierarchical reordering model (HRM) (Galley and Manning, 2008). When integrated into a phrase-based decoder, Durrani et al. (2013b) have shown the OSM to outperform bilingual LMs on MTUs. Therefore, we directly compare ourselves with a 7-gram OSM implemented into our phrasebased decoder as an additional feature. The OSM is trained on the same data as the ETM for all tasks. Bilingual data statistics for all tasks are shown in Table 1. For each system setting we evaluate three MERT runs using multeval (Clark et al., 2011). Results are reported in B LEU (Papineni et al., 2001) and T ER (Snover et al., 2006). The optimization criterion for all experiments is"
W15-3033,J03-1002,1,0.0268062,"e EdTM deletion model approximates the probability of e0 conditioned on all unaligned source words fb0 and is obtained by averaging over all unaligned source words: p(e0 |fbb0I ) = 3.2.2 ∑ j∈b0 Count Models and Smoothing So far, we have introduced the ETM and shown how to include unaligned words and multiple word dependencies. However, there are various possibilities to train the lexicon and alignment probabilities derived in Subsections 3.1 and 3.2. As a starting point, we apply relative frequencies obtained from bilingual training data, where the Viterbi alignment is estimated using GIZA++ (Och and Ney, 2003). In order to address data sparseness, we apply interpolated Kneser-Ney smoothing as described in (Chen and Goodman, 1998). In comparison to monolingual n-grams used in LMs, we lack any clear order of e, f , e0 , f 0 and ∆, since they include bilingual and reordering information. Similar to the approach taken by Mari˜no et al. (2006), we model the probability of the bilingual word pair (e, f ) given its predecessor (e0 , f 0 , ∆) which also includes the jump class. The EdTM lexicon model for dependencies on previously aligned target words is computed as alignment probability The direct probabi"
W15-3033,J04-4002,1,0.620968,"ining data of the IWSLT 2014 German→English, English→French and the DARPA BOLT Chinese→English, Arabic→English translation tasks. 4 Integration into Phrase-based Decoding therefore leads to a larger search space, in practice it does not degrade the search accuracy, as experiments with relaxed pruning parameters have shown. In this work, we apply a standard phrase-based translation system (Koehn et al., 2003). The decoding process is implemented as a beam search for the best translation given a set of models hm (eI1 , sK1 , f1J ). The goal of search is to maximize the log-linear feature score (Och and Ney, 2004): ( ) ˆ eˆI1 = arg max I,eI1 ,sK 1 M ∑ λm hm (eI1 , sK1 , f1J ) m=1 , 5 Evaluation We perform experiments on the largescale IWSLT 20142 (Cettolo et al., 2014) German→English, English→French and the large-scale DARPA BOLT Chinese→English, Arabic→English tasks. As mentioned in Section 4, all baseline systems include phrasal and lexical smoothing scores trained in both directions. Word alignments are trained with GIZA++, by sequentially running 5 iterations each for the IBM-1, HMM and IBM-4 alignment models. The domain of IWSLT consists of lecture-type talks presented at TED conferences which are"
W15-3033,D15-1165,1,0.333454,"e use of reordering gaps, i.e. it utilizes a simpler reordering approach. The OSM uses one joint model for reorderings and translations. In contrast, the ETM incorporates separate models to estimate the probability of words and the probability of reorderings. Furthermore, the OSM has the drawback that it extracts the MTUs sentencewise, thus one word can appear in several MTUs extracted from different sentence pairs. Since an MTUs is treated as an atomic unit, this results in a distribution of probability mass on overlapping events. The ETM overcomes this drawback by operating on single words. Guta et al. (2015) propose the conversion of bilingual sentence pairs and word alignments into joint translation and reordering (JTR) sequences. They investigate n-gram models with modified Kneser-Ney smoothing, feed-forward and recurrent neural networks trained on JTR sequences. In comparison to the OSM, JTR models have smaller vocabulary sizes, as they operate on words, and incorporate simpler reordering structures. Nevertheless, they are shown to perform slightly better than the OSM when included into the log-linear framework of a phrase-based decoder. Previous Work Various approaches have been taken to comp"
W15-3033,W99-0604,1,0.821917,"Missing"
W15-3033,P13-2121,0,0.133495,"Missing"
W15-3033,P03-1021,0,0.0276926,"ifference criterion (Moore and Lewis, 2010). In total, 1.7 billion running words are taken for LM training. For English→French, we use a large general domain 5-gram LM and an indomain 5-gram LM. Both are estimated with the KenLM toolkit (Heafield et al., 2013) using interpolated Kneser-Ney smoothing. For the general domain LM, we first select 12 of the English Shuffled News, 41 of the French Shuffled News as well as both the English and French Gigaword corpora (10) where sK1 = s1 . . . sK is the hidden phrase alignment. The feature weights λm are tuned with minimum error rate training (MERT) (Och, 2003). The models hm , that are part of all baselines presented in this work, are phrasal and lexical translation scores in both directions, an n-gram LM, a simple distance-based distortion model and word and phrase penalties. All phrase pairs that are licensed by the word alignment are extracted from the training corpus and their probabilities estimated as relative frequencies. Moreover, the word alignment each phrase pair has been extracted from is memorized in the phrase table. Our extended translation models are integrated into this framework as additional features hm . They are trained in both"
W15-3033,E14-1003,0,0.361425,"13) explore different Markov chain orderings for an n-gram model on MTUs. These are not integrated into decoding, but used in N-best rescoring. Another generative, word-based Markov chain translation model is presented by Feng and Cohn (2013). It exploits 283 a hierarchical Pitman-Yor process for smoothing, but is only applied to induce word alignments. Their follow-up work (Feng et al., 2014) introduces a Markov-model on MTUs, similar to the OSM described above. Finally, there has been recent research on applying neural network models for extended context (Le et al., 2012; Auli et al., 2013; Hu et al., 2014; Devlin et al., 2014; Sundermeyer et al., 2014). All of these papers focus on lexical context and ignore the reordering aspect covered in our work. 3 (a) forward Figure 3: Overview of the jump classes ∆ j¯, j . same target position i, there are two possible jump classes: ( → (’step forward’), j = j¯ + 1 ∆ j¯, j = y (’jump forward’), j > j¯ + 1. Extended Translation Models In the following, we depict the derivations of the EiTM and the EdTM. Although they operate in opposite translation directions, both models incorporate the inverted alignment bI1 . Given a source sentence f1J and its transla"
W15-3033,2001.mtsummit-papers.68,0,0.0602704,"for comparison, we also experiment with a hierarchical reordering model (HRM) (Galley and Manning, 2008). When integrated into a phrase-based decoder, Durrani et al. (2013b) have shown the OSM to outperform bilingual LMs on MTUs. Therefore, we directly compare ourselves with a 7-gram OSM implemented into our phrasebased decoder as an additional feature. The OSM is trained on the same data as the ETM for all tasks. Bilingual data statistics for all tasks are shown in Table 1. For each system setting we evaluate three MERT runs using multeval (Clark et al., 2011). Results are reported in B LEU (Papineni et al., 2001) and T ER (Snover et al., 2006). The optimization criterion for all experiments is B LEU. 5.1 model # parameters phrase-based translation 57,155,149 EdTM lexicon alignment deletion 35,511,396 19,899,812 15,276,718 334,866 EiTM lexicon alignment deletion 34,994,534 20,153,114 14,791,722 49,698 Table 2: The number of model parameters for the BOLT Arabic→English bilingual training data after filtering. B LEU T ER Baseline + HRM 30.7 49.3 + EiTM Ge↔En none Ge→En Ge↔En 31.4 31.6 31.6 31.8 48.3 48.1 48.2 48.2 + EdTM none Ge↔En Ge→En Ge↔En Table 3: Results for the German→English IWSLT data. The syste"
W15-3033,2006.amta-papers.25,0,0.0333176,"t with a hierarchical reordering model (HRM) (Galley and Manning, 2008). When integrated into a phrase-based decoder, Durrani et al. (2013b) have shown the OSM to outperform bilingual LMs on MTUs. Therefore, we directly compare ourselves with a 7-gram OSM implemented into our phrasebased decoder as an additional feature. The OSM is trained on the same data as the ETM for all tasks. Bilingual data statistics for all tasks are shown in Table 1. For each system setting we evaluate three MERT runs using multeval (Clark et al., 2011). Results are reported in B LEU (Papineni et al., 2001) and T ER (Snover et al., 2006). The optimization criterion for all experiments is B LEU. 5.1 model # parameters phrase-based translation 57,155,149 EdTM lexicon alignment deletion 35,511,396 19,899,812 15,276,718 334,866 EiTM lexicon alignment deletion 34,994,534 20,153,114 14,791,722 49,698 Table 2: The number of model parameters for the BOLT Arabic→English bilingual training data after filtering. B LEU T ER Baseline + HRM 30.7 49.3 + EiTM Ge↔En none Ge→En Ge↔En 31.4 31.6 31.6 31.8 48.3 48.1 48.2 48.2 + EdTM none Ge↔En Ge→En Ge↔En Table 3: Results for the German→English IWSLT data. The systems are optimized with MERT on t"
W15-3033,2014.amta-researchers.3,0,0.482182,"m our approach: BILMs treat jointly aligned source words as atomic units, ignore source deletions and do not include reordering context. The Operation Sequence Model (OSM) introduced in (Durrani et al., 2011; Durrani et al., 2013a) includes n-grams of both translation and reordering operations in a consistent framework. It utilizes minimal translation units (MTUs) and is applied in a corresponding OSM decoder. Experiments in (Durrani et al., 2013b) show that a slightly enhanced version of OSM performs best when integrated into the log-linear framework of a phrase-based decoder. Both the BILM (Stewart et al., 2014) and the OSM (Durrani et al., 2014) can Although our approach is similar, there are the following significant differences: On the one hand, the ETM estimates the probability of single words conditioned on an extended lexical and reordering context, whereas the JTR n-gram model predicts the probability of bilingual word pairs. On the other hand, we do not assume linear sequences of dependencies, but propose and explicit treatment of multiply aligned words. Deng and Byrne (2005) present an HMM approach for word-to-phrase alignments, which performs similar to IBM-4 on the task of bitext alignment"
W15-3033,D14-1003,1,0.866615,"erings for an n-gram model on MTUs. These are not integrated into decoding, but used in N-best rescoring. Another generative, word-based Markov chain translation model is presented by Feng and Cohn (2013). It exploits 283 a hierarchical Pitman-Yor process for smoothing, but is only applied to induce word alignments. Their follow-up work (Feng et al., 2014) introduces a Markov-model on MTUs, similar to the OSM described above. Finally, there has been recent research on applying neural network models for extended context (Le et al., 2012; Auli et al., 2013; Hu et al., 2014; Devlin et al., 2014; Sundermeyer et al., 2014). All of these papers focus on lexical context and ignore the reordering aspect covered in our work. 3 (a) forward Figure 3: Overview of the jump classes ∆ j¯, j . same target position i, there are two possible jump classes: ( → (’step forward’), j = j¯ + 1 ∆ j¯, j = y (’jump forward’), j > j¯ + 1. Extended Translation Models In the following, we depict the derivations of the EiTM and the EdTM. Although they operate in opposite translation directions, both models incorporate the inverted alignment bI1 . Given a source sentence f1J and its translation eI1 , EiTM models the inverse probability p"
W15-3033,D13-1138,1,0.880176,"sentence pairs and the 5-gram LM on 2.9 billion running words in total. The ETM is trained on an indomain subset of 67.8K sentences and the test set contains 1844 sentences. For the Arabic→English BOLT task, we use only the in-domain data for training the baseline and the ETM. The training and test sets contain text drawn from discussion forums in Egyptian Arabic. The evaluation set contains 1510 bilingual sentence pairs. The baseline systems for all tasks - except the Arabic→English BOLT task, where preliminary experiments showed no improvement - contain a 7-gram word cluster language model (Wuebker et al., 2013) and for comparison, we also experiment with a hierarchical reordering model (HRM) (Galley and Manning, 2008). When integrated into a phrase-based decoder, Durrani et al. (2013b) have shown the OSM to outperform bilingual LMs on MTUs. Therefore, we directly compare ourselves with a 7-gram OSM implemented into our phrasebased decoder as an additional feature. The OSM is trained on the same data as the ETM for all tasks. Bilingual data statistics for all tasks are shown in Table 1. For each system setting we evaluate three MERT runs using multeval (Clark et al., 2011). Results are reported in B"
W15-3033,2002.tmi-tutorials.2,0,0.219139,"Missing"
W15-3033,N13-1002,0,0.173239,"extended lexical and reordering context, whereas the JTR n-gram model predicts the probability of bilingual word pairs. On the other hand, we do not assume linear sequences of dependencies, but propose and explicit treatment of multiply aligned words. Deng and Byrne (2005) present an HMM approach for word-to-phrase alignments, which performs similar to IBM-4 on the task of bitext alignment and can also be applied for more powerful phrase induction. Feng et al. (2013) introduce an reordering model based on sequence labeling techniques by converting the reordering problem into a a tagging task. Zhang et al. (2013) explore different Markov chain orderings for an n-gram model on MTUs. These are not integrated into decoding, but used in N-best rescoring. Another generative, word-based Markov chain translation model is presented by Feng and Cohn (2013). It exploits 283 a hierarchical Pitman-Yor process for smoothing, but is only applied to induce word alignments. Their follow-up work (Feng et al., 2014) introduces a Markov-model on MTUs, similar to the OSM described above. Finally, there has been recent research on applying neural network models for extended context (Le et al., 2012; Auli et al., 2013; Hu"
W15-3033,P02-1040,0,\N,Missing
W15-3033,N03-1017,0,\N,Missing
W15-3033,C12-3061,1,\N,Missing
W15-3033,N12-1005,0,\N,Missing
W15-3033,P14-2023,0,\N,Missing
W15-3034,P14-2023,0,0.117028,"d networks in rescoring. Given the success of feedforward translation models in phrase-based decoding, it is natural to ask how RNN translation models perform if they are integrated in decoding. This paper investigates the performance of RNN language and translation models in phrasebased decoding. For RNNs that depend on an unbounded target context, their integration into a phrase-based decoder employing beam search requires relaxing the pruning parameters, which makes translation inefficient. Therefore, we apply approximations to integrate RNN translation models during phrase-based decoding. Auli and Gao (2014) use approximate scoring to integrate This work explores the application of recurrent neural network (RNN) language and translation models during phrasebased decoding. Due to their use of unbounded context, the decoder integration of RNNs is more challenging compared to the integration of feedforward neural models. In this paper, we apply approximations and use caching to enable RNN decoder integration, while requiring reasonable memory and time resources. We analyze the effect of caching on translation quality and speed, and use it to integrate RNN language and translation models into a phras"
W15-3034,D13-1106,0,0.148693,"number of nodes in the search graph, which in turn leads to reducing the variance between the hypotheses lying within the beam, and focusing the decoding effort on hypotheses that are similar to each other. Since the RNN LM computes a hidden state h(e1i−1 ) encoding the sequence ei−1 1 , another way is to extend the search state of the node to (C, e˜, j, h(ei−1 1 )). However, such extension would pose the same problem for recombination as the one encountered if the full history sequence is stored. Therefore, we resort to approximate RNN LM evaluation in decoding. An approximation proposed in (Auli et al., 2013) is to extend the search node with the RNN hidden state, but to ignore the hidden state when deciding which nodes to recombine. That is, two search nodes are deemed equivalent if they share the same triple (C, e˜, j), even if they have different RNN hidden states. Upon recombination, one of the two hidden states is kept and stored in the resulting recombined node. RNN translation model in Section 4.2 with minor changes. First, we will briefly introduce the RNN LM. The LM probability p(ei |ei−1 1 ) of the target word ei at position i depends on the unbounded target history ei−1 1 . The probabil"
W15-3034,P11-2031,0,0.236944,"Missing"
W15-3034,P14-1129,0,0.159377,"Missing"
W15-3034,D08-1089,0,0.351748,"Missing"
W15-3034,D15-1165,1,0.843143,"can be integrated efficiently without the need for approximations. We compare decoding using RNNs to rescoring n-best lists on two tasks: IWSLT 2013 German→English, and BOLT Arabic→English. We demonstrate that the performance of decoding with RNNs is at least as good as using them in rescoring. 1 Introduction Applying neural networks to statistical machine translation has been gaining increasing attention recently. Neural network language and translation models have been successfully applied to rescore the first-pass decoding output (Le et al., 2012; Sundermeyer et al., 2014; Hu et al., 2014; Guta et al., 2015). These models include feedforward and recurrent neural networks. A more ambitious move is to apply neural networks directly during decoding, which in principle 294 Proceedings of the Tenth Workshop on Statistical Machine Translation, pages 294–303, c Lisboa, Portugal, 17-18 September 2015. 2015 Association for Computational Linguistics. stead of the usual cross-entropy. They train recurrent neural LMs without the need to normalize the output layer, but training becomes computationally more expensive as each training example is an n-best list instead of a sentence. At decoding time, however, s"
W15-3034,W12-2703,0,0.0338501,"f millions of partial hypotheses. Scoring such a number of hypotheses using neural models is expensive, mainly due to the usually large output layer. Nevertheless, decoder integration has been done in (Vaswani et al., 2013) for feedforward neural language models. Devlin et al. (2014) integrate feedforward translation models into phrase-based decoding reporting major improvements, which highlight the strength of the underlying models. In related fields like e. g. language modeling, RNNs has been shown to perform considerably better than standard feedforward architectures (Mikolov et al., 2011; Arisoy et al., 2012; Sundermeyer et al., 2013; Liu et al., 2014). Sundermeyer et al. (2014) also show that RNN translation models outperform feedforward networks in rescoring. Given the success of feedforward translation models in phrase-based decoding, it is natural to ask how RNN translation models perform if they are integrated in decoding. This paper investigates the performance of RNN language and translation models in phrasebased decoding. For RNNs that depend on an unbounded target context, their integration into a phrase-based decoder employing beam search requires relaxing the pruning parameters, which"
W15-3034,E14-1003,0,0.324754,"at a special RNN can be integrated efficiently without the need for approximations. We compare decoding using RNNs to rescoring n-best lists on two tasks: IWSLT 2013 German→English, and BOLT Arabic→English. We demonstrate that the performance of decoding with RNNs is at least as good as using them in rescoring. 1 Introduction Applying neural networks to statistical machine translation has been gaining increasing attention recently. Neural network language and translation models have been successfully applied to rescore the first-pass decoding output (Le et al., 2012; Sundermeyer et al., 2014; Hu et al., 2014; Guta et al., 2015). These models include feedforward and recurrent neural networks. A more ambitious move is to apply neural networks directly during decoding, which in principle 294 Proceedings of the Tenth Workshop on Statistical Machine Translation, pages 294–303, c Lisboa, Portugal, 17-18 September 2015. 2015 Association for Computational Linguistics. stead of the usual cross-entropy. They train recurrent neural LMs without the need to normalize the output layer, but training becomes computationally more expensive as each training example is an n-best list instead of a sentence. At decod"
W15-3034,C12-2104,0,0.114976,"n models that were introduced in (Sundermeyer et al., 2014), due to their success in rescoring nbest lists. The rest of this paper is structured as follows. In Section 2 we review the related work. The RNN LM integration and caching strategies are discussed in Section 3, while Section 4 discusses the integration of exact and approximate RNN translation models. We analyze the effect of approximation and caching on translation quality and speed in Section 5. The section also includes the translation experiments comparing decoding vs. rescoring. Finally we conclude with Section 6. 2 Related Work Schwenk (2012) proposed a feedforward network that predicts phrases of a fixed maximum length, such that all phrase words are predicted at once. The prediction is conditioned on the source phrase. The model was used to compute additional phrase table scores, and the phrase table was used for decoding. No major difference was reported compared to rescoring using the model. Our work focuses on neural network scoring performed online during decoding, capturing dependencies that extend beyond phrase boundaries. Online usage of neural networks during decoding requires tackling the costly output normalization ste"
W15-3034,2006.amta-papers.25,0,0.0642062,"Missing"
W15-3034,N03-1017,0,0.0831576,"Missing"
W15-3034,N12-1005,0,0.0722926,"into phrase-based decoding. We also show that a special RNN can be integrated efficiently without the need for approximations. We compare decoding using RNNs to rescoring n-best lists on two tasks: IWSLT 2013 German→English, and BOLT Arabic→English. We demonstrate that the performance of decoding with RNNs is at least as good as using them in rescoring. 1 Introduction Applying neural networks to statistical machine translation has been gaining increasing attention recently. Neural network language and translation models have been successfully applied to rescore the first-pass decoding output (Le et al., 2012; Sundermeyer et al., 2014; Hu et al., 2014; Guta et al., 2015). These models include feedforward and recurrent neural networks. A more ambitious move is to apply neural networks directly during decoding, which in principle 294 Proceedings of the Tenth Workshop on Statistical Machine Translation, pages 294–303, c Lisboa, Portugal, 17-18 September 2015. 2015 Association for Computational Linguistics. stead of the usual cross-entropy. They train recurrent neural LMs without the need to normalize the output layer, but training becomes computationally more expensive as each training example is an"
W15-3034,D14-1003,1,0.452753,"ses using neural models is expensive, mainly due to the usually large output layer. Nevertheless, decoder integration has been done in (Vaswani et al., 2013) for feedforward neural language models. Devlin et al. (2014) integrate feedforward translation models into phrase-based decoding reporting major improvements, which highlight the strength of the underlying models. In related fields like e. g. language modeling, RNNs has been shown to perform considerably better than standard feedforward architectures (Mikolov et al., 2011; Arisoy et al., 2012; Sundermeyer et al., 2013; Liu et al., 2014). Sundermeyer et al. (2014) also show that RNN translation models outperform feedforward networks in rescoring. Given the success of feedforward translation models in phrase-based decoding, it is natural to ask how RNN translation models perform if they are integrated in decoding. This paper investigates the performance of RNN language and translation models in phrasebased decoding. For RNNs that depend on an unbounded target context, their integration into a phrase-based decoder employing beam search requires relaxing the pruning parameters, which makes translation inefficient. Therefore, we apply approximations to int"
W15-3034,P10-2041,0,0.0511,"Missing"
W15-3034,D13-1140,0,0.166833,"g and reranking fixed nbest lists. Recently, neural networks were used for standalone decoding using a simple beam-search word-based decoder (Sutskever et al., 2014; Bahdanau et al., 2015). Another approach is to apply neural models directly in a phrase-based decoder. We focus on this approach, which is challenging since phrase-based decoding typically involves generating tens or even hundreds of millions of partial hypotheses. Scoring such a number of hypotheses using neural models is expensive, mainly due to the usually large output layer. Nevertheless, decoder integration has been done in (Vaswani et al., 2013) for feedforward neural language models. Devlin et al. (2014) integrate feedforward translation models into phrase-based decoding reporting major improvements, which highlight the strength of the underlying models. In related fields like e. g. language modeling, RNNs has been shown to perform considerably better than standard feedforward architectures (Mikolov et al., 2011; Arisoy et al., 2012; Sundermeyer et al., 2013; Liu et al., 2014). Sundermeyer et al. (2014) also show that RNN translation models outperform feedforward networks in rescoring. Given the success of feedforward translation mo"
W15-3034,D13-1138,1,0.853909,"Missing"
W15-3034,P03-1021,0,0.0199939,"Missing"
W15-3034,P02-1040,0,0.0911051,"Missing"
W15-3034,W10-1738,1,\N,Missing
W15-3060,E06-1005,1,\N,Missing
W15-3060,E99-1010,0,\N,Missing
W15-3060,D08-1088,1,\N,Missing
W15-3060,P02-1040,0,\N,Missing
W15-3060,P04-1077,0,\N,Missing
W15-3060,P08-2021,0,\N,Missing
W15-3060,W12-3140,1,\N,Missing
W15-3060,N07-2017,1,\N,Missing
W15-3060,E14-2008,1,\N,Missing
W15-3060,N07-1029,0,\N,Missing
W15-3060,J97-3002,0,\N,Missing
W15-3060,D08-1011,0,\N,Missing
W15-3060,W04-3250,0,\N,Missing
W15-3060,W14-3310,1,\N,Missing
W15-3060,N12-1005,0,\N,Missing
W15-3060,W13-2223,1,\N,Missing
W16-2206,W14-4001,1,0.798869,"duced an attention mechanism to the encoder-decoder approach, allowing the decoder to attend to certain source words. This method was refined in (Luong et al., 2015) to allow for local attention, which makes the decoder attend to representations of source words residing within a window. These translation models have shown competitive results, outperforming phrase-based systems when using ensembles on Schwenk (2012) proposed a feed-forward network that computes phrase scores offline, and the scores were added to the phrase table of a phrasebased system. Offline phrase scoring was also done in (Alkhouli et al., 2014) using semantic phrase features obtained using simple neural networks. In comparison, our work does not rely on the phrase-based system, rather, the neural net55 4 works are used to hypothesize translation candidates directly, and the scores are computed online during decoding. We use the feed-forward joint model introduced in (Devlin et al., 2014) as a lexical model, and introduce a lexicalized alignment model based on it. In addition, we modify the bidirectional joint model presented in (Sundermeyer et al., 2014a) and compare it to the feed-forward variant. These lexical models were applied"
W16-2206,W15-3034,1,0.746185,"Missing"
W16-2206,D15-1165,1,0.812485,"tperforms attention-based NMT on two tasks: IWSLT 2013 German→English and BOLT Chinese→English. We also show promising results for re-aligning the training data using neural models. 1 Introduction Neural networks have been gaining a lot of attention recently in areas like speech recognition, image recognition and natural language processing. In machine translation, NNs are applied in two main ways: In N -best rescoring, the neural model is used to score the first-pass decoding output, limiting the model to a fixed set of hypotheses (Le et al., 2012; Sundermeyer et al., 2014a; Hu et al., 2014; Guta et al., 2015). The second approach integrates the NN into decoding, potentially allowing it to directly determine the search space. There are two approaches to use neural models in decoding. The first integrates the mod54 Proceedings of the First Conference on Machine Translation, Volume 1: Research Papers, pages 54–65, c Berlin, Germany, August 11-12, 2016. 2016 Association for Computational Linguistics tasks like IWSLT English→German 2015 (Luong and Manning, 2015). models on the IWSLT 2013 German→English and BOLT Chinese→English task. 1.1 In this work, we follow the same standalone neural translation app"
W16-2206,E14-1003,0,0.0187792,"hat our system outperforms attention-based NMT on two tasks: IWSLT 2013 German→English and BOLT Chinese→English. We also show promising results for re-aligning the training data using neural models. 1 Introduction Neural networks have been gaining a lot of attention recently in areas like speech recognition, image recognition and natural language processing. In machine translation, NNs are applied in two main ways: In N -best rescoring, the neural model is used to score the first-pass decoding output, limiting the model to a fixed set of hypotheses (Le et al., 2012; Sundermeyer et al., 2014a; Hu et al., 2014; Guta et al., 2015). The second approach integrates the NN into decoding, potentially allowing it to directly determine the search space. There are two approaches to use neural models in decoding. The first integrates the mod54 Proceedings of the First Conference on Machine Translation, Volume 1: Research Papers, pages 54–65, c Berlin, Germany, August 11-12, 2016. 2016 Association for Computational Linguistics tasks like IWSLT English→German 2015 (Luong and Manning, 2015). models on the IWSLT 2013 German→English and BOLT Chinese→English task. 1.1 In this work, we follow the same standalone ne"
W16-2206,P15-1001,0,0.0248365,"In addition, we modify the bidirectional joint model presented in (Sundermeyer et al., 2014a) and compare it to the feed-forward variant. These lexical models were applied in phrase-based systems. In this work, we apply them in a standalone NMT framework. Forced alignment was applied to train phrase tables in (Wuebker et al., 2010; Peitz et al., 2012). We generate forced alignments using a neural decoder, and use them to re-train neural models. Tackling the costly normalization of the output layer during decoding has been the focus of several papers (Vaswani et al., 2013; Devlin et al., 2014; Jean et al., 2015). We propose a simple method to speed up decoding using a classfactored output layer with almost no loss in translation quality. 3 There are two common network architectures used in machine translation: feed-forward NNs (FFNN) and recurrent NNs (RNN). In this section we will discuss alignment-based feed-forward and recurrent neural networks. These networks are conditioned on the word alignment, in addition to the source and target words. 4.1 ˆ bi +m ) p(ei |bi1 , e1i−1 , f1J ) = p(ei |ei−1 i−n , fˆ bi −m Statistical Machine Translation ˆ source words fˆbi +m = fˆbi −m , ..., fˆbi+m centered bi"
W16-2206,D14-1179,0,0.0193239,"Missing"
W16-2206,P11-2031,0,0.0286513,"Missing"
W16-2206,N03-1017,0,0.0454637,"→English task. The corpora statistics are shown in Table 1. The IWSLT phrase-based baseline system is trained on all available bilingual data, and uses a 4-gram LM with modified Kneser-Ney smoothing (Kneser and Ney, 1995; Chen and Goodman, 1998), trained with the SRILM toolkit (Stolcke, 2002). As additional data sources for the LM, we selected parts of the Shuffled News and LDC English Gigaword corpora based on the cross-entropy difference (Moore and Lewis, 2010), resulting in a total of 1.7 billion running words for LM training. The phrase-based baseline is a standard phrasebased SMT system (Koehn et al., 2003) tuned with MERT (Och, 2003) and contains a hierarchical reordering model (Galley and Manning, 2008). The in-domain data consists of 137K sentences. The BOLT Chinese→English task is evaluated on the “discussion forum” domain. We use a 5gram LM trained on 2.9 billion running words in total. The in-domain data consists of a subset of 67.8K sentences. We used a set of 1845 sentences as a tune set. The evaluation set test1 contains 1844 and test2 contains 1124 sentences. We use the FFNN architecture for the lexical and alignment models. Both models use a window of 9 source words, and 5 target hist"
W16-2206,N12-1005,0,0.0600393,"s alignments during search. We demonstrate that our system outperforms attention-based NMT on two tasks: IWSLT 2013 German→English and BOLT Chinese→English. We also show promising results for re-aligning the training data using neural models. 1 Introduction Neural networks have been gaining a lot of attention recently in areas like speech recognition, image recognition and natural language processing. In machine translation, NNs are applied in two main ways: In N -best rescoring, the neural model is used to score the first-pass decoding output, limiting the model to a fixed set of hypotheses (Le et al., 2012; Sundermeyer et al., 2014a; Hu et al., 2014; Guta et al., 2015). The second approach integrates the NN into decoding, potentially allowing it to directly determine the search space. There are two approaches to use neural models in decoding. The first integrates the mod54 Proceedings of the First Conference on Machine Translation, Volume 1: Research Papers, pages 54–65, c Berlin, Germany, August 11-12, 2016. 2016 Association for Computational Linguistics tasks like IWSLT English→German 2015 (Luong and Manning, 2015). models on the IWSLT 2013 German→English and BOLT Chinese→English task. 1.1 In"
W16-2206,2015.iwslt-evaluation.11,0,0.149006,"score the first-pass decoding output, limiting the model to a fixed set of hypotheses (Le et al., 2012; Sundermeyer et al., 2014a; Hu et al., 2014; Guta et al., 2015). The second approach integrates the NN into decoding, potentially allowing it to directly determine the search space. There are two approaches to use neural models in decoding. The first integrates the mod54 Proceedings of the First Conference on Machine Translation, Volume 1: Research Papers, pages 54–65, c Berlin, Germany, August 11-12, 2016. 2016 Association for Computational Linguistics tasks like IWSLT English→German 2015 (Luong and Manning, 2015). models on the IWSLT 2013 German→English and BOLT Chinese→English task. 1.1 In this work, we follow the same standalone neural translation approach. However, we have a different treatment of alignments. While the attention-based soft-alignment model computes an alignment distribution as an intermediate step within the neural model, we follow the hard alignment concept used in phrase extraction. We separate the alignment model from the lexical model, and train them independently. At translation time, the decoder hypothesizes and scores the alignment path in addition to the translation. Motivat"
W16-2206,P14-1129,0,0.0333798,"Missing"
W16-2206,D15-1166,0,0.220087,"first-pass decoding output, limiting the model to a fixed set of hypotheses (Le et al., 2012; Sundermeyer et al., 2014a; Hu et al., 2014; Guta et al., 2015). The second approach integrates the NN into decoding, potentially allowing it to directly determine the search space. There are two approaches to use neural models in decoding. The first integrates the mod54 Proceedings of the First Conference on Machine Translation, Volume 1: Research Papers, pages 54–65, c Berlin, Germany, August 11-12, 2016. 2016 Association for Computational Linguistics tasks like IWSLT English→German 2015 (Luong and Manning, 2015). models on the IWSLT 2013 German→English and BOLT Chinese→English task. 1.1 In this work, we follow the same standalone neural translation approach. However, we have a different treatment of alignments. While the attention-based soft-alignment model computes an alignment distribution as an intermediate step within the neural model, we follow the hard alignment concept used in phrase extraction. We separate the alignment model from the lexical model, and train them independently. At translation time, the decoder hypothesizes and scores the alignment path in addition to the translation. Motivat"
W16-2206,D08-1089,0,0.0613501,"stem is trained on all available bilingual data, and uses a 4-gram LM with modified Kneser-Ney smoothing (Kneser and Ney, 1995; Chen and Goodman, 1998), trained with the SRILM toolkit (Stolcke, 2002). As additional data sources for the LM, we selected parts of the Shuffled News and LDC English Gigaword corpora based on the cross-entropy difference (Moore and Lewis, 2010), resulting in a total of 1.7 billion running words for LM training. The phrase-based baseline is a standard phrasebased SMT system (Koehn et al., 2003) tuned with MERT (Och, 2003) and contains a hierarchical reordering model (Galley and Manning, 2008). The in-domain data consists of 137K sentences. The BOLT Chinese→English task is evaluated on the “discussion forum” domain. We use a 5gram LM trained on 2.9 billion running words in total. The in-domain data consists of a subset of 67.8K sentences. We used a set of 1845 sentences as a tune set. The evaluation set test1 contains 1844 and test2 contains 1124 sentences. We use the FFNN architecture for the lexical and alignment models. Both models use a window of 9 source words, and 5 target history words. Both models use two hidden layers, the first has 1000 units and the second has 500 units."
W16-2206,P10-2041,0,0.0121809,"orpora and NN statistics. 7 Experiments We carry out experiments on two tasks: the IWSLT 2013 German→English shared translation task,1 and the BOLT Chinese→English task. The corpora statistics are shown in Table 1. The IWSLT phrase-based baseline system is trained on all available bilingual data, and uses a 4-gram LM with modified Kneser-Ney smoothing (Kneser and Ney, 1995; Chen and Goodman, 1998), trained with the SRILM toolkit (Stolcke, 2002). As additional data sources for the LM, we selected parts of the Shuffled News and LDC English Gigaword corpora based on the cross-entropy difference (Moore and Lewis, 2010), resulting in a total of 1.7 billion running words for LM training. The phrase-based baseline is a standard phrasebased SMT system (Koehn et al., 2003) tuned with MERT (Och, 2003) and contains a hierarchical reordering model (Galley and Manning, 2008). The in-domain data consists of 137K sentences. The BOLT Chinese→English task is evaluated on the “discussion forum” domain. We use a 5gram LM trained on 2.9 billion running words in total. The in-domain data consists of a subset of 67.8K sentences. We used a set of 1845 sentences as a tune set. The evaluation set test1 contains 1844 and test2 c"
W16-2206,P03-1021,0,0.0607309,"search space is composed of both alignment and translation decisions. In contrast, the search space in attention-based decoding is composed of translation decisions only. We embed the models in a log-linear framework, which is commonly used in phrase-based systems. The goal of the decoder is to find the best scoring hypothesis as follows. ) ( M X J I ˆI Iˆ λm hm (f , e , b ) eˆ = arg max max 1 I,eI1 ˆbI 1 1 1 1 m=1 where λm is the model weight associated with the model hm , and M is the total number of models. The model weights are automatically tuned using minimum error rate training (MERT) (Och, 2003). Our main system includes a lexical neural model, an alignment neural model, and a word penalty, which is the count of target words. The word penalty becomes important at the end of translation, where hypotheses in the beam might have different final lengths. 6 Forced-Alignment Training Since the models we use require alignments for training, we initially use word alignments produced using HMM/IBM models using GIZA++ as initial alignments. At first, the FFJM and the FFAM are trained separately until convergence, then the models are used to generate new word alignments by force-decoding the tr"
W16-2206,P14-1138,0,0.091353,"alignment model has a first-order dependence that takes place at the input and output of the model, rather than an architectural modification of the neural network. Yang et al. (2013) use NN-based lexical and alignment models, but they give up the probabilistic interpretation and produce unnormalized scores instead. Furthermore, they model alignments using a simple distortion model that has no dependence on lexical context. The models are used to produce new alignments which are in turn used to train phrase systems. This leads to no significant difference in terms of translation performance. Tamura et al. (2014) propose a lexicalized RNN alignment model. The model still produces non-probabilistic scores, and is used to generate word alignments used to train phrase-based systems. In this work, we develop a feed-forward neural alignment model that computes probabilistic scores, and use it directly in standalone decoding, without constraining it to the phrase-based framework. In addition, we use the neural models to produce alignments that are used to re-train the same neural models. Related Work Most recently, NNs have been trained on large amounts of data, and applied to translate independent of the p"
W16-2206,P02-1040,0,0.101949,"Missing"
W16-2206,C12-2091,1,0.814866,"4 works are used to hypothesize translation candidates directly, and the scores are computed online during decoding. We use the feed-forward joint model introduced in (Devlin et al., 2014) as a lexical model, and introduce a lexicalized alignment model based on it. In addition, we modify the bidirectional joint model presented in (Sundermeyer et al., 2014a) and compare it to the feed-forward variant. These lexical models were applied in phrase-based systems. In this work, we apply them in a standalone NMT framework. Forced alignment was applied to train phrase tables in (Wuebker et al., 2010; Peitz et al., 2012). We generate forced alignments using a neural decoder, and use them to re-train neural models. Tackling the costly normalization of the output layer during decoding has been the focus of several papers (Vaswani et al., 2013; Devlin et al., 2014; Jean et al., 2015). We propose a simple method to speed up decoding using a classfactored output layer with almost no loss in translation quality. 3 There are two common network architectures used in machine translation: feed-forward NNs (FFNN) and recurrent NNs (RNN). In this section we will discuss alignment-based feed-forward and recurrent neural n"
W16-2206,D13-1140,0,0.0609277,"a lexicalized alignment model based on it. In addition, we modify the bidirectional joint model presented in (Sundermeyer et al., 2014a) and compare it to the feed-forward variant. These lexical models were applied in phrase-based systems. In this work, we apply them in a standalone NMT framework. Forced alignment was applied to train phrase tables in (Wuebker et al., 2010; Peitz et al., 2012). We generate forced alignments using a neural decoder, and use them to re-train neural models. Tackling the costly normalization of the output layer during decoding has been the focus of several papers (Vaswani et al., 2013; Devlin et al., 2014; Jean et al., 2015). We propose a simple method to speed up decoding using a classfactored output layer with almost no loss in translation quality. 3 There are two common network architectures used in machine translation: feed-forward NNs (FFNN) and recurrent NNs (RNN). In this section we will discuss alignment-based feed-forward and recurrent neural networks. These networks are conditioned on the word alignment, in addition to the source and target words. 4.1 ˆ bi +m ) p(ei |bi1 , e1i−1 , f1J ) = p(ei |ei−1 i−n , fˆ bi −m Statistical Machine Translation ˆ source words fˆ"
W16-2206,popovic-ney-2006-pos,1,0.834319,"Missing"
W16-2206,W10-1738,1,0.813649,"zes did not lead to improvements. We apply part-of-speech-based long-range verb reordering rules to the German side in a preprocessing step for all German→English systems (Popovi´c and Ney, 2006), including the baselines. The Chinese→English systems use no such preordering. We use the GIZA++ word alignments to train the models. The networks are fine-tuned by training additional epochs on the in-domain data only (Luong and Manning, 2015). The LMs are only used in the phrase-based systems in both tasks, but not in the NMT systems. All translation experiments are performed with the Jane toolkit (Vilar et al., 2010; Wuebker et al., 2012). The alignment-based NNs are trained using an extension of the rwthlm toolkit (Sundermeyer et al., 2014b). We use an implementation based on Blocks (van Merri¨enboer et al., 2015) and Theano (Bergstra et al., 2010; Bastien et al., 2012) for the attention-based experiments. All results are meahttp://www.iwslt2013.org 60 test 2010 B LEU T ER rable performance is achieved on test 2010. In order to highlight the difference between using the FFJM and the BJM, we replace the FFJM scores after obtaining the N -best lists with the BJM scores and apply rescoring (row #9). In com"
W16-2206,C12-2104,0,0.0141988,"translate independent of the phrase-based framework. Sutskever et al. (2014) introduced the pure encoder-decoder approach, which avoids the concept of word alignments. Bahdanau et al. (2015) introduced an attention mechanism to the encoder-decoder approach, allowing the decoder to attend to certain source words. This method was refined in (Luong et al., 2015) to allow for local attention, which makes the decoder attend to representations of source words residing within a window. These translation models have shown competitive results, outperforming phrase-based systems when using ensembles on Schwenk (2012) proposed a feed-forward network that computes phrase scores offline, and the scores were added to the phrase table of a phrasebased system. Offline phrase scoring was also done in (Alkhouli et al., 2014) using semantic phrase features obtained using simple neural networks. In comparison, our work does not rely on the phrase-based system, rather, the neural net55 4 works are used to hypothesize translation candidates directly, and the scores are computed online during decoding. We use the feed-forward joint model introduced in (Devlin et al., 2014) as a lexical model, and introduce a lexicaliz"
W16-2206,P10-1049,1,0.19884,"her, the neural net55 4 works are used to hypothesize translation candidates directly, and the scores are computed online during decoding. We use the feed-forward joint model introduced in (Devlin et al., 2014) as a lexical model, and introduce a lexicalized alignment model based on it. In addition, we modify the bidirectional joint model presented in (Sundermeyer et al., 2014a) and compare it to the feed-forward variant. These lexical models were applied in phrase-based systems. In this work, we apply them in a standalone NMT framework. Forced alignment was applied to train phrase tables in (Wuebker et al., 2010; Peitz et al., 2012). We generate forced alignments using a neural decoder, and use them to re-train neural models. Tackling the costly normalization of the output layer during decoding has been the focus of several papers (Vaswani et al., 2013; Devlin et al., 2014; Jean et al., 2015). We propose a simple method to speed up decoding using a classfactored output layer with almost no loss in translation quality. 3 There are two common network architectures used in machine translation: feed-forward NNs (FFNN) and recurrent NNs (RNN). In this section we will discuss alignment-based feed-forward a"
W16-2206,P16-1009,0,0.0596364,"Missing"
W16-2206,C12-3061,1,0.84211,"improvements. We apply part-of-speech-based long-range verb reordering rules to the German side in a preprocessing step for all German→English systems (Popovi´c and Ney, 2006), including the baselines. The Chinese→English systems use no such preordering. We use the GIZA++ word alignments to train the models. The networks are fine-tuned by training additional epochs on the in-domain data only (Luong and Manning, 2015). The LMs are only used in the phrase-based systems in both tasks, but not in the NMT systems. All translation experiments are performed with the Jane toolkit (Vilar et al., 2010; Wuebker et al., 2012). The alignment-based NNs are trained using an extension of the rwthlm toolkit (Sundermeyer et al., 2014b). We use an implementation based on Blocks (van Merri¨enboer et al., 2015) and Theano (Bergstra et al., 2010; Bastien et al., 2012) for the attention-based experiments. All results are meahttp://www.iwslt2013.org 60 test 2010 B LEU T ER rable performance is achieved on test 2010. In order to highlight the difference between using the FFJM and the BJM, we replace the FFJM scores after obtaining the N -best lists with the BJM scores and apply rescoring (row #9). In comparison to row #7, we o"
W16-2206,2006.amta-papers.25,0,0.104205,"Missing"
W16-2206,P13-1017,0,0.0190223,"covering long context without having to explicitly address the smoothing problem that arises in countbased models. 2 Cohn et al. (2016) introduce several modifications to the attention-based model inspired by traditional word alignment concepts. They modify the network architecture, adding a first-order dependence by making the attention vector computed for a target position directly dependent on that of the previous position. Our alignment model has a first-order dependence that takes place at the input and output of the model, rather than an architectural modification of the neural network. Yang et al. (2013) use NN-based lexical and alignment models, but they give up the probabilistic interpretation and produce unnormalized scores instead. Furthermore, they model alignments using a simple distortion model that has no dependence on lexical context. The models are used to produce new alignments which are in turn used to train phrase systems. This leads to no significant difference in terms of translation performance. Tamura et al. (2014) propose a lexicalized RNN alignment model. The model still produces non-probabilistic scores, and is used to generate word alignments used to train phrase-based sy"
W16-2206,D14-1003,1,0.835673,"ng search. We demonstrate that our system outperforms attention-based NMT on two tasks: IWSLT 2013 German→English and BOLT Chinese→English. We also show promising results for re-aligning the training data using neural models. 1 Introduction Neural networks have been gaining a lot of attention recently in areas like speech recognition, image recognition and natural language processing. In machine translation, NNs are applied in two main ways: In N -best rescoring, the neural model is used to score the first-pass decoding output, limiting the model to a fixed set of hypotheses (Le et al., 2012; Sundermeyer et al., 2014a; Hu et al., 2014; Guta et al., 2015). The second approach integrates the NN into decoding, potentially allowing it to directly determine the search space. There are two approaches to use neural models in decoding. The first integrates the mod54 Proceedings of the First Conference on Machine Translation, Volume 1: Research Papers, pages 54–65, c Berlin, Germany, August 11-12, 2016. 2016 Association for Computational Linguistics tasks like IWSLT English→German 2015 (Luong and Manning, 2015). models on the IWSLT 2013 German→English and BOLT Chinese→English task. 1.1 In this work, we follow the"
W16-2212,J92-4003,0,0.450598,"ls in SMT, Introduction Phrase-based systems for statistical machine translation (SMT) (Zens et al., 2002; Koehn et al., 2003) have shown state-of-the-art performance over the last decade. However, due to the huge size of phrase vocabulary, it is difficult to collect robust statistics for lots of phrase pairs. The standard phrase translation model thus tends to be sparse (Koehn, 2010). A fundamental solution to a sparsity problem in natural language processing is to reduce the vocabulary size. By mapping words onto a smaller label space, the models can be trained to have denser distributions (Brown et al., 1992; Miller et al., 2004; Koo et al., 2008). Examples of such labels are part-of-speech (POS) tags or lemmas. In this work, we investigate the vocabulary reduction for phrase translation models with respect to various vocabulary choice. We evaluate two types of smoothing models for phrase translation probability using different kinds of word-level labels. In particular, we use automatically generated word classes (Brown et al., 1992) to obtain 110 Proceedings of the First Conference on Machine Translation, Volume 1: Research Papers, pages 110–117, c Berlin, Germany, August 11-12, 2016. 2016 Assoc"
W16-2212,N13-1003,0,0.0132699,"aard (2011) verify the effectiveness of word classes as factors. Assuming probabilistic mappings between words and labels, the factorization implies a combinatorial expansion of the phrase table with regard to different vocabularies. Wuebker et al. (2013) show a simplified case of the factored translation by adopting hard assignment from words to labels. In the end, they train the existing translation, language, and reordering models on word classes to build the corresponding smoothing models. Other types of features are also trained on wordlevel labels, e.g. hierarchical reordering features (Cherry, 2013), an n-gram-based translation model (Durrani et al., 2014), and sparse word pair features (Haddow et al., 2015). The first and the third are trained with a large-scale discriminative training algorithm. For all usages of word-level labels in SMT, Introduction Phrase-based systems for statistical machine translation (SMT) (Zens et al., 2002; Koehn et al., 2003) have shown state-of-the-art performance over the last decade. However, due to the huge size of phrase vocabulary, it is difficult to collect robust statistics for lots of phrase pairs. The standard phrase translation model thus tends to"
W16-2212,C14-1041,0,0.0150933,"es as factors. Assuming probabilistic mappings between words and labels, the factorization implies a combinatorial expansion of the phrase table with regard to different vocabularies. Wuebker et al. (2013) show a simplified case of the factored translation by adopting hard assignment from words to labels. In the end, they train the existing translation, language, and reordering models on word classes to build the corresponding smoothing models. Other types of features are also trained on wordlevel labels, e.g. hierarchical reordering features (Cherry, 2013), an n-gram-based translation model (Durrani et al., 2014), and sparse word pair features (Haddow et al., 2015). The first and the third are trained with a large-scale discriminative training algorithm. For all usages of word-level labels in SMT, Introduction Phrase-based systems for statistical machine translation (SMT) (Zens et al., 2002; Koehn et al., 2003) have shown state-of-the-art performance over the last decade. However, due to the huge size of phrase vocabulary, it is difficult to collect robust statistics for lots of phrase pairs. The standard phrase translation model thus tends to be sparse (Koehn, 2010). A fundamental solution to a spars"
W16-2212,D08-1089,0,0.0619408,"Missing"
W16-2212,W15-3013,0,0.0151807,"words and labels, the factorization implies a combinatorial expansion of the phrase table with regard to different vocabularies. Wuebker et al. (2013) show a simplified case of the factored translation by adopting hard assignment from words to labels. In the end, they train the existing translation, language, and reordering models on word classes to build the corresponding smoothing models. Other types of features are also trained on wordlevel labels, e.g. hierarchical reordering features (Cherry, 2013), an n-gram-based translation model (Durrani et al., 2014), and sparse word pair features (Haddow et al., 2015). The first and the third are trained with a large-scale discriminative training algorithm. For all usages of word-level labels in SMT, Introduction Phrase-based systems for statistical machine translation (SMT) (Zens et al., 2002; Koehn et al., 2003) have shown state-of-the-art performance over the last decade. However, due to the huge size of phrase vocabulary, it is difficult to collect robust statistics for lots of phrase pairs. The standard phrase translation model thus tends to be sparse (Koehn, 2010). A fundamental solution to a sparsity problem in natural language processing is to redu"
W16-2212,J82-2005,0,0.757906,"Missing"
W16-2212,D07-1091,0,0.0662732,"scenarios of different scales, showing that the smoothing works better with more parallel corpora. This work systematically analyzes the smoothing effect of vocabulary reduction for phrase translation models. We extensively compare various word-level vocabularies to show that the performance of smoothing is not significantly affected by the choice of vocabulary. This result provides empirical evidence that the standard phrase translation model is extremely sparse. Our experiments also reveal that vocabulary reduction is more effective for smoothing large-scale phrase tables. 1 2 Related Work Koehn and Hoang (2007) propose integrating a label vocabulary as a factor into the phrase-based SMT pipeline, which consists of the following three steps: mapping from words to labels, labelto-label translation, and generation of words from labels. Rishøj and Søgaard (2011) verify the effectiveness of word classes as factors. Assuming probabilistic mappings between words and labels, the factorization implies a combinatorial expansion of the phrase table with regard to different vocabularies. Wuebker et al. (2013) show a simplified case of the factored translation by adopting hard assignment from words to labels. In"
W16-2212,D13-1138,1,0.932935,"that vocabulary reduction is more effective for smoothing large-scale phrase tables. 1 2 Related Work Koehn and Hoang (2007) propose integrating a label vocabulary as a factor into the phrase-based SMT pipeline, which consists of the following three steps: mapping from words to labels, labelto-label translation, and generation of words from labels. Rishøj and Søgaard (2011) verify the effectiveness of word classes as factors. Assuming probabilistic mappings between words and labels, the factorization implies a combinatorial expansion of the phrase table with regard to different vocabularies. Wuebker et al. (2013) show a simplified case of the factored translation by adopting hard assignment from words to labels. In the end, they train the existing translation, language, and reordering models on word classes to build the corresponding smoothing models. Other types of features are also trained on wordlevel labels, e.g. hierarchical reordering features (Cherry, 2013), an n-gram-based translation model (Durrani et al., 2014), and sparse word pair features (Haddow et al., 2015). The first and the third are trained with a large-scale discriminative training algorithm. For all usages of word-level labels in"
W16-2212,N03-1017,0,0.0689207,"In the end, they train the existing translation, language, and reordering models on word classes to build the corresponding smoothing models. Other types of features are also trained on wordlevel labels, e.g. hierarchical reordering features (Cherry, 2013), an n-gram-based translation model (Durrani et al., 2014), and sparse word pair features (Haddow et al., 2015). The first and the third are trained with a large-scale discriminative training algorithm. For all usages of word-level labels in SMT, Introduction Phrase-based systems for statistical machine translation (SMT) (Zens et al., 2002; Koehn et al., 2003) have shown state-of-the-art performance over the last decade. However, due to the huge size of phrase vocabulary, it is difficult to collect robust statistics for lots of phrase pairs. The standard phrase translation model thus tends to be sparse (Koehn, 2010). A fundamental solution to a sparsity problem in natural language processing is to reduce the vocabulary size. By mapping words onto a smaller label space, the models can be trained to have denser distributions (Brown et al., 1992; Miller et al., 2004; Koo et al., 2008). Examples of such labels are part-of-speech (POS) tags or lemmas. I"
W16-2212,W04-3250,0,0.358142,"Missing"
W16-2212,P08-1068,0,0.0668088,"Missing"
W16-2212,N04-1043,0,0.0187443,"ion Phrase-based systems for statistical machine translation (SMT) (Zens et al., 2002; Koehn et al., 2003) have shown state-of-the-art performance over the last decade. However, due to the huge size of phrase vocabulary, it is difficult to collect robust statistics for lots of phrase pairs. The standard phrase translation model thus tends to be sparse (Koehn, 2010). A fundamental solution to a sparsity problem in natural language processing is to reduce the vocabulary size. By mapping words onto a smaller label space, the models can be trained to have denser distributions (Brown et al., 1992; Miller et al., 2004; Koo et al., 2008). Examples of such labels are part-of-speech (POS) tags or lemmas. In this work, we investigate the vocabulary reduction for phrase translation models with respect to various vocabulary choice. We evaluate two types of smoothing models for phrase translation probability using different kinds of word-level labels. In particular, we use automatically generated word classes (Brown et al., 1992) to obtain 110 Proceedings of the First Conference on Machine Translation, Volume 1: Research Papers, pages 110–117, c Berlin, Germany, August 11-12, 2016. 2016 Association for Computatio"
W16-2212,E99-1010,0,0.183726,"Missing"
W16-2212,P03-1021,0,0.0228894,"Missing"
W16-2212,W11-2155,0,0.288481,"el vocabularies to show that the performance of smoothing is not significantly affected by the choice of vocabulary. This result provides empirical evidence that the standard phrase translation model is extremely sparse. Our experiments also reveal that vocabulary reduction is more effective for smoothing large-scale phrase tables. 1 2 Related Work Koehn and Hoang (2007) propose integrating a label vocabulary as a factor into the phrase-based SMT pipeline, which consists of the following three steps: mapping from words to labels, labelto-label translation, and generation of words from labels. Rishøj and Søgaard (2011) verify the effectiveness of word classes as factors. Assuming probabilistic mappings between words and labels, the factorization implies a combinatorial expansion of the phrase table with regard to different vocabularies. Wuebker et al. (2013) show a simplified case of the factored translation by adopting hard assignment from words to labels. In the end, they train the existing translation, language, and reordering models on word classes to build the corresponding smoothing models. Other types of features are also trained on wordlevel labels, e.g. hierarchical reordering features (Cherry, 201"
W16-2212,C12-3061,1,\N,Missing
W16-2320,W16-2304,1,0.833347,"factored word representation of the source and the target. On the source side we use the word surface form and two automatic word classes using 100 and 1,000 classes. On the Romanian side, we add the POS information as an additional word factor. 2 3.2 Preprocessing The data provided for the task was preprocessed once, by LIMSI, and shared with all the participants, in order to ensure consistency between systems. On the English side, preprocessing consists of tokenizing and truecasing using the Moses toolkit (Koehn et al., 2007). On the Romanian side, the data is tokenized using LIMSI’s tokro (Allauzen et al., 2016), a rulebased tokenizer that mainly normalizes diacritics and splits punctuation and clitics. This data is truecased in the same way as the English side. In addition, the Romanian sentences are also tagged, lemmatized, and chunked using the TTL tagger (Tufis¸ et al., 2008). 3 The LIMSI system uses NCODE (Crego et al., 2011), which implements the bilingual n-gram approach to SMT (Casacuberta and Vidal, 2004; Crego and Mari˜no, 2006; Mari˜no et al., 2006) that is closely related to the standard phrase-based approach (Zens et al., 2002). In this framework, translation is divided into two steps. T"
W16-2320,W05-0909,0,0.583183,"ions from multiple hypotheses which are obtained from different translation approaches, i.e., the systems described in the previous section. A system combination implementation developed at RWTH Aachen University (Freitag et al., 2014a) is used to combine the outputs of the different engines. The consensus translations outperform the individual hypotheses in terms of translation quality. The first step in system combination is the generation of confusion networks (CN) from I input translation hypotheses. We need pairwise alignments between the input hypotheses, which are obtained from METEOR (Banerjee and Lavie, 2005). The hypotheses are then reordered to match a selected skeleton hypothesis in terms of word ordering. We generate I different CNs, each having one of the input systems as the skeleton hypothesis, and the final lattice is the union of all I generated CNs. In Figure 1 an example of a confusion network with I = 4 input translations is depicted. Decoding of a confusion network finds the best path in the network. Each arc is assigned a score of a linear model combination of M different models, which includes word penalty, 3-gram language model trained on the input hypotheses, a binary primary syst"
W16-2320,P13-2071,1,0.873371,"odel trained on all available data. Words in the Common Crawl dataset that appear fewer than 500 times were replaced by UNK, and all singleton ngrams of order 3 or higher were pruned. We also use a 7-gram class-based language model, trained on the same data. 512 word Edinburgh Phrase-based System Edinburgh’s phrase-based system is built using the Moses toolkit, with fast align (Dyer et al., 2013) for word alignment, and KenLM (Heafield et al., 2013) for language model training. In our Moses setup, we use hierarchical lexicalized reordering (Galley and Manning, 2008), operation sequence model (Durrani et al., 2013), domain indicator features, and binned phrase count features. We use all available parallel data for the translation model, and all available Romanian text for the language model. We use two different 5-gram language models; one built from all the monolingual target text concatenated, without pruning, and one 3 USFD Phrase-based System 4 http://www.quest.dcs.shef.ac.uk/ quest_files/features_blackbox_baseline_ 17 https://github.com/rsennrich/nematus 348 the large building the large home a big huge house house a newsdev2016/1 and newsdev2016/2. The first part was used as development set while t"
W16-2320,D15-1129,1,0.847985,"training and evaluation. The language model uses 3 stacked LSTM layers, with 350 nodes each. The BJM has a projection layer, and computes a forLMU The LMU system integrates a discriminative rule selection model into a hierarchical SMT system, as described in (Tamchyna et al., 2014). The rule selection model is implemented using the highspeed classifier Vowpal Wabbit2 which is fully integrated in Moses’ hierarchical decoder. During decoding, the rule selection model is called at each rule application with syntactic context information as feature templates. The features are the same as used by Braune et al. (2015) in their string-to-tree system, including both lexical and soft source syntax features. The translation model features comprise the standard hierarchical features (Chiang, 2005) with an additional feature for the rule selection model (Braune et al., 2016). Before training, we reduce the number of translation rules using significance testing (Johnson et al., 2007). To extract the features of the rule selection model, we parse the English part of our 2 http://hunch.net/˜vw/ (VW). Implemented by John Langford and many others. 346 URLs, e-mail addresses, etc.). During translation a rule-based loc"
W16-2320,N13-1073,0,0.034805,"preordering model of (de Gispert et al., 2015). The preordering model is trained for 30 iterations on the full MGIZA-aligned training data. We use two language models, built using KenLM. The first is a 5-gram language model trained on all available data. Words in the Common Crawl dataset that appear fewer than 500 times were replaced by UNK, and all singleton ngrams of order 3 or higher were pruned. We also use a 7-gram class-based language model, trained on the same data. 512 word Edinburgh Phrase-based System Edinburgh’s phrase-based system is built using the Moses toolkit, with fast align (Dyer et al., 2013) for word alignment, and KenLM (Heafield et al., 2013) for language model training. In our Moses setup, we use hierarchical lexicalized reordering (Galley and Manning, 2008), operation sequence model (Durrani et al., 2013), domain indicator features, and binned phrase count features. We use all available parallel data for the translation model, and all available Romanian text for the language model. We use two different 5-gram language models; one built from all the monolingual target text concatenated, without pruning, and one 3 USFD Phrase-based System 4 http://www.quest.dcs.shef.ac.uk/ ques"
W16-2320,J04-2004,0,0.0194677,"en systems. On the English side, preprocessing consists of tokenizing and truecasing using the Moses toolkit (Koehn et al., 2007). On the Romanian side, the data is tokenized using LIMSI’s tokro (Allauzen et al., 2016), a rulebased tokenizer that mainly normalizes diacritics and splits punctuation and clitics. This data is truecased in the same way as the English side. In addition, the Romanian sentences are also tagged, lemmatized, and chunked using the TTL tagger (Tufis¸ et al., 2008). 3 The LIMSI system uses NCODE (Crego et al., 2011), which implements the bilingual n-gram approach to SMT (Casacuberta and Vidal, 2004; Crego and Mari˜no, 2006; Mari˜no et al., 2006) that is closely related to the standard phrase-based approach (Zens et al., 2002). In this framework, translation is divided into two steps. To translate a source sentence into a target sentence, the source sentence is first reordered according to a set of rewriting rules so as to reproduce the target word order. This generates a word lattice containing the most promising source permutations, which is then translated. Since the translation step is monotonic, this approach is able to rely on the n-gram assumption to decompose the joint probabilit"
W16-2320,2011.mtsummit-papers.30,0,0.020392,"-based System The RWTH hierarchical setup uses the open source translation toolkit Jane 2.3 (Vilar et al., 2010). Hierarchical phrase-based translation (HPBT) (Chiang, 2007) induces a weighted synchronous context-free grammar from parallel text. In addition to the contiguous lexical phrases, as used in phrase-based translation (PBT), hierarchical phrases with up to two gaps are also extracted. Our baseline model contains models with phrase translation probabilities and lexical smoothing probabilities in both translation directions, word and phrase penalty, and enhanced low frequency features (Chen et al., 2011). It also contains binary features to distinguish between hierarchical and non-hierarchical phrases, the glue rule, and rules with non-terminals at the boundaries. We use the cube pruning algorithm (Huang and Chiang, 2007) for decoding. The system uses three backoff language models (LM) that are estimated with the KenLM toolkit (Heafield et al., 2013) and are integrated into the decoder as separate models in the log-linear combination: a full 4-gram LM (trained on all data), a limited 5-gram LM (trained only on in-domain data), and a 7-gram word class language model (wcLM) (Wuebker et al., 201"
W16-2320,N12-1047,0,0.591808,"rescoring. The phrase-based system is trained on all available parallel training data. The phrase 345 more specifically its implementation in XenC (Rousseau, 2013). As a result, one third of the initial corpus is removed. Finally, we make a linear interpolation of these models, using the SRILM toolkit (Stolcke, 2002). 3.3 training data using the Berkeley parser (Petrov et al., 2006). For model prediction during tuning and decoding, we use parsed versions of the development and test sets. We train the rule selection model using VW and tune the weights of the translation model using batch MIRA (Cherry and Foster, 2012). The 5-gram language model is trained using KenLM (Heafield et al., 2013) on the Romanian part of the Common Crawl corpus concatenated with the Romanian part of the training data. LMU-CUNI The LMU-CUNI contribution is a constrained Moses phrase-based system. It uses a simple factored setting: our phrase table produces not only the target surface form but also its lemma and morphological tag. On the input, we include lemmas, POS tags and information from dependency parses (lemma of the parent node and syntactic relation), all encoded as additional factors. The main difference from a standard p"
W16-2320,E14-2008,1,0.72015,"tems are combined using RWTH’s system combination approach. The final submission shows an improvement of 1.0 B LEU compared to the best single system on newstest2016. 1 Introduction Quality Translation 21 (QT21) is a European machine translation research project with the aim 1 http://www.statmt.org/wmt16/ translation-task.html 344 Proceedings of the First Conference on Machine Translation, Volume 2: Shared Task Papers, pages 344–355, c Berlin, Germany, August 11-12, 2016. 2016 Association for Computational Linguistics mented in Jane, RWTH’s open source statistical machine translation toolkit (Freitag et al., 2014a). The Jane system combination is a mature implementation which previously has been successfully employed in other collaborative projects and for different language pairs (Freitag et al., 2013; Freitag et al., 2014b; Freitag et al., 2014c). In the remainder of the paper, we present the technical details of the QT21/HimL combined machine translation system and the experimental results obtained with it. The paper is structured as follows: We describe the common preprocessing used for most of the individual engines in Section 2. Section 3 covers the characteristics of the different individual en"
W16-2320,P05-1033,0,0.151933,"ative rule selection model into a hierarchical SMT system, as described in (Tamchyna et al., 2014). The rule selection model is implemented using the highspeed classifier Vowpal Wabbit2 which is fully integrated in Moses’ hierarchical decoder. During decoding, the rule selection model is called at each rule application with syntactic context information as feature templates. The features are the same as used by Braune et al. (2015) in their string-to-tree system, including both lexical and soft source syntax features. The translation model features comprise the standard hierarchical features (Chiang, 2005) with an additional feature for the rule selection model (Braune et al., 2016). Before training, we reduce the number of translation rules using significance testing (Johnson et al., 2007). To extract the features of the rule selection model, we parse the English part of our 2 http://hunch.net/˜vw/ (VW). Implemented by John Langford and many others. 346 URLs, e-mail addresses, etc.). During translation a rule-based localisation feature is applied. ward recurrent state encoding the source and target history, a backward recurrent state encoding the source future, and a third LSTM layer to combin"
W16-2320,J07-2003,0,0.558191,"this model is to better condition lexical choices by using the source context and to improve morphological and topical coherence by modeling the (limited left-hand side) target context. We also take advantage of the target factors by using a 7-gram language model trained on sequences of Romanian morphological tags. Finally, our system also uses a standard lexicalized reordering model. 3.4 3.5 RWTH Aachen University: Hierarchical Phrase-based System The RWTH hierarchical setup uses the open source translation toolkit Jane 2.3 (Vilar et al., 2010). Hierarchical phrase-based translation (HPBT) (Chiang, 2007) induces a weighted synchronous context-free grammar from parallel text. In addition to the contiguous lexical phrases, as used in phrase-based translation (PBT), hierarchical phrases with up to two gaps are also extracted. Our baseline model contains models with phrase translation probabilities and lexical smoothing probabilities in both translation directions, word and phrase penalty, and enhanced low frequency features (Chen et al., 2011). It also contains binary features to distinguish between hierarchical and non-hierarchical phrases, the glue rule, and rules with non-terminals at the bou"
W16-2320,W14-3310,1,0.909876,"tems are combined using RWTH’s system combination approach. The final submission shows an improvement of 1.0 B LEU compared to the best single system on newstest2016. 1 Introduction Quality Translation 21 (QT21) is a European machine translation research project with the aim 1 http://www.statmt.org/wmt16/ translation-task.html 344 Proceedings of the First Conference on Machine Translation, Volume 2: Shared Task Papers, pages 344–355, c Berlin, Germany, August 11-12, 2016. 2016 Association for Computational Linguistics mented in Jane, RWTH’s open source statistical machine translation toolkit (Freitag et al., 2014a). The Jane system combination is a mature implementation which previously has been successfully employed in other collaborative projects and for different language pairs (Freitag et al., 2013; Freitag et al., 2014b; Freitag et al., 2014c). In the remainder of the paper, we present the technical details of the QT21/HimL combined machine translation system and the experimental results obtained with it. The paper is structured as follows: We describe the common preprocessing used for most of the individual engines in Section 2. Section 3 covers the characteristics of the different individual en"
W16-2320,D14-1179,0,0.0138582,"Missing"
W16-2320,2014.iwslt-evaluation.7,1,0.925781,"tems are combined using RWTH’s system combination approach. The final submission shows an improvement of 1.0 B LEU compared to the best single system on newstest2016. 1 Introduction Quality Translation 21 (QT21) is a European machine translation research project with the aim 1 http://www.statmt.org/wmt16/ translation-task.html 344 Proceedings of the First Conference on Machine Translation, Volume 2: Shared Task Papers, pages 344–355, c Berlin, Germany, August 11-12, 2016. 2016 Association for Computational Linguistics mented in Jane, RWTH’s open source statistical machine translation toolkit (Freitag et al., 2014a). The Jane system combination is a mature implementation which previously has been successfully employed in other collaborative projects and for different language pairs (Freitag et al., 2013; Freitag et al., 2014b; Freitag et al., 2014c). In the remainder of the paper, we present the technical details of the QT21/HimL combined machine translation system and the experimental results obtained with it. The paper is structured as follows: We describe the common preprocessing used for most of the individual engines in Section 2. Section 3 covers the characteristics of the different individual en"
W16-2320,D08-1089,0,0.0211464,", built using KenLM. The first is a 5-gram language model trained on all available data. Words in the Common Crawl dataset that appear fewer than 500 times were replaced by UNK, and all singleton ngrams of order 3 or higher were pruned. We also use a 7-gram class-based language model, trained on the same data. 512 word Edinburgh Phrase-based System Edinburgh’s phrase-based system is built using the Moses toolkit, with fast align (Dyer et al., 2013) for word alignment, and KenLM (Heafield et al., 2013) for language model training. In our Moses setup, we use hierarchical lexicalized reordering (Galley and Manning, 2008), operation sequence model (Durrani et al., 2013), domain indicator features, and binned phrase count features. We use all available parallel data for the translation model, and all available Romanian text for the language model. We use two different 5-gram language models; one built from all the monolingual target text concatenated, without pruning, and one 3 USFD Phrase-based System 4 http://www.quest.dcs.shef.ac.uk/ quest_files/features_blackbox_baseline_ 17 https://github.com/rsennrich/nematus 348 the large building the large home a big huge house house a newsdev2016/1 and newsdev2016/2. T"
W16-2320,N15-1105,0,0.046766,"Missing"
W16-2320,W08-0509,0,0.06624,"probability 0.2, and also drop out full words with probability 0.1. We clip the gradient norm to 1.0 (Pascanu et al., 2013). We train the models with Adadelta (Zeiler, 2012), reshuffling the training corpus between epochs. We validate the model every 10 000 minibatches via B LEU on a validation set, and perform early stopping on B LEU. Decoding is performed with beam search with a beam size of 12. A more detailed description of the system, and more experimental results, can be found in (Sennrich et al., 2016a). 3.10 3.11 USFD’s phrase-based system is built using the Moses toolkit, with MGIZA (Gao and Vogel, 2008) for word alignment and KenLM (Heafield et al., 2013) for language model training. We use all available parallel data for the translation model. A single 5-gram language model is built using all the target side of the parallel data and a subpart of the monolingual Romanian corpora selected with Xenc-v2 (Rousseau, 2013). For the latter we use all the parallel data as in-domain data and the first half of newsdev2016 as development set. The feature weights are tuned with MERT (Och, 2003) on the first half of newsdev2016. The system produces distinct 1000-best lists, for which we extend the featur"
W16-2320,W16-2315,1,0.820309,"vs et al., 2012) that features language-specific data filtering and cleaning modules. Tilde’s system was trained on all available parallel data. Two language models are trained using KenLM (Heafield, 2011): 1) a 5-gram model using the Europarl and SETimes2 corpora, and 2) a 3-gram model using the Common Crawl corpus. We also apply a custom tokenization tool that takes into account specifics of the Romanian language and handles non-translatable entities (e.g., file paths, 347 up with entries from a background phrase table extracted from the automatically produced News Crawl 2015 parallel data. Huck et al. (2016) give a more in-depth description of the Edinburgh/LMU hierarchical machine translation system, along with detailed experimental results. 3.9 built from only News Crawl 2015, with singleton 3-grams and above pruned out. The weights of all these features and models are tuned with k-best MIRA (Cherry and Foster, 2012) on first the half of newsdev2016. In decoding, we use MBR (Kumar and Byrne, 2004), cube-pruning (Huang and Chiang, 2007) with a pop-limit of 5000, and the Moses ”monotone at punctuation” switch (to prevent reordering across punctuation) (Koehn and Haddow, 2009). Edinburgh Neural Sy"
W16-2320,D07-1103,0,0.032902,"bbit2 which is fully integrated in Moses’ hierarchical decoder. During decoding, the rule selection model is called at each rule application with syntactic context information as feature templates. The features are the same as used by Braune et al. (2015) in their string-to-tree system, including both lexical and soft source syntax features. The translation model features comprise the standard hierarchical features (Chiang, 2005) with an additional feature for the rule selection model (Braune et al., 2016). Before training, we reduce the number of translation rules using significance testing (Johnson et al., 2007). To extract the features of the rule selection model, we parse the English part of our 2 http://hunch.net/˜vw/ (VW). Implemented by John Langford and many others. 346 URLs, e-mail addresses, etc.). During translation a rule-based localisation feature is applied. ward recurrent state encoding the source and target history, a backward recurrent state encoding the source future, and a third LSTM layer to combine them. All layers have 350 nodes. The neural networks are implemented using an extension of the RWTHLM toolkit (Sundermeyer et al., 2014b). The parameter weights are optimized with MERT ("
W16-2320,W14-3360,0,0.0191919,"NMT system on newsdev2016/2, but lags behind on newstest2016. Removing the by itself weakest system shows a slight degradation on newsdev2016/2 and newstest2016, hinting that it still provides valuable information. Table 2 shows a comparison between all systems by scoring the translation output against each other in T ER and B LEU. We see that the neural networks outputs differ the most from all the other systems. Figure 1: System A: the large building; System B: the large home; System C: a big house; System D: a huge house; Reference: the big house. classes were generated using the method of Green et al. (2014). 4 System Combination System combination produces consensus translations from multiple hypotheses which are obtained from different translation approaches, i.e., the systems described in the previous section. A system combination implementation developed at RWTH Aachen University (Freitag et al., 2014a) is used to combine the outputs of the different engines. The consensus translations outperform the individual hypotheses in terms of translation quality. The first step in system combination is the generation of confusion networks (CN) from I input translation hypotheses. We need pairwise alig"
W16-2320,P07-2045,1,0.010375,", 2015) as well as neural network language and translation models. These models use a factored word representation of the source and the target. On the source side we use the word surface form and two automatic word classes using 100 and 1,000 classes. On the Romanian side, we add the POS information as an additional word factor. 2 3.2 Preprocessing The data provided for the task was preprocessed once, by LIMSI, and shared with all the participants, in order to ensure consistency between systems. On the English side, preprocessing consists of tokenizing and truecasing using the Moses toolkit (Koehn et al., 2007). On the Romanian side, the data is tokenized using LIMSI’s tokro (Allauzen et al., 2016), a rulebased tokenizer that mainly normalizes diacritics and splits punctuation and clitics. This data is truecased in the same way as the English side. In addition, the Romanian sentences are also tagged, lemmatized, and chunked using the TTL tagger (Tufis¸ et al., 2008). 3 The LIMSI system uses NCODE (Crego et al., 2011), which implements the bilingual n-gram approach to SMT (Casacuberta and Vidal, 2004; Crego and Mari˜no, 2006; Mari˜no et al., 2006) that is closely related to the standard phrase-based"
W16-2320,P13-2121,0,0.0645203,"Missing"
W16-2320,W11-2123,0,0.124165,"nslation is divided into two steps. To translate a source sentence into a target sentence, the source sentence is first reordered according to a set of rewriting rules so as to reproduce the target word order. This generates a word lattice containing the most promising source permutations, which is then translated. Since the translation step is monotonic, this approach is able to rely on the n-gram assumption to decompose the joint probability of a sentence pair into a sequence of bilingual units called tuples. We train three Romanian 4-gram language models, pruning all singletons with KenLM (Heafield, 2011). We use the in-domain monolingual corpus, the Romanian side of the parallel corpora and a subset of the (out-of-domain) Common Crawl corpus as training data. We select indomain sentences from the latter using the MooreLewis (Moore and Lewis, 2010) filtering method, Translation Systems Each group contributed one or more systems. In this section the systems are presented in alphabetic order. 3.1 LIMSI KIT The KIT system consists of a phrase-based machine translation system using additional models in rescoring. The phrase-based system is trained on all available parallel training data. The phras"
W16-2320,N04-1022,0,0.037676,"f the Romanian language and handles non-translatable entities (e.g., file paths, 347 up with entries from a background phrase table extracted from the automatically produced News Crawl 2015 parallel data. Huck et al. (2016) give a more in-depth description of the Edinburgh/LMU hierarchical machine translation system, along with detailed experimental results. 3.9 built from only News Crawl 2015, with singleton 3-grams and above pruned out. The weights of all these features and models are tuned with k-best MIRA (Cherry and Foster, 2012) on first the half of newsdev2016. In decoding, we use MBR (Kumar and Byrne, 2004), cube-pruning (Huang and Chiang, 2007) with a pop-limit of 5000, and the Moses ”monotone at punctuation” switch (to prevent reordering across punctuation) (Koehn and Haddow, 2009). Edinburgh Neural System Edinburgh’s neural machine translation system is an attentional encoder-decoder (Bahdanau et al., 2015), which we train with nematus.3 We use byte-pair-encoding (BPE) to achieve openvocabulary translation with a fixed vocabulary of subword symbols (Sennrich et al., 2016c). We produce additional parallel training data by automatically translating the monolingual Romanian News Crawl 2015 corpu"
W16-2320,2015.iwslt-papers.3,1,0.744353,"g. It uses two word-based n-gram language models and three additional non-word language models. Two of them are automatic word class-based (Och, 1999) language models, using 100 and 1,000 word classes. In addition, we use a POS-based language model. During decoding, we use a discriminative word lexicon (Niehues and Waibel, 2013) as well. We rescore the system output using a 300-best list. The weights are optimized on the concatenation of the development data and the SETimes2 dev set using the ListNet algorithm (Niehues et al., 2015). In rescoring, we add the source discriminative word lexica (Herrmann et al., 2015) as well as neural network language and translation models. These models use a factored word representation of the source and the target. On the source side we use the word surface form and two automatic word classes using 100 and 1,000 classes. On the Romanian side, we add the POS information as an additional word factor. 2 3.2 Preprocessing The data provided for the task was preprocessed once, by LIMSI, and shared with all the participants, in order to ensure consistency between systems. On the English side, preprocessing consists of tokenizing and truecasing using the Moses toolkit (Koehn e"
W16-2320,J06-4004,0,0.106202,"Missing"
W16-2320,2009.iwslt-papers.4,0,0.0984189,"target history, a backward recurrent state encoding the source future, and a third LSTM layer to combine them. All layers have 350 nodes. The neural networks are implemented using an extension of the RWTHLM toolkit (Sundermeyer et al., 2014b). The parameter weights are optimized with MERT (Och, 2003) towards the B LEU metric. 3.6 3.8 The UEDIN-LMU HPBT system is a hierarchical phrase-based machine translation system (Chiang, 2005) built jointly by the University of Edinburgh and LMU Munich. The system is based on the open source Moses implementation of the hierarchical phrase-based paradigm (Hoang et al., 2009). In addition to a set of standard features in a log-linear combination, a number of non-standard enhancements are employed to achieve improved translation quality. Specifically, we integrate individual language models trained over the separate corpora (News Crawl 2015, Europarl, SETimes2) directly into the log-linear combination of the system and let MIRA (Cherry and Foster, 2012) optimize their weights along with all other features in tuning, rather than relying on a single linearly interpolated language model. We add another background language model estimated over a concatenation of all Ro"
W16-2320,P10-2041,0,0.0238386,"ontaining the most promising source permutations, which is then translated. Since the translation step is monotonic, this approach is able to rely on the n-gram assumption to decompose the joint probability of a sentence pair into a sequence of bilingual units called tuples. We train three Romanian 4-gram language models, pruning all singletons with KenLM (Heafield, 2011). We use the in-domain monolingual corpus, the Romanian side of the parallel corpora and a subset of the (out-of-domain) Common Crawl corpus as training data. We select indomain sentences from the latter using the MooreLewis (Moore and Lewis, 2010) filtering method, Translation Systems Each group contributed one or more systems. In this section the systems are presented in alphabetic order. 3.1 LIMSI KIT The KIT system consists of a phrase-based machine translation system using additional models in rescoring. The phrase-based system is trained on all available parallel training data. The phrase 345 more specifically its implementation in XenC (Rousseau, 2013). As a result, one third of the initial corpus is removed. Finally, we make a linear interpolation of these models, using the SRILM toolkit (Stolcke, 2002). 3.3 training data using"
W16-2320,P07-1019,0,0.236745,"grammar from parallel text. In addition to the contiguous lexical phrases, as used in phrase-based translation (PBT), hierarchical phrases with up to two gaps are also extracted. Our baseline model contains models with phrase translation probabilities and lexical smoothing probabilities in both translation directions, word and phrase penalty, and enhanced low frequency features (Chen et al., 2011). It also contains binary features to distinguish between hierarchical and non-hierarchical phrases, the glue rule, and rules with non-terminals at the boundaries. We use the cube pruning algorithm (Huang and Chiang, 2007) for decoding. The system uses three backoff language models (LM) that are estimated with the KenLM toolkit (Heafield et al., 2013) and are integrated into the decoder as separate models in the log-linear combination: a full 4-gram LM (trained on all data), a limited 5-gram LM (trained only on in-domain data), and a 7-gram word class language model (wcLM) (Wuebker et al., 2013) trained on all data and with a output vocabulary of 143K words. The system produces 1000-best lists which are reranked using a LSTM-based (Hochreiter and Schmidhuber, 1997; Gers et al., 2000; Gers et al., 2003) language"
W16-2320,2012.amta-papers.19,1,0.778005,"common preprocessing used for most of the individual engines in Section 2. Section 3 covers the characteristics of the different individual engines, followed by a brief overview of our system combination approach (Section 4). We then summarize our empirical results in Section 5, showing that we achieve better translation quality than with any individual engine. Finally, in Section 6, we provide a statistical analysis of certain linguistic phenomena, specifically the prediction precision on morphological attributes. We conclude the paper with Section 7. table is adapted to the SETimes2 corpus (Niehues and Waibel, 2012). The system uses a prereordering technique (Rottmann and Vogel, 2007) in combination with lexical reordering. It uses two word-based n-gram language models and three additional non-word language models. Two of them are automatic word class-based (Och, 1999) language models, using 100 and 1,000 word classes. In addition, we use a POS-based language model. During decoding, we use a discriminative word lexicon (Niehues and Waibel, 2013) as well. We rescore the system output using a 300-best list. The weights are optimized on the concatenation of the development data and the SETimes2 dev set usin"
W16-2320,W11-2211,1,0.902733,"ty words, and no lower limit to the amount of words covered by right-hand side non-terminals at extraction time. We discard rules with non-terminals on their right-hand side if they are singletons in the training data. In order to promote better reordering decisions, we implemented a feature in Moses that resembles the phrase orientation model for hierarchical machine translation as described by Huck et al. (2013) and extend our system with it. The model scores orientation classes (monotone, swap, discontinuous) for each rule application in decoding. We finally follow the approach outlined by Huck et al. (2011) for lightly-supervised training of hierarchical systems. We automatically translate parts (1.2M sentences) of the monolingual Romanian News Crawl 2015 corpus to English with a Romanian→English phrase-based statistical machine translation system (Williams et al., 2016). The foreground phrase table extracted from the human-generated parallel data is filled RWTH Neural System The second system provided by the RWTH is an attention-based recurrent neural network similar to (Bahdanau et al., 2015). The implementation is based on Blocks (van Merri¨enboer et al., 2015) and Theano (Bergstra et al., 20"
W16-2320,W13-2264,1,0.852517,"stic phenomena, specifically the prediction precision on morphological attributes. We conclude the paper with Section 7. table is adapted to the SETimes2 corpus (Niehues and Waibel, 2012). The system uses a prereordering technique (Rottmann and Vogel, 2007) in combination with lexical reordering. It uses two word-based n-gram language models and three additional non-word language models. Two of them are automatic word class-based (Och, 1999) language models, using 100 and 1,000 word classes. In addition, we use a POS-based language model. During decoding, we use a discriminative word lexicon (Niehues and Waibel, 2013) as well. We rescore the system output using a 300-best list. The weights are optimized on the concatenation of the development data and the SETimes2 dev set using the ListNet algorithm (Niehues et al., 2015). In rescoring, we add the source discriminative word lexica (Herrmann et al., 2015) as well as neural network language and translation models. These models use a factored word representation of the source and the target. On the source side we use the word surface form and two automatic word classes using 100 and 1,000 classes. On the Romanian side, we add the POS information as an additio"
W16-2320,W13-2258,1,0.869431,"extraction, we impose less strict extraction constraints than the Moses defaults. We extract more hierarchical rules by allowing for a maximum of ten symbols on the source side, a maximum span of twenty words, and no lower limit to the amount of words covered by right-hand side non-terminals at extraction time. We discard rules with non-terminals on their right-hand side if they are singletons in the training data. In order to promote better reordering decisions, we implemented a feature in Moses that resembles the phrase orientation model for hierarchical machine translation as described by Huck et al. (2013) and extend our system with it. The model scores orientation classes (monotone, swap, discontinuous) for each rule application in decoding. We finally follow the approach outlined by Huck et al. (2011) for lightly-supervised training of hierarchical systems. We automatically translate parts (1.2M sentences) of the monolingual Romanian News Crawl 2015 corpus to English with a Romanian→English phrase-based statistical machine translation system (Williams et al., 2016). The foreground phrase table extracted from the human-generated parallel data is filled RWTH Neural System The second system prov"
W16-2320,E99-1010,0,0.040797,"ion 5, showing that we achieve better translation quality than with any individual engine. Finally, in Section 6, we provide a statistical analysis of certain linguistic phenomena, specifically the prediction precision on morphological attributes. We conclude the paper with Section 7. table is adapted to the SETimes2 corpus (Niehues and Waibel, 2012). The system uses a prereordering technique (Rottmann and Vogel, 2007) in combination with lexical reordering. It uses two word-based n-gram language models and three additional non-word language models. Two of them are automatic word class-based (Och, 1999) language models, using 100 and 1,000 word classes. In addition, we use a POS-based language model. During decoding, we use a discriminative word lexicon (Niehues and Waibel, 2013) as well. We rescore the system output using a 300-best list. The weights are optimized on the concatenation of the development data and the SETimes2 dev set using the ListNet algorithm (Niehues et al., 2015). In rescoring, we add the source discriminative word lexica (Herrmann et al., 2015) as well as neural network language and translation models. These models use a factored word representation of the source and th"
W16-2320,P03-1021,0,0.501814,". To extract the features of the rule selection model, we parse the English part of our 2 http://hunch.net/˜vw/ (VW). Implemented by John Langford and many others. 346 URLs, e-mail addresses, etc.). During translation a rule-based localisation feature is applied. ward recurrent state encoding the source and target history, a backward recurrent state encoding the source future, and a third LSTM layer to combine them. All layers have 350 nodes. The neural networks are implemented using an extension of the RWTHLM toolkit (Sundermeyer et al., 2014b). The parameter weights are optimized with MERT (Och, 2003) towards the B LEU metric. 3.6 3.8 The UEDIN-LMU HPBT system is a hierarchical phrase-based machine translation system (Chiang, 2005) built jointly by the University of Edinburgh and LMU Munich. The system is based on the open source Moses implementation of the hierarchical phrase-based paradigm (Hoang et al., 2009). In addition to a set of standard features in a log-linear combination, a number of non-standard enhancements are employed to achieve improved translation quality. Specifically, we integrate individual language models trained over the separate corpora (News Crawl 2015, Europarl, SE"
W16-2320,D14-1003,1,0.932306,"with the KenLM toolkit (Heafield et al., 2013) and are integrated into the decoder as separate models in the log-linear combination: a full 4-gram LM (trained on all data), a limited 5-gram LM (trained only on in-domain data), and a 7-gram word class language model (wcLM) (Wuebker et al., 2013) trained on all data and with a output vocabulary of 143K words. The system produces 1000-best lists which are reranked using a LSTM-based (Hochreiter and Schmidhuber, 1997; Gers et al., 2000; Gers et al., 2003) language model (Sundermeyer et al., 2012) and a LSTM-based bidirectional joined model (BJM) (Sundermeyer et al., 2014a). The models have a class-factored output layer (Goodman, 2001; Morin and Bengio, 2005) to speed up training and evaluation. The language model uses 3 stacked LSTM layers, with 350 nodes each. The BJM has a projection layer, and computes a forLMU The LMU system integrates a discriminative rule selection model into a hierarchical SMT system, as described in (Tamchyna et al., 2014). The rule selection model is implemented using the highspeed classifier Vowpal Wabbit2 which is fully integrated in Moses’ hierarchical decoder. During decoding, the rule selection model is called at each rule appli"
W16-2320,P06-1055,0,0.0121776,"anslation Systems Each group contributed one or more systems. In this section the systems are presented in alphabetic order. 3.1 LIMSI KIT The KIT system consists of a phrase-based machine translation system using additional models in rescoring. The phrase-based system is trained on all available parallel training data. The phrase 345 more specifically its implementation in XenC (Rousseau, 2013). As a result, one third of the initial corpus is removed. Finally, we make a linear interpolation of these models, using the SRILM toolkit (Stolcke, 2002). 3.3 training data using the Berkeley parser (Petrov et al., 2006). For model prediction during tuning and decoding, we use parsed versions of the development and test sets. We train the rule selection model using VW and tune the weights of the translation model using batch MIRA (Cherry and Foster, 2012). The 5-gram language model is trained using KenLM (Heafield et al., 2013) on the Romanian part of the Common Crawl corpus concatenated with the Romanian part of the training data. LMU-CUNI The LMU-CUNI contribution is a constrained Moses phrase-based system. It uses a simple factored setting: our phrase table produces not only the target surface form but als"
W16-2320,2007.tmi-papers.21,0,0.0230136,"n 2. Section 3 covers the characteristics of the different individual engines, followed by a brief overview of our system combination approach (Section 4). We then summarize our empirical results in Section 5, showing that we achieve better translation quality than with any individual engine. Finally, in Section 6, we provide a statistical analysis of certain linguistic phenomena, specifically the prediction precision on morphological attributes. We conclude the paper with Section 7. table is adapted to the SETimes2 corpus (Niehues and Waibel, 2012). The system uses a prereordering technique (Rottmann and Vogel, 2007) in combination with lexical reordering. It uses two word-based n-gram language models and three additional non-word language models. Two of them are automatic word class-based (Och, 1999) language models, using 100 and 1,000 word classes. In addition, we use a POS-based language model. During decoding, we use a discriminative word lexicon (Niehues and Waibel, 2013) as well. We rescore the system output using a 300-best list. The weights are optimized on the concatenation of the development data and the SETimes2 dev set using the ListNet algorithm (Niehues et al., 2015). In rescoring, we add t"
W16-2320,P16-1161,1,0.729045,"omanian part of the training data. LMU-CUNI The LMU-CUNI contribution is a constrained Moses phrase-based system. It uses a simple factored setting: our phrase table produces not only the target surface form but also its lemma and morphological tag. On the input, we include lemmas, POS tags and information from dependency parses (lemma of the parent node and syntactic relation), all encoded as additional factors. The main difference from a standard phrasebased setup is the addition of a feature-rich discriminative translation model which is conditioned on both source- and target-side context (Tamchyna et al., 2016). The motivation for using this model is to better condition lexical choices by using the source context and to improve morphological and topical coherence by modeling the (limited left-hand side) target context. We also take advantage of the target factors by using a 7-gram language model trained on sequences of Romanian morphological tags. Finally, our system also uses a standard lexicalized reordering model. 3.4 3.5 RWTH Aachen University: Hierarchical Phrase-based System The RWTH hierarchical setup uses the open source translation toolkit Jane 2.3 (Vilar et al., 2010). Hierarchical phrase-"
W16-2320,tufis-etal-2008-racais,0,0.107217,"Missing"
W16-2320,P16-1009,1,0.78198,"and models are tuned with k-best MIRA (Cherry and Foster, 2012) on first the half of newsdev2016. In decoding, we use MBR (Kumar and Byrne, 2004), cube-pruning (Huang and Chiang, 2007) with a pop-limit of 5000, and the Moses ”monotone at punctuation” switch (to prevent reordering across punctuation) (Koehn and Haddow, 2009). Edinburgh Neural System Edinburgh’s neural machine translation system is an attentional encoder-decoder (Bahdanau et al., 2015), which we train with nematus.3 We use byte-pair-encoding (BPE) to achieve openvocabulary translation with a fixed vocabulary of subword symbols (Sennrich et al., 2016c). We produce additional parallel training data by automatically translating the monolingual Romanian News Crawl 2015 corpus into English (Sennrich et al., 2016b), which we combine with the original parallel data in a 1-to-1 ratio. We use minibatches of size 80, a maximum sentence length of 50, word embeddings of size 500, and hidden layers of size 1024. We apply dropout to all layers (Gal, 2015), with dropout probability 0.2, and also drop out full words with probability 0.1. We clip the gradient norm to 1.0 (Pascanu et al., 2013). We train the models with Adadelta (Zeiler, 2012), reshufflin"
W16-2320,P12-3008,0,0.0597108,"Missing"
W16-2320,P16-1162,1,0.259658,"and models are tuned with k-best MIRA (Cherry and Foster, 2012) on first the half of newsdev2016. In decoding, we use MBR (Kumar and Byrne, 2004), cube-pruning (Huang and Chiang, 2007) with a pop-limit of 5000, and the Moses ”monotone at punctuation” switch (to prevent reordering across punctuation) (Koehn and Haddow, 2009). Edinburgh Neural System Edinburgh’s neural machine translation system is an attentional encoder-decoder (Bahdanau et al., 2015), which we train with nematus.3 We use byte-pair-encoding (BPE) to achieve openvocabulary translation with a fixed vocabulary of subword symbols (Sennrich et al., 2016c). We produce additional parallel training data by automatically translating the monolingual Romanian News Crawl 2015 corpus into English (Sennrich et al., 2016b), which we combine with the original parallel data in a 1-to-1 ratio. We use minibatches of size 80, a maximum sentence length of 50, word embeddings of size 500, and hidden layers of size 1024. We apply dropout to all layers (Gal, 2015), with dropout probability 0.2, and also drop out full words with probability 0.1. We clip the gradient norm to 1.0 (Pascanu et al., 2013). We train the models with Adadelta (Zeiler, 2012), reshufflin"
W16-2320,W10-1738,1,0.885055,"rget-side context (Tamchyna et al., 2016). The motivation for using this model is to better condition lexical choices by using the source context and to improve morphological and topical coherence by modeling the (limited left-hand side) target context. We also take advantage of the target factors by using a 7-gram language model trained on sequences of Romanian morphological tags. Finally, our system also uses a standard lexicalized reordering model. 3.4 3.5 RWTH Aachen University: Hierarchical Phrase-based System The RWTH hierarchical setup uses the open source translation toolkit Jane 2.3 (Vilar et al., 2010). Hierarchical phrase-based translation (HPBT) (Chiang, 2007) induces a weighted synchronous context-free grammar from parallel text. In addition to the contiguous lexical phrases, as used in phrase-based translation (PBT), hierarchical phrases with up to two gaps are also extracted. Our baseline model contains models with phrase translation probabilities and lexical smoothing probabilities in both translation directions, word and phrase penalty, and enhanced low frequency features (Chen et al., 2011). It also contains binary features to distinguish between hierarchical and non-hierarchical ph"
W16-2320,P15-4020,1,0.815128,"data for the translation model. A single 5-gram language model is built using all the target side of the parallel data and a subpart of the monolingual Romanian corpora selected with Xenc-v2 (Rousseau, 2013). For the latter we use all the parallel data as in-domain data and the first half of newsdev2016 as development set. The feature weights are tuned with MERT (Och, 2003) on the first half of newsdev2016. The system produces distinct 1000-best lists, for which we extend the feature set with the 17 baseline black-box features from sentencelevel Quality Estimation (QE) produced with Quest++4 (Specia et al., 2015). The 1000-best lists are then reranked and the top-best hypothesis extracted using the nbest rescorer available within the Moses toolkit. 3.12 UvA We use a phrase-based machine translation system (Moses) with a distortion limit of 6 and lexicalized reordering. Before translation, the English source side is preordered using the neural preordering model of (de Gispert et al., 2015). The preordering model is trained for 30 iterations on the full MGIZA-aligned training data. We use two language models, built using KenLM. The first is a 5-gram language model trained on all available data. Words in"
W16-2320,W16-2327,1,0.84726,"Missing"
W16-2320,D13-1138,1,0.859072,"(Chen et al., 2011). It also contains binary features to distinguish between hierarchical and non-hierarchical phrases, the glue rule, and rules with non-terminals at the boundaries. We use the cube pruning algorithm (Huang and Chiang, 2007) for decoding. The system uses three backoff language models (LM) that are estimated with the KenLM toolkit (Heafield et al., 2013) and are integrated into the decoder as separate models in the log-linear combination: a full 4-gram LM (trained on all data), a limited 5-gram LM (trained only on in-domain data), and a 7-gram word class language model (wcLM) (Wuebker et al., 2013) trained on all data and with a output vocabulary of 143K words. The system produces 1000-best lists which are reranked using a LSTM-based (Hochreiter and Schmidhuber, 1997; Gers et al., 2000; Gers et al., 2003) language model (Sundermeyer et al., 2012) and a LSTM-based bidirectional joined model (BJM) (Sundermeyer et al., 2014a). The models have a class-factored output layer (Goodman, 2001; Morin and Bengio, 2005) to speed up training and evaluation. The language model uses 3 stacked LSTM layers, with 350 nodes each. The BJM has a projection layer, and computes a forLMU The LMU system integra"
W16-2320,2002.tmi-tutorials.2,0,0.0608664,"omanian side, the data is tokenized using LIMSI’s tokro (Allauzen et al., 2016), a rulebased tokenizer that mainly normalizes diacritics and splits punctuation and clitics. This data is truecased in the same way as the English side. In addition, the Romanian sentences are also tagged, lemmatized, and chunked using the TTL tagger (Tufis¸ et al., 2008). 3 The LIMSI system uses NCODE (Crego et al., 2011), which implements the bilingual n-gram approach to SMT (Casacuberta and Vidal, 2004; Crego and Mari˜no, 2006; Mari˜no et al., 2006) that is closely related to the standard phrase-based approach (Zens et al., 2002). In this framework, translation is divided into two steps. To translate a source sentence into a target sentence, the source sentence is first reordered according to a set of rewriting rules so as to reproduce the target word order. This generates a word lattice containing the most promising source permutations, which is then translated. Since the translation step is monotonic, this approach is able to rely on the n-gram assumption to decompose the joint probability of a sentence pair into a sequence of bilingual units called tuples. We train three Romanian 4-gram language models, pruning all"
W16-2321,D08-1089,0,\N,Missing
W16-2321,P02-1040,0,\N,Missing
W16-2321,W10-1738,1,\N,Missing
W16-2321,D13-1138,1,\N,Missing
W16-2321,W09-0432,0,\N,Missing
W16-2321,W05-0909,0,\N,Missing
W16-2321,D14-1003,1,\N,Missing
W16-2321,E14-2008,1,\N,Missing
W16-2321,J03-1002,1,\N,Missing
W16-2321,D14-1179,0,\N,Missing
W16-2321,P07-1019,0,\N,Missing
W16-2321,C12-3061,1,\N,Missing
W16-2321,2013.iwslt-evaluation.16,1,\N,Missing
W16-2321,W14-3310,1,\N,Missing
W16-2321,J07-2003,0,\N,Missing
W16-2321,P13-2121,0,\N,Missing
W16-2321,P03-1021,0,\N,Missing
W16-2321,W15-3034,1,\N,Missing
W16-2342,P02-1040,0,\N,Missing
W16-2342,W07-0734,0,\N,Missing
W16-2342,W15-3049,0,\N,Missing
W16-2342,W14-3354,0,\N,Missing
W17-4711,C96-2141,1,\N,Missing
W17-4711,P02-1040,0,\N,Missing
W17-4711,W10-1738,1,\N,Missing
W17-4711,P07-2045,0,\N,Missing
W17-4711,D14-1003,1,\N,Missing
W17-4711,J03-1002,1,\N,Missing
W17-4711,C12-3061,1,\N,Missing
W17-4711,P14-1138,0,\N,Missing
W17-4711,P13-1017,0,\N,Missing
W17-4711,2006.iwslt-papers.7,1,\N,Missing
W17-4711,D16-1162,0,\N,Missing
W17-4711,2016.amta-researchers.10,0,\N,Missing
W17-4711,D16-1249,0,\N,Missing
W17-4711,P17-2020,1,\N,Missing
W17-4734,W05-0909,0,0.158301,"ions from multiple hypotheses which are obtained from different translation approaches, i.e., the systems described in the previous section. A system combination implementation developed at RWTH Aachen University (Freitag et al., 2014a) is used to combine the outputs of the different engines. The consensus translations outperform the individual hypotheses in terms of translation quality. The first step in system combination is the generation of confusion networks (CN) from I input translation hypotheses. We need pairwise alignments between the input hypotheses, which are obtained from METEOR (Banerjee and Lavie, 2005). The hypotheses are then reordered to match a selected skeleton hypothesis in terms of word ordering. We generate I different CNs, each having one of the input systems as the skeleton hypothesis, and the final lattice is the union of all I generated CNs. In Figure 1 an example of a confusion network with I = 4 input translations is depicted. Decoding of a confusion network finds the best path in the network. Each arc is assigned a score of a linear model combination of M different models, which includes word penalty, 3-gram language model trained on the input hypotheses, a binary primary syst"
W17-4734,P09-1064,0,0.0328843,"translations. pothesis, and a binary voting feature for each system. The binary voting feature for a system is 1 if and only if the decoded word is from that system, and 0 otherwise. The different model weights for system combination are trained with MERT (Och, 2003) and optimized towards 8·B LEU −T ER. 4.2 Consensus-based System Selection 5 Experimental Evaluation As a secondary solution for system combination, we used USFD’s consensus-based n-nbest list selection approach (Blain et al., 2017) for system combination by combining each system’s output in the form of a n-best list. Inspired by DeNero et al. (2009)’s work on consensus-based Minimum Bayes Risk (MBR) decoding which compares different types of similarity metrics (B LEU, W ER, etc.) under a SMT setup, USFD designed a reranking approach to empirically evaluate the effect of consensus on the varying n-best list in NMT. Given a n-best list, each translation hypothesis is scored against the other MT candidates of the search space towards an automatic metric. In our experiment we considered three automatic metrics amongst the most widely used and which have been shown to be well correlated with human judgments (Bojar et al., 2016): B LEU, B EER"
W17-4734,D17-1209,1,0.891192,"Missing"
W17-4734,E14-2008,1,0.856971,"many 2 Charles University, Prague, Czech Republic 3 Karlsruhe Institute of Technology, Karlsruhe, Germany 4 LIMSI, CNRS, Universit´e Paris Saclay, 91 403 Orsay, France 5 Tilde, Riga, Latvia 6 University of Amsterdam, Amsterdam, Netherlands 7 University of Edinburgh, Edinburgh, UK 8 University of Sheffield, Sheffield, UK Abstract English→Latvian translation engines which have been set up by different project partners. The outputs of all these individual engines are combined using the system combination approach as implemented in Jane, RWTH’s open source statistical machine translation toolkit (Freitag et al., 2014a). The Jane system combination is a mature implementation which previously has been successfully employed in other collaborative projects and for different language pairs (Peter et al., 2016; Freitag et al., 2013, 2014b,c). As an alternative way of combining our systems, all outputs have been merged as the form of a n-best list and a consensus-based system-selection applied to obtain as best translation hypothesis the candidate that is most similar to the most likely translations amongst those systems. This paper describes the joint submission of the QT21 projects for the English→Latvian tran"
W17-4734,W16-2302,1,0.832947,". Inspired by DeNero et al. (2009)’s work on consensus-based Minimum Bayes Risk (MBR) decoding which compares different types of similarity metrics (B LEU, W ER, etc.) under a SMT setup, USFD designed a reranking approach to empirically evaluate the effect of consensus on the varying n-best list in NMT. Given a n-best list, each translation hypothesis is scored against the other MT candidates of the search space towards an automatic metric. In our experiment we considered three automatic metrics amongst the most widely used and which have been shown to be well correlated with human judgments (Bojar et al., 2016): B LEU, B EER (Stanojevic and Simaan, 2014) or C HR F (Popovic, 2015). The entire list of MT candidates is then entirely re-ranked according to the averaged score of each candidate. Different from most re-ranking approaches which make use of additional information usually treated as new model components and combined with the existing ones, we here focus only on the MT candidates. The difference between the consensus-based n-best list selection and an oracle translation is the absence Since only one development set was provided we split the given development set into two parts: newsdev2017/1 a"
W17-4734,W14-3310,1,0.870459,"many 2 Charles University, Prague, Czech Republic 3 Karlsruhe Institute of Technology, Karlsruhe, Germany 4 LIMSI, CNRS, Universit´e Paris Saclay, 91 403 Orsay, France 5 Tilde, Riga, Latvia 6 University of Amsterdam, Amsterdam, Netherlands 7 University of Edinburgh, Edinburgh, UK 8 University of Sheffield, Sheffield, UK Abstract English→Latvian translation engines which have been set up by different project partners. The outputs of all these individual engines are combined using the system combination approach as implemented in Jane, RWTH’s open source statistical machine translation toolkit (Freitag et al., 2014a). The Jane system combination is a mature implementation which previously has been successfully employed in other collaborative projects and for different language pairs (Peter et al., 2016; Freitag et al., 2013, 2014b,c). As an alternative way of combining our systems, all outputs have been merged as the form of a n-best list and a consensus-based system-selection applied to obtain as best translation hypothesis the candidate that is most similar to the most likely translations amongst those systems. This paper describes the joint submission of the QT21 projects for the English→Latvian tran"
W17-4734,W17-4703,1,0.884283,"Missing"
W17-4734,2014.iwslt-evaluation.7,1,0.873477,"many 2 Charles University, Prague, Czech Republic 3 Karlsruhe Institute of Technology, Karlsruhe, Germany 4 LIMSI, CNRS, Universit´e Paris Saclay, 91 403 Orsay, France 5 Tilde, Riga, Latvia 6 University of Amsterdam, Amsterdam, Netherlands 7 University of Edinburgh, Edinburgh, UK 8 University of Sheffield, Sheffield, UK Abstract English→Latvian translation engines which have been set up by different project partners. The outputs of all these individual engines are combined using the system combination approach as implemented in Jane, RWTH’s open source statistical machine translation toolkit (Freitag et al., 2014a). The Jane system combination is a mature implementation which previously has been successfully employed in other collaborative projects and for different language pairs (Peter et al., 2016; Freitag et al., 2013, 2014b,c). As an alternative way of combining our systems, all outputs have been merged as the form of a n-best list and a consensus-based system-selection applied to obtain as best translation hypothesis the candidate that is most similar to the most likely translations amongst those systems. This paper describes the joint submission of the QT21 projects for the English→Latvian tran"
W17-4734,W17-4737,1,0.831634,"Missing"
W17-4734,W11-2123,0,0.0435093,"o this end, k-best hypothesis from the dictionary were generated, as well as the n-best hypothesis 3.4 Tilde The Tilde system is a Moses phrase-based SMT system that was trained on the Tilde MT platform (Vasil¸jevs et al., 2012). The system was trained using all available parallel data - 1.74 million unique sentence pairs after filtering, and 3 million unique sentence pairs that were acquired by re-translating a random selection of indomain monolingual sentences with a neural machine translation system (Pinnis et al., 2017). The system has a 5-gram language model that was trained using KenLM (Heafield, 2011) on all available monolingual data (27.83 million unique sentences). 3.5 UEDIN The University of Edinburgh’s system is an attentional encoder-decoder (Bahdanau et al., 2015), trained using the Nematus toolkit (Sennrich et al., 2017c). As training data, we used all parallel and synthetic data, which was tokenized, truecased, and filtered as described in Section 2. After filtering, the data was segmented into subword units using byte-pair-encoding (BPE), for which we used 90,000 operations, jointly learned over both sides of the parallel corpora. We used word embeddings of size 512 and hidden la"
W17-4734,W15-3049,0,0.0536506,"Missing"
W17-4734,E17-2025,0,0.0291776,"l and synthetic data, which was tokenized, truecased, and filtered as described in Section 2. After filtering, the data was segmented into subword units using byte-pair-encoding (BPE), for which we used 90,000 operations, jointly learned over both sides of the parallel corpora. We used word embeddings of size 512 and hidden layers of size 1024, with the size of the source and target network vocabularies fixed to the size of the respective BPE vocabularies. In order to reduce the size of the models, the target-side embedding weights were tied with the transpose of 350 the output weight matrix (Press and Wolf, 2017). We used a deep transition architecture inspired by the one proposed by Zilly et al. (2016) for language modelling. In experiments conducted during feature development, we found that this gave consistent improvements across multiple language pairs. We also applied layer normalisation (Ba et al., 2016) to all recurrent and feed-forward layers, except for layers that are followed by a softmax. In preliminary experiments, we found that using layer normalisation led to faster convergence and resulted in slightly better performance. We trained the models with adam (Kingma and Ba, 2015), using a le"
W17-4734,E17-3017,0,0.0486901,"Missing"
W17-4734,P17-4012,0,0.0301124,"stem for the WMT 2017 shared task for machine translation of news 1 are seven individual 1 http://www.statmt.org/wmt17/ translation-task.html 348 Proceedings of the Conference on Machine Translation (WMT), Volume 2: Shared Task Papers, pages 348–357 c Copenhagen, Denmark, September 711, 2017. 2017 Association for Computational Linguistics tool. The number of sentences being removed is approximately 50000. in Neural Monkey. Instead, the translations were generated using greedy search. 3 3.2 Translation Systems The neural machine translation models from KIT are built with the OpenNMT framework (Klein et al., 2017), which is a multi-layer LSTM encoder decoder network. We trained the models with 2.1 million parallel sentence pairs concatenated with 2.8 million pairs from backtranslation provided by University of Edinburgh. The networks have 1024 hidden units for each of 2 LSTM layers for both encoder and decoder. Furthermore, we experiment a number of features with the baseline: First, we found out that using a context gate to mask activities between the decoder hidden state and the source context vector before producing the distribution at each time step (Tu et al., 2016a) is simple yet beneficial for p"
W17-4734,D17-1159,0,0.0716203,"Missing"
W17-4734,D16-1096,0,0.0289091,"rom backtranslation provided by University of Edinburgh. The networks have 1024 hidden units for each of 2 LSTM layers for both encoder and decoder. Furthermore, we experiment a number of features with the baseline: First, we found out that using a context gate to mask activities between the decoder hidden state and the source context vector before producing the distribution at each time step (Tu et al., 2016a) is simple yet beneficial for performance. Second, we strengthen the attentional network with a coverage vector accumulating the previous attentional information, similar to the work of Mi et al. (2016) and Tu et al. (2016b). Using the two techniques helps improve the BLEU score on the newsdev2017 set by 1.1 (tokenized) BLEU. By using ensembling 3 networks with different configs and rescoring using a model trained with reversed target sentences, we managed to reach 26.96 BLEU score for the development set, which yields 2.8 point of improvement compared to the baseline model. Details about the effect of each technique is described in Pham et al. (2017) Each group contributed one or more systems. In this section the systems are presented in alphabetic order. 3.1 KIT CUNI The CUNI component of"
W17-4734,P03-1021,0,0.0379532,"re case-sensitive. of reference translation: each translation hypothesis is scored against all the other hypotheses used as references while in an oracle translation each translation hypothesis is scored against a single reference. This results in obtaining as best translation hypothesis the candidate that is most similar to the most likely translations. pothesis, and a binary voting feature for each system. The binary voting feature for a system is 1 if and only if the decoded word is from that system, and 0 otherwise. The different model weights for system combination are trained with MERT (Och, 2003) and optimized towards 8·B LEU −T ER. 4.2 Consensus-based System Selection 5 Experimental Evaluation As a secondary solution for system combination, we used USFD’s consensus-based n-nbest list selection approach (Blain et al., 2017) for system combination by combining each system’s output in the form of a n-best list. Inspired by DeNero et al. (2009)’s work on consensus-based Minimum Bayes Risk (MBR) decoding which compares different types of similarity metrics (B LEU, W ER, etc.) under a SMT setup, USFD designed a reranking approach to empirically evaluate the effect of consensus on the varyi"
W17-4734,P16-1162,0,0.11892,"he effect of each technique is described in Pham et al. (2017) Each group contributed one or more systems. In this section the systems are presented in alphabetic order. 3.1 KIT CUNI The CUNI component of the system was built using Neural Monkey2 (Helcl and Libovick´y, 2017), a flexible sequence-to-sequence toolkit implementing primarily the Bahdanau et al. (2015) model but useful also in multi-modal translation and multi-task training. We used essentially the baseline setup of the system as released for the WMT17 NMT Training Task3 (Bojar et al., 2017) for an 8GB GPU card. This involves BPE (Sennrich et al., 2016) with 30k merges, maximum sentence length for both source and target limited to 50 (BPE) tokens, no dropout and embeddings (both source and target) of 600, vocabulary shared between encoder and decoder, attention and conditional GRU (Firat and Cho, 2016). We experimented with the RNN size of the encoder and decoder and increased them to 800 instead of 600, at the expense of reducing batch size to 10. The batch size of 30 with this enlarged model would still fit into our GPU card but this run was prematurely interrupted due to a hardware failure and we noticed that it converges slower in terms"
W17-4734,W14-3354,0,0.0640118,"Missing"
W17-4734,P16-5005,0,0.0206781,"with the OpenNMT framework (Klein et al., 2017), which is a multi-layer LSTM encoder decoder network. We trained the models with 2.1 million parallel sentence pairs concatenated with 2.8 million pairs from backtranslation provided by University of Edinburgh. The networks have 1024 hidden units for each of 2 LSTM layers for both encoder and decoder. Furthermore, we experiment a number of features with the baseline: First, we found out that using a context gate to mask activities between the decoder hidden state and the source context vector before producing the distribution at each time step (Tu et al., 2016a) is simple yet beneficial for performance. Second, we strengthen the attentional network with a coverage vector accumulating the previous attentional information, similar to the work of Mi et al. (2016) and Tu et al. (2016b). Using the two techniques helps improve the BLEU score on the newsdev2017 set by 1.1 (tokenized) BLEU. By using ensembling 3 networks with different configs and rescoring using a model trained with reversed target sentences, we managed to reach 26.96 BLEU score for the development set, which yields 2.8 point of improvement compared to the baseline model. Details about th"
W17-4734,P16-1008,0,0.0235141,"with the OpenNMT framework (Klein et al., 2017), which is a multi-layer LSTM encoder decoder network. We trained the models with 2.1 million parallel sentence pairs concatenated with 2.8 million pairs from backtranslation provided by University of Edinburgh. The networks have 1024 hidden units for each of 2 LSTM layers for both encoder and decoder. Furthermore, we experiment a number of features with the baseline: First, we found out that using a context gate to mask activities between the decoder hidden state and the source context vector before producing the distribution at each time step (Tu et al., 2016a) is simple yet beneficial for performance. Second, we strengthen the attentional network with a coverage vector accumulating the previous attentional information, similar to the work of Mi et al. (2016) and Tu et al. (2016b). Using the two techniques helps improve the BLEU score on the newsdev2017 set by 1.1 (tokenized) BLEU. By using ensembling 3 networks with different configs and rescoring using a model trained with reversed target sentences, we managed to reach 26.96 BLEU score for the development set, which yields 2.8 point of improvement compared to the baseline model. Details about th"
W17-4734,P12-3008,0,0.0243602,"Missing"
W17-4735,W09-0432,0,\N,Missing
W17-4735,W05-0909,0,\N,Missing
W17-4735,W17-4711,1,\N,Missing
W18-6318,P02-1040,0,\N,Missing
W18-6318,D14-1003,1,\N,Missing
W18-6318,N03-1017,0,\N,Missing
W18-6318,J03-1002,1,\N,Missing
W18-6318,P14-1138,0,\N,Missing
W18-6318,P13-1017,0,\N,Missing
W18-6318,D16-1162,0,\N,Missing
W18-6318,2016.amta-researchers.10,0,\N,Missing
W18-6318,D16-1249,0,\N,Missing
W18-6318,W16-2206,1,\N,Missing
W18-6318,P17-1141,0,\N,Missing
W18-6318,W17-4711,1,\N,Missing
W18-6318,W17-4716,0,\N,Missing
W18-6318,P18-2060,1,\N,Missing
W18-6318,D16-1138,0,\N,Missing
W18-6409,E17-3017,0,0.0644998,"Missing"
W18-6409,P07-2045,0,0.0194962,"slation (NMT) systems of the RWTH Aachen University developed for the English ↔ German news translation task of the EMNLP 2018 Third Conference on Machine Translation (WMT 2018). Our work is based on iterative back-translation using a shared encoder-decoder NMT model. We extensively compare different vocabulary types, word embedding initialization schemes and optimization methods for our model. We also investigate gating and weight normalization for the word embedding layer. 1 2 Pre- and Postprocessing Our preprocessing pipeline consists of a tokenization with a script from the Moses toolkit (Koehn et al., 2007), lower-casing, and the introduction of a number category token which replaces all occurrences of numbers. We use joint BPE in our experiments and apply it at this stage of preprocessing. After the search procedure, we first monotonically replace number tokens with their original content, and unknown words to the target hypothesis by their order of occurrence in the source sentence. This method is very restrictive, as it fails when, e.g., more unknown tokens are hypothesized than there are in the source sentence due to an unknown token being attended twice. Since, to our knowledge, there are n"
W18-6409,Q17-1010,0,0.122245,"Missing"
W18-6409,J82-2005,0,0.52989,"Missing"
W18-6409,P11-2031,0,0.0348676,"alized with the value of 1. √ vfj · Ef (fj ) · D f¯j = + pos(j) (7) ||Ef (fj )||2 4 4.2 We constrain our results to the newstest2017 and newstest2018 data sets in the German → English translation direction. B LEU (Papineni et al., 2002), computed with mteval from the Moses toolkit (Koehn et al., 2007), and T ER (Snover et al., 2006), computed with TERCom, are used as evaluation metrics. B LEU scores are casesensitive and T ER is scored lower-cased. All presented scores are percentages. For the experiments in Sections 5.3 and 5.4 we additionally test for statistical significance with MultEval (Clark et al., 2011). Lample et al. (2017) propose a model selection criterion based on round-trip B LEU scores, however we do not notice a correlation of this measure and B LEU between experiments. The more expressive the model is, the better round-trip B LEU scores it will get, whereas B LEU itself does not change. Therefore we choose to validate on newstest2015 on the German → English translation direction for the feature study. For our final submission, we select optimization method, embedding initialization and vocabulary types based on B LEU on the German → English direction of newstest2017 and select the b"
W18-6409,P02-1040,0,0.100619,"ntinuous output values and therefore might cause very high or low gradient values in the encoder and decoder parameters, especially at the beginning of training. Weight normalization (Salimans and Kingma, 2016), as shown in Equation 7, normalizes each word embedding by its L2 -norm and introduces an additional tunable parameter vfj for each word, that rescales the vector. It is initialized with the value of 1. √ vfj · Ef (fj ) · D f¯j = + pos(j) (7) ||Ef (fj )||2 4 4.2 We constrain our results to the newstest2017 and newstest2018 data sets in the German → English translation direction. B LEU (Papineni et al., 2002), computed with mteval from the Moses toolkit (Koehn et al., 2007), and T ER (Snover et al., 2006), computed with TERCom, are used as evaluation metrics. B LEU scores are casesensitive and T ER is scored lower-cased. All presented scores are percentages. For the experiments in Sections 5.3 and 5.4 we additionally test for statistical significance with MultEval (Clark et al., 2011). Lample et al. (2017) propose a model selection criterion based on round-trip B LEU scores, however we do not notice a correlation of this measure and B LEU between experiments. The more expressive the model is, the"
W18-6409,D18-2015,1,0.867836,"Missing"
W18-6409,P16-1162,0,0.0798328,"concepts proposed in previous research and perform a thorough comparison of the main components of each method. Additionally, we augment the word embedding initialization with weight normalization to improve its integration in the model and with a gating technique to allow the model to learn task specific information. The main findings of this paper are: (i) the iterative method (Lample et al., 2017) outperforms the online training method (Artetxe et al., 2017), (ii) cross-lingual embedding initialization is required in the online method and (iii) byte-pair encoding (BPE)-based vocabularies (Sennrich et al., 2016) outperform word-based vocabularies in online training. This paper is organized as follows: Section 2 describes pre- and postprocessing pipelines, corpora selection and vocabularies used in our experiments. Section 3 details the models used in this work together with the embedding augmentation 2.1 Corpora Selection We use monolingual News Crawl articles from 2014 to 20171 as our training corpora for both German and English languages. 100M sentences are sub-sampled for pre-training word embeddings and 5M sentences are used for translation model training. 1 http://www.statmt.org/wmt18/ translati"
W18-6409,2006.amta-papers.25,0,0.0645672,"decoder parameters, especially at the beginning of training. Weight normalization (Salimans and Kingma, 2016), as shown in Equation 7, normalizes each word embedding by its L2 -norm and introduces an additional tunable parameter vfj for each word, that rescales the vector. It is initialized with the value of 1. √ vfj · Ef (fj ) · D f¯j = + pos(j) (7) ||Ef (fj )||2 4 4.2 We constrain our results to the newstest2017 and newstest2018 data sets in the German → English translation direction. B LEU (Papineni et al., 2002), computed with mteval from the Moses toolkit (Koehn et al., 2007), and T ER (Snover et al., 2006), computed with TERCom, are used as evaluation metrics. B LEU scores are casesensitive and T ER is scored lower-cased. All presented scores are percentages. For the experiments in Sections 5.3 and 5.4 we additionally test for statistical significance with MultEval (Clark et al., 2011). Lample et al. (2017) propose a model selection criterion based on round-trip B LEU scores, however we do not notice a correlation of this measure and B LEU between experiments. The more expressive the model is, the better round-trip B LEU scores it will get, whereas B LEU itself does not change. Therefore we cho"
W18-6409,W10-1738,1,0.803775,"their order of occurrence in the source sentence. This method is very restrictive, as it fails when, e.g., more unknown tokens are hypothesized than there are in the source sentence due to an unknown token being attended twice. Since, to our knowledge, there are no well-founded methods of pin-pointing which source words are attended during the generation of a target word in the Transformer (Vaswani et al., 2017), we decided for the forementioned method. As postprocessing, we first convert subwords to words. Lower-cased words are then frequentcased using the tools provided in the Jane toolkit (Vilar et al., 2010). As a final step, the text is detokenized using the detokenizer from Moses and punctuation is normalized. Introduction Unsupervised NMT was recently investigated in (Artetxe et al., 2017; Lample et al., 2017, 2018) and has shown promising results in language pairs like German to English. For the WMT 2018 unsupervised learning track, we combine the concepts proposed in previous research and perform a thorough comparison of the main components of each method. Additionally, we augment the word embedding initialization with weight normalization to improve its integration in the model and with a g"
W18-6409,P18-1005,0,0.031431,"roach, the pre-trained vectors are not updated during training. Ding and Duh (2018) perform a simpler approach to combine both kinds of embeddings, in which they concatenate the word vectors and, as in this work, keep the pre-trained embeddings fixed during training. 1. Translate monolingual corpora with the model at iteration n − 1 2. Train for one epoch on the back-translated and monolingual corpora Throughout this work, we denote an iteration as the forementioned steps. We restrict ourselves to only one epoch for model training per iteration, 379 Our idea is most similar to the concept in (Yang et al., 2018), where the authors also employ a gating mechanism on the embeddings, but combine it with the output of the encoder in order to reinforce a language-independent encoder representation. 3.5 Model optimization is performed with the AdaM (Kingma and Ba, 2014) algorithm using a learning rate of 10−4 and a momentum parameter β1 = 0.5. Training sequences are limited to 50 words or subwords. Parameters are initialized with Glorot initialization (Glorot and Bengio, 2010). The batch method is trained for 5 iterations, 800K updates, for a total of 6 days and the online method is trained for roughly the"
W19-4309,2009.mtsummit-btm.6,0,0.0929124,"Missing"
W19-4309,P16-1189,0,0.0197078,"translation parameters (Koehn and Knowles, 2017). Even for high-resource language pairs, it is common to augment the training data with web-crawled bilingual sentences to improve the translation performance (Bojar et al., 2018). Using crawled data in MT typically involves two core steps: mining and filtering. Mining parallel sentences, i.e. aligning source and target sentences, is usually done with lots of heuristics and features: document/URL meta information (Resnik and Smith, 2003; Espl´a-Gomis and Forcada, 2009), sentence lengths with selfinduced lexicon (Moore, 2002; Varga et al., 2005; Etchegoyhen and Azpeitia, 2016), word alignment statistics and linguistic tags (S.tef˘anescu et al., 2012; Kaufmann, 2012). Filtering aligned sentence pairs also often involves heavy feature engineering (Taghipour et al., • We propose a simple end-to-end training approach of bilingual sentence embeddings with parallel and monolingual data only of the corresponding language pair. • We use a multilayer perceptron (MLP) as a trainable similarity measure to match source and target sentence embeddings. • We compare various similarity measures for embeddings in terms of score distribution, geometric interpretation, and performanc"
W19-4309,P17-1042,0,0.0717948,"Missing"
W19-4309,W18-6317,0,0.160623,"similarity between the source embedding vector and the target embedding vector. It is much more efficient than scoring by decoding, e.g. with a translation model. Bilingual sentence embeddings have been studied primarily for transfer learning of monolingual downstream tasks across languages (Hermann and Blunsom, 2014; Pham et al., 2015; Zhou et al., 2016). However, few papers apply it to bilingual corpus mining; many of them require parallel training data with additional pivot languages (Espana-Bonet et al., 2017; Schwenk, 2018) or lack an investigation into similarity between the embeddings (Guo et al., 2018). This work solves these issues as follows: We propose a novel model architecture and training algorithm to learn bilingual sentence embeddings from a combination of parallel and monolingual data. Our method connects autoencoding and neural machine translation to force the source and target sentence embeddings to share the same space without the help of a pivot language or an additional transformation. We train a multilayer perceptron on top of the sentence embeddings to extract good bilingual sentence pairs from nonparallel or noisy parallel data. Our approach shows promising performance on s"
W19-4309,P14-1006,0,0.0418409,". Bilingual sentence embeddings can be an elegant and unified solution for parallel corpus mining and filtering. They compress the information of each sentence into a single vector, which lies in a shared space between source and target languages. Scoring a source-target sentence pair is done by computing similarity between the source embedding vector and the target embedding vector. It is much more efficient than scoring by decoding, e.g. with a translation model. Bilingual sentence embeddings have been studied primarily for transfer learning of monolingual downstream tasks across languages (Hermann and Blunsom, 2014; Pham et al., 2015; Zhou et al., 2016). However, few papers apply it to bilingual corpus mining; many of them require parallel training data with additional pivot languages (Espana-Bonet et al., 2017; Schwenk, 2018) or lack an investigation into similarity between the embeddings (Guo et al., 2018). This work solves these issues as follows: We propose a novel model architecture and training algorithm to learn bilingual sentence embeddings from a combination of parallel and monolingual data. Our method connects autoencoding and neural machine translation to force the source and target sentence"
W19-4309,Q17-1010,0,0.0448804,"ence embedding and the MLP similarity on two tasks: sentence alignment recovery and parallel corpus filtering. The sentence embedding was trained with WMT 2018 English-German parallel data and 100M German sentences from the News Crawl monolingual data1 , where we use German as the autoencoded language. All sentences were lowercased and limited to the length of 60. We learned the byte pair encoding (Sennrich et al., 2016) jointly for the two languages with 20k merge operations. We pre-trained bilingual word embeddings on 100M sentences from the News Crawl data for each language using FASTTEXT (Bojanowski et al., 2017) and MUSE (Conneau et al., 2018). Our sentence embedding model has 1-layer RNN encoder/decoder, where the word embedding and hidden layers have a size of 512. The training was done with stochastic gradient descent with initial learning rate of 1.0, batch size of 120 sentences, and maximum 800k updates. After 100k updates, we reduced the learning rate by a factor of 0.9 for every 50k updates. Our MLP similarity model has 2 hidden layers of size 512 with ReLU (Nair and Hinton, 2010), trained with SCIKIT- LEARN (Pedregosa et al., 2011) with maximum 1,000 updates. For a positive training set, we u"
W19-4309,E17-3017,0,0.0604814,"Missing"
W19-4309,P12-1092,0,0.0622461,"ation while preserving strong performance in parallel corpus filtering. Neither of the above-mentioned methods utilize monolingual data. We integrate autoencoding into NMT to maximize the usage of parallel and monolingual data together in learning bilingual sentence embeddings. pus filtering tasks without a complex combination of translation/language models. • We analyze the effect of negative examples on training an MLP similarity, using different levels of negativity. 2 Related Work Bilingual representation of a sentence was at first built by averaging pre-trained bilingual word embeddings (Huang et al., 2012; Klementiev et al., 2012). The compositionality from words to sentences is integrated into end-to-end training in Hermann and Blunsom (2014). Explicit modeling of a sentence-level bilingual embedding was first discussed in Chandar et al. (2013), training an autoencoder on monolingual sentence embeddings of two languages. Pham et al. (2015) jointly learn bilingual sentence and word embeddings by feeding a shared sentence embedding to n-gram models. Zhou et al. (2016) add document-level alignment information to this model as a constraint in training. Recently, sequence-to-sequence NMT models we"
W19-4309,W18-6478,0,0.0210459,"domains. Artetxe and Schwenk (2018b) relax this data condition to pairwise parallel data including the pivot language, but it is still unrealistic for many scenarios (see Section 4.2). In contrast, our method needs only parallel and monolingual data for source and target languages of concern without any pivot languages. Hassan et al. (2018) train a bidirectional NMT model with a single encoder-decoder, taking the average of top-layer encoder states as the sentence embedding. They do not include any details on the data or translation performance before/after the filtering with this embedding. Junczys-Dowmunt (2018) apply this method to WMT 2018 parallel corpus filtering task, yet showing significantly worse performance than a combination of translation/language models. Our method shows comparable results to such model combinations in the same task. Guo et al. (2018) replace the decoder with a 3 Bilingual Sentence Embeddings A bilingual sentence embedding function maps sentences from both the source and target language into a single joint vector space. Once we obtain such a space, we can search for a similar target sentence embedding given a source sentence embedding, or vice versa. 3.1 Model In this wor"
W19-4309,C12-3035,0,0.0293869,"ugment the training data with web-crawled bilingual sentences to improve the translation performance (Bojar et al., 2018). Using crawled data in MT typically involves two core steps: mining and filtering. Mining parallel sentences, i.e. aligning source and target sentences, is usually done with lots of heuristics and features: document/URL meta information (Resnik and Smith, 2003; Espl´a-Gomis and Forcada, 2009), sentence lengths with selfinduced lexicon (Moore, 2002; Varga et al., 2005; Etchegoyhen and Azpeitia, 2016), word alignment statistics and linguistic tags (S.tef˘anescu et al., 2012; Kaufmann, 2012). Filtering aligned sentence pairs also often involves heavy feature engineering (Taghipour et al., • We propose a simple end-to-end training approach of bilingual sentence embeddings with parallel and monolingual data only of the corresponding language pair. • We use a multilayer perceptron (MLP) as a trainable similarity measure to match source and target sentence embeddings. • We compare various similarity measures for embeddings in terms of score distribution, geometric interpretation, and performance in downstream tasks. • We demonstrate competitive performance in sentence alignment recov"
W19-4309,2012.eamt-1.37,0,0.0499692,"Missing"
W19-4309,C12-1089,0,0.0401476,"ng strong performance in parallel corpus filtering. Neither of the above-mentioned methods utilize monolingual data. We integrate autoencoding into NMT to maximize the usage of parallel and monolingual data together in learning bilingual sentence embeddings. pus filtering tasks without a complex combination of translation/language models. • We analyze the effect of negative examples on training an MLP similarity, using different levels of negativity. 2 Related Work Bilingual representation of a sentence was at first built by averaging pre-trained bilingual word embeddings (Huang et al., 2012; Klementiev et al., 2012). The compositionality from words to sentences is integrated into end-to-end training in Hermann and Blunsom (2014). Explicit modeling of a sentence-level bilingual embedding was first discussed in Chandar et al. (2013), training an autoencoder on monolingual sentence embeddings of two languages. Pham et al. (2015) jointly learn bilingual sentence and word embeddings by feeding a shared sentence embedding to n-gram models. Zhou et al. (2016) add document-level alignment information to this model as a constraint in training. Recently, sequence-to-sequence NMT models were adapted to learn cross-"
W19-4309,W18-6453,0,0.0452699,"Missing"
W19-4309,P16-1162,0,0.0458575,"English→German NMT models. Each NMT model is a 3-layer base Transformer (Vaswani et al., 2017) trained on the same training data as the sentence embedding. Evaluation We evaluated our bilingual sentence embedding and the MLP similarity on two tasks: sentence alignment recovery and parallel corpus filtering. The sentence embedding was trained with WMT 2018 English-German parallel data and 100M German sentences from the News Crawl monolingual data1 , where we use German as the autoencoded language. All sentences were lowercased and limited to the length of 60. We learned the byte pair encoding (Sennrich et al., 2016) jointly for the two languages with 20k merge operations. We pre-trained bilingual word embeddings on 100M sentences from the News Crawl data for each language using FASTTEXT (Bojanowski et al., 2017) and MUSE (Conneau et al., 2018). Our sentence embedding model has 1-layer RNN encoder/decoder, where the word embedding and hidden layers have a size of 512. The training was done with stochastic gradient descent with initial learning rate of 1.0, batch size of 120 sentences, and maximum 800k updates. After 100k updates, we reduced the learning rate by a factor of 0.9 for every 50k updates. Our M"
W19-4309,W17-3204,0,0.0154316,"t the help of a pivot language or an additional transformation. We train a multilayer perceptron on top of the sentence embeddings to extract good bilingual sentence pairs from nonparallel or noisy parallel data. Our approach shows promising performance on sentence alignment recovery and the WMT 2018 parallel corpus filtering tasks with only a single model. 1 Introduction Data crawling is increasingly important in machine translation (MT), especially for neural network models. Without sufficient bilingual data, neural machine translation (NMT) fails to learn meaningful translation parameters (Koehn and Knowles, 2017). Even for high-resource language pairs, it is common to augment the training data with web-crawled bilingual sentences to improve the translation performance (Bojar et al., 2018). Using crawled data in MT typically involves two core steps: mining and filtering. Mining parallel sentences, i.e. aligning source and target sentences, is usually done with lots of heuristics and features: document/URL meta information (Resnik and Smith, 2003; Espl´a-Gomis and Forcada, 2009), sentence lengths with selfinduced lexicon (Moore, 2002; Varga et al., 2005; Etchegoyhen and Azpeitia, 2016), word alignment s"
W19-4309,P15-1107,0,0.035249,"and take the last decoder state sI as the sentence embedding of eI1 , but it is not compatible with the source embedding and contradicts the way in which the model is trained. Therefore, we attach another encoder of the target language to the same (target) decoder: Element-wise Max-pooling hJ ¯1 h ¯2 h ... ¯ I = enctgt (eI ) h 1 1 >  ¯ ¯ s0 = max hi1 , ... , max hiD ¯I h i=1,...,I f1 f2 fJ e1 e2 enctgt has the same architecture as encsrc . The model has now an additional information flow from a target input sentence to the same target (output) sentence, also known as sequential autoencoder (Li et al., 2015). Figure 1 is a diagram of our model. A decoder is shared between NMT and autoencoding parts; it takes either source or target sentence embedding and does not differentiate between the two when producing an output. The two encoders are constrained to provide mathematically consistent representations over the languages (to the decoder). Note that our model does not have any attention component (Bahdanau et al., 2014). The attention mechanism in NMT makes the decoder attend to encoder representations at all source positions. This is counterintuitive for our purpose; we need to optimize the encod"
W19-4309,2011.mtsummit-papers.47,1,0.796087,"Missing"
W19-4309,moore-2002-fast,0,0.14849,"n (NMT) fails to learn meaningful translation parameters (Koehn and Knowles, 2017). Even for high-resource language pairs, it is common to augment the training data with web-crawled bilingual sentences to improve the translation performance (Bojar et al., 2018). Using crawled data in MT typically involves two core steps: mining and filtering. Mining parallel sentences, i.e. aligning source and target sentences, is usually done with lots of heuristics and features: document/URL meta information (Resnik and Smith, 2003; Espl´a-Gomis and Forcada, 2009), sentence lengths with selfinduced lexicon (Moore, 2002; Varga et al., 2005; Etchegoyhen and Azpeitia, 2016), word alignment statistics and linguistic tags (S.tef˘anescu et al., 2012; Kaufmann, 2012). Filtering aligned sentence pairs also often involves heavy feature engineering (Taghipour et al., • We propose a simple end-to-end training approach of bilingual sentence embeddings with parallel and monolingual data only of the corresponding language pair. • We use a multilayer perceptron (MLP) as a trainable similarity measure to match source and target sentence embeddings. • We compare various similarity measures for embeddings in terms of score d"
W19-4309,D17-1319,0,0.0472068,"Missing"
W19-4309,W15-1512,0,0.0840953,"ings can be an elegant and unified solution for parallel corpus mining and filtering. They compress the information of each sentence into a single vector, which lies in a shared space between source and target languages. Scoring a source-target sentence pair is done by computing similarity between the source embedding vector and the target embedding vector. It is much more efficient than scoring by decoding, e.g. with a translation model. Bilingual sentence embeddings have been studied primarily for transfer learning of monolingual downstream tasks across languages (Hermann and Blunsom, 2014; Pham et al., 2015; Zhou et al., 2016). However, few papers apply it to bilingual corpus mining; many of them require parallel training data with additional pivot languages (Espana-Bonet et al., 2017; Schwenk, 2018) or lack an investigation into similarity between the embeddings (Guo et al., 2018). This work solves these issues as follows: We propose a novel model architecture and training algorithm to learn bilingual sentence embeddings from a combination of parallel and monolingual data. Our method connects autoencoding and neural machine translation to force the source and target sentence embeddings to share"
W19-4309,P16-1133,0,0.053472,"Missing"
W19-4309,J03-3002,0,0.166902,", especially for neural network models. Without sufficient bilingual data, neural machine translation (NMT) fails to learn meaningful translation parameters (Koehn and Knowles, 2017). Even for high-resource language pairs, it is common to augment the training data with web-crawled bilingual sentences to improve the translation performance (Bojar et al., 2018). Using crawled data in MT typically involves two core steps: mining and filtering. Mining parallel sentences, i.e. aligning source and target sentences, is usually done with lots of heuristics and features: document/URL meta information (Resnik and Smith, 2003; Espl´a-Gomis and Forcada, 2009), sentence lengths with selfinduced lexicon (Moore, 2002; Varga et al., 2005; Etchegoyhen and Azpeitia, 2016), word alignment statistics and linguistic tags (S.tef˘anescu et al., 2012; Kaufmann, 2012). Filtering aligned sentence pairs also often involves heavy feature engineering (Taghipour et al., • We propose a simple end-to-end training approach of bilingual sentence embeddings with parallel and monolingual data only of the corresponding language pair. • We use a multilayer perceptron (MLP) as a trainable similarity measure to match source and target sentenc"
W19-4309,L16-1561,0,0.0763216,"Missing"
W19-4309,W18-6487,1,0.893114,"Missing"
W19-4309,P18-2037,0,0.198364,"nd target languages. Scoring a source-target sentence pair is done by computing similarity between the source embedding vector and the target embedding vector. It is much more efficient than scoring by decoding, e.g. with a translation model. Bilingual sentence embeddings have been studied primarily for transfer learning of monolingual downstream tasks across languages (Hermann and Blunsom, 2014; Pham et al., 2015; Zhou et al., 2016). However, few papers apply it to bilingual corpus mining; many of them require parallel training data with additional pivot languages (Espana-Bonet et al., 2017; Schwenk, 2018) or lack an investigation into similarity between the embeddings (Guo et al., 2018). This work solves these issues as follows: We propose a novel model architecture and training algorithm to learn bilingual sentence embeddings from a combination of parallel and monolingual data. Our method connects autoencoding and neural machine translation to force the source and target sentence embeddings to share the same space without the help of a pivot language or an additional transformation. We train a multilayer perceptron on top of the sentence embeddings to extract good bilingual sentence pairs fro"
W19-4309,W17-2619,0,0.47874,"ords to sentences is integrated into end-to-end training in Hermann and Blunsom (2014). Explicit modeling of a sentence-level bilingual embedding was first discussed in Chandar et al. (2013), training an autoencoder on monolingual sentence embeddings of two languages. Pham et al. (2015) jointly learn bilingual sentence and word embeddings by feeding a shared sentence embedding to n-gram models. Zhou et al. (2016) add document-level alignment information to this model as a constraint in training. Recently, sequence-to-sequence NMT models were adapted to learn cross-lingual sentence embeddings. Schwenk and Douze (2017) connect multiple source encoders to a shared decoder of a pivot target language, forcing the consistency of encoder representations. Schwenk (2018) extend this work to use a single encoder for many source languages. Both methods rely on N -way parallel training data, which are seriously limited to certain languages and domains. Artetxe and Schwenk (2018b) relax this data condition to pairwise parallel data including the pivot language, but it is still unrealistic for many scenarios (see Section 4.2). In contrast, our method needs only parallel and monolingual data for source and target langua"
W19-4309,W18-6401,0,\N,Missing
W19-5205,P11-2031,0,0.114919,"Missing"
W19-5205,D18-1045,0,0.298264,"a restricted search space. Our statements are investigated on the WMT 2018 German ↔ English news translation task. 1 Introduction Neural machine translation (NMT) (Bahdanau et al., 2014; Vaswani et al., 2017) systems make use of back-translation (Sennrich et al., 2016a) to leverage monolingual data during the training. Here an inverse, target-to-source, translation model generates synthetic source sentences, by translating a target monolingual corpus, which are then jointly used as bilingual data. Sampling-based synthetic data generation schemes were recently shown to outperform beam search (Edunov et al., 2018; Imamura et al., 2018). However, the generated corpora are reported to stray away from the distribution of natural data (Edunov et al., 2018). In this work, we focus on investigating why sampling creates better training data by re-writing the loss criterion of an NMT model to include a model-based data generator. 2 Related Work Sennrich et al. (2016a) introduce the backtranslation technique for NMT and show that the quality of the back-translation model, and therefore resulting pseudo-corpus, has a positive effect on the quality of the subsequent source-to-target model. These findings are fur"
W19-5205,J93-2003,0,0.0865454,"250k updates for all variants. Table 1 showcases the translation quality of the models trained on different kinds of synthetic corpora. Contrary to the observations in Edunov et al. (2018), unrestricted sampling does not outperform beam search and once the search space is restricted all methods perform similarly well. To further investigate this, we look at other relevant statistics of a generated corpus and the performance of the subsequent models in Table 2. These are the perplexities (P PL) of the model on the training and development data and the entropy of a target-to-source IBM-1 model (Brown et al., 1993) trained with GIZA++ (Och and Ney, 2003). The training set P PL varies strongly with each generation method since each produces hypotheses of differing quality. All methods with a restricted search space have a larger translation entropy and smaller training P PL than natural data. This is due to the sentences being less noisy and also the translation options being less varied. Unrestricted sam5.3 Real-world Scenario Previously, we applied different synthetic data generation methods to a controlled scenario for the purpose of investigation. We extend the experiments to the original WMT 2018 Ge"
W19-5205,E17-3017,0,0.0326212,"nimum probability and (ii) weighted sampling from the N -best candidates. D⊂Dsrc :|D|=N 5 5.1 Experiments Setup This section makes use of the WMT 2018 German ↔ English 3 news translation task, consisting of 5.9M bilingual sentences. The German and English monolingual data is subsampled from the deduplicated NewsCrawl2017 corpus. In total 4M sentences are used for German and English monolingual data. All data is tokenized, true-cased and then preprocessed with joint byte pair encoding (Sennrich et al., 2016b)4 . We train Base Transformer (Vaswani et al., 2017) models using the Sockeye toolkit (Hieber et al., 2017). Optimization is done with Adam (Kingma and Ba, 2014) with a learning rate of 3e4, multiplied with 0.7 after every third 20k-update checkpoint without improvements in development set perplexity. In Sections 5.2 and 5.3, word batch sizes of 16k and 4k are used respectively. Inference uses a beam size of 5 and applies hypothesis length normalization. Case-sensitive B LEU (Papineni et al., 2002) is computed using the mteval 13a.pl script from Moses (Koehn et al., 2007). Model selection is performed based on the B LEU performance on newstest2015. All experiments were performed using the workflow"
W19-5205,W18-6315,0,0.0401113,"rated corpora are reported to stray away from the distribution of natural data (Edunov et al., 2018). In this work, we focus on investigating why sampling creates better training data by re-writing the loss criterion of an NMT model to include a model-based data generator. 2 Related Work Sennrich et al. (2016a) introduce the backtranslation technique for NMT and show that the quality of the back-translation model, and therefore resulting pseudo-corpus, has a positive effect on the quality of the subsequent source-to-target model. These findings are further investigated in (Hoang et al., 2018; Burlot and Yvon, 2018) where the authors confirm work effect. In our work, we expand upon this concept by arguing that the quality of the resulting model not only depends on the † Now at DeepL GmbH. 45 Proceedings of the Fourth Conference on Machine Translation (WMT), Volume 1: Research Papers, pages 45–52 c Florence, Italy, August 1-2, 2019. 2019 Association for Computational Linguistics 3.1 data fitness of the back-translation model but also on how sentences are generated from it. Cotterell and Kreutzer (2018) frame backtranslation as a variational process, with the space of source sentences as the latent space."
W19-5205,W18-2703,0,0.0302983,"). However, the generated corpora are reported to stray away from the distribution of natural data (Edunov et al., 2018). In this work, we focus on investigating why sampling creates better training data by re-writing the loss criterion of an NMT model to include a model-based data generator. 2 Related Work Sennrich et al. (2016a) introduce the backtranslation technique for NMT and show that the quality of the back-translation model, and therefore resulting pseudo-corpus, has a positive effect on the quality of the subsequent source-to-target model. These findings are further investigated in (Hoang et al., 2018; Burlot and Yvon, 2018) where the authors confirm work effect. In our work, we expand upon this concept by arguing that the quality of the resulting model not only depends on the † Now at DeepL GmbH. 45 Proceedings of the Fourth Conference on Machine Translation (WMT), Volume 1: Research Papers, pages 45–52 c Florence, Italy, August 1-2, 2019. 2019 Association for Computational Linguistics 3.1 data fitness of the back-translation model but also on how sentences are generated from it. Cotterell and Kreutzer (2018) frame backtranslation as a variational process, with the space of source sentenc"
W19-5205,W18-2707,0,0.429799,"space. Our statements are investigated on the WMT 2018 German ↔ English news translation task. 1 Introduction Neural machine translation (NMT) (Bahdanau et al., 2014; Vaswani et al., 2017) systems make use of back-translation (Sennrich et al., 2016a) to leverage monolingual data during the training. Here an inverse, target-to-source, translation model generates synthetic source sentences, by translating a target monolingual corpus, which are then jointly used as bilingual data. Sampling-based synthetic data generation schemes were recently shown to outperform beam search (Edunov et al., 2018; Imamura et al., 2018). However, the generated corpora are reported to stray away from the distribution of natural data (Edunov et al., 2018). In this work, we focus on investigating why sampling creates better training data by re-writing the loss criterion of an NMT model to include a model-based data generator. 2 Related Work Sennrich et al. (2016a) introduce the backtranslation technique for NMT and show that the quality of the back-translation model, and therefore resulting pseudo-corpus, has a positive effect on the quality of the subsequent source-to-target model. These findings are further investigated in (H"
W19-5205,P07-2045,0,0.02036,"te pair encoding (Sennrich et al., 2016b)4 . We train Base Transformer (Vaswani et al., 2017) models using the Sockeye toolkit (Hieber et al., 2017). Optimization is done with Adam (Kingma and Ba, 2014) with a learning rate of 3e4, multiplied with 0.7 after every third 20k-update checkpoint without improvements in development set perplexity. In Sections 5.2 and 5.3, word batch sizes of 16k and 4k are used respectively. Inference uses a beam size of 5 and applies hypothesis length normalization. Case-sensitive B LEU (Papineni et al., 2002) is computed using the mteval 13a.pl script from Moses (Koehn et al., 2007). Model selection is performed based on the B LEU performance on newstest2015. All experiments were performed using the workflow manager Sisyphus (Peter et al., 2018). We report the statistical significance of 4.2.1 Restricted Sampling The first approach follows sampling directly from the model p(·|eI1 , f1j−1 ) at each position j, but only taking words with at least τ ∈ [0, 0.5) probability into account. Afterwards, another softmax activation2 is performed only over these words by masking all the remaining ones with large negative values. If no words have over τ probability, then the maximum"
W19-5205,J03-1002,1,0.0349749,"owcases the translation quality of the models trained on different kinds of synthetic corpora. Contrary to the observations in Edunov et al. (2018), unrestricted sampling does not outperform beam search and once the search space is restricted all methods perform similarly well. To further investigate this, we look at other relevant statistics of a generated corpus and the performance of the subsequent models in Table 2. These are the perplexities (P PL) of the model on the training and development data and the entropy of a target-to-source IBM-1 model (Brown et al., 1993) trained with GIZA++ (Och and Ney, 2003). The training set P PL varies strongly with each generation method since each produces hypotheses of differing quality. All methods with a restricted search space have a larger translation entropy and smaller training P PL than natural data. This is due to the sentences being less noisy and also the translation options being less varied. Unrestricted sam5.3 Real-world Scenario Previously, we applied different synthetic data generation methods to a controlled scenario for the purpose of investigation. We extend the experiments to the original WMT 2018 German ↔ English task and showcase the res"
W19-5205,P02-1040,0,0.107845,"al data. All data is tokenized, true-cased and then preprocessed with joint byte pair encoding (Sennrich et al., 2016b)4 . We train Base Transformer (Vaswani et al., 2017) models using the Sockeye toolkit (Hieber et al., 2017). Optimization is done with Adam (Kingma and Ba, 2014) with a learning rate of 3e4, multiplied with 0.7 after every third 20k-update checkpoint without improvements in development set perplexity. In Sections 5.2 and 5.3, word batch sizes of 16k and 4k are used respectively. Inference uses a beam size of 5 and applies hypothesis length normalization. Case-sensitive B LEU (Papineni et al., 2002) is computed using the mteval 13a.pl script from Moses (Koehn et al., 2007). Model selection is performed based on the B LEU performance on newstest2015. All experiments were performed using the workflow manager Sisyphus (Peter et al., 2018). We report the statistical significance of 4.2.1 Restricted Sampling The first approach follows sampling directly from the model p(·|eI1 , f1j−1 ) at each position j, but only taking words with at least τ ∈ [0, 0.5) probability into account. Afterwards, another softmax activation2 is performed only over these words by masking all the remaining ones with la"
W19-5205,D18-2015,1,0.776873,"done with Adam (Kingma and Ba, 2014) with a learning rate of 3e4, multiplied with 0.7 after every third 20k-update checkpoint without improvements in development set perplexity. In Sections 5.2 and 5.3, word batch sizes of 16k and 4k are used respectively. Inference uses a beam size of 5 and applies hypothesis length normalization. Case-sensitive B LEU (Papineni et al., 2002) is computed using the mteval 13a.pl script from Moses (Koehn et al., 2007). Model selection is performed based on the B LEU performance on newstest2015. All experiments were performed using the workflow manager Sisyphus (Peter et al., 2018). We report the statistical significance of 4.2.1 Restricted Sampling The first approach follows sampling directly from the model p(·|eI1 , f1j−1 ) at each position j, but only taking words with at least τ ∈ [0, 0.5) probability into account. Afterwards, another softmax activation2 is performed only over these words by masking all the remaining ones with large negative values. If no words have over τ probability, then the maximum probability word is chosen. Note that a large τ gets closer to greedy search (τ ≥ 0.5) and a lower value gets near to unrestricted sampling. q(f |eI1 , f1j−1 ; p) = ("
W19-5205,P16-1009,0,0.508908,"beyond its heuristic usage. Our formulation covers broader synthetic data generation schemes, including sampling from a target-to-source NMT model. With this formulation, we point out fundamental problems of the sampling-based approaches and propose to remedy them by (i) disabling label smoothing for the target-to-source model and (ii) sampling from a restricted search space. Our statements are investigated on the WMT 2018 German ↔ English news translation task. 1 Introduction Neural machine translation (NMT) (Bahdanau et al., 2014; Vaswani et al., 2017) systems make use of back-translation (Sennrich et al., 2016a) to leverage monolingual data during the training. Here an inverse, target-to-source, translation model generates synthetic source sentences, by translating a target monolingual corpus, which are then jointly used as bilingual data. Sampling-based synthetic data generation schemes were recently shown to outperform beam search (Edunov et al., 2018; Imamura et al., 2018). However, the generated corpora are reported to stray away from the distribution of natural data (Edunov et al., 2018). In this work, we focus on investigating why sampling creates better training data by re-writing the loss c"
W19-5205,P16-1162,0,\N,Missing
W97-1014,J93-2003,0,0.0115926,"Missing"
W97-1014,H92-1073,0,\N,Missing
W99-0604,E99-1010,1,0.604945,"alignment A is represented as a matrix with binary values. A matrix element&quot; with value 1 means that the words at the corresponding positions are aligned and the value 0 means that the words are not aligned. If a source word is not aligned to a target word then it is aligned to the empty word e0 which shall be at the imaginary position i = 0. This alignment representation is a generalization of the baseline alignments described in (Brown et al., 1993) and allows for many-to-many alignments. The classes used in F and E are automatically trained bilingual classes using the method described in (Och, 1999) and constitute a partition of the vocabulary of source and target language. The class functions .T and E map words to their classes. The use of classes instead of words themselves has the advantage of a better generalization. If there exist classes in source and target language which contain all towns it is possible that an alignment template learned using a special town can be generalized to all towns. In Fig. 2 an example of an alignment template is shown. An alignment template z = (F, E, A) is app(ilj; A) A(i,j) = EiA(i,j) (4) 3.2 The phrase level alignment In order to describe the phrase"
W99-0604,P97-1037,1,0.808341,"t given in some source language into a target language. We are given a source string f / = fl...fj...fJ, which is to be translated into a target string e{ = el...ei...ex. Among all possible target strings, we will choose the string with the highest probability: = argmax {Pr(ezIlflJ)} e1 = argmax {Pr(e[). Pr(f/le~) } • (1) The argmax operation denotes the search problem, i.e. the generation of the output sentence in the target language. Pr(e{) is the language 20 model of the target language, whereas Pr (ff~lelI) is the translation model. Many statistical translation models (Vogel et al., 1996; Tillmann et al., 1997; Niessen et al., 1998; Brown et al., 1993) try to model word-toword correspondences between source and target words. The model is often further restricted that each source word is assigned exactly one target word. These alignment models are sireilar to the concept of Hidden Markov models (HMM) in speech recognition. The alignment mapping is j ~ i = aj from source position j to target position i = aj. The use of this alignment model raises major problems as it fails to capture dependencies between groups of words. As experiments have shown it is difficult to handle different word order and the"
W99-0604,C96-2141,1,0.916143,"translation of a text given in some source language into a target language. We are given a source string f / = fl...fj...fJ, which is to be translated into a target string e{ = el...ei...ex. Among all possible target strings, we will choose the string with the highest probability: = argmax {Pr(ezIlflJ)} e1 = argmax {Pr(e[). Pr(f/le~) } • (1) The argmax operation denotes the search problem, i.e. the generation of the output sentence in the target language. Pr(e{) is the language 20 model of the target language, whereas Pr (ff~lelI) is the translation model. Many statistical translation models (Vogel et al., 1996; Tillmann et al., 1997; Niessen et al., 1998; Brown et al., 1993) try to model word-toword correspondences between source and target words. The model is often further restricted that each source word is assigned exactly one target word. These alignment models are sireilar to the concept of Hidden Markov models (HMM) in speech recognition. The alignment mapping is j ~ i = aj from source position j to target position i = aj. The use of this alignment model raises major problems as it fails to capture dependencies between groups of words. As experiments have shown it is difficult to handle diffe"
W99-0604,1993.mtsummit-1.11,0,0.062018,"Missing"
W99-0604,P98-2221,0,0.078569,"emented extensions allowing for one-to-many alignments. In section 3 we describe the alignment template approach which explicitly models shallow phrases and in doing so tries to overcome the above mentioned restrictions of singleword alignments. The described method is an improvement of (Och and Weber, 1998), resulting in an improved training and a faster search organization. The basic idea is to model two different alignment levels: a phrase level alignment between phrases and a word level alignment between single words within these phrases. Similar aims are pursued by (Alshawi et al., 1998; Wang and Waibel, 1998) but differently approached. In section 4 we compare the two methods using the Verbmobil task. 2 Single-Word Based Approach new target word is generated. 2.1 B a s i c A p p r o a c h In this section, we shortly review a translation approach based on the so-called monotonicity requirement (Tillmann et al., 1997). Our aim is to provide a basis for comparing the two different translation approaches presented. In Eq. (1), Pr(e~) is the language model, which is a trigram language model in this case. For the translation model Pr(flJ[e{) we make the assumption that each source word is aligned to exa"
W99-0604,J93-2003,0,0.126301,"language. We are given a source string f / = fl...fj...fJ, which is to be translated into a target string e{ = el...ei...ex. Among all possible target strings, we will choose the string with the highest probability: = argmax {Pr(ezIlflJ)} e1 = argmax {Pr(e[). Pr(f/le~) } • (1) The argmax operation denotes the search problem, i.e. the generation of the output sentence in the target language. Pr(e{) is the language 20 model of the target language, whereas Pr (ff~lelI) is the translation model. Many statistical translation models (Vogel et al., 1996; Tillmann et al., 1997; Niessen et al., 1998; Brown et al., 1993) try to model word-toword correspondences between source and target words. The model is often further restricted that each source word is assigned exactly one target word. These alignment models are sireilar to the concept of Hidden Markov models (HMM) in speech recognition. The alignment mapping is j ~ i = aj from source position j to target position i = aj. The use of this alignment model raises major problems as it fails to capture dependencies between groups of words. As experiments have shown it is difficult to handle different word order and the translation of compound nouns• In this pap"
W99-0604,P98-2158,0,0.0277594,"language into a target language. We are given a source string f / = fl...fj...fJ, which is to be translated into a target string e{ = el...ei...ex. Among all possible target strings, we will choose the string with the highest probability: = argmax {Pr(ezIlflJ)} e1 = argmax {Pr(e[). Pr(f/le~) } • (1) The argmax operation denotes the search problem, i.e. the generation of the output sentence in the target language. Pr(e{) is the language 20 model of the target language, whereas Pr (ff~lelI) is the translation model. Many statistical translation models (Vogel et al., 1996; Tillmann et al., 1997; Niessen et al., 1998; Brown et al., 1993) try to model word-toword correspondences between source and target words. The model is often further restricted that each source word is assigned exactly one target word. These alignment models are sireilar to the concept of Hidden Markov models (HMM) in speech recognition. The alignment mapping is j ~ i = aj from source position j to target position i = aj. The use of this alignment model raises major problems as it fails to capture dependencies between groups of words. As experiments have shown it is difficult to handle different word order and the translation of compou"
W99-0604,C98-2153,0,\N,Missing
W99-0604,P98-1006,0,\N,Missing
W99-0604,C98-1006,0,\N,Missing
W99-0604,P98-2162,1,\N,Missing
W99-0604,C98-2157,1,\N,Missing
