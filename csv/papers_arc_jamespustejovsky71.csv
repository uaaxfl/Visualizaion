2021.starsem-1.21,Neural Metaphor Detection with Visibility Embeddings,2021,-1,-1,2,1,992,gitit kehat,Proceedings of *SEM 2021: The Tenth Joint Conference on Lexical and Computational Semantics,0,"We present new results for the problem of sequence metaphor labeling, using the recently developed Visibility Embeddings. We show that concatenating such embeddings to the input of a BiLSTM obtains consistent and significant improvements at almost no cost, and we present further improved results when visibility embeddings are combined with BERT."
2021.naacl-srw.11,Exploration and Discovery of the {COVID}-19 Literature through Semantic Visualization,2021,-1,-1,4,1,3192,jingxuan tu,Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Student Research Workshop,0,"We propose semantic visualization as a linguistic visual analytic method. It can enable exploration and discovery over large datasets of complex networks by exploiting the semantics of the relations in them. This involves extracting information, applying parameter reduction operations, building hierarchical data representation and designing visualization. We also present the accompanying COVID-SemViz a searchable and interactive visualization system for knowledge exploration of COVID-19 data to demonstrate the application of our proposed method. In the user studies, users found that semantic visualization-powered COVID-SemViz is helpful in terms of finding relevant information and discovering unknown associations."
2021.naacl-demos.8,{COVID}-19 Literature Knowledge Graph Construction and Drug Repurposing Report Generation,2021,-1,-1,20,0,4844,qingyun wang,Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Demonstrations,0,"To combat COVID-19, both clinicians and scientists need to digest the vast amount of relevant biomedical knowledge in literature to understand the disease mechanism and the related biological functions. We have developed a novel and comprehensive knowledge discovery framework, COVID-KG to extract fine-grained multimedia knowledge elements (entities, relations and events) from scientific literature. We then exploit the constructed multimedia knowledge graphs (KGs) for question answering and report generation, using drug repurposing as a case study. Our framework also provides detailed contextual sentences, subfigures, and knowledge subgraphs as evidence. All of the data, KGs, reports."
2020.nlpcovid19-2.28,{A}sk{M}e: A {LAPPS} {G}rid-based {NLP} Query and Retrieval System for Covid-19 Literature,2020,-1,-1,5,0,16302,keith suderman,Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020,0,"In a recent project, the Language Application Grid was augmented to support the mining of scientific publications. The results of that ef- fort have now been repurposed to focus on Covid-19 literature, including modification of the LAPPS Grid {``}AskMe{''} query and retrieval engine. We describe the AskMe system and discuss its functionality as compared to other query engines available to search covid-related publications."
2020.lrec-1.684,Reproducing Neural Ensemble Classifier for Semantic Relation Extraction in{S}cientific Papers,2020,-1,-1,4,1,18013,kyeongmin rim,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Within the natural language processing (NLP) community, shared tasks play an important role. They define a common goal and allowthe the comparison of different methods on the same data. SemEval-2018 Task 7 involves the identification and classification of relationsin abstracts from computational linguistics (CL) publications. In this paper we describe an attempt to reproduce the methods and resultsfrom the top performing system at for SemEval-2018 Task 7. We describe challenges we encountered in the process, report on the resultsof our system, and discuss the ways that our attempt at reproduction can inform best practices."
2020.lrec-1.725,A Formal Analysis of Multimodal Referring Strategies Under Common Ground,2020,46,0,2,1,6041,nikhil krishnaswamy,Proceedings of the 12th Language Resources and Evaluation Conference,0,"In this paper, we present an analysis of computationally generated mixed-modality definite referring expressions using combinations of gesture and linguistic descriptions. In doing so, we expose some striking formal semantic properties of the interactions between gesture and language, conditioned on the introduction of content into the common ground between the (computational) speaker and (human) viewer, and demonstrate how these formal features can contribute to training better models to predict viewer judgment of referring expressions, and potentially to the generation of more natural and informative referring expressions."
2020.lrec-1.726,Improving Neural Metaphor Detection with Visual Datasets,2020,-1,-1,2,1,992,gitit kehat,Proceedings of the 12th Language Resources and Evaluation Conference,0,"We present new results on Metaphor Detection by using text from visual datasets. Using a straightforward technique for sampling text from Vision-Language datasets, we create a data structure we term a visibility word embedding. We then combine these embeddings in a relatively simple BiLSTM module augmented with contextualized word representations (ELMo), and show improvement over previous state-of-the-art approaches that use more complex neural network architectures and richer linguistic features, for the task of verb classification."
2020.lrec-1.893,Interchange Formats for Visualization: {LIF} and {MMIF},2020,-1,-1,5,1,18013,kyeongmin rim,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Promoting interoperrable computational linguistics (CL) and natural language processing (NLP) application platforms and interchange-able data formats have contributed improving discoverabilty and accessbility of the openly available NLP software. In this paper, wediscuss the enhanced data visualization capabilities that are also enabled by inter-operating NLP pipelines and interchange formats.For adding openly available visualization tools and graphical annotation tools to the Language Applications Grid (LAPPS Grid) andComputational Linguistics Applications for Multimedia Services (CLAMS) toolboxes, we have developed interchange formats that cancarry annotations and metadata for text and audiovisual source data. We descibe those data formats and present case studies where wesuccessfully adopt open-source visualization tools and combine them with CL tools."
2020.emnlp-tutorials.5,"Representation, Learning and Reasoning on Spatial Language for Downstream {NLP} Tasks",2020,-1,-1,2,0,1061,parisa kordjamshidi,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts,0,"Understating spatial semantics expressed in natural language can become highly complex in real-world applications. This includes applications of language grounding, navigation, visual question answering, and more generic human-machine interaction and dialogue systems. In many of such downstream tasks, explicit representation of spatial concepts and relationships can improve the capabilities of machine learning models in reasoning and deep language understanding. In this tutorial, we overview the cutting-edge research results and existing challenges related to spatial language understanding including semantic annotations, existing corpora, symbolic and sub-symbolic representations, qualitative spatial reasoning, spatial common sense, deep and structured learning models. We discuss the recent results on the above-mentioned applications {--}that need spatial language learning and reasoning {--} and highlight the research gaps and future directions."
2020.dmr-1.1,A Continuation Semantics for {A}bstract {M}eaning {R}epresentation,2020,-1,-1,3,1,20915,kenneth lai,Proceedings of the Second International Workshop on Designing Meaning Representations,0,"Abstract Meaning Representation (AMR) is a simple, expressive semantic framework whose emphasis on predicate-argument structure is effective for many tasks. Nevertheless, AMR lacks a systematic treatment of projection phenomena, making its translation into logical form problematic. We present a translation function from AMR to first order logic using continuation semantics, which allows us to capture the semantic context of an expression in the form of an argument. This is a natural extension of AMR{'}s original design principles, allowing us to easily model basic projection phenomena such as quantification and negation as well as complex phenomena such as bound variables and donkey anaphora."
2020.coling-main.373,A Two-Level Interpretation of Modality in Human-Robot Dialogue,2020,-1,-1,3,0,5431,lucia donatelli,Proceedings of the 28th International Conference on Computational Linguistics,0,"We analyze the use and interpretation of modal expressions in a corpus of situated human-robot dialogue and ask how to effectively represent these expressions for automatic learning. We present a two-level annotation scheme for modality that captures both content and intent, integrating a logic-based, semantic representation and a task-oriented, pragmatic representation that maps to our robot{'}s capabilities. Data from our annotation task reveals that the interpretation of modal expressions in human-robot dialogue is quite diverse, yet highly constrained by the physical environment and asymmetrical speaker/addressee relationship. We sketch a formal model of human-robot common ground in which modality can be grounded and dynamically interpreted."
W19-3303,Modeling Quantification and Scope in {A}bstract {M}eaning {R}epresentations,2019,0,0,1,1,993,james pustejovsky,Proceedings of the First International Workshop on Designing Meaning Representations,0,"In this paper, we propose an extension to Abstract Meaning Representations (AMRs) to encode scope information of quantifiers and negation, in a way that overcomes the semantic gaps of the schema while maintaining its cognitive simplicity. Specifically, we address three phenomena not previously part of the AMR specification: quantification, negation (generally), and modality. The resulting representation, which we call {``}Uniform Meaning Representation{''} (UMR), adopts the predicative core of AMR and embeds it under a {``}scope{''} graph when appropriate. UMR representations differ from other treatments of quantification and modal scope phenomena in two ways: (a) they are more transparent; and (b) they specify default scope when possible.{`}"
W19-3318,{V}erb{N}et Representations: Subevent Semantics for Transfer Verbs,2019,0,1,5,0.640607,4915,susan brown,Proceedings of the First International Workshop on Designing Meaning Representations,0,"This paper announces the release of a new version of the English lexical resource VerbNet with substantially revised semantic representations designed to facilitate computer planning and reasoning based on human language. We use the transfer of possession and transfer of information event representations to illustrate both the general framework of the representations and the types of nuances the new representations can capture. These representations use a Generative Lexicon-inspired subevent structure to track attributes of event participants across time, highlighting oppositions and temporal and causal relations among the subevents."
W19-2512,Computational Linguistics Applications for Multimedia Services,2019,0,0,3,1,18013,kyeongmin rim,"Proceedings of the 3rd Joint {SIGHUM} Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature",0,"We present Computational Linguistics Applications for Multimedia Services (CLAMS), a platform that provides access to computational content analysis tools for archival multimedia material that appear in different media, such as text, audio, image, and video. The primary goal of CLAMS is: (1) to develop an interchange format between multimodal metadata generation tools to ensure interoperability between tools; (2) to provide users with a portable, user-friendly workflow engine to chain selected tools to extract meaningful analyses; and (3) to create a public software development kit (SDK) for developers that eases deployment of analysis tools within the CLAMS platform. CLAMS is designed to help archives and libraries enrich the metadata associated with their mass-digitized multimedia collections, that would otherwise be largely unsearchable."
W19-1915,Distinguishing Clinical Sentiment: The Importance of Domain Adaptation in Psychiatric Patient Health Records,2019,23,0,4,1,24772,eben holderness,Proceedings of the 2nd Clinical Natural Language Processing Workshop,0,"Recently natural language processing (NLP) tools have been developed to identify and extract salient risk indicators in electronic health records (EHRs). Sentiment analysis, although widely used in non-medical areas for improving decision making, has been studied minimally in the clinical setting. In this study, we undertook, to our knowledge, the first domain adaptation of sentiment analysis to psychiatric EHRs by defining psychiatric clinical sentiment, performing an annotation project, and evaluating multiple sentence-level sentiment machine learning (ML) models. Results indicate that off-the-shelf sentiment analysis tools fail in identifying clinically positive or negative polarity, and that the definition of clinical sentiment that we provide is learnable with relatively small amounts of training data. This project is an initial step towards further refining sentiment analysis methods for clinical use. Our long-term objective is to incorporate the results of this project as part of a machine learning model that predicts inpatient readmission risk. We hope that this work will initiate a discussion concerning domain adaptation of sentiment analysis to the clinical setting."
W19-0601,A Dynamic Semantics for Causal Counterfactuals,2019,0,0,2,1,20915,kenneth lai,Proceedings of the 13th International Conference on Computational Semantics - Student Papers,0,"Under the standard approach to counterfactuals, to determine the meaning of a counterfactual sentence, we consider the {``}closest{''} possible world(s) where the antecedent is true, and evaluate the consequent. Building on the standard approach, some researchers have found that the set of worlds to be considered is dependent on context; it evolves with the discourse. Others have focused on how to define the {``}distance{''} between possible worlds, using ideas from causal modeling. This paper integrates the two ideas. We present a semantics for counterfactuals that uses a distance measure based on causal laws, that can also change over time. We show how our semantics can be implemented in the Haskell programming language."
W19-0507,Generating a Novel Dataset of Multimodal Referring Expressions,2019,0,1,2,1,6041,nikhil krishnaswamy,Proceedings of the 13th International Conference on Computational Semantics - Short Papers,0,"Referring expressions and definite descriptions of objects in space exploit information both about object characteristics and locations. To resolve potential ambiguity, referencing strategies in language can rely on increasingly abstract concepts to distinguish an object in a given location from similar ones elsewhere, yet the description of the intended location may still be imprecise or difficult to interpret. Meanwhile, modalities such as gesture may communicate spatial information such as locations in a more concise manner. In real peer-to-peer communication, humans use language and gesture together to reference entities, with a capacity for mixing and changing modalities where needed. While recent progress in AI and human-computer interaction has created systems where a human can interact with a computer multimodally, computers often lack the capacity to intelligently mix modalities when generating referring expressions. We present a novel dataset of referring expressions combining natural language and gesture, describe its creation and evaluation, and its uses to train computational models for generating and interpreting multimodal referring expressions."
D19-6211,Assessing the Efficacy of Clinical Sentiment Analysis and Topic Extraction in Psychiatric Readmission Risk Prediction,2019,17,0,7,0,16850,elena alvarezmellado,Proceedings of the Tenth International Workshop on Health Text Mining and Information Analysis (LOUHI 2019),0,"Predicting which patients are more likely to be readmitted to a hospital within 30 days after discharge is a valuable piece of information in clinical decision-making. Building a successful readmission risk classifier based on the content of Electronic Health Records (EHRs) has proved, however, to be a challenging task. Previously explored features include mainly structured information, such as sociodemographic data, comorbidity codes and physiological variables. In this paper we assess incorporating additional clinically interpretable NLP-based features such as topic extraction and clinical sentiment analysis to predict early readmission risk in psychiatry patients."
W18-5615,Analysis of Risk Factor Domains in Psychosis Patient Health Records,2018,23,0,6,1,24772,eben holderness,Proceedings of the Ninth International Workshop on Health Text Mining and Information Analysis,0,"Readmission after discharge from a hospital is disruptive and costly, regardless of the reason. However, it can be particularly problematic for psychiatric patients, so predicting which patients may be readmitted is critically important but also very difficult. Clinical narratives in psychiatric electronic health records (EHRs) span a wide range of topics and vocabulary; therefore, a psychiatric readmission prediction model must begin with a robust and interpretable topic extraction component. We created a data pipeline for using document vector similarity metrics to perform topic extraction on psychiatric EHR data in service of our long-term goal of creating a readmission risk classifier. We show initial results for our topic extraction model and identify additional features we will be incorporating in the future."
W18-4704,"The Revision of {ISO}-Space,Focused on the Movement Link",2018,-1,-1,2,0,18931,kiyong lee,Proceedings 14th Joint {ACL} - {ISO} Workshop on Interoperable Semantic Annotation,0,None
W18-4301,Every Object Tells a Story,2018,0,1,1,1,993,james pustejovsky,Proceedings of the Workshop Events and Stories in the News 2018,0,"Most work within the computational event modeling community has tended to focus on the interpretation and ordering of events that are associated with verbs and event nominals in linguistic expressions. What is often overlooked in the construction of a global interpretation of a narrative is the role contributed by the objects participating in these structures, and the latent events and activities conventionally associated with them. Recently, the analysis of visual images has also enriched the scope of how events can be identified, by anchoring both linguistic expressions and ontological labels to segments, subregions, and properties of images. By semantically grounding event descriptions in their visualization, the importance of object-based attributes becomes more apparent. In this position paper, we look at the narrative structure of objects: that is, how objects reference events through their intrinsic attributes, such as affordances, purposes, and functions. We argue that, not only do objects encode conventionalized events, but that when they are composed within specific habitats, the ensemble can be viewed as modeling coherent event sequences, thereby enriching the global interpretation of the evolving narrative being constructed."
L18-1009,Integrating {G}enerative {L}exicon Event Structures into {V}erb{N}et,2018,0,0,2,0.640607,4915,susan brown,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
L18-1206,Bridging the {LAPPS} {G}rid and {CLARIN},2018,0,0,3,0,17752,erhard hinrichs,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
L18-1282,Towards an {ISO} Standard for the Annotation of Quantification,2018,0,1,2,0,16745,harry bunt,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
L18-1335,An Evaluation Framework for Multimodal Interaction,2018,0,3,2,1,6041,nikhil krishnaswamy,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
W17-7415,Enriching the Notion of Path in {ISO}-Space,2017,-1,-1,1,1,993,james pustejovsky,Proceedings of the 13th Joint {ISO}-{ACL} Workshop on Interoperable Semantic Annotation ({ISA}-13),0,None
W17-7103,Creating Common Ground through Multimodal Simulations,2017,-1,-1,1,1,993,james pustejovsky,Proceedings of the {IWCS} workshop on Foundations of Situated and Multimodal Communication,0,None
W17-6919,Communicating and Acting: Understanding Gesture in Simulation Semantics,2017,30,4,11,1,6041,nikhil krishnaswamy,{IWCS} 2017 {---} 12th International Conference on Computational Semantics {---} Short papers,0,None
S17-2093,{S}em{E}val-2017 Task 12: Clinical {T}emp{E}val,2017,6,23,4,0,224,steven bethard,Proceedings of the 11th International Workshop on Semantic Evaluation ({S}em{E}val-2017),0,"Clinical TempEval 2017 aimed to answer the question: how well do systems trained on annotated timelines for one medical condition (colon cancer) perform in predicting timelines on another medical condition (brain cancer)? Nine sub-tasks were included, covering problems in time expression identification, event expression identification and temporal relation identification. Participant systems were evaluated on clinical and pathology notes from Mayo Clinic cancer patients, annotated with an extension of TimeML for the clinical domain. 11 teams participated in the tasks, with the best systems achieving F1 scores above 0.55 for time expressions, above 0.70 for event expressions, and above 0.40 for temporal relations. Most tasks observed about a 20 point drop over Clinical TempEval 2016, where systems were trained and evaluated on the same domain (colon cancer)."
I17-2018,Integrating Vision and Language Datasets to Measure Word Concreteness,2017,8,0,2,1,992,gitit kehat,Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 2: Short Papers),0,"We present and take advantage of the inherent visualizability properties of words in visual corpora (the textual components of vision-language datasets) to compute concreteness scores for words. Our simple method does not require hand-annotated concreteness score lists for training, and yields state-of-the-art results when evaluated against concreteness scores lists and previously derived scores, as well as when used for metaphor detection."
E17-5006,Building Multimodal Simulations for Natural Language,2017,-1,-1,1,1,993,james pustejovsky,Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Tutorial Abstracts,0,"In this tutorial, we introduce a computational framework and modeling language (VoxML) for composing multimodal simulations of natural language expressions within a 3D simulation environment (VoxSim). We demonstrate how to construct voxemes, which are visual object representations of linguistic entities. We also show how to compose events and actions over these objects, within a restricted domain of dynamics. This gives us the building blocks to simulate narratives of multiple events or participate in a multimodal dialogue with synthetic agents in the simulation environment. To our knowledge, this is the first time such material has been presented as a tutorial within the CL community.This will be of relevance to students and researchers interested in modeling actionable language, natural language communication with agents and robots, spatial and temporal constraint solving through language, referring expression generation, embodied cognition, as well as minimal model creation.Multimodal simulation of language, particularly motion expressions, brings together a number of existing lines of research from the computational linguistic, semantics, robotics, and formal logic communities, including action and event representation (Di Eugenio, 1991), modeling gestural correlates to NL expressions (Kipp et al., 2007; Neff et al., 2008), and action event modeling (Kipper and Palmer, 2000; Yang et al., 2015). We combine an approach to event modeling with a scene generation approach akin to those found in work by (Coyne and Sproat, 2001; Siskind, 2011; Chang et al., 2015). Mapping natural language expressions through a formal model and a dynamic logic interpretation into a visualization of the event described provides an environment for grounding concepts and referring expressions that is interpretable by both a computer and a human user. This opens a variety of avenues for humans to communicate with computerized agents and robots, as in (Matuszek et al., 2013; Lauria et al., 2001), (Forbes et al., 2015), and (Deits et al., 2013; Walter et al., 2013; Tellex et al., 2014). Simulation and automatic visualization of events from natural language descriptions and supplementary modalities, such as gestures, allows humans to use their native capabilities as linguistic and visual interpreters to collaborate on tasks with an artificial agent or to put semantic intuitions to the test in an environment where user and agent share a common context.In previous work (Pustejovsky and Krishnaswamy, 2014; Pustejovsky, 2013a), we introduced a method for modeling natural language expressions within a 3D simulation environment built on top of the game development platform Unity (Goldstone, 2009). The goal of that work was to evaluate, through explicit visualizations of linguistic input, the semantic presuppositions inherent in the different lexical choices of an utterance. This work led to two additional lines of research: an explicit encoding for how an object is itself situated relative to its environment; and an operational characterization of how an object changes its location or how an agent acts on an object over time, e.g., its affordance structure. The former has developed into a semantic notion of situational context, called a habitat (Pustejovsky, 2013a; McDonald and Pustejovsky, 2014), while the latter is addressed by dynamic interpretations of event structure (Pustejovsky and Moszkowicz, 2011; Pustejovsky and Krishnaswamy, 2016b; Pustejovsky, 2013b).The requirements on building a visual simulation from language include several components. We require a rich type system for lexical items and their composition, as well as a language for modeling the dynamics of events, based on Generative Lexicon (GL). Further, a minimal embedding space (MES) for the simulation must be determined. This is the 3D region within which the state is configured or the event unfolds. Object-based attributes for participants in a situation or event also need to be specified; e.g., orientation, relative size, default position or pose, etc. The simulation establishes an epistemic condition on the object and event rendering, imposing an implicit point of view (POV). Finally, there must be some sort of agent-dependent embodiment; this determines the relative scaling of an agent and its event participants and their surroundings, as it engages in the environment.In order to construct a robust simulation from linguistic input, an event and its participants must be embedded within an appropriate minimal embedding space. This must sufficiently enclose the event localization, while optionally including space enough for a frame of reference for the event (the viewer{\^a}â¬{\mbox{$^\mbox{TM}$}}s perspective).We first describe the formal multimodal foundations for the modeling language, VoxML, which creates a minimal simulation from the linguistic input interpreted by the multimodal language, DITL. We then describe VoxSim, the compositional modeling and simulation environment, which maps the minimal VoxML model of the linguistic utterance to a simulation in Unity. This knowledge includes specification of object affordances, e.g., what actions are possible or enabled by use an object.VoxML (Pustejovsky and Krishnaswamy, 2016b; Pustejovsky and Krishnaswamy, 2016a) encodes semantic knowledge of real-world objects represented as 3D models, and of events and attributes related to and enacted over these objects. VoxML goes beyond the limitations of existing 3D visual markup languages by allowing for the encoding of a broad range of semantic knowledge that can be exploited by a simulation platform such as VoxSim.VoxSim (Krishnaswamy and Pustejovsky, 2016a; Krishnaswamy and Pustejovsky, 2016b) uses object and event semantic knowledge to generate animated scenes in real time without a complex animation interface. It uses the Unity game engine for graphics and I/O processing and takes as input a simple natural language utterance. The parsed utterance is semantically interpreted and transformed into a hybrid dynamic logic representation (DITL), and used to generate a minimal simulation of the event when composed with VoxML knowledge. 3D assets and VoxML-modeled nominal objects and events are created with other Unity-based tools, and VoxSim uses the entirety of the composed information to render a visualization of the described event.The tutorial participants will learn how to build simulatable objects, compose dynamic event structures, and simulate the events running over the objects. The toolkit consists of object and program (event) composers and the runtime environment, which allows for the user to directly manipulate the objects, or interact with synthetic agents in VoxSim. As a result of this tutorial, the student will acquire the following skill set: take a novel object geometry from a library and model it in VoxML; apply existing library behaviors (actions or events) to the new VoxML object; model attributes of new objects as well as introduce novel attributes; model novel behaviors over objects.The tutorial modules will be conducted within a build image of the software. Access to libraries will be provided by the instructors. No knowledge of 3D modeling or the Unity platform will be required."
2017.lilt-15.1,Lexical Factorization and Syntactic Behavior,2017,-1,-1,1,1,993,james pustejovsky,"Linguistic Issues in Language Technology, Volume 15, 2017",0,"In this paper, we examine the correlation between lexical semantics and the syntactic realization of the different components of a word{'}s meaning in natural language. More specifically, we will explore the effect that lexical factorization in verb semantics has on the suppression or expression of semantic features within the sentence. Factorization was a common analytic tool employed in early generative linguistic approaches to lexical decomposition, and continues to play a role in contemporary semantics, in various guises and modified forms. Building on the unpublished analysis of verbs of seeing in Joshi (1972), we argue here that the significance of lexical factorization is twofold: first, current models of verb meaning owe much of their insight to factor-based theories of meaning; secondly, the factorization properties of a lexical item appear to influence, both directly and indirectly, the possible syntactic expressibility of arguments and adjuncts in sentence composition. We argue that this information can be used to compute what we call the factor expression likelihood (FEL) associated with a verb in a sentence. This is the likelihood that the overt syntactic expression of a factor will cooccur with the verb. This has consequences for the compositional mechanisms responsible for computing the meaning of the sentence, as well as significance in the creation of computational models attempting to capture linguistic behavior over large corpora."
W16-5202,{LAPPS}/Galaxy: Current State and Next Steps,2016,0,3,4,0,16303,nancy ide,Proceedings of the Third International Workshop on Worldwide Language Service Infrastructure and Second Workshop on Open Infrastructures and Analysis Frameworks for Human Language Technologies ({WLSI}/{OIAF}4{HLT}2016),0,"The US National Science Foundation (NSF) SI2-funded LAPPS/Galaxy project has developed an open-source platform for enabling complex analyses while hiding complexities associated with underlying infrastructure, that can be accessed through a web interface, deployed on any Unix system, or run from the cloud. It provides sophisticated tool integration and history capabilities, a workflow system for building automated multi-step analyses, state-of-the-art evaluation capabilities, and facilities for sharing and publishing analyses. This paper describes the current facilities available in LAPPS/Galaxy and outlines the project{'}s ongoing activities to enhance the framework."
W16-3807,The Development of Multimodal Lexical Resources,2016,-1,-1,1,1,993,james pustejovsky,Proceedings of the Workshop on Grammar and Lexicon: interactions and interfaces ({G}ram{L}ex),0,"Human communication is a multimodal activity, involving not only speech and written expressions, but intonation, images, gestures, visual clues, and the interpretation of actions through perception. In this paper, we describe the design of a multimodal lexicon that is able to accommodate the diverse modalities that present themselves in NLP applications. We have been developing a multimodal semantic representation, VoxML, that integrates the encoding of semantic, visual, gestural, and action-based features associated with linguistic expressions."
S16-1165,{S}em{E}val-2016 Task 12: Clinical {T}emp{E}val,2016,15,60,5,0.138781,224,steven bethard,Proceedings of the 10th International Workshop on Semantic Evaluation ({S}em{E}val-2016),0,"Clinical TempEval 2016 evaluated temporal information extraction systems on the clinical domain. Nine sub-tasks were included, covering problems in time expression identification, event expression identification and temporal relation identification. Participant systems were trained and evaluated on a corpus of clinical and pathology notes from the Mayo Clinic, annotated with an extension of TimeML for the clinical domain. 14 teams submitted a total of 40 system runs, with the best systems achieving near-human performance on identifying events and times. On identifying temporal relations, there was a gap between the best systems and human performance, but the gap was less than half the gap of Clinical TempEval 2015."
L16-1073,The Language Application Grid and Galaxy,2016,0,0,3,0,16303,nancy ide,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"The NSF-SI2-funded LAPPS Grid project is a collaborative effort among Brandeis University, Vassar College, Carnegie-Mellon University (CMU), and the Linguistic Data Consortium (LDC), which has developed an open, web-based infrastructure through which resources can be easily accessed and within which tailored language services can be efficiently composed, evaluated, disseminated and consumed by researchers, developers, and students across a wide variety of disciplines. The LAPPS Grid project recently adopted Galaxy (Giardine et al., 2005), a robust, well-developed, and well-supported front end for workflow configuration, management, and persistence. Galaxy allows data inputs and processing steps to be selected from graphical menus, and results are displayed in intuitive plots and summaries that encourage interactive workflows and the exploration of hypotheses. The Galaxy workflow engine provides significant advantages for deploying pipelines of LAPPS Grid web services, including not only means to create and deploy locally-run and even customized versions of the LAPPS Grid as well as running the LAPPS Grid in the cloud, but also access to a huge array of statistical and visualization tools that have been developed for use in genomics research."
L16-1730,{V}ox{ML}: A Visualization Modeling Language,2016,23,7,1,1,993,james pustejovsky,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"We present the specification for a modeling language, VoxML, which encodes semantic knowledge of real-world objects represented as three-dimensional models, and of events and attributes related to and enacted over these objects.VoxML is intended to overcome the limitations of existing 3D visual markup languages by allowing for the encoding of a broad range of semantic knowledge that can be exploited by a variety of systems and platforms, leading to multimodal simulations of real-world scenarios using conceptual objects that represent their semantic values"
C16-2012,{V}ox{S}im: A Visual Platform for Modeling Motion Language,2016,12,9,2,1,6041,nikhil krishnaswamy,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: System Demonstrations",0,"Much existing work in text-to-scene generation focuses on generating static scenes. By introducing a focus on motion verbs, we integrate dynamic semantics into a rich formal model of events to generate animations in real time that correlate with human conceptions of the event described. This paper presents a working system that generates these animated scenes over a test set, discussing challenges encountered and describing the solutions implemented."
W15-0204,The Semantics of Image Annotation,2015,32,0,2,0,37152,julia bosquegil,Proceedings of the 11th Joint {ACL}-{ISO} Workshop on Interoperable Semantic Annotation ({ISA}-11),0,None
S15-2134,{S}em{E}val-2015 Task 5: {QA} {T}emp{E}val - Evaluating Temporal Information Understanding with Question Answering,2015,10,22,6,0.75,37290,hector llorens,Proceedings of the 9th International Workshop on Semantic Evaluation ({S}em{E}val 2015),0,"QA TempEval shifts the goal of previous TempEvals away from an intrinsic evaluation methodology toward a more extrinsic goal of question answering. This evaluation requires systems to capture temporal information relevant to perform an end-user task, as opposed to corpus-based evaluation where all temporal information is equally important. Evaluation results show that the best automated TimeML annotations reach over 30% recall on questions with xe2x80x98yesxe2x80x99 answer and about 50% on easier questions with xe2x80x98noxe2x80x99 answers. Features that helped achieve better results are event coreference and a time expression reasoner."
S15-2136,{S}em{E}val-2015 Task 6: Clinical {T}emp{E}val,2015,7,73,4,0.157232,224,steven bethard,Proceedings of the 9th International Workshop on Semantic Evaluation ({S}em{E}val 2015),0,"Clinical TempEval 2015 brought the temporal information extraction tasks of past TempEval campaigns to the clinical domain. Nine sub-tasks were included, covering problems in time expression identification, event expression identification and temporal relation identification. Participant systems were trained and evaluated on a corpus of clinical notes and pathology reports from the Mayo Clinic, annotated with an extension of TimeML for the clinical domain. Three teams submitted a total of 13 system runs, with the best systems achieving near-human performance on identifying events and times, but with a large performance gap still remaining for temporal relations."
S15-2149,{S}em{E}val-2015 Task 8: {S}pace{E}val,2015,27,14,1,1,993,james pustejovsky,Proceedings of the 9th International Workshop on Semantic Evaluation ({S}em{E}val 2015),0,"Human languages exhibit a variety of strategies for communicating spatial information, including toponyms, spatial nominals, locations that are described in relation to other locations, and movements along paths. SpaceEval is a combined information extraction and classification task with the goal of identifying and categorizing such spatial information. In this paper, we describe the SpaceEval task, annotation schema, and corpora, and evaluate the performance of several supervised and semi-supervised machine learning systems developed with the goal of automating this task."
W14-6004,Extracting Aspects and Polarity from Patents,2014,16,0,3,0.434783,38199,peter anick,Proceedings of the {COLING} Workshop on Synchronic and Diachronic Approaches to Analyzing Technical Language,0,"We describe an approach to terminology extraction from patent corpora that follows from a view of patents as xe2x80x9cpositive reviewsxe2x80x9d of inventions. As in aspect-based sentiment analysis, we focus on identifying not only the components of products but also the attributes and tasks which, in the case of patents, serve to justify an inventionxe2x80x99s utility. These semantic roles (component, task, attribute) can serve as a high level ontology for categorizing domain terminology, within which the positive/negative polarity of attributes serves to identify technical goals and obstacles. We show that bootstrapping using a very small set of domain-independent lexico-syntactic features may be sufficient for constructing domainspecific classifiers capable of assigning semantic roles and polarity to terms in domains as diverse as computer science and health."
W14-5204,The Language Application Grid Web Service Exchange Vocabulary,2014,15,10,2,0,16303,nancy ide,Proceedings of the Workshop on Open Infrastructures and Analysis Frameworks for {HLT},0,"In the context of the Linguistic Applications LAPPS Grid project, we have undertaken the definition of a Web Service Exchange Vocabulary WS-EV specifying a terminology for a core of linguistic objects and properties exchanged among NLP tools that consume and produce linguistically annotated data. The goal is not to define a new set of terms, but rather to provide a single web location where terms relevant for exchange among NLP tools are defined and provide a sameAs link to all known web-based definitions that correspond to them. The WS-EV is intended to be used by a federation of six grids currently being formed but is usable by any web service platform."
W14-5206,A Conceptual Framework of Online Natural Language Processing Pipeline Application,2014,19,3,2,0,38279,chunqi shi,Proceedings of the Workshop on Open Infrastructures and Analysis Frameworks for {HLT},0,"This paper describes a conceptual framework that enables online NLP pipelined applications to solve various interoperability issues and data exchange problems between tools and platforms; e.g., tokenizers and part-of-speech taggers from GATE, UIMA, or other platforms. We propose a restful wrapping solution, which allows for universal resource identification for data management, a unified interface for data exchange, and a light-weight serialization for data visualization. In addition, we propose a semantic mapping-based pipeline composition, which allows experts to interactively exchange data between heterogeneous components."
S14-1014,Generating Simulations of Motion Events from Verbal Descriptions,2014,43,7,1,1,993,james pustejovsky,Proceedings of the Third Joint Conference on Lexical and Computational Semantics (*{SEM} 2014),0,"In this paper, we describe a computational model for motion events in natural language that maps from linguistic expressions, through a dynamic event interpretation, into three-dimensional temporal simulations in a model. Starting with the model from (Pustejovsky and Moszkowicz, 2011), we analyze motion events using temporally-traced Labelled Transition Systems. We model the distinction between path- and manner-motion in an operational semantics, and further distinguish different types of manner-of-motion verbs in terms of the mereo-topological relations that hold throughout the process of movement. From these representations, we generate minimal models, which are realized as three-dimensional simulations in software developed with the game engine, Unity. The generated simulations act as a conceptual xe2x80x9cdebuggerxe2x80x9d for the semantics of different motion verbs: that is, by testing for consistency and informativeness in the model, simulations expose the presuppositions associated with linguistic expressions and their compositions. Because the model generation component is still incomplete, this paper focuses on an implementation which maps directly from linguistic interpretations into the Unity code snippets that create the simulations."
Q14-1012,Temporal Annotation in the Clinical Domain,2014,32,79,11,0,39080,william iv,Transactions of the Association for Computational Linguistics,0,"This article discusses the requirements of a formal specification for the annotation of temporal information in clinical narratives. We discuss the implementation and extension of ISO-TimeML for annotating a corpus of clinical notes, known as the THYME corpus. To reflect the information task and the heavily inference-based reasoning demands in the domain, a new annotation guideline has been developed, {``}the THYME Guidelines to ISO-TimeML (THYME-TimeML){''}. To clarify what relations merit annotation, we distinguish between linguistically-derived and inferentially-derived temporal orderings in the text. We also apply a top performing TempEval 2013 system against this new resource to measure the difficulty of adapting systems to the clinical domain. The corpus is available to the community and has been proposed for use in a SemEval 2015 task."
pustejovsky-yocum-2014-image,Image Annotation with {ISO}-Space: Distinguishing Content from Structure,2014,28,3,1,1,993,james pustejovsky,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"Natural language descriptions of visual media present interesting problems for linguistic annotation of spatial information. This paper explores the use of ISO-Space, an annotation specification to capturing spatial information, for encoding spatial relations mentioned in descriptions of images. Especially, we focus on the distinction between references to representational content and structural components of images, and the utility of such a distinction within a compositional semantics. We also discuss how such a structure-content distinction within the linguistic annotation can be leveraged to compute further inferences about spatial configurations depicted by images with verbal captions. We construct a composition table to relate content-based relations to structure-based relations in the image, as expressed in the captions. While still preliminary, our initial results suggest that a weak composition table is both sound and informative for deriving new spatial relations."
anick-etal-2014-identification,Identification of Technology Terms in Patents,2014,11,3,3,0.434783,38199,peter anick,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"Natural language analysis of patents holds promise for the development of tools designed to assist analysts in the monitoring of emerging technologies. One component of such tools is the identification of technology terms. We describe an approach to the discovery of technology terms using supervised machine learning and evaluate its performance on subsets of patents in three languages: English, German, and Chinese."
ide-etal-2014-language,The Language Application Grid,2014,19,32,2,0,16303,nancy ide,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"The Language Application (LAPPS) Grid project is establishing a framework that enables language service discovery, composition, and reuse and promotes sustainability, manageability, usability, and interoperability of natural language Processing (NLP) components. It is based on the service-oriented architecture (SOA), a more recent, web-oriented version of the ÂpipelineÂ architecture that has long been used in NLP for sequencing loosely-coupled linguistic analyses. The LAPPS Grid provides access to basic NLP processing tools and resources and enables pipelining such tools to create custom NLP applications, as well as composite services such as question answering and machine translation together with language resources such as mono- and multi-lingual corpora and lexicons that support NLP. The transformative aspect of the LAPPS Grid is that it orchestrates access to and deployment of language resources and processing functions available from servers around the globe and enables users to add their own language resources, services, and even service grids to satisfy their particular needs."
W13-5401,Dynamic Event Structure and Habitat Theory,2013,-1,-1,1,1,993,james pustejovsky,Proceedings of the 6th International Conference on Generative Approaches to the Lexicon ({GL}2013),0,None
W13-5413,Informativeness Constraints and Compositionality,2013,-1,-1,2,0,40538,olga batiukova,Proceedings of the 6th International Conference on Generative Approaches to the Lexicon ({GL}2013),0,None
W13-0705,Where Things Happen: On the Semantics of Event Localization,2013,30,4,1,1,993,james pustejovsky,Proceedings of the {IWCS} 2013 Workshop on Computational Models of Spatial Language Interpretation and Generation ({C}o{SLI}-3),0,"The problem of temporally situating events in language has been approached by a number of philosophical techniques, including Davidsonxe2x80x99s particularist theory of event individuation [6, 5] and Kimxe2x80x99s property exemplification theory [16]. Both of these theories have been developed within linguistic semantic traditions, as well (cf. [24, 2] and others). However, the problem of event localization (spatially situating events) has not been discussed as extensively in the semantics literature. In this paper, I discuss the procedures for identifying where events, as expressed in natural language, are located in space. Aspects of the semantics of event localization have been recently proposed, including the notion of the xe2x80x9cshapexe2x80x9d of a movement [8, 39], as well as treating movement verbs as xe2x80x9cpath creationxe2x80x9d predicates [29]. In this paper, I build on these and some additional observations to outline a more general semantics of event localization. I then outline a procedure that extends the path metaphor used for motion predicates, distinguishing between the event locus and the spatial aspect of an event. In the process, I discuss how localization is supervenient upon the participants in the events."
W13-0503,Capturing Motion in {ISO}-{S}pace{B}ank,2013,11,6,1,1,993,james pustejovsky,Proceedings of the 9th Joint {ISO} - {ACL} {SIGSEM} Workshop on Interoperable Semantic Annotation,0,"This paper presents the first description of the motion subcorpus of ISO-SpaceBank (MotionBank) and discusses how motion-events are represented in ISO-Space 1.5, a specification language for the representation of spatial information in language. We present data from this subcorpus with examples from the pilot annotation, focusing specifically on the annotation of motion-events and their various participants. These data inform further discussion of outstanding issues concerning semantic annotation, such as quantification and measurement. We address these questions briefly as they impact the design of ISO-Space."
W13-0509,Inference Patterns with Intensional Adjectives,2013,6,5,1,1,993,james pustejovsky,Proceedings of the 9th Joint {ISO} - {ACL} {SIGSEM} Workshop on Interoperable Semantic Annotation,0,"In this paper we report on an ongoing multiinstitution effort to encode inferential patterns associated with adjective modification in English. We focus here on a subset of intensional adjectives typically referred to as xe2x80x9cnon-subsectivexe2x80x9d predicates. This class includes adjectives such as alleged, supposed, so-called, and related modally subordinating predicates. We discuss the initial results of corpus-based investigations to discriminate the patterns of inference associated with these adjectives. Based on these studies, we have created an initial annotation specification that we are using to create a corpus of adjectiverelated inferences in English."
S13-2001,"{S}em{E}val-2013 Task 1: {T}emp{E}val-3: Evaluating Time Expressions, Events, and Temporal Relations",2013,21,183,6,0.952381,37291,naushad uzzaman,"Second Joint Conference on Lexical and Computational Semantics (*{SEM}), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation ({S}em{E}val 2013)",0,"Within the SemEval-2013 evaluation exercise, the TempEval-3 shared task aims to advance research on temporal information processing. It follows on from TempEval-1 and -2, with: a three-part structure covering temporal expression, event, and temporal relation extraction; a larger dataset; and new single measures to rank systems xe2x80x90 in each task and in general. In this paper, we describe the participantsxe2x80x99 approaches, results, and the observations from the results, which may guide future research in this area."
W12-3601,The Role of Linguistic Models and Language Annotation in Feature Selection for Machine Learning,2012,0,0,1,1,993,james pustejovsky,Proceedings of the Sixth Linguistic Annotation Workshop,0,"As NLP confronts the challenge of Big Data for natural language text, the role played by linguistically annotated data in training machine learning algorithms is reaching a critical question. Namely, what role can annotated corpora play for supervised learning algorithms when the datasets become significantly outsized, compared to the gold standards used for training? The use of semi-supervised learning techniques to help solve this problem is a good next step, one that requires not less adherence to annotated data, but an even stricter adherence to linguistic models and the features that are derived from these models for subsequent annotation."
P12-4001,Qualitative Modeling of Spatial Prepositions and Motion Expressions,2012,0,0,2,0,42626,inderjeet mani,Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts,0,"The ability to understand spatial prepositions and motion in natural language will enable a variety of new applications involving systems that can respond to verbal directions, map travel guides, display incident reports, etc., providing for enhanced information extraction, question-answering, information retrieval, and more principled text to scene rendering. Until now, however, the semantics of spatial relations and motion verbs has been highly problematic. This tutorial presents a new approach to the semantics of spatial descriptions and motion expressions based on linguistically interpreted qualitative reasoning. Our approach allows for formal inference from spatial descriptions in natural language, while leveraging annotation schemes for time, space, and motion, along with machine learning from annotated corpora. We introduce a compositional semantics for motion expressions that integrates spatial primitives drawn from qualitative calculi."
verhagen-pustejovsky-2012-tarsqi,The {TARSQI} Toolkit,2012,29,7,2,1,3193,marc verhagen,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"We present and demonstrate the updated version of the TARSQI Toolkit, a suite of temporal processing modules that extract temporal information from natural language texts. It parses the document and identifies temporal expressions, recognizes events, anchor events to temporal expressions and orders events relative to each other. The toolkit was previously demonstrated at COLING 2008, but has since seen substantial changes including: (1) incorporation of a new time expression tagger, (2){\textasciitilde}embracement of stand-off annotation, (3) application to the medical domain and (4) introduction of narrative containers."
rumshisky-etal-2012-word,Word Sense Inventories by Non-Experts.,2012,15,11,4,0.54332,8218,anna rumshisky,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"In this paper, we explore different strategies for implementing a crowdsourcing methodology for a single-step construction of an empirically-derived sense inventory and the corresponding sense-annotated corpus. We report on the crowdsourcing experiments using implementation strategies with different HIT costs, worker qualification testing, and other restrictions. We describe multiple adjustments required to ensure successful HIT design, given significant changes within the crowdsourcing community over the last three years."
vogel-etal-2012-atlis,{ATLIS}: Identifying Locational Information in Text Automatically,2012,6,1,3,0,43332,john vogel,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"ATLIS (short for Â ATLIS Tags Locations in StringsÂ) is a tool being developed using a maximum-entropy machine learning model for automatically identifying information relating to spatial and locational information in natural language text. It is being developed in parallel with the ISO-Space standard for annotation of spatial information (Pustejovsky, Moszkowicz {\&} Verhagen 2011). The goal of ATLIS is to be able to take in a document as raw text and mark it up with ISO-Space annotation data, so that another program could use the information in a standardized format to reason about the semantics of the spatial information in the document. The tool (as well as ISO-Space itself) is still in the early stages of development. At present it implements a subset of the proposed ISO-Space annotation standard: it identifies expressions that refer to specific places, as well as identifying prepositional constructions that indicate a spatial relationship between two objects. In this paper, the structure of the ATLIS tool is presented, along with preliminary evaluations of its performance."
pustejovsky-moszkowicz-2012-role,The Role of Model Testing in Standards Development: The Case of {ISO}-Space,2012,18,7,1,1,993,james pustejovsky,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"In this paper, we describe the methodology being used to develop certain aspects of ISO-Space, an annotation language for encoding spatial and spatiotemporal information as expressed in natural language text. After reviewing the requirements of a specification for capturing such knowledge from linguistic descriptions, we describe how ISO-Space has developed to meet the needs of the specification. ISO-Space is an emerging resource that is being developed in the context of an iterative effort to test the specification model with annotation, a methodology called MAMA (Model-Annotate-Model-Annotate) (Pustejovsky and Stubbs, 2012). We describe the genres of text that are being used in a pilot annotation study, in order to both refine and enrich the specification language by way of crowd sourcing simple annotation tasks with Amazon's Mechanical Turk Service."
J12-2002,Are You Sure That This Happened? Assessing the Factuality Degree of Events in Text,2012,54,76,2,1,18027,roser sauri,Computational Linguistics,0,"Identifying the veracity, or factuality, of event mentions in text is fundamental for reasoning about eventualities in discourse. Inferences derived from events judged as not having happened, or as being only possible, are different from those derived from events evaluated as factual. Event factuality involves two separate levels of information. On the one hand, it deals with polarity, which distinguishes between positive and negative instantiations of events. On the other, it has to do with degrees of certainty (e.g., possible, probable), an information level generally subsumed under the category of epistemic modality. This article aims at contributing to a better understanding of how event factuality is articulated in natural language. For that purpose, we put forward a linguistic-oriented computational model which has at its core an algorithm articulating the effect of factuality relations across levels of syntactic embedding. As a proof of concept, this model has been implemented in De Facto, a factuality profiler for eventualities mentioned in text, and tested against a corpus built specifically for the task, yielding an F1 of 0.70 (macro-averaging) and 0.80 (micro-averaging). These two measures mutually compensate for an over-emphasis present in the other (either on the lesser or greater populated categories), and can therefore be interpreted as the lower and upper bounds of the De Facto's performance."
W11-0419,Increasing Informativeness in Temporal Annotation,2011,11,34,1,1,993,james pustejovsky,Proceedings of the 5th Linguistic Annotation Workshop,0,"In this paper, we discuss some of the challenges of adequately applying a specification language to an annotation task, as embodied in a specific guideline. In particular, we discuss some issues with TimeML motivated by error analysis on annotated TLINKs in TimeBank. We introduce a document level information structure we call a narrative container (NC), designed to increase informativeness and accuracy of temporal relation identification. The narrative container is the default interval containing the events being discussed in the text, when no explicit temporal anchor is given. By exploiting this notion in the creation of a new temporal annotation over TimeBank, we were able to reduce inconsistencies and increase informativeness when compared to existing TLINKs in TimeBank."
W11-0224,Medstract - The Next Generation,2011,2,0,2,1,3193,marc verhagen,Proceedings of {B}io{NLP} 2011 Workshop,0,"We present MedstractPlus, a resource for mining relations from the Medline bibliographic database. It was built on the remains of Medstract, a previously created resource that included a bio-relation server and an acronym database. MedstractPlus uses simple and scalable natural language processing modules to structure text and is designed with reusability and extendibility in mind."
S10-1005,{S}em{E}val-2010 Task 7: Argument Selection and Coercion,2010,33,8,1,1,993,james pustejovsky,Proceedings of the 5th International Workshop on Semantic Evaluation,0,"We describe the Argument Selection and Coercion task for the SemEval-2010 evaluation exercise. This task involves characterizing the type of compositional operation that exists between a predicate and the arguments it selects. Specifically, the goal is to identify whether the type that a verb selects is satisfied directly by the argument, or whether the argument must change type to satisfy the verb typing. We discuss the problem in detail, describe the data preparation for the task, and analyze the results of the submissions."
S10-1010,{S}em{E}val-2010 Task 13: {T}emp{E}val-2,2010,7,220,4,1,3193,marc verhagen,Proceedings of the 5th International Workshop on Semantic Evaluation,0,"Tempeval-2 comprises evaluation tasks for time expressions, events and temporal relations, the latter of which was split up in four sub tasks, motivated by the notion that smaller subtasks would make both data preparation and temporal relation extraction easier. Manually annotated data were provided for six languages: Chinese, English, French, Italian, Korean and Spanish."
pustejovsky-etal-2010-iso,{ISO}-{T}ime{ML}: An International Standard for Semantic Annotation,2010,8,113,1,1,993,james pustejovsky,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"In this paper, we present ISO-TimeML, a revised and interoperable version of the temporal markup language, TimeML. We describe the changes and enrichments made, while framing the effort in a more general methodology of semantic annotation. In particular, we assume a principled distinction between the annotation of an expression and the representation which that annotation denotes. This involves not only the specification of an annotation language for a particular phenomenon, but also the development of a meta-model that allows one to interpret the syntactic expressions of the specification semantically."
cieri-etal-2010-road,A Road Map for Interoperable Language Resource Metadata,2010,0,5,8,0,17560,christopher cieri,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"LRs remain expensive to create and thus rare relative to demand across languages and technology types. The accidental re-creation of an LR that already exists is a nearly unforgivable waste of scarce resources that is unfortunately not so easy to avoid. The number of catalogs the HLT researcher must search, with their different formats, make it possible to overlook an existing resource. This paper sketches the sources of this problem and outlines a proposal to rectify along with a new vision of LR cataloging that will to facilitates the documentation and exploitation of a much wider range of LRs than previously considered."
W09-3716,{GLML}: Annotating Argument Selection and Coercion,2009,26,10,1,1,993,james pustejovsky,Proceedings of the Eight International Conference on Computational Semantics,0,"In this paper we introduce a methodology for annotating compositional operations in natural language text, and describe a mark-up language, GLML, based on Generative Lexicon, for identifying such relations. While most annotation systems capture surface relationships, GLML captures the compositional history of the argument selection relative to the predicate. We provide a brief overview of GL before moving on to our proposed methodology for annotating with GLML. There are three main tasks described in the paper: (i) Compositional mechanisms of argument selection; (ii) Qualia in modification constructions; (iii) Type selection in modification of dot objects. We explain what each task includes and provide a description of the annotation interface. We also include the XML format for GLML including examples of annotated sentences."
W09-3034,The {SILT} and {F}la{R}e{N}et International Collaboration for Interoperability,2009,-1,-1,2,0,16303,nancy ide,Proceedings of the Third Linguistic Annotation Workshop ({LAW} {III}),0,None
W09-2414,{S}em{E}val-2010 Task 7: Argument Selection and Coercion,2009,25,4,1,1,993,james pustejovsky,Proceedings of the Workshop on Semantic Evaluations: Recent Achievements and Future Directions ({SEW}-2009),0,"In this paper, we describe the Argument Selection and Coercion task, currently in development for the SemEval-2 evaluation exercise scheduled for 2010. This task involves characterizing the type of compositional operation that exists between a predicate and the arguments it selects. Specifically, the goal is to identify whether the type that a verb selects is satisfied directly by the argument, or whether the argument must change type to satisfy the verb typing. We discuss the problem in detail and describe the data preparation for the task."
W09-2418,"{S}em{E}val-2010 Task 13: Evaluating Events, Time Expressions, and Temporal Relations ({T}emp{E}val-2)",2009,4,41,1,1,993,james pustejovsky,Proceedings of the Workshop on Semantic Evaluations: Recent Achievements and Future Directions ({SEW}-2009),0,"We describe the TempEval-2 task which is currently in preparation for the SemEval-2010 evaluation exercise. This task involves identifying the temporal relations between events and temporal expressions in text. Six distinct subtasks are defined, ranging from identifying temporal and event expressions, to anchoring events to temporal expressions, and ordering events relative to each other."
C08-3012,Temporal Processing with the {TARSQI} Toolkit,2008,16,77,2,1,3193,marc verhagen,Coling 2008: Companion volume: Demonstrations,0,"We present the TARSQI Toolkit (TTK), a modular system for automatic temporal and event annotation of natural language texts. TTK identifies temporal expressions and events in natural language texts, and parses the document to order events and to anchor them to temporal expressions."
C08-2024,Integrating Motion Predicate Classes with Spatial and Temporal Annotations,2008,13,26,1,1,993,james pustejovsky,Coling 2008: Companion volume: Posters,0,"We propose a spatio-temporal markup for the annotation of motion predicates in text, informed by a lexical semantic classification of these verbs. We incorporate this classification within a spatial event structure, based on Generative Lexicon Theory. We discuss how the spatial event structure suggests changes to annotation systems designed solely for temporal or spatial phenomena, resulting in spatio-temporal annotation."
W07-1517,Combining Independent Syntactic and Semantic Annotation Schemes,2007,5,8,3,1,3193,marc verhagen,Proceedings of the Linguistic Annotation Workshop,0,"We present MAIS, a UIMA-based environment for combining information from various annotated resources. Each resource contains one mode of linguistic annotation and remains independent from the other resources. Interactions between annotations are defined based on use cases."
S07-1014,{S}em{E}val-2007 Task 15: {T}emp{E}val Temporal Relation Identification,2007,4,212,6,1,3193,marc verhagen,Proceedings of the Fourth International Workshop on Semantic Evaluations ({S}em{E}val-2007),0,"The TempEval task proposes a simple way to evaluate automatic extraction of temporal relations. It avoids the pitfalls of evaluating a graph of inter-related labels by defining three sub tasks that allow pairwise evaluation of temporal relations. The task not only allows straightforward evaluation, it also avoids the complexities of full temporal parsing."
D07-1010,Automatically Identifying the Arguments of Discourse Connectives,2007,0,50,2,1,25034,ben wellner,Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning ({EMNLP}-{C}o{NLL}),0,None
W06-1317,Classification of Discourse Coherence Relations: An Exploratory Study using Multiple Knowledge Sources,2006,-1,-1,2,1,25034,ben wellner,Proceedings of the 7th {SIG}dial Workshop on Discourse and Dialogue,0,None
P06-1095,Machine Learning of Temporal Relations,2006,20,206,5,0,42626,inderjeet mani,Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,1,"This paper investigates a machine learning approach for temporally ordering and anchoring events in natural language texts. To address data sparseness, we used temporal reasoning as an over-sampling method to dramatically expand the amount of training data, resulting in predictive accuracy on link labeling as high as 93% using a Maximum Entropy classifier on human annotated data. This method compared favorably against a series of increasingly sophisticated baselines involving expansion of rules derived from human intuitions."
havasi-etal-2006-bulb,{BULB}: A Unified Lexical Browser,2006,9,2,2,0,7950,catherine havasi,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"Natural language processing researchers currently have access to a wealth of information about words and word senses. This presents problems as well as resources, as it is often difficult to search through and coordinate lexical information across various data sources. We have approached this problem by creating a shared environment for various lexical resources. This browser, BULB (Brandeis Unified Lexical Browser) and its accompanying front-end provides the NLP researcher with a coordinated display from many of the available lexical resources, focusing, in particular, on a newly developed lexical database, the Brandeis Semantic Ontology (BSO). BULB is a module-based browser focusing on the interaction and display of modules from existing NLP tools. We discuss the BSO, PropBank, FrameNet, WordNet, and CQP, as well as other modules which will extend the system. We then outline future extensions to this work and present a release schedule for BULB."
pustejovsky-etal-2006-towards,Towards a Generative Lexical Resource: The {B}randeis Semantic Ontology,2006,9,46,1,1,993,james pustejovsky,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"In this paper we describe the structure and development of the Brandeis Semantic Ontology (BSO), a large generative lexicon ontology and lexical database. The BSO has been designed to allow for more widespread access to Generative Lexicon-based lexical resources and help researchers in a variety of computational tasks. The specification of the type system used in the BSO largely follows that proposed by the SIMPLE specification (Busa et al., 2001), which was adopted by the EU-sponsored SIMPLE project (Lenci et al., 2000)."
verhagen-etal-2006-annotation,Annotation of Temporal Relations with Tango,2006,7,10,4,1,3193,marc verhagen,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"Temporal annotation is a complex task characterized by low markup speed and low inter-annotator agreements scores. Tango is a graphical annotation tool for temporal relations. It is developed for the TimeML annotation language and allows annotators to build a graph that resembles a timeline. Temporal relations are added by selecting events and drawing labeled arrows between them. Tango is integrated with a temporal closure component and includes features like SmartLink, user prompting and automatic linking of time expressions. Tango has been used to create two corpora with temporal annotation, TimeBank and the AQUAINT Opinion corpus."
rumshisky-pustejovsky-2006-inducing,Inducing Sense-Discriminating Context Patterns from Sense-Tagged Corpora,2006,10,6,2,0.54332,8218,anna rumshisky,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"Traditionally, context features used in word sense disambiguation are based on collocation statistics and use only minimal syntactic and semantic information. Corpus Pattern Analysis is a technique for producing knowledge-rich context features that capture sense distinctions. It involves (1) identifying sense-carrying context patterns and using the derived context features to discriminate between the unseen instances. Both stages require manual seeding. In this paper, we show how to automate inducing sense-discriminating context features from a sense-tagged corpus."
sauri-etal-2006-slinket,{S}link{ET}: A Partial Modal Parser for Events,2006,16,21,3,1,18027,roser sauri,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"We present SlinkET, a parser for identifying contexts of event modality in text developed within the TARSQI (Temporal Awareness and Reasoning Systems for Question Interpretation) research framework. SlinkET is grounded on TimeML, a specification language for capturing temporal and event related information in discourse, which provides an adequate foundation to handle event modality. SlinkET builds on top of a robust event recognizer, and provides each relevant event with a value that specifies the degree of certainty about its factuality; e.g., whether it has happened or holds (factive or counter-factive), whether it is being reported or witnessed by somebody else (evidential), or if it is introduced as a possibility (modal). It is based on well-established technology in the field (namely, finite-state techniques), and informed with corpus-induced knowledge that relies on basic information, such as morphological features, POS, and chunking. SlinkET is under continuing development and it currently achieves a performance ratio of 70{\%} F1-measure."
W05-1302,Adaptive String Similarity Metrics for Biomedical Reference Resolution,2005,20,10,3,0.952381,25034,ben wellner,"Proceedings of the {ACL}-{ISMB} Workshop on Linking Biological Literature, Ontologies and Databases: Mining Biological Semantics",0,"In this paper we present the evaluation of a set of string similarity metrics used to resolve the mapping from strings to concepts in the UMLS MetaThesaurus. String similarity is conceived as a single component in a full Reference Resolution System that would resolve such a mapping. Given this qualification, we obtain positive results achieving 73.6 F-measure (76.1 precision and 71.4 recall) for the task of assigning the correct UMLS concept to a given string. Our results demonstrate that adaptive string similarity methods based on Conditional Random Fields outperform standard metrics in this domain."
W05-0302,"Merging {P}rop{B}ank, {N}om{B}ank, {T}ime{B}ank, {P}enn {D}iscourse {T}reebank and Coreference",2005,21,21,1,1,993,james pustejovsky,Proceedings of the Workshop on Frontiers in Corpus Annotations {II}: Pie in the Sky,0,"Many recent annotation efforts for English have focused on pieces of the larger problem of semantic annotation, rather than initially producing a single unified representation. This paper discusses the issues involved in merging four of these efforts into a unified linguistic structure: PropBank, NomBank, the Discourse Treebank and Coreference Annotation undertaken at the University of Essex. We discuss resolving overlapping and conflicting annotation as well as how the various annotation schemes can reinforce each other to produce a representation that is greater than the sum of its parts."
P05-3021,Automating Temporal Annotation with {TARSQI},2005,13,137,9,1,3193,marc verhagen,Proceedings of the {ACL} Interactive Poster and Demonstration Sessions,0,"We present an overview of TARSQI, a modular system for automatic temporal annotation that adds time expressions, events and temporal relations to news texts."
H05-1088,{E}vita: A Robust Event Recognizer For {QA} Systems,2005,29,126,4,1,18027,roser sauri,Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing,0,"We present Evita, an application for recognizing events in natural language texts. Although developed as part of a suite of tools aimed at providing question answering systems with information about both temporal and intensional relations among events, it can be used independently as an event extraction tool. It is unique in that it is not limited to any pre-established list of relation types (events), nor is it restricted to a specific domain. Evita performs the identification and tagging of event expressions based on fairly simple strategies, informed by both linguistic-and statistically-based data. It achieves a performance ratio of 80.12% F-measure."
W04-1908,Automated Induction of Sense in Context,2004,28,37,1,1,993,james pustejovsky,Proceedings of the 5th International Workshop on Linguistically Interpreted Corpora,0,"In this paper, we introduce a model for sense assignment which relies on assigning senses to the contexts within which words appear, rather than to the words themselves. We argue that word senses as such are not directly encoded in the lexicon of the language. Rather, each word is associated with one or more stereotypical syntagmatic patterns, which we call selection contexts. Each selection context is associated with a meaning, which can be expressed in any of various formal or computational manifestations. We present a formalism for encoding contexts that help to determine the semantic contribution of a word in an utterance. Further, we develop a methodology through which such stereotypical contexts for words and phrases can be identified from very large corpora, and subsequently structured in a selection context dictionary, encoding both stereotypical syntactic and semantic information. We present some preliminary results."
W04-0208,Temporal Discourse Models for Narrative Structure,2004,23,29,2,0.230975,42626,inderjeet mani,Proceedings of the Workshop on Discourse Annotation,0,"Getting a machine to understand human narratives has been a classic challenge for NLP and AI. This paper proposes a new representation for the temporal structure of narratives. The representation is parsimonious, using temporal relations as surrogates for discourse relations. The narrative models, called Temporal Discourse Models, are tree-structured, where nodes include abstract events interpreted as pairs of time points and where the dominance relation is expressed by temporal inclusion. Annotation examples and challenges are discussed, along with a report on progress to date in creating annotated corpora."
C04-1133,Automated Induction of Sense in Context,2004,28,37,1,1,993,james pustejovsky,{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics,0,"In this paper, we introduce a model for sense assignment which relies on assigning senses to the contexts within which words appear, rather than to the words themselves. We argue that word senses as such are not directly encoded in the lexicon of the language. Rather, each word is associated with one or more stereotypical syntagmatic patterns, which we call selection contexts. Each selection context is associated with a meaning, which can be expressed in any of various formal or computational manifestations. We present a formalism for encoding contexts that help to determine the semantic contribution of a word in an utterance. Further, we develop a methodology through which such stereotypical contexts for words and phrases can be identified from very large corpora, and subsequently structured in a selection context dictionary, encoding both stereotypical syntactic and semantic information. We present some preliminary results."
N03-5006,Annotation of Temporal and Event Expressions,2003,0,1,1,1,993,james pustejovsky,Companion Volume of the Proceedings of {HLT}-{NAACL} 2003 - Tutorial Abstracts,0,"Humans live in a dynamic world, where actions bring about consequences, and the facts and properties associated with entities change over time. Without a robust ability to identify events in NL data and temporally situate them, the real 91aboutness92 of the information can be missed. In appreciation of this need, there has recently been a renewed interest in temporal and event-based reasoning for NLP, aimed at addressing challenges in areas such as information extraction, question-answering, and summarization.This tutorial will begin with an overview of theoretical work on tense, aspect, and event structure in natural language, as well as the fundamentals of temporal reasoning. It will then go on to discuss the annotation of temporal and event expressions in corpora, including the TimeML specification language and other results from the ARDA/NRRC Workshop on Temporal and Event Recognition for Question Answering Systems (TERQAS). The tutorial will examine how to formally distinguish events and their temporal anchoring in documents, and will discuss algorithms for ordering events mentioned in a document relative to each other and for computing closure over an entire discourse of events.Tutorial attendees can expect to learn about current methodologies and computational resources, the outstanding problems in the area, as well as obtain follow-up pointers to the research literature. Attendees should be familiar with information extraction and the notion of corpus annotation. The course should appeal to those with an interest in leveraging robust semantic analysis for tasks like question-answering, information extraction, and summarization."
W02-0312,{M}edstract: creating large-scale information servers from biomedical texts,2002,15,53,1,1,993,james pustejovsky,Proceedings of the {ACL}-02 Workshop on Natural Language Processing in the Biomedical Domain,0,"The automatic extraction of information from Medline articles and abstracts (commonly referred to now as the biobibliome) promises to play an increasingly critical role in aiding research while speeding up the discovery process. We have been developing robust natural language tools for the automated extraction of structured information from biomedical texts as part of a project we call MEDSTRACT. Here we will describe an architecture for developing databases for domain specific information servers for research and support in the biomedical community. These are currently comprised of the following: a Bio-Relation Server, and the Bio-Acronym server, Acromed, which will include also aliases. Each information server is derived automatically from an integration of diverse components which employ robust natural language processing of Medline text and IE techniques. The front-end consists of conventional search and navigation capabilities, as well as visualization tools that help to navigate the databases and explore the results of a search. It is hoped that this set of applications will allow for quick, structured access to relevant information on individual genes by biologists over the web."
pustejovsky-2002-creating,Creating Domain-specific Information Servers,2002,0,0,1,1,993,james pustejovsky,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,None
C94-2112,On the Proper Role of Coercion in Semantic Typing,1994,18,5,1,1,993,james pustejovsky,{COLING} 1994 Volume 2: The 15th {I}nternational {C}onference on {C}omputational {L}inguistics,0,"In this paper, we discuss the phenomenon of logical polysemy in natural language as addressed by Generative Lexicon Theory. We discuss generally the role of type and sortal coercion operations in the semantics, and specifically the conditions on the application of coercion in aspectual predicates and other contexts. We reply to some recent discussion regarding the use of coercion in the grammar, and show that type changing operations are both useful and explanatory mechanisms for capturing linguistic and computational generalizations."
X93-1021,{CRL}/{B}randeis: The {D}iderot System,1993,8,7,5,0.833333,53660,jim cowie,"TIPSTER TEXT PROGRAM: PHASE {I}: Proceedings of a Workshop held at Fredricksburg, Virginia, September 19-23, 1993",0,Diderot is an information extraction system built at CRL and Brandeis University over the past two years. It was produced as part of our efforts in the Tipster project. The same overall system architecture has been used for English and Japanese and for the micro-electronics and joint venture domains.
M93-1015,{CRL/B}randeis: Description of the \\textit{ {D}iderot} System as Used for {MUC}-5,1993,8,4,6,0.833333,53660,jim cowie,"Fifth Message Understanding Conference ({MUC}-5): Proceedings of a Conference Held in Baltimore, {M}aryland, August 25-27, 1993",0,This report describes the major developments over the last six months in completing the Diderot information extraction system for the MUC-5 evaluation.Diderot is an information extraction system built at CRL and Brandeis University over the past two years. It was produced as part of our efforts in the Tipster project. The same overall system architecture has been used for English and Japanese and for the micro-electronics and joint venture domains.The past history of the system is discussed and the operation of its major components described. A summary of scores at the 24 month workshop is given and the performance of the system on the texts selected for the system walkthrough is discussed.
M93-1027,Summary of Workshop on Lexicons for Text Extraction,1993,0,0,1,1,993,james pustejovsky,"Fifth Message Understanding Conference ({MUC}-5): Proceedings of a Conference Held in Baltimore, {M}aryland, August 25-27, 1993",0,"This workshop discussed the problems with lexicon development in the context of MUC-style application programs. The topics ranged from general issues in lexicon portability (Cahill), to Japanese lexicons (Mauldin) and problems encountered with MRDs in sublanguage domains (Pustejovsky)."
J93-2005,Lexical Semantic Techniques for Corpus Analysis,1993,72,130,1,1,993,james pustejovsky,Computational Linguistics,0,"In this paper we outline a research program for computational linguistics, making extensive use of text corpora. We demonstrate how a semantic framework for lexical knowledge can suggest richer relationships among words in text beyond that of simple co-occurrence. The work suggests how linguistic phenomena such as metonymy and polysemy might be exploitable for semantic tagging of lexical items. Unlike with purely statistical collocational analyses, the framework of a semantic theory allows the automatic construction of predictions about deeper semantic relationships among words appearing in collocational systems. We illustrate the approach for the acquisition of lexical information for several classes of nominals, and how such techniques can fine-tune the lexical structures acquired from an initial seeding of a machine-readable dictionary. In addition to conventional lexical semantic relations, we show how information concerning lexical presuppositions and preference relations can also be acquired from corpora, when analyzed with the appropriate semantic tools. Finally, we discuss the potential that corpus studies have for enriching the data set for theoretical linguistic research, as well as helping to confirm or disconfirm linguistic hypotheses."
M92-1014,{CRL}/{NMSU} and {B}randeis {M}uc{B}ruce: {MUC}-4 Test Results and Analysis,1992,-1,-1,4,0.833333,53660,jim cowie,"{F}ourth {M}essage {U}understanding {C}onference ({MUC}-4): Proceedings of a Conference Held in {M}c{L}ean, {V}irginia, {J}une 16-18, 1992",0,None
H92-1047,The Acquisition of Lexical Semantic Knowledge from Large Corpora,1992,12,13,1,1,993,james pustejovsky,"Speech and Natural Language: Proceedings of a Workshop Held at Harriman, New York, {F}ebruary 23-26, 1992",0,"Machine-readable dictionaries provide the raw material from which to construct computationally useful representations of the generic vocabulary contained within it. Many sublanguages, however, are poorly represented in on-line dictionaries, if represented at all. Vocabularies geared to specialized domains are necessary for many applications, such as text categorization and information retrieval. In this paper I describe research devoted to developing techniques for building sublanguage lexicons via syntactic and statistical corpus analysis coupled with analytic techniques based on the tenets of a generative lexicon."
J91-4003,The {G}enerative {L}exicon,1991,0,0,1,1,993,james pustejovsky,Computational Linguistics,0,"In this paper, I will discuss four major topics relating to current research in lexical semantics: methodology, descriptive coverage, adequacy of the representation, and the computational usefulnes..."
C90-2002,An Application of Lexical Semantics to Knowledge Acquisition from Corpora,1990,20,19,2,0.434783,38199,peter anick,{COLING} 1990 Volume 2: Papers presented to the 13th International Conference on Computational Linguistics,0,"In this paper, we describe a program of research designed to explore how a lexical semantic theory may be exploited for extracting information from corpora suitable for use in Information Retrieval applications. Unlike with purely statistical collocational analyses, the framework of a semantic theory allows the automatic construction of predictions about semantic relationships among words appearing in collocational systems. We illustrate the approach for the acquisition of lexical information for several classes of nominals."
C90-2007,Lexical Ambiguity and The Role of Knowledge Representation in Lexicon Design,1990,7,26,2,0,37086,branimir boguraev,{COLING} 1990 Volume 2: Papers presented to the 13th International Conference on Computational Linguistics,0,"The traditional framework for ambiguity resolution employs only 'static' knowledge, expressed generally as selectional restrictions or domain specific constraints, and makes no use of any specific knowledge manipulation mechanisms apart from the simple ability to match valences of structurally related words. In contrast, this paper suggests how a theory of lexical semantics making use of a knowledge representation framework offers a richer, more expressive vocabulary for lexical information. In particular, by performing specialized inference over the ways in which aspects of knowledge structures of words in context can be composed, mutually compatible and contextully relevant lexical components of words and phrases are highlighted. In the view presented here, lexical ambiguity resolution is an integral part of the same procedure that creates the semantic interpretation of a sentence itself."
J89-3005,Language and Spatial Cognition,1989,-1,-1,1,1,993,james pustejovsky,Computational Linguistics,0,None
C88-2110,On The Semantic Interpretation of Nominals,1988,15,33,1,1,993,james pustejovsky,{C}oling {B}udapest 1988 Volume 2: {I}nternational {C}onference on {C}omputational {L}inguistics,0,"In this paper we examine a subset of polysemous elements, the logical structure of nominals, and argue that many cases of polysemy have well-defined calculi, which interact with the grammar in predictable and determinate ways for disambiguation. These calculi constitute part of the lexical organization of the grammar and contribute to the lexical semantics of a word. The lexical system of the grammar is distinct from the conceptual representation associated with a lexical item, where polysemy is less constrained by grammar. We propose a structured semantic representation, the Lexical Conceptual Paradigm (LCP) which groups nouns into paradigmatic classes exhibiting like behavior."
P87-1024,On the Acquisition of Lexical Entries: The Perceptual Origin of Thematic Relations,1987,18,9,1,1,993,james pustejovsky,25th Annual Meeting of the Association for Computational Linguistics,1,"This paper describes a computational model of concept acquisition for natural language. We develop a theory of lexical semantics, the Extended Aspect Calculus, which together with a markedness theory for thematic relations, constrains what a possible word meaning can be. This is based on the supposition that predicates from the perceptual domain are the primitives for more abstract relations. We then describe an implementation of this model, TULLY, which mirrors the stages of lexical acquisition for children."
P87-1028,Lexical Selection in the Process of Language Generation,1987,11,18,1,1,993,james pustejovsky,25th Annual Meeting of the Association for Computational Linguistics,1,"In this paper we argue that lexical selection plays a more important role in the generation process than has commonly been assumed. To stress the importance of lexical-semantic input to generation, we explore the distinction and treatment of generating open and closed class lexical items, and suggest an additional classification of the latter into discourse-oriented and proposition-oriented items. Finally, we discuss how lexical selection is influenced by thematic (focus) information in the input."
H86-1015,{TAG}{'}s as a Grammatical Formalism for Generation,1986,12,2,2,0.284277,38634,david mcdonald,"Strategic Computing - Natural Language Workshop: Proceedings of a Workshop Held at Marina del Rey, California, May 1-2, 1986",0,"Tree Adjoining Grammars, or TAG's, (Joshi, Levy & Takahashi 1975; Joshi 1983; Kroch & Joshi 1985) were developed as an alternative to the standard syntactic formalisms that are used in theoretical analyses of language. They are attractive because they may provide just the aspects of context sensitive expressive power that actually appear in human languages while otherwise remaining context free.This paper describes how we have applied the theory of Tree Adjoining Grammars to natural language generation. We have been attracted to TAG's because their central operation-the extension of an initial phrase structure tree through the inclusion, at very specifically constrained locations, of one or more auxiliary trees-corresponds directly to certain central operations of our own, performance-oriented theory.We begin by briefly describing TAG's as a formalism for phrase structure in a competence theory, and summarize the points in the theory of TAG's that are germaine to our own theory. We then consider generally the position of a grammar within the generation process, introducing our use of TAG's through a contrast with how others have used systemic grammars. This takes us to the core results of our paper: using examples from our research with weft-written texts from newspapers, we walk through our TAG inspired treatments of raising and wh-movement, and show the correspondence of the TAG 'adjunction operation and our attachment process.In the final section we discuss extensions to the theory, motivated by the way we use the operation corresponding to TAG's adjunction in performance. This suggests that the competence theory of TAG's can be profitably projected to structures at the morphological level as well as the present syntactic level."
P85-1012,{TAG}{'}s as a Grammatical Formalism for Generation,1985,12,34,2,0,38634,david mcdonald,23rd Annual Meeting of the Association for Computational Linguistics,1,"Tree Adjoining Grammars, or TAG's, (Joshi, Levy & Takahashi 1975; Joshi 1983; Kroch & Joshi 1985) were developed as an alternative to the standard syntactic formalisms that are used in theoretical analyses of language. They are attractive because they may provide just the aspects of context sensitive expressive power that actually appear in human languages while otherwise remaining context free.This paper describes how we have applied the theory of Tree Adjoining Grammars to natural language generation. We have been attracted to TAG's because their central operation---the extension of an initial phrase structure tree through the inclusion, at very specifically constrained locations, of one or more auxiliary trees---corresponds directly to certain central operations of our own, performance-oriented theory.We begin by briefly describing TAG's as a formalism for phrase structure in a competence theory, and summarize the points in the theory of TAG's that are germaine to our own theory. We then consider generally the position of a grammar within the generation process, introducing our use of TAG's through a contrast with how others have used systemic grammars. This takes us to the core results of our paper: using examples from our research with weil-written texts from newspapers, we walk through our TAG inspired treatments of raising and wh-movement, and show the correspondence of the TAG adjunction operation and our attachment process.In the final section we discuss extensions to the theory, motivated by the way we use the operation corresponding to TAG's adjunction in performance. This suggests that the competence theory of TAG's can be profitably projected to structures at the morphological level as well as the present syntactic level."
E85-1027,A Computational Theory of Prose Style for Natural Language Generation,1985,7,18,2,0,38634,david mcdonald,Second Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"In this paper we report on initial research we have conducted on a computational theory of prose style. Our theory speaks to the following major points:1. Where in the generation process style is taken into account.2. How a particular prose style is represented; what stylistic rules look like;3. What modifications to a generation algorithm are needed; what the decision is that evaluates stylistic alternatives;4. What elaborations to the normal description of surface structure are necessary to make it usable as a plan for the text and a reference for these decisions;5. What kinds of information decisions about style have access to.Our theory emerged out of design experiments we have made over the past year with our natural language generation system, the Zetalisp program MUMBLE. In the process we have extended MUMBLE through the addition of an additional process that now mediates between content planning and linguistic realization. This new process, which we call attachment, provides the further significant benefit that text structure is no longer dictated by the structure of the message: the sequential order and dominance relationships of concepts in the message no longer force one form onto the words and phrases in the text. Instead, rhetorical and intentional directives can be interpreted flexibly in the context of the ongoing discourse and stylistic preferences. The text is built up through composition under the direction of linguistic organizing principles, rather than having to follow conceptual principles in lockstep.We will begin by describing what we mean by prose style and then introducing the generation task that lead us to this theory, the reproduction of short encyclopedia articles on African tribes. We will then use that task to outline the parts of our theory and the operations of the attachment process. Finally we will compare our techniques to the related work of Davey, McKeown and Derr, and Gabriel, and consider some of the possible psycholinguistic hypotheses that it may lead to."
1985.tmi-1.16,The Level Hypothesis in Discourse Analysis,1985,-1,-1,1,1,993,james pustejovsky,Proceedings of the first Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,None
