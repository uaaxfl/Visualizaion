2021.inlg-1.12,Explaining Decision-Tree Predictions by Addressing Potential Conflicts between Predictions and Plausible Expectations,2021,-1,-1,2,0,5929,sameen maruf,Proceedings of the 14th International Conference on Natural Language Generation,0,"We offer an approach to explain Decision Tree (DT) predictions by addressing potential conflicts between aspects of these predictions and plausible expectations licensed by background information. We define four types of conflicts, operationalize their identification, and specify explanatory schemas that address them. Our human evaluation focused on the effect of explanations on users{'} understanding of a DT{'}s reasoning and their willingness to act on its predictions. The results show that (1) explanations that address potential conflicts are considered at least as good as baseline explanations that just follow a DT path; and (2) the conflict-based explanations are deemed especially valuable when users{'} expectations disagree with the DT{'}s predictions."
2021.emnlp-main.233,Lifelong Explainer for Lifelong Learners,2021,-1,-1,3,0,9123,xuelin situ,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"Lifelong Learning (LL) black-box models are dynamic in that they keep learning from new tasks and constantly update their parameters. Owing to the need to utilize information from previously seen tasks, and capture commonalities in potentially diverse data, it is hard for automatic explanation methods to explain the outcomes of these models. In addition, existing explanation methods, e.g., LIME, which are computationally expensive when explaining a static black-box model, are even more inefficient in the LL setting. In this paper, we propose a novel Lifelong Explanation (LLE) approach that continuously trains a student explainer under the supervision of a teacher {--} an arbitrary explanation algorithm {--} on different tasks undertaken in LL. We also leverage the Experience Replay (ER) mechanism to prevent catastrophic forgetting in the student explainer. Our experiments comparing LLE to three baselines on text classification tasks show that LLE can enhance the stability of the explanations for all seen tasks and maintain the same level of faithfulness to the black-box model as the teacher, while being up to 10{\^{}}2 times faster at test time. Our ablation study shows that the ER mechanism in our LLE approach enhances the learning capabilities of the student explainer. Our code is available at https://github.com/situsnow/LLE."
2021.acl-long.415,Learning to Explain: Generating Stable Explanations Fast,2021,-1,-1,2,0,9123,xuelin situ,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),1,"The importance of explaining the outcome of a machine learning model, especially a black-box model, is widely acknowledged. Recent approaches explain an outcome by identifying the contributions of input features to this outcome. In environments involving large black-box models or complex inputs, this leads to computationally demanding algorithms. Further, these algorithms often suffer from low stability, with explanations varying significantly across similar examples. In this paper, we propose a Learning to Explain (L2E) approach that learns the behaviour of an underlying explanation algorithm simultaneously from all training examples. Once the explanation algorithm is distilled into an explainer network, it can be used to explain new instances. Our experiments on three classification tasks, which compare our approach to six explanation algorithms, show that L2E is between 5 and 7.5{\mbox{$\times$}}10{\^{}}4 times faster than these algorithms, while generating more stable explanations, and having comparable faithfulness to the black-box model."
W19-5936,Influence of Time and Risk on Response Acceptability in a Simple Spoken Dialogue System,2019,0,0,2,0,23775,andisheh partovi,Proceedings of the 20th Annual SIGdial Meeting on Discourse and Dialogue,0,"We describe a longitudinal user study conducted in the context of a Spoken Dialogue System for a household robot, where we examined the influence of time displacement and situational risk on users{'} preferred responses. To this effect, we employed a corpus of spoken requests that asked a robot to fetch or move objects in a room. In the first stage of our study, participants selected among four response types to these requests under two risk conditions: low and high. After some time, the same participants rated several responses to the previous requests {---} these responses were instantiated from the four response types. Our results show that participants did not rate highly their own response types; moreover, they rated their own response types similarly to different ones. This suggests that, at least in this context, people{'}s preferences at a particular point in time may not reflect their general attitudes, and that various reasonable response types may be equally acceptable. Our study also reveals that situational risk influences the acceptability of some response types."
U18-1007,Exploring Textual and Speech information in Dialogue Act Classification with Speaker Domain Adaptation,2018,10,0,5,0,3742,xuanli he,Proceedings of the Australasian Language Technology Association Workshop 2018,0,"In spite of the recent success of Dialogue Act (DA) classification, the majority of prior works focus on text-based classification with oracle transcriptions, i.e. human transcriptions, instead of Automatic Speech Recognition (ASR){'}s transcriptions. In spoken dialog systems, however, the agent would only have access to noisy ASR transcriptions, which may further suffer performance degradation due to domain shift. In this paper, we explore the effectiveness of using both acoustic and textual signals, either oracle or ASR transcriptions, and investigate speaker domain adaptation for DA classification. Our multimodal model proves to be superior to the unimodal models, particularly when the oracle transcriptions are not available. We also propose an effective method for speaker domain adaptation, which achieves competitive results."
N18-1115,The Context-Dependent Additive Recurrent Neural Net,2018,0,2,4,1,4061,quan tran,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",0,"Contextual sequence mapping is one of the fundamental problems in Natural Language Processing (NLP). Here, instead of relying solely on the information presented in the text, the learning agents have access to a strong external signal given to assist the learning process. In this paper, we propose a novel family of Recurrent Neural Network unit: the Context-dependent Additive Recurrent Neural Network (CARNN) that is designed specifically to address this type of problem. The experimental results on public datasets in the dialog problem (Babi dialog Task 6 and Frame), contextual language model (Switchboard and Penn Tree Bank) and question answering (Trec QA) show that our novel CARNN-based architectures outperform previous methods."
P17-2083,A Generative Attentional Neural Network Model for Dialogue Act Classification,2017,0,5,3,1,4061,quan tran,Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"We propose a novel generative neural network architecture for Dialogue Act classification. Building upon the Recurrent Neural Network framework, our model incorporates a novel attentional technique and a label to label connection for sequence learning, akin to Hidden Markov Models. The experiments show that both of these innovations lead our model to outperform strong baselines for dialogue act classification on MapTask and Switchboard corpora. We further empirically analyse the effectiveness of each of the new innovations."
E17-1041,A Hierarchical Neural Model for Learning Sequences of Dialogue Acts,2017,14,11,2,1,4061,quan tran,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 1, Long Papers",0,"We propose a novel hierarchical Recurrent Neural Network (RNN) for learning sequences of Dialogue Acts (DAs). The input in this task is a sequence of utterances (i.e., conversational contributions) comprising a sequence of tokens, and the output is a sequence of DA labels (one label per utterance). Our model leverages the hierarchical nature of dialogue data by using two nested RNNs that capture long-range dependencies at the dialogue level and the utterance level. This model is combined with an attention mechanism that focuses on salient tokens in utterances. Our experimental results show that our model outperforms strong baselines on two popular datasets, Switchboard and MapTask; and our detailed empirical analysis highlights the impact of each aspect of our model."
D17-1229,Preserving Distributional Information in Dialogue Act Classification,2017,0,6,2,1,4061,quan tran,Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing,0,"This paper introduces a novel training/decoding strategy for sequence labeling. Instead of greedily choosing a label at each time step, and using it for the next prediction, we retain the probability distribution over the current label, and pass this distribution to the next prediction. This approach allows us to avoid the effect of label bias and error propagation in sequence learning/decoding. Our experiments on dialogue act classification demonstrate the effectiveness of this approach. Even though our underlying neural network model is relatively simple, it outperforms more complex neural models, achieving state-of-the-art results on the MapTask and Switchboard corpora."
W16-5108,A Corpus of Tables in Full-Text Biomedical Research Publications,2016,26,0,2,1,33530,tatyana shmanina,Proceedings of the Fifth Workshop on Building and Evaluating Resources for Biomedical Text Mining ({B}io{T}xt{M}2016),0,"The development of text mining techniques for biomedical research literature has received increased attention in recent times. However, most of these techniques focus on prose, while much important biomedical data reside in tables. In this paper, we present a corpus created to serve as a gold standard for the development and evaluation of techniques for the automatic extraction of information from biomedical tables. We describe the guidelines used for corpus annotation and the manner in which they were developed. The high inter-annotator agreement achieved on the corpus, and the generic nature of our annotation approach, suggest that the developed guidelines can serve as a general framework for table annotation in biomedical and other scientific domains. The annotated corpus and the guidelines are available at \url{http://www.csse.monash.edu.au/research/umnl/data/index.shtml}."
N16-1090,Inter-document Contextual Language model,2016,5,5,2,1,4061,quan tran,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,None
U14-1007,A Comparative Study of Weighting Schemes for the Interpretation of Spoken Referring Expressions,2014,12,0,2,0.221502,38922,su kim,Proceedings of the Australasian Language Technology Association Workshop 2014,0,"This paper empirically explores the influence of two types of factors on the interpretation of spoken object descriptions: (1) descriptive attributes, e.g., colour and size; and (2) interpretation stages, e.g., syntax and pragmatics. We also investigate two schemes for combining attributes when estimating the goodness of an interpretation: Multiplicative and Additive. Our results show that the former scheme outperforms the latter, and that the weights assigned to the attributes of a description and the stages of an interpretation influence interpretation accuracy."
U14-1016,Challenges in Information Extraction from Tables in Biomedical Research Publications: a Dataset Analysis,2014,19,1,3,1,33530,tatyana shmanina,Proceedings of the Australasian Language Technology Association Workshop 2014,0,"We present a study of a dataset of tables from biomedical research publications. Our aim is to identify characteristics of biomedical tables that pose challenges for the task of extracting information from tables, and to determine which parts of research papers typically contain information that is useful for this task. Our results indicate that biomedical tables are hard to interpret without their source papers due to the brevity of the entries in the tables. In many cases, unstructured text segments, such as table titles, footnotes and non-table prose discussing a table, are required to interpret the table's entries."
J14-2003,Authorship Attribution with Topic Models,2014,60,37,2,1,39975,yanir seroussi,Computational Linguistics,0,"Authorship attribution deals with identifying the authors of anonymous texts. Traditionally, research in this field has focused on formal texts, such as essays and novels, but recently more attention has been given to texts generated by on-line users, such as e-mails and blogs. Authorship attribution of such on-line texts is a more challenging task than traditional authorship attribution, because such texts tend to be short, and the number of candidate authors is often larger than in traditional settings. We address this challenge by using topic models to obtain author representations. In addition to exploring novel ways of applying two popular topic models to this task, we test our new model that projects authors and documents to two disjoint topic spaces. Utilizing our model in authorship attribution yields state-of-the-art performance on several data sets, containing either formal texts written by a few authors or informal texts generated by tens to thousands of on-line users. We also present experimental results that demonstrate the applicability of topical author representations to two other problems: inferring the sentiment polarity of texts, and predicting the ratings that users would give to items such as movies."
U13-1012,Impact of Corpus Diversity and Complexity on {NER} Performance,2013,15,2,2,1,33530,tatyana shmanina,Proceedings of the Australasian Language Technology Association Workshop 2013 ({ALTA} 2013),0,We describe a cross-corpora evaluation of disease mention recognition for two annotated biomedical corpora: the Human Variome Project Corpus and the Arizona Disease Corpus. Our analysis of the performance of a state-of-the-art NER tool in terms of the characteristics and annotation schema of these corpora shows that these factors significantly affect performance.
U13-1014,Error Detection in Automatic Speech Recognition,2013,15,1,2,0,41182,farshid zavareh,Proceedings of the Australasian Language Technology Association Workshop 2013 ({ALTA} 2013),0,"We offer a supervised machine learning approach for recognizing erroneous words in the output of a speech recognizer. We have investigated several sets of features combined with two word configurations, and compared the performance of two classifiers: Decision Trees and Naive Bayes. Evaluation was performed on a corpus of 400 spoken referring expressions, with Decision Trees yielding a high recognition accuracy."
I13-1026,Evaluation of the Scusi? Spoken Language Interpretation System {--} A Case Study,2013,20,4,2,0,4,thomas kleinbauer,Proceedings of the Sixth International Joint Conference on Natural Language Processing,0,"We present a performance evaluation framework for Spoken Language Understanding (SLU) modules, focusing on three elements: (1) characterization of spoken utterances, (2) experimental design, and (3) quantitative evaluation metrics. We then describe the application of our framework to Scusi?xe2x80x94 our SLU system that focuses on referring expressions."
I13-1027,A Noisy Channel Approach to Error Correction in Spoken Referring Expressions,2013,19,3,2,0.221502,38922,su kim,Proceedings of the Sixth International Joint Conference on Natural Language Processing,0,"We offer a noisy channel approach for recognizing and correcting erroneous words in referring expressions. Our mechanism handles three types of errors: it removes noisy input, inserts missing prepositions, and replaces mis-heard words (at present, they are replaced by generic words). Our mechanism was evaluated on a corpus of 295 spoken referring expressions, improving interpretation performance."
U12-1008,Experimental Evaluation of a Lexicon- and Corpus-based Ensemble for Multi-way Sentiment Analysis,2012,20,5,2,0,42581,minh cao,Proceedings of the Australasian Language Technology Association Workshop 2012,0,"We describe a probabilistic approach that combines information obtained from a lexicon with information obtained from a Naive Bayes (NB) classifier for multi-way sentiment analysis. Our approach also employs grammatical structures to perform adjustments for negations, modifiers and sentence connectives. The performance of this method is compared with that of an NB classifier with feature selection, and MCST xe2x80x93 a state-of-the-art system. The results of our evaluation show that the performance of our hybrid approach is at least as good as that of these systems. We also examine the influence of three factors on performance: (1) sentiment-ambiguous sentences, (2) probability of the most probable star rating, and (3) coverage of the lexicon and the NB classifier. Our results indicate that the consideration of these factors supports the identification of regions of improved reliability for sentiment analysis."
P12-2052,Authorship Attribution with Author-aware Topic Models,2012,30,35,3,1,39975,yanir seroussi,Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"Authorship attribution deals with identifying the authors of anonymous texts. Building on our earlier finding that the Latent Dirichlet Allocation (LDA) topic model can be used to improve authorship attribution accuracy, we show that employing a previously-suggested Author-Topic (AT) model outperforms LDA when applied to scenarios with many authors. In addition, we define a model that combines LDA and AT by representing authors and documents over two disjoint topic sets, and show that our model outperforms LDA, AT and support vector machines on datasets with many authors."
Y11-1039,In Situ Text Summarisation for Museum Visitors,2011,20,1,4,0,1468,timothy baldwin,"Proceedings of the 25th Pacific Asia Conference on Language, Information and Computation",0,"This paper presents an experiment on in situ summarisation in a museum context. We implement a range of standard summarisation algorithms, and use them to generate summaries for individual exhibit areas in a museum, intended for in situ delivery to a museum visitor on a mobile device. Personalisation is relative to a visitorxe2x80x99s preference for summary length, the visitorxe2x80x99s relative interest in a given exhibit topic, as well as (optionally) the summary history. We find that the best-performing summarisation strategy is the Centroid algorithm, and that content diversification and customisation of summary length have a significant impact on user ratings of summary quality."
W11-0321,Authorship Attribution with {L}atent {D}irichlet {A}llocation,2011,19,41,2,1,39975,yanir seroussi,Proceedings of the Fifteenth Conference on Computational Natural Language Learning,0,"The problem of authorship attribution -- attributing texts to their original authors -- has been an active research area since the end of the 19th century, attracting increased interest in the last decade. Most of the work on authorship attribution focuses on scenarios with only a few candidate authors, but recently considered cases with tens to thousands of candidate authors were found to be much more challenging. In this paper, we propose ways of employing Latent Dirichlet Allocation in authorship attribution. We show that our approach yields state-of-the-art performance for both a few and many candidate authors, in cases where these authors wrote enough texts to be modelled effectively."
C10-2178,"Interpreting Pointing Gestures and Spoken Requests {--} A Probabilistic, Salience-based Approach",2010,15,0,1,1,5930,ingrid zukerman,Coling 2010: Posters,0,"We present a probabilistic, salience-based approach to the interpretation of pointing gestures together with spoken utterances. Our mechanism models dependencies between spatial and temporal aspects of gestures and features of utterances. For our evaluation, we collected a corpus of requests which optionally included pointing. Our results show that pointing information improves interpretation accuracy."
C10-1008,A Hierarchical Classifier Applied to Multi-way Sentiment Detection,2010,23,15,2,0,46513,adrian bickerstaffe,Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010),0,"This paper considers the problem of document-level multi-way sentiment detection, proposing a hierarchical classifier algorithm that accounts for the inter-class similarity of tagged sentiment-bearing texts. This type of classifier also provides a natural mechanism for reducing the feature space of the problem. Our results show that this approach improves on state-of-the-art predictive performance for movie reviews with three-star and four-star ratings, while simultaneously reducing training times and memory requirements."
W09-3907,Towards the Interpretation of Utterance Sequences in a Dialogue System,2009,17,2,1,1,5930,ingrid zukerman,Proceedings of the {SIGDIAL} 2009 Conference,0,"This paper describes a probabilistic mechanism for the interpretation of sentence sequences developed for a spoken dialogue system mounted on a robotic agent. The mechanism receives as input a sequence of sentences, and produces an interpretation which integrates the interpretations of individual sentences. For our evaluation, we collected a corpus of hypothetical requests to a robot. Our mechanism exhibits good performance for sentence pairs, but requires further improvements for sentence sequences."
J09-4010,An Empirical Study of Corpus-Based Response Automation Methods for an {E}-mail-Based Help-Desk Domain,2009,37,8,2,1,47359,yuval marom,Computational Linguistics,0,"This article presents an investigation of corpus-based methods for the automation of help-desk e-mail responses. Specifically, we investigate this problem along two operational dimensions: (1) information-gathering technique, and (2) granularity of the information. We consider two information-gathering techniques (retrieval and prediction) applied to information represented at two levels of granularity (document-level and sentence-level). Document-level methods correspond to the reuse of an existing response e-mail to address new requests. Sentence-level methods correspond to applying extractive multi-document summarization techniques to collate units of information from more than one e-mail. Evaluation of the performance of the different methods shows that in combination they are able to successfully automate the generation of responses for a substantial portion of e-mail requests in our corpus. We also investigate a meta-selection process that learns to choose one method to address a new inquiry e-mail, thus providing a unified response automation solution."
W06-1319,Balancing Conflicting Factors in Argument Interpretation,2006,-1,-1,1,1,5930,ingrid zukerman,Proceedings of the 7th {SIG}dial Workshop on Discourse and Dialogue,0,None
W06-0706,Automating Help-desk Responses: A Comparative Study of Information-gathering Approaches,2006,9,3,2,1,47359,yuval marom,Proceedings of the Workshop on Task-Focused Summarization and Question Answering,0,"We present a comparative study of corpus-based methods for the automatic synthesis of email responses to help-desk requests. Our methods were developed by considering two operational dimensions: (1) information-gathering technique, and (2) granularity of the information. In particular, we investigate two techniques -- retrieval and prediction -- applied to information represented at two levels of granularity -- sentence-level and document level. We also developed a hybrid method that combines prediction with retrieval. Our results show that the different approaches are applicable in different situations, addressing a combined 72% of the requests with either complete or partial responses."
P05-1028,Exploring and Exploiting the Limited Utility of Captions in Recognizing Intention in Information Graphics,2005,11,26,6,0,44181,stephanie elzer,Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics ({ACL}{'}05),1,"This paper presents a corpus study that explores the extent to which captions contribute to recognizing the intended message of an information graphic. It then presents an implemented graphic interpretation system that takes into account a variety of communicative signals, and an evaluation study showing that evidence obtained from shallow processing of the graphic's caption has a significant impact on the system's success. This work is part of a larger project whose goal is to provide sight-impaired users with effective access to information graphics."
J05-1007,"Book Review: Argumentation Machines: New Frontiers in Argumentation and Computation, edited by Chris Reed and Timothy {J}. Norman",2005,-1,-1,1,1,5930,ingrid zukerman,Computational Linguistics,0,None
C04-1068,Filtering Speaker-Specific Words from Electronic Discussions,2004,5,1,1,1,5930,ingrid zukerman,{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics,0,"The work presented in this paper is the first step in a project which aims to cluster and summarise electronic discussions in the context of help-desk applications. The eventual objective of this project is to use these summaries to assist help-desk users and operators. In this paper, we identify features of electronic discussions that influence the clustering process, and offer a filtering mechanism that removes undesirable influences. We tested the clustering and filtering processes on electronic newsgroup discussions, and evaluated their performance by means of two experiments: coarse-level clustering and simple information retrieval. Our evaluation shows that our filtering mechanism has a significant positive effect on both tasks."
W03-2104,An Information-theoretic Approach for Argument Interpretation,2003,6,0,2,0,49805,sarah george,Proceedings of the Fourth {SIG}dial Workshop of Discourse and Dialogue,0,None
W03-1613,Lexical Paraphrasing for Document Retrieval and Node Identification,2003,13,7,1,1,5930,ingrid zukerman,Proceedings of the Second International Workshop on Paraphrasing,0,"We investigate lexical paraphrasing in the context of two distinct applications: document retrieval and node identification. Document retrieval --- the first step in question answering --- retrieves documents that contain answers to user queries. Node identification --- performed in the context of a Bayesian argumentation system --- matches users' Natural Language sentences to nodes in a Bayesian network. Lexical paraphrases are generated using syntactic, semantic and corpus-based information. Our evaluation shows that lexical paraphrasing improves retrieval performance for both applications."
W02-0227,A Minimum Message Length Approach for Argument Interpretation,2002,10,3,1,1,5930,ingrid zukerman,Proceedings of the Third {SIG}dial Workshop on Discourse and Dialogue,0,"We describe a mechanism which receives as input a segmented argument composed of NL sentences, and generates an interpretation. Our mechanism relies on the Minimum Message Length Principle for the selection of an interpretation among candidate options. This enables our mechanism to cope with noisy input in terms of wording, beliefs and argument structure; and reduces its reliance on a particular knowledge representation. The performance of our system was evaluated by distorting automatically generated arguments, and passing them to the system for interpretation. In 75% of the cases, the interpretations produced by the system matched precisely or almost-precisely the representation of the original arguments."
C02-1047,"Towards a Noise-Tolerant, Representation-Independent Mechanism for Argument Interpretation",2002,7,6,1,1,5930,ingrid zukerman,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"We describe a mechanism for the interpretation of arguments, which can cope with noisy conditions in terms of wording, beliefs and argument structure. This is achieved through the application of the Minimum Message Length Principle to evaluate candidate interpretations. Our system receives as input a quasi-Natural Language argument, where propositions are presented in English, and generates an interpretation of the argument in the form of a Bayesian network (BN). Performance was evaluated by distorting the system's arguments (generated from a BN) and feeding them to the system for interpretation. In 75% of the cases, the interpretations produced by the system matched precisely or almost-precisely the representation of the original arguments."
C02-1161,Lexical Query Paraphrasing for Document Retrieval,2002,10,37,1,1,5930,ingrid zukerman,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"We describe a mechanism for the generation of lexical paraphrases of queries posed to an Internet resource. These paraphrases are generated using WordNet and part-of-speech information to propose synonyms for the content words in the queries. Statistical information, obtained from a corpus, is then used to rank the paraphrases. We evaluated our mechanism using 404 queries whose answers reside in the LA Times subset of the TREC-9 corpus. There was a 14% improvement in performance when paraphrases were used for document retrieval."
P01-1070,Using Machine Learning Techniques to Interpret {WH}-questions,2001,9,26,1,1,5930,ingrid zukerman,Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics,1,"We describe a set of supervised machine learning experiments centering on the construction of statistical models of WH-questions. These models, which are built from shallow linguistic features of questions, are employed to predict target variables which represent a user's informational goals. We report on different aspects of the predictive performance of our models, including the influence of various training and testing factors on predictive performance, and examine the relationships among the target variables."
W00-1406,Towards the Generation of Rebuttals in a {B}ayesian Argumentation System,2000,8,10,2,0,54183,nathalie jitnah,{INLG}{'}2000 Proceedings of the First International Conference on Natural Language Generation,0,"We describe a mechanism which generates rebuttals to a user's rejoinders in the context of arguments generated from Bayesian networks. This mechanism is implemented in an interactive argumentation system. Given an argument generated by the system and an interpretation of a user's rejoinder, the generation of the rebuttal takes into account the intended effect of the user's rejoinder, determined on a model of the user's beliefs, and its actual effect, determined on a model of the system's beliefs. We consider three main rebuttal strategies: refute the user's rejoinder, strengthen the argument goal, and dismiss the user's line of reasoning."
W00-1408,Using Argumentation Strategies in Automated Argument Generation,2000,11,29,1,1,5930,ingrid zukerman,{INLG}{'}2000 Proceedings of the First International Conference on Natural Language Generation,0,"During argumentation, people persuade their audience using a variety of strategies, e.g., hypothetical reasoning, reasoning by cases and ordinary premise-to-goal arguments. In this paper, we offer an operational definition of the conditions for pursuing these strategies, and incorporate into a Bayesian argument-generation system a mechanism for proposing applicable argumentation strategies, generating specific arguments based on these strategies, and selecting a final argument."
W98-1416,Attention During Argument Generation and Presentation,1998,12,4,1,1,5930,ingrid zukerman,Natural Language Generation,0,"We describe the operation of our argumentation system, and discuss its use of attentional focus during both content planning and argument presentation. During content planning, attentional focus guides an abductive process used to build-up arguments. This process is applied to a model of a user's xe2x80xa2 beliefs and a normative model. During argument presentation, attentional focus supports the generation of enthymematic arguments."
W98-1212,A {B}ayesian Approach to Automating Argumentation,1998,14,2,3,0,54184,richard mcconachy,New Methods in Language Processing and Computational Natural Language Learning,0,"Our argumentation system NAG uses Bayesian networks in a user model and in a normative model to assemble and assess nice arguments, that is arguments which balance persuasiveness with normative correctness. Attentional focus is simulated in both models to select relevant subnetworks for Bayesian propagation. Bayesian propagation in the user model is modified to represent some human cognitive weaknesses. The subnetworks are expanded in an iterative abductive process until argumentative goals are achieved in both models, when the argument is presented to the user."
W98-1222,Extracting Phoneme Pronunciation Information from Corpora,1998,10,4,2,0,55144,ian thomas,New Methods in Language Processing and Computational Natural Language Learning,0,"We present a procedure that determines a set of phonemes possibly intended by a speaker from a recognized or uttered phone. This information will be used to allow a speech recognizer to take pronunciation into account or to consider input from a noisy source during lexical access. We investigate the hypothesis that different pronunciations of a phone occur within groups of sounds physically produced the same way, and use the Minimum Message Length principle to consider the effect of a phoneme's context on its pronunciation."
W94-0305,Discourse Planning as an Optimization Process,1994,11,3,1,1,5930,ingrid zukerman,Proceedings of the Seventh International Workshop on Natural Language Generation,0,"Discourse planning systems developed to date apply local considerations in order to generate an initial presentation that achieves a given communicative goal. However, they lack a global criterion for selecting among alternative presentations. In this paper, we cast the problem of planning discourse as an optimization problem, which allows the definition of a global optimization criterion. In particular, we consider two such criteria: (1) generating the most concise discourse, and (2) generating the 'shallowest' discourse, i. e., discourse that requires the least prerequisite information. These criteria are embodied in a discourse planning mechanism which considers the following factors: (1) the effect of a user's inferences from planned utterances on his/her beliefs, (2) the amount of prerequisite information a user requires to understand an utterance, and (3) the amount of information that must be included in referring expressions which identify the concepts mentioned in an utterance. This mechanism is part of a discourse planning system called WISHFULII which generates explanations about concepts in technical domains."
J91-3007,Current Research in Natural Language Generation,1991,-1,-1,1,1,5930,ingrid zukerman,Computational Linguistics,0,None
W90-0121,Generating Peripheral Rhetorical Devices by Consulting a User Model,1990,15,3,1,1,5930,ingrid zukerman,Proceedings of the Fifth International Workshop on Natural Language Generation,0,None
