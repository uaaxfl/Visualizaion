bost-moore-2014-analysis,georgila-etal-2008-fully,1,\N,Missing
bost-moore-2014-analysis,moller-etal-2008-corpus,0,\N,Missing
bost-moore-2014-analysis,cucchiarini-etal-2006-jasmin,0,\N,Missing
bost-moore-2014-analysis,W10-4321,1,\N,Missing
C98-1051,J96-2004,0,0.0906387,"Missing"
E03-1072,J96-2004,0,0.0738041,"ation assumptions fail on selected examples. However, in eliminating the assumptions it is likely that we will introduce more errors than we correct. For example, it is clear that some answers take initiative; if a speaker asks &quot;what time is it?&quot; and the listener gives more information than the current time, then the listener has taken initiative. However, if the speaker asks &quot;what causes current to flow?&quot;, it is much more difficult to say which answers take initiative. Similarly, it is difficult to say when a ques`These guidelines are based on comments by Krippendorff (1980) as summarized in Carletta (1996). Krippendorff considered the case of two annotated variables. He said that comparisons were reliable when the kappas for those variables were above 0.8. 3 1n this study, hierarchical discourse segments were annotated using changes in initiative as a starting point; these changes were taken as marking either a segment endpoint or the beginning of a nested segment. tion following a question takes initiative. Some factors are the content of the second question, how many times the first speaker has been interrupted, and the reaction of the first speaker. But it seems very difficult to define thes"
E03-1072,A00-2027,0,0.0613447,"Missing"
E03-1072,W01-1607,0,0.0233313,"rranging actions, or setting parameters. Whittaker and Stenton (1988) do not define initiative beyond calling it control of the dialogue by its participants. Their work is notable in that 1 The page numbers come from the digital version: http://citeseer.nj.nec.com/244268.htm1 they define a set of rules (see Figure 1) specifying who has initiative for each turn in a dialogue. These rules approximate the more complex definition given by Chu-Carroll and Brown and have been used in several projects because they facilitate reliable annotation (Strayer and Heeman, 2001; Jordan and Di Eugenio, 1997; Doran et al., 2001; Walker and Whittaker, 1990). 2.2 Initiative in human-human corpora Previous work has shown a pattern to how initiative shifts among dialogue participants in problem-solving dialogues. Guinn (1996) used simulated conversational agents to argue that the most efficient problem-solving dialogues are those where the participant who knows the most about the current subtask takes initiative. The corpus analysis of Walker and Whittaker (1990) gives evidence that in natural dialogue, knowledgeable speakers do take initiative. Walker and Whittaker studied task-oriented dialogues (TODs) involving an ex"
E03-1072,J86-3001,0,0.224375,"Missing"
E03-1072,W01-1621,0,0.0129757,"fer to adding or taking away actions from the plan, rearranging actions, or setting parameters. Whittaker and Stenton (1988) do not define initiative beyond calling it control of the dialogue by its participants. Their work is notable in that 1 The page numbers come from the digital version: http://citeseer.nj.nec.com/244268.htm1 they define a set of rules (see Figure 1) specifying who has initiative for each turn in a dialogue. These rules approximate the more complex definition given by Chu-Carroll and Brown and have been used in several projects because they facilitate reliable annotation (Strayer and Heeman, 2001; Jordan and Di Eugenio, 1997; Doran et al., 2001; Walker and Whittaker, 1990). 2.2 Initiative in human-human corpora Previous work has shown a pattern to how initiative shifts among dialogue participants in problem-solving dialogues. Guinn (1996) used simulated conversational agents to argue that the most efficient problem-solving dialogues are those where the participant who knows the most about the current subtask takes initiative. The corpus analysis of Walker and Whittaker (1990) gives evidence that in natural dialogue, knowledgeable speakers do take initiative. Walker and Whittaker studi"
E03-1072,P90-1010,0,0.435481,"setting parameters. Whittaker and Stenton (1988) do not define initiative beyond calling it control of the dialogue by its participants. Their work is notable in that 1 The page numbers come from the digital version: http://citeseer.nj.nec.com/244268.htm1 they define a set of rules (see Figure 1) specifying who has initiative for each turn in a dialogue. These rules approximate the more complex definition given by Chu-Carroll and Brown and have been used in several projects because they facilitate reliable annotation (Strayer and Heeman, 2001; Jordan and Di Eugenio, 1997; Doran et al., 2001; Walker and Whittaker, 1990). 2.2 Initiative in human-human corpora Previous work has shown a pattern to how initiative shifts among dialogue participants in problem-solving dialogues. Guinn (1996) used simulated conversational agents to argue that the most efficient problem-solving dialogues are those where the participant who knows the most about the current subtask takes initiative. The corpus analysis of Walker and Whittaker (1990) gives evidence that in natural dialogue, knowledgeable speakers do take initiative. Walker and Whittaker studied task-oriented dialogues (TODs) involving an expert guiding a novice through"
E03-1072,P88-1015,0,0.672625,"e) from task initiative. They define dialogue initiative by stating that it &quot;tracks the lead in determining the current discourse focus&quot; (p. 6), 1 and that task initiative &quot;tracks the lead in the development of the agents&apos; plan&quot; (p. 6). Presumably, determining the discourse focus means setting the discourse segment purpose as defined in Grosz and Sidner&apos;s (1986) theory of discourse. What it means to take the lead in developing the agents&apos; plan depends on the plan representation but informally can refer to adding or taking away actions from the plan, rearranging actions, or setting parameters. Whittaker and Stenton (1988) do not define initiative beyond calling it control of the dialogue by its participants. Their work is notable in that 1 The page numbers come from the digital version: http://citeseer.nj.nec.com/244268.htm1 they define a set of rules (see Figure 1) specifying who has initiative for each turn in a dialogue. These rules approximate the more complex definition given by Chu-Carroll and Brown and have been used in several projects because they facilitate reliable annotation (Strayer and Heeman, 2001; Jordan and Di Eugenio, 1997; Doran et al., 2001; Walker and Whittaker, 1990). 2.2 Initiative in hu"
E03-1072,P96-1037,0,\N,Missing
E06-1009,P04-1009,0,0.4848,"learly, alternative strategies to sequential presentation of information in SDS are needed. Recently, two approaches have been proposed. In the user-model (UM) based approach, the system identifies a small number of options that best match the user’s preferences (Moore et al., 2004; Walker et al., 2004). In the summarize and refine (SR) approach, the system structures the large number of options into a small number of clusters that share attributes. The system summarizes the clusters based on their attributes and then prompts the user to provide additional constraints (Polifroni et al., 2003; Chung, 2004). In this paper, we present an algorithm that combines the benefits of these two approaches in an approach to information presentation that integrates user modelling with automated clustering. 65 Thus, the system provides detail only about those options that are of some relevance to the user, where relevance is determined by the user model. If there are multiple relevant options, a clusterbased tree structure orders these options to allow for stepwise refinement. The effectiveness of the tree structure, which directs the dialogue flow, is optimized by taking the user’s preferences into account"
E06-1009,P01-1066,0,0.276542,"ably, increases overall user satisfaction, and significantly improves the user’s overview of the available options. Moreover, our results suggest that presenting users with a brief summary of the irrelevant options increases users’ confidence in having heard about all relevant options. 1 Introduction The goal of spoken dialogue systems (SDS) is to offer efficient and natural access to applications and services, such as email and calendars, travel and entertainment booking, and product recommendation. In evaluating nine SDS in the DARPA Communicator domain (flight, hotel, and rental car hire), Walker et al. (2001) found that (1) shorter task duration correlates with higher user satisfaction, and (2) the information presentation phase of dialogues is the primary contributor to dialogue duration. During this phase, the typical system enumerates the set of options that match the user’s constraints, as shown in Figure 1. The user can then refine these options by offering new constraints. When the number of options to be presented is large, this process can be painstaking, leading to reduced user satisfaction. Moreover, as Johanna D. Moore School of Informatics University of Edinburgh Edinburgh, EH8 9LW, GB"
E06-1009,W03-2123,0,\N,Missing
E06-1009,W04-0601,0,\N,Missing
E06-1009,P96-1039,0,\N,Missing
E06-1009,W02-2110,0,\N,Missing
E06-1035,J97-1003,0,0.715272,"of the annotation procedure. 3.3 Probabilistic models Our goal is to investigate the impact of ASR errors on the selection of features and the choice of models for segmenting topics at different levels of granularity. We compare two segmentation models: (1) an unsupervised lexical cohesion-based model (LM) using solely lexical cohesion information, and (2) feature-based combined models (CM) that are trained on a combination of lexical cohesion and conversational features. 3.3.1 Lexical cohesion-based model In this study, we use Galley et al.’s (2003) LCSeg algorithm, a variant of TextTiling (Hearst, 1997). LCSeg hypothesizes that a major topic shift is likely to occur where strong term repetitions start and end. The algorithm works with two adjacent analysis windows, each of a fixed size which is empirically determined. For each utterance boundary, LCSeg calculates a lexical cohesion score by computing the cosine similarity at the transition between the two windows. Low similarity indicates low lexical cohesion, and a sharp change in lexical cohesion score indicates a high probability of an actual topic boundary. The principal difference between LCSeg and TextTiling is that LCSeg measures simi"
E06-1035,J02-1002,0,0.199496,"as cue phrases and overlapping speech, are better indicators for the toplevel prediction task. We also find that the transcription errors inevitable in ASR output have a negative impact on models that combine lexical-cohesion and conversational features, but do not change the general preference of approach for the two tasks. 1 Introduction Text segmentation, i.e., determining the points at which the topic changes in a stream of text, plays an important role in applications such as topic detection and tracking, summarization, automatic genre detection and information retrieval and extraction (Pevzner and Hearst, 2002). In recent Steve Renals School of Informatics University of Edinburgh Edinburgh, EH8 9LW, GB s.renals@ed.ac.uk work, researchers have applied these techniques to corpora such as newswire feeds, transcripts of radio broadcasts, and spoken dialogues, in order to facilitate browsing, information retrieval, and topic detection (Allan et al., 1998; van Mulbregt et al., 1999; Shriberg et al., 2000; Dharanipragada et al., 2000; Blei and Moreno, 2001; Christensen et al., 2005). In this paper, we focus on segmentation of multiparty dialogues, in particular recordings of small group meetings. We compar"
E06-1035,C00-2140,0,0.222661,"Missing"
E06-1035,P03-1071,0,0.683548,"hesizing where major topic changes occur and hypothesizing where more subtle nested topic shifts occur. In addition, because we do not wish to make the assumption that high quality transcripts of meeting records, such as those produced by human transcribers, will be commonly available, we require algorithms that operate directly on automatic speech recognition (ASR) output. 2 Previous Work Prior research on segmentation of spoken “documents” uses approaches that were developed for text segmentation, and that are based solely on textual cues. These include algorithms based on lexical cohesion (Galley et al., 2003; Stokes et al., 2004), as well as models using annotated features (e.g., cue phrases, part-of-speech tags, coreference relations) that have been determined to correlate with segment boundaries (Gavalda et al., 1997; Beeferman et al., 1999). Blei et al. (2001) 273 and van Mulbregt et al. (1999) use topic language models and variants of the hidden Markov model (HMM) to identify topic segments. Recent systems achieve good results for predicting topic boundaries when trained and tested on human transcriptions. For example, Stokes et al. (2004) report an error rate (Pk) of 0.25 on segmenting broad"
E06-1035,A97-1003,0,0.0357873,"uch as those produced by human transcribers, will be commonly available, we require algorithms that operate directly on automatic speech recognition (ASR) output. 2 Previous Work Prior research on segmentation of spoken “documents” uses approaches that were developed for text segmentation, and that are based solely on textual cues. These include algorithms based on lexical cohesion (Galley et al., 2003; Stokes et al., 2004), as well as models using annotated features (e.g., cue phrases, part-of-speech tags, coreference relations) that have been determined to correlate with segment boundaries (Gavalda et al., 1997; Beeferman et al., 1999). Blei et al. (2001) 273 and van Mulbregt et al. (1999) use topic language models and variants of the hidden Markov model (HMM) to identify topic segments. Recent systems achieve good results for predicting topic boundaries when trained and tested on human transcriptions. For example, Stokes et al. (2004) report an error rate (Pk) of 0.25 on segmenting broadcast news stories using unsupervised lexical cohesion-based approaches. However, topic segmentation of multiparty dialogue seems to be a considerably harder task. Galley et al. (2003) report an error rate (Pk) of 0."
E09-2009,P08-2050,0,0.0555286,"lenge is a new Internetbased evaluation effort for natural language generation systems. In this paper, we motivate and describe the software infrastructure that we developed to support this challenge. 1 Introduction Natural language generation (NLG) systems are notoriously hard to evaluate. On the one hand, simply comparing system outputs to a gold standard is not appropriate because there can be multiple generated outputs that are equally good, and finding metrics that account for this variability and produce results consistent with human judgments and task performance measures is difficult (Belz and Gatt, 2008; Stent et al., 2005; Foster, 2008). On the other hand, lab-based evaluations with human subjects to assess each aspect of the system’s functionality are expensive and time-consuming. These characteristics make it hard to compare different systems and measure progress. GIVE (“Generating Instructions in Virtual Environments”) (Koller et al., 2007) is a research challenge for the NLG community designed to provide a new approach to NLG system evaluation. In the GIVE scenario, users try to solve a treasure hunt in a virtual 3D world that they have not seen before. The computer has a complete symbo"
E09-2009,W08-1113,0,0.0796843,"ffort for natural language generation systems. In this paper, we motivate and describe the software infrastructure that we developed to support this challenge. 1 Introduction Natural language generation (NLG) systems are notoriously hard to evaluate. On the one hand, simply comparing system outputs to a gold standard is not appropriate because there can be multiple generated outputs that are equally good, and finding metrics that account for this variability and produce results consistent with human judgments and task performance measures is difficult (Belz and Gatt, 2008; Stent et al., 2005; Foster, 2008). On the other hand, lab-based evaluations with human subjects to assess each aspect of the system’s functionality are expensive and time-consuming. These characteristics make it hard to compare different systems and measure progress. GIVE (“Generating Instructions in Virtual Environments”) (Koller et al., 2007) is a research challenge for the NLG community designed to provide a new approach to NLG system evaluation. In the GIVE scenario, users try to solve a treasure hunt in a virtual 3D world that they have not seen before. The computer has a complete symbolic representation of the virtual e"
E12-1048,W09-3906,1,0.839205,"ts or a simple property, e.g., “Which components in circuit 1 are in a closed path?” or “Are bulbs A and B wired • Help request: any expression indicating that the student does not know the answer and without domain content. • Social: any expression such as “sorry” which appears to relate to social interaction and has no recognizable domain content. • Uninterpretable: the system could not arrive at any interpretation of the utterance. It will respond by identifying the likely source of error, if possible (e.g., a word it does not understand) and asking the student to rephrase their utterance (Dzikovska et al., 2009). 472 If the student utterance was determined to be an answer, it is further diagnosed for correctness as discussed in (Dzikovska et al., 2010b), using a domain reasoner together with semantic representations of expected correct answers supplied by human tutors. The resulting diagnosis contains the following information: • Consistency: whether the student statement correctly describes the facts mentioned in the question and the simulation environment: e.g., student saying “Switch X is closed” is labeled inconsistent if the question stipulated that this switch is open. • Diagnosis: an analysis"
E12-1048,P10-4003,1,0.753988,"The answers were then manually annotated to create a gold standard evaluation corpus. 2.2 B EETLE II Interpretation Output The interpretation component of B EETLE II uses a syntactic parser and a set of hand-authored rules to extract the domain-specific semantic representations of student utterances from the text. The student answer is first classified with respect to its domain-specific speech act, as follows: Evaluation Procedure • Answer: a contentful expression to which the system responds with a tutoring action, either accepting it as correct or remediating the problems as discussed in (Dzikovska et al., 2010a). Data Collection We collected transcripts of students interacting with B EETLE II (Dzikovska et al., 2010b), a tutorial dialogue system for teaching conceptual knowledge in the basic electricity and electronics domain. The system is a learning environment with a self-contained curriculum targeted at students with no knowledge of high school physics. When interacting with the system, students spend 3-5 hours going through pre-prepared reading material, building and observing circuits in a simulator, and talking with a dialogue-based computer tutor via a text-based chat interface. During the"
E12-1048,N06-1034,0,0.0262995,"components of the system most need improvement, with user satisfaction as the outcome metric (M¨oller et al., 2007; M¨oller et al., 2008; Walker et al., 2000; Larsen, 2003). In tutorial dialogue, PARADISE studies investigated 471 Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 471–481, c Avignon, France, April 23 - 27 2012. 2012 Association for Computational Linguistics which manually annotated features predict learning outcomes, to justify new features needed in the system (Forbes-Riley et al., 2007; Rotaru and Litman, 2006; Forbes-Riley and Litman, 2006). We adapt the PARADISE methodology to evaluating individual NLP components, linking commonly used intrinsic evaluation scores with extrinsic outcome metrics. We describe an evaluation of an interpretation component of a tutorial dialogue system, with student learning gain as the target outcome measure. We first describe the evaluation setup, which uses standard classification accuracy metrics for system evaluation (Section 2). We discuss the results of the intrinsic system evaluation in Section 3. We then show that standard evaluation metrics do not serve as good predictors of system performa"
E12-1048,W06-3503,0,0.0248726,"nt utterance. The speech act and the diagnosis are passed to the tutorial planner which makes decisions about feedback. They constitute the output of the interpretation component, and its quality is likely to affect the learning outcomes, therefore we need an effective way to evaluate it. In future work, performance of individual pipeline components could also be evaluated in a similar fashion. 2.3 Data Annotation The general idea of breaking down the student answer into correct, incorrect and missing parts is common in tutorial dialogue systems (Nielsen et al., 2008; Dzikovska et al., 2010b; Jordan et al., 2006). However, representation details are highly system specific, and difficult and time-consuming to annotate. Therefore we implemented a simplified annotation scheme which classifies whole answers as correct, partially correct but incomplete, or contradictory, without explicitly identifying the correct and incorrect parts. This makes it easier to create the gold standard and still retains useful information, because tutoring systems often choose the tutoring strategy based on the general answer class (correct, incomplete, or contradictory). In addition, this allows us to cast the problem in term"
E12-1048,H91-1061,0,0.648626,"Missing"
E12-1048,P08-1006,0,0.0263873,"arser, is included in a larger system, it is not always clear that improvements in intrinsic evaluation scores will translate into improved overall system performance. Therefore, extrinsic or task-based evaluation can be used to complement intrinsic evaluations. For example, NLP components such as parsers and co-reference resolution algorithms could be compared in terms of how much they contribute to the performance of a textual entailment (RTE) system (Sammons et al., 2010; Yuret et al., 2010); parser performance could be evaluated by how well it contributes to an information retrieval task (Miyao et al., 2008). However, task-based evaluation can be difficult and expensive for interactive applications. Specifically, task-based evaluation for dialogue systems typically involves collecting data from a number of people interacting with the system, which is time-consuming and labor-intensive. Thus, it is desirable to develop an off-line evaluation procedure that relates intrinsic evaluation metrics to predicted interaction outcomes, reducing the need to conduct experiments with human participants. This problem can be addressed via the use of the PARADISE evaluation methodology for spoken dialogue system"
E12-1048,W06-1611,0,0.0237525,"ystems to establish which components of the system most need improvement, with user satisfaction as the outcome metric (M¨oller et al., 2007; M¨oller et al., 2008; Walker et al., 2000; Larsen, 2003). In tutorial dialogue, PARADISE studies investigated 471 Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 471–481, c Avignon, France, April 23 - 27 2012. 2012 Association for Computational Linguistics which manually annotated features predict learning outcomes, to justify new features needed in the system (Forbes-Riley et al., 2007; Rotaru and Litman, 2006; Forbes-Riley and Litman, 2006). We adapt the PARADISE methodology to evaluating individual NLP components, linking commonly used intrinsic evaluation scores with extrinsic outcome metrics. We describe an evaluation of an interpretation component of a tutorial dialogue system, with student learning gain as the target outcome measure. We first describe the evaluation setup, which uses standard classification accuracy metrics for system evaluation (Section 2). We discuss the results of the intrinsic system evaluation in Section 3. We then show that standard evaluation metrics do not serve as go"
E12-1048,P10-1122,0,0.0279849,"Fscore on the same data set to compare the performance of different approaches to the same NLP problem. However, once a component, such as a parser, is included in a larger system, it is not always clear that improvements in intrinsic evaluation scores will translate into improved overall system performance. Therefore, extrinsic or task-based evaluation can be used to complement intrinsic evaluations. For example, NLP components such as parsers and co-reference resolution algorithms could be compared in terms of how much they contribute to the performance of a textual entailment (RTE) system (Sammons et al., 2010; Yuret et al., 2010); parser performance could be evaluated by how well it contributes to an information retrieval task (Miyao et al., 2008). However, task-based evaluation can be difficult and expensive for interactive applications. Specifically, task-based evaluation for dialogue systems typically involves collecting data from a number of people interacting with the system, which is time-consuming and labor-intensive. Thus, it is desirable to develop an off-line evaluation procedure that relates intrinsic evaluation metrics to predicted interaction outcomes, reducing the need to conduct exp"
E12-1048,S10-1009,0,0.0662581,"Missing"
E12-1048,W07-0304,0,\N,Missing
georgila-etal-2008-fully,moller-etal-2008-corpus,1,\N,Missing
georgila-etal-2008-fully,cucchiarini-etal-2006-jasmin,0,\N,Missing
H93-1032,P89-1025,1,0.905982,"ationalScience Foundation,ReseerchInitiationAward. • explicit reference to a previous explanation (or portion thereof) in order to point out similarities (differences) between the material currently being explained and material presented in earfier explanation(s), • omission of previously explained material to avoid distracting student from what is new, • explicit marking of repeated material to distinguish it from new material (e.g., ""As I said b e f o r e , . . . "") • elaboration of previous material in the form of generalizations, more detail, or justifications. 1 Building on previous work [2, 3] we have implemented an explanation facifity that maintains a discourse history and uses it in planning subsequent explanations. We are using this explanation facility as part of two intelligent systems. The first is a patient education system intended to provide patients with information about their disease, possible therapies, and medications [4, 5]. The second is an intelligent coached practice environment for training avionics technicians to troubleshoot complex electronic equipment [6]. In order to generate texts that exploit previous discourse, a system must have the following capabiliti"
H93-1032,P89-1009,0,\N,Missing
H93-1032,J86-3001,0,\N,Missing
H93-1032,P84-1078,0,\N,Missing
J10-2001,P02-1041,0,0.189312,"Missing"
J10-2001,C00-1007,0,0.0839111,"extended to apply across turns as well. 172 White, Clark, and Moore Generating Tailored Descriptions with Appropriate Intonation it implements a hybrid symbolic-statistical chart realization algorithm that combines (1) a theoretically grounded approach to syntax and semantic composition, with (2) the use of integrated language models for making choices among the options left open by the grammar. In so doing, it brings together the symbolic chart realization (Kay 1996; Shemtov 1997; Carroll et al. 1999; Moore 2002) and statistical realization (Knight and Hatzivassiloglou 1995; Langkilde 2000; Bangalore and Rambow 2000; Langkilde-Geary 2002; Oh and Rudnicky 2002; Ratnaparkhi 2002) traditions. Another recent approach to combining these traditions appears in Carroll and Oepen (2005), where parse selection techniques are incorporated into an HPSG realizer. Like other realizers, the OpenCCG realizer is partially responsible for determining word order and inﬂection. For example, the realizer determines that also should preferably follow the verb in There is also a very cheap ﬂight on Air France, whereas in other cases it typically precedes the verb, as in I also have a ﬂight that leaves London at 3:45 p.m. It al"
J10-2001,W03-2123,0,0.0691506,"re ARE seats in business class)theme (on the British Airways ﬂight)rheme (that arrives at four twenty p.m.)rheme , where the division of the sentence into theme and rheme phrases is shown informally using parentheses, and contrastive emphasis (on ARE) is shown using small caps. (See Section 2.6.2 for details of how emphasis and phrasing are realized by pitch accents and edge tones.) 2.2 Architecture The architecture of the FLIGHTS generator appears in Figure 3. OAA (Martin, Cheyer, and Moran 1999) serves as a communications hub, with the following agents responsible for speciﬁc tasks: DIPPER (Bos et al. 2003) for dialogue management; a Java agent that implements an additive multi-attribute value function (AMVF), a decision-theoretic model of the user’s preferences (Carenini and Moore 2000, 2006), for user modeling; OPlan (Currie and Tate 1991) for content planning; Xalan XSLT5 and OpenCCG (White 5 http://xml.apache.org/xalan-j/. 163 Computational Linguistics Volume 36, Number 2 Figure 3 FLIGHTS generation architecture. 2004, 2006a, 2006b) for sentence planning and surface realization; and Festival (Taylor, Black, and Caley 1998) for speech synthesis. The user modeling, content planning, sentence p"
J10-2001,W05-0307,0,0.0391251,"Missing"
J10-2001,W00-1407,1,0.657912,"or sequential presentation. In particular, we require better algorithms for: 1. selecting the most relevant subset of options to mention, as well as the attributes that are most relevant to choosing among them; and 2. determining how to organize and express the descriptions of the selected options and attributes, in ways that are both easy to understand and memorable.1 In this article, we describe how we have addressed these points in the FLIGHTS2 system, reviewing and extending the description given in Moore et al. (2004). FLIGHTS follows previous work (Carberry, Chu-Carroll, and Elzer 1999; Carenini and Moore 2000; Walker et al. 2002) in applying decision-theoretic models of user preferences to the generation of tailored descriptions of the most relevant available options. Multiattribute decision theory provides a detailed account of how models of user preferences can be used in decision making (Edwards and Barron 1994). Such preference models have been shown to enable systems to present information in ways that are concise and 1 An issue we do not address in this article is whether a multimodal system would be more effective than a voice-only one. We believe that these needs, and in particular the nee"
J10-2001,I05-1015,0,0.0310471,"istical chart realization algorithm that combines (1) a theoretically grounded approach to syntax and semantic composition, with (2) the use of integrated language models for making choices among the options left open by the grammar. In so doing, it brings together the symbolic chart realization (Kay 1996; Shemtov 1997; Carroll et al. 1999; Moore 2002) and statistical realization (Knight and Hatzivassiloglou 1995; Langkilde 2000; Bangalore and Rambow 2000; Langkilde-Geary 2002; Oh and Rudnicky 2002; Ratnaparkhi 2002) traditions. Another recent approach to combining these traditions appears in Carroll and Oepen (2005), where parse selection techniques are incorporated into an HPSG realizer. Like other realizers, the OpenCCG realizer is partially responsible for determining word order and inﬂection. For example, the realizer determines that also should preferably follow the verb in There is also a very cheap ﬂight on Air France, whereas in other cases it typically precedes the verb, as in I also have a ﬂight that leaves London at 3:45 p.m. It also enforces subject–verb agreement, for example, between is and ﬂight, or between are and seats. Less typically, in FLIGHTS and in the COMIC12 system, the OpenCCG re"
J10-2001,P04-1009,0,0.0916248,"(SR) approach, in which the system structures a large number of options into a small number 194 White, Clark, and Moore Generating Tailored Descriptions with Appropriate Intonation of clusters that share attributes. The system then summarizes the clusters based on their attributes, implicitly prompting the user to provide additional constraints. The system produces summaries such as I have found 983 restaurants. Most of them are located in Boston and Cambridge. There are 32 choices for cuisine. I also have information about price range. which help the user get an overview of the option space. Chung (2004) extended this approach by proposing a constraint relaxation strategy for coping with queries that are too restrictive to be satisﬁed by any option. Pon-Barry, Weng, and Varges (2006) found that fewer dialogue turns were necessary when the system proactively suggested reﬁnements and relaxations. However, as argued in Demberg and Moore (2006), there are several limitations to the SR approach. First, many turns may be required during the reﬁnement process. Second, if there is no optimal solution, exploration of trade-offs is difﬁcult. Finally, the attributes on which the data has been clustered"
J10-2001,E06-1009,1,0.947729,"straints to winnow down a large set before querying the database of options. Other researchers have argued that it is important to allow users to browse the data for a number of reasons: (1) if there are many options that share attribute values, they will be very close in score when ranked using the UM-based approach; (2) users may not be able to provide constraints until they hear more information about the space of options; and (3) the UM-based approach does not give users an overview of the option space, and this may reduce their conﬁdence that they have been told about the best option(s) (Demberg and Moore 2006). Polifroni, Chung, and Seneff (2003) proposed a “summarize and reﬁne” (SR) approach, in which the system structures a large number of options into a small number 194 White, Clark, and Moore Generating Tailored Descriptions with Appropriate Intonation of clusters that share attributes. The system then summarizes the clusters based on their attributes, implicitly prompting the user to provide additional constraints. The system produces summaries such as I have found 983 restaurants. Most of them are located in Boston and Cambridge. There are 32 choices for cuisine. I also have information about"
J10-2001,W04-0601,1,0.792537,"the Xalan XSLT processor to transform the output of the content planner into a sequence of LFs that can be realized by the OpenCCG agent. It is intended to be a relatively straightforward component, as the content planner has been designed to implement the most important high-level generation choices. Its primary responsibility is to lexicalize the basic speech acts in the content plan—which may appear in referring expressions—along with the rhetorical speech acts that connect them together. When alternative lexicalizations are available, all possibilities are included in a packed structure (Foster and White 2004; White 2006a). The sentence planner is also responsible for adding discourse markers such as also and but, adding pronouns, and choosing sentence boundaries. It additionally implements a small number of rhetorical restructuring operations for enhanced ﬂuency. The sentence planner makes use of approximately 50 XSLT templates to recursively transform content plans into logical forms. An example logical form that results from applying these templates to the content plan shown in Figure 7 appears in Figure 8 (with alternative lexicalizations suppressed). As described further in Section 2.6.1, the"
J10-2001,P96-1027,0,0.0744473,"CG open source realizer (White 2004, 2006a, 2006b). A distinguishing feature of OpenCCG is that 11 In future work, these checks could be extended to apply across turns as well. 172 White, Clark, and Moore Generating Tailored Descriptions with Appropriate Intonation it implements a hybrid symbolic-statistical chart realization algorithm that combines (1) a theoretically grounded approach to syntax and semantic composition, with (2) the use of integrated language models for making choices among the options left open by the grammar. In so doing, it brings together the symbolic chart realization (Kay 1996; Shemtov 1997; Carroll et al. 1999; Moore 2002) and statistical realization (Knight and Hatzivassiloglou 1995; Langkilde 2000; Bangalore and Rambow 2000; Langkilde-Geary 2002; Oh and Rudnicky 2002; Ratnaparkhi 2002) traditions. Another recent approach to combining these traditions appears in Carroll and Oepen (2005), where parse selection techniques are incorporated into an HPSG realizer. Like other realizers, the OpenCCG realizer is partially responsible for determining word order and inﬂection. For example, the realizer determines that also should preferably follow the verb in There is also"
J10-2001,P95-1034,0,0.0223846,"G is that 11 In future work, these checks could be extended to apply across turns as well. 172 White, Clark, and Moore Generating Tailored Descriptions with Appropriate Intonation it implements a hybrid symbolic-statistical chart realization algorithm that combines (1) a theoretically grounded approach to syntax and semantic composition, with (2) the use of integrated language models for making choices among the options left open by the grammar. In so doing, it brings together the symbolic chart realization (Kay 1996; Shemtov 1997; Carroll et al. 1999; Moore 2002) and statistical realization (Knight and Hatzivassiloglou 1995; Langkilde 2000; Bangalore and Rambow 2000; Langkilde-Geary 2002; Oh and Rudnicky 2002; Ratnaparkhi 2002) traditions. Another recent approach to combining these traditions appears in Carroll and Oepen (2005), where parse selection techniques are incorporated into an HPSG realizer. Like other realizers, the OpenCCG realizer is partially responsible for determining word order and inﬂection. For example, the realizer determines that also should preferably follow the verb in There is also a very cheap ﬂight on Air France, whereas in other cases it typically precedes the verb, as in I also have a"
J10-2001,E03-1057,0,0.0771914,"Missing"
J10-2001,A00-2023,0,0.0397805,"checks could be extended to apply across turns as well. 172 White, Clark, and Moore Generating Tailored Descriptions with Appropriate Intonation it implements a hybrid symbolic-statistical chart realization algorithm that combines (1) a theoretically grounded approach to syntax and semantic composition, with (2) the use of integrated language models for making choices among the options left open by the grammar. In so doing, it brings together the symbolic chart realization (Kay 1996; Shemtov 1997; Carroll et al. 1999; Moore 2002) and statistical realization (Knight and Hatzivassiloglou 1995; Langkilde 2000; Bangalore and Rambow 2000; Langkilde-Geary 2002; Oh and Rudnicky 2002; Ratnaparkhi 2002) traditions. Another recent approach to combining these traditions appears in Carroll and Oepen (2005), where parse selection techniques are incorporated into an HPSG realizer. Like other realizers, the OpenCCG realizer is partially responsible for determining word order and inﬂection. For example, the realizer determines that also should preferably follow the verb in There is also a very cheap ﬂight on Air France, whereas in other cases it typically precedes the verb, as in I also have a ﬂight that leave"
J10-2001,W02-2103,0,0.0261241,"urns as well. 172 White, Clark, and Moore Generating Tailored Descriptions with Appropriate Intonation it implements a hybrid symbolic-statistical chart realization algorithm that combines (1) a theoretically grounded approach to syntax and semantic composition, with (2) the use of integrated language models for making choices among the options left open by the grammar. In so doing, it brings together the symbolic chart realization (Kay 1996; Shemtov 1997; Carroll et al. 1999; Moore 2002) and statistical realization (Knight and Hatzivassiloglou 1995; Langkilde 2000; Bangalore and Rambow 2000; Langkilde-Geary 2002; Oh and Rudnicky 2002; Ratnaparkhi 2002) traditions. Another recent approach to combining these traditions appears in Carroll and Oepen (2005), where parse selection techniques are incorporated into an HPSG realizer. Like other realizers, the OpenCCG realizer is partially responsible for determining word order and inﬂection. For example, the realizer determines that also should preferably follow the verb in There is also a very cheap ﬂight on Air France, whereas in other cases it typically precedes the verb, as in I also have a ﬂight that leaves London at 3:45 p.m. It also enforces subject–ve"
J10-2001,W02-2106,0,0.0286781,"006b). A distinguishing feature of OpenCCG is that 11 In future work, these checks could be extended to apply across turns as well. 172 White, Clark, and Moore Generating Tailored Descriptions with Appropriate Intonation it implements a hybrid symbolic-statistical chart realization algorithm that combines (1) a theoretically grounded approach to syntax and semantic composition, with (2) the use of integrated language models for making choices among the options left open by the grammar. In so doing, it brings together the symbolic chart realization (Kay 1996; Shemtov 1997; Carroll et al. 1999; Moore 2002) and statistical realization (Knight and Hatzivassiloglou 1995; Langkilde 2000; Bangalore and Rambow 2000; Langkilde-Geary 2002; Oh and Rudnicky 2002; Ratnaparkhi 2002) traditions. Another recent approach to combining these traditions appears in Carroll and Oepen (2005), where parse selection techniques are incorporated into an HPSG realizer. Like other realizers, the OpenCCG realizer is partially responsible for determining word order and inﬂection. For example, the realizer determines that also should preferably follow the verb in There is also a very cheap ﬂight on Air France, whereas in ot"
J10-2001,P06-1140,1,0.892961,"ence of words, pitch accents, and edge tones that maximizes the probability assigned by an n-gram model for the domain. In an approach that is more similar in spirit to ours, Bulyko and Ostendorf (2002) likewise aim to reproduce distinctive intonational patterns in a limited domain. However, unlike our approach, theirs makes use of simple templates for generating paraphrases, as their focus is on how deferring the ﬁnal choice of wording and prosodic realization to their synthesizer enables them to achieve more natural sounding synthetic speech. Following on the work described in this article, Nakatsu and White (2006) present a discriminative approach to realization ranking based on predicted synthesis quality that is directly compatible with the FLIGHTS system. Turning to our synthesis evaluation, we note that debate over the standardization of speech synthesis evaluation continues, with the Blizzard Challenge (Black and Tokuda 2005; Fraser and King 2007) proving to be a useful forum for discussing and performing evaluation across different synthesis platforms. Mayo, Clark, and King (2005) have proposed to evaluate speech synthesis evaluation from a perceptual viewpoint to discover 196 White, Clark, and M"
J10-2001,2001.mtsummit-papers.68,0,0.0187001,"Missing"
J10-2001,2006.amta-papers.25,0,0.0227143,"Missing"
J10-2001,J05-1002,0,0.0608301,"Missing"
J10-2001,W02-2110,0,0.105773,"n. In particular, we require better algorithms for: 1. selecting the most relevant subset of options to mention, as well as the attributes that are most relevant to choosing among them; and 2. determining how to organize and express the descriptions of the selected options and attributes, in ways that are both easy to understand and memorable.1 In this article, we describe how we have addressed these points in the FLIGHTS2 system, reviewing and extending the description given in Moore et al. (2004). FLIGHTS follows previous work (Carberry, Chu-Carroll, and Elzer 1999; Carenini and Moore 2000; Walker et al. 2002) in applying decision-theoretic models of user preferences to the generation of tailored descriptions of the most relevant available options. Multiattribute decision theory provides a detailed account of how models of user preferences can be used in decision making (Edwards and Barron 1994). Such preference models have been shown to enable systems to present information in ways that are concise and 1 An issue we do not address in this article is whether a multimodal system would be more effective than a voice-only one. We believe that these needs, and in particular the need to express informat"
J10-2001,P01-1066,0,0.197174,"Missing"
J10-2001,W06-1403,1,0.804155,"or to transform the output of the content planner into a sequence of LFs that can be realized by the OpenCCG agent. It is intended to be a relatively straightforward component, as the content planner has been designed to implement the most important high-level generation choices. Its primary responsibility is to lexicalize the basic speech acts in the content plan—which may appear in referring expressions—along with the rhetorical speech acts that connect them together. When alternative lexicalizations are available, all possibilities are included in a packed structure (Foster and White 2004; White 2006a). The sentence planner is also responsible for adding discourse markers such as also and but, adding pronouns, and choosing sentence boundaries. It additionally implements a small number of rhetorical restructuring operations for enhanced ﬂuency. The sentence planner makes use of approximately 50 XSLT templates to recursively transform content plans into logical forms. An example logical form that results from applying these templates to the content plan shown in Figure 7 appears in Figure 8 (with alternative lexicalizations suppressed). As described further in Section 2.6.1, the logical for"
J10-2001,N03-2002,0,\N,Missing
J10-2001,P02-1040,0,\N,Missing
J11-3003,E06-1009,1,0.764138,"designed to select attributes that generalize well over the data (i.e., produce large clusters of options), and thus lead to efﬁcient summarization. Hence attributes that partition the data set into a small number of clusters are preferred. If the attribute that is best for summarization is not of interest to a particular user, dialog duration is increased unnecessarily. This in turn may lead to reduced user satisfaction, as the results of our evaluation suggest (see Section 4.1.3). 3. Our Approach: User Model Based Summarize and Reﬁne (UMSR) Our approach, the UMSR approach ﬁrst described in Demberg and Moore (2006), is intended to capture the complementary strengths of the two previous approaches. It exploits information from a user model to reduce dialog duration by selecting only options that are relevant to the user. In addition, we introduce a content structuring algorithm that supports stepwise reﬁnement, as in Polifroni, Chung, and Seneff (2003), 494 Demberg, Winterboer, and Moore A Strategy for Information Presentation in SDSs but in which the structuring reﬂects the user’s preferences. Thus our approach maintains the beneﬁts of user tailoring, while also being capable of dealing with a large num"
J11-3003,W03-2123,0,\N,Missing
J11-3003,W06-1304,0,\N,Missing
J11-3003,H01-1015,0,\N,Missing
J11-3003,P01-1066,0,\N,Missing
J11-3003,W09-3901,1,\N,Missing
J11-3003,P04-1009,0,\N,Missing
J11-3003,P03-1033,0,\N,Missing
J11-3003,P08-1055,0,\N,Missing
J11-3003,P03-2038,0,\N,Missing
J11-3003,J10-2001,1,\N,Missing
J92-4007,J86-3001,0,0.975313,"and Stede 1992). In addition, m a n y descriptive studies of discourse have e m p l o y e d RST (Fox 1987; Linden, Cumming, and Martin 1992; Matthiessen and T h o m p s o n 1988). However, recent w o r k by Moore and Paris (1992) noted that RST cannot be used as the sole means of controlling discourse structure in an interactive dialogue system, because RST representations provide insufficient information to support the generation of appropriate responses to &quot;follow-up questions.&quot; The basic problem is that an RST representation of a discourse does not fully specify the intentional structure (Grosz and Sidner 1986) of that discourse. Intentional structure is crucial for responding effectively to questions that address a previous utterance: without a record of what an utterance was intended to achieve, it is impossible to elaborate or clarify that utterance. 1 Further consideration has led us to conclude that the difficulty observed by Moore and Paris stems from a more fundamental problem with RST analyses. RST presumes that, in general, there will be a single, preferred rhetorical relation holding between consecutive discourse elements. In fact, as has been noted in other w o r k on discourse structure"
J92-4007,P89-1025,1,0.789498,"Missing"
J92-4007,J93-4004,1,\N,Missing
J93-4004,J86-3001,0,0.833781,"(called action summaries) encoded in N O A H - s t y l e plan operators (Sacerdoti 1977) to generate these hypotheses. T h e o r e m - p r o v i n g is then used to determine if a series of p r o p o s e d actions will have the desired effect on the hearer's mental state. The systems that have been built within 653 Computational Linguistics Volume 19, Number 4 this framework to date (Cohen 1978; Appelt 1985) plan short (one- or two-sentence) texts to achieve the speakers' goal(s). In this approach, the intentional structure describing the speaker's purposes and the relationships between them (Grosz and Sidner 1986) is explicitly represented. However, this approach does not represent or use rhetorical knowledge about how speech acts may be combined into larger bodies of coherent text to achieve a speaker's goals. It assumes that appropriate axioms could be added to generate longer texts, and that the text produced will be coherent as a byproduct of the planning process. However, this has not been demonstrated. Moreover, we believe that building a system to produce multisentential texts directly from the logics proposed by proponents of this approach would prove to be computationally infeasible. We see tw"
J93-4004,P84-1076,0,0.0293139,"rease the hearer's ability to perform the action (ENABLEMENT),how much of this information to present, in what order, at what level of detail, etc. Moreover, the theory states that the nucleus and satellite portions of a text may occur in any order, relations may occur any number of times, and a nucleus or satellite may be expanded into a text employing any other relation at any point. In order to use RST, a text generation system must have control strategies that dictate how to find such knowledge in the knowledge base, when and what relations should occur, how many times, and in what order. Mann (1984) suggested that goal pursuit methods used in artificial intelligence could be applied to RST for text generation. Schemata can be viewed as means for achieving the goals stated as their effects, and the constraints on relations as a kind of precondition to using a particular schema. However, much work must be done to formalize the constraints and effects of the RST relations and schemata in order to use RST in a text generation system. One attempt at formalization was made by Hovy (1991), who operationalized a subset of the RST relation definitions for use as plan operators in a text structuri"
J93-4004,J92-4007,1,0.64877,"n a MOTIVATION relation to the nucleus. 8 This is because the knowledge base search originally retrieved this as the information that is most relevant to helping this hearer identify the Phillips screwdriver. 667 Computational Linguistics Volume 19, Number 4 Because of this dichotomy between the two classes of RST relations, we conclude that any approach to discourse structure that relies solely on rhetorical relations or predicates and does not explicitly encode information about intentions is inadequate for handling dialogues. Hovy's (1991) approach suffers from this problem. 9 Moreover, as Moore and Pollack (1992) argue, a straightforward approach to revising such an operationalization of RST by modifying subject matter operators to indicate associated intentions cannot succeed. Such an approach &quot;presumes a one-to-one mapping between the ways in which information can be related and the ways in which intentions combine into a coherent plan to affect a hearer's mental state.&quot; We have just shown examples indicating that no such mapping exists. 5. A Text Planner for Advisory Dialogues In this section we present a text planner that constructs explanations based on the intentions of the speaker at each step"
J93-4004,J88-3006,1,0.828219,"dual parts of the text on the hearer, as well as how the parts relate to one another rhetorically. We present a text planner that records this information and show how the resulting structure is used to respond appropriately to a follow-up question. 1. I n t r o d u c t i o n Explanation systems must p r o d u c e multisentential texts, including justifications of their actions, descriptions of their problem-solving strategies, and definitions of the terms they use. Previous research in natural language generation has s h o w n that schemata of rhetorical predicates (McKeown 1985; McCoy 1989; Paris 1988) or rhetorical relations (Hovy 1991) can be used to capture the structure of coherent multisentential texts. Schemata are scriptlike entities that encode standard patterns of discourse structure. Associating a schema with a communicative goal allows a system to generate a text that achieves the goal. However, we have found that schemata are insufficient as a discourse model for advisory dialogues. Although they encode standard patterns of discourse structure, schemata do not include a representation of the intended effects of the components of a schema, nor h o w these intentions are related t"
J93-4004,W90-0112,0,0.0142145,"hetorical predicates or relations for natural language generation. Third, as illustrated by the two alternative operators for achieving a MOTIVATION subgoal shown in Figures 15 or 16, in our plan language we can represent very general strategies that are applicable across domains, as well as very specific strategies that may be necessary to handle the idiosyncratic language used in a particular domain. While one may argue that the operator in Figure 16 could be replaced by a more general, domain-independent operator, this does not obviate the need for domain-specific communication strategies. Rambow (1990) argues that domain-specific communication knowledge must be used (whether implicitly or explicitly) in all planned communica676 Johanna D. Moore and C6cile L. Paris Planning Text for Advisory Dialogs tion, and advocates that domain communication knowledge be represented explicitly. In our plan language, some types of domain-specific communication strategies can be represented in plan operators. When there are multiple operators capable of achieving a given effect, the constraint mechanism controls which operators are deemed appropriate in a given context. Note, however, that we do not wish to"
J93-4004,E91-1003,0,0.00657889,"Missing"
J96-3006,P94-1006,0,0.0113427,"sis of the two theories would be useful to researchers in both natural language interpretation and generation. 1. Introduction Within the computational discourse community, there is a long-standing debate between proponents of theories based on domain-independent rhetorical relations (most notably Rhetorical Structure Theory, Mann and Thompson 1988, henceforth RST; see also Hobbs 1985) and those who subscribe to theories based on intentionality (most notably that of Grosz and Sidner 1986, henceforth G&S). While some researchers have tried to integrate the two approaches (Moore and Paris 1993; Asher and Lascarides 1994; Hobbs 1993), the two are usually viewed as competing theories. Here we argue that G&S and RST are essentially similar in what they say about how speakers&apos; intentions determine a structure of their discourse. Intentional structure describes the roles that discourse actions play in the speaker&apos;s communicative plan to achieve desired effects on the hearer&apos;s mental state. Intentions encode what the speaker was trying to accomplish with a given portion of discourse. The relations between intentions indicate whether one intention contributes to the satisfaction of another (dominance) or whether on"
J96-3006,J86-3001,0,0.964491,"lations in the discourse and how this structure might be related to the intentional structure is discussed. We suggest the synthesis of the two theories would be useful to researchers in both natural language interpretation and generation. 1. Introduction Within the computational discourse community, there is a long-standing debate between proponents of theories based on domain-independent rhetorical relations (most notably Rhetorical Structure Theory, Mann and Thompson 1988, henceforth RST; see also Hobbs 1985) and those who subscribe to theories based on intentionality (most notably that of Grosz and Sidner 1986, henceforth G&S). While some researchers have tried to integrate the two approaches (Moore and Paris 1993; Asher and Lascarides 1994; Hobbs 1993), the two are usually viewed as competing theories. Here we argue that G&S and RST are essentially similar in what they say about how speakers&apos; intentions determine a structure of their discourse. Intentional structure describes the roles that discourse actions play in the speaker&apos;s communicative plan to achieve desired effects on the hearer&apos;s mental state. Intentions encode what the speaker was trying to accomplish with a given portion of discourse."
J96-3006,J95-3007,0,0.0159608,"esearch and DevelopmentCenter, Universityof Pittsburgh, Pittsburgh, PA 15260. E-mail: jmoore@cs.pitt.edu (~) 1996 Association for Computational Linguistics Computational Linguistics Volume 22, Number 3 Prior research has established that recognition of intentional structure, and therefore appropriate generation of cues to such structure, is crucial for many discourseprocessing tasks. Grosz and Sidner (1986) argued that intentional structure is crucial for anaphora resolution and plan recognition. Hirschberg et al. (1987) show that intentional structure plays a role in intonation. In addition, Moore (1995, in press) shows that intentional structure is crucial for responding effectively to questions that refer to prior discourse and to communication failures. Further research indicates that intentional structure is an important factor in determining when to generate discourse cues (e.g., &quot;because,&quot; &quot;thus,&quot; &quot;although&quot;), which discourse cues to select, and where to place those cues (Moser and Moore 1995, in preparation). In this paper, we compare what G&S and RST say about intentional structure. We use the term Intentional Linguistic Structure, or ILS, as a theory-neutral way of referring to the"
J96-3006,J93-4004,1,0.803208,"We suggest the synthesis of the two theories would be useful to researchers in both natural language interpretation and generation. 1. Introduction Within the computational discourse community, there is a long-standing debate between proponents of theories based on domain-independent rhetorical relations (most notably Rhetorical Structure Theory, Mann and Thompson 1988, henceforth RST; see also Hobbs 1985) and those who subscribe to theories based on intentionality (most notably that of Grosz and Sidner 1986, henceforth G&S). While some researchers have tried to integrate the two approaches (Moore and Paris 1993; Asher and Lascarides 1994; Hobbs 1993), the two are usually viewed as competing theories. Here we argue that G&S and RST are essentially similar in what they say about how speakers&apos; intentions determine a structure of their discourse. Intentional structure describes the roles that discourse actions play in the speaker&apos;s communicative plan to achieve desired effects on the hearer&apos;s mental state. Intentions encode what the speaker was trying to accomplish with a given portion of discourse. The relations between intentions indicate whether one intention contributes to the satisfaction of anothe"
J96-3006,J92-4007,1,0.957932,"rse. Intentional structure describes the roles that discourse actions play in the speaker&apos;s communicative plan to achieve desired effects on the hearer&apos;s mental state. Intentions encode what the speaker was trying to accomplish with a given portion of discourse. The relations between intentions indicate whether one intention contributes to the satisfaction of another (dominance) or whether one intention must be satisfied before another (satisfaction-precedence) (Grosz and Sidner 1986). In contrast, informational structure is concerned with domain relations among the things being talked about. Moore and Pollack (1992) argue that both intentional and informational analyses are needed simultaneously. * Learning Research and DevelopmentCenter, and Department of Linguistics, Universityof Pittsburgh, Pittsburgh, PA 15260. E-mail: moser@isp.pitt.edu t Department of Computer Science,and Learning Research and DevelopmentCenter, Universityof Pittsburgh, Pittsburgh, PA 15260. E-mail: jmoore@cs.pitt.edu (~) 1996 Association for Computational Linguistics Computational Linguistics Volume 22, Number 3 Prior research has established that recognition of intentional structure, and therefore appropriate generation of cues t"
J96-3006,P95-1018,1,0.859238,"nd Sidner (1986) argued that intentional structure is crucial for anaphora resolution and plan recognition. Hirschberg et al. (1987) show that intentional structure plays a role in intonation. In addition, Moore (1995, in press) shows that intentional structure is crucial for responding effectively to questions that refer to prior discourse and to communication failures. Further research indicates that intentional structure is an important factor in determining when to generate discourse cues (e.g., &quot;because,&quot; &quot;thus,&quot; &quot;although&quot;), which discourse cues to select, and where to place those cues (Moser and Moore 1995, in preparation). In this paper, we compare what G&S and RST say about intentional structure. We use the term Intentional Linguistic Structure, or ILS, as a theory-neutral way of referring to the structure of a discourse determined by the speaker&apos;s intentions. The definition of ILS comprises one of the major claims in G&S. ILS is not directly addressed in RST, but is implicit in the RST concept of nuclearity. We argue that the key to reconciling ILS in the two theories lies in the correspondence between the dominance relation between intentions in G&S and the nucleus:satellite relation betwee"
J97-1001,P96-1009,0,0.0207517,"model of dialogue (Power 1979; Houghton and Isard 1985), the interaction of risk-taking dialogue strategies and corresponding repair strategies (Carletta 1992), the relationship between resource bounds, task complexity, and dialogue strategies (Walker 1996; Jordan and Walker 1996), the role of belief revision in tasks in which agents negotiate a problem solution (Logan, Reece, and Sparck-Jones 1994), and the relationship between mixed initiative and knowledge distribution (Guinn 1994). Empirical research in testbeds for human-computer dialogue interfaces is very recent (Hirschman et al. 1990; Allen et al. 1996). This method supports studies of the interaction of various components; for example Danieli and Gerbino (1995) propose an implicit recovery metric for evaluating how the dialogue manager overcomes limitations in the speech recognizer. Other research parameterizes the dialogue manager to select different behaviors in different contexts, such as expert vs. novice discourse strategies (Kamm 1995), different repair strategies (Hirschman and Pao 1993), or different degrees of initiative (Potjer et al. 1996; Smith and Gordon, this volume). These dialogue interfaces also provide an opportunity for t"
J97-1001,P95-1017,0,0.0972862,"sifiers functions as a causal model, which can then be examined and further tested. For example, this method has been used to identify features for predicting accent assignment in text-tospeech (Hirschberg 1993), for repairing disfluencies (Nakatani and Hirschberg 1993), cue vs. noncue uses of discourse cue words (Litman 1996; Siegel and McKeown 1994), discourse segment boundaries (Grosz and Hirschberg 1992; Passonneau and Litman, this volume), intonational phrase boundaries (Wang and Hirschberg 1992), and the Computational Linguistics Volume 23, Number 1 most likely antecedents for anaphors (Aone and Bennet 1995; Connolly, Burger, and Day 1994). Discourse tagging is also instrumental in stage 3 of our empirical method, by producing a test set that can be used for comparison to a program&apos;s output. This method is used by most of the articles in this volume. A common application is testing coreference resolution algorithms; the tags indicate the preferred interpretation of a potentially ambiguous utterance containing anaphoric noun phrases (Walker 1989; Suri and McCoy 1994; Chinchor and Sundheim 1995). Coreference algorithms are then tested on their ability to select the right equivalence class for an a"
J97-1001,E89-1039,0,0.0548772,"Missing"
J97-1001,P92-1002,0,0.0215406,"st set that can be used for comparison to a program&apos;s output. This method is used by most of the articles in this volume. A common application is testing coreference resolution algorithms; the tags indicate the preferred interpretation of a potentially ambiguous utterance containing anaphoric noun phrases (Walker 1989; Suri and McCoy 1994; Chinchor and Sundheim 1995). Coreference algorithms are then tested on their ability to select the right equivalence class for an anaphoric noun phrase. The same method has been applied to empirically testing an algorithm for resolving verb phrase ellipsis (Hardt 1992). In each case, we can generalize on the basis of specific features from studies of specific algorithms operating on specific corpora, whenever the corpora represent a general task for the algorithm. The more varied the test data is, the more generalizable we expect the results to be. For example, the claim that a model is general can be supported by test corpora representing different genres (Fox 1987; Kroch and Hindle 1982), or different language families (Strube and Hahn 1996; Iida 1997; Di Eugenio 1997; Hoffman 1997). Human performance can also be compared to algorithm output through the u"
J97-1001,H93-1004,0,0.0378651,"Missing"
J97-1001,H90-1023,0,0.191522,"nning as an underlying model of dialogue (Power 1979; Houghton and Isard 1985), the interaction of risk-taking dialogue strategies and corresponding repair strategies (Carletta 1992), the relationship between resource bounds, task complexity, and dialogue strategies (Walker 1996; Jordan and Walker 1996), the role of belief revision in tasks in which agents negotiate a problem solution (Logan, Reece, and Sparck-Jones 1994), and the relationship between mixed initiative and knowledge distribution (Guinn 1994). Empirical research in testbeds for human-computer dialogue interfaces is very recent (Hirschman et al. 1990; Allen et al. 1996). This method supports studies of the interaction of various components; for example Danieli and Gerbino (1995) propose an implicit recovery metric for evaluating how the dialogue manager overcomes limitations in the speech recognizer. Other research parameterizes the dialogue manager to select different behaviors in different contexts, such as expert vs. novice discourse strategies (Kamm 1995), different repair strategies (Hirschman and Pao 1993), or different degrees of initiative (Potjer et al. 1996; Smith and Gordon, this volume). These dialogue interfaces also provide"
J97-1001,J94-4002,0,0.02252,"prove the performance of a speech recognizer with tag-specific language models (Taylor et al. 1996), and whether an induced discourse model based on the tagging can predict the next dialogue act in the dialogue, and thus affect how the system translates the next utterance (Reithinger and Maier 1995; Nagata 1992). Tagging is also critical for ablation studies, where algorithm features are selectively turned off, and performance examined. Tagging can characterize the input in terms of features the algorithm uses for producing the target behavior or characterize the target behavior. For example, Lappin and Leass (1994) report an ablation study of an anaphora resolution algorithm, operating on computer manuals, in which various factors that were hypothesized to determine the most likely antecedent were selectively turned off. (See also Dagan et al. [1995]). Sample results include the finding that there is no effect on performance, for this type of text, when an antecedent&apos;s likelihood is increased for parallelism. Another use of discourse tagging is for algorithm induction using automatic classifiers, such as C4.5 or CART, that produce decision trees from data sets described by a set of features (Brieman et"
J97-1001,H91-1061,0,0.0426602,"Missing"
J97-1001,J92-4007,1,0.796955,"out input features that affect the target behavior are found in previous work (stage 1 of the methodology). In this case, the tagging contributes to developing a causal model. The tagged corpus is used to test whether the features predict the target behavior. For example, researchers have devised algorithms for generating the surface form of explanations and instructions from underlying intention-based representations by tagging naturally occurring discourses for surface form features, informational relations, and intentional relations (Vander Linden and Di Eugenio 1996; Moser and Moore 1995; Moore and Pollack 1992; Paris and Scott 1994). Another promising area is speech act (dialogue move) tagging, where, for example, researchers have tested whether an automatic tagger trained on the tagged corpus can improve the performance of a speech recognizer with tag-specific language models (Taylor et al. 1996), and whether an induced discourse model based on the tagging can predict the next dialogue act in the dialogue, and thus affect how the system translates the next utterance (Reithinger and Maier 1995; Nagata 1992). Tagging is also critical for ablation studies, where algorithm features are selectively tur"
J97-1001,J91-1002,0,0.0107243,"planation) or a response (e.g., reply, acknowledgment). The paper discusses issues with determining the reliability and generality of tagging sets, and with refining tag sets on the basis of reliability data (Carletta 1996; Condon and Cech 1995). The Discourse Working Group is also applying this tagging scheme to other dialogue types to evaluate its generality (Hirschman et al. 1996; Luperfoy 1996). 3.2 Hearst The target behavior that Hearst is concerned with is subtopic identification in expository texts. She tests the hypothesis that term repetition is a primary feature of textual cohesion (Morris and Hirst 1991) by using it as the basis for two different algorithms for identifying multiparagraph subtopical units. The algorithms are evaluated by comparing the units they propose against a baseline of randomly generated topic boundaries, and against a corpus tagged by human judges. Precision, recall, and K (Carletta 1996; Krippendorf 1980) are used as evaluation metrics to assess the performance of the two algorithms. In order to generalize, Hearst tests the algorithm&apos;s performance on a new task: that of distinguishing boundaries between sets of concatenated news articles. Hearst&apos;s algorithm performs co"
J97-1001,P95-1018,1,0.844334,"rizable) dialogue models implemented in human-computer dialogue interfaces. H o w are these methods used and how do they contribute to the development of general theories? Discourse tagging classifies discourse units in naturally occurring texts or dialogues into one of a set of categories. Discourse units range from referring expressions and syntactic constructions (Fox 1987; Kroch and Hindle 1982; Prince 1985), to words or phrases (Heeman and Allen 1994; Hirschberg and Litman 1993; Novick and Sutton 1994), to utterances and relationships among them (Dahlback 1991; Reithinger and Maier 1995; Moser and Moore 1995; Nagata 1992; Rose et al. 1995), to multiutterance units identified by a range of criteria such as speaker intention or initiative (Flammia and Zue 1995a; Hirschberg and Nakatani 1996; Whittaker and Stenton 1988). The article by Carletta et al. (this volume) presents a tagging scheme for three levels of discourse structure. Discourse tags categorize either features of the input (independent variables) or features of the output (dependent variables). Often hypotheses about input features that affect the target behavior are found in previous work (stage 1 of the methodology). In this case, the"
J97-1001,P93-1007,0,0.0256028,"trees from data sets described by a set of features (Brieman et al. 1984; Quinlan 1993). This approach uses automatic methods for stages 2 and 3 of our empirical research strategy. Since discourse tagging associates sets of features with discourse phenomena, tagged data is used as input to these automatic classifiers. The decision tree produced by the classifiers functions as a causal model, which can then be examined and further tested. For example, this method has been used to identify features for predicting accent assignment in text-tospeech (Hirschberg 1993), for repairing disfluencies (Nakatani and Hirschberg 1993), cue vs. noncue uses of discourse cue words (Litman 1996; Siegel and McKeown 1994), discourse segment boundaries (Grosz and Hirschberg 1992; Passonneau and Litman, this volume), intonational phrase boundaries (Wang and Hirschberg 1992), and the Computational Linguistics Volume 23, Number 1 most likely antecedents for anaphors (Aone and Bennet 1995; Connolly, Burger, and Day 1994). Discourse tagging is also instrumental in stage 3 of our empirical method, by producing a test set that can be used for comparison to a program&apos;s output. This method is used by most of the articles in this volume. A"
J97-1001,P94-1014,0,0.0614787,"mpirical Studies in Discourse models using computer-computer dialogue simulation; and (9) Testbeds of (parameterizable) dialogue models implemented in human-computer dialogue interfaces. H o w are these methods used and how do they contribute to the development of general theories? Discourse tagging classifies discourse units in naturally occurring texts or dialogues into one of a set of categories. Discourse units range from referring expressions and syntactic constructions (Fox 1987; Kroch and Hindle 1982; Prince 1985), to words or phrases (Heeman and Allen 1994; Hirschberg and Litman 1993; Novick and Sutton 1994), to utterances and relationships among them (Dahlback 1991; Reithinger and Maier 1995; Moser and Moore 1995; Nagata 1992; Rose et al. 1995), to multiutterance units identified by a range of criteria such as speaker intention or initiative (Flammia and Zue 1995a; Hirschberg and Nakatani 1996; Whittaker and Stenton 1988). The article by Carletta et al. (this volume) presents a tagging scheme for three levels of discourse structure. Discourse tags categorize either features of the input (independent variables) or features of the output (dependent variables). Often hypotheses about input features"
J97-1001,P89-1016,0,0.0280877,"dialogue systems. Because testing dialogue systems requires a fully implemented natural language system, there are two empirical methods for testing hypotheses about discourse models that are independent of the current state of the art in speech or language processing. The first method is Wizard-of-Oz simulation, and the second is computational testbeds for dialogue simulation. In the Wizard-of-Oz (WOZ) approach, a human wizard simulates the behavior of a program interacting with a human to carry out a particular task in a particular domain (Dahlb~ick and Jonsson 1989; Hirschman et al. 1993; Oviatt and Cohen 1989; Whittaker and Stenton 1989). The WOZ method can, in principle, be used to test, refine, or generalize any behavior implementable in a program and thus is appropriate at several stages of our methodology. For example, the wizard may follow a proto4 Walker and Moore Empirical Studies in Discourse col that includes particular system limitations or error-handling strategies, to explore potential problems before implementation, e.g. determining how the program&apos;s level of interactivity affects the complexity of the instructions it is given (Oviatt and Cohen 1989). In addition, WOZ is often used to"
J97-1001,P95-1005,0,0.06507,"Missing"
J97-1001,C96-1059,0,0.0244856,"Missing"
J97-1001,P89-1031,1,0.803546,"tional phrase boundaries (Wang and Hirschberg 1992), and the Computational Linguistics Volume 23, Number 1 most likely antecedents for anaphors (Aone and Bennet 1995; Connolly, Burger, and Day 1994). Discourse tagging is also instrumental in stage 3 of our empirical method, by producing a test set that can be used for comparison to a program&apos;s output. This method is used by most of the articles in this volume. A common application is testing coreference resolution algorithms; the tags indicate the preferred interpretation of a potentially ambiguous utterance containing anaphoric noun phrases (Walker 1989; Suri and McCoy 1994; Chinchor and Sundheim 1995). Coreference algorithms are then tested on their ability to select the right equivalence class for an anaphoric noun phrase. The same method has been applied to empirically testing an algorithm for resolving verb phrase ellipsis (Hardt 1992). In each case, we can generalize on the basis of specific features from studies of specific algorithms operating on specific corpora, whenever the corpora represent a general task for the algorithm. The more varied the test data is, the more generalizable we expect the results to be. For example, the claim"
J97-1001,P90-1010,1,0.782305,"but volunteers relevant facts. Dialogue structure is tagged via a model that segments circuit repair dialogues into five phases: introduction, assessment, diagnosis, repair and test. Then Smith and Gordon examine how the subdialogue length varies depending on initiative mode. Their results exemplify the empirical generalization strategy by showing that a subdialogue model based on WOZ simulations can be generalized to human-computer dialogues. They also show that claims about the effect of initiative on dialogue structure in human-human dialogues in other domains (Whittaker and Stenton 1988; Walker and Whittaker 1990) generalize to human-computer dialogues in the circuit repair domain. Further generalizations could result from determining whether the subdialogue model can be used in other types of human-human or human-computer problemsolving dialogues. 3.6 Yeh and Mellish The target behavior that Yeh and Mellish model is the generation of anaphoric noun phrases in Chinese texts. The algorithm must select from among zero pronouns, overt pronouns, and full noun phrases; in addition, for full noun phrases, appropriate content must be determined. Their training set is a corpus of Chinese texts tagged for anaph"
J97-1001,P96-1036,0,0.0128781,"aphoric noun phrase. The same method has been applied to empirically testing an algorithm for resolving verb phrase ellipsis (Hardt 1992). In each case, we can generalize on the basis of specific features from studies of specific algorithms operating on specific corpora, whenever the corpora represent a general task for the algorithm. The more varied the test data is, the more generalizable we expect the results to be. For example, the claim that a model is general can be supported by test corpora representing different genres (Fox 1987; Kroch and Hindle 1982), or different language families (Strube and Hahn 1996; Iida 1997; Di Eugenio 1997; Hoffman 1997). Human performance can also be compared to algorithm output through the use of reaction time or comprehension or production experiments (Brennan 1995; Gordon, Grosz, and Gilliom 1993; Hudson-D&apos;Zmura 1988). These methods allow researchers fine-grained control of the phenomena studied, and avoid problems with sparse data that can arise with corpus analyses. Reaction time studies also provide researchers with an indirect measure of how humans process a particular phenomenon; processing times can then be compared with the predictions of a model. The meth"
J97-1001,P88-1015,0,0.0985833,"urse units in naturally occurring texts or dialogues into one of a set of categories. Discourse units range from referring expressions and syntactic constructions (Fox 1987; Kroch and Hindle 1982; Prince 1985), to words or phrases (Heeman and Allen 1994; Hirschberg and Litman 1993; Novick and Sutton 1994), to utterances and relationships among them (Dahlback 1991; Reithinger and Maier 1995; Moser and Moore 1995; Nagata 1992; Rose et al. 1995), to multiutterance units identified by a range of criteria such as speaker intention or initiative (Flammia and Zue 1995a; Hirschberg and Nakatani 1996; Whittaker and Stenton 1988). The article by Carletta et al. (this volume) presents a tagging scheme for three levels of discourse structure. Discourse tags categorize either features of the input (independent variables) or features of the output (dependent variables). Often hypotheses about input features that affect the target behavior are found in previous work (stage 1 of the methodology). In this case, the tagging contributes to developing a causal model. The tagged corpus is used to test whether the features predict the target behavior. For example, researchers have devised algorithms for generating the surface for"
J97-1001,E89-1016,0,0.0146249,"use testing dialogue systems requires a fully implemented natural language system, there are two empirical methods for testing hypotheses about discourse models that are independent of the current state of the art in speech or language processing. The first method is Wizard-of-Oz simulation, and the second is computational testbeds for dialogue simulation. In the Wizard-of-Oz (WOZ) approach, a human wizard simulates the behavior of a program interacting with a human to carry out a particular task in a particular domain (Dahlb~ick and Jonsson 1989; Hirschman et al. 1993; Oviatt and Cohen 1989; Whittaker and Stenton 1989). The WOZ method can, in principle, be used to test, refine, or generalize any behavior implementable in a program and thus is appropriate at several stages of our methodology. For example, the wizard may follow a proto4 Walker and Moore Empirical Studies in Discourse col that includes particular system limitations or error-handling strategies, to explore potential problems before implementation, e.g. determining how the program&apos;s level of interactivity affects the complexity of the instructions it is given (Oviatt and Cohen 1989). In addition, WOZ is often used to collect sample dialogues tha"
J97-1001,J93-3003,0,\N,Missing
J97-1001,E95-1034,0,\N,Missing
J97-1001,H91-1062,0,\N,Missing
J97-1001,C90-2047,0,\N,Missing
J97-1001,P95-1016,0,\N,Missing
J97-1001,P94-1041,0,\N,Missing
J97-1001,J94-2006,0,\N,Missing
J97-1001,P96-1038,0,\N,Missing
J97-1001,J93-3001,0,\N,Missing
J98-3004,P84-1065,0,0.17828,"Missing"
J98-3004,W96-0406,0,0.0800088,"l estate sales data), lacking any obvious graphical depiction. Second, although our long term goal is to generate coordinated multimedia explanations using informational graphics and natural language, our focus in this paper was on generating effective natural language explanations about the graphical presentations. In order to do this, the system had to explicitly reason about the perceptual complexity of the presentation. Generating such captions is an important component of constructing multimedia explanations involving integrative graphical displays. The POSTGRAPttE system (Fasciano 1996; Fasciano and Lapalme 1996) is the closest related research effort. As in our work, PoSTGRAPI-IE generates statistical graphics and accompanying captions. However, the issues considered in our work differ from those in POSTGRAPI-IE in several ways and both the text and the graphics generated by PosTGRAPHE emphasize aspects orthogonal to the ones considered in our project. For instance, PoSTGRAPI-IE can take as input a list of aspects that should be conveyed by the presentation. (These goals are represented in the system as a predefined set of templates, such as, ""show the evolution of &lt;attribute-name-I} with respect to"
J98-3004,J95-2003,0,0.0573025,"Missing"
J98-3004,W96-0403,0,0.0172925,"the events suggests that one discuss the asking 10 This is conventionalfor languagesthat are written from left to right, and may be differentin other languages that are written from right to left. 453 Computational Linguistics Volume 24, Number 3 price of a house before the selling price, this would lead to mentioning the right edge before the left edge, contrary to the default ordering. 5.3 Aggregation Module Once the speech acts are ordered, they are passed to the aggregation module. In the general case, aggregation in natural language is a very difficult problem (Dalianis 1996; Shaw 1995; Huang and Fiedler 1996). Fortunately, our generation task requires a type of aggregation that is relatively straightforward. Our aggregation strategy only conjoins pairs of contiguous propositions about the same grapheme type in the same space. The module checks for grapheme types rather than specific graphemes to cover circumstances where, for instance, a chart may have a number of grey and black bars (which are different graphemes of the same type). This enables the system to generate text of the form ""The grey bars indicate the selling price of the house, whereas the black bars indicate the asking price."" When tw"
J98-3004,A92-1007,0,0.093667,"ark blue lines on the left). The number of troops was 400,000 in the earliest segments, 100,000 in the later segments, and 10,000 in the last segments. The city and date of each battle is shown by the labels of a yellow diamond, which shows the battle&apos;s location. This caption can help users understand the various attributes and the underlying relations between them--conveyed so succinctly by the graphic. Although several projects have focused on the question of how such intelligent graphical presentations can be automatically generated (e.g., Casner 1991; Mackinlay 1986; Roth and Hefley 1993; Kerpedjiev 1992), they have not addressed the problem of generating the accompanying textual explanations. Without this ability, automatic graphical presentation systems will necessarily be limited to generating conventionalized graphics that do not use novel means to express complex relationships among data attributes, or risk generating displays that users will find difficult to fully comprehend and utilize. In designing our framework for generating natural language captions we have adapted and integrated work in natural language generation (NLG) by a number of researchers--including ourselves--in different"
J98-3004,P90-1013,0,0.31129,"t shows the neighborhood (1) (2) (3) The system would need to realize that position was the only attribute of the mark being used for a mapping, and position is always clear in a graph and need not explicitly be mentioned; thus resulting in statement (2). However, since the mark is the only grapheme used in the graph, the system could leave off mentioning the mark as well, thus resulting in statement (3). There are two ways of dealing with this issue: (i) The system could apply iterative refinements of the referring expressions generated by the planner, as done in the local brevity algorithm (Reiter 1990). However, this single case would have substantially increased the computational cost of generating referring expressions in all cases, without significantly improving any of the other (perfectly appropriate) referring expressions generated by the module. (ii) The system could recognize this specific situation at a higher level and process the speech acts appropriately to avoid this situation completely. Thus, rather than considering this situation as a problem of generating an appropriate expression for the concept position of the mark in the third chart, we have chosen to push this problem u"
J98-3004,P95-1053,0,0.0231098,"ing between the events suggests that one discuss the asking 10 This is conventionalfor languagesthat are written from left to right, and may be differentin other languages that are written from right to left. 453 Computational Linguistics Volume 24, Number 3 price of a house before the selling price, this would lead to mentioning the right edge before the left edge, contrary to the default ordering. 5.3 Aggregation Module Once the speech acts are ordered, they are passed to the aggregation module. In the general case, aggregation in natural language is a very difficult problem (Dalianis 1996; Shaw 1995; Huang and Fiedler 1996). Fortunately, our generation task requires a type of aggregation that is relatively straightforward. Our aggregation strategy only conjoins pairs of contiguous propositions about the same grapheme type in the same space. The module checks for grapheme types rather than specific graphemes to cover circumstances where, for instance, a chart may have a number of grey and black bars (which are different graphemes of the same type). This enables the system to generate text of the form ""The grey bars indicate the selling price of the house, whereas the black bars indicate t"
J98-3004,W94-0302,1,0.906609,"ing referring expressions, example generation, and linearization. Given the applied nature of our work, in selecting specific NLG techniques we followed a parsimonious approach. For each subtask we selected the simplest technique that was capable, in conjunction with the behavior of the other subtasks, of producing coherent text that could express the propositions we needed to convey. The generation process starts with content selection. For this process, we use LONCBOW, a domain-independent discourse planner originally developed as part of a project aimed at generating tutorial explanations (Young and Moore 1994). Using plan operators that encode discourse strategies devised for the task of generating captions, the planner determines what information should be included in the captions (and consequently what should be left out), and how to organize the selected information. Operator constraints analyze the structure of the graphic presentation and the perceptual complexity of the graphical display to enable the planner to select and apply appropriate strategies. The output of the text planning stage is then further processed by a microplanner, a sequence of modules implementing inter- and Figurative ma"
J98-3004,J94-2003,0,\N,Missing
J98-3004,C94-1086,0,\N,Missing
N06-1047,W05-0905,1,0.46767,"ity, and listener feedback. This speech features approach is contrasted with a second summarization approach using only textual features—a centroid method [3] using a latent semantic representation of utterances. These individual approaches are compared to a combined approach as well as random baseline summaries. This paper also introduces a new evaluation scheme for automatic summaries of meeting recordings, using a weighted precision score based on multiple human annotations of each meeting transcript. This evaluation scheme is described in detail below and is motivated by previous findings [4] suggesting that n-gram based metrics like ROUGE [5] do not correlate well in this domain. 2. Previous Work In the field of speech summarization in general, research investigating speech-specific characteristics has focused largely on prosodic features such as F0 mean and standard deviation, pause information, syllable duration and energy. Koumpis and Renals [1] investigated prosodic features for summarizing voicemail messages in order to send voicemail summaries to mobile devices. Hori et al. [6] have developed an integrated speech summarization approach, based on finite state transducers, in"
N06-1047,N03-1020,0,0.189477,"roach is contrasted with a second summarization approach using only textual features—a centroid method [3] using a latent semantic representation of utterances. These individual approaches are compared to a combined approach as well as random baseline summaries. This paper also introduces a new evaluation scheme for automatic summaries of meeting recordings, using a weighted precision score based on multiple human annotations of each meeting transcript. This evaluation scheme is described in detail below and is motivated by previous findings [4] suggesting that n-gram based metrics like ROUGE [5] do not correlate well in this domain. 2. Previous Work In the field of speech summarization in general, research investigating speech-specific characteristics has focused largely on prosodic features such as F0 mean and standard deviation, pause information, syllable duration and energy. Koumpis and Renals [1] investigated prosodic features for summarizing voicemail messages in order to send voicemail summaries to mobile devices. Hori et al. [6] have developed an integrated speech summarization approach, based on finite state transducers, in which the recognition and summarization components"
N06-1047,J02-4003,0,0.0561096,"t al. [8] explored using only prosodic features for summarization. Maskey and Hirschberg similarly found that prosodic features alone resulted in good quality summaries of 367 Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 367–374, c New York, June 2006. 2006 Association for Computational Linguistics Broadcast News. In the meetings domain (using the ICSI corpus), Murray et al. [2] compared text summarization approaches with feature-based approaches using prosodic features, with human judges favoring the feature-based approaches. Zechner [9] investigated summarizing several genres of speech, including spontaneous meeting speech. Though relevance detection in his work relied largely on tf.idf scores, Zechner also explored cross-speaker information linking and question/answer detection, so that utterances could be extracted not only according to high tf.idf scores, but also if they were linked to other informative utterances. Similarly, this work aims to detect important utterances that may not be detectable according to lexical features or prosodic prominence, but are nonetheless linked to high speaker activity, decision-making, o"
N06-1047,W04-2319,0,0.0114112,"00 word limit for each heading, and told that there must be text for the general abstract, but that the other headings may have null annotations for some meetings. Annotators who were new to the data were encouraged to listen to a meeting straight through before beginning to author the summary. Immediately after authoring a textual summary, annotators were asked to create an extractive summary, using a different GUI. This GUI showed both their textual summary and the orthographic transcription, without topic segmentation but with one line per dialogue act based on the pre-existing MRDA coding [14]. Annotators were told to extract dialogue acts that together would convey the information in the textual summary, and could be used to support the correctness of that summary. They were given no specific instructions about the number or percentage of acts to extract or about redundant dialogue acts. For each dialogue act extracted, they were then required in a second pass to choose the sentences from the textual summary supported by the dialogue act, creating a manyto-many mapping between the recording and the textual summary. Although the expectation was 370 that each extracted dialogue act"
N06-1047,N04-1019,0,0.0888865,"Missing"
N06-2031,P05-1022,0,0.00889376,"stical analysis in this paper aims to make headway towards such a model. Recently, priming phenomena1 have been exploited to aid automated processing, for instance in automatic speech recognition using cache models, but only recently have attempts been made at using 1 The term priming refers to a process that influences linguistic decision-making. An instance of priming occurs when a syntactic structure or lexical item giving evidence of a linguistic choice (prime) influences the recipient to make the same decision, i.e. re-use the structure, at a later choice-point (target). them in parsing (Charniak and Johnson, 2005). In natural language generation, repetition can be used to increase the alignment of human and computers. A surface-level approach is possible by biasing the n-gram language model used to select the output string from a variety of possible utterances (Brockmann et al., 2005). Priming effects are common and well known. For instance, speakers access lexical items more quickly after a semantically or phonologically similar prime. Recent work demonstrates large effects for particular synonymous alternations (e.g., active vs. passive voice) using traditional laboratory experiments with human subje"
N06-2031,H94-1020,0,0.0199256,"in task-oriented dialogue. A recent psychological perspective models Interactive Alignment between speakers (Pickering and Garrod, 2004), where mutual understanding about task and situation depends on lower-level priming effects. Under the model, we expect priming effects to be stronger when a task requires highlevel alignment of situation models. 2 Method 2.1 Dialogue types We examined two corpora. Switchboard contains 80,000 utterances of spontaneous spoken conversations over the telephone among randomly paired, North American speakers, syntactically annotated with phrase-structure grammar (Marcus et al., 1994). The HCRC Map Task corpus comprises more than 110 dialogues with a total of 20, 400 utterances (Anderson et al., 1991). Like Switchboard, HCRC Map Task is a corpus of spoken, two-person dialogue in English. However, Map Task contains task-oriented dialogue: interlocutors work together to achieve a task as quickly and efficiently as possible. Subjects were asked to give each other directions with the help of a map. The interlocutors are in the same room, but have separate, slightly different maps and are unable to see each other’s maps. 2.2 Syntactic repetitions Both corpora are annotated with"
N06-2044,N01-1028,0,0.0184465,"ystem response. Recent research has focused on generating dialogue strategies automatically. This work is based on modelling dialogue as a markov decision process, formalised by a finite state space S, a finite action Progress has been made with this approach but some important challenges remain. For instance, very little success has been achieved with the large state spaces that are typical of real-life systems. Similarly, work on summarising learned strategies for interpretation by human developers has so far only been applied to tasks where each state-action pair is explicitly represented (Lecœuche, 2001). This tabular representation severely limits the size of the state space. We propose an alternative approach to finding optimal dialogue policies. We make use of XCS, an evolutionary reinforcement learning algorithm that seeks to represent a policy as a compact set of stateaction rules (Wilson, 1995). We suggest that this algorithm could overcome both the challenge of large state spaces and the desire for strategy inspectability. In this paper, we focus on the issue of inspectability. We present a series of experiments that illustrate how XCS can be used to evolve dialogue strategies that are"
N07-1004,P05-1054,0,0.0307456,"of the Trend-Watching segments are DM Segments. Functional segments, such as Chitchat, Opening and Closing, almost never include decisions. 4.2 Features Used To provide a qualitative account of the effect of different feature types on the task of automatic decision detection, we have conducted empirical analysis on four major types of features: lexical, prosodic, contextual and topical features. 4.2.1 Lexical Features Previous research has studied lexical differences (i.e., occurrence counts of N-grams) between various aspects of speech, such as topics (Hsueh and Moore, 2006), speaker gender (Boulis and Ostendorf, 2005), and story-telling conversation (Gordon and Ganesan, 2005). As we expect that lexical differences also exist in DM conversations, we generated language models from the DM Dialogue Acts in the corpus. The comparison of the language models generated from the DM dialogue Acts and the rest of the conversations shows that some differences exist between the two models: (1) decision making conversations are more likely to contain we than I and You; (2) in decision-making conversations there are more explicit mentions of topical words, such as advanced chips and functional design; (3) in decisionType"
N07-1004,P04-1085,0,0.0633583,"omatically extracting these argument models is a challenging task. However, researchers have begun to make progress towards this goal. For example, Gatica et al. (2005) and Wrede and Shriberg (2003) automatically identify the level of emotion in meeting spurts (e.g., group level of interest, hot spots). Other researchers have developed models for detecting agreement and disagreement in meetings, using models that combine lexical features with prosodic features (e.g., pause, duration, F0, speech rate) (Hillard et al., 2003) and structural information (e.g., the previous and following speaker) (Galley et al., 2004). More recently, Purver et al. (2006) have tackled the problem of detecting one type of decision, namely action items, which embody the transfer of group responsibility. However, no prior work has addressed the problem of automatically identifying decision-making units more generally in multiparty meetings. Moreover, no previous research has provided a quantitative account of the effects of different feature types on the task of automatic decision detection. 26 3 Research Goal Our aim is to develop models for automatically detecting segments of conversation that contain decisions directly from"
N07-1004,garofolo-etal-2004-nist,0,0.0320341,"ll decisions are recorded in meeting minutes or annotated in the speech recordings, it Spontaneous face-to-face dialogues in meetings violate many assumptions made by techniques previously developed for broadcast news (e.g., TDT and TRECVID), telephone conversations (e.g., Switchboard), and human-computer dialogues (e.g., DARPA Communicator). In order to develop techniques for understanding multiparty dialogues, smart meeting rooms have been built at several institutes to record large corpora of meetings in natural contexts, including CMU (Waibel et al., 2001), LDC (Cieri et al., 2002), NIST (Garofolo et al., 2004), ICSI (Janin et al., 2003), and in the context of the IM2/M4 project (Marchand-Mailet, 2003). More recently, scenario-based meetings, in which partic25 Proceedings of NAACL HLT 2007, pages 25–32, c Rochester, NY, April 2007. 2007 Association for Computational Linguistics ipants are assigned to different roles and given specific tasks, have been recorded in the context of the CALO project (the Y2 Scenario Data) (CALO, 2003) and the AMI project (Carletta et al., 2005). The availability of meeting corpora has enabled researchers to begin to develop descriptive models of meeting discussions. Some"
N07-1004,W06-3405,0,0.103125,"models is a challenging task. However, researchers have begun to make progress towards this goal. For example, Gatica et al. (2005) and Wrede and Shriberg (2003) automatically identify the level of emotion in meeting spurts (e.g., group level of interest, hot spots). Other researchers have developed models for detecting agreement and disagreement in meetings, using models that combine lexical features with prosodic features (e.g., pause, duration, F0, speech rate) (Hillard et al., 2003) and structural information (e.g., the previous and following speaker) (Galley et al., 2004). More recently, Purver et al. (2006) have tackled the problem of detecting one type of decision, namely action items, which embody the transfer of group responsibility. However, no prior work has addressed the problem of automatically identifying decision-making units more generally in multiparty meetings. Moreover, no previous research has provided a quantitative account of the effects of different feature types on the task of automatic decision detection. 26 3 Research Goal Our aim is to develop models for automatically detecting segments of conversation that contain decisions directly from the audio recordings and transcripts"
N07-4005,W06-1643,0,\N,Missing
N07-4005,P03-1071,0,\N,Missing
N07-4005,E06-1035,1,\N,Missing
P00-1020,W00-1407,1,0.654664,"sually for the sake of brevity. According to argumentation theory, the selection of what evidence to mention in an argument should be based on a measure of the evidence strength of support (or opposition) to the main claim of the argument (Mayberry and Golden 1996). Furthermore, argumentation theory suggests that for evaluative arguments the measure of evidence strength should be based on a model of the intended reader’s values and preferences. Following argumentation theory, we have designed an argumentative strategy for generating evaluative arguments that are properly arranged and concise (Carenini and Moore 2000). In our strategy, we assume that the reader’s values and preferences are represented as an additive multiattribute value function (AMVF), a conceptualization based on multiattribute utility theory (MAUT)(Clemen 1996). This allows us to adopt and extend a measure of evidence strength proposed in previous work on explaining decision theoretic advice based on an AMVF (Klein1994). Figure 1 Sample additive multiattribute value function (AMVF) The argumentation strategy has been implemented as part of a complete argument generator. Other modules of the generator include a microplanner, which perfor"
P00-1020,J97-1004,0,\N,Missing
P00-1020,J98-3001,0,\N,Missing
P05-1030,P01-1031,0,0.012834,"onf extent: yes (d) The first of May? mood: decl completeness: partial rel-antecedent: reformul source: np-ref severity: cont-conf extent: yes (d) Monday the first or Monday the eighth? mood: alt-q completeness: partial rel-antecedent: addition source: np-ref severity: cont-repet extent: yes In R&S’s classification scheme, ambiguities about CRs having different sources cannot be resolved entirely as example (2.a) shows. However, in contrast to PGH, the overall approach is a different one: instead of explaining causes of CRs within a theoretic-semantic model (as the three different readings of Ginzburg and Cooper (2001) do), they infer the interpretation of the CR from the context. Ambiguities get resolved by the reply of the addressee and the satisfaction of the CR initiator indicates the “mutually agreed interpretation” . R&S’s multi-dimensional CR description allows the fine-grained distinctions needed to generate natural CRs to be made. For example, PGH’s general category of RFs can be made more specific via the values for the feature relation to antecedent. In addition, the form feature is not restricted to syntax; it includes features such as intonation and coherence, which are useful for generating th"
P05-1030,W04-2325,0,0.712003,"Four levels of grounding Introduction Clarification requests in conversation ensure and maintain mutual understanding and thus play a significant role in robust and efficient dialogue interaction. From a theoretical perspective, the model of grounding explains how mutual understanding is established. According to Clark (1996), speakers and listeners ground mutual understanding on four levels of coordination in an action ladder, as shown in Table 1. Several current research dialogue systems can detect errors on different levels of grounding (Paek and Horvitz, 2000; Larsson, 2002; Purver, 2004; Schlangen, 2004). However, only the work of Purver (2004) addresses the question of how the source of the error affects the form the CR takes. In this paper, we investigate the use of formfunction mappings derived from human-human dialogues to inform the generation of CRs. We identify the factors that determine which function a CR should take and identify function-form correlations that can be used to guide the automatic generation of CRs. In Section 2, we discuss the classification schemes used in two recent corpus studies of CRs in human-human dialogue, and assess their applicability to the problem of gener"
P05-1030,W01-1616,0,\N,Missing
P06-1108,W04-3217,1,0.876125,". The Story Rewriting Task A task used in schools is the story rewriting task, where a story, the exemplar story, is read to the students, and afterwards the story is rewritten by each student, providing a corpus of rewritten stories. This task tests the students ability to both listen and write, while removing from the student the cognitive load needed to generate a new plot. This task is reminiscent of the well-known “War of the Ghosts” experiment used in psychology for studying memory (Bartlett, 1932) and related to work in fields such as summarization (Lemaire et al., 2005) and narration (Halpin et al., 2004). 1.2 Agent Design The goal of the agent is to classify each of the rewritten stories for overall plot quality. This rating can be used to give “coarse-grained” general advice. The agent should then provide “finegrained” specific advice to the student on how their plot could be improved. The agent should be able to detect if the story should be re-read or a human teacher summoned to help the student. To accomplish this task, we extract events that represent the entities and their actions in the plot from both the exemplar and the rewritten stories. A plot comparison algorithm checks for the pr"
P06-1108,W06-1807,1,0.815892,"Missing"
P06-1108,C04-1180,0,0.0300972,"Missing"
P06-1108,W03-0907,0,0.0311963,"Missing"
P06-1108,N04-1019,0,0.078598,"Missing"
P06-1108,grover-etal-2000-lt,0,0.0412977,"Missing"
P07-1102,C00-1027,0,0.161861,"Missing"
P07-1102,H05-1104,0,0.0660532,"Missing"
P07-1102,W06-1637,1,0.645653,"quently, subjects were allowed to freely complete a sentence such as the following one, describing a picture they were shown: 2. The patient showed ... Subjects were more likely to complete (2) with a double-object construction when primed with (1b), and with a prepositional object construction when primed with (1a). In a previous corpus-study, using transcriptions of spontaneous, task-oriented and non-task-oriented dialogue, utterances were annotated with syntactic trees, which we then used to determine the phrasestructure rules that licensed production (and comprehension) of the utterances (Reitter et al., 2006b). For each rule, the time of its occurrence was noted, e.g. we noted 3. 117.9s NP → AT AP NN a fenced meadow 4. 125.5s NP → AT AP NN the abandoned cottage In this study, we then found that the re-occurrence of a rule (as in 4) was correlated with the temporal distance to the first occurrence (3), e.g., 7.6 seconds. The shorter the distance between prime (3) and target (4), the more likely were rules to re-occur. 809 In a conversation, priming may lead a speaker to choose a verb over a synonym because their interlocutor has used it a few seconds before. This, in turn, will increase the likeli"
P07-1102,A00-2028,0,0.0115291,"Missing"
P07-1128,P03-1071,0,0.606149,"vious work, the problem of automatic dialogue segmentation is often considered as similar to the problem of topic segmentation. Therefore, research has adopted techniques previously developed Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 1016–1023, c Prague, Czech Republic, June 2007. 2007 Association for Computational Linguistics to segment topics in text (Kozima, 1993; Hearst, 1997; Reynar, 1998) and in read speech (e.g., broadcast news) (Ponte and Croft, 1997; Allan et al., 1998). For example, lexical cohesion-based algorithms, such as LCSEG (Galley et al., 2003), or its word frequency-based predecessor TextTile (Hearst, 1997) capture topic shifts by modeling the similarity of word repetition in adjacent windows. However, recent work has shown that LCSEG is less successful in identifying “agenda-based conversation segments” (e.g., presentation, group discussion) that are typically signalled by differences in group activity (Hsueh and Moore, 2006). This is not surprising since LCSEG considers only lexical cohesion. Previous work has shown that training a segmentation model with features that are extracted from knowledge sources other than words, such a"
P07-1128,P93-1020,0,0.373893,"xtracted from knowledge sources other than words, such as speaker interaction (e.g., overlap rate, pause, and speaker change) (Galley et al., 2003), or participant behaviors, e.g., note taking cues (Banerjee and Rudnicky, 2006), can outperform LCSEG on similar tasks. In many other fields of research, a variety of features have been identified as indicative of segment boundaries in different types of recorded speech. For example, Brown et al. (1980) have shown that a discourse segment often starts with relatively high pitched sounds and ends with sounds of pitch within a more compressed range. Passonneau and Litman (1993) identified that topic shifts often occur after a pause of relatively long duration. Other prosodic cues (e.g., pitch contour, energy) have been studied for their correlation with story segments in read speech (Tur et al., 2001; Levow, 2004; Christensen et al., 2005) and with theory-based discourse segments in spontaneous speech (e.g., directiongiven monologue) (Hirschberg and Nakatani, 1996). In addition, head and hand/forearm movements are used to detect group-action based segments (McCowan et al., 2005; Al-Hames et al., 2005). However, many other features that we expect to signal segment bo"
P07-1128,J86-3001,0,0.540114,"ohanna D. Moore School of Informatics University of Edinburgh Edinburgh, UK EH8 9WL J.Moore@ed.ac.uk reasons: First, empirical analysis has shown that annotating transcripts with semantic information (e.g., topics) enables users to browse and find information from multimedia archives more efficiently (Banerjee et al., 2005). Second, because the automatically generated segments make up for the lack of explicit orthographic cues (e.g., story and paragraph breaks) in conversational speech, dialogue segmentation is useful in many spoken language understanding tasks, including anaphora resolution (Grosz and Sidner, 1986), information retrieval (e.g., as input for the TREC Spoken Document Retrieval (SDR) task), and summarization (Zechner and Waibel, 2000). This study therefore aims to explore whether a Maximum Entropy (MaxEnt) classifier can integrate multiple knowledge sources for segmenting recorded speech. In this paper, we first evaluate the effectiveness of features that have been proposed in previous work, with a focus on features that can be extracted automatically. Second, we examine other knowledge sources that have not been studied systematically in previous work, but which we expect to be good predi"
P07-1128,J01-1002,0,0.0256923,"form LCSEG on similar tasks. In many other fields of research, a variety of features have been identified as indicative of segment boundaries in different types of recorded speech. For example, Brown et al. (1980) have shown that a discourse segment often starts with relatively high pitched sounds and ends with sounds of pitch within a more compressed range. Passonneau and Litman (1993) identified that topic shifts often occur after a pause of relatively long duration. Other prosodic cues (e.g., pitch contour, energy) have been studied for their correlation with story segments in read speech (Tur et al., 2001; Levow, 2004; Christensen et al., 2005) and with theory-based discourse segments in spontaneous speech (e.g., directiongiven monologue) (Hirschberg and Nakatani, 1996). In addition, head and hand/forearm movements are used to detect group-action based segments (McCowan et al., 2005; Al-Hames et al., 2005). However, many other features that we expect to signal segment boundaries have not been studied systematically. For instance, speaker intention (i.e., dialogue act types) and conversational context (e.g., speaker role). In addition, although these features are expected to be complementary to"
P07-1128,2005.sigdial-1.13,0,0.329705,"Missing"
P07-1128,C00-2140,0,0.0254762,"s has shown that annotating transcripts with semantic information (e.g., topics) enables users to browse and find information from multimedia archives more efficiently (Banerjee et al., 2005). Second, because the automatically generated segments make up for the lack of explicit orthographic cues (e.g., story and paragraph breaks) in conversational speech, dialogue segmentation is useful in many spoken language understanding tasks, including anaphora resolution (Grosz and Sidner, 1986), information retrieval (e.g., as input for the TREC Spoken Document Retrieval (SDR) task), and summarization (Zechner and Waibel, 2000). This study therefore aims to explore whether a Maximum Entropy (MaxEnt) classifier can integrate multiple knowledge sources for segmenting recorded speech. In this paper, we first evaluate the effectiveness of features that have been proposed in previous work, with a focus on features that can be extracted automatically. Second, we examine other knowledge sources that have not been studied systematically in previous work, but which we expect to be good predictors of dialogue segments. In addition, as our ultimate goal is to develop an information retrieval module that can be operated in a fu"
P07-1128,J97-1003,0,0.709451,"be operated in a fully automatic fashion, we also investigate the impact of automatic speech recognition (ASR) errors on the task of dialogue segmentation. 2 Previous Work In previous work, the problem of automatic dialogue segmentation is often considered as similar to the problem of topic segmentation. Therefore, research has adopted techniques previously developed Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 1016–1023, c Prague, Czech Republic, June 2007. 2007 Association for Computational Linguistics to segment topics in text (Kozima, 1993; Hearst, 1997; Reynar, 1998) and in read speech (e.g., broadcast news) (Ponte and Croft, 1997; Allan et al., 1998). For example, lexical cohesion-based algorithms, such as LCSEG (Galley et al., 2003), or its word frequency-based predecessor TextTile (Hearst, 1997) capture topic shifts by modeling the similarity of word repetition in adjacent windows. However, recent work has shown that LCSEG is less successful in identifying “agenda-based conversation segments” (e.g., presentation, group discussion) that are typically signalled by differences in group activity (Hsueh and Moore, 2006). This is not surprisin"
P07-1128,P87-1023,0,0.351162,"TOP PK 0.29 0.35 0.30 0.29 0.30 0.29 WD 0.33 0.35 0.34 0.31 0.35 0.33 Hyp 7.6 3.5 6.8 7.4 7.3 6.7 SUB PK 0.35 0.37 0.35 0.33 0.35 0.36 WD 0.38 0.38 0.37 0.35 0.37 0.38 Table 4: Performance change of taking out each individual feature class from the ALL model. Table 4 illustrates the error rate change (i.e., increased or decreased PK and WD score)7 that is incurred by leaving out one feature class from the ALL model. Results show that CONV, PROS, MOTION and CTXT can be taken out from the ALL model individually without increasing the error rate significantly.8 Morevoer, the combined models al6 Hirschberg and Litman (1987) have proposed to discriminate the different uses intonationally. 7 Note that the increase in error rate indicates performance degradation, and vice versa. 8 Sign tests were used to test for significant differences between means in each fold of cross validation. 1020 LX1+MOT LX1+CTXT MOT+PROS MOT+CTXT Hyp 61.2 96.2 5.3 6.2 20.2 6.3 62.0 2.7 TOP PK 0.53 0.36 0.27 0.30 0.39 0.28 0.34 0.33 WD 0.72 0.40 0.30 0.33 0.49 0.31 0.34 0.33 Hyp 65.1 96.2 6.9 7.3 24.8 7.2 62.1 2.3 SUB PK 0.49 0.38 0.32 0.36 0.39 0.33 0.37 0.37 WD 0.66 0.41 0.35 0.38 0.47 0.35 0.37 0.37 Table 5: Effects of combining complem"
P07-1128,P96-1038,0,0.0378701,"types of recorded speech. For example, Brown et al. (1980) have shown that a discourse segment often starts with relatively high pitched sounds and ends with sounds of pitch within a more compressed range. Passonneau and Litman (1993) identified that topic shifts often occur after a pause of relatively long duration. Other prosodic cues (e.g., pitch contour, energy) have been studied for their correlation with story segments in read speech (Tur et al., 2001; Levow, 2004; Christensen et al., 2005) and with theory-based discourse segments in spontaneous speech (e.g., directiongiven monologue) (Hirschberg and Nakatani, 1996). In addition, head and hand/forearm movements are used to detect group-action based segments (McCowan et al., 2005; Al-Hames et al., 2005). However, many other features that we expect to signal segment boundaries have not been studied systematically. For instance, speaker intention (i.e., dialogue act types) and conversational context (e.g., speaker role). In addition, although these features are expected to be complementary to one another, few of the previous studies have looked at the question how to use conditional approaches to model the 1017 correlation among features. 3 Methodology 3.1"
P07-1128,E06-1035,1,0.948792,"nt topics in text (Kozima, 1993; Hearst, 1997; Reynar, 1998) and in read speech (e.g., broadcast news) (Ponte and Croft, 1997; Allan et al., 1998). For example, lexical cohesion-based algorithms, such as LCSEG (Galley et al., 2003), or its word frequency-based predecessor TextTile (Hearst, 1997) capture topic shifts by modeling the similarity of word repetition in adjacent windows. However, recent work has shown that LCSEG is less successful in identifying “agenda-based conversation segments” (e.g., presentation, group discussion) that are typically signalled by differences in group activity (Hsueh and Moore, 2006). This is not surprising since LCSEG considers only lexical cohesion. Previous work has shown that training a segmentation model with features that are extracted from knowledge sources other than words, such as speaker interaction (e.g., overlap rate, pause, and speaker change) (Galley et al., 2003), or participant behaviors, e.g., note taking cues (Banerjee and Rudnicky, 2006), can outperform LCSEG on similar tasks. In many other fields of research, a variety of features have been identified as indicative of segment boundaries in different types of recorded speech. For example, Brown et al. ("
P07-1128,P93-1041,0,0.0909677,"dule that can be operated in a fully automatic fashion, we also investigate the impact of automatic speech recognition (ASR) errors on the task of dialogue segmentation. 2 Previous Work In previous work, the problem of automatic dialogue segmentation is often considered as similar to the problem of topic segmentation. Therefore, research has adopted techniques previously developed Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 1016–1023, c Prague, Czech Republic, June 2007. 2007 Association for Computational Linguistics to segment topics in text (Kozima, 1993; Hearst, 1997; Reynar, 1998) and in read speech (e.g., broadcast news) (Ponte and Croft, 1997; Allan et al., 1998). For example, lexical cohesion-based algorithms, such as LCSEG (Galley et al., 2003), or its word frequency-based predecessor TextTile (Hearst, 1997) capture topic shifts by modeling the similarity of word repetition in adjacent windows. However, recent work has shown that LCSEG is less successful in identifying “agenda-based conversation segments” (e.g., presentation, group discussion) that are typically signalled by differences in group activity (Hsueh and Moore, 2006). This is"
P07-1128,N04-4035,0,0.0165847,"lar tasks. In many other fields of research, a variety of features have been identified as indicative of segment boundaries in different types of recorded speech. For example, Brown et al. (1980) have shown that a discourse segment often starts with relatively high pitched sounds and ends with sounds of pitch within a more compressed range. Passonneau and Litman (1993) identified that topic shifts often occur after a pause of relatively long duration. Other prosodic cues (e.g., pitch contour, energy) have been studied for their correlation with story segments in read speech (Tur et al., 2001; Levow, 2004; Christensen et al., 2005) and with theory-based discourse segments in spontaneous speech (e.g., directiongiven monologue) (Hirschberg and Nakatani, 1996). In addition, head and hand/forearm movements are used to detect group-action based segments (McCowan et al., 2005; Al-Hames et al., 2005). However, many other features that we expect to signal segment boundaries have not been studied systematically. For instance, speaker intention (i.e., dialogue act types) and conversational context (e.g., speaker role). In addition, although these features are expected to be complementary to one another,"
P08-2013,georgila-etal-2008-fully,1,0.87922,"(Czaja and Lee, 2007) that present challenges for user modelling. To our knowledge no one so far has built statistical user simulation models for older people. The only statistical spoken dialogue system for older people we are aware of is Nursebot, an early application of statistical methods (POMDPs) within the context of a medication reminder system (Roy et al., 2000). In this study, we build SUs for both younger and older adults using n-grams. Our data comes from a fully annotated corpus of 447 interactions of older and younger users with a Wizard-of-Oz (WoZ) appointment scheduling system (Georgila et al., 2008). We then evaluate these models using standard metrics (Schatzmann et al., 2005; Georgila et al., 2006) and compare our findings with the results of statistical corpus analysis. The novelty of our work lies in two areas. First, to the best of our knowledge this is the first time that statistical SUs have been built for the increasingly important population of older users. Secondly, a general (but as yet untested) assumption in this field is that current SUs are “enough like” real users for training good policies, and that testing system performance in simulated dialogues is an accurate indicat"
P08-2013,2005.sigdial-1.6,1,0.939881,"good predictor of the behaviour of different types of users, which provides evidence for the validity of current user simulation evaluation metrics. 1 Introduction Using machine learning to induce dialogue management policies requires large amounts of training data, and thus it is typically not feasible to build such models solely with data from real users. Instead, data from real users is used to build simulated users (SUs), who then interact with the system as often as needed. In order to learn good policies, the behaviour of the SUs needs to cover the range of variation seen in real users (Schatzmann et al., 2005; Georgila et al., 2006). Furthermore, SUs are critical for evaluating candidate dialogue policies. To date, several techniques for building SUs have been investigated and metrics for evaluating their quality have been proposed (Schatzmann et al., 2005; Georgila et al., 2006). However, to our knowledge, no one has tried to build user simulations for different populations of real users and measure whether results from evaluating the quality of those simulations agree with what is known about those particular types of real users, extracted from other studies of those populations. This is presuma"
P09-2076,P08-2050,0,0.0421031,"U. of Edinburgh Robert.Dale@mq.edu.au Introduction Recently, there has been an increased interest in evaluating and comparing natural language generation (NLG) systems on shared tasks (Belz, 2009; Dale and White, 2007; Gatt et al., 2008). However, this is a notoriously hard problem (Scott and Moore, 2007): Task-based evaluations with human experimental subjects are time-consuming and expensive, and corpus-based evaluations of NLG systems are problematic because a mismatch between humangenerated output and system-generated output does not necessarily mean that the system’s output is inferior (Belz and Gatt, 2008). This lack of evaluation methods which are both effective and efficient is a serious obstacle to progress in NLG research. The GIVE Challenge (Byron et al., 2009) is a recent shared task which takes a third approach to NLG evaluation: By connecting NLG systems to experimental subjects over the Internet, it achieves a true task-based evaluation at a much lower cost. Indeed, the first GIVE Challenge acquired data from over 1100 experimental subjects online. However, it still remains to be shown that the results that can be obtained in this way are in fact comparable to more established task-bas"
P09-2076,J09-1008,0,0.0108405,"In this paper, we validate this novel NLG evaluation methodology by comparing the Internet-based results with results we collected in a lab experiment. We find that the results delivered by both methods are consistent, but the Internetbased approach offers the statistical power necessary for more fine-grained evaluations and is cheaper to carry out. 1 dbyron@ccs.neu.edu justine@northwestern.edu Sara Dalzel-Job U. of Edinburgh Robert.Dale@mq.edu.au Introduction Recently, there has been an increased interest in evaluating and comparing natural language generation (NLG) systems on shared tasks (Belz, 2009; Dale and White, 2007; Gatt et al., 2008). However, this is a notoriously hard problem (Scott and Moore, 2007): Task-based evaluations with human experimental subjects are time-consuming and expensive, and corpus-based evaluations of NLG systems are problematic because a mismatch between humangenerated output and system-generated output does not necessarily mean that the system’s output is inferior (Belz and Gatt, 2008). This lack of evaluation methods which are both effective and efficient is a serious obstacle to progress in NLG research. The GIVE Challenge (Byron et al., 2009) is a recent"
P09-2076,W09-0628,1,0.930466,"tems on shared tasks (Belz, 2009; Dale and White, 2007; Gatt et al., 2008). However, this is a notoriously hard problem (Scott and Moore, 2007): Task-based evaluations with human experimental subjects are time-consuming and expensive, and corpus-based evaluations of NLG systems are problematic because a mismatch between humangenerated output and system-generated output does not necessarily mean that the system’s output is inferior (Belz and Gatt, 2008). This lack of evaluation methods which are both effective and efficient is a serious obstacle to progress in NLG research. The GIVE Challenge (Byron et al., 2009) is a recent shared task which takes a third approach to NLG evaluation: By connecting NLG systems to experimental subjects over the Internet, it achieves a true task-based evaluation at a much lower cost. Indeed, the first GIVE Challenge acquired data from over 1100 experimental subjects online. However, it still remains to be shown that the results that can be obtained in this way are in fact comparable to more established task-based evaluation efforts, which are based on a carefully selected subject pool and carried out in a controlled laboratory Justine Cassell Northwestern U. Johanna Moor"
P09-2076,W08-1131,0,0.0426993,"ovel NLG evaluation methodology by comparing the Internet-based results with results we collected in a lab experiment. We find that the results delivered by both methods are consistent, but the Internetbased approach offers the statistical power necessary for more fine-grained evaluations and is cheaper to carry out. 1 dbyron@ccs.neu.edu justine@northwestern.edu Sara Dalzel-Job U. of Edinburgh Robert.Dale@mq.edu.au Introduction Recently, there has been an increased interest in evaluating and comparing natural language generation (NLG) systems on shared tasks (Belz, 2009; Dale and White, 2007; Gatt et al., 2008). However, this is a notoriously hard problem (Scott and Moore, 2007): Task-based evaluations with human experimental subjects are time-consuming and expensive, and corpus-based evaluations of NLG systems are problematic because a mismatch between humangenerated output and system-generated output does not necessarily mean that the system’s output is inferior (Belz and Gatt, 2008). This lack of evaluation methods which are both effective and efficient is a serious obstacle to progress in NLG research. The GIVE Challenge (Byron et al., 2009) is a recent shared task which takes a third approach t"
P09-2076,W09-0629,0,\N,Missing
P10-2009,2005.sigdial-1.14,0,0.0935802,"Conference Short Papers, pages 43–48, c Uppsala, Sweden, 11-16 July 2010. 2010 Association for Computational Linguistics word sense assigned to an ambiguous word, or an incorrectly resolved referential expression. Our approach to selecting an error recovery policy is to prefer non-understandings to misunderstandings. There is a known trade-off in spoken dialogue systems between allowing misunderstandings, i.e., cases in which a system accepts and acts on an incorrect interpretation of an utterance, and non-understandings, i.e., cases in which a system rejects an utterance as uninterpretable (Bohus and Rudnicky, 2005). Since misunderstandings on the part of a computer tutor are known to negatively impact student learning, and since in human-human tutorial dialogue the majority of student responses using unexpected terminology are classified as incorrect (Jordan et al., 2009), it would be a reasonable approach for a tutorial dialogue system to deal with potential interpretation problems by treating low-confidence interpretations as non-understandings and focusing on an effective non-understanding recovery policy.1 We implemented two different policies for comparison. Our baseline policy does not attempt any"
P10-2009,W09-3906,1,0.909803,"Missing"
P10-2009,P10-4003,1,0.831745,"itly addressing the difference in acceptable phrasing may not be sufficient for effective tutoring. In Section 2 we describe our tutoring system, and the two tutoring policies implemented for the experiment. In Section 3 we present experimental results and an analysis of correlations between different types of interpretation problems, learning gain and user satisfaction. Finally, in Section 4 we discuss the implications of our results for error recovery policies in tutorial dialogue systems. 2 Tutorial Dialogue System and Error Recovery Policies This work is based on evaluation of B EETLE II (Dzikovska et al., 2010), a tutorial dialogue system which provides tutoring in basic electricity and electronics. Students read pre-authored materials, experiment with a circuit simulator, and then are asked to explain their observations. B EETLE II uses a deep parser together with a domain-specific diagnoser to process student input, and a deep generator to produce tutorial feedback automatically depending on the current tutorial policy. It also implements an error recovery policy to deal with interpretation problems. Students currently communicate with the system via a typed chat interface. While typing removes th"
P10-4003,W07-1207,1,0.608123,"authored curriculum slides and carry out exercises which involve experimenting with the circuit simulator and explaining the observed behavior. The system also asks some high-level questions, such as “What is voltage?”. The system architecture is shown in Figure 2. The system uses a standard interpretation pipeline, with domain-independent parsing and generation components supported by domain specific reasoners for decision making. The architecture is discussed in detail in the rest of this section. 2.1 Domain Reasoning and Diagnosis Interpretation Components We use the TRIPS dialogue parser (Allen et al., 2007) to parse the utterances. The parser provides a domain-independent semantic representation including high-level word senses and semantic role labels. The contextual interpreter then uses a reference resolution approach similar to Byron (2002), and an ontology mapping mechanism (Dzikovska et al., 2008a) to produce a domain-specific semantic representation of the student’s output. Utterance content is represented as a set of extracted objects and relations between them. Negation is supported, together with a heuristic scoping algorithm. The interpreter also performs basic ellipsis resolution. Fo"
P10-4003,P02-1011,0,0.00881647,"own in Figure 2. The system uses a standard interpretation pipeline, with domain-independent parsing and generation components supported by domain specific reasoners for decision making. The architecture is discussed in detail in the rest of this section. 2.1 Domain Reasoning and Diagnosis Interpretation Components We use the TRIPS dialogue parser (Allen et al., 2007) to parse the utterances. The parser provides a domain-independent semantic representation including high-level word senses and semantic role labels. The contextual interpreter then uses a reference resolution approach similar to Byron (2002), and an ontology mapping mechanism (Dzikovska et al., 2008a) to produce a domain-specific semantic representation of the student’s output. Utterance content is represented as a set of extracted objects and relations between them. Negation is supported, together with a heuristic scoping algorithm. The interpreter also performs basic ellipsis resolution. For example, it can determine that in the answer to the question “Which bulbs will be on and which bulbs will be off in this diagram?”, “off” can be taken to mean “all bulbs in the di2.3 Tutorial Planner The tutorial planner implements a set of"
P10-4003,W09-3906,1,0.852005,"gh-specificity, it attempts to hint at a two-place relation, for example, “Here’s a hint: the battery is connected to something.” The tutorial policy makes a high-level decision as to which strategy to use (for example, “acknowledge the correct part and give a high specificity hint”) based on the answer analysis and dialogue context. At present, the system takes into consideration the number of incorrect answers received in response to the current question and the number of uninterpretable answers.1 In addition to a remediation policy, the tutorial planner implements an error recovery policy (Dzikovska et al., 2009). Since the system accepts unrestricted input, interpretation errors are unavoidable. Our recovery policy is modeled on the TargetedHelp (Hockey et al., 2003) policy used in task-oriented dialogue. If the system cannot find an interpretation for an utterance, it attempts to produce a message that describes the problem but without giving away the answer, for example, “I’m sorry, I’m having a problem understanding. I don’t know the word power.” The help message is accompanied with a hint at the appropriate level, also depending on the number of previous incorrect and non-interpretable answers. 2"
P10-4003,P10-2009,1,0.827012,"the last turn the system combines the information from the tutor’s hint and the student’s answers and restates the complete answer since the current answer was completed over multiple turns. 4 derstandings. In dialogue management and generation, the key issue we are planning to investigate is that of linguistic alignment. The analysis of the data we have collected indicates that student satisfaction may be affected if the system rephrases student answers using different words (for example, using better terminology) but doesn’t explicitly explain the reason why different terminology is needed (Dzikovska et al., 2010). Results from other systems show that measures of semantic coherence between a student and a system were positively associated with higher learning gain (Ward and Litman, 2006). Using a deep generator to automatically generate system feedback gives us a level of control over the output and will allow us to devise experiments to study those issues in more detail. From the point of view of tutoring research, we are planning to use the system to answer questions about the effectiveness of different approaches to tutoring, and the differences between human-human and human-computer tutoring. Previ"
P89-1025,P85-1007,0,0.02541,"ntentional, attentional, and rhetorical structure of the generated text. In addition, since the expert system explanation facility is intended to be used by many different users, the text planner takes knowledge about the user into account. In our system, the user model contains the user's domain goals and the knowledge he is assumed to have about the domain. THE PLAN LANGUAGE In our plan language, intentional goals are represented in terms of the effects the speaker intends his utterance to have on the hearer. Following Hovy (1988a), we use the terminology for expressing beliefs developed by Cohen and Levesque (1985) in their theory of rational interaction, but have found the need to extend the terminology to represent the types of intentional goals necessary for the kinds of responses desired in an advisory setting. Although Cohen and Levesque have subsequently retracted some aspects of their theory of rational interaction (Cohen and Levesque, 1987), the utilityof their notation for our purposes remains unaffected, as argued in (Hovy, 1989).2 aPEA recommends transformations that improve the 'style' of the user's code. It does not attempt to understand the content of the user's program. 2Space limitations"
P89-1025,P88-1020,0,0.613791,"RPA) under a NASA Ames cooperative agreement number NCC 2-520. The authors would like to thank William Swartout for comments on earlier versions of this paper. 203 DIALOGUES&quot; C~cile L. Paris USC/information Sciences Institute 4676 Admiralty Way Marina del Key, CA 90292-6695, USA the discourse. In contrast, most text generation systems (with the notable exception of KAMP (Appelt, 1985)) have used only rhetorical and attentional information to produce coherent text (McKeown, 1985, McCoy, 1985, Paris, 1988b), omitting intentional information, or conflating intentional and rhetorical information (Hovy, 1988b). No text generation system records or reasons about the rhetorical, the attentional, as well as the intentional structures of the texts it produces. In this paper, we argue that to successfully participate in an explanation dialogue, a generation system must maintain the kinds of information outlined by Grosz and Sidner as well as an explicit representation of the rhetorical structure of the texts it generates. We present a text planner that builds a detailed text plan, containing the intentional, attentional, and rhetorical structures of the responses it produces. The main focus of this pa"
P89-1025,J88-3006,1,0.244126,"The research described in this paper was supported by the Defense Advanced Research Projects Agency (DARPA) under a NASA Ames cooperative agreement number NCC 2-520. The authors would like to thank William Swartout for comments on earlier versions of this paper. 203 DIALOGUES&quot; C~cile L. Paris USC/information Sciences Institute 4676 Admiralty Way Marina del Key, CA 90292-6695, USA the discourse. In contrast, most text generation systems (with the notable exception of KAMP (Appelt, 1985)) have used only rhetorical and attentional information to produce coherent text (McKeown, 1985, McCoy, 1985, Paris, 1988b), omitting intentional information, or conflating intentional and rhetorical information (Hovy, 1988b). No text generation system records or reasons about the rhetorical, the attentional, as well as the intentional structures of the texts it produces. In this paper, we argue that to successfully participate in an explanation dialogue, a generation system must maintain the kinds of information outlined by Grosz and Sidner as well as an explicit representation of the rhetorical structure of the texts it generates. We present a text planner that builds a detailed text plan, containing the inten"
P89-1025,J86-3001,0,\N,Missing
P95-1018,C90-3018,0,0.555351,"c text generation. Much previous work in this area has relied on ad hoc methods. Our coding scheme for the exhaustive analysis of discourse allows a systematic evaluation and refinement of hypotheses concerning cues. We report two results based on this analysis: a comparison of the distribution of Sn~CE and BECAUSEin our corpus, and the impact of embeddedness on cue selection. Discourse cues play a crucial role in many discourse processing tasks, including plan recognition (Litman and Allen, 1987), anaphora resolution (Gross and Sidner, 1986), and generation of coherent multisentential texts (Elhadad and McKeown, 1990; Roesner and Stede, 1992; Scott and de Souza, 1990; Zukerman, 1990). Cues are words or phrases such as BECAUSE, FIRST, ALTHOUGHand ALSO that mark structural and semantic relationships between discourse entities. While some specific issues concerning cue usage have been resolved (e.g., the disambiguation of discourse and sentential cues (Hirschberg and Litman, 1993)), our concern is to identify general strategies of cue selection and placement that can be implemented for automatic text generation. Relevant research in reading comprehension presents a mixed picture (Goldman and Murray, 1992; Lo"
P95-1018,J86-3001,0,0.84495,"utors, m a y itself be a segment with a core:contributor 1 structure, or m a y be a simpler functional element. There are three types of simpler functional elements: (1) units, which are descriptions of domain states and actions, (2) matrix elements, which express a mental attitude, a prescription or an evaluation by embedding another element, and (3) relation clusters, which are otherwise like segments except that they have no core:coatributor structure. This approach synthesizes ideas which were previously thought incompatible from two theories of discourse structure, the theory proposed by Grosz and Sidner (1986) and Rhetorical Structure Theory (RST) proposed by M a n n and Thompson (1988). The idea that the hierarchical segment structure of discourse originates with intentions of the speaker, and thus the defining feature of a segment is that there be a recognizable segment purpose, is due to Grosz and Sidner. The idea that discourse is hierarchically structured by palrwise relations in which one relatum (the nucleus) is more central to the speaker&apos;s purpose is due to Mann and T h o m p son. Work by Moore and Pollack (1992) modified the R S T assumption t h a t these palrwise relations are unique, de"
P95-1018,J93-3003,0,0.0288214,"cue selection. Discourse cues play a crucial role in many discourse processing tasks, including plan recognition (Litman and Allen, 1987), anaphora resolution (Gross and Sidner, 1986), and generation of coherent multisentential texts (Elhadad and McKeown, 1990; Roesner and Stede, 1992; Scott and de Souza, 1990; Zukerman, 1990). Cues are words or phrases such as BECAUSE, FIRST, ALTHOUGHand ALSO that mark structural and semantic relationships between discourse entities. While some specific issues concerning cue usage have been resolved (e.g., the disambiguation of discourse and sentential cues (Hirschberg and Litman, 1993)), our concern is to identify general strategies of cue selection and placement that can be implemented for automatic text generation. Relevant research in reading comprehension presents a mixed picture (Goldman and Murray, 1992; Lorch, 1989), suggesting that felicitous use of cues improves comprehension and recall, but that indiscriminate use of cues may have detrimental effects on recall (Millis et al., 1993) and that the benefit of cues may depend on the subjects&apos; reading skill and level of domain knowledge (McNamara et al., In press). However, interpreting the research is problematic becau"
P95-1018,J92-4007,1,0.773334,"incompatible from two theories of discourse structure, the theory proposed by Grosz and Sidner (1986) and Rhetorical Structure Theory (RST) proposed by M a n n and Thompson (1988). The idea that the hierarchical segment structure of discourse originates with intentions of the speaker, and thus the defining feature of a segment is that there be a recognizable segment purpose, is due to Grosz and Sidner. The idea that discourse is hierarchically structured by palrwise relations in which one relatum (the nucleus) is more central to the speaker&apos;s purpose is due to Mann and T h o m p son. Work by Moore and Pollack (1992) modified the R S T assumption t h a t these palrwise relations are unique, demonstrating t h a t intentional and informational relations occur simultaneously. Moser and Moore (1993) point out the correspondence between the relation of dominance a m o n g intentions in Grosz and Sidner and the nucleussatellite distinction in RST. Because our analysis realizes this relation/distinction in a form different from both intention dominance and nuclearity, we have chosen the new terms core and contributor. To illustrate the application of R D A , consider the partial tutor explanation in Figure i t."
P95-1018,W93-0225,1,0.809653,"e idea that the hierarchical segment structure of discourse originates with intentions of the speaker, and thus the defining feature of a segment is that there be a recognizable segment purpose, is due to Grosz and Sidner. The idea that discourse is hierarchically structured by palrwise relations in which one relatum (the nucleus) is more central to the speaker&apos;s purpose is due to Mann and T h o m p son. Work by Moore and Pollack (1992) modified the R S T assumption t h a t these palrwise relations are unique, demonstrating t h a t intentional and informational relations occur simultaneously. Moser and Moore (1993) point out the correspondence between the relation of dominance a m o n g intentions in Grosz and Sidner and the nucleussatellite distinction in RST. Because our analysis realizes this relation/distinction in a form different from both intention dominance and nuclearity, we have chosen the new terms core and contributor. To illustrate the application of R D A , consider the partial tutor explanation in Figure i t. The purpose of this segment is to inform the student that she made the strategy error of testing inside paxt3 too soon. The constituent that expresses the purpose, in this case (B),"
P95-1018,P93-1020,0,0.0347241,"Missing"
P95-1018,P92-1050,0,0.0105127,"ut their task; they are trained. Finally, the data is not spoken as in these other studies. Future work will include a more extensive reliability study, one that includes the intentional and informational relations. 132 3 Initial results and their application For each t u t o r explanation in our corpus, each coder analyzes the text as described above, and then enters this analysis into a database. The technique of representing an analysis in a database and then using database queries to test hypotheses is similar to work using R S T analyses to investigate the form of purpose clauses (Vander Linden et al., 1992). Because our analysis is exhaustive, information a b o u t b o t h occurrence and nonoccurrence of cues can be retrieved from the database in order to test and modify hypotheses a b o u t cue usage. T h a t is, b o t h cuebased and factor-based retrievals are possible. In cue-based retrievals, we use an occurrence of the cue under investigation as the criterion for retrieving the value of its hypothesized descriptive factors. Factorbased retrievals provide information a b o u t cues that is unique to this study. In factor-based retrieval, the occurrence of a combination of descriptive factor"
P95-1018,P94-1002,0,\N,Missing
P97-1011,P95-1018,1,0.923129,"ific rhetorical structures (RSsner and Stede, 1992; Scott and de Souza, 1990; Vander Linden and Martin, 1995). Other hypotheses about cue usage derive from work on discourse coherence and structure. Previous research (Hobbs, 1985; Grosz and Sidner, 1986; Schiffrin, 1987; M a n n and Thompson, 1988; Elhadad and McKeown, 1990), which has been largely descriptive, suggests factors such as structural features of the discourse (e.g.,levelof embedding and segment complexity), intentional and informational relations in that structure, ordering of relata, and syntactic form of discourse constituents. Moser and Moore (1995; 1997) coded a corpus of naturally occurring tutorial explanations for the range of features identified in prior work. Because they were also interested in the contrast between occurrence and non-occurrence of cues, they exhaustively coded for all of the factors thought to contribute to cue usage in all of the text. From their study, Moscr and Moore identifiedseveral interesting correlations between particular features and specific aspects of cue usage, and were able to test specific hypotheses from the hterature that were based on constructed examples. In this paper, we focus on cue occurren"
P97-1011,W96-0402,1,0.874243,"Missing"
P97-1011,P84-1055,0,0.151533,"r cue occurrence and placement from a corpus of data coded for a variety of features previously thought to affect cue usage. Our experiments enable us to identify the features with most predictive power, and show that machine learning can be used to induce decision trees useful for text generation. 1 Introduction Discourse cues are words or phrases, such as because, first, and although, that mark structural and semantic relationships between discourse entities. They play a crucial role in many discourse processing tasks, including plan recognition (Litman and Allen, 1987), text comprehension (Cohen, 1984; Hobbs, 1985; Mann and Thompson, 1986; Reichman-Adar, 1984), and anaphora resolution (Grosz and Sidner, 1986). Moreover, research in reading comprehension indicates that felicitous use of cues improves comprehension and recall (Goldman, 1988), but that their indiscriminate use may have detrimental effects on recall (Millis, Graesser, and Haberlandt, 1993). Our goal is to identify general strategies for cue usage that can be implemented for automatic text generation. From the generation perspective, cue usage consists of three distinct, but interrelated problems: (1) occurrence: whether or not"
P97-1011,C90-3018,0,0.42976,", but that their indiscriminate use may have detrimental effects on recall (Millis, Graesser, and Haberlandt, 1993). Our goal is to identify general strategies for cue usage that can be implemented for automatic text generation. From the generation perspective, cue usage consists of three distinct, but interrelated problems: (1) occurrence: whether or not to include a cue in the generated text, (2) placement: where the cue should be placed in the text, and (3) selection: what lexical item(s) should be used. Prior work in text generation has focused on cue selection (McKeown and Elhadad, 1991; Elhadad and McKeown, 1990), or on the relation between *Learning Research & Development Center tComputer Science Department, and Learning Research ~z Development Center tlntelllgentSystems Program P a o l u c c i ""+ cue occurrence and placement and specific rhetorical structures (RSsner and Stede, 1992; Scott and de Souza, 1990; Vander Linden and Martin, 1995). Other hypotheses about cue usage derive from work on discourse coherence and structure. Previous research (Hobbs, 1985; Grosz and Sidner, 1986; Schiffrin, 1987; M a n n and Thompson, 1988; Elhadad and McKeown, 1990), which has been largely descriptive, suggests"
P97-1011,J86-3001,0,0.889413,"ought to affect cue usage. Our experiments enable us to identify the features with most predictive power, and show that machine learning can be used to induce decision trees useful for text generation. 1 Introduction Discourse cues are words or phrases, such as because, first, and although, that mark structural and semantic relationships between discourse entities. They play a crucial role in many discourse processing tasks, including plan recognition (Litman and Allen, 1987), text comprehension (Cohen, 1984; Hobbs, 1985; Mann and Thompson, 1986; Reichman-Adar, 1984), and anaphora resolution (Grosz and Sidner, 1986). Moreover, research in reading comprehension indicates that felicitous use of cues improves comprehension and recall (Goldman, 1988), but that their indiscriminate use may have detrimental effects on recall (Millis, Graesser, and Haberlandt, 1993). Our goal is to identify general strategies for cue usage that can be implemented for automatic text generation. From the generation perspective, cue usage consists of three distinct, but interrelated problems: (1) occurrence: whether or not to include a cue in the generated text, (2) placement: where the cue should be placed in the text, and (3) se"
P97-1011,W96-0208,0,0.0177431,"93, Ch. 4) for details. Thus, below we will report the average estimated error rate on the test set, as computed by 10-fold cross-validation experiments. The algorithm We chose the C4.5 learning algorithm (Quinlan, 1993) because it is well suited to a domain such as ours with discrete valued attributes. Moreover, C4.5 produces decision trees and rule sets, both often used in text generation to implement mappings from function features to forms? Finally, C4.5 is both readily available, and is a benchmark learning algorithm that has been extensively used in NLP applications, e.g. (Litman, 1996; Mooney, 1996; Vander Linden and Di Eugenio, 1996). As our dataset is small, the results we report are based on cross-validation, which (Weiss and Kulikowski, 1091) recommends as the best method to evaluate decision trees on datasets whose cardinality is in the hundreds. Data for learning should be divided into training and test sets; however, for small datasets this has the disadvantage that a sizable portion of the data is not available for learning. Crossvalidation obviates this problem by running the algorithm N times (N=10 is a typical value): in each run, (N~l)th of the data, randomly chosen, is used"
P97-1011,W94-0302,1,0.875054,"Missing"
P97-1011,J95-1002,0,\N,Missing
P97-1011,P87-1014,0,\N,Missing
P98-1052,J96-2004,0,0.156522,"Missing"
W00-1407,W00-1402,1,0.904203,"n her model of preferences (i.e., the argumentative The argumentation strategy has been intent is equal to the expected value, so MD=0) 6. implemented as a set of plan operators. Using We now examine the strategy in detail, after these operators the Longbow discourse planner introducing necessary, terminology. The subject (Young and Moore 1994) selects and arranges the content of the argument. We have applied 5 a,.or~, is an alternative such that Vo v~,(a,,,,r~,)=O, our strategy in a system that serves as a realwhereas abL.,is an alternative suchthat Vo vo(abe.¢~)=l estate personal assistant (Carenini 2000a). The 6 An alternative strategy, for generating arguments system presents information about houses whose argumentative intent was-greater (or lower) available on the market in graphical format. The than the expected value, could also be defined in our user explores this information by means of framework. However, this strategy should boost the interactive techniques, and can request a natural evaluation of supporting evidence and include only weak counterarguments, or hide them overall (the opposite if the target value was lower than the expected value) 7 The steps in the strategy are marked"
W00-1407,J98-3002,0,0.0179712,"Missing"
W04-2801,A00-2041,0,0.0322907,"Missing"
W04-2801,P98-1059,0,0.0130963,"ntain links between logical predicates and the corresponding words typed by the user. Section 6 discusses our reference resolution module and how it calculates confidence scores and records the transformations that it makes (from logical predicates to simulated objects in the domain reasoner). In section 7, we discuss how we calculate global confidence scores and link references to simulated objects back to the user’s referring expression. Dialogue History Domain Reasoner (BEER) NUBEE Response Generation Figure 1: NLU-centric diagram of BEETLE 3 Spelling Correction NUBEE’s spelling corrector (Elmi and Evens, 1998) and robust parser are both part of the Carmel workbench and the interface between the two is predefined. The spelling corrector uses the parser’s lexicon as its dictionary and attempts to fix spelling and typing errors in known words. Since the parser’s lexicon is typically much smaller than a lexical database such as WordNet (Miller, 1990), there is a reduction in token ambiguity (i.e., the number of possible replacements to consider) but the spelling of unknown words will not be corrected. The simplification is also made that known words are never misspelled versions of other known words (e"
W04-2801,C94-1042,0,0.0213594,"ench We use the Carmel workbench (Ros´e, 2000; Ros´e et al., 2003) for parsing and post-processing. In Carmel’s AUTOSEM framework: “semantic interpretation [operates] in parallel with syntactic interpretation at parse time in a lexicon driven fashion. ... [Semantic] knowledge is encoded declaratively within a meaning representation specification. Semantic constructor functions are compiled automatically from this specification and then linked into lexical entries” (Ros´e, 2000, p. 311). Carmel comes with a wide-coverage English grammar that is compatible with the wide-coverage COMLEX lexicon (Grishman et al., 1994). For each COMLEX entry that we wanted to add into NUBEE’s lexicon, we specified its meaning as shown below for the words “connect”, “battery”, and “wire”. procedure SEARCH-WORD (SYNSETS) connect: connect’, subject->agent, 1. SEARCH-DOWN (SYNSETS) object->theme, 2. if height threshold not reached then modifier->destination SEARCH-WORD (hypernyms for SYNSETS) battery: battery’ wire: wire’ procedure SEARCH-DOWN (SYNSETS) This simplified example of the meaning specification assigns a predicate to each word, and in the case of a 1. search all words having a verb such as “connect” assigns a mapping"
W04-2801,W98-0718,0,0.0173147,"res described above returns a set of replacement candidates which are treated as equally likely. In future work, we plan to revise this search process to use a distance metric such as one of those discussed in (Budanitsky and Hirst, 2001). Such distance metrics take into account factors such as the overall depth of the WordNet taxonomy and the frequency of synsets in a corpus, and will allow us to better control the search process. Although we know of no work on using WordNet to handle unknown words during interpretation, there is work on using WordNet for lexical variation during generation. Jing (1998) presents an algorithm for converting WordNet into a domain-specific taxonomy of replaceable words. First, words and synsets are removed that do not appear in a corpus representative of the domain. The senses of verb arguments in the corpus are disambiguated based on the intuition that words appearing as the same argument to the same verb should have senses close to each other in WordNet. Consider an example from Jing’s domain of generating basketball news reports. The verb “add” takes words such as “rebound”, “throw”, and “shot” as objects. Jing states that “rebound” and “throw” have senses t"
W04-2801,P00-1018,0,0.0304678,"p. 149). We have taken this idea further and explored the issues involved in computing confidence scores for larger constituents. Some of these issues are linked to our twostage semantic analysis. However, Carmel’s two-stage interpretation process (i.e., a domain-independent parsing stage and a domain-dependent predicate mapping stage) is not idiosyncratic to the Carmel workbench. Dzikovska et al. (2002) adopt such a two stage approach because their NLU sub-system is used in multiple domains (e.g., transportation planning, medication advice) necessitating reuse of resources wherever possible. Milward (2000) uses a two stage approach because it increases robustness. When the parser is not able to build a parse tree covering the entire input, there will still be a semantic chart composed of partial parses and their associated semantic feature values. For the domain of airline flight information, Milward defines post-processing rules that scan this semantic chart looking for information such as departure times. Our goal in this paper was to highlight the architectural trade-offs of such features on controlling fidelity. 9 Future Work Our search process for unknown word handling is rudimentary. Each"
W04-2801,C98-1057,0,\N,Missing
W04-3217,A00-2018,0,0.0137719,"-enabled natural language processing component can add mark-up to the text, and use any mark-up that the previous components made. All layers in the pipeline are fully automatic. For our pipeline we used LT-TTT (Language Technology Text Tokenization Toolkit) (Grover et al., 2000). Once words are tokenized and sentence boundaries detected by LT-TTT, LT-POS tags the words using the Penn Treebank tag-set without parsing the sentences. While a full parse could be generated by a statistical parser, such parses would likely be incorrect for the ungrammatical sentences often generated by the pupils (Charniak, 2000). Pronouns are resolved using a cascading rule-based approach directly inspired by the CogNIAC algorithm (Baldwin, 1997) with two variations. First, it resolves in distinct cascades for singular and then plural pronouns. Second, it resolves using only the CogNIAC rules that can be determined using Penn Treebank tags. The words are lemmatized using an augmented version of the SCOL Toolset and sentences are chunked using the Cass Chunker (Abney, 1995). There is a trade-off between this chunking approach that works on ungrammatical sentences and one that requires a full parse such as those using"
W04-3217,grover-etal-2000-lt,0,0.0961596,"be extracted from raw text by layering NLP modules using an XML-based pipeline. Our main constraint was that the text of the pupil was rarely grammatical, restricting our choice of NLP components to those that did not require a correct parse or were in any other ways dependent on grammatical sentences. At each level of processing, an XML-enabled natural language processing component can add mark-up to the text, and use any mark-up that the previous components made. All layers in the pipeline are fully automatic. For our pipeline we used LT-TTT (Language Technology Text Tokenization Toolkit) (Grover et al., 2000). Once words are tokenized and sentence boundaries detected by LT-TTT, LT-POS tags the words using the Penn Treebank tag-set without parsing the sentences. While a full parse could be generated by a statistical parser, such parses would likely be incorrect for the ungrammatical sentences often generated by the pupils (Charniak, 2000). Pronouns are resolved using a cascading rule-based approach directly inspired by the CogNIAC algorithm (Baldwin, 1997) with two variations. First, it resolves in distinct cascades for singular and then plural pronouns. Second, it resolves using only the CogNIAC r"
W04-3217,J92-4007,1,0.63206,"Rater B’s ratings were used as the gold standard. The distribution of plot ratings are given in Table 1. 4 A Minimal Event Calculus The most similar discourse analysis program to the one needed by StoryStation is the essay-grading component of “Criterion” by ETS technologies (Burstein et al., 2003), which is designed to annotate parts of an essay according to categories such as “Thesis, “Main Points,” “Support,” and “Conclusion.” Burstein et. al. (2003) uses Rhetorical Structure Theory to parse the text into discourse relations based on satellites and nuclei connected by rhetorical relations. Moore and Pollack (1992) note that Rhetorical Structure Theory conflates the informational (the information being conveyed) and intentional (the effects on the reader’s beliefs or attitudes) levels of discourse. Narratives are primarily informational, and so tend to degenerate to long sequences of elaboration or sequence relations. Since in the story rewriting task the students are attempting to convey information about the narrative, unlike the primarily persuasive task of an essay, our system focuses on the informational level as embodied by a simplified event calculus. Another tutoring system similar to ours is th"
W04-3217,W03-0907,0,0.125232,"e composed of the relationships among entities, such as “the boy becomes an elf,” which is composed of a “boy” and “elf” interacting via “becoming,” which we call the event name. This is because the use of such verbs is an indicator of the presence of an event in the story. In this manner events are relationships labeled with an event name, and entities are arguments to these relationships as in propositional logic. Together these can form events such as become(boy,elf), and this formulation maps partially onto Shanahan’s event calculus which has been used in other story-understanding models (Mueller, 2003). The key difference between an event calculus and a collection of propositions is that time is explicitly represented in the event calculus. Each story consists of a group of events that are present in the story, e1 ...eh . Each event consists of an event name, a time variable t, and a set of entities arranged in an ordered set n1 ...na . An event must contain one and only one event name. The event names are usually verbs, while the entities tend to be, but are not exclusively, nouns. Time is made explicit through a variable t. Normally, the Shanahan event calculus has a series of predicates"
W05-0905,P03-1069,0,0.00807599,"utomatic metrics, for the reason that automatic metrics of readability and coherence have not been widely discussed in the field of summarization. Though subjective evaluations of summaries are often divided into informativeness and readability questions, only automatic metrics of informativeness have been investigated in-depth by the summarization community. We believe that the development of automatic metrics for coherence and readability should be a high priority for researchers in summarization evaluation and plan on pursuing this avenue of research. For example, work on coherence in NLG (Lapata, 2003) could potentially inform summarization evaluation. Mani (Mani et al., 0.8 4.1.1 ASR versus Manual ROUGE-1-MAN ROUGE-2-MAN ROUGE-L-MAN ROUGE-1-ASR ROUGE-2-ASR ROUGE-L-ASR 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0 1 2 3 1=FB1, 2=LSA, 3=MMR, 4=FB2 4 Figure 1: ROUGE Scores for the Summarization Approaches 1999) is one of the few papers to have discussed measuring summary readability automatically. 4 Results The results of these experiments can be analyzed in various ways: significant differences of ROUGE results across summarization approaches, deterioration of ROUGE results on ASR versus manual transcripts,"
W05-0905,N03-1020,0,0.582657,"on of summary quality on ASR output versus manual transcripts, and to determine whether manual extracts are rated significantly higher than automatic extracts. 1 Introduction In the field of automatic summarization, it is widely agreed upon that more attention needs to be paid to the development of standardized approaches to summarization evaluation. For example, the current incarnation of the Document Understanding Conference is putting its main focus on the development of evaluation schemes, including semiautomatic approaches to evaluation. One semiautomatic approach to evaluation is ROUGE (Lin and Hovy, 2003), which is primarily based on ngram co-occurrence between automatic and human summaries. A key question of the research contained herein is how well ROUGE correlates with human judgments of summaries within the domain Three basic approaches to summarization are evaluated and compared below: Maximal Marginal Relevance, Latent Semantic Analysis, and featurebased classification. The other major comparisons in this paper are between summaries on ASR versus manual transcripts, and between manual and automatic extracts. For example, regarding the former, it might be expected that summaries on ASR tr"
W05-0905,P99-1072,0,0.0162471,"Missing"
W05-0905,W04-2319,0,0.0358772,"o they talk about?”; • decisions made by the group; • progress and achievements; • problems described The annotators were given a 200 word limit for each heading, and told that there must be text for the general abstract, but that the other headings may have null annotations for some meetings. Immediately after authoring a textual summary, annotators were asked to create an extractive summary, using a different GUI. This GUI showed both their textual summary and the orthographic transcription, without topic segmentation but with one line per dialogue act based on the pre-existing MRDA coding (Shriberg et al., 2004) (The dialogue act categories themselves were not displayed, just the segmentation). Annotators were told to extract dialogue acts that together would convey the information in the textual summary, and could be used to 35 support the correctness of that summary. They were given no specific instructions about the number or percentage of acts to extract or about redundant dialogue act. For each dialogue act extracted, they were then required in a second pass to choose the sentences from the textual summary supported by the dialogue act, creating a many-to-many mapping between the recording and t"
W05-0905,A00-2025,0,0.545023,"Missing"
W07-2319,W04-0210,0,0.0204119,"creating tutorial feedback to make the tutor’s responses sound more natural. A formal evaluation showed that a version with revision significantly improved learning gain over a version without it. In addition to C IRC S IM, annotation has been used in the generation community to attempt to discover relationships or prove effectiveness. Litman and Forbes-Riley (2006) annotated a large array of factors that might potentially affect learning and used χ-square tests over sequences of dialogue moves to discover which of those factors had the greatest influence on learning gain. The G NOME project (Poesio, 2004) created annotation schemes of noun phrases and their co-referring pronouns in order to be able to utilize them for evaluating pronominalization algorithms. Related Work Adding generated natural language dialogue to a tutorial system is a complex task whether using templates or deep generation since interactivity allows for a wide range of local variation in context. 3 Background We are attempting to semi-automatically formulate remediation strategies using a corpus of human124 Tutor: Differentiate sin(2x) Student: cos(x) Tutor: Again we have to use the chain rule. Tutor: So the answer you gav"
W08-1123,W07-2322,0,0.294952,"tream such as Pandora1 and discuss interesting trivia or facts about music tracks recently played to the user. User modeling could make these texts much more natural and less repetitive, and comparisons and contrasts between music artists or tracks could also provide users with a novel way to explore their music collection. The Methodius system (Isard, 2007) continues in a line of research which began with ILEX (O’Donnell et al., 2001) and continued with MPIRO (Isard et al., 2003) and now also NaturalOWL 1 Johanna Moore ICCS/HCRC School of Informatics University of Edinburgh J.Moore@ed.ac.uk (Galanis and Androutsopoulos, 2007). Like these other systems, Methodius creates customizable descriptions of objects from an database, but it features a novel algorithm for generating comparisons between a new object and objects that have previously been encountered, which stands out from previous research in this area because it uses several explicit parameters to choose the most relevant and interesting comparisons given the context (Isard, 2007). There have been previous evaluations of some of these systems, including (Cox et al., 1999; Karasimos and Isard, 2004). Karasimos and Isard conducted an evaluation of comparisons a"
W08-1123,karasimos-isard-2004-multi,1,0.872159,"Informatics University of Edinburgh J.Moore@ed.ac.uk (Galanis and Androutsopoulos, 2007). Like these other systems, Methodius creates customizable descriptions of objects from an database, but it features a novel algorithm for generating comparisons between a new object and objects that have previously been encountered, which stands out from previous research in this area because it uses several explicit parameters to choose the most relevant and interesting comparisons given the context (Isard, 2007). There have been previous evaluations of some of these systems, including (Cox et al., 1999; Karasimos and Isard, 2004). Karasimos and Isard conducted an evaluation of comparisons and aggregation in the M-PIRO system. The results showed that participants learned more and perceived that they learned more from texts that contained comparisons and aggregations than they did from texts that did not. In this study, we investigate whether these results generalize to our new domain, and we isolate the effect of comparisons from that of aggregation. 2 Knowledge Base Construction 2.1 Corpus Collection We collected a small corpus to investigate the type of facts disc jockeys tend to say about music. We selected two genr"
W09-0619,P08-1080,0,0.0151469,"s to put small tasks requiring human intelligence on the web. Deploying MT is advantageous because it attracts many visitors due to its affiliation with the well established Amazon website and thus eases recruitment of new participants especially from outside the usual student population. In addition, conducting experiments online significantly reduces the effort involved in data collection for the experimenter. Moreover, the website allows for convenient payment for both participants and the experimenter. For these reasons, MT has recently been used in a number of language experiments (e.g., Kaisser et al., 2008; Kittur et al., 2008). 4.1 4.2 Experimental setup and procedure In order to resemble the interface that was used in the previous experiment as closely as possible in terms of the general “look and feel”, a web-based interface was implemented using Adobe’s Flash format. We chose the widely used Flash format because it can be integrated into the MT environment easily and allows for tighter user control in comparison with standard HTML pages. For example, we made it impossible for users to reread the presented information once they read the corresponding question. With standard HMTL users would"
W09-0619,polifroni-walker-2006-learning,0,0.014525,"and connectives, on comprehension and recall in information presentation for natural language generation (NLG) as used in spoken dialogue systems (SDS). Spoken dialogue systems have traditionally used simple templates to present options (e.g., flights, restaurants) and their attributes to users (Walker et al., 2004). Recently, however, researchers have proposed approaches to information presentation that use linguistic devices (e.g., but, however, moreover, only, just, also etc.) in order to highlight specific properties of and relations between items presented to the user, e.g. associations (Polifroni and Walker, 2006) and contrasts (Winterboer and Moore, 2007). Previous research indicates that linguistic devices such as connectives facilitate comprehension (see BenAnath, 2005, for a review). However, to our knowledge, no empirical validation has been performed to test whether using linguistic devices has an effect on comprehension and recall of the information presentated.  Messina’s price is £22. It has very good food quality, attentive service, and decent d´ecor. Ray’s price is £34. It has very good food quality, excellent service, and impressive d´ecor. Alhambra’s price is £16. It has good food quality"
W09-0628,P08-2050,0,0.0293624,"ure of the task imposes high demands on the system’s efficiency). But if Why a new NLG evaluation paradigm? The GIVE Challenge addresses a need for a new evaluation paradigm for natural language generation (NLG). NLG systems are notoriously hard to evaluate. On the one hand, simply comparing system outputs to a gold standard using automatic comparison algorithms has limited value because there can be multiple generated outputs that are equally good. Finding metrics that account for this variability and produce results consistent with human judgments and task performance measures is difficult (Belz and Gatt, 2008; Stent et al., 2005; Foster, 2008). Human assessments of system outputs are preferred, but lab-based evaluations that allow human subjects to assess each aspect of the system’s functionality are expensive and time-consuming, thereby favoring larger labs with adequate resources to conduct human subjects studies. Human assessment studies are also difficult to replicate across sites, so system developers that are geographically separated find it dif166 extended to two-way dialog, the task can also involve issues of prosody generation (i.e., research on text/concept-to-speech generation), discour"
W09-0628,W08-1113,0,0.0343662,"he system’s efficiency). But if Why a new NLG evaluation paradigm? The GIVE Challenge addresses a need for a new evaluation paradigm for natural language generation (NLG). NLG systems are notoriously hard to evaluate. On the one hand, simply comparing system outputs to a gold standard using automatic comparison algorithms has limited value because there can be multiple generated outputs that are equally good. Finding metrics that account for this variability and produce results consistent with human judgments and task performance measures is difficult (Belz and Gatt, 2008; Stent et al., 2005; Foster, 2008). Human assessments of system outputs are preferred, but lab-based evaluations that allow human subjects to assess each aspect of the system’s functionality are expensive and time-consuming, thereby favoring larger labs with adequate resources to conduct human subjects studies. Human assessment studies are also difficult to replicate across sites, so system developers that are geographically separated find it dif166 extended to two-way dialog, the task can also involve issues of prosody generation (i.e., research on text/concept-to-speech generation), discourse generation, and human-robot inte"
W09-0628,E09-2009,1,0.68788,"onnects to the Matchmaker and is randomly assigned an NLG server and a game world. The client and NLG server then communicate over the course of one game. At the end of the game, the client displays a questionnaire to the user, and the game log and questionnaire data are uploaded to the Matchmaker and stored in a database. Note that this division allows the challenge to be conducted without making any assumptions about the internal structure of an NLG system. The GIVE software is implemented in Java and available as an open-source Google Code project. For more details about the software, see (Koller et al., 2009). 3.2 3.3 Materials Figs. 3–5 show the layout of the three evaluation worlds. The worlds were intended to provide varying levels of difficulty for the direction-giving systems and to focus on different aspects of the problem. World 1 is very similar to the development world that the research teams were given to test their system on. World 2 was intended to focus on object descriptions - the world has only one room which is full of objects and buttons, many of which cannot be distinguished by simple descriptions. World 3, on the other hand, puts more emphasis on navigation directions as the wor"
W09-0628,W06-1412,1,0.744385,"appeal to younger students, the task can also be used as a pedagogical exercise to stimulate interest among secondary-school students in the research challenges found in NLG or Computational Linguistics more broadly. Embedding the NLG task in a virtual world encourages the participating research teams to consider communication in a situated setting. This makes the NLG task quite different than in other NLG challenges. For example, experiments have shown that human instruction givers make the instruction follower move to a different location in order to use a simpler referring expression (RE) (Stoia et al., 2006). That is, RE generation becomes a very different problem than the classical non-situated Dale & Reiter style RE generation, which focuses on generating REs that are single noun phrases in the context of an unchanging world. On the other hand, because the virtual environments scenario is so open-ended, it – and specifically the instruction-giving task – can potentially be of interest to a wide range of NLG researchers. This is most obvious for research in sentence planning (GRE, aggregation, lexical choice) and realization (the real-time nature of the task imposes high demands on the system’s"
W09-3901,P04-1009,0,0.60479,"is important for several reasons: (1) to avoid overburdening the user’s memory by presenting too many options; (2) to ensure that the user is given an overview of the available option space so that the optimal option can be found; and (3) to minimise the number of dialogue turns (hence dialogue duration) required for the user to find an acceptable option. As Walker et al. (2001) showed, failing to meet this third goal may reduce overall user satisfaction. Recently several approaches have been proposed to overcome the shortcomings of the sequential enumeration strategy (Polifroni et al., 2003; Chung, 2004; Demberg and Moore, 2006; Polifroni and Walker, 2008). Because of the complexity of building a complete end-to-end SDS, these approaches have been evaluated using an “overhearer” methodology in which dialogues are either hand-crafted or simulated and then presented to subjects, either as textual transcripts Introduction Spoken dialogue systems (SDS) that help users find a desired option (e.g., flight, restaurant, movie) from the set of options satisfying their constraints typically present options sequentially, ordered along a default dimension (e.g., by price or departure time). An example i"
W09-3901,E06-1009,1,0.722326,"porary dining area, with simple floral displays and leather seating. It serves Indian cuisine. It is located in the city centre. The average price is £24 per person. Recent work on information presentation in dialogue systems combines user modelling (UM) and stepwise refinement through clustering and summarisation (SR) in the UMSR approach. An evaluation in which participants rated dialogue transcripts showed that UMSR presents complex trade-offs understandably, provides users with a good overview of their options, and increases users’ confidence that all relevant options have been presented (Demberg and Moore, 2006). In this paper, we evaluate the effectiveness of the UMSR approach in a more realistic setting, by incorporating this information presentation technique into a full endto-end dialogue system in the city information domain, and comparing it with the traditional approach of presenting information sequentially. Our results suggest that despite complications associated with a real dialogue system setting, the UMSR model retains its advantages. 1 Number 2: Saffrani’s decor is modern, the dining room wee, though the menu is enormous, and the atmosphere charming. It offers new Indian dishes never be"
W09-3901,J08-4002,1,0.918965,"formation about price range. M: Okay tell me about the ones in Boston. S: I have found 401 restaurants in Boston. There are 29 choices for cuisine. M: Do you have any that serve seafood? S: I have found 19 seafood restaurants. They are predominantly in Back Bay, the North End, South Boston and the South End. 3 The TownInfo System The TownInfo SDS was developed as part of the EC project TALK (Lemon et al., 2006). Users can search for hotels, bars and restaurants in an artificial town. The system supports two dialogue strategies, one hand-crafted and another learnt using Reinforcement Learning (Henderson et al., 2008). For the current experiment we used the hand-crafted strategy. Natural language understanding is performed using a keyword-based parser and natural language generation is based on templates. The information presentation is sequential. An example is given in Fig. 1, taken from the modified version of TownInfo for the current experiment. Although the original TownInfo system supported speech input and speech output, here we use text input/output to make sure that our results are not influenced by poor recognition accuracy or intelligibility due to poor speech synthesis. Of course, as we mention"
W09-3901,E06-2009,1,0.920615,"tion sequentially. Our results suggest that despite complications associated with a real dialogue system setting, the UMSR model retains its advantages. 1 Number 2: Saffrani’s decor is modern, the dining room wee, though the menu is enormous, and the atmosphere charming. It offers new Indian dishes never before seen in Edinburgh. It serves Indian, seafood cuisine. It is located in the city centre. The average price is £28 per person. Number 3: Britannia Spice . . . Figure 1: Example of sequential information presentation in the city information domain (modified version of the TownInfo system (Lemon et al., 2006)). and reduced user satisfaction. Thus a major challenge in the development of SDS is to improve information presentation algorithms. This is important for several reasons: (1) to avoid overburdening the user’s memory by presenting too many options; (2) to ensure that the user is given an overview of the available option space so that the optimal option can be found; and (3) to minimise the number of dialogue turns (hence dialogue duration) required for the user to find an acceptable option. As Walker et al. (2001) showed, failing to meet this third goal may reduce overall user satisfaction. R"
W09-3901,P08-1055,0,0.0728398,"to avoid overburdening the user’s memory by presenting too many options; (2) to ensure that the user is given an overview of the available option space so that the optimal option can be found; and (3) to minimise the number of dialogue turns (hence dialogue duration) required for the user to find an acceptable option. As Walker et al. (2001) showed, failing to meet this third goal may reduce overall user satisfaction. Recently several approaches have been proposed to overcome the shortcomings of the sequential enumeration strategy (Polifroni et al., 2003; Chung, 2004; Demberg and Moore, 2006; Polifroni and Walker, 2008). Because of the complexity of building a complete end-to-end SDS, these approaches have been evaluated using an “overhearer” methodology in which dialogues are either hand-crafted or simulated and then presented to subjects, either as textual transcripts Introduction Spoken dialogue systems (SDS) that help users find a desired option (e.g., flight, restaurant, movie) from the set of options satisfying their constraints typically present options sequentially, ordered along a default dimension (e.g., by price or departure time). An example is shown in Fig. 1. The user can then navigate through"
W09-3901,P01-1066,0,0.215684,"ntation in the city information domain (modified version of the TownInfo system (Lemon et al., 2006)). and reduced user satisfaction. Thus a major challenge in the development of SDS is to improve information presentation algorithms. This is important for several reasons: (1) to avoid overburdening the user’s memory by presenting too many options; (2) to ensure that the user is given an overview of the available option space so that the optimal option can be found; and (3) to minimise the number of dialogue turns (hence dialogue duration) required for the user to find an acceptable option. As Walker et al. (2001) showed, failing to meet this third goal may reduce overall user satisfaction. Recently several approaches have been proposed to overcome the shortcomings of the sequential enumeration strategy (Polifroni et al., 2003; Chung, 2004; Demberg and Moore, 2006; Polifroni and Walker, 2008). Because of the complexity of building a complete end-to-end SDS, these approaches have been evaluated using an “overhearer” methodology in which dialogues are either hand-crafted or simulated and then presented to subjects, either as textual transcripts Introduction Spoken dialogue systems (SDS) that help users f"
W09-3906,W08-0902,0,0.0188545,"to generate contentful talk (Purandare and Litman, 2008), results in improved learning. However, the systems’ ability to understand student language, and therefore to encourage contentful talk, is limited by the state of current language technology. Moreover, student language may be particularly difficult to interpret since students are often unaware of proper terminology, and may phrase their answers in unexpected ways. For example, a recent error analysis for a domain-independent diagnoser trained on a large corpus showed that a high proportion of errors were due to unexpected paraphrases (Nielsen et al., 2008). In small domains, domain-specific grammars and lexicons can cover most common phrasings used by students to ensure robust interpretation (Aleven, 2003; Glass, 2000). However, as the size of the domain and the range of possible questions and answers grows, achieving complete coverage becomes more difficult. For essays in large domains, statistical methods can be used to identify problems with the answer (Jordan et al., 2006; Graesser et al., 1999), but these approaches do not perform well on relatively short single-sentence explanations, and such systems often revert to short-answer questions"
W09-3906,W07-1207,1,0.880153,"two sentences, but they involve complex linguistic phenomena, including conjunction, negation, relative clauses, anaphora and ellipsis. The system is connected to a knowledge base which serves as a model for the domain and a rea1 Answers to explanation questions are hand-coded by tutors because they are not always required to be logically complete (Dzikovska et al., 2008). However, they are checked for consistency as described later, so they have to be expressed in terms that the knowledge base can reason about. 2 We are using a deep parser that produces semantic analyses of student’s input (Allen et al., 2007). However, these have to undergo further lexical interpretation, so we are treating them as syntactic analyses for purposes of this paper. 40 most frequent sense of “broken” is is-damaged, as in “the bulb is broken”. Ideally, the system lexicon would define “broken” as ambiguous between those two senses. If only the “damaged” sense is defined, the system will arrive at an incorrect interpretation (misunderstanding), which is false by definition, as the is-damaged relation applies only to bulbs in our domain. Thus the system will say “you said that the path is damaged, but that’s not true”. Sin"
W09-3906,2005.sigdial-1.14,0,0.48562,"ing, but the language that can be understood by a computer system is limited by the current technology. Techniques for dealing with understanding problems have been developed primarily for spoken dialogue systems in informationseeking domains, and are not always appropriate for tutorial dialogue. We present a classification of interpretation errors and our approach for dealing with them within an implemented tutorial dialogue system. 1 This paper presents a classification of nonunderstandings, defined as the errors where the system fails to arrive at an interpretation of the user’s utterance (Bohus and Rudnicky, 2005), and a set of strategies for dealing with them in an implemented tutorial dialogue system. Our system differs from many existing systems in two ways. First, all dialogue is typed. This was done in part to avoid speech recognition issues and allow for more complex language input than would otherwise be possible. But it is also a valid modality for tutoring there are now many GUI-based tutoring systems in existence, and as distance and online learning have become more popular, students are increasingly familiar with typed dialogue in chat rooms and discussion boards. Second, different genres im"
W09-3906,J97-1006,0,0.0378857,"reducing the number of misunderstandings over time. This gives us reason to believe that our system can achieve similar effects in tutorial dialogue. While we don’t suggest alternative domain utterances due to the tutoring reasons described earlier, the progressively more specific hints serve a similar function. To what extent this impacts learning and interaction with the system will have to be determined in future evaluations. troubleshooting rather than conceptual knowledge. The SHERLOCK tutor (Katz et al., 1998) used only menu-based input, limiting possible dialogue. Circuit Fix-It Shop (Smith and Gordon, 1997) was a task-oriented system which allowed for speech input, but with very limited vocabulary. Our system’s larger vocabulary and complex input result in different types of non-understandings that cannot be resolved with simple confirmation messages. A number of researchers have developed error taxonomies for spoken dialogue systems (Paek, 2003; M¨oller et al., 2007). Our classification does not have speech recognition errors (since we are using typed dialogue), and we have a more complex interpretation stack than the domain-specific parsing utilized by many SDSs. However, some types of errors"
W09-3906,P02-1011,0,0.0729756,"will still occur - for example, when the system resolves a pronoun incorrectly. Dealing with such situations is planned as part of future work. 3 soning engine. It represents the objects and relationships the system can reason about, and is used to compute answers to factual questions.1 The student answers are processed using a standard NLP pipeline. All utterances are parsed to obtain syntactic analyses.2 The lexical-semantic interpreter takes analyses from the parser and maps them to semantic representations using concepts from the domain model. A reference resolution algorithm similar to (Byron, 2002) is used to find referents for named objects such as “bulb A” and for pronouns. Once an interpretation of a student utterance has been obtained, it is checked in two ways. First, its internal consistency is verified. For example, if the student says “Bulb A will be on because it is in a closed path”, we first must ensure that their answer is consistent with what is on the screen - that bulb A is indeed in a closed path. Otherwise the student probably has a problem either with understanding the diagrams or with understanding concepts such as “closed path”. These problems indicate lack of basic"
W09-3908,W01-0514,1,0.653193,"eriment comparing our algorithm to well-known topic-segmentation algorithms and discuss the results. 4.1 Automatic segmentation in the literature One of the most widely-cited discourse segmentation algorithms is TextTiling (Hearst, 1997). Designed to segment texts into multi-paragraph subtopics, it works by operationalizing the notion of lexical cohesion (Halliday and Hasan, 1976). TextTiling and related algorithms exploit the collocation of semantically related lexemes to measure coherence. Recent improvements to this method include the use of alternative lexical similarity metrics like LSA (Choi et al., 2001) and alternative segmentation methods like the minimum cut model (Malioutov and Barzilay, 2006) and ranking and clustering (Choi, 2000). Recently, Bayesian approaches which model topics as a lexical generative process have been employed (Purver et al., 2006; Eisenstein and Barzilay, 2008). What these algorithms all share is a focus on the semantic content of the discourse. Passonneau and Litman (1997) is another of the most widely-cited articles on discourse segmentation. Their overall approach combines an investigation of prosodic features, cue words, and entity reference. As described above,"
W09-3908,A00-2004,0,0.205432,"ure One of the most widely-cited discourse segmentation algorithms is TextTiling (Hearst, 1997). Designed to segment texts into multi-paragraph subtopics, it works by operationalizing the notion of lexical cohesion (Halliday and Hasan, 1976). TextTiling and related algorithms exploit the collocation of semantically related lexemes to measure coherence. Recent improvements to this method include the use of alternative lexical similarity metrics like LSA (Choi et al., 2001) and alternative segmentation methods like the minimum cut model (Malioutov and Barzilay, 2006) and ranking and clustering (Choi, 2000). Recently, Bayesian approaches which model topics as a lexical generative process have been employed (Purver et al., 2006; Eisenstein and Barzilay, 2008). What these algorithms all share is a focus on the semantic content of the discourse. Passonneau and Litman (1997) is another of the most widely-cited articles on discourse segmentation. Their overall approach combines an investigation of prosodic features, cue words, and entity reference. As described above, their approach to using entity reference is motivated by Centering theory (Grosz et al., 1995) and the hypothesis that intentional str"
W09-3908,de-marneffe-etal-2006-generating,0,0.00840811,"Missing"
W09-3908,poesio-kabadjov-2004-general,0,0.0360775,"Missing"
W09-3908,D08-1035,0,0.0660268,"municative task. The results indicate that there is a difference in granularity between the two tasks, with intentional segmentation relating to finer-grained structure. Hearst’s segments have a mean of about 200 words to P&L’s 40. Also, two hierarchical topic segmentations of meetings (Hsueh, 2008; Gruenstein et al., 2008) have averages above 400 words for the smallest level of segment. To our knowledge, P&L is the only existing study of automatic intention-based segmentation. However, their work has been frequently cited as a study of topic-oriented segmentation, e.g., (Galley et al., 2003; Eisenstein and Barzilay, 2008). Also, recent research in conversational genres (Galley et al., 2003; Hsueh and Moore, 2007) analyze events like discussing an agenda or giving a presentation, which resemble more intentional categories. Interestingly, these algorithms demonstrate the benefit of including non-lexical, non-semantic features. The results imply that further analysis is needed to understand the links between different types of coherence and different types of segmentation. It is important to place our experiment on intentional segmentation in context with the most commonly studied automatic segmentation task: top"
W09-3908,P06-1003,0,0.0262809,"nt texts into multi-paragraph subtopics, it works by operationalizing the notion of lexical cohesion (Halliday and Hasan, 1976). TextTiling and related algorithms exploit the collocation of semantically related lexemes to measure coherence. Recent improvements to this method include the use of alternative lexical similarity metrics like LSA (Choi et al., 2001) and alternative segmentation methods like the minimum cut model (Malioutov and Barzilay, 2006) and ranking and clustering (Choi, 2000). Recently, Bayesian approaches which model topics as a lexical generative process have been employed (Purver et al., 2006; Eisenstein and Barzilay, 2008). What these algorithms all share is a focus on the semantic content of the discourse. Passonneau and Litman (1997) is another of the most widely-cited articles on discourse segmentation. Their overall approach combines an investigation of prosodic features, cue words, and entity reference. As described above, their approach to using entity reference is motivated by Centering theory (Grosz et al., 1995) and the hypothesis that intentional structure is exhibited in the attentional relationships between discourse referents. Hearst and P&L try to achieve different"
W09-3908,J86-3001,0,0.759164,"ies, e.g. tense, aspect, and person deixis, are a useful basis for automatic intentional discourse segmentation. We present a novel algorithm and test our hypothesis on a set of intentionally segmented conversational monologues. Our algorithm performs better than a simple baseline and as well as or better than well-known lexical-semantic segmentation methods. 1 1.1 Participant subjectivity and involvement The approach we take to this problem is founded upon two basic ideas. The first is that the activities we are interested in represent a coarse level of the intentional structure of dialogue (Grosz and Sidner, 1986). In other words, each activity is unified by a common purpose that is shared between the participants. This suggests there may be linguistic properties which are shared amongst the utterances of a given activity episode. The second idea concerns the properties which distinguish different activity types. We propose that activity types may be usefully distinguished according to two complex properties of utterances, both of which concern relationships between the participants and the utterance: participant subjectivity and participant involvement. Participant subjectivity concerns attitudinal an"
W09-3908,J94-2004,0,0.25871,"Missing"
W09-3908,J95-2003,0,0.423716,"atural aggregation of utterances into discourse segments. The attentional state of the dialogue, which contains salient objects and relations and allows for the efficient generation and interpretation of utterances, is then dependent upon this interrelated intentional and linguistic structure in the emerging dialogue. Grosz and Sidner’s theory suggests that attentional state is parasitic upon the underlying intentional structure. This implication has informed many approaches which relate referring expressions (an attentional phenomenon) to discourse structure. One example is Centering theory (Grosz et al., 1995), which concerns the relationship of referring expressions to discourse coherence. Another is P&L, who demonstrated that co-reference and inferred relations between noun phrases are a useful basis for automatic intentional segmentation. Our approach expands on this by highlighting PearStories-09 (Chafe, 1980) 21.2 22.1 22.2 22.3 22.4 23.1 23.2 23.3 23.4 24.1 24.2 24.3 24.4 24.5 24.6 25.1 26.1 26.2 26.3 Background and Related Work okay. Meanwhile, there are three little boys, up on the road a little bit, and they see this little accident. And u-h they come over, and they help him, and you know,"
W09-3908,grover-tobin-2006-rule,0,0.0130278,"outine for automatically extracting the linguistic features which indicate such properties. Finally, the dialogue is segmented at locations of high discontinuity in that feature space. The algorithm works in four phases: pre-processing, feature extraction, similarity measurement, and boundary assignment. 3.2.1 Pre-processing For pre-processing, disfluencies are removed by deleting repeated strings of words and incomplete words. The transcript is then parsed (Klein and Manning, 2002), and a collection of typed grammatical dependencies are generated (de Marneffe et al., 2006). The TTT2 chunker (Grover and Tobin, 2006) is then used to perform tense and aspect tagging. 3.2.2 Feature extraction Feature extraction is the most important and novel part of our algorithm. Each prosodic phrase (the corpus uses prosodic phrases as sentence-like units, see Data section) is assigned values for five binary features. The extracted features correspond to a set of utterance properties which were identified manually through corpus analysis. The first four relate directly to individual activity types and are therefore mutually exclusive properties. 3.2.3 Similarity measurement Similarity measurement is calculated according"
W09-3908,2007.sigdial-1.40,1,0.816781,"tely significant 59 5 Table 2: Results comparing our method to topicoriented segmentation methods. NP-auto Human NM 09 C 99 TEXTTILING Random P (k) .21 .44 .44 .41 .50 κ .58 .11 .08 .05 .00 F1 .65 .24 .22 .18 .15 Rec. .64 .24 .20 .16 .14 Future work in intentional segmentation is needed. Our ultimate goal is to extend this work to more conversational domains (e.g., multi-party planning meetings) and to define the richer set of perspectives and related deictic features that would be needed for them. For example, we hypothesize that the different uses of second-person pronouns in conversations (Gupta et al., 2007) are likely to reflect alternative activity types. Our feature set and extraction methods will therefore need to be further developed to capture this complexity. The other question we would like to address is the relationship between various types of coherence (e.g., topical, referential, perspectival, etc.) and different types (and levels) of discourse structure. Our current approach uses a feature space that is orthogonal to most existing segmentation methods. This has allowed us to gain a deeper understanding of the relationship between certain linguistic features and the underlying intenti"
W09-3908,J97-1003,0,0.580219,"ntentional segmentation in context with the most commonly studied automatic segmentation task: topicbased segmentation. While the two tasks are distinct, the literature has drawn connections between them which can at times be confusing. In this section, we attempt to clarify those connections by pointing out some of their differences and similarities. We also conduct an experiment comparing our algorithm to well-known topic-segmentation algorithms and discuss the results. 4.1 Automatic segmentation in the literature One of the most widely-cited discourse segmentation algorithms is TextTiling (Hearst, 1997). Designed to segment texts into multi-paragraph subtopics, it works by operationalizing the notion of lexical cohesion (Halliday and Hasan, 1976). TextTiling and related algorithms exploit the collocation of semantically related lexemes to measure coherence. Recent improvements to this method include the use of alternative lexical similarity metrics like LSA (Choi et al., 2001) and alternative segmentation methods like the minimum cut model (Malioutov and Barzilay, 2006) and ranking and clustering (Choi, 2000). Recently, Bayesian approaches which model topics as a lexical generative process h"
W09-3908,P07-1128,1,0.851043,", with intentional segmentation relating to finer-grained structure. Hearst’s segments have a mean of about 200 words to P&L’s 40. Also, two hierarchical topic segmentations of meetings (Hsueh, 2008; Gruenstein et al., 2008) have averages above 400 words for the smallest level of segment. To our knowledge, P&L is the only existing study of automatic intention-based segmentation. However, their work has been frequently cited as a study of topic-oriented segmentation, e.g., (Galley et al., 2003; Eisenstein and Barzilay, 2008). Also, recent research in conversational genres (Galley et al., 2003; Hsueh and Moore, 2007) analyze events like discussing an agenda or giving a presentation, which resemble more intentional categories. Interestingly, these algorithms demonstrate the benefit of including non-lexical, non-semantic features. The results imply that further analysis is needed to understand the links between different types of coherence and different types of segmentation. It is important to place our experiment on intentional segmentation in context with the most commonly studied automatic segmentation task: topicbased segmentation. While the two tasks are distinct, the literature has drawn connections"
W09-3908,P06-1004,0,0.0152922,"uss the results. 4.1 Automatic segmentation in the literature One of the most widely-cited discourse segmentation algorithms is TextTiling (Hearst, 1997). Designed to segment texts into multi-paragraph subtopics, it works by operationalizing the notion of lexical cohesion (Halliday and Hasan, 1976). TextTiling and related algorithms exploit the collocation of semantically related lexemes to measure coherence. Recent improvements to this method include the use of alternative lexical similarity metrics like LSA (Choi et al., 2001) and alternative segmentation methods like the minimum cut model (Malioutov and Barzilay, 2006) and ranking and clustering (Choi, 2000). Recently, Bayesian approaches which model topics as a lexical generative process have been employed (Purver et al., 2006; Eisenstein and Barzilay, 2008). What these algorithms all share is a focus on the semantic content of the discourse. Passonneau and Litman (1997) is another of the most widely-cited articles on discourse segmentation. Their overall approach combines an investigation of prosodic features, cue words, and entity reference. As described above, their approach to using entity reference is motivated by Centering theory (Grosz et al., 1995)"
W09-3908,J97-1005,0,0.450864,"c phenomena which express participantrelational properties may be used as an effective means of intentional discourse segmentation. This is based on the idea that if adjacent discourse segments have different activity types, then they are distinguishable by participant-relational features. If we can reliably extract such features, then this would allow segmentation of the dialogue accordingly. We test our hypothesis by constructing an algorithm and examining its performance on an existing set of intentionally segmented conversational monologues (i.e., one person speaks while another listens) (Passonneau and Litman, 1997, henceforth P&L). While our long term goal is to apply our techniques to multi-party conversations (and to a somewhat coarser-grained analysis), using this dataset is a stepping-stone toward that end which allows us to compare our results with existing intentional segmentation algorithms. An example dialogue extract from the dataset is shown in Dialogue 1. Two horizontal lines indicate a segment boundary which was identified by at least 3 of 7 annotators. A single horizontal line indicates a segment boundary which was identified by 2 or fewer annotators. In the exam2 The influential work of G"
W09-3908,P03-1071,0,\N,Missing
W10-1841,W05-0307,0,0.0241778,"es. Our work builds directly upon this work by extending the annotation scheme to all person-referring expressions. course references with a rich set of syntactic, semantic, and pragmatic properties. For example, the DRAMA scheme (Passonneau, 1997) and the GNOME scheme (Poesio, 2000; Poesio, 2004) include labels for features such as bridging relation type and NP type in addition to a rich representation of referent semantics. Other schemes label animacy, prosody, and information structure to study their relationship to the organization and salience of discourse reference (Nissim et al., 2004; Calhoun et al., 2005). Recent developments include the explicit handling of anaphoric ambiguity and discourse deixis (Poesio and Artstein, 2008). Despite the depth and detail of these schemes, participant reference has not been their main concern. The annotations by Poesio et al. (2000; 2004) include dialogue source material, but the rather constrained interactional situations do not elicit a rich set of references to participants. The scheme thus employs simple default labels for words like I and you. The work by Nissim et al., (2004) is an annotation of the Switchboard corpus (Godfrey et al., 1992), which contai"
W10-1841,nissim-etal-2004-annotation,0,0.0276067,"ague or difficult cases. Our work builds directly upon this work by extending the annotation scheme to all person-referring expressions. course references with a rich set of syntactic, semantic, and pragmatic properties. For example, the DRAMA scheme (Passonneau, 1997) and the GNOME scheme (Poesio, 2000; Poesio, 2004) include labels for features such as bridging relation type and NP type in addition to a rich representation of referent semantics. Other schemes label animacy, prosody, and information structure to study their relationship to the organization and salience of discourse reference (Nissim et al., 2004; Calhoun et al., 2005). Recent developments include the explicit handling of anaphoric ambiguity and discourse deixis (Poesio and Artstein, 2008). Despite the depth and detail of these schemes, participant reference has not been their main concern. The annotations by Poesio et al. (2000; 2004) include dialogue source material, but the rather constrained interactional situations do not elicit a rich set of references to participants. The scheme thus employs simple default labels for words like I and you. The work by Nissim et al., (2004) is an annotation of the Switchboard corpus (Godfrey et a"
W10-1841,J97-1002,0,0.0516383,"Missing"
W10-1841,poesio-artstein-2008-anaphoric,0,0.0216077,"urse references with a rich set of syntactic, semantic, and pragmatic properties. For example, the DRAMA scheme (Passonneau, 1997) and the GNOME scheme (Poesio, 2000; Poesio, 2004) include labels for features such as bridging relation type and NP type in addition to a rich representation of referent semantics. Other schemes label animacy, prosody, and information structure to study their relationship to the organization and salience of discourse reference (Nissim et al., 2004; Calhoun et al., 2005). Recent developments include the explicit handling of anaphoric ambiguity and discourse deixis (Poesio and Artstein, 2008). Despite the depth and detail of these schemes, participant reference has not been their main concern. The annotations by Poesio et al. (2000; 2004) include dialogue source material, but the rather constrained interactional situations do not elicit a rich set of references to participants. The scheme thus employs simple default labels for words like I and you. The work by Nissim et al., (2004) is an annotation of the Switchboard corpus (Godfrey et al., 1992), which contains only two participants who are neither co-present nor socially connected. Participant reference is thus rather constraine"
W10-1841,W04-0210,0,0.028816,"tion of the generic/referential distinction, and reference resolution for referential cases. In addition to the generic/referential distinction and an addressing-based reference annotation, the scheme employed special classes for reported speech and fillers and allowed annotators to indicate vague or difficult cases. Our work builds directly upon this work by extending the annotation scheme to all person-referring expressions. course references with a rich set of syntactic, semantic, and pragmatic properties. For example, the DRAMA scheme (Passonneau, 1997) and the GNOME scheme (Poesio, 2000; Poesio, 2004) include labels for features such as bridging relation type and NP type in addition to a rich representation of referent semantics. Other schemes label animacy, prosody, and information structure to study their relationship to the organization and salience of discourse reference (Nissim et al., 2004; Calhoun et al., 2005). Recent developments include the explicit handling of anaphoric ambiguity and discourse deixis (Poesio and Artstein, 2008). Despite the depth and detail of these schemes, participant reference has not been their main concern. The annotations by Poesio et al. (2000; 2004) incl"
W10-1841,doddington-etal-2004-automatic,0,0.00948225,"f the person-referring labeling process in Section 3.4 and present a brief summary of the annotation tool in Section 3.5. Schemes for information extraction In contrast to the schemes described above, which are mainly driven toward investigating linguistic theories of discourse processing, some reference annotation projects are motivated instead by information extraction applications. For these projects (which includes our own), a priority is placed on entity semantics and coreference to known entities in the world. For example, the objective of the Automatic Content Extraction (ACE) program (Doddington et al., 2004) is to recognize and extract entities, events, and relations between them, directly from written and spoken sources, mostly from broadcast news. The schemes thus focus on identifying and labeling the properties of entities in the real world, and then marking expressions as referring to these entities. Recent work in the ACE project has expanded the scope of this task to include cross-document recognition and resolution (Strassel et al., 2008). In the ACE scheme (Linguistic Data Consortium, 2008), per3.1 Source Material The source material is drawn from two source corpora: the AMI corpus (McCow"
W10-1841,W09-3944,0,0.0115386,"solution and reference generation. These schemes have been applied to both text and dialogue and label dis257 son reference is a central component, and in the broadcast conversation component of the corpus there is an extensive inventory of participant references. The annotation scheme contains a distinction between specific, underspecified, and general entities, as well as a distinction between persons and organizations. Another closely related set of studies are four recent investigations of second-person reference resolution (Gupta et al., 2007a; Gupta et al., 2007b; Frampton et al., 2009; Purver et al., 2009). These studies are based upon a common set of annotations of the word you in source material from the Switchboard and ICSI Meeting corpora. The purpose for the annotations was to support learning of classifiers for two main problems: disambiguation of the generic/referential distinction, and reference resolution for referential cases. In addition to the generic/referential distinction and an addressing-based reference annotation, the scheme employed special classes for reported speech and fillers and allowed annotators to indicate vague or difficult cases. Our work builds directly upon this w"
W10-1841,E09-1032,0,0.012947,"oblems like anaphora resolution and reference generation. These schemes have been applied to both text and dialogue and label dis257 son reference is a central component, and in the broadcast conversation component of the corpus there is an extensive inventory of participant references. The annotation scheme contains a distinction between specific, underspecified, and general entities, as well as a distinction between persons and organizations. Another closely related set of studies are four recent investigations of second-person reference resolution (Gupta et al., 2007a; Gupta et al., 2007b; Frampton et al., 2009; Purver et al., 2009). These studies are based upon a common set of annotations of the word you in source material from the Switchboard and ICSI Meeting corpora. The purpose for the annotations was to support learning of classifiers for two main problems: disambiguation of the generic/referential distinction, and reference resolution for referential cases. In addition to the generic/referential distinction and an addressing-based reference annotation, the scheme employed special classes for reported speech and fillers and allowed annotators to indicate vague or difficult cases. Our work build"
W10-1841,strassel-etal-2008-linguistic,0,0.0343313,"Missing"
W10-1841,2007.sigdial-1.40,1,0.850558,"se in the study of discourse processing problems like anaphora resolution and reference generation. These schemes have been applied to both text and dialogue and label dis257 son reference is a central component, and in the broadcast conversation component of the corpus there is an extensive inventory of participant references. The annotation scheme contains a distinction between specific, underspecified, and general entities, as well as a distinction between persons and organizations. Another closely related set of studies are four recent investigations of second-person reference resolution (Gupta et al., 2007a; Gupta et al., 2007b; Frampton et al., 2009; Purver et al., 2009). These studies are based upon a common set of annotations of the word you in source material from the Switchboard and ICSI Meeting corpora. The purpose for the annotations was to support learning of classifiers for two main problems: disambiguation of the generic/referential distinction, and reference resolution for referential cases. In addition to the generic/referential distinction and an addressing-based reference annotation, the scheme employed special classes for reported speech and fillers and allowed annotators to indi"
W10-1841,P07-2027,0,0.0313843,"se in the study of discourse processing problems like anaphora resolution and reference generation. These schemes have been applied to both text and dialogue and label dis257 son reference is a central component, and in the broadcast conversation component of the corpus there is an extensive inventory of participant references. The annotation scheme contains a distinction between specific, underspecified, and general entities, as well as a distinction between persons and organizations. Another closely related set of studies are four recent investigations of second-person reference resolution (Gupta et al., 2007a; Gupta et al., 2007b; Frampton et al., 2009; Purver et al., 2009). These studies are based upon a common set of annotations of the word you in source material from the Switchboard and ICSI Meeting corpora. The purpose for the annotations was to support learning of classifiers for two main problems: disambiguation of the generic/referential distinction, and reference resolution for referential cases. In addition to the generic/referential distinction and an addressing-based reference annotation, the scheme employed special classes for reported speech and fillers and allowed annotators to indi"
W10-4233,gargett-etal-2010-give,1,0.375374,"Missing"
W10-4233,E09-2009,1,0.722559,"in the virtual world. This is in contrast to GIVE-1, where players could only turn by 90 degree increments, and jump forward and backward by discrete steps. This feature of the way the game controls were set Method Following the approach from the GIVE-1 Challenge (Koller et al., 2010), we connected the NLG systems to users over the Internet. In each game run, one user and one NLG system were paired up, with the system trying to guide the user to success in a specific game world. 3.1 Software infrastructure We adapted the GIVE-1 software to the GIVE-2 setting. The GIVE software infrastructure (Koller et al., 2009a) consists of three different modules: The client, which is the program which the user runs on their machine to interact with the virtual world (see Fig. 1); a collection of NLG servers, which generate instructions in real-time and send them to the client; and a matchmaker, which chooses a random NLG server and virtual world for each incoming connection from a client and stores the game results in a database. The most visible change compared to GIVE-1 was to modify the client so it permitted free movement in the virtual world. This change further necessitated a number of modifications to the"
W10-4233,P09-2076,1,0.840837,"in the virtual world. This is in contrast to GIVE-1, where players could only turn by 90 degree increments, and jump forward and backward by discrete steps. This feature of the way the game controls were set Method Following the approach from the GIVE-1 Challenge (Koller et al., 2010), we connected the NLG systems to users over the Internet. In each game run, one user and one NLG system were paired up, with the system trying to guide the user to success in a specific game world. 3.1 Software infrastructure We adapted the GIVE-1 software to the GIVE-2 setting. The GIVE software infrastructure (Koller et al., 2009a) consists of three different modules: The client, which is the program which the user runs on their machine to interact with the virtual world (see Fig. 1); a collection of NLG servers, which generate instructions in real-time and send them to the client; and a matchmaker, which chooses a random NLG server and virtual world for each incoming connection from a client and stores the game results in a database. The most visible change compared to GIVE-1 was to modify the client so it permitted free movement in the virtual world. This change further necessitated a number of modifications to the"
W10-4233,W11-2830,0,\N,Missing
W10-4233,W11-2848,0,\N,Missing
W10-4233,W11-2846,0,\N,Missing
W10-4233,W11-2849,0,\N,Missing
W10-4233,W11-2847,0,\N,Missing
W10-4233,W11-2851,1,\N,Missing
W10-4233,W11-2852,0,\N,Missing
W10-4233,W11-2850,0,\N,Missing
W10-4321,E09-1078,0,0.068512,"Missing"
W10-4321,W09-3916,0,\N,Missing
W10-4321,P06-1024,0,\N,Missing
W10-4321,P09-2005,0,\N,Missing
W10-4321,P08-2013,1,\N,Missing
W11-2019,P10-2009,1,0.932763,"user satisfaction questionnaire using SDS questionnaires for guidance and then apply factor analysis to investigate the underlying dimensions. We compare our results to analyses from two previous studies: SASSI (Hone and Graham, 2000), which is a validated questionnaire intended for use with a variety of task-oriented dialogue systems, and a more recent “modified SASSI” questionnaire which is a version of SASSI adapted for use with the INSPIRE home control system (M¨oller et al., 2007). Henceforth we will refer to this as INSPIRE. 3 B EETLE II Tutorial Dialogue System The goal of B EETLE II (Dzikovska et al., 2010c) is to teach students conceptual knowledge in the domain of basic electricity and electronics. The system is built on the premise that encouraging students to explain their answers and to talk about the domain will lead to improved learning, a finding consistent with analyses of human-human tutoring in several domains (Purandare and Litman, 2008; Litman et al., 2009). B EETLE II has been engineered to test this hypothesis by eliciting contentful talk through explanation questions. The B EETLE II learning material consists of two self-contained lessons suitable for college-level students with"
W11-2019,P10-4003,1,0.874224,"user satisfaction questionnaire using SDS questionnaires for guidance and then apply factor analysis to investigate the underlying dimensions. We compare our results to analyses from two previous studies: SASSI (Hone and Graham, 2000), which is a validated questionnaire intended for use with a variety of task-oriented dialogue systems, and a more recent “modified SASSI” questionnaire which is a version of SASSI adapted for use with the INSPIRE home control system (M¨oller et al., 2007). Henceforth we will refer to this as INSPIRE. 3 B EETLE II Tutorial Dialogue System The goal of B EETLE II (Dzikovska et al., 2010c) is to teach students conceptual knowledge in the domain of basic electricity and electronics. The system is built on the premise that encouraging students to explain their answers and to talk about the domain will lead to improved learning, a finding consistent with analyses of human-human tutoring in several domains (Purandare and Litman, 2008; Litman et al., 2009). B EETLE II has been engineered to test this hypothesis by eliciting contentful talk through explanation questions. The B EETLE II learning material consists of two self-contained lessons suitable for college-level students with"
W11-2041,P10-2009,1,0.883988,"ing down compound questions into individual questions). This resulted in a realistic tutoring setup, which presents interesting challenges to language processing components, involving a wide variety of language phenomena. We demonstrate a version of the system that underwent a user evaluation in 2009, which found significant learning gains for students interacting with the system. The experimental data collection compared two different dialogue policies implemented in the system, and resulted in a corpus supporting research into a variety of questions about humancomputer dialogue interaction (Dzikovska et al., 2010a). 338 Proceedings of the SIGDIAL 2011: the 12th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 338–340, c Portland, Oregon, June 17-18, 2011. 2011 Association for Computational Linguistics Figure 1: Screenshot of the B EETLE II system 2 Example Interaction The B EETLE II system delivers basic electricity and electronics tutoring to students with no prior knowledge of the subject. A screenshot is shown in Figure 1. The student interface includes an area to display reading material, a circuit simulator, and a dialogue history window. Currently all interactions wi"
W11-2041,W11-2019,1,0.74254,"hint about the object that needs to be men339 tioned. Finally, in the last turn the system combines the information from the tutor’s hint and the student’s answers and restates the complete answer since the current answer was completed over multiple turns. 3 Data Analysis and Future Work The data collected with the B EETLE II system has been used to investigate several research questions regarding discourse and dialogue: the effectiveness of different error recovery strategies (Dzikovska et al., 2010b); the underlying dimensions of user satisfaction and their relationship with learning gain (Dzikovska et al., 2011); the relationship between (student) alignment in dialogue and learning gain (Steinhauser et al., 2011); and the differences between students’ social and metacognitive statements depending on the interaction style (Dzikovska et al., 2010a). We are currently annotating the data with additional interaction parameters, including correctness of student answers and appropriateness of system hints. This will allow us to apply PARADISE Tutor: Student: Tutor: Student: Tutor: Student: Tutor: Why was bulb A on when switch Y was open and switch Z was closed? because it had a closed path Right. There is a"
W11-2816,E06-1009,1,\N,Missing
W13-1738,2005.sigdial-1.14,0,0.0304718,"re as the primary evaluation metric. Dzikovska et al. (2013) used a statistical classifier based on lexical overlap, taken from (Dzikovska et al., 2012a), and evaluated 3 different rule-based policies for combining its output with that of the semantic interpreter. In two of those policies the interpreter’s output is always used if it is available, and the classifier’s label is used for a (subset of) noninterpretable utterances: 1. NoReject: the classifier’s label is used in all cases where semantic interpretation fails, thus 2 We will refer to such utterances as “non-interpretable” following (Bohus and Rudnicky, 2005). 295 creating a system that never rejects student input as non-interpretable 2. NoRejectCorrect: the classifier’s label is used for non-interpretable utterances which are labeled as “correct” by the classifier. This more conservative policy aims to ensure that correct student answers are always accepted, but incorrect answers may still be rejected with a request to rephrase. We conducted a new experiment to evaluate these two policies together with an enhanced classifier, discussed in the next section. 3.2 Classifier For this paper, we extended the classifier from the previous study (Dzikovsk"
W13-1738,P10-2009,1,0.904598,"ery policies. 1 Introduction Giving students formative feedback as they interact with educational applications, such as simulated training environments, problem-solving tutors, serious games, and exploratory learning environments, is known to be important for effective learning (Shute, 2008). Suitable feedback can include context-appropriate confirmations, hints, and suggestions to help students refine their answers and increase their understanding of the subject. Providing this type of feedback automatically, in natural language, is the goal of tutorial dialogue systems (Aleven et al., 2002; Dzikovska et al., 2010b; Graesser et al., 1999; Jordan et al., 2006; Litman and Silliman, 2004; Khuwaja et al., 1994; Pon-Barry et al., 2004; VanLehn et al., 2007). Much work in NLP for educational applications has focused on automated answer grading (Leacock Real-time simulations and serious games are commonly used in STEM learning environments to increase student engagement and support exploratory learning (Rutten et al., 2012; Mayo, 2007). Natural language dialogue can help improve learning in such systems by asking students to explain their reasoning, either directly during interaction, or during post-problem r"
W13-1738,P10-4003,1,0.916394,"ery policies. 1 Introduction Giving students formative feedback as they interact with educational applications, such as simulated training environments, problem-solving tutors, serious games, and exploratory learning environments, is known to be important for effective learning (Shute, 2008). Suitable feedback can include context-appropriate confirmations, hints, and suggestions to help students refine their answers and increase their understanding of the subject. Providing this type of feedback automatically, in natural language, is the goal of tutorial dialogue systems (Aleven et al., 2002; Dzikovska et al., 2010b; Graesser et al., 1999; Jordan et al., 2006; Litman and Silliman, 2004; Khuwaja et al., 1994; Pon-Barry et al., 2004; VanLehn et al., 2007). Much work in NLP for educational applications has focused on automated answer grading (Leacock Real-time simulations and serious games are commonly used in STEM learning environments to increase student engagement and support exploratory learning (Rutten et al., 2012; Mayo, 2007). Natural language dialogue can help improve learning in such systems by asking students to explain their reasoning, either directly during interaction, or during post-problem r"
W13-1738,E12-1048,1,0.689421,"ements in Section 4. 2 Background The SRA corpus is made up of two subsets: (1) the SciEntsBank subset, consisting of written responses to assessment questions (Nielsen et al., 2008b), and (2) the Beetle subset consisting of utterances collected from student interactions with the B EETLE II tutorial dialogue system (Dzikovska et al., 2010b). The SRA corpus annotation scheme defines 5 classes of student answers (“correct”, “partially-correct-incomplete”, “contradictory”, “irrelevant” and “non-domain”). Each utterance is assigned to one of the 5 classes based on pre-existing manual annotations (Dzikovska et al., 2012b). We focus on the Beetle subset because the Beetle data comes from an implemented system, meaning that we also have access to the semantic interpretations of student utterances produced by the B EETLE II interpretation component. The system uses finegrained semantic analysis to produce detailed diagnoses of student answers in terms of correct, incorrect, missing and irrelevant parts. We developed a set of rules to map these diagnoses onto the SRA corpus 5-class annotation scheme to support system evaluation (Dzikovska et al., 2012a). In our previous work (Dzikovska et al., 2013), we used thi"
W13-1738,N12-1021,1,0.873526,"ements in Section 4. 2 Background The SRA corpus is made up of two subsets: (1) the SciEntsBank subset, consisting of written responses to assessment questions (Nielsen et al., 2008b), and (2) the Beetle subset consisting of utterances collected from student interactions with the B EETLE II tutorial dialogue system (Dzikovska et al., 2010b). The SRA corpus annotation scheme defines 5 classes of student answers (“correct”, “partially-correct-incomplete”, “contradictory”, “irrelevant” and “non-domain”). Each utterance is assigned to one of the 5 classes based on pre-existing manual annotations (Dzikovska et al., 2012b). We focus on the Beetle subset because the Beetle data comes from an implemented system, meaning that we also have access to the semantic interpretations of student utterances produced by the B EETLE II interpretation component. The system uses finegrained semantic analysis to produce detailed diagnoses of student answers in terms of correct, incorrect, missing and irrelevant parts. We developed a set of rules to map these diagnoses onto the SRA corpus 5-class annotation scheme to support system evaluation (Dzikovska et al., 2012a). In our previous work (Dzikovska et al., 2013), we used thi"
W13-1738,D10-1119,0,0.0283573,"ng the best combination policy in both cases and significantly outperforming the semantic interpreter alone. However, the Sim20NI classifier has the advantage of needing significantly less annotated data to achieve this performance. 4 Discussion and Future Work Our research focuses on combining deep and shallow processing by supplementing fine-grained semantic interpretations from a rule-based system with more coarse-grained classification labels. Alternatively, we could try to learn structured semantic representations from annotated text (Zettlemoyer and Collins, 2005; Wong and Mooney, 2007; Kwiatkowski et al., 2010), or to learn more finegrained assessment labels (Nielsen et al., 2008a). However, such approaches require substantially larger annotation effort. Therefore, we believe it is worth exploring the use of the simpler 5-label annotation scheme from the SRA corpus. We previously showed that it is possible to improve system performance by combining the output of a symbolic interpreter with that of a statistical classifier (Dzikovska et al., 2013). The best combination policy used the statistical classifier to label utterances rejected as non-interpretable by the rule-based interpreter. In this paper"
W13-1738,N04-3002,0,0.269549,"uk Abstract and Chodorow, 2003; Pulman and Sukkarieh, 2005; Mohler et al., 2011). Automated answer assessment systems are commonly trained on large text corpora. They compare the text of a student answer with the text of one or more reference answers supplied by human instructors and calculate a score reflecting the quality of the match. Automated grading methods are integrated into intelligent tutoring systems (ITS) by having system developers anticipate both correct and incorrect responses to each question, with the system choosing the best match (Graesser et al., 1999; Jordan et al., 2006; Litman and Silliman, 2004; VanLehn et al., 2007). Such systems have wide domain coverage and are robust to ill-formed input. However, as matching relies on shallow features and does not provide semantic representations of student answers, this approach is less suitable for dynamically generating adaptive natural language feedback (Dzikovska et al., 2013). We present an experiment aimed at improving interpretation robustness of a tutorial dialogue system that relies on detailed semantic interpretation and dynamic natural language feedback generation. We show that we can improve overall interpretation quality by combini"
W13-1738,P11-1076,0,0.0421391,"Missing"
W13-1738,nielsen-etal-2008-annotating,0,0.15078,"needed without compromising performance of the combined system. The rest of the paper is organized as follows. In Section 2 we describe an architecture for combining semantic interpretation and classification in a system with dynamic natural language feedback generation. In Section 3 we describe an experiment to improve combined system performance using a classifier trained only on non-interpretable utterances. We discuss future improvements in Section 4. 2 Background The SRA corpus is made up of two subsets: (1) the SciEntsBank subset, consisting of written responses to assessment questions (Nielsen et al., 2008b), and (2) the Beetle subset consisting of utterances collected from student interactions with the B EETLE II tutorial dialogue system (Dzikovska et al., 2010b). The SRA corpus annotation scheme defines 5 classes of student answers (“correct”, “partially-correct-incomplete”, “contradictory”, “irrelevant” and “non-domain”). Each utterance is assigned to one of the 5 classes based on pre-existing manual annotations (Dzikovska et al., 2012b). We focus on the Beetle subset because the Beetle data comes from an implemented system, meaning that we also have access to the semantic interpretations of"
W13-1738,W05-0202,0,0.0306536,"Missing"
W13-1738,W10-4344,0,0.0251301,"ntic analysis for the majority of utterances, and falls back on a shallower statistical classifier for utterances that are difficult for the interpreter. This policy assumes that it is always better to use a content-free prompt than to reject a non-interpretable student utterance. How297 ever, interpretation problems can arise from incorrect uses of terminology, and learning to speak in the language of the domain has been positively correlated with learning outcomes (Steinhauser et al., 2011). Therefore, rejecting some non-interpretable answers as incorrect could be a valid tutoring strategy (Sagae et al., 2010; Dzikovska et al., 2010a). The B EETLE II system offers several error recovery strategies intended to help students phrase their answers in more acceptable ways by giving a targeted help message, e.g., “I am sorry, I’m having trouble understanding. Paths cannot be broken, only components can be broken” (Dzikovska et al., 2010a). Therefore, it may be worthwhile to consider other combination policies. We evaluated the NoRejectCorrect policy, which uses the statistical classifier to identify correct answers rejected by the semantic interpreter and asks for rephrasings in other cases. Using this"
W13-1738,P07-1121,0,0.0386351,"F1 , with NoReject being the best combination policy in both cases and significantly outperforming the semantic interpreter alone. However, the Sim20NI classifier has the advantage of needing significantly less annotated data to achieve this performance. 4 Discussion and Future Work Our research focuses on combining deep and shallow processing by supplementing fine-grained semantic interpretations from a rule-based system with more coarse-grained classification labels. Alternatively, we could try to learn structured semantic representations from annotated text (Zettlemoyer and Collins, 2005; Wong and Mooney, 2007; Kwiatkowski et al., 2010), or to learn more finegrained assessment labels (Nielsen et al., 2008a). However, such approaches require substantially larger annotation effort. Therefore, we believe it is worth exploring the use of the simpler 5-label annotation scheme from the SRA corpus. We previously showed that it is possible to improve system performance by combining the output of a symbolic interpreter with that of a statistical classifier (Dzikovska et al., 2013). The best combination policy used the statistical classifier to label utterances rejected as non-interpretable by the rule-based"
W13-1738,C00-2137,0,0.0131529,"g computed from the values of AnswerNeg and BestOverlapNeg. Again, we distinguish three cases: they have the same polarity (both the student answer and the reference answer contain negation markers, or both have no negation markers); they have opposite polarity; or the student answer contains a negation marker associated with an expression of confusion, as described above. 3.3 Evaluation Evaluation results are shown in Table 1. Unless otherwise specified, all performance differences discussed in the text are significant on an approximate randomization significance test with 10,000 iterations (Yeh, 2000). Adding the new features to create the Sim20 classifier resulted in a performance improvement compared to the Sim8 classifier, raising macroaveraged F1 from 0.45 to 0.48, with an improvement in contradiction detection as intended. But these improvements did not translate into improvements in the combined systems. Combinations using Sim20 performed exactly the same as the combinations using Sim8 (not shown due to space limitations, see 296 (Dzikovska et al., 2013)). Clearly, more sophisticated features are needed to obtain further performance gains in the combined systems. However, we noted th"
W18-3306,D15-1303,0,0.215431,"acted at the word level. Before conducting all unimodal and multimodal experiments, we aligned all the features to the word level using the SDK. This down-samples the visual and vocal features to the word level by computing the averaged feature vectors for all frames within a word. 3.4 Modality Fusion Strategies We test four fusion strategies here: Early Fusion (EF), Tensor Fusion Network (TFN), Late Fusion (LF), and Hierarchical Fusion (HF). EF and LF are the most widely used fusion strategies in multimodal recognition studies and were shown to be effective for multimodal sentiment analysis (Poria et al., 2015). TFN achieved state-of-the-art performance on the CMU-MOSI database (Zadeh et al., 2017). HF is a form of hybrid fusion strategy shown to be effective for multimodal emotion recognition (Tian et al., 2016). The structure of the EF model is shown in Figure 3. The feature vectors are simply concatenated in the EF model. A drop-out rate of 0.2 is applied to the combined feature vector. We then stack one layer of 128 LSTM units and three layers of 32 ReLU units with an L2 regularizer weight of 0.01 on top of the multimodal inputs. To compare performance of the fusion strategies, this same structu"
W18-3306,P17-1081,0,0.0122966,"Keras deep learning library (Chollet et al., 2015). 3.3 bedding features provided by the SDK, which are 300-dimensional GloVe word vectors. There are 26,295 words in total (3,107 unique words) in the opinion segments of the CMU-MOSI database. Following Zadeh et al. (2017), for the verbal unimodal model we build a neural network with one layer of 128 Long Short-Term Memory (LSTM) units and one layer of 64 ReLU activation units, as shown in Figure 2. Previous work has found that context information is important for multimodal sentiment analysis, and the use of LSTM allows us to include history (Poria et al., 2017). Multimodal Features Figure 2: Verbal unimodal tri-task model For the vocal modality, we use the COVAREP feature set provided by the SDK. These are 74 vocal features including 12 Mel-frequency cepstral coefficients, pitch tracking and voiced/unvoiced segmenting features, glottal source parameters, peak slope parameters, and maxima dispersion quotients. The vocal features are extracted from the audio recordings at a sampling rate of 100Hz. For the visual modality, we use the FACET feature set provided by the SDK. These are 46 visual features including facial indicators of 9 types of emotion (a"
W18-3306,balahur-etal-2010-sentiment,0,0.0962936,"Missing"
W18-3306,D13-1170,0,0.00352799,", and verbal (e.g., lexical content). These are sometimes referred to as “the three Vs” of communication (Mehrabian et al., 1971). Multimodal sentiment analysis research focuses on understanding how an individual modality conveys sentiment information (intra-modal dynamics), and how they interact with each other (intermodal dynamics). It is a challenging research area and state-of-the-art performance of automatic sentiment prediction has room for improvement compared to human performance (Zadeh et al., 2018a). scales with varying numbers of steps. For example, the Stanford Sentiment Treebank (Socher et al., 2013) used a 7-point Likert scale to annotate sentiments. Such sentiment annotation schemes have two aspects: polarity (positive/negative values) and intensity (steps within the positive or negative range of values). This similarity suggests connections between emotions defined in terms of Valence and Arousal, and sentiments defined with polarity and intensity, as shown in Table 1. However, while previous work on multimodal emotion recognition often predicts Arousal and Valence separately, most previous work on multimodal sentiment analysis generally predicts the sentiment score as a single number."
W18-3306,P18-1208,0,0.0233489,"Missing"
W18-3306,D17-1115,0,\N,Missing
W93-0225,J86-3001,0,0.0821494,"Missing"
W93-0225,J92-4007,1,0.894552,"Missing"
W94-0302,P91-1007,0,0.0754298,"shows that there is nothing in their semantics to prevent them from generating incorrect plans, generating plans with redundant steps, or failing to find plans 2 Representation in Discourse Plans Previous approaches have viewed the discourse planner as a means to producing a specification of a discourse that can be given to a text realization system in order to produce a series of sentences in a natural language. Recent work has shown that plans play a much larger role in agent interaction [16]. In particular, the structure of discourse plans plays a role in the comprehension of the discourse [6, 11, 16] and contributes to the nature of subsequent communication [15, 24]. 2.1 Representing Intentional Structure As has been noted [15, 16, 24], a precise definition of intention in discourse plans is crucial for enabling systems to respond appropiiately to failures of their communicative actions. When a hearer reveals that an in13 7th InternationalGeneration Workshop * Kennebunkport, Maine * June 21-24, 1994 tended effect of a previous discourse did not succeed, the speaker should re-try to achieve that effect. If, however, the effect that failed was not an intended effect, the speaker need not ge"
W94-0302,J93-4004,1,0.603748,") planning systems to represent hierarchical discourse plans. We show how this algorithm, called DPOCL (Decompositional POCL), provides a formal and explicit model of intentional and informational structure in its plans. In addition, we discuss DPOCL's formal properties. Abstract Research in discourse processing has ident~ed two representational requirements for discourse planning systems. First, discourse plans must adequately represent the intentional structure of the utterances they produce in order to enable a computations.] discourse agent to respond effectively to communicative failures [15]. Second, discourse plans must represent the information~ structure of utterances. In addition to these representational requirements, we argue that discourse planners ahonid be formally characterizab]e in terms of soundness and completeness. 1 Introduction Research in discourse processing has identified two representational requirements for discourse planning systems. First, discourse plans must adequately represent the ino tentionai structure of the utterances they produce in order to enable a computational discourse agent to respond effectively to communicative failures [15]. Second, discou"
W94-0302,J92-4007,1,0.851282,"Missing"
W94-0302,P92-1050,0,0.0113253,"e plans must adequately represent the ino tentionai structure of the utterances they produce in order to enable a computational discourse agent to respond effectively to communicative failures [15]. Second, discourse plans must represent the informational structure of utterances. Discourse interpretation requires that an agent be able to recognize the relationships between the information conveyed in consecutive elements of discourse (e.g., [7, 16]). Choosing syntactic structures and connective markers that convey these relationships requires that a discourse generator represent informational [19, 21, 22] as well as intentional [4] structure. Because there is not a fixed, one-to-one mapping between intentional and informational structures, discourse plans must include an explicit representation of both types of structure [15, 16]. In addition to these representational requirements, we argue that discourse planners should meet certain computational requirements. Most current discourse planners are based on the original NOAH [20] model of hierarchical planning [1, 2, 9, 13, 15]. These systems rely on customized planning algorithms with procedural semantics for the purposes of solving specific te"
W94-0302,C90-3018,0,0.0568278,"e ino tentionai structure of the utterances they produce in order to enable a computational discourse agent to respond effectively to communicative failures [15]. Second, discourse plans must represent the informational structure of utterances. Discourse interpretation requires that an agent be able to recognize the relationships between the information conveyed in consecutive elements of discourse (e.g., [7, 16]). Choosing syntactic structures and connective markers that convey these relationships requires that a discourse generator represent informational [19, 21, 22] as well as intentional [4] structure. Because there is not a fixed, one-to-one mapping between intentional and informational structures, discourse plans must include an explicit representation of both types of structure [15, 16]. In addition to these representational requirements, we argue that discourse planners should meet certain computational requirements. Most current discourse planners are based on the original NOAH [20] model of hierarchical planning [1, 2, 9, 13, 15]. These systems rely on customized planning algorithms with procedural semantics for the purposes of solving specific text-planning problems. The i"
W94-0302,J86-3001,0,0.702918,"rarchical planning. They rely on customized planning algorithms with pr0cedurai semantics for the purposes of solving specific text-planning problems, and thus their representations and algorithms suffer from being unprincipled and difficult to analyze. Although these systems have resulted in successful text generation for specific domains and text types, careful analysis of these programs shows that there is nothing in their semantics to prevent them from generating incorrect plans, generating plans with redundant steps, or failing to find plans in situations where they exist. As Hovy et ai. [8] point out, these problems stem from an approach to discourse planning that does not clearly distinguish between the representation of communicative action and the design of a planning algorithm that manipulates that representation. In most previous work, there has been no clear separation between the knowledge about the preconditions and effects of communicative acts and the knowledge about planning used to construct discourse plans. To the extent that these planners have been able to avoid generating incorrect or redundant plans, they have done so by severely limiting the expressive power of"
W96-0509,W90-0111,0,0.0301958,"Missing"
W96-0509,W94-0302,1,0.889601,"Missing"
W96-0509,J86-3001,0,\N,Missing
W98-0210,W96-0501,0,0.0681644,"Missing"
W98-0210,W96-0406,0,0.176725,"Missing"
W98-0210,W98-1403,1,0.80227,"Missing"
W98-1403,C94-1086,0,0.0424359,"Missing"
W98-1403,W96-0501,0,0.139461,"Missing"
W98-1403,W96-0406,0,0.161923,"Missing"
W98-1403,W98-0210,1,0.802348,"Missing"
W98-1403,P83-1007,0,0.137782,"Missing"
W98-1403,J95-3003,0,0.0529492,"Missing"
W98-1403,P97-1027,0,0.0311588,"Missing"
W98-1403,P86-1029,0,0.607367,"Missing"
W98-1403,P97-1026,0,0.125619,"Missing"
whittaker-etal-2002-fish,P00-1020,1,\N,Missing
whittaker-etal-2002-fish,P01-1066,1,\N,Missing
