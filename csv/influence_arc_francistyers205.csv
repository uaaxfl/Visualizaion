2009.eamt-1.17,P97-1032,0,0.309899,"Missing"
2009.eamt-1.17,C90-3030,0,0.0290991,"to tense in Lule Sámi, but not in North Sámi. This is due to the fact, that Lule Sámi has different present tense and past tense forms of the verb. North Sámi, on the other hand only has one form to express both present and past tense. The tense distinction is made by means of the main verb following the negation verb as in ii boade ¯ (‘he/she does not come’) and ii boahtán (‘he/she did not come’). ii 2.1.2 Disambiguation (Constraint Grammar) Disambiguation of morphological and shallow syntactic tags is handled by the North Sámi parser. The parser uses Constraint Grammar, a formalism based on Karlsson (1990) and Karlsson (1995) and further developed by Tapanainen (1996) and Bick (2000). The approach is bottom-up, which means that all input (ideally) receives one or more analyses. Those analyses are then one by one removed except for the last reading, which is never removed. The parser uses the output of the morphological transducer as an input and adds shallow syntactic tags. Syntax tags do not only function as the basis of a dependency tree structure representation, but also disambiguate morphology, e.g. homonymous genitive and accusative forms are distinguished on the level of syntax (genitive"
2009.eamt-1.29,2007.mtsummit-papers.40,0,0.0629827,"Missing"
2009.eamt-1.29,W08-0309,0,0.0316494,"exicon. In example 2, another kind of extension could be used by the decoder. In French, inflected verbs require the presence of subject pronouns, whereas in Breton this is not the case. This may lead to alignment errors were taken. The first was to simply add the bilingual transfer lexicon from the system to the end of the training data. This consisted of 10,797 lemmata. The second was to automatically generate appropriate mappings between all of the surface forms of the given lemmata in the dictionaries of this system. There has been existing research in this area, for example Dugast et al. (2008) generated a parallel corpus from a rule-based system to train a phrase-based system, and Schwenk (2009) uses an inflected dictionary to produce training data for a statistical system, albeit in a well resourced language pair (French–English). In order to generate the surface-form mappings, an expansion of all possible surface forms was taken, along with analyses in the Breton morphological analyser. These analyses were then passed through the rest of the Apertium pipeline in or215 Evaluation and error analysis System system 1 system 2 system 3 system 4 Description word-for-word baseline phras"
2009.freeopmt-1.3,2005.mtsummit-osmtw.2,1,0.834247,"Missing"
2009.freeopmt-1.3,J82-2005,0,0.74795,"Missing"
2009.freeopmt-1.3,2001.mtsummit-papers.14,0,0.379014,"Missing"
2009.freeopmt-1.3,2005.mtsummit-osmtw.4,1,0.894947,"Missing"
2009.freeopmt-1.3,carreras-etal-2004-freeling,0,0.0349938,"lan (ca) and es and Galician (gl). The MT engine and tools in Apertium were not built from scratch, but are rather the result of a complete FOS rewriting and extension of two existing MT systems developed by the Transducens group at the Universitat d’Alacant, namely interNOSTRUM4 (Canals-Marote et al., 2001) (es– ca) and Traductor Universia5 (Garrido-Alenda et al., 2004) (es–Portuguese (pt)),to provide a platform to build MT systems for related languages. Linguistic data for the initial language pairs were built combining in-house resources with FOS data such as the ones present in Freeling6 (Carreras et al., 2004). cian, Catalan (also called Valencian), and Occitan (Aranese). Other languages such as Asturian or Aragonese have a more limited legal status. 2 This consortium, which involved 4 universities (Universitat d’Alacant, Universitat Polit`ecnica de Catalunya, Universidade de Vigo and Euskal Herriko Unibertsitatea) 2 companies (Eleka Ingeniaritza Linguistikoa, imaxin|software) and 1 Foundation (Elhuyar) adopted the name Opentrad during the project. Currently this name is used as a trademark by some of the companies in the original consortium to commercialize machine translation services based on Ap"
2009.freeopmt-1.3,2005.eamt-1.12,1,0.880475,"Missing"
2009.freeopmt-1.3,2007.tmi-papers.22,1,0.893387,"Missing"
2009.freeopmt-1.3,2009.eamt-1.29,1,0.815961,"Missing"
2009.freeopmt-1.3,2009.eamt-1.17,1,0.865984,"Missing"
2009.freeopmt-1.3,J08-3010,0,\N,Missing
2009.freeopmt-1.4,2009.freeopmt-1.4,1,0.0512826,"Missing"
2009.freeopmt-1.4,W04-1511,0,0.220769,"Missing"
2009.freeopmt-1.4,2006.amta-papers.25,0,0.0893192,"Missing"
2009.freeopmt-1.4,E09-2008,0,0.0969758,"Missing"
2009.freeopmt-1.4,W06-3114,0,0.0739245,"Missing"
2009.freeopmt-1.4,2006.amta-papers.26,0,0.275721,"Missing"
2009.freeopmt-1.4,2007.mtsummit-papers.40,0,0.595587,"Missing"
2009.freeopmt-1.4,przybocki-etal-2006-edit,0,0.246963,"Missing"
2009.freeopmt-1.4,2009.eamt-1.9,1,\N,Missing
2009.freeopmt-1.6,2005.mtsummit-papers.11,0,0.00373666,"For proper names, toponyms etc., we used the method described in Tyers and Pienaar (2008) to extract translations from Wikipedia. • Changes in auxiliary verbs – There are some verbs in Swedish which do not take the same auxiliary verb in forming periphrastic verb forms as in Danish, for example in Swedish Tv˚a personer har b¨orjat ‘Two people has begun’ translated to Danish To personer er begyndt ‘Two people has begun’ (literally, ‘Two people are begun’). • Probabilistic dictionary – Finally, we trained a statistical machine translation system using Moses (Koehn et al., 2007) on the Europarl (Koehn, 2005) parallel corpus. From this we took the probabilistic lexicon, and performed the same operation as with the wordlists above. In doing this we simply took the most probable translation that was in both the Swedish and Danish monolingual dictionaries. • Changes in passive formation – In Swedish, certain verbs in the passive (sl˚a ‘hit’, ligga ‘lie’, anta ‘suppose’, . . . ) must be translated in Danish using an inflected form of the verb blive ‘become’ in the active voice and the past participle. All bilingual dictionary entries were manually checked and bad entries altered or discarded. It is wo"
2009.freeopmt-1.6,P07-2045,0,0.00487056,"e was being believed’. • Wikipedia – For proper names, toponyms etc., we used the method described in Tyers and Pienaar (2008) to extract translations from Wikipedia. • Changes in auxiliary verbs – There are some verbs in Swedish which do not take the same auxiliary verb in forming periphrastic verb forms as in Danish, for example in Swedish Tv˚a personer har b¨orjat ‘Two people has begun’ translated to Danish To personer er begyndt ‘Two people has begun’ (literally, ‘Two people are begun’). • Probabilistic dictionary – Finally, we trained a statistical machine translation system using Moses (Koehn et al., 2007) on the Europarl (Koehn, 2005) parallel corpus. From this we took the probabilistic lexicon, and performed the same operation as with the wordlists above. In doing this we simply took the most probable translation that was in both the Swedish and Danish monolingual dictionaries. • Changes in passive formation – In Swedish, certain verbs in the passive (sl˚a ‘hit’, ligga ‘lie’, anta ‘suppose’, . . . ) must be translated in Danish using an inflected form of the verb blive ‘become’ in the active voice and the past participle. All bilingual dictionary entries were manually checked and bad entries"
2010.eamt-1.13,2009.eamt-1.29,1,0.898781,"the noun plays an important part in the system of initial consonant mutations. For example, feminine singular nouns mutate after the definite article, bro ‘country’ and ar vro ‘the country’, but masculine singular nouns do not, mor ‘boat’ ar mor ‘the sea’. Adjectives inflect for comparative, superlative and There have been two releases of the system (apertium-br-fr), the first one is version 0.1, which was released in May of 2009, and the second is version 0.2, released in March of 2010. Also mentioned in the paper are the results from the prototype word-for-word system that was presented in Tyers (2009). 2 Development The system is based on the Apertium machine translation platform.2 The platform was originally aimed at the Romance languages of the Iberian peninsula, but has also been adapted for other language pairs, and in particular languages from the Celtic group, e.g. Welsh (Tyers and Donnelly, 2009). The whole platform, both programs and data, are licensed under the Free Software Foundation’s General Public Licence3 (GPL) and all the software and data for the 22 supported language pairs (and the other pairs being worked on) is available for download from the project website. The initia"
2011.eamt-1.22,W04-0108,0,0.0435844,"Missing"
2011.eamt-1.22,W04-3250,0,0.183678,"Missing"
2011.eamt-1.22,laureys-etal-2004-evaluation,0,0.0699736,"Missing"
2011.eamt-1.30,A00-1031,0,0.0363154,"for unknown words, i.e. words not known to the dictionary, is guessed by applying rules based on morphological suffixes and endings. IceMorphy does not generate word forms, it only carries out analysis. • IceTagger: A linguistic rule-based PoS tagger (Loftsson, 2008). The tagger produces disambiguated morphosyntactic tags from the tagset of the IFD corpus. The tagger uses IceMorphy for morphological analysis and applies both local rules and heuristics for disambiguation. • TriTagger: A statistical PoS tagger. This trigram tagger is a re-implemenation of the well-known HMM tagger described by Brants (2000). It is trained on the IFD corpus. • Lemmald: A lemmatiser (Ingason et al., 2008). The method used combines a datadriven method with linguistic knowledge to maximise accuracy. Wallenberg, 2008; Loftsson et al., 2009) has shown that the morphological complexity of the Icelandic language, and the relatively small training corpus in relation to the size of the tagset, is to blame for a rather low tagging accuracy (compared to related languages). Taggers that are purely based on machine learning (including HMM trigram taggers) have not been able to produce high accuracy when tagging Icelandic text"
2011.eamt-1.30,P08-2009,0,0.0620785,"Missing"
2011.eamt-1.30,2009.freeopmt-1.3,1,0.840521,"advantages, e.g. it is data-driven, language independent, does not need linguistic experts, and prototypes of new systems can by built quickly and at a low cost. On the other hand, the need for parallel corpora as training data in SMT is also its main disadvantage, because such corpora are not available for a myriad of languages, especially the so-called less-resourced languages, i.e. languages for which few, if any, natural language processing (NLP) resources are available. When there is a lack of parallel corpora, other machine translation (MT) methods, such as rule-based MT, e.g. Apertium (Forcada et al., 2009), may be used to create MT systems. In this paper, we describe the development of a prototype of an open source rule-based Icelandic→English (is-en) MT system based on Apertium and IceNLP, an NLP toolkit for processing and analysing Icelandic texts (Loftsson and Rögnvaldsson, 2007b). A decade ago, the Icelandic language could have been categorised as a less-resourced language. The current situation, however, is much better thanks to the development of IceNLP and various linguistic resources (Rögnvaldsson et al., 2009). On the other hand, no large parallel corpus, in which Icelandic is one of t"
2011.eamt-1.30,W07-2419,0,0.190914,"Missing"
2011.eamt-1.30,W09-4616,0,0.0274821,"Missing"
2011.eamt-1.30,2009.freeopmt-1.6,1,0.837974,". Based on our error analysis, we conclude that better translation quality may be achieved by replacing only the tagging component of Apertium with the corresponding module in IceNLP, but leaving morphological analysis to Apertium. We think that our work can be viewed as a guideline for other researchers wanting to develop hybrid MT systems based on Apertium. 2 Apertium The Apertium shallow-transfer MT platform was originally aimed at the Romance languages of the Iberian peninsula, but has also been adapted for other languages, e.g. Welsh (Tyers and Donnelly, 2009) and Scandinavian languages (Nordfalk, 2009). The whole platform, both programs and data, is free and open source and all the software and data for the supported language pairs is available for download from the project website5 . The Apertium platform consists of the following main modules: • A morphological analyser: Performs tokenisation and morphological analysis which for a given surface form returns all of the possible lexical forms (analyses) of the word. morphologically analysed words, chooses the most likely sequence of PoS tags. • Lexical selection: A lexical selection module based on Constraint Grammar (Karlsson et al., 1995)"
2011.freeopmt-1.12,E06-1032,0,0.0135857,"Apertium is approximately ten absolute points over Google for TER and GTM. For these metrics Apertium-i is between the other two systems, roughly four points below Apertium and six over Google. The differences in GTM both between Apertium and Apertium-i and between Apertium-i and Google are significant. 7 http://www.ark.cs.cmu.edu/MT/ http://www.computing.dcu.ie/ ˜nstroppa/index.php?page=softwares 9 http://translate.google.com 8 On the other hand, Google is the best system according to BLEU and NIST scores. It is worth mentioning that these metrics are known to be biased towards SMT systems (Callison-Burch and Osborne, 2006). Google obtains 1.69 absolute BLEU points over Apertium but the difference is not statistically significant. With respect to NIST, the difference is of 0.44 points and it is significant. Apertium is significantly better than Apertium-i both for BLEU (7.98 points) and for NIST (1.18 points). 5 Conclusions This paper has presented an Italian→Catalan RBMT system obtained by automatically deriving its linguistic data from existing Italian– Spanish and Catalan–Spanish systems. Only a limited amount of manual work was carried out to (i) correct the inconsistencies found in the resulting dictionarie"
2011.freeopmt-1.12,A92-1018,0,0.0157289,"s and propose lines of future work. 2 Background Apertium is an open-source rule-based machine translation platform initially built for related lanF. S´ anchez-Mart´ınez, J.A. P´ erez-Ortiz (eds.) Proceedings of the Second International Workshop on Free/Open-Source Rule-Based Machine Translation, p. 77–81 Barcelona, Spain, January 2011. http://hdl.handle.net/10609/5650 guage pairs (such as Spanish–Portuguese), but later expanded to deal with more divergent pairs. It uses finite-state transducers (Roche and Schabes, 1997) for lexical processing, hidden Markov models for part-of-speech tagging (Cutting et al., 1992), and multi-stage finite-state chunking for structural transfer. The linguistic data needed to create a machine translation system between two languages in Apertium are: morphological dictionaries for the source language and for the target language, a bilingual dictionary, structural transfer rules and a tagger definition file with optional linguistic restrictions to train an optimal statistical part-ofspeech tagger. Since its first version in 2005, the number of language pairs available has grown steadily and today (as of 20th November, 2010) there are 25 released stable language pairs, with"
2011.freeopmt-1.12,2005.mtsummit-papers.11,0,0.193007,"nt words that are missing according to a corpus analysis. The system is evaluated on the KDE4 corpus and outperforms Google Translate by approximately ten absolute points in terms of both TER and GTM. 1 existing language pairs. Our approach builds an MT system for a language pair a–b given existing systems for the language pairs a–c and b–c. Specifically, we have built a new language pair for the Apertium RBMT engine, Italian–Catalan, by exploiting the existing Spanish–Italian and Catalan–Spanish language pairs. It is worth mentioning the lack of parallel resources for Catalan (e.g. Europarl (Koehn, 2005) is the most widely used resource of parallel documents for European languages, but it does not cover Catalan). Our motivation can be then summarised by the following two basic ideas: • RBMT is a competitive and useful approach for those languages for which there are no parallel corpora available (Forcada, 2006). • Reutilising data from similar existing language pairs can significantly reduce the amount of work required to build a new language pair. Introduction One of the most common criticisms towards RuleBased Machine Translation (RBMT) regards the amount of work necessary to build a system"
2011.freeopmt-1.12,J10-4005,0,0.0128417,"rallel corpora available (Forcada, 2006). • Reutilising data from similar existing language pairs can significantly reduce the amount of work required to build a new language pair. Introduction One of the most common criticisms towards RuleBased Machine Translation (RBMT) regards the amount of work necessary to build a system for a new language pair (Somers, 2003). In fact, in a traditional scenario, linguists with expertise in the source and target language need to manually build all the dictionary entries and transfer rules. Conversely, in the Statistical Machine Translation (SMT) approach (Koehn, 2010), no such effort is required as the system can be automatically built from parallel corpora. However, this approach is only applicable for those language pairs for which big amounts of parallel text are available. In this paper we present an automatically built RBMT system by exploiting linguistic data from ∗ This research has been partially funded by the EU project PANACEA (7FP-ITC-248064). The rest of the paper is structured as follows. The following section presents the RBMT system Apertium, emphasising on approaches that consider reuse of resources and automatic acquisition of linguistic d"
2011.freeopmt-1.12,P02-1040,0,0.0829786,"Missing"
2011.freeopmt-1.12,2006.amta-papers.25,0,0.0374957,"Missing"
2011.freeopmt-1.12,tiedemann-nygaard-2004-opus,0,0.0803559,"Missing"
2011.freeopmt-1.12,2003.mtsummit-papers.51,0,0.0739646,"Missing"
2011.freeopmt-1.12,2009.eamt-1.17,1,0.83112,"tion pairs and for other language technologies. Source-language morphological dictionaries are theoretically independent from the target language, although in practice some bias does exist towards the target language; bilingual dictionaries and structural transfer rules have to be created specifically for each translation pair. Several papers describe the creation of data for new Apertium language pairs, using a variety of approaches, including the reuse of existing free/open source resources (S´anchez-Mart´ınez et al., 2008; S´anchez-Mart´ınez and Forcada, 2009; Ginest´ı-Rosell et al., 2009; Tyers et al., 2009; Tyers and Donnelly, 2009; Unhammer and Trosterud, 2009) and the use of Crossdics (Armentano and Forcada, 2008),2 a program provided in the Apertium platform that, given two existing systems between the language pairs a– c and b–c, is used to obtain dictionaries for a new translation pair a–b. This is the method we used to 1 wiki.apertium.org http://wiki.apertium.org/wiki/ Crossdics 2 create the Italian–Catalan translation pair, using the available Apertium translation pairs Spanish– Italian and Spanish–Catalan. According to (Armentano and Forcada, 2008), using Crossdics to cross dictionaries"
2011.freeopmt-1.12,2009.freeopmt-1.7,0,0.0147808,". Source-language morphological dictionaries are theoretically independent from the target language, although in practice some bias does exist towards the target language; bilingual dictionaries and structural transfer rules have to be created specifically for each translation pair. Several papers describe the creation of data for new Apertium language pairs, using a variety of approaches, including the reuse of existing free/open source resources (S´anchez-Mart´ınez et al., 2008; S´anchez-Mart´ınez and Forcada, 2009; Ginest´ı-Rosell et al., 2009; Tyers et al., 2009; Tyers and Donnelly, 2009; Unhammer and Trosterud, 2009) and the use of Crossdics (Armentano and Forcada, 2008),2 a program provided in the Apertium platform that, given two existing systems between the language pairs a– c and b–c, is used to obtain dictionaries for a new translation pair a–b. This is the method we used to 1 wiki.apertium.org http://wiki.apertium.org/wiki/ Crossdics 2 create the Italian–Catalan translation pair, using the available Apertium translation pairs Spanish– Italian and Spanish–Catalan. According to (Armentano and Forcada, 2008), using Crossdics to cross dictionaries and adding some manual work to correct and improve the r"
2012.eamt-1.54,2011.eamt-1.30,1,0.817279,"sible solutions would be to generate all possible combinations of translations, and score them on a language model of the target language. This approach is taken in the METIS - II system (Melero et al., 2007). This has the benefit of being easy to implement, and only requiring a bilingual dictionary and a monolingual target language corpus. It has the drawbacks of being both slow – many translations must be performed – and not very customisable – control over the final translation is left to the TL model. Another possible solution, and one that is already used in some Apertium language pairs (Brandt et al., 2011; Wiechetek et al., 2010) is to use constraint grammar (Karlsson et al., 1995) rules to choose between possible alternative translations. An advantage of this is that the constraint grammar formalism is well known, and powerful, allowing context searches of unlimited size. However, it is too slow to be able to be used for production systems, as the speed is in the order of a few hundred words per second as opposed to thousands of words per second for the slowest Apertium module. Another approach not requiring a parallel corpus is presented by Dagan and Itai (1994). They first parse the SL sent"
2012.eamt-1.54,2007.tmi-papers.6,0,0.0412968,"he most adequate sense. Thus, it is not necessary to choose between a series of finegrained senses if all these senses result in the same final translation. The dominant approach to MT for language pairs with sufficient training data is phrase-based statistical machine translation; in this approach, lexical selection is performed by a combination of coocurrence in the phrase table, and score from the targetlanguage model (Koehn, 2010). There have however been attempts to improve on this by looking at global lexical selection over the whole sentence, see e.g. (Venkatapathy and Bangalore, 2007; Carpuat and Wu, 2007). In order to test different approaches to lexical selection for RBMT, we use the Apertium (Forcada et al., 2011) platform. This free/open-source platform includes 30 language pairs (as of February 2012). Sánchez-Martínez et al. (2007) describe a method to perform lexical selection in Apertium based on training a source-language bag-of-words model using TL cooccurrence statistics. This approach was tested, but abandoned as it produced less adequate translations than using the translation marked as default by a linguist in the bilingual dictionary. Other possible solutions would be to generate"
2012.eamt-1.54,J94-4003,0,0.61255,"n some Apertium language pairs (Brandt et al., 2011; Wiechetek et al., 2010) is to use constraint grammar (Karlsson et al., 1995) rules to choose between possible alternative translations. An advantage of this is that the constraint grammar formalism is well known, and powerful, allowing context searches of unlimited size. However, it is too slow to be able to be used for production systems, as the speed is in the order of a few hundred words per second as opposed to thousands of words per second for the slowest Apertium module. Another approach not requiring a parallel corpus is presented by Dagan and Itai (1994). They first parse the SL sentence and extract syntactic relations, such as verb + object, they then translate these with a bilingual dictionary and use collocation statistics from a TL corpus to choose the most adequate translation. While this method does not rely on the existence of a parallel corpus, it does depend on some way of identifying SL syntactic relations – which may not be available in all RBMT systems. The rest of the paper is laid out as follows: Section 2 presents some design decisions that were made in the development of the module. Section 3 describes in detail the rule forma"
2012.eamt-1.54,J03-1002,0,0.00473992,"found in the Apertium monolingual dictionary. We use version 6.0 of the EuroParl corpus (Koehn, 2005), and take the first 1.4 million lines for training.1 We used the Apertium English to Spanish pair apertium-en-es2 as it is one of the few pairs that has dictionaries with more than one alternative translation per word.3 4.1 Learning lexical selection rules from a parallel corpus The procedure to learn rules from a parallel corpus is as follows: We first morphologically analyse and disambiguate for part-of-speech both the SL and TL sides of the corpus. These are then word-aligned with GIZA++ (Och and Ney, 2003). 1 The remaining lines were held out for future use. Available from http://wiki.apertium.org/wiki/ SVN; SVN revision: 35684 3 The lexical selection module is available as free/open-source software in the package apertium-lex-tools. This paper uses SVN revision: 35799 2 217 We then pass the SL side of the corpus through the lexical-transfer stage of the MT system we are learning the rules for; this gives three sets of sentences: the tagged SL sentences, the tagged TL sentences and the possible translations of the SL words into the TL yielded by the bilingual dictionary. We take these three set"
2012.eamt-1.54,P02-1040,0,0.0913672,"Missing"
2012.eamt-1.54,W04-3250,0,0.276079,"Missing"
2012.eamt-1.54,2005.mtsummit-papers.11,0,0.049944,"a parallel corpus, and test the module on a well-known task for the evaluation of MT. The experimental setup follows the training of the baseline system in the shared task on MT at WMT11 (Callison-Burch et al., 2011), with the following differences: In place of the default Moses perl-based tokeniser, tokenisation was done using the Apertium morphological analyser (CortésVaíllo and Ortiz-Rojas, 2011). The corpus was also not lowercased; instead the case of known words was changed to the dictionary case as found in the Apertium monolingual dictionary. We use version 6.0 of the EuroParl corpus (Koehn, 2005), and take the first 1.4 million lines for training.1 We used the Apertium English to Spanish pair apertium-en-es2 as it is one of the few pairs that has dictionaries with more than one alternative translation per word.3 4.1 Learning lexical selection rules from a parallel corpus The procedure to learn rules from a parallel corpus is as follows: We first morphologically analyse and disambiguate for part-of-speech both the SL and TL sides of the corpus. These are then word-aligned with GIZA++ (Och and Ney, 2003). 1 The remaining lines were held out for future use. Available from http://wiki.ape"
2012.eamt-1.54,J10-4005,0,0.0209504,"age (TL). The task is related to the task of word-sense disambiguation (Ide and Véronis, 1998). The difference is that its aim is to find the most adequate translation, not the most adequate sense. Thus, it is not necessary to choose between a series of finegrained senses if all these senses result in the same final translation. The dominant approach to MT for language pairs with sufficient training data is phrase-based statistical machine translation; in this approach, lexical selection is performed by a combination of coocurrence in the phrase table, and score from the targetlanguage model (Koehn, 2010). There have however been attempts to improve on this by looking at global lexical selection over the whole sentence, see e.g. (Venkatapathy and Bangalore, 2007; Carpuat and Wu, 2007). In order to test different approaches to lexical selection for RBMT, we use the Apertium (Forcada et al., 2011) platform. This free/open-source platform includes 30 language pairs (as of February 2012). Sánchez-Martínez et al. (2007) describe a method to perform lexical selection in Apertium based on training a source-language bag-of-words model using TL cooccurrence statistics. This approach was tested, but aba"
2012.eamt-1.54,W07-0413,0,0.0277975,"e most adequate translation, not the most adequate sense. Thus, it is not necessary to choose between a series of finegrained senses if all these senses result in the same final translation. The dominant approach to MT for language pairs with sufficient training data is phrase-based statistical machine translation; in this approach, lexical selection is performed by a combination of coocurrence in the phrase table, and score from the targetlanguage model (Koehn, 2010). There have however been attempts to improve on this by looking at global lexical selection over the whole sentence, see e.g. (Venkatapathy and Bangalore, 2007; Carpuat and Wu, 2007). In order to test different approaches to lexical selection for RBMT, we use the Apertium (Forcada et al., 2011) platform. This free/open-source platform includes 30 language pairs (as of February 2012). Sánchez-Martínez et al. (2007) describe a method to perform lexical selection in Apertium based on training a source-language bag-of-words model using TL cooccurrence statistics. This approach was tested, but abandoned as it produced less adequate translations than using the translation marked as default by a linguist in the bilingual dictionary. Other possible solution"
2012.eamt-1.54,H05-1097,0,0.430219,"Missing"
2012.eamt-1.54,2004.tmi-1.9,0,0.114922,"Missing"
2012.freeopmt-1.6,2011.freeopmt-1.9,0,0.047555,"Missing"
2013.mtsummit-papers.22,2007.mtsummit-papers.61,0,0.389198,"o provide high accuracy in its translations, but being a prototype system by design, had relatively low coverage. Besides these systems, several previous works on making machine translation systems between Turkic languages exist, although to our knowledge none are publicly available except for the Turkish–Azerbaijani pair available through Google Translate.1 Some MT systems have been reported that translate between Turkish and other Turkic languages, including Turkish– Crimean Tatar (Altintas, 2001b), Turkish–Azerbaijani (Hamzaoğlu, 1993), Turkish–Tatar (Gilmullin, 2008), and Turkish–Turkmen (Tantuğ et al., 2007), though none of these have been released to a public audience. 3 Languages Both Tatar and Kazakh belong to the Kypchak (or Northwestern) group of Turkic languages. The spoken and written languages share some level of mutual intelligibility to native speakers, though this is somewhat limited, and is obscured by different orthographical conventions and some opaque correspondences. Kazakh is primarily spoken in Kazakhstan, where it is the national language, sharing official status with Russian as an official language. Large communities of native speakers also exist in China, neighbouring Central"
2013.mtsummit-papers.22,2012.eamt-1.54,1,0.895618,"ar; Section 4 describes the system and the tools used to construct it; Section 5 gives a preliminary evaluation of the system; and finally Section 6 describes our aims for future work and some concluding remarks. 2 Previous work Within the Apertium project, work on several MT systems between Turkic languages has been started (Turkish–Kyrgyz, Azeri–Turkish, Tatar–Bashkir), but the Kazakh–Tatar system described by the present study is the closest to production-ready of them. Among these systems is a prototype Tatar–Bashkir machine translation system which was built by the authors of this paper (Tyers et al., 2012a); due to the closeness of these languages, it proved to provide high accuracy in its translations, but being a prototype system by design, had relatively low coverage. Besides these systems, several previous works on making machine translation systems between Turkic languages exist, although to our knowledge none are publicly available except for the Turkish–Azerbaijani pair available through Google Translate.1 Some MT systems have been reported that translate between Turkish and other Turkic languages, including Turkish– Crimean Tatar (Altintas, 2001b), Turkish–Azerbaijani (Hamzaoğlu, 1993)"
2013.mtsummit-papers.22,washington-etal-2012-finite,1,0.844833,"ansducers The morphological transducers are based on the Helsinki Finite State Toolkit (Linden et al., 2011), a free/opensource reimplementation of the Xerox finite-state toolchain, popular in the field of morphological analysis. It implements both the lexc formalism for defining lexicons, and the twol and xfst formalisms for modeling morphophonological rules. It also supports other finite state transducer formalisms such as sfst. This toolkit has been chosen as it — or the equivalent XFST — has been widely used for other Turkic languages (Çöltekin, 2010; Altintas, 2001a; Tantuğ et al., 2006; Washington et al., 2012; Tyers et al., 2012a), and is available under a free/open-source licence. The morphologies of both languages are implemented in lexc, and the morphophonologies of both languages are implemented in twol. Use of lexc allows for straightforward definition of different word classes and subclasses. For example, Tatar (but not Kazakh) has two classes of verbs: one which takes a harmonised high vowel in the infinitive (the default), and one which takes a harmonised low vowel in the infinitive. Class membership cannot be predicted based on any phonological criteria and is simply a lexical property of"
2013.mtsummit-papers.22,coltekin-2010-freely,0,0.13353,"as it moves through the pipeline. 4.2 Morphological transducers The morphological transducers are based on the Helsinki Finite State Toolkit (Linden et al., 2011), a free/opensource reimplementation of the Xerox finite-state toolchain, popular in the field of morphological analysis. It implements both the lexc formalism for defining lexicons, and the twol and xfst formalisms for modeling morphophonological rules. It also supports other finite state transducer formalisms such as sfst. This toolkit has been chosen as it — or the equivalent XFST — has been widely used for other Turkic languages (Çöltekin, 2010; Altintas, 2001a; Tantuğ et al., 2006; Washington et al., 2012; Tyers et al., 2012a), and is available under a free/open-source licence. The morphologies of both languages are implemented in lexc, and the morphophonologies of both languages are implemented in twol. Use of lexc allows for straightforward definition of different word classes and subclasses. For example, Tatar (but not Kazakh) has two classes of verbs: one which takes a harmonised high vowel in the infinitive (the default), and one which takes a harmonised low vowel in the infinitive. Class membership cannot be predicted based o"
2015.eamt-1.19,2000.tc-1.5,0,\N,Missing
2015.eamt-1.20,J96-1002,0,0.220719,"actually lexical selection in MT; they used a parser to identify syntactic relations such as subject–object or subject–verb. After generating all the possible translations for a given input sentence using an ambiguous bilingual dictionary, they extract the syntactic tuples from the TL and count the frequency in a previously-trained TL model of tuples. They use maximum-likelihood estimation to calculate the probability that a given 1 145 Such as a morphological or syntactic analyser. TL tuple is the translation of a given SL tuple, with an automatically determined confidence threshold. Later, Berger et al. (1996) illustrated the use of maximum-entropy classifiers on the specific problem of lexical selection in IBM-style word-based statistical MT. Other authors (Melero et al., 2007) have used TL models to rank the translations resulting from all possible combinations of lexical selections. Nowadays, in state-of-the-art phrasebased statistical MT (Koehn, 2010), lexical selection is taken care of by a combination of the translation model and the language model. The translation model provides probabilities of translation between words or word sequences (often referred to as phrases) in the source and targ"
2015.eamt-1.20,J94-4003,0,0.491982,"mputational cost. 1 Mikel L. Forcada Dept. Lleng. i Sist. Inform., Universitat d’Alacant, E-03071 Alacant 1.1 Introduction Corpus-based machine translation (MT) has been the primary research direction in the field of MT in recent years. However, rule-based MT (RBMT) systems are still being developed, and there are many successful commercial and non-commercial systems. One reason for the continued development of RBMT systems is that in order to be successful, c 2015 The authors. This article is licensed under a Creative Commons 3.0 licence, no derivative works, attribution, CCBY-ND. Prior work Dagan and Itai (1994) used the term word sense disambiguation to refer to what is actually lexical selection in MT; they used a parser to identify syntactic relations such as subject–object or subject–verb. After generating all the possible translations for a given input sentence using an ambiguous bilingual dictionary, they extract the syntactic tuples from the TL and count the frequency in a previously-trained TL model of tuples. They use maximum-likelihood estimation to calculate the probability that a given 1 145 Such as a morphological or syntactic analyser. TL tuple is the translation of a given SL tuple, wi"
2015.eamt-1.20,W04-3250,0,0.0634887,"module returns more than one translation, Apertium will select the default one if marked or the first one of not.12 The table in Figure 2 gives an overview of the inputs.In the description it is assumed that the reference translation has been annotated by hand. However, hand annotation is a time-consuming process, and was not possible. A description of how the reference was built is given in Section 3.4. diff(Tr (si ), Tt (si )) = 3.3.2 3.3.3 Confidence intervals Confidence intervals for both metrics will be calculated through bootstrap resampling (Efron and Tibshirani, 1994) as described by Koehn (2004). In all cases, bootstrap resampling will be carried out for 1,000 iterations. Where the p = 0.05 confidence intervals overlap, we will also perform paired bootstrap resampling (Koehn, 2004). 3.4 For creating the test corpora, providing a SL corpus for training, and a TL corpus for scoring, we used four parallel corpora: • Ofis ar Brezhoneg (OAB): This parallel corpus of Breton and French has been collected specifically for lexical-selection experiments from translations produced by Ofis ar Brezhoneg ‘The Office of the Breton language’. The corpus has recently been made available online throug"
2015.eamt-1.20,2005.mtsummit-papers.11,0,0.020643,"is ar Brezhoneg ‘The Office of the Breton language’. The corpus has recently been made available online through OPUS.13 • South-East European Times (SETimes): Described in Tyers and Alperen (2010), this corpus is a multilingual corpus of the Balkan languages (and English) in the news domain. The Macedonian and English part will be used. • Open Data Euskadi (OpenData): This is a Basque–Spanish parallel corpus made from the translation memories of the Herri Arduralaritzaren Euskal Erakundea ‘Basque Institute of Public Administration’.14 • European Parliament Proceedings (EuroParl): Described by Koehn (2005), this is a multilingual corpus of the European Union official languages. We are using the English–Spanish data from version 7.15 Machine translation performance This is an extrinsic evaluation, which ideally would test how much the system improves as regards an approximate measurement of final translation quality in a real system. For this task, we use the widely-used BLEU metric (Papineni et al., 2002). This is not ideal for evaluating the task of a lexical selection module as the performance of the module will depend greatly on (a) the coverage of the bilingual dictionaries of the RBMT syst"
2015.eamt-1.20,J10-4005,0,0.0126561,"use maximum-likelihood estimation to calculate the probability that a given 1 145 Such as a morphological or syntactic analyser. TL tuple is the translation of a given SL tuple, with an automatically determined confidence threshold. Later, Berger et al. (1996) illustrated the use of maximum-entropy classifiers on the specific problem of lexical selection in IBM-style word-based statistical MT. Other authors (Melero et al., 2007) have used TL models to rank the translations resulting from all possible combinations of lexical selections. Nowadays, in state-of-the-art phrasebased statistical MT (Koehn, 2010), lexical selection is taken care of by a combination of the translation model and the language model. The translation model provides probabilities of translation between words or word sequences (often referred to as phrases) in the source and target language. The TL model provides probabilities of word sequences in the TL. Mareˇcek et al. (2010) trained a maximum-entropy lexical selector for their dependency-grammar-based transfer system TectoMT using a bilingual corpus. More recently, Tyers et al. (2012) presented a method of lexical selection for RBMT based on rules which select or remove t"
2015.eamt-1.20,P07-2045,0,0.00877625,"cluded to show the upper bound for the performance of the lexical-selection module. • Target language model (TLM). One method of lexical selection is to use the existing MT system to generate all the possible translations for an input sentence, and then score these translations on-line on a model of the TL. The highest scoring sentence is then output. This is the method used by Melero et al. (2007). 4 Results As we are working with binary features, we use the implementation of generalised iterative scaling 16 The exact configuration of GIZA ++ used is equivalent to running the M OSES toolkit (Koehn et al., 2007) in default configuration up to step three of training. 17 The development corpus was used for checking the value for frequency pruning of features. 150 Pair br-fr mk-en eu-es en-es Lines 57,305 190,493 765,115 1,467,708 Extract. 4,668 19,747 87,907 312,162 train 2,668 17,747 85,907 310,162 dev 1,000 1,000 1,000 1,000 test 1,000 1,000 1,000 1,000 No. amb 603 13,134 1,806 2,082 Av. amb 3.06 3.06 3.11 2.28 Table 1: Statistics about the source corpora. The column no. amb gives the number of unique tokens with more than one possible translation. The column av. amb gives the average number of trans"
2015.eamt-1.20,W10-1730,0,0.0445016,"Missing"
2015.eamt-1.20,P14-2123,0,0.0132542,"arrain    0 otherwise (1) This feature considers a context of zero words to the left of the problem word and one word (+ handi) to the right of it. As a result of training, each of the nF features hsk (t, c) in the classifier is assigned a weight λsk . Combining these weights of active features as in equation (2) yields the probability of a translation t for word s in context c. n ps (t|c) = (2) k=1 In this equation, Z s (c) is a normalising constant. Thus, the most probable translation t? can be found using t? = arg max ps (t|c) = arg max t∈Ts (s) 2 The work by Ravi and Knight (2011) and Nuhn and Ney (2014), who decipher word-ciphered text using monolingual corpora only may be seen as a generalised version of the problem of lexical selection without parallel corpora. F X 1 exp λsk hsk (t, c) Z s (c) nF X λsk hsk (t, c), t∈Ts (s) k=1 (3) 3 146 We follow the notation of Berger et al. (1996) S→ preposti=|G| → ({gi }i=1 , S) → lexsel → (g ? , S) → → τ (g ? , S) lexsel lexsel Figure 1: A schema of the lexical selection process: source sentence S has |G |lexical selection paths gi : lexsel selects one of them g ? , which is used to generate translation τ (g ? , S). where Ts (s) is the set of possible"
2015.eamt-1.20,J03-1002,0,0.00850824,"ough for all pairs there is a parallel corpus available for evaluation (see Section 3.3).5 Breton–French (Tyers, 2010): Bilingual dictionaries were not built with polysemy in mind from the outset, but some entries were added later to start work on lexical selection.6 Macedonian–English: The Macedonian–English pair in Apertium was created specifically for the purposes of running lexical-selection experiments. The lexical resources for the pair were tuned to the SETimes parallel corpus (Tyers and Alperen, 2010). The most probable entry from automatic word alignment of this corpus using GIZA ++ (Och and Ney, 2003) was checked to ensure that it was an adequate translation, and if so marked as the default.7 As a result of attempting to include all possible translations, the average number of translations per word is much higher than in other pairs.8 Basque–Spanish (Ginest´ı-Rosell et al., 2009): alternative translations were included in the bilingual dictionary.9 English–Spanish: The English–Spanish pair was developed from a combination of the English– Catalan and Spanish–Catalan pairs, and contains a number of entries in the bilingual dictionary with more than one translation.10 3.3 Performance measures"
2015.eamt-1.20,P02-1040,0,0.100052,"Missing"
2015.eamt-1.20,P11-1002,0,0.0207978,"andi (t, c) = handi follows arrain    0 otherwise (1) This feature considers a context of zero words to the left of the problem word and one word (+ handi) to the right of it. As a result of training, each of the nF features hsk (t, c) in the classifier is assigned a weight λsk . Combining these weights of active features as in equation (2) yields the probability of a translation t for word s in context c. n ps (t|c) = (2) k=1 In this equation, Z s (c) is a normalising constant. Thus, the most probable translation t? can be found using t? = arg max ps (t|c) = arg max t∈Ts (s) 2 The work by Ravi and Knight (2011) and Nuhn and Ney (2014), who decipher word-ciphered text using monolingual corpora only may be seen as a generalised version of the problem of lexical selection without parallel corpora. F X 1 exp λsk hsk (t, c) Z s (c) nF X λsk hsk (t, c), t∈Ts (s) k=1 (3) 3 146 We follow the notation of Berger et al. (1996) S→ preposti=|G| → ({gi }i=1 , S) → lexsel → (g ? , S) → → τ (g ? , S) lexsel lexsel Figure 1: A schema of the lexical selection process: source sentence S has |G |lexical selection paths gi : lexsel selects one of them g ? , which is used to generate translation τ (g ? , S). where Ts (s)"
2015.eamt-1.20,2010.eamt-1.13,1,0.827828,"uild RBMT systems. Translation is implemented as a pipeline consisting of the following modules: morphological analysis, morphological disambiguation, lexical transfer, lexical selection, structural transfer and morphological generation. 3.2 Language pairs Evaluation will be performed using four Apertium (Forcada et al., 2011) language pairs. These pairs have been selected as they include languages with different morphological complexity, and different amounts of resources available — although for all pairs there is a parallel corpus available for evaluation (see Section 3.3).5 Breton–French (Tyers, 2010): Bilingual dictionaries were not built with polysemy in mind from the outset, but some entries were added later to start work on lexical selection.6 Macedonian–English: The Macedonian–English pair in Apertium was created specifically for the purposes of running lexical-selection experiments. The lexical resources for the pair were tuned to the SETimes parallel corpus (Tyers and Alperen, 2010). The most probable entry from automatic word alignment of this corpus using GIZA ++ (Och and Ney, 2003) was checked to ensure that it was an adequate translation, and if so marked as the default.7 As a r"
2015.eamt-1.20,2012.eamt-1.54,1,0.760078,"Missing"
2015.eamt-1.20,H05-1097,0,0.0896984,"Missing"
2018.jeptalnrecital-court.1,K17-3009,0,0.0616854,"Missing"
2018.jeptalnrecital-court.1,2009.eamt-1.29,1,0.794347,"Missing"
2020.iwclul-1.2,W13-5610,0,0.0217225,"egmentation (producing the stem plus list of aﬃxes). Still, a given surface form may have several possible analyses and several possible segmentations. Uralic languages are highly agglutinative, that is, inﬂection is often performed by appending suﬃxes to the lemma. For such languages, stemming and lemmatisation agree, allowing one dimension of comparison between morphological analysers and surface segmenters. Such agglutinative languages typically do not have all surface forms listed in a dictionary; users wishing to look up a word must lemmatise before performing the lookup. Software tools (Johnson et al., 2013) are being developed to combine the lemmatisation and lookup operations. Further, most Uralic languages are low-resourced, meaning large corpora (necessary for the training of some analysers and segmenters) are not readily available. In such cases, software engineers, linguists and system designers must decide whether to invest eﬀort in obtaining a large enough corpus for statistical methods or in writing rulesets for a rule-based system. Abstract Uralilaisten kielten sanakirjahakuihin tarvitaan lemmatisoijia, jotka tulevat tarpeeseen kielenoppijan etsiessä sanan perusmuotoa. Tutkimme miten pä"
2020.iwclul-1.5,L18-1530,0,0.220498,"Missing"
2020.iwclul-1.5,W17-0109,1,0.910499,"language model edits the neural network’s output and the hyper-parameter beta controls the cost of inserting word breaks. A 4.2 DeepSpeech The transcriptions are in a Cyrillic writing system that follows the rules of Komi orthography. A similar system has been used in a recent Komi dialect dictionary (Безносикова et al., 2012). This convention was selected for various reasons, both practical and methodological. Having the results of language documentation work in written standard, when it exists, makes the work accessible for the community and allows better integration of language technology (Gerstenberger et al., 2017a,b). This is also obvious with the current study, as the speech recognition system that operates with the orthography is arguably more useful for the community than one which outputs a transcription system that only specialists in the ﬁeld can easily understand. That being said, the use of orthography also makes some tasks such as speech recoghttps://github.com/mozilla/DeepSpeech/releases/tag/v0.5.1 33 the transferred layers, provides the best boost in performance. We therefore follow suit, and cut oﬀ two layers and allow ﬁne-tuning for our transfer models. For convenience, we used English a"
2020.iwclul-1.5,W11-2123,0,0.0873203,"ow ﬁne-tuning for our transfer models. For convenience, we used English as the source language because it ships with DeepSpeech and is known to have good results. Languages with comparable performance which are historically related to Komi, such as the main contact language Russian, provide potential avenues of research worth further experimentation. A language model is a critical piece of DeepSpeech because it corrects for the fact that every character in the orthography is not pronounced in natural speech. We generated out n-gram trie language model, as in Hannun et al. (2014), using kenlm (Heaﬁeld, 2011) with the default parameters. Because a language model is trained on unlabeled text, we can train it on a much larger corpus than the speech dataset. Our corpus is composed of several books, newspaper articles, an old Wikipedia dump, and the Komi Republic website. These are all in the standard, modern Zyrian orthography. We found that the quantity of data provided by these various sources was more eﬀective than using the transcriptions from our data. Because the language model is applied to the output of the neural network, it can be tuned separately. Therefore, in the interest of time, we tra"
2020.lrec-1.314,E09-2008,0,0.670021,"collected data and the scripts which were created for mapping the transcription to Cyrillic words and segmentation are available at the repository with the developed analyser.8 Most Evenki examples in this paper are taken from the Siberian Lang corpora. If an example is from the other source, the source is specified. 2.2. Existing morphological analysers This section describes two existing morphological analysers for Evenki, evenkiMorph and the Evenki analyser from IEA RAS. evenkiMorph 9 is a morphological analyser, which was developed by means of a free/open-source finite-state toolkit foma (Hulden, 2009). It is able to produce analyses for the open classes of nouns, adjectives, verbs, adverbs, and numerals. Function words are not included. The lexicon contains 17,500 words with Russian translation. The lexc file consists of 40 continuation lexica.10 Phonological rewrite rules consist of 16 rules that cover most common morphological alternations, such as consonant assimilation and i-epenthesis. The transducer processes words in an ASCII phonetic string format. Words in Cyrillic can be converted to the required format using a Python script which is provided with the analyser. An example of the"
2020.lrec-1.314,K17-3009,0,0.0302676,"ey contain either an affix -мӣ о-мӣ ‘to do’ or end with a hyphen, indicating a bare stem о-. In the latter case the stems can also belong to other parts of speech, and for this reason the extracted stems were proofread, however, they needed only a small number of corrections. 16 http://www.evengus.ru/prilozheniya/ lingvo/ 17 http://evenkiteka.ru/ In order to determine the part of speech of other words, Russian translations were used. If a translation was a phrase, then the head of the phrase was chosen. POS-tagging and dependency parsing was produced using Russian-SynTagRus, a UDPipe model (Straka and Straková, 2017) for Russian. In most cases nouns and adjectives were defined correctly, however, some adjectives, adverbs, participles and converbs were also determined as nouns, so the resulting lists of words were checked and corrected. As for the drawbacks of the OCR version of the dictionary (Myreeva et al., 2004), not all symbols were recognized, so the process of extracting words and their definitions required also fixing unrecognized symbols. Apart from that, many words in the OCR version do not have vowel length marks in comparison to the original dictionary in pdf format. In order to reduce the numb"
2020.lrec-1.474,W17-0237,0,0.066613,"Missing"
2020.lrec-1.474,C90-3030,0,0.159528,"f unseen tokens. We have tested both Laplace smoothing and Simple Good-Turing methods to generate a secondary weightlist for the tokens that weren’t part of the training corpus. So, this unigram-counts based model will end-up generating two different weightlists: • A weightlist based on the unigram counts of each analysis in the corpus. • A default weightlist based on Laplace smoothing or simple Good-Turing smoothing. 4.1.2. Constraint Grammar-based weightlist A constraint grammar is a set of rules for selecting or removing certain analyses given the lexical forms of the previous/next tokens (Karlsson, 1990). For English, a constraint grammar might have a rule that selects the infinitive analysis of a verb if it’s preceded by the word to. The rule written in CG-3 format will be ""SELECT Inf IF (0C V) (-1C To) ;"" which can interpreted as select 3844 the infinitive analysis if the current token is a verb and the previous token is to. Given a large unannotated corpus, First the list of candidate analyses for the whole corpus is generated. Then, the Constraint Grammar is used to filter the lists of analyses. The remaining candidate analyses are considered to be a tagged corpus that is used to estimate"
2020.lrec-1.474,C16-1018,0,0.0149672,"The research demonstrated how using unsupervised rules can lead to better models. The author’s intuition is to favor compounds with less number of segments. Then, using a training corpus, the uni-gram counts of token-compound pairs are used to disambiguate between compounds having the same number of segments. S´anchez-Mart´ınez et al. (2008) developed a way to build a part of speech tagger / disambiguator by training a Hidden Markov Model that is used in a pipeline of a machine translator. The authors proved how making use of information from the target language yields better disambiguators. Shen et al. (2016) explored the usage of deep learning techniques for the morphological disambiguation task through Long short term-memory(LSTM)-based neural architectures depending on features extracted from the word and its context. They used two different Embedding models, One for the list of candidate analyses of the token and the other for the context’s words and their respective analyses. These deep learning models depend on having large tagged data-sets that can be used to optimize the cost function. 3. 0 e:e/0 1 u:u/0 2 r:r/0 3 o:o/0 4 ε:&lt;n&gt;/0 5 ε:&lt;sg&gt;/0 ε:&lt;pl&gt;/0 Background Finite state transducers can"
2020.lrec-1.474,ui-dhonnchadha-van-genabith-2006-part,0,0.159659,"Missing"
2020.lrec-1.474,washington-etal-2014-finite,1,0.793207,"are larger than those of the first one such that those paths are less favorable. Additionally, The final and default weightlist makes use of Laplace Smoothing such that every path that was part of the unweighted FST is added to the final weighted FST. 5. Experiments Different weighting methods are implemented as a set of shell scripts and Python 3 scripts 1 . Apertium’s lttoolbox (lexical toolbox) and hfst are used to apply different FST operations and transformations. Linguistic resources such as: unweighted morphological analyzers, tagged corpora and constraint grammars for English, Kazakh (Washington et al., 2014) and Serbo-Croatian2 that were used throughout the experiments are actually available as part of Apertium’s resources. 5.1. Word2vec models Word2vec model has two common architectures: Continous Bag of Words (CBoW) and Skip-gram (SG). According to the results reached by Mikolov et al. (2013) on the Semantic-Syntactic Word Relationship test set, Models based on the skip-gram architecture perform better on semantic similarity tasks while the continuous bag of words perform better on syntactic similarity tasks. In our model, we are more interested in using word2vec models that can find the words"
2020.lrec-1.474,N06-1042,0,0.14848,"Missing"
2020.lrec-1.497,de-marneffe-etal-2006-generating,1,\N,Missing
2020.lrec-1.497,zeman-2008-reusable,1,\N,Missing
2020.lrec-1.497,de-marneffe-etal-2014-universal,1,\N,Missing
2020.lrec-1.497,W08-1301,1,\N,Missing
2020.lrec-1.497,petrov-etal-2012-universal,0,\N,Missing
2020.lrec-1.497,P13-1051,1,\N,Missing
2020.lrec-1.497,P15-2111,0,\N,Missing
2020.lrec-1.497,L16-1376,1,\N,Missing
2020.lrec-1.497,L16-1262,1,\N,Missing
2020.lrec-1.497,W18-6012,1,\N,Missing
2020.lrec-1.520,fiscus-etal-2006-multiple,0,0.0829245,"5 26.42 33.83 43.20 24.92 43.76 5 17.96 24.98 31.94 18.42 29.74 35.10 30.38 28.63 36.41 43.19 25.28 43.69 Table 3: Fine-Tuned Transfer Learning Character Error Rate for each language, in addition to a baseline trained from scratch on the target language data. Bolded values display best model per language. Shading indicates relative performance per language, with darker indicating better models. The results from all experiments can be found in Table (3). Each cell in the table contains the Character Error Rate (CER)12 of the resulting model on the test set, defined as the Levenshtein distance (Fiscus et al., 2006) of the characters between the ground-truth transcript and the decoding result. The results in Table (3) show how the number of layers transfered (columns) influence the performance on individual target languages (rows). Shaded cells indicate relative performance per language, where a darker cell represents a more accurate model. From this table we observe a trend in which four layers copied from pre-trained English DeepSpeech result in the best final model. This trend becomes more obvious in Figure (5), where we average the improvement over all languages relative to the number of layers trans"
2020.sigmorphon-1.1,K18-3001,1,0.899071,"logical reinflection, we specifically focus on typological diversity and aim to investigate systems’ ability to generalize across typologically distinct languages many of which are low-resource. For example, if a neural network architecture works well for a sample of IndoEuropean languages, should the same architecture also work well for Tupi–Guarani languages (where nouns are “declined” for tense) or Austronesian languages (where verbal morphology is frequently prefixing)? 2 Task Description The 2020 iteration of our task is similar to CoNLL-SIGMORPHON 2017 (Cotterell et al., 2017) and 2018 (Cotterell et al., 2018) in that participants are required to design a model that learns to generate inflected forms from a lemma and a set of morphosyntactic features that derive the desired target form. For each language we provide a separate training, development, and test set. More historically, all of these tasks resemble the classic “wug”-test that Berko (1958) developed to test child and human knowledge of English nominal morphology. Unlike the task from earlier years, this year’s task proceeds in three phases: a Development Phase, a Generalization Phase, and an Evaluation Phase, in which each phase introduces"
2020.sigmorphon-1.1,K17-2001,1,0.928876,"e SIGMORPHON shared task on morphological reinflection, we specifically focus on typological diversity and aim to investigate systems’ ability to generalize across typologically distinct languages many of which are low-resource. For example, if a neural network architecture works well for a sample of IndoEuropean languages, should the same architecture also work well for Tupi–Guarani languages (where nouns are “declined” for tense) or Austronesian languages (where verbal morphology is frequently prefixing)? 2 Task Description The 2020 iteration of our task is similar to CoNLL-SIGMORPHON 2017 (Cotterell et al., 2017) and 2018 (Cotterell et al., 2018) in that participants are required to design a model that learns to generate inflected forms from a lemma and a set of morphosyntactic features that derive the desired target form. For each language we provide a separate training, development, and test set. More historically, all of these tasks resemble the classic “wug”-test that Berko (1958) developed to test child and human knowledge of English nominal morphology. Unlike the task from earlier years, this year’s task proceeds in three phases: a Development Phase, a Generalization Phase, and an Evaluation Pha"
2020.sigmorphon-1.1,W09-0106,0,0.0385713,"n variably surface as prefixes, suffixes, infixes, or circumfixes (Dryer, 2013). Most Eurasian and Australian languages strongly favor suffixation, and the same holds true, but to a lesser extent, for South American and New Guinean languages (Dryer, 2013). In Mesoamerican languages and African languages spoken below the Sahara, prefixation is dominant instead. These are just three dimensions of variation in morphology, and the cross-linguistic variation is already considerable. Such cross-lingual variation makes the development of natural language processing (NLP) applications challenging. As Bender (2009, 2016) notes, many current architectures and training and tuning algorithms still present language-specific biases. The most commonly used language for developing NLP applications is English. Along the above dimensions, English is productively concatenative, a mixture of analytic and synthetic, and largely suffixing in its inflectional morphology. With respect to languages that exhibit inflectional morphology, English is relatively impoverished.1 Importantly, English is just one morphological system among many. A larger goal of natural language processing is that the system work for any prese"
2020.sigmorphon-1.1,2020.lrec-1.344,1,0.878264,"Missing"
2020.sigmorphon-1.1,2020.sigmorphon-1.15,0,0.0565092,"Missing"
2020.sigmorphon-1.1,2020.sigmorphon-1.14,0,0.0439232,"Missing"
2020.sigmorphon-1.1,L16-1379,0,0.0190826,"Missing"
2020.sigmorphon-1.1,K17-2010,1,0.837279,"l baselines were based on a neural transducer (Wu and Cotterell, 2019), which is essentially a hard monotonic attention model (mono-*). The second baseline is a transformer (Vaswani et al., 2017) adopted for character-level tasks that currently holds the state-of-the-art on the 2017 SIGMORPHON shared task data (Wu et al., 2020, trm-*). Both models take the lemma and morphological tags as input and output the target inflection. The baseline is further expanded to include the data augmentation technique used by Anastasopoulos and Neubig (2019, -aug-) (conceptually similar to the one proposed by Silfverberg et al. (2017)). Relying on a simple characterlevel alignment between lemma and form, this technique replaces shared substrings of length &gt; 3 with random characters from the language’s alphabet, producing hallucinated lemma–tag–form triples. Both neural baselines were trained in mono- (*-single) and multilingual (shared parameters among the same family, *-shared) settings. 6 Many teams based their models on the transformer architecture. NYU-CUBoulder experimented with a vanilla transformer model (NYU-CUBoulder-04-0), a pointer-generator transformer that allows for a copy mechanism (NYU-CUBoulder-02-0), and"
2020.sigmorphon-1.1,2020.sigmorphon-1.4,0,0.0612223,"Missing"
2020.sigmorphon-1.1,W19-4207,0,0.0125147,"c attention model with improved alignment strategy. This model is further improved (flexica-03-1) by introducing a data hallucination technique which is based on phonotactic modelling of extremely low-resource languages (Shcherbakov et al., 2016). LTI focused on their earlier model (Anastasopoulos and Neubig, 2019), a neural multi-source encoder–decoder with two-step attention architecture, training it with hallucinated data, cross-lingual transfer, and romanization of scripts to improve performance on low-resource languages. DeepSpin reimplemented gated sparse two-headed attention model from Peters and Martins (2019) and trained it on all languages at once (massively multilingual). The team experimented with two modifications of the softmax function: sparsemax (Martins and Astudillo, 2016, deepspin-02-1) and 1.5-entmax (Peters et al., 2019, deepspin-01-1). Neural Neural baselines were based on a neural transducer (Wu and Cotterell, 2019), which is essentially a hard monotonic attention model (mono-*). The second baseline is a transformer (Vaswani et al., 2017) adopted for character-level tasks that currently holds the state-of-the-art on the 2017 SIGMORPHON shared task data (Wu et al., 2020, trm-*). Both"
2020.sigmorphon-1.1,P19-1146,0,0.0351308,"Missing"
2020.sigmorphon-1.1,P19-1148,1,0.838088,"lti-source encoder–decoder with two-step attention architecture, training it with hallucinated data, cross-lingual transfer, and romanization of scripts to improve performance on low-resource languages. DeepSpin reimplemented gated sparse two-headed attention model from Peters and Martins (2019) and trained it on all languages at once (massively multilingual). The team experimented with two modifications of the softmax function: sparsemax (Martins and Astudillo, 2016, deepspin-02-1) and 1.5-entmax (Peters et al., 2019, deepspin-01-1). Neural Neural baselines were based on a neural transducer (Wu and Cotterell, 2019), which is essentially a hard monotonic attention model (mono-*). The second baseline is a transformer (Vaswani et al., 2017) adopted for character-level tasks that currently holds the state-of-the-art on the 2017 SIGMORPHON shared task data (Wu et al., 2020, trm-*). Both models take the lemma and morphological tags as input and output the target inflection. The baseline is further expanded to include the data augmentation technique used by Anastasopoulos and Neubig (2019, -aug-) (conceptually similar to the one proposed by Silfverberg et al. (2017)). Relying on a simple characterlevel alignme"
2020.sigmorphon-1.1,2020.sigmorphon-1.5,0,0.0487999,"Missing"
2020.sltu-1.47,L18-1530,0,0.158023,"in the target language, and online texts are a very useful resource when developing language models in this context. Keywords: Zyrian Komi (kpv), automatic speech-recognition, documentary linguistics 1. Introduction Speech recognition has lots of potential to be a highly useful technology while working with the world’s various endangered languages. In recent years numerous studies have been conducted on this topic, and especially the recent work on phoneme recognition is reaching very promising results on endangered language corpora (Wisniewski et al., 2020; Michaud et al., 2019). Persephone (Adams et al., 2018) and Elpis (Foley et al., 2018) have been the most widely used systems in the language documentation context, but as the field is rapidly evolving, various methods are available. One of them is Mozilla’s DeepSpeech (Hannun et al., 2014). By finding new, more effective ways to use these methods, we can open up their usage to low resource languages. Language documentation is one area in which these methods can be applied. Levow et al. (2017) propose a number of tasks demonstrating the usefulness of natural language processing to language documentation, including speech processing. In this paper"
2020.sltu-1.47,W19-0311,1,0.931674,"sly was developed from more formal varieties of written language (literature and Wikipedia), it did not match the domain of the speech data to be recognized, i.e. more informal spoken language recordings. Two obvious differences are the frequent use of discourse particles and code switching to the majority language, Russian, which are atypical of written language. Other differences between written and spoken language are the insertion of dialectal words or word forms and the preference for shorter syntactic units in the latter. Since written language used in social media tends to be informal (Arkhangelskiy, 2019) we hypothesized that a language model based on a social media corpus would result in significantly higher ASR accuracy. In fact, Komi is actively used in social media today and useful corpus data has recently been published by Timofey Arkhangelskiy. The Komi-Zyrian corpora2 consist of two different sections: a standard written language corpus of 1.76 million words (called the ”Main Corpus”), and the “Social Me2 https://github.com/mozilla/DeepSpeech 336 http://komi-zyrian.web-corpora.net Corpus Size Speech 35 hours Wiki and Books Literary Social 1.78M tokens 1.39M tokens 1.37M tokens Combined"
2020.sltu-1.47,I13-1041,0,0.0252259,"6) and Krylova et al. (2015), and more recent, similar work has also been conducted in Finland (Jauhiainen et al., 2019). In the future, it could be a promising avenue to combine all these sources, but for our current work we focus on one set of text corpora published last year (Arkhangelskiy, 2019), see above. The kenlm language model (Heafield, 2011) used by DeepSpeech takes as input a plain-text file with one sentence per line. These were obtained from the annotated corpus files using tsakorpus2kenlm script5 . Since it is common for social media data to be noisy and contain code switching (Baldwin et al., 2013), automatic language tagging and some text cleaning were performed when building the corpus. The latter included fixing characters with diacritics typed in one of the popular conventions, e.g. replacing о: with ö or Latin i with its identically looking Cyrillic counterpart. Therefore, the social media language model was based on somewhat cleaner data than the original social media posts. The conversion included two additional cleaning stages. First, only sentences with less than one-third OOV words (as determined by a rule-based Komi analyzer6 ) were included, to avoid wrongly tagged Russian s"
2020.sltu-1.47,2020.iwclul-1.5,1,0.71377,"ys to use these methods, we can open up their usage to low resource languages. Language documentation is one area in which these methods can be applied. Levow et al. (2017) propose a number of tasks demonstrating the usefulness of natural language processing to language documentation, including speech processing. In this paper we report our latest results using DeepSpeech. In a recent study we investigated the usefulness of automatic speech-recognition (ASR) in a low-resource scenario, which is generalizable for the fieldwork-based documentation of a medium-size endangered language of Russia (Hjortnaes et al., 2020). We ran various experiments with 35 hours of spoken dialectal Zyrian Komi (Permic &lt; Uralic, henceforth Komi) to optimize the training parameters for DeepSpeech1 and explored the impact of transfer learning on our corpus. Although the work was a promising start, further research was acutely needed as the reached accuracy 1 was very low. In this study, we continue our previous work by exploring new potential methods to improve our results. Specifically, we are looking at how to improve the language model (LM) in order to reach higher accuracy in the ASR. In our earlier experiments, tuning the l"
2020.sltu-1.47,W17-0106,0,0.0233233,"t work on phoneme recognition is reaching very promising results on endangered language corpora (Wisniewski et al., 2020; Michaud et al., 2019). Persephone (Adams et al., 2018) and Elpis (Foley et al., 2018) have been the most widely used systems in the language documentation context, but as the field is rapidly evolving, various methods are available. One of them is Mozilla’s DeepSpeech (Hannun et al., 2014). By finding new, more effective ways to use these methods, we can open up their usage to low resource languages. Language documentation is one area in which these methods can be applied. Levow et al. (2017) propose a number of tasks demonstrating the usefulness of natural language processing to language documentation, including speech processing. In this paper we report our latest results using DeepSpeech. In a recent study we investigated the usefulness of automatic speech-recognition (ASR) in a low-resource scenario, which is generalizable for the fieldwork-based documentation of a medium-size endangered language of Russia (Hjortnaes et al., 2020). We ran various experiments with 35 hours of spoken dialectal Zyrian Komi (Permic &lt; Uralic, henceforth Komi) to optimize the training parameters for"
2020.udw-1.22,W18-4804,1,0.655433,"tion of Chukotka was 50,526 in 2010. According to the 2010 census it was spoken by 5,095 people, or around a third of the ethnic population. Today most speakers are over the age of 50, and, even by the 1990s intergenerational transmission had been disrupted (Dunn, 1999). The language exhibits polypersonal agreement, ergative–absolutive alignment, and a subject–object–verb basic word order in transitive clauses. The language is severely under-resourced and there has been very little computational work on this language. We are only aware of a description of a ﬁnite-state morphological analyser (Andriyanets and Tyers, 2018). There have been a number of theoretical and descriptive linguistic works on noun incorporation in Chukchi, including Spencer (1995) who gives a general overview and Polinsky (1990) who covers subject incorporation. We used the Amguema corpus, available through the «Chuklang»10 site, which is a corpus of spoken Chukchi in the Amguema variant. The corpus consists of both audio recordings and transcriptions with glosses and translations in Russian and English. There are a total of 65 texts, most of which are elicited 9 This is the most conservative variant of our proposal, the most essential pa"
2020.udw-1.22,2020.lrec-1.497,1,0.892377,"Missing"
2020.udw-1.22,J05-1004,0,0.297305,"or person and number. In Chukchi however, fewer than half of all sentences contain an explicit pronoun or external noun phrase argument. Arguments are either encoded via incorporation, agreement or by a combination of these two processes. As Dunn (1999, §7.2) observes, personal pronouns are “textually rare and pragmatically marked”, and “in unelicited texts […] are not used for anaphoric speciﬁcation of arguments in clauses”. This clearly has implications for language technology applications and further linguistic analysis. Annotation schemes for predicate–argument structure such as PropBank (Palmer et al., 2005; Haverinen et al., 2015) are often annotated over the tree structure, and systems for co-reference resolution such as Xrenner (Zeldes and Zhang, 2016) rely on the dependency structure to add co-reference information. Semantic parsing systems such as Universal Semantic Parsing (Reddy et al., 2017) also rely on the dependency structure. If incorporated objects are kept out of the tree structure, then speciﬁc language-speciﬁc solutions will have to be made in each downstream application for the languages that exhibit incorporation. It is our belief that the most adequate place to represent this"
2020.udw-1.22,D17-1009,0,0.0154199,"ally rare and pragmatically marked”, and “in unelicited texts […] are not used for anaphoric speciﬁcation of arguments in clauses”. This clearly has implications for language technology applications and further linguistic analysis. Annotation schemes for predicate–argument structure such as PropBank (Palmer et al., 2005; Haverinen et al., 2015) are often annotated over the tree structure, and systems for co-reference resolution such as Xrenner (Zeldes and Zhang, 2016) rely on the dependency structure to add co-reference information. Semantic parsing systems such as Universal Semantic Parsing (Reddy et al., 2017) also rely on the dependency structure. If incorporated objects are kept out of the tree structure, then speciﬁc language-speciﬁc solutions will have to be made in each downstream application for the languages that exhibit incorporation. It is our belief that the most adequate place to represent this information is in the morphosyntactic structure as part of the dependency tree. 6 Future work We have been able to obtain permission to annotate a further corpus of Chukchi. This corpus contains an additional 1,000 sentences (approx. 11,500 tokens) of parallel text in Chukchi and Russian from the"
2020.udw-1.22,L16-1376,0,0.0147975,"onally, it would require substantial eﬀort on the part of annotators, who would need to be both ﬂuent in the language (to be able to generate the non-incorporated equivalents of clauses with incorporation), and expert in the annotation scheme. For many (if not most) under-resourced and marginalised languages, this does not obtain. Furthermore, the information structure of the incorporated and non-incorporated forms are diﬀerent, so further processing would need to distinguish unconverted transitive clauses and converted ones.8 Our proposal is to encode it in the enhanced dependency structure (Schuster and Manning, 2016). The enhanced structure is built on top of the basic dependencies and may include: 7 For simplicity we restrict discussion of antipassivising verbs (Dunn, 1999, §12.2.1) here, where the incorporation of an object does not reduce the valency, and some other non-patient role is promoted to the object slot. 8 To aid the reader, one could imagine a hypothetical annotation scheme whereby analytic passives must be rewritten as nonpassive with a feature indicating passivisation. root punct advmod 1 Нэмыӄэй neməqej also ADV 2 ныманэванԓясӄэвӄэнат nəmanewanɬasqewqenat they came to ask for money VERB a"
2020.udw-1.22,W17-0417,0,0.012395,"ographically, there are few if any in Europe or most of Asia, but they are spoken by many indigenous communities in the Arctic region, the Americas, Australia and Papua New Guinea (Fortescue et al., 2017). We present the ﬁrst work on annotating noun incorporation in a language1 using the Universal Dependencies guidelines — and probably the ﬁrst medium-scale computational annotation work of any kind of a language of the noun-incorporating type.2 This work is licensed under a Creative Commons Attribution 4.0 International Licence. Licence details: http:// creativecommons.org/licenses/by/4.0/. 1 Senuma and Aizawa (2017) present a treebank of Ainu, a language that is recorded as exhibiting noun incorporation. The treebank contains 36 sentences. The authors state that noun incorporation for Ainu is only used in poetry and ﬁxed expressions but provide no quantative evidence. Note that this existence of incorporation as a marginal phenomenon is not the case for all languages that exhibit incorporation. 2 We note that Bick (2019) presents a dependency formalism for Greenlandic, which has a phenomenon similar to noun incorporation, but that we distinguish as lexical aﬃxing — a large, but closed, set of verbalising"
2020.udw-1.22,W16-0713,0,0.0131103,"are either encoded via incorporation, agreement or by a combination of these two processes. As Dunn (1999, §7.2) observes, personal pronouns are “textually rare and pragmatically marked”, and “in unelicited texts […] are not used for anaphoric speciﬁcation of arguments in clauses”. This clearly has implications for language technology applications and further linguistic analysis. Annotation schemes for predicate–argument structure such as PropBank (Palmer et al., 2005; Haverinen et al., 2015) are often annotated over the tree structure, and systems for co-reference resolution such as Xrenner (Zeldes and Zhang, 2016) rely on the dependency structure to add co-reference information. Semantic parsing systems such as Universal Semantic Parsing (Reddy et al., 2017) also rely on the dependency structure. If incorporated objects are kept out of the tree structure, then speciﬁc language-speciﬁc solutions will have to be made in each downstream application for the languages that exhibit incorporation. It is our belief that the most adequate place to represent this information is in the morphosyntactic structure as part of the dependency tree. 6 Future work We have been able to obtain permission to annotate a furt"
2020.udw-1.23,W16-5403,0,0.0281401,"so used in other syntactic contexts, as an attributive function. We consider this usage a homograph of the case marker, assuming that it is influenced by Chinese. I.e., i is a modifier particle PART instead of a case marker ADP. The attributive function of i occurs frequently in Cabcal News. There are two types of attributive functions: In the first case, i marks adjectival modifiers. In Figure 4, sˇahvrun ‘cold’ is an adjective and directly modifies mujilen ‘heart’, but there is an i without obvious function. We assume that this is borrowed from Chinese. We follow the Chinese-HK UD treebank (Leung et al., 2016; Wong et al., 2017) and annotate the adjective as the head of the particle i. The particle i is treated as a mark:rel dependent of the adjective. In the second case, i marks adverbial modifiers. In Figure 5, ten is a noun, meaning ‘pole, extreme’. The following particle i marks it to be an adverbial modifier of the adjective amba ‘big’, describing the degree of the adjective. Thus ten is an adjunct depending on the adjective with the relation obl, and i depends on ten with the relation mark:adv indicating that the noun functions as an adverbial modifier. 4.3 Topic Marker oci Xibe uses the can"
2020.udw-1.23,W17-7604,1,0.838203,"lation. Tokenization assumes that all words are separated by spaces or punctuation. We annotated each word with its lemma, UTS part of speech tag, morphological features, and dependency annotation. For the first 544 sentences, the annotation work was carried out by two annotators. The first annotator annotated 464 sentences, and the second annotator annotated 80 sentences. The 80 sentences by the second annotator were checked by the first annotator to keep the annotation consistent. As for the second part of the data, the annotation was performed by the first annotator. We used UD Annotatrix (Tyers et al., 2017) to facilitate our annotation. 3.3 Transliteration The writing system of Xibe is untypical in that its writing direction is from top to bottom, from left to right. The Xibe script is based on Manchu script with slight modifications, which uses traditional Mongolian letters. Xibe letters have different forms: Most of the letters have three forms at initial, medial, or final position, but some letters just have one or two forms. In Table 1, all letters but ng ᡢ are the initial forms. For ng ᡢ, we show the final form since it cannot occur in initial position. Modern written Xibe has 5 vowels, 19"
2020.udw-1.23,W17-6530,0,0.0207762,"tactic contexts, as an attributive function. We consider this usage a homograph of the case marker, assuming that it is influenced by Chinese. I.e., i is a modifier particle PART instead of a case marker ADP. The attributive function of i occurs frequently in Cabcal News. There are two types of attributive functions: In the first case, i marks adjectival modifiers. In Figure 4, sˇahvrun ‘cold’ is an adjective and directly modifies mujilen ‘heart’, but there is an i without obvious function. We assume that this is borrowed from Chinese. We follow the Chinese-HK UD treebank (Leung et al., 2016; Wong et al., 2017) and annotate the adjective as the head of the particle i. The particle i is treated as a mark:rel dependent of the adjective. In the second case, i marks adverbial modifiers. In Figure 5, ten is a noun, meaning ‘pole, extreme’. The following particle i marks it to be an adverbial modifier of the adjective amba ‘big’, describing the degree of the adjective. Thus ten is an adjunct depending on the adjective with the relation obl, and i depends on ten with the relation mark:adv indicating that the noun functions as an adverbial modifier. 4.3 Topic Marker oci Xibe uses the canonical word order of"
2021.americasnlp-1.14,2020.lrec-1.326,1,0.909944,"hpark129@illinois.edu lanes@illinois.edu Abstract This paper describes the development of the first Universal Dependencies (UD, Nivre et al., 2016, 2020) treebank for St. Lawrence Island Yupik, an endangered language spoken in the Bering Strait region. While the UD guidelines provided a general framework for our annotations, language-specific decisions were made necessary by the rich morphology of the polysynthetic language. Most notably, we annotated a corpus at the morpheme level as well as the word level. The morpheme level annotation was conducted using an existing morphological analyzer (Chen et al., 2020) and manual disambiguation. By comparing the two resulting annotation schemes, we argue that morpheme-level annotation is essential for polysynthetic languages like St. Lawrence Island Yupik. Word-level annotation results in degenerate trees for some Yupik sentences and often fails to capture syntactic relations that can be manifested at the morpheme level. Dependency parsing experiments provide further support for morpheme-level annotation. Implications for UD annotation of other polysynthetic languages are discussed. 1 Introduction The Universal Dependencies (UD) project (Nivre et al., 2016,"
2021.americasnlp-1.14,L16-1262,0,0.0949651,"Missing"
2021.americasnlp-1.14,2020.lrec-1.497,1,0.889495,"Missing"
2021.americasnlp-1.14,W17-0412,0,0.0248529,"the single orthographic token (dámelo) is annotated as multiple syntactic words, and that information can be used to collapse the annotations to the single orthographic token when needed. In our case, we treat each multi-morphemic Yupik word as a UD “multiword expression,” with Yupik morphemes serving as the tokens within the “multiword expression.” Recognizing the UD project’s lexicalist view of syntax, we provide a script to convert our morpheme-level annotations into word-level annotations. This script deterministically merges each multi-morphemic word into a single word token using Udapi (Popel et al., 2017). Because our morpheme-level annotation does not strictly follow the entirety of the UD guidelines, a small number of sentences had to be manually corrected after the conversion. We plan to release our morpheme-level annotation in UD version 2.8 along with descriptions of the conversion process from the morphemelevel annotations to the word-level annotations. In annotating Yupik sentences with dependency relations, we therefore treat each Yupik morpheme as a token rather than treating each Yupik word as a token. This necessarily requires that Yupik words be analyzed and segmented into morpheme"
2021.americasnlp-1.14,K17-3009,0,0.139555,"x and cop relations are only available at the morpheme level in Yupik. While a small number of particles act as marker, the mark relation was also primarily attributed to derivational suffixes. When annotating Yupik sentences at the word level, such dependency relations are lost. Only when we annotate at the morpheme level can we find such constructions, which may be invaluable in subsequent linguistic inquiries or computational applications alike. 7 Parsing experiments In order to investigate the practical usage of the annotations, we conducted automatic parsing experiments using UDPipe 1.2 (Straka and Straková, 2017) and UDPipe 2.0 (Straka, 2018). The UDPipe project6 provides a trainable pipeline for any UD treebanks in the CoNLL-U format. 7.1 Data We made use of two sets of data: the Jacobson corpus and a separate test corpus annotated using the same word-level and morpheme-level annotation schemes. A text extracted from Nagai (2001) was annotated to provide an out-of-domain test set. The Nagai corpus was smaller than the entire Jacobson corpus with 360 word tokens or 834 tokens when including morphemes. The Nagai corpus is quite distinct from the Jacobson corpus. The former is a collection of an elder Y"
2021.americasnlp-1.14,2020.udw-1.22,1,0.936607,"a polysynthetic language spoken in parts of Alaska and Chukotka, Russia, within the framework of the UD guidelines. While UD is a framework for word-level annotations, we argue that morpheme-level annotations are more meaningful for polysynthetic languages. We provide morpheme-level annotations for Yupik in addition to word-level annotations.2 We believe that subword-level annotations can help better capture morphosyntactic relations for polysynthetic languages and assist further dependency annotations and morphosyntactic research for polysynthetic languages. Previously Tyers and Mishchenkova (2020) called for the need to annotate parts of words in regard to noun incorporation in Chukchi. They proposed annotating a noun incorporated into a verb via morphology as a separate token available in the enhanced dependency structure. While our approach is motivated by a similar need to annotate subword units for another polysynthetic language, our paper focuses on morpheme-level annotations, which may be applied to other types of multi-morphemic words than just noun incorporation. In what follows, we describe the characteristics of the Yupik language (§2) and show how we annotated a corpus at th"
2021.americasnlp-1.14,K18-2001,0,0.0363898,"Missing"
2021.americasnlp-1.2,D19-1279,0,0.0433793,"as adverbial modifiers and provide a feature AdvType=Dir for linguists interested in querying the corpus for this phenomenon. 6.9 7 Experiments Here we present two experiments using the corpus. The first is an evaluation of three different parsing pipelines and the second is an experiment in using automatic parsing for mining linguistic examples. 7.1 Automatic parsing In order to test the usage of the corpus for automatic parsing, performed three experiments using three off-the-shelf natural-language processing pipelines: UDPipe 1.2 (Straka et al., 2016), UDPipe 2.0 (Straka, 2018) and UDify (Kondratyuk and Straka, 2019). Version 1.2 (Straka et al., 2016) of UDPipe is a pipeline-based model where tokenisation is performed by a BiLSTM, morphological analysis and part-of-speech tagging are performed using an averaged perceptron model and dependency parsing uses a transition-based non-projective parser, where transitions are predicted by a neural network. Version 2.0 (Straka, 2018) is a complete rewrite of the UDPipe parser. It implements a joint model for part-of-speech tagging, morphological analysis, lemmatisation and parsing. The parsing model is graph-based using the Chu-Liu/Edmonds algorithm for decoding."
2021.americasnlp-1.2,L16-1680,0,0.0730778,"es, being either modifiers or copredicates. We analyse them as adverbial modifiers and provide a feature AdvType=Dir for linguists interested in querying the corpus for this phenomenon. 6.9 7 Experiments Here we present two experiments using the corpus. The first is an evaluation of three different parsing pipelines and the second is an experiment in using automatic parsing for mining linguistic examples. 7.1 Automatic parsing In order to test the usage of the corpus for automatic parsing, performed three experiments using three off-the-shelf natural-language processing pipelines: UDPipe 1.2 (Straka et al., 2016), UDPipe 2.0 (Straka, 2018) and UDify (Kondratyuk and Straka, 2019). Version 1.2 (Straka et al., 2016) of UDPipe is a pipeline-based model where tokenisation is performed by a BiLSTM, morphological analysis and part-of-speech tagging are performed using an averaged perceptron model and dependency parsing uses a transition-based non-projective parser, where transitions are predicted by a neural network. Version 2.0 (Straka, 2018) is a complete rewrite of the UDPipe parser. It implements a joint model for part-of-speech tagging, morphological analysis, lemmatisation and parsing. The parsing mode"
2021.americasnlp-1.2,2020.lrec-1.497,1,0.869971,"Missing"
2021.americasnlp-1.3,N18-1116,0,0.0162446,"uage modeling, and some relevant related work. Introduction 2.1 Nahuatl variants2 The diversity of language in a linguistic continuum presents an interesting challenge to the development of language technology. For marginalized and endangered languages, the general lack of resources in the language as a whole exacerbates this challenge. Character-level features have been shown to be effective for a wide range of textual NLP tasks, including language identification (Dunning, 1994; Veena et al., 2018), native language detection (Kulmizev et al., 2017), and machine translation (Lee et al., 2017; Chen et al., 2018). Furthermore, they offer the advantage of requiring little-to-no preprocessing or linguistic engineering (e.g. word tokenization, morphological segmentation, etc.) other than possibly orthographic normalization3 . In this paper we investigate the usefulness of character language models in addressing questions about variation within a linguistic continuum. Specifically, we examine the extent to which these simNahuatl is a polysynthetic, agglutinating UtoAztecan language continuum spoken throughout Mexico and Mesoamerica. The Mexican Government’s Instituto Nacional de Lenguas Indígenas (INALI)"
2021.americasnlp-1.3,Q17-1026,0,0.0282408,"the language, language modeling, and some relevant related work. Introduction 2.1 Nahuatl variants2 The diversity of language in a linguistic continuum presents an interesting challenge to the development of language technology. For marginalized and endangered languages, the general lack of resources in the language as a whole exacerbates this challenge. Character-level features have been shown to be effective for a wide range of textual NLP tasks, including language identification (Dunning, 1994; Veena et al., 2018), native language detection (Kulmizev et al., 2017), and machine translation (Lee et al., 2017; Chen et al., 2018). Furthermore, they offer the advantage of requiring little-to-no preprocessing or linguistic engineering (e.g. word tokenization, morphological segmentation, etc.) other than possibly orthographic normalization3 . In this paper we investigate the usefulness of character language models in addressing questions about variation within a linguistic continuum. Specifically, we examine the extent to which these simNahuatl is a polysynthetic, agglutinating UtoAztecan language continuum spoken throughout Mexico and Mesoamerica. The Mexican Government’s Instituto Nacional de Lengua"
2021.americasnlp-1.3,2020.vardial-1.1,0,0.0272538,"unsupervised subword tokenization for written Nahuatl for future experiments. 21 Proceedings of the First Workshop on Natural Language Processing for Indigenous Languages of the Americas, pages 21–27 June 11, 2021. ©2021 Association for Computational Linguistics user. Finally, for applications that generate text on a user’s behalf, such as predictive keyboards and spellchecking systems, it is vital to maintain consistency in both language variant and orthographic norms. 2.2 guage variants, most notably highlighted in the Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial) (Gaman et al., 2020). Particularly relevant to the work presented in this paper, Gamallo et al. (2017) describe a method for discriminating between similar languages using word and character n-gram language model perplexity. Character language models have also been shown to be effective in distinguishing between dialects of written Arabic (Sadat et al., 2014; Malmasi et al., 2015). With respect to Nahuatl, Farfan (2019) analyzed contemporary written Nahuatl variants for points of convergence using a finite-state morphological analyzer built from a grammar of Classical Nahuatl. Other efforts in developing language"
2021.americasnlp-1.3,2021.computel-1.10,1,0.667156,"language model perplexity. Character language models have also been shown to be effective in distinguishing between dialects of written Arabic (Sadat et al., 2014; Malmasi et al., 2015). With respect to Nahuatl, Farfan (2019) analyzed contemporary written Nahuatl variants for points of convergence using a finite-state morphological analyzer built from a grammar of Classical Nahuatl. Other efforts in developing language technology for Nahuatl include a large parallel Nahuatl-Spanish text corpus (Gutierrez-Vasques et al., 2016), and a morphological analyzer for the Western Sierra (nhi) variant (Pugh et al., 2021). Language Modeling Language models are probability distributions over sequences of vocabulary items with parameters learned from data. They are ubiquitous in Natural Language Processing in areas including machine translation, automatic speech recognition, and spelling correction, among others. Traditional ngram language models estimate the conditional probability of each vocabulary item given contexts of preceding vocabulary items based on their frequency in the data. Neural language models represent each vocabulary item as a distributed feature vector, and learn the joint probability functio"
2021.americasnlp-1.6,D19-1279,0,0.236536,"through parallel corpora, sometimes called annotation projection, is well-studied; in Mayan languages, Palmer et al. (2010) use a parallel corpus as a bridge to a higher-resourced language for which a part-ofspeech tagger already exists. In the absence of such a corpus, so-called “zeroshot” methods are created from other (presumably higher-resourced) languages and applied to the target language. The main balance to strike is between specificity of resources (how closely-related are the other languages) and quantity of resources (how much linguistic data is accessible). UDify of Kondratyuk and Straka (2019) is an example of preferring the latter: a deep neural architecture is trained on all of the Universal Dependencies treebanks. The former strategy can be seen in Huck et al. (2019), where in addition to annotation projection, authors attempt zero-shot tagging of Ukrainian with a model trained on Russian. 3 seen in Table 1. We studied the performance of several popular part-of-speech taggers within the Universal Dependencies ecosystem; these are reviewed in section 4. Performance was computed as F1 scores for lemmatisation, universal part-of-speech (UPOS), and universal morphological features ("
2021.americasnlp-1.6,kuhn-mateo-toledo-2004-applying,0,0.162276,"ing interlinearly glossed texts. They work with Uspanteko, a language of the Greater Quichean branch, and the closest language to K’iche’ we were able to identify with published studies of computational morphology. They explore several different systems: inducing morphology from parallel texts, an unsupervised segmentation+clustering strategy, and an interactive training strategy with a linguist. In Sachse and Dürr (2016), a set of preliminary annotation conventions for Mayan languages in general, and K’iche’ in particular, are proposed. A maximum-entropy part-of-speech tagger is presented in Kuhn and Mateo-Toledo (2004) for Q’anjob’al, which, like K’iche’, is a Mayan language of Guatemala. They work with a custom selection Introduction This paper presents a survey of approaches to partof-speech tagging for K’iche’, a Mayan language spoken principally in Guatemala. The Mayan languages are a group of related languages spoken throughout Mesoamerica. K’iche’ belongs to the Eastern branch, which contains 14 other languages, including Kaqchikel in the Quichean subgroup and Uspanteko which belongs to its own subgroup. Part-of-speech tagging has wide usage in corpus and computational linguistics and natural language"
2021.americasnlp-1.6,2020.lrec-1.497,1,0.877296,"Missing"
2021.americasnlp-1.6,W18-5815,0,0.0651171,"Missing"
2021.americasnlp-1.6,W19-1425,0,0.056017,"Missing"
2021.americasnlp-1.6,L16-1680,0,0.0197225,"ion were all evaluated on small part-ofspeech-tagged corpora of 157 (Kaqchikel) and 160 (Uspanteko) sentences. For results and overviews of the languages, see section 6. 4 the reported hardware. Error could be introduced into these estimates from many sources: only the reported device is considered, ignoring many other components of the machine; devices are assumed to run at their TDP the entire runtime; the UDify numbers as reported by Kondratyuk and Straka (2019) are approximate. Systems We tested morphological analysis on three systems designed for Universal Dependencies treebanks: UDPipe (Straka et al., 2016), UDPipe 2 (Straka, 2018), and UDify (Kondratyuk and Straka, 2019). Of these, only UDPipe had a working tokeniser. For other taggers we trained, we trained the UDPipe tokeniser and other tagger together. We thus present combined tokeniser-tagger systems. UDPipe (Straka et al., 2016) is a languageindependent trainable tokeniser, lemmatiser, POS tagger, and dependency parser designed to train on and produce Universal Dependencies-format treebanks. It uses gated linear units for tokenisation, averaged perceptrons for part-of-speech tagging, and a neural network classifier for dependency parsing."
2021.americasnlp-1.6,2021.americasnlp-1.2,1,0.733001,"Missing"
2021.americasnlp-1.6,K18-2001,0,0.0183665,"cy parser designed to train on and produce Universal Dependencies-format treebanks. It uses gated linear units for tokenisation, averaged perceptrons for part-of-speech tagging, and a neural network classifier for dependency parsing. It is the least resource-hungry model in our study by an order of magnitude or more, and we trained it from-scratch using the K’iche’ corpus in section 3. UDPipe 2 (Straka, 2018) is a Python prototype for a Tensorflow-based deep neural network POStagger, lemmatiser, and dependency parser. It won high rankings in the CoNLL 2018 shared task on multilingual parsing (Zeman et al., 2018), taking first place by one metric. Deep neural methods have achieved impressive performance results in recent years, but take considerable computational resources to train. We used UDPipe 2 without pretrained embeddings, and trained it from-scratch using the K’iche’ corpus in section 3. UDify (Kondratyuk and Straka, 2019) is a AllenNLP-based multilingual model using BERT pretrained embeddings and trained on the combined Universal Dependencies treebank collection; we fine-tuned this pretrained model on our K’iche’ data. This was our most resource-intensive model, even though we only fine-tuned"
2021.americasnlp-1.9,W18-4804,1,0.684731,"y popular, require large amounts of annotated data to be trained. This in turn requires large numbers of trained annotators to annotate it. Given that neither of these are available, we apply tried-and-tested technique relying on formal linguistic description by means of finite-state transducers. Finite-state techniques have been widely applied to morphological modelling of many languages and are state of the art for many languages, especially those with non-trivial morphology such as languages described as agglutinative (Çöltekin, 2010; Pirinen, 2015) or polysynthetic (Schwartz et al., 2020; Andriyanets and Tyers, 2018). The remainder of the article is laid out as follows: In Section 2 we give an overview of Guaraní, paying special attention to aspects of morphology and morphosyntax. Section 3 reviews the prior work, Section 4 describes the implementation of the analyser, including information about the linguistic data and tools used. We evaluate our analyser in Section 5, giving both a qualitative, quantitative and comparative evaluation. And finally in Section 6 we give some final remarks and comment on potential future work for Guaraní. Abstract This article describes the development of morphological anal"
2021.americasnlp-1.9,W15-3021,0,0.0697693,"Missing"
2021.americasnlp-1.9,2018.jeptalnrecital-court.1,1,0.83621,"Missing"
2021.americasnlp-1.9,coltekin-2010-freely,0,0.0366093,"ised approaches, including neural networks which have become increasingly popular, require large amounts of annotated data to be trained. This in turn requires large numbers of trained annotators to annotate it. Given that neither of these are available, we apply tried-and-tested technique relying on formal linguistic description by means of finite-state transducers. Finite-state techniques have been widely applied to morphological modelling of many languages and are state of the art for many languages, especially those with non-trivial morphology such as languages described as agglutinative (Çöltekin, 2010; Pirinen, 2015) or polysynthetic (Schwartz et al., 2020; Andriyanets and Tyers, 2018). The remainder of the article is laid out as follows: In Section 2 we give an overview of Guaraní, paying special attention to aspects of morphology and morphosyntax. Section 3 reviews the prior work, Section 4 describes the implementation of the analyser, including information about the linguistic data and tools used. We evaluate our analyser in Section 5, giving both a qualitative, quantitative and comparative evaluation. And finally in Section 6 we give some final remarks and comment on potential future w"
2021.americasnlp-1.9,W17-6509,1,0.872543,"Missing"
2021.americasnlp-1.9,W13-5610,0,0.0696886,"Missing"
2021.americasnlp-1.9,W16-0523,0,0.0276112,"subsume both morphological analysis and morphological generation is one of the core tasks in the field of natural language processing. It is used in a wide variety of areas, including but not limited to: orthographic correction (Pirinen and Lindén, 2014), electronic dictionaries (Johnson et al., 2013), morphological segmentation for machine translation (Tiedemann et al., 2015; Forcada et al., 2011), as an additional knowledge source for parsing languages with nontrivial morphology (Gökırmak and Tyers, 2017; Tyers and Ravishankar, 2018), and in computerassisted language-learning applications (Ledbetter and Dickinson, 2016). In this article we describe a morphological analyser for Paraguayan Guaraní (in Guaraní: Avanẽ’e, ISO-639: gn, grn), one of the official languages of Paraguay. Although Guaraní is an official language and spoken by over six million people throughout the South American continent (Eberhard et al., 2018), it does not benefit from a wide range of freely-available data and tools for building natural language processing systems. If we use Wikipedia as a proxy for viability of crowdsourcing linguistic data, as in (Moshagen et al., 2014), we see that although Guaraní has a large speaker population,"
2021.computel-1.8,L18-1530,0,0.0152912,"), it becomes easier to develop these tools for low resource languages and to create best practice standards for doing so. This is the fundamental goal of Common Voice (Ardila et al., 2020). Others also work on individual languages, such as Fantaye et al. (2020) and Dalmia et al. (2018). In the language documentation context we have seen a large number of experiments on endangered languages in the last few years, but often focusing on the datasets with a single speaker. Under this constraint a few hours of transcribed data has already shown to result in a relatively good accuracy, as shown by Adams et al. (2018). Also Partanen et al. (2020) report very good results on the extinct Samoyedic language Kamas, where https://dict.fu-lab.ru http://komicorpora.ru 64 the model was also trained with one speaker, for whom, however, a relatively large corpus exists. Under many circumstances it is realistic and important to record individual speakers in numerous recording sessions, and such collections appear to be numerous in the archives containing past field recordings, so there is no doubt that also single speaker systems can be useful, although not ideal. Recently, Shi et al. (2021) also report very encourag"
2021.computel-1.8,W19-0311,0,0.0213665,"earning from the Russian model we trained to Komi again using each of the three language models. We obtained the English model from DeepSpeech’s released models for 0.8.2. Figure 1: Mozilla’s DeepSpeech architecture (Meyer, 2019) on the 500000 most common words in the relevant text corpus. We constructed three language models using various quantities of available Komi and Russian data. The first is exclusively Komi and is constructed using the Komi-Zyrian corpora6 which consists of a main corpus of 1.39 million words in the literary domain and a 1.37 million word corpus from social media (see Arkhangelskiy, 2019). This serves as our baseline language model. The second includes all available text data from both the Komi corpora and the Russian Wikipedia dump from September 1st, 2020, which contains over 786 million tokens. We did not expect this largely Russian model to perform especially well, but include it anyway as an additional point of comparison. The last language model was constructed by cutting the Russian Wikipedia dump down to the same number of tokens as the combined Komi corpora such that the model is based on an equal amount of Komi and Russian data. 4 The best Word Error Rate and best Ch"
2021.computel-1.8,W11-2100,0,0.0732632,"g sets and 3 Language Models DeepSpeech outputs its best guess as to the transcription, but that is based entirely on the contents of the audio and does not account for spelling or punctuation. In order to address this, the output is put through a function which attempts to maximize the weighted probability of the model output and a probabilistic language model with two tuneable parameters. The first, α, determines how much the language model is allowed to edit the network output. The second, β, controls inserting spaces (Hannun et al., 2014). Our language models were constructed using Kenlm (Heafield, 2011) Methodology 3.1 DeepSpeech 4 https://github.com/mozilla/ DeepSpeech/releases 5 https://github.com/mozilla/ DeepSpeech/ https://commonvoice.mozilla.org/ 65 Corpus Komi Speech Russian Speech Size 35 hours 105 hours Komi Literary Komi Social Komi Text Combined 1.39M tokens 1.37M tokens 2.76M tokens Russian Wiki 786M tokens Table 1: Token counts for the speech corpora and text corpora used to create the language models. layer after the LSTM layer, yielded the best performance. The softmax function outputs a letter of the alphabet for each time stamp and re-initializing is necessary to accommodate"
2021.computel-1.8,2020.sltu-1.47,1,0.756072,"Missing"
2021.computel-1.8,2020.iwclul-1.5,1,0.842642,"ets. DeepSpeech automatically detects plateaus and reduces the learning rate by a factor of 10 when no further improvement is being made on the dev set. We trained a Russian model using DeepSpeech from the standard random initialization using the hyperparameters defined above. DeepSpeech saves the best performing model, which we then use for transfer learning later. 3.4 Data The Russian speech corpus we use is from Mozilla’s Common Voice3 project and contains about 105 hours of speech data (Ardila et al., 2020). The Komi data consists of about 35 hours of dialectal speech, and is described in Hjortnaes et al. (2020b). 3.2 Data Preprocessing To prepare both our Komi and Russian data, we split it into 8/1/1 training, dev, and testing sets and 3 Language Models DeepSpeech outputs its best guess as to the transcription, but that is based entirely on the contents of the audio and does not account for spelling or punctuation. In order to address this, the output is put through a function which attempts to maximize the weighted probability of the model output and a probabilistic language model with two tuneable parameters. The first, α, determines how much the language model is allowed to edit the network outp"
2021.computel-1.8,W18-6015,1,0.835507,", Online, March 2–3, 2021. need a full linguistic description, and some already have established orthographies and variety of descriptions available. For example, in the case of Komi our transcription choice is the existing orthography which is also used in other resources (Gerstenberger et al., 2016, 32). Our spoken language corpus is connected with the entire NLP ecosystem of the Komi language, which includes Finite State Transducer (Rueter, 2000), well developed dictionaries both online1 and in print (Rueter et al., 2020; Beznosikova et al., 2012; Alnajjar et al., 2019), several treebanks (Partanen et al., 2018) and also written language corpora (Fedina, 2019)2 . We use this technical stack to annotate our corpus directly into the ELAN files (Gerstenberger et al., 2017), but also to create versions where identifiable information has been restricted (Partanen et al., 2020). Thereby our goal is not to describe the language from the scratch, but to create a spoken language corpus that is not separate from the rest of the work and infrastructure done on this language. From this point of view we need an ASR system that produces the contemporary orthography, and not purely the phonetic or phonemic levels."
2021.computel-1.8,2021.eacl-main.96,0,0.0385806,"Missing"
2021.emnlp-main.475,P19-1310,0,0.0472944,"Missing"
2021.emnlp-main.475,2020.acl-main.688,0,0.0272912,"the source and target language and, even misleading (e.g. en-az vs az-en). Reuse the same script. In fact, the best 6 models on sults in the human evaluations for mid-resource the X-WMT test sets all have Latin scripts in both pairs seem a lot more closely clustered than in the the source and target language. A suboptimal per- BLEU/ChrF figure. These results further emphaformance in the face of a script disparity is a known size the pitfalls of automatic metrics of MT evaluphenomenon (Anastasopoulos and Neubig, 2019; ation and emphasize the role of native speakers in Murikinati et al., 2020; Aji et al., 2020; Amrhein the MT process. 5882 Pair en–tr ru–tr tr–uz uz–tr en–uz uz–en en–kk kk–en tr–az az–tr en–ky ky–en en–az az–en ru–uz uz–ru kk–tt* tt–kk* ru–sah sah–ru uz–kaa kaa-uz kk-ky ky-kk Test size 800 800 700 700 800 800 700 700 500 500 500 500 600 600 800 800 678 678 300 300 300 300 500 500 Baseline BLEU ChrF 19.87 0.51 8.81 0.41 1.58 0.23 1.73 0.22 6.60 0.42 12.32 0.48 6.99 0.38 9.75 0.46 9.68 0.33 11.53 0.49 3.18 0.19 4.30 0.40 8.88 0.41 12.14 0.42 5.95 0.39 7.45 0.37 4.13 0.22 3.75 0.17 0.08 0.20 0.31 0.16 5.39 0.41 5.24 0.44 0.14 0.09 0.11 0.13 Google Translate BLEU ChrF 69.24 0.83 24.79 0"
2021.emnlp-main.475,2020.findings-emnlp.223,0,0.036924,"Missing"
2021.emnlp-main.475,D19-1091,0,0.0620492,"Missing"
2021.emnlp-main.475,D08-1078,0,0.0639284,"ming available (Guzm´an et al., 2019; Ojha et al., 2020; Fraser, 2020; Ansari et al., 2020), there are still a large amount of underrepresented languages excluded from MT evaluation. In addition to the cost of preparing such labor-intensive annotations, the lack of training resources also limits the evaluation of MT models in 1 https://github.com/ turkic-interlingua/til-mt MT? terms of their applicability across a wide range of world languages. On the other hand, many studies have pointed to the limited applicability of prominent methods in MT research including models and evaluation metrics (Birch et al., 2008; Stanojevi´c et al., 2015; Bugliarello et al., 2020) in translating languages with varying linguistic typology. In order to extend the evaluation of the state-ofthe-art methods in MT (Joshi et al., 2019) and ultimately aid in designing methods with wider range of applicability, in this paper, we present a largescale case study of MT methods in a very challenging case of the Turkic language family. The Turkic 5876 Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 5876–5890 c November 7–11, 2021. 2021 Association for Computational Linguistics language"
2021.emnlp-main.475,2009.iwslt-papers.1,0,0.0438681,"are available through the Apertium3 website. For individual languages in our corpus, there are several proposed MT systems and linguistic resources: Azerbaijani (Hamzaoglu, 1993; Fatullayev et al., 2008), Bashkir (Tyers et al., 2012), Crimean Tatar (G¨okırmak et al., 2019; Altıntas¸, 2001), Karakalpak (Kadirov, 2015), Kazakh (Assylbekov and Nurkas, 2014; Sundetova et al., 2015; Littell et al., 2019; Briakou and Carpuat, 2019; Tukeyev et al., 2019), Kyrgyz (C ¸ etin and Ismailova), Sakha (Ivanova et al., 2019), Turkmen (Tantug et al., 2007), Turkish (Turhan, 1997; ElKahlout and Oflazer, 2006; Bisazza and Federico, 2009; Tantu˘g et al., 2011; Ataman et al., 2017), Tatar (Salimzyanov et al., 2013; Khusainov et al., 2018; Valeev et al., 2019; G¨okırmak et al., 2019), Tuvan (Killackey, 2013), Uyghur (Mahsut et al., 2004; Nimaiti and Izumi, 2014; Song and Dai, 2015; Wang et al., 2020), Uzbek (Axmedova et al., 2019). Yet, to our knowledge, there has not been a study that covers Turkic languages in such a large extent as ours, both in terms of multi-lingual parallel corpora and benchmarks including multi-way comparable test sets in all languages. 3 TIL Corpus Our parallel corpus is collected through unifying publi"
2021.emnlp-main.475,P15-1166,0,0.0259694,"r the encoder, but for the decoder both dimensions are increased to 1024. All models are trained with the Adam optimizer (Kingma and Ba, 2015) over cross-entropy loss with a maximum learning rate of 3 ∗ 10−4 and a minimum of 1∗10−8 , which warms up for the first 4800 training steps and then decays after reaching the maximum. We use a training batch size of 4096. We use perplexity as our early stopping metric with a patience of 5 epochs. We set a dropout (Srivastava et al., 2014) probability of 0.3 in both the encoder and the decoder. We apply a byte pair encoding (BPE) (Sennrich et al., 2015; Dong et al., 2015) with a joint vocabulary size of 4K and 32K for low- and mid/high-resource scenarios respectively. All models use the Joey NMT (Kreutzer et al., 2019) implementation and apex14 where possible to speed up training. Models were trained on preemptible GPUs freely available on Google Colab.15 4.2 Test Sets High-quality and diverse test sets are essential in evaluating the strength and weaknesses of MT systems. We curate 3 test sets covering 3 translation domains: religious (Bible), conversational (TED Talks), and news (X-WMT). Bible dataset is the main source that exists across almost all of the 2"
2021.emnlp-main.475,W06-3102,0,0.186151,"Missing"
2021.emnlp-main.475,W19-6721,0,0.0575605,"Missing"
2021.emnlp-main.475,W19-5308,0,0.0225264,"based MT framework for Turkic languages and demonstrates the performance with 4 language pairs. Washington et al. (2019) demonstrates several rule-based MT systems built for Turkic languages which are available through the Apertium3 website. For individual languages in our corpus, there are several proposed MT systems and linguistic resources: Azerbaijani (Hamzaoglu, 1993; Fatullayev et al., 2008), Bashkir (Tyers et al., 2012), Crimean Tatar (G¨okırmak et al., 2019; Altıntas¸, 2001), Karakalpak (Kadirov, 2015), Kazakh (Assylbekov and Nurkas, 2014; Sundetova et al., 2015; Littell et al., 2019; Briakou and Carpuat, 2019; Tukeyev et al., 2019), Kyrgyz (C ¸ etin and Ismailova), Sakha (Ivanova et al., 2019), Turkmen (Tantug et al., 2007), Turkish (Turhan, 1997; ElKahlout and Oflazer, 2006; Bisazza and Federico, 2009; Tantu˘g et al., 2011; Ataman et al., 2017), Tatar (Salimzyanov et al., 2013; Khusainov et al., 2018; Valeev et al., 2019; G¨okırmak et al., 2019), Tuvan (Killackey, 2013), Uyghur (Mahsut et al., 2004; Nimaiti and Izumi, 2014; Song and Dai, 2015; Wang et al., 2020), Uzbek (Axmedova et al., 2019). Yet, to our knowledge, there has not been a study that covers Turkic languages in such a large extent as"
2021.emnlp-main.475,2020.loresmt-1.4,0,0.0352394,"English and Russian along with number of L1 speakers and two- and three-letter language codes. The column MT? indicates if there are currently available online machine translation systems for the language. (K: thousand, M: million.) Introduction Having been studied widely over the last few decades, machine translation (MT) evaluation has traditionally focused on European languages, due to limitations of the available technology as well as resources. Although low-resource MT has recently started to gain more attention and new evaluation benchmarks are becoming available (Guzm´an et al., 2019; Ojha et al., 2020; Fraser, 2020; Ansari et al., 2020), there are still a large amount of underrepresented languages excluded from MT evaluation. In addition to the cost of preparing such labor-intensive annotations, the lack of training resources also limits the evaluation of MT models in 1 https://github.com/ turkic-interlingua/til-mt MT? terms of their applicability across a wide range of world languages. On the other hand, many studies have pointed to the limited applicability of prominent methods in MT research including models and evaluation metrics (Birch et al., 2008; Stanojevi´c et al., 2015; Bugliarel"
2021.emnlp-main.475,P02-1040,0,0.114917,"nd the syntactic and lexical features (Zhang et al., 2019; Sellam et al., 2020; Rei et al., 2020). Methods relying on contextual embeddings to capture the semantic similarity between the hypothesis and references fall short in terms of their language coverage. This is largely due to the pretraining of these evaluation models that require a significant of monolingual data which most of the low-resource languages lack. In this study, we evaluate our systems using both automatic metrics and human evaluation of translations. 5.1 Automatic Metrics for MT We employ two widely adopted metrics: BLEU (Papineni et al., 2002) and ChrF (Popovi´c, 2015). BLEU utilizes modified n-gram precision where the consecutive n-grams of the system translation are compared with the consecutive n-grams of the reference translation. We use the standard SacreBLEU implementation (Post, 2018). ChrF applies the same method at the level of character n-gram and we use the original implementation from the paper as provided through NLTK library.17 17 Human Evaluation To perform a more holistic analysis of MT systems, it is critical to involve native speakers in the evaluation process. We conducted a human evaluation campaign using a rand"
2021.emnlp-main.475,W15-3049,0,0.0440703,"Missing"
2021.emnlp-main.475,W18-6319,0,0.0180113,"s is largely due to the pretraining of these evaluation models that require a significant of monolingual data which most of the low-resource languages lack. In this study, we evaluate our systems using both automatic metrics and human evaluation of translations. 5.1 Automatic Metrics for MT We employ two widely adopted metrics: BLEU (Papineni et al., 2002) and ChrF (Popovi´c, 2015). BLEU utilizes modified n-gram precision where the consecutive n-grams of the system translation are compared with the consecutive n-grams of the reference translation. We use the standard SacreBLEU implementation (Post, 2018). ChrF applies the same method at the level of character n-gram and we use the original implementation from the paper as provided through NLTK library.17 17 Human Evaluation To perform a more holistic analysis of MT systems, it is critical to involve native speakers in the evaluation process. We conducted a human evaluation campaign using a randomly sampled subset of 250 sentences from X-WMT or Bible (whenever X-WMT was not available) for evaluating the outputs of 14 bilingual baseline models. Our assessment is based on Direct Assessment (DA) test (Nießen et al., 2000; Papineni et al., 2002; D"
2021.emnlp-main.475,W12-3152,0,0.0287094,"y written in different scripts depending on which country the speakers are in. This orthographic diversity makes collecting and collating text resources difficult, as many texts may be available only in a previously-used orthography and conversion between orthographic systems is never deterministic owing to the large number of loan words in many texts. 2.2 MT of Turkic Languages The need for more comprehensive and diverse multilingual parallel corpora has sped up the creation of such large-scale resources for many language families and linguistic regions (Koehn, 2005; Choudhary and Jha, 2011; Post et al., 2012; Nomoto et al., 2018; Espl`a-Gomis et al., 2019; ∀ et al., 2020). Tiedemann (2020) released a large-scale corpus for over 500 languages covering thousands of translation directions. The corpus includes 14 Turkic languages and provides bilingual baselines for all translation directions present in the corpus. However, the varying and limited size of the test sets does not allow for the extensive analysis and comparisons between different model artifacts, linguistic features, and translation domains. Khusainov et al. (2020) collected a large-scale Russian-Turkic parallel corpus for 6 language pa"
2021.emnlp-main.475,2013.mtsummit-papers.22,1,0.701412,"orpus, there are several proposed MT systems and linguistic resources: Azerbaijani (Hamzaoglu, 1993; Fatullayev et al., 2008), Bashkir (Tyers et al., 2012), Crimean Tatar (G¨okırmak et al., 2019; Altıntas¸, 2001), Karakalpak (Kadirov, 2015), Kazakh (Assylbekov and Nurkas, 2014; Sundetova et al., 2015; Littell et al., 2019; Briakou and Carpuat, 2019; Tukeyev et al., 2019), Kyrgyz (C ¸ etin and Ismailova), Sakha (Ivanova et al., 2019), Turkmen (Tantug et al., 2007), Turkish (Turhan, 1997; ElKahlout and Oflazer, 2006; Bisazza and Federico, 2009; Tantu˘g et al., 2011; Ataman et al., 2017), Tatar (Salimzyanov et al., 2013; Khusainov et al., 2018; Valeev et al., 2019; G¨okırmak et al., 2019), Tuvan (Killackey, 2013), Uyghur (Mahsut et al., 2004; Nimaiti and Izumi, 2014; Song and Dai, 2015; Wang et al., 2020), Uzbek (Axmedova et al., 2019). Yet, to our knowledge, there has not been a study that covers Turkic languages in such a large extent as ours, both in terms of multi-lingual parallel corpora and benchmarks including multi-way comparable test sets in all languages. 3 TIL Corpus Our parallel corpus is collected through unifying publicly available datasets and additional parallel data we prepare by crawling pu"
2021.emnlp-main.475,2020.acl-main.704,0,0.0245541,"inal direction of the translation. While Bashkir and Sakha have been translated by professional translators, other languages have been translated and validated (by another person) by proficient bilingual speakers of both the source and target language. The curation of this test set is an ongoing and growing effort currently covering 88 language directions. 5 Evaluation Automatic evaluation metrics are very commonplace in MT research, and there has been a recent line of work exploring better metrics that capture translation quality beyond the syntactic and lexical features (Zhang et al., 2019; Sellam et al., 2020; Rei et al., 2020). Methods relying on contextual embeddings to capture the semantic similarity between the hypothesis and references fall short in terms of their language coverage. This is largely due to the pretraining of these evaluation models that require a significant of monolingual data which most of the low-resource languages lack. In this study, we evaluate our systems using both automatic metrics and human evaluation of translations. 5.1 Automatic Metrics for MT We employ two widely adopted metrics: BLEU (Papineni et al., 2002) and ChrF (Popovi´c, 2015). BLEU utilizes modified n-gra"
2021.emnlp-main.475,W15-3031,0,0.0733761,"Missing"
2021.emnlp-main.475,P07-2048,0,0.0535447,"emonstrates several rule-based MT systems built for Turkic languages which are available through the Apertium3 website. For individual languages in our corpus, there are several proposed MT systems and linguistic resources: Azerbaijani (Hamzaoglu, 1993; Fatullayev et al., 2008), Bashkir (Tyers et al., 2012), Crimean Tatar (G¨okırmak et al., 2019; Altıntas¸, 2001), Karakalpak (Kadirov, 2015), Kazakh (Assylbekov and Nurkas, 2014; Sundetova et al., 2015; Littell et al., 2019; Briakou and Carpuat, 2019; Tukeyev et al., 2019), Kyrgyz (C ¸ etin and Ismailova), Sakha (Ivanova et al., 2019), Turkmen (Tantug et al., 2007), Turkish (Turhan, 1997; ElKahlout and Oflazer, 2006; Bisazza and Federico, 2009; Tantu˘g et al., 2011; Ataman et al., 2017), Tatar (Salimzyanov et al., 2013; Khusainov et al., 2018; Valeev et al., 2019; G¨okırmak et al., 2019), Tuvan (Killackey, 2013), Uyghur (Mahsut et al., 2004; Nimaiti and Izumi, 2014; Song and Dai, 2015; Wang et al., 2020), Uzbek (Axmedova et al., 2019). Yet, to our knowledge, there has not been a study that covers Turkic languages in such a large extent as ours, both in terms of multi-lingual parallel corpora and benchmarks including multi-way comparable test sets in all"
2021.iwclul-1.1,2020.lrec-1.520,1,0.736346,"in the recordings more automatically. Within the research of ASR at Uralic languages we can also mention the study on Samoyedic languages by Partanen et al. (2020), where relatively good accuracies were reported for single speaker scenarios. In the context of minority languages spoken in Russia, Wisniewski et al. (2020) also reported recently on their experiment with Bashkir. There have also been approaches to create keyword spotting without an ASR system at the background (van der Westhuizen et al., 2021). 4 Test data In the test data we look at two compendia. The first is the Common Voice (Ardila et al., 2020) collection of the data for Hungarian and Estonian, and the second is the collection of available data for Finnish and Komi. The datasets are described below, with the first selection representing more artificial read literary language sentences, and the second containing spontaneous spoken language. 4.1 Common Voice Common Voice (Ardila et al., 2020) is a project aimed at collecting speech data for all of the world’s languages. One of the advantages of Common Voice is that, for the languages supported, it provides a very convenient way to contribute and distribute voice recordings. The data c"
2021.iwclul-1.1,2020.iwclul-1.5,1,0.728338,"(Turunen and Kurimo, 2008) have studied the detection of morphemes from unsegmented Finnish audio recordings. Several experiments for Komi ASR have been conducted, but the quality has not yet reached levels where the models are particularly useful. The steady progress the work has yielded, however, warrants optimism. In the first reported experiment the results were extremely bad, but demonstrated that in principle these systems can be trained with the currently available data, and some insight was shown to the roles the language models and transfer learning may have in the training process (Hjortnaes et al., 2020). A later study refined the language model with online materials, which improved the result considerably (Hjortnaes et al., 2020). All these models used English as the source language in transfer learning. Most recently an investigation was done about the possible use of other languages, and the transfer learning with Russian Common Voice data was tested (Hjortnæs et al., 2021). The results improved due to changes in the DeepSpeech architecture between different versions, but the English transfer learning still gave better results due to the quantity of data available. Further testing of these"
2021.iwclul-1.1,2021.computel-1.8,1,0.739809,"ad, but demonstrated that in principle these systems can be trained with the currently available data, and some insight was shown to the roles the language models and transfer learning may have in the training process (Hjortnaes et al., 2020). A later study refined the language model with online materials, which improved the result considerably (Hjortnaes et al., 2020). All these models used English as the source language in transfer learning. Most recently an investigation was done about the possible use of other languages, and the transfer learning with Russian Common Voice data was tested (Hjortnæs et al., 2021). The results improved due to changes in the DeepSpeech architecture between different versions, but the English transfer learning still gave better results due to the quantity of data available. Further testing of these models by the authors has shown that producing an accurate transcript from a very clearly pronounced Komi speech can work relatively well. In real spontaneous speech the results are extremely sporadic. However, since there is also a clear ratio of correctly recognized words, or their parts, we believe testing the model in real world scenarios for other down stream tasks such a"
2021.iwclul-1.1,2020.paclic-1.60,1,0.664487,"dual keywords we improve the possibility of recognizing the words we want to find even further. Unfortunately this scenario is not entirely realistic, as in many instances we cannot know what themes and words are present. However, there are also many instances where metadata containing keyword and topic information exists, and the researchers who have done the recordings often have acute information about the topics covered, which they may want to locate in the recordings more automatically. Within the research of ASR at Uralic languages we can also mention the study on Samoyedic languages by Partanen et al. (2020), where relatively good accuracies were reported for single speaker scenarios. In the context of minority languages spoken in Russia, Wisniewski et al. (2020) also reported recently on their experiment with Bashkir. There have also been approaches to create keyword spotting without an ASR system at the background (van der Westhuizen et al., 2021). 4 Test data In the test data we look at two compendia. The first is the Common Voice (Ardila et al., 2020) collection of the data for Hungarian and Estonian, and the second is the collection of available data for Finnish and Komi. The datasets are de"
2021.naacl-main.435,P18-1198,0,0.0303327,"of the speech signal: specifically the presence or absence of the fricative [s] in the output of the network and the amplitude of frication. They show that manipulation of the variables changes these features in a predictable manner. Similarly to our work, Beguˇs (2020b) also scales state activations and observes the effect on the output of the network. In a related investigation of reduplication, Beguˇs (2020a) train GAN models on speech and identify variables which trigger reduplication in the speech signal. Extensive work exists on linguistic probing experiments for neural representations (Conneau et al., 2018a,b; Clark et al., 2019). A recent probing paper by Torroba Hennigen et al. (2020) is more directly related to our work. They present a decomposable probe for finding small sets of hidden states which encode for linguistically relevant information, particularly morphosyntactic information. Our work shares the aim of not only identifying if information is present in a neural system, but also examining how it is represented. However, we additionally perform experiments on manipulating network activations and examine how such manipulations influence the outputs of the network. Interpretation of n"
2021.naacl-main.435,D18-1269,0,0.0139971,"of the speech signal: specifically the presence or absence of the fricative [s] in the output of the network and the amplitude of frication. They show that manipulation of the variables changes these features in a predictable manner. Similarly to our work, Beguˇs (2020b) also scales state activations and observes the effect on the output of the network. In a related investigation of reduplication, Beguˇs (2020a) train GAN models on speech and identify variables which trigger reduplication in the speech signal. Extensive work exists on linguistic probing experiments for neural representations (Conneau et al., 2018a,b; Clark et al., 2019). A recent probing paper by Torroba Hennigen et al. (2020) is more directly related to our work. They present a decomposable probe for finding small sets of hidden states which encode for linguistically relevant information, particularly morphosyntactic information. Our work shares the aim of not only identifying if information is present in a neural system, but also examining how it is represented. However, we additionally perform experiments on manipulating network activations and examine how such manipulations influence the outputs of the network. Interpretation of n"
2021.naacl-main.435,K17-2001,1,0.890174,"Missing"
2021.naacl-main.435,2020.scil-1.5,0,0.0342658,"Missing"
2021.naacl-main.435,W19-4828,0,0.0254706,"cifically the presence or absence of the fricative [s] in the output of the network and the amplitude of frication. They show that manipulation of the variables changes these features in a predictable manner. Similarly to our work, Beguˇs (2020b) also scales state activations and observes the effect on the output of the network. In a related investigation of reduplication, Beguˇs (2020a) train GAN models on speech and identify variables which trigger reduplication in the speech signal. Extensive work exists on linguistic probing experiments for neural representations (Conneau et al., 2018a,b; Clark et al., 2019). A recent probing paper by Torroba Hennigen et al. (2020) is more directly related to our work. They present a decomposable probe for finding small sets of hidden states which encode for linguistically relevant information, particularly morphosyntactic information. Our work shares the aim of not only identifying if information is present in a neural system, but also examining how it is represented. However, we additionally perform experiments on manipulating network activations and examine how such manipulations influence the outputs of the network. Interpretation of neural representations in"
2021.naacl-main.435,2020.emnlp-main.15,0,0.0345602,"in the output of the network and the amplitude of frication. They show that manipulation of the variables changes these features in a predictable manner. Similarly to our work, Beguˇs (2020b) also scales state activations and observes the effect on the output of the network. In a related investigation of reduplication, Beguˇs (2020a) train GAN models on speech and identify variables which trigger reduplication in the speech signal. Extensive work exists on linguistic probing experiments for neural representations (Conneau et al., 2018a,b; Clark et al., 2019). A recent probing paper by Torroba Hennigen et al. (2020) is more directly related to our work. They present a decomposable probe for finding small sets of hidden states which encode for linguistically relevant information, particularly morphosyntactic information. Our work shares the aim of not only identifying if information is present in a neural system, but also examining how it is represented. However, we additionally perform experiments on manipulating network activations and examine how such manipulations influence the outputs of the network. Interpretation of neural representations in recurrent neural models has been an active area of resear"
2021.naacl-main.435,W16-2010,0,0.0450767,"Missing"
2021.naacl-main.435,W18-1817,0,0.0614385,"Missing"
2021.naacl-main.435,W19-4219,0,0.045635,"Missing"
2021.naacl-main.435,W97-1012,0,0.577375,"rticularly morphosyntactic information. Our work shares the aim of not only identifying if information is present in a neural system, but also examining how it is represented. However, we additionally perform experiments on manipulating network activations and examine how such manipulations influence the outputs of the network. Interpretation of neural representations in recurrent neural models has been an active area of research over a long period of time starting with Elman (1990). However, representations in models of phonology have received less attention than many other subfields of NLP. Rodd (1997) investigates learning of Turkish vowel harmony by a character-based RNN language model trained on Our approach was inspired by the now-classic word forms. The paper investigates hidden state ac- paper on visualization and interpretation of recurtivations of RNN models while varying the hidden rent networks by Karpathy et al. (2015) in that we state dimensionality between 1 and 4. It presents also seek individual interpretable dimensions. The evidence that RNN hidden states can capture Turk- work by Dalvi et al. (2019) on analyzing individish vowel harmony patterns when a sufficient num- ual n"
2021.naacl-main.435,W18-0314,1,0.84302,". The paper investigates hidden state ac- paper on visualization and interpretation of recurtivations of RNN models while varying the hidden rent networks by Karpathy et al. (2015) in that we state dimensionality between 1 and 4. It presents also seek individual interpretable dimensions. The evidence that RNN hidden states can capture Turk- work by Dalvi et al. (2019) on analyzing individish vowel harmony patterns when a sufficient num- ual neurons in networks trained for linguistic tasks ber of hidden dimensions are available. In a similar (POS tagging as well as semantic and morphologivein, Silfverberg et al. (2018) investigate phoneme cal tagging) is more closely related to the present representations for Finnish, Spanish and Turkish work. They present a general methodology for finding correlations between embedding represen- uncovering neurons which encode linguistic infortations and phonological distinctive features. Ko- mation by training a classifier to predict linguistic lachina and Magyar (2019) present an investiga- features of the input based on the representations tion of phone embeddings learned using word2vec generated by the network. They also show that it is (Mikolov et al., 2013) for simul"
2021.sigmorphon-1.25,K18-3001,1,0.679933,"l marker used for expressing case, familiarity, plurality, and (sometimes) gender within animate nouns. Pronouns are marked for different cases and honorificity levels. These paradigms are generated on the basis of a manually annotated corpus of Magahi folktales. We used a raw dataset from the literary domain. First, we annotated the dataset with the Universal Dependency morphological feature tags at token level using the CoNLL-U editor (Heinecke, 2019). We then converted the annotated dataset into the UniMorph schema using the script available for converting UD data into the UniMorph tagset (McCarthy et al., 2018). To finalize the data, we manually validated the dataset against the UniMorph schema (Sylak-Glassman et al., 2015a). Brajbhasha, or Braj is one of the Indo-Aryan languages spoken in the Western Indian states of Uttar Pradesh, Madhya Pradesh, and Rajasthan. Grierson (1908) groups Brajbhasha under Western Hindi of the Central Group in the Indo-Aryan family, along with other languages like Hindustani, Bangaru, Kannauji, and Bundeli. Braj is not generally used in education or for any official purposes in any Braj spoken state, but it has a very rich literary tradition. Also in order to preserve,"
2021.sigmorphon-1.25,K17-2001,1,0.858355,"Missing"
2021.sigmorphon-1.25,U19-1001,1,0.893844,"nje-ng ‘1/3PL-again-wrong-BENmeat-cook-PP’ (“I cooked the wrong meat for them again”). As shown, the form has several prefixes and suffixes attached to the stem. As in other Australian languages, long vowels are typically represented by double characters, and trills with “rr”.3 According to Evans’ (2003) analysis, the verb template contains 12 affix slots which include two incorporated noun classes, and derivational affixes such as the benefactive and comitative. The data included in this set are verbs extracted from the Kunwinjku translation of the Bible using the morphological analyzer from Lane and Bird (2019) and manually verified by human annotators. 3.2 Afro-Asiatic The Afro-Asiatic language family is represented by the Semitic subgroup. 3.2.1 Semitic: Classical Syriac Classical Syriac is a dialect of the Aramaic language and is attested as early as the 1st century CE. As with most Semitic languages, it displays non-concatenative morphology involving primarily tri-consonantal roots. Syriac nouns and adjectives are conventionally classified into three ‘states’— Emphatic, Absolute, Construct—which loosely correlate with the syntactic features of definiteness, indeterminacy and the genitive. There"
2021.sigmorphon-1.25,U19-1005,1,0.782664,"respect to morphology and realized in the UniMorph schema (Sylak-Glassman et al., 2015b). Morphosyntactic features (such as “the dative case” or “the past tense”) in the UniMorph occupy an intermediate position between the descriptive categories and comparative concepts. The set of features was initially established on the basis of analysis of typological literature, and refined with the addition of new languages to the UniMorph database (Kirov et al., 2018; McCarthy et al., 2020). Since 2016, SIGMORPHON organized shared tasks on morphological reinflection (Cotterell et al., 2016, 2017, 2018; McCarthy et al., 2019; Vylomova et al., 2020) that aimed at evaluating contemporary systems. Parallel to that, they also served as a platform for enriching the UniMorph database with new languages. For instance, the 2020 shared task (Vylomova et al., 2020) featured 90 typologically diverse languages derived from various linguistic resources. This year, we are bringing many under-resourced languages (languages of Peru, Russia, India, Australia, Papua New Guinea) and dialects (e.g., for Arabic and Kurdish). The sample is highly diverse: it contains languages with templatic, concatenative (fusional and agglutinative)"
2021.sigmorphon-1.25,W02-0604,0,0.0878472,"Missing"
2021.sigmorphon-1.25,U08-1018,0,0.0643919,"through affixation, compounding, or reduplication. The four types of Indonesian affixes are prefixes, suffixes, circumfixes (combination of prefixes and suffixes), and infixes (inside the base form). Indonesian uses both full and partial reduplication processes to form words. Full reduplication is often used to express the plural forms of nouns, while partial reduplication is typically used to derive forms that might have a different category than their base forms. Unlike English, the distinction between inflectional and derivational morphological processes in Indonesian is not always clear (Pisceldo et al., 2008). In this shared task, the Indonesian data is created by bootstrapping the data from an Indonesian Wikipedia dump. Using a list of possible Indonesian affixes, we collect unique word forms from Wikipedia and analyze them using MorphInd (Larasati et al., 2011), a morphological analyzer tool for Indonesian based on an FST. We manually create a mapping between the MorphInd tagset and the UniMorph schema. We then use this mapping and apply some additional rule-based formulas created by Indonesian linguists to build the final dataset (Table 9). 3.9.2 Malayo-Polynesian: Kodi/Kodhi Kodi or Kodhi [koâ"
2021.sigmorphon-1.25,N19-1119,0,0.0213266,"ugmentation technique presented by Anastasopoulos and Neubig (2019). More specifically, the team implemented an encoder–decoder model with an attention mechanism. The encoder processes a character sequence using an LSTM-based RNN with attention. Tags are encoded with a selfattention (Vaswani et al., 2017) position-invariant module. The decoder is an LSTM with separate attention mechanisms for the lemma and the tags. GUClasp focus their efforts on exploring strategies for training a multilingual model, in particular, they implement the following strategies: curriculum learning with competence (Platanios et al., 2019) based on character frequency and L BME GUClasp afb amh ara arz heb syc ame cni ind kod aym ckt itl gup bra bul ces ckb deu kmr mag nld pol por rus spa see ail evn sah tyv krl lud olo vep 92.39 98.16 99.76 95.27 97.46 21.71 82.46 99.5 81.31 94.62 99.98 44.74 32.4 14.75 58.52 98.9 98.03 99.46 97.98 98.21 70.2 98.28 99.54 99.85 98.07 99.82 78.28 6.84 51.9 99.95 99.97 99.88 59.46 99.72 99.72 81.71 93.81 94.86 87.12 89.93 10.57 55.94 93.36 55.68 87.1 99.97 52.63 31.28 21.31 56.91 96.46 94.00 96.60 91.94 98.09 72.24 94.91 98.52 99.11 94.32 97.65 40.97 6.46 51.5 99.69 99.78 98.50 59.46 98.2 97.05 sj"
2021.sigmorphon-1.25,2020.acl-main.597,1,0.915066,"arget inflected form—and removed all forms other than verbs, nouns, or adjectives. We then capped the dataset sizes to a maximum of 100,000 instances per language, subsampling when necessary. Finally, we create a 70–10–20 train–dev–test split per language, splitting the data across these sets at the instance level (as opposed to, e.g., the lemma one). As such, the information about a lemma’s declension or inflection class is spread out across these train, dev and test sets, making this task much simpler than if one had to predict the entire class from the lemma’s form alone, as done by, e.g., Williams et al. (2020) and Liu and Hulden (2021). 5 Baseline Systems The organizers provide four neural systems as baselines, a product of two models and optional data augmentation. The first model is a transformer (Vaswani et al., 2017, TRM), and the second model is an adaption of the transformer to character-level transduction tasks (Wu et al., 2021, CHR-TRM), which holds the state-of-the-art on the 2017 SIGMORPHON shared task data. Both models follow the hyperparameters of Wu et al. (2021). The optional data augmentation follows the technique proposed by Anastasopoulos and Neubig (2019). Rely14 The new languages"
C14-1073,drobac-etal-2014-heuristic,0,0.022074,"Missing"
C14-1073,E09-2008,1,0.881321,"by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/ 772 Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers, pages 772–780, Dublin, Ireland, August 23-29 2014. We do not attempt here to add a new method to this list; instead, we concentrate on three practical aspects of FST-based CG. First, we report accurate measurements of the real-world performance of one of the methods above. Second, we endeavour to optimise the implementation of the selected method. All three works used foma, an open source FST library (Hulden, 2009b; Hulden, 2009a). We show that while foma is fast, relying on specialised FST application code instead of a generic library clearly benefits performance. We also demonstrate what further improvements can be achieved by exploiting the peculiarities of CG. Lastly, our research also aims to fill the niche left by the lack of openly accessible finite-state CG implementations. Section 2 briefly introduces the method we chose to evaluate. In the rest of the paper, we present our optimisations in a way that mirrors the actual development process. We start out with a simple rule engine based on foma,"
C14-1073,W11-4406,1,0.849866,"e free/open-source VISL CG-3 (Bick, 2000; Didriksen, 2011). Constraint grammar, however, has its drawbacks, one of which is speed. The Apertium machine translation project (Forcada et al., 2011) uses both CG (via VISL CG-3) and n-gram based models for morphological disambiguation, and while CG achieves higher accuracy, the n-gram model runs about ten times faster. In this paper, we investigate how using finite-state transducers (FST) for CG application can help to bridge the performance gap. In recent years, several methods have been proposed for compiling a CG to FST and applying it on text: Hulden (2011) compiles CG rules to transducers and runs them on the input sentences; Peltonen (2011) converts the sentences into ambiguous automata and attempts to eliminate branches by intersecting them with the rule FSTs; finally, Yli-Jyr¨a (2011) creates a single FST from the grammar and applies it on featurised input. Unfortunately, none of the authors report exact performance measurements of their systems. Yli-Jyr¨a published promising numbers for the preprocessing step, but nothing on the overall performance. Peltonen, on the other hand, observed that “VISL CG-3 was 1,500 times faster” than his imple"
C14-1073,C90-3030,0,0.293307,"ile these formalisms serve their purpose as proofs of the concept, the performance of the generated transducers lags behind other CG implementations and taggers. In this paper, we argue that the fault lies with using generic finite-state libraries, and not with the formalisms themselves. We present an open-source implementation that capitalises on the characteristics of CG rule application to improve execution time. On smaller grammars our implementation achieves performance comparable to the current open-source state of the art. 1 Introduction Constraint grammar (CG), described originally by Karlsson (1990), is a rule-based formalism for various linguistics tasks, including morphological analysis, clause boundary detection and surface syntactic parsing. It has been used in a wide range of application areas, such as morphological disambiguation, grammar checking and machine translation (Bick, 2011). CG owns its popularity to two reasons: first, it achieves high accuracy on free text. Second, it works for languages where the annotated corpora required by statistical parsing methods are not available, but a linguist willing to work on the rules is. The original CG has since been superseded by CG-2"
C14-1073,W05-1106,0,0.0341418,"Missing"
C14-1073,2010.eamt-1.13,1,0.843745,"development. Therefore, we have written a small Hungarian CG, aimed to fully disambiguate a short Hungarian story, which was used as the development corpus. Since Hungarian is not properly supported by Apertium yet, morphological analysis was carried out by Hunmorph (Tr´on et al., 2005), and the tags were translated to the Apertium tagset with a transducer in foma. The performance of fomacg-proc has been measured against that of VISL CG. The programs were benchmarked with three Apertium CG grammars: the toy Hungarian grammar mentioned earlier, the Breton grammar from the br-fr language pair (Tyers, 2010), and the version of the Finnish grammar originally written by Karlsson in the North S´ami–Finnish (sme-fin) pair. Seeing that in the early phases, only the Hungarian grammar was used for development, results for the other two languages are reported only for the later steps. Each grammar was run on a test corpus. For Breton, we used the corpus in the br-fr language pair, which consists of 1,161 sentences. There are no Finnish and Hungarian corpora in Apertium; for the former, we used a 1,620-sentence excerpt from the 2013-Nov-14 snapshot of the Finnish Wikipedia, while for the latter, the shor"
C16-1325,W03-2405,0,0.250537,"me the first Turkish treebank to be included in a UD release. The treebank was created by automatic conversion of the IMST This work is licenced under a Creative Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/ 1 http://universaldependencies.org/ License details: http:// 3444 Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers, pages 3444–3454, Osaka, Japan, December 11-17 2016. Treebank (Sulubacak et al., 2016), which is itself a reannotation of the METU-Sabancı Turkish Treebank (Oflazer et al., 2003; Atalay et al., 2003). Although the annotation framework of the IMST Treebank was revised, it is still fundamentally similar to that of the METU-Sabancı Treebank and radically different from the UD framework in both morphology and syntax. In this paper, we describe the procedures employed in converting the annotation schemes of the IMST Treebank to the corresponding UD-compliant schemes. We also provide comparative statistics on the composition of the IMST Treebank before and after the conversion. Afterwards, we report our initial parsing results on the new IMST-UD Treebank in comparison with the original IMST Tre"
C16-1325,de-marneffe-etal-2006-generating,0,0.185725,"Missing"
C16-1325,de-marneffe-etal-2014-universal,1,0.918476,"Missing"
C16-1325,E06-1012,0,0.552875,"Missing"
C16-1325,J08-3003,1,0.900686,"Missing"
C16-1325,W11-3806,1,0.873339,"Missing"
C16-1325,P99-1033,0,0.107905,"word has a separate row, each containing a tabdelimited array of morphosyntactic data pertaining to the word. In compliance with the UD standard, the converted sentences were output in the CoNLL-U format.2 The sections to follow present explanations and discussions on the procedures of mapping morphological and syntactic data, as well as some idiosyncratic linguistic phenomena. Quick reference tables were also provided where applicable, showing what conditions on the source unit are required to assign which properties to the target unit. 2.1 Segmentation The inflectional group (IG) formalism (Oflazer, 1999; Hakkani-T¨ur et al., 2002) was designed to make the highly agglutinative typology of Turkish tractable for language processing. Since then, it has seen usage in many influential works (Oflazer, 2003; Eryi˘git and Oflazer, 2006) and has become the de facto standard in parsing Turkish. According to the formalism, orthographic tokens are divided into morphosyntactic words from derivational boundaries.3 These units are called the inflectional groups (IGs) of the token. The IG formalism establishes these, rather than orthographic tokens, as the syntactic units of the sentence. The original IMST t"
C16-1325,J03-4001,0,0.0451041,"mat.2 The sections to follow present explanations and discussions on the procedures of mapping morphological and syntactic data, as well as some idiosyncratic linguistic phenomena. Quick reference tables were also provided where applicable, showing what conditions on the source unit are required to assign which properties to the target unit. 2.1 Segmentation The inflectional group (IG) formalism (Oflazer, 1999; Hakkani-T¨ur et al., 2002) was designed to make the highly agglutinative typology of Turkish tractable for language processing. Since then, it has seen usage in many influential works (Oflazer, 2003; Eryi˘git and Oflazer, 2006) and has become the de facto standard in parsing Turkish. According to the formalism, orthographic tokens are divided into morphosyntactic words from derivational boundaries.3 These units are called the inflectional groups (IGs) of the token. The IG formalism establishes these, rather than orthographic tokens, as the syntactic units of the sentence. The original IMST treebank also follows its predecessors in using the IG formalism. The rightmost IG governs the word, while every other IG depends on the next one in line with the exclusive relation DERIV. Though a com"
C16-1325,petrov-etal-2012-universal,0,0.0603661,"the UD framework is at least as viable for Turkish as the original annotation framework of the IMST Treebank. 1 Introduction The Universal Dependencies (UD)1 project is an international collaborative project to make cross-linguistically consistent treebanks available for a wide variety of languages. Currently in version 1.3, the UD project covers 40 languages, including two Turkic languages: Kazakh, which was annotated from scratch, and Turkish, the creation of which is described in this paper. The universal annotation guidelines of UD are based on the Google Universal Part-of-Speech Tagset (Petrov et al., 2012) for parts of speech, the Interset framework (Zeman, 2008) for morphological features, and Stanford Dependencies (De Marneffe et al., 2006; Tsarfaty, 2013; De Marneffe et al., 2014) for dependency relations. The objective of harmonizing annotation guidelines as far as possible is to make comparison of parsing results and investigating cross-linguistic methods across languages easier. This is achieved by a number of principles, including the primacy of content words, distinguishing core arguments from modifiers and distinguishing clausal constituents from nominals. The IMST-UD Treebank was firs"
C16-1325,W13-4915,1,0.888478,"Missing"
C16-1325,P13-2103,0,0.0332315,"roject is an international collaborative project to make cross-linguistically consistent treebanks available for a wide variety of languages. Currently in version 1.3, the UD project covers 40 languages, including two Turkic languages: Kazakh, which was annotated from scratch, and Turkish, the creation of which is described in this paper. The universal annotation guidelines of UD are based on the Google Universal Part-of-Speech Tagset (Petrov et al., 2012) for parts of speech, the Interset framework (Zeman, 2008) for morphological features, and Stanford Dependencies (De Marneffe et al., 2006; Tsarfaty, 2013; De Marneffe et al., 2014) for dependency relations. The objective of harmonizing annotation guidelines as far as possible is to make comparison of parsing results and investigating cross-linguistic methods across languages easier. This is achieved by a number of principles, including the primacy of content words, distinguishing core arguments from modifiers and distinguishing clausal constituents from nominals. The IMST-UD Treebank was first released in UD version 1.3 and became the first Turkish treebank to be included in a UD release. The treebank was created by automatic conversion of the"
C16-1325,zeman-2008-reusable,0,0.0261613,"l annotation framework of the IMST Treebank. 1 Introduction The Universal Dependencies (UD)1 project is an international collaborative project to make cross-linguistically consistent treebanks available for a wide variety of languages. Currently in version 1.3, the UD project covers 40 languages, including two Turkic languages: Kazakh, which was annotated from scratch, and Turkish, the creation of which is described in this paper. The universal annotation guidelines of UD are based on the Google Universal Part-of-Speech Tagset (Petrov et al., 2012) for parts of speech, the Interset framework (Zeman, 2008) for morphological features, and Stanford Dependencies (De Marneffe et al., 2006; Tsarfaty, 2013; De Marneffe et al., 2014) for dependency relations. The objective of harmonizing annotation guidelines as far as possible is to make comparison of parsing results and investigating cross-linguistic methods across languages easier. This is achieved by a number of principles, including the primacy of content words, distinguishing core arguments from modifiers and distinguishing clausal constituents from nominals. The IMST-UD Treebank was first released in UD version 1.3 and became the first Turkish"
C16-1325,J08-4010,1,\N,Missing
cortes-etal-2012-free,E06-1032,0,\N,Missing
cortes-etal-2012-free,P02-1040,0,\N,Missing
cortes-etal-2012-free,W08-0327,0,\N,Missing
cortes-etal-2012-free,2009.freeopmt-1.7,0,\N,Missing
K17-3001,K17-3023,0,0.0375672,"Missing"
K17-3001,P16-1231,1,0.301678,"M Table 1: The supporting data overview: the number of words (M = million; K = thousand) for each language. http://commoncrawl.org/ Except for Ancient Greek, which was gathered from the Perseus Digital Library. 3 http://github.com/CLD2Owners/cld2 4 http://unicode.org/reports/tr15/ 3 verted to Unicode character NO-BREAK SPACE (U+00A0).5 The dimensionality of the word embeddings was chosen to be 100 after thorough discussion – more dimensions may yield better results and are commonly used, but even with just 100, the uncompressed word embeddings for the 45 languages take 135 GiB. Also note that Andor et al. (2016) achieved state-of-the-art results with 64 dimensions. The word embeddings were precomputed using word2vec (Mikolov et al., 2013) with the following options: word2vec -min-count 10 -size 100 -window 10 -negative 5 -iter 2 -threads 16 -cbow 0 -binary 0. The precomputed word embeddings are available on-line (Ginter et al., 2017). 2.3 this shared task, i.e., not included in any previous UD release. The PUD treebank consists of 1000 sentences currently in 18 languages (15 K to 27 K words, depending on the language), which were randomly picked from on-line newswire and Wikipedia;7 usually only a fe"
K17-3001,W06-2920,0,0.0145655,"categorization of the different approaches of the participating systems. Introduction Ten years ago, two CoNLL shared tasks were a major milestone for parsing research in general and dependency parsing in particular. For the first time dependency treebanks in more than ten languages were available for learning parsers. Many of them were used in follow-up work, evaluating parsers on multiple languages became standard, and multiple state-of-the-art, open-source parsers became available, facilitating production of dependency structures to be used in downstream applications. While the two tasks (Buchholz and Marsi, 2006; Nivre et al., 2007) were extremely important in setting the scene for the following years, there were also limitations that complicated application of their results: (1) gold-standard to1 Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies, pages 1–19, c 2017 Association for Computational Linguistics Vancouver, Canada, August 3-4, 2017. kenization and part-of-speech tags in the test data moved the tasks away from real-world scenarios, and (2) incompatible annotation schemes made cross-linguistic comparison impossible. CoNLL 2017 has picked"
K17-3001,K17-3017,0,0.147208,"emains with participants, and since open sourcing the software underlying a paper is still the exception rather than the rule. To ensure both, TIRA supplies participants with a virtual machine, offering a range of commonly used operating systems in order not to limit the choice of technology stacks and development environments. Once deployed and tested, the virtual machines are archived to preserve the software within. Many participants agreed to share their code so that we decided to collect the respective projects in a kind of open source proceedings at GitHub.14 4.3 by Straka and Strakov´a (2017) as one of the competing systems. Straka and Strakov´a (2017) describe both these versions in more detail. The baseline models were released together with the UD 2.0 training data, one model for each treebank. Because only training and development data were available during baseline model training, we put aside a part of the training data for hyperparameter tuning, and evaluated the baseline model performance on development data. We called this data split baseline model split. The baseline models, the baseline model split, and also UD 2.0 training data with morphology predicted by 10-fold jack"
K17-3001,K17-3005,0,0.0752704,"Missing"
K17-3001,K17-3026,0,0.0310687,"E 90.88 82.31 82.46 LyS-FASTPARSE 90.88 82.31 79.14 NAIST SATO 90.88 82.31 82.46 Orange – Deski˜n 90.88 38.81 15.38 UALING 90.88 82.31 82.46 UParse 90.88 82.31 82.46 naistCL 90.88 82.31 82.46 Table 5: Universal POS tags, features and lemmas (ordered by UPOS F1 scores). duce suboptimal results when deployed on a machine different from the one where it was trained. Several teams used the library and may have been affected; for the Uppsala team (de Lhoneux et al., 2017) the issue led to official LAS = 65.11 (23rd place) instead of 69.66 (9th place). In the second case, the ParisNLP system (De La Clergerie et al., 2017) used a wrong method of recognizing the input language, which was not supported in the test data (but unfortunately it was possible to get along with it in development and trial data). Simply crashing could mean that the task moderator would show the team their diagnostic output and they would fix the bug; however, the parser was robust enough to switch to a languageagnostic mode and produced results that were not great, but also not so bad to alert the moderator and make him investigate. Thus the official LAS of the system is 60.02 (27th place) while without the bug it could have been 70.35 ("
K17-3001,K17-3021,0,0.0954088,"emains with participants, and since open sourcing the software underlying a paper is still the exception rather than the rule. To ensure both, TIRA supplies participants with a virtual machine, offering a range of commonly used operating systems in order not to limit the choice of technology stacks and development environments. Once deployed and tested, the virtual machines are archived to preserve the software within. Many participants agreed to share their code so that we decided to collect the respective projects in a kind of open source proceedings at GitHub.14 4.3 by Straka and Strakov´a (2017) as one of the competing systems. Straka and Strakov´a (2017) describe both these versions in more detail. The baseline models were released together with the UD 2.0 training data, one model for each treebank. Because only training and development data were available during baseline model training, we put aside a part of the training data for hyperparameter tuning, and evaluated the baseline model performance on development data. We called this data split baseline model split. The baseline models, the baseline model split, and also UD 2.0 training data with morphology predicted by 10-fold jack"
K17-3001,K17-3022,1,0.891655,"Missing"
K17-3001,K17-3025,0,0.0327614,"Missing"
K17-3001,K17-3024,0,0.050508,"Missing"
K17-3001,K17-3027,0,0.0537913,"Missing"
K17-3001,K17-3014,0,0.0756362,"Missing"
K17-3001,K17-3015,0,0.0745209,"Missing"
K17-3001,K17-3007,0,0.0511894,"Missing"
K17-3001,L16-1262,1,0.869327,"Missing"
K17-3001,W14-6111,0,0.0253686,"Missing"
K17-3001,W17-0411,1,0.831758,"ossible when the system run completed; before that, even the task moderator would not see whether the system was really producing output and not just sitting in an endless loop. Especially given the scale of operations this year, this turned out to be a major obstacle for some participants; TIRA needs to be improved by offering more finegrained process monitoring tools, both for organizers and participants. Content-word Labeled Attachment Score (CLAS) has been proposed as an alternative parsing metric that is tailored to the UD annotation style and more suitable for cross-language comparison (Nivre and Fang, 2017). It differs from LAS in that it only considers relations between content words. Attachment of function words is disregarded because it corresponds to morphological features in other languages (and morphology is not evaluated in this shared task). Furthermore, languages with many function words (e.g., English) have longer sentences than morphologically rich languages (e.g., Finnish), hence a single error in Finnish costs the parser significantly more than an error in English. CLAS also disregards attachment of punctuation. As CLAS is still experimental, we have designated full LAS as our main"
K17-3001,K17-3003,0,0.0845341,"Missing"
K17-3001,W17-0412,1,0.869806,"Missing"
K17-3001,L16-1680,1,0.0475333,"Missing"
K17-3001,K17-3009,1,0.104147,"Missing"
K17-3001,tiedemann-2012-parallel,0,0.0126153,"oses (so that follow-up research is not obstructed). We deliberately did not place upper bounds on data sizes (in contrast to e.g. Nivre et al. (2007)), despite the fact that processing large amounts of data may be difficult for some teams. Our primary objective was to determine the capability of current parsers with the data that is currently available. In practice, the task was formally closed, i.e., we listed the approved data resources so that all participants were aware of their options. However, the selection was rather broad, ranging from Wikipedia dumps over the OPUS parallel corpora (Tiedemann, 2012) to morphological transducers. Some of the resources were proposed by the participating teams. 2.2 Supporting Data To enable the induction of custom embeddings and the use of semi-supervised methods in general, the participants were provided with supporting resources primarily consisting of large text corpora for (nearly) all of the languages in the task, as well as embeddings pre-trained on these corpora. 1 Outside CoNLL, there were several other parsing tasks in the meantime, which naturally also explored previously unadressed aspects—for example SANCL (Petrov and McDonald, 2012) or SPMRL (S"
K17-3001,K17-3016,0,0.0605417,"Missing"
K17-3001,K17-3020,0,0.0375614,"Missing"
K17-3001,K17-3013,0,0.0456211,"Missing"
K17-3001,D07-1096,1,\N,Missing
K17-3001,K17-3002,1,\N,Missing
K17-3001,K17-3019,0,\N,Missing
K17-3001,K17-3012,1,\N,Missing
K17-3001,K17-3006,0,\N,Missing
K17-3001,K17-3010,0,\N,Missing
K17-3001,K17-3018,0,\N,Missing
K17-3001,K17-3028,1,\N,Missing
K17-3001,K17-3011,0,\N,Missing
L16-1407,coltekin-2010-freely,0,0.179143,"set of the tagset of Bayyr-ool and Voinov (2012), that is it makes more distinctions rather than fewer distinctions, and as such conversion from our tagset to theirs would be feasible. 4. Development 4.1. Background The transducer is designed based on the Helsinki Finite State Toolkit (Linden et al., 2011) which is popular in the field of morphological analysis. It implements both the lexc formalism for defining lexicons, and the twol and xfst formalisms for modelling morphophonological rules. This toolkit has been chosen as it has been widely used for other Turkic languages, such as Turkish (Çöltekin, 2010), Kyrgyz (Washington et al., 2012), Kazakh, Tatar, and Kumyk (Washington et al., 2014), and is available under a free/open-source licence. 4.2. Morphotactics Tuvan morphotactics, like that of other Turkic languages is characterised by a concatenative suffixing morphology, with a large number of inflectional and derivational morphemes. 2562 1 http://www.apertium.org 4.2.1. Nominal The nominal morphotactics, used for modelling the inflection of nouns and substantivised adjectives, is essentially identical to that in use in previous transducers for Turkic languages (Washington et al., 2014, 2012)"
L16-1407,washington-etal-2014-finite,1,0.737216,"Missing"
L16-1407,L16-1407,1,0.0513221,"Missing"
L16-1409,E14-1060,0,0.0575171,"Missing"
L16-1409,Y10-1077,0,0.201912,"ملڪmulk ‘country’ demonstrating how badly encoded text is dealt with. The left side is the output and the right side is the input. Note that the [ ڪk] character also has initial, medial and final forms, but these are produced with a separate code point, ( ـU+0640). ble 2, also drawing a comparison with GF lexicon. There are total 72 paradigms in our analyser right now. for masculine nouns. 4. Developing the morphological analyser 4.1. Orthographic issues We initiated our work on developing Sindhi morphological analyser with the help of three resources. The first one was an article by (Rahman and Bhatti, 2010), which described how Sindhi nouns inflect. This aided us in creating our first few paradigms for nouns. Along with noun paradigms we also created paradigms for some closed categories, such as, prepositions, conjunctions, and open categories of adjectives and adverbs. The second resource was Sindhi GF library. It helped us in verifying some of the paradigms that we had already defined. It was also helpful in adding verb and pronoun paradigms and improve the paradigms for nouns. The third resource was a corpus, a collection of articles from Sindhi Wikipedia. Then, we used our knowledge of Sindh"
L16-1409,O12-1028,0,0.0415948,"Missing"
L18-1411,coltekin-2010-freely,0,0.0813053,"Missing"
L18-1411,P84-1038,0,0.316883,"exicon Lf and compose it with the two-level error rule ﬁle E , creating the transducer with all the possible strings Tf (this includes orthographic errors). After that, we subtract the strings in Tf that are in Tn and append a tag to each string indicating orthographic error, <err_orth>, and call this the error transducer Te . The ﬁnal transducer is the union of Tn and Te where each pair of erroneous surface form and analysis has a tag indicating it is an error at the end of the analysis. 4. 3.3. Morphophonology The morphophonological component is implemented using two-level morphology, twol (Koskenniemi, 1984); a total of 24 rules are applied to the lexical forms (see §3.1.) in order to produce surface forms. Results We calculate the naïve coverage for the analyser over a number of available corpora: Gagauz Wikipedia, a collection of 2 We chose Cyrillic {л} ‘l’ to represent this as Latin ‘l’ was used for the plural morpheme. 2589 Lexical form Morphotactic form insan<n><pl><px3sp><dat> ↔ insan>{L}{A}r>{s}{I}{n}>{й}{A} Table 1: Morphotactic representation of the surface form insannarına ‘to the people of’. The symbols within ‘{’ and ‘}’ characters are archiphonemes which may appear in the surface as"
L18-1411,C16-1325,1,0.80063,"analyser. Table 4 shows the coverage of each of the parts of speech according to the test corpus. Note that unlike the naïve coverage, this is a coverage of a random set of tokens and does not take frequency into account. Even so we can see that most of the unknown words come from the open classes (adjectives, nouns and proper nouns). Figure 2 gives an example of output from the transducer. 5. Future work As Gagauz is syntactically very close to Turkish, we would like to try cross-lingual methods to morphological disambiguation and dependency parsing. There is an existing treebank of Turkish (Sulubacak et al., 2016) in the format of the Universal Dependencies project and this would be ideal to train a statistical disambiguator. In addition we would also like to explore machine translation between Turkish and Gagauz using the Apertium platform (Forcada et al., 2011). It is worth noting that there are a number of problems in the phonological rules that we are intending to ﬁx. We would also like to expand the lexicon. 6. Concluding remarks We have presented the ﬁrst computational model of Gagauz morphology. The transducer has good coverage of a range of available corpora and can handle a range of issues rel"
L18-1411,washington-etal-2014-finite,1,0.90255,"s often not present and there is instead a long vowel. This is not limited to morphology, and some of the lexicon also exhibits this difference, as can be seen in the same example of Turkish daha and Gagauz taa ‘more’. Like many other languages post-Soviet nations, certain writing conventions have been adopted from Russian, such as a long dash – between the subject and predicate of a declarative sentence with a zero copula. Arab dili – angisindä laf eder arab halkı ‘The Arabic language – that which the Arab people speak.’ 3. Methodology Development broadly follows the methodology described in Washington et al. (2014), using the Helsinki FiniteState Toolkit, HFST (Lindén, 2009). This toolkit supports the lexc formalism for building lexicons and the twol for defining phonological constraints. It also supports weighted finite-state transducers. The system is composed of a lexical transducer implemented in the lexc formalism, and three phonological/orthographical transducers implemented in the twol formalism. For example, in the passive the archiphoneme is -{i}{л}2 , the {л} changes to n if it is preceeded by an -l-. For example the underlying form of bulunduk ‘we were found’ is bul-{i}{л}-{D}{I}-k. The twol"
R19-1101,W17-0109,0,0.0282931,"suggests that regarding ‘digital language divide’ such small regional languages must be represented more by creating and using resources in digital format. One of the drawbacks while working with these languages is clearly the small amount of data to begin with (written or spoken, annotated or nonannotated) (Riza, 2008). Current dominant computational methods and tools are mostly used on languages with large corpora, following a statistical approach to train their systems according to a relevant task. However, with little data at hand these methods may not present a good solution. Therefore, Gerstenberger et al. (2017) suggests a rulebased morpho-syntactic modelling for annotating small language data. On their study of Komi language, his results show by-far signiﬁcant advantages of rule-based approaches for endangered languages by providing much more precise results in tagging as well as ‘full- ﬂedged grammatical description based on broad empirical evidence’ and a future development for computer-assisted language learning systems. In this study, the aim is to create a morphological analyzer using the Helsinki Finite State Toolkit (HFST) that will help to overcome manual annotation of a potential Laz corpus"
R19-1101,I08-3018,0,0.107887,"ared and published by İsmail Bucaklişi and Hasan Uzunhasanoğlu. The following years, Bucaklişi also published the ﬁrst Laz grammar book (Kavaklı, 2015) and has begun teaching Laz at Boğaziçi University in İstanbul as an elective course since 2011. The foundation of the Lazika Publishing Collective in 2011 has given rise to the publication of more than 70 books on Laz language and literature (Kavaklı, 2015). Laz language is only one of many that faces the danger of extinction. By the end of this century, many will not survive with the decreasing number of the native speakers of such languages (Riza, 2008). This has alarmed not only native speakers of these languages but also research community to direct their attention for language documentation as well as preservation and revitalization studies for these languages (Ćavar et al., 2016; Gerstenberger et al., 2017). Bird (2009) calls out for a ‘new kind of computational linguistics’ in his paper that would protect this endangered invaluable cultural heritage by helping to accelerate these studies, and he ends his paper with these words ‘Who knows, we may even postpone the day when these languages utter their last words.’ which emphasizes the imp"
R19-1101,L16-1632,0,0.0693164,"Missing"
W12-5017,baldwin-awab-2006-open,0,0.0772183,"Missing"
W12-5017,C90-3030,0,0.0234013,"aTos method gave us about 12,000 translation entries, but also required a manual check due the amount of noise in the resulting data. Finally, some entries were added manually, which included closed word classes and words that frequently appeared in Wikipedia but were not yet added to the bilingual dictionary. 4.4 Disambiguation The output from the morphological analysis is disambiguated using Apertium’s statistical disambiguator module. The module implements a bigram part-of-speech tagger based on hidden Markov models (HMM). To improve the accuracy of our disambiguator, a Constraint Grammar (Karlsson, 1990) could be used as a pre-disambiguator module before feeding the input to the HMM, which is left for future work. 4.5 Lexical selection rules Given the closeness of the languages, lexical selection is not a large problem between Indonesian and Malaysian. However, a number of rules can be written for ambiguous words; for example, the Malaysian preposition daripada ‘from (to explain the origin of something), than (comparison)’ can be translated into Indonesian as either dari ‘from’ or daripada ‘than (comparison)’, depending on the surrounding context. Another example is the copulas adalah and ial"
W12-5017,J03-1002,0,0.00272472,"d the dictionary from scratch. At the moment, the bilingual dictionary contains 12,142 entries, which was developed in several ways described below. First, most of the entries were added using automatic word alignments. We created an Indonesian-Malaysian parallel corpus by translating many articles taken from Malaysian Wikipedia. The translation process is mostly automatic, with the help of existing MalaysianIndonesian machine translation systems such as Google Translate.6 Next the Wikipedia corpus is tagged using our morphological analyser, and word alignments were created by running GIZA++ (Och and Ney, 2003) on the tagged corpus. We fed the probabilistic dictionary into the ReTraTos toolbox (Caseli et al., 2006), which extracts both phrases and single-word translations from alignments, and converts them into Apertium translation entries. The ReTraTos method gave us about 12,000 translation entries, but also required a manual check due the amount of noise in the resulting data. Finally, some entries were added manually, which included closed word classes and words that frequently appeared in Wikipedia but were not yet added to the bilingual dictionary. 4.4 Disambiguation The output from the morpho"
W12-5017,P02-1040,0,0.0865117,"rious articles in Malaysian Wikipedia. The translation quality was measured using Word Error Rate (WER), a metric based on the 7 Here coverage is defined as naïve coverage, that is for any given surface form at least one analysis is returned by our monolingual dictionaries 8 http://id.wikipedia.org/; idwiki-20120429-pages-articles.xml.bz2 9 http://ms.wikipedia.org/; mswiki-20120428-pages-articles.xml.bz2 196 Levenshtein distance (Levenshtein, 1966). We calculated the WER for each sentence using the apertium-eval-translator10 tool. The WER metric was preferred to other MT metrics such as BLEU (Papineni et al., 2002) since we want to evaluate the system for the postedition task. That is, we want to assess the amount of manual labour needed to improve the machine-generated translation.11 For the Malaysian to Indonesian direction, the sentences were translated by the system, and then postedited by a native Indonesian speaker. For the Indonesian to Malaysian direction, we used the reference translation, as postedited by the native speaker and used it as a source of Indonesian to be translated to Malaysian, then the original Malaysian sentence was used as the reference translation. Corpus Direction Tokens Unk"
W12-5017,2011.freeopmt-1.12,1,0.854463,"tp://www.lmp.ucla.edu/Profile.aspx?menu=004&LangID=89 Last accessed: October 2012 192 We have chosen the rule-based approach, instead of the ubiquitous corpus-based statistical approach, due to the dearth of parallel corpora for the two languages. Moreover, the closeness between the two languages makes the rule-based approach favourable. Recent development for closely related languages with the rule-based approach have shown competitive performance with respect to the statistical approach, e.g. the rule-based Swedish→Danish system in Tyers and Nordfalk (2009) and the Italian→Catalan system in Toral et al. (2011), where both systems outperform a rivaling statistical-based system. 4 System The system is based on the Apertium machine translation platform (Forcada et al., 2011).2 The platform was originally aimed at the Romance languages of the Iberian peninsula, but has also been adapted for other, more distantly related language pairs. The whole platform, both programs and data, are licensed under the Free Software Foundation’s General Public Licence3 (GPL) and all the software and data for the 33 supported language pairs (and the other pairs being worked on) is available for download from the project"
W12-5017,2009.freeopmt-1.6,1,0.846319,"aluation of our system, which has not been done before. 1 http://www.lmp.ucla.edu/Profile.aspx?menu=004&LangID=89 Last accessed: October 2012 192 We have chosen the rule-based approach, instead of the ubiquitous corpus-based statistical approach, due to the dearth of parallel corpora for the two languages. Moreover, the closeness between the two languages makes the rule-based approach favourable. Recent development for closely related languages with the rule-based approach have shown competitive performance with respect to the statistical approach, e.g. the rule-based Swedish→Danish system in Tyers and Nordfalk (2009) and the Italian→Catalan system in Toral et al. (2011), where both systems outperform a rivaling statistical-based system. 4 System The system is based on the Apertium machine translation platform (Forcada et al., 2011).2 The platform was originally aimed at the Romance languages of the Iberian peninsula, but has also been adapted for other, more distantly related language pairs. The whole platform, both programs and data, are licensed under the Free Software Foundation’s General Public Licence3 (GPL) and all the software and data for the 33 supported language pairs (and the other pairs being"
W14-4612,N13-1131,0,0.049427,"Missing"
W14-4612,2005.mtsummit-papers.11,0,0.0302242,"All of the tweets had at least one instance of code-switching. 3.2 Alphabet n-gram approach We use the character n-gram approach along with some heuristics which are relevant to our problem domain of identifying segments for subsequent processing. We would like to both predict the code switched points but looking at the surrounding structure also decide the inclusion of them into the current or the next segment. We first built character language models using IRSTLM (Federico et al., 2008) for the five languages in question. For English and French a model was trained using the EuroParl corpus (Koehn, 2005). For Breton, Welsh and Irish we used corpora of text crawled from the web. To ensure no bias and also since our dataset for Breton was around 1.5 million, we sampled the same size of data for all the five languages. In order to build a character language model we replaced spaces with the underscore symbol ‘ ’, and then placed a space character between each character. Punctuation and non-letter characters are also part of this language model. For example, the word ‘sl´ainte!’ would be broken down into a sequence of {‘ s’, ‘s l’, ‘l a´ ’, ‘´a i’, ‘i n’, ‘n t’, ‘t e’, ‘e !’, ‘! ’}. 3.3 Sequence"
W14-4612,P12-3005,0,0.306843,"cribes an experiment to perform language identification on a sub-sentence basis. The typical case of language identification is to detect the language of documents or sentences. However, it may be the case that a single sentence or segment contains more than one language. This is especially the case in texts where code switching occurs. 1 Introduction Determining the language of a piece of text is one of the first steps that must be taken before proceeding with further computational processing. This task has received a substantial amount of attention in recent years (Cavnar and Trenkle, 1994; Lui and Baldwin, 2012). However, previous research has on the whole assumed that a given text will be in a single language. When dealing with text from formal domains, this may be the case — although there are exceptions — such as quotations embedded in the text in another language. But when dealing with informal text, particularly in languages where the speech community is predominantly bi- or multi-lingual, this assumption may not hold. The work presented in this paper was motivated by the problems in normalising non-standard input for the Celtic languages as a precursor to machine translation. When applying a no"
W14-4612,W03-0419,0,0.0590975,"Missing"
W15-1822,P85-1030,0,0.729048,"Missing"
W15-1822,P09-1014,0,0.0570332,"Missing"
W15-1822,D13-1088,0,0.815236,"Missing"
W15-1822,C90-3030,0,0.349582,"omatic stress placement State-of-the-art morphological analysis in Russian is based on finite-state technology (Nožov, 2003; Segalovich, 2003). To our knowledge, no existing open-source, broad-coverage resources are available for analyzing and generating stressed wordforms. Therefore, we developed free and opensource finite-state tools capable of analyzing and generating stressed wordforms, based on the wellknown Grammatical Dictionary of Russian (Zaliznjak, 1977). Our Finite-State Transducer4 (FST) generates all possible morphosyntactic readings of each wordform, and our Constraint Grammar5 (Karlsson, 1990; Karlsson et al., 1995) then removes some readings based on syntactic context. The ultimate success of our stress placement system depends on the performance of the constraint grammar. Ideally, the constraint grammar would successfully remove all but the correct reading for each token, but in practice some tokens still have more than one reading remaining. Therefore, we also evaluate various approaches to deal with the remaining ambiguity, as described below. Table 1 shows two possible sets of readings for the token kosti, as well as the output of each approach described below. The first colu"
W15-1822,P84-1038,0,0.617519,"e sets of readings for the token kosti, as well as the output of each approach described below. The first column exhibits stress ambiguity between the noun readings and the imperative verb reading. The second column shows a similar set of readings, after the constraint grammar has removed the imperative verb reading. This results in only stress-irrelevant ambiguity. The bare approach is to not mark stress on words with more than one reading. Since both sets of readings in Table 1 have more than one reading, bare does not output a stressed form. 4 Using two-level morphology (Koskenniemi, 1983; Koskenniemi, 1984), implemented in both xfst (Beesley and Karttunen, 2003) and hfst (Linden et al., 2011) 5 Implemented using vislcg3 constraint grammar parser (http://beta.visl.sdu.dk/cg3.html). Proceedings of the 20th Nordic Conference of Computational Linguistics (NODALIDA 2015) 175 Readings: bare safe randReading freqReading кость-N-F-SG-GEN kósti кость-N-F-SG-DAT kósti костить-V-IPFV-IMP kostí kosti kosti kósti (p=0.67) or kostí (p=0.33) kósti кость-N-F-SG-GEN kósti кость-N-F-SG-DAT kósti kosti kósti kósti kósti Table 1: Example output of each stress placement approach, given a particular set of readings f"
W15-1822,W12-2019,0,0.0237967,"Missing"
W15-1822,W83-0114,0,\N,Missing
W15-1827,N13-1037,0,0.0210163,"e method we present outperforms the baseline of simply treating colloquial Finnish as standard Finnish, but is outperformed by a phrase-based MT system trained by the evaluation corpus. The paper also presents preliminary results which show promise for using normalisation in the machine translation task. 1 Introduction Most language technology tools are designed or trained based on standard language forms, where they exist. The application of these tools to non-standard language can cause a substantial decrease in quality for example in machine translation, parsing and part-of-speech tagging (Eisenstein, 2013). Non-standard language can have different orthographic conventions, along with different morphology, syntax and stylistics. For language-technology researchers working on non-standard forms of language, there are two clear options: either create new tools to process non-standard text, or create tools to preprocess non-standard text, standardising it to be subsequently processed by existing tools. This paper evaluates a number of methods for converting colloquial Finnish to standard Finnish and describes a parallel corpus for evaluation. Francis M. Tyers HSL-fakultehta, UiT Norgga a´ rktalaˇs"
W15-1827,2005.mtsummit-papers.11,0,0.00563586,"s are then ranked using an n-gram language model of standard Finnish and either an n-best list or the best candidate is output. 4 Experiments 4.1 Rule-based normalisation For the rule-based normalisation we applied a set of regular-expression based replace rules to the input text to produce all the possible candidate sentences in standard Finnish and then used a target-language model to rank the possible candidates. The candidate with the highest rank was selected as the normalised sentence. For the targetlanguage model we used the Finnish side of the English–Finnish EuroParl parallel corpus (Koehn, 2005). We developed two sets of rules: • rules-1: 273 rules from Karlsson (2008)’s grammar of Finnish (§95–97). The rules took around one hour to implement. • rules-2: 98 rules written by examining the development corpus, these rules also took approximately one hour to implement. The rules included both simple one-to-one (‘m¨a’ → ‘min¨a’) and one-to-many (‘emm¨a’ → ‘en min¨a’) word correspondences, and also regular expression substitutions which could match a prefix or a suffix (‘(?+)nkaa’ → ‘1n kanssa’). Table 3 gives an example trace of the system on a simple sentence using three replace rules."
W15-1827,P12-2059,0,0.0213559,"emented using the Moses toolkit (Koehn et al., 2007). The training set up was that used for the baseline system in the WMT shared tasks on machine translation.4 The target-language model corpus, trained using KenLM (Heafield, 2011), used was the same as in the rule-based experiments. We trained models based on two approaches, the first being phrase-based machine translation (PBMT, Zens et al. (2002)) and the second on character-based machine translation 4 http://www.statmt.org/wmt11/baseline.html Proceedings of the 20th Nordic Conference of Computational Linguistics (NODALIDA 2015) 221 (CBMT, Nakov and Tiedemann (2012); Tiedemann (2009)). For both approaches we trained two systems, the first used the normalised part of the corpus as the target language; the second used the standardised part of the corpus as the target language. The idea behind this was that the normalised part of the corpus would be closer to the original colloquial text than the standardised part, making it easier to learn the alignment model. Character-based Nakov and Tiedemann (2012) present a method of statistical machine translation on the character level between related languages that takes advantage of phrase-based machine translatio"
W15-1827,W14-4605,0,0.10132,"eas of research related to the task of text normalisation. Text proofing tools, such as spelling and grammar checkers (Kukich, 1992) can be used to encourage adherence to particular orthographic or grammatical norms. Accent and diacritic restoration — for example in Scannell (2011) — is similar in that it aims to bring text closer to standard orthography in order to facilitate treatment by automatic tools. Another related area is machine translation between different written norms of the same language, for example between Norwegian Bokm˚al and Norwegian Nynorsk (Unhammer and Trosterud, 2009). Scannell (2014) presents a method for normalising pre-standardised text in Irish to the modern standard. The method relies on a translation model consisting of word-to-word correspondences in addition to spelling rules. Each word-toword mapping has the same conditional probability and a penalty is assigned to each spelling rule application. Decoding works by processing the source sentence word-for-word left-to-right, keeping track of the possible ‘hypothesis’ translations and their probabilities, and when the end of sentence is reached, the most probable is output. 2.1 Colloquial Finnish Viinikka and Voutila"
W15-1827,2009.eamt-1.3,0,0.0202674,"kit (Koehn et al., 2007). The training set up was that used for the baseline system in the WMT shared tasks on machine translation.4 The target-language model corpus, trained using KenLM (Heafield, 2011), used was the same as in the rule-based experiments. We trained models based on two approaches, the first being phrase-based machine translation (PBMT, Zens et al. (2002)) and the second on character-based machine translation 4 http://www.statmt.org/wmt11/baseline.html Proceedings of the 20th Nordic Conference of Computational Linguistics (NODALIDA 2015) 221 (CBMT, Nakov and Tiedemann (2012); Tiedemann (2009)). For both approaches we trained two systems, the first used the normalised part of the corpus as the target language; the second used the standardised part of the corpus as the target language. The idea behind this was that the normalised part of the corpus would be closer to the original colloquial text than the standardised part, making it easier to learn the alignment model. Character-based Nakov and Tiedemann (2012) present a method of statistical machine translation on the character level between related languages that takes advantage of phrase-based machine translation architecture. Th"
W15-1827,2009.freeopmt-1.7,0,0.0274341,"d work There are a number of areas of research related to the task of text normalisation. Text proofing tools, such as spelling and grammar checkers (Kukich, 1992) can be used to encourage adherence to particular orthographic or grammatical norms. Accent and diacritic restoration — for example in Scannell (2011) — is similar in that it aims to bring text closer to standard orthography in order to facilitate treatment by automatic tools. Another related area is machine translation between different written norms of the same language, for example between Norwegian Bokm˚al and Norwegian Nynorsk (Unhammer and Trosterud, 2009). Scannell (2014) presents a method for normalising pre-standardised text in Irish to the modern standard. The method relies on a translation model consisting of word-to-word correspondences in addition to spelling rules. Each word-toword mapping has the same conditional probability and a penalty is assigned to each spelling rule application. Decoding works by processing the source sentence word-for-word left-to-right, keeping track of the possible ‘hypothesis’ translations and their probabilities, and when the end of sentence is reached, the most probable is output. 2.1 Colloquial Finnish Vii"
W15-1827,W11-2123,0,0.0220311,"ne-to-one (‘m¨a’ → ‘min¨a’) and one-to-many (‘emm¨a’ → ‘en min¨a’) word correspondences, and also regular expression substitutions which could match a prefix or a suffix (‘(?+)nkaa’ → ‘1n kanssa’). Table 3 gives an example trace of the system on a simple sentence using three replace rules. 4.2 Statistical machine translation The statistical-machine translation approaches were implemented using the Moses toolkit (Koehn et al., 2007). The training set up was that used for the baseline system in the WMT shared tasks on machine translation.4 The target-language model corpus, trained using KenLM (Heafield, 2011), used was the same as in the rule-based experiments. We trained models based on two approaches, the first being phrase-based machine translation (PBMT, Zens et al. (2002)) and the second on character-based machine translation 4 http://www.statmt.org/wmt11/baseline.html Proceedings of the 20th Nordic Conference of Computational Linguistics (NODALIDA 2015) 221 (CBMT, Nakov and Tiedemann (2012); Tiedemann (2009)). For both approaches we trained two systems, the first used the normalised part of the corpus as the target language; the second used the standardised part of the corpus as the target l"
W15-1827,P07-2045,0,\N,Missing
W15-4918,J10-4005,0,0.031301,"t results depending on text domain and the relative number of gaps in a sentence. The paper is organised as follows: in section 2 we describe the gap-ﬁlling method for assimilation evaluation: the task layout, the choice of words, and how the tasks are generated. Section 3 introduces the experimental material, the evaluators, the distribution of tasks and the evaluation procedure. In section 4 we describe and discuss the experiment results. Finally, section 5 draws some conclusions. This paper is concerned primarily with assimilation evaluation; for a deeper discussion on evaluation see e.g. (Koehn, 2010, ch. 8). 2 Methodology This section discusses the reasoning behind the gap-ﬁlling method and task structure. The gapﬁlling method of evaluating machine translation for assimilation purposes is based on the following hypothesis: a reader’s understanding of a given text correlates with the number of words they are able to correctly restore in the text. Therefore, the base of an assimilation task is a (reference) sen2 https://github.com/Sereni/Appraise tence, where some of the words are blacked out, or removed. The sentence is produced by a human (as opposed to machine-translated), and it is in"
W15-4918,2000.tc-1.5,0,0.793401,"post-editing and comparison by bilingual experts (Ginestí-Rosell et al., 2009), and multiple choice tests (Jones et al., 2007; Trosterud and Unhammer, 2012). These approaches are often costly and prone to subjectivity: see the discussion by O’Regan and Forcada (2013). As an alternative, the modiﬁcation of cloze testing (Taylor, 1953) was introduced for assimilation evaluation, ﬁrst by Trosterud and Unhammer (2012) as a supplementary technique, and then by O’Regan and Forcada (2013) as a stand-alone method. Prior to this, cloze tests have been used to evaluate raw MT quality (Van Slype, 1979; Somers and Wild, 2000). While these authors ask informants to ﬁll gaps in MT output, Trosterud and Unhammer (2012) and O’Regan and Forcada (2013) ask informants to ﬁll gaps in the reference (human) translation. A designated number of keywords is removed from the human-translated sentences. The evaluators are then asked to ﬁll the gaps with suitable words with and without the help of MT output. The gap-ﬁlling task models how well users comprehend the key points of the text, as it is roughly equivalent with answering questions. Thus, the method does not directly evaluate the quality of machine-produced text, but rath"
W15-4918,2012.freeopmt-1.3,0,0.132569,"primary purpose. Despite the fact that, as a result of widespread usage of online MT, assimilation (or gisting) c 2015 The authors. This article is licensed under a Creative � Commons 3.0 licence, no derivative works, attribution, CCBY-ND. is currently the most frequent application of MT (in 2012, daily output of Google Translate matched the yearly output of human translations1 ), few methodologies are established for assimilation evaluation of MT. The methods include post-editing and comparison by bilingual experts (Ginestí-Rosell et al., 2009), and multiple choice tests (Jones et al., 2007; Trosterud and Unhammer, 2012). These approaches are often costly and prone to subjectivity: see the discussion by O’Regan and Forcada (2013). As an alternative, the modiﬁcation of cloze testing (Taylor, 1953) was introduced for assimilation evaluation, ﬁrst by Trosterud and Unhammer (2012) as a supplementary technique, and then by O’Regan and Forcada (2013) as a stand-alone method. Prior to this, cloze tests have been used to evaluate raw MT quality (Van Slype, 1979; Somers and Wild, 2000). While these authors ask informants to ﬁll gaps in MT output, Trosterud and Unhammer (2012) and O’Regan and Forcada (2013) ask informa"
W15-4919,J96-1002,0,0.236061,"s actually lexical selection in MT; they used a parser to identify syntactic relations such as subject–object or subject–verb. After generating all the possible translations for a given input sentence using an ambiguous bilingual dictionary, they extract the syntactic tuples from the TL and count the frequency in a previously-trained TL model of tuples. They use maximum-likelihood estimation to calculate the probability that a given 1 145 Such as a morphological or syntactic analyser. TL tuple is the translation of a given SL tuple, with an automatically determined conﬁdence threshold. Later, Berger et al. (1996) illustrated the use of maximum-entropy classiﬁers on the speciﬁc problem of lexical selection in IBM-style word-based statistical MT. Other authors (Melero et al., 2007) have used TL models to rank the translations resulting from all possible combinations of lexical selections. Nowadays, in state-of-the-art phrasebased statistical MT (Koehn, 2010), lexical selection is taken care of by a combination of the translation model and the language model. The translation model provides probabilities of translation between words or word sequences (often referred to as phrases) in the source and target"
W15-4919,J94-4003,0,0.496098,"putational cost. 1 Mikel L. Forcada Dept. Lleng. i Sist. Inform., Universitat d’Alacant, E-03071 Alacant 1.1 Introduction Corpus-based machine translation (MT) has been the primary research direction in the ﬁeld of MT in recent years. However, rule-based MT (RBMT) systems are still being developed, and there are many successful commercial and non-commercial systems. One reason for the continued development of RBMT systems is that in order to be successful, c 2015 The authors. This article is licensed under a Creative � Commons 3.0 licence, no derivative works, attribution, CCBY-ND. Prior work Dagan and Itai (1994) used the term word sense disambiguation to refer to what is actually lexical selection in MT; they used a parser to identify syntactic relations such as subject–object or subject–verb. After generating all the possible translations for a given input sentence using an ambiguous bilingual dictionary, they extract the syntactic tuples from the TL and count the frequency in a previously-trained TL model of tuples. They use maximum-likelihood estimation to calculate the probability that a given 1 145 Such as a morphological or syntactic analyser. TL tuple is the translation of a given SL tuple, wi"
W15-4919,W04-3250,0,0.066516,"tion module returns more than one translation, Apertium will select the default one if marked or the ﬁrst one of not.12 The table in Figure 2 gives an overview of the inputs.In the description it is assumed that the reference translation has been annotated by hand. However, hand annotation is a time-consuming process, and was not possible. A description of how the reference was built is given in Section 3.4. diﬀ(Tr (si ), Tt (si )) = 3.3.2 3.3.3 Conﬁdence intervals Conﬁdence intervals for both metrics will be calculated through bootstrap resampling (Efron and Tibshirani, 1994) as described by Koehn (2004). In all cases, bootstrap resampling will be carried out for 1,000 iterations. Where the p = 0.05 conﬁdence intervals overlap, we will also perform paired bootstrap resampling (Koehn, 2004). 3.4 For creating the test corpora, providing a SL corpus for training, and a TL corpus for scoring, we used four parallel corpora: • Oﬁs ar Brezhoneg (OAB): This parallel corpus of Breton and French has been collected speciﬁcally for lexical-selection experiments from translations produced by Oﬁs ar Brezhoneg ‘The Ofﬁce of the Breton language’. The corpus has recently been made available online through OPU"
W15-4919,2005.mtsummit-papers.11,0,0.0323006,"Oﬁs ar Brezhoneg ‘The Ofﬁce of the Breton language’. The corpus has recently been made available online through OPUS.13 • South-East European Times (SETimes): Described in Tyers and Alperen (2010), this corpus is a multilingual corpus of the Balkan languages (and English) in the news domain. The Macedonian and English part will be used. • Open Data Euskadi (OpenData): This is a Basque–Spanish parallel corpus made from the translation memories of the Herri Arduralaritzaren Euskal Erakundea ‘Basque Institute of Public Administration’.14 • European Parliament Proceedings (EuroParl): Described by Koehn (2005), this is a multilingual corpus of the European Union ofﬁcial languages. We are using the English–Spanish data from version 7.15 Machine translation performance This is an extrinsic evaluation, which ideally would test how much the system improves as regards an approximate measurement of ﬁnal translation quality in a real system. For this task, we use the widely-used BLEU metric (Papineni et al., 2002). This is not ideal for evaluating the task of a lexical selection module as the performance of the module will depend greatly on (a) the coverage of the bilingual dictionaries of the RBMT system"
W15-4919,J10-4005,0,0.0125822,"ey use maximum-likelihood estimation to calculate the probability that a given 1 145 Such as a morphological or syntactic analyser. TL tuple is the translation of a given SL tuple, with an automatically determined conﬁdence threshold. Later, Berger et al. (1996) illustrated the use of maximum-entropy classiﬁers on the speciﬁc problem of lexical selection in IBM-style word-based statistical MT. Other authors (Melero et al., 2007) have used TL models to rank the translations resulting from all possible combinations of lexical selections. Nowadays, in state-of-the-art phrasebased statistical MT (Koehn, 2010), lexical selection is taken care of by a combination of the translation model and the language model. The translation model provides probabilities of translation between words or word sequences (often referred to as phrases) in the source and target language. The TL model provides probabilities of word sequences in the TL. Mareˇcek et al. (2010) trained a maximum-entropy lexical selector for their dependency-grammar-based transfer system TectoMT using a bilingual corpus. More recently, Tyers et al. (2012) presented a method of lexical selection for RBMT based on rules which select or remove t"
W15-4919,P07-2045,0,0.0115657,"Missing"
W15-4919,W10-1730,0,0.0432849,"Missing"
W15-4919,P14-2123,0,0.0130906,"di follows arrain    0 otherwise (1) This feature considers a context of zero words to the left of the problem word and one word (+ handi) to the right of it. As a result of training, each of the nF features hsk (t, c) in the classiﬁer is assigned a weight λsk . Combining these weights of active features as in equation (2) yields the probability of a translation t for word s in context c. n ps (t|c) = (2) k=1 In this equation, Z s (c) is a normalising constant. Thus, the most probable translation t� can be found using t� = arg max ps (t|c) = arg max 2 The work by Ravi and Knight (2011) and Nuhn and Ney (2014), who decipher word-ciphered text using monolingual corpora only may be seen as a generalised version of the problem of lexical selection without parallel corpora. F � 1 λsk hsk (t, c) exp Z s (c) t∈Ts (s) 3 146 nF � t∈Ts (s) k=1 We follow the notation of Berger et al. (1996) λsk hsk (t, c), (3) S→ preposti=|G| → ({gi }i=1 , S) → lexsel → (g � , S) → → τ (g � , S) lexsel lexsel Figure 1: A schema of the lexical selection process: source sentence S has |G |lexical selection paths gi : lexsel selects one of them g � , which is used to generate translation τ (g � , S). where Ts (s) is the set of"
W15-4919,J03-1002,0,0.007507,"hough for all pairs there is a parallel corpus available for evaluation (see Section 3.3).5 Breton–French (Tyers, 2010): Bilingual dictionaries were not built with polysemy in mind from the outset, but some entries were added later to start work on lexical selection.6 Macedonian–English: The Macedonian–English pair in Apertium was created speciﬁcally for the purposes of running lexical-selection experiments. The lexical resources for the pair were tuned to the SETimes parallel corpus (Tyers and Alperen, 2010). The most probable entry from automatic word alignment of this corpus using GIZA ++ (Och and Ney, 2003) was checked to ensure that it was an adequate translation, and if so marked as the default.7 As a result of attempting to include all possible translations, the average number of translations per word is much higher than in other pairs.8 Basque–Spanish (Ginest´ı-Rosell et al., 2009): alternative translations were included in the bilingual dictionary.9 English–Spanish: The English–Spanish pair was developed from a combination of the English– Catalan and Spanish–Catalan pairs, and contains a number of entries in the bilingual dictionary with more than one translation.10 3.3 Performance measures"
W15-4919,P02-1040,0,0.0984287,"Missing"
W15-4919,P11-1002,0,0.0208438,"rrain  +handi (t, c) = handi follows arrain    0 otherwise (1) This feature considers a context of zero words to the left of the problem word and one word (+ handi) to the right of it. As a result of training, each of the nF features hsk (t, c) in the classiﬁer is assigned a weight λsk . Combining these weights of active features as in equation (2) yields the probability of a translation t for word s in context c. n ps (t|c) = (2) k=1 In this equation, Z s (c) is a normalising constant. Thus, the most probable translation t� can be found using t� = arg max ps (t|c) = arg max 2 The work by Ravi and Knight (2011) and Nuhn and Ney (2014), who decipher word-ciphered text using monolingual corpora only may be seen as a generalised version of the problem of lexical selection without parallel corpora. F � 1 λsk hsk (t, c) exp Z s (c) t∈Ts (s) 3 146 nF � t∈Ts (s) k=1 We follow the notation of Berger et al. (1996) λsk hsk (t, c), (3) S→ preposti=|G| → ({gi }i=1 , S) → lexsel → (g � , S) → → τ (g � , S) lexsel lexsel Figure 1: A schema of the lexical selection process: source sentence S has |G |lexical selection paths gi : lexsel selects one of them g � , which is used to generate translation τ (g � , S). whe"
W15-4919,2010.eamt-1.13,1,0.828127,"uild RBMT systems. Translation is implemented as a pipeline consisting of the following modules: morphological analysis, morphological disambiguation, lexical transfer, lexical selection, structural transfer and morphological generation. 3.2 Language pairs Evaluation will be performed using four Apertium (Forcada et al., 2011) language pairs. These pairs have been selected as they include languages with different morphological complexity, and different amounts of resources available — although for all pairs there is a parallel corpus available for evaluation (see Section 3.3).5 Breton–French (Tyers, 2010): Bilingual dictionaries were not built with polysemy in mind from the outset, but some entries were added later to start work on lexical selection.6 Macedonian–English: The Macedonian–English pair in Apertium was created speciﬁcally for the purposes of running lexical-selection experiments. The lexical resources for the pair were tuned to the SETimes parallel corpus (Tyers and Alperen, 2010). The most probable entry from automatic word alignment of this corpus using GIZA ++ (Och and Ney, 2003) was checked to ensure that it was an adequate translation, and if so marked as the default.7 As a re"
W15-4919,2012.eamt-1.54,1,0.760313,"Missing"
W15-4919,H05-1097,0,0.0938983,"Missing"
W17-0214,E06-1032,0,0.0750094,"ew Testament on the other hand is rather well covered and has practically uniformly distributed coverage throughout. To measure the performance of the translator we used the Word Error Rate metric—an edit-distance metric based on Levenshtein distance (Levenshtein, 1966). We had three small North Sámi corpora along with their manually post-edited translations into Finnish to measure the WER. We have chosen not to measure the translation quality with automatic measures such as BLEU, as they are not the best suited to measure quality of translations for the use case, for further details see also Callison-Burch et al. (2006; Smith et al. (2016; Smith et al. (2014). For translation post-edition we used three freely Evaluation All evaluation was tested against a specific version of Apertium SVN10 and Giellatekno SVN11 . The lexical coverage of the system was calculated over freely available corpora of North Sámi. We used a recent dump of Wikipedia 12 as well as a translation of the New Testament. The corpora were divided into 10 parts each; the coverage numbers given are the averages of the calculated percentages of number of words analysed for each of these parts, and the standard deviation presented is the 9 Cf."
W17-0214,C90-3030,0,0.279036,"Missing"
W17-0214,2009.eamt-1.17,1,0.752397,"and North Sámi. The paper will be laid out as follows: Section 2 gives a short review of some previous work in the area of Uralic-Uralic language machine translation; Section 3 introduces Finnish and North Sámi and compares their grammar; Section 4 describes the system and the tools used to construct it; Section 5 gives a preliminary evaluation of the system; and finally Section 6 describes our aims for future work and some concluding remarks. 2 Previous work Within the Apertium platform, work on several MT systems from North Sámi to Norwegian and to other Sámi languages have been developed (Tyers et al., 2009; Wiechetek et al., 2010; Trosterud and Unhammer, 2013; Antonsen et al., 2016)). Besides these systems, several previous works on making machine translation systems between Uralic languages exist, although to our knowledge none are publicly available, except for North Sámi 1 https://gtweb.uit.no/jorgal 0 Authors 2 https://translate.google.com are listed here alphabetically 115 Proceedings of the 21st Nordic Conference of Computational Linguistics, pages 115–122, c Gothenburg, Sweden, 23-24 May 2017. 2017 Link¨oping University Electronic Press velopment will be needed to fulfil such a function."
W17-0214,W13-5631,1,0.852792,"16 4.1 Architecture of the system 4.2 Morphological transducers The morphological transducers are compiled with the Helsinki Finite State Technology (Lindén et al., 2009),5 a free/open-source reimplementation of the Xerox finite-state tool-chain, popular in the field of morphological analysis. It implements both the lexc morphology description language for defining lexicons, and the twol and xfst scripting languages for modeling morphophonological rules. This toolkit has been chosen as it—or the equivalent XFST—has been widely used for other Uralic languages (Koskenniemi, 1983; Pirinen, 2015; Moshagen et al., 2013), and is available under a free/open-source licence. The morphologies of both languages are implemented in lexc, and the morphophonologies of both languages are implemented in twolc. The same morphological description is used for both analysis and generation. To avoid overgeneration, any alternative forms are marked with one of two marks, LR (only analyser) or RL (only generator). Instead of the usual compile/invert to compile the transducers, we compile twice, once the generator, without the LR paths, and then again the analyser without the RL paths. The Apertium translation engine consists o"
W17-0214,2013.mtsummit-papers.22,1,0.550659,"T Norgga Árktalaš universitehta, Giela ja kultuvrra instituhtta, Romssa, Norga  Universität Hamburg, Hamburger Zentrum für Sprachkorpora, Deutschland  Institute of the Estonian Language, Estonia ryan.txanson@gmail.com, tommi.antero.pirinen@uni-hamburg.de, tiina.puolakainen@eki.ee, {francis.tyers, trond.trosterud}@uit.no kevin@unhammer.org to Norwegian1 , and the translation between Estonian, Finnish and Hungarian being available via English as a pivot language in Google Translate.2 For non-Uralic pairs there are also numerous similarly laid out systems e.g. in Apertium’s Turkic pairs, e.g. (Salimzyanov et al., 2013), that can offer insights on how the pair is implemented, which are detailed later in the article but the main parts are the same. Abstract This paper presents a machine translation system between Finnish and North Sámi, two Uralic languages. In this paper we concentrate on the translation direction to Finnish. As a background, the differences between the two languages is presented, followed by how the system was designed to handle some of these differences. We then provide an evaluation of the system’s performance and directions for future work. 1 3 The languages North Sámi and Finnish belong"
W17-0214,W16-3414,0,0.0155283,"d is rather well covered and has practically uniformly distributed coverage throughout. To measure the performance of the translator we used the Word Error Rate metric—an edit-distance metric based on Levenshtein distance (Levenshtein, 1966). We had three small North Sámi corpora along with their manually post-edited translations into Finnish to measure the WER. We have chosen not to measure the translation quality with automatic measures such as BLEU, as they are not the best suited to measure quality of translations for the use case, for further details see also Callison-Burch et al. (2006; Smith et al. (2016; Smith et al. (2014). For translation post-edition we used three freely Evaluation All evaluation was tested against a specific version of Apertium SVN10 and Giellatekno SVN11 . The lexical coverage of the system was calculated over freely available corpora of North Sámi. We used a recent dump of Wikipedia 12 as well as a translation of the New Testament. The corpora were divided into 10 parts each; the coverage numbers given are the averages of the calculated percentages of number of words analysed for each of these parts, and the standard deviation presented is the 9 Cf. (Antonsen and Trost"
W17-0215,antonsen-etal-2010-reusing,1,0.791733,"native. smn shares the system of grammatical and local cases with sme, but has two extra cases: partitive and abessive (corresponding to the sme postpositional phrase N haga (‘without N’)). smn also makes a distinction between accusative and genitive, most notably in the plural. sma and smj have a richer case system than sme: their genitive and accusative forms are always distinct from each other. Moreover, unlike the locative case syncretism in sme for in and from spatial relations, these languages encode the two different 4 For a presentation of the grammatical analysers and generators, see Antonsen et al. (2010) and Antonsen and Trosterud (forthcoming). 124 Figure 1: Translation pipeline and processing example for Son bargá vuođđoeláhusas ‘He works in-the-primary-sector’ from sme to sma relations by inessive and elative case, respectively. Hence, given the case syncretism of the SL, one of the challenges for the MT system is to make the contextually correct case distinction in the target language. In NP-internal agreement in sme, the adjective does not agree with its head noun, but gets a separate attributive form, invariant in the different cases, but marking membership in the NP. In principle, all"
W17-0215,2007.mtsummit-papers.5,0,0.0164904,"ion 2), give an overview of the project (Section 3), describe the evaluation method of the systems (Section 4) and discuss different aspects of the evaluation method (Section 5). Finally, we point out the importance of such systems both for research and for society (Section 6). 2.1 Previous work The literature on Saami MT includes several works. Relevant here is an article about an early version of an MT system sme → sma on a limited domain, where sme is used as pivot language for nob to sma translation (Antonsen et al., 2016)3 . In a study on pivot translation for under-resourced languages, (Babych et al., 2007) a Ukrainian– English RBMT system performes better with the 2 http://www.ethnologue.com and Pasanen (2015) other works are (Tyers et al., 2009) on an early sme → smj system, comparing rule-based and statistical MT, (Wiechetek et al., 2010) on lexical selection rules for the same language pair, and (Trosterud and Unhammer, 2013) on an evaluation of a sme → nob system. 3 The 1 We will refer to the working languages by their language code: sma, sme, smj and smn for South, North, Lule and Inari Saami, as well as nob and fin for Norwegian Bokmål and Finnish. 123 Proceedings of the 21st Nordic Confe"
W17-0215,2010.eamt-1.35,0,0.0793857,"Missing"
W17-0215,2009.eamt-1.17,1,0.330131,"the evaluation method (Section 5). Finally, we point out the importance of such systems both for research and for society (Section 6). 2.1 Previous work The literature on Saami MT includes several works. Relevant here is an article about an early version of an MT system sme → sma on a limited domain, where sme is used as pivot language for nob to sma translation (Antonsen et al., 2016)3 . In a study on pivot translation for under-resourced languages, (Babych et al., 2007) a Ukrainian– English RBMT system performes better with the 2 http://www.ethnologue.com and Pasanen (2015) other works are (Tyers et al., 2009) on an early sme → smj system, comparing rule-based and statistical MT, (Wiechetek et al., 2010) on lexical selection rules for the same language pair, and (Trosterud and Unhammer, 2013) on an evaluation of a sme → nob system. 3 The 1 We will refer to the working languages by their language code: sma, sme, smj and smn for South, North, Lule and Inari Saami, as well as nob and fin for Norwegian Bokmål and Finnish. 123 Proceedings of the 21st Nordic Conference of Computational Linguistics, pages 123–131, c Gothenburg, Sweden, 23-24 May 2017. 2017 Link¨oping University Electronic Press Figure 1 o"
W17-0607,C16-1325,1,0.827327,"Missing"
W17-4006,E09-2008,0,0.0937046,"Missing"
W17-6509,W14-0101,0,0.0351119,"Missing"
W17-6509,W15-1807,0,0.250995,"trees, for example Ezê ‘I will’ will be shown as ⁅Ez- -ê⁆. contracted with the ﬁrst person singular pronoun. 4.2 Preprocessing Preprocessing the corpus consists of running the text through the Kurmanji morphological analyser available from Apertium (Forcada et al., 2011), which also performs tokenisation of multi-word units based on the longest match left-to-right. The morphological analyser returns all the possible morphological analyses for each word based on a lexicon of around 13,800 lexemes. After tokenisation and morphological analysis, the text is processed with a constraint-grammar (Bick and Didriksen, 2015) based disambiguator for Kurmanji consisting of 85 rules which remove inappropriate analyses in kuwiki-20150901-pagesCoNLL-U is the ﬁle format used in Universal Dependencies for storing treebanks. A description of the format can be found here: http://universaldependencies. = construct case, The tags used in the glosses are: = oblique case, = progressive aspect, = narrative tense, 2 = second person singular. https://svn.code.sf.net/p/apertium/ org/format.html svn/languages/apertium-kmr 66 collaborative project to make cross-linguistically consistent treebanks available for a wide variety of"
W17-6509,K17-3001,1,0.882123,"Missing"
W17-6509,P13-2054,0,0.0308189,"gs by Celadet Ali Bedirxan himself, in most languages of the Middle East, French and English. Many of these grammars are written for the purpose of teaching beginners, and most of these introductory grammars lack important details required for proper linguistic reference. Many grammars also have a good deal of inﬂuence from majority languages in the countries they were written. This particularly comes to light when the writer of a grammar describes and thinks about elements of Kurmanji with analogy to Turkish. A text corpus of Kurmanji and Sorani Kurdish by the name of Pewan was introduced in Esmaili and Salavati (2013). Pewan is a plaintext corpus created for the purpose of information retrieval, and was the Original title: The Adventure of the Speckled Band. Bişarê Segman is widely believed to be a nom de plume of Celadet Berdixan, who died in 1951. http://bnk.institutkurde.org/ 65 Text S T T /S non-proj Dr. Rweylot Wikipedia 339 415 4,717 5,543 13.9 13.4 17.9 16.6 Total: 780 10,260 13.2 17.2 phological analyser in the lemma column, e.g. both heya and heye will have the lemma hebûn (the existential copula). Another orthography issue becomes apparent in tokenisation. In the Sherlock story, in some cases"
W17-6509,Q16-1023,0,0.0266522,"lowing sentence, Wextê Holmes vegeriya...saet jî bû bû yek, “By the time Holmes returned, the clock had struck one’, the subordinationg conjunction wextê ‘by’ introduces the adverbial clause. ccomp cop hatine 5.8.3 Adverbial clauses punct nsubj ku Con ? ? advcl nsubj 5.8.2 Relative clauses Relative clauses can be introduced in three ways, which are not necessarily mutually exclusive. mark nsubj 6 Parsing performance In order to test the treebank in a real setting, we evaluated three widely-used popular dependency parsers: Maltparser (Nivre et al., 2007), UDPipe (Straka et al., 2016) and BiST (Kiperwasser and Goldberg, 2016). In addition we provide results for using the treebank for part-of-speech tagging using UDPipe, to be able to compare with Walther et al. (2010). The BiST parser requires a separate development set for tuning. The set we used was the sample data from the shared task, this was 20 sentences, or 242 tokens. Both UDPipe and BiST parsers are also able to use word embeddings, we trained the embeddings using word2vec (Mikolov et al., 2013) on the raw text of the Kurdish Wikipedia. For Maltparser we used the default settings and for BiST parser we tested the MST algorithm. We performed 10-fold cross-"
W17-6509,L16-1680,0,0.118849,"s in the region, many speakers of the various dialects of Kurmanji are not aware of a Kurdish literature, and some are even shocked to learn that Kurdish languages are written at all. Kurmanji has two grammatical genders, masculine and feminine; four cases: nominative, oblique, construct and vocative; and deﬁniteness marked on nouns. The language has prepositions and postpositions, and also combinations of these which form circumpositions. Verbs are formed from two stems, past and present. 1 Introduction With current end-to-end pipelines for tokenisation, tagging and parsing, such as UDPipe (Straka et al., 2016), a treebank is no longer simply a collection of annotated sentences, but could be considered a vital basic language resource. Given just the treebank a statistical model can be trained which performs everything up to dependency parsing. This paper describes such a treebank for Kurmanji Kurdish, a language spoken in parts of Iran, Iraq, Syria, Armenia and Turkey. The treebank was created as one of the surprise languages for the CoNLL 2017 shared task in dependency parsing (Zeman et al., 2017); but it is hoped that it provides a template for further development of language technology for Kurma"
W17-7604,W15-1807,0,0.0687409,"Missing"
W17-7604,W17-6514,0,0.0861331,"Missing"
W17-7604,W13-3711,0,0.0803227,"The collection today includes over 100 treebanks for over 54 languages, making it among the most diverse collections of freely-available openly-licensed language data. A large proportion of the treebanks currently available through Universal Dependencies are conversions from previous annotation schemes. However, recently treebanks are being released which have been annotated from scratch, leading to the need for annotation interfaces. There are a number of existing interfaces in use for annotating UD treebanks from scratch, from the web-based such as B (Stenetorp et al., 2012) and Arborator (Gerdes, 2013) to offline tools like TrEd 2 and the TDT Editor of the Turku Dependency Treebank (Haverinen et al., 2014).3 One of the things that these tools have in common is that they are not designed specifically for Universal Dependencies and so do not provide a convenient way of treating issues such as the two-level segmentation scheme (where a single surface token may be split into several syntactic words, e.g. Spanish dímelo ‘say it to me’ → dí|me|lo) and generally cannot take advantage of the annotation guidelines to provide validation feedback to the user (for example punctuation nodes may not have"
W17-7604,W17-6509,1,0.716851,"Missing"
W17-7604,W17-0233,0,0.0828359,"Missing"
W17-7604,L16-1262,0,0.119445,"Missing"
W17-7604,W17-0412,0,0.040061,"Missing"
W17-7618,W14-6502,0,0.0281697,"mes different levels of orthographic normalisation. The corpus includes a non-disambiguated sub-corpus and a disambiguated one (see Table 1 for statistics about its composition). In the nondisambiguated sub-corpus, there is only Bambara texts without any annotation. Annotation in the disambiguated sub-corpus, consists of part-of-speech tags, glosses and a respective token in a normalized orthography (with tones). A user is able either to search the entire corpus or to limit their search to the disambiguated sub-corpus. Texts have been and continue to be disambiguated by volunteers using Daba (Maslinsky, 2014), a morphological analyser based on a language-independent framework dictionary and = presentative copula; = locative copula; = equative copula; = negative copula; = imperfective predicative marker; = infinitive predicative marker; = quotative ‘copula’; = prohibitive predicative marker; = plural; NP = noun phrase; = relative pronoun/determinative; . = negative perfective predicatve marker; = suffix, which derives a dynamic verb from a qualitative verb. 139 Figure 1: Example of a disambiguated sentence. The output format is machine-readable HTML. A free translation of the sentence into English"
W17-7618,L16-1262,0,0.0783429,"Missing"
W17-7618,W17-0417,0,0.0195728,"y are treated as conjunctions. We manually resolved these ambiguities, annotating them with the appropriate universal tag according to context. We used the following language-specific features for Bambara: AdjType=Attr was used for adjectives with the suffix -/man/ and Valency=1 was used for intransitive verbs, while Valency=2 was used for transitive verbs. The feature AdjType=Attr is also used in the Afrikaans treebank to mark attributive adjectives (in Afrikaans adjectives have separate attributive and predicative forms). The feature Valency=1 has been proposed for use in the Ainu treebank (Senuma and Aizawa, 2017). 3 A reviewer suggests that we could have these as separate tokens with the part of speech tag AUX for both parts and the dependency relation fixed. As this would allow us to maintain the same tokenisation as the original we are planning to implement this change. 140 In addition to converting the part-of-speech tags and morphological features a number of sentences were annotated for dependencies using the UD A annotation tool (Tyers et al., 2018) by a single annotator in discussion with various linguists while developing the guidelines. 5 Dependency scheme In this section, we describe some of"
W17-7618,L16-1680,0,0.0118327,"an existing part-of-speech annotated corpus of Bambara, which contains approximately 900,000 tokens. We also describe the annotation of a small treebank of 116 sample sentences, which were picked randomly. 1 Introduction One of the basic language resources has, for a long time, been a part-of-speech tagged (or morphologically disambiguated) corpus. In recent years, treebanks — collections of sentences annotated for syntactic structure — have become increasingly available and vital resources, both for natural-language processing and corpus linguistics. Current end-to-end pipelines like UDPipe (Straka et al., 2016), which perform each stage of the classic NLP pipeline from tokenisation to dependency parsing, make it easy to go from a situation where a language has no effective language resources to one where the language has a functional pipeline in a few months as opposed to a few years of work. A crucial prerequisite for building a treebank is to have a set of annotation guidelines which describe how particular syntactic structures are to be represented. In our work on creating a treebank for Bambara we have chosen version 2.0 of the Universal Dependencies scheme (Nivre et al., 2016) as it provides re"
W18-4804,L18-1416,0,0.563474,"d the lexicon. Unfortunately there are no other machine-readable published dictionaries of Chukchi, so to a certain extent this would need to be done by hand. One possible approach would be to use a guesser module which could guess the tags for unknown roots and then check them manually. We are also planning to come up with a solution for incorporation and compounding and are currently investigating possible approaches. A third idea is to look at reworking some of the phonological processes. Either by splitting all of the processes into separate rules by switching to rewrite rules, as in e.g. Chen and Schwartz (2018), or alternatively having several levels of two-level rules, e.g. splitting the application of schwa epenthesis (see Figure 3) into a separate ruleset. As this project is now cooperating with the research community working on Amguema dialect, another possible avenue for improvement would be to adapt the analyser to this variety of Chukchi. In the longer term, we would like to investigate the creation of a spellchecker, although the coverage of the lexicon is currently too small, the sparsity of corpus data and the complexity of Chukchi morphology make ﬁnite-state spellchecking, such as descri"
W18-4804,E09-2008,0,0.708413,"aps between surface forms and lexical forms (lemmas and morphosyntactic tags). An analyser of this sort has a wide variety of uses, including for automating the process of corpus annotation for linguistic research as well as for creating prooﬁng tools (such as spellcheckers) and for lemmatising for electronic dictionary lookup for language learners — in a language with heavy preﬁxing and suﬃxing morphology, determining the stem is not a simple matter. Our approach is based on the Helsinki Finite-State Toolkit (HFST, Linden et al. (2011)). We chose this toolkit over other toolkits such as foma Hulden (2009), as in addition to the xfst sequential rule formalism it also supports two-level phonological rules and weighted automata. We took an existing machine-readable dictionary and converted it to the lexc lexicon format, we then implemented the morphotactics (morpheme combinatorics) in lexc and used two-level (twol) rules for modelling phonological and some morphotactic constraints. The remainder of the paper is laid out as follows: Section 2 gives a short introduction to Chukchi from a grammatical and sociolinguistic perspective; Section 3 describes other attempts at building a morphological anal"
W18-4804,W17-0102,0,0.286157,"The transducer described in this paper is designed based on the Helsinki Finite State Toolkit (HFST, (Linden et al., 2011)), which is popular in the ﬁeld of morphological analysis. It implements both the lexc formalism for deﬁning lexicon and morphotactics, and the twol and xfst formalisms for modelling morphophonological rules. This toolkit has been chosen because it, or the related foma (Hulden, 2009), has been widely used for other agglutinative and polysynthetic languages, such as Navajo (Hulden and Bischoﬀ, 2008), the Dene languages (Arppe et al., 2017), Quechua (Rios, 2016) and Arapaho (Kazeminejad et al., 2017), and is available under a free/open-source licence. A ﬁnite-state transducer is a formal way to map surface forms and analyses (lexical forms) to one another. For example, гэӈээккэтэ /ɣeŋeekkete/ ‘ -daughter’ would receive the analysis ӈээккэт&lt;n&gt;&lt;com&gt;. The transducer accepts the form as input and outputs the analysis, and vice versa. When used for modelling natural-language morphology, a ﬁnite-state transducer is a directed graph where the arcs encode relations between input symbols and output symbols. These symbols may be letters, linguistic tags or archiphonemes Analysing or generating a"
W18-5412,P18-1027,0,0.0235091,"duction In recent years, recurrent neural network (RNN) models have emerged as a powerful architecture for a variety of NLP tasks (Goldberg, 2017). In particular, gated versions, such as Long Short-Term Networks (LSTMs) (Hochreiter and Schmidhuber, 1997) and Gated Recurrent Units (GRU) (Cho et al., 2014; Chung et al., 2014) achieve state-of-the-art results in tasks such as language modeling, parsing, and machine translation. RNNs were shown to be able to capture longterm dependencies and statistical regularities in input sequences (Karpathy et al., 2015; Linzen et al., 2016; Shi et al., 2016; Jurafsky et al., 2018; Gulordava et al., 2018). An adequate evaluation of 98 Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, pages 98–107 c Brussels, Belgium, November 1, 2018. 2018 Association for Computational Linguistics hierarchal relations between sentence constituents. Labeled data for such a task requires only the collection of sentences that exhibit agreement from an unannotated corpora. However, those works have focused on relatively small set of languages: several Indo-European languages and a Semitic language (Hebrew). As we show, drawing conclusio"
W18-5412,P81-1022,0,0.172915,"Missing"
W18-5412,P15-1033,0,0.0132923,"rn to Capture Agreement? The Case of Basque Shauli Ravfogel1 and Francis M. Tyers2,3 and Yoav Goldberg1,4 1 Computer Science Department, Bar Ilan University 2 School of Linguistics, Higher School of Economics 3 Department of Linguistics, Indiana University 4 Allen Institute for Artificial Intelligence {shauli.ravfogel, yoav.goldberg}@gmail.com, ftyers@prompsit.com Abstract the ability of RNNs to capture syntactic structure requires a use of established benchmarks. A common approach is the use of an annotated corpus to learn an explicit syntax-oriented task, such as parsing or shallow parsing (Dyer et al., 2015; Kiperwasser and Goldberg, 2016; Dozat and Manning, 2016) . While such an approach does evaluate the ability of the model to learn syntax, it has several drawbacks. First, the annotation process relies on human experts and is thus demanding in term of resources. Second, by its very nature, training a model on such a corpus evaluates it on a human-dictated notion of grammatical structure, and is tightly coupled to a linguistic theory. Lastly, the supervised training process on such a corpus provides the network with explicit grammatical labels (e.g. a parse tree). While this is sometimes desir"
W18-5412,Q16-1023,1,0.870669,"Missing"
W18-5412,Q16-1037,1,0.856665,"he model’s ability to capture regularities in language. While this approach does not suffer from the above discussed drawbacks, it conflates syntactical capacity with other factors such as world knowledge and frequency of lexical items. Furthermore, the LM task does not provide one clear answer: one cannot be “right” or “wrong” in language modeling, only softly worse or better than other systems. A different approach is testing the model on a grammatical task that does not require an extensive grammatical annotation, but is yet indicative of syntax comprehension. Specifically, previous works (Linzen et al., 2016; Bernardy and Lappin, 2017; Gulordava et al., 2018) used the task of predicting agreement, which requires detecting Sequential neural networks models are powerful tools in a variety of Natural Language Processing (NLP) tasks. The sequential nature of these models raises the questions: to what extent can these models implicitly learn hierarchical structures typical to human language, and what kind of grammatical phenomena can they acquire? We focus on the task of agreement prediction in Basque, as a case study for a task that requires implicit understanding of sentence structure and the acquis"
W18-5412,D16-1159,0,0.0332025,"language. 1 Introduction In recent years, recurrent neural network (RNN) models have emerged as a powerful architecture for a variety of NLP tasks (Goldberg, 2017). In particular, gated versions, such as Long Short-Term Networks (LSTMs) (Hochreiter and Schmidhuber, 1997) and Gated Recurrent Units (GRU) (Cho et al., 2014; Chung et al., 2014) achieve state-of-the-art results in tasks such as language modeling, parsing, and machine translation. RNNs were shown to be able to capture longterm dependencies and statistical regularities in input sequences (Karpathy et al., 2015; Linzen et al., 2016; Shi et al., 2016; Jurafsky et al., 2018; Gulordava et al., 2018). An adequate evaluation of 98 Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, pages 98–107 c Brussels, Belgium, November 1, 2018. 2018 Association for Computational Linguistics hierarchal relations between sentence constituents. Labeled data for such a task requires only the collection of sentences that exhibit agreement from an unannotated corpora. However, those works have focused on relatively small set of languages: several Indo-European languages and a Semitic language (Hebrew). As we"
W18-5412,N18-1108,0,0.608688,"nguage. While this approach does not suffer from the above discussed drawbacks, it conflates syntactical capacity with other factors such as world knowledge and frequency of lexical items. Furthermore, the LM task does not provide one clear answer: one cannot be “right” or “wrong” in language modeling, only softly worse or better than other systems. A different approach is testing the model on a grammatical task that does not require an extensive grammatical annotation, but is yet indicative of syntax comprehension. Specifically, previous works (Linzen et al., 2016; Bernardy and Lappin, 2017; Gulordava et al., 2018) used the task of predicting agreement, which requires detecting Sequential neural networks models are powerful tools in a variety of Natural Language Processing (NLP) tasks. The sequential nature of these models raises the questions: to what extent can these models implicitly learn hierarchical structures typical to human language, and what kind of grammatical phenomena can they acquire? We focus on the task of agreement prediction in Basque, as a case study for a task that requires implicit understanding of sentence structure and the acquisition of a complex but consistent morphological syst"
W18-6017,Q16-1022,0,0.0804508,"Missing"
W18-6017,E17-1022,0,0.0169327,"e. At the moment this is done in a deterministic fashion using the 1-best alignment from the word aligner. This has two primary drawbacks: (1) It could be however that there exist better alignments, but we miss them by choosing only the best; and (2) we then have to use imperfect heuristics to attempt to make a valid tree when the alignments do not result in one. One idea we have had would be to view the projection problem as one of finding the best tree in a graph of alignments. These alignments could come from several word aligners, or even from using simple attachment rules such as in e.g. Alonso et al. (2017). Another avenue is to improve how arcs in the projected graph are weighted. At the moment we do only raw voting, but information from other languages in terms of distribution of part-of-speech tags, features and dependency relations could potentially improve the results. (3) project (fao) (nob) root root obl advmod case nsubj Maja bor nå i Maja (nno) nú root obl advmod case nsubj í Malmø. bur no i Maja Malmø. obl advmod case nsubj (dan) býr nú í Malmø. (fao) root root obl advmod case nsubj Maja býr (fao) root Maja advmod case nsubj Malmø. obl bor nu i root obl advmod case nsubj Malmø. Maja (s"
W18-6017,antonsen-etal-2010-reusing,0,0.020986,"), in that we use spanning tree to find the best parse in a graph that has been induced from aligned parallel corpora. However, their focus is on crosslinguality rather than on producing the best system for a related language, and as such the performance they report is lower. It is also worth noting the work by Schlichtkrull and Søgaard (2017), who present a system that can learn from dependency graphs over tokens as opposed to over the well-formed dependency trees that are typically assumed for other systems. In terms of dependency parsing specifically for Faroese, we can include the work by Antonsen et al. (2010), who apply a slightly-modified rulebased parser written for North Sámi to parsing Faroese. They achieved good results, F-score of over 0.98, on a small test set of 100 sentences. Unfortunately their work is not directly comparable as it relies on a very different annotation scheme to that which we use in our work, in addition they did 3.1 Raw data The Faroese raw data that we used in our experiments comes from Wikipedia dump which was preliminary cleaned of all the markup using the WikiExtractor script.1 Then, both manually and via regular expressions, we deleted non-Faroese texts, poetic tex"
W18-6017,N13-1073,0,0.0339115,"Missing"
W18-6017,W17-6509,1,0.833455,"exicalised models Figure 1: Example of pivot translation from Faroese to Swedish, Danish and Norwegian Nynorsk via Norwegian Bokmål. The sentence Maja býr nú í Malmø translates in English as ‘Maja now lives in Malmø’. The translation to the other Nordic languages is word-by-word and monotonic. first author in discussion with a native speaker of Faroese and members of the Universal Dependencies community.3 The part-of-speech tags and features were converted automatically to ones compatible with Universal Dependencies using a lookup table and the longest-match set overlap procedure described in Gökırmak and Tyers (2017). 3.3 In this section we describe the two baseline methods and our multi-source approach. Other treebanks For training the delexicalised models we used the following treebanks: UD_Swedish-Talbanken, UD_Danish-DDT (Johannsen et al., 2015), UD_Norwegian-Bokmaal (Øvrelid and Hohle, 2016) and UD_Norwegian-Nynorsk. Some statistics about these treebanks are presented in Table 1. 3.4 4 Methodology Machine translation Faroese is not supported by the mainstream online machine translation engines and there are very few parallel sentence pairs available. For example, the widely-cited OPUS collection (Tie"
W18-6017,H05-1066,0,0.0920492,"e from all of the languages. We first build a dependency graph for each Faroese sentence using the arcs found in all of the parsed translations of that sentence. The arcs are weighted, like in the voting scheme from the CoNLL-07 shared task (Nivre et al., 2007), such that each language is counted as a single vote for that arc. The dependency relations are voted for independently after the best tree has been found. To find the best tree in the weighted graph, we use the maximum-spanning tree (MST) algorithm of Chu (1965); Edmonds (1967). This algorithm is widely used in dependency parsing, cf. McDonald et al. (2005). The algorithm is composed of the following steps: 1. For each vertex, pick the the incoming edge with the highest weight. 2. Check the graph for cycles. If there are no cycles and the graph is a tree, then return this graph as the resulting MST. 3. If there are cycles, then, for each cycle, isolate the cycle from the tree, find the incoming (to any vertex of the cycle), edge with the highest weight, then remove all the edges within the cycle which conflict with it. 4. Then repeat the steps 2-3 until there are no cycles. 147 Here we present a comparison between the performance of baseline mod"
W18-6017,D11-1006,0,0.501194,"troduction In this paper, we describe and compare a number of approaches to cross-lingual parsing for Faroese, a Nordic language spoken by approximately 66,000 people on the Faroe Islands in the North Atlantic. Faroese is a moderately underresourced language. It has a standardised orthography and fairly long written tradition, but lacks large syntactically-annotated corpora. There are however related well-resourced languages, such as Norwegian (both Bokmål and Nynorsk), DanUsing these treebanks we perform experiments using two well-known methods, delexicalised parsing (Zeman and Resnik, 2008; McDonald et al., 2011) and synthetic treebanking using annotation projection (Tiedemann and Agić, 2016), and in addition propose a new method based on voting over possible projected trees using the maximum spanning tree algorithm. This can be thought of as creating a synthetic treebank where the tree for each sentence is the result of voting over the set of trees generated by parsing different translations. The remainder of the paper is laid out as follows: Section 2 describes prior work on both Faroese and on cross-lingual dependency parsing; Section 3 describes the resources we used for the experiments, including"
W18-6017,L16-1262,0,0.140835,"Missing"
W18-6017,E17-1021,0,0.0606169,"ificantly better results by combining the trees produced by the top three systems, and found that even after adding all the systems, including the worst-performing system, the performance did not drop below that of the top-performing system. Our work is very similar to Agić et al. (2016), in that we use spanning tree to find the best parse in a graph that has been induced from aligned parallel corpora. However, their focus is on crosslinguality rather than on producing the best system for a related language, and as such the performance they report is lower. It is also worth noting the work by Schlichtkrull and Søgaard (2017), who present a system that can learn from dependency graphs over tokens as opposed to over the well-formed dependency trees that are typically assumed for other systems. In terms of dependency parsing specifically for Faroese, we can include the work by Antonsen et al. (2010), who apply a slightly-modified rulebased parser written for North Sámi to parsing Faroese. They achieved good results, F-score of over 0.98, on a small test set of 100 sentences. Unfortunately their work is not directly comparable as it relies on a very different annotation scheme to that which we use in our work, in add"
W18-6017,K17-3009,0,0.0606514,"an Nynorsk), we first translated the Faroese Wikipedia (§3.1) to that language using the Apertium machine translation system. In the case of Swedish, Danish and Norwegian Nynorsk, the translation is pivoted via Norwegian Bokmål. This is demonstrated in Figure 1. The original Faroese text and the translation is then aligned using fastalign (Dyer et al., 2013), a word-aligned based on IBM Model 2. Both translations and alignments are largely word-for-word and monotonic. We then parse the translation using a lexicalised model trained on the training portion of the relevant treebank using UDPipe (Straka and Straková, 2017). This results in a collection of: original Faroese sentences, translations of those sentences, a word-by-word alignment between the Faroese sentences and the translated sentences, and a tree for each of the translated sentences. 146 The next step is to take the trees over the translated sentences and project them back to the original Faroese sentences, as is shown in Figure 2. The final trees are then used for training a lexicalised model using UDPipe for parsing Faroese. Language Sentences Tokens 28,701 28,632 28,016 28,611 758,999 768,662 765,203 753,597 Swedish Danish Norwegian Bokmål Norw"
W18-6017,2016.eamt-2.8,0,0.0777536,"Missing"
W18-6017,W17-1216,0,0.0236171,"OS and morphology). 2 In the experiments we used raw Faroese text extracted from Wikipedia, a manually created gold-standard corpus of trees, treebanks for the source languages (Danish, Swedish and Norwegian) and machine translation systems between the languages. The following subsections describe these resources. 3 Resources Prior work Our work is closely related to two main trends in cross-lingual dependency parsing. The first is multi-source delexicalised dependency parsing as described by McDonald et al. (2011). The second is the work on synthetic treebanking by Tiedemann and Agić (2016); Tiedemann (2017). In these works, sentences in the target language (e.g. Faroese) is first translated by a machine translation system to a well-resourced language (e.g. Norwegian). The machine-translated Norwegian sentences are then parsed by a parser trained on a treebank of Norwegian, and word aligned to the Faroese originals. The output tree from the Norwegian parser is then projected back to the Faroese sentences via the word alignments. In terms of voting for parse trees, the CoNLL shared task on dependency parsing in 2007 (Nivre et al., 2007) reported that using a similar architecture to the one we desc"
W18-6017,2009.freeopmt-1.7,0,0.0603688,"Missing"
W18-6017,I08-3008,0,0.211005,"and Nordic languages. Introduction In this paper, we describe and compare a number of approaches to cross-lingual parsing for Faroese, a Nordic language spoken by approximately 66,000 people on the Faroe Islands in the North Atlantic. Faroese is a moderately underresourced language. It has a standardised orthography and fairly long written tradition, but lacks large syntactically-annotated corpora. There are however related well-resourced languages, such as Norwegian (both Bokmål and Nynorsk), DanUsing these treebanks we perform experiments using two well-known methods, delexicalised parsing (Zeman and Resnik, 2008; McDonald et al., 2011) and synthetic treebanking using annotation projection (Tiedemann and Agić, 2016), and in addition propose a new method based on voting over possible projected trees using the maximum spanning tree algorithm. This can be thought of as creating a synthetic treebank where the tree for each sentence is the result of voting over the set of trees generated by parsing different translations. The remainder of the paper is laid out as follows: Section 2 describes prior work on both Faroese and on cross-lingual dependency parsing; Section 3 describes the resources we used for th"
W18-6017,L16-1250,0,0.039748,"notonic. first author in discussion with a native speaker of Faroese and members of the Universal Dependencies community.3 The part-of-speech tags and features were converted automatically to ones compatible with Universal Dependencies using a lookup table and the longest-match set overlap procedure described in Gökırmak and Tyers (2017). 3.3 In this section we describe the two baseline methods and our multi-source approach. Other treebanks For training the delexicalised models we used the following treebanks: UD_Swedish-Talbanken, UD_Danish-DDT (Johannsen et al., 2015), UD_Norwegian-Bokmaal (Øvrelid and Hohle, 2016) and UD_Norwegian-Nynorsk. Some statistics about these treebanks are presented in Table 1. 3.4 4 Methodology Machine translation Faroese is not supported by the mainstream online machine translation engines and there are very few parallel sentence pairs available. For example, the widely-cited OPUS collection (Tiedemann, 2016) contains fewer than 7,000 sentences pairs for Faroese–Danish, Faroese–English, Faroese– Norwegian and Faroese–Swedish. This makes creating a corpus-based machine translation model unlikely to succeed. There is however a prototype rule-based machine translation system fro"
W19-0301,K17-2002,0,0.0170852,"because the field of data-driven morphological analysis in general remains underexplored at the present time. Classically, morphological analyzers have been extended using morphological guessers (Lindén, 2009), however, the premise for such work is quite different—An existing analyzer is modified to analyze unknown word forms based on orthographically similar known word forms. In contrast, we explore a setting, where the starting point is a morphologically analyzed corpus and the aim is to learn a model for analyzing unseen text. Outside of the domain of Uralic languages, Nicolai and Kondrak (2017) frame morphological analysis as a discriminative string transduction task. They present experiments on Dutch, English, German and Spanish. In contrast to Nicolai and Kondrak (2017), Moeller et al. (2018) use a neural encoder-decoder system for morphological analysis of Arapaho verbs. Their system returns both lemmas and morphological tags but it cannot handle ambiguous analyses in general. Our work is inspired by the neural encoder-decoder approach presented by Moeller et al. (2018) but we do handle unrestricted ambiguity. In contrast to data-driven morphological analysis, data-driven morpho"
W19-0301,K18-3001,1,0.911079,"Missing"
W19-0301,K17-2001,0,0.0608936,"Missing"
W19-0301,K18-2013,0,0.110969,"work in the area has been going on for many years (cf. Koskenniemi (1983)). There is also a growing body of work on data-driven morphological tagging for Uralic languages, especially Finnish. Here, a system is trained to find a single contextually appropriate analysis for each token in a text. Examples of Although novel lexical items can cause problems for data-driven systems as well, most data-driven systems are still able to analyze any word form in principle. Code available at https://github.com/mpsilfve/morphnet. 2 work exploring morphological tagging for Finnish include Kanerva et al. (2018) and Silfverberg et al. (2015). However, work on full data-driven morphological analysis, where the task is to return all and only the valid analyses for each token irrespective of sentence context, is almost non-existent for Uralic languages. The only system known to the authors is the recent neural analyzer for Finnish presented by Silfverberg and Hulden (2018). The system first encodes an input word form into a vector representation using an LSTM encoder. It then applies one binary logistic classifier conditioned on this vector representation for each morphological tag (for example NOUN|Num"
W19-0301,W16-2010,0,0.0284187,"(2018) use a neural encoder-decoder system for morphological analysis of Arapaho verbs. Their system returns both lemmas and morphological tags but it cannot handle ambiguous analyses in general. Our work is inspired by the neural encoder-decoder approach presented by Moeller et al. (2018) but we do handle unrestricted ambiguity. In contrast to data-driven morphological analysis, data-driven morphological generation has received a great deal of attention lately due to several shared tasks organized by CoNLL and SIGMORPHON (Cotterell et al., 2016, 2017, 2018). The most successful approaches (Kann and Schütze, 2016; Bergmanis et al., 2017; Makarov et al., 2017; Makarov and Clematide, 2018) to the generation task involve different flavors of the neural encoder-decoder model. Therefore, we opted for applying it in our morphological analyzer. 3 Model This section presents the encoder-decoder model used in the experiments. 3.1 An Encoder-Decoder Model for Morphological Analysis Following Moeller et al. (2018), we formulate morphological analysis as a characterlevel string transduction task and use an LSTM (Hochreiter and Schmidhuber, 1997) encoder-decoder model with attention (Bahdanau et al., 2014) for per"
W19-0301,P17-4012,0,0.0434466,"cting several output candidates from the model using beam search and selecting the most probable candidates as model outputs. The number of outputs is controlled by a probability threshold hyperparameter p. We extract the least number of top scoring candidates whose combined probability mass is greater than p. Additionally, we restrict the maximal number of output candidates using a single hyperparameter N . The hyperparamaters p and N are tuned on the development data. 3.2 Implementation Details We implement our LSTM encoder-decoder model using the OpenNMT neural machine translation toolkit (Klein et al., 2017). We use 500-dimensional character and tag embeddings for input and output characters as well as POS and MSD tags. These are processed by a 2-layer bidirectional LSTM encoder with hidden state size 500. Encoder representations are fed into a 2-layer LSTM decoder with hidden state size 500. During inference, we use beam search with beam width 10. When training, we use a batch size of 64 and train for 10,000 steps where one step corresponds to updating on a single mini-batch. Model parameters are optimized using the Adam optimization algorithm (Kingma and Ba, 2014). 4 4 Data We use two datasets"
W19-0301,W18-4802,0,0.137683,"essers (Lindén, 2009), however, the premise for such work is quite different—An existing analyzer is modified to analyze unknown word forms based on orthographically similar known word forms. In contrast, we explore a setting, where the starting point is a morphologically analyzed corpus and the aim is to learn a model for analyzing unseen text. Outside of the domain of Uralic languages, Nicolai and Kondrak (2017) frame morphological analysis as a discriminative string transduction task. They present experiments on Dutch, English, German and Spanish. In contrast to Nicolai and Kondrak (2017), Moeller et al. (2018) use a neural encoder-decoder system for morphological analysis of Arapaho verbs. Their system returns both lemmas and morphological tags but it cannot handle ambiguous analyses in general. Our work is inspired by the neural encoder-decoder approach presented by Moeller et al. (2018) but we do handle unrestricted ambiguity. In contrast to data-driven morphological analysis, data-driven morphological generation has received a great deal of attention lately due to several shared tasks organized by CoNLL and SIGMORPHON (Cotterell et al., 2016, 2017, 2018). The most successful approaches (Kann an"
W19-0301,L16-1247,0,0.0263337,"Missing"
W19-0301,E17-2034,0,0.0768008,"ages is unsurprising because the field of data-driven morphological analysis in general remains underexplored at the present time. Classically, morphological analyzers have been extended using morphological guessers (Lindén, 2009), however, the premise for such work is quite different—An existing analyzer is modified to analyze unknown word forms based on orthographically similar known word forms. In contrast, we explore a setting, where the starting point is a morphologically analyzed corpus and the aim is to learn a model for analyzing unseen text. Outside of the domain of Uralic languages, Nicolai and Kondrak (2017) frame morphological analysis as a discriminative string transduction task. They present experiments on Dutch, English, German and Spanish. In contrast to Nicolai and Kondrak (2017), Moeller et al. (2018) use a neural encoder-decoder system for morphological analysis of Arapaho verbs. Their system returns both lemmas and morphological tags but it cannot handle ambiguous analyses in general. Our work is inspired by the neural encoder-decoder approach presented by Moeller et al. (2018) but we do handle unrestricted ambiguity. In contrast to data-driven morphological analysis, data-driven morpho"
W19-0301,W15-1821,0,0.0232865,"big. Lemmas Tags MSDs Th. forms 1.80 — 137 2452 — Table 2: Quantitative description of the Finnish treebank dataset. We give the number of unique train, dev and test word forms, as well as, the average number of analyses per word form (Ambig.), the number of unique lemmas (Lemmas), the number of unique tags such as NOUN and Number=Sing (Tags) and the number of unique morphosyntactic descriptions such as NOUN|Number=Sing|Case=Nom (MSDs). 4.2 Finnish Treebank Data Our second dataset was presented by Silfverberg and Hulden (2018). It is the Finnish part of the Universal Dependencies treebank v1 (Pyysalo et al., 2015) which has been analyzed using the OMorFi morphological analyzer (Pirinen et al., 2017). We used the splits into training, development and test sets provided by Silfverberg and Hulden (2018). In contrast to the Uralic Wikipedia datasets, which is a type-level resource consisting of analyses for unique word forms, the Finnish treebank data is a token-level resource consisting of morphologically analyzed running text. Therefore, the same word form can occur multiple times in the dataset. This means that the training, development and test sets are not disjoint which makes the task somewhat easier"
W19-0301,W18-0210,1,0.873504,"Missing"
W19-0301,W17-0607,1,0.818739,"Missing"
W19-0301,W18-0209,1,0.390326,"cause problems for data-driven systems as well, most data-driven systems are still able to analyze any word form in principle. Code available at https://github.com/mpsilfve/morphnet. 2 work exploring morphological tagging for Finnish include Kanerva et al. (2018) and Silfverberg et al. (2015). However, work on full data-driven morphological analysis, where the task is to return all and only the valid analyses for each token irrespective of sentence context, is almost non-existent for Uralic languages. The only system known to the authors is the recent neural analyzer for Finnish presented by Silfverberg and Hulden (2018). The system first encodes an input word form into a vector representation using an LSTM encoder. It then applies one binary logistic classifier conditioned on this vector representation for each morphological tag (for example NOUN|Number=Sg|Case=Nom). The classifier is used to determine if the tag is a valid analysis for the given input word form. Similarly to Silfverberg and Hulden (2018), our system is also a neural morphological analyzer but unlike Silfverberg and Hulden (2018) we incorporate lemmatization. Moreover, the design of our system considerably differs from their system as explai"
W19-0301,W17-0608,0,0.0678951,"Missing"
W19-1401,W19-1402,0,0.268136,"Missing"
W19-1401,P19-1068,1,0.913629,"guages and asked to predict the valid morphological analyses for a seventh, unseen language. In the “Semi-Closed” track, the process was the same, only participants were provided with additional raw data by the organisers. This was in the form of raw text Wikipedia dumps, bilingual dictionaries from the Apertium project and any treebanks available in the known languages from the Universal Dependencies project. Moldavian vs. Romanian Cross-dialect Topic identification (MRC): In the Moldavian vs. Romanian Cross-topic Identification shared task, we provided participants with the MOROCO data set (Butnaru and Ionescu, 2019) which contains Moldavian and Romanian samples of text collected from the news domain. The samples belong to one of the following six topics: culture, finance, politics, science, sports, and tech. The samples are pre-processed in order to eliminate named entities. For each sample, the data set provides corresponding dialectal and category labels. To this end, we proposed three subtasks for the 2019 VarDial Evaluation Campaign. The first sub-task was a binary classification by dialect task, in which a classification model is required to discriminate between the Moldavian and the Romanian dialec"
W19-1401,W18-3929,1,0.894916,"Missing"
W19-1401,W19-1413,1,0.836296,"Missing"
W19-1401,W19-1416,0,0.056458,"Missing"
W19-1401,W18-3907,1,0.895659,"Missing"
W19-1401,Y96-1018,1,0.197287,"k. 5.5 Summary Three teams participated in this first iteration of the cross-lingual analysis task. Two of the teams employed variations of neural encoderdecoder systems. Apart from lemmatization performance, it proved to be difficult to attain consistent improvements over the neural baseline systems. However, the suffix stripping approach used by the HSE team did deliver clear improvements in lemmatization for both Turkic and Romance languages. 6 6.1 Dataset Texts to distinguish between the two variations were compiled from the two existing corpora of news: Sinica Corpus for Taiwan Mandarin (Chen et al., 1996) and LCMC (The Lancaster Corpus of Mandarin Chinese, (McEnery and Xiao, 2003)) for Mainland Mandarin. Both corpora are segmented and tokenized. We remove the punctuation and unify the orthography used to eliminate orthographic cues. Since both corpora are balanced corpora, our initial thought was to provide genre-aware classification. However, inspection of both corpora suggested the genres were not defined in the same way and are not distributed homogeneously. In the next edition this idea may be exploited by using some additional resources as genre vs. regional variations which is an importa"
W19-1401,W19-1419,1,0.847943,"Missing"
W19-1401,W19-1414,0,0.0601978,"Missing"
W19-1401,W16-4801,1,0.6692,"Missing"
W19-1401,W19-1420,0,0.0913091,"ces from newspapers for each Mandarin variety. The main task is to determine if a sentence is written in the Mandarin Cuneiform Language Identification (CLI): This shared task focused on discriminating between languages and dialects originally written using the cuneiform script. The task included 2 dif2 Team Adaptcenter BAM dkosmajac DTeam SharifCL ghpaetzold gretelliz92 ekh IUCL HSE itsalexyang lonewolf MineriaUNAM NRC-CNRC R2I LIS PZ SC-UPB situx SUKI tearsofjoy T¨ubingenOslo Twist Bytes Total GDI CMA DMT X MRC CLI X X System Description Papers (Butnaru, 2019) X X X X X X (Tudoreanu, 2019) (Doostmohammadi and Nassajian, 2019) X X (Hu et al., 2019) (Mikhailov et al., 2019) (Yang and Xiang, 2019) X X X X X X X X (Bernier-Colborne et al., 2019) (Chifu, 2019) (Paetzold and Zampieri, 2019) (Onose and Cercel, 2019) X X X X X X X 7 5 X 8 X X 6 3 (Jauhiainen et al., 2019b) (Wu et al., 2019) (C¸o¨ ltekin and Barnes, 2019) (Benites et al., 2019) 14 Table 1: The teams that participated in the Third VarDial Evaluation Campaign. took part in, and a reference to each of the 14 system description papers published in the VarDial workshop proceedings. ferent languages: Sumerian and Akkadian. Furthermore, the Akkadian language was"
W19-1401,W19-1415,0,0.0347692,"Missing"
W19-1401,L18-1550,0,0.0287077,"sed on a majority voting scheme applied on five classification models: kNearest Neighbors, Logistic Regression, Support Vector Machines, Neural Networks and Random Forests. For the first and the third runs, the models are trained on both training and development sets. For the second run, the model is trained only on the training set. SC-UPB. The SC-UPB team first cleaned the dataset by removing stopwords as well as special characters. The first run submitted to each of the three subtasks is based on a model that represents text as the mean of word vectors given by a pretrained FastText model (Grave et al., 2018). The representation is provided as input to a Recurrent Neural Network with gated recurrent units, which is trained using the Adam optimizer with a batch size of 64 for 20 epochs and early stopping. The second run submitted to each of the three subtasks is based on a hierarchical attention network introduced by Yang et al. (2016). The model is trained using the Adam optimizer with a batch size of 64 for 20 epochs and early stopping. tearsofjoy. The tearsofjoy team used a linear SVM classifier with a combination of character and word n-gram features, which are weighted with the BM25 weighting"
W19-1401,W18-4802,0,0.0115539,"zers is a substantial task. It entails creation of extensive word lists and grammatical descriptions. This requires both linguistic expertise and technical expertise in the rule formalism which is used. Hence, there exists a demand for less labor intensive approaches especially for lowresource languages. Classically, rule-based analyzers have been augmented with statistical guessers which provide analyses for out-of-lexicon word forms (Lind´en, 2009). Recently, purely data-driven morphological analysis has received increasing attention (Nicolai and Kondrak, 2017; Silfverberg and Hulden, 2018; Moeller et al., 2018; Silfverberg and Tyers, 2019). Purely data-driven systems learn an analysis model from a data set of morphologically analyzed word forms and can then be applied 5.1 Dataset The dataset was compiled specifically for the shared task. We used the Wikipedias in all the languages to create a frequency list of surface tokens for each language. We then analysed these lists using the morphological analysers from the Apertium (Forcada et al., 2011) project. The lists of analyses were trimmed to include only openclass parts of speech (nouns, adjectives, adverbs and verbs). We then removed any form whic"
W19-1401,W19-1417,0,0.0619352,"Missing"
W19-1401,E17-2034,0,0.0280356,"e-art for this task, however, developing rule-based analyzers is a substantial task. It entails creation of extensive word lists and grammatical descriptions. This requires both linguistic expertise and technical expertise in the rule formalism which is used. Hence, there exists a demand for less labor intensive approaches especially for lowresource languages. Classically, rule-based analyzers have been augmented with statistical guessers which provide analyses for out-of-lexicon word forms (Lind´en, 2009). Recently, purely data-driven morphological analysis has received increasing attention (Nicolai and Kondrak, 2017; Silfverberg and Hulden, 2018; Moeller et al., 2018; Silfverberg and Tyers, 2019). Purely data-driven systems learn an analysis model from a data set of morphologically analyzed word forms and can then be applied 5.1 Dataset The dataset was compiled specifically for the shared task. We used the Wikipedias in all the languages to create a frequency list of surface tokens for each language. We then analysed these lists using the morphological analysers from the Apertium (Forcada et al., 2011) project. The lists of analyses were trimmed to include only openclass parts of speech (nouns, adjective"
W19-1401,D18-1135,1,0.824726,"016). The model is trained using the Adam optimizer with a batch size of 64 for 20 epochs and early stopping. tearsofjoy. The tearsofjoy team used a linear SVM classifier with a combination of character and word n-gram features, which are weighted with the BM25 weighting scheme. Their model’s parameters are tuned independently for each subtask, using random search and 5-fold crossvalidation. The tearsofjoy team also tried a transductive learning approach which is based on retraining the model by adding confident predictions from the test set to the training set, an idea previously studied in (Ionescu and Butnaru, 2018). • Binary classification by dialect (subtask 1) – the task is to discriminate between the Moldavian and the Romanian dialects. • MD→RO cross-dialect multi-class categorization by topic (subtask 2) – the task is to classify the samples written in the Romanian dialect into six topics, using a model trained on samples written in the Moldavian dialect. • RO→MD cross-dialect multi-class categorization by topic (subtask 3) – the task is to classify the samples written in the Moldavian dialect into six topics, using a model trained on samples written in the Romanian dialect. 7.2 Participants and App"
W19-1401,W19-1409,1,0.877823,"Missing"
W19-1401,W19-1418,0,0.0615736,"Missing"
W19-1401,N16-1174,0,0.0228023,"t. SC-UPB. The SC-UPB team first cleaned the dataset by removing stopwords as well as special characters. The first run submitted to each of the three subtasks is based on a model that represents text as the mean of word vectors given by a pretrained FastText model (Grave et al., 2018). The representation is provided as input to a Recurrent Neural Network with gated recurrent units, which is trained using the Adam optimizer with a batch size of 64 for 20 epochs and early stopping. The second run submitted to each of the three subtasks is based on a hierarchical attention network introduced by Yang et al. (2016). The model is trained using the Adam optimizer with a batch size of 64 for 20 epochs and early stopping. tearsofjoy. The tearsofjoy team used a linear SVM classifier with a combination of character and word n-gram features, which are weighted with the BM25 weighting scheme. Their model’s parameters are tuned independently for each subtask, using random search and 5-fold crossvalidation. The tearsofjoy team also tried a transductive learning approach which is based on retraining the model by adding confident predictions from the test set to the training set, an idea previously studied in (Ione"
W19-1401,W19-1423,1,0.825557,"e ranking for subtask 3, as shown in Table 8. 7.4 Dataset Summary We proposed three MRC subtasks for VarDial 2019. Three participants submitted runs for all three subtasks, and another two participants submitted runs only for subtask 1. Two teams (DTeam 5 12 http://oracc.museum.upenn.edu Language or Dialect Sumerian Old Babylonian Middle Babylonian peripheral Standard Babylonian Neo-Babylonian Late Babylonian Neo-Assyrian two systems in more detail. The PZ team used a SVM metaclassifier ensemble of several linear SVM classifiers trained using character n-gram and character skip-gram features. Paetzold and Zampieri (2019) give further details. The SharifCL team submitted three runs and their best performing system was an ensemble of a SVM and a NB classifier (Doostmohammadi and Nassajian, 2019). The ghpaetzold team submitted only one run using 2-layer compositional recurrent neural network that learns numerical representations of sentences based on their words, and of words based on their characters. Their system is described in more detail by Paetzold and Zampieri (2019). The ekh team used a sum of relative frequencies of character bigrams together with a penalty value for those bigrams or unigrams that were"
W19-1401,W17-1201,1,0.803354,"Missing"
W19-1401,L16-1641,1,0.880892,"Missing"
W19-1401,W14-5307,1,0.821127,"Missing"
W19-1401,W18-0209,1,0.707638,"r, developing rule-based analyzers is a substantial task. It entails creation of extensive word lists and grammatical descriptions. This requires both linguistic expertise and technical expertise in the rule formalism which is used. Hence, there exists a demand for less labor intensive approaches especially for lowresource languages. Classically, rule-based analyzers have been augmented with statistical guessers which provide analyses for out-of-lexicon word forms (Lind´en, 2009). Recently, purely data-driven morphological analysis has received increasing attention (Nicolai and Kondrak, 2017; Silfverberg and Hulden, 2018; Moeller et al., 2018; Silfverberg and Tyers, 2019). Purely data-driven systems learn an analysis model from a data set of morphologically analyzed word forms and can then be applied 5.1 Dataset The dataset was compiled specifically for the shared task. We used the Wikipedias in all the languages to create a frequency list of surface tokens for each language. We then analysed these lists using the morphological analysers from the Apertium (Forcada et al., 2011) project. The lists of analyses were trimmed to include only openclass parts of speech (nouns, adjectives, adverbs and verbs). We then"
W19-1401,W19-0301,1,0.916428,"task. It entails creation of extensive word lists and grammatical descriptions. This requires both linguistic expertise and technical expertise in the rule formalism which is used. Hence, there exists a demand for less labor intensive approaches especially for lowresource languages. Classically, rule-based analyzers have been augmented with statistical guessers which provide analyses for out-of-lexicon word forms (Lind´en, 2009). Recently, purely data-driven morphological analysis has received increasing attention (Nicolai and Kondrak, 2017; Silfverberg and Hulden, 2018; Moeller et al., 2018; Silfverberg and Tyers, 2019). Purely data-driven systems learn an analysis model from a data set of morphologically analyzed word forms and can then be applied 5.1 Dataset The dataset was compiled specifically for the shared task. We used the Wikipedias in all the languages to create a frequency list of surface tokens for each language. We then analysed these lists using the morphological analysers from the Apertium (Forcada et al., 2011) project. The lists of analyses were trimmed to include only openclass parts of speech (nouns, adjectives, adverbs and verbs). We then removed any form which did not include at least one"
W19-1401,E14-2006,0,0.0437089,"Missing"
W19-1401,W19-1422,0,0.0730531,"Missing"
W19-1401,W19-1412,0,0.0741523,"Missing"
W19-4022,P14-2104,0,0.178218,"guistics Sejong POS (S) Park et al. (2016, 2017), etc. This is done in order to avoid data sparsity, because longer segmentation granularity can combine words in an exponential way. We propose a new approach to annotation using a morphologically separated word based on the approach for annotating multiword tokens (MWT) in the CoNLL-U format.2 Using the new annotation scheme, we can also explore tasks beyond POS tagging such as named-entity recognition (NER) and semantic role labelling (SRL). While there are a number of papers looking at NER for Korean (Chung et al., 2003; Yun, 2007), and SRL (Kim et al., 2014)3 , these tasks have hardly been discussed in previous literature on Korean language processing. It has been considered to be difficult to deal with using the current annotation scheme of the Sejong POS corpus because of the limitations of the current eojeol-based annotation and the agglutinative characteristics of the language. For example, for NER, having postpositions attached to the last word in the phrase they modify can make it more difficult to identify the named entity. The annotation scheme we propose (see Figure 3) is also different from the current annotation scheme in Universal Dep"
W19-4022,W12-3411,1,0.878488,"POS tagging (Hong, 2009; Na, 2015; Park et al., 2016) and dependency parsing (Oh, 2009; Oh and Cha, 2010; Park et al., 2013). There are, however, different segmentation granularity levels — that is, ways to tokenise words in sentences — for Korean which have been independently proposed in previous work as basic units. This paper explores the Sejong POS-tagged corpus to define a new annotation method for endto-end morphological analysis and POS tagging. Many upstream applications for Korean language processing are based on a segmentation scheme in which all morphemes are separated. For example Choi et al. (2012) and Park et al. (2016) present work on phrase-structure parsing, and work on statistical machine translation (SMT) is presented by In 1998 the Ministry of Culture and Tourism of Korea launched the 21st Century Sejong Project to promote Korean language information processing. The project is named after Sejong the Great who conceived and led the invention of hangul, the Korean alphabet. The corpus was released in 2003 and was continually updated until 2011, producing the largest corpus of Korean to date. It includes the several types of texts: historical, contemporary, and parallel texts. The s"
W19-4022,J93-2004,0,0.069373,"Missing"
W19-4022,W11-3801,0,0.616816,"Missing"
W19-4022,P13-2017,0,0.085832,"Missing"
W19-4022,L18-1347,0,0.386647,"ic POS tag field does not converge. Recall that the language-specific POS tag is the sequence of concatenated POS tags such as NNP+JKG or NNG+XSN+VCP+ETM. The number of these POS patterns is exponential because of the agglutinative nature of words in Korean. However, it can be a serious problem for system implementation if we want to deal with the entire Sejong corpus Comparison with the current UD annotation There are currently two Korean treebanks available in UD v2.2: the Google Korean Universal Dependency Treebank (McDonald et al., 2013) and the KAIST Korean Universal Dependency Treebank (Chun et al., 2018). For the lemma and language-specific POS tag fields, they use annotation concatenation using the plus sign as shown in Figure 4. We note that Sejong and KAIST tag sets are used as language-specific POS tags, re5 Previous work often used cross validation or a corpus split without specific corpus-splitting guidelines. This makes it difficult to correctly compare the POS tagging results. For future reference and to be able to reproduce the results, we propose an explicit-split method for the Sejong POS tagged corpus in Appendix C. 198 1 2 3 4 5 6 7 8 9 10 11 12 프랑스의 세계적인 의상 디자이너 엠마누엘 웅가로가 실내 장식용"
W19-4022,W03-1121,0,0.232892,"9. 2019 Association for Computational Linguistics Sejong POS (S) Park et al. (2016, 2017), etc. This is done in order to avoid data sparsity, because longer segmentation granularity can combine words in an exponential way. We propose a new approach to annotation using a morphologically separated word based on the approach for annotating multiword tokens (MWT) in the CoNLL-U format.2 Using the new annotation scheme, we can also explore tasks beyond POS tagging such as named-entity recognition (NER) and semantic role labelling (SRL). While there are a number of papers looking at NER for Korean (Chung et al., 2003; Yun, 2007), and SRL (Kim et al., 2014)3 , these tasks have hardly been discussed in previous literature on Korean language processing. It has been considered to be difficult to deal with using the current annotation scheme of the Sejong POS corpus because of the limitations of the current eojeol-based annotation and the agglutinative characteristics of the language. For example, for NER, having postpositions attached to the last word in the phrase they modify can make it more difficult to identify the named entity. The annotation scheme we propose (see Figure 3) is also different from the cu"
W19-4022,W17-5601,1,0.460037,"Missing"
W19-4022,K17-3009,0,0.0746174,"Missing"
W19-4022,Y16-2002,1,0.898519,"ner of interior textile decorations.’ (See Table 1 for POS tag information in the Sejong corpus) Introduction POS tags for the entire annotated corpus. Figure 1 shows an example of the annotation in the Sejong POS-tagged corpus. As the Sejong corpus is the largest annotated corpus of Korean and as it uses a segmentation scheme based on eojeols, most Korean language processing systems have subsequently been developed using this as their basic segmentation scheme. There are many language processing systems based on the eojeol-segmentation schemes, for example: POS tagging (Hong, 2009; Na, 2015; Park et al., 2016) and dependency parsing (Oh, 2009; Oh and Cha, 2010; Park et al., 2013). There are, however, different segmentation granularity levels — that is, ways to tokenise words in sentences — for Korean which have been independently proposed in previous work as basic units. This paper explores the Sejong POS-tagged corpus to define a new annotation method for endto-end morphological analysis and POS tagging. Many upstream applications for Korean language processing are based on a segmentation scheme in which all morphemes are separated. For example Choi et al. (2012) and Park et al. (2016) present wor"
W19-4022,petrov-etal-2012-universal,0,0.180334,"Missing"
W19-4022,C16-1046,0,0.0321692,"Missing"
W19-6010,washington-etal-2014-finite,1,0.764357,"e main categories. 4.2 Tagsets The native tagset of the analyser is based on the tagsets used by other Turkic-language transducers in the Apertium platform. In addition we provide a mapping from this tagset to one compatible with Universal Dependencies (Nivre et al., 2016) based on 125 rules and a set overlap algorithm. The rules are composed of triples of (lemma, part of speech, features) and are applied deterministically longestoverlap ﬁrst over the source language analyses. 4.3 Morphotactics The morphotactics of the transducer are adapted from those of the Kazakh transducer described by Washington et al. (2014). The nominal morphotactics are almost identical between Kazakh and Crimean Tatar. The verbal morphotactics are rather diﬀerent, and we here followed Kavitskaya (2010). Compiled by IBT Russia/CIS, https://ibt.org.ru Content dump from the Crimean Tatar Wikipedia, https: //crh.wikipedia.org, dated 2018-12-01. See for example Washington et al. (2016) for a description. Available online at http://www.apertium.org. Available in the repository as texts/crh-feats.tsv. The transliterator is implemented as a separate substring-to-substring lexc grammar and twol ruleset. The lexc grammar deﬁnes a t"
W19-6805,coltekin-2010-freely,0,0.0322624,"to change frequent diﬀerences, e.g. Turkish hava, “air”, vs. Crimean Tatar ava, or similarly hoca, “teacher”, vs. oca 4.2 Morphological transducers The morphological transducers are based on the popular Helsinki Finite State Technology (Linden et al., 2011), a free/open-source reimplementation of the Xerox ﬁnite-state toolchain. It provides both the lexc formalism for deﬁning lexicons and the twol and xfst formalisms for modelling morphophonological rules. Along with its open-source license, this toolkit is used as it — or the equivalent XFST — has been widely used for other Turkic languages (Cöltekin, 2010; Altıntaş and Çiçekli, 2001; Tantuğ et al., 2006; Washington et al., 2012; Tyers et al., 2012b). The morphologies of both languages are implemented in lexc, and the morphophonologies of both languages are implemented in twol. Use of lexc allows for straightforward deﬁnition of diﬀerent word classes and subclasses. For example, Crimean Tatar and Turkish have two classes of verbs that have different vowels in the aorist morpheme. Class membership cannot be predicted based on any phonological criteria and is simply a lexical property of any given verb. For example, the Turkish verbs ısır and • C"
W19-6805,P17-4012,0,0.0108385,"he sentence “I don’t need feudal types like that,” is translated with gerekmez instead of the equivalent lazım değil. The RBMT preserves the meaning but doesn’t produce the correct vowel harmony in feodaller, and the NMT produces the translation “I don’t need pastures like this.” We use the metrics BLEU (Papineni et al., 2002) and Word Error Rate, a metric based on Levenshtein distance (Levenshtein, 1966) to evaluate our system on parallel corpora and compare it with the performance of a Neural Machine Translation system trained on the same corpora. We use an NMT-Small model from the OpenNMT (Klein et al., 2017) framework for the neural translation. The model we train is word-level, using Byte-pair Encoding (Sennrich et al., 2015). 10 https://ktat.krymr.com/ To evaluate our system the need arises for parallel corpora. While aligned sentences ready for MT training are not available, a number of academic works published in Turkey provide Crimean Tatar–language text along with Turkish translations. These works are mostly collections of folk tales (Bakırcı, 2010) and selections from Crimean Tatar literature in the Soviet period, from sources including the literary journal Yıldız (Atıcı, 2008; Hendem, 200"
W19-6805,W17-3204,0,0.0119205,"oted that none of the parallel corpora used for evaluation were used while developing the RBMT system, including the train and development sets. The majority of RBMT errors are mostly due either to mistakes and gaps in the morphophonology components and disambiguation errors or input words being out of the vocabulary. The NMT errors, however, seem to stem from simple lack of data. The ﬁgures achieved given only 360 thousand tokens of training data on each side seems to be consistent with experiments conducted in the literature concerning the relation of NMT performance and the amount of data (Koehn and Knowles, 2017). Taken along with the relative lack of standardization of the language, this should account to some degree for the poor performance. The sheer similarity (and not inconsiderable mutual intelligibility) of the two languages also beneﬁts the RBMT and the scenario where no system at all is used, in comparison to an NMT system that does not have adequate data to encode and decode input text properly. 6 Conclusion To our knowledge we have presented the ﬁrst ever publicly available MT system between Crimean Tatar and Turkish, which is available online for use on Apertium’s website.11 It has near pr"
W19-6805,P07-2045,0,0.00938836,"Missing"
W19-6805,P02-1040,0,0.109456,"ightly worse, due to the fact that this corpus is “dirtier”: it contains orthographical errors, wiki code, repetitions, as well as quite a few proper nouns. 5.2 Translation Quality Table 2 shows a Crimean Tatar sentence and its translations by both our RBMT system and the NMT system. In both the sentence “I don’t need feudal types like that,” is translated with gerekmez instead of the equivalent lazım değil. The RBMT preserves the meaning but doesn’t produce the correct vowel harmony in feodaller, and the NMT produces the translation “I don’t need pastures like this.” We use the metrics BLEU (Papineni et al., 2002) and Word Error Rate, a metric based on Levenshtein distance (Levenshtein, 1966) to evaluate our system on parallel corpora and compare it with the performance of a Neural Machine Translation system trained on the same corpora. We use an NMT-Small model from the OpenNMT (Klein et al., 2017) framework for the neural translation. The model we train is word-level, using Byte-pair Encoding (Sennrich et al., 2015). 10 https://ktat.krymr.com/ To evaluate our system the need arises for parallel corpora. While aligned sentences ready for MT training are not available, a number of academic works publis"
W19-6805,2013.mtsummit-papers.22,1,0.642815,"bution, CCBY-ND. 1 http://wiki.apertium.org Jonathan North Washington Linguistics Department Swarthmore College Swarthmore, PA, USA jwashin1@swarthmore.edu also presenting an example of a Crimean Tatar sentence and its translations into Turkish by the systems compared. Finally Section 6 describes our aims for future work and some concluding remarks. 2 Previous work Within the Apertium project, work on several MT systems between Turkic languages has been started (Turkish–Kyrgyz, Azeri–Turkish, Tatar–Bashkir), but until the release of the pair which this paper presents, the Kazakh–Tatar system (Salimzyanov et al., 2013) was the only one of release level quality, and accordingly the only one released. Besides these systems and those that are corporately available,2 a handful of previous works on machine translation systems between Turkic languages exist. MT systems have been reported that translate between Turkish and other Turkic languages, including Turkish–Crimean Tatar (Altıntaş, 2001), Turkish–Azerbaijani (Hamzaoglu, 1993), Turkish– Tatar (Gilmullin, 2008), and Turkish–Turkmen (Tantuğ et al., 2007), though none of these have been released to a public audience. In the development of this system, we use an"
W19-6805,2007.mtsummit-papers.61,0,0.0211922,"Tatar–Bashkir), but until the release of the pair which this paper presents, the Kazakh–Tatar system (Salimzyanov et al., 2013) was the only one of release level quality, and accordingly the only one released. Besides these systems and those that are corporately available,2 a handful of previous works on machine translation systems between Turkic languages exist. MT systems have been reported that translate between Turkish and other Turkic languages, including Turkish–Crimean Tatar (Altıntaş, 2001), Turkish–Azerbaijani (Hamzaoglu, 1993), Turkish– Tatar (Gilmullin, 2008), and Turkish–Turkmen (Tantuğ et al., 2007), though none of these have been released to a public audience. In the development of this system, we use another system developed within the Apertium project, a morphological analyzer for Crimean Tatar (Tyers et al., 2019). 3 Languages While Turkish and Crimean Tatar belong to diﬀerent branches of the Turkic family—Oghuz (Southwestern Turkic) and Kypchak (Northwestern Turkic) respectively—historical contact has been intense enough to make the written standards of the two languages somewhat mutually intelligible, although diﬀerences in modern vocabulary prevent more complete mutual intelligibi"
W19-6805,2012.eamt-1.54,1,0.88058,"ly hoca, “teacher”, vs. oca 4.2 Morphological transducers The morphological transducers are based on the popular Helsinki Finite State Technology (Linden et al., 2011), a free/open-source reimplementation of the Xerox ﬁnite-state toolchain. It provides both the lexc formalism for deﬁning lexicons and the twol and xfst formalisms for modelling morphophonological rules. Along with its open-source license, this toolkit is used as it — or the equivalent XFST — has been widely used for other Turkic languages (Cöltekin, 2010; Altıntaş and Çiçekli, 2001; Tantuğ et al., 2006; Washington et al., 2012; Tyers et al., 2012b). The morphologies of both languages are implemented in lexc, and the morphophonologies of both languages are implemented in twol. Use of lexc allows for straightforward deﬁnition of diﬀerent word classes and subclasses. For example, Crimean Tatar and Turkish have two classes of verbs that have different vowels in the aorist morpheme. Class membership cannot be predicted based on any phonological criteria and is simply a lexical property of any given verb. For example, the Turkish verbs ısır and • Consulting a Crimean Tatar to Russian Dictionary manually7 • Consulting a Turkish (Ottoman) dic"
W19-6805,W19-6010,1,0.89236,"systems and those that are corporately available,2 a handful of previous works on machine translation systems between Turkic languages exist. MT systems have been reported that translate between Turkish and other Turkic languages, including Turkish–Crimean Tatar (Altıntaş, 2001), Turkish–Azerbaijani (Hamzaoglu, 1993), Turkish– Tatar (Gilmullin, 2008), and Turkish–Turkmen (Tantuğ et al., 2007), though none of these have been released to a public audience. In the development of this system, we use another system developed within the Apertium project, a morphological analyzer for Crimean Tatar (Tyers et al., 2019). 3 Languages While Turkish and Crimean Tatar belong to diﬀerent branches of the Turkic family—Oghuz (Southwestern Turkic) and Kypchak (Northwestern Turkic) respectively—historical contact has been intense enough to make the written standards of the two languages somewhat mutually intelligible, although diﬀerences in modern vocabulary prevent more complete mutual intelligibility. 2 e.g., Google Translate, http://translate.google.com Turkish is the oﬃcial language in Turkey, and an oﬃcial language in Cyprus. It is a recognized minority language in Greece, Iraq, Kosovo, Macedonia and Romania. Th"
W19-6805,washington-etal-2012-finite,1,0.773997,"ean Tatar ava, or similarly hoca, “teacher”, vs. oca 4.2 Morphological transducers The morphological transducers are based on the popular Helsinki Finite State Technology (Linden et al., 2011), a free/open-source reimplementation of the Xerox ﬁnite-state toolchain. It provides both the lexc formalism for deﬁning lexicons and the twol and xfst formalisms for modelling morphophonological rules. Along with its open-source license, this toolkit is used as it — or the equivalent XFST — has been widely used for other Turkic languages (Cöltekin, 2010; Altıntaş and Çiçekli, 2001; Tantuğ et al., 2006; Washington et al., 2012; Tyers et al., 2012b). The morphologies of both languages are implemented in lexc, and the morphophonologies of both languages are implemented in twol. Use of lexc allows for straightforward deﬁnition of diﬀerent word classes and subclasses. For example, Crimean Tatar and Turkish have two classes of verbs that have different vowels in the aorist morpheme. Class membership cannot be predicted based on any phonological criteria and is simply a lexical property of any given verb. For example, the Turkish verbs ısır and • Consulting a Crimean Tatar to Russian Dictionary manually7 • Consulting a T"
W19-6904,Q17-1010,0,0.0085008,"rmed the CEG corpus (forms, lemmas and POS) into UD’s CoNLL-U format (cf. figure 1) and replaced CEG’s part-of-speech tags into UD UPOS. During this step we also corrected annotation errors (notably non-ambiguous cases) and added information about which consonant mutation is present, if any. We then used the Eurfa full-form dictionary to enrich the CoNLL-U format with morpho-syntactic features. On this UD compatible Welsh corpus, we trained the UDpipe tagger and lemmatizer (Straka and Strakov´a, 2017) using word embeddings for Welsh trained on the Welsh Wikipedia with FastText and provided by Bojanowski et al. (2017). With this model we POS-tagged our corpus. A second script preannotated some basic dependency relations (caseand det relations). In addition to the UD standard, we defined language specific XPOS (table 1), a morphological feature Mutation with three values to indicate the consonant mutation, since they carry syntactically relevant information, and some subtypes for dependency relations, also frequently used in other languages: acl:relcl (relative clauses) and flat:name (flat structures for multi-word named entities). UPOS ADJ ADP AUX NOUN PRON PROPN Welsh specific XPOS pos, cmp, eq, ord, sup"
W19-6904,D19-1279,0,0.0235764,"Missing"
W19-6904,W17-0411,0,0.0268968,"sults per UPOS. baseline +Eurfa UPOS 89.2 87.9 XPOS 87.3 87.5 Lemma 86.7 93.5 Table 4: results of POS tagging and lemmatisation (Fmeasure Nearly half of the word forms in the test corpus are out-of-vocabulary (OOV) with respect to the training corpus. The dictionary provided roughly half of the missing words. Thus a quarter of the words in the test corpus remains OOV, which may explain the unexpected low performance (UDpipe switches off its guesser, if a dictionary is provided). The results of dependency analysis are presented in table 6 using 3 of the standard metrics for dependency parsing (Nivre and Fang, 2017), Labelled Attachment Score (LAS, evaluates heads and dependency labels) or Content Word LAS (CLAS, as LAS, but only for dependency relations of content words (excluding aux, cop, mark, det, clf, case, cc). We run four tests, a model trained solely on the treebank, with dependencies parsed on the results of the tagger, and dependencies parsed using gold tags. The other two tests use the Eurfa dictionary again. The better results of tagging with the full form lexicon, also improves the dependency parsing, if the parsing is done on predicted POS tags. All three metrics increase accordingly. base"
W19-6904,2018.jeptalnrecital-court.1,1,0.450582,"tated corpus of Welsh within the Universal Dependencies (UD) project. We explain how the corpus was prepared, and some Welsh-specific constructions that require attention. The treebank currently contains 10 756 tokens. An 10-fold cross evaluation shows that results of both, tagging and dependency parsing, are similar to other treebanks of comparable size, notably the other Celtic language treebanks within the UD project. 1 Introduction The Welsh Treebank is the third Celtic language within the Universal Dependencies project (Nivre et al., 2016), after Irish (Lynn and Foster, 2016) and Breton (Tyers and Ravishankar, 2018). The main goal of the Universal Dependencies treebanks is to have many different languages annotated with identical guidelines and universally defined set of universal POS tags and dependency relations. These cross-linguistically consistent grammatical annotations can be used, for instance, for typological language comparison or developping and evaluating cross-linguistic tagging and parsing tools. The motivation was twofold: To have a Welsh treebank annotated using the same guidelines as many existing treebanks which permits language comparison and to have a (start for a) treebank which can"
W19-6904,williams-jones-2008-acquiring,0,0.035508,"(10 641 forms). The Welsh treebank is comparable in size to the Breton treebank (10 348 tokens, 888 sentences). The Irish treebank is twice as big with 23 964 tokens (1 020 sentences). UD treebanks vary very much in size. Currently the largest UD treebank is the German-HDT with 3 055 010 tokens. The smallest is Tagalog with just 292 words. Average size for all treebanks is 150 827 tokens, median size is 43 754 tokens. 4 3 Related Work Welsh has been the object of research in computational linguistics, notably for speech recognition and speech synthesis (Williams, 1999; Williams et al., 2006; Williams and Jones, 2008), as well as spell checking and machine translation. An overview can be found in Heinecke (2005), more detailed information about existing language technology for Welsh is accessible at http:// techiaith.cymru. Research on Welsh syntax within various frameworks is very rich: Awbery (1976), Rouveret (1990), Sadler (1998), Sadler (1999), Roberts (2004), Borsley et al. (2007), Tallerman (2009), Borsley (2010) to cite a few. The only available annotated corpus to our knowledge is Cronfa Electroneg o Gymraeg (CEG) (Ellis et al., 2001), which contains about one million tokens, annotated with POS and"
W19-6904,williams-etal-2006-tools,0,0.0317171,"ontains only 183 lemmas (10 641 forms). The Welsh treebank is comparable in size to the Breton treebank (10 348 tokens, 888 sentences). The Irish treebank is twice as big with 23 964 tokens (1 020 sentences). UD treebanks vary very much in size. Currently the largest UD treebank is the German-HDT with 3 055 010 tokens. The smallest is Tagalog with just 292 words. Average size for all treebanks is 150 827 tokens, median size is 43 754 tokens. 4 3 Related Work Welsh has been the object of research in computational linguistics, notably for speech recognition and speech synthesis (Williams, 1999; Williams et al., 2006; Williams and Jones, 2008), as well as spell checking and machine translation. An overview can be found in Heinecke (2005), more detailed information about existing language technology for Welsh is accessible at http:// techiaith.cymru. Research on Welsh syntax within various frameworks is very rich: Awbery (1976), Rouveret (1990), Sadler (1998), Sadler (1999), Roberts (2004), Borsley et al. (2007), Tallerman (2009), Borsley (2010) to cite a few. The only available annotated corpus to our knowledge is Cronfa Electroneg o Gymraeg (CEG) (Ellis et al., 2001), which contains about one million tok"
W19-6904,K18-2001,0,0.0277047,"Missing"
washington-etal-2012-finite,coltekin-2010-freely,0,\N,Missing
washington-etal-2014-finite,coltekin-2010-freely,0,\N,Missing
washington-etal-2014-finite,washington-etal-2012-finite,1,\N,Missing
