2021.case-1.21,{AMU}-{EURANOVA} at {CASE} 2021 Task 1: Assessing the stability of multilingual {BERT},2021,-1,-1,4,1,11999,leo bouscarrat,Proceedings of the 4th Workshop on Challenges and Applications of Automated Extraction of Socio-political Events from Text (CASE 2021),0,"This paper explains our participation in task 1 of the CASE 2021 shared task. This task is about multilingual event extraction from news. We focused on sub-task 4, event information extraction. This sub-task has a small training dataset and we fine-tuned a multilingual BERT to solve this sub-task. We studied the instability problem on the dataset and tried to mitigate it."
2020.mwe-1.14,Edition 1.2 of the {PARSEME} Shared Task on Semi-supervised Identification of Verbal Multiword Expressions,2020,-1,-1,1,1,12002,carlos ramisch,Proceedings of the Joint Workshop on Multiword Expressions and Electronic Lexicons,0,"We present edition 1.2 of the PARSEME shared task on identification of verbal multiword expressions (VMWEs). Lessons learned from previous editions indicate that VMWEs have low ambiguity, and that the major challenge lies in identifying test instances never seen in the training data. Therefore, this edition focuses on unseen VMWEs. We have split annotated corpora so that the test corpora contain around 300 unseen VMWEs, and we provide non-annotated raw corpora to be used by complementary discovery methods. We released annotated and raw corpora in 14 languages, and this semi-supervised challenge attracted 7 teams who submitted 9 system results. This paper describes the effort of corpus creation, the task design, and the results obtained by the participating systems, especially their performance on unseen expressions."
2020.mwe-1.16,{S}een2{U}nseen at {PARSEME} Shared Task 2020: All Roads do not Lead to Unseen Verb-Noun {VMWE}s,2020,-1,-1,3,1,16512,caroline pasquer,Proceedings of the Joint Workshop on Multiword Expressions and Electronic Lexicons,0,"We describe the Seen2Unseen system that participated in edition 1.2 of the PARSEME shared task on automatic identification of verbal multiword expressions (VMWEs). The identification of VMWEs that do not appear in the provided training corpora (called unseen VMWEs) {--} with a focus here on verb-noun VMWEs {--} is based on mutual information and lexical substitution or translation of seen VMWEs. We present the architecture of the system, report results for 14 languages, and propose an error analysis."
2020.multilingualbio-1.4,Multilingual enrichment of disease biomedical ontologies,2020,0,0,4,1,11999,leo bouscarrat,Proceedings of the LREC 2020 Workshop on Multilingual Biomedical Text Processing (MultilingualBIO 2020),0,"Translating biomedical ontologies is an important challenge, but doing it manually requires much time and money. We study the possibility to use open-source knowledge bases to translate biomedical ontologies. We focus on two aspects: coverage and quality. We look at the coverage of two biomedical ontologies focusing on diseases with respect to Wikidata for 9 European languages (Czech, Dutch, English, French, German, Italian, Polish, Portuguese and Spanish) for both, plus Arabic, Chinese and Russian for the second. We first use direct links between Wikidata and the studied ontologies and then use second-order links by going through other intermediate ontologies. We then compare the quality of the translations obtained thanks to Wikidata with a commercial machine translation tool, here Google Cloud Translation."
2020.coling-main.296,Verbal Multiword Expression Identification: Do We Need a Sledgehammer to Crack a Nut?,2020,-1,-1,3,1,16512,caroline pasquer,Proceedings of the 28th International Conference on Computational Linguistics,0,"Automatic identification of multiword expressions (MWEs), like {`}to cut corners{'} (to do an incomplete job), is a pre-requisite for semantically-oriented downstream applications. This task is challenging because MWEs, especially verbal ones (VMWEs), exhibit surface variability. This paper deals with a subproblem of VMWE identification: the identification of occurrences of previously seen VMWEs. A simple language-independent system based on a combination of filters competes with the best systems from a recent shared task: it obtains the best averaged F-score over 11 languages (0.6653) and even the best score for both seen and unseen VMWEs due to the high proportion of seen VMWEs in texts. This highlights the fact that focusing on the identification of seen VMWEs could be a strategy to improve VMWE identification in general."
2020.coling-main.298,{SLICE}: Supersense-based Lightweight Interpretable Contextual Embeddings,2020,-1,-1,2,0,21397,cindy aloui,Proceedings of the 28th International Conference on Computational Linguistics,0,"Contextualised embeddings such as BERT have become de facto state-of-the-art references in many NLP applications, thanks to their impressive performances. However, their opaqueness makes it hard to interpret their behaviour. SLICE is a hybrid model that combines supersense labels with contextual embeddings. We introduce a weakly supervised method to learn interpretable embeddings from raw corpora and small lists of seed words. Our model is able to represent both a word and its context as embeddings into the same compact space, whose dimensions correspond to interpretable supersenses. We assess the model in a task of supersense tagging for French nouns. The little amount of supervision required makes it particularly well suited for low-resourced scenarios. Thanks to its interpretability, we perform linguistic analyses about the predicted supersenses in terms of input word and context representations."
W19-5110,"Without lexicons, multiword expression identification will never fly: A position statement",2019,0,0,3,0.889788,16493,agata savary,Proceedings of the Joint Workshop on Multiword Expressions and WordNet (MWE-WN 2019),0,"Because most multiword expressions (MWEs), especially verbal ones, are semantically non-compositional, their automatic identification in running text is a prerequisite for semantically-oriented downstream applications. However, recent developments, driven notably by the PARSEME shared task on automatic identification of verbal MWEs, show that this task is harder than related tasks, despite recent contributions both in multilingual corpus annotation and in computational models. In this paper, we analyse possible reasons for this state of affairs. They lie in the nature of the MWE phenomenon, as well as in its distributional properties. We also offer a comparative analysis of the state-of-the-art systems, which exhibit particularly strong sensitivity to unseen data. On this basis, we claim that, in order to make strong headway in MWE identification, the community should bend its mind into coupling identification of MWEs with their discovery, via syntactic MWE lexicons. Such lexicons need not necessarily achieve a linguistically complete modelling of MWEs{'} behavior, but they should provide minimal morphosyntactic information to cover some potential uses, so as to complement existing MWE-annotated corpora. We define requirements for such minimal NLP-oriented lexicon, and we propose a roadmap for the MWE community driven by these requirements."
W19-5121,The Impact of Word Representations on Sequential Neural {MWE} Identification,2019,0,0,2,0,23917,nicolas zampieri,Proceedings of the Joint Workshop on Multiword Expressions and WordNet (MWE-WN 2019),0,"Recent initiatives such as the PARSEME shared task allowed the rapid development of MWE identification systems. Many of those are based on recent NLP advances, using neural sequence models that take continuous word representations as input. We study two related questions in neural MWE identification: (a) the use of lemmas and/or surface forms as input features, and (b) the use of word-based or character-based embeddings to represent them. Our experiments on Basque, French, and Polish show that character-based representations yield systematically better results than word-based ones. In some cases, character-based representations of surface forms can be used as a proxy for lemmas, depending on the morphological complexity of the language."
N19-1393,Typological Features for Multilingual Delexicalised Dependency Parsing,2019,0,1,5,1,26277,manon scholivet,"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",0,The existence of universal models to describe the syntax of languages has been debated for decades. The availability of resources such as the Universal Dependencies treebanks and the World Atlas of Language Structures make it possible to study the plausibility of universal grammar from the perspective of dependency parsing. Our work investigates the use of high-level language descriptions in the form of typological features for multilingual dependency parsing. Our experiments on multilingual parsing for 40 languages show that typological information can indeed guide parsers to share information between similar languages beyond simple language identification.
J19-1001,Unsupervised Compositionality Prediction of Nominal Compounds,2019,53,6,4,0.986395,23678,silvio cordeiro,Computational Linguistics,0,"Nominal compounds such as red wine and nut case display a continuum of compositionality, with varying contributions from the components of the compound to its semantics. This article proposes a framework for compound compositionality prediction using distributional semantic models, evaluating to what extent they capture idiomaticity compared to human judgments. For evaluation, we introduce data sets containing human judgments in three languages: English, French, and Portuguese. The results obtained reveal a high agreement between the models and human predictions, suggesting that they are able to incorporate information about idiomaticity. We also present an in-depth evaluation of various factors that can affect prediction, such as model and corpus parameters and compositionality operations. General crosslingual analyses reveal the impact of morphological variation and corpus size in the ability of the model to predict compositionality, and of a uniform combination of the components for best results."
W18-4925,Edition 1.1 of the {PARSEME} Shared Task on Automatic Identification of Verbal Multiword Expressions,2018,0,2,1,1,12002,carlos ramisch,"Proceedings of the Joint Workshop on Linguistic Annotation, Multiword Expressions and Constructions ({LAW}-{MWE}-{C}x{G}-2018)",0,"This paper describes the PARSEME Shared Task 1.1 on automatic identification of verbal multiword expressions. We present the annotation methodology, focusing on changes from last year{'}s shared task. Novel aspects include enhanced annotation guidelines, additional annotated data for most languages, corpora for some new languages, and new evaluation settings. Corpora were created for 20 languages, which are also briefly discussed. We report organizational principles behind the shared task and the evaluation metrics employed for ranking. The 17 participating systems, their methods and obtained results are also presented and analysed."
W18-4932,{V}ar{IDE} at {PARSEME} Shared Task 2018: Are Variants Really as Alike as Two Peas in a Pod?,2018,0,0,2,1,16512,caroline pasquer,"Proceedings of the Joint Workshop on Linguistic Annotation, Multiword Expressions and Constructions ({LAW}-{MWE}-{C}x{G}-2018)",0,"We describe the VarIDE system (standing for Variant IDEntification) which participated in the edition 1.1 of the PARSEME shared task on automatic identification of verbal multiword expressions (VMWEs). Our system focuses on the task of VMWE variant identification by using morphosyntactic information in the training data to predict if candidates extracted from the test corpus could be idiomatic, thanks to a naive Bayes classifier. We report results for 19 languages."
W18-4933,{V}eyn at {PARSEME} Shared Task 2018: Recurrent Neural Networks for {VMWE} Identification,2018,0,1,3,0,23917,nicolas zampieri,"Proceedings of the Joint Workshop on Linguistic Annotation, Multiword Expressions and Constructions ({LAW}-{MWE}-{C}x{G}-2018)",0,"This paper describes the Veyn system, submitted to the closed track of the PARSEME Shared Task 2018 on automatic identification of verbal multiword expressions (VMWEs). Veyn is based on a sequence tagger using recurrent neural networks. We represent VMWEs using a variant of the begin-inside-outside encoding scheme combined with the VMWE category tag. In addition to the system description, we present development experiments to determine the best tagging scheme. Veyn is freely available, covers 19 languages, and was ranked ninth (MWE-based) and eight (Token-based) among 13 submissions, considering macro-averaged F1 across languages."
N18-2068,Towards a Variability Measure for Multiword Expressions,2018,0,2,4,1,16512,caroline pasquer,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)",0,"One of the most outstanding properties of multiword expressions (MWEs), especially verbal ones (VMWEs), important both in theoretical models and applications, is their idiosyncratic variability. Some MWEs are always continuous, while some others admit certain types of insertions. Components of some MWEs are rarely or never modified, while some others admit either specific or unrestricted modification. This unpredictable variability profile of MWEs hinders modeling and processing them as {``}words-with-spaces{''} on the one hand, and as regular syntactic structures on the other hand. Since variability of MWEs is a matter of scale rather than a binary property, we propose a 2-dimensional language-independent measure of variability dedicated to verbal MWEs based on syntactic and discontinuity-related clues. We assess its relevance with respect to a linguistic benchmark and its utility for the tasks of VMWE classification and variant identification on a French corpus."
C18-1219,"If you{'}ve seen some, you{'}ve seen them all: Identifying variants of multiword expressions",2018,-1,-1,3,1,16512,caroline pasquer,Proceedings of the 27th International Conference on Computational Linguistics,0,"Multiword expressions, especially verbal ones (VMWEs), show idiosyncratic variability, which is challenging for NLP applications, hence the need for VMWE identification. We focus on the task of variant identification, i.e. identifying variants of previously seen VMWEs, whatever their surface form. We model the problem as a classification task. Syntactic subtrees with previously seen combinations of lemmas are first extracted, and then classified on the basis of features relevant to morpho-syntactic variation of VMWEs. Feature values are both absolute, i.e. hold for a particular VMWE candidate, and relative, i.e. based on comparing a candidate with previously seen VMWEs. This approach outperforms a baseline by 4 percent points of F-measure on a French corpus."
W17-6941,{L}ex{S}ub{NC}: A Dataset of Lexical Substitution for Nominal Compounds,2017,21,0,5,0,15682,rodrigo wilkens,{IWCS} 2017 {---} 12th International Conference on Computational Semantics {---} Short papers,0,"In the context of NLP tasks such as text simplification, lexicons containing information about semantically related words are an important resource for evaluating the quality of the system output. Existing resources containing lexical substitutes have been built with a focus on single words. In this paper, we present a lexical substitution dataset for Portuguese nominal compounds. The compounds have varying degrees of compositionality, conventionality and frequency, and we investigate the impact of these characteristics on the suggestions of lexical substitution made by native speakers. No strong correlations are found for these factors on the number or type of responses provided. However, a significant effect of compositionality is found in the use of one of the component words (head or modifier) as a substitute. The resulting resource, LexSubNC, contains over 1,500 manually validated substitutes for 180 compounds, further classified according to the type of response."
W17-1704,The {PARSEME} Shared Task on Automatic Identification of Verbal Multiword Expressions,2017,5,8,2,0.655044,16493,agata savary,Proceedings of the 13th Workshop on Multiword Expressions ({MWE} 2017),0,"Multiword expressions (MWEs) are known as a {``}pain in the neck{''} for NLP due to their idiosyncratic behaviour. While some categories of MWEs have been addressed by many studies, verbal MWEs (VMWEs), such as to take a decision, to break one{'}s heart or to turn off, have been rarely modelled. This is notably due to their syntactic variability, which hinders treating them as {``}words with spaces{''}. We describe an initiative meant to bring about substantial progress in understanding, modelling and processing VMWEs. It is a joint effort, carried out within a European research network, to elaborate universal terminologies and annotation guidelines for 18 languages. Its main outcome is a multilingual 5-million-word annotated corpus which underlies a shared task on automatic identification of VMWEs. This paper presents the corpus annotation methodology and outcome, the shared task organisation and the results of the participating systems."
W17-1711,Discovering Light Verb Constructions and their Translations from Parallel Corpora without Word Alignment,2017,0,2,2,0,32032,natalie vargas,Proceedings of the 13th Workshop on Multiword Expressions ({MWE} 2017),0,"We propose a method for joint unsupervised discovery of multiword expressions (MWEs) and their translations from parallel corpora. First, we apply independent monolingual MWE extraction in source and target languages simultaneously. Then, we calculate translation probability, association score and distributional similarity of co-occurring pairs. Finally, we rank all translations of a given MWE using a linear combination of these features. Preliminary experiments on light verb constructions show promising results."
W17-1723,Identification of Ambiguous Multiword Expressions Using Sequence Models and Lexical Resources,2017,3,1,2,1,26277,manon scholivet,Proceedings of the 13th Workshop on Multiword Expressions ({MWE} 2017),0,"We present a simple and efficient tagger capable of identifying highly ambiguous multiword expressions (MWEs) in French texts. It is based on conditional random fields (CRF), using local context information as features. We show that this approach can obtain results that, in some cases, approach more sophisticated parser-based MWE identification methods without requiring syntactic trees from a treebank. Moreover, we study how well the CRF can take into account external information coming from a lexicon."
J17-4005,{S}urvey: Multiword Expression Processing: A {S}urvey,2017,208,24,5,0,5618,mathieu constant,Computational Linguistics,0,"Multiword expressions (MWEs) are a class of linguistic forms spanning conventional word boundaries that are both idiosyncratic and pervasive across different languages. The structure of linguistic processing that depends on the clear distinction between words and phrases has to be re-thought to accommodate MWEs. The issue of MWE handling is crucial for NLP applications, where it raises a number of challenges. The emergence of solutions in the absence of guiding principles motivates this survey, whose aim is not only to provide a focused review of MWE processing, but also to clarify the nature of interactions between MWE processing and downstream applications. We propose a conceptual framework within which challenges and research contributions can be positioned. It offers a shared understanding of what is meant by {``}MWE processing,{''} distinguishing the subtasks of MWE discovery and identification. It also elucidates the interactions between MWE processing and two use cases: Parsing and machine translation. Many of the approaches in the literature can be differentiated according to how MWE processing is timed with respect to underlying use cases. We discuss how such orchestration choices affect the scope of MWE-aware systems. For each of the two MWE processing subtasks and for each of the two use cases, we conclude on open issues and research perspectives."
2017.jeptalnrecital-court.1,Annotation d{'}expressions polylexicales verbales en fran{\\c{c}}ais (Annotation of verbal multiword expressions in {F}rench),2017,-1,-1,3,0,16504,marie candito,Actes des 24{\\`e}me Conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Volume 2 - Articles courts,0,"Nous d{\'e}crivons la partie fran{\c{c}}aise des donn{\'e}es produites dans le cadre de la campagne multilingue PARSEME sur l{'}identification d{'}expressions polylexicales verbales (Savary et al., 2017). Les expressions couvertes pour le fran{\c{c}}ais sont les expressions verbales idiomatiques, les verbes intrins{\`e}quement pronominaux et une g{\'e}n{\'e}ralisation des constructions {\`a} verbe support. Ces ph{\'e}nom{\`e}nes ont {\'e}t{\'e} annot{\'e}s sur le corpus French-UD (Nivre et al., 2016) et le corpus Sequoia (Candito {\&} Seddah, 2012), soit un corpus de 22 645 phrases, pour un total de 4 962 expressions annot{\'e}es. On obtient un ratio d{'}une expression annot{\'e}e tous les 100 tokens environ, avec un fort taux d{'}expressions discontinues (40{\%})."
W16-1804,Filtering and Measuring the Intrinsic Quality of Human Compositionality Judgments,2016,10,1,1,1,12002,carlos ramisch,Proceedings of the 12th Workshop on Multiword Expressions,0,"This paper analyzes datasets with numerical scores that quantify the semantic compositionality of MWEs. We present the results of our analysis of crowdsourced compositionality judgments for noun compounds in three languages. Our goals are to look at the characteristics of the annotations in different languages; to examine intrinsic quality measures for such data; and to measure the impact of filters proposed in the literature on these measures. The cross-lingual results suggest that greater agreement is found for the extremes in the compositionality scale, and that outlier annotation removal is more effective than outlier annotator removal."
S16-1140,{UFRGS}{\\&}{LIF} at {S}em{E}val-2016 Task 10: Rule-Based {MWE} Identification and Predominant-Supersense Tagging,2016,0,2,2,1,23678,silvio cordeiro,Proceedings of the 10th International Workshop on Semantic Evaluation ({S}em{E}val-2016),0,"This paper presents our approach towards the SemEval-2016 Task 10 - Detecting Minimal Semantic Units and their Meanings. Systems are expected to provide a representation of lexical semantics by (1) segmenting tokens into words and multiword units and (2) providing a supersense tag for segments that function as nouns or verbs. Our pipeline rule-based system uses no external resources and was implemented using the mwetoolkit. First, we extract and filter known MWEs from the training corpus. Second, we group input tokens of the test corpus based on this lexicon, with special treatment for non-contiguous expressions. Third, we use an MWE-aware predominant-sense heuristic for supersense tagging. We obtain an F-score of 51.48% for MWE identification and 49.98% for supersense tagging."
P16-2026,How Naked is the Naked Truth? A Multilingual Lexicon of Nominal Compound Compositionality,2016,11,7,1,1,12002,carlos ramisch,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,None
P16-1187,Predicting the Compositionality of Nominal Compounds: Giving Word Embeddings a Hard Time,2016,41,16,2,1,23678,silvio cordeiro,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"Distributional semantic models (DSMs) are often evaluated on artificial similarity datasets containing single words or fully compositional phrases. We present a large-scale multilingual evaluation of DSMs for predicting the degree of semantic compositionality of nominal compounds on 4 datasets for English and French. We build a total of 816 DSMs and perform 2,856 evaluations using word2vec, GloVe, and PPMI-based models. In addition to the DSMs, we compare the impact of different parameters, such as level of corpus preprocessing, context window size and number of dimensions. The results obtained have a high correlation with human judgments, being comparable to or outperforming the state of the art for some datasets (Spearman's xcfx81=.82 for the Reddy dataset)."
L16-1194,mwetoolkit+sem: Integrating Word Embeddings in the mwetoolkit for Semantic {MWE} Processing,2016,16,0,2,1,23678,silvio cordeiro,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"This paper presents mwetoolkit+sem: an extension of the mwetoolkit that estimates semantic compositionality scores for multiword expressions (MWEs) based on word embeddings. First, we describe our implementation of vector-space operations working on distributional vectors. The compositionality score is based on the cosine distance between the MWE vector and the composition of the vectors of its member words. Our generic system can handle several types of word embeddings and MWE lists, and may combine individual word representations using several composition techniques. We evaluate our implementation on a dataset of 1042 English noun compounds, comparing different configurations of the underlying word embeddings and word-composition models. We show that our vector-based scores model non-compositionality better than standard association measures such as log-likelihood."
L16-1363,{D}e{Q}ue: A Lexicon of Complex Prepositions and Conjunctions in {F}rench,2016,9,0,1,1,12002,carlos ramisch,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"We introduce DeQue, a lexicon covering French complex prepositions (CPRE) like {``}{\`a} partir de{''} (from) and complex conjunctions (CCONJ) like {``}bien que{''} (although). The lexicon includes fine-grained linguistic description based on empirical evidence. We describe the general characteristics of CPRE and CCONJ in French, with special focus on syntactic ambiguity. Then, we list the selection criteria used to build the lexicon and the corpus-based methodology employed to collect entries. Finally, we quantify the ambiguity of each construction by annotating around 100 sentences randomly taken from the FRWaC. In addition to its theoretical value, the resource has many potential practical applications. We intend to employ DeQue for treebank annotation and to train a dependency parser that can takes complex constructions into account."
W15-0908,Never-Ending Multiword Expressions Learning,2015,35,4,3,0,37085,alexandre rondon,Proceedings of the 11th Workshop on Multiword Expressions,0,"This paper introduces NEMWEL, a system that performs Never-Ending MultiWord Expressions Learning. Instead of using a static corpus and classifier, NEMWEL applies supervised learning on automatically crawled news texts. Moreover, it uses its own results to periodically retrain the classifier, bootstrapping on its own results. In addition to a detailed description of the systemxe2x80x99s architecture and its modules, we report the results of a manual evaluation. It shows that NEMWEL is capable of learning new expressions over time with improved precision."
P15-1108,Joint Dependency Parsing and Multiword Expression Tokenization,2015,24,6,2,0,5812,alexis nasr,Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),1,"Complex conjunctions and determiners are often considered as pretokenized units in parsing. This is not always realistic, since they can be ambiguous. We propose a model for joint dependency parsing and multiword expressions identification, in which complex function words are represented as individual tokens linked with morphological dependencies. Our graph-based parser includes standard second-order features and verbal subcategoriza-tion features derived from a syntactic lexicon .We train it on a modified version of the French Treebank enriched with morphological dependencies. It recognizes 81.79% of ADVque conjunctions with 91.57% precision, and 82.74% of deDET determiners with 86.70% precision."
laranjeira-etal-2014-comparing,Comparing the Quality of Focused Crawlers and of the Translation Resources Obtained from them,2014,18,7,4,0,39339,bruno laranjeira,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"Comparable corpora have been used as an alternative for parallel corpora as resources for computational tasks that involve domain-specific natural language processing. One way to gather documents related to a specific topic of interest is to traverse a portion of the web graph in a targeted way, using focused crawling algorithms. In this paper, we compare several focused crawling algorithms using them to collect comparable corpora on a specific domain. Then, we compare the evaluation of the focused crawling algorithms to the performance of linguistic processes executed after training with the corresponding generated corpora. Also, we propose a novel approach for focused crawling, exploiting the expressive power of multiword expressions."
padro-etal-2014-comparing,Comparing Similarity Measures for Distributional Thesauri,2014,23,4,4,0,18764,muntsa padro,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"Distributional thesauri have been applied for a variety of tasks involving semantic relatedness. In this paper, we investigate the impact of three parameters: similarity measures, frequency thresholds and association scores. We focus on the robustness and stability of the resulting thesauri, measuring inter-thesaurus agreement when testing different parameter values. The results obtained show that low-frequency thresholds affect thesaurus quality more than similarity measures, with more agreement found for increasing thresholds.These results indicate the sensitivity of distributional thesauri to frequency. Nonetheless, the observed differences do not transpose over extrinsic evaluation using TOEFL-like questions. While this may be specific to the task, we argue that a careful examination of the stability of distributional resources prior to application is needed."
D14-1047,Nothing like Good Old Frequency: Studying Context Filters for Distributional Thesauri,2014,19,6,4,0,18764,muntsa padro,Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP}),0,"Much attention has been given to the impact of informativeness and similarity measures on distributional thesauri. We investigate the effects of context filters on thesaurus quality and propose the use of cooccurrence frequency as a simple and inexpensive criterion. For evaluation, we measure thesaurus agreement with WordNet and performance in answering TOEFL-like questions. Results illustrate the sensitivity of distributional thesauri to filters."
W13-1014,Identifying Pronominal Verbs: Towards Automatic Disambiguation of the Clitic {`}se{'} in {P}ortuguese,2013,10,1,4,0.666667,30756,magali duran,Proceedings of the 9th Workshop on Multiword Expressions,0,"A challenging topic in Portuguese language processing is the multifunctional and ambiguous use of the clitic pronoun se, which impacts NLP tasks such as syntactic parsing, semantic role labeling and machine translation. Aiming to give a step forward towards the automatic disambiguation of se, our study focuses on the identification of pronominal verbs, which correspond to one of the six uses of se as a clitic pronoun, when se is considered a CONSTITUTIVE PARTICLE of the verb lemma to which it is bound, as a multiword unit. Our strategy to identify such verbs is to analyze the results of a corpus search and to rule out all the other possible uses of se. This process evidenced the features needed in a computational lexicon to automatically perform the disambiguation task. The availability of the resulting lexicon of pronominal verbs on the web enables their inclusion in broader lexical resources, such as the Portuguese versions of Wordnet, Propbank and VerbNet. Moreover, it will allow the revision of parsers and dictionaries already in use."
W12-4002,A Serious Game for Building a {P}ortuguese Lexical-Semantic Network,2012,0,2,2,0,28248,mathieu mangeot,Proceedings of the 3rd Workshop on the People{'}s Web Meets {NLP}: Collaboratively Constructed Semantic Resources and their Applications to {NLP},0,"This paper presents a game with a purpose for the construction of a Portuguese lexical-semantic network. The network creation is implicit, as players collaboratively create links between words while they have fun. We describe the principles and implementation of the platform. As this is an ongoing project, we discuss challenges and long-term goals.We present the current network in terms a quantitative and qualitative analysis, comparing it to other resources. Finally, we describe our target applications."
W12-3904,A Comparable Corpus Based on Aligned Multilingual Ontologies,2012,11,5,3,0,42183,roger granada,Proceedings of the First Workshop on Multilingual Modeling,0,"In this paper we present a methodology for building comparable corpus, using multilingual ontologies of a scpecific domain. This resource can be exploited to foster research on multilingual corpus-based ontology learning, population and matching. The building resource process is exemplified by the construction of annotated comparable corpora in English, Portuguese, and French. The corpora, from the conference organization domain, are built using the multilingual ontology concept labels as seeds for crawling relevant documents from the web through a search engine. Using ontologies allows a better coverage of the domain. The main goal of this paper is to describe the design methodology followed by the creation of the corpora. We present a preliminary evaluation and discuss their characteristics and potential applications."
W12-3301,A Broad Evaluation of Techniques for Automatic Acquisition of Multiword Expressions,2012,15,17,1,1,12002,carlos ramisch,Proceedings of {ACL} 2012 Student Research Workshop,0,"Several approaches have been proposed for the automatic acquisition of multiword expressions from corpora. However, there is no agreement about which of them presents the best cost-benefit ratio, as they have been evaluated on distinct datasets and/or languages. To address this issue, we investigate these techniques analysing the following dimensions: expression type (compound nouns, phrasal verbs), language (English, French) and corpus size. Results show that these techniques tend to extract similar candidate lists with high recall (~ 80%) for nominals and high precision (~ 70%) for verbals. The use of association measures for candidate filtering is useful but some of them are more onerous and not significantly better than raw counts. We finish with an evaluation of flexibility and an indication of which technique is recommended for each language-type-size context."
W12-3311,A Generic Framework for Multiword Expressions Treatment: from Acquisition to Applications,2012,248,22,1,1,12002,carlos ramisch,Proceedings of {ACL} 2012 Student Research Workshop,0,"This paper presents an open and flexible methodological framework for the automatic acquisition of multiword expressions (MWEs) from monolingual textual corpora. This research is motivated by the importance of MWEs for NLP applications. After briefly presenting the modules of the framework, the paper reports extrinsic evaluation results considering two applications: computer-aided lexicography and statistical machine translation. Both applications can benefit from automatic MWE acquisition and the expressions acquired automatically from corpora can both speed up and improve their quality. The promising results of previous and ongoing experiments encourage further investigation about the optimal way to integrate MWE treatment into these and many other applications."
W12-0911,Get out but don{'}t fall down: verb-particle constructions in child language,2012,31,2,3,0,7141,aline villavicencio,Proceedings of the Workshop on Computational Models of Language Acquisition and Loss,0,"Much has been discussed about the challenges posed by Multiword Expressions (MWEs) given their idiosyncratic, flexible and heterogeneous nature. Nonetheless, children successfully learn to use them and eventually acquire a number of Multiword Expressions comparable to that of simplex words. In this paper we report a wide-coverage investigation of a particular type of MWE: verb-particle constructions (VPCs) in English and their usage in child-produced and child-directed sentences. Given their potentially higher complexity in relation to simplex verbs, we examine whether they appear less prominently in child-produced than in child-directed speech, and whether the VPCs that children produce are more conservative than adults, displaying proportionally reduced lexical repertoire of VPCs or of verbs in these combinations. The results obtained indicate that regardless of any additional complexity VPCs feature widely in children data following closely adult usage. Studies like these can inform the development of computational models for language acquisition."
F12-3011,Une plate-forme g{\\'e}n{\\'e}rique et ouverte pour le traitement des expressions polylexicales (An Open and Generic Framework for the Acquisition of Multiword Expressions) [in {F}rench],2012,-1,-1,1,1,12002,carlos ramisch,"Proceedings of the Joint Conference JEP-TALN-RECITAL 2012, volume 3: RECITAL",0,None
W11-0812,Identifying and Analyzing {B}razilian {P}ortuguese Complex Predicates,2011,14,13,2,0.666667,30756,magali duran,Proceedings of the Workshop on Multiword Expressions: from Parsing and Generation to the Real World,0,"Semantic Role Labeling annotation task depends on the correct identification of predicates, before identifying arguments and assigning them role labels. However, most predicates are not constituted only by a verb: they constitute Complex Predicates (CPs) not yet available in a computational lexicon. In order to create a dictionary of CPs, this study employs a corpus-based methodology. Searches are guided by POS tags instead of a limited list of verbs or nouns, in contrast to similar studies. Results include (but are not limited to) light and support verb constructions. These CPs are classified into idiomatic and less idiomatic. This paper presents an in-depth analysis of this phenomenon, as well as an original resource containing a set of 773 annotated expressions. Both constitute an original and rich contribution for NLP tools in Brazilian Portuguese that perform tasks involving semantics."
W11-0822,Fast and Flexible {MWE} Candidate Generation with the mwetoolkit,2011,9,6,2,0,42231,vitor araujo,Proceedings of the Workshop on Multiword Expressions: from Parsing and Generation to the Real World,0,"We present an experimental environment for computer-assisted extraction of Multiword Expressions (MWEs) from corpora. Candidate extraction works in two steps: generation and filtering. We focus on recent improvements in the former, for which we increased speed and flexibility. We present examples that show the potential gains for users and applications."
ramisch-etal-2010-mwetoolkit,mwetoolkit: a Framework for Multiword Expression Identification,2010,20,47,1,1,12002,carlos ramisch,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"This paper presents the Multiword Expression Toolkit (mwetoolkit), an environment for type and language-independent MWE identification from corpora. The mwetoolkit provides a targeted list of MWE candidates, extracted and filtered according to a number of user-defined criteria and a set of standard statistical association measures. For generating corpus counts, the toolkit provides both a corpus indexation facility and a tool for integration with web search engines, while for evaluation, it provides validation and annotation facilities. The mwetoolkit also allows easy integration with a machine learning tool for the creation and application of supervised MWE extraction models if annotated data is available. In our experiment, the mwetoolkit was tested and evaluated in the context of MWE extraction in the biomedical domain. Our preliminary results show that the toolkit performs better than other approaches, especially concerning recall. Moreover, this first version can also be extended in several ways in order to improve the quality of the results."
C10-3015,Multiword Expressions in the wild? The mwetoolkit comes in handy,2010,9,35,1,1,12002,carlos ramisch,Coling 2010: Demonstrations,0,"The mwetoolkit is a tool for automatic extraction of Multiword Expressions (MWEs) from monolingual corpora. It both generates and validates MWE candidates. The generation is based on surface forms, while for the validation, a series of criteria for removing noise are provided, such as some (language independent) association measures. In this paper, we present the use of the mwetoolkit in a standard configuration, for extracting MWEs from a corpus of general-purpose English. The functionalities of the toolkit are discussed in terms of a set of selected examples, comparing it with related work on MWE extraction."
C10-2120,Web-based and combined language models: a case study on noun compound identification,2010,15,13,1,1,12002,carlos ramisch,Coling 2010: Posters,0,"This paper looks at the web as a corpus and at the effects of using web counts to model language, particularly when we consider them as a domain-specific versus a general-purpose resource. We first compare three vocabularies that were ranked according to frequencies drawn from general-purpose, specialised and web corpora. Then, we look at methods to combine heterogeneous corpora and evaluate the individual and combined counts in the automatic extraction of noun compounds from English general-purpose and specialised texts. Better n-gram counts can help improve the performance of empirical NLP systems that rely on n-gram language models."
W08-2107,"Picking them up and Figuring them out: Verb-Particle Constructions, Noise and Idiomaticity",2008,20,18,1,1,12002,carlos ramisch,{C}o{NLL} 2008: Proceedings of the Twelfth Conference on Computational Natural Language Learning,0,"This paper investigates, in a first stage, some methods for the automatic acquisition of verb-particle constructions (VPCs) taking into account their statistical properties and some regular patterns found in productive combinations of verbs and particles. Given the limited coverage provided by lexical resources, such as dictionaries, and the constantly growing number of VPCs, possible ways of automatically identifying them are crucial for any NLP task that requires some degree of semantic interpretation. In a second stage we also study whether the combination of statistical and linguistic properties can provide some indication of the degree of idiomaticity of a given VPC. The results obtained show that such combination can successfully be used to detect VPCs and distinguish idiomatic from compositional cases."
D07-1110,Validation and Evaluation of Automatically Acquired Multiword Expressions for Grammar Engineering,2007,19,50,5,0,7141,aline villavicencio,Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning ({EMNLP}-{C}o{NLL}),0,"This paper focuses on the evaluation of methods for the automatic acquisition of Multiword Expressions (MWEs) for robust grammar engineering. First we investigate the hypothesis that MWEs can be detected by the distinct statistical properties of their component words, regardless of their type, comparing 3 statistical measures: mutual information (MI), xefxbfxbd 2 and permutation entropy (PE). Our overall conclusion is that at least two measures, MI and PE, seem to differentiate MWEs from non-MWEs. We then investigate the influence of the size and quality of different corpora, using the BNC and the Web search engines Google and Yahoo. We conclude that, in terms of language usage, web generated corpora are fairly similar to more carefully built corpora, like the BNC, indicating that the lack of control and balance of these corpora are probably compensated by their size. Finally, we show a qualitative evaluation of the results of automatically adding extracted MWEs to existing linguistic resources. We argue that such a process improves qualitatively, if a more compositional approach to grammar/lexicon automated extension is adopted."
