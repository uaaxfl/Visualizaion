2020.jeptalnrecital-demos.1,"D{\\'e}mo de {AMALD}-serveur et {AMALD}-corpus, d{\\'e}di{\\'e}s {\\`a} l{'}analyse morphologique de l{'}allemand (Demonstration of {AMALD}-serveur and {AMALD}-corpus, dedicated to the morphological analysis of {G}erman)",2020,-1,-1,1,1,18749,christian boitet,"Actes de la 6e conf{\\'e}rence conjointe Journ{\\'e}es d'{\\'E}tudes sur la Parole (JEP, 33e {\\'e}dition), Traitement Automatique des Langues Naturelles (TALN, 27e {\\'e}dition), Rencontre des {\\'E}tudiants Chercheurs en Informatique pour le Traitement Automatique des Langues (R{\\'E}CITAL, 22e {\\'e}dition). Volume 4 : D{\\'e}monstrations et r{\\'e}sum{\\'e}s d'articles internationaux",0,"Le projet AMALDarium vise {\`a} offrir sur la plateforme lingwarium.org (1) un service d{'}analyse morphologique de l{'}allemand (AMALD-serveur), {\`a} grande couverture et de haute qualit{\'e}, traitant la flexion, la d{\'e}rivation et la composition, ainsi que les verbes {\`a} particule s{\'e}parable s{\'e}par{\'e}e (ou agglutin{\'e}e), (2) un corpus de r{\'e}f{\'e}rence de haute qualit{\'e} donnant tous les r{\'e}sultats possibles de l{'}analyse morphologique, avant filtrage par une m{\'e}thode statistique ou syntaxique, et (3) une plateforme (AMALD-{\'e}val) permettant d{'}organiser des {\'e}valuations comparatives, dans la perspective d{'}am{\'e}liorer les performances d{'}algorithmes d{'}apprentissage en morphologie. Nous pr{\'e}sentons ici une d{\'e}monstration en ligne seulement de AMALD-serveur et AMALD-corpus. Le corpus est un sous-ensemble anonymis{\'e} et v{\'e}rifi{\'e} d{'}un corpus en allemand form{\'e} de textes sur le cancer du sein, contenant de nombreux mots compos{\'e}s techniques."
W18-3815,Towards an Automatic Classification of Illustrative Examples in a Large {J}apanese-{F}rench Dictionary Obtained by {OCR},2018,0,0,1,1,18749,christian boitet,Proceedings of the First Workshop on Linguistic Resources for Natural Language Processing,0,"We work on improving the Cesselin, a large and open source Japanese-French bilingual dictionary digitalized by OCR, available on the web, and contributively improvable online. Labelling its examples (about 226000) would significantly enhance their usefulness for language learners. Examples are proverbs, idiomatic constructions, normal usage examples, and, for nouns, phrases containing a quantifier. Proverbs are easy to spot, but not examples of other types. To find a method for automatically or at least semi-automatically annotating them, we have studied many entries, and hypothesized that the degree of lexical similarity between results of MT into a third language might give good cues. To confirm that hypothesis, we sampled 500 examples and used Google Translate to translate into English their Japanese expressions and their French translations. The hypothesis holds well, in particular for distinguishing examples of normal usage from idiomatic examples. Finally, we propose a detailed annotation procedure and discuss its future automatization."
W16-5324,Corpus and dictionary development for classifiers/quantifiers towards a {F}rench-{J}apanese machine translation,2016,0,1,2,0,28249,mutsuko tomokiyo,Proceedings of the 5th Workshop on Cognitive Aspects of the Lexicon ({C}og{AL}ex - V),0,"Although quantifiers/classifiers expressions occur frequently in everyday communications or written documents, there is no description for them in classical bilingual paper dictionaries, nor in machine-readable dictionaries. The paper describes a corpus and dictionary development for quantifiers/classifiers, and their usage in the framework of French-Japanese machine translation (MT). They often cause problems of lexical ambiguity and of set phrase recognition during analysis, in particular for a long-distance language pair like French and Japanese. For the development of a dictionary aiming at ambiguity resolution for expressions including quantifiers and classifiers which may be ambiguous with common nouns, we have annotated our corpus with UWs (interlingual lexemes) of UNL (Universal Networking Language) found on the UNL-jp dictionary. The extraction of potential classifiers/quantifiers from corpus is made by UNLexplorer web service. Keywords : classifiers, quantifiers, phraseology study, corpus annotation, UNL (Universal Networking Language), UWs dictionary, Tori Bank, French-Japanese machine translation (MT)."
W16-4915,An Aligned {F}rench-{C}hinese corpus of 10{K} segments from university educational material,2016,0,0,4,1,18762,ruslan kalitvianski,Proceedings of the 3rd Workshop on Natural Language Processing Techniques for Educational Applications ({NLPTEA}2016),0,"This paper describes a corpus of nearly 10K French-Chinese aligned segments, produced by post-editing machine translated computer science courseware. This corpus was built from 2013 to 2016 within the PROJECT{\_}NAME project, by native Chinese students. The quality, as judged by native speakers, is ad-equate for understanding (far better than by reading only the original French) and for getting better marks. This corpus is annotated at segment-level by a self-assessed quality score. It has been directly used as supplemental training data to build a statistical machine translation system dedicated to that sublanguage, and can be used to extract the specific bilingual terminology. To our knowledge, it is the first corpus of this kind to be released."
2016.jeptalnrecital-demo.9,H{\\'e}lo{\\\\\i}se, une plate-forme pour d{\\'e}velopper des syst{\\`e}mes de {TA} compatibles Ariane en r{\\'e}seau (Heloise," a platform for collaborative development of Ariane-compatible {MT} systems)""",2016,-1,-1,2,1,18750,vincent berment,Actes de la conf{\\'e}rence conjointe JEP-TALN-RECITAL 2016. volume 5 : D{\\'e}monstrations,0,"Dans cette d{\'e}mo, nous montrons comment utiliser H{\'e}lo{\""\i}se pour d{\'e}velopper des syst{\`e}mes de TA."
W15-5947,Post-editing a chapter of a specialized textbook into 7 languages: importance of terminological proximity with {E}nglish for productivity,2015,11,0,2,0,36408,ritesh shah,Proceedings of the 12th International Conference on Natural Language Processing,0,"Access to textbooks in onexe2x80x99s own language, in parallel with the original version in the instructional language, is known to be quite helpful for foreign students studying abroad. Cooperative post-editing (PE) of specialized textbook pretranslations by the foreign students themselves is a good way to produce the xe2x80x9dtargetxe2x80x9d versions, if the students find it rewarding, and not too time-consuming, that is, no longer than about 15-20 minutes per standard page (of 1400 characters or 250 words). In the experiment reported here, PE has been performed on a whole chapter of 4420 words (in English), or about 18 standard pages, into 7 languages (Portuguese, Japanese, Russian, Spanish, Bengali, Hindi, Marathi), native tongues of the participants. Average PE time has been measured, and when possible correlated with primary PE time (the time spent in editing a MT pre-translation in the PE text area). When terms are cognates of English terms (as in French, Spanish, Portuguese, and even Russian or Japanese), because neologisms are directly borrowed from English, or built using similar roots (often Latin or Greek) and similar word formation mechanisms (composition, affixation of special prefixes and suffixes), target terms can be xe2x80x9dguessedxe2x80x9d and PE time is in the order of 15 minutes per page, even if the target language is considered xe2x80x9ddistantxe2x80x9d from English. On the other hand, PE times increase by a factor of 3 to 5 when the target language is terminologically distant from English. We found that xe2x88x97Ritesh.Shah@imag.fr xe2x80xa0Christian.Boitet@imag.fr xe2x80xa1pb@cse.iitb.ac.in is the case of Hindi, Bengali and Marathi, and probably of all Indic languages. Previous experiments seem to have missed that important point, because they were performed on too short texts (often, only a few paragraphs), and on xe2x80x9deasyxe2x80x9d pairs like English-French. A consequence is that, for terminologically distant language pairs, one should begin by separately collecting, or if necessary coining, the terms in the target languages."
W14-4713,Jibiki-{LINKS}: a tool between traditional dictionaries and lexical networks for modelling lexical resources,2014,18,0,4,0,7842,ying zhang,Proceedings of the 4th Workshop on Cognitive Aspects of the Lexicon ({C}og{AL}ex),0,"Between simple electronic dictionaries such as the TLFi (computerized French Language Treasure) 1 and lexical networks like WordNet 2 (Diller et al., 1990; Vossen, 1998), the lexical databases are growing at high speed. Our work is about the addition of rich links to lexical databases, in the context of the parallel development of lexical networks. Current research on management tools for lexical databases is strongly influenced by the field of massive data (big data) and by the Web of data (linked data). In lexical networks, one can build and use arbitrary links, but possible queries cannot model all the usual interactions with lexicographers-developers and users, that are needed, and derive from the paper world. Our work aims to find a solution that allows for the main advantages of lexical networks, while providing the equivalent of paper dictionaries by doing the lexicographic work in lexical DBs."
F14-2003,On-going Cooperative Research towards Developing Economy-Oriented {C}hinese-{F}rench {SMT} Systems with a New {SMT} Framework,2014,-1,-1,3,0,8480,yidong chen,Proceedings of TALN 2014 (Volume 2: Short Papers),0,None
W13-4706,{U}rdu {H}indi Machine Transliteration using {SMT},2013,32,3,2,1,40630,abbas malik,Proceedings of the 4th Workshop on South and Southeast {A}sian Natural Language Processing,0,"Transliteration is a process of transcribing a word of the source language into the target language such that when the native speaker of the target language pronounces it, it sounds as the native pronunciation of the source word. Statistical techniques have brought significant advances and have made real progress in various fields of Natural Language Processing (NLP). In this paper, we have analysed the application of Statistical Machine Translation (SMT) for solving the problem of Urdu Hindi transliteration using a parallel lexicon. We have designed total 24 Statistical Transliteration (ST) systems by combining different types of alignments, translation models and target language models. We have performed total 576 experiments and have reported significant results. From Hindixe2x80x93toxe2x80x93Urdu transliteration, we have achieved the maximum word-level accuracy of 71.5%. From Urduxe2x80x93toxe2x80x93Hindi transliteration, the maximum word-level accuracy is 77.8% when the input Urdu text contains all necessary diacritical marks and 77% when the input Urdu text does not contain all necessary diacritical marks. At character-level, transliteration accuracy is more than 90% in both directions."
F13-2032,An extended morphological analyzer of {G}erman handling verbal forms with separated separable particles (Un analyseur morphologique {\\'e}tendu de l{'}allemand traitant les formes verbales {\\`a} particule s{\\'e}par{\\'e}e) [in {F}rench],2013,0,2,2,0,18751,jeanphilippe guilbaud,Proceedings of TALN 2013 (Volume 2: Short Papers),0,None
2013.mtsummit-wptp.12,Online production of {HQ} parallel corpora and permanent task-based evaluation of multiple {MT} systems: both can be obtained through i{MAG}s with no added cost,2013,-1,-1,2,1,3887,lingxiao wang,Proceedings of the 2nd Workshop on Post-editing Technology and Practice,0,None
C12-3002,{H}eloise {---} An {A}riane-{G}5 Compatible Rnvironment for Developing Expert {MT} Systems Online,2012,2,0,2,1,18750,vincent berment,Proceedings of {COLING} 2012: Demonstration Papers,0,"Heloise is a reengineering of the specialised languages for linguistic programming (SLLPs) of Ariane-G5 running both Linux and Windows. Heloise makes the core of Ariane-G5 available to anyone willing to develop xe2x80x9cexpertxe2x80x9d (i.e. relying on linguistic expertise) operational machine translation (MT) systems in that framework, used with success since the 80xe2x80x99s to build many prototypes and a few systems of the xe2x80x9cmultilevel transferxe2x80x9d and xe2x80x9cinterlinguaxe2x80x9d architecture. This initiative is part of the movement to reduce the digital divide by providing easily understandable tools that allow the development of lingware for poorly-resourced languages (xcfx80-languages). This demo article presents Heloise and provides some information about ongoing development using it."
C12-3018,An In-Context and Collaborative Software Localisation Model,2012,5,0,2,0,18550,amel fraisse,Proceedings of {COLING} 2012: Demonstration Papers,0,"We propose a demonstration of our in context and collaborative software localisation model. It involves volunteer localisers and end users in the localisation process via an efficient and dynamic workflow: while using an application (in context), users knowing the source language of the application (often but not always English) can modify strings of the user interface presented by the application in their current context. The implementation of that approach to localisation requires the integration of a collaborative platform. That leads to a new tripartite localisation workflow. We have experimented with our approach on Notepad. A demonstration video is proposed as a supplementary material."
C12-3032,Collaborative Computer-Assisted Translation Applied to Pedagogical Documents and Literary Works,2012,2,1,2,1,18762,ruslan kalitvianski,Proceedings of {COLING} 2012: Demonstration Papers,0,"This paper showcases three applications of GETALP's iMAG (Interactive Multilingual Access Gateway) technology. IMAGs allow internet users to navigate a selected website in the language of their choice (using machine translation), as well as to collaboratively and incrementally improve the translation through a web-based interface. One of GETALP's ongoing projects is MACAU (Multilingual Access and Contributive Appropriation for Universities), a platform that allows users to reuse existing pedagogical material to generate adaptive content. We demonstrate how student- and teacher-produced lecture notes can be translated into different languages in the context of MACAU, and show the same approach applied to textbooks and to literary works. xd0x9fxd1x80xd0xb8xd0xbcxd0xb5xd0xbdxd0xb5xd0xbdxd0xb8xd0xb5 xd0xbaxd0xbexd0xbbxd0xbbxd0xb5xd0xbaxd1x82xd0xb8xd0xb2xd0xbdxd0xbexd0xb3xd0xbe xd0xb0xd0xb2xd1x82xd0xbexd0xbcxd0xb0xd1x82xd0xb8xd0xb7xd0xb8xd1x80xd0xbexd0xb2xd0xb0xd0xbdxd0xbexd0xb3xd0xbe xd0xbfxd0xb5xd1x80xd0xb5xd0xb2xd0xbexd0xb4xd0xb0 xd0xba xd1x83xd1x87xd0xb5xd0xb1xd0xbdxd1x8bxd0xbc xd0xbcxd0xb0xd1x82xd0xb5xd1x80xd0xb8xd0xb0xd0xbbxd0xb0xd0xbc xd0xb8 xd0xbbxd0xb8xd1x82xd0xb5xd1x80xd0xb0xd1x82xd1x83xd1x80xd0xbdxd1x8bxd0xbc xd1x80xd0xb0xd0xb1xd0xbexd1x82xd0xb0xd0xbc xd0xa0xd0x95xd0x97xd0xaexd0x9cxd0x95 xd0xadxd1x82xd0xb0 xd1x81xd1x82xd0xb0xd1x82xd1x8cxd1x8f xd0xb4xd0xb5xd0xbcxd0xbexd0xbdxd1x81xd1x82xd1x80xd0xb8xd1x80xd1x83xd0xb5xd1x82 xd1x82xd1x80xd0xb8 xd0xbfxd1x80xd0xb8xd0xbcxd0xb5xd0xbdxd0xb5xd0xbdxd0xb8xd1x8f xd1x82xd0xb5xd1x85xd0xbdxd0xbexd0xbbxd0xbexd0xb3xd0xb8xd0xb8 iMAG (Interactive Multilingual Access Gateway) xd0xbbxd0xb0xd0xb1xd0xbexd1x80xd0xb0xd1x82xd0xbexd1x80xd0xb8xd0xb8 GETALP-LIG. IMAG-xd0xb8 xd0xbfxd0xbexd0xb7xd0xb2xd0xbexd0xbbxd1x8fxd1x8exd1x82 xd0x98xd0xbdxd1x82xd0xb5xd1x80xd0xbdxd0xb5xd1x82-xd0xbfxd0xbexd0xbbxd1x8cxd0xb7xd0xbexd0xb2xd0xb0xd1x82xd0xb5xd0xbbxd1x8fxd0xbc xd0xbfxd0xbexd1x81xd0xb5xd1x89xd0xb0xd1x82xd1x8c xd0xb8xd0xb7xd0xb1xd1x80xd0xb0xd0xbdxd0xbdxd1x8bxd0xb9 xd0xb2xd0xb5xd0xb1-xd1x81xd0xb0xd0xb9xd1x82 xd0xbdxd0xb0 xd0xb6xd0xb5xd0xbbxd0xb0xd0xb5xd0xbcxd0xbexd0xbc xd1x8fxd0xb7xd1x8bxd0xbaxd0xb5 xd0xb1xd0xbbxd0xb0xd0xb3xd0xbexd0xb4xd0xb0xd1x80xd1x8f xd0xbcxd0xb0xd1x88xd0xb8xd0xbdxd0xbdxd0xbexd0xbcxd1x83 xd0xbfxd0xb5xd1x80xd0xb5xd0xb2xd0xbexd0xb4xd1x83, xd0xb0 xd1x82xd0xb0xd0xba xd0xb6xd0xb5 xd0xbfxd0xbexd1x81xd1x82xd0xb5xd0xbfxd0xb5xd0xbdxd0xbdxd0xbe xd0xbaxd0xbexd0xbbxd0xbbxd0xb5xd0xbaxd1x82xd0xb8xd0xb2xd0xbdxd0xbe xd1x83xd0xbbxd1x83xd1x87xd1x88xd0xb0xd1x82xd1x8c xd0xbfxd0xb5xd1x80xd0xb5xd0xb2xd0xbexd0xb4 xd1x87xd0xb5xd1x80xd0xb5xd0xb7 xd0xb2xd0xb5xd0xb1-xd0xb8xd0xbdxd1x82xd0xb5xd1x80xd1x84xd0xb5xd0xb9xd1x81. xd0x9exd0xb4xd0xb8xd0xbd xd0xb8xd0xb7 xd1x82xd0xb5xd0xbaxd1x83xd1x89xd0xb8xd1x85 xd0xbfxd1x80xd0xbexd0xb5xd0xbaxd1x82xd0xbexd0xb2 GETALP - MACAU (Multilingual Access and Contributive Appropriation for Universities), xd0xbfxd0xbbxd0xb0xd1x82xd1x84xd0xbexd1x80xd0xbcxd0xb0, xd0xbfxd0xbexd0xb7xd0xb2xd0xbexd0xbbxd1x8fxd1x8exd1x89xd0xb0xd1x8f xd0xbfxd0xbexd0xbbxd1x8cxd0xb7xd0xbexd0xb2xd0xb0xd1x82xd0xb5xd0xbbxd1x8fxd0xbc xd0xb8xd1x81xd0xbfxd0xbexd0xbbxd1x8cxd0xb7xd0xbexd0xb2xd0xb0xd1x82xd1x8c xd1x81xd1x83xd1x89xd0xb5xd1x81xd1x82xd0xb2xd1x83xd1x8exd1x89xd0xb8xd0xb5 xd0xbfxd0xb5xd0xb4xd0xb0xd0xb3xd0xbexd0xb3xd0xb8xd1x87xd0xb5xd1x81xd0xbaxd0xb8xd0xb5 xd0xbcxd0xb0xd1x82xd0xb5xd1x80xd0xb8xd0xb0xd0xbbxd1x8b, xd1x87xd1x82xd0xbexd0xb1xd1x8b xd0xb3xd0xb5xd0xbdxd0xb5xd1x80xd0xb8xd1x80xd0xbexd0xb2xd0xb0xd1x82xd1x8c xd0xbfxd0xb5xd1x80xd1x81xd0xbexd0xbdxd0xb0xd0xbbxd0xb8xd0xb7xd0xb8xd1x80xd0xbexd0xb2xd0xb0xd0xbdxd0xbdxd1x8bxd0xb5 xd1x83xd1x80xd0xbexd0xbaxd0xb8. xd0x9cxd1x8b xd0xbfxd0xbexd0xbaxd0xb0xd0xb7xd1x8bxd0xb2xd0xb0xd0xb5xd0xbc, xd0xbaxd0xb0xd0xba xd0xbaxd0xbexd0xbdxd1x81xd0xbfxd0xb5xd0xbaxd1x82xd1x8b xd1x81xd1x82xd1x83xd0xb4xd0xb5xd0xbdxd1x82xd0xbexd0xb2 xd0xb8 xd1x83xd1x87xd0xb8xd1x82xd0xb5xd0xbbxd0xb5xd0xb9 xd0xbcxd0xbexd0xb3xd1x83xd1x82 xd0xb1xd1x8bxd1x82xd1x8c xd0xbfxd0xb5xd1x80xd0xb5xd0xb2xd0xb5xd0xb4xd0xb5xd0xbdxd1x8b xd0xbdxd0xb0 xd1x80xd0xb0xd0xb7xd0xbbxd0xb8xd1x87xd0xbdxd1x8bxd0xb5 xd1x8fxd0xb7xd1x8bxd0xbaxd0xb8 xd0xb2 xd0xbaxd0xbexd0xbdxd1x82xd0xb5xd0xbaxd1x81xd1x82xd0xb5 MACAU, xd0xb8 xd0xb4xd0xb5xd0xbcxd0xbexd0xbdxd1x81xd1x82xd1x80xd0xb8xd1x80xd1x83xd0xb5xd0xbc xd0xbfxd1x80xd0xb8xd0xbcxd0xb5xd0xbdxd0xb5xd0xbdxd0xb8xd0xb5 xd0xb4xd0xb0xd0xbdxd0xbdxd0xbexd0xb3xd0xbe xd0xbfxd0xbexd0xb4xd1x85xd0xbexd0xb4xd0xb0 xd0xba xd1x83xd1x87xd0xb5xd0xb1xd0xbdxd0xb8xd0xbaxd0xb0xd0xbc xd0xb8 xd0xbbxd0xb8xd1x82xd0xb5xd1x80xd0xb0xd1x82xd1x83xd1x80xd0xbdxd1x8bxd0xbc xd1x80xd0xb0xd0xb1xd0xbexd1x82xd0xb0xd0xbc."
C12-3060,"Demo of i{MAG} Possibilities: {MT}-postediting, Translation Quality Evaluation, Parallel Corpus Production",2012,0,1,3,0,43676,ling wang,Proceedings of {COLING} 2012: Demonstration Papers,0,None
C12-2012,{H}eloise {---} A Reengineering of {A}riane-{G}5 {SLLP}s for Application to {\\mbox{$\\pi$}}-languages,2012,2,2,2,1,18750,vincent berment,Proceedings of {COLING} 2012: Posters,0,"Heloise is a reengineering of the specialised languages for linguistic programming (SLLPs) of Ariane-G5 running both Linux and Windows. Heloise makes the core of Ariane-G5 available to anyone willing to develop xe2x80x9cexpertxe2x80x9d (i.e. relying on linguistic expertise) operational machine translation (MT) systems in that framework, used with success since the 80xe2x80x99s to build many prototypes and a few systems of the xe2x80x9cmultilevel transferxe2x80x9d and xe2x80x9cinterlinguaxe2x80x9d architecture. This initiative is part of the movement to reduce the digital divide by providing easily understandable tools that allow the development of lingware for poorly-resourced languages (xcfx80-languages). This paper shows how Heloise can contribute to the democratisation of quality MT, describes some technical aspects of it, and provides elements of comparison with Ariane-G5."
Y11-1050,Learning-to-Translate Based on the {S}-{SSTC} Annotation Schema,2011,8,1,3,0,41422,enya tang,"Proceedings of the 25th Pacific Asia Conference on Language, Information and Computation",0,"We present the S-SSTC framework for machine translation (MT), introduced in 2002 and developed since as a set of working MT systems (SiSTeC-ebmt). Our approach is example-based, but differs from other EBMT approaches in that it uses alignments of string-tree alignments, and in that supervised learning is an integral part of the approach. Our model directly deals with three main difficulties in the traditional treatment of MT that stem from its separation from the translation task (the 'world'). First, by allowing the system to learn from real translation examples directly, we avoid the need to indefinitely pursue the elusive goal of writing grammars to exactly describe intermediate syntacticosemantic monolingual representations and their correspondences. Second, we make explicit the dependence of the MT system performance on the input from the environment. That is possible only because the learning process uses feedback from the real translation knowledge when constructing its knowledge representation. Third, such MT systems using an inductively learned knowledge base yield a desirable non-regressive behavior by using translation mistakes to improve their knowledge base."
2011.tc-1.10,Operationalization of interactive multilingual gateways (i{MAG}s) in the Traouiero project,2011,2,0,1,1,18749,christian boitet,Proceedings of Translating and the Computer 33,0,"We will explain and demonstrate iMAGs (interactive Multilingual Access Gateways), in particular on a scientific laboratory web site and on the Greater Grenoble (La Metro) web site. This bilingual presentation has been obtained using an iMAG. Presentation This presentation is an adaptation and update of an article presented as a demonstration only to TALN-2010. The names of the files have been kept the same, although their contents are slightly different. The iMAG concept has been proposed by Ch. Boitet and V. Bellynck in 2006 (Boitet & al. 2008, Boitet & al. 2005), and reached prototype status in November 2008, with a first demonstration on the LIG laboratory Web site. It has been adapted to the DSR (Digital Silk Road) Web site in April 2009, and then to more than 50 other Web sites. These first prototypes are extensions of the SECTra_w (Huynh & al. 2008) online translation corpora support system. Since the beginning of 2011, we are operationalizing this software with a view to deploy it as a multilingual access infrastructure, in the context of the French ANR (National Agency for Research) Traouiero  emergence  project. An iMAG is an interactive Multilingual Access Gateway very much like Google Translate at first sight: one gives it a URL (starting Web site) and an access language and then navigates in that access language. When the cursor hovers over a segment (usually a sentence or a title), a palette shows the source segment and proposes to contribute by correcting the target segment, in effect post-editing an MT result. With Google Translate, the page does not change after contribution, and if another page contains the same segment, its translation is still the rough MT result, not the polished post-edited version. The more recent Google Translation Toolkit enables one to MT-translate and then post-edit online full Web pages from sites such as Wikipedia, but again the corrected segments don't appear when one later browses the Wikipedia page in the access language. By contrast, an iMAG is dedicated to an elected Web site, or rather to the elected sublanguage defined by one or more URLs and their textual content. It contains a translation memory (TM) and a specific, preterminological dictionary (pTD), both dedicated to the elected sublanguage. Segments are pretranslated not by a unique MT system, but by a (selectable) set of MT systems. Systran and Google are mainly used now, but specialized systems developed from the postedited part of the TM, and based on Moses, will be also used in the future. The powerful online contributive platforms SECTra_w and PIVAX (Nguyen & al. 2007) are used to support the TMs and pTDs. Translated pages are built with the best segment translations available so far. While reading a translated page, it is possible not only to contribute to the segment under the cursor, but also to seamlessly switch to SECTra_w online post-editing environment, equipped with proactive dictionary help and good filtering and search-and-replace functions, and then back to the reading context. A translation relay is being implemented to define the iMAGs or other translation gateways used by an elected Web site, select and parameterize the MT systems and translation routes used for various language pairs, and manage users, groups, projects (some contributions may be organized, other opportunistic), and access rights. Finally, MT systems tailored to the selected sublanguage can be built (by combinations of empirical and expert methods) from the TM and the pTD dedicated to a given elected Web site. That approach will inherently raise the linguistic and terminological quality of the MT results, hopefully converting them from rough into raw translations. The demonstration will use some iMAGs created by the AXiMAG startup for various Web sites, such as those of the LIG lab (http://service.aximag.fr:8180/xwiki/bin/view/imag/liglab) and of La Metro (Greater Grenoble) web site (http://service.aximag.fr:8180/xwiki/bin/view/imag/lametro), where access in Chinese and English was enabled in 2010 for the Shanghai Expo."
2011.jeptalnrecital-court.39,Communaut{\\'e}s {I}nternet comme sources de pr{\\'e}terminologie ({I}nternet communities as sources of preterminology),2011,-1,-1,2,0,33503,mohammad daoud,Actes de la 18e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles courts,0,"Cet article d{\'e}crit deux exp{\'e}riences sur la construction de ressources terminologiques multilingues (preterminologies) pr{\'e}liminaires, mais grandes, gr{\^a}ce {\`a} des communaut{\'e}s Internet, et s{'}appuie sur ces exp{\'e}riences pour cibler des donn{\'e}es terminologiques plus raffin{\'e}es venant de communaut{\'e}s Internet et d{'}applications Web 2.0. La premi{\`e}re exp{\'e}rience est une passerelle de contribution pour le site Web de la Route de la Soie num{\'e}rique (DSR). Les visiteurs contribuent en effet {\`a} un r{\'e}f{\'e}rentiel lexical multilingue d{\'e}di{\'e}, pendant qu{'}ils visitent et lisent les livres archiv{\'e}s, parce qu{'}ils sont int{\'e}ress{\'e}s par le domaine et ont tendance {\`a} {\^e}tre polygottes. Nous avons recueilli 1400 contributions lexicales en 4 mois. La seconde exp{\'e}rience est bas{\'e}e sur le JeuxDeMots arabe, o{\`u} les joueurs en ligne contribuent {\`a} un r{\'e}seau lexical arabe. L{'}exp{\'e}rience a entra{\^\i}n{\'e} une croissance r{\'e}guli{\`e}re du nombre de joueurs et de contributions, ces derni{\`e}res contenant des termes absents et des mots de dialectes oraux."
W10-4009,Ontology driven content extraction using interlingual annotation of texts in the {OMNIA} project,2010,18,2,5,0,37968,achille falaise,Proceedings of the 4th Workshop on Cross Lingual Information Access,0,"OMNIA is an on-going project that aims to retrieve images accompanied with multilingual texts. In this paper, we propose a generic method (language and domain independent) to extract conceptual information from such texts and spontaneous user requests. First, texts are labelled with interlingual annotation, then a generic extractor taking a domain ontology as a parameter extract relevant conceptual information. Implementation is also presented with a first experiment and preliminary results."
W10-4012,Multilinguization and Personalization of {NL}-based Systems,2010,4,0,2,1,18371,najeh hajlaoui,Proceedings of the 4th Workshop on Cross Lingual Information Access,0,None
W10-3303,Multilingual Lexical Network from the Archives of the Digital Silk Road,2010,8,1,3,0,45248,hansmohammad daoud,Proceedings of the 6th Workshop on {O}ntologies and {L}exical {R}esources,0,"We are describing the construction process of a specialized multilingual lexical resource dedicated for the ar- chive of the Digital Silk Road DSR. The DSR project creates digital archives of cultural heritage along the historical Silk Road; more than 116 of basic references on Silk Road have been digitized and made available online. These books are written in various languages and attract people from different linguistic back- ground, therefore, we are trying to build a multilingual repository for the termi- nology of the DSR to help its users, and increase the accessibility of these books. The construction of a terminological da- tabase using a classical approach is dif- ficult and expensive. Instead, we are in- troducing specialized lexical resources that can be constructed by the commu- nity and its resources; we call it Multi- lingual Preterminological Graphs MPGs. We build such graphs by ana- lyzing the access log files of the website of the Digital Silk Road. We aim at making this graph as a seed repository so multilingual volunteers can contrib- ute. We have used the access log files of the DSR since its beginning in 2003, and obtained an initial graph of around 116,000 terms. As an application, We have used this graph to obtain a preter- minological multilingual database that has a number of applications."
ramisch-etal-2010-mwetoolkit,mwetoolkit: a Framework for Multiword Expression Identification,2010,20,47,3,0,12002,carlos ramisch,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"This paper presents the Multiword Expression Toolkit (mwetoolkit), an environment for type and language-independent MWE identification from corpora. The mwetoolkit provides a targeted list of MWE candidates, extracted and filtered according to a number of user-defined criteria and a set of standard statistical association measures. For generating corpus counts, the toolkit provides both a corpus indexation facility and a tool for integration with web search engines, while for evaluation, it provides validation and annotation facilities. The mwetoolkit also allows easy integration with a machine learning tool for the creation and application of supervised MWE extraction models if annotated data is available. In our experiment, the mwetoolkit was tested and evaluated in the context of MWE extraction in the biomedical domain. Our preliminary results show that the toolkit performs better than other approaches, especially concerning recall. Moreover, this first version can also be extended in several ways in order to improve the quality of the results."
C10-3015,Multiword Expressions in the wild? The mwetoolkit comes in handy,2010,9,35,3,0,12002,carlos ramisch,Coling 2010: Demonstrations,0,"The mwetoolkit is a tool for automatic extraction of Multiword Expressions (MWEs) from monolingual corpora. It both generates and validates MWE candidates. The generation is based on surface forms, while for the validation, a series of criteria for removing noise are provided, such as some (language independent) association measures. In this paper, we present the use of the mwetoolkit in a standard configuration, for extracting MWEs from a corpus of general-purpose English. The functionalities of the toolkit are discussed in terms of a set of selected examples, comparing it with related work on MWE extraction."
C10-2091,Finite-state Scriptural Translation,2010,22,2,2,1,40630,abbas malik,Coling 2010: Posters,0,"We use robust and fast Finite-State Machines (FSMs) to solve scriptural translation problems. We describe a phonetico-morphotactic pivot UIT (universal intermediate transcription), based on the common phonetic repository of Indo-Pak languages. It is also extendable to other language groups. We describe a finite-state scriptural translation model based on finite-state transducers and UIT. We report its performance on Hindi, Urdu, Punjabi and Seraiki corpora. For evaluation, we design two classification scales based on the word and sentence accuracies for translation system classifications. We also show that subjective evaluations are vital for real life usage of a translation system in addition to objective evaluations."
C10-2120,Web-based and combined language models: a case study on noun compound identification,2010,15,13,3,0,12002,carlos ramisch,Coling 2010: Posters,0,"This paper looks at the web as a corpus and at the effects of using web counts to model language, particularly when we consider them as a domain-specific versus a general-purpose resource. We first compare three vocabularies that were ranked according to frequencies drawn from general-purpose, specialised and web corpora. Then, we look at methods to combine heterogeneous corpora and evaluate the individual and combined counts in the automatic extraction of noun compounds from English general-purpose and specialised texts. Better n-gram counts can help improve the performance of empirical NLP systems that rely on n-gram language models."
2010.jeptalnrecital-demonstration.3,The i{MAG} concept: multilingual access gateway to an elected Web sites with incremental quality increase through collaborative post-edition of {MT} pretranslations,2010,0,2,1,1,18749,christian boitet,Actes de la 17e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. D{\\'e}monstrations,0,"We will demonstrate iMAGs (interactive Multilingual Access Gateways), in particular on a scientific laboratory web site and on the Greater Grenoble (La M{\'e}tro) web site."
2010.jeptalnrecital-court.7,Weak Translation Problems {--} a case study of Scriptural Translation,2010,4,0,2,0,45925,muhammad malik,Actes de la 17e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles courts,0,"General purpose, high quality and fully automatic MT is believed to be impossible. We are interested in scriptural translation problems, which are weak sub-problems of the general problem of translation. We introduce the characteristics of the weak problems of translation and of the scriptural translation problems, describe different computational approaches (finite-state, statistical and hybrid) to solve these problems, and report our results on several combinations of Indo-Pak languages and writing systems."
W09-3536,A Hybrid Model for {U}rdu {H}indi Transliteration,2009,11,20,3,1,40630,abbas malik,Proceedings of the 2009 Named Entities Workshop: Shared Task on Transliteration ({NEWS} 2009),0,"We report in this paper a novel hybrid approach for Urdu to Hindi transliteration that combines finite-state machine (FSM) based techniques with statistical word language model based approach. The output from the FSM is filtered with the word language model to produce the correct Hindi output. The main problem handled is the case of omission of diacritical marks from the input Urdu text. Our system produces the correct Hindi output even when the crucial information in the form of diacritic marks is absent. The approach improves the accuracy of the transducer-only approach from 50.7% to 79.1%. The results reported show that performance can be improved using a word language model to disambiguate the output produced by the transducer-only approach, especially when diacritic marks are not present in the Urdu input."
2009.mtsummit-btm.3,A Web Service Enabling Gradable Post-edition of Pre-translations Produced by Existing Translation Tools: Practical Use to Provide High-quality Translation of an Online Encyclopedia,2009,-1,-1,2,1,30965,herve blanchon,Beyond Translation Memories: New Tools for Translators Workshop,0,None
huynh-etal-2008-sectra,"{SECT}ra{\\_}w.1: an Online Collaborative System for Evaluating, Post-editing and Presenting {MT} Translation Corpora",2008,8,10,2,0,47527,congphap huynh,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"SECTra{\_}w is a web-oriented system mainly dedicated to the evaluation of MT systems. After importing a source corpus, and possibly reference translations, one can call various MT systems, store their results, and have a collection of human judges perform subjective evaluation online (fluidity, adequacy). It is also possible to perform objective, task-oriented evaluation by letting humans post-edit the MT results, using a web translation editor, and measuring an edit distance and/or the post-editing time. The post-edited results can be added to the set of reference translations, or constitute it if there were no references. SECTra{\_}w makes it possible to show not only tables of figures as results of an evaluation campaign, but also the real data (source, MT outputs, references, post-edited outputs), and to make the post-edition effort sensible by transforming the trace of the edit distance computation in an intuitive presentation, much like a ÂrevisionÂ presentation in Word. The system is written in java under Xwiki and uses the Ajax technique. It can handle large, multilingual and multimedia corpora: EuroParl, BTEC, ERIM (bilingual interpreted dialogues with audio and text), Unesco-B@bel, and a test corpus by France Telecom have been loaded together and used in tests."
C08-1068,{H}indi {U}rdu Machine Transliteration using Finite-State Transducers,2008,12,30,2,1,40630,abbas malik,Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008),0,"Finite-state Transducers (FST) can be very efficient to implement inter-dialectal transliteration. We illustrate this on the Hindi and Urdu language pair. FSTs can also be used for translation between surface-close languages. We introduce UIT (universal intermediate transcription) for the same pair on the basis of their common phonetic repository in such a way that it can be extended to other languages like Arabic, Chinese, English, French, etc. We describe a transliteration model based on FST and UIT, and evaluate it on Hindi and Urdu corpora."
2008.jeptalnrecital-long.24,Les architectures linguistiques et computationnelles en traduction automatique sont ind{\\'e}pendantes,2008,-1,-1,1,1,18749,christian boitet,Actes de la 15{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Contrairement {\`a} une id{\'e}e r{\'e}pandue, les architectures linguistiques et computationnelles des syst{\`e}mes de traduction automatique sont ind{\'e}pendantes. Les premi{\`e}res concernent le choix des repr{\'e}sentations interm{\'e}diaires, les secondes le type d{'}algorithme, de programmation et de ressources utilis{\'e}s. Il est ainsi possible d{'}utiliser des m{\'e}thodes de calcul Â« expertes Â» ou Â« empiriques Â» pour construire diverses phases ou modules de syst{\`e}mes d{'}architectures linguistiques vari{\'e}es. Nous terminons en donnant quelques {\'e}l{\'e}ments pour le choix de ces architectures en fonction des situations traductionnelles et des ressources disponibles, en termes de dictionnaires, de corpus, et de comp{\'e}tences humaines."
Y07-1008,{BEYT}rans: A Free Online Collaborative {W}iki-Based {CAT} Environment Designed for Online Translation Communities,2007,4,4,3,1,48845,youcef bey,"Proceedings of the 21st Pacific Asia Conference on Language, Information and Computation",0,"This paper introduces BEYTrans (Better Environment for Your TRANSlation), the first experimental environment for free online collaborative computer-aided translation. The requirements and functionalities related to individual translators and communities of translators are distinguished and described. These functionalities have been integrated in a Wiki-based complete environment, equipped with all currently possible asynchronous linguistic resources and translation aids. Functions provided by BEYTrans are also compared with existing CAT systems and ongoing experiments are discussed."
2007.jeptalnrecital-long.12,"Vers un m{\\'e}ta-{EDL} complet, puis un {EDL} universel pour la {TAO}",2007,-1,-1,2,0,49474,hongthai nguyen,Actes de la 14{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Un {``}m{\'e}ta-EDL{''} (m{\'e}ta-Environnement de D{\'e}veloppement Linguiciel) pour la TAO permet de piloter {\`a} distance un ou plusieurs EDL pour construire des syst{\`e}mes de TAO h{\'e}t{\'e}rog{\`e}nes. Partant de CASH, un m{\'e}ta-EDL d{\'e}di{\'e} {\`a} Ariane-G5, et de WICALE 1.0, un premier m{\'e}ta-EDL g{\'e}n{\'e}rique mais aux fonctionnalit{\'e}s minimales, nous d{\'e}gageons les probl{\`e}mes li{\'e}s {\`a} l{'}ajout de fonctionnalit{\'e}s riches comme l{'}{\'e}dition et la navigation en local, et donnons une solution impl{\'e}ment{\'e}e dans WICALE 2.0. Nous y int{\'e}grons maintenant une base lexicale pour les syst{\`e}mes {\`a} Â« pivot lexical Â», comme UNL/U++. Un but {\`a} plus long terme est de passer d{'}un tel m{\'e}ta-EDL g{\'e}n{\'e}rique multifonctionnel {\`a} un EDL Â« universel Â», ce qui suppose la r{\'e}ing{\'e}nierie des compilateurs et des moteurs des langages sp{\'e}cialis{\'e}s pour la programmation linguistique (LSPL) support{\'e}s par les divers EDL."
O06-5003,"Data Management in {QRL}ex, an Online Aid System for Volunteer Translators{'}",2006,10,5,3,1,48845,youcef bey,"International Journal of Computational Linguistics {\\&} {C}hinese Language Processing, Volume 11, Number 4, {D}ecember 2006",0,"This paper proposes a new framework for a system which will help online volunteers to perform translations on their PCs while sharing resources and tools and communicating via websites. The current status of such online volunteer translators and their translation practices and tools are examined, along with related work also being discussed. General requirements are derived from these considerations. The approach taken in this study for dealing with heterogeneous linguistic resources relies on an XML structure maximizing efficiency and enabling all of the desired functionalities. The QRLex environment is under development and implements this new framework."
2006.iwslt-evaluation.3,{IWSLT}-06: experiments with commercial {MT} systems and lessons from subjective evaluations,2006,11,12,1,1,18749,christian boitet,Proceedings of the Third International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This is a short report of our participation to IWSLT-06. First, we let 2 commercial systems participate as fairly as possible (Systran v5.0 for CE, JE, AE, & IE, Atlas-II for JE), taking care of preprocessing and postprocessing tasks, and tuning as many pairs as possible by creating user dictionaries and finding a good combination of parameters (such as dictionary priority). Second, we took part in the subjective evaluation of CE results (fluency and adequacy). Details on experiments and methodological remarks are provided, with a perspective to introduce less expensive and more objective humanand task-related evaluation methods."
Y05-1005,A Framework for Data Management for the Online Volunteer Translators{'} Aid System {QRL}ex,2005,-1,-1,3,1,48845,youcef bey,"Proceedings of the 19th Pacific Asia Conference on Language, Information and Computation",0,None
W04-2215,{P}olyphra{Z}: a Tool for the Management of Parallel Corpora,2004,3,1,2,1,18371,najeh hajlaoui,Proceedings of the Workshop on Multilingual Linguistic Resources,0,"The PolyphraZ tool is being developed in the framework of the TraCorpEx project (Translation of Corpora of Examples), to manage parallel multilingual corpora through the web. Corpus files (monolingual or multilingual) are firstly converted to a standard coding (CXM.dtd, UTF8). Then, they are assembled (CPXM.dtd) to visualize them in parallel through the web. In a third stage, they are put in a Multilingual Polyphraz Memory (MPM). A polyphrase is a structure containing an original sentence and various proposals of equivalent sentences, in the same and other languages. An MPM stores one or more corpora of polyphrazes. The MPM part of PolyphraZ has 3 main web interfaces. One is a web-oriented translator workstation (TWS), where suggestions or translations come from the MPM itself, which functions as its own translation memory, and from calls to MT systems. Another serves to send sentences to MT systems with appropriate parameters, and to run various evaluation measures (NIST, BLEU, and distance computations) in order to propose to the translator a best proposal. A third interface is planned for giving feedbacks to the developers of the MT systems, in the form of lists of unknown or wrongly translated words, with suggestions for correct translations, and of parallel presentation of pairs of translations showing the editing work to be done to get one from the other. The first 2 stages are operational, and used for experimentation and MT evaluation on the CSTAR 5-lingual BTEC corpus and on the Japanese-English Tanaka corpus used as a source of examples in electronic dictionaries (JDict, Papillon). A main goal of this effort is to offer occasional and volunteer translators and posteditors access to a free TWS and to sharable translation memories put in the MPM format."
fafiotte-etal-2004-collecting,Collecting and Sharing Bilingual Spontaneous Speech Corpora: the {C}hin{F}a{D}ial Experiment,2004,3,0,2,0,47565,georges fafiotte,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"We describe here the three main platforms in the ERIM family of Web-based environments for human interpreting, two of them in more details, ERIM-Interp and ERIM-Collect, then ERIM-Aid. Each platform supports an aspect of the collecting or study of spontaneous bilingual dialogues, translated by an interpreter. ERIM-Interp is the core environment, providing mediated communication between speakers and human interpreters over the network. Using ERIM-Collect, French-Chinese interpreting data have been collected within the 3-year ChinFaDial project supported by LIAMA, a French-Chinese laboratory in Beijing. These raw speech data will be made available in the spring of 2004 on an open-access basis, using the DistribDial server, on a CLIPSGETA website. Our goal is to extend such corpora, on a collaborative scheme, to allow other research groups to contribute to the site whatever annotations they may have created, and to share them under the same conditions (GPL). An ERIM-Aid variant is intended to provide focused machine aids to Web-based human interpreters, or to monolingual distant speakers conversing in different languages."
2004.jeptalnrecital-long.11,Deux premi{\\`e}res {\\'e}tapes vers les documents auto-explicatifs,2004,-1,-1,2,1,30965,herve blanchon,Actes de la 11{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Dans le cadre du projet LIDIA, nous avons montr{\'e} que dans de nombreuses situations, la TA Fond{\'e}e sur le Dialogue (TAFD) pour auteur monolingue peut offrir une meilleure solution en traduction multicible que les aides aux traducteurs, ou la traduction avec r{\'e}vision, m{\^e}me si des langages contr{\^o}l{\'e}s sont utilis{\'e}s. Nos premi{\`e}res exp{\'e}riences ont mis en {\'e}vidence le besoin de conserver les Â« intentions de l{'}auteur Â» au moyen Â« d{'}annotations de d{\'e}sambigu{\""\i}sation Â». Ces annotations permettent de transformer le document source en un Document Auto-Explicatif (DAE). Nous pr{\'e}sentons ici une solution pour int{\'e}grer ces annotations dans un document XML et les rendre visibles et utilisables par un lecteur pour une meilleure compr{\'e}hension du Â« vrai contenu Â» du document. Le concept de Document Auto-Explicatif pourrait changer profond{\'e}ment notre fa{\c{c}}on de comprendre des documents importants ou {\'e}crits dans un style complexe. Nous montrerons aussi qu{'}un DAE, traduit dans une langue cible L, pourrait aussi {\^e}tre transform{\'e}, sans interaction humaine, en un DAE en langue L si un analyseur et un d{\'e}sambigu{\""\i}seur sont disponibles pour cette langue L. Ainsi, un DAE pourrait {\^e}tre utilis{\'e} dans un contexte monolingue, mais aussi dans un contexte multilingue sans travail humain additionnel."
2004.iwslt-papers.1,"Spoken dialogue translation systems evaluation: results, new trends, problems and proposals",2004,23,7,2,1,30965,herve blanchon,Proceedings of the First International Workshop on Spoken Language Translation: Papers,0,"It is important to evaluate Spoken Dialogue Translation Systems, but as we show by analyzing evaluation methods in the Verbmobil, C-STAR II, and the Nespole! projects, the current state of the art is not fully satisfactory. Subjective methods are too costly, and objective methods, although cheaper, donxe2x80x99t give good indications about usability. We propose some ideas to improve that situation."
2004.iwslt-papers.5,{P}olyphra{Z}: a tool for the quantitative and subjective evaluation of parallel corpora,2004,0,0,2,1,18371,najeh hajlaoui,Proceedings of the First International Workshop on Spoken Language Translation: Papers,0,None
2004.iwslt-evaluation.3,Towards fairer evaluations of commercial {MT} systems on basic travel expressions corpora,2004,-1,-1,2,1,30965,herve blanchon,Proceedings of the First International Workshop on Spoken Language Translation: Evaluation Campaign,0,None
2003.mtsummit-papers.45,{SYSTRAN} new generation: the {XML} translation workflow,2003,2,3,2,0,13889,jean senellart,Proceedings of Machine Translation Summit IX: Papers,0,"Customization of Machine Translation (MT) is a prerequisite for corporations to adopt the technology. It is therefore important but nonetheless challenging. Ongoing implementation proves that XML is an excellent exchange device between MT modules that efficiently enables interaction between the user and the processes to reach highly granulated structure-based customization. Accomplished through an innovative approach called the SYSTRAN Translation Stylesheet, this method is coherent with the current evolution of the {``}authoring process{''}. As a natural progression, the next stage in the customization process is the integration of MT in a multilingual tool kit designed for the {``}authoring process{''}."
W02-1705,The {PAPILLON} Project: Cooperatively Building a Multilingual Lexical Data-base to Derive Open Source Dictionaries {\\&} Lexicons,2002,9,18,1,1,18749,christian boitet,COLING-02: The 2nd Workshop on NLP and XML (NLPXML-2002),0,"The PAPILLON project aims at creating a cooperative, free, permanent, web-oriented and personalizable environment for the development and the consultation of a multilingual lexical database. The initial motivation is the lack of dictionaries, both for humans and machines, between French and many Asian languages. In particular, although there are large F-J paper usage dictionaries, they are usable only by Japanese literates, as they never contain both original (kanji/kana) and romaji writing. This applies as well to Thai, Vietnamese, Lao, etc."
W02-1602,Coedition to Share Text Revision across Languages and Improve {MT} a Posteriori,2002,11,6,1,1,18749,christian boitet,{COLING}-02: Machine Translation in Asia,0,"Coedition of a natural language text and its representation in some interlingual form seems the best and simplest way to share text revision across languages. For various reasons, UNL graphs are the best candidates in this context. We are developing a prototype where, in the simplest sharing scenario, naive users interact directly with the text in their language (L0), and indirectly with the associated graph. The modified graph is then sent to the UNL-L0 deconverter and the result shown. If is is satisfactory, the errors were probably due to the graph, not to the deconverter, and the graph is sent to deconverters in other languages. Versions in some other languages known by the user may be displayed, so that improvement sharing is visible and encouraging. As new versions are added with appropriate tags and attributes in the original multilingual document, nothing is ever lost, and cooperative working on a document is rendered feasible. On the internal side, liaisons are established between elements of the text and the graph by using broadly available resources such as a L0-English or better a L0-UNL dictionary, a morphosyntactic parser of L0, and a canonical graph2tree transformation. Establishing a best correspondence between the UNL-treeL0 and the MS-L0 structure, a lattice, may be done using the dictionary and trying to align the tree and the selected trajectory with as few crossing liaisons as possible. A central goal of this research is to merge approaches from pivot MT, interactive MT, and multilingual text authoring."
lafourcade-boitet-2002-unl,{UNL} Lexical Selection with Conceptual Vectors,2002,9,9,2,0,5594,mathieu lafourcade,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"When deconverting a UNL graph into some natural language LG, we often encounter lexical items (called UWs) made of an English headword and formalized semantic restrictions, such as look for (icl>do, agt>person), which are not yet connected to lemmas, so that is it necessary to find a nearest UW in the UNL-LG dictionary, such as look for (icl>action, agt>human, obj>thing). Then, this UW may be connected to several lemmas of LG. In order to solve these problems of incompleteness and polysemy, we are applying a method based on the computation of conceptual vectors, previously used successfully in the context of thematic indexing of French and English documents."
2002.jeptalnrecital-long.25,La co{\\'e}dition langueâ{UNL} pour partager la r{\\'e}vision entre les langues d{'}un document multilingue : un concept unificateur,2002,-1,-1,1,1,18749,christian boitet,Actes de la 9{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"La co{\'e}dition d{'}un texte en langue naturelle et de sa repr{\'e}sentation dans une forme interlingue semble le moyen le meilleur et le plus simple de partager la r{\'e}vision du texte vers plusieurs langues. Pour diverses raisons, les graphes UNL sont les meilleurs candidats dans ce contexte. Nous d{\'e}veloppons un prototype o{\`u}, dans le sc{\'e}nario avec partage le plus simple, des utilisateurs {``}na{\""\i}fs{''} interagissent directement avec le texte dans leur langue (L0), et indirectement avec le graphe associ{\'e} pour corriger les erreurs. Le graphe modifi{\'e} est ensuite envoy{\'e} au d{\'e}convertisseur UNL-L0 et le r{\'e}sultat est affich{\'e}. S{'}il est satisfaisant, les erreurs {\'e}taient probablement dues au graphe et non au d{\'e}convertisseur, et le graphe est envoy{\'e} aux d{\'e}convertisseurs vers d{'}autres langues. Les versions dans certaines autres langues connues de l{'}utilisateur peuvent {\^e}tre affich{\'e}es, de sorte que le partage de l{'}am{\'e}lioration soit visible et encourageant. Comme les nouvelles versions sont ajout{\'e}es dans le document multilingue original avec des balises et des attributs appropri{\'e}s, rien n{'}est jamais perdu, et le travail coop{\'e}ratif sur un m{\^e}me document est rendu possible. Du c{\^o}t{\'e} interne, des liaisons sont {\'e}tablies entre des {\'e}l{\'e}ments du texte et du graphe en utilisant des ressources largement disponibles comme un dictionnaire L0-anglais, ou mieux L0-UNL, un analyseur morphosyntaxique de L0, et une transformation canonique de graphe UNL {\`a} arbre. On peut {\'e}tablir une {``}meilleure{''} correspondance entre {``}l{'}arbre-UNL+L0{''} et la {``}structure MS-L0{''}, une treille, en utilisant le dictionnaire et en cherchant {\`a} aligner l{'}arbre et une trajectoire avec aussi peu que possible de croisements de liaisons. Un but central de cette recherche est de fusionner les approches de la TA par pivot, de la TA interactive, et de la g{\'e}n{\'e}ration multilingue de texte."
2001.mtsummit-road.1,Four technical and organizational keys to handle more languages and improve quality (on demand) in {MT},2001,16,10,1,1,18749,christian boitet,Workshop on MT2010: Towards a Road Map for MT,0,"Despite considerable investment over the past 50 years, only a small number of language pairs is covered by MT systems designed for information access, and even fewer are capable of quality translation or speech translation. To open the door toward MT of adequate quality for all languages (at least in principle), we propose four keys. On the technical side, we should (1) dramatically increase the use of learning techniques which have demonstrated their potential at the research level, and (2) use pivot architectures, the most universally usable pivot being UNL. On the organizational side, the keys are (3) the cooperative development of open source linguistic resources on the Web, and (4) the construction of systems where quality can be improved ``on demand'' by users, either a priori through interactive disambiguation, or a posteriori by correcting the pivot representation through any language, thereby unifying MT, computer-aided authoring, and multilingual generation."
C00-2111,On {UNL} as the future {``}html of the linguistic content{''} {\\&} the reuse of existing {NLP} components in {UNL}-related applications with the example of a {UNL}-{F}rench deconverter,2000,9,27,2,1,37933,gilles serasset,{COLING} 2000 Volume 2: The 18th International Conference on Computational Linguistics,0,"After 3 years of specifying the UNL (Universal Networking Language) language and prototyping deconverters from more than 12 languages and enconverters for about 4, the UNL project has opened to the community by publishing the specifications (v2.0) of the UNL language, intended to encode the meaning of NL utterances as semantic hypergraphs and to be used as a pivot representation in multilingual information and communication systems.A UNL document is an html document with special tags to delimit the utterances and their rendering in UNL and in all natural languages currently handled. UNL can be viewed as the future html of the linguistic content. It is only an interface format, leading as well to the reuse of existing NLP components as to the development of original tools in a variety of possible applications, from automatic rough enconversion for information retrieval and information gathering translation to partially interactive enconversion or deconversion for higher quality.We illustrate these points by describing an UNL-French deconverter organized as a specific localizer followed by a classical MT transfer and an existing generator."
1999.mtsummit-1.19,A research perspective on how to democratize machine translation and translation aids aiming at high quality final output,1999,28,9,1,1,18749,christian boitet,Proceedings of Machine Translation Summit VII,0,"Machine Translation (MT) systems and Translation Aids (TA) aiming at cost-effective high quality final translation are not yet usable by small firms, departments and individuals, and handle only a few languages and language pairs. This is due to a variety of reasons, some of them not frequently mentioned. But commercial, technical and cultural reasons make it mandatory to find ways to democratize MT and TA. This goal could be attained by: (1) giving users, free of charge, TA client tools and server resources in exchange for the permission to store and refine on the server linguistic resources produced while using TA; (2) establishing a synergy between MT and TA, in particular by using them jointly in translation projects where translators codevelop the lexical resources specific to MT; (3) renouncing the illusion of fully automatic general purpose high quality MT (FAHQMT) and go for semi-automaticity (SAHQMT), where user participation, made possible by recent technical network-oriented advances, is used to solve ambiguities otherwise computationnally unsolvable due to the impossibility, intractability or cost of accessing the necessary knowledge; (4) adopting a hybrid (symbolic {\&} numerical) and ``pivot'' approach for MT, where pivot lexemes arc UNL or UNL inspired English-oriented denotations of (sets of) interlingual acceptions or word/term senses, and the rest of the representation of utterances is either fully abstract and interlingual as in UNL, or, less ambitiously but more realistically, obtained by adding to an abstract English multilevel structure features underspecified in English but essential for other languages, including minority languages."
1999.mtsummit-1.33,{UNL}-{F}rench deconversion as transfer {\\&} generation from an interlingua with possible quality enhancement through offline human interaction,1999,-1,-1,2,1,37933,gilles serasset,Proceedings of Machine Translation Summit VII,0,"We present the architecture of the UNL-French deconverter, which ``generates'' from the UNL interlingua by first ``localizing'' the UNL form for French, within UNL, and then applying slightly adapted but classical transfer and generation techniques, implemented in GETA's Ariane-G5 environment, supplemented by some UNL-specific tools. Online interaction can be used during deconversion to enhance output quality and is now used for development purposes. We show how interaction could be delayed and embedded in the postedition phase, which would then interact not directly with the output text, but indirectly with several components of the deconverter. Interacting online or offline can improve the quality not only of the utterance at hand, but also of the utterances processed later, as various preferences may be automatically changed to let the deconverter ``learn''."
P98-2197,Transforming Lattices into Non-deterministic Automata with Optional Null Arcs,1998,2,2,2,0,38003,mark seligman,"36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 2",0,"The problem of transforming a lattice into a non-deterministic finite state automaton is non-trivial. We present a transformation algorithm which tracks, for each node of an automaton under construction, the larcs which it reflects and the lattice nodes at their origins and extremities. An extension of the algorithm permits the inclusion of null, or epsilon, arcs in the output automaton. The algorithm has been successfully applied to lattices derived from dictionaries, i.e. very large corpora of strings."
C98-2192,Transforming Lattices into Non-deterministic Automata with Optional Null Arcs,1998,2,2,2,0,38003,mark seligman,{COLING} 1998 Volume 2: The 17th International Conference on Computational Linguistics,0,"The problem of transforming a lattice into a non-deterministic finite state automaton is non-trivial. We present a transformation algorithm which tracks, for each node of an automaton under construction, the larcs which it reflects and the lattice nodes at their origins and extremities. An extension of the algorithm permits the inclusion of null, or epsilon, arcs in the output automaton. The algorithm has been successfully applied to lattices derived from dictionaries, i.e. very large corpora of strings."
C96-1022,Theory and practice of ambiguity labelling with a view to interactive disambiguation in text and speech {MT},1996,5,3,1,1,18749,christian boitet,{COLING} 1996 Volume 1: The 16th International Conference on Computational Linguistics,0,"In many contexts, automatic analyzers cannot fully disambiguate a sentence or an utterance reliably, but can produce ambiguous results containing the correct interpretation. It is useful to study vatious properties of these ambiguities in the view of subsequent total or partial interactive disambiguation. We have proposed a technique for labelling ambiguities in texts and in dialogue transcriptions, and experimented it on mulitilingual data. It has been first necessary to define formally the very notion of ambiguity relative to a representation system, as well as associated concepts such as ambiguity kernel, ambiguity scope, ambiguity occurrence."
1995.mtsummit-1.7,Factors for success and failure in {MT},1995,-1,-1,1,1,18749,christian boitet,Proceedings of Machine Translation Summit V,0,None
C94-1070,The {``}Whiteboard{''} Architecture: A Way to Integrate Heterogeneous Components of {NLP} Systems,1994,15,25,1,1,18749,christian boitet,{COLING} 1994 Volume 1: The 15th {I}nternational {C}onference on {C}omputational {L}inguistics,0,"We present a new software architecture for NLP systems made of heterogeneous components, and demonstrate an architectural prototype we have built at ATR in the context of Speech Translation."
1994.bcs-1.22,Dialogue-Based {MT} and self-explaining documents as an alternative to {MAHT} and {MT} of controlled languages,1994,-1,-1,1,1,18749,christian boitet,Proceedings of the Second International Conference on Machine Translation: Ten years on,0,"We argue that, in many situations, Dialogue-Based MT is likely to offer better solutions to translation needs than machine aids to translators or batch MT, even if controlled languages are used. Objections to DBMT have led us to introduce the new concept of {``}self-explaining document{''}, which might be used in monolingual as well as in multilingual contexts, and deeply change our way of understanding important or difficult written material."
1993.mtsummit-1.15,"Practical Speech Translation Systems will Integrate Human Expertise, Multimodal Communication, and Interactive Disambiguation",1993,3,3,1,1,18749,christian boitet,Proceedings of Machine Translation Summit IV,0,"Summary It has always been remarkably difficult to build really practical Machine Translation (MT) and Speech Processing (SP) systems. As Speech Translation (ST) combines the difficulties of both endeavours, it should come as no surprise that the first prototypes, although well-researched and brilliantly demonstrated, cannot be extended towards practical systems. Dramatic progress in both MT and SP technology is not being likely to be witnessed in the near future. Besides necessary but inherently limited improvements in the component technologies, the construction of practical ST systems will require better user-friendliness, achievable through the introduction of a human expert (interpreter), multimodal communication facilities between the expert and the speakers, and various control and feed-back facilities. Because of the quality and coverage required of the Speech Recognition (SR) and Natural Language Analysis (NLA) components in realistic applications and their inherent difficulty, however, it will also be necessary to involve the end users (the speakers) in these processes, by encouraging them to control their own voice, and asking them to help through multimodal active and passive disambiguation."
C92-3148,Multilinguisation d{'}un editeur de documents structures. Application a un dictionnaire trilingue,1992,2,1,2,0,54359,huy phan,{COLING} 1992 Volume 3: The 14th {I}nternational {C}onference on {C}omputational {L}inguistics,0,None
C92-1005,About these proceedings,1992,0,0,1,1,18749,christian boitet,{COLING} 1992 Volume 1: The 14th {I}nternational {C}onference on {C}omputational {L}inguistics,0,None
C90-3006,"Towards Personal {MT}: general design, dialogue structure, potential role of speech",1990,3,22,1,1,18749,christian boitet,{COLING} 1990 Volume 3: Papers presented to the 13th International Conference on Computational Linguistics,0,"Personal MT (PMT) is a new concept in dialogue-based MT (DBMT), which we are currently studying and prototyping in the LIDIA project Ideally, a PMT system should run on PCs and be usable by everybody. To get his/her text translated into one or several languages, the writer would accept to cooperate with the system in order to standardize and clarify his/her document. There are many interesting aspects in the design of such a system. The paper briefly presents some of them (HyperText, distributed architecture, guided language, hybrid transfer/interlingua, the goes on to study in more detail the structure of the dialogue with the writer and the place of speech synthesis [1]."
C90-2006,"Towards Personal {MT}: general design, dialogue structure, potential role of speech",1990,3,22,1,1,18749,christian boitet,{COLING} 1990 Volume 2: Papers presented to the 13th International Conference on Computational Linguistics,0,"Personal MT (PMT) is a new concept in dialogue-based MT (DBMT), which we are currently studying and prototyping in the LIDIA project Ideally, a PMT system should run on PCs and be usable by everybody. To get his/her text translated into one or several languages, the writer would accept to cooperate with the system in order to standardize and clarify his/her document. There are many interesting aspects in the design of such a system. The paper briefly presents some of them (HyperText, distributed architecture, guided language, hybrid transfer/interlingua, the goes on to study in more detail the structure of the dialogue with the writer and the place of speech synthesis [1]."
1988.tmi-1.23,Bernard Vauqois{'} contribution to the theory and practice of building {MT} systems: a historical perspective,1988,-1,-1,1,1,18749,christian boitet,Proceedings of the Second Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,None
1986.tc-1.16,Current machine translation systems developed with {GETA}{'}s methodology and software tools,1986,-1,-1,1,1,18749,christian boitet,Proceedings of Translating and the Computer 8: A profession on the move,0,None
J85-1003,Automated Translation at Grenoble University,1985,5,66,2,0,58160,bernard vauquois,Computational Linguistics,0,"The authors thank Dr. Slocum for the opportunity to present the work on machine translation at Grenoble. The plan he has proposed for the contributions to this special issue was certainly a very good starting point, as a common frame to present various systems around the world. It is, however, inevitable that we could not completely fit into it, so that we have sometimes taken some liberty for which we hope to be excused."
E85-1011,Various Representations of Text Proposed for {E}urotra,1985,5,0,1,1,18749,christian boitet,Second Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"We introduce several general notions concerning the texts and the particularities of text processing on a computer support, in relation to some problems which are specific to M(A)T. And we present the solution we have proposed for the duration of the EUROTRA project."
1985.tmi-1.3,A Case Study in Software Evolution: from Ariane-78.4 to Ariane-85,1985,-1,-1,1,1,18749,christian boitet,Proceedings of the first Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,None
1985.tmi-1.6,On the Design of Expert Systems Grafted on {MT} Systems,1985,-1,-1,2,0,58342,gerber,Proceedings of the first Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,None
P84-1100,Expert Systems and Other New Techniques in {MT} Systems,1984,4,16,1,1,18749,christian boitet,10th International Conference on Computational Linguistics and 22nd Annual Meeting of the Association for Computational Linguistics,1,"Our MT systems integrate many advanced concepts from the fields of computer science, linguistics, and AI: specialized languages for linguistic programming based on production systems, complete linguistic programming environment, multilevel representations, organization of the lexicons around lexical units, units of translation of the size of several paragraphs, possibility of using text-driven heuristic strategies.We are now beginning to integrate new techniques: unified design of an integrated lexical data-base containing the lexicon in natural and coded form, use of the static grammars formalism as a specification language, addition of expert systems equipped with extralinguistic or metalinguistic knowledge, and design of a kind of structural metaeditor (driven by a static grammar) allowing the interactive construction of a document in the same way as syntactic editors are used for developing programs. We end the paper by mentioning some projects for long-term research."
