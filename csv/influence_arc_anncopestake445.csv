1992.tmi-1.1,C88-1007,0,0.0236387,"xample, an acceptable translation for the English sentence John swam across the river in Spanish would be Juan cruzó el río nadando where English swim across NP is translationally equivalent to cruzar NP nadando (&apos;cross NP swimming&apos;; Beaven, 1992). Translation mismatches of this complexity present difficulties with respect to both lexical representation and generation. Because the mismatch in this case arises from diverging regimes of lexicalization, 1 it would be desirable to state the equivalence at the lexical level; this can be done using lexical transfer techniques, e.g. bilingual signs (Beaven & Whitelock 1988; Whitelock, 1988; Zajac, 1989; Estival et al., 1990; Tsujii, 1991). At the same time, one side of the equivalence (the Spanish side in our example) involves a phrase with a &apos;gap&apos; inside (i.e. the &apos;goal&apos; argument) which can only be filled after the input source-language string is analyzed. For generation purposes, it would thus be more convenient to establish the translation equivalence through structural correspondences which relate phrasal descriptions in the source and target languages, following the treatment of head switching mismatches proposed by Kaplan et al. (1989). However, the use o"
1992.tmi-1.1,P91-1028,0,0.061436,"Missing"
1992.tmi-1.1,A92-1012,1,0.915133,"specific lexical semantic classes which are unmotivated from the perspective of the monolingual grammars. The goal of this paper is to present a strongly lexicalist approach to translation equivalence where lexical transfer can be made to drive generation without direct reference to phrasal transfer. 2 Background Within the ACQUILEX project, 1 we are testing the feasibility of constructing a multilingual Lexical Knowledge Base (LKB) for a large subset of nouns and verbs using monolingual lexicons semiautomatically derived from English, Spanish, Dutch and Italian machine-readable dictionaries (Copestake, 1992; Sanfilippo & Poznański, 1992; Ageno et al, 1992; Vossen, 1992; Calzolari, 1991). The ACQUILEX LKB provides a lexicon development environment which uses a typed graph-based unification formalism as representation language.2 It allows the user to define an inheritance network of types with associated features, and to create lexicons where such types are semi-automatically assigned to lexical templates which encode word-sense specific information extracted from machine-readable dictionaries. Consider, for example, the LKB entry relative to the first sense of the verb swim in the Longman Diction"
1992.tmi-1.1,P90-1017,0,0.160824,"s of thematic information (Dowty, 1991; Jackendoff, 1990) within a neo-Davidsonian approach to verb semantics (Sanfilippo, 1990, 1992). A box around a type as in the case of np-cat in Figure 1 indicates that the feature structure associated with the type has been shrunk to ease graphical representation. 3 Figure 2: LKB entries for the Italian and Spanish translations of swim In principle, the use of a common type system in the domain of semantic representation could be made to provide the kind of conceptual representation which is used in interlingual approaches to MT (Lytinen & Schank, 1982; Dorr, 1990). This is not the case, however, in the ACQUILEX LKB where semantic decomposition is only partially executed; for example, language-specific predicates (i.e. names of word senses such as swim_l_1_1) are still needed to differentiate word meanings. Consequently, our treatment makes it possible to exploit some of the advantages of an interlingual approach without a specific commitment to expressing all aspects of word meaning in terms of a language-independent semantic representation. While use of an interlingual semantic representation is appealing in that it should be the best solution to the"
1992.tmi-1.1,E89-1037,0,0.0768854,"bilingual signs (Beaven & Whitelock 1988; Whitelock, 1988; Zajac, 1989; Estival et al., 1990; Tsujii, 1991). At the same time, one side of the equivalence (the Spanish side in our example) involves a phrase with a &apos;gap&apos; inside (i.e. the &apos;goal&apos; argument) which can only be filled after the input source-language string is analyzed. For generation purposes, it would thus be more convenient to establish the translation equivalence through structural correspondences which relate phrasal descriptions in the source and target languages, following the treatment of head switching mismatches proposed by Kaplan et al. (1989). However, the use of phrasal transfer to cope with lexically governed mismatches requires the creation of specialised equivalents of phrase structure rules restricted to specific lexical semantic classes which are unmotivated from the perspective of the monolingual grammars. The goal of this paper is to present a strongly lexicalist approach to translation equivalence where lexical transfer can be made to drive generation without direct reference to phrasal transfer. 2 Background Within the ACQUILEX project, 1 we are testing the feasibility of constructing a multilingual Lexical Knowledge Bas"
1992.tmi-1.1,A92-1011,1,0.901248,"semantic classes which are unmotivated from the perspective of the monolingual grammars. The goal of this paper is to present a strongly lexicalist approach to translation equivalence where lexical transfer can be made to drive generation without direct reference to phrasal transfer. 2 Background Within the ACQUILEX project, 1 we are testing the feasibility of constructing a multilingual Lexical Knowledge Base (LKB) for a large subset of nouns and verbs using monolingual lexicons semiautomatically derived from English, Spanish, Dutch and Italian machine-readable dictionaries (Copestake, 1992; Sanfilippo & Poznański, 1992; Ageno et al, 1992; Vossen, 1992; Calzolari, 1991). The ACQUILEX LKB provides a lexicon development environment which uses a typed graph-based unification formalism as representation language.2 It allows the user to define an inheritance network of types with associated features, and to create lexicons where such types are semi-automatically assigned to lexical templates which encode word-sense specific information extracted from machine-readable dictionaries. Consider, for example, the LKB entry relative to the first sense of the verb swim in the Longman Dictionary of Contemporary English (P"
1992.tmi-1.1,E91-1048,0,0.0291036,"Missing"
1992.tmi-1.1,P89-1001,0,0.0186365,"English sentence John swam across the river in Spanish would be Juan cruzó el río nadando where English swim across NP is translationally equivalent to cruzar NP nadando (&apos;cross NP swimming&apos;; Beaven, 1992). Translation mismatches of this complexity present difficulties with respect to both lexical representation and generation. Because the mismatch in this case arises from diverging regimes of lexicalization, 1 it would be desirable to state the equivalence at the lexical level; this can be done using lexical transfer techniques, e.g. bilingual signs (Beaven & Whitelock 1988; Whitelock, 1988; Zajac, 1989; Estival et al., 1990; Tsujii, 1991). At the same time, one side of the equivalence (the Spanish side in our example) involves a phrase with a &apos;gap&apos; inside (i.e. the &apos;goal&apos; argument) which can only be filled after the input source-language string is analyzed. For generation purposes, it would thus be more convenient to establish the translation equivalence through structural correspondences which relate phrasal descriptions in the source and target languages, following the treatment of head switching mismatches proposed by Kaplan et al. (1989). However, the use of phrasal transfer to cope wit"
1995.tmi-1.2,J94-4004,0,0.160124,"ppo et al&apos;s encoding of a neoDavidsonian semantics by use of proto-roles is not significant. We show a linearized equivalent of their encoding of the semantics for nadando8 and the corresponding MRS representation below: [e2][while(e2, el) ∧ nadar(e2) ∧ p-agt-cause-move-manner(e2, x1) ∧ P(e1)} A simplified form of the MRS representations for (15a) and (15b) are shown in Figure 6. We assume that strict intransitive manner of motion verbs such as swim are related 7 For some other approaches to this mismatch problem see, for example, Isabelle et al, 1988; Beaven, 1992; Nirenburg and Levin, 1992; Dorr, 1994. 8 We have omitted the classification of events which Sanfilippo et al adopt — this is an important part of the analysis but is not relevant to the comparison with MRS since we could implement it in exactly the same way, by typing event variables. Apart from this, we have essentially preserved the analysis, but we do not reproduce the original FS here, since it is multiply nested, due to the use of a binary and and over 20 lines of text. 27 Figure 6: Simplified MRS representations for Kim swam across the river and Kim cruzó el río nadando 28 to entries subcategorized for a PP expressing a pat"
1995.tmi-1.2,C88-1053,0,0.0220099,". For current purposes, the distinction between MRS and Sanfilippo et al&apos;s encoding of a neoDavidsonian semantics by use of proto-roles is not significant. We show a linearized equivalent of their encoding of the semantics for nadando8 and the corresponding MRS representation below: [e2][while(e2, el) ∧ nadar(e2) ∧ p-agt-cause-move-manner(e2, x1) ∧ P(e1)} A simplified form of the MRS representations for (15a) and (15b) are shown in Figure 6. We assume that strict intransitive manner of motion verbs such as swim are related 7 For some other approaches to this mismatch problem see, for example, Isabelle et al, 1988; Beaven, 1992; Nirenburg and Levin, 1992; Dorr, 1994. 8 We have omitted the classification of events which Sanfilippo et al adopt — this is an important part of the analysis but is not relevant to the comparison with MRS since we could implement it in exactly the same way, by typing event variables. Apart from this, we have essentially preserved the analysis, but we do not reproduce the original FS here, since it is multiply nested, due to the use of a binary and and over 20 lines of text. 27 Figure 6: Simplified MRS representations for Kim swam across the river and Kim cruzó el río nadando 2"
1995.tmi-1.2,P95-1035,0,0.0506489,"ose with the appropriate coindexation. The advantage of this approach is that the transfer component contains no information about the monolingual grammar, since it merely relates existing lexical entries, and that the problem of LF equivalence is to a large extent circumvented, because the transfer component only indicates the relation of the lexical signs by coindexation. One major disadvantage of Shake-and-Bake as originally described is lack of efficiency, since the generator/parser has to consider a number of possibilities which is factorial in the number of signs in the target sentence. Poznanski et al (1995) show 16 that polynomial complexity in Shake-and-Bake generation can be achieved by including extra information from the target language grammar that constrains the possibilities tried by the generator. Although this potentially dilutes the original ideal of independent grammars, it still has advantages over alternative approaches since it could be made clear that this is control information. Even so, Shake-and-Bake (and related systems such as those described by Sanfilippo et al (1992) and Trujillo (1995)) have other disadvantages inherent to strongly lexicalist approaches. Representing phras"
1995.tmi-1.2,1992.tmi-1.1,1,0.513766,"r has to consider a number of possibilities which is factorial in the number of signs in the target sentence. Poznanski et al (1995) show 16 that polynomial complexity in Shake-and-Bake generation can be achieved by including extra information from the target language grammar that constrains the possibilities tried by the generator. Although this potentially dilutes the original ideal of independent grammars, it still has advantages over alternative approaches since it could be made clear that this is control information. Even so, Shake-and-Bake (and related systems such as those described by Sanfilippo et al (1992) and Trujillo (1995)) have other disadvantages inherent to strongly lexicalist approaches. Representing phrasal equivalences is cumbersome, since they have to be stated in terms of sets of monolingual entries. The requirement that grammars be absolutely lexicalist restricts the frameworks for which it is appropriate and is even in conflict with recent proposals within HPSG (Sag 1995). As we will illustrate in §3.1, some translation equivalences cannot be encoded simply by relating indices in a conventional semantic framework, and therefore cannot be treated without expansion and complication o"
1995.tmi-1.2,J93-1008,0,0.0225423,"essions. For simplicity, in the examples in this paper we will take the object language to be predicate calculus, but MRS is intended to be compatible with DRT. The advantages of allowing various types of semantic underspecification for translation purposes are well-known (see e.g. Alshawi et al (1991), Kay et al (1994)), so here we concentrate on the advantages of flatness or minimal structure in a semantic representation language. The problem of ensuring that a grammar can generate from a particular semantic representation is well-known: it has been discussed in the context of generation by Shieber (1993) and in machine translation by Landsbergen (1987) and Whitelock (1992) 15 among others. One difficulty is the problem of logical form equivalence: even though the grammar may accept a logical form (LF) logically equivalent to a particular LF which is input to the generator, there is no guarantee that it will generate from that syntactic form of the input LF. To take a trivial example, an English grammar might naturally produce the logical form in (la) from fierce black cat, while a straightforward transfer from the natural Spanish representation of gato negro y feroz shown in (1b) would produc"
1995.tmi-1.2,C92-2117,0,0.583056,"the object language to be predicate calculus, but MRS is intended to be compatible with DRT. The advantages of allowing various types of semantic underspecification for translation purposes are well-known (see e.g. Alshawi et al (1991), Kay et al (1994)), so here we concentrate on the advantages of flatness or minimal structure in a semantic representation language. The problem of ensuring that a grammar can generate from a particular semantic representation is well-known: it has been discussed in the context of generation by Shieber (1993) and in machine translation by Landsbergen (1987) and Whitelock (1992) 15 among others. One difficulty is the problem of logical form equivalence: even though the grammar may accept a logical form (LF) logically equivalent to a particular LF which is input to the generator, there is no guarantee that it will generate from that syntactic form of the input LF. To take a trivial example, an English grammar might naturally produce the logical form in (la) from fierce black cat, while a straightforward transfer from the natural Spanish representation of gato negro y feroz shown in (1b) would produce the LF in ( 1 c ) , which the English grammar probably would not all"
2007.mtsummit-ucnlg.18,C92-1038,0,0.0869102,"Missing"
2007.mtsummit-ucnlg.18,P04-1052,1,0.848516,"omains System IDs: CAM-B, CAM-T, CAM-BU and CAM-TU Advaith Siddharthan & Ann Copestake University of Cambridge {as372,aac10}@cl.cam.ac.uk Abstract We present four variations of our 2004 incremental algorithm (Siddharthan and Copestake, 2004), and present results on both the Furniture and People datasets. discriminating power as only one criteria for selecting attributes and allowed for the easy incorporation of other considerations such as reference modification. 2.1 Quantifying Discriminating Power For each attribute of the referent, we define the following three quotients. 1 Introduction In Siddharthan and Copestake (2004), we presented an algorithm for generating referring expressions in open domains. Our algorithm was novel in that it was intended for open domains where attribute classification in infeasible, and in that it provided the first incremental algorithm that could handle relations as well as attributes. In that paper we evaluated our algorithm by trying to reproduce referrring expressions in the Penn WSJ Treebank. Here, we describe four variations of the general method described there and evaluate it on both the furniture and People datasets. 2 Overview of 2004 algorithm GRE algorithms make the fol"
2020.coling-main.256,D16-1250,0,0.0680169,"night, 2002). Apart from the distributional signal, the early approaches make use of other monolingual clues, e.g. word spelling, cognates or word frequency.3 More recent approaches leverage the distributional signal in word embeddings without any explicit linguistic clues. Many current models (Mikolov et al., 2013; Ruder et al., 2019) learn a linear transformation between two monolingual word embedding spaces, often guided by an initial set of seed translations. This seed dictionary frequently spans several thousand word pairs (Mikolov et al., 2013; Xing et al., 2015; Lazaridou et al., 2015; Artetxe et al., 2016) but one can also provide weaker supervision, through listing only identical strings or shared numerals (Artetxe et al., 2017; Søgaard et al., 2018). For unsupervised BLI, the initial translations may also be induced automatically through exploiting the structure of the monolingual embedding spaces (Zhang et al., 2017; Conneau et al., 2018; Artetxe et al., 2018b). We focus on supervised and weakly supervised BLI which outperform unsupervised approaches (Glavaˇs et al., 2019). The BLI models are typically evaluated using the precision@k metric, which tells us how many times the correct translat"
2020.coling-main.256,P17-1042,0,0.0271259,"ng, cognates or word frequency.3 More recent approaches leverage the distributional signal in word embeddings without any explicit linguistic clues. Many current models (Mikolov et al., 2013; Ruder et al., 2019) learn a linear transformation between two monolingual word embedding spaces, often guided by an initial set of seed translations. This seed dictionary frequently spans several thousand word pairs (Mikolov et al., 2013; Xing et al., 2015; Lazaridou et al., 2015; Artetxe et al., 2016) but one can also provide weaker supervision, through listing only identical strings or shared numerals (Artetxe et al., 2017; Søgaard et al., 2018). For unsupervised BLI, the initial translations may also be induced automatically through exploiting the structure of the monolingual embedding spaces (Zhang et al., 2017; Conneau et al., 2018; Artetxe et al., 2018b). We focus on supervised and weakly supervised BLI which outperform unsupervised approaches (Glavaˇs et al., 2019). The BLI models are typically evaluated using the precision@k metric, which tells us how many times the correct translation of a source form is among the k-best candidates returned by the model. In this work we exclusively consider the precision"
2020.coling-main.256,P18-1073,0,0.0227704,"ion between two monolingual word embedding spaces, often guided by an initial set of seed translations. This seed dictionary frequently spans several thousand word pairs (Mikolov et al., 2013; Xing et al., 2015; Lazaridou et al., 2015; Artetxe et al., 2016) but one can also provide weaker supervision, through listing only identical strings or shared numerals (Artetxe et al., 2017; Søgaard et al., 2018). For unsupervised BLI, the initial translations may also be induced automatically through exploiting the structure of the monolingual embedding spaces (Zhang et al., 2017; Conneau et al., 2018; Artetxe et al., 2018b). We focus on supervised and weakly supervised BLI which outperform unsupervised approaches (Glavaˇs et al., 2019). The BLI models are typically evaluated using the precision@k metric, which tells us how many times the correct translation of a source form is among the k-best candidates returned by the model. In this work we exclusively consider the precision@1 metric, which is the least forgiving. 2.3 Morphological Inflection: A Challenge for BLI Most datasets for BLI operate at the level of inflected forms and impose no restriction on the morphosyntactic category of translated words. From a"
2020.coling-main.256,P13-1133,0,0.0642117,"ska et al. (2019). As discussed in §2.3, given that inflectional morphology is present in the induced lexicon, BLI models should be trained and evaluated on datasets which list a range of compatible inflected form pairs for every source-target lexeme pair. At this time, the dictionaries of Czarnowska et al. (2019) are the only publicly available resource that meets this criterion, and, for this reason, they are the most important evaluation benchmark used in this work. The dictionaries were generated based on Open Multilingual WordNet (Bond and Paik, 2012), Extended Open Multilingual WordNet (Bond and Foster, 2013) and UniMorph8 (Kirov et al., 2016; McCarthy et al., 2020), a resource comprised of inflectional word paradigms for 107 languages. The dictionaries only list parts of speech that undergo inflection in either the source or the target language; these are nouns, adjectives and verbs in the Romance languages. Conneau et al. (2018). MUSE (Conneau et al., 2018) was generated using an “internal translation tool” and is one of the few other resources which covers pairs of Romance languages. However, it is skewed towards most frequent forms: The vast majority of forms in MUSE are ranked in the top 10k"
2020.coling-main.256,J90-2002,0,0.81584,"ected form that lexicographers have chosen to be representative of the lexeme. For example, the lexeme RUN’s lemma is run. In many languages, the infinitive is the verbal lemma and the nominative singular is the nominal lemma. We consider a lexicon of a language to be a set of inflected forms.2 2.2 Bilingual Lexicon Induction In the NLP literature, the BLI task is to translate a given list of source-side word forms into the most appropriate corresponding target-side word forms. It dates back to 1990s. The first data-driven experiments on parallel corpora made use of word-alignment techniques (Brown et al., 1990; Kupiec, 1993; Smadja and McKeown, 1994). Such approaches were later extended to operate on non-parallel or even unrelated texts by leveraging the correlation between word co-occurrence patterns in different languages (Rapp, 1995; Fung and Lo, 1998; Fung, 1998; Koehn and Knight, 2002). Apart from the distributional signal, the early approaches make use of other monolingual clues, e.g. word spelling, cognates or word frequency.3 More recent approaches leverage the distributional signal in word embeddings without any explicit linguistic clues. Many current models (Mikolov et al., 2013; Ruder et"
2020.coling-main.256,K17-2001,1,0.898886,"Missing"
2020.coling-main.256,D19-1090,1,0.853852,"odules have no means of handling irregular morphology, beyond the irregular forms they have been exposed to during training. Guided by this insight, we propose an alternative version of our model, which employs a special treatment for forms likely to have irregular morphology—the most frequent forms (Bybee, 1995a; Baayen and Lieber, 1996; Wu et al., 2019a). We term this extension the hybrid model. It employs a frequency-based heuristic and translates the source form through its lemma only if the lemma is more frequent.6 Otherwise, it translates the inflected form 4 Indeed, the dictionaries of Czarnowska et al. (2019) on which we experiment also make this assumption. Note that the translator’s distribution, as defined in eq. (3) and eq. (4), is over all inflected forms in the target lexicon. An alternative would be to define a distribution over lemmata only. However, this would require filtering out all non-lemma forms from the target embedding matrix, which is not trivial. In our preliminary experiments, we observed that this can lead to a further performance increase. 6 We rely on the order of FAST T EXT embeddings for the relative ranking of inflected forms. 5 2850 directly, using only the translator co"
2020.coling-main.256,P19-1070,1,0.883225,"Missing"
2020.coling-main.256,L18-1550,0,0.0423771,"to supervised and semi-supervised approaches. 5.3 Skyline We also consider a version of our model which uses an oracle analyzer—the source lemma λs and tag τs are known a priori. The skyline provides an upper-bound of performance—to wit, what performance would be achievable if the model had had access to more information about the translated source form. 5.4 Experimental Details We implemented all models in PyTorch (Paszke et al., 2019), adapting the code of Wu et al. (2019b) for the transducers (analyzer and inflector). Throughout our experiments we used the Wikipedia FAST T EXT embeddings (Grave et al., 2018), which we length-normalized and mean-centered before training the models. As is standard, we trained all translators on the top 200k most frequent word forms in the vocabularies of both languages. To evaluate on very rare forms present in the dictionaries of Czarnowska et al. (2019) which are out-of-vocabulary (OOV) for FAST T EXT, we created an OOV FAST T EXT embedding for every OOV form that appears in a union of WordNet and UniMorph and appended those representations to the original embedding matrices.10 We evaluated all models using precision@1 as a metric, which is equivalent to accuracy"
2020.coling-main.256,D19-1328,0,0.0227454,"the source or the target language; these are nouns, adjectives and verbs in the Romance languages. Conneau et al. (2018). MUSE (Conneau et al., 2018) was generated using an “internal translation tool” and is one of the few other resources which covers pairs of Romance languages. However, it is skewed towards most frequent forms: The vast majority of forms in MUSE are ranked in the top 10k of the vocabularies in their respective languages, causing it to omit many morphological variants of words. The dataset also suffers from other issues, such as a high level of noise coming from proper nouns (Kementchedjhieva et al., 2019). Thus, we do not view this resource as a reasonable benchmark for BLI. 5.2 Baselines Artetxe et al. (2016). They learn an orthogonal linear transformation matrix between the source language space and the target language space, after length-normalizing and mean-centering the monolingual embedding matrices. Their method is fully supervised and works best with large amounts of training data (several thousand translation pairs). Ruder et al. (2018). They introduce a weakly supervised, self-learning model, which can induce a dictionary given only a handful of initial, seed translations. This is ac"
2020.coling-main.256,L16-1498,0,0.0605189,"3, given that inflectional morphology is present in the induced lexicon, BLI models should be trained and evaluated on datasets which list a range of compatible inflected form pairs for every source-target lexeme pair. At this time, the dictionaries of Czarnowska et al. (2019) are the only publicly available resource that meets this criterion, and, for this reason, they are the most important evaluation benchmark used in this work. The dictionaries were generated based on Open Multilingual WordNet (Bond and Paik, 2012), Extended Open Multilingual WordNet (Bond and Foster, 2013) and UniMorph8 (Kirov et al., 2016; McCarthy et al., 2020), a resource comprised of inflectional word paradigms for 107 languages. The dictionaries only list parts of speech that undergo inflection in either the source or the target language; these are nouns, adjectives and verbs in the Romance languages. Conneau et al. (2018). MUSE (Conneau et al., 2018) was generated using an “internal translation tool” and is one of the few other resources which covers pairs of Romance languages. However, it is skewed towards most frequent forms: The vast majority of forms in MUSE are ranked in the top 10k of the vocabularies in their respe"
2020.coling-main.256,W02-0902,0,0.391248,"lected forms.2 2.2 Bilingual Lexicon Induction In the NLP literature, the BLI task is to translate a given list of source-side word forms into the most appropriate corresponding target-side word forms. It dates back to 1990s. The first data-driven experiments on parallel corpora made use of word-alignment techniques (Brown et al., 1990; Kupiec, 1993; Smadja and McKeown, 1994). Such approaches were later extended to operate on non-parallel or even unrelated texts by leveraging the correlation between word co-occurrence patterns in different languages (Rapp, 1995; Fung and Lo, 1998; Fung, 1998; Koehn and Knight, 2002). Apart from the distributional signal, the early approaches make use of other monolingual clues, e.g. word spelling, cognates or word frequency.3 More recent approaches leverage the distributional signal in word embeddings without any explicit linguistic clues. Many current models (Mikolov et al., 2013; Ruder et al., 2019) learn a linear transformation between two monolingual word embedding spaces, often guided by an initial set of seed translations. This seed dictionary frequently spans several thousand word pairs (Mikolov et al., 2013; Xing et al., 2015; Lazaridou et al., 2015; Artetxe et a"
2020.coling-main.256,P93-1003,0,0.087534,"cographers have chosen to be representative of the lexeme. For example, the lexeme RUN’s lemma is run. In many languages, the infinitive is the verbal lemma and the nominative singular is the nominal lemma. We consider a lexicon of a language to be a set of inflected forms.2 2.2 Bilingual Lexicon Induction In the NLP literature, the BLI task is to translate a given list of source-side word forms into the most appropriate corresponding target-side word forms. It dates back to 1990s. The first data-driven experiments on parallel corpora made use of word-alignment techniques (Brown et al., 1990; Kupiec, 1993; Smadja and McKeown, 1994). Such approaches were later extended to operate on non-parallel or even unrelated texts by leveraging the correlation between word co-occurrence patterns in different languages (Rapp, 1995; Fung and Lo, 1998; Fung, 1998; Koehn and Knight, 2002). Apart from the distributional signal, the early approaches make use of other monolingual clues, e.g. word spelling, cognates or word frequency.3 More recent approaches leverage the distributional signal in word embeddings without any explicit linguistic clues. Many current models (Mikolov et al., 2013; Ruder et al., 2019) le"
2020.coling-main.256,P15-1027,0,0.0406645,"Fung, 1998; Koehn and Knight, 2002). Apart from the distributional signal, the early approaches make use of other monolingual clues, e.g. word spelling, cognates or word frequency.3 More recent approaches leverage the distributional signal in word embeddings without any explicit linguistic clues. Many current models (Mikolov et al., 2013; Ruder et al., 2019) learn a linear transformation between two monolingual word embedding spaces, often guided by an initial set of seed translations. This seed dictionary frequently spans several thousand word pairs (Mikolov et al., 2013; Xing et al., 2015; Lazaridou et al., 2015; Artetxe et al., 2016) but one can also provide weaker supervision, through listing only identical strings or shared numerals (Artetxe et al., 2017; Søgaard et al., 2018). For unsupervised BLI, the initial translations may also be induced automatically through exploiting the structure of the monolingual embedding spaces (Zhang et al., 2017; Conneau et al., 2018; Artetxe et al., 2018b). We focus on supervised and weakly supervised BLI which outperform unsupervised approaches (Glavaˇs et al., 2019). The BLI models are typically evaluated using the precision@k metric, which tells us how many tim"
2020.coling-main.256,W19-4226,1,0.850478,"ctored into two parts. The first part, the inflector, produces an inflected form ιt given a lemma λt and a morphological tag τt . This problem has been well studied in the NLP literature (Cotterell et al., 2016; Cotterell et al., 2017). The second part, tag translator, determines the possible target-side morphological tags that are compatible with the features present in the source tag. In principle, our model is compatible with any probabilistic inflector. In this paper, we employ the model of Wu et al. (2019b), which obtained the single-model state of the art at the time of experimentation (McCarthy et al., 2019). The model has a latent character-level monotonic alignment between the source and target inflections that is jointly learned with the transducer and is, in effect, a neuralized version of a hidden Markov model for translation (Vogel et al., 1996). 2849 In this work we focus on closely related languages and make a simplifying assumption that there exists a single most-plausible translation for each inflected form.4 We formalize the tag translator using an indicator function: ( 1 if τt = τs p(τt |τs ) = 0 if τt 6= τs For experiments with more distant language pairs one can define p(τt |τs ) to"
2020.coling-main.256,W16-1614,0,0.0589174,"ms belonging to different morpho-syntactic categories for French–Spanish. was a success, but, on the other, our more nuanced conclusion is that the task of BLI, as currently researched in NLP, is ill-defined with respect to inflectional morphology. Indeed, the authors suggest that BLI needs redirection going forward. The recent trend in BLI research is to remain data-driven and to avoid specialist linguistic annotation. Current projection-based approaches to BLI depend heavily on the assumption that the lexicons of different languages are approximately isomorphic (Mikolov et al., 2013; Miceli Barone, 2016). However, given the immense variation in morphological systems of worlds’ languages, this assumption is prima fascie false. Consider the simple contradiction of Spanish and English, where the first exhibits much more morphological inflection than the latter; there can be no one-to-one alignment between the words in those two lexicons. The failure of the isomorphism assumption has been discussed and addressed in many recent works on cross-lingual word embeddings (Søgaard et al., 2018; Nakashole and Flauger, 2018; Ormazabal et al., 2019; Vuli´c et al., 2019; Patra et al., 2019). However, none o"
2020.coling-main.256,P18-2036,0,0.0223414,"t the lexicons of different languages are approximately isomorphic (Mikolov et al., 2013; Miceli Barone, 2016). However, given the immense variation in morphological systems of worlds’ languages, this assumption is prima fascie false. Consider the simple contradiction of Spanish and English, where the first exhibits much more morphological inflection than the latter; there can be no one-to-one alignment between the words in those two lexicons. The failure of the isomorphism assumption has been discussed and addressed in many recent works on cross-lingual word embeddings (Søgaard et al., 2018; Nakashole and Flauger, 2018; Ormazabal et al., 2019; Vuli´c et al., 2019; Patra et al., 2019). However, none of those studies directly target inflectional morphology. In this work we highlight that inflectional morphology complicates BLI and NLP researchers should strive to develop a cleaner way to integrate it into their models. We contend the models we present make progress in this direction but there is still a long way to go. We now make three concrete suggestions for BLI going forward. The first two involve engaging with morphology more seriously and are extensions to the ideas in this paper. The third focuses on b"
2020.coling-main.256,P19-1492,0,0.0209653,"anguages are approximately isomorphic (Mikolov et al., 2013; Miceli Barone, 2016). However, given the immense variation in morphological systems of worlds’ languages, this assumption is prima fascie false. Consider the simple contradiction of Spanish and English, where the first exhibits much more morphological inflection than the latter; there can be no one-to-one alignment between the words in those two lexicons. The failure of the isomorphism assumption has been discussed and addressed in many recent works on cross-lingual word embeddings (Søgaard et al., 2018; Nakashole and Flauger, 2018; Ormazabal et al., 2019; Vuli´c et al., 2019; Patra et al., 2019). However, none of those studies directly target inflectional morphology. In this work we highlight that inflectional morphology complicates BLI and NLP researchers should strive to develop a cleaner way to integrate it into their models. We contend the models we present make progress in this direction but there is still a long way to go. We now make three concrete suggestions for BLI going forward. The first two involve engaging with morphology more seriously and are extensions to the ideas in this paper. The third focuses on backing away from morphol"
2020.coling-main.256,P19-1018,0,0.0207411,"v et al., 2013; Miceli Barone, 2016). However, given the immense variation in morphological systems of worlds’ languages, this assumption is prima fascie false. Consider the simple contradiction of Spanish and English, where the first exhibits much more morphological inflection than the latter; there can be no one-to-one alignment between the words in those two lexicons. The failure of the isomorphism assumption has been discussed and addressed in many recent works on cross-lingual word embeddings (Søgaard et al., 2018; Nakashole and Flauger, 2018; Ormazabal et al., 2019; Vuli´c et al., 2019; Patra et al., 2019). However, none of those studies directly target inflectional morphology. In this work we highlight that inflectional morphology complicates BLI and NLP researchers should strive to develop a cleaner way to integrate it into their models. We contend the models we present make progress in this direction but there is still a long way to go. We now make three concrete suggestions for BLI going forward. The first two involve engaging with morphology more seriously and are extensions to the ideas in this paper. The third focuses on backing away from morphology. More Fine-Grained Lexicons. Our first"
2020.coling-main.256,P95-1050,0,0.688785,"a lexicon of a language to be a set of inflected forms.2 2.2 Bilingual Lexicon Induction In the NLP literature, the BLI task is to translate a given list of source-side word forms into the most appropriate corresponding target-side word forms. It dates back to 1990s. The first data-driven experiments on parallel corpora made use of word-alignment techniques (Brown et al., 1990; Kupiec, 1993; Smadja and McKeown, 1994). Such approaches were later extended to operate on non-parallel or even unrelated texts by leveraging the correlation between word co-occurrence patterns in different languages (Rapp, 1995; Fung and Lo, 1998; Fung, 1998; Koehn and Knight, 2002). Apart from the distributional signal, the early approaches make use of other monolingual clues, e.g. word spelling, cognates or word frequency.3 More recent approaches leverage the distributional signal in word embeddings without any explicit linguistic clues. Many current models (Mikolov et al., 2013; Ruder et al., 2019) learn a linear transformation between two monolingual word embedding spaces, often guided by an initial set of seed translations. This seed dictionary frequently spans several thousand word pairs (Mikolov et al., 2013;"
2020.coling-main.256,P18-2062,0,0.0349516,"edictable items (e.g. Prasada and Pinker (1993) Pinker and Prince (1994)). 3 For more references we refer the reader to the survey of Ruder et al. (2019). 2848 evaluated on datasets that contain a more representative range of morphological inflections. We use the term morphologically enriched dictionary for such bilingual lexicons (see §5.1). To our knowledge, we are the first to explicitly model inflectional morphology in BLI. Closest to our endeavor, Yang et al. (2019) address morphology in BLI by incorporating grammatical information learned by a pre-trained denoising language model, while Riley and Gildea (2018) enhance the projection-based approach of Artetxe et al. (2017) with orthographic features to improve performance on BLI for related languages. 3 A Joint Model for Morphologically Aware Word-level Translation The primary contribution of this work is a morphologically aware probabilistic model for word-level translation. Our model exploits a simple intuition: Because the core unit of meaning is the lexeme, one should translate through the lexeme and then inflect the word according to the target language’s morphology. Notation. In the task of BLI, we consider a source language s and a target lan"
2020.coling-main.256,D18-1042,1,0.886316,"n for both the source and the target language, although in practice these look-up functions are distinct. The model has a single matrix of parameters: Ω ∈ RNt ×Ns where Ns is the source embedding dimensionality and Nt the target embedding dimensionality. Our translator is defined as the following conditional model p(λt |λs ) =  1 exp e(λt )> Ω e(λs ) Z(λs ) (3) X (4) where the normalizer is defined as Z(λs ) = exp e(λ0t )> Ω e(λs )  λ0t ∈Lt Note that this log-bilinear model differs from most embedding-based bilingual lexicon inducers which predict embeddings, rather than words. For example, Ruder et al. (2018)’s approach contains a multivariate Gaussian over the target-language’s embedding space.5 Orthogonal Regularization. During training we employ a special regularization term on the parameter matrix Ω. Specifically, we use R(Ω) = α Ω> Ω − I (5) F with a tunable “strength” hyperparameter α ∈ R≥0 . This term encourages the translation matrix to be orthogonal, which has led to consistent gains in past work (Xing et al., 2015; Artetxe et al., 2016; Ruder et al., 2018). 3.3 The Analyzer: p(λs , τs |ιs ) For our probabilistic analyzer we use the same hard attention model as in the inflector. The model"
2020.coling-main.256,H94-1027,0,0.381259,"e chosen to be representative of the lexeme. For example, the lexeme RUN’s lemma is run. In many languages, the infinitive is the verbal lemma and the nominative singular is the nominal lemma. We consider a lexicon of a language to be a set of inflected forms.2 2.2 Bilingual Lexicon Induction In the NLP literature, the BLI task is to translate a given list of source-side word forms into the most appropriate corresponding target-side word forms. It dates back to 1990s. The first data-driven experiments on parallel corpora made use of word-alignment techniques (Brown et al., 1990; Kupiec, 1993; Smadja and McKeown, 1994). Such approaches were later extended to operate on non-parallel or even unrelated texts by leveraging the correlation between word co-occurrence patterns in different languages (Rapp, 1995; Fung and Lo, 1998; Fung, 1998; Koehn and Knight, 2002). Apart from the distributional signal, the early approaches make use of other monolingual clues, e.g. word spelling, cognates or word frequency.3 More recent approaches leverage the distributional signal in word embeddings without any explicit linguistic clues. Many current models (Mikolov et al., 2013; Ruder et al., 2019) learn a linear transformation"
2020.coling-main.256,P18-1072,1,0.891487,"Missing"
2020.coling-main.256,C96-2141,0,0.765278,"t, tag translator, determines the possible target-side morphological tags that are compatible with the features present in the source tag. In principle, our model is compatible with any probabilistic inflector. In this paper, we employ the model of Wu et al. (2019b), which obtained the single-model state of the art at the time of experimentation (McCarthy et al., 2019). The model has a latent character-level monotonic alignment between the source and target inflections that is jointly learned with the transducer and is, in effect, a neuralized version of a hidden Markov model for translation (Vogel et al., 1996). 2849 In this work we focus on closely related languages and make a simplifying assumption that there exists a single most-plausible translation for each inflected form.4 We formalize the tag translator using an indicator function: ( 1 if τt = τs p(τt |τs ) = 0 if τt 6= τs For experiments with more distant language pairs one can define p(τt |τs ) to be a multi-label classifier. 3.2 The Translator: p(λt |λt ) As our translator, we construct a log-bilinear model that yields a distribution over all elements in the target lexicon. We assume the existence of both source- and target-side embeddings"
2020.coling-main.256,D19-1449,0,0.0245645,"Missing"
2020.coling-main.256,P19-1505,1,0.888004,"ns of handling irregular morphology, beyond the irregular forms they have been exposed to during training. Guided by this insight, we propose an alternative version of our model, which employs a special treatment for forms likely to have irregular morphology—the most frequent forms (Bybee, 1995a; Baayen and Lieber, 1996; Wu et al., 2019a). We term this extension the hybrid model. It employs a frequency-based heuristic and translates the source form through its lemma only if the lemma is more frequent.6 Otherwise, it translates the inflected form 4 Indeed, the dictionaries of Czarnowska et al. (2019) on which we experiment also make this assumption. Note that the translator’s distribution, as defined in eq. (3) and eq. (4), is over all inflected forms in the target lexicon. An alternative would be to define a distribution over lemmata only. However, this would require filtering out all non-lemma forms from the target embedding matrix, which is not trivial. In our preliminary experiments, we observed that this can lead to a further performance increase. 6 We rely on the order of FAST T EXT embeddings for the relative ranking of inflected forms. 5 2850 directly, using only the translator co"
2020.coling-main.256,P19-1148,1,0.891112,"ιt ,τt i∈π t hιt ,τt i∈π t inflector tag translator The joint distribution over forms and tags is factored into two parts. The first part, the inflector, produces an inflected form ιt given a lemma λt and a morphological tag τt . This problem has been well studied in the NLP literature (Cotterell et al., 2016; Cotterell et al., 2017). The second part, tag translator, determines the possible target-side morphological tags that are compatible with the features present in the source tag. In principle, our model is compatible with any probabilistic inflector. In this paper, we employ the model of Wu et al. (2019b), which obtained the single-model state of the art at the time of experimentation (McCarthy et al., 2019). The model has a latent character-level monotonic alignment between the source and target inflections that is jointly learned with the transducer and is, in effect, a neuralized version of a hidden Markov model for translation (Vogel et al., 1996). 2849 In this work we focus on closely related languages and make a simplifying assumption that there exists a single most-plausible translation for each inflected form.4 We formalize the tag translator using an indicator function: ( 1 if τt ="
2020.coling-main.256,N15-1104,0,0.0421115,"Fung and Lo, 1998; Fung, 1998; Koehn and Knight, 2002). Apart from the distributional signal, the early approaches make use of other monolingual clues, e.g. word spelling, cognates or word frequency.3 More recent approaches leverage the distributional signal in word embeddings without any explicit linguistic clues. Many current models (Mikolov et al., 2013; Ruder et al., 2019) learn a linear transformation between two monolingual word embedding spaces, often guided by an initial set of seed translations. This seed dictionary frequently spans several thousand word pairs (Mikolov et al., 2013; Xing et al., 2015; Lazaridou et al., 2015; Artetxe et al., 2016) but one can also provide weaker supervision, through listing only identical strings or shared numerals (Artetxe et al., 2017; Søgaard et al., 2018). For unsupervised BLI, the initial translations may also be induced automatically through exploiting the structure of the monolingual embedding spaces (Zhang et al., 2017; Conneau et al., 2018; Artetxe et al., 2018b). We focus on supervised and weakly supervised BLI which outperform unsupervised approaches (Glavaˇs et al., 2019). The BLI models are typically evaluated using the precision@k metric, whi"
2020.coling-main.256,P19-1308,0,0.0385215,"975), McClelland et al. (1987) and Bybee (1995b), and stands in opposition to alternative views of the lexicon being comprised of only the unpredictable items (e.g. Prasada and Pinker (1993) Pinker and Prince (1994)). 3 For more references we refer the reader to the survey of Ruder et al. (2019). 2848 evaluated on datasets that contain a more representative range of morphological inflections. We use the term morphologically enriched dictionary for such bilingual lexicons (see §5.1). To our knowledge, we are the first to explicitly model inflectional morphology in BLI. Closest to our endeavor, Yang et al. (2019) address morphology in BLI by incorporating grammatical information learned by a pre-trained denoising language model, while Riley and Gildea (2018) enhance the projection-based approach of Artetxe et al. (2017) with orthographic features to improve performance on BLI for related languages. 3 A Joint Model for Morphologically Aware Word-level Translation The primary contribution of this work is a morphologically aware probabilistic model for word-level translation. Our model exploits a simple intuition: Because the core unit of meaning is the lexeme, one should translate through the lexeme and"
2020.coling-main.256,P17-1179,0,0.0330424,"r et al., 2019) learn a linear transformation between two monolingual word embedding spaces, often guided by an initial set of seed translations. This seed dictionary frequently spans several thousand word pairs (Mikolov et al., 2013; Xing et al., 2015; Lazaridou et al., 2015; Artetxe et al., 2016) but one can also provide weaker supervision, through listing only identical strings or shared numerals (Artetxe et al., 2017; Søgaard et al., 2018). For unsupervised BLI, the initial translations may also be induced automatically through exploiting the structure of the monolingual embedding spaces (Zhang et al., 2017; Conneau et al., 2018; Artetxe et al., 2018b). We focus on supervised and weakly supervised BLI which outperform unsupervised approaches (Glavaˇs et al., 2019). The BLI models are typically evaluated using the precision@k metric, which tells us how many times the correct translation of a source form is among the k-best candidates returned by the model. In this work we exclusively consider the precision@1 metric, which is the least forgiving. 2.3 Morphological Inflection: A Challenge for BLI Most datasets for BLI operate at the level of inflected forms and impose no restriction on the morphosy"
2021.findings-emnlp.145,2020.acl-main.184,1,0.925771,"alog models (Ghandeharioun et al., (Zhang et al., 2018) with topic-shift annotations. 2019; Einolghozati et al., 2019; Liu et al., 2018) To the best of our knowledge, TIAGE is the have been reported to perform well in generating first dataset that focuses on topic-shift behaviors on-topic utterances in dialog scenarios. However, in open-domain dialog data. TIAGE contains those models still struggle to proactively gener- a human annotated dataset with 7,861 gold stanate appropriate topic-shift utterances in conversa- dard topic-shift annotations, and a weak supervitions (Holtzman et al., 2020; Zhang et al., 2020a). sion dataset to adapt pretrained NLG systems to It is beneficial for dialog systems to be able to PersonaChat-style data. The inter-annotator agreeshift topics fluently. As shown in Figure 1, topic- ment for topic-shift annotations in TIAGE is 0.479. shift behaviors are commonly observed in human With TIAGE, we propose three tasks to study conversations (Brown and Yule, 1983). Fluent topic topic-shift behaviors: topic-shift detection, topicshifts therefore are crucial for dialog models to shift triggered response generation and topic-aware be able to model or mimic human conversational dia"
2021.findings-emnlp.145,P18-1205,0,0.101746,"ntly? Topic B I finally had some spare time, so I tended my rose garden. Figure 1: An example of topic-shift behaviors in human conversations. Topic-shift utterances are highlighted in green and in italic. Changing the topic helps keep the conversation going on. shift topics away from tired topics, chatbots risk generating dull responses or repeating themselves regarding a specific topic. To facilitate research on topic-shift dialog modeling, we curate a Topic-shIft Aware dialoG datasEt 1 Introduction (TIAGE) by augmenting the PersonaChat dataset Existing dialog models (Ghandeharioun et al., (Zhang et al., 2018) with topic-shift annotations. 2019; Einolghozati et al., 2019; Liu et al., 2018) To the best of our knowledge, TIAGE is the have been reported to perform well in generating first dataset that focuses on topic-shift behaviors on-topic utterances in dialog scenarios. However, in open-domain dialog data. TIAGE contains those models still struggle to proactively gener- a human annotated dataset with 7,861 gold stanate appropriate topic-shift utterances in conversa- dard topic-shift annotations, and a weak supervitions (Holtzman et al., 2020; Zhang et al., 2020a). sion dataset to adapt pretrained"
2021.findings-emnlp.145,2020.acl-demos.30,0,0.546247,"alog models (Ghandeharioun et al., (Zhang et al., 2018) with topic-shift annotations. 2019; Einolghozati et al., 2019; Liu et al., 2018) To the best of our knowledge, TIAGE is the have been reported to perform well in generating first dataset that focuses on topic-shift behaviors on-topic utterances in dialog scenarios. However, in open-domain dialog data. TIAGE contains those models still struggle to proactively gener- a human annotated dataset with 7,861 gold stanate appropriate topic-shift utterances in conversa- dard topic-shift annotations, and a weak supervitions (Holtzman et al., 2020; Zhang et al., 2020a). sion dataset to adapt pretrained NLG systems to It is beneficial for dialog systems to be able to PersonaChat-style data. The inter-annotator agreeshift topics fluently. As shown in Figure 1, topic- ment for topic-shift annotations in TIAGE is 0.479. shift behaviors are commonly observed in human With TIAGE, we propose three tasks to study conversations (Brown and Yule, 1983). Fluent topic topic-shift behaviors: topic-shift detection, topicshifts therefore are crucial for dialog models to shift triggered response generation and topic-aware be able to model or mimic human conversational dia"
2021.findings-emnlp.145,N18-2075,0,0.0434018,"Missing"
2021.findings-emnlp.145,N18-1187,0,0.14335,"An example of topic-shift behaviors in human conversations. Topic-shift utterances are highlighted in green and in italic. Changing the topic helps keep the conversation going on. shift topics away from tired topics, chatbots risk generating dull responses or repeating themselves regarding a specific topic. To facilitate research on topic-shift dialog modeling, we curate a Topic-shIft Aware dialoG datasEt 1 Introduction (TIAGE) by augmenting the PersonaChat dataset Existing dialog models (Ghandeharioun et al., (Zhang et al., 2018) with topic-shift annotations. 2019; Einolghozati et al., 2019; Liu et al., 2018) To the best of our knowledge, TIAGE is the have been reported to perform well in generating first dataset that focuses on topic-shift behaviors on-topic utterances in dialog scenarios. However, in open-domain dialog data. TIAGE contains those models still struggle to proactively gener- a human annotated dataset with 7,861 gold stanate appropriate topic-shift utterances in conversa- dard topic-shift annotations, and a weak supervitions (Holtzman et al., 2020; Zhang et al., 2020a). sion dataset to adapt pretrained NLG systems to It is beneficial for dialog systems to be able to PersonaChat-styl"
2021.findings-emnlp.145,J97-1005,0,0.514072,"isting work in dialog systems falls into two broad categories. Task-oriented dialog systems (Budzianowski et al., 2018; Liu et al., 2018) help users complete tasks in specific domains. Opendomain dialog systems (Chen and Gao, 2017; Tang et al., 2019) allow agents to have open-ended conversations with users. Most existing dialog models (Fang et al., 2018; Zhang et al., 2020b; Ghandeharioun et al., 2019) emphasize end-to-end response generation, and do not explicitly address the topicshift problem in dialog generation. Early work in topic detection and segmentation (Hirschberg and Litman, 1993; Passonneau and Litman, 1997) focused on identifying cue phrases (such as on a different note) or examining lexical cohesion to segment topical chunks. Other work (Fiscus and Doddington, 2002) investigated topic detection and tracking (TDT) in a stream of broadcast news stories. More recent work (Glavas and Somasundaran, 2020) has explored utilizing neural networks to address topic segmentation. Although some of the existing work (Galley et al., 2003; Arnold et al., 2019) has investigated topic detection in dialog-style data, the generation aspect of topicshift modeling in dialog settings is still unclear. #Dialogs #Insta"
A92-1012,A92-1044,0,0.103996,"Missing"
A92-1012,W91-0209,1,0.835955,"pecifying the lexical entry from which information is inherited by default; as explained in Section 4 this also partially defines the lexical semantic type (RQS type), which is c _ n a t _ s u b s t in this example (for comestible, natural, substance). A fragment of the RQs type hierarchy is also shown in Figure 2 2. The differentia can be partially interpreted relative to the RQS type; in this example < r q s : o r i g i n > = "" k i p "" is an indication that kippevlees comes from kip; eventually this will allow their lexical entries to be linked automatically by the appropriate lexical rule (Copestake and Briscoe, 1991; Copestake et al., 1992). The feature ORIGIN is introduced at type n a t u r a l (the FS definition of n a t u r a l is shown in Figure 2, top right, before expansion by inheritance from n o m r q s ) . Since n a t u r a l is a parent of c_nat_subst, ORIGIN is an appropriate feature for c_nat._subst. The feature T E L I C is used to provide a slot for the semantics of the verb sense which is associated with the purpose of an entity (eating in this case). The way in which such a representation may be used in the treatment of logical metonymy was described in Briscoe et al (1990). Other feature"
A92-1012,J91-4003,0,0.0348075,"Missing"
A92-1012,A92-1011,0,0.180726,"relatively rich and detailed; applications which do not make use of detailed lexicM semantic information can simply discard the information. Clearly the converse is not true, and a more impoverished representation would be less generally useful. We thus aim for representations which are as rich as possible in information which we can extract automatically, and represent formally, but which are also well motivated linguistically a n d / o r useful for practical NLP applications. This also applies to our use of thematic roles in the semantics; see the examples of LKB entries for verbs given in Sanfilippo and Poznanski (1992, this volume). 3 The type system In the definition of a type hierarchy we follow Carpenter(1990) very closely. The type hierarchy defines a partial order (notated E_, ""is more specific than"") on the types and specifies which types are consistent. Only FSs with mutually consistent types can be unified - two types which are unordered in the hierarchy are assumed to be inconsistent unless the user explicitly specifies a common subtype. Every consistent set of types S C_ TYPE must have a unique greatest lower bound or 90 meet (notation [7S). 3 This condition allows FSs to be typed deterministical"
C08-1082,P06-4020,0,0.0395891,"Missing"
C08-1082,P99-1004,0,0.556273,". . . , P (c|C ||w)). This vector defines the parameters of a categorical or multinomial probability distribution, giving a useful probabilistic interpretation of the distributional model. As the vector for each target word must sum to 1, the marginal distributions of target words have little effect on the resulting similarity estimates. Many 649 Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 649–656 Manchester, August 2008 similarity measures and weighting functions have been proposed for distributional vectors; comparative studies include Lee (1999), Curran (2003) and Weeds and Weir (2005). finite n-element sets X ⊆ X Pand for all vectors n v = (v1 , . . . , vn ) ∈ R with i vi = 0 2.2 Whereas positive semi-definite kernels correspond to inner products in a Hilbert space F, negative semi-definite kernels correspond to squared dis˜ y) = 0 only when tances. In particular, if k(x, p x = y then k˜ is a metric. If a function k is psd, then −k is always nsd, but the converse does not hold.1 However, Berg et al. (1984) describe two simple methods for inducing a positive semi˜ definite function k from negative semi-definite k: Kernel Methods for"
C08-1082,S07-1080,0,0.0292659,"Missing"
C08-1082,W07-1108,1,0.906852,"Missing"
C08-1082,P08-1027,0,0.0749961,"Missing"
C08-1082,S07-1003,0,0.133598,"Missing"
C08-1082,P05-1050,0,0.023483,"ra, 2003; Cuturi et al., 2005; Hein and Bousquet, 2005), but they have previously been applied only to standard image and text classification benchmark tasks. We seem to be the first to use distributional kernels for semantic classification and to note their connection with familiar lexical similarity measures. Indeed, the only research we are aware of on kernels tailored for lexical similarity is the small body of work on WordNet kernels, e.g., Basili et al. (2006). In contrast, Support Vector Machines have been widely adopted for computational semantic tasks, from word sense disambiguation (Gliozzo et al., 2005) to semantic role labelling (Pradhan et al., 2004). The standard feature sets for semantic role labelling and many other tasks are collections of heterogeneous features that do not correspond to probability distributions. So long as the features are restricted to positive values, distributional kernels can be applied; it will be interesting (and informative) to see whether they retain their superiority in this setting. One advantage of kernel methods is that kernels can be defined for non-vectorial data structures such as strings, trees, graphs and sets. A promising topic of future research is"
C08-1082,I05-1082,0,0.0888565,"Missing"
C08-1082,J06-3003,0,0.0181772,". . . , 212 ) through cross-validation on the training set. In addition, the width parameter α was optimised in the same way for the rbf kernels. The number of optimisation folds differed according to the size of the dataset and the number of training-test splits to be evaluated: we used 10 folds for the compound task, leave-one-out cross-validation for SemEval Task 4 and 25 folds for the verb classification task. 3.2 Compound Noun Interpretation The task of interpreting the semantics of noun compounds is one which has recently received considerable attention (Lauer, 1995; Girju et al., 2005; Turney, 2006). For a given noun-noun compound, the problem is to identify the semantic relation between the compound’s constituents – that a kitchen knife is a knife used in a kitchen but a steel knife is a knife made of steel.2 The difficulty of the task is due to the fact that the knowledge required to interpret compounds is not made explicit in the contexts where they appear, and hence standard context-based methods for classifying semantic relations in text cannot be applied. Most previous work making use of lexical similarity has been based on WordNet measures (Kim and Baldwin, ´ S´eaghdha and Copes20"
C08-1082,J05-4002,0,0.210223,"ctor defines the parameters of a categorical or multinomial probability distribution, giving a useful probabilistic interpretation of the distributional model. As the vector for each target word must sum to 1, the marginal distributions of target words have little effect on the resulting similarity estimates. Many 649 Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 649–656 Manchester, August 2008 similarity measures and weighting functions have been proposed for distributional vectors; comparative studies include Lee (1999), Curran (2003) and Weeds and Weir (2005). finite n-element sets X ⊆ X Pand for all vectors n v = (v1 , . . . , vn ) ∈ R with i vi = 0 2.2 Whereas positive semi-definite kernels correspond to inner products in a Hilbert space F, negative semi-definite kernels correspond to squared dis˜ y) = 0 only when tances. In particular, if k(x, p x = y then k˜ is a metric. If a function k is psd, then −k is always nsd, but the converse does not hold.1 However, Berg et al. (1984) describe two simple methods for inducing a positive semi˜ definite function k from negative semi-definite k: Kernel Methods for Computing Similarity and Distance In this"
C08-1082,W05-1202,0,0.021848,"ubtree counts. We adopt the perspective that this mapping represents structures xi ∈ X as measures over substructures x ¯1 , . . . , x ¯d . Properly normalised, this gives a distributional probability vector (P (¯ x1 ), . . . , P (¯ xd )) similar to those used for computing lexical similarity. This perspective motivates the use of distributional inner products instead of the dot products implicitly used in standard convolution kernels. Several authors have suggested applying distributional similarity measures to sentences and phrases for tasks such as question answering (Lin and Pantel, 2001; Weeds et al., 2005). Distributional kernels on strings and trees should provide a flexible implementation of these suggestions that is compatible with SVM classification and does not require manual feature engineering. Furthermore, there is a ready generalisation to kernels on sets of structures; if a set is represented as the normalised sum of its member embeddings in feature space F, distributional methods can be applied directly. 6 Conclusion In this paper we have introduced distributional kernels for classification with co-occurrence probability distributions. The suitability of distributional kernels for se"
C90-2008,P85-1008,0,0.257452,"sarily a long event which, whilst plausible, is not entailed under this interpretation of long. In order to avoid this effect using unification-based techniques it is necessary to explicitly copy the structure that specifies the telic role. We suggested in section 1 that NPs, such as the fact, can denote propositions 'directly'. Similarly, we think that there is no metonymy involved in examples such as John enjoyed the experience /film-making and so forth. In these cases, we claim that the NPs in question denote events 'directly'. Thus, we are lead to an 'ontologically promiscuous' semantics (Hobbs, 1985). However, recent developments in model-theoretic semantics which treat properties as basic entities (e.g. Chierchia & Turner, 1988) support this position. Indeed the interpretation of eventdenoting NPs in complement position with enjoy strongly suggests that these NPs must be analysed as denoting propositional functions since their 'missing argument' must be associated with the subject of enjoy. For instance, John likes marriage can mean that John likes the institution but John enjoys marriage can only mean that he enjoys being in the state of marriage (to someone). Figure 2b In (la) we show"
C90-2008,J87-3004,0,0.028895,"Missing"
C90-2008,E89-1024,0,0.0425772,"Missing"
C90-2008,P89-1005,0,0.0285092,"position. Indeed the interpretation of eventdenoting NPs in complement position with enjoy strongly suggests that these NPs must be analysed as denoting propositional functions since their 'missing argument' must be associated with the subject of enjoy. For instance, John likes marriage can mean that John likes the institution but John enjoys marriage can only mean that he enjoys being in the state of marriage (to someone). Figure 2b In (la) we show the formula which can be read off the DAG in Figure 2b given straightforward assumptions about the semantic interpretation of the formalism (e.g. Moore, 1989). The lexical entry for enjoy specifies that its complement must denote an event which can be syntactically an NP or progressive VP and that, if the NP is type-shifted, the relic role supplies the understood predicate. The resulting formulae associated with the VP and S are shown in (lb,c). (1) a) ~ x e' ~ y ?read(e' x y) & book(y) b) ~ x 3 e e' y past(e) & enjoy(e x e') & ?read(e' x y) & book(y) c) 3 e e' y past(e) & enjoy(e j e') & ?read(e' j y) & book(y) We follow Hobbs (1985), Alshawi et al. (1989), Moens et at. (1989) and others in using an event-based calculus for reasons of computationa"
C90-2008,P89-1012,0,0.0197511,"ating an approach whereby lexical entries inherit some of their structure from higher nodes in the taxonomy. Qualia structure could thus be inherited from word senses rather than abstract templates; for example Burgundy would inherit its telic role from the noun drink. If abstract templates were still needed they could be inserted into the inheritance hierarchy at the appropriate points. The approaches above only specify how the qualia structure is inherited, rather than how it is initially det~'mined. In recent work, the IBM lexical systems group have used their lexical database system (e.g. Neff & Boguraev, 1989) with a number of MRDs to generate lists of pre~licates which are applied to books by searching through definition fields for the occurrence of book in a position denoting 'typical object' of the headword. For instance, LDOCE defines sag with '(of a book, performance, etc.) to become uninteresting during part of the length'. Using these techniques with three dictionaries resulted in the following list of verbs: abridge, abstract, annotate, appreciate, autograph, ban, bang about, borrow, bring out, burlesque, bowdlerize, call in, castigate, castrate, catalogue, censor, chuck away, churn out, cl"
C90-2008,C88-2110,0,0.0322556,"Missing"
copestake-etal-2002-multiword,W98-0707,0,\N,Missing
copestake-etal-2002-multiword,P97-1018,1,\N,Missing
copestake-etal-2004-lexicon,copestake-flickinger-2000-open,1,\N,Missing
copestake-etal-2004-lexicon,villavicencio-etal-2004-multilingual,1,\N,Missing
copestake-etal-2004-lexicon,copestake-etal-2002-multiword,1,\N,Missing
copestake-etal-2004-lexicon,W02-1210,0,\N,Missing
copestake-flickinger-2000-open,1996.amta-1.6,0,\N,Missing
copestake-flickinger-2000-open,A00-2022,0,\N,Missing
copestake-flickinger-2000-open,J99-1002,1,\N,Missing
copestake-flickinger-2000-open,C94-1042,0,\N,Missing
copestake-flickinger-2000-open,A92-1012,1,\N,Missing
copestake-flickinger-2000-open,C96-2120,0,\N,Missing
copestake-flickinger-2000-open,P99-1061,0,\N,Missing
copestake-flickinger-2000-open,P97-1028,0,\N,Missing
copestake-flickinger-2000-open,P99-1052,0,\N,Missing
copestake-flickinger-2000-open,2000.iwpt-1.19,0,\N,Missing
D19-1090,P17-1042,0,0.480953,"imental paradigm in which we independently control for four different variables: the word form’s frequency, morphology, the lexeme frequency and the lexeme (a total of 480 experiments). Our comprehensive analysis reveals that BLI models can generalize for frequent morphosyntactic categories, even of infrequent lexemes, but fail to generalize for the more rare categories. This yields a more nuanced picture of the known deficiency of word embeddings to underperform on infrequent words (Gong et al., 2018). Our findings also contradict the strong empirical claims made elsewhere in the literature (Artetxe et al., 2017; Conneau et al., 2018; Ruder et al., 2018; Grave et al., 2018b), as we observe that performance severely degrades when the evaluation includes rare morphological variants of a word and infrequent lexemes. We picture this general trend in Figure 1, which also highlights the skew of existing dictionaries towards more frequent words.2 As our final contribution, we demonstrate that better encoding of morphology is indeed beneficial: enforcing a simple morphological constraint yields consistent performance improvements for all Romance language pairs and many of the Slavic language pairs. 2 2.1 Mor"
D19-1090,P18-1073,0,0.206257,"ˇre moˇre moˇre N ; NOM ; PL N ; DAT; SG N ; NOM ; SG N ; INS ; PL N ; GEN ; PL N ; ESS ; SG N ; DAT; PL Table 1: An example extract from our morphologically complete Polish–Czech dictionary. tions of new and less common forms, not present in the existing resources. In spite of this, most ground truth lexica used for BLI evaluation contain mainly frequent word forms. Many available resources are restricted to the top 200k most frequent words; this applies to the English–Italian dictionary of Dinu et al. (2015), the English–German and English– Finnish dictionaries of Artetxe et al. (2017), and Artetxe et al. (2018a)’s English–Spanish resource. The dictionaries of Irvine and Callison-Burch (2017) contain only the top most frequent 10k words for each language. Zhang et al. (2017) extracted their Spanish–English and Italian–English lexica from Open Multilingual WordNet (Bond and Paik, 2012), a resource which only yields high frequency, lemma level mappings. Another example is the recent MUSE dataset (Conneau et al., 2018), which was generated using an “internal translation tool”, and in which the majority of word pairs consist of forms ranked in the top 10k of the vocabularies of their respective language"
D19-1090,Q17-1010,1,0.332483,"al., 2018) and our morphologically complete dictionary, which contains many rare morphological variants of words. The numbers above the bars correspond to the number of translated source words (a hyphen represents an empty dictionary). 1 The dictionaries are available at https://github. com/pczarnowska/morph_dictionaries. ? Sebastian is now affiliated with DeepMind. humans do. Generalization to rare and novel words is arguably the main point of BLI as a task—most frequent translation pairs are already contained in digital dictionaries. Modern word embeddings encode character-level knowledge (Bojanowski et al., 2017), which should—in principle—enable the models to learn this behaviour; but morphological generalization has never been directly tested. Most existing dictionaries used for BLI evaluation do not account for the full spectrum of linguistic properties of language. Specifically, as we demonstrate in §2, they omit most morphological inflections of even common lexemes. To enable a more thorough evaluation we introduce a new resource: 40 morphologically complete dictionar974 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conferen"
D19-1090,P13-1133,0,0.0277452,"ocus on pairs of genetically-related languages for which we can cleanly map one morphological inflection onto another.3 We selected 5 languages from the Slavic family: Polish, Czech, Russian, Slovak and Ukrainian, and 5 Romance languages: French, Spanish, Italian, Portuguese and Catalan. Table 1 presents an example extract from our resource; every source–target pair is followed by their corresponding lemmata and a shared tag. We generated our dictionaries automatically based on openly available resources: Open Multilingual WordNet (Bond and Paik, 2012) and Extended Open Multilingual WordNet4 (Bond and Foster, 2013), both of which are collections of lexical databases which group words into sets of synonyms (synsets), and UniMorph5 (Kirov et al., 2016)—a resource comprised of inflectional word paradigms for 107 languages, extracted from Wiktionary6 and annotated according to the UniMorph schema (Sylak-Glassman, 2016). For each language pair (L1, L2) we first generated lemma translation pairs by mapping all L1 lemmata to all L2 lemmata for each synset that appeared in both L1 3 One may translate talked, the past tense of talk, into many different Spanish forms, but the Portuguese falavam has, arguably, onl"
D19-1090,L18-1550,1,0.925323,"erent variables: the word form’s frequency, morphology, the lexeme frequency and the lexeme (a total of 480 experiments). Our comprehensive analysis reveals that BLI models can generalize for frequent morphosyntactic categories, even of infrequent lexemes, but fail to generalize for the more rare categories. This yields a more nuanced picture of the known deficiency of word embeddings to underperform on infrequent words (Gong et al., 2018). Our findings also contradict the strong empirical claims made elsewhere in the literature (Artetxe et al., 2017; Conneau et al., 2018; Ruder et al., 2018; Grave et al., 2018b), as we observe that performance severely degrades when the evaluation includes rare morphological variants of a word and infrequent lexemes. We picture this general trend in Figure 1, which also highlights the skew of existing dictionaries towards more frequent words.2 As our final contribution, we demonstrate that better encoding of morphology is indeed beneficial: enforcing a simple morphological constraint yields consistent performance improvements for all Romance language pairs and many of the Slavic language pairs. 2 2.1 Morphological Dictionaries Existing Dictionaries Frequent word fo"
D19-1090,J17-2001,0,0.0525854,"GEN ; PL N ; ESS ; SG N ; DAT; PL Table 1: An example extract from our morphologically complete Polish–Czech dictionary. tions of new and less common forms, not present in the existing resources. In spite of this, most ground truth lexica used for BLI evaluation contain mainly frequent word forms. Many available resources are restricted to the top 200k most frequent words; this applies to the English–Italian dictionary of Dinu et al. (2015), the English–German and English– Finnish dictionaries of Artetxe et al. (2017), and Artetxe et al. (2018a)’s English–Spanish resource. The dictionaries of Irvine and Callison-Burch (2017) contain only the top most frequent 10k words for each language. Zhang et al. (2017) extracted their Spanish–English and Italian–English lexica from Open Multilingual WordNet (Bond and Paik, 2012), a resource which only yields high frequency, lemma level mappings. Another example is the recent MUSE dataset (Conneau et al., 2018), which was generated using an “internal translation tool”, and in which the majority of word pairs consist of forms ranked in the top 10k of the vocabularies of their respective languages. Another problem associated with existing resources is ‘semantic leakage’ between"
D19-1090,L16-1498,0,0.045505,"Missing"
D19-1090,D18-1042,1,0.74662,"but they will only have seen the less frequent, first-person plural future form hablar´amos a few times. Nevertheless, they would have no problem translating the latter. In this paper we ask whether current methods for bilingual lexicon induction (BLI) generalize morphologically as k Re ma 00 50 0 - ini ng OO Vs - –6 k - 00 00 –5 k - 40 0 k 30 0 k - 00 –3 20 0 00 –2 00 - –4 - 10 0 0k 0k –5 –1 50 10 –1 vo ca +O b OV s In Introduction - k - 0.0 Figure 1: The relation between the BLI performance and the frequency of source words in the test dictionary. The graph presents results for the model of Ruder et al. (2018) evaluated on both the MUSE dictionary (Conneau et al., 2018) and our morphologically complete dictionary, which contains many rare morphological variants of words. The numbers above the bars correspond to the number of translated source words (a hyphen represents an empty dictionary). 1 The dictionaries are available at https://github. com/pczarnowska/morph_dictionaries. ? Sebastian is now affiliated with DeepMind. humans do. Generalization to rare and novel words is arguably the main point of BLI as a task—most frequent translation pairs are already contained in digital dictionaries. Modern"
D19-1090,N13-1011,0,0.0656821,"Missing"
D19-1090,P17-1179,0,0.0476665,"olish–Czech dictionary. tions of new and less common forms, not present in the existing resources. In spite of this, most ground truth lexica used for BLI evaluation contain mainly frequent word forms. Many available resources are restricted to the top 200k most frequent words; this applies to the English–Italian dictionary of Dinu et al. (2015), the English–German and English– Finnish dictionaries of Artetxe et al. (2017), and Artetxe et al. (2018a)’s English–Spanish resource. The dictionaries of Irvine and Callison-Burch (2017) contain only the top most frequent 10k words for each language. Zhang et al. (2017) extracted their Spanish–English and Italian–English lexica from Open Multilingual WordNet (Bond and Paik, 2012), a resource which only yields high frequency, lemma level mappings. Another example is the recent MUSE dataset (Conneau et al., 2018), which was generated using an “internal translation tool”, and in which the majority of word pairs consist of forms ranked in the top 10k of the vocabularies of their respective languages. Another problem associated with existing resources is ‘semantic leakage’ between train and evaluation sets. As we demonstrate in §2.3, it is common for a single lex"
dayrell-etal-2012-rhetorical,W06-3309,0,\N,Missing
dayrell-etal-2012-rhetorical,P06-4011,0,\N,Missing
dayrell-etal-2012-rhetorical,J96-2004,0,\N,Missing
dayrell-etal-2012-rhetorical,I08-1050,0,\N,Missing
dayrell-etal-2012-rhetorical,W08-0908,0,\N,Missing
E09-1001,P98-1013,0,0.0629081,"ould have to be lexeme-specific: e.g., LEAVER 1 (‘departer’) versus LEAVER 2 (‘bequeather’). However this does nothing for semantic generalisation, blocks the use of argument labels in syntactic generalisations and leads to an extreme proliferation of lexical types when using typed feature structure formalisms (one type would be required per lexeme). The labels add no additional information and could trivially be added automatically to an RMRS if this were useful for human readers. Much more interesting is the use of richer lexical semantic generalisations, such as those employed in FrameNet (Baker et al., 1998). In principle, at least, we could (and should) systematically link the ERG to FrameNet, but this would be a form of semantic enrichment mediated via the SEM-I (cf Roa et al. (2008)), and not an alternative technique for argument indexation. 4 4.1 RMRS-to-DMRS In order to transform an RMRS into a DMRS, we will treat the RMRS as made up of three subgraphs: Label equality graph. Each EP in an RMRS has a label, which may be shared with any number of other EPs. This can be captured in DMRS via a graph linking EPs: if this is done exhaustively, there would be n(n − 1)/2 binary non-directional links"
E09-1001,W02-1502,0,0.0350232,"ument indexing (§3), is a relatively clear case in which the constraints imposed by grammar engineering have a significant effect on choice between plausible alternatives. I have chosen to talk about this both because of its relationship with the currently popular task of semantic role labelling and because the DELPH - IN approach is now fairly stable after a quite considerable degree of experimentation. What I am reporting is thus a perspective on work done primarily by Flickinger within the English Resource Grammar (ERG: Flickinger (2000)) and by Bender in the context of the Grammar Matrix (Bender et al., 2002), though I’ve been involved in many of the discussions. The second main topic (§4) is new work on a semantic dependency representation which can be derived from MRS, extending the previous work by Oepen (Oepen and Lønning, 2006). Here, the motivation came from an engineering perspective, but the nature of the representation, and indeed the fact that it is possible at all, reveals some interesting aspects of semantic composition in the grammars. 2 See Flickinger and Bender (2003) and Flickinger et al. (2003) for the use of MRS in DELPH - IN grammars. 2 l1:a1: some q, BV(a1,x4), RSTR(a1,h5), BOD"
E09-1001,2005.mtsummit-papers.22,0,0.0345663,"roach, as opposed to using semantically richer roles such as AGENT, GOAL and INSTRUMENT. An MRS can, in fact, be written using a conventional predicate-argument representation. A representation which uses ordered argument labels can be recovered from this in the obvious way. E.g., l:like v 1(e,x,y) is equivalent to l:a:like v 1(e), ARG 1(a,x), ARG 2(a,y). A fairly large inventory of argument labels is actually used in the DELPH - IN grammars (e.g., RSTR, BODY). To recover these from the conventional predicate-argument notation requires a look up in a semantic interface component (the SEM - I, Flickinger et al. (2005)). But open-class predicates use the ARGn convention, where n is 0,1,2,3 or 4 and the discussion here 3 In fact, most of the choices about semantics made by grammar writers concern the behaviour of constructions and thus these non-lexical predicates, but this would require another paper to discuss. 4 I am simplifying for expository convenience. In current DELPH - IN grammars, quantifiers have an ARG 0 which corresponds to the bound variable. This should not be the characteristic variable of the quantifier (it is the characteristic variable of a nominal EP), since its role in the scoped forms i"
E09-1001,P08-1111,0,0.0151853,"nevertheless abstracting over semantically-irrelevant idiosyncratic detail. Compared to much of the linguistics literature, our analyses are relatively superficial, but this is essentially because the broad-coverage computational 1 For instance, we cannot afford to underspecify number on nouns because of examples such as The hash browns is getting angry (from Pollard and Sag (1994) p.85). Proceedings of the 12th Conference of the European Chapter of the ACL, pages 1–9, c Athens, Greece, 30 March – 3 April 2009. 2009 Association for Computational Linguistics 1 2 linguistically adequate (e.g., Bender (2008)) and is compatible with generation (e.g., Carroll et al. (1999), Carroll and Oepen (2005)). Ideally, we want support for shallow as well as deep syntactic analysis (which was the reason for developing RMRS), enrichment by deeper analysis (including lexical semantics and anaphora resolution, both the subject of ongoing work), and (robust) inference. The motivation for the development of dependency-style representations (including Dependency MRS (DMRS) discussed in §4) has been to improve ease of use for consumers of the representation and human annotators, as well as use in statistical ranking"
E09-1001,I05-1015,0,0.0523413,"mpared to much of the linguistics literature, our analyses are relatively superficial, but this is essentially because the broad-coverage computational 1 For instance, we cannot afford to underspecify number on nouns because of examples such as The hash browns is getting angry (from Pollard and Sag (1994) p.85). Proceedings of the 12th Conference of the European Chapter of the ACL, pages 1–9, c Athens, Greece, 30 March – 3 April 2009. 2009 Association for Computational Linguistics 1 2 linguistically adequate (e.g., Bender (2008)) and is compatible with generation (e.g., Carroll et al. (1999), Carroll and Oepen (2005)). Ideally, we want support for shallow as well as deep syntactic analysis (which was the reason for developing RMRS), enrichment by deeper analysis (including lexical semantics and anaphora resolution, both the subject of ongoing work), and (robust) inference. The motivation for the development of dependency-style representations (including Dependency MRS (DMRS) discussed in §4) has been to improve ease of use for consumers of the representation and human annotators, as well as use in statistical ranking of analyses/realisations (Fujita et al. (2007), Oepen and Lønning (2006)). Integration wi"
E09-1001,W07-1204,0,0.0234413,"neration (e.g., Carroll et al. (1999), Carroll and Oepen (2005)). Ideally, we want support for shallow as well as deep syntactic analysis (which was the reason for developing RMRS), enrichment by deeper analysis (including lexical semantics and anaphora resolution, both the subject of ongoing work), and (robust) inference. The motivation for the development of dependency-style representations (including Dependency MRS (DMRS) discussed in §4) has been to improve ease of use for consumers of the representation and human annotators, as well as use in statistical ranking of analyses/realisations (Fujita et al. (2007), Oepen and Lønning (2006)). Integration with distributional semantic techniques is also of interest. The MRS and RMRS languages This paper concerns only representations which are output by deep grammars, which use MRS, but it will be convenient to talk in terms of RMRS and to describe the RMRSs that are constructed under those assumptions. Such RMRSs are interconvertible with MRSs.2 The description is necessarily terse and contains the minimal detail necessary to follow the remainder of the paper. An RMRS is a description of a set of trees corresponding to scoped logical forms. Fig 1 shows an"
E09-1001,P85-1008,0,0.702473,"icular, it retains information about a quantifier’s N0 , since this forms the restrictor of the generalised quantifier (for instance Most white cats are deaf has different truth conditions from Most deaf cats are white). An interesting example of nominal modification is shown in Fig 3. Notice that whose has a decomposed semantics combining two non-lexeme predicates def explicit q and poss. Unusually, the relative clause has a gap which is not an argument of its semantic head (it’s an argument of poss rather than bite v 1). This means that when the relative clause 5 Related work and conclusion Hobbs (1985) described a philosophy of computational compositional semantics that is in some respects similar to that presented here. But, as far as I am aware, the Core Language Engine book (Alshawi, 1992) provided the first detailed description of a truly computational approach to compositional semantics: in any case, Steve Pulman provided my own introduction to the idea. Currently, the ParGram project also undertakes largescale multilingual grammar engineering work: see Crouch and King (2006) and Crouch (2006) for an account of the semantic composition techniques now being used. I am not aware of any o"
E09-1001,E09-1052,0,0.0219145,"ate on discussing work which has used Minimal Recursion Semantics (MRS: Copestake et al. (2005)) or Robust Minimal Recursion Semantics (RMRS: Copestake (2003)). The ( R ) MRS approach has been adopted as a common framework for the DELPH - IN initiative (Deep Linguistic Processing with HPSG: http://www.delph-in.net) and the work discussed here has been done by and in collaboration with researchers involved in DELPH - IN. The programme of developing computational compositional semantics has a large number of aspects. It is important that the semantics has a logically-sound interpretation (e.g., Koller and Lascarides (2009), Thater (2007)), is crossThis paper discusses computational compositional semantics from the perspective of grammar engineering, in the light of experience with the use of Minimal Recursion Semantics in DELPH - IN grammars. The relationship between argument indexation and semantic role labelling is explored and a semantic dependency notation (DMRS) is introduced. 1 Introduction The aim of this paper is to discuss work on compositional semantics from the perspective of grammar engineering, which I will take here as the development of (explicitly) linguistically-motivated computational grammars"
E09-1001,P01-1019,1,0.677978,"nstraints (the only type considered here) indicate that, in the scoped forms, a label must either plug a hole directly or be connected to it via a chain of quantifiers. Hole arguments (other than the BODY of a quantifier) are always linked to a label via a qeq or other constraint (in a deep grammar RMRS). Variables survive in the models of RMRSs (i.e., the fully scoped trees) whereas holes and labels do not. The belated ‘introduction’ to MRS in Copestake et al. (2005) primarily covered formal representation of complete utterances. Copestake (2007a) described uses of ( R ) MRS in applications. Copestake et al. (2001) and Copestake (2007b) concern the algebra for composition. What I want to do here is to concentrate on less abstract issues in the syntax-semantics interface. I will discuss two cases where the grammar engineering perspective is important and where there are some conclusions about compositional semantics which are relevant beyond DELPH - IN. The first, argument indexing (§3), is a relatively clear case in which the constraints imposed by grammar engineering have a significant effect on choice between plausible alternatives. I have chosen to talk about this both because of its relationship wit"
E09-1001,oepen-lonning-2006-discriminant,0,0.57237,"l et al. (1999), Carroll and Oepen (2005)). Ideally, we want support for shallow as well as deep syntactic analysis (which was the reason for developing RMRS), enrichment by deeper analysis (including lexical semantics and anaphora resolution, both the subject of ongoing work), and (robust) inference. The motivation for the development of dependency-style representations (including Dependency MRS (DMRS) discussed in §4) has been to improve ease of use for consumers of the representation and human annotators, as well as use in statistical ranking of analyses/realisations (Fujita et al. (2007), Oepen and Lønning (2006)). Integration with distributional semantic techniques is also of interest. The MRS and RMRS languages This paper concerns only representations which are output by deep grammars, which use MRS, but it will be convenient to talk in terms of RMRS and to describe the RMRSs that are constructed under those assumptions. Such RMRSs are interconvertible with MRSs.2 The description is necessarily terse and contains the minimal detail necessary to follow the remainder of the paper. An RMRS is a description of a set of trees corresponding to scoped logical forms. Fig 1 shows an example of an RMRS and it"
E09-1001,J05-1004,0,0.0295988,"nto discussion of syntax to explain in detail here. While the majority of cases are straightforward, a few are not (e.g., because they depend on decisions about which form is taken as the base in an alternation). However, all decisions are made at the level of lexical types: adding an entry for a lexeme for a DELPH - IN grammar only requires working out its lexical type(s) (from syntactic behaviour and very constrained semantic notions, e.g., control). The actual assignment of arguments to an utterance is just a consequence of parsing. Argument labelling is thus quite different from PropBank (Palmer et al., 2005) role labelling despite the unfortunate similarity of the PropBank naming scheme. It follows from the fixed arity of predicates that lexemes with different numbers of arguments should be given different predicate symbols. There is usually a clear sense distinction when this occurs. For instance, we should distinguish between the ‘depart’ and ‘bequeath’ senses of leave because the first takes an ARG 1 and an ARG 2 (optional) and the second ARG 1, ARG 2 (optional), ARG 3. We do not draw sense distinctions where there is no usage which the grammar could disambiguate. Of course, there are obvious"
E09-1001,P08-2048,0,0.0131854,"n syntactic generalisations and leads to an extreme proliferation of lexical types when using typed feature structure formalisms (one type would be required per lexeme). The labels add no additional information and could trivially be added automatically to an RMRS if this were useful for human readers. Much more interesting is the use of richer lexical semantic generalisations, such as those employed in FrameNet (Baker et al., 1998). In principle, at least, we could (and should) systematically link the ERG to FrameNet, but this would be a form of semantic enrichment mediated via the SEM-I (cf Roa et al. (2008)), and not an alternative technique for argument indexation. 4 4.1 RMRS-to-DMRS In order to transform an RMRS into a DMRS, we will treat the RMRS as made up of three subgraphs: Label equality graph. Each EP in an RMRS has a label, which may be shared with any number of other EPs. This can be captured in DMRS via a graph linking EPs: if this is done exhaustively, there would be n(n − 1)/2 binary non-directional links. E.g., for the RMRS in Fig 1, we need to link big a 1, angry a 1 and dog n 1 and this takes 3 links. Obviously the effect of equality could be captured by a smaller number of links"
E09-1001,W07-1210,1,0.893383,"ia relationships between holes and labels. In particular qeq constraints (the only type considered here) indicate that, in the scoped forms, a label must either plug a hole directly or be connected to it via a chain of quantifiers. Hole arguments (other than the BODY of a quantifier) are always linked to a label via a qeq or other constraint (in a deep grammar RMRS). Variables survive in the models of RMRSs (i.e., the fully scoped trees) whereas holes and labels do not. The belated ‘introduction’ to MRS in Copestake et al. (2005) primarily covered formal representation of complete utterances. Copestake (2007a) described uses of ( R ) MRS in applications. Copestake et al. (2001) and Copestake (2007b) concern the algebra for composition. What I want to do here is to concentrate on less abstract issues in the syntax-semantics interface. I will discuss two cases where the grammar engineering perspective is important and where there are some conclusions about compositional semantics which are relevant beyond DELPH - IN. The first, argument indexing (§3), is a relatively clear case in which the constraints imposed by grammar engineering have a significant effect on choice between plausible alternatives"
E09-1071,P05-1050,0,0.0101251,"ata classes that maximises the minimum distance or margin from the training points in each class to the boundary. The geometry of the space in which this boundary is set depends on the 622 3.3 kernel function used to compare data items. By tailoring the choice of kernel to the task at hand, the user can use prior knowledge and intuition to improve classification performance. One useful property of kernels is that any sum or linear combination of kernel functions is itself a valid kernel. Theoretical analyses (Cristianini et al., 2001; Joachims et al., 2001) and empirical investigations (e.g., Gliozzo et al. (2005)) have shown that combining kernels in this way can have a beneficial effect when the component kernels capture different “views” of the data while individually attaining similar levels of discriminative performance. In the experiments described below, we make use of this insight to integrate lexical and relational information for semantic classification of compound nouns. 3.2 The necessary starting point for our implementation of relational similarity is a means of comparing contexts. Contexts can be represented in a variety of ways, from unordered bags of words to rich syntactic structures."
E09-1071,I05-1082,0,0.143941,"we have noted above that PairClass implicitly uses a feature representation similar to the one presented above as (6) by extracting subsequence patterns from observed cooccurrences of word pair members. Indeed, PairClass can be viewed as a special case of our frameRelated work Turney et al. (2003) suggest combining various information sources for solving SAT analogy problems. However, previous work on compound interpretation has generally used either lexical similarity or relational similarity but not both in combination. Previously proposed lexical models include the WordNet-based methods of Kim and Baldwin (2005) and Girju et al. (2005), and the 627 work; the differences from the model we have used consist in the use of a different embedding function φP C and a more restricted notion of context, a frequency cutoff to eliminate less common subsequences and the Gaussian kernel to compare vectors. While we cannot compare methods directly as we do not possess the large corpus of 5 × 1010 words used by Turney, we have tested the impact of each of these modifications on our model.4 None improve performance with our set kernels, but the only statistically significant effect is that of changing the embedding"
E09-1071,W07-1108,1,0.884485,"Missing"
E09-1071,C08-1082,1,0.796759,"Missing"
E09-1071,H05-1092,0,0.0383327,"Missing"
E09-1071,J06-3003,0,0.250528,"of the 12th Conference of the European Chapter of the ACL, pages 621–629, c Athens, Greece, 30 March – 3 April 2009. 2009 Association for Computational Linguistics 621 per can also be applied successfully to other relational reasoning tasks; we suggest some directions for future research in Section 7. 2 hold between the members of each pair. A relational distributional hypothesis therefore states that two word pairs are semantically similar if their members appear together in similar contexts. The distinction between lexical and relational similarity for word pair comparison is recognised by Turney (2006) (he calls the former attributional similarity), though the methods he presents focus ´ S´eaghdha and Copeson relational similarity. O take’s (2007) classification of information sources for noun compound interpretation also includes a description of lexical and relational similarity. Approaches to compound noun interpretation have tended to use either lexical or relational similarity, though rarely both (see Section 6 below). Two models of word pair similarity While there is a long tradition of NLP research on methods for calculating semantic similarity between words, calculating similarity b"
E09-1071,C08-1114,0,0.0615733,"w1 ) log2 ( c + P (c|w2 ) log2 ( String embedding functions i:s[i]=u λ is a decay parameter between 0 and 1; the smaller its value, the more the influence of a discontinuous subsequence is reduced. When l = 1 this corresponds to a “bag-of-words” embedding. Gap-weighted string kernels implicitly compute the similarity between two strings s, t as an inner product hφ(s), φ(t)i. Lodhi et al. (2002) present an efficient dynamic programming algorithm that evaluates this kernel in O(l|s||t|) time without explicitly representing the feature vectors φ(s), φ(t). An alternative embedding is that used by Turney (2008) in his PairClass system (see Section 6). For the PairClass embedding φP C , an n-word context P (c|w1 ) ) P (c|w1 ) + P (c|w2 ) P (c|w2 ) )] (3) P (c|w1 ) + P (c|w2 ) A straightforward method of extending this model to word pairs is to represent each pair (w1 , w2 ) as the concatenation of the co-occurrence probability vectors for w1 and w2 . Taking kjsd as a measure of word similarity and introducing parameters α and β to scale the contributions of w1 and w2 respectively, we retrieve the lexical model of pair similarity defined above in (1). Without prior knowledge of the relative importance"
E09-1071,P06-4020,0,0.020408,"the real time cost of the procedure. 4.3 Relational features Lexical features Our implementation of the lexical similarity ´ S´eaghdha model uses the same feature set as O and Copestake (2008). Two corpora were used to extract co-occurrence information: the written component of the BNC (Burnard, 1995) and the Google Web 1T 5-Gram Corpus (Brants and Franz, 2006). For each noun appearing as a compound constituent in the dataset, we estimate a cooccurrence distribution based on the nouns in coordinative constructions. Conjunctions are identified in the BNC by first parsing the corpus with RASP (Briscoe et al., 2006) and extracting instances of the conj grammatical relation. As the 5-Gram corpus does not contain full sentences it cannot be parsed, so regular expressions were used to extract coordinations. In each corpus, the set of co-occurring terms is restricted to the 10,000 most frequent conjuncts in that corpus so that each constituent distribution is represented with a 10,000dimensional vector. The probability vector for the compound is created by appending the two constituent vectors, each scaled by 0.5 to weight both ´ S´eaghdha and Copestake (2008) achieve their single O best result with a differ"
E09-1071,P07-1073,0,0.0253129,"Missing"
E09-1071,C08-1011,0,0.351543,"Missing"
E09-1071,W07-0612,0,0.0118992,"noun-noun relation expressed by a given compound is not explicit in its surface form: a steel knife may be a knife made from steel but a kitchen knife is most likely to be a knife used in a kitchen, not a knife made from a kitchen. The assumption made by similarity-based interpretation methods is that the likely meaning of a novel compound can be predicted by comparing it to previously seen compounds whose meanings are known. This is a natural framework for computational techniques; there is also empirical evidence for similaritybased interpretation in human compound processing (Ryder, 1994; Devereux and Costello, 2007). Many methods are available for computing semantic similarity between individual words, but certain NLP tasks require the comparison of word pairs. This paper presents a kernel-based framework for application to relational reasoning tasks of this kind. The model presented here combines information about two distinct types of word pair similarity: lexical similarity and relational similarity. We present an efficient and flexible technique for implementing relational similarity and show the effectiveness of combining lexical and relational models by demonstrating state-ofthe-art results on a co"
E09-1071,S07-1003,0,0.136136,"Missing"
J99-1002,C90-2007,0,0.0279027,"e general types to be overridden by conflicting default information on more specific types. We define what we believe is the first version of default unification to fully satisfy these criteria, and argue that it can improve the representation of a range of phenomena in syntax, semantics and the lexico-pragmatic interface. 1. Introduction The utility of defaults in linguistic representation has been w i d e l y discussed (for an overview, see Daelemans, de Smedt, and Gazdar [1992]). The most c o m m o n linguistic application for default inheritance is to encode lexical generalizations (e.g., Boguraev and Pustejovsky 1990; Briscoe, Copestake, and Boguraev 1990; Vossen and Copestake 1993; Daelemans 1987; Evans and Gazdar 1989a, 1989b, 1996; Flickinger, Pollard, and Wasow 1985; Flickinger 1987; Flickinger and N e r b o n n e 1992; Kilgarriff 1993; Krieger and N e r b o n n e 1993; Sanfilippo 1993; Shieber 1986a), but defaults have also been used for specification in syntactic theory (e.g., Gazdar 1987; Shieber 1986b), and for the analysis of gapping constructions (Kaplan 1987) and ellipsis (Grover et al. 1994). In Lascarides et al. (1996), we argued for the role of defaults both in descriptions of the lexicon an"
J99-1002,P90-1021,0,0.210417,"fault unification operating over them. We will justify these assumptions with respect to particular linguistic examples in Section 4. In this paper, we define an order-independent typed default unification operation called YADU (Yet Another Default Unification), which we believe is the first definition of default unification that fulfills all of the above criteria. 1.2 P r e v i o u s D e f i n i t i o n s of D e f a u l t O p e r a t i o n s o n Feature Structures There have been a number of previous definitions of default unification, including those given by: van den Berg and Pr6st (1991), Bouma (1990, 1992), Calder (1991), Carpenter (1993), Copestake (1992, 1993), Russell, Carroll, and Warwick-Armstrong (1991), and Russell et al. (1993). These definitions were all based on Kaplan's sketch of priority union (Kaplan 1987) and are asymmetric since one feature structure (FS) is taken to be indefeasible while the other is defeasible. This operation is not commutative or associative (Carpenter 1993). Although there are some applications for which an asymmetric operation is useful (see Section 6.5), the order dependency makes it un57 Computational Linguistics Volume 25, Number 1 desirable as a b"
J99-1002,J92-2003,0,0.750235,"xample demonstrates this: Where tl u t2 u t3 aMc=_L bMc=_L aUb=T [~1 TI/ {((I!: ~]l,tl ). c::. .],t2), ([c <>[t3] b],t2)} n[~::; / {([F:<],t3)} We just show h o w to calculate the defeasible TFS D12 =ao, DefFS(Fi~~F2): ) D12 ~.s { IF <] } / : ~/([ ~s ]~'~ E..1 ~ ~1~/~-~F <l~/ ""({[ ~ S'][~: S~] }~'~ ~F<~ / = [~ s.]'[ ~Gs b] 79 Computational Linguistics Volume 25, Number 1 G:: I Thus D12 ~ D1 N D2 in this case, even though [, G :: ~¢ We have suggested that because TDFSs contain more information than the defaults that win, the notion of conflict is more complex than in Carpenter (1992, 1993) and Bouma (1992). Their definitions of default unification correspond to the situations where we are unifying basic TDFSs. This is because these record default information but, like Carpenter's and Bouma's accounts, they don't track overridden default values from the unification history (because there hasn't been any unification his<to>ry).We can prove that the typed unification property for basic TDFSs is one where H reduces to Mwhen there is no conflict among the TFS components. The corollary I below follows from the above theorem and the following lemma: Lemma 7: DefFS for Basic TDFSs Let F be a basic TDFS"
J99-1002,1995.tmi-1.2,1,0.730013,"st | CPS list ] HD-DTR SS: ) SUBJ: list SPR : list CPS: list [- hd-phr / ] [SS VAL: [] ' HD-DTR SSVAL : [][CPS : o] i S~UBJ : list ] /SPR:list | tCPS:list J [SS VAL : ] {( HD-DTR ~ VAL: [] ,hd-phr), ] [ SS VAL SUBJ : [] , hd-phr), ( [ HD-DTR SS VAL SUBJ : [] / ( [ SS VAL SPR: [i3 ], hd-phr), [ HD-DTR SS VANLSPR : [] ([[ HD-DTR SS VAL CPS: [ ] CPS [] ~], hd-phr), SS VAL ([HD-DTRSSVALCPS:/o])} Figure 15 Encoding VALP using the Basic TDFS notation (SYNSEM is abbreviated SS, COMPS is CPS). coding used in the ERG. This is k n o w n as Minimal Recursion Semantics (MRS) and is described in detail in Copestake et al. (1995), though for the sake of simplicity w e will ignore most of the details in these examples, including all discussion of quantification. The semantics (i.e., the value for the CONTENT feature) for the lexical sign for dog is shown in (7a). This has an interpretation roughly equivalent to that of (7b). (7) a. [INDEX: i[AGRNUi:sg]_dog_rel LISZT: ( INST : [] b. Ax[dog(x)] The feature INDEX in (7a) indicates the equivalent of the lambda variable in (7b). Features on the index indicate agreement, in the usual w a y in HPSG: here the noun will agree with a verb that takes singular agreement (we only c"
J99-1002,E87-1012,0,0.0562573,"fine what we believe is the first version of default unification to fully satisfy these criteria, and argue that it can improve the representation of a range of phenomena in syntax, semantics and the lexico-pragmatic interface. 1. Introduction The utility of defaults in linguistic representation has been w i d e l y discussed (for an overview, see Daelemans, de Smedt, and Gazdar [1992]). The most c o m m o n linguistic application for default inheritance is to encode lexical generalizations (e.g., Boguraev and Pustejovsky 1990; Briscoe, Copestake, and Boguraev 1990; Vossen and Copestake 1993; Daelemans 1987; Evans and Gazdar 1989a, 1989b, 1996; Flickinger, Pollard, and Wasow 1985; Flickinger 1987; Flickinger and N e r b o n n e 1992; Kilgarriff 1993; Krieger and N e r b o n n e 1993; Sanfilippo 1993; Shieber 1986a), but defaults have also been used for specification in syntactic theory (e.g., Gazdar 1987; Shieber 1986b), and for the analysis of gapping constructions (Kaplan 1987) and ellipsis (Grover et al. 1994). In Lascarides et al. (1996), we argued for the role of defaults both in descriptions of the lexicon and g r a m m a r and to allow the linguistic c o m p o n e n t to make defeasible p"
J99-1002,J92-2004,0,0.776459,"Missing"
J99-1002,C90-3052,0,0.0214184,"r which the indefeasible c o m p o n e n t meets the applicable constraints, and the use of N in the definitions can be replaced b y a variant of unification that maintains well-formedness, hence guaranteeing that the default feature structure is also well-formed. We omit the details, since w e w a n t to keep the definition of the default operation as general as possible, and there are a n u m b e r of different constraint languages within feature structure f r a m e w o r k s (e.g., Alshawi et al. 1991; 70 Lascarides and Copestake Default Representation Carpenter 1992; D6rre and Eisle 1991; Emele and Zajac 1990; G e r d e m a n n and King 1994; Krieger and Sch/ifer 1994; de Paiva 1993; Smolka 1989). In fact, in the examples in this paper, the only use we make of types is functionally equivalent to the use of templates in u n t y p e d FS systems, so going into the details of well-formedness with respect to one particular system seems redundant. 3.4 Unification at Nonroot Nodes In grammars based on the use of (T)FSs, it is often necessary to be able to unify structures at nodes other than the root. For example, if grammar rules or schemata are described as TFSs (as we will assume in Section 4), then"
J99-1002,E89-1009,0,0.129494,"ieve is the first version of default unification to fully satisfy these criteria, and argue that it can improve the representation of a range of phenomena in syntax, semantics and the lexico-pragmatic interface. 1. Introduction The utility of defaults in linguistic representation has been w i d e l y discussed (for an overview, see Daelemans, de Smedt, and Gazdar [1992]). The most c o m m o n linguistic application for default inheritance is to encode lexical generalizations (e.g., Boguraev and Pustejovsky 1990; Briscoe, Copestake, and Boguraev 1990; Vossen and Copestake 1993; Daelemans 1987; Evans and Gazdar 1989a, 1989b, 1996; Flickinger, Pollard, and Wasow 1985; Flickinger 1987; Flickinger and N e r b o n n e 1992; Kilgarriff 1993; Krieger and N e r b o n n e 1993; Sanfilippo 1993; Shieber 1986a), but defaults have also been used for specification in syntactic theory (e.g., Gazdar 1987; Shieber 1986b), and for the analysis of gapping constructions (Kaplan 1987) and ellipsis (Grover et al. 1994). In Lascarides et al. (1996), we argued for the role of defaults both in descriptions of the lexicon and g r a m m a r and to allow the linguistic c o m p o n e n t to make defeasible proposals to discourse p"
J99-1002,J96-2002,0,0.0979706,"Missing"
J99-1002,J92-3002,0,0.0323222,"Missing"
J99-1002,C94-2154,0,0.0604848,"Missing"
J99-1002,P94-1003,0,0.0108481,"n linguistic application for default inheritance is to encode lexical generalizations (e.g., Boguraev and Pustejovsky 1990; Briscoe, Copestake, and Boguraev 1990; Vossen and Copestake 1993; Daelemans 1987; Evans and Gazdar 1989a, 1989b, 1996; Flickinger, Pollard, and Wasow 1985; Flickinger 1987; Flickinger and N e r b o n n e 1992; Kilgarriff 1993; Krieger and N e r b o n n e 1993; Sanfilippo 1993; Shieber 1986a), but defaults have also been used for specification in syntactic theory (e.g., Gazdar 1987; Shieber 1986b), and for the analysis of gapping constructions (Kaplan 1987) and ellipsis (Grover et al. 1994). In Lascarides et al. (1996), we argued for the role of defaults both in descriptions of the lexicon and g r a m m a r and to allow the linguistic c o m p o n e n t to make defeasible proposals to discourse processing/pragmatics. Most current constraint-based systems either do not support defaults or only allow them at a metalevel, as part of an extended description language. Our aim is to allow defaults as a fully integrated part of a t y p e d feature structure system. 1 In general, although there have been several approaches to formalizing default inheritance within feature structure langu"
J99-1002,E93-1026,0,0.0182538,"on of a range of phenomena in syntax, semantics and the lexico-pragmatic interface. 1. Introduction The utility of defaults in linguistic representation has been w i d e l y discussed (for an overview, see Daelemans, de Smedt, and Gazdar [1992]). The most c o m m o n linguistic application for default inheritance is to encode lexical generalizations (e.g., Boguraev and Pustejovsky 1990; Briscoe, Copestake, and Boguraev 1990; Vossen and Copestake 1993; Daelemans 1987; Evans and Gazdar 1989a, 1989b, 1996; Flickinger, Pollard, and Wasow 1985; Flickinger 1987; Flickinger and N e r b o n n e 1992; Kilgarriff 1993; Krieger and N e r b o n n e 1993; Sanfilippo 1993; Shieber 1986a), but defaults have also been used for specification in syntactic theory (e.g., Gazdar 1987; Shieber 1986b), and for the analysis of gapping constructions (Kaplan 1987) and ellipsis (Grover et al. 1994). In Lascarides et al. (1996), we argued for the role of defaults both in descriptions of the lexicon and g r a m m a r and to allow the linguistic c o m p o n e n t to make defeasible proposals to discourse processing/pragmatics. Most current constraint-based systems either do not support defaults or only allow them at a metalev"
J99-1002,P91-1028,0,0.477223,"Missing"
J99-1002,C86-1050,0,0.0298201,"atic interface. 1. Introduction The utility of defaults in linguistic representation has been w i d e l y discussed (for an overview, see Daelemans, de Smedt, and Gazdar [1992]). The most c o m m o n linguistic application for default inheritance is to encode lexical generalizations (e.g., Boguraev and Pustejovsky 1990; Briscoe, Copestake, and Boguraev 1990; Vossen and Copestake 1993; Daelemans 1987; Evans and Gazdar 1989a, 1989b, 1996; Flickinger, Pollard, and Wasow 1985; Flickinger 1987; Flickinger and N e r b o n n e 1992; Kilgarriff 1993; Krieger and N e r b o n n e 1993; Sanfilippo 1993; Shieber 1986a), but defaults have also been used for specification in syntactic theory (e.g., Gazdar 1987; Shieber 1986b), and for the analysis of gapping constructions (Kaplan 1987) and ellipsis (Grover et al. 1994). In Lascarides et al. (1996), we argued for the role of defaults both in descriptions of the lexicon and g r a m m a r and to allow the linguistic c o m p o n e n t to make defeasible proposals to discourse processing/pragmatics. Most current constraint-based systems either do not support defaults or only allow them at a metalevel, as part of an extended description language. Our aim is to al"
J99-1002,C94-1072,0,0.0264188,"he sign. Signs may be lexical or phrasal, but always correspond to constraints that may be represented using typed feature structures. In what follows, we will instead use TDFSs, and take various liberties with the feature geometry for ease of exposition. However, although much simplified, the treatment in the grammar fragments here is substantially based on that assumed in the English Resource Grammar (ERG) under development at CSLI (Flickinger, Sag, and Copestake, in preparation). The ERG itself has been developed without making use of defaults up to this point, using the DISCO/PAGE system (Uszkoreit et al. 1994), but it also runs within the LKB system (Copestake 1992). YADU has been implemented within the latter system, replacing the earlier version of default unification described in Copestake (1993). Before giving detailed examples, however, we must make some further remarks on the assumptions we are making about persistent and nonpersistent defaults in these fragments. In the example of inflectional morphology that we gave in Section 2, we mentioned that the defaults could not persist beyond the lexicon, since the values for the suffixes must be treated as hard information by the parser/generator."
J99-1002,P93-1028,0,0.724758,"rk, because unification failure is required to p r e v e n t ungrammatical structures. From this perspective, it seems reasonable to expect g r a m m a r s and lexicons to have a monotonic backbone, which encodes the main architectural properties of the feature structures. Since construction of g r a m m a r s and lexicons is error-prone, we believe that g r a m m a r writers will w a n t to p r e v e n t accidental overriding of such structural information b y ensuring that it is indefeasible. We therefore believe that it is desirable that defaults be explicitly marked, and, as s h o w n b y Young and Rounds (1993), this is a necessary condition for the order-independence of default unification (criterion 5, below). 2. Default tmification n e v e r fails unless there is conflict in nondefault information. The usual assumption about conflicting defaults is that they do not result in an inconsistent k n o w l e d g e state (e.g., Reiter 1980). So, it is clearly desirable that unification failure does not occur as a side effect of the w a y default information is defined. . Default unification behaves like monotonic unification in the cases w h e r e monotonic unification w o u l d succeed. We w a n t to u"
J99-1002,P85-1032,0,\N,Missing
J99-1002,J92-3003,0,\N,Missing
J99-4002,J96-2001,0,0.0215072,"ly have no evidence that a more complex approach is justified, given that our main aim is to rank unseen senses by plausibility. Another problem is the need to ensure that classes have comparable frequency distributions. This could matter if there were competing lexical rules, defined on different but overlapping classes, since if one class has a high percentage of low-frequency words compared to the other, the estimate of its productivity will tend to be lower. The productivity figure could be adjusted to allow for item frequency within classes. We will not discuss this further here, but see Baayen and Sproat (1996) for discussion of the related phenomenon of ambiguous derivational affixes. Schiitze (1997, 133f.) argues, in the context of a detailed critique of Pinker (1989), that accounts of lexical rules that do not include a quantitative component cannot form the basis for a satisfactory theory of the acquisition of lexical rules by language learners. The seed for the formation of a specific lexical rule must be comparison of the semantics and alternation/derivation behavior of a class of lexical items, but since there will always be noise in the form of exceptions because of the inherent semiproducti"
J99-4002,J92-2003,0,0.0640116,"Missing"
J99-4002,P94-1021,0,0.0325076,"Missing"
J99-4002,E95-1012,0,0.027227,"nt not to utilize abnormal or rare means of conveying particular messages. We can model this aspect of language use as a conditional probability that a word form will be associated to a specific lexical entry, derived using a maximum likelihood estimator: 7 Pr°b(lexical-entry I w ° r d - f ° r m ) = freq(lexical-entry with word-form) freq(word-form) This proposal is not novel and is the analogue of proposals to associate probabilities with initial trees in, for example, a lexicalized tree adjoining grammar (Resnik 1992; Schabes 1992). However, it differs from recent proposals by, for example, Brew (1995), to associate probabilities with values on paths in a TFS formalism underlying HPSG, as the probabilistic information is much less fine-grained. We associate a single probability with each complete TDFS that represents a lexical entry. In a probabilistic grammar based on this approach, the probability of a derivation must depend in part on details of the grammatical approach adopted. In a categorial framework it may be there are only mutually exclusive schemata for combining lexical entries into phrasal and clausal signs, so the probability of a given derivation can be treated as the product"
J99-4002,W96-0303,1,0.841797,"n Copestake and Briscoe [1995]; see Section 7), the relative productivity of each rule will be estimated in the manner described above, but the more specialized rule is likely to be more productive since it will apply to fewer entries than the more general rule. Similarly, in Figure 21, we assumed a Use-Substance lexical rule, but a more accurate estimation of probabilities might be obtained by considering specialized subclasses. This approach to deriving estimates of the productivity of lexical rules is applied to four denominal verb forma516 Briscoe and Copestake Lexical Rules tion rules in Briscoe and Copestake (1996), where the probabilities of the basic and derived word forms are estimated from part-of-speech tagged textual corpora. The probabilistic approach we have presented is part of a theory of language use or performance rather than one of competence or grammatical representation. As such it is not a part of the T(D)FS representation language, which is intended as a general formalism in which paradigmatic (lexical) and syntagmatic (syntactic and semantic) theories can be encoded or embedded. This probabilistic approach to lexical rules integrates neatly with extant proposals to control application"
J99-4002,J91-3003,0,0.276349,"nct Introduction, which can recursively add adverbial categories to the SUBCAT list of a verbal category. There are three main problems with the treatment of lexical, or what might be better termed unary, rules as a h o m o g e n e o u s class. * Computer Laboratory, University of Cambridge, Pembroke Street, Cambridge CB2 3QG, UK. E-maih ejb@cl.cam.ac.uk t Center for the Study of Language and Information, Stanford University, Ventura Hall, Stanford, CA 94305. E-mail: aac@csli.stanford.edu (~) 1999 Association for Computational Linguistics Computational Linguistics Volume 25, Number 4 Firstly, Carpenter (1991) demonstrates that if lexical rules are able to perform arbitrary manipulations (deletion, addition, and permutation) of potentially unbounded lists, any recursively enumerable language can be generated, even if the nonderived lexicon and grammar only generate context-free languages. However, once we are committed to treating rules such as Passive and Adjunct Introduction in a homogeneous way, restrictions that prevent lexical rules from increasing generative capacity, such as constraining the use of category variables, bounding the length of the suBCAT list, or limiting recursive application,"
J99-4002,J93-1001,0,0.0199297,"Missing"
J99-4002,1995.tmi-1.2,1,0.876318,"25, Number 4 intrans-verb PHON: [] SYN r RESULT : ssign ] : [ ACTIVE: n p s i g n • J r . • ~ r v-a~t-cause-move 1 SEM . &lt; verD-reJ . ~V~NT: e [EVENT:e] [ARG: • ] &gt; LALTS: [] [ TRANS-ALT : caus-inchoat ] • trans-caus-verb PHON: [] SYN [RESULT [ RESUcw:ssign ]] : : ACTIVE npslgn m ACTIVE npsign [~ r p&apos;agt&apos;cause ] . [ p&apos;pat&apos;m°ve ] SEM :&lt; [,verb&apos;relEvENT:e]j.|EVENT:e EVENT:e / &gt; LARG: [~ ARG: [] J •ALTS : [] Figure 4 The Causative-Inchoative lexical rule: Sanfilippo&apos;s approach. we are using an abbreviated version of the &quot;minimally-recursive&quot; style of encoding for the semantics (MRS) described by Copestake et al. (1995). The semantics for the causative form of gallop described is equivalent in linearized notation to: [gallop(e) A p-agt-cause(e, x) A p-pat-move(e, y)] However, the rule can only apply if the transitive entry for gallop specifies caus-inchoat as the value of ALTS TRANS-ALT.An immediate problem arises, because as Pinker (1989) and others have argued, the rule is semiproductive rather than purely abbreviatory, in the sense that nonce usages are clearly interpreted conventionally as being novel (mis)applications of such rules. As in for example, Kim subscribed his friend to Byte for a year or Don&apos;"
J99-4002,P97-1018,1,0.891387,"Missing"
J99-4002,E89-1009,0,0.0899967,"Missing"
J99-4002,J96-2002,0,0.0194019,"Missing"
J99-4002,P95-1014,0,0.0176077,"be subsumed by one of the basic descriptions or by a description derived via one or more lexical rule applications (i.e., any description tagged [] ). This latter step integrates the interpretation of lexical rules into the underlying constraint logic of TFS descriptions by structure sharing information between descriptions of basic and derived lexical entries. In view of the unrestricted generative power of conventional HPSG-style lexical rules (Carpenter 1991), naive generative application of recursive or cyclic rules can lead to nontermination during parsing. Bouma and van Noord (1994) and Johnson and Dorre (1995) propose techniques for delayed evaluation of lexical rules so that they apply &quot;on demand&quot; at parse time. Meurers and Minnen (1997) present a computational framework for efficient application of Meurers&apos; (1995) formalization of lexical rules. In their covariation approach, a finite-state machine for the application of lexical rules is derived by computing possible &quot;follow&quot; relations between the set of rules. Next, pruned finite-state machines are associated with classes of actual lexical entries representing the restricted set of rules that can apply to those entries. Finally, entries themselv"
J99-4002,P91-1008,0,0.0108986,"Missing"
J99-4002,J99-1002,1,0.88576,"he full range of rules proposed shows that Carpenter&apos;s (1991) postulated upper bound on the length of list-valued attributes such as SUBCATin the lexicon cannot be maintained, leading to unrestricted generative capacity in constraint-based formalisms utilizing HPSG-style lexical rules. We argue that it is preferable to subdivide such rules into a class of semiproductive lexically governed genuinely lexical rules, and a class offully productive unary syntactic rules. We develop a restricted approach to lexical rules in a typed default feature structure (TDFS) framework (Lascarides et al. 1995; Lascarides and Copestake 1999), which has enough expressivity to state, for example, rules of verb diathesis alternation, but which does not allow arbitrary manipulation of list-valued features. An interpretation of such lexical rules within a probabilistic version of a TDFS-based linguistic (lexical and grammatical) theory allows us to capture the semiproductive nature of genuinely lexical rules, steering an intermediate course between fully generative or purely abbreviatory rules. We illustrate the utility of this approach with a treatment of dative constructions within a linguistic framework that borrows insights from t"
J99-4002,J92-2002,0,0.0276146,"features that are omitted have their values copied over, giving the notation shown in Figure 2. A number of modifications of this original proposal within the HPSG framework have been proposed. Copestake and Briscoe (1992) and Copestake (1992) represent lexical rules as TFSs containing 1 and 0 attributes representing input and output descriptions of the lexical rule, respectively. This enables lexical rules to be encoded in a type hierarchy and for relationships between rules to be expressed via type inheritance. The interpretation of lexical rules is analogous to that of grammar rules (e.g., Shieber 1992), and such rules can be thought of as equivalent to unary grammar rules. 489 Computational Linguistics Volume 25, Number 4 3rdsng-lr IN: [base] [ 3rdsn~: ] OUT : |PHOI~ :f3rdsng( [], []) [ 3RDSNG: [] Figure 3 Reformulated Third Singular Verb Formation lexical rule. Calcagno (1995) develops an algorithm for improving the notation for lexical rules by eliminating the need to specify what is copied from input to output. Meurers (1995) also develops a similar algorithm but, although he augments the description language to allow lexical rules to be written in this abbreviated notation, he interpret"
J99-4002,W91-0209,1,\N,Missing
J99-4002,J97-4003,0,\N,Missing
J99-4002,J92-2004,0,\N,Missing
J99-4002,J94-3010,0,\N,Missing
J99-4002,C92-2066,0,\N,Missing
J99-4002,J92-3003,0,\N,Missing
J99-4002,P93-1028,0,\N,Missing
L16-1197,W08-2227,0,0.0173107,"Missing"
L16-1197,W13-2322,0,0.0564346,"DMRS has a proper representation of scope and is fully inter-convertible with other forms of *MRS. It thus makes use of the full power of the ERG for semantic description. DMRS has been used in a number of applications (e.g., Reiplinger et al. (2012), Sch¨afer et al. (2011), Herbelot (2013), Horvat et al. (2015), Emerson and Copestake (2015)) and our aim is to increase its use. There have, of course, been earlier graph-based semantic representation languages, including some which support genuine logical forms (e.g., Allen et al. (2008)). The popularity of Abstract Meaning Representation (AMR; Banarescu et al. (2013)) has led to increased interest in graphbased formalisms. Bender et al. (2015) discusses why compositionality (as assumed in *MRS but not in AMR) is an 1240 • MRS well-formedness: A DMRS meets this condition if it can be converted into a well-formed MRS as defined by Copestake et al. (2005). Informally, a well-formed MRS is one that can be specialized into one or more scope-resolved structures. For a grammar where all semantic composition operations and lexical entries are correctly specified, all MRS structures produced by/accepted by the grammar for an utterance will meet this well-formednes"
L16-1197,W15-0128,1,0.857773,"er forms of *MRS. It thus makes use of the full power of the ERG for semantic description. DMRS has been used in a number of applications (e.g., Reiplinger et al. (2012), Sch¨afer et al. (2011), Herbelot (2013), Horvat et al. (2015), Emerson and Copestake (2015)) and our aim is to increase its use. There have, of course, been earlier graph-based semantic representation languages, including some which support genuine logical forms (e.g., Allen et al. (2008)). The popularity of Abstract Meaning Representation (AMR; Banarescu et al. (2013)) has led to increased interest in graphbased formalisms. Bender et al. (2015) discusses why compositionality (as assumed in *MRS but not in AMR) is an 1240 • MRS well-formedness: A DMRS meets this condition if it can be converted into a well-formed MRS as defined by Copestake et al. (2005). Informally, a well-formed MRS is one that can be specialized into one or more scope-resolved structures. For a grammar where all semantic composition operations and lexical entries are correctly specified, all MRS structures produced by/accepted by the grammar for an utterance will meet this well-formedness condition,1 and hence the set of DMRSs which are well-formed under this cond"
L16-1197,P13-2131,0,0.0147456,"nnected to open class words which are unlikely to be repeated. If all of the neighbouring nodes already match uniquely and there is only one node in the other graph containing the corresponding neighbourhood, we can conclude a match of the node in question. Subsequently, we continue to perform an exhaustive search over all the possible combinations if there are still unmatched nodes left. The other two matching approaches find the best possible match, even a non-exact one, and assess its quality with an F-score, computed based on the number of matched nodes and links, similarly to a metric by Cai and Knight (2013). Nodes and links are treated as equally important. The surface-aligned matching uses the fact that parser output contains information on which part of the original string corresponds to a given predicate. By ordering the DMRS nodes by the position of their predicates in a sentence, we can limit the search space of the matching algorithm. There are two ways to use this form of matching. The matched subgraph returned as the result of the query can include only nodes from the query, or it can include all the nodes corresponding to the aligned region of the surface. For example, if we query for b"
L16-1197,W07-1210,1,0.808818,"providing standard operations on DMRS and giving illustrative examples of their potential use in applications. 2. • Basic well-formedness: simply requires that the DMRS is a graph with well-formed labels on nodes and edges. If the bare EQ links described above are excluded, the graph must be acyclic, but not necessarily connected. An Outline of DMRS Rather than give a formal introduction to DMRS, we will outline its properties by means of the example shown in Fig 1. This shows a scoped structure in predicate calculus using generalized quantifiers, the corresponding MRS, the Robust MRS (RMRS; Copestake (2007b)), and finally the DMRS. Both MRS and RMRS can be regarded as a flat list of elementary predications, unlike a conventional logical representation which uses nesting to convey scope. The labels (l1, l2 etc) shown in the MRS and RMRS structures together with the qeq constraints represent (underspecified) scope restrictions (e.g., the restrictor of every). The ERG actually uses argument labels internally (RSTR, ARG 1 etc), but to make the comparison with the scoped representation clearer, the MRS in Figure 1 is shown in a format which omits them. RMRS always makes the argument labels explicit:"
L16-1197,E09-1001,1,0.782845,"r et al. (2005)). Flickinger et al. (2014) described an approach to documenting the fundamentals of ERS, allowing users to look up the detailed analysis of particular grammatical constructions. The Elementary Dependency representation (Oepen and Lønning, 2006) is simpler than *MRS and captures many aspects of ERS while being relatively similar to familiar syntactic dependency formalisms. It can be used for comparative parser evaluation as well as other applications (Ivanova et al. (2012), Dridan and Oepen (2011)). In this paper, we concentrate on resources for processing Dependency MRS (DMRS; Copestake (2009)). This is a version of MRS which can be represented as a dependency graph, with no need for variables. Unlike Elementary Dependencies, DMRS has a proper representation of scope and is fully inter-convertible with other forms of *MRS. It thus makes use of the full power of the ERG for semantic description. DMRS has been used in a number of applications (e.g., Reiplinger et al. (2012), Sch¨afer et al. (2011), Herbelot (2013), Horvat et al. (2015), Emerson and Copestake (2015)) and our aim is to increase its use. There have, of course, been earlier graph-based semantic representation languages,"
L16-1197,W11-2927,0,0.0572904,"towards addressing this. There is a standardized semantic interface to the grammars (the SEM-I: Flickinger et al. (2005)). Flickinger et al. (2014) described an approach to documenting the fundamentals of ERS, allowing users to look up the detailed analysis of particular grammatical constructions. The Elementary Dependency representation (Oepen and Lønning, 2006) is simpler than *MRS and captures many aspects of ERS while being relatively similar to familiar syntactic dependency formalisms. It can be used for comparative parser evaluation as well as other applications (Ivanova et al. (2012), Dridan and Oepen (2011)). In this paper, we concentrate on resources for processing Dependency MRS (DMRS; Copestake (2009)). This is a version of MRS which can be represented as a dependency graph, with no need for variables. Unlike Elementary Dependencies, DMRS has a proper representation of scope and is fully inter-convertible with other forms of *MRS. It thus makes use of the full power of the ERG for semantic description. DMRS has been used in a number of applications (e.g., Reiplinger et al. (2012), Sch¨afer et al. (2011), Herbelot (2013), Horvat et al. (2015), Emerson and Copestake (2015)) and our aim is to in"
L16-1197,W13-5715,0,0.0132675,"(e.g., Packard et al. (2014)) and natural language interfaces (e.g., Packard (2014)). In several cases (including Packard et al. (2014), Lien and Kouylekov (2014), Packard (2014), Yao and Zhang (2010), MacKinlay et al. (2009)) an ERS-based system has outperformed other approaches in a competitive task. While an ERG-based system is not suitable for applications which require rapid analysis of very large quantities of text, parsing accuracy is competitive with other approaches and is generally good on new domains without any need for substantial training or adaptation (MacKinlay et al. (2010), Dridan and Oepen (2013)). ERS is especially suitable in applications which require high precision in semantic tasks and where some lack of recall due to parse failure rates is tolerable. Furthermore, the ERG is bidirectional and ERSs can also be used for realization. However, the adoption of ERS (and *MRS with other grammars) has been limited outside the DELPH-IN community, despite the fact that the resources are all Open Source. Anecdotally, a major problem is the complexity of the analyses. The DELPH-IN community have taken various steps towards addressing this. There is a standardized semantic interface to the gr"
L16-1197,W15-0101,1,0.906726,"ns (Ivanova et al. (2012), Dridan and Oepen (2011)). In this paper, we concentrate on resources for processing Dependency MRS (DMRS; Copestake (2009)). This is a version of MRS which can be represented as a dependency graph, with no need for variables. Unlike Elementary Dependencies, DMRS has a proper representation of scope and is fully inter-convertible with other forms of *MRS. It thus makes use of the full power of the ERG for semantic description. DMRS has been used in a number of applications (e.g., Reiplinger et al. (2012), Sch¨afer et al. (2011), Herbelot (2013), Horvat et al. (2015), Emerson and Copestake (2015)) and our aim is to increase its use. There have, of course, been earlier graph-based semantic representation languages, including some which support genuine logical forms (e.g., Allen et al. (2008)). The popularity of Abstract Meaning Representation (AMR; Banarescu et al. (2013)) has led to increased interest in graphbased formalisms. Bender et al. (2015) discusses why compositionality (as assumed in *MRS but not in AMR) is an 1240 • MRS well-formedness: A DMRS meets this condition if it can be converted into a well-formed MRS as defined by Copestake et al. (2005). Informally, a well-formed M"
L16-1197,2005.mtsummit-papers.22,0,0.0406099,"y suitable in applications which require high precision in semantic tasks and where some lack of recall due to parse failure rates is tolerable. Furthermore, the ERG is bidirectional and ERSs can also be used for realization. However, the adoption of ERS (and *MRS with other grammars) has been limited outside the DELPH-IN community, despite the fact that the resources are all Open Source. Anecdotally, a major problem is the complexity of the analyses. The DELPH-IN community have taken various steps towards addressing this. There is a standardized semantic interface to the grammars (the SEM-I: Flickinger et al. (2005)). Flickinger et al. (2014) described an approach to documenting the fundamentals of ERS, allowing users to look up the detailed analysis of particular grammatical constructions. The Elementary Dependency representation (Oepen and Lønning, 2006) is simpler than *MRS and captures many aspects of ERS while being relatively similar to familiar syntactic dependency formalisms. It can be used for comparative parser evaluation as well as other applications (Ivanova et al. (2012), Dridan and Oepen (2011)). In this paper, we concentrate on resources for processing Dependency MRS (DMRS; Copestake (2009"
L16-1197,flickinger-etal-2010-wikiwoods,0,0.572734,"Missing"
L16-1197,flickinger-etal-2014-towards,0,0.178565,"which require high precision in semantic tasks and where some lack of recall due to parse failure rates is tolerable. Furthermore, the ERG is bidirectional and ERSs can also be used for realization. However, the adoption of ERS (and *MRS with other grammars) has been limited outside the DELPH-IN community, despite the fact that the resources are all Open Source. Anecdotally, a major problem is the complexity of the analyses. The DELPH-IN community have taken various steps towards addressing this. There is a standardized semantic interface to the grammars (the SEM-I: Flickinger et al. (2005)). Flickinger et al. (2014) described an approach to documenting the fundamentals of ERS, allowing users to look up the detailed analysis of particular grammatical constructions. The Elementary Dependency representation (Oepen and Lønning, 2006) is simpler than *MRS and captures many aspects of ERS while being relatively similar to familiar syntactic dependency formalisms. It can be used for comparative parser evaluation as well as other applications (Ivanova et al. (2012), Dridan and Oepen (2011)). In this paper, we concentrate on resources for processing Dependency MRS (DMRS; Copestake (2009)). This is a version of MR"
L16-1197,W13-0204,0,0.189046,"evaluation as well as other applications (Ivanova et al. (2012), Dridan and Oepen (2011)). In this paper, we concentrate on resources for processing Dependency MRS (DMRS; Copestake (2009)). This is a version of MRS which can be represented as a dependency graph, with no need for variables. Unlike Elementary Dependencies, DMRS has a proper representation of scope and is fully inter-convertible with other forms of *MRS. It thus makes use of the full power of the ERG for semantic description. DMRS has been used in a number of applications (e.g., Reiplinger et al. (2012), Sch¨afer et al. (2011), Herbelot (2013), Horvat et al. (2015), Emerson and Copestake (2015)) and our aim is to increase its use. There have, of course, been earlier graph-based semantic representation languages, including some which support genuine logical forms (e.g., Allen et al. (2008)). The popularity of Abstract Meaning Representation (AMR; Banarescu et al. (2013)) has led to increased interest in graphbased formalisms. Bender et al. (2015) discusses why compositionality (as assumed in *MRS but not in AMR) is an 1240 • MRS well-formedness: A DMRS meets this condition if it can be converted into a well-formed MRS as defined by"
L16-1197,W15-0116,1,0.931069,"ll as other applications (Ivanova et al. (2012), Dridan and Oepen (2011)). In this paper, we concentrate on resources for processing Dependency MRS (DMRS; Copestake (2009)). This is a version of MRS which can be represented as a dependency graph, with no need for variables. Unlike Elementary Dependencies, DMRS has a proper representation of scope and is fully inter-convertible with other forms of *MRS. It thus makes use of the full power of the ERG for semantic description. DMRS has been used in a number of applications (e.g., Reiplinger et al. (2012), Sch¨afer et al. (2011), Herbelot (2013), Horvat et al. (2015), Emerson and Copestake (2015)) and our aim is to increase its use. There have, of course, been earlier graph-based semantic representation languages, including some which support genuine logical forms (e.g., Allen et al. (2008)). The popularity of Abstract Meaning Representation (AMR; Banarescu et al. (2013)) has led to increased interest in graphbased formalisms. Bender et al. (2015) discusses why compositionality (as assumed in *MRS but not in AMR) is an 1240 • MRS well-formedness: A DMRS meets this condition if it can be converted into a well-formed MRS as defined by Copestake et al. (2005"
L16-1197,W12-3602,0,0.013371,"ave taken various steps towards addressing this. There is a standardized semantic interface to the grammars (the SEM-I: Flickinger et al. (2005)). Flickinger et al. (2014) described an approach to documenting the fundamentals of ERS, allowing users to look up the detailed analysis of particular grammatical constructions. The Elementary Dependency representation (Oepen and Lønning, 2006) is simpler than *MRS and captures many aspects of ERS while being relatively similar to familiar syntactic dependency formalisms. It can be used for comparative parser evaluation as well as other applications (Ivanova et al. (2012), Dridan and Oepen (2011)). In this paper, we concentrate on resources for processing Dependency MRS (DMRS; Copestake (2009)). This is a version of MRS which can be represented as a dependency graph, with no need for variables. Unlike Elementary Dependencies, DMRS has a proper representation of scope and is fully inter-convertible with other forms of *MRS. It thus makes use of the full power of the ERG for semantic description. DMRS has been used in a number of applications (e.g., Reiplinger et al. (2012), Sch¨afer et al. (2011), Herbelot (2013), Horvat et al. (2015), Emerson and Copestake (20"
L16-1197,E14-3009,0,0.0278191,"mmar is the English Resource Grammar (ERG; Flickinger (2000)). *MRS from the ERG (henceforth English Resource Semantics: ERS) and other DELPH-IN grammars has been successfully used in a number of applications. These include machine translation (e.g., Bond et al. (2011)), information extraction and question answering (e.g., Copestake et al. (2006), Frank et al. (2005), MacKinlay et al. (2009), MacKinlay et al. (2012)), extraction of ontological relationships (e.g., Herbelot and Copestake (2006)), question generation (e.g., Yao and Zhang (2010), Yao et al. (2012)), entailment recognition (e.g., Lien and Kouylekov (2014)), detection of scope of negation (e.g., Packard et al. (2014)) and natural language interfaces (e.g., Packard (2014)). In several cases (including Packard et al. (2014), Lien and Kouylekov (2014), Packard (2014), Yao and Zhang (2010), MacKinlay et al. (2009)) an ERS-based system has outperformed other approaches in a competitive task. While an ERG-based system is not suitable for applications which require rapid analysis of very large quantities of text, parsing accuracy is competitive with other approaches and is generally good on new domains without any need for substantial training or adap"
L16-1197,W09-1410,0,0.0627464,"Missing"
L16-1197,oepen-lonning-2006-discriminant,0,0.141887,"on of ERS (and *MRS with other grammars) has been limited outside the DELPH-IN community, despite the fact that the resources are all Open Source. Anecdotally, a major problem is the complexity of the analyses. The DELPH-IN community have taken various steps towards addressing this. There is a standardized semantic interface to the grammars (the SEM-I: Flickinger et al. (2005)). Flickinger et al. (2014) described an approach to documenting the fundamentals of ERS, allowing users to look up the detailed analysis of particular grammatical constructions. The Elementary Dependency representation (Oepen and Lønning, 2006) is simpler than *MRS and captures many aspects of ERS while being relatively similar to familiar syntactic dependency formalisms. It can be used for comparative parser evaluation as well as other applications (Ivanova et al. (2012), Dridan and Oepen (2011)). In this paper, we concentrate on resources for processing Dependency MRS (DMRS; Copestake (2009)). This is a version of MRS which can be represented as a dependency graph, with no need for variables. Unlike Elementary Dependencies, DMRS has a proper representation of scope and is fully inter-convertible with other forms of *MRS. It thus m"
L16-1197,2004.tmi-1.2,0,0.109409,"Missing"
L16-1197,P14-1007,0,0.0357342,"S from the ERG (henceforth English Resource Semantics: ERS) and other DELPH-IN grammars has been successfully used in a number of applications. These include machine translation (e.g., Bond et al. (2011)), information extraction and question answering (e.g., Copestake et al. (2006), Frank et al. (2005), MacKinlay et al. (2009), MacKinlay et al. (2012)), extraction of ontological relationships (e.g., Herbelot and Copestake (2006)), question generation (e.g., Yao and Zhang (2010), Yao et al. (2012)), entailment recognition (e.g., Lien and Kouylekov (2014)), detection of scope of negation (e.g., Packard et al. (2014)) and natural language interfaces (e.g., Packard (2014)). In several cases (including Packard et al. (2014), Lien and Kouylekov (2014), Packard (2014), Yao and Zhang (2010), MacKinlay et al. (2009)) an ERS-based system has outperformed other approaches in a competitive task. While an ERG-based system is not suitable for applications which require rapid analysis of very large quantities of text, parsing accuracy is competitive with other approaches and is generally good on new domains without any need for substantial training or adaptation (MacKinlay et al. (2010), Dridan and Oepen (2013)). ERS"
L16-1197,S14-2144,0,0.0181581,"d other DELPH-IN grammars has been successfully used in a number of applications. These include machine translation (e.g., Bond et al. (2011)), information extraction and question answering (e.g., Copestake et al. (2006), Frank et al. (2005), MacKinlay et al. (2009), MacKinlay et al. (2012)), extraction of ontological relationships (e.g., Herbelot and Copestake (2006)), question generation (e.g., Yao and Zhang (2010), Yao et al. (2012)), entailment recognition (e.g., Lien and Kouylekov (2014)), detection of scope of negation (e.g., Packard et al. (2014)) and natural language interfaces (e.g., Packard (2014)). In several cases (including Packard et al. (2014), Lien and Kouylekov (2014), Packard (2014), Yao and Zhang (2010), MacKinlay et al. (2009)) an ERS-based system has outperformed other approaches in a competitive task. While an ERG-based system is not suitable for applications which require rapid analysis of very large quantities of text, parsing accuracy is competitive with other approaches and is generally good on new domains without any need for substantial training or adaptation (MacKinlay et al. (2010), Dridan and Oepen (2013)). ERS is especially suitable in applications which require h"
L16-1197,W12-3206,0,0.0397673,"Missing"
L16-1197,P11-4002,0,0.0269745,"Missing"
P01-1019,P89-1005,0,0.0742803,"notes an element of H × . . . H × P(G), where the Hs (= L × I) are the new hook and holes. Note that the language Σ is first order, and we do not use λ-abstraction over higher order elements.6 For example, in the standard Montagovian view, a quantifier such as every SEMENTs 5 Note every is a predicate rather than a quantifier in this language, since MRSs are partial descriptions of logical forms in a base language. 6 Even though we do not use λ-calculus for composition, we could make use of λ-abstraction as a representation device, for instance for dealing with adjectives such as former, cf., Moore (1989). is represented by the higher-order expression λP λQ∀x(P (x), Q(x)). In our framework, however, every is the following (using qeq conditions, as in the LinGO ERG): [hf , x]{[]subj , []comp1 , [h0 , x]spec , . . .} [he : every(x, hr , hs )][hr =q h0 ]{} and dog is: [hd , y]{[]subj , []comp1 , []spec , . . .}[hd : dog(y)][]{} So these composes via opspec to yield every dog: [hf , x]{[]subj , []comp1 , []spec , . . .} [he : every(x, hr , hs ), hd : dog(y)] [hr =q h0 ]{h0 = hd , x = y} This SEMENT is semantically equivalent to: [hf , x]{[]subj , []comp1 , []spec , . . .} [he : every(x, hr , hs ),"
P04-1052,E91-1028,0,0.108148,"tractor, it is quadratic in n. The IA compares each attribute of the discourse referent to only one attribute per distractor and is linear in n. Note, however, that values for n of over 4 are rare. 3.3 Relations Semantically, attributes describe an entity (e.g., the small grey dog) and relations relate an entity to other entities (e.g., the dog in the bin). Relations are troublesome because in relating an entity e o to e1 , we need to recursively generate a referring expression for e1 . The IA does not consider relations and the referring expression is constructed out of attributes alone. The Dale and Haddock (1991) algorithm allows for relational descriptions but involves exponential global search, or a greedy search approximation. To incorporate relational descriptions in the incremental framework would require a classification system which somehow takes into account the relations themselves and the secondary entities e1 etc. This again suggests that the existing algorithms force the incrementality at the wrong stage in the generation process. Our approach computes the order in which attributes are incorporated after observing the context, by quantifying their utility through the quotient DQ. This make"
P04-1052,E03-1017,0,0.0322441,"ge  colour black Assuming that the *preferred-attributes* list is [size, colour, ...], the algorithm would first compare the values of the size attribute (both large), disregard that attribute as not being discriminating, compare the values of the colour attribute and return the brown dog. Subsequent work on referring expression generation has expanded the logical framework to allow reference by negation (the dog that is not black) and references to multiple entities (the brown or black dogs) (van Deemter, 2002), explored different search algorithms for finding the minimal description (e.g., Horacek (2003)) and offered different representation frameworks like graph theory (Krahmer et al., 2003) as alternatives to AVMs. However, all these approaches are based on very similar formalisations of the problem, and all make the following assumptions: 1. 2. 3. 4. A semantic representation exists. A classification scheme for attributes exists. The linguistic realisations are unambiguous. Attributes cannot be reference modifying. All these assumptions are violated when we move from generation in a very restricted domain to regeneration in an open domain. In regeneration tasks such as summarisation, open-"
P04-1052,J03-1003,0,0.0672025,"Missing"
P04-1052,C92-1038,0,0.17427,"ther entities in the discourse domain. For example, if there were a small brown dog (small1(x) ∧ brown1(x) ∧ dog1(x)) in context, the minimal description for the big brown dog would be big1(x) ∧ dog1(x)1 . This semantic framework makes it difficult to apply existing referring expression generation algorithms to the many regeneration tasks that are important today; for example, summarisation, openended question answering and text simplification. Unlike in traditional generation, the starting point in 1 The predicate dog1 is selected because it has a distinguished status, referred to as type in Reiter and Dale (1992). One such predicate has to to be present in the description. these tasks is unrestricted text, rather than a semantic representation of a small domain. It is difficult to extract the required semantics from unrestricted text (this task would require sense disambiguation, among other issues) and even harder to construct a classification for the extracted predicates in the manner that existing approaches require (cf., §2). In this paper, we present an algorithm for generating referring expressions in open domains. We discuss the literature and detail the problems in applying existing approaches"
P04-1052,W00-1424,0,0.0326096,"Missing"
P04-1052,J02-1003,0,0.606438,"Missing"
P04-1052,J93-2004,0,\N,Missing
P04-1052,P90-1013,0,\N,Missing
P08-4002,briscoe-carroll-2002-robust,0,0.0259199,"Missing"
P08-4002,N03-2024,0,0.0623531,"Missing"
P08-4002,C04-1129,1,0.843101,"Missing"
P97-1018,W96-0303,1,0.944192,"ne meaning, but this does not preclude other uses in sufficiently marked contexts (e.g., Bauer&apos;s (1983) example of garbage man with an interpretation analogous to snowman). Because of the difficulty of resolving lexical ambiguity, it is usual in NLP applications to exclude &apos;rare&apos; senses from the lexicon, and to explicitly list frequent forms, rather than to derive them. But this increases errors due to unexpected vocabulary, especially for highly productive derivational processes. For this and other reasons it is preferable to assume some generative devices in the lexicon (Pustejovsky, 1995). Briscoe and Copestake (1996) argue that a differential estimation of the productivity of derivation processes allows an approximation of the probabilities of previously unseen derived uses. If more probable senses are preferred by the system, the proliferation of senses that results from unconstrained use of lexical rules or other generative devices is effectively controlled. An interacting issue is the granularity of meaning of derived forms. If the lexicon produces a small number of very underspecifled senses for a wordform, the ambiguity problem is apparently reduced, but pragmatics may have insufficient information w"
P97-1018,W96-0309,0,0.0428282,"tton(y) A bag(x) A made-of(y, x)] 2. Ax[cotton(y) A bag(x) A TELIC(bag)(y,x)] = Ax[cotton(y) A bag(x) A contain(y, x)] 2We formalise this with typed default feature structures (Lascarides et al, 1996). Schemata can be regarded formally as lexical/grammar rules (lexical rules and grammar rules being very similar in our framework) but inefficiency due to multiple interpretations is avoided in the implementation by using a form of packing. 138 3. Ax[R(y, x) A -~(made-of(y, x) V contain(y, x) V ...)] The predicate made-of is to be interpreted as material constituency (e.g. Link (1983)). We follow Johnston and Busa (1996) in using Pustejovsky&apos;s (1995) concept of telic role to encode the purpose of an artifact. These schemata give minimal indications of compound semantics: it may be desirable to provide more information (Johnston et al, 1995), but we will not discuss that here. Established compounds may have idiosyncratic interpretations or inherit from one or more schemata (though compounds with multiple established senses due to ambiguity in the relationship between constituents rather than lexical ambiguity are fairly unusual). But established compounds may also have unestablished interpretations, although,"
P97-1018,C92-2066,0,\N,Missing
rupp-etal-2008-language,W07-1008,1,\N,Missing
rupp-etal-2008-language,W06-1613,1,\N,Missing
rupp-etal-2008-language,P07-2012,1,\N,Missing
rupp-etal-2008-language,P06-4020,0,\N,Missing
rupp-etal-2008-language,J96-2004,0,\N,Missing
rupp-etal-2008-language,N07-1040,1,\N,Missing
rupp-etal-2008-language,W06-2718,1,\N,Missing
togia-copestake-2014-tagntext,1995.iwpt-1.8,0,\N,Missing
togia-copestake-2014-tagntext,W12-0105,0,\N,Missing
togia-copestake-2014-tagntext,W11-2702,0,\N,Missing
togia-copestake-2014-tagntext,P07-2009,0,\N,Missing
W00-0708,P98-1085,0,0.40635,"Missing"
W00-0708,1991.mtsummit-papers.16,0,0.0574635,"Missing"
W00-0708,W00-1427,1,0.528054,"In this paper we investigate the use of corpus data to collect statistical generalizations about article use in English so as to be able to generate them automatically. We use data from the Penn Treebank as input to a memory-based learner (TiMBL 3.0; Daelemans et al., 2000) that is used to predict whether to generate the or alan or no article. 1 We discuss a variety of lexical, syntactic and semantic features that * Visiting CSLI, Stanford University (2000). t Visiting CSLI, Stanford University (1999-2000). 1We assume a postprocessor to determine whether to generate a or a n a s described in Minnen et al. (2000). Abstract Article choice can pose difficult problems in applications such as machine translation and automated summarization. In this paper, we investigate the use of corpus data to collect statistical generalizations about article use in English in order to be able to generate articles automatically to supplement a symbolic generator. We use data from the Penn Treebank as input to a memory-based learner (TiMBL 3.0; Daelemans et al., 2000) which predicts whether to generate an article with respect to an English base noun phrase. We discuss competitive results obtained using a variety of lexic"
W00-0708,1993.tmi-1.18,0,0.473714,"Missing"
W00-0708,P97-1056,0,0.0490389,"Missing"
W00-0708,C94-1002,1,0.918681,"Missing"
W00-0708,W97-0506,1,0.601846,"even if they are able to use a keyboard. Many have to rely on a slower physical interface (headstick, head-pointer, eye-tracker etc). We are attempting to use a range of NLP technology to improve text input speed for such users. Article choice is particularly important for this application: many AAC users drop articles and resort to a sort of telegraphese, but this causes degradation in comprehension of synthetic speech and contributes to its perception as unnatural and robot-like. Our particular goal is to be able to use an article generator in conjunction with a symbolic generator for AAC (Copestake, 1997; Carroll et al., 1999). In this paper we investigate the use of corpus data to collect statistical generalizations about article use in English so as to be able to generate them automatically. We use data from the Penn Treebank as input to a memory-based learner (TiMBL 3.0; Daelemans et al., 2000) that is used to predict whether to generate the or alan or no article. 1 We discuss a variety of lexical, syntactic and semantic features that * Visiting CSLI, Stanford University (2000). t Visiting CSLI, Stanford University (1999-2000). 1We assume a postprocessor to determine whether to generate a"
W00-0708,C90-2023,0,\N,Missing
W00-0708,C98-1082,0,\N,Missing
W04-0411,calzolari-etal-2002-towards,0,0.0555863,"the words in the MWE (e.g. eat up, where the particle up adds a completive sense to eat). Given the flexibility and variation in form of MWEs and the complex interrelations that may be found between their components, an encoding that treats them as invariant strings (a words with spaces approach), will not be adequate to fully describe any such expression appropriately with the exception of Computer Laboratory University of Cambridge William Gates Building, JJ Thomson Avenue Cambridge, CB3 0FD, UK aac10,bmw20,faml2 @cl.cam.ac.uk  the simplest fixed cases such as ad hoc ((Sag et al., 2002), (Calzolari et al., 2002)). Different strategies for encoding MWEs have been employed by different lexical resources with varying degrees of success, depending on the type of MWE. One case is the Alvey Tools Lexicon (Carroll and Grover, 1989), which has a good coverage of phrasal verbs, providing extensive information about their syntactic aspects (variation in word order, subcategorisation, etc), but it does not distinguish compositional from non-compositional entries neither does it specify entries that can be productively formed. WordNet, on the other hand, covers a large number of MWEs (Fellbaum, 1998), but does n"
W04-0411,copestake-flickinger-2000-open,1,0.702664,"te name like v rel. A type like transverb embodies the constraints defined for a given construction (in this case transitive verbs), in a particular grammar, and these vary from grammar to grammar. Thus, these words can be expanded into full feature structures during processing according to the constraints defined in a specific grammar. Table 1: LINGO ERG lexical database encoding identifier like tv 1 orthography like type trans-verb predicate like v rel This table shows a minimal encoding for simplex words, but it can serve as basis for a more complete one. That is the case of the LinGO ERG (Copestake and Flickinger, 2000) lexicon, which adopts for its database version, a compatible but more complex encoding which is successfully used to describe simplex words (Copestake et al., 2004). In the next sections, we investigate what would be necessary for extending this encoding for successfully capturing MWEs. 3 Idioms Idioms constitute a complex case of MWEs, allowing a great deal of variation. Some idioms are 1 The identifier and semantic relation names follow the standard adopted by the LinGO ERG (Copestake and Flickinger, 2000), while the grammatical type names are also compatible with it. very flexible and can"
W04-0411,copestake-etal-2002-multiword,1,0.863803,"variation in word order, subcategorisation, etc), but it does not distinguish compositional from non-compositional entries neither does it specify entries that can be productively formed. WordNet, on the other hand, covers a large number of MWEs (Fellbaum, 1998), but does not provide information about their variability. Neither of these resources covers idioms. The challenge in designing adequate lexical resources for MWEs, is to ensure that the variability and the extra dimensions required by the different types of MWE can be captured. Such a move is called for by Calzolari et al. (2002) and Copestake et al. (2002). Calzolari et al. (2002) discuss these problems while attempting to establish the standards for MWE description in the context of multilingual lexical resources. Their focus is on MWEs that are productive and that present regularities that can be generalised and applied to other classes of words that have similar properties. Copestake et al. (2002) present an initial schema for MWE description and we build on these ideas here, by proposing an architecture for a lexical encoding of MWEs, which allows for a unified treatment of different kinds of MWE. In what follows, we start by laying out the"
W04-0411,villavicencio-etal-2004-multilingual,1,0.819615,"MWE, in the MWE Type table. Different types of MWEs can be straightforwardly described using this encoding, as discussed in terms of idioms and VPCs. A database employing this encoding can be integrated with a particular grammar, providing the grammar system with a useful repertoire of MWEs. This is the case of the MWE grammar (Villavicencio, 2003) and of the wide-coverage LinGO ERG (Flickinger, 2004), both implemented on the framework of HPSG and successfully integrated with this database. This encoding is also used as basis of the architecture for a multilingual database of MWEs defined by Villavicencio et al. (2004), which has the added complexity of having to record the correspondences and differences in MWEs in different languages: different word orders, different lexical and syntactic constructions, etc. In terms of usage, this encoding means that the search facilities provided by the database can help the user investigate MWEs with particular properties. This in turn can be used to aid the addition of new MWEs to the database by analogy with existing MWEs with similar characteristics. 7 Acknowledgements This research was supported in part by the NTT/Stanford Research Collaboration, research project o"
W04-0411,W03-1808,1,0.922437,"seem to follow productive patterns (e.g. the resultative combinations walk/jump/run up/down/out/in/away/around/... from joining these verbs and the directional/locative particles up, down, out, in, away, around, ...). This is discussed in Fraser (1976), who notes that the semantic properties of verbs seem to affect their possibility of combination with particles. For productive VPCs, one possibility is then to use the entries of verbs already listed in a lexical resource to productively generate VPC entries by combining them with particles according to their semantic classes, as discussed by Villavicencio (2003). However, there are also cases of semi-productivity, since the possibilities of combinations are not fully predictable from a particular verb and particle (e.g. phone/ring/call/*telephone up). Thus, although some classes of VPCs can be productively generated from verb entries, to avoid overgeneration we adopt an approach where the remaining VPCs need to be explicitly licensed by the specification of the appropriate VPC entry. To sum up, for VPC entries an appropriate encoding needs to maintain the link between a VPC and the corresponding simplex form, from where the VPC inherits many of its c"
W04-0411,W98-0707,0,\N,Missing
W04-0411,copestake-etal-2004-lexicon,1,\N,Missing
W06-2718,callmeier-etal-2004-deepthought,0,0.0317893,"PH-IN tools1 . This provides a flexible standoff pointer scheme suitable for various types of data, a lattice encodes structural ambiguity, intraannotation relationships are encoded, and annotations are decorated with structured content. We provide an XML serialization for intercomponent communication. 2 The DELPH-IN collaboration DELPH-IN is a loose international collaboration of researchers developing open-source software components for language processing. These components include deep parsers, deep grammars for various natural languages, and tools for shallower processing. The HOG system (Callmeier et al., 2004) for the integration of shallow and deep linguistic processors (using a pipeline making use of XML plus XSLT transformations to pass data between processors) was developed during the Deep Thought project, as was a standard for the integration of semantic analyses produced by diverse components: RMRS (Copestake, 2003) allows underspecification of semantic analyses in such a way that the analysis produced by a shallow component may be considered an underspecification of a fuller semantic analysis produced by a deeper component. Other work (Waldron et al., 2006) has provided a representation of p"
W06-2718,waldron-etal-2006-preprocessing,1,0.839416,"ower processing. The HOG system (Callmeier et al., 2004) for the integration of shallow and deep linguistic processors (using a pipeline making use of XML plus XSLT transformations to pass data between processors) was developed during the Deep Thought project, as was a standard for the integration of semantic analyses produced by diverse components: RMRS (Copestake, 2003) allows underspecification of semantic analyses in such a way that the analysis produced by a shallow component may be considered an underspecification of a fuller semantic analysis produced by a deeper component. Other work (Waldron et al., 2006) has provided a representation of partial analyses at the level of tokenization/morphology – using a modification of MAF (Clement and de la Clergerie, 2005). Current work within the SciBorg project2 is investigating more fine-grained integration of shallow and deep processors. 1 Background An NLP system aims to map linguistic data to a description at some suitable level of representation. To achieve this various component processes must perform complex tasks. Increasingly these individual processes are performed by distinct software components in cooperation. The expressiveness of communicatio"
W07-1108,P06-4020,0,0.0438332,"information derived from it will arguably describe the data items more accurately than information from other sources. However, this information may be very sparse given the corpus’ size. For comparison we also use a 187 million word subset of the English Gigaword Corpus (Graff, 2003) to derive relational information in Section 6. This subset consists of every paragraph in the Gigaword Corpus belonging to articles tagged as ‘story’ and containing both constituents of a compound in the dataset, whether or not they are compounded there. Both corpora were lemmatised, tagged and parsed with RASP (Briscoe et al., 2006). 3.3 Learning Algorithm In all our experiments we use a one-against-all implementation of the Support Vector Machine.4 Except for the work described in Section 6.2 we used the linear kernel K(x, y) = x · y to compute similarity between vector representations of the data items. The linear kernel consistently achieved superior performance to the more flexible Gaussian kernel in a range tests, presumably due to the sensitivity of 3 4 http://www.natcorp.ox.ac.uk/ The software used was LIBSVM (Chang and Lin, 2001). the Gaussian kernel to its parameter settings.5 Oneagainst-all classification (trai"
W07-1108,P04-1054,0,0.0473698,"nal Linguistics A simple but effective method for exploiting these contexts is to count features that co-occur with the target items in those contexts. Co-occurrence may be defined in terms of proximity in the text, lexical patterns, or syntactic patterns in a parse graph. We can parameterise our notion of context further, for example by enforcing a constraint that the cooccurrence correspond to a particular type of grammatical relation or that co-occurrence features belong to a particular word class.2 Research in NLP frequently makes use of one or more of these similarity types. For example, Culotta and Sorensen (2004) combine word similarity and relation similarity for relation extraction; Gliozzo et al. (2005) combine word similarity and token similarity for word sense disambiguation. Turney (2006) discusses word similarity (which he calls ”attributional similarity”) and relation similarity, but focusses on the latter and does not perform a comparative study of the kind presented here. The experiments described here investigate type, word and relation similarity. However, token similarity clearly has a role to play in the interpretation task, as a given compound type can have a different meaning in differ"
W07-1108,J93-1003,0,0.112711,"Missing"
W07-1108,P05-1050,0,0.0669112,"co-occur with the target items in those contexts. Co-occurrence may be defined in terms of proximity in the text, lexical patterns, or syntactic patterns in a parse graph. We can parameterise our notion of context further, for example by enforcing a constraint that the cooccurrence correspond to a particular type of grammatical relation or that co-occurrence features belong to a particular word class.2 Research in NLP frequently makes use of one or more of these similarity types. For example, Culotta and Sorensen (2004) combine word similarity and relation similarity for relation extraction; Gliozzo et al. (2005) combine word similarity and token similarity for word sense disambiguation. Turney (2006) discusses word similarity (which he calls ”attributional similarity”) and relation similarity, but focusses on the latter and does not perform a comparative study of the kind presented here. The experiments described here investigate type, word and relation similarity. However, token similarity clearly has a role to play in the interpretation task, as a given compound type can have a different meaning in different contexts – for example, a school book can be a book used in school, a book belonging to a s"
W07-1108,N04-1016,0,0.155057,"Missing"
W07-1108,P03-1017,0,0.0533308,"Missing"
W07-1108,P07-3013,1,0.886942,"Missing"
W07-1108,W06-0503,0,0.050903,"Missing"
W07-1108,J06-3003,0,0.0568222,"at might plausibly be of interest: 1. The contexts in which instances of the compound type appear (type similarity); e.g., all sentences in the corpus that contain the compound bread knife. 2. The contexts in which instances of each constituent appear (word similarity); e.g., all sentences containing the word bread or the word knife. 3. The contexts in which both constituents appear together (relation similarity); e.g., all sentences containing both bread and knife. 4. The context in which the particular compound token was found (token similarity). 1 Such as Girju et al. (2005), Girju (2006), Turney (2006). Lapata and Keller’s (2004) unsupervised approach is a notable exception. 57 Proceedings of the Workshop on A Broader Perspective on Multiword Expressions, pages 57–64, c Prague, June 2007. 2007 Association for Computational Linguistics A simple but effective method for exploiting these contexts is to count features that co-occur with the target items in those contexts. Co-occurrence may be defined in terms of proximity in the text, lexical patterns, or syntactic patterns in a parse graph. We can parameterise our notion of context further, for example by enforcing a constraint that the cooccu"
W07-1210,briscoe-carroll-2002-robust,0,0.0385315,"llows compatible semantic representations at a phrasal level as well as at a sentence level. The next section (§2) describes the most important features of MRS, RMRS and the earlier work on the algebra. We then outline how the algebra can be used for implementing deep non-TFS approaches (§3) and explain how it works with RMRS (§4). This is followed by discussion of the extension to grammars without a detailed lexicon (§5). To briefly illustrate the practical applications, section (§6) outlines how RMRS semantics is constructed from RASP (Robust accurate domain-independent statistical parsing: Briscoe and Carroll (2002)). 2 MRS, RMRS and the algebra Details of MRS, RMRS and the algebra are given in the cited papers, but we will briefly introduce them here for convenience. Fig. 1 illustrates an MRS from a deep grammar (based on the ERG output, but simplified for expository purposes), an equivalent RMRS and a very underspecified RMRS, derived from a POS tagger. MRS achieves a flat representation via the use of labels on EPs, thus factoring out scopal relationships. Scope constraints (HCONS) are shown as qeq relationships (=q equality modulo quantifiers: the 73 Proceedings of the ACL 2007 Workshop on Deep Lingu"
W07-1210,P01-1019,1,0.736598,"RMRSs: RMRS output from shallower systems is less fully specified than the output from deeper systems, but in principle fully compatible. In our work, the semantics produced by a deep grammar is taken as normative when developing semantic representations from shallower processing. For English, the target semantic representations are those produced by the English Resource Grammar ( ERG, Flickinger (2000)). The MRS/RMRS approach has been adopted as a common framework for the DELPH - IN initiative (Deep Linguistic Processing with HPSG: http://www.delph-in.net). An algebra for MRS was defined by Copestake et al. (2001) (henceforth CLF) and forms the starting point for the work reported here. The aim of CLF was to formalise the notion of semantic composition within grammars expressed in a typed feature structure (TFS) logic. Here, we extend that work to non-lexicalist approaches and also describe how the formal principles of composition used in MRS can be adapted to produce a formalism for RMRS composition. Thus we demonstrate that the algebra applies to grammar engineering across a much wider range of frameworks than was originally envisaged. Besides its theoretical interest, this result has practical benef"
W07-1210,P04-1032,0,0.0124813,"r and Frank (2005) demonstrate RMRS construction from TIGER dependencies, but do not attempt to match a deep parser output. 8 Conclusion We have demonstrated that the MRS algebra, originally intended as a formalisation of some aspects of semantic composition in constraint-based grammars, can be extended to RMRS and other types of grammar framework and can be used as the basis of a full implementation of composition. The algebra can thus be used much more widely than originally envisaged and could be exploited by a wide range of parsers. Useful properties concerning monotonicity and scope (see Fuchss et al. (2004)) are thus guaranteed for a range of grammars. Phrasal-level compatibility of RMRS (to the extent that this is syntactically possible) is also an important result. The main practical outcome of this work so far has been a semantic component for the RASP system which produces representations compatible with that of the ERG without compromising RASP speed or robustness. RASP - RMRSs have already been used in systems for question answering, information extraction, email response, creative authoring and ontology extraction (e.g., Uszkoreit et al. (2004), Watson et al. (2003), Herbelot and Copestak"
W07-1210,C04-1180,0,\N,Missing
W08-0608,P07-2012,1,0.884006,"Missing"
W08-0608,W07-1008,1,0.718424,"Missing"
W08-0608,N04-4028,0,0.163757,"ence. In n-best operation, the n best sequences for the sentence are identified, along with their probabilities, for example by coupling the Viterbi algorithm with A* search. In confidence-based operation, potential entities (with a probability above a threshold) are identified directly, without directly seeking a single optimal labelling for the entire sentence. This is done by examining the probability of the label transitions within the entity, and the forward and backward probabilities at the start and end of the entity. This mode has been termed the Constrained ForwardBackward algorithm (Culotta and McCallum, 2004). Where a single unambiguous non-overlapping labelling is required, it can be obtained by identifying cases where the entities overlap, and discarding those with lower probabilities. Confidence-based extraction has two main advantages. First, it enables the balance between precision and recall to be controlled by varying the probability threshold. Second, confidence-based NER avoids over-commitment in systems where it is used as a preprocessor, since multiple overlapping options can be used as input to later components. The optimum balance between recall and precision depends on the applicatio"
W08-0608,P06-1141,0,0.0392053,"Missing"
W08-0608,N04-2002,0,0.0614129,"Missing"
W08-0608,W07-1033,0,0.154217,"Missing"
W08-0608,W04-2401,0,\N,Missing
W08-0608,C02-1151,0,\N,Missing
W08-0608,W06-1673,0,\N,Missing
W08-0608,P05-1051,0,\N,Missing
W08-0608,P06-2055,0,\N,Missing
W08-0608,W04-0705,0,\N,Missing
W08-0608,W07-1000,0,\N,Missing
W09-0623,H05-1042,0,0.605593,"captured by constructing a tag with tag attribute team1 player4, and tag value ‘SR Tendulkar’. The fact he achieved 113 runs is encapsulated by another tag, with tag attribute as team1 player4 R and tag value as ‘113’. Then if the report contained the phrase ‘Tendulkar made 113 off 102 balls’ we would hope to match the ‘Tendulkar’ factoid with our tag value ‘SR Tendulkar’, the ‘113’ factoid with our tag value ‘113’ and replace both factoids with their respective tag attributes, in this case team1 player4 and team1 player4 R respectively. Similar methods for this problem have been employed by Barzilay and Lapata (2005) and Duboue and McKeown (2003). The basic idea behind our 6-step process for alignment is that we align those factoids we are bowled’, M for ‘maiden overs’, R for ‘runs conceded’ and W for ‘wickets taken’. Econ is ‘economy rate’, or number of runs per over. It is important to note that Figure 1 omits the opposing team’s innings (comprising new instances of the ‘Batting’, ‘Fall of Wickets’ and ‘Bowling’ sections), and some additional statistics found at the bottom of the scorecard. 2 For example in Figure 1 we can see the number 6 appearing four times: twice as the number of 4s for two differen"
W09-0623,W03-1016,0,0.493738,"ed document (Reiter and Dale, 2000). Consider the task of generating a cricket match report, given the scorecard for that match. Such a scorecard would typically contain a large number of statistics pertaining to the game as a whole as well as individual players (e.g. see Figure 1). Our aim is to identify which statistics should be selected by the NLG system. Much work has been done in the field of content selection, in a diverse range of domains e.g. weather forecasts (Coch, 1998). Approaches are usually domain specific and predominantly based on structured tables of well-defined input data. Duboue and McKeown (2003) attempted a statistical approach to content selection using a substantial corpus of biographical summaries paired with selected content, where they extracted rules 2 Data Acquisition & Alignment We first must obtain appropriately aligned cricket data, for the purposes of machine learning. Our data comes from the online Wisden almanack (Cricinfo, 2007), which we used to download 133 match report/scorecard pairs. We employed an HTML parser to extract the main text from the match report webpage, and the match data-tables from the scorecard webpage. An example scorecard can be found in Figure 11"
W10-1809,J93-2004,0,0.0348021,"t of guidelines to mark some specific linguistic phenomenon in some given text. However, we would argue that, when considering the aims of an annotation task and its relation to the existing linguistic literature, it becomes possible to distinguish between various types of annotation. Further, we will show that our own effort situates itself in a little studied relation to formal semantics. The most basic type of annotation is the one where computational linguists mark large amounts of textual data with well-known and wellunderstood labels. The production of tree banks like the Penn Treebank (Marcus et al, 1993) makes use of undisputed linguistic categories such as parts of speech. The aim is to make the computer learn and use irrefutable bits of linguistics. (Note that, despite agreement, the representation of those categories may differ: see for example the range of available parts of speech tag sets.) This type of task mostly involves basic syntactic knowledge, but can be taken to areas of syntax and seman74 of quantification resolution as choosing the ‘correct’ set relation for a particular noun phrase in a particular sentence – implying some sort of truth value at work throughout the process: th"
W10-1809,W04-0210,0,0.123608,"use the SPC tag”. The GNOME annotation scheme is closer in essence to the literature on genericity and much more detailed than the ACE guidelines. However, the scheme distinguishes only between generic and non-generic entities, as in the ACE corpus case, and the corpus itself is limited to three genres: museum labels, pharmaceutical leaflets, and tutorial dialogues. The guidelines are therefore tailored to the domains under consideration; for instance, bare noun phrases are said to be typically generic. This restricted solution has the advantage of providing good agreement between annotators (Poesio, 2004 reports a Kappa value of 0.82 for this annotation). 4 generics, allowing us to assess how our quantificational reading fares in a real annotation task. Finally, the use of an open resource means that the corpus can be freely distributed.2 In order to create our annotation corpus, we first isolated the first 100,000 pages in our snapshot and parsed them into a Robust Minimal Recursion Semantics (RMRS) representation (Copestake, 2004) using first the RASP parser (Briscoe et al, 2006) and the RASP to RMRS converter (Ritchie, 2004). We then extracted all constructions of the type Subject-Verb-Obj"
W10-1809,J08-3001,0,0.0602982,"Missing"
W10-1809,W06-1312,0,0.0391735,"the studied phenomena have a (somewhat) clear, agreed upon definition (Kingsbury et al, 2002). We must clarify that in those cases, the choice of a formalism may already imply a certain theoretical position – leading to potential incompatibilities between formalisms. However, the categories for such annotation are themselves fixed: there is a generally agreed broad understanding of concepts such as noun phrases and coordination. Another type of annotation concerns tasks where the linguistic categories at play are not fixed. One example is discourse annotation according to rhetorical function (Teufel et al, 2006) where humans are asked to differentiate between several discursive categories such as ‘contrast’ or ‘weakness’. In such a task, the computational linguist develops a theory where different states or values are associated with various phenomena. In order to show that the world functions according to the model presented, experimentation is required. This usually takes the form of an annotation task where several human subjects are required to mark pieces of text following guidelines inferred from the model. The intuition behind the annotation effort is that agreement between humans support the"
W10-1809,P06-4020,0,\N,Missing
W11-0118,P06-4020,0,0.0197429,"lot and Copestake, 2010.) 170 5.3 Features We give the system article and number information for the noun phrase to be quantified, as well as the tense of the verbal predicate following it. In order to cater for proper nouns, we also indicate whether the head of the noun phrase is capitalised or not. Article, number and capitalisation information is similarly provided for the object of the verb. All features are automatically extracted from the Robust Minimal Recursion Semantics (RMRS, Copestake, 2004) representation of the sentence in which the noun phrase appears (obtained via a RASP parse, Briscoe et al., 2006). The following shows an example of a feature line for a particular noun phrase (the sentence in which the noun phrase appears is also given): ORIGINAL: [His early blues influences] included artists such as Robert Johnson, Bukka White, Skip James and Sleepy John Estes. FEATURES: past,possessive,plural,nocap,bare,plural,nocap Note that articles belonging to the same class are labelled according to that class: all possessive articles, for instance, are simply marked as ‘possessive’. This is the same for demonstrative articles. 5.4 Experiments and results The aim of this work is not only to produ"
W11-0118,E09-1001,1,0.822605,"Missing"
W11-0118,W10-1809,1,0.924335,"e, no attempt at the automatic specification of quantification has been made before. In consequence, we start our investigation with the simplest possible type of machine learning algorithm, using as determining features the direct syntactic context of the statement to be quantified. The general idea of such a system is that grammatical information such as the number of a subject noun phrase and the tense of its verbal predicate may be statistically related to its classification. 5.1 Gold standard We built a gold standard by re-using and expanding the quantification annotations we produced in Herbelot and Copestake (2010). This small corpus, which contains randomly extracted Wikipedia5 sentences, provides 300 instances of triply annotated subject noun phrases. The categories used for annotation are the natural language quantifiers ONE, SOME, MOST, ALL and the label QUANT (for noun phrases of the type some cats, most turtles or more than 37 unicorns which, being explicitly quantified, do not enter our underquantification account and must be marked with a separate label). In order to convert the multiple 4 5 A more comprehensive discussion can be found in Herbelot (2010). http://www.wikipedia.org/ 169 annotation"
W11-0118,1995.mtsummit-1.1,0,0.0839121,"irical coverage (beyond ‘standard’ linguistic examples), c) lends itself to evaluation by human annotation and d) can be derived automatically. We draw on work in formal linguistics, but by formulating the problem as quantification resolution, we obtain an account which is more tractable from an NLP perspective. We also present preliminary experiments that automate quantification resolution using a syntax-driven classifier. 2 Under(specified) quantification The phenomenon of ambiguous quantification overlaps with genericity. Generic NPs have traditionally been described as referring to kinds (Krifka et al., 1995) and one of their most frequent syntactic expressions is the bare plural, although they occur in definite and indefinite singulars too, as well as bare singulars. There are many views on the semantics of generics (e.g. Carlson, 1995; Pelletier and Asher, 1997; Heyer, 1990; Leslie, 2008) but one of them is that they quantify (Cohen, 1996), although, puzzlingly enough, not always with the same quantifier: 7. Dogs are in my garden = Some dogs... 8. Frenchmen eat horsemeat = Some/Relatively-many Frenchmen... (For the relatively many reading, see Cohen, 2001.) 9. Cars have four wheels = Most cars.."
W11-2315,2009.mtsummit-btm.1,0,\N,Missing
W11-2315,W10-1607,1,\N,Missing
W11-2315,W03-1602,0,\N,Missing
W11-2315,P08-1040,0,\N,Missing
W11-2315,W10-0406,0,\N,Missing
W11-2315,daelemans-etal-2004-automatic,0,\N,Missing
W11-2315,E99-1042,0,\N,Missing
W11-2707,P09-1092,0,0.0363717,"Missing"
W11-2707,P10-1036,0,0.0606094,"Missing"
W11-2707,P99-1018,0,0.383122,"in order to look at degree of reversibility: What proportion of the two orderings do we find in a corpus? This means that we require relatively large corpora to obtain good estimates in order to evaluate a model. Of course, if we are interested in analogical models of binomial ordering, as mentioned at the end of §2, we need a reasonably large corpus of binomials to develop the model. Ideally this should be a different corpus from the one used for evaluation. We note that some experiments on premodifier ordering have found a considerable drop in performance when testing on a different domain (Shaw and Hatzivassiloglou, 1999). Using a single corpus split into training and test data would, of course, be problematic when working with binomial types. We have thus developed a relatively novel methodology of using an automatically parsed corpus in combination with frequencies from Web data. This is discussed in the next section. 4 Binomial corpora and corpus investigation In this section, we describe the resources we have developed for investigating binomials and addressing some of the evaluation questions introduced in the previous section. We then present an initial analysis of some of the corpus data. 4.1 Benor and"
W13-0602,D10-1115,0,0.0411635,"ositional semantics: i.e., which used lexical semantics as part of the models that assigned syntactic structure or logical form.1 There are reasons to think that distributional approaches could well be more appropriate in such contexts, but a demonstration of this will involve looking at a broad range of phenomena. This paper is intended as a first step in outlining some of the issues that might be considered. I first want to distinguish the discussion of lexical meaning here from the various approaches to deriving distributional meaning from sentences investigated by Clark and Pulman (2007), Baroni and Zamparelli (2010), Mitchell and Lapata (2010), Guevara (2011) and others which in turn relates to previous approaches to combining connectionist and symbolic approaches (e.g., Smolensky and Legendre, 2006). That line of work assumes that a syntactic representation (or perhaps a logical form) is available to guide the process of composition of distributions.2 This work is mostly orthogonal to the issue I wish 1 Note that use ‘compositional semantics’ in its predominant sense to mean an approach in the tradition of Montague grammar, construed broadly, but including a treatment of quantification. 2 I note the pos"
W13-0602,S12-1023,0,0.158878,"Missing"
W13-0602,flickinger-etal-2010-wikiwoods,0,0.0521819,"ween singular and plural forms as measured using distributional techniques are predominantly mass (in that they are frequently found in contexts which select for mass terms, and infrequently found in contexts that select for count terms). This would fit with the assumption that some sort of meaning shift has to occur for a mass noun to be pluralized. However, the use of distributions here is limited to measuring semantic (dis)similarity. Building more complex models would require a corpus which makes distinctions between count and mass contexts systematically. The ERG-parsed Wikiwoods corpus (Flickinger et al., 2010) contains such information, but it is unclear whether this is sufficiently accurate to allow the relevant meaning shifts to be detected. So this outline suggests something about the types of models that are of interest. Distributions must be sensitive to distinctions such as count / mass. If we take this as a syntactic distinction, then the appropriate models are ones in which distributions contain syntactic information.8 The advantage of the distributional model over the GOFLS approaches is that frequency effects are an integral part, and hence there is a natural account of the oddness of exa"
W13-0602,W11-0115,0,0.0925941,"part of the models that assigned syntactic structure or logical form.1 There are reasons to think that distributional approaches could well be more appropriate in such contexts, but a demonstration of this will involve looking at a broad range of phenomena. This paper is intended as a first step in outlining some of the issues that might be considered. I first want to distinguish the discussion of lexical meaning here from the various approaches to deriving distributional meaning from sentences investigated by Clark and Pulman (2007), Baroni and Zamparelli (2010), Mitchell and Lapata (2010), Guevara (2011) and others which in turn relates to previous approaches to combining connectionist and symbolic approaches (e.g., Smolensky and Legendre, 2006). That line of work assumes that a syntactic representation (or perhaps a logical form) is available to guide the process of composition of distributions.2 This work is mostly orthogonal to the issue I wish 1 Note that use ‘compositional semantics’ in its predominant sense to mean an approach in the tradition of Montague grammar, construed broadly, but including a treatment of quantification. 2 I note the possibility of working with logical forms, sinc"
W13-0602,C65-1010,0,0.402306,"fly touch on the use of hyponymy relationships in modelling the semantics of individual lexemes in §4. At this point, a nomenclature issue arises, since there is no good collective term for the non-distributional approaches. ‘Non-distributional’ is clunky. To talk about ‘traditional’ or ‘classical’ lexical semantics seems inappropriate given the the earliest distributional work (e.g., Harris, 1954) predates, for example, the feature-based approach of Fodor and Katz (1963) (the first computational work on distributions was underway at this point, although the first publication I am aware of is Harper (1965)). The term ‘symbolic’ is problematic, since distributional semantics is also symbolic. So, in the absence of a better alternative, I will use ‘Good old-fashioned lexical semantics’ (GOFLS) by analogy with Haugeland’s ‘Good old-fashioned AI’ (GOFAI: Haugeland, 1985). Hence the question that forms the title of this paper: “Can distributional approaches improve on Good Old-Fashioned Lexical Semantics?”. Models using hand-crafted GOFLS were integrated into parsing in a range of approaches from the 1970s onwards. For example, Boguraev (1979) used semantic preferences expressed in terms of semantic"
W13-0602,J03-2004,0,0.256265,"nomena (Verspoor, 1997) is a case in point: to allow for the data there with a GOFLS model would have required fine-grained distinctions to be drawn which were otherwise unmotivated. Since that was precisely the problem with previous approaches to lexical semantics that had partly motivated the development of GL (see Pustejovsky’s discussion and criticism of sense enumeration, for example), there was reason to doubt the classic GL model on theoretical grounds. Distributional-style approaches have been successfully adopted as models in investigation of some of the ‘classic’ GL phenomena (e.g., Lapata and Lascarides, 2003). However, these models are partial in that the distributional techniques have been used in isolation, rather than as part of an integrated syntactic-logical-distributional model. Furthermore, the aim in most published work is to show the best performance on a particular test set, rather than to build models which demonstrate good performance on a broad range of phenomena, let alone build fully-integrated broad-coverage systems.3 nouns and NPs acting as temporal modifiers. These might be expected to be relevant to the choice of functions for combining distributions. 3 Baroni and Lenci (2010) a"
W13-0602,P04-3026,0,0.335858,"ts something about the types of models that are of interest. Distributions must be sensitive to distinctions such as count / mass. If we take this as a syntactic distinction, then the appropriate models are ones in which distributions contain syntactic information.8 The advantage of the distributional model over the GOFLS approaches is that frequency effects are an integral part, and hence there is a natural account of the oddness of examples such as (5). The problem, from a practical perspective, is that distributions created over individual instances produce a severe sparse data problem (cf Rapp, 2004). It is also, of course, implausible to assume that unusual cases such as that illustrated in (5) will actually be attested for all lexemes where they are possible in principle. What is actually required is an approach where certain uses may be postulated even though not actually attested with a particular word. Rather than discuss this with respect to marginal examples such as (5), I will turn to the phenomenon of 6 Of course, the distributions for mass and count versions of a lexeme could just be constructed separately, but this is analogous to the simplistic lexicalist account where there a"
W13-0602,W11-0130,0,0.028097,"semantics affects syntax, some mechanism is required in the overall architecture to make syntax sensitive to the lexical semantic representation. This is not to say that there are no points of contact. For instance, in the notion of cocomposition described in Pustejovsky’s Generative Lexicon (GL) work (e.g., Pustejovsky, 1995) the composition function is determined both by functor and argument. This can be perhaps related to some of the more recent work on composition with distributional semantics, where individual words can be associated with different composition functions (as suggested by Washtell (2011)). But GL is an exception in treating composition as part of a theory of lexical semantics, and even GL makes rather conventional assumptions about compositional semantics in many respects. Hence discussion of this is not part of the current paper. I will concentrate here on research on modelling the behaviour of individual words rather than work on the traditional relationships between words (or word senses) — hyponymy, synonymy, antonymy and meronymy. Though this is not the focus of the current discussion, I will briefly touch on the use of hyponymy relationships in modelling the semantics o"
W13-0602,J10-4006,0,\N,Missing
W15-0101,P08-1037,0,0.0246803,"ms of syntactic structure. However, while similarity might be appropriate for handing coordination, since conjuncts are likely to be semantically similar, this does not generalise well to other relations, where the lexical items involved may be semantically related, but not similar. Bergsma et al. (2011) approach coordination ambiguity using annotated text, aligned bilingual text, and plain monolingual text, building statistics of lexical association. However, this method works at the string level, without semantic annotations, and there is no clear generalisation to other semantic relations. Agirre et al. (2008) use lexical semantics in parsing, both in general and considering PP-attachment in particular. They replace tokens with more general WordNet synsets, which reduces data sparsity for standard lexicalised parsing techniques. Our LDA approach essentially provides an alternative method to back-off to semantic classes, without having to deal with the problem of word sense disambiguation. 2 3 Generative Model 3.1 Modelling an Arbitrary Relation Despite the vast variety of syntactic frameworks, many parsers will produce semantic or syntactic relations in some form. We might therefore rephrase parse"
W15-0101,J96-1002,0,0.0241931,"y. However, rare lexical items will have low probabilities, even if they are a close semantic fit, so we should normalise by the words’ overall probability of occurrence, P (x) and P (y), as shown in (3). The denominator can be interpreted as co-occurrence of x and y under the null hypothesis that they are generated independently, according to their overall frequency. We do not normalise by P (r), so that the frequency of the relation is still taken into account, which is important, as we will see in section 3.2. P (r, x, y) score (r, x, y) = (3) P (x) P (y) A Maximum Entropy parser (MaxEnt; Berger et al., 1996) relies on a set of features f1 , . . . , fm with corresponding weights λ1 , . . . , λm . The probability of a parse t for a sentence s is given in (4), where Z is a normalisation constant which can often be neglected. The values of the weights λi are chosen to maximise the likelihood of training data, sometimes including a Gaussian prior for regularisation. P (t|s) = m X 1 λi fi (t) exp Z i=1 (4) To incorporate the above scores into a MaxEnt parser, we could define a feature which sums the scores of all relations in a parse. However, the scores in (3) are always positive, so this would bias u"
W15-0101,P11-1135,0,0.0231167,"ark et al. (2009) use lexical similarity measures in resolving coordination ambiguities. They propose two similarity systems, one based on WordNet, and the other on distributional information extracted from Wikipedia using the C&C parser. Hogan (2007) also consider similarity, both of the head words and also in terms of syntactic structure. However, while similarity might be appropriate for handing coordination, since conjuncts are likely to be semantically similar, this does not generalise well to other relations, where the lexical items involved may be semantically related, but not similar. Bergsma et al. (2011) approach coordination ambiguity using annotated text, aligned bilingual text, and plain monolingual text, building statistics of lexical association. However, this method works at the string level, without semantic annotations, and there is no clear generalisation to other semantic relations. Agirre et al. (2008) use lexical semantics in parsing, both in general and considering PP-attachment in particular. They replace tokens with more general WordNet synsets, which reduces data sparsity for standard lexicalised parsing techniques. Our LDA approach essentially provides an alternative method t"
W15-0101,J99-2002,0,0.040351,"he standard deviation provides an error estimate, which we explore in section 5.3. 3.3.3 Model Selection Training requires fixing the hyperparameters T , α, β and γ in advance. Griffiths and Steyvers (2004) recommend setting parameters to maximise the training data’s log-likelihood L. However, this could result in overfitting, if more parameters are used than necessary; intuitively, some topics may end up matching random noise. One alternative is the Akaike Information Criterion (AIC; Akaike, 1974), which penalises the dimensionality k of the parameter space, and is defined as 2k − 2 log (L). Bruce and Wiebe (1999) demonstrate that such a criterion in natural language processing can avoid overfitting. We have T − 1 independent parameters from θ, and T (V − 1) from each of ϕ and ψ, where V is the vocabulary size.4 Neglecting lower order terms, this gives k = 2T V . However, rare lemmas appear in few topics, giving sparse frequency counts, so k is effectively much lower. We are not aware of a method to deal with such sparse values. However, a simple work-around is to pretend V is smaller, for example V = 1000, effectively ignoring parameters for rare lexical items. 4 Reordering topics only represents a fi"
W15-0101,P96-1025,0,0.0260446,"ith handannotated data, as explained in section 4. Results are presented in section 5, which we discuss in section 6. Finally, we give suggestions for future work in section 7, and conclude in section 8. 2 Related Work The mathematical framework described in section 3.3 follows the “Rooth-LDA” model described by ´ S´eaghdha (2010). However, he uses it to model verbs’ selectional preferences, not for parse ranking. O The main difference in this work is to train multiple such models and compare their probabilities. The use of lexical information in parse ranking has been explored for some time. Collins (1996) used bilexical dependencies derived from parse trees, estimating the probabiliity of a relation given a sentence. We consider instead the plausibility of relations, which can be included in a more general ranking model. Rei and Briscoe (2013) consider re-ranking the output of a parser which includes bilexical grammatical relations. They use co-occurrence frequencies to produce confidence scores for each relation, and combine these to produce a score for the entire parse. To smooth the scores, they use a semantic vector space model to find similar lexical items, and average the scores for all"
W15-0101,E09-1001,1,0.801986,"ortion of nominal attachment 4.2 Training Data We trained the model using the WikiWoods corpus (Flickinger et al., 2010), which is both large, and also has rich syntactic and semantic annotations. It was produced from the full English Wikipedia using the PET parser (Callmeier, 2000; Toutanova et al., 2005) trained on the gold-standard subcorpus WeScience (Ytrestøl et al, 2009), and using the English Resource Grammar (ERG; Flickinger, 2000). Of particular note is that the ERG incorporates Minimal Recursion Semantics (MRS; Copestake et al., 2005), which can be expressed using dependency graphs (Copestake, 2009). The relations mentioned in section 3.2 are not explicit in the ERG, since prepositions are represented as nodes, with edges to mark their arguments. To produce a set of training data, we searched for all preposition nodes5 in the corpus, which either had both arguments ARG1 and ARG2 saturated, or, if no ARG1 was present, was the ARG1 of another node. We split the data based on nominal or verbal attachment, discarding PPs attached to other parts of speech. Each training instance was then a tuple of the form (v, p, n) or (n1 , p, n2 ), for verbal or nominal attachment, respectively. We used le"
W15-0101,flickinger-etal-2010-wikiwoods,0,0.326889,"Missing"
W15-0101,P07-1086,0,0.0349801,"guous cases, and the second plays an important role in building a framework that can handle arbitrary types of ambiguity. This provides a significant advantage over many discriminative approaches to PP-attachment: despite Zhao and Lin’s impressive results, it is unclear how their method could be extended to cope with arbitrary ambiguity in a full sentence. Clark et al. (2009) use lexical similarity measures in resolving coordination ambiguities. They propose two similarity systems, one based on WordNet, and the other on distributional information extracted from Wikipedia using the C&C parser. Hogan (2007) also consider similarity, both of the head words and also in terms of syntactic structure. However, while similarity might be appropriate for handing coordination, since conjuncts are likely to be semantically similar, this does not generalise well to other relations, where the lexical items involved may be semantically related, but not similar. Bergsma et al. (2011) approach coordination ambiguity using annotated text, aligned bilingual text, and plain monolingual text, building statistics of lexical association. However, this method works at the string level, without semantic annotations, a"
W15-0101,N10-1004,0,0.0606182,"Missing"
W15-0101,P10-1045,0,0.0824744,"Missing"
W15-0101,H94-1048,0,0.276918,"an object. Duplicates were removed, since this would unfairly weight those examples: some repeated cases, such as (store metadata in format), are limited in their domain. If the same tuple occurred with different attachment sites, the most common site was used, which happened twice, or if neither was more common, it was discarded, which happened four times. This produced 3485 unique sequences, of which 2157 contained one of the nine prepositions under consideration. The data is available on https://github.com/guyemerson/WeSciencePP. The second data set was extracted from the Penn Treebank by Ratnaparkhi et al. (1994). This dataset has been widely used, allowing a comparison with other approaches. We extracted tuples with one of 5 The ERG includes some prepositions in the “sense” field of a verb, rather than as a separate node. This is done for semantically opaque constructions, such as rely on a friend, where the meaning cannot be described in terms of rely and on a friend. We may wish to ignore such cases for two reasons: firstly, the preposition often appears either immediately following the verb or sentence-finally, which makes ambiguous sentences less common; secondly, the semantics is often idiosyncr"
W15-0101,N13-1040,0,0.0861631,"framework described in section 3.3 follows the “Rooth-LDA” model described by ´ S´eaghdha (2010). However, he uses it to model verbs’ selectional preferences, not for parse ranking. O The main difference in this work is to train multiple such models and compare their probabilities. The use of lexical information in parse ranking has been explored for some time. Collins (1996) used bilexical dependencies derived from parse trees, estimating the probabiliity of a relation given a sentence. We consider instead the plausibility of relations, which can be included in a more general ranking model. Rei and Briscoe (2013) consider re-ranking the output of a parser which includes bilexical grammatical relations. They use co-occurrence frequencies to produce confidence scores for each relation, and combine these to produce a score for the entire parse. To smooth the scores, they use a semantic vector space model to find similar lexical items, and average the scores for all such items. From this point of view, our LDA model is an alternative smoothing method. Additionally, both our approach and theirs can be seen as examples of self-training. However, their re-ranking approach must be applied on the output of a p"
W15-0101,J93-1005,0,\N,Missing
W15-0116,J14-3008,1,0.901539,"Missing"
W15-0116,P06-1130,0,0.0456936,"Missing"
W15-0116,I05-1015,0,0.0296606,"imal Recursion Semantics representations. The approach treats realization as a translation problem, transforming the Dependency MRS graph representation to a surface string. Translation is based on a Synchronous Context-Free Grammar that is automatically extracted from a large corpus of parsed sentences. We have evaluated the new approach on the Wikiwoods corpus, where it shows promising results.1 1 Introduction Realization from Minimal Recursion Semantics (MRS) representations has traditionally used a chartbased approach governed by a resource grammar. Introduced by Carroll et al. (1999) and Carroll and Oepen (2005), the chart-based approach is lexically-driven and is able to produce a large number of candidate surface strings which may be ranked using an N-gram language model or using discriminative machine learning (Velldal and Oepen, 2005; Velldal, 2009). As the chart-based realization relies on a resource grammar, it tends to perform well when realizing from MRS representations that were created by a parser using the same resource grammar. However, the chart-based approach may fail to produce any output when the MRS representation has missing or incorrect parts. This is a significant issue for the MR"
W15-0116,P05-1033,0,0.490564,"mantic transfer translation systems such as LOGON (Lø nning et al., 2004) due to the difficulty of the translation problem. Consequently, the realization component is unable to produce any output and, in turn, translation fails. In this paper we describe a first attempt at statistical realization from MRS representations. The approach treats realization as a translation problem, transforming the Dependency MRS graph representation to a surface string. The approach draws inspiration from Statistical Machine Translation, namely the hierarchical phrase-based approach to translation introduced by Chiang (2005, 2007). We will refer to the new approach as Hierarchical Statistical Semantic Realization or HSSR. As part of the HSSR system, we present an approach for the automatic extraction of salient hierarchical rules for realization. The approach creates rules by considering DMRS subgraphs and corresponding surface substrings. The rules are created in two stages, first creating terminal rules, followed by nonterminal rules. The latter are created by ‘subtracting’ terminal rules from each other. The realization rules are extracted from a large parsed corpus to form a Synchronous Context-Free Grammar"
W15-0116,J07-2003,0,0.0502277,") introducing glue rules which would combine realized parts of subgraphs despite missing connecting predicates; (3) increasing the size of the grammar in hope that such rules would be extracted from examples. We find the second preferable to others as it also enables realization in other instances of missing rules (not to mention that there are instances of predicates with four arguments). However, introduction of glue rules is nontrivial as it can create spurious ambiguity in the decoder - a situation where many distinct derivations with the same model features and realizations are produced (Chiang, 2007). An increase in spurious ambiguity would affect the decoder efficiency and cause problems for advanced tuning procedures depending on n-best lists, such as MERT. The fifth and final example realization demonstrates the variability of output that the realization system is able to produce. This highlights the deficiencies of using N-gram precision measures such as BLEU for evaluating realization (and translation) output. 5 Related Work In this paper we described a first attempt at statistical realization from MRS representations using synchronous context-free grammar. In this section we discuss"
W15-0116,W07-1210,1,0.808066,"f the trees corresponding to the different scopes, maintaining the constraints between the elements via qeq constraints (=q , equality modulo quantifier) between hole arguments and labels. Intuitively, a qeq constraint, h =q l, enables one or more quantifiers to float between the label l and handle h but we will not explain the details here. Replacing the equalities with qeq constraints in the example above underspecifies scope, giving the MRS shown in (2). Robust Minimal Recursion Semantics (RMRS) is a modified MRS representation that also allows underspecification of relational information (Copestake, 2007). The transformation process between MRS and RMRS splits off most of arguments of elementary predicates and refers to them using anchors (a). e.g., in (4), l8: _accept(e2, _, x) becomes l8:a4:_accept(e2), ARG2(a4, x). Dependency MRS (DMRS) (Copestake, 2009) is an alternative representation interconvertible with MRS or RMRS. It has minimal redundancy in its structure and was developed for the purpose of readability and ease of use for both humans and computational applications. A DMRS is a directed graph with elementary predicates as nodes. It is constructed from a RMRS representation by combin"
W15-0116,E09-1001,1,0.889159,"rs to float between the label l and handle h but we will not explain the details here. Replacing the equalities with qeq constraints in the example above underspecifies scope, giving the MRS shown in (2). Robust Minimal Recursion Semantics (RMRS) is a modified MRS representation that also allows underspecification of relational information (Copestake, 2007). The transformation process between MRS and RMRS splits off most of arguments of elementary predicates and refers to them using anchors (a). e.g., in (4), l8: _accept(e2, _, x) becomes l8:a4:_accept(e2), ARG2(a4, x). Dependency MRS (DMRS) (Copestake, 2009) is an alternative representation interconvertible with MRS or RMRS. It has minimal redundancy in its structure and was developed for the purpose of readability and ease of use for both humans and computational applications. A DMRS is a directed graph with elementary predicates as nodes. It is constructed from a RMRS representation by combining 3 subgraphs: (1) Label equality graph, connecting EPs with shared labels; (2) Handle-to-label qeq graph, connecting handles and labels; (3) Variable graph, connecting EPs with their arguments. Upon merging the three subgraphs, the redundant links are de"
W15-0116,1995.tmi-1.2,1,0.574164,"ted its performance on the Wikiwoods corpus (Flickinger et al., 2010), a large deep parsed corpus of English Wikipedia which provides a large collection of MRS representations aligned with surface realizations that are suitable for learning the realization grammar. We measure the performance of the HSSR system using BLEU and discuss its strengths and weakness using example output. The system shows promising results, with the main issues stemming from the lack of efficiency. 2 Minimal Recursion Semantics Minimal Recursion Semantics (MRS) is a framework for computational semantics introduced by Copestake et al. (1995) and formally described in Copestake et al. (2005). As discussed there, MRS is a metalanguage for describing semantic structures in some underlying object language: the object language usually discussed is predicate calculus with generalized quantifiers. MRS was designed to be a tractable representation for large-scale parsing and generation, while not sacrificing expressiveness. It provides flat semantic representations that enable underspecification and can be integrated with grammatical representation in a number of frameworks. While MRS has been used in a wide variety of grammars, we conce"
W15-0116,E14-1028,1,0.896541,"Missing"
W15-0116,D10-1055,0,0.0255589,"shortest path through the WFSA, N-shortest paths can be extracted to produce an N-best list of realizations. An N-best list of realizations can be re-ranked using various strategies to improve the performance of the realizer. The strategies include re-ranking with a stronger language model and reranking using discriminative machine learning with a larger set of features. 4 Evaluation We evaluated the HSSR approach by realizing a set of parsed MRS representations and comparing the realized surface strings against the original sentences. We use the BLEU metric for comparison of surface strings. Espinosa et al. (2010) have investigated the use of various automatic evaluation metrics to measure the quality of realization output. They have found that several standard Statistical Machine Translation evaluation metrics, including BLEU, correlate moderately well with human judgment of adequacy and fluency for the string realization task. The authors conclude that these metrics are useful for measuring incremental progress of a realization system, but advise caution when comparing different realization systems. 4.1 Experimental setup We trained and evaluated the HSSR system on a subset of the Wikiwoods corpus. T"
W15-0116,flickinger-etal-2010-wikiwoods,0,0.369996,"Missing"
W15-0116,W11-2123,0,0.0177643,"age, we performed general predicate node filtering from DMRS graphs to remove nodes that would introduce unnecessary complexity in rule extraction and decoding. On the other hand, we augmented the DMRS representations with explicit punctuation nodes and links, as the graphs otherwise do not contain information regarding punctuation. We evaluated the system using 2-gram, 3-gram, and 4-gram language models. We estimated the language models on the entire Wikiwoods corpus, consisting of 800 million words (excluding tuning and training sets). The language models were estimated using KenLM toolkit (Heafield, 2011) with interpolated modified Kneser-Ney smoothing (Chen and Goodman, 1998). Rule extraction on the training set of 1 million DMRS graph-surface string pairs produced 7.3 million realization rules. Practical limitations mentioned above apply: we extracted rules with at most 2 nonterminals, and the size of source side is at most five nodes. We tuned the log-linear model weights using simple grid search over several iterations against the BLEU evaluation metric (Papineni et al., 2002). A mature system could instead be optimized using standard tuning approaches from SMT, for example MERT (Och, 2003"
W15-0116,E14-3010,1,0.833728,"using N-gram precision measures such as BLEU for evaluating realization (and translation) output. 5 Related Work In this paper we described a first attempt at statistical realization from MRS representations using synchronous context-free grammar. In this section we discuss similar approaches to realization. One way of categorizing realization systems is according to the type of input assumed. Some authors have worked on the problem of word ordering, where the input is a bag of words, possibly combined with partial ordering information (e.g., Zhang and Clark (2011), de Gispert et al. (2014), Horvat and Byrne (2014)). Other systems take as input some form of meaning representation designed for a limited domain: such systems may be tested on the GEOQUERY corpus, for instance. Of particular relevance to us is Wong and Mooney (2007) which investigates SMT based techniques: they experiment with a phrase-based SMT method, a system that inverts an SMT-based semantic parser and a third approach which is a hybrid of these. Other systems take as input a structured representation which is intended to be flexible enough to cover general language: most such systems are associated with bidirectional approaches, and t"
W15-0116,N09-1049,0,0.0603197,"Missing"
W15-0116,D08-1076,0,0.0263776,"lated modified Kneser-Ney smoothing (Chen and Goodman, 1998). Rule extraction on the training set of 1 million DMRS graph-surface string pairs produced 7.3 million realization rules. Practical limitations mentioned above apply: we extracted rules with at most 2 nonterminals, and the size of source side is at most five nodes. We tuned the log-linear model weights using simple grid search over several iterations against the BLEU evaluation metric (Papineni et al., 2002). A mature system could instead be optimized using standard tuning approaches from SMT, for example MERT (Och, 2003) and LMERT (Macherey et al., 2008; Waite et al., 2011). The decoding times of the current system implementation can be relatively long. We enforced reasonable computation time by terminating decoding of a DMRS graph after 300 seconds. This occurred for 96/1000 examples in the test set. As BLEU significantly penalizes short or omitted output using the brevity penalty, we computed the BLEU scores only on decoded examples. The final evaluation example set is the same between all systems in order to keep the scores comparable between them. 4.2 Results and discussion We obtain the following results on decoded DMRS graphs of the te"
W15-0116,P03-1021,0,0.0106901,"ld, 2011) with interpolated modified Kneser-Ney smoothing (Chen and Goodman, 1998). Rule extraction on the training set of 1 million DMRS graph-surface string pairs produced 7.3 million realization rules. Practical limitations mentioned above apply: we extracted rules with at most 2 nonterminals, and the size of source side is at most five nodes. We tuned the log-linear model weights using simple grid search over several iterations against the BLEU evaluation metric (Papineni et al., 2002). A mature system could instead be optimized using standard tuning approaches from SMT, for example MERT (Och, 2003) and LMERT (Macherey et al., 2008; Waite et al., 2011). The decoding times of the current system implementation can be relatively long. We enforced reasonable computation time by terminating decoding of a DMRS graph after 300 seconds. This occurred for 96/1000 examples in the test set. As BLEU significantly penalizes short or omitted output using the brevity penalty, we computed the BLEU scores only on decoded examples. The final evaluation example set is the same between all systems in order to keep the scores comparable between them. 4.2 Results and discussion We obtain the following results"
W15-0116,P02-1040,0,0.0925743,"ar model over derivations D: P (D) ∝ Y θi (D)λi (2) i where θi are features defined over rules used in derivation D and λi are feature weights. We define four features to aid realization: bidirectional conditional translation probabilities P (source|target) and P (target|source), N-gram language model probability, and word insertion penalty. The bidirectional probability features are trained by performing rule extraction and using rule frequency counts to estimate the probabilities. The feature weights λi of the log-linear model are tuned using grid search over the parameter space using BLEU (Papineni et al., 2002) as the measure of performance. 3.4 Decoder The task of the decoder is to generate a string realization for a (previously unseen) MRS representation. The decoder uses a grammar estimated on a training corpus as the source of translation rules. We base the HSSR decoder on the ideas behind the HiFST hierarchical phrase-based translation system, presented in Iglesias et al. (2009). Following the description in Allauzen et al. (2014), our decoder operates in three stages: 1. Realization: The decoder constructs a Weighted Finite State Acceptor (WFSA) encoding all possible realizations under a given"
W15-0116,2005.mtsummit-papers.15,0,0.0124032,"r that is automatically extracted from a large corpus of parsed sentences. We have evaluated the new approach on the Wikiwoods corpus, where it shows promising results.1 1 Introduction Realization from Minimal Recursion Semantics (MRS) representations has traditionally used a chartbased approach governed by a resource grammar. Introduced by Carroll et al. (1999) and Carroll and Oepen (2005), the chart-based approach is lexically-driven and is able to produce a large number of candidate surface strings which may be ranked using an N-gram language model or using discriminative machine learning (Velldal and Oepen, 2005; Velldal, 2009). As the chart-based realization relies on a resource grammar, it tends to perform well when realizing from MRS representations that were created by a parser using the same resource grammar. However, the chart-based approach may fail to produce any output when the MRS representation has missing or incorrect parts. This is a significant issue for the MRS representations produced as a result of semantic transfer in semantic transfer translation systems such as LOGON (Lø nning et al., 2004) due to the difficulty of the translation problem. Consequently, the realization component i"
W15-0116,W11-2827,0,0.0187123,"is quite unlike a conventional 115 logic. The earlier work on MRS (i.e., Carroll et al. (1999) and subsequent papers listed in the introduction) used the flatness of its structure to facilitate the use of a chart generation approach, while in our work on generation from DMRS, the input is a graph. In terms of methodology, our work is perhaps closest to (Cahill and van Genabith, 2006) whose PCFG system for robust probabilistic generation is based on approximations to a LFG automatically extracted from a treebank. However, the nature of the input and the techniques employed are very different. White (2011) investigates an approach which has some similarities with ours, using MT-style glue rules for robustness in conjunction with a realizer based on CCG, but his approach is directed at patching up failed realizations. 6 Conclusions and Future Work In this paper, we presented a first attempt at statistical realization from MRS representations. The approach treats realization as a translation problem, transforming the Dependency MRS graph representation to a surface string. The HSSR approach draws inspiration from Statistical Machine Translation. We evaluated the performance of the new approach on"
W15-0116,N07-1022,0,0.0280931,"hronous context-free grammar. In this section we discuss similar approaches to realization. One way of categorizing realization systems is according to the type of input assumed. Some authors have worked on the problem of word ordering, where the input is a bag of words, possibly combined with partial ordering information (e.g., Zhang and Clark (2011), de Gispert et al. (2014), Horvat and Byrne (2014)). Other systems take as input some form of meaning representation designed for a limited domain: such systems may be tested on the GEOQUERY corpus, for instance. Of particular relevance to us is Wong and Mooney (2007) which investigates SMT based techniques: they experiment with a phrase-based SMT method, a system that inverts an SMT-based semantic parser and a third approach which is a hybrid of these. Other systems take as input a structured representation which is intended to be flexible enough to cover general language: most such systems are associated with bidirectional approaches, and they have generally been tested with representations produced by parsers or with trees from manually-annotated treebanks. For instance, a number of systems have been built that take LFG fstructures as input (Cahill and"
W15-0116,D11-1106,0,0.0145421,"le to produce. This highlights the deficiencies of using N-gram precision measures such as BLEU for evaluating realization (and translation) output. 5 Related Work In this paper we described a first attempt at statistical realization from MRS representations using synchronous context-free grammar. In this section we discuss similar approaches to realization. One way of categorizing realization systems is according to the type of input assumed. Some authors have worked on the problem of word ordering, where the input is a bag of words, possibly combined with partial ordering information (e.g., Zhang and Clark (2011), de Gispert et al. (2014), Horvat and Byrne (2014)). Other systems take as input some form of meaning representation designed for a limited domain: such systems may be tested on the GEOQUERY corpus, for instance. Of particular relevance to us is Wong and Mooney (2007) which investigates SMT based techniques: they experiment with a phrase-based SMT method, a system that inverts an SMT-based semantic parser and a third approach which is a hybrid of these. Other systems take as input a structured representation which is intended to be flexible enough to cover general language: most such systems"
W15-0116,W12-6219,0,\N,Missing
W15-0128,adolphs-etal-2008-fine,1,0.866719,"Missing"
W15-0128,P98-1013,0,0.191125,"tic representations and deploying them at scale to create a large sembank including diverse genres. Such representations can be created compositionally, where the content and internal structure of the representations is constrained by syntactic structure, or non-compositionally, where annotators encode their understanding of a sentence directly. The latter category is exemplified by Abstract Meaning Representation (AMR; Langkilde and Knight 1998; Banarescu et al. 2013). In the former category, we find both manual annotation projects, such as PropBank (Kingsbury and Palmer, 2002) and FrameNet (Baker et al., 1998), which annotate semantic information with reference to syntactic structure, and grammar-based annotation initiatives such as the Redwoods Treebank (Oepen et al., 2004), TREPIL (Rosén et al., 2005), and the Groningen Meaning Bank (Basile et al., 2012). We argue here that a grammar-based, compositional approach is critical to achieving this long-range goal, in particular because it supports more comprehensive representations (§4.1), produced with better consistency (§4.2) and greater scalability (§4.3). The drawback to a grammar-based approach is that it cannot, in itself, include information t"
W15-0128,W13-2322,0,0.651957,"emantics either for parsing or for generation. 4 Benefits of Compositionality We are concerned here with the goal of designing task-independent semantic representations and deploying them at scale to create a large sembank including diverse genres. Such representations can be created compositionally, where the content and internal structure of the representations is constrained by syntactic structure, or non-compositionally, where annotators encode their understanding of a sentence directly. The latter category is exemplified by Abstract Meaning Representation (AMR; Langkilde and Knight 1998; Banarescu et al. 2013). In the former category, we find both manual annotation projects, such as PropBank (Kingsbury and Palmer, 2002) and FrameNet (Baker et al., 1998), which annotate semantic information with reference to syntactic structure, and grammar-based annotation initiatives such as the Redwoods Treebank (Oepen et al., 2004), TREPIL (Rosén et al., 2005), and the Groningen Meaning Bank (Basile et al., 2012). We argue here that a grammar-based, compositional approach is critical to achieving this long-range goal, in particular because it supports more comprehensive representations (§4.1), produced with bett"
W15-0128,basile-etal-2012-developing,0,0.204582,"ture, or non-compositionally, where annotators encode their understanding of a sentence directly. The latter category is exemplified by Abstract Meaning Representation (AMR; Langkilde and Knight 1998; Banarescu et al. 2013). In the former category, we find both manual annotation projects, such as PropBank (Kingsbury and Palmer, 2002) and FrameNet (Baker et al., 1998), which annotate semantic information with reference to syntactic structure, and grammar-based annotation initiatives such as the Redwoods Treebank (Oepen et al., 2004), TREPIL (Rosén et al., 2005), and the Groningen Meaning Bank (Basile et al., 2012). We argue here that a grammar-based, compositional approach is critical to achieving this long-range goal, in particular because it supports more comprehensive representations (§4.1), produced with better consistency (§4.2) and greater scalability (§4.3). The drawback to a grammar-based approach is that it cannot, in itself, include information that is not compositional, but as we will develop further in §6 below, it is possible to have the best of both worlds, adding non-compositional information as additional annotation layers over grammar-produced semantic representations. 4.1 Comprehensiv"
W15-0128,P11-1059,0,0.0201877,"ication, rather than a strong claim about lexical meaning. Another kind of non-compositional meaning layer is that which requires some sort of further computation over linguistic structure. This can be seen as purely monotonic addition of further constraints on underspecified meaning representations, but it is not compositional in the sense that it is never (strictly) constrained by grammatical structure. In this category, we find quantifier scope ambiguity resolution (e.g. Higgins and Sadock 2003), coreference resolution (e.g. Hobbs 1979), and the determination of the focus of negation (e.g. Blanco and Moldovan 2011). All of these build on partial constraints provided by the grammar, but in all cases, the interpretation of particular sentences in context will correspond to one (or a subset) of the possibilities allowed by the grammar. The next layer of meaning annotation to consider corresponds to discourse processing. This includes the calculation of presupposition projection (e.g. Van der Sandt 1992; Zaenen and Karttunen 2013; Venhuizen et al. 2013), coherence relations/rhetorical structure (e.g. Marcu 1997), and the annotation of discourse moves/adjacency pairs (Shriberg et al., 2004). These aspects of"
W15-0128,W97-1502,0,0.546635,"ee and ERS for each of these sentences are made available as the Redwoods Treebank; at the end of 2014, the current version of Redwoods encompasses gold-standard ERG analyses for 85,000 utterances (∼1.5 million tokens) of running text from half a dozen different genres and domains. In more detail, the task of annotation for a sentence consists of making binary decisions about the set of discriminants each of which partitions the parse forest into two: all of the analyses which employ the particular rule or lexical entry, and the rest of the analyses which do not. This method, originating with Carter 1997, enables the human annotator to rapidly discard analyses in order to isolate the intended analysis, or to conclude that the correct analysis is unavailable. As a reference point for speed of annotation using this method, an expert treebanker using the current ‘1214’ version of the ERG annotated 2400 sentences (37,200 words) from the Brown corpus in 1400 minutes, for an average rate of 1.7 sentences per minute.3 Annotations produced by this method of choosing among the candidate analyses licensed by a grammar will thus record those components of sentence meaning which are constrained by the gr"
W15-0128,P01-1019,1,0.580225,"nnotation. As Szabó (2013) points out, there are many different interpretations of the principle of compositionality in the literature. Since we are concerned with annotation, the issue is compositionality of meaning representations (rather than denotation, for instance). In order to ask which aspects of meaning are compositional, we provide the following working definition:1 1 In Szabó’s terms, our definition of compositionality is local, distributive, and language-bound and furthermore consistent with the rule-to-rule principle. It is also consistent with the notion of compositionality from Copestake et al. (2001) and implemented in the ERG, which furthermore adds the constraint that the function for determining meanings of complex expressions must be monotonic in the sense that it cannot remove or overwrite any information contributed by the constituents. 240 (1) A meaning system (or subsystem) is compositional if: • it consists of a finite (but possibly very large) number of arbitrary atomic symbol-meaning pairings; • it is possible to create larger symbol-meaning pairings by combining the atomic pairings through a finite set of rules; • the meaning of any non-atomic symbol-meaning pairing is a funct"
W15-0128,W11-2927,1,0.716728,"Missing"
W15-0128,flickinger-etal-2010-wikiwoods,1,0.898233,"Missing"
W15-0128,P82-1014,0,0.754755,"fits. We then report on a small inter-annotator agreement study to quantify the consistency of semantic representations produced via this grammar-based method. 1 Introduction Kate and Wong (2010) define ‘semantic parsing’ as “the task of mapping natural language sentences into complete formal meaning representations which a computer can execute for some domain-specific application.” At this level of generality, semantic parsing has been a cornerstone of NLU from its early days, including work seeking to support dialogue systems, database interfaces, or machine translation (Woods et al., 1972; Gawron et al., 1982; Alshawi, 1992, inter alios). What distinguishes most current work in semantic parsing from such earlier landmarks of old-school NLU is (a) the use of (highly) taskand domain-specific meaning representations (e.g. the RoboCup or GeoQuery formal language) and (b) a lack of emphasis on natural language syntax, i.e. a tacit expectation to map (more or less) directly from a linguistic surface form to an abstract representation of its meaning. This approach risks conflating a distinction that has long played an important role in the philosophy of language and theoretical linguistics (Quine, 1960;"
W15-0128,J03-1004,0,0.0864457,"Missing"
W15-0128,W07-1501,0,0.0215267,"entions. Some of the information we would like to see in such annotations is grammatically constrained, and we have argued that representations of those aspects of meaning are best built compositionally. However, there are further aspects of meaning which are closely tied to the linguistic signal but are not constrained by sentencelevel grammar (or only partially so constrained). We agree here with Basile et al. (2012) and Banarescu et al. (2013) that a single resource that combines multiple different types of semantic annotations, all applied to the same text, will be most valuable (see also Ide and Suderman 2007). However, just because some aspects of the desired representations cannot be created in a grammar-based fashion does not mean that what can be done with a grammar has no value. To get the best of both worlds, one should start from grammar-derived semantic annotations and then either add further layers of annotation (e.g. word sense, coreference) or, should larger paraphrase sets be desired, systematically simplify aspects of the grammar-derived representations, effectively ‘bleaching’ some of the contrasts. In moving from the current state of the art towards more comprehensive representations"
W15-0128,P10-5006,0,0.0583505,"al itself. We further argue that compositional construction of such sentence meaning representations affords better consistency, more comprehensiveness, greater scalability, and less duplication of effort for each new NLP application. For concreteness, we describe one well-tested grammar-based method for producing sentence meaning representations which is efficient for annotators, and which exhibits many of the above benefits. We then report on a small inter-annotator agreement study to quantify the consistency of semantic representations produced via this grammar-based method. 1 Introduction Kate and Wong (2010) define ‘semantic parsing’ as “the task of mapping natural language sentences into complete formal meaning representations which a computer can execute for some domain-specific application.” At this level of generality, semantic parsing has been a cornerstone of NLU from its early days, including work seeking to support dialogue systems, database interfaces, or machine translation (Woods et al., 1972; Gawron et al., 1982; Alshawi, 1992, inter alios). What distinguishes most current work in semantic parsing from such earlier landmarks of old-school NLU is (a) the use of (highly) taskand domain-"
W15-0128,kingsbury-palmer-2002-treebank,0,0.223431,"e goal of designing task-independent semantic representations and deploying them at scale to create a large sembank including diverse genres. Such representations can be created compositionally, where the content and internal structure of the representations is constrained by syntactic structure, or non-compositionally, where annotators encode their understanding of a sentence directly. The latter category is exemplified by Abstract Meaning Representation (AMR; Langkilde and Knight 1998; Banarescu et al. 2013). In the former category, we find both manual annotation projects, such as PropBank (Kingsbury and Palmer, 2002) and FrameNet (Baker et al., 1998), which annotate semantic information with reference to syntactic structure, and grammar-based annotation initiatives such as the Redwoods Treebank (Oepen et al., 2004), TREPIL (Rosén et al., 2005), and the Groningen Meaning Bank (Basile et al., 2012). We argue here that a grammar-based, compositional approach is critical to achieving this long-range goal, in particular because it supports more comprehensive representations (§4.1), produced with better consistency (§4.2) and greater scalability (§4.3). The drawback to a grammar-based approach is that it cannot"
W15-0128,P98-1116,0,0.0854027,"equire the computation of semantics either for parsing or for generation. 4 Benefits of Compositionality We are concerned here with the goal of designing task-independent semantic representations and deploying them at scale to create a large sembank including diverse genres. Such representations can be created compositionally, where the content and internal structure of the representations is constrained by syntactic structure, or non-compositionally, where annotators encode their understanding of a sentence directly. The latter category is exemplified by Abstract Meaning Representation (AMR; Langkilde and Knight 1998; Banarescu et al. 2013). In the former category, we find both manual annotation projects, such as PropBank (Kingsbury and Palmer, 2002) and FrameNet (Baker et al., 1998), which annotate semantic information with reference to syntactic structure, and grammar-based annotation initiatives such as the Redwoods Treebank (Oepen et al., 2004), TREPIL (Rosén et al., 2005), and the Groningen Meaning Bank (Basile et al., 2012). We argue here that a grammar-based, compositional approach is critical to achieving this long-range goal, in particular because it supports more comprehensive representations (§"
W15-0128,I11-1028,1,0.818925,"to abstract away from task-irrelevant details of linguistic expression, task-independent representations only have that luxury when the variation is truly (sentence) meaning preserving. A task-independent semantic representation should capture exactly the meaning encoded in the linguistic signal itself, as it is is not possible to know, a priori, which parts of that sentence meaning will be critical to determining speaker meaning in any given application. 3 This rate is roughly consistent with an earlier experiment using the same Redwoods treebanking method where annotation times were noted: MacKinlay et al. (2011) report a somewhat slower mean annotation time by an expert annotator of 0.6 sentences per minute, but this difference can be attributed to the greater average sentence length (and hence increased number of discriminants to be determined) for that biomedical corpus: 23.4 tokens compared with 15.5 for the Brown data. 243 h h1 , h h1 , h4 :personh0 : 6i(ARG0 x 5 ), h6 :_no_qh0 : 6i(ARG0 x 5 , RSTR h7 , BODY h8 ), h2 :_eat_v_1h7 : 11i(ARG0 e3 , ARG1 x 5 , ARG2 i 9 ) { h1 =q h2 , h7 =q h4 } i h4 :_every_qh0 : 5i(ARG0 x 6 , RSTR h7 , BODY h5 ), h8 :_person_n_1h6 : 12i(ARG0 x 6 ), h2 :_fail_v_1h13 :"
W15-0128,P97-1013,0,0.0300129,"resolution (e.g. Hobbs 1979), and the determination of the focus of negation (e.g. Blanco and Moldovan 2011). All of these build on partial constraints provided by the grammar, but in all cases, the interpretation of particular sentences in context will correspond to one (or a subset) of the possibilities allowed by the grammar. The next layer of meaning annotation to consider corresponds to discourse processing. This includes the calculation of presupposition projection (e.g. Van der Sandt 1992; Zaenen and Karttunen 2013; Venhuizen et al. 2013), coherence relations/rhetorical structure (e.g. Marcu 1997), and the annotation of discourse moves/adjacency pairs (Shriberg et al., 2004). These aspects of meaning clearly build on information provided during sentence-level processing, including lexically determined veridicality contexts (e.g. (2a) vs. (2b)) as well as discourse connectives. In both cases, the grammatical structure links embedded clauses to the relevant lexical predicates. 2 We assume here that word sense is a property of roots, rather than fully inflected forms. Productive derivational morphology supports compositionally built-up meanings for morphologically complex words. Semi-prod"
W15-0128,J94-1007,0,0.713929,"act representation of its meaning. This approach risks conflating a distinction that has long played an important role in the philosophy of language and theoretical linguistics (Quine, 1960; Grice, 1968), viz. the contrast between those aspects of meaning that are determined by the linguistic signal alone (called ‘timeless’, ‘conventional’, ‘standing’, or ‘sentence’ meaning), on the one hand, and aspects of meaning that are particular to a context of use (‘utterer’, ‘speaker’, or ‘occasion’ meaning, or ‘interpretation’), on the other hand. Relating this tradition to computational linguistics, Nerbonne (1994, p. 134) notes: Linguistic semantics does not furnish a characterization of the interpretation of utterances in use, which is what one finally needs for natural language understanding applications—rather, it (mostly) provides a characterization of conventional content, that part of meaning determined by linguistic form. Interpretation is not determined by 239 Proceedings of the 11th International Conference on Computational Semantics, pages 239–249, c London, UK, April 15-17 2015. 2015 Association for Computational Linguistics form, however, nor by its derivative content. In order to interpre"
W15-0128,oepen-lonning-2006-discriminant,1,0.897769,"Missing"
W15-0128,W04-2319,0,0.0143789,"negation (e.g. Blanco and Moldovan 2011). All of these build on partial constraints provided by the grammar, but in all cases, the interpretation of particular sentences in context will correspond to one (or a subset) of the possibilities allowed by the grammar. The next layer of meaning annotation to consider corresponds to discourse processing. This includes the calculation of presupposition projection (e.g. Van der Sandt 1992; Zaenen and Karttunen 2013; Venhuizen et al. 2013), coherence relations/rhetorical structure (e.g. Marcu 1997), and the annotation of discourse moves/adjacency pairs (Shriberg et al., 2004). These aspects of meaning clearly build on information provided during sentence-level processing, including lexically determined veridicality contexts (e.g. (2a) vs. (2b)) as well as discourse connectives. In both cases, the grammatical structure links embedded clauses to the relevant lexical predicates. 2 We assume here that word sense is a property of roots, rather than fully inflected forms. Productive derivational morphology supports compositionally built-up meanings for morphologically complex words. Semi-productive morphological processes and frozen or lexicalized complex forms complica"
W15-0128,W13-0122,0,0.0367255,"scope ambiguity resolution (e.g. Higgins and Sadock 2003), coreference resolution (e.g. Hobbs 1979), and the determination of the focus of negation (e.g. Blanco and Moldovan 2011). All of these build on partial constraints provided by the grammar, but in all cases, the interpretation of particular sentences in context will correspond to one (or a subset) of the possibilities allowed by the grammar. The next layer of meaning annotation to consider corresponds to discourse processing. This includes the calculation of presupposition projection (e.g. Van der Sandt 1992; Zaenen and Karttunen 2013; Venhuizen et al. 2013), coherence relations/rhetorical structure (e.g. Marcu 1997), and the annotation of discourse moves/adjacency pairs (Shriberg et al., 2004). These aspects of meaning clearly build on information provided during sentence-level processing, including lexically determined veridicality contexts (e.g. (2a) vs. (2b)) as well as discourse connectives. In both cases, the grammatical structure links embedded clauses to the relevant lexical predicates. 2 We assume here that word sense is a property of roots, rather than fully inflected forms. Productive derivational morphology supports compositionally bu"
W15-0128,W08-0606,0,0.0207628,"As this level of processing concerns relationships both within and across sentences, it is clearly not compositional with respect to sentence grammar. We consider it an open question whether there are compositional processes at higher levels of structure that constrain these aspects of meaning in analogous ways, but we note that in presupposition processing at least, a notion of defeasibility is required (Asher and Lascarides, 2011). Finally, there are semantic annotations that attempt to capture what speakers are trying to do with their speech acts. This includes tasks like hedge detection (Vincze et al., 2008) and the annotation of social acts such as authority claims and alignment moves (Morgan et al., 2013) or the pursuit of power in dialogue (Swayamdipta and Rambow, 2012). While in some cases there are keywords that have a strong association with particular categories in these annotation schemes, these aspects of meaning are clearly not anchored in the structure of sentences but rather relate to the goals that speakers have in uttering sentences. Lacking a firm link to the structure of sentences, they do not appear to be compositional. We have seen in this (necessarily brief) section that existi"
W15-0128,W13-0505,0,0.01847,"tegory, we find quantifier scope ambiguity resolution (e.g. Higgins and Sadock 2003), coreference resolution (e.g. Hobbs 1979), and the determination of the focus of negation (e.g. Blanco and Moldovan 2011). All of these build on partial constraints provided by the grammar, but in all cases, the interpretation of particular sentences in context will correspond to one (or a subset) of the possibilities allowed by the grammar. The next layer of meaning annotation to consider corresponds to discourse processing. This includes the calculation of presupposition projection (e.g. Van der Sandt 1992; Zaenen and Karttunen 2013; Venhuizen et al. 2013), coherence relations/rhetorical structure (e.g. Marcu 1997), and the annotation of discourse moves/adjacency pairs (Shriberg et al., 2004). These aspects of meaning clearly build on information provided during sentence-level processing, including lexically determined veridicality contexts (e.g. (2a) vs. (2b)) as well as discourse connectives. In both cases, the grammatical structure links embedded clauses to the relevant lexical predicates. 2 We assume here that word sense is a property of roots, rather than fully inflected forms. Productive derivational morphology sup"
W15-0128,C98-1112,0,\N,Missing
W15-0128,C98-1013,0,\N,Missing
W16-1605,L16-1197,1,0.792283,"Missing"
W16-1605,P15-1144,0,0.0856854,"(4) Given the semantic functions, choosing a predicate for a entity can be hard-coded, for simplicity. The probability of choosing a predicate c for an entity x is weighted by the predicate’s frequency fc and the value of its semantic function tc (x) (how true the predicate is of the entity), as shown in (6)-(7). This is a mean field approximation to the stochastic truth values shown in figure 3. (1) bi xi 1 1 + exp (E p ) (3) x(n) Furthermore, since sparse representations have been shown to be beneficial in NLP, both for applications and for interpretability of features (Murphy et al., 2012; Faruqui et al., 2015), we can enforce sparsity in these entity vectors by fixing a specific number of units to be active at any time. Swersky et al. (2012) introduce this RBM variant as the Cardinality RBM, and also give an efficient exact sampling procedure using belief propagation. Since we are using sparse representations, we also assume that all link weights are non-negative. Now that we’ve defined the background distribution over situations, we turn to the semantic functions tc , which map entities x to probabilities. We implement these as feedforward networks, as shown in (4)-(5). For simplicity, we do not i"
W16-1605,J15-4004,0,0.0878081,"nd Initial Experiments 4.2 In this section, we report the first experiments carried out within our framework. 4.1 No. instances 10,091,234 6,301,280 14,868,213 31,260,727 Evaluation As our first attempt at evaluation, we chose to look at two lexical similarity datasets. The aim of this evaluation was simply to verify that the model was learning something reasonable. We did not expect this task to illustrate our model’s strengths, since we need richer tasks to exploit its full expressiveness. Both of our chosen datasets aim to evaluate similarity, rather than thematic relatedness: the first is Hill et al. (2015)’s SimLex-999 dataset, and the second is Finkelstein et al. (2001)’s WordSim353 dataset, which was split by Agirre et al. (2009) into similarity and relatedness subsets. So far, we have not tuned hyperparameters. Results are given in table 2. We also trained Mikolov et al. (2013)’s Word2Vec model on the SVO data described in section 4.1, in order to give a direct comparison of models on the same training data. In particular, we used the continuous bag-of-words model with negative sampling, ˇ uˇrek and Sojka (2010)’s as implemented in Reh˚ gensim package, with off-the-shelf hyperparameter setti"
W16-1605,P14-2050,0,0.250388,"of predicates by treating truth values as random variables,1 Current approaches to distributional semantics generally involve representing words as points in a high-dimensional vector space. However, vectors do not provide ‘natural’ composition operations that have clear analogues with operations in formal semantics, which makes it challenging to perform inference, or capture various aspects of meaning studied by semanticists. This is true whether the vectors are constructed using a count approach (e.g. Turney and Pantel, 2010) or an embedding approach (e.g. Mikolov et al., 2013), and indeed Levy and Goldberg (2014b) showed that there are close links between them. Even the tensorial approach described by Coecke et al. (2010) and Baroni et al. (2014), which naturally captures argument structure, does not allow an obvious account of context dependence, or logical inference. In this paper, we build on insights drawn from formal semantics, and seek to learn representa1 The move to replace absolute truth values with probabilities has parallels in much computational work based on formal logic. For example, Garrette et al. (2011) incorporate distributional information in a Markov Logic Network (Richardson and"
W16-1605,W11-0112,0,0.157897,"d Pantel, 2010) or an embedding approach (e.g. Mikolov et al., 2013), and indeed Levy and Goldberg (2014b) showed that there are close links between them. Even the tensorial approach described by Coecke et al. (2010) and Baroni et al. (2014), which naturally captures argument structure, does not allow an obvious account of context dependence, or logical inference. In this paper, we build on insights drawn from formal semantics, and seek to learn representa1 The move to replace absolute truth values with probabilities has parallels in much computational work based on formal logic. For example, Garrette et al. (2011) incorporate distributional information in a Markov Logic Network (Richardson and Domingos, 2006). However, while their approach allows probabilistic inference, they rely on existing distributional vectors, and convert similarity scores to weighted logical formulae. Instead, we aim to learn representations which are directly interpretable within in a probabilistic logic. 40 Proceedings of the 1st Workshop on Representation Learning for NLP, pages 40–52, c Berlin, Germany, August 11th, 2016. 2016 Association for Computational Linguistics 1 0 Figure 1: Comparison between a semantic function and"
W16-1605,S13-1001,0,0.289362,"sent these varied relationships on a single scale of similarity. For example, it could be sensible to treat aunt and uncle either as synonyms (they refer to relatives of the same degree of relatedness) or as antonyms (they are “opposite” in some sense). Which view is more appropriate will depend on the application, or on the context. 5 Related Work As mentioned above, Coecke et al. (2010) and Baroni et al. (2014) introduce a tensor-based framework that incorporates argument structure through tensor contraction. However, for logical inference, we need to know how one vector can entail another. Grefenstette (2013) explores one method to do this; however, they do not show that this approach is learnable from distributional information, and furthermore, they prove that quantifiers cannot be expressed with tensors. Balkır (2014), working in the tensorial framework, uses the quantum mechanical notion of a “mixed state” to model uncertainty. However, this doubles the number of tensor indices, so squares the number of dimensions (e.g. vectors become matrices). In the original framework, expressions with several arguments already have a high dimensionality (e.g. whose is represented by a fifth-order tensor),"
W16-1605,Q15-1008,0,0.0784369,"from section 2.1, P (x|t). However, the opposite conditional probability, P (t|x), more easily allows composition. For instance, if we know two predicates are true (t1 and t2 ), we cannot easily combine P (x|t1 ) and P (x|t2 ) to get P (x|t1 , t2 ) – intuitively, we’re generating x twice. In contrast, for semantic functions, we can write P (t1 , t2 |x) = P (t1 |x)P (t2 |x). G¨ardenfors (2004) argues concepts should be modelled as convex subsets of a semantic space. Erk (2009) builds on this idea, but their model requires pre-trained count vectors, while we learn our representations directly. McMahan and Stone (2015) also learn representations directly, considering colour terms, which are grounded in a wellunderstood perceptual space. Instead of considering a single subset, they use a probability distribution over subsets: P (A|t) for A ⊂ X . This is more general than a semantic P function P (t|x), since we can write P (t|x) = A3v P (A|t). However, this framework may be too general, since it means we cannot determine the truth of a predicate until we know the entire set A. To avoid this issue, they factorise the distribution, by assuming different boundaries of the set are independent. However, this is eq"
W16-1605,C12-1118,0,0.027948,"θ (2) (n) xi − b0(c) (4) Given the semantic functions, choosing a predicate for a entity can be hard-coded, for simplicity. The probability of choosing a predicate c for an entity x is weighted by the predicate’s frequency fc and the value of its semantic function tc (x) (how true the predicate is of the entity), as shown in (6)-(7). This is a mean field approximation to the stochastic truth values shown in figure 3. (1) bi xi 1 1 + exp (E p ) (3) x(n) Furthermore, since sparse representations have been shown to be beneficial in NLP, both for applications and for interpretability of features (Murphy et al., 2012; Faruqui et al., 2015), we can enforce sparsity in these entity vectors by fixing a specific number of units to be active at any time. Swersky et al. (2012) introduce this RBM variant as the Cardinality RBM, and also give an efficient exact sampling procedure using belief propagation. Since we are using sparse representations, we also assume that all link weights are non-negative. Now that we’ve defined the background distribution over situations, we turn to the semantic functions tc , which map entities x to probabilities. We implement these as feedforward networks, as shown in (4)-(5). For"
W16-1605,P10-1045,0,0.0295043,"Missing"
W16-1605,N12-1076,0,\N,Missing
W16-1605,flickinger-etal-2010-wikiwoods,0,\N,Missing
W16-1605,D08-1094,0,\N,Missing
W16-1605,W09-1109,0,\N,Missing
W16-1605,N09-1003,0,\N,Missing
W16-1605,2014.lilt-9.5,0,\N,Missing
W16-1605,I11-1127,0,\N,Missing
W16-1605,J16-4007,0,\N,Missing
W17-3533,L16-1197,1,0.901137,"Missing"
W17-3533,E09-1001,1,0.749219,"antic representations present a challenge to generators. In the worst-case scenario chart generation has exponential complexity with respect to the size of the representation, although the algorithm can be modified to improve the performance (Carroll et al., 1999; White, 2004). In this paper we propose chunking (Muszy´nska, 2016) as a way to reduce memory and time cost of realization. The general idea of chunking is that strings and semantic representations can be divided DELPH-IN framework The semantic representation we use in our experiments is Dependency Minimal Recursion Semantics (DMRS) (Copestake, 2009), developed as part of the DELPH-IN initiative1 , together with several widecoverage HPSG-based grammars, notably the English Resource Grammar (ERG) (Flickinger, 2000; Flickinger et al., 2014). The ERG is a broadcoverage, symbolic, bidirectional grammar of English. The DELPH-IN realization systems have been used successfully in a number of applications, such as question generation (Yao et al., 2012), paraphrasing logic forms for teaching purposes (Flickinger, 2016) and abstractive summarisation (Fang et al., 2016). An example of a DMRS graph is shown in Fig. 1. Nodes correspond to predicates,"
W17-3533,C16-1055,1,0.888899,"Missing"
W17-3533,flickinger-etal-2014-towards,0,0.0134708,"the algorithm can be modified to improve the performance (Carroll et al., 1999; White, 2004). In this paper we propose chunking (Muszy´nska, 2016) as a way to reduce memory and time cost of realization. The general idea of chunking is that strings and semantic representations can be divided DELPH-IN framework The semantic representation we use in our experiments is Dependency Minimal Recursion Semantics (DMRS) (Copestake, 2009), developed as part of the DELPH-IN initiative1 , together with several widecoverage HPSG-based grammars, notably the English Resource Grammar (ERG) (Flickinger, 2000; Flickinger et al., 2014). The ERG is a broadcoverage, symbolic, bidirectional grammar of English. The DELPH-IN realization systems have been used successfully in a number of applications, such as question generation (Yao et al., 2012), paraphrasing logic forms for teaching purposes (Flickinger, 2016) and abstractive summarisation (Fang et al., 2016). An example of a DMRS graph is shown in Fig. 1. Nodes correspond to predicates, edges (links) represent relations between them. It is inter-convertible 1 Deep Linguistic delph-in.net Processing with HPSG, 218 Proceedings of The 10th International Natural Language Generati"
W17-3533,P16-3014,1,0.878516,"Missing"
W17-6806,N09-1003,0,0.191976,"Missing"
W17-6806,2014.lilt-9.5,0,0.106584,"nt neural network, which processes text one token at a time, updating a hidden state vector at each token. The final hidden state can be seen as a representation of the whole sequence. However, the state cannot be directly compared to the word vectors – indeed, they may have different numbers of dimensions. Other architectures have been proposed, aiming to use syntactic structure, such as recursive neural networks (Socher et al., 2010). However, this still does not use semantic structure – for example, there is no connection between active and passive voice sentences. Coecke et al. (2010) and Baroni et al. (2014) introduce a tensor-based approach, where words are represented not just by vectors, but also by higher-order tensors, which combine according to argument structure: nouns are vectors, intransitive verbs are matrices (mapping noun vectors to sentence vectors), transitive verbs are third-order tensors (mapping pairs of noun vectors to sentence vectors), and so on. However, Grefenstette (2013) showed that quantifiers cannot be expressed in this framework. Furthermore, in all the above methods, it is unclear how to perform inference, While we can use the representations as input features for anot"
W17-6806,J16-4007,0,0.0444234,"e (2013) showed that quantifiers cannot be expressed in this framework. Furthermore, in all the above methods, it is unclear how to perform inference, While we can use the representations as input features for another system, they do not have an inherent logical interpretation. Balkir et al. (2016) extend the tensor-based framework to allow inference, but rely on existing vectors, and must assume the dimensions have logical interpretations. Lewis and Steedman (2013) use distributional information to cluster predicates, but this leaves no graded notion of similarity. Garrette et al. (2011) and Beltagy et al. (2016) incorporate a vector space model into a Markov Logic Network, in the form of weighted inference rules (the truth of one predicate implying the truth of another). However, this assumes we can interpret similarity in terms of inference (a position defended by Erk (2016)), and requires existing vectors, rather than directly learning logical representations from distributional data. Many proposals exist for contextualising vectors. Erk and Pad´o (2008) and Thater et al. (2011) modify a vector according to syntactic dependencies. However, by proposing new operations, they make assumptions about th"
W17-6806,2015.lilt-10.4,0,0.17341,"ecific vector, by combining the most similar contexts in a corpus. However, this reduces the amount of training data. Lui et al. (2012)’s “per-lemma” model uses Latent Dirichlet Allocation to model contextual meaning as a mixture of senses, but this requires training a separate LDA model for each word. Furthermore, all of these methods focus on a specific kind of context, making it nontrivial to generalise them to arbitrary contexts. Our notion of probabilistic truth values is similar to the Austinian truth values in the framework of probabilistic Type Theory with Records (TTR) (Cooper, 2005; Cooper et al., 2015). Sutton (2015, 2017) takes a similar probabilistic approach to truth values to deal with philosophical problems concerning gradable predicates. Our stochastic generation of situations is also similar to the approach taken by Goodman and Lassiter (2015), who represent semantics with the stochastic lambda calculus, using handwritten probabilistic models to show how semantics and world knowledge can interact. While these approaches are in principle compatible with our work, they do not provide an approach to distributional semantics. We use Minimal Recursion Semantics (Copestake et al., 2005), a"
W17-6806,E09-1001,1,0.892307,"nal Semantics as Model-Theoretic Semantics Now we have described the above probabilistic generalisation of a model structure, we explain how Functional Distributional Semantics can be seen as implementing such a generalised model structure. E&C define a probabilistic graphical model to generate semantic dependency graphs like that in Fig. 1. The aim is to train the model in an unsupervised2 way on a parsed corpus – that is, to optimise the model parameters to maximise the probability of generating the dependency graphs in the corpus. Furthermore, Dependency Minimal Recursion Semantics (DMRS) (Copestake, 2009) allows a logical 1 We could add an ‘ID’ feature to distinguish otherwise identical individuals, but will not take this approach here. Following Ghahramani (2004), supervised learning requires both inputs and outputs, while unsupervised learning requires only inputs. The annotations in our training corpus are not desired outputs, so learning is unsupervised in this sense. 2 interpretation of the dependency graphs: each node represents a predicate, and the ARG links represent argument structure. The graphical model in Fig. 2 generates dependency graphs corresponding to transitive sentences – th"
W17-6806,L16-1197,1,0.905041,"Missing"
W17-6806,W16-1605,1,0.785815,"utationally efficient measure of similarity, in the form of cosine similarity. However, even if we can train models that produce good similarity scores, a vector space does not provide natural operations for other aspects of meaning. How can vectors be composed to form semantic representations for larger phrases? Can we say that one vector implies another? How do we capture how meanings vary according to context? An overview of existing approaches to these questions is given in §2, but these issues do not have clear solutions. In contrast, the framework of Functional Distributional Semantics (Emerson and Copestake, 2016) (henceforth E&C) aims to overcome such issues, not by extending a vector space model, but by learning a different kind of representation. Each predicate is represented not by a vector, but by a function, which forms part of a probabilistic graphical model. In §3, we build on the description given by E&C, and explain how this graphical model can in fact be viewed as encapsulating a probabilistic version of model theory. With this connection, we can naturally transfer concepts in formal semantics to this probabilistic framework, and we culminate in §3.5 by showing how generalised quantifiers ca"
W17-6806,D08-1094,0,0.101128,"Missing"
W17-6806,P10-2017,0,0.0794849,"Missing"
W17-6806,flickinger-etal-2014-towards,0,0.0199213,". 4 More generally, we may have a set of predicates and quantified expressions. In this case, we can condition on all truth values in the set. We consider a single random truth value, for ease of exposition. 5 This account does not cover cardinal quantifiers. However, the English Resource Grammar (ERG) represents numbers not as quantifiers, but as additional predicates. This is compatible with Link (2002)’s lattice-theoretic approach, which allows reference to plural individuals without quantification. For more information on the semantic analyses in the ERG, see the documentation produced by Flickinger et al. (2014), which is available here: http://www.delph-in.net/esd 4 From Conditional Dependence to Context Dependence In the previous section, we saw how a model structure can be generalised using probability distributions. In this section, we show how this approach allows us to capture context-dependent meanings using conditional probabilities, in a natural way. 4.1 Occasion Meaning versus Standing Meaning When discussing context dependence (a challenge for both formal semantics and vector-based semantics), it is helpful to distinguish two kinds of meaning, following Quine (1960): standing meaning refer"
W17-6806,flickinger-etal-2010-wikiwoods,0,0.0395071,"all pixies in the situation, so we first find the joint mean field distribution for all pixies, and then apply the semantic function for gardener to the mean field vector for the person pixie. Note how the contextdependent meaning of person (the mean field vector) is crucial to this calculation – although we are only applying applying the gardener function to the person vector, this vector depends on all predicates in the context. 5 Experimental Results We trained our model using WikiWoods7 , a corpus providing DMRS graphs for 55m sentences of English (900m tokens). WikiWoods was produced by Flickinger et al. (2010) and Solberg (2012) from the July 2008 dump of the full English Wikipedia, using the English Resource Grammar (Flickinger, 2000, 2011) and the PET parser (Callmeier, 2001; Toutanova et al., 2005), with parse ranking trained on the manually treebanked subcorpus WeScience (Ytrestøl et al., 2009). It is distributed by DELPH-IN. We extracted SVO triples (in a slight abuse of terminology), by which we mean DMRS subgraphs comprising a verbal predicate and nominal ARG 1 and/or ARG 2, discarding pronouns and named entities. This gives 10m full SVO triples, and a further 21m where one of the two argume"
W17-6806,W11-0112,0,0.0262039,"so on. However, Grefenstette (2013) showed that quantifiers cannot be expressed in this framework. Furthermore, in all the above methods, it is unclear how to perform inference, While we can use the representations as input features for another system, they do not have an inherent logical interpretation. Balkir et al. (2016) extend the tensor-based framework to allow inference, but rely on existing vectors, and must assume the dimensions have logical interpretations. Lewis and Steedman (2013) use distributional information to cluster predicates, but this leaves no graded notion of similarity. Garrette et al. (2011) and Beltagy et al. (2016) incorporate a vector space model into a Markov Logic Network, in the form of weighted inference rules (the truth of one predicate implying the truth of another). However, this assumes we can interpret similarity in terms of inference (a position defended by Erk (2016)), and requires existing vectors, rather than directly learning logical representations from distributional data. Many proposals exist for contextualising vectors. Erk and Pad´o (2008) and Thater et al. (2011) modify a vector according to syntactic dependencies. However, by proposing new operations, they"
W17-6806,D16-1235,0,0.0741908,"Missing"
W17-6806,S13-1001,0,0.380404,"ursive neural networks (Socher et al., 2010). However, this still does not use semantic structure – for example, there is no connection between active and passive voice sentences. Coecke et al. (2010) and Baroni et al. (2014) introduce a tensor-based approach, where words are represented not just by vectors, but also by higher-order tensors, which combine according to argument structure: nouns are vectors, intransitive verbs are matrices (mapping noun vectors to sentence vectors), transitive verbs are third-order tensors (mapping pairs of noun vectors to sentence vectors), and so on. However, Grefenstette (2013) showed that quantifiers cannot be expressed in this framework. Furthermore, in all the above methods, it is unclear how to perform inference, While we can use the representations as input features for another system, they do not have an inherent logical interpretation. Balkir et al. (2016) extend the tensor-based framework to allow inference, but rely on existing vectors, and must assume the dimensions have logical interpretations. Lewis and Steedman (2013) use distributional information to cluster predicates, but this leaves no graded notion of similarity. Garrette et al. (2011) and Beltagy"
W17-6806,W13-0112,0,0.0215801,"s. For each triple, we calculated the mean field vector for the verb, conditioned on all three predicates. We then calculated the probability that the other verb’s predicate is true of this mean field vector, similarly to Fig. 4b (the only difference being that we are interested in pixie y, not pixie x). To get a symmetric score, we multiplied the probabilities in both directions. Results are given in the “GS2011” column of Table 2. The performance of our model (.25) matches the best model Grefenstette and Sadrzadeh consider. The performance of our ensemble (.32) matches the improved model of Grefenstette et al. (2013), despite using less training data. Furthermore, the fact that the ensemble outperforms both the semantic function model and the vector space model shows that the two models have learnt different kinds of information. This is not simply due to the combined model having a larger capacity – increasing the size of the individual models did not give this improvement. 5.3 Composition of Relative Clauses The RELPRON dataset was produced by Rimell et al. (2016). It consists of a set of ‘terms’, each paired with up to ten ‘properties’. Each property is a short phrase, consisting of a hypernym of the t"
W17-6806,D11-1129,0,0.345546,", we can naturally transfer concepts in formal semantics to this probabilistic framework, and we culminate in §3.5 by showing how generalised quantifiers can be interpreted in our probabilistic model. In §4, we look at how to naturally derive context-dependent representations, and further, how these representations can be used for certain kinds of inference and semantic composition. In §5, we turn to using the model in practice, and evaluate on three tasks. Firstly, we look at lexical similarity, to show it is competitive with vector-based models. Secondly, we consider the dataset produced by Grefenstette and Sadrzadeh (2011), which measures the similarity of verbs in the context of a specific subject and object. Finally, we consider the RELPRON dataset produced by Rimell et al. (2016), which requires matching individual nouns to short phrases including relative clauses. Our aim is to show that, not only does the connection with formal semantics give us well-motivated techniques to tackle these disparate datasets, but this also leads to improvements in performance. 2 Related Work One approach to compositionality in a vector space model is to find a composition function that maps a pair of vectors to a new vector i"
W17-6806,W13-0204,0,0.0197358,"sentence’, where each ‘token’ is a predicate. Finding a good evaluation task is far from obvious. Simple similarity tasks do not require semantic structure, while tasks like textual entailment require a level of coverage beyond the scope of this paper. We consider the SVO similarity and RELPRON datasets, described below, because they provide restricted tasks in which we can explore approaches to semantic composition. The results on RELPRON were also reported by E&C2, but we give further error analysis here. In future work, we plan to use the datasets produced by Herbelot and Vecchi (2016) and Herbelot (2013), where pairs of ‘concepts’ (such as tricycle) and ‘features’ (such as is small) are annotated with suitable quantifiers (out of these options: all, most, some, few, no). One challenge posed by these datasets is the syntactic variation in the features, such as has 3 wheels and lives on coasts. These datasets can be seen as a further stepping stone between this paper and general textual entailment. 7 http://moin.delph-in.net/WikiWoods https://github.com/delph-in/pydelphin 9 https://github.com/delph-in/pydmrs 10 https://github.com/guyemerson/sem-func 8 Model Word2Vec SVO Word2Vec Semantic Functi"
W17-6806,D15-1003,0,0.105533,"al truth-conditional function with only 0 and 1 as values. every(x) picture(x) a(z) ∃(y) story(z) ∅ tell(y) ∧ ARG 1(y, x) ∧ ARG 2(y, z) Figure 3: Fully scoped representation of the most likely reading of Every picture tells a story. Each non-terminal node is a quantifier, its left child its restriction, and its right child its body. We assume that event variables are existentially quantified with no constraints on the restriction. 3.5 Interpretation of Quantifiers Interpreting the semantic function model as a probabilistic model structure, we can define quantification in a natural way. Unlike Herbelot and Vecchi (2015), we are not mapping from a distributional space to a model structure, but directly interpreting quantifiers in our distributional model. To assign a truth value to DMRS graph, we must first convert it to a fully scoped representation, such as in Fig. 3. In cases of scope ambiguity, a single DMRS graph allows several scoped representations, and this conversion must resolve the ambiguity.3 In a complete structure, there is one quantifier for each MRS variable, and hence also for each pixie-valued random variable, as there is a one-to-one mapping between them. For each quantifier, we define a bi"
W17-6806,2016.lilt-13.2,0,0.0223875,"riple was used to produce one ‘sentence’, where each ‘token’ is a predicate. Finding a good evaluation task is far from obvious. Simple similarity tasks do not require semantic structure, while tasks like textual entailment require a level of coverage beyond the scope of this paper. We consider the SVO similarity and RELPRON datasets, described below, because they provide restricted tasks in which we can explore approaches to semantic composition. The results on RELPRON were also reported by E&C2, but we give further error analysis here. In future work, we plan to use the datasets produced by Herbelot and Vecchi (2016) and Herbelot (2013), where pairs of ‘concepts’ (such as tricycle) and ‘features’ (such as is small) are annotated with suitable quantifiers (out of these options: all, most, some, few, no). One challenge posed by these datasets is the syntactic variation in the features, such as has 3 wheels and lives on coasts. These datasets can be seen as a further stepping stone between this paper and general textual entailment. 7 http://moin.delph-in.net/WikiWoods https://github.com/delph-in/pydelphin 9 https://github.com/delph-in/pydmrs 10 https://github.com/guyemerson/sem-func 8 Model Word2Vec SVO Word"
W17-6806,J15-4004,0,0.279693,"ning set, so that we can directly compare with Rimell et al.’s results. For GS2011, the ensemble model uses SVO Word2Vec, while for RELPRON, it uses normal Word2Vec. 5.1 Lexical Similarity We evaluated our model on several lexical similarity datasets. Our aim is firstly to show that the performance of our model is competitive with state-of-the-art vector space models, and secondly to show that our model can specifically target similarity rather than relatedness. For example, while the predicates painter and painting are related, they are true of very different individuals. We used SimLex-999 (Hill et al., 2015) and SimVerb-3500 (Gerz et al., 2016), which both aim to measure similarity, not relatedness; MEN (Bruni et al., 2014); and WordSim-353 (Finkelstein et al., 2001), which Agirre et al. (2009) split into similarity and relatedness subsets. To calculate a similarity score in our model, we can use the conditional probability of one predicate being true, given that another predicate is true, as shown in Fig. 4a. To make this into a symmetric score, we can multiply the conditional probabilities in both directions. Results are shown in Table 1.11 We can see that the semantic function model is competi"
W17-6806,Q15-1016,0,0.0312084,"of the semantic functions using random positive-only projections, a simple random-indexing technique introduced by QasemiZadeh and Kallmeyer (2016). The total number of dimensions is fixed, and each context predicate is randomly assigned to a context dimension (which means that many contexts will be randomly assigned to the same dimension). For each target predicate, we count how many times each context dimension appears. With these counts, we can calculate a standard PPMI vector. This method lets us initialise vectors in very little time, and we can use the same hyperparameters discussed by Levy et al. (2015). However, it should be noted that, because we are not using the vectors in the same way, the ideal hyperparameters are not the same. In particular, we found that, unlike for normal word vectors, it was unhelpful to use a negative offset for PPMI scores. Once the semantic function parameters have been initialised, the CaRBM parameters can be initialised based on mean field vectors. Each semantic function defines a no-context mean field vector, as described in §4.4 for Fig. 4a. For each SVO triple in the training data, we can take the mean field vectors for the observed predicates, and for each"
W17-6806,U12-1006,0,0.0156469,"ms of inference (a position defended by Erk (2016)), and requires existing vectors, rather than directly learning logical representations from distributional data. Many proposals exist for contextualising vectors. Erk and Pad´o (2008) and Thater et al. (2011) modify a vector according to syntactic dependencies. However, by proposing new operations, they make assumptions about the properties of the space, which may not apply to all models. Erk and Pad´o (2010) build a context-specific vector, by combining the most similar contexts in a corpus. However, this reduces the amount of training data. Lui et al. (2012)’s “per-lemma” model uses Latent Dirichlet Allocation to model contextual meaning as a mixture of senses, but this requires training a separate LDA model for each word. Furthermore, all of these methods focus on a specific kind of context, making it nontrivial to generalise them to arbitrary contexts. Our notion of probabilistic truth values is similar to the Austinian truth values in the framework of probabilistic Type Theory with Records (TTR) (Cooper, 2005; Cooper et al., 2015). Sutton (2015, 2017) takes a similar probabilistic approach to truth values to deal with philosophical problems co"
W17-6806,Q15-1008,0,0.0387205,"odels, as explained in §3.4. Others have also proposed representing the meaning of a predicate as a classifier. Larsson (2013) represents the meaning of a perceptual concept as a classifier of perceptual input, in the TTR framework. Schlangen et al. (2016) train image classifiers using captioned images, and Zarrieß and Schlangen (2017a,b) build on this, using distributional similarity to help train such classifiers. However, they do not learn an interpretable representation directly from text; rather, they use similarity scores to generalise from one label of an image to other similar labels. McMahan and Stone (2015) represent the meaning of a colour term as a probabilistic region of colour space, which could also be interpreted as a probabilistic classifier. However, this model was not intended to be a general-purpose distributional model. 3 From Model Theory to Probability Theory In this section, we show how model theory can be recast in a probabilistic setting. The aim is not to detail a full probabilistic logic, but rather to show how we can define a family of probability distributions that capture traditional model structures as a special case, while also allowing structured representations of the ki"
W17-6806,oepen-lonning-2006-discriminant,0,0.0900411,"Missing"
W17-6806,S16-2024,0,0.0860249,"d/or ARG 2, discarding pronouns and named entities. This gives 10m full SVO triples, and a further 21m where one of the two arguments is missing. For further details, see E&C. To preprocess the corpus, we used the python packages pydelphin8 (developed by Michael Goodman), and pydmrs9 (Copestake et al., 2016). Our source code is available online.10 Carefully initialising the model parameters allows us to drastically reduce the necessary training time. We initialised the parameters of the semantic functions using random positive-only projections, a simple random-indexing technique introduced by QasemiZadeh and Kallmeyer (2016). The total number of dimensions is fixed, and each context predicate is randomly assigned to a context dimension (which means that many contexts will be randomly assigned to the same dimension). For each target predicate, we count how many times each context dimension appears. With these counts, we can calculate a standard PPMI vector. This method lets us initialise vectors in very little time, and we can use the same hyperparameters discussed by Levy et al. (2015). However, it should be noted that, because we are not using the vectors in the same way, the ideal hyperparameters are not the sa"
W17-6806,J16-4004,0,0.213045,"our probabilistic model. In §4, we look at how to naturally derive context-dependent representations, and further, how these representations can be used for certain kinds of inference and semantic composition. In §5, we turn to using the model in practice, and evaluate on three tasks. Firstly, we look at lexical similarity, to show it is competitive with vector-based models. Secondly, we consider the dataset produced by Grefenstette and Sadrzadeh (2011), which measures the similarity of verbs in the context of a specific subject and object. Finally, we consider the RELPRON dataset produced by Rimell et al. (2016), which requires matching individual nouns to short phrases including relative clauses. Our aim is to show that, not only does the connection with formal semantics give us well-motivated techniques to tackle these disparate datasets, but this also leads to improvements in performance. 2 Related Work One approach to compositionality in a vector space model is to find a composition function that maps a pair of vectors to a new vector in the same space. Mitchell and Lapata (2010) compare a variety of such functions, but they find that componentwise addition and multiplication are in fact competit"
W17-6806,P16-1115,0,0.0517177,"els to show how semantics and world knowledge can interact. While these approaches are in principle compatible with our work, they do not provide an approach to distributional semantics. We use Minimal Recursion Semantics (Copestake et al., 2005), as it can be represented using dependency graphs – this allows a more natural connection with probabilistic graphical models, as explained in §3.4. Others have also proposed representing the meaning of a predicate as a classifier. Larsson (2013) represents the meaning of a perceptual concept as a classifier of perceptual input, in the TTR framework. Schlangen et al. (2016) train image classifiers using captioned images, and Zarrieß and Schlangen (2017a,b) build on this, using distributional similarity to help train such classifiers. However, they do not learn an interpretable representation directly from text; rather, they use similarity scores to generalise from one label of an image to other similar labels. McMahan and Stone (2015) represent the meaning of a colour term as a probabilistic region of colour space, which could also be interpreted as a probabilistic classifier. However, this model was not intended to be a general-purpose distributional model. 3 F"
W17-6806,I11-1127,0,0.0650588,"Missing"
W17-6806,E17-2014,0,0.143665,"Missing"
W17-6806,P17-1023,0,0.150809,"Missing"
W17-6806,Q13-1015,0,\N,Missing
W18-1003,D16-1203,0,0.0311306,"ome degree of comparability if they are ever to be capable of justifying or explaining their behavior. The ‘Clever Hans effect’ thus refers to situations where we wrongly and prematurely attribute such human-like reasoning mechanisms to trained models, when more careful and systematic investigations would have revealed our misjudgement. Crowdsourced visual questions have other unexpected properties. Goyal et al. (2017) and Mahendru et al. (2017) note how questions rarely talk about objects that are not present in the image, hence an existential question like “Do you see a...?” is mostly true. Agrawal et al. (2016) also give the example of questions like “What covers the ground?”, which can confidently be answered with “snow” because of biases in common realworld scenes, or, more precisely, biases in the photographs of real-world scenes. Such biases help to explain why some text-only systems turn out to perform well on visual question answering when evaluated on the VQA Dataset. Sturm (2014) compared such unexpected cues when evaluation machine learning systems to the story of ‘Clever Hans’, a horse exhibited in the early 20th century which was claimed to understand German and have extensive arithmetica"
W18-1003,W16-3203,0,0.0302841,"al., 2017; Agrawal et al., 2016) has suggested that the popular VQA Dataset (Antol et al., 2015) is inadequate, due to various issues which allow a system to achieve competitive performance without truly learning these abilities. To address this, modifications to the existing VQA Dataset and several artificial VQA datasets have been released. The former include C-VQA (Agrawal et al., 2017), a new composition-focused split, and VQA 2.0 (Goyal et al., 2017), an extension based on minimal image pairs. Similar approaches have been proposed in the context of image captioning (Shekhar et al., 2017; Hodosh and Hockenmaier, 2016), which relate to our proposal in that they modify language in a principled way. However, despite ‘mild artificiality’, some issues with real-world data like the VQA Dataset remain. On the other hand, examples of new artificial datasets include the SHAPES dataset (Andreas et al., 2016), the CLEVR dataset (Johnson et al., 2017a), the NLVR dataset (Suhr et al., 2017), and the ShapeWorld framework (Kuhnle and Copestake, 2017), which is our implementation of the proposal presented here. They all consist of images showing abstract scenes with colored objects and, except for NLVR, use artificially p"
W18-1003,D16-1162,0,0.0293446,"A more fundamental form of this effect is illustrated by recent investigations in image recognition. Szegedy et al. (2014) and Nguyen et al. (2015) have shown surprisingly odd system behavior when confronted with either only minimally modified images or almost random noise. This behavior seems due to the specific interplay of a few parameters which dominate the model’s decision, and have led to an entire research subfield on adversarial instances in vision. Such investigations are not yet as prominent in the NLP community, although see, e.g., Jia and Liang (2017), Sproat and Jaitly (2016) and Arthur et al. (2016). The ability to work with raw input data and to pick up correlations/biases, which humans cannot always manifest in explicit symbolic rules, is precisely the strength of DNNs as feature extractors. But given the often millions of parameters and large number of unstructured input values, it is difficult to avoid unexpected hidden cues. Real-world data with its enormous ‘sample space’, 2.3 Guiding principles for DNN evaluation Compositionality is a fundamental aspect of language, and consequently a necessary prerequisite for any claim about ‘understanding’ natural language. Besides being requir"
W18-1003,D17-1215,0,0.032722,"s for multimodal information (Jabri et al., 2016). A more fundamental form of this effect is illustrated by recent investigations in image recognition. Szegedy et al. (2014) and Nguyen et al. (2015) have shown surprisingly odd system behavior when confronted with either only minimally modified images or almost random noise. This behavior seems due to the specific interplay of a few parameters which dominate the model’s decision, and have led to an entire research subfield on adversarial instances in vision. Such investigations are not yet as prominent in the NLP community, although see, e.g., Jia and Liang (2017), Sproat and Jaitly (2016) and Arthur et al. (2016). The ability to work with raw input data and to pick up correlations/biases, which humans cannot always manifest in explicit symbolic rules, is precisely the strength of DNNs as feature extractors. But given the often millions of parameters and large number of unstructured input values, it is difficult to avoid unexpected hidden cues. Real-world data with its enormous ‘sample space’, 2.3 Guiding principles for DNN evaluation Compositionality is a fundamental aspect of language, and consequently a necessary prerequisite for any claim about ‘un"
W18-1003,E09-1001,1,0.752014,"grammar, and the CLEVR dataset (Johnson et al., 2017a) a more complex one based on functional building blocks, both template-based and specifically designed for their data. For our approach we leverage technology made available by the DELPH-IN (Deep Linguistic Processing with HPSG) consortium. More specifically, we make use of the broad-coverage, bidirectional2 , high-precision English Resource Grammar (Flickinger, 2000), which builds on the compositional semantic framework of Minimal Recursion Semantics (Copestake et al., 2005). For our system we use one of its variant, Dependency MRS (DMRS, Copestake (2009), Copestake et al. (2016)), and generate natural language sentences from abstract DMRS graphs using Packard’s parser-generator ACE3 . We have found that DMRS graphs can easily be enriched with appropriate semantics to be evaluated on a given world model. This means that the internals of the language system are essentially using a form of model-theoretic semantics. However, the external presentation of our task is still ‘natural’, i.e. only consists of image and language. Compositional representations like DMRS further enable us to produce an infinite number of captions of arbitrary syntactic c"
W18-1003,L16-1197,1,0.891192,"Missing"
W18-1003,P17-2034,0,0.153033,"et al., 2017), a new composition-focused split, and VQA 2.0 (Goyal et al., 2017), an extension based on minimal image pairs. Similar approaches have been proposed in the context of image captioning (Shekhar et al., 2017; Hodosh and Hockenmaier, 2016), which relate to our proposal in that they modify language in a principled way. However, despite ‘mild artificiality’, some issues with real-world data like the VQA Dataset remain. On the other hand, examples of new artificial datasets include the SHAPES dataset (Andreas et al., 2016), the CLEVR dataset (Johnson et al., 2017a), the NLVR dataset (Suhr et al., 2017), and the ShapeWorld framework (Kuhnle and Copestake, 2017), which is our implementation of the proposal presented here. They all consist of images showing abstract scenes with colored objects and, except for NLVR, use artificially produced language. Language generation for SHAPES and CLEVR is template-based and dataset-specific, while ShapeWorld leverages an existing broadcoverage semantic grammar formalism. These datasets are introduced with the motivation to provide a clear and challenging evaluation for VQA systems. Johnson et al. (2017a) and Kuhnle and Copestake (2017) investigated popula"
W18-1003,D17-1097,0,0.0201612,"ppropriately to other situations. The longer-term problem is that, while we do not expect that DNNs will simulate human capabilities in a fine-grained way, there has to be some degree of comparability if they are ever to be capable of justifying or explaining their behavior. The ‘Clever Hans effect’ thus refers to situations where we wrongly and prematurely attribute such human-like reasoning mechanisms to trained models, when more careful and systematic investigations would have revealed our misjudgement. Crowdsourced visual questions have other unexpected properties. Goyal et al. (2017) and Mahendru et al. (2017) note how questions rarely talk about objects that are not present in the image, hence an existential question like “Do you see a...?” is mostly true. Agrawal et al. (2016) also give the example of questions like “What covers the ground?”, which can confidently be answered with “snow” because of biases in common realworld scenes, or, more precisely, biases in the photographs of real-world scenes. Such biases help to explain why some text-only systems turn out to perform well on visual question answering when evaluated on the VQA Dataset. Sturm (2014) compared such unexpected cues when evaluati"
W18-1003,P17-1024,0,0.011341,"recent work (Goyal et al., 2017; Agrawal et al., 2016) has suggested that the popular VQA Dataset (Antol et al., 2015) is inadequate, due to various issues which allow a system to achieve competitive performance without truly learning these abilities. To address this, modifications to the existing VQA Dataset and several artificial VQA datasets have been released. The former include C-VQA (Agrawal et al., 2017), a new composition-focused split, and VQA 2.0 (Goyal et al., 2017), an extension based on minimal image pairs. Similar approaches have been proposed in the context of image captioning (Shekhar et al., 2017; Hodosh and Hockenmaier, 2016), which relate to our proposal in that they modify language in a principled way. However, despite ‘mild artificiality’, some issues with real-world data like the VQA Dataset remain. On the other hand, examples of new artificial datasets include the SHAPES dataset (Andreas et al., 2016), the CLEVR dataset (Johnson et al., 2017a), the NLVR dataset (Suhr et al., 2017), and the ShapeWorld framework (Kuhnle and Copestake, 2017), which is our implementation of the proposal presented here. They all consist of images showing abstract scenes with colored objects and, exce"
W19-0408,N09-1003,0,0.0736666,"imilarity evaluation is one of the most common methods of testing vector space semantic models. The similarity datasets consist of word-pairs associated with human-assigned similarity scores. The task is to measure how well the model’s scores, obtained using the learned embeddings, correlate with the gold-standard. After the scores are computed for each pair, typically using the cosine similarity measure, the pairs are ranked by these values. This ranking is then compared to the gold-standard ranking using Spearman’s rank correlation coefficient. The datasets used for this evaluation included Agirre et al. (2009)’s relatedness and similarity splits of WordSim353 (WS353) (Finkelstein et al., 2001), MEN (Bruni et al., 2014) which consists of 3000 similar and related pairs, the Rare Word (RW) collection (Luong et al., 2013), incorporating 2034 pairs of infrequent and morphologically complex words, SimLex-999 (Hill et al., 2016) consisting of 999 similar word pairs and SimVerb-3500 (Gerz et al., 2016) which includes 3500 similar verb-only pairs. The models performed best using 300 dimensional embeddings and 20 negative samples (apart from SG, which performed best with 15 samples). As reported in Table 1,"
W19-0408,P14-2131,0,0.0324194,"tic relations but the labels are disregarded (SGdep). Our primary evaluation involved a number of standard word similarity datasets, as well as the RELPRON dataset (Rimell et al., 2016). In addition, we tested our model’s performance on the task of differentiating between similarity and relatedness relations and evaluated it qualitatively, by manually inspecting the types of captured similarities. We also conduct experiments on three extrinsic tasks: dependency-parsing, chunking and part-of-speech tagging. Previous findings have shown the dependency embeddings are well suited for these tasks (Bansal et al., 2014; Melamud et al., 2016) so our primary objective here was to compare the performance of DM to that of LG. All models were trained on the WikiWoods corpus (Flickinger et al., 2010), which contains a 2008 Wikipedia snapshot, counting approximately 1.3M articles. Throughout this work we used Universal Dependencies (Nivre et al., 2016; Schuster and Manning, 2016) with all training examples for the dependency models generated from WikiWoods parsed with the Stanford Neural Network Dependency parser (Chen and Manning, 2014). Because words typically participate in only a few relations, the number of t"
W19-0408,J10-4006,0,0.057531,"labels and only pick words in relation with the target. The first approach was taken in some of the earliest works incorporating syntactic information into the count-based DSMs. Grefenstette (1994) used V C that consists of tokens such as subject-of-talk and his vectors held binary values denoting whether the target-word has co-occurred with the contexts in V C . This approach was later extended by Lin (1998) who replaced the binary values with frequency counts. Even more methods for incorporating syntactic information were introduced in the general frameworks of Pad´o and Lapata (2007)’s and Baroni and Lenci (2010). Baroni and Lenci (2010) represented corpus-extracted frequencies of (word, link, word) tuples as a third order tensor and, through its matricisation, generated various matrix-arrangements of the data. In particular, as an alternative to the standard word by (link, word) matrix, the framework allows the focus to be placed on links (which can be dependencies) and represent them in terms of the words they connect through a link by (word, word) matrix. More recently, Levy and Goldberg (2014) modified Skip-gram to use contexts of the form contextword’s form/label. The context-word can be either t"
W19-0408,D10-1115,0,0.106292,"he relation linking the target to its context. An important feature of the model is its inherent ability to represent chains of dependency relations – it can be easily extended to handle contexts coming from further dependencies of the target by multiplying the context-word vector by a number of matrices, as further explained in Section 4.2. The dependency-matrices modify meanings captured in the context-word vectors. In this behaviour, they are similar to representations of relational words, such as verbs or adjectives, in Compositional Semantic Models based on tensor products. For instance, Baroni and Zamparelli (2010) represent adjectives as matrices that enhance information encoded in the noun vectors with adjective-specific characteristics. Another example is the model of Paperno et al. (2014) in which each relational word is associated with a vector encoding its core meaning and a number of matrices – one for each argument the word takes. The matrices act as linear maps on the corresponding arguments’ vectors, altering those depending on the role they play with respect to the predicate. At its core, this role corresponds to the type of dependency linking these words. This is closely aligned with the app"
W19-0408,D14-1082,0,0.412389,"us findings have shown the dependency embeddings are well suited for these tasks (Bansal et al., 2014; Melamud et al., 2016) so our primary objective here was to compare the performance of DM to that of LG. All models were trained on the WikiWoods corpus (Flickinger et al., 2010), which contains a 2008 Wikipedia snapshot, counting approximately 1.3M articles. Throughout this work we used Universal Dependencies (Nivre et al., 2016; Schuster and Manning, 2016) with all training examples for the dependency models generated from WikiWoods parsed with the Stanford Neural Network Dependency parser (Chen and Manning, 2014). Because words typically participate in only a few relations, the number of training data instances obtained from the parses was a third of the number obtained for Skip-gram. We tuned the embedding dimensionality for all tasks and the number of negative samples for RELPRON and word similarity. For the extrinsic tasks we experimented with dimensions 50, 100 and 200, while for RELPRON and word similarity we experimented with setting m to 5, 10 and 15, and considered dimensions of 50, 100, 200 and 300. In the case of word similarity we based the hyperparameter choice on the SimLex-999 results, a"
W19-0408,W17-6806,1,0.861921,"Missing"
W19-0408,flickinger-etal-2010-wikiwoods,0,0.0704682,"al., 2016). In addition, we tested our model’s performance on the task of differentiating between similarity and relatedness relations and evaluated it qualitatively, by manually inspecting the types of captured similarities. We also conduct experiments on three extrinsic tasks: dependency-parsing, chunking and part-of-speech tagging. Previous findings have shown the dependency embeddings are well suited for these tasks (Bansal et al., 2014; Melamud et al., 2016) so our primary objective here was to compare the performance of DM to that of LG. All models were trained on the WikiWoods corpus (Flickinger et al., 2010), which contains a 2008 Wikipedia snapshot, counting approximately 1.3M articles. Throughout this work we used Universal Dependencies (Nivre et al., 2016; Schuster and Manning, 2016) with all training examples for the dependency models generated from WikiWoods parsed with the Stanford Neural Network Dependency parser (Chen and Manning, 2014). Because words typically participate in only a few relations, the number of training data instances obtained from the parses was a third of the number obtained for Skip-gram. We tuned the embedding dimensionality for all tasks and the number of negative sa"
W19-0408,D16-1235,0,0.052894,"Missing"
W19-0408,P14-2050,0,0.512758,"ctures. In particular, the Skip-gram model of Mikolov et al. (2013) has gained a lot of traction due to its efficiency and high quality representations. Skip-gram embeddings are trained with an objective that forces them to be similar to the vectors of their words’ contexts. The latter, context-word vectors, are a separate parameter of the model jointly learned along with the main target-word vectors. Like most DSMs, Mikolov et al. (2013)’s model derives contexts of a word from a pre-defined window of words that surround it. An alternative way of defining contexts in Skip-gram was explored by Levy and Goldberg (2014), who altered the model to accept contexts coming from a different vocabulary to that of the target-words. The contexts were retrieved from targets’ syntactic dependency relations and were a concatenation of the word linked to the target and the dependency-label. Each context type was associated with an independent vector representation. In contrast to Skip-gram, which captures relatedness1 , Levy and Goldberg (2014)’s embeddings exhibited a more intuitive notion of similarity. For example, the former regards the vector for abba, a popular Swedish pop group, as close to that for agnetha – a na"
W19-0408,P98-2127,0,0.467283,"in. For instance, among the contexts composed from dog would be dog/nsubj and dog/dobj. Alternatively, one can keep the vocabulary unchanged and adjust the context selection method to disregard the labels and only pick words in relation with the target. The first approach was taken in some of the earliest works incorporating syntactic information into the count-based DSMs. Grefenstette (1994) used V C that consists of tokens such as subject-of-talk and his vectors held binary values denoting whether the target-word has co-occurred with the contexts in V C . This approach was later extended by Lin (1998) who replaced the binary values with frequency counts. Even more methods for incorporating syntactic information were introduced in the general frameworks of Pad´o and Lapata (2007)’s and Baroni and Lenci (2010). Baroni and Lenci (2010) represented corpus-extracted frequencies of (word, link, word) tuples as a third order tensor and, through its matricisation, generated various matrix-arrangements of the data. In particular, as an alternative to the standard word by (link, word) matrix, the framework allows the focus to be placed on links (which can be dependencies) and represent them in terms"
W19-0408,W13-3512,0,0.0801383,"e how well the model’s scores, obtained using the learned embeddings, correlate with the gold-standard. After the scores are computed for each pair, typically using the cosine similarity measure, the pairs are ranked by these values. This ranking is then compared to the gold-standard ranking using Spearman’s rank correlation coefficient. The datasets used for this evaluation included Agirre et al. (2009)’s relatedness and similarity splits of WordSim353 (WS353) (Finkelstein et al., 2001), MEN (Bruni et al., 2014) which consists of 3000 similar and related pairs, the Rare Word (RW) collection (Luong et al., 2013), incorporating 2034 pairs of infrequent and morphologically complex words, SimLex-999 (Hill et al., 2016) consisting of 999 similar word pairs and SimVerb-3500 (Gerz et al., 2016) which includes 3500 similar verb-only pairs. The models performed best using 300 dimensional embeddings and 20 negative samples (apart from SG, which performed best with 15 samples). As reported in Table 1, DM outperformed LG on all benchmarks and SGdep on all similarity datasets. The latter demonstrates that the labels are a valuable information source and our model’s superiority over LG should not be attributed so"
W19-0408,N16-1118,0,0.018948,"labels are disregarded (SGdep). Our primary evaluation involved a number of standard word similarity datasets, as well as the RELPRON dataset (Rimell et al., 2016). In addition, we tested our model’s performance on the task of differentiating between similarity and relatedness relations and evaluated it qualitatively, by manually inspecting the types of captured similarities. We also conduct experiments on three extrinsic tasks: dependency-parsing, chunking and part-of-speech tagging. Previous findings have shown the dependency embeddings are well suited for these tasks (Bansal et al., 2014; Melamud et al., 2016) so our primary objective here was to compare the performance of DM to that of LG. All models were trained on the WikiWoods corpus (Flickinger et al., 2010), which contains a 2008 Wikipedia snapshot, counting approximately 1.3M articles. Throughout this work we used Universal Dependencies (Nivre et al., 2016; Schuster and Manning, 2016) with all training examples for the dependency models generated from WikiWoods parsed with the Stanford Neural Network Dependency parser (Chen and Manning, 2014). Because words typically participate in only a few relations, the number of training data instances"
W19-0408,W16-2504,0,0.0251256,"esults of the dependency parsing, part-of-speech tagging and chunking evaluation. achieved by the models measured with the unlabeled (UAS) and labeled attachment scores (LAS). Although all models performed well on this task, DM proved to be the best input-embedding initialisation. DMio performed overall best, demonstrating that utilising information encoded in the output-embeddings can be more beneficial than simply increasing the dimensionality of the embeddings. 4.6 Part-of-speech Tagging For the POS tagging we made use of the publicly available word embedding evaluation framework, VecEval (Nayak et al., 2016). VecEval’s word-labelling model resembles the one introduced by Collobert et al. (2011). First, it constructs the representation of the token’s context by concatenating embeddings of the surrounding words and then passes it through two neural network layers, followed by a softmax classifier. We trained and tested this model using the same WSJ splits used for the dependency parsing task. We initialised the model with the embeddings of DM, LG and SG and experimented with two settings: one that allows fine-tuning the embeddings to the task through backpropagation (tuned) and one that keeps the e"
W19-0408,L16-1262,0,0.0762584,"Missing"
W19-0408,J07-2002,0,0.363823,"Missing"
W19-0408,P14-1009,0,0.0277667,"ontexts coming from further dependencies of the target by multiplying the context-word vector by a number of matrices, as further explained in Section 4.2. The dependency-matrices modify meanings captured in the context-word vectors. In this behaviour, they are similar to representations of relational words, such as verbs or adjectives, in Compositional Semantic Models based on tensor products. For instance, Baroni and Zamparelli (2010) represent adjectives as matrices that enhance information encoded in the noun vectors with adjective-specific characteristics. Another example is the model of Paperno et al. (2014) in which each relational word is associated with a vector encoding its core meaning and a number of matrices – one for each argument the word takes. The matrices act as linear maps on the corresponding arguments’ vectors, altering those depending on the role they play with respect to the predicate. At its core, this role corresponds to the type of dependency linking these words. This is closely aligned with the approach taken in this work, with the main difference lying in the granularity of representations. 3.1 Training The model’s training objective closely resembles that of Skip-gram (Eq."
W19-0408,J16-4004,0,0.431483,"portant to note here that the incorporation of VdL does not influence the negative-sampling procedure. For each positive example the system samples m triples, which all share the same Vt and VdL as the original – the labels are not sampled. 4 Evaluation We compared the performance of our model to that of Skip-gram (SG), Levy and Goldberg (2014)’s model (LG) and Skip-gram for which the contexts are retrieved from the target’s syntactic relations but the labels are disregarded (SGdep). Our primary evaluation involved a number of standard word similarity datasets, as well as the RELPRON dataset (Rimell et al., 2016). In addition, we tested our model’s performance on the task of differentiating between similarity and relatedness relations and evaluated it qualitatively, by manually inspecting the types of captured similarities. We also conduct experiments on three extrinsic tasks: dependency-parsing, chunking and part-of-speech tagging. Previous findings have shown the dependency embeddings are well suited for these tasks (Bansal et al., 2014; Melamud et al., 2016) so our primary objective here was to compare the performance of DM to that of LG. All models were trained on the WikiWoods corpus (Flickinger"
W19-0408,L16-1376,0,0.023425,"inspecting the types of captured similarities. We also conduct experiments on three extrinsic tasks: dependency-parsing, chunking and part-of-speech tagging. Previous findings have shown the dependency embeddings are well suited for these tasks (Bansal et al., 2014; Melamud et al., 2016) so our primary objective here was to compare the performance of DM to that of LG. All models were trained on the WikiWoods corpus (Flickinger et al., 2010), which contains a 2008 Wikipedia snapshot, counting approximately 1.3M articles. Throughout this work we used Universal Dependencies (Nivre et al., 2016; Schuster and Manning, 2016) with all training examples for the dependency models generated from WikiWoods parsed with the Stanford Neural Network Dependency parser (Chen and Manning, 2014). Because words typically participate in only a few relations, the number of training data instances obtained from the parses was a third of the number obtained for Skip-gram. We tuned the embedding dimensionality for all tasks and the number of negative samples for RELPRON and word similarity. For the extrinsic tasks we experimented with dimensions 50, 100 and 200, while for RELPRON and word similarity we experimented with setting m t"
W19-0408,W00-0726,0,0.267274,"Missing"
W19-4806,D16-1203,0,0.0281083,"identifying the more numerous set. It can in particular be concluded that the system does not actually learn to explicitly 5 Related work Visual question answering (VQA) is the general task of answering questions about visual scenes. Since the introduction of the VQA Dataset (Antol et al., 2015), this dataset was widely used as evaluation benchmark for multimodal deep learning. It provides a shallow categorization of questions, including basic count questions, however, these categories are far too coarse for our purposes. Motivated by various problems with the VQA Dataset (Goyal et al., 2017; Agrawal et al., 2016), a range of artificial abstract datasets have been introduced recently. CLEVR (Johnson et al., 2017a) consists of rendered images of geometric objects and questions generated based on templates, covering some abilities like number or attribute comparison in more detail, but still in a fixed categorization. NLVR (Suhr et al., 2017) contains crowdsourced statements about abstract images, but does not sort them according to some criteria. Recently, the COG dataset (Yang et al., 2018) was introduced, which most explicitly focuses on replicating psychological experiments for deep learning models,"
W19-4806,W16-3211,0,0.0298453,"world images, formulated as a classification task over five classes ranging from “0” to “4 or more”. In a more general numberper-category classification setup, Chattopadhyay et al. (2017) investigate different methods of obtaining counts per object category, including one which is inspired by subitizing. Moving beyond explicit number classification, (Zhang et al., 2018) recently introduced a dedicated counting module for visual question answering. Other work looks at a similar classification task, but for proper quantifiers like “no”, “few”, “most”, “all”, first on abstract images of circles (Sorodoc et al., 2016), then on natural scenes (Sorodoc et al., 2018). Recently, Pezzelle et al. (2018) investigated a hierarchy of quantifier-related classification abilities, from comparatives via quantifiers like the ones above to fine-grained proportions. Wu et al. (2018), besides investigating precise numerosity via number classification as above, also look at approximate numerosity as binary greater/smaller decision, which closely corresponds to our experiments. However, on the one hand, their focus is on the subitizing ability, not the approximate number system. On the other hand, their experiments follow a"
W19-4806,P17-2034,0,0.0330129,"tion benchmark for multimodal deep learning. It provides a shallow categorization of questions, including basic count questions, however, these categories are far too coarse for our purposes. Motivated by various problems with the VQA Dataset (Goyal et al., 2017; Agrawal et al., 2016), a range of artificial abstract datasets have been introduced recently. CLEVR (Johnson et al., 2017a) consists of rendered images of geometric objects and questions generated based on templates, covering some abilities like number or attribute comparison in more detail, but still in a fixed categorization. NLVR (Suhr et al., 2017) contains crowdsourced statements about abstract images, but does not sort them according to some criteria. Recently, the COG dataset (Yang et al., 2018) was introduced, which most explicitly focuses on replicating psychological experiments for deep learning models, hence most related to our work. However, their dataset does not contain any number or quantifier statements. There is some work on investigating deep neural networks which look at numerosity from a more 53 1 1 0.9 0.9 0.8 0.8 0.7 0.6 0.5 1 2 3 random paired part. model 0.7 random paired part. 0.6 4 5 6 7 8 0.5 1 9 10 1.11 1.16 1.25"
W19-4806,N18-1039,0,0.0124877,"“0” to “4 or more”. In a more general numberper-category classification setup, Chattopadhyay et al. (2017) investigate different methods of obtaining counts per object category, including one which is inspired by subitizing. Moving beyond explicit number classification, (Zhang et al., 2018) recently introduced a dedicated counting module for visual question answering. Other work looks at a similar classification task, but for proper quantifiers like “no”, “few”, “most”, “all”, first on abstract images of circles (Sorodoc et al., 2016), then on natural scenes (Sorodoc et al., 2018). Recently, Pezzelle et al. (2018) investigated a hierarchy of quantifier-related classification abilities, from comparatives via quantifiers like the ones above to fine-grained proportions. Wu et al. (2018), besides investigating precise numerosity via number classification as above, also look at approximate numerosity as binary greater/smaller decision, which closely corresponds to our experiments. However, on the one hand, their focus is on the subitizing ability, not the approximate number system. On the other hand, their experiments follow a different methodology in that they already train models on specifically designed"
W96-0303,P93-1005,0,0.0175841,"which was derived with much greater amounts of human effort, has a slightly better performance, the difference is not great. Automatic acquisition of information from corpora is a partial answer to this problem, and one which is in many respects complementary to the approach assumed here, but successful acquisition of a broad-coverage lexicon from a really large corpus would lead to a similar problem of massive ambiguity as we see in the case of productive lexical rules. Control of syntactic ambiguity by the use of lexical and other probabilities has been demonstrated by several authors (e.g. Black et al., 1993; Schabes, 1992; Resnik, 1992), but the difficulty of acquisition means that the validity of utilizing lexical probabilities of the type assumed here has not yet been demonstrated on a large scale. This approach fits in most naturally with systems where probabilistic information is incorporated systematically. However it could be useful with more traditional systems. Different applications could utilize probabilistic information in different ways. For word choice in generation, it would be appropriate to take the highest-probability suitable entry, and, if none are attested, to construct a phr"
W96-0303,P94-1021,0,0.077893,"Missing"
W96-0303,A88-1019,0,0.0763999,"Missing"
W96-0303,C94-1042,0,0.0417729,"ncy statements. In the introductory section, we argued that this approach cannot be correct in principle, because of the problem of nonce senses. But it is also demonstrably inadequate, at least for systems which are not limited to a narrow domain. In an experiment with a wide-coverage parsing system (Alvey NL Tools, ANLT) Briscoe and Carroll (1993) observed that half of the parse failures were caused by inaccurate subcategorization information in the lexicon. The ANLT lexicon was derived semi-automatically from a machine readable dictionary (LDOCE), and although the COMLEX syntax dictionary (Grishman et al., 1994), which was derived with much greater amounts of human effort, has a slightly better performance, the difference is not great. Automatic acquisition of information from corpora is a partial answer to this problem, and one which is in many respects complementary to the approach assumed here, but successful acquisition of a broad-coverage lexicon from a really large corpus would lead to a similar problem of massive ambiguity as we see in the case of productive lexical rules. Control of syntactic ambiguity by the use of lexical and other probabilities has been demonstrated by several authors (e.g"
W96-0303,P95-1014,0,0.138039,"al rules is also possible, though controlled by probabilities associated with rule application. We discuss how the necessary probabilities and estimates of lexical rule productivity may be acquired from corpora. 1 Introduction Lexicalist linguistic theories, such as HPSG, LFG and categorial grammar, rely heavily on lexical rules. Recently, techniques have been described which address the efficiency issues that this raises for fully productive rules, such as inflectional rules and 'syntactic rules' (such as the HPSG complement extraction lexical rule). For example, Bouma & van Noord (1994) and Johnson & Dorre (1995) propose techniques for delayed evaluation of lexical rules so that they apply 'on demand' at parse time. Meurers ~ Minnen (1995) present a covariation approach, in which a finite-state machine for the application of lexical rules is derived by computing possible follow relations between the set of rules and then pruned FSMs are associated with classes of actual lexical entries representing the restricted set of rules which can apply to those entries. Finally, entries themselves are extended with information common to all their derived variants. These techniques achieve most of the advantages"
W96-0303,P93-1032,0,0.0147151,"or limited domains this may well be the best approach. We are more interested in incorporating probabilities in a large, reusable, lexical knowledge base. Recent developments in corpus processing techniques have made this more feasible. For instance, work on word sense disambiguation in corpora (e.g. Resnik 1995), could lead to an estimate of frequencies for word senses in general, with rule-derived senses simply being a special case. Many lexical rules involve changes in subcategorization, and automatic techniques for extracting subcategorization from corpora (e.g. Briscoe and Carroll, 1995; Manning, 1993) could eventually be exploited to give frequency information. In some cases, a combination of large corpora and sense taxonomies can be used to provide a rough estimate of lexical rule productivity suitable for instantiating the formulae given in the 12 previous section. For example, we examined verbs derived from several classes of noun from the 90 million word written portion of the British National Corpus, using the wordlists compiled by A d a m Kilgarriff. We looked at four classes of nouns: vehicles, dances, hitting weapons (e.g. club, whip) and decOrative coatings (e.g. lacquer, varnish)"
W96-0303,W95-0105,0,0.0280426,"to acquire probabilities for attested senses, and to derive appropriate estimates of lexical rule productivity. Probabilities of different word senses can be learned by a running analyzer, to the extent that lexical ambiguities are resolved either during processing or by an external oracle, and for limited domains this may well be the best approach. We are more interested in incorporating probabilities in a large, reusable, lexical knowledge base. Recent developments in corpus processing techniques have made this more feasible. For instance, work on word sense disambiguation in corpora (e.g. Resnik 1995), could lead to an estimate of frequencies for word senses in general, with rule-derived senses simply being a special case. Many lexical rules involve changes in subcategorization, and automatic techniques for extracting subcategorization from corpora (e.g. Briscoe and Carroll, 1995; Manning, 1993) could eventually be exploited to give frequency information. In some cases, a combination of large corpora and sense taxonomies can be used to provide a rough estimate of lexical rule productivity suitable for instantiating the formulae given in the 12 previous section. For example, we examined ver"
W96-0303,C92-2066,0,\N,Missing
W96-0303,J93-1002,1,\N,Missing
W97-0506,J92-1002,0,0.027517,"Missing"
waldron-etal-2006-preprocessing,callmeier-etal-2004-deepthought,1,\N,Missing
waldron-etal-2006-preprocessing,lee-etal-2004-towards,0,\N,Missing
waldron-etal-2006-preprocessing,W03-0802,1,\N,Missing
waldron-etal-2006-preprocessing,P03-1014,1,\N,Missing
waldron-etal-2006-preprocessing,briscoe-carroll-2002-robust,0,\N,Missing
waldron-etal-2006-preprocessing,schafer-2006-ontonerdie,1,\N,Missing
