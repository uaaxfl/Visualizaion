2021.emnlp-main.349,Generic resources are what you need: Style transfer tasks without task-specific parallel training data,2021,-1,-1,2,0,6235,huiyuan lai,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"Style transfer aims to rewrite a source text in a different target style while preserving its content. We propose a novel approach to this task that leverages generic resources, and without using any task-specific parallel (source{--}target) data outperforms existing unsupervised approaches on the two most popular style transfer tasks: formality transfer and polarity swap. In practice, we adopt a multi-step procedure which builds on a generic pre-trained sequence-to-sequence model (BART). First, we strengthen the model{'}s ability to rewrite by further pre-training BART on both an existing collection of generic paraphrases, as well as on synthetic pairs created using a general-purpose lexical resource. Second, through an iterative back-translation approach, we train two models, each in a transfer direction, so that they can provide each other with synthetically generated pairs, dynamically in the training process. Lastly, we let our best resulting model generate static synthetic pairs to be used in a supervised training regime. Besides methodology and state-of-the-art results, a core contribution of this work is a reflection on the nature of the two tasks we address, and how their differences are highlighted by their response to our approach."
2021.acl-short.62,Thank you {BART}! Rewarding Pre-Trained Models Improves Formality Style Transfer,2021,-1,-1,2,0,6235,huiyuan lai,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers),0,"Scarcity of parallel data causes formality style transfer models to have scarce success in preserving content. We show that fine-tuning pre-trained language (GPT-2) and sequence-to-sequence (BART) models boosts content preservation, and that this is possible even with limited amounts of parallel data. Augmenting these models with rewards that target style and content {--}the two core aspects of the task{--} we achieve a new state-of-the-art."
2020.wmt-1.29,"Machine Translation for {E}nglish{--}{I}nuktitut with Segmentation, Data Acquisition and Pre-Training",2020,-1,-1,6,0,13819,christian roest,Proceedings of the Fifth Conference on Machine Translation,0,"Translating to and from low-resource polysynthetic languages present numerous challenges for NMT. We present the results of our systems for the English{--}Inuktitut language pair for the WMT 2020 translation tasks. We investigated the importance of correct morphological segmentation, whether or not adding data from a related language (Greenlandic) helps, and whether using contextual word embeddings improves translation. While each method showed some promise, the results are mixed."
2020.wmt-1.130,Data Selection for Unsupervised Translation of {G}erman{--}{U}pper {S}orbian,2020,-1,-1,2,0,13820,lukas edman,Proceedings of the Fifth Conference on Machine Translation,0,"This paper describes the methods behind the systems submitted by the University of Groningen for the WMT 2020 Unsupervised Machine Translation task for German{--}Upper Sorbian. We investigate the usefulness of data selection in the unsupervised setting. We find that we can perform data selection using a pretrained model and show that the quality of a set of sentences or documents can have a great impact on the performance of the UNMT system trained on it. Furthermore, we show that document-level data selection should be preferred for training the XLM model when possible. Finally, we show that there is a trade-off between quality and quantity of the data used to train UNMT systems."
2020.emnlp-main.371,Character-level Representations Improve {DRS}-based Semantic Parsing Even in the Age of {BERT},2020,-1,-1,2,0.833333,6244,rik noord,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,"We combine character-level and contextual language model representations to improve performance on Discourse Representation Structure parsing. Character representations can easily be added in a sequence-to-sequence model in either one encoder or as a fully separate encoder, with improvements that are robust to different language models, languages and data sets. For English, these improvements are larger than adding individual sources of linguistic information or adding non-contextual embeddings. A new method of analysis based on semantic tags demonstrates that the character-level representations improve performance across a subset of selected semantic phenomena."
2020.eamt-1.10,Low-Resource Unsupervised {NMT}: Diagnosing the Problem and Providing a Linguistically Motivated Solution,2020,-1,-1,2,0,13820,lukas edman,Proceedings of the 22nd Annual Conference of the European Association for Machine Translation,0,"Unsupervised Machine Translation has been advancing our ability to translate without parallel data, but state-of-the-art methods assume an abundance of monolingual data. This paper investigates the scenario where monolingual data is limited as well, finding that current unsupervised methods suffer in performance under this stricter setting. We find that the performance loss originates from the poor quality of the pretrained monolingual embeddings, and we offer a potential solution: dependency-based word embeddings. These embeddings result in a complementary word representation which offers a boost in performance of around 1.5 BLEU points compared to standard word2vec when monolingual data is limited to 1 million sentences per language. We also find that the inclusion of sub-word information is crucial to improving the quality of the embeddings."
2020.eamt-1.14,Fine-grained Human Evaluation of Transformer and Recurrent Approaches to Neural Machine Translation for {E}nglish-to-{C}hinese,2020,-1,-1,2,0,20839,yuying ye,Proceedings of the 22nd Annual Conference of the European Association for Machine Translation,0,"This research presents a fine-grained human evaluation to compare the Transformer and recurrent approaches to neural machine translation (MT), on the translation direction English-to-Chinese. To this end, we develop an error taxonomy compliant with the Multidimensional Quality Metrics (MQM) framework that is customised to the relevant phenomena of this translation direction. We then conduct an error annotation using this customised error taxonomy on the output of state-of-the-art recurrent- and Transformer-based MT systems on a subset of WMT2019{'}s news test set. The resulting annotation shows that, compared to the best recurrent system, the best Transformer system results in a 31{\%} reduction of the total number of errors and it produced significantly less errors in 10 out of 22 error categories. We also note that two of the systems evaluated do not produce any error for a category that was relevant for this translation direction prior to the advent of NMT systems: Chinese classifiers."
2020.eamt-1.20,Reassessing Claims of Human Parity and Super-Human Performance in Machine Translation at {WMT} 2019,2020,18,0,1,1,9426,antonio toral,Proceedings of the 22nd Annual Conference of the European Association for Machine Translation,0,"We reassess the claims of human parity and super-human performance made at the news shared task of WMT2019 for three translation directions: EnglishâGerman, EnglishâRussian and GermanâEnglish. First we identify three potential issues in the human evaluation of that shared task: (i) the limited amount of intersen- tential context available, (ii) the limited translation proficiency of the evaluators and (iii) the use of a reference transla- tion. We then conduct a modified eval- uation taking these issues into account. Our results indicate that all the claims of human parity and super-human perfor- mance made at WMT2019 should be re- futed, except the claim of human parity for EnglishâGerman. Based on our findings, we put forward a set of recommendations and open questions for future assessments of human parity in machine translation."
W19-7604,Practical Statistics for Research in Machine Translation and Translation Studies,2019,-1,-1,1,1,9426,antonio toral,Proceedings of Machine Translation Summit XVII: Tutorial Abstracts,0,"The tutorial will introduce a set of very useful statistical tests for conducting analyses in the research areas of Machine Translation (MT) and Translation Studies (TS). For each statistical test, the presenter will: 1) introduce it in the context of a common research example that pertains to the area of MT and/or TS 2) explain the technique behind the test and its assumptions 3) cover common pitfalls when the test is applied in research studies, and 4) conduct a hands-on activity so that attendees can put the knowledge acquired in practice straight-away. All examples and exercises will be in R. The following statistical tests will be covered: t-tests (both parametric and non-parametric), bootstrap resampling, Pearson and Spearman correlation coefficients, linear mixed-effects models."
W19-6627,Post-editese: an Exacerbated Translationese,2019,19,0,1,1,9426,antonio toral,Proceedings of Machine Translation Summit XVII: Research Track,0,"Post-editing (PE) machine translation (MT) is widely used for dissemination because it leads to higher productivity than human translation from scratch (HT). In addition, PE translations are found to be of equal or better quality than HTs. However, most such studies measure quality solely as the number of errors. We conduct a set of computational analyses in which we compare PE against HT on three different datasets that cover five translation directions with measures that address different translation universals and laws of translation: simplification, normalisation and interference. We find out that PEs are simpler and more normalised and have a higher degree of interference from the source language than HTs."
W19-5343,Neural Machine Translation for {E}nglish{--}{K}azakh with Morphological Segmentation and Synthetic Data,2019,0,0,1,1,9426,antonio toral,"Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",0,"This paper presents the systems submitted by the University of Groningen to the English{--} Kazakh language pair (both translation directions) for the WMT 2019 news translation task. We explore the potential benefits of (i) morphological segmentation (both unsupervised and rule-based), given the agglutinative nature of Kazakh, (ii) data from two additional languages (Turkish and Russian), given the scarcity of English{--}Kazakh data and (iii) synthetic data, both for the source and for the target language. Our best submissions ranked second for KazakhâEnglish and third for EnglishâKazakh in terms of the BLEU automatic evaluation metric."
W19-5208,The Effect of Translationese in Machine Translation Test Sets,2019,16,2,2,0,2660,mike zhang,Proceedings of the Fourth Conference on Machine Translation (Volume 1: Research Papers),0,"The effect of translationese has been studied in the field of machine translation (MT), mostly with respect to training data. We study in depth the effect of translationese on test data, using the test sets from the last three editions of WMT{'}s news shared task, containing 17 translation directions. We show evidence that (i) the use of translationese in test sets results in inflated human evaluation scores for MT systems; (ii) in some cases system rankings do change and (iii) the impact translationese has on a translation direction is inversely correlated to the translation quality attainable by state-of-the-art MT systems for that direction."
W19-0504,Linguistic Information in Neural Semantic Parsing with Multiple Encoders,2019,0,0,2,0.833333,6244,rik noord,Proceedings of the 13th International Conference on Computational Semantics - Short Papers,0,"Recently, sequence-to-sequence models have achieved impressive performance on a number of semantic parsing tasks. However, they often do not exploit available linguistic resources, while these, when employed correctly, are likely to increase performance even further. Research in neural machine translation has shown that employing this information has a lot of potential, especially when using a multi-encoder setup. We employ a range of semantic and syntactic resources to improve performance for the task of Discourse Representation Structure Parsing. We show that (i) linguistic features can be beneficial for neural semantic parsing and (ii) the best method of adding these features is by using multiple encoders."
W18-6312,Attaining the Unattainable? Reassessing Claims of Human Parity in Neural Machine Translation,2018,0,20,1,1,9426,antonio toral,Proceedings of the Third Conference on Machine Translation: Research Papers,0,"We reassess a recent study (Hassan et al., 2018) that claimed that machine translation (MT) has reached human parity for the translation of news from Chinese into English, using pairwise ranking and considering three variables that were not taken into account in that previous study: the language in which the source side of the test set was originally written, the translation proficiency of the evaluators, and the provision of inter-sentential context. If we consider only original source text (i.e. not translated from another language, or translationese), then we find evidence showing that human parity has not been achieved. We compare the judgments of professional translators against those of non-experts and discover that those of the experts result in higher inter-annotator agreement and better discrimination between human and machine translations. In addition, we analyse the human translations of the test set and identify important translation issues. Finally, based on these findings, we provide a set of recommendations for future human evaluations of MT."
Q18-1043,Exploring Neural Methods for Parsing Discourse Representation Structures,2018,0,7,3,0.731707,6244,rik noord,Transactions of the Association for Computational Linguistics,0,"Neural methods have had several recent successes in semantic parsing, though they have yet to face the challenge of producing meaning representations based on formal semantics. We present a sequence-to-sequence neural semantic parser that is able to produce Discourse Representation Structures (DRSs) for English sentences with high accuracy, outperforming traditional DRS parsers. To facilitate the learning of the output, we represent DRSs as a sequence of flat clauses and introduce a method to verify that produced DRSs are well-formed and interpretable. We compare models using characters and words as input and see (somewhat surprisingly) that the former performs better than the latter. We show that eliminating variable names from the output using De Bruijn indices increases parser performance. Adding silver training data boosts performance even further."
E17-1100,A Multifaceted Evaluation of Neural versus Phrase-Based Machine Translation for 9 Language Directions,2017,0,33,1,1,9426,antonio toral,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 1, Long Papers",0,"We aim to shed light on the strengths and weaknesses of the newly introduced neural machine translation paradigm. To that end, we conduct a multifaceted evaluation in which we compare outputs produced by state-of-the-art neural machine translation and phrase-based machine translation systems for 9 language directions across a number of dimensions. Specifically, we measure the similarity of the outputs, their fluency and amount of reordering, the effect of sentence length and performance across different error categories. We find out that translations produced by neural machine translation systems are considerably different, more fluent and more accurate in terms of word order compared to those produced by phrase-based systems. Neural machine translation systems are also more accurate at producing inflected forms, but they perform poorly when translating very long sentences."
W16-3423,Re-assessing the Impact of {SMT} Techniques with Human Evaluation: a Case Study on {E}nglish{---}{C}roatian,2016,0,4,1,1,9426,antonio toral,Proceedings of the 19th Annual Conference of the {E}uropean Association for Machine Translation,0,None
W16-2322,"{A}bu-{M}a{T}ran at {WMT} 2016 Translation Task: Deep Learning, Morphological Segmentation and Tuning on Character Sequences",2016,27,8,2,0,9987,victor sanchezcartagena,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,"This paper presents the systems submitted by the Abu-MaTran project to the Englishto-Finnish language pair at the WMT 2016 news translation task. We applied morphological segmentation and deep learning in order to address (i) the data scarcity problem caused by the lack of in-domain parallel data in the constrained task and (ii) the complex morphology of Finnish. We submitted a neural machine translation system, a statistical machine translation system reranked with a neural language model and the combination of their outputs tuned on character sequences. The combination and the neural system were ranked first and second respectively according to automatic evaluation metrics and tied for the first place in the human evaluation."
L16-1469,{T}weet{MT}: A Parallel Microblog Corpus,2016,11,1,7,0,5339,inaki vicente,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"We introduce TweetMT, a parallel corpus of tweets in four language pairs that combine five languages (Spanish from/to Basque, Catalan, Galician and Portuguese), all of which have an official status in the Iberian Peninsula. The corpus has been created by combining automatic collection and crowdsourcing approaches, and it is publicly available. It is intended for the development and testing of microtext machine translation systems. In this paper we describe the methodology followed to build the corpus, and present the results of the shared task in which it was tested."
L16-1471,Producing Monolingual and Parallel Web Corpora at the Same Time - {S}pider{L}ing and Bitextor{'}s Love Affair,2016,0,0,3,0.147059,264,nikola ljubevsic,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"This paper presents an approach for building large monolingual corpora and, at the same time, extracting parallel data by crawling the top-level domain of a given language of interest. For gathering linguistically relevant data from top-level domains we use the SpiderLing crawler, modified to crawl data written in multiple languages. The output of this process is then fed to Bitextor, a tool for harvesting parallel data from a collection of documents. We call the system combining these two tools Spidextor, a blend of the names of its two crucial parts. We evaluate the described approach intrinsically by measuring the accuracy of the extracted bitexts from the Croatian top-level domain {``}.hr{''} and the Slovene top-level domain {``}.si{''}, and extrinsically on the English-Croatian language pair by comparing an SMT system built from the crawled data with third-party systems. We finally present parallel datasets collected with our approach for the English-Croatian, English-Finnish, English-Serbian and English-Slovene language pairs."
L16-1721,"Enhancing Cross-border {EU} {E}-commerce through Machine Translation: Needed Language Resources, Challenges and Opportunities",2016,0,0,3,0,35428,meritxell barrera,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"This paper discusses the role that statistical machine translation (SMT) can play in the development of cross-border EU e-commerce,by highlighting extant obstacles and identifying relevant technologies to overcome them. In this sense, it firstly proposes a typology of e-commerce static and dynamic textual genres and it identifies those that may be more successfully targeted by SMT. The specific challenges concerning the automatic translation of user-generated content are discussed in detail. Secondly, the paper highlights the risk of data sparsity inherent to e-commerce and it explores the state-of-the-art strategies to achieve domain adequacy via adaptation. Thirdly, it proposes a robust workflow for the development of SMT systems adapted to the e-commerce domain by relying on inexpensive methods. Given the scarcity of user-generated language corpora for most language pairs, the paper proposes to obtain monolingual target-language data to train language models and aligned parallel corpora to tune and evaluate MT systems by means of crowdsourcing."
2016.gwc-1.24,Using {W}ordnet to Improve Reordering in Hierarchical Phrase-Based Statistical Machine Translation,2016,0,0,2,0,36129,arefeh kazemi,Proceedings of the 8th Global WordNet Conference (GWC),0,"We propose the use of WordNet synsets in a syntax-based reordering model for hierarchical statistical machine translation (HPB-SMT) to enable the model to generalize to phrases not seen in the training data but that have equivalent meaning. We detail our methodology to incorporate synsets{'} knowledge in the reordering model and evaluate the resulting WordNet-enhanced SMT systems on the English-to-Farsi language direction. The inclusion of synsets leads to the best BLEU score, outperforming the baseline (standard HPB-SMT) by 0.6 points absolute."
2016.eamt-2.19,{A}bu-{M}a{T}ran: automatic building of machine translation,2016,-1,-1,1,1,9426,antonio toral,Proceedings of the 19th Annual Conference of the European Association for Machine Translation: Projects/Products,0,None
W15-4906,Dependency-based Reordering Model for Constituent Pairs in Hierarchical {SMT},2015,30,1,2,0,36129,arefeh kazemi,Proceedings of the 18th Annual Conference of the {E}uropean Association for Machine Translation,0,"We propose a novel dependency-based reordering model for hierarchical SMT that predicts the translation order of two types of pairs of constituents of the source tree: head-dependent and dependent-dependent. Our model uses the dependency structure of the source sentence to capture the mediumand long-distance reorderings between these pairs of constituents. We describe our reordering model in detail and then apply it to a language pair in which the languages involved follow different word order patterns, English (SVO) and Farsi (free word order being SOV the most frequent pattern). Our model outperforms a baseline (standard hierarchical SMT) by 0.78 BLEU points absolute, statistically significant at p = 0.01."
W15-4944,{A}bu-{M}a{T}ran: Automatic building of Machine Translation,2015,48,0,1,1,9426,antonio toral,Proceedings of the 18th Annual Conference of the {E}uropean Association for Machine Translation,0,None
W15-3022,{A}bu-{M}a{T}ran at {WMT} 2015 Translation Task: Morphological Segmentation and Web Crawling,2015,28,8,8,0.866432,8609,raphael rubino,Proceedings of the Tenth Workshop on Statistical Machine Translation,0,"This paper presents the machine translation systems submitted by the Abu-MaTran project for the Finnishxe2x80x90English language pair at the WMT 2015 translation task. We tackle the lack of resources and complex morphology of the Finnish language by (i) crawling parallel and monolingual data from the Web and (ii) applying rule-based and unsupervised methods for morphological segmentation. Several statistical machine translation approaches are evaluated and then combined to obtain our final submissions, which are the top performing English-to-Finnish unconstrained (all automatic metrics) and constrained (BLEU), and Finnish-to-English constrained (TER) systems."
W15-0714,Translating Literary Text between Related Languages using {SMT},2015,30,5,1,1,9426,antonio toral,Proceedings of the Fourth Workshop on Computational Linguistics for Literature,0,"We explore the feasibility of applying machinen translation (MT) to the translation of literaryn texts. To that end, we measure the translatability of literary texts by analysing paralleln corpora and measuring the degree of freedomn of the translations and the narrowness of then domain. We then explore the use of domainn adaptation to translate a novel between two related languages, Spanish and Catalan. Thisn is the first time that specific MT systems aren built to translate novels. Our best system outperforms a strong baseline by 4.61 absoluten points (9.38% relative) in terms of BLEU andn is corroborated by other automatic evaluationn metrics. We provide evidence that MT cann be useful to assist with the translation of novels between closely-related languages, namelyn (i) the translations produced by our best system are equal to the ones produced by a professional human translator in almost 20% ofn cases with an additional 10% requiring at mostn 5 character edits, and (ii) a complementary human evaluation shows that over 60% of then translations are perceived to be of the same (orn even higher) quality by native speakers."
2015.eamt-1.7,Dependency-based Reordering Model for Constituent Pairs in Hierarchical {SMT},2015,30,1,2,0,38031,arefeh kazemiy,Proceedings of the 18th Annual Conference of the European Association for Machine Translation,0,"We propose a novel dependency-based reordering model for hierarchical SMT that predicts the translation order of two types of pairs of constituents of the source tree: head-dependent and dependent-dependent. Our model uses the dependency structure of the source sentence to capture the mediumand long-distance reorderings between these pairs of constituents. We describe our reordering model in detail and then apply it to a language pair in which the languages involved follow different word order patterns, English (SVO) and Farsi (free word order being SOV the most frequent pattern). Our model outperforms a baseline (standard hierarchical SMT) by 0.78 BLEU points absolute, statistically significant at p = 0.01."
2015.eamt-1.45,{A}bu-{M}a{T}ran: Automatic building of Machine Translation,2015,48,0,1,1,9426,antonio toral,Proceedings of the 18th Annual Conference of the European Association for Machine Translation,0,None
W14-3319,{A}bu-{M}a{T}ran at {WMT} 2014 Translation Task: Two-step Data Selection and {RBMT}-Style Synthetic Rules,2014,20,4,2,0.866432,8609,raphael rubino,Proceedings of the Ninth Workshop on Statistical Machine Translation,0,"This paper presents the machine translation systems submitted by the AbuMaTran project to the WMT 2014 translation task. The language pair concerned is Englishxe2x80x90French with a focus on French as the target language. The French to English translation direction is also considered, based on the word alignment computed in the other direction. Large language and translation models are built using all the datasets provided by the shared task organisers, as well as the monolingual data from LDC. To build the translation models, we apply a two-step data selection method based on bilingual crossentropy difference and vocabulary saturation, considering each parallel corpus individually. Synthetic translation rules are extracted from the development sets and used to train another translation model. We then interpolate the translation models, minimising the perplexity on the development sets, to obtain our final SMT system. Our submission for the English to French translation task was ranked second amongst nine teams and a total of twenty submissions."
toral-2014-tlaxcala,{TLAXCALA}: a multilingual corpus of independent news,2014,7,0,1,1,9426,antonio toral,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"We acquire corpora from the domain of independent news from the Tlaxcala website. We build monolingual corpora for 15 languages and parallel corpora for all the combinations of those 15 languages. These corpora include languages for which only very limited such resources exist (e.g. Tamazight). We present the acquisition process in detail and we also present detailed statistics of the produced corpora, concerning mainly quantitative dimensions such as the size of the corpora per language (for the monolingual corpora) and per language pair (for the parallel corpora). To the best of our knowledge, these are the first publicly available parallel and monolingual corpora for the domain of independent news. We also create models for unsupervised sentence splitting for all the languages of the study."
rubino-etal-2014-quality,Quality Estimation for Synthetic Parallel Data Generation,2014,22,1,2,0.866432,8609,raphael rubino,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,This paper presents a novel approach for parallel data generation using machine translation and quality estimation. Our study focuses on pivot-based machine translation from English to Croatian through Slovene. We generate an EnglishâCroatian version of the Europarl parallel corpus based on the EnglishâSlovene Europarl corpus and the Apertium rule-based translation system for SloveneâCroatian. These experiments are to be considered as a first step towards the generation of reliable synthetic parallel data for under-resourced languages. We first collect small amounts of aligned parallel data for the SloveneâCroatian language pair in order to build a quality estimation system for sentence-level Translation Edit Rate (TER) estimation. We then infer TER scores on automatically translated Slovene to Croatian sentences and use the best translations to build an EnglishâCroatian statistical MT system. We show significant improvement in terms of automatic metrics obtained on two test sets using our approach compared to a random selection of synthetic parallel data.
ljubesic-toral-2014-cawac,ca{W}a{C} {--} A web corpus of {C}atalan and its application to language modeling and machine translation,2014,15,7,2,0.147059,264,nikola ljubevsic,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"In this paper we present the construction process of a web corpus of Catalan built from the content of the .cat top-level domain. For collecting and processing data we use the Brno pipeline with the spiderling crawler and its accompanying tools. To the best of our knowledge the corpus represents the largest existing corpus of Catalan containing 687 million words, which is a significant increase given that until now the biggest corpus of Catalan, CuCWeb, counts 166 million words. We evaluate the resulting resource on the tasks of language modeling and statistical machine translation (SMT) by calculating LM perplexity and incorporating the LM in the SMT pipeline. We compare language models trained on different subsets of the resource with those trained on the Catalan Wikipedia and the target side of the parallel data used to train the SMT system."
E14-4036,Active Learning for Post-Editing Based Incrementally Retrained {MT},2014,18,3,5,0,33902,aswarth dara,"Proceedings of the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics, volume 2: Short Papers",0,"Machine translation, in particular statistical machine translation (SMT), is making big inroads into the localisation and translation industry. In typical workflows (S)MT output is checked and (where required) manually post-edited by human translators. Recently, a significant amount of research has concentrated on capturing human post-editing outputs as early as possible to incrementally update/modify SMT models to avoid repeat mistakes. Typically in these approaches, MT and post-edits happen sequentially and chronologically, following the way unseen data (the translation job) is presented. In this paper, we add to the existing literature addressing the question whether and if so, to what extent, this process can be improved upon by Active Learning, where input is not presented chronologically but dynamically selected according to criteria that maximise performance with respect to (whatever is) the remaining data. We explore novel (source side-only) selection criteria and show performance increases of 0.67-2.65 points TER absolute on average on typical industry data sets compared to sequential PEbased incrementally retrained SMT."
2014.tc-1.23,Is machine translation ready for literature,2014,-1,-1,1,1,9426,antonio toral,Proceedings of Translating and the Computer 36,0,None
2014.eamt-1.45,Extrinsic evaluation of web-crawlers in machine translation: a study on {C}roatian-{E}nglish for the tourism domain,2014,-1,-1,1,1,9426,antonio toral,Proceedings of the 17th Annual conference of the European Association for Machine Translation,0,None
2014.amta-wptp.5,Perception vs. reality: measuring machine translation post-editing productivity,2014,-1,-1,2,0,4999,federico gaspari,Proceedings of the 11th Conference of the Association for Machine Translation in the Americas,0,"This paper presents a study of user-perceived vs real machine translation (MT) post-editing effort and productivity gains, focusing on two bidirectional language pairs: English{---}German and English{---}Dutch. Twenty experienced media professionals post-edited statistical MT output and also manually translated comparative texts within a production environment. The paper compares the actual post-editing time against the users{'} perception of the effort and time required to post-edit the MT output to achieve publishable quality, thus measuring real (vs perceived) productivity gains. Although for all the language pairs users perceived MT post-editing to be slower, in fact it proved to be a faster option than manual translation for two translation directions out of four, i.e. for Dutch to English, and (marginally) for English to German. For further objective scrutiny, the paper also checks the correlation of three state-of-the-art automatic MT evaluation metrics (BLEU, METEOR and TER) with the actual post-editing time."
W13-2803,Hybrid Selection of Language Model Training Data Using Linguistic Information and Perplexity,2013,11,13,1,1,9426,antonio toral,Proceedings of the Second Workshop on Hybrid Approaches to Translation,0,"We explore the selection of training data for language models using perplexity. We introduce three novel models that make use of linguistic information and evaluate them on three different corpora and two languages. In four out of the six scenarios a linguistically motivated method outperforms the purely statistical state-of-theart approach. Finally, a method which combines surface forms and the linguistically motivated methods outperforms the baseline in all the scenarios, selecting data whose perplexity is between 3.49% and 8.17% (depending on the corpus and language) lower than that of the baseline."
W13-2227,The {CNGL}-{DCU}-{P}rompsit Translation Systems for {WMT}13,2013,14,10,2,0.477883,8609,raphael rubino,Proceedings of the Eighth Workshop on Statistical Machine Translation,0,"This paper presents the experiments conducted by the Machine Translation group at DCU and Prompsit Language Engineering for the WMT13 translation task. Three language pairs are considered: SpanishEnglish and French-English in both directions and German-English in that direction. For the Spanish-English pair, the use of linguistic information to select parallel data is investigated. For the FrenchEnglish pair, the usefulness of the small indomain parallel corpus is evaluated, compared to an out-of-domain parallel data sub-sampling method. Finally, for the German-English system, we describe our work in addressing the long distance reordering problem and a system combination strategy."
N13-3005,A Web Application for the Diagnostic Evaluation of Machine Translation over Specific Linguistic Phenomena,2013,12,1,1,1,9426,antonio toral,Proceedings of the 2013 {NAACL} {HLT} Demonstration Session,0,"This paper presents a web application and a web service for the diagnostic evaluation of Machine Translation (MT). These web-based tools are built on top of DELiC4MT, an opensource software package that assesses the performance of MT systems over user-defined linguistic phenomena (lexical, morphological, syntactic and semantic). The advantage of the web-based scenario is clear; compared to the standalone tool, the user does not need to carry out any installation, configuration or maintenance of the tool."
2013.mtsummit-papers.17,Meta-Evaluation of a Diagnostic Quality Metric for Machine Translation,2013,20,0,2,0.434779,1243,sudip naskar,Proceedings of Machine Translation Summit XIV: Papers,0,"Diagnostic evaluation of machine translation (MT) is an approach to evaluation that provides finer-grained information compared to state-of-the-art automatic metrics. This paper evaluates DELiC4MT, a diagnostic metric that assesses the performance of MT systems on user-defined linguistic phenomena. We present the results obtained using this diagnostic metric when evaluating three MT systems that translate from English to French, with a comparison against both human judgements and a set of representative automatic evaluation metrics. In addition, as the diagnostic metric relies on word alignments, the paper compares the margin of error in diagnostic evaluation when using automatic word alignments as opposed to gold standard manual alignments. We observed that this diagnostic metric is capable of accurately reflecting translation quality, can be used reliably with automatic word alignments and, in general, correlates well with automatic metrics and, more importantly, with human judgements."
2013.mtsummit-european.14,"{M}oses{C}ore: {M}oses Open Source Evaluation and Support Co-ordination for {O}ut{R}each and Exploitation {PANACEA}: Platform for Automatic, Normalised Annotation and Cost-Effective Acquisition of Language Resources for Human Language Technologies",2013,-1,-1,3,0,17513,nuria bel,Proceedings of Machine Translation Summit XIV: European projects,0,None
2013.mtsummit-european.15,"{PANACEA}: Platform for Automatic, Normalised Annotation and Cost-Effective Acquisition of Language Resources for Human Language Technologies",2013,-1,-1,3,0,17513,nuria bel,Proceedings of Machine Translation Summit XIV: European projects,0,None
W12-5705,Topic Modeling-based Domain Adaptation for System Combination,2012,25,5,2,0,37719,tsuyoshi okita,Proceedings of the Second Workshop on Applying Machine Learning Techniques to Optimise the Division of Labour in Hybrid {MT},0,"This paper gives the system description of the domain adaptation team of Dublin City University for our participation in the system combination task in the Second Workshop on Applying Machine Learning Techniques to Optimise the Division of Labour in Hybrid MT (ML4HMT-12). We used the results of unsupervised document classification as meta information to the system combination module. For the Spanish-English data, our strategy achieved 26.33 BLEU points, 0.33 BLEU points absolute improvement over the standard confusion-network-based system combination. This was the best score in terms of BLEU among six participants in ML4HMT-12."
W12-5606,A Diagnostic Evaluation Approach Targeting {MT} Systems for {I}ndian Languages,2012,26,1,3,0,42065,renu balyan,Proceedings of the Workshop on Machine Translation and Parsing in {I}ndian Languages,0,"This paper addresses diagnostic evaluation of machine translation (MT) systems for Indian languages, English to Hindi translation in particular. Evaluation of MT output is an important but difficult task. The difficulty arises primarily from some inherent characteristics of the language pairs, which range from simple word-level discrepancies to more difficult structural variations for Hindi from English, such as reduplication of words, free word order etc. The proposed scheme is based on identification of linguistic units (often referred to as checkpoints). We use the diagnostic evaluation tool DELiC4MT to analyze the contribution of various PoS classes for different categories. We further suggest some additional checkpoints based on named entities, ambiguous words, word order and inflections that are relevant for the evaluation of Hindi. The evaluation of these checkpoints provides a detailed analysis and helps in monitoring how an MT system handles these linguistic phenomena as well. This also provides valuable feedback to MT developers as to where the system is performing poorly and how the output can possibly be improved. The effectiveness of the approach was tested on 5 English to Hindi MT systems and it was observed that the system-level DELiC4MT scores correlate well with the scores produced by the most commonly used automatic evaluation metrics (BLEU, NIST, METEOR and TER) while providing finer-grained information."
poch-etal-2012-towards,Towards a User-Friendly Platform for Building Language Resources based on Web Services,2012,16,4,2,1,39867,marc poch,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"This paper presents the platform developed in the PANACEA project, a distributed factory that automates the stages involved in the acquisition, production, updating and maintenance of Language Resources required by Machine Translation and other Language Technologies. We adopt a set of tools that have been successfully used in the Bioinformatics field, they are adapted to the needs of our field and used to deploy web services, which can be combined to build more complex processing chains (workflows). This paper describes the platform and its different components (web services, registry, workflows, social network and interoperability). We demonstrate the scalability of the platform by carrying out a set of massive data experiments. Finally, a validation of the platform across a set of required criteria proves its usability for different types of users (non-technical users and providers)."
E12-2001,Language Resources Factory: case study on the acquisition of Translation Memories,2012,9,1,2,1,39867,marc poch,Proceedings of the Demonstrations at the 13th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"This paper demonstrates a novel distributed architecture to facilitate the acquisition of Language Resources. We build a factory that automates the stages involved in the acquisition, production, updating and maintenance of these resources. The factory is designed as a platform where functionalities are deployed as web services, which can be combined in complex acquisition chains using workflows. We show a case study, which acquires a Translation Memory for a given pair of languages and a domain using web services for crawling, sentence alignment and conversion to TMX."
C12-1135,Simple and Effective Parameter Tuning for Domain Adaptation of Statistical Machine Translation,2012,25,15,2,0.834433,23042,pavel pecina,Proceedings of {COLING} 2012,0,"Current state-of-the-art Statistical Machine Translation systems are based on log-linear models that combine a set of feature functions to score translation hypotheses during decoding. The models are parametrized by a vector of weights usually optimized on a set of sentences and their reference translations, called development data. In this paper, we explore a (common and industry relevant) scenario where a system trained and tuned on general domain data needs to be adapted to a specific domain for which no or only very limited in-domain bilingual data is available. It turns out that such systems can be adapted successfully by re-tuning model parameters using surprisingly small amounts of parallel in-domain data, by cross-tuning or no tuning at all. We show in detail how and why this is effective, compare the approaches and effort involved. We also study the effect of system hyperparameters (such as maximum phrase length and development data size) and their optimal values in this scenario."
2012.eamt-1.10,Efficiency-based evaluation of aligners for industrial applications,2012,-1,-1,1,1,9426,antonio toral,Proceedings of the 16th Annual conference of the European Association for Machine Translation,0,None
2012.eamt-1.38,Domain Adaptation of Statistical Machine Translation using Web-Crawled Resources: A Case Study,2012,44,17,2,0.834433,23042,pavel pecina,Proceedings of the 16th Annual conference of the European Association for Machine Translation,0,"We tackle the problem of domain adaptation of Statistical Machine Translation by exploiting domain-specific data acquired by domain-focused web-crawling. We design and evaluate a procedure for automatic acquisition of monolingual and parallel data and their exploitation for training, tuning, and testing in a phrase-based Statistical Machine Translation system. We present a strategy for using such resources depending on their availability and quantity supported by results of a large-scale evaluation on the domains of Natural Environment and Labour Legislation and two language pairs: Englishxe2x80x90French, English-Greek. The average observed increase of BLEU is substantial at 49.5% relative."
2012.eamt-1.67,Pivot-based Machine Translation between Statistical and Black Box systems,2012,18,1,1,1,9426,antonio toral,Proceedings of the 16th Annual conference of the European Association for Machine Translation,0,"This paper presents a novel approach to pivot-based machine translation (MT): while the state-of-the-art uses two statistical systems, this proposal treats the second system as a black box. Our approach effecively provides pivot-based MT to target languages for which no suitable bilingual corpora are available to build statistical systems, as long as any other kind of MT system is available. We experiment with an algorithm that uses two features to find the best translation: the translation score provided by the first system and fluency of the final translation. Despite its simplicity, this approach yields significant improvements over the baseline, which translates the source sentences using the two MT systems sequentially. We have experimented with two scenarios, technical documentation in Romance languages and newswire in Slavic languages, obtaining 11.88% and 13.32% relative improvements in terms of BLEU, respectively."
W11-4417,An Open-Source Finite State Morphological Transducer for {M}odern {S}tandard {A}rabic,2011,14,23,3,1,24071,mohammed attia,Proceedings of the 9th International Workshop on Finite State Methods and Natural Language Processing,0,"We develop an open-source large-scale finitestate morphological processing toolkit (AraComLex) for Modern Standard Arabic (MSA) distributed under the GPLv3 license. The morphological transducer is based on a lexical database specifically constructed for this purpose. In contrast to previous resources, the database is tuned to MSA, eliminating lexical entries no longer attested in contemporary use. The database is built using a corpus of 1,089,111,204 words, a pre-annotation tool, machine learning techniques, and knowledge-based pattern matching to automatically acquire lexical knowledge. Our morphological transducer is evaluated and compared to LDC's SAMA (Standard Arabic Morphological Analyser)."
2011.mtsummit-papers.60,A Framework for Diagnostic Evaluation of {MT} Based on Linguistic Checkpoints,2011,-1,-1,2,0.503946,1243,sudip naskar,Proceedings of Machine Translation Summit XIII: Papers,0,None
2011.freeopmt-1.7,Automatic acquisition of named entities for rule-based machine translation,2011,18,4,1,1,9426,antonio toral,Proceedings of the Second International Workshop on Free/Open-Source Rule-Based Machine Translation,0,"This paper proposes to enrich RBMT dictionaries with Named Entities (NEs) automatically acquired from Wikipedia. The method is applied to the Apertium English{--}Spanish system and its performance compared to that of Apertium with and without handtagged NEs. The system with automatic NEs outperforms the one without NEs, while results vary when compared to a system with handtagged NEs (results are comparable for SpanishâEnglish but slightly worst for EnglishâSpanish). Apart from that, adding automatic NEs contributes to decreasing the amount of unknown terms by more than 10{\%}."
2011.freeopmt-1.12,An {I}talian to {C}atalan {RBMT} system reusing data from existing language pairs,2011,16,6,1,1,9426,antonio toral,Proceedings of the Second International Workshop on Free/Open-Source Rule-Based Machine Translation,0,This paper presents an ItalianâCatalan RBMT system automatically built by combining the linguistic data of the existing pairs Spanish{--}Catalan and Spanish{--}Italian. A lightweight manual postprocessing is carried out in order to fix inconsistencies in the automatically derived dictionaries and to add very frequent words that are missing according to a corpus analysis. The system is evaluated on the KDE4 corpus and outperforms Google Translate by approximately ten absolute points in terms of both TER and GTM.
2011.eamt-1.4,A Comparative Evaluation of Research vs. Online {MT} Systems,2011,19,3,1,1,9426,antonio toral,Proceedings of the 15th Annual conference of the European Association for Machine Translation,0,"This paper reports MT evaluation experiments that were conducted at the end of year 1 of the EU-funded CoSynen 1 project for three language combinations, considering translations from German, Italian and Dutch into English. We present a comparative evaluation of the MT software developed within the project against four of the leading free webbased MT systems across a range of state-of-the-art automatic evaluation metrics. The data sets from the news domain that were created and used for training purposes and also for this evaluation exercise, which are available to the research community, are also described. The evaluation results for the news domain are very encouraging: the CoSyne MT software consistently beats the rule-based MT systems, and for translations from Italian and Dutch into English in particular the scores given by some of the standard automatic evaluation metrics are not too distant from those obtained by wellestablished statistical online MT systems."
2011.eamt-1.11,Towards a User-Friendly Webservice Architecture for Statistical Machine Translation in the {PANACEA} project,2011,-1,-1,1,1,9426,antonio toral,Proceedings of the 15th Annual conference of the European Association for Machine Translation,0,None
2011.eamt-1.40,Towards Using Web-Crawled Data for Domain Adaptation in Statistical Machine Translation,2011,22,25,2,0.834433,23042,pavel pecina,Proceedings of the 15th Annual conference of the European Association for Machine Translation,0,"This paper reports on the ongoing work focused on domain adaptation of statistical machine translation using domain-specific data obtained by domain-focused web crawling. We present a strategy for crawling monolingual and parallel data and their exploitation for testing, language modelling, and system tuning in a phrase-based machine translation framework. The proposed approach is evaluated on the domains of Natural Environment and Labour Legislation and two language pairs: Englishxe2x80x90French and Englishxe2x80x90Greek."
W10-3704,Automatic Extraction of {A}rabic Multiword Expressions,2010,17,50,2,1,24071,mohammed attia,Proceedings of the 2010 Workshop on Multiword Expressions: from Theory to Applications,0,"In this paper we investigate the automatic acquisition of Arabic Multiword Expressions (MWE). We propose three complementary approaches to extract MWEs from available data resources. The rst approach relies on the correspondence asymmetries between Arabic Wikipedia titles and titles in 21 different languages. The second approach collects English MWEs from Princeton WordNet 3.0, translates the collection into Arabic using Google Translate, and utilizes different search engines to validate the output. The third uses lexical association measures to extract MWEs from a large unannotated corpus. We experimentally explore the feasibility of each approach and measure the quality and coverage of the output against gold standards."
attia-etal-2010-automatically,An Automatically Built Named Entity Lexicon for {A}rabic,2010,21,26,2,1,24071,mohammed attia,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"We have adapted and extended the automatic Multilingual, Interoperable Named Entity Lexicon approach to Arabic, using Arabic WordNet (AWN) and Arabic Wikipedia (AWK). First, we extract AWNÂs instantiable nouns and identify the corresponding categories and hyponym subcategories in AWK. Then, we exploit Wikipedia inter-lingual links to locate correspondences between articles in ten different languages in order to identify Named Entities (NEs). We apply keyword search on AWK abstracts to provide for Arabic articles that do not have a correspondence in any of the other languages. In addition, we perform a post-processing step to fetch further NEs from AWK not reachable through AWN. Finally, we investigate diacritization using matching with geonames databases, MADA-TOKAN tools and different heuristics for restoring vowel marks of Arabic NEs. Using this methodology, we have extracted approximately 45,000 Arabic NEs and built, to the best of our knowledge, the largest, most mature and well-structured Arabic NE lexical resource to date. We have stored and organised this lexicon following the LMF ISO standard. We conduct a quantitative and qualitative evaluation against a manually annotated gold standard and achieve precision scores from 95.83{\%} (with 66.13{\%} recall) to 99.31{\%} (with 61.45{\%} recall) according to different values of a threshold."
W09-2420,{S}em{E}val-2010 Task 17: All-words Word Sense Disambiguation on a Specific Domain,2009,30,20,5,0,8824,eneko agirre,Proceedings of the Workshop on Semantic Evaluations: Recent Achievements and Future Directions ({SEW}-2009),0,"Domain portability and adaptation of NLP components and Word Sense Disambiguation systems present new challenges. The difficulties found by supervised systems to adapt might change the way we assess the strengths and weaknesses of supervised and knowledgebased WSD systems. Unfortunately, all existing evaluation datasets for specific domains are lexical-sample corpora. With this paper we want to motivate the creation of an allwords test dataset for WSD on the environment domain in several languages, and present the overall design of this SemEval task."
R09-1080,A Study on Linking {W}ikipedia Categories to {W}ordnet Synsets using Text Similarity,2009,18,16,1,1,9426,antonio toral,Proceedings of the International Conference {RANLP}-2009,0,"This paper studies the application of text similarity methods to disambiguate ambiguous links between WordNet nouns and Wikipedia categories. The methods range from word overlap between glosses, random projections, WordNetbased similarity, and a full-fledged textual entailment system. Both unsupervised and supervised combinations have been tried. The goldstandard with disambiguated links is publicly available. The results range from 64.7% for the first sense heuristic, 68% for an unsupervised combination, and up to 77.74% for a supervised combination."
toral-etal-2008-named,Named Entity {W}ord{N}et,2008,9,37,1,1,9426,antonio toral,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"This paper presents the automatic extension of Princeton WordNet with Named Entities (NEs). This new resource is called Named Entity WordNet. Our method maps the noun is-a hierarchy of WordNet to Wikipedia categories, identifies the NEs present in the latter and extracts different information from them such as written variants, definitions, etc. This information is inserted into a NE repository. A module that converts from this generic repository to the WordNet specific format has been developed. The paper explores different aspects of our methodology such as the treatment of polysemous terms, the identification of hyponyms within the Wikipedia categorization system, the identification of Wikipedia articles which are NEs and the design of a NE repository compliant with the LMF ISO standard. So far, this procedure enriches WordNet with 310,742 NEs and 381,043 Âinstance ofÂ relations."
magnini-etal-2008-evaluation,Evaluation of Natural Language Tools for {I}talian: {EVALITA} 2007,2008,20,12,9,0,1501,bernardo magnini,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"EVALITA 2007, the first edition of the initiative devoted to the evaluation of Natural Language Processing tools for Italian, provided a shared framework where participantsÂ systems had the possibility to be evaluated on five different tasks, namely Part of Speech Tagging (organised by the University of Bologna), Parsing (organised by the University of Torino), Word Sense Disambiguation (organised by CNR-ILC, Pisa), Temporal Expression Recognition and Normalization (organised by CELCT, Trento), and Named Entity Recognition (organised by FBK, Trento). We believe that the diffusion of shared tasks and shared evaluation practices is a crucial step towards the development of resources and tools for Natural Language Processing. Experiences of this kind, in fact, are a valuable contribution to the validation of existing models and data, allowing for consistent comparisons among approaches and among representation schemes. The good response obtained by EVALITA, both in the number of participants and in the quality of results, showed that pursuing such goals is feasible not only for English, but also for other languages."
ruimy-toral-2008-semantic,More Semantic Links in the {SIMPLE}-{CLIPS} Database,2008,7,5,2,0,48459,nilda ruimy,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"Notwithstanding its acknowledged richness, the SIMPLE semantic model does not offer the representational vocabulary for encoding some conceptual links holding between events and their participants and among co-participants in events. Although critical for boosting performance in many NLP application tasks, such deep lexical information is therefore only partially encoded in the SIMPLE-CLIPS Italian semantic database. This paper reports on the enrichment of the SIMPLE relation set by some expressive means, namely semantic relations, borrowed from the EuroWordNet model and their implementation in the SIMPLE-CLIPS lexicon. The original situation existing in the database, as to the expression of this type of information is described and the loan descriptive vocabulary presented. Strategies based on the exploitation of the source lexicon data were adopted to induce new information: a wide range of semantic - but also syntactic - information was investigated for singling out word senses candidate to be linked by the new relations. The lexicon enrichment by 5,000 new relations instantiated so far has therefore been carried out as a largely automated, low-effort and cost-free process, with no heavy human intervention. The redundancy set off by such an extension of information is being addressed by the implementation of inheritance in the SIMPLE-CLIPS database (Del Gratta et al., 2008)."
del-gratta-etal-2008-simple,Simple-Clips ongoing research: more information with less data by implementing inheritance,2008,2,3,3,0,29721,riccardo gratta,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"This paper presents the application of inheritance to the formal taxonomy (is-a) of a semantically rich Language Resource based on the Generative Lexicon theory, SIMPLE-CLIPS. The aim is to lighten the representation of its semantic layer by reducing the number of encoded relations. A prediction calculation on the impact of introducing inheritance regarding space occupancy is carried out, yielding a significant space reduction of 22{\%}. This is corroborated by its actual application, which reduces the number of explicitly encoded relations in this lexicon by 18.4{\%}. Later on, we study the issues that inheritance poses to the Language Resources, and discuss sensitive solutions to tackle each of them, including examples. Finally, we present a discussion on the application of inheritance, from which two side effect advantages arise: consistency enhancement and inference capabilities."
W06-2809,A proposal to automatically build and maintain gazetteers for Named Entity Recognition by using {W}ikipedia,2006,-1,-1,1,1,9426,antonio toral,Proceedings of the Workshop on {NEW} {TEXT} Wikis and blogs and other dynamic text sources,0,None
