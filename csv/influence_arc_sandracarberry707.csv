C00-2107,J98-3002,1,0.918495,"xpress doubt, particularly in cases where it has incomplete or uncertain knowledge. Examination of natural language corpora shows that expressions of doubt may be realized in a variety of forms. Furthermore, the form of the utterance conveys information about the nature of the doubt that is important for the subsequent resolution of the con ict. Thus a collaborative natural language system must be able to generate utterances that convey doubt naturally and e ectively. This paper presents our work on realizing expressions of doubt appropriately in natural language dialogues. 2 Previous Work In Chu-Carroll and Carberry (1998) the collaborative planning process is modeled as a ProposeEvaluate-Modify cycle, in which an agent is able to detect con icts in belief and initiate collaborative negotiation subdialogues to attempt to resolve the con icts. They use a modi ed version of Galliers belief revision mechanism(Galliers, 1992; Logan et al., 1994) to determine whether to accept a proposition and in determining which con icting beliefs to use to refute an utterance that is not accepted. However, their work does not address how an expression of doubt should be realized in a natural language utterance. Vander Linden and"
C00-2107,J99-1001,1,0.929143,"tly, often in sentence fragments. Since such eciency of expression is the expected natural form of discourse, a hearer is likely to derive unintended implications from signi cantly less economical realizations. Expressions of doubt, by our de nition, signal nonacceptance because of `uncertain disbelief. In order for the doubted agent to attempt to collaborate in resolving the doubt, he needs to know several things. Most basically, he needs to recognize that there is doubt in a particular utterance. In the absence of an objection to an utterance, the speaker will assume an implicit acceptance(Lambert and Carberry, 1999). To eciently negotiate an acceptable resolution to the belief con ict, ideally the doubted agent must know something about the beliefs of the doubting agent; in particular, which belief(s) are causing her nonacceptance, and the strength of these beliefs. If the doubted agent decides to retain his original beliefs, this information helps him to construct an argument that will be maximally e ective and ecient in his attempt to convince the doubting agent(Chu-Carroll and Carberry, 1998). To identify how expressions of doubt are realized in naturally occurring dialogue and how these realization"
C00-2107,C96-1059,0,0.0733095,"Missing"
C14-1057,J07-4004,0,0.0116036,"account when retrieving graphics and that doing so results in a model with better performance than a baseline model that relies on matching query words with words in the graphic. 1 Introduction Infographics are non-pictorial graphics such as bar charts and line graphs. When such graphics appear in popular media, they generally have a high-level message that they are intended to convey. For example, the graphic in Figure 1 ostensibly conveys the message that Toyota has the highest profit among the automobile companies listed. Thus infographics are a form of language since, according to Clark (Clark and Curran, 2007), language is any deliberate signal that is intended to convey a message. Although much research has addressed the retrieval of documents, very little attention has been given to the retrieval of infographics. Yet research has shown that the content of an infographic is often not included in the article’s text (Carberry et al., 2006). Thus infographics are an important knowledge source that should be accessible to users of a digital library. Techniques that have been effective for document or image retrieval are inadequate for the retrieval of infographics. Current search engines employ strate"
C86-1006,J81-1001,0,\N,Missing
C86-1006,J81-4001,0,\N,Missing
C86-1006,P84-1063,0,\N,Missing
C86-1006,J80-3003,0,\N,Missing
C88-2119,P85-1024,1,0.838042,"state. 1 This section describes definition-glving situations identified in this study. An expert may give a definition either in response to a user&apos;s request or spontaneously. Occasions for providing definitions arise most obviously when the user asks a question of the form &quot;What is ... ?&quot; or &quot;What is the significance o f . . . ? &quot; The question doesn&apos;t have to be explicit, however, as illustrated in the exchange below, which is an excerpt from a money-management talk show transcript: E: &quot;I&apos;d llke to see you put that into two different Southern utilities.&quot; U: &quot;Southern utilities?&quot; As shown in [Carberry 1985], such elliptical fragments are often intended to elicit clarification and explanation of the repeated term. In addition to giving definitions in response to a request by the user, the expert may provide a definition as part of correcting a user misconception [McCoy 1986], or may generate definitions spontaneously. There are several reasons an expert may give spontaneous definitions. He may provide additional definitional information to justify use of a concept, tie may think it likely that the user doesn&apos;t know about the entity being introduced. The expert may want to ensure that he and the"
C88-2119,J88-3003,1,0.843344,"the appropriate Operation explanation depends on the use to which the entity will be put by t h e information-seeker. Selecting Definition Content 6 Our strategy assumes a knowledge base consisting of a generalization hierarchy containing domain knowledge, a plan library, and a lexicon. The user model has three components: 1. a model of the user&apos;s domain knowledge in the form of markings on the knowledge base showing the pieces with which the user is familiar [Kass 1987], 2. a model of the user&apos;s underlying t/ak-related plan and current focus of attention in the plan, given by a context tree [Carberry 1988], 3. a model of how receptive the user is to various kinds of information, given by weightings on strategic predicates. The first two components will be dynamically updated during the dialogue as shown in [Kass 1987] and [Carberry 1988]. The third component will also be updated dynamically in response to the user&apos;s receptivity to types of definitions and his own usage of strategic predicates. 6.1 Weighting Predicates When a definition occasion arises, a local predicate receptivity model is created. Starting with a copy of the current global weights representing the user&apos;s general receptivity"
C88-2119,P86-1016,0,0.0300188,"&quot;What is ... ?&quot; or &quot;What is the significance o f . . . ? &quot; The question doesn&apos;t have to be explicit, however, as illustrated in the exchange below, which is an excerpt from a money-management talk show transcript: E: &quot;I&apos;d llke to see you put that into two different Southern utilities.&quot; U: &quot;Southern utilities?&quot; As shown in [Carberry 1985], such elliptical fragments are often intended to elicit clarification and explanation of the repeated term. In addition to giving definitions in response to a request by the user, the expert may provide a definition as part of correcting a user misconception [McCoy 1986], or may generate definitions spontaneously. There are several reasons an expert may give spontaneous definitions. He may provide additional definitional information to justify use of a concept, tie may think it likely that the user doesn&apos;t know about the entity being introduced. The expert may want to ensure that he and the user are working with the same definition. The statement below is an example of a spontaneous definition from a recipe-giving dialogue: E: 3 &quot;You use a spring-form pan - - the kind that ,allows you to separate the bottom and the sides once you have prepared your dish.&quot; De"
C88-2119,J88-3006,0,\N,Missing
C90-2048,J86-3001,0,\N,Missing
C92-1049,P89-1026,0,0.264863,"Missing"
C92-1049,P91-1006,0,0.175518,"Missing"
C92-1049,J81-4001,0,0.101889,"Missing"
C92-1049,J89-2001,1,0.851792,"cognition of domain actions endows a system with the ability to successfnlly address m a n y important and difficult problems in understanding. Several researchers have also investigated the recognition of problem-solving actions [LA87, Ram9I, Wil81]. For example, if a user wants to earn a degree, the user might perform problem-solving actions of 1) evaluating alternative degrees (i.e., the user might decide whether a BS or a BA is more desirable), 2) instantiating the type of degree to be earned, and 3) building a plan for performing the domain action of earning the selected degree. Carberry [Car89] points out the importance of recognizing discourse actions, the communicative actions that speakers perform iu making an utterance (e.g., asking a question, providing baekgrouml information, or expressing surprise). Discourse actions provide expectations for subsequent utterances (e.g., when a question is asked, one expects the question to be accepted and eventually answered). Recognition of some discourse actions such ms Give-Background also explains the purpose of an utterance and bow it should be interpreted; rather than just a statement of fact, the utterance providing background informat"
C92-1049,P92-1025,1,\N,Missing
C92-1049,P91-1007,1,\N,Missing
C92-1049,J86-3001,0,\N,Missing
C98-1081,J93-4004,0,0.0366069,"vidual text plans represented as RST-style trees, and produces a smaller set of more complex trees representing integrated messages that still achieve the multiple communicative goals of the individual text plans. Domain-independent rules are used to capture strategies across domains, while the facility for addition of domain-dependent rules enables the system to be tuned to the requirements of a particular domain. The system has been tested on a corpus of critiques in the domain of t r a u m a care. 1 Overview Many natural language systems have been developed to generate coherent text plans (Moore and Paris, 1993; Hovy, 1991; Wanner and Hovy, 1996; Zukerman and MeConaehy, 1995). However, none has the ability to take a set of independently generated yet inter-related text plans and produce integrated plans that realize all of the communicative goals in a concise and coherent manner. R T P I (Rule-based Text Plan Integrator) was designed to perform this task. The need for coherence requires that the system be able to * This work was supported by the National Library of Medicine under grant R01-LM-05764-01. We thank Bonnie Webber and John Clarke for their suggestions and advice during the course of this"
C98-1081,W96-0401,0,0.39357,"T-style trees, and produces a smaller set of more complex trees representing integrated messages that still achieve the multiple communicative goals of the individual text plans. Domain-independent rules are used to capture strategies across domains, while the facility for addition of domain-dependent rules enables the system to be tuned to the requirements of a particular domain. The system has been tested on a corpus of critiques in the domain of t r a u m a care. 1 Overview Many natural language systems have been developed to generate coherent text plans (Moore and Paris, 1993; Hovy, 1991; Wanner and Hovy, 1996; Zukerman and MeConaehy, 1995). However, none has the ability to take a set of independently generated yet inter-related text plans and produce integrated plans that realize all of the communicative goals in a concise and coherent manner. R T P I (Rule-based Text Plan Integrator) was designed to perform this task. The need for coherence requires that the system be able to * This work was supported by the National Library of Medicine under grant R01-LM-05764-01. We thank Bonnie Webber and John Clarke for their suggestions and advice during the course of this research. 512 identify and resolve"
C98-2183,W95-0101,0,0.255952,"system replaces variables in the templates with appropriate values to generate rules. l~br example, the following template can be ~This condition is true only for the first utterance of a dialogue. 1151 instantiated with w = &quot; n o &quot; , X = S U G G E S T , and Y_=REJECT to produce the last rule in Figure 1. IF utterance lA contains the word w AND the tag on the utterance preceding ~l is X__ T H E N change u&apos;s tag to Y__ We have observed that TBL has a number of attractive characteristics for the task of computing dialogue acts. TBL has been effective on a similar 2 task, Part-of-Speech Tagging (Brill, 1995a). Also, TBL&apos;s rules are relatively intuitive, so a h u m a n (:an analyze tile rules to determine what the system has learned and perhaps develop a theory. TBL is very good at discarding irrelevant rules, because the effect of irrelevant rules on a training cortms is essentially random, resulting in low improvement scores. In addition, our implementation can accommodate a wide variety of different types of features, including set-valued features, features .that consider the context of surrounding utterances, and features that can take distant context into account. These and other attractive"
C98-2183,J86-3001,0,0.109164,"rtms is essentially random, resulting in low improvement scores. In addition, our implementation can accommodate a wide variety of different types of features, including set-valued features, features .that consider the context of surrounding utterances, and features that can take distant context into account. These and other attractive characteristics of TBL are discussed further in Samuel et al. (1998b). Dialogue Act Tagging To address a significant concern in machine learning, called the sparse d a t a problem, we nmst select an appropriate set of features. Researchers in discourse, such as Grosz and Sidner (1986), Lambert (1993), Hirschberg and Litman (1993), Chen (1995), Andernach (1996), Samuel (1996), and Chu-Carroll (1998) have suggested several features that might be relevant for the task of computing dialogue acts. Our system can consider the following features of an utterance: 1) tile cue phrases a in the utterance; 2) the word n-grams a in the utterance; 3) the dialogue act cues 3 in the utterance; 4) the entire utterance for one-, two-, or three-word utterances; 5) speaker information 4 for the utter2The part-of-speech tag of a word is dependent on the word&apos;s internal features and on the surr"
C98-2183,J93-3003,0,0.377499,"low improvement scores. In addition, our implementation can accommodate a wide variety of different types of features, including set-valued features, features .that consider the context of surrounding utterances, and features that can take distant context into account. These and other attractive characteristics of TBL are discussed further in Samuel et al. (1998b). Dialogue Act Tagging To address a significant concern in machine learning, called the sparse d a t a problem, we nmst select an appropriate set of features. Researchers in discourse, such as Grosz and Sidner (1986), Lambert (1993), Hirschberg and Litman (1993), Chen (1995), Andernach (1996), Samuel (1996), and Chu-Carroll (1998) have suggested several features that might be relevant for the task of computing dialogue acts. Our system can consider the following features of an utterance: 1) tile cue phrases a in the utterance; 2) the word n-grams a in the utterance; 3) the dialogue act cues 3 in the utterance; 4) the entire utterance for one-, two-, or three-word utterances; 5) speaker information 4 for the utter2The part-of-speech tag of a word is dependent on the word&apos;s internal features and on the surrounding words; similarly, the dialogue act of"
C98-2183,E95-1037,0,0.0140816,"ition, our implementation can accommodate a wide variety of different types of features, including set-valued features, features .that consider the context of surrounding utterances, and features that can take distant context into account. These and other attractive characteristics of TBL are discussed further in Samuel et al. (1998b). Dialogue Act Tagging To address a significant concern in machine learning, called the sparse d a t a problem, we nmst select an appropriate set of features. Researchers in discourse, such as Grosz and Sidner (1986), Lambert (1993), Hirschberg and Litman (1993), Chen (1995), Andernach (1996), Samuel (1996), and Chu-Carroll (1998) have suggested several features that might be relevant for the task of computing dialogue acts. Our system can consider the following features of an utterance: 1) tile cue phrases a in the utterance; 2) the word n-grams a in the utterance; 3) the dialogue act cues 3 in the utterance; 4) the entire utterance for one-, two-, or three-word utterances; 5) speaker information 4 for the utter2The part-of-speech tag of a word is dependent on the word&apos;s internal features and on the surrounding words; similarly, the dialogue act of an utterance"
C98-2183,P97-1011,0,0.038268,"Missing"
C98-2183,W97-0320,0,0.00990377,", to address limitations of TBL, we introduce a Monte Carlo strategy for training efficiently and a committee method for computing confidence measures. These ideas are combined in our working implementation, which labels held-out data as accurately as any other reported system for the dialogue act tagging task. Introduction Although machine learning approaches have achieved success in many areas of Natural Language Processing, researchers have only recently begun to investigate applying machine learning methods to discourse-level problems (Reithinger and Klesen, 1997; Di Eugenio et al., 1997; Wiebe et al., 1997; Andernach, 1996; Litman, 1994). An important task in discourse understanding is to interpret an utterance&apos;s dialogue act, which is a concise abstraction of a speaker&apos;s intention, such as SUGGEST and ACCEPT. Recognizing dialogue acts is critical for discourse-level understanding and can also be useful for other applications, such as resolving ambiguity in speech recognition. However, tomputing dialogue acts is a challenging task, because often a dialogue act cannot be directly inferred from a literal interpretation of an utterance. We have investigated applying Transformation-Based Learning ("
C98-2183,J95-4004,0,\N,Missing
J12-3004,W98-1435,0,0.0678968,"our future work. 2. Background 2.1 Related Work There has been a growing interest in language systems that generate textual summaries of non-linguistic input data (Reiter 2007). The overall goal of these systems, generally referred to as data-to-text systems, is to enable efﬁcient processing of large volumes of numeric data by supporting traditional visualisation modalities and to reduce the effort spent by human experts on analyzing the data. Various examples of datato-text systems in the literature include systems that summarize weather forecast data (Goldberg, Driedger, and Kittredge 1994; Coch 1998), stock market data (Kukich 1983), and georeferenced data (Turner, Sripada, and Reiter 2009). One of the most successful data-to-text generation research efforts is the SumTime project, which uses pattern recognition techniques to generate textual summaries of automatically generated time-series data in order to convey the signiﬁcant and interesting events (such as spikes and oscillations) that a domain expert would recognize by analyzing the data. The SumTime-Mousam (Somayajulu, Reiter, and Davy 2003) and SumTime-Turbine (Yu et al. 2007) systems were designed to summarize weather forecast dat"
J12-3004,P05-1007,0,0.0422219,"Missing"
J12-3004,W98-1501,0,0.0516016,"portant. We hypothesize that providing alternative access to what the graphic looks like is not enough and that the user should be provided with the message and knowledge that one would gain from viewing the graphic. We argue that the textual summaries generated by our approach could be associated with graphics as ALT texts so that individuals with sight impairments would be provided with the high-level content of graphics while reading electronic documents via screen readers. 2.2.2 Document Summarization. Research has extensively investigated various techniques for single (Hovy and Lin 1996; Baldwin and Morton 1998) and multi-document summarization (Goldstein et al. 2000; Schiffman, Nenkova, and McKeown 2002). The summary should provide the topic and an overview of the summarized documents by identifying the important and interesting aspects of these documents. Document summarizers generally evaluate and extract items of information from documents according to their relevance to a particular request (such as a request for a person or an event) and address discourse related issues such as removing redundancies (Radev et al. 2004) and ordering sentences (Barzilay, Elhadad, and McKeown 2002) in order to mak"
J12-3004,N06-1046,0,0.0679969,"Missing"
J12-3004,W08-1127,0,0.0925435,"Missing"
J12-3004,P87-1022,0,0.481365,"Missing"
J12-3004,W00-0405,0,0.124524,"o what the graphic looks like is not enough and that the user should be provided with the message and knowledge that one would gain from viewing the graphic. We argue that the textual summaries generated by our approach could be associated with graphics as ALT texts so that individuals with sight impairments would be provided with the high-level content of graphics while reading electronic documents via screen readers. 2.2.2 Document Summarization. Research has extensively investigated various techniques for single (Hovy and Lin 1996; Baldwin and Morton 1998) and multi-document summarization (Goldstein et al. 2000; Schiffman, Nenkova, and McKeown 2002). The summary should provide the topic and an overview of the summarized documents by identifying the important and interesting aspects of these documents. Document summarizers generally evaluate and extract items of information from documents according to their relevance to a particular request (such as a request for a person or an event) and address discourse related issues such as removing redundancies (Radev et al. 2004) and ordering sentences (Barzilay, Elhadad, and McKeown 2002) in order to make the summary more coherent. It is widely accepted that"
J12-3004,W11-2703,1,0.887556,"Missing"
J12-3004,J86-3001,0,0.637976,"Missing"
J12-3004,J95-2003,0,0.153317,"Missing"
J12-3004,P88-1020,0,0.237425,"Missing"
J12-3004,J09-1003,0,0.0326888,"Missing"
J12-3004,J04-4001,0,0.0628968,"Missing"
J12-3004,J03-1003,0,0.0347988,"Missing"
J12-3004,P83-1022,0,0.657399,"2.1 Related Work There has been a growing interest in language systems that generate textual summaries of non-linguistic input data (Reiter 2007). The overall goal of these systems, generally referred to as data-to-text systems, is to enable efﬁcient processing of large volumes of numeric data by supporting traditional visualisation modalities and to reduce the effort spent by human experts on analyzing the data. Various examples of datato-text systems in the literature include systems that summarize weather forecast data (Goldberg, Driedger, and Kittredge 1994; Coch 1998), stock market data (Kukich 1983), and georeferenced data (Turner, Sripada, and Reiter 2009). One of the most successful data-to-text generation research efforts is the SumTime project, which uses pattern recognition techniques to generate textual summaries of automatically generated time-series data in order to convey the signiﬁcant and interesting events (such as spikes and oscillations) that a domain expert would recognize by analyzing the data. The SumTime-Mousam (Somayajulu, Reiter, and Davy 2003) and SumTime-Turbine (Yu et al. 2007) systems were designed to summarize weather forecast data and the data from gas turbine e"
J12-3004,A97-1039,0,0.151601,"Missing"
J12-3004,J97-1004,0,0.0314434,"Missing"
J12-3004,C96-2123,0,0.126574,"phic is important. We hypothesize that providing alternative access to what the graphic looks like is not enough and that the user should be provided with the message and knowledge that one would gain from viewing the graphic. We argue that the textual summaries generated by our approach could be associated with graphics as ALT texts so that individuals with sight impairments would be provided with the high-level content of graphics while reading electronic documents via screen readers. 2.2.2 Document Summarization. Research has extensively investigated various techniques for single (Hovy and Lin 1996; Baldwin and Morton 1998) and multi-document summarization (Goldstein et al. 2000; Schiffman, Nenkova, and McKeown 2002). The summary should provide the topic and an overview of the summarized documents by identifying the important and interesting aspects of these documents. Document summarizers generally evaluate and extract items of information from documents according to their relevance to a particular request (such as a request for a person or an event) and address discourse related issues such as removing redundancies (Radev et al. 2004) and ordering sentences (Barzilay, Elhadad, and McK"
J12-3004,A97-1041,0,0.198943,"Missing"
J12-3004,W98-1411,0,0.0675056,"Missing"
J12-3004,J93-4004,0,0.464877,"Missing"
J12-3004,N03-2024,0,0.0917821,"Missing"
J12-3004,J88-3006,0,0.496121,"Missing"
J12-3004,W07-2315,0,0.136716,"content in natural language. Particular attention is devoted to our methodology for generating referring expressions for certain graphical elements such as a descriptor of what is being measured in the graphic. Section 8 presents a user study that was conducted to evaluate the effectiveness of the generated summaries for the purposes of this research by measuring readers’ comprehension. Section 9 concludes the article and outlines our future work. 2. Background 2.1 Related Work There has been a growing interest in language systems that generate textual summaries of non-linguistic input data (Reiter 2007). The overall goal of these systems, generally referred to as data-to-text systems, is to enable efﬁcient processing of large volumes of numeric data by supporting traditional visualisation modalities and to reduce the effort spent by human experts on analyzing the data. Various examples of datato-text systems in the literature include systems that summarize weather forecast data (Goldberg, Driedger, and Kittredge 1994; Coch 1998), stock market data (Kukich 1983), and georeferenced data (Turner, Sripada, and Reiter 2009). One of the most successful data-to-text generation research efforts is t"
J12-3004,P04-1011,0,0.0741627,"Missing"
J12-3004,W98-1419,0,0.0654086,"Missing"
J12-3004,J94-2006,1,0.474029,"Missing"
J12-3004,W09-0607,0,0.0295757,"Missing"
J12-3004,W09-0629,0,\N,Missing
J12-3004,X98-1026,0,\N,Missing
J88-3003,P85-1024,1,0.959453,"information-seeker to suggest variants of an ill-formed utterance that might represent the information-seeker's intentions or at least satisfy his perceived needs. We have also developed a method for understanding intersentential elliptical utterances that occur during the course of an informationseeking dialogue. Our strategy uses discourse expectations and our model of the speaker' s plan to identify the discourse goal that he is pursuing via an elliptical fragment and to interpret his elliptical utterance relative to his task-related plan. Our work on understanding ellipsis is presented in Carberry (1985). Section 2 of this paper briefly reviews related work in plan recognition, and Section 3 presents our strategy for dynamically inferring a model of the user's plan from an ongoing dialog. Section 4 describes our mechanism for reasoning on this context model to understand a class of utterances that is problematic for current natural language systems. These ideas have been implemented and tested in the IREPS system (Intelligent REsPonse System). This is an ongoing research effort whose objective is a robust natural language interface to information systems. The component that infers the user's"
J88-3003,C86-1006,1,0.865759,"Missing"
J88-3003,P86-1033,0,0.0621259,"e 14, Number 3, September 1988 Sandra Carberry Modeling the User's Plans and Goals Learn-Material(_agent:&PERSON, -sect:&SECTIONS, _syI:&SYLLABI) Plan-Body: Learn-From-Person(_agent:&PERSON, .sect:&SECTIONS, _fac:&FACULTY) where Teaches(_fac:&FACULTY, _sect:&SECTIONS) Learn-From-Text(.agent:&PERSON, _txt:&TEXTS) where Uses(_sect:&SECTIONS, _txt:&TEXTS) Effects: Learn-Material(_agent:&PERSON, -seet:&SECTIONS, -syl:&SYLLABI) Figure 1. Plan For Learning Course Material. individual utterances must be related to one another to build the user's plan as the dialog progresses. Sidner (1983, 1985) and Litman (1986) developed enhanced models of plan inference. However, both were concerned with dialogs that were initiated in order to begin or continue execution of an underlying task (display of structures on a graphics terminal and meeting/boarding a train), and the dialogs were therefore constrained by the order in which individual actions in the task had to be executed. In addition, Sidner investigated how discourse markers aid in recognizing the speaker's intent, and Litman studied a meta-plan framework for task dialogs. Pollack (1986) has recently proposed that plans be viewed as mental phenomena. She"
J88-3003,P86-1016,0,0.0428632,"le. This view is supported by the work of Pollack, Hirschberg, and Webber (1982). They suggested that expert-novice dialogs could be viewed as a negotiation process, during which not only an acceptable solution is negotiated, but also understanding of the terminology and the beliefs of the participants. The context model is one component of the system's beliefs, as is its belief that this model accurately reflects the plan under construction by IS. Modeling the User's Plans and Goals 5.1 RELATED WORK Several research efforts have addressed problems related to plan disparity. Kaplan (1982) and McCoy (1986) investigated misconceptions about domain knowledge and proposed responses intended to remove the misconceptions. However, such misconceptions may not be exhibited when they first influence the informationseeker's plan construction; in such cases, disparate plans may result, and correction will entail both a response correcting the misconception and further processing to bring the system's context model and the plan under construction by the information-seeker back into alignment. Allen's plan inference system (Allen et al. 1980) could accommodate some user misconceptions. It did not expressly"
J88-3003,J80-3003,0,0.0195639,"Missing"
J88-3003,P86-1032,0,0.768147,"ld the user's plan as the dialog progresses. Sidner (1983, 1985) and Litman (1986) developed enhanced models of plan inference. However, both were concerned with dialogs that were initiated in order to begin or continue execution of an underlying task (display of structures on a graphics terminal and meeting/boarding a train), and the dialogs were therefore constrained by the order in which individual actions in the task had to be executed. In addition, Sidner investigated how discourse markers aid in recognizing the speaker's intent, and Litman studied a meta-plan framework for task dialogs. Pollack (1986) has recently proposed that plans be viewed as mental phenomena. She contends that, in order to comprehend an utterance and relate it to the user's plan, the system must reason about the configuration of beliefs and intentions that it should ascribe to the speaker. This will be discussed further in Section 5. 3 INFERRINGAND MODELING THE TASK-RELATEDPLAN In order to reason about what the user wants to accomplish, the system must have knowledge about the goals that a user might pursue in a domain and plans for accomplishing these goals. We view a plan as the means by which an agent can accomplis"
J88-3003,J81-1001,0,0.122696,"aper, the information-seeker and inforraation-provider will be referred to as IS and IP, respectively. 2 RELATEDWORK ON PLAN RECOGNITION IN DIALOG Early work in dialog understanding concentrated on apprentice-expert dialogs, during which an expert guided an apprentice in performing a task. Grosz (1977) formulated heuristics for recognizing shifts in focus of attention in the task structure and presented a strategy that used the knowledge currently focused on by the dialog participants to identify the referents of definite noun phrases appearing in an utterance. Robinson (Robinson et al. 1980, Robinson 1981) extended Grosz's work and developed a process model for determining the referents of verb phrases, such as variants of do in the utterance "" I ' v e done it."" However, in apprentice-expert dialogs, the overall task that the apprentice is attempting to perform is known at the outset of the dialog, and the ordering of actions and subtasks in the plan being executed strongly influences the dialog between expert and apprentice. This differs from the kind of information-seeking dialogs that we are investigating, in which the information-seeker is attempting to construct a plan for a task that will"
J88-3003,J81-4001,0,0.0191391,"all task. One possible explanation for this behavior is that it may require less mental effort than switching back and forth among partially constructed plans for different subgoals. The second factor producing structure in our dialogs is their cooperative nature. Since the dialogs are cooperative and miscommunication can occur if both dialog participants are not focused on the same subset of knowledge (Grosz 1981), we expect IS to shift topic slowly between consecutive utterances and to adhere to the focusing constraints espoused by McKeown (1985). McKeown expanded on focus rules proposed by Sidner (1981) to explain how speakers should organize their utterances when faced with a choice of topic. In particular, McKeown claims that a speaker should move to a recently introduced topic if he has something further to say about it; otherwise he will have to reintroduce the topic at a later time. Similarly, the speaker should choose to finish discussion of the current topic before switching back to a previous one. Our focusing heuristics rely on these expectations about possible shifts in focus of attention in IS' s underlying task-related plan to identify which candidate focused plan is most apropos"
J88-3003,C80-1027,0,0.0239555,"roperties of the listener's world model. This is not to say that the speaker necessarily holds an incorrect view of the world, or even one that differs from the listener's view, but only that the semantic representation of the speaker's utterance does not conform to the listener's world model. We shall say that such an utterance is pragmatically ill-formed. Consider, for example, the query IS: ""What is the area of the special weapons magazine of the Alamo?"" that appears in a dialog transcript of an informationseeker attempting to load cargo onto ships using the REL natural language interface (Thompson 1980). A semantic representation of this query will contain the proposition Area(SPECIAL-WEAPONS-MAG, _areaval:&SQ-FT) The system was unable to understand this query, since its semantic representation erroneously presumed that storage locations had an area attribute in the associated data base. ff a human information-provider had a similar problem in understanding the utterance, or considered the meaning of "" a r e a "" ambiguous, he might be able to use the context established by the preceding dialog to identify what the information-seeker really wanted to know. For example, if IS's goal was to loa"
J89-2001,J88-3003,1,0.905708,"r, in attempting to deduce the speaker&apos;s intent, will be guided by Grice&apos;s conversational maxims (Grice 1975). In particular, Grice&apos;s maxims of manner and relation suggest that the speaker believes his utterance is an adequate vehicle for conveying his intentions and that the utterance is relevant to the current dialog. A cooperative listener will have assimilated the preceding dialog, inferred much of the underlying task-related plan motivating the speaker&apos;s queries, and be focused on that aspect of the task on which the information-seeker&apos;s attention was centered (Grosz 1977; Carberry 1983; Carberry 1988) immediately prior to the new utterance. Given an incomplete utterance, the listener can use this acquired knowledge to attempt to deduce the speaker&apos;s intentions by trying to fit the utterance into the partially constructed plan, and thereby enable the dialog to continue without interruption. This claim that the speaker&apos;s underlying task-related plan is an essential component of an ellipsis interpretation strategy is further supported by research demonstrating the need for considering such plans in understanding other types of utterances. Grosz (1977) and Robinson (1981) used models of the sp"
J89-2001,P83-1025,0,0.36131,"y range from sentences that fail to include all requisite semantic information to syntactically incomplete sentence fragments. In many cases, these utterances cannot be understood in isolation, but must be interpreted within the established context. Precisely how this should be done is a difficult problem for natural language systems. One might suggest that the problem be avoided in man-machine communication by training human users to employ only syntactically and semantically complete utterances. However, this does not appear to be feasible, as demonstrated in an empirical study conducted by Carbonell (1983) in which it was shown that human users find it easy to avoid complex syntactic structures but difficult to avoid incomplete utterances. Even if it were possible to train users to avoid incomplete utterances, these restrictions would be undesirable. Constraining man-machine communication to only a subset of the utterances normally employed by humans would force users to give less attention to their problem solving goals in order to concentrate more on the preciseness of their utterances. In addition, it appears that fragmentary utterances are not merely a result of sloppy communication. Althou"
J89-2001,H86-1021,0,0.0556372,"Missing"
J89-2001,J86-4002,0,0.0234372,"IS wants to know the referent of CS461 since CS461 was mentioned in IP&apos;s previous response; it is also reasonable for IP to believe that IS may not know the referent of CS461. Let us examine this latter belief in greater detail. One might ask why IP did not provide an extended description of CS461 in her previous response, if she believes that IS cannot satisfactorily identify the course from its department and number. This is not an issue with which this paper is concerned, but we will suggest one possibility. In constructing a description, IP uses knowledge about the listener (Appelt 1985, Goodman 1986) to produce a concise reference that she believes will be acceptable. Sometimes she will be quite certain that the listener will be able to identify the referent of her description--for example, perhaps the same description has been used successfully before. At other times, IP will be uncertain whether the description is sufficiently detailed; she could go to the extreme and include every detail at her disposal, but this may confuse the listener and hamper identification (Goodman 1986). Therefore, if IP does not know that IS can identify the referent of an entity from her description, she must"
J89-2001,J80-3003,0,0.657031,"Missing"
J89-2001,E89-1005,0,0.066559,"Missing"
J89-2001,J81-1001,0,0.199926,"z 1977; Carberry 1983; Carberry 1988) immediately prior to the new utterance. Given an incomplete utterance, the listener can use this acquired knowledge to attempt to deduce the speaker&apos;s intentions by trying to fit the utterance into the partially constructed plan, and thereby enable the dialog to continue without interruption. This claim that the speaker&apos;s underlying task-related plan is an essential component of an ellipsis interpretation strategy is further supported by research demonstrating the need for considering such plans in understanding other types of utterances. Grosz (1977) and Robinson (1981) used models of the speaker&apos;s task in apprentice-expert dialogs to determine the referents of definite noun phrases and verb phrases. Perrault and Allen (Perrault et al. 1980) used expectations of speaker goals, and inference of their plans for achieving these goals, in the interpretation of indirect speech acts. In addition, Allen (Allen et al. 1980) introduced the concept of a plan-based strategy for interpreting fragmentary utterances at the outset of a dialog in a restricted domain. 4.2 SHARED BELIEFS Shared beliefs, beliefs which the listener believes speaker and listener mutually hold, a"
J89-2001,J81-4001,0,0.59509,"erts back to addressing the original expectation and answers the initial query posed by IP. 4.4 PROCESSING KNOWLEDGE Our transcript analysis indicates that plan recognition strategies and focusing techniques are necessary components of processing knowledge for interpreting intersentential ellipsis. Plan recognition strategies are essential in order to infer a model of the speaker&apos;s underlying task-related plan, shown earlier to be an essential component of factual knowledge, and to consider possible expansions of that plan when processing elliptical fragments. Focusing techniques (Grosz 1977; Sidner 1981; Robinson 1981; McKeown 1985; Carberry 1988) are necessary in order to identify that portion of the underlying plan to which a fragmentary utterance refers. Consider again the dialog in Example 3. The focus of attention in this dialog is on considering the job applicants and evaluating them; therefore IS is most expected to continue with this subtask before considering other aspects of his overall task (Carberry 1983, 1988). As a result, IS&apos;s fragmentary utterance &quot;Tom&apos;s recommendation?&quot; will be understood as a request for Tom&apos;s opinion about the suitability of the job applicants for the job"
J89-2001,C80-1027,0,0.0173904,"ks include expanding a company&apos;s product line, purchasing a home, pursuing a degree, or even taking a vacation. We have selected this class of dialogs because they are typical of a large percentage of the interactions with database management systems, decision support systems, and expert systems. However, the principles presented in this paper should be extendible to other kinds of dialogs. Our hypotheses and strategies were motivated by an analysis of naturally occurring dialogs from several domains, including a radio call-in show 4 providing advice on investments, interactions with the REL (Thompson 1980) natural language interface to a ship data base, and student advisement sessions. We are assuming that the natural language system plays the role of information-provider and that communication is via a typical terminal. Since our primary interest in this research is the affect of expectations and inferred knowledge on 77 Sandra Carberry A Pragmatics-Based Approach to Ellipsis Resolution ellipsis understanding, we have not considered the contribution of clue words (words and phrases, such as &quot; N o w &quot; and &quot;As I was saying&quot;, that contain information about the structure of a discourse (Reichman 1"
J89-2001,P82-1016,0,0.0863985,"H e thinks Bob Jones and Ann Doe have the necessary background and should be invited for an interview.&quot; In Example 2, Speaker l&apos;s goal is to cash a check, and relevant plans can include a subplan for getting a particular distribution of paper money; in Example 3, Speaker l&apos;s goal is hiring programming consultants, perhaps for an introductory programming course, and the relevant plans for doing this include a subplan for identifying the best applicant. Previous research on understanding intersentential ellipsis has emphasized syntactic and semantic strategies (Hendrix et al. 1978; Waltz 1978; Weischedel and Sondheimer 1982; Carbonell 1983), but the contributions of the speaker&apos;s plans and goals to the interpretation of ellipsis has hitherto been inadequately explored. One objective of our research has been to investigate a plan-based framework for understanding intersentential ellipsis that occurs in task-oriented dialogs. Our work shows that elliptical fragments can be viewed as highlighting aspects of the information-seeker&apos;s task-related plan, with the focus of attention in the plan providing the context in which the fragment should be understood. But identifying the aspect of the speaker&apos;s plan highlighted"
J89-2001,J86-3001,0,\N,Missing
J98-3002,H91-1064,0,0.0300273,"REsolver), produces responses in a university course advisement domain, where the system plays the role of an advisor who is helping a student develop a plan to achieve her domain goal. 1 The system is mutually presumed to have greater expertise in some aspects of the domain (for example, the system is presumed to be an authority on requirements for degrees but to have less certain knowledge about other aspects such as individual professor&apos;s sabbatical plans), while the user is assumed to be more knowledgeable about his particular likes and dislikes. 2. Related Work 2.1 Modeling Collaboration Allen (1991) proposed a discourse model that differentiates among the shared and individual beliefs that agents might hold during collaboration. His model consists of six plan modalities, organized hierarchically with inheritance in order to accommodate the different states of beliefs during collaboration. The plan modalities include plan fragments that are private to an agent, those proposed by an agent but not yet acknowledged by the other, those proposed by an agent and acknowledged but not yet accepted by the other agent, and a shared plan between the two agents. Plan fragments move from the lower-lev"
J98-3002,P95-1019,1,0.832192,"fifty five. T: That one&apos;s sold out. C: That&apos;s sold out? T: Completely sold out. N o w there&apos;s a Delta four ten connects with Dallas arrives eight forty. We will use the term collaborative negotiation (Sidner 1994) to refer to the kinds of negotiation reflected in our transcripts, in which each agent is driven by the goal of devising a plan that satisfies the interests of the agents as a group, instead of one that maximizes their own individual interests. Further analysis shows that a couple of features distinguish collaborative negotiation from argumentation and noncollaborative negotiation (Chu-Carroll and Carberry 1995c). First, an agent engaging in collaborative negotiation does not insist on winning an argument, and will not argue for the sake of arguing; thus she may change her beliefs if another agent presents convincing justification for an opposing belief. This feature differentiates collaborative negotiation from argumentation (Birnbaum, Flowers, and McGuire 1980; Reichman 1981; Flowers and Dyer 1984; Cohen 1987; Quilici 1992). Second, agents involved in collaborative negotiation are open and honest with one another; they will not deliberately present false information to the other agents, present in"
J98-3002,J95-3003,0,0.150339,"atically accept claims that are presented to him, and would cause the speaker to believe that it is unnecessary to present evidence that the hearer already knows or should be able to infer (even though this evidence may not currently be part of his attentional focus). Walker investigated the efficiency of different communicative strategies, particularly the use of informationally redundant utterances (IRU&apos;s), under different assumptions about resource limits and processing costs, and her work suggests that effective use of IRU&apos;s can reduce effort during collaborative planning and negotiation. Heeman and Hirst (1995) investigated collaboration on referring expressions of objects copresent with the dialogue participants. They viewed the processes of building referring expressions and identifying their referents as a collaborative activity, and modeled them in a plan-based paradigm. Their model allows for negotiation in selecting amongst multiple candidate referents; however, such negotiation is restricted to the disambiguation process, instead of a negotiation process in which agents try to resolve conflicting beliefs. Edmonds (1994) studied an aspect of collaboration similar to that studied by Heeman and"
J98-3002,P91-1007,1,0.873118,"haw 1991). Furthermore, the agents may collaborate on establishing certain mutual beliefs that indirectly contribute to the construction of their domain plan. For example, they may collaborate on a mutual belief about whether a particular course is offered next semester as a means of determining whether taking the course is feasible. Finally, the agents engage in communicative actions in order to exchange the above desired information. To represent the different types of knowledge necessary for modeling a collaborative dialogue, we use an enhanced version of the tripartite model presented in (Lambert and Carberry 1991) to capture the intentions of the dialogue participants. The enhanced dialogue model (Chu-Carroll and Carberry 1994) has four levels: the domain level, which consists of the domain plan being constructed to achieve the agents&apos; shared domain goal(s); the problem-solving level which contains the actions being performed to construct the domain plan; the belief level, which consists of the mutual beliefs pursued to further the problem-solving intentions; and the discourse level which contains the communicative actions initiated to achieve the mutual beliefs. Actions at the discourse level can cont"
J98-3002,J87-1002,0,0.0287104,"their own individual interests. Further analysis shows that a couple of features distinguish collaborative negotiation from argumentation and noncollaborative negotiation (Chu-Carroll and Carberry 1995c). First, an agent engaging in collaborative negotiation does not insist on winning an argument, and will not argue for the sake of arguing; thus she may change her beliefs if another agent presents convincing justification for an opposing belief. This feature differentiates collaborative negotiation from argumentation (Birnbaum, Flowers, and McGuire 1980; Reichman 1981; Flowers and Dyer 1984; Cohen 1987; Quilici 1992). Second, agents involved in collaborative negotiation are open and honest with one another; they will not deliberately present false information to the other agents, present information in such a way as to mislead the other agents, or strategically hold back information from other agents for later use. This feature distinguishes collaborative negotiation from noncollaborative negotiation such as labor negotiation (Sycara 1989). As shown in Table 1, our corpus analysis also found 29 cases in which an agent either explicitly or implicitly indicated uncertainty about whether to ac"
J98-3002,C94-2182,0,0.0236694,"can reduce effort during collaborative planning and negotiation. Heeman and Hirst (1995) investigated collaboration on referring expressions of objects copresent with the dialogue participants. They viewed the processes of building referring expressions and identifying their referents as a collaborative activity, and modeled them in a plan-based paradigm. Their model allows for negotiation in selecting amongst multiple candidate referents; however, such negotiation is restricted to the disambiguation process, instead of a negotiation process in which agents try to resolve conflicting beliefs. Edmonds (1994) studied an aspect of collaboration similar to that studied by Heeman and Hirst. However, he was concerned with collaborating on references to objects that are not mutually known to the dialogue participants (such as references to landmarks in direction-giving dialogues). Again, Edmonds captures referent identification as a collaborative process and models it within the planning/plan recognition paradigms. However, he focuses on situations in which an agent&apos;s first attempt at describing a referent is considered insufficient by the recipient and the agents collaborate on expanding the descripti"
J98-3002,J88-3005,0,0.017828,"lyzed collaborative task-oriented dialogues and developed a theory of conversational acts that models conversation using actions at four different 358 Chu-Carroll and Carberry Response Generation in Planning Dialogues levels: turn-taking acts, grounding acts, core speech acts, and argumentation acts. However, his work focuses on the recognition of such actions, in particular grounding acts, and utilizes a simple dialogue management model to determine appropriate acknowledgments from the system. 2.2 Cooperative Response Generation Many researchers (McKeown, Wish, and Matthews 1985; Paris 1988; McCoy 1988; Sarner and Carberry 1990; Zukerman and McConachy 1993; Logan et al. 1994) have argued that information from the user model should affect a generation system&apos;s decision on what to say and how to say it. One user model attribute with such an effect is the user&apos;s domain knowledge, which Paris (1988) argues not only influences the amount of information given (based on Grice&apos;s Maxim of Quantity [Grice 1975]), but also the kind of information provided. McCoy(1988) uses the system&apos;s model of the user&apos;s domain knowledge to determine possible reasons for a detected misconception and to provide approp"
J98-3002,J93-4004,0,0.0337832,"ct and its immediate resolution&quot; (Logan et al. 1994, 141); thus they do not provide a mechanism for extended collaborative negotiation. On the other hand, our analysis of naturally occurring collaborative negotiation dialogues shows that conflict resolution does extend beyond a single exchange of conflicting beliefs; therefore we employ a recursive ProposeEvaluate-Modify framework that allows for extended negotiation. Furthermore, their system deals with one conflict at a time, while our model is capable of selecting a focus in its pursuit of conflict resolution when multiple conflicts arise. Moore and Paris (1993) developed a text planner that captures both intentional and rhetorical information. Since their system includes a Persuade operator for convincing a user to perform an action, it does not assume that the hearer would perform a recommended action without additional motivation. However, although they provide a mechanism for responding to requests for further information, they do not identify strategies for negotiating with the user if the user expresses conflict with the system&apos;s recommendation. Raskutti and Zukerman (1994) developed a system that generates disambiguating and information-seekin"
J98-3002,J88-3006,0,0.0462798,"m (1994) analyzed collaborative task-oriented dialogues and developed a theory of conversational acts that models conversation using actions at four different 358 Chu-Carroll and Carberry Response Generation in Planning Dialogues levels: turn-taking acts, grounding acts, core speech acts, and argumentation acts. However, his work focuses on the recognition of such actions, in particular grounding acts, and utilizes a simple dialogue management model to determine appropriate acknowledgments from the system. 2.2 Cooperative Response Generation Many researchers (McKeown, Wish, and Matthews 1985; Paris 1988; McCoy 1988; Sarner and Carberry 1990; Zukerman and McConachy 1993; Logan et al. 1994) have argued that information from the user model should affect a generation system&apos;s decision on what to say and how to say it. One user model attribute with such an effect is the user&apos;s domain knowledge, which Paris (1988) argues not only influences the amount of information given (based on Grice&apos;s Maxim of Quantity [Grice 1975]), but also the kind of information provided. McCoy(1988) uses the system&apos;s model of the user&apos;s domain knowledge to determine possible reasons for a detected misconception and to pr"
J98-3002,P86-1032,0,0.0109632,"the first type, while wh-questions and yes-no questions produce proposals for the second and third types of beliefs, respectively,s In order to provide the necessary information for performing proposal evaluation and response generation, we hypothesize a recognition algorithm, based on Lambert and Carberry (1991), that infers agents&apos; intentions from their utterances. This algorithm makes use of linguistic knowledge, contextual knowledge, and world knowledge, and utilizes a library of generic recipes for performing domain, problem-solving, and discourse actions. The library of generic recipes (Pollack 1986) contains templates for performing actions. The recipes are also used by our response generation system in planning its responses to user utterances, and will be discussed in further detail in Section 5.2. Our system is presented with a dialogue model capturing a new user proposal and its relation to the preceding dialogue. Based on our Propose-Evaluate-Modify framew o r k the system will evaluate the proposed domain and problem-solving actions, as well as the proposed mutual beliefs, to determine whether to accept the proposal. In 5 Note that wh-quesfions p r o p o s e that the agents come to"
J98-3002,C92-3136,0,0.0180016,"ndividual interests. Further analysis shows that a couple of features distinguish collaborative negotiation from argumentation and noncollaborative negotiation (Chu-Carroll and Carberry 1995c). First, an agent engaging in collaborative negotiation does not insist on winning an argument, and will not argue for the sake of arguing; thus she may change her beliefs if another agent presents convincing justification for an opposing belief. This feature differentiates collaborative negotiation from argumentation (Birnbaum, Flowers, and McGuire 1980; Reichman 1981; Flowers and Dyer 1984; Cohen 1987; Quilici 1992). Second, agents involved in collaborative negotiation are open and honest with one another; they will not deliberately present false information to the other agents, present information in such a way as to mislead the other agents, or strategically hold back information from other agents for later use. This feature distinguishes collaborative negotiation from noncollaborative negotiation such as labor negotiation (Sycara 1989). As shown in Table 1, our corpus analysis also found 29 cases in which an agent either explicitly or implicitly indicated uncertainty about whether to accept or reject"
J98-3002,P91-1006,0,0.0256954,"l, we first address the modeling of agent intentions, which forms the basis of our representation of agent proposals. 4. Modeling the Dialogue In task-oriented collaborative planning, the agents clearly collaborate on constructing their domain plan. In the university course advisement domain, a domain action may be agent A getting a Master&apos;s degree in CS (Get-Masters(A,CS)). The agents may also collaborate on the strategies used to construct the domain plan, such as determining whether to investigate in parallel the different plans for an action or whether to first consider one plan in depth (Ramshaw 1991). Furthermore, the agents may collaborate on establishing certain mutual beliefs that indirectly contribute to the construction of their domain plan. For example, they may collaborate on a mutual belief about whether a particular course is offered next semester as a means of determining whether taking the course is feasible. Finally, the agents engage in communicative actions in order to exchange the above desired information. To represent the different types of knowledge necessary for modeling a collaborative dialogue, we use an enhanced version of the tripartite model presented in (Lambert a"
J98-3002,P95-1005,0,0.0186751,"Missing"
J98-3002,C92-1054,0,0.617373,"eration in Planning Dialogues this paper, we focus on proposal evaluation and modification at the belief level. Readers interested in issues regarding proposal evaluation and modification with respect to proposed actions should refer to Chu-Carroll and Carberry (1994, in press) and Chu-Carroll (1996). 5. Determining Acceptance or Rejection of Proposed Beliefs 5.1 Evaluating Proposed Beliefs Previous research has noted that agents do not merely believe or disbelieve a proposition; instead, they often consider some beliefs to be stronger (less defeasible) than others (Lambert and Carberry 1992; Walker 1992; Cawsey et al. 1993). Thus, we associate a strength with each belief by an agent; this strength indicates the agent&apos;s confidence in the belief being an accurate description of situations in the real world. The strength of a belief is modeled with endorsements, which are explicit records of factors that affect one&apos;s certainty in a hypothesis (Cohen 1985), following Cawsey et al. (1993) and Logan et al. (1994). We adopt the endorsements proposed by Galliers (1992), based primarily on the source of the information, modified to include the strength of the informing agent&apos;s belief as conveyed by t"
J98-3002,P90-1010,0,0.0341382,"d our processes for evaluating proposed beliefs and initiating information-sharing to resolve the system&apos;s uncertainty in its acceptance of the proposal. The final outcome of the evaluation process is an informed decision about whether the system should accept or reject EA&apos;s proposal. When the system rejects EA&apos;s proposal, it will attempt to modify the proposal instead of simply discarding it. This section describes algorithms for producing responses in negotiation subdialogues initiated as part of the modification process. The collaborative planning principle in Whittaker and Stenton (1988); Walker and Whittaker (1990); and Walker (1992) suggests that &quot;conversants must provide evidence of a detected discrepancy in belief as soon as possible&apos;(Walker 1992, 349). Thus, once an agent detects a relevant conflict, she must notify the other agent of the conflict and attempt to resolve it--to do otherwise is to fail in her responsibilities as a collaborative participant. A conflict is &quot;relevant&quot; to the task at hand if it affects the domain plan being constructed. In terms of proposed beliefs, detected conflicts are relevant only if they contribute to resolving the agents&apos; disagreement about a top-level proposed bel"
J98-3002,P88-1015,0,0.00984727,"The previous section described our processes for evaluating proposed beliefs and initiating information-sharing to resolve the system&apos;s uncertainty in its acceptance of the proposal. The final outcome of the evaluation process is an informed decision about whether the system should accept or reject EA&apos;s proposal. When the system rejects EA&apos;s proposal, it will attempt to modify the proposal instead of simply discarding it. This section describes algorithms for producing responses in negotiation subdialogues initiated as part of the modification process. The collaborative planning principle in Whittaker and Stenton (1988); Walker and Whittaker (1990); and Walker (1992) suggests that &quot;conversants must provide evidence of a detected discrepancy in belief as soon as possible&apos;(Walker 1992, 349). Thus, once an agent detects a relevant conflict, she must notify the other agent of the conflict and attempt to resolve it--to do otherwise is to fail in her responsibilities as a collaborative participant. A conflict is &quot;relevant&quot; to the task at hand if it affects the domain plan being constructed. In terms of proposed beliefs, detected conflicts are relevant only if they contribute to resolving the agents&apos; disagreement a"
J98-3002,P92-1025,1,\N,Missing
J99-1001,P85-1024,1,0.482416,"or accomplishing a task. If the collaboration is to be successful, the participants must agree on the plan being constructed and the actions being taken to construct it. Thus, since a communicated proposition is presumed to be relevant to this plan construction process, the dialogue participants are obligated to communicate as soon as possible any discrepancies in belief about such propositions (Walker and Whittaker 1990; Chu-Carroll and Carberry 1995b) and to enter into a negotiation subdialogue in which they attempt to &quot;square away&quot; (Joshi 1982) their disparate beliefs. In our earlier work (Carberry 1985, 1989), we claimed that a cooperative participant must accept a response or pursue discourse goals directed toward being able to accept the response. As we noted there, this acceptance need not be explicitly communicated to the other participant; for example, failure to initiate a negotiation subdialogue con21 Computational Linguistics Volume 25, Number 1 veys implicit acceptance of the proposition communicated by an Inform action. This notion of implicit acceptance is similar to an expanded form of Perrault's default reasoning about the effects of an inform act (Perrault 1990). Our model cap"
J99-1001,J88-3003,1,0.470893,"I Ref-Request(EA,CA, _fac, Teaches(_fac,CS360)) I [ Surface-WH-Question(EA,CA, _fac, TeachesC.fac,CS360)) J EA: I I Answer-Ref(CA,EA, fac, Teaches(_fac,CS360)) [ Ilnform(CA, EA, Teaches(Dr.Smith,CS360)) [ * [Tell(CA, EA, Teaches(Dr.Smith,CS360)) I Who is teaching CS3607 I Surface-Say-Prop(CA,EA, Teaches(Dr.Smith,CS360)) I CA: Dr. Smith is teaching CS360. Key: * Currentfocusof attention Figure 5 Sample discourse tree. 4.4 Hypothesizing Discourse Acts by Chaining Our process model starts with the semantic representation of a new utterance and uses plan inference rules (Allen and Perrault 1980; Carberry 1988) along with constraint satisfaction (Litman and Allen 1987) to hypothesize chains of actions A1,A2 . . . . . An that the speaker might be intending to perform with the utterance. In such a chain, action Ai contributes to the performance of its successor action Ai+l. For example, the semantic representation of an utterance such as &quot;Dr. Smith is teaching Architecture&quot; is Surface-Say-Prop(_agentl, _agent2, Teaches(Dr.Smith, Architecture)) A Surface-Say-Prop is a subaction in the recipe for a Tell discourse act, which in turn is a subaction in the recipe for an Inform discourse act. Thus chaining"
J99-1001,J89-2001,1,0.691454,"Missing"
J99-1001,P95-1019,1,0.906938,"of evidence when that is all that is available. 4.6 Implicit Acceptance In a collaborative task-oriented dialogue, the participants are working together to construct a plan for accomplishing a task. If the collaboration is to be successful, the participants must agree on the plan being constructed and the actions being taken to construct it. Thus, since a communicated proposition is presumed to be relevant to this plan construction process, the dialogue participants are obligated to communicate as soon as possible any discrepancies in belief about such propositions (Walker and Whittaker 1990; Chu-Carroll and Carberry 1995b) and to enter into a negotiation subdialogue in which they attempt to &quot;square away&quot; (Joshi 1982) their disparate beliefs. In our earlier work (Carberry 1985, 1989), we claimed that a cooperative participant must accept a response or pursue discourse goals directed toward being able to accept the response. As we noted there, this acceptance need not be explicitly communicated to the other participant; for example, failure to initiate a negotiation subdialogue con21 Computational Linguistics Volume 25, Number 1 veys implicit acceptance of the proposition communicated by an Inform action. This"
J99-1001,J98-3002,1,0.584524,"Missing"
J99-1001,J87-1002,0,0.0333776,"s can either provide evidence for a generic discourse act (such as an expression of doubt) or evidence that the conditions are satisfied for performing a specific discourse act (such as expressing doubt that Dr. Smith is teaching Architecture). In addition, contextual knowledge can suggest a particular interpretation when equivalent evidence exists for several specific discourse acts. These knowledge sources are discussed in the next sections. 3.1 Linguistic Knowledge 3.1.1 Evidence for a Generic Discourse Act. A number of researchers (Reichman 1978, 1985; Grosz and Sidner 1986; Polanyi 1986; Cohen 1987; Hirschberg and Litman 1987; Litman and Allen 1987; Schiffrin 1987; Hinkelman 1989; Litman and Hirschberg 1990; Knott and Dale 1994; Knott and Mellish 1996; Marcu 1997) have investigated the use in discourse of special words and phrases such as but, anyway, and by the way. They found that these clue words, or discourse markers, have a number of different functions, including indicating the role of an utterance in the dialogue, conveying the relationship between utterances, suggesting shifts in focus of attention, conveying the structure of the discourse, etc. Consider again the dialogue shown"
J99-1001,J95-2003,0,0.0355993,"Missing"
J99-1001,J86-3001,0,0.506767,"ual knowledge. These knowledge sources can either provide evidence for a generic discourse act (such as an expression of doubt) or evidence that the conditions are satisfied for performing a specific discourse act (such as expressing doubt that Dr. Smith is teaching Architecture). In addition, contextual knowledge can suggest a particular interpretation when equivalent evidence exists for several specific discourse acts. These knowledge sources are discussed in the next sections. 3.1 Linguistic Knowledge 3.1.1 Evidence for a Generic Discourse Act. A number of researchers (Reichman 1978, 1985; Grosz and Sidner 1986; Polanyi 1986; Cohen 1987; Hirschberg and Litman 1987; Litman and Allen 1987; Schiffrin 1987; Hinkelman 1989; Litman and Hirschberg 1990; Knott and Dale 1994; Knott and Mellish 1996; Marcu 1997) have investigated the use in discourse of special words and phrases such as but, anyway, and by the way. They found that these clue words, or discourse markers, have a number of different functions, including indicating the role of an utterance in the dialogue, conveying the relationship between utterances, suggesting shifts in focus of attention, conveying the structure of the discourse, etc. Conside"
J99-1001,P89-1026,0,0.037815,"n of doubt) or evidence that the conditions are satisfied for performing a specific discourse act (such as expressing doubt that Dr. Smith is teaching Architecture). In addition, contextual knowledge can suggest a particular interpretation when equivalent evidence exists for several specific discourse acts. These knowledge sources are discussed in the next sections. 3.1 Linguistic Knowledge 3.1.1 Evidence for a Generic Discourse Act. A number of researchers (Reichman 1978, 1985; Grosz and Sidner 1986; Polanyi 1986; Cohen 1987; Hirschberg and Litman 1987; Litman and Allen 1987; Schiffrin 1987; Hinkelman 1989; Litman and Hirschberg 1990; Knott and Dale 1994; Knott and Mellish 1996; Marcu 1997) have investigated the use in discourse of special words and phrases such as but, anyway, and by the way. They found that these clue words, or discourse markers, have a number of different functions, including indicating the role of an utterance in the dialogue, conveying the relationship between utterances, suggesting shifts in focus of attention, conveying the structure of the discourse, etc. Consider again the dialogue shown in Figure 1. If EA had followed (7)-(8) with (9a) (9)a. EA: Isn't Architecture one"
J99-1001,P91-1007,1,0.766752,"logic in which belief/disbelief pairs capture how strongly a proposition is believed (Driankov 1988; Bonarini, Cappelletti, and Corrao 1990). 6 This work appears to be the only formally defined and well-developed logic that models strength of belief. With the exception that Driankov's logic does not inchide a state of weak belief, it appears to provide the representational and reasoning capability needed by our system and we intend to investigate it for future use. 4.2 Discourse Recipes In previous work, we noted the need to differentiate among domain, problem-solving, and discourse actions (Lambert and Carberry 1991; Elzer 1995). In task-oriented consultation dialogues, the participants are constructing a plan for achieving some domain goal, such as owning a home, and the resultant plan will consist of domain actions such as applying for a mortgage. In order to construct the domain plan, the participants pursue problem-solving actions such as evaluating alternative domain actions or correcting an action in the partially constructed domain plan. Domain and problemsolving actions have been investigated by many researchers (Allen and Perrault 1980; Perrault and Allen 1980; Wilensky 1981; Litman and Allen 19"
J99-1001,P92-1025,1,0.814966,"Missing"
J99-1001,C90-2044,0,0.0195882,"vidence that the conditions are satisfied for performing a specific discourse act (such as expressing doubt that Dr. Smith is teaching Architecture). In addition, contextual knowledge can suggest a particular interpretation when equivalent evidence exists for several specific discourse acts. These knowledge sources are discussed in the next sections. 3.1 Linguistic Knowledge 3.1.1 Evidence for a Generic Discourse Act. A number of researchers (Reichman 1978, 1985; Grosz and Sidner 1986; Polanyi 1986; Cohen 1987; Hirschberg and Litman 1987; Litman and Allen 1987; Schiffrin 1987; Hinkelman 1989; Litman and Hirschberg 1990; Knott and Dale 1994; Knott and Mellish 1996; Marcu 1997) have investigated the use in discourse of special words and phrases such as but, anyway, and by the way. They found that these clue words, or discourse markers, have a number of different functions, including indicating the role of an utterance in the dialogue, conveying the relationship between utterances, suggesting shifts in focus of attention, conveying the structure of the discourse, etc. Consider again the dialogue shown in Figure 1. If EA had followed (7)-(8) with (9a) (9)a. EA: Isn't Architecture one of our required courses? th"
J99-1001,P91-1005,0,0.0177297,"referring is viewed as a collaborative process and each conversation unit is viewed as a contribution, which consists of 1) an utterance that performs a referring action, and 2) the utterances required to understand the referent described in the utterance. Heeman (1991) implemented this model in a plan-based collaborative model of dialogue that is able to plan and recognize referring expressions and their corrections. Other collaborative models assume that two participants are working together to achieve a common goal (Cohen and Levesque 1990a, 1991a, 1991b; Lochbaum, Grosz, and Sidner 1990; Lochbaum 1991; Grosz and Sidner 1990; Searle 1990). Searle (1990) proposes a model in which the two agents working together have a joint intention, a &quot;we intention,&quot; instead of individual intentions. Cohen and Levesque (1990a, 1990b, 1990c, 1991a, 1991b) have developed a formal theory in which agents are jointly committed to accomplishing a goal, so both parties have individual intentions to accomplish the goal as part of their joint commitment. Grosz, Lochbaum, and Sidner (Grosz and Sidner 1990; Lochbaum, Grosz, and Sidner 1990; Lochbaum 1991) have specified a system in which two agents are working to acc"
J99-1001,J95-4001,0,0.0159846,"level; we will briefly discuss the domain and problem-solving levels in Section 5.1.) This latter case corresponds to initiating a new discourse segment, and thus a new discourse tree is constructed at the discourse level. Our algorithm identifies a best interpretation of the speaker's utterance. However, since the algorithm uses heuristics, its interpretation can be incorrect and miscommunication can result. Our current system does not include mechanisms for detecting and recovering from such errors. Clark and Schaeffer (1989) discuss second, third, and fourth turn repairs in discourse, and McRoy and Hirst (1995) provide an excellent formal model of repair in dialogue. 5. Modeling Negotiation Subdialogues The preceding sections have provided the key mechanisms necessary for modeling negotiation subdialogues. Our recipes differentiate between the effects and the goals of a discourse act. Thus, instead of assuming that a communicated proposition will automatically be accepted by the listener, the effect of our Inform action is only that 19 The action at the focus of attention and some of its ancestor actions may have completed successfully, which becomes evident when the participants choose not to addre"
J99-1001,J80-3003,0,0.081498,"m-solving, and discourse actions (Lambert and Carberry 1991; Elzer 1995). In task-oriented consultation dialogues, the participants are constructing a plan for achieving some domain goal, such as owning a home, and the resultant plan will consist of domain actions such as applying for a mortgage. In order to construct the domain plan, the participants pursue problem-solving actions such as evaluating alternative domain actions or correcting an action in the partially constructed domain plan. Domain and problemsolving actions have been investigated by many researchers (Allen and Perrault 1980; Perrault and Allen 1980; Wilensky 1981; Litman and Allen 1987; van Beek and Cohen 1986; Ramshaw 1989; Carberry 1990). Discourse actions are communicative actions that are executed by the dialogue participants in order to obtain or convey the information needed to pursue the problemsolving actions necessary for constructing the domain plan. Examples of very different discourse actions include answering a question, informing, and expressing doubt. Although our system models domain, problem-solving, and discourse actions, this paper is only concerned with recognizing discourse acts, particularly complex discourse acts"
J99-1001,E89-1005,0,0.0234068,"ed consultation dialogues, the participants are constructing a plan for achieving some domain goal, such as owning a home, and the resultant plan will consist of domain actions such as applying for a mortgage. In order to construct the domain plan, the participants pursue problem-solving actions such as evaluating alternative domain actions or correcting an action in the partially constructed domain plan. Domain and problemsolving actions have been investigated by many researchers (Allen and Perrault 1980; Perrault and Allen 1980; Wilensky 1981; Litman and Allen 1987; van Beek and Cohen 1986; Ramshaw 1989; Carberry 1990). Discourse actions are communicative actions that are executed by the dialogue participants in order to obtain or convey the information needed to pursue the problemsolving actions necessary for constructing the domain plan. Examples of very different discourse actions include answering a question, informing, and expressing doubt. Although our system models domain, problem-solving, and discourse actions, this paper is only concerned with recognizing discourse acts, particularly complex discourse acts such as expressing doubt. Our system's knowledge about how to perform actions"
J99-1001,P95-1016,0,0.0123543,"Missing"
J99-1001,P95-1005,0,0.0374058,"Missing"
J99-1001,C92-1054,0,0.0166245,"ssible topics might be addressed. However, she does not provide a detailed computational mechanism for recognizing the role of each utterance in a debate. 7.3 Models of Collaborative Behavior Several models of discourse have recently been built which view conversation as a kind of collaborative behavior in which speakers try to make themselves understood and listeners work with speakers to help speakers attain this goal. Clark and Schaefer (1989) contend that utterances must be &quot;grounded,&quot; or understood, by both parties, but they do not address conflicts in belief, only lack of understanding. Walker (1992) has found many occasions of redundancy in collaborative dialogues, and explains these by claiming that people repeat themselves in order to ensure that each utterance has been understood. 29 Clark and Wilkes-Gibbs (1990) propose a collaborative model of dialogue in which referring is viewed as a collaborative process and each conversation unit is viewed as a contribution, which consists of 1) an utterance that performs a referring action, and 2) the utterances required to understand the referent described in the utterance. Heeman (1991) implemented this model in a plan-based collaborative mod"
J99-1001,P90-1010,0,0.0929897,"ng to accept just one kind of evidence when that is all that is available. 4.6 Implicit Acceptance In a collaborative task-oriented dialogue, the participants are working together to construct a plan for accomplishing a task. If the collaboration is to be successful, the participants must agree on the plan being constructed and the actions being taken to construct it. Thus, since a communicated proposition is presumed to be relevant to this plan construction process, the dialogue participants are obligated to communicate as soon as possible any discrepancies in belief about such propositions (Walker and Whittaker 1990; Chu-Carroll and Carberry 1995b) and to enter into a negotiation subdialogue in which they attempt to &quot;square away&quot; (Joshi 1982) their disparate beliefs. In our earlier work (Carberry 1985, 1989), we claimed that a cooperative participant must accept a response or pursue discourse goals directed toward being able to accept the response. As we noted there, this acceptance need not be explicitly communicated to the other participant; for example, failure to initiate a negotiation subdialogue con21 Computational Linguistics Volume 25, Number 1 veys implicit acceptance of the proposition communic"
J99-1001,P87-1023,0,\N,Missing
J99-1001,P97-1013,0,\N,Missing
J99-3004,E91-1033,0,0.0323108,"nse. However, if R's beliefs have changed since the original question was asked by Q (e.g., as a result of information about Q's beliefs obtained from Q's follow-up question), then it is possible in our approach for R's response to contain different information. Furthermore, in our approach the original response may provide the information that a questioner would have to elicit by follow-up questions in a system that can provide only direct answers. Finally, our use of interpretation during plan pruning has precursors in previous work. In Horacek's,approach to generating concise explanations (Horacek 1991), a set of propositions representing the full explanation is pruned by eliminating propositions that can be derived from the remaining ones by a set of contextual rules. Jameson and Wahlster (1982) use an anticipation feedback loop algorithm to generate elliptical utterances. 6. Implementation and Evaluation We have implemented a prototype of the model in Common LISP. The implemented system can interpret and generate the types of examples discussed in Sections 4 and 5 and the specific examples tested in the experiments described below. The overall coverage of the implemented system can be defi"
J99-3004,P88-1020,0,0.13621,"Missing"
J99-3004,P91-1008,0,0.0344011,"ved. Our model predicts that the scalar implicature potentially licensed in (17)ii (i.e., that R has not gotten both letters for A yet) is no longer cancelable after R's turn in (17)iv, since b y that point, the participants apparently w o u l d share the belief that Q had succeeded in recognizing R's discourse plan u n d e r l y i n g (17)iiY (17) i. Q: H a v e y o u gotten the letters for A yet? ii. R: I've gotten the letter from X. iii. Q: Then let's discuss B now. iv. R: O.K. I think we should interview B, d o n ' t you? Inference of coherence relations has been used in modeling temporal (Lascarides and Asher 1991; Lascarides, Asher, and Oberlander 1992) and other defeasible discourse inferences (Hobbs 1978; Dahlgren 1989). Inference of plausible coherence relations is necessary but not sufficient for interpreting indirect answers. For example, Q also must believe that there is a shared discourse expectation of an answer to a particular question. In other words, in our model, discourse plans provide additional constraints on the beliefs and intentions of the speaker that a hearer uses in interpreting a response. Another limitation of the above approaches is that they provide no explanation for the p h"
J99-3004,P92-1001,0,0.0577005,"Missing"
J99-3004,J93-4004,0,0.194944,"-indicated, as illustrated in Section 5.2.7. 58 However, Hirschberg's model does not account for other types of indirect answers, which can be constructed using the other operators (or other combinations of the above operators) in our model, nor for other motives for selecting Use-contrast such as answer-ref-indicated and appeasement-indicated. Rhetorical or coherence relations (Grimes 1975; Halliday 1976; M a n n and T h o m p son 1988) have been used in several text-generation systems to aid in ordering parts of a text (e.g., H o v y 1988) as well as in content planning (e.g., McKeown 1985; Moore and Paris 1993). The discourse plan operators based on coherence relations in our model 58 As mentioned earlier, the coherence rules for cr-contrast as well as the rules for clarify-extent-indicated make use of notions elucidated by Hirschberg (1985). 425 Computational Linguistics Volume 25, Number 3 (i.e., the operators used as satellites of top-level operators) play a similar role in content planning. However, none of the above approaches model the speaker's motivation for selecting optional satellites. Stimulus conditions provide principled discourse-level knowledge (based upon principles of efficiency, a"
J99-3004,J92-4007,0,0.0280092,"model the speaker's motivation for selecting optional satellites. Stimulus conditions provide principled discourse-level knowledge (based upon principles of efficiency, accuracy, and politeness) for choice of an appropriate discourse strategy. Also, stimulus conditions enable content selection to be sensitive not only to the current discourse context, but also to the anticipated effect of a part of the planned response. Finally, none of the above systems incorporate a model of discourse plan recognition into the generation process, which enables indirect answers to be generated in our model. Moore and Pollack (1992) show the need to distinguish the intentional and informational structure of discourse, where the latter is characterized by the sort of relations classified as subject-matter relations in RST. In our model, the operators used as satellites of top-level answer discourse plan operators are based on relations similar to RST's subject-matter relations. The primary goals of these operators are similar to the effect fields of the corresponding RST relation definitions. However, our model does distinguish the two types of knowledge. In our model stimulus conditions reflect, though they do not direct"
J99-3004,J80-3003,0,0.780051,"relations is necessary but not sufficient for interpreting indirect answers. For example, Q also must believe that there is a shared discourse expectation of an answer to a particular question. In other words, in our model, discourse plans provide additional constraints on the beliefs and intentions of the speaker that a hearer uses in interpreting a response. Another limitation of the above approaches is that they provide no explanation for the p h e n o m e n o n of loss of cancelability described above. Plan recognition has been used to m o d e l the interpretation of indirect speech acts (Perrault and Allen 1980; H i n k e l m a n 1989) and ellipsis (Carberry 1990; Litman 1986), discourse p h e n o m e n a that share with conversational implicature the two necessary conditions described above, cancelablity and speaker intention. However, these models are inadequate for interpreting indirect answers, i.e., for deriving an implicated answer p from an indirect answer q. In these models, for p to be derivable from q, it is necessary 34 of course, in the case where R provides only I'm going to campus, both yes and no interpretations would be inferred as equally plausible in our model. Although prosodic in"
P84-1045,J83-3003,0,\N,Missing
P84-1045,C80-1008,0,\N,Missing
P84-1045,C80-1027,0,\N,Missing
P84-1045,P84-1030,0,\N,Missing
P85-1024,P82-1016,0,0.0344206,"Missing"
P85-1024,J80-3003,0,\N,Missing
P85-1024,J81-1001,0,\N,Missing
P85-1024,J83-3001,0,\N,Missing
P85-1024,J81-4001,0,\N,Missing
P85-1024,P83-1007,0,\N,Missing
P85-1024,P83-1025,0,\N,Missing
P85-1024,P82-1028,0,\N,Missing
P85-1024,P84-1063,0,\N,Missing
P91-1007,J89-2001,1,0.874575,"Missing"
P91-1007,J80-3003,0,0.0325728,"Missing"
P91-1007,P91-1006,0,0.0772077,"Missing"
P91-1007,P88-1020,0,0.0429644,"Missing"
P91-1007,P91-1052,1,\N,Missing
P91-1007,P89-1025,0,\N,Missing
P91-1007,J86-3001,0,\N,Missing
P92-1009,P90-1012,1,0.497848,"Missing"
P92-1009,P89-1025,0,0.0223559,"in which a speaker actually changes her mind. In our model, since implicatures correspond to goals of inferred or constructed hierarchical plans, we avoid this problem. (22A) and (23A) both correspond to step 2 of Affirm (with Elaboration), TelI(S,H,B); several different discourse plan operators can be used to construct a plan for this Tell action. For example, one operator for Tell(S,H,B) is given below in (24); the operator represents that in telling H that B, where B describes an agent's volitional action, a speaker may provide motivation for the agent's action. 8To use the terminology of (Moore & Paris, 1989; Moore & Paris, 1988), the labelled arcs represent satellites, a n d the unlabelled arcs nucleii. However, note t h a t in their model, a nucleus can n o t be optional. T h i s differs from our approach, in t h a t we have shown t h a t direct replies are optional in contexts such as those described by plan operators such as Affirm (with Elaboration). 9Determiuing this requires t h a t the e n d of the relevant discourse u n i t be marked/recognlzed by cue phrases, intonation, or shift of focus; we plan to investigate this problem. 68 Affirm (with Elaboration) I (Elaboration) Tell (MVA) I wen"
P92-1009,P84-1044,0,0.0486086,"In (8), as in (6), A is a proposition that an action of type T was not performed. (8) Deny (with Obstacle) Applicability conditions: 1) S BMB plausible(Obstacle(B,A)) Bo~ (unordered) : (optional) S inform H that A 2) T e l I ( S , H , B ) Goals: 1) H believe t h a t A 2) H believe that Obstacle(B,A) In (8) (and in the discourse plan operators to follow) the"" formalism described above is used; 'S' and 'H' denote speaker and hearer, respectively; 'BMB' is the one-sided mutual beliefs operator (Clark & Marshall, 1981); 'inform' denotes an illocutionary act of informing; 'believe' is Hintikka's (Hintikka, 1962) belief operator; 'TelI(S,H,B)' is a subgoal that can be achieved in a number of ways (to b e discussed shortly), including just by S informing H that B; and steps of the body are not ordered. (Note that to use these operators for generation of direct replies, we must provide a method to determine a suitable ordering of the steps. Also, although it is sufficient for interpretation to specify that step 1 is optional, for generation, more information is required to decide whether it can or should be omitted; e.g., it should not be omitted if S believes that H might believe that some relation bes"
P92-1009,E91-1033,0,0.0583446,"Missing"
P92-1009,J80-3003,0,0.767438,"cularized conversational implicature (Green, 1990; Horacek, 1991; Joshi, Webber & Weischedel, 1984a; .]oshi, Webber Weischedel, 1984b; Reiter, 1990; Whiner & Maida, 1991) has treated other kinds of implicature than we consider here. ttirschberg (Hirschberg, 1985) provided licensing rules making use of mutual beliefs about salient partial orderings of entities in 1°We plan to implement an inference mechanism for the discourse relation inference rules. 11Note that A's goals depend, in part, on the illocutionarylevel representation of Q's request. We assume that an analysis, such as provided in (Perrault & Allen, 1980), is available. 69 4 the discourse context to calculate the scalar implicatures of an utterance. Our model is similar to Hirschberg's in that both rely on the representation of aspects of context to generate implicatures, and our discourse plan operators are roughly analogous in function to her licensing rules. However, her model makes no use of discourse relations. Therefore, it does not handle several kinds of indirect replies which we treat. For example, although A in (27) could be analyzed as scalar implicating a 'no' in some contexts, Hirschberg's model could not account for the use of A"
P92-1009,P88-1020,0,0.189487,"Missing"
P92-1009,H86-1017,0,0.024141,"Missing"
P92-1009,P90-1013,0,0.0286038,"e for ,hich a) the applicability conditions hold, and b) the goals include S's goals. 2. If more than one operator was selected in step I, then choose one. Also, determine step ordering and whether it is necessary to include optional steps. (We are currently investigating how these choices are determined.) 3. Construct a plan from the chosen operator and execute it. 3 Comparison search to Past ReMost previous work in computational or formal linguistics on particularized conversational implicature (Green, 1990; Horacek, 1991; Joshi, Webber & Weischedel, 1984a; .]oshi, Webber Weischedel, 1984b; Reiter, 1990; Whiner & Maida, 1991) has treated other kinds of implicature than we consider here. ttirschberg (Hirschberg, 1985) provided licensing rules making use of mutual beliefs about salient partial orderings of entities in 1°We plan to implement an inference mechanism for the discourse relation inference rules. 11Note that A's goals depend, in part, on the illocutionarylevel representation of Q's request. We assume that an analysis, such as provided in (Perrault & Allen, 1980), is available. 69 4 the discourse context to calculate the scalar implicatures of an utterance. Our model is similar to Hir"
P92-1009,P84-1029,0,0.0846765,"Missing"
P92-1009,P91-1007,1,0.808081,"ints in a coherent conversation, the participants share certain expectations (Reichman, 1984; Carberry, 1990) about what kind of utterance is appropriate. In the type of exchange we are studying, at the point after Q's contribution, the participants share the beliefs that Q has requested to be informed if p and that the request was appropriate; hence, they share the discourse expectation that for A to be cooperative, he must now say as much as he can truthfully say in regard to the truth of p. (For convenience, we shall refer to this expectation as Answer-YNQ(p).) A discourse plan operator 3 (Lambert & Carberry, 1991) is a representation of a normal or conventional way of accomplishing certain communicative goals. Alternatively, a discourse plan operator could be considered as a defeasihle rule expressing the typical (intended) effect(s) of a sequence of illocutionary acts in a context in which certain applicability conditions hold. These discourse plan operators are mutually known by the conversational participants, and can be used by a speaker to construct a plan for achieving his communicative goals. We provide a set of discourse plan operators which can be used by A as part of a plan for fulfilling Ans"
P92-1009,P91-1008,0,0.0433879,"r algorithms (including developing an inference mechanism for the discourse relation rules); extending our model to other types of implicatures; and investigating the integration of our model into general interpretation and generation frameworks. (27) Q: Did you read the first chapter? A: I took it to the beach with me. Furthermore, Hirschberg provided no computational method for determining the salient partially ordered set in a context. Also, in her model, implicatures are calculated one sentence at a time, which has the potential problems described above. Lascarides, Asher, and Oberlander (Lascarides & Asher, 1991; Lascarides & Oberlander, 1992) described the interpretation and generation of temporal implicatures. Although that type of implicature (being Manner-based) is somewhat different from what we are studying, we have adopted their technique of providing defeasible inference rules for inferring discourse relations. References In philosophy, Thomason (Thomason, 1990) suggested that discourse expectations play a role in some implicatures. McCafferty (McCafferty, 1987) argued that interpreting certain implicated replies requires domain plan reconstruction. However, he did not provide a computational"
P92-1025,P91-1007,1,0.755039,"). Others have examined more cooperative dialogues. Clark and Schaefer (1989) contend that utterances must be grounded, or understood, by both parties, but they do not address conflicts in belief, only lack of understanding. Walker (1991) has shown that evidence is often provided to ensure both understanding and believing an utterance, but she does not address recognizing lack of belief or lack of understanding. Reichman (1981) outlines a model for informal debate, but does not provide a detailed computational mechanism for recognizing the role of each utterance in a debate. In previous work (Lambert and Carberry, 1991), we described a tripartite plan-based model of dialogue that recognizes and differentiates three different kinds of actions: domain, problemsolving, and discourse. Domain actions relate to performing tasks in a given domain. We are modeling cooperative dialogues in which one agent has a domain goal and is working with another helpful, more expert agent to determine what domain actions to perform in order to accomplish this goal. Many researchers (Allen, 1979; Carberry, 1987; Goodman and Litman, 1992; Pollack, 1990; Sidner, 1985) have shown that recognition of domain plans and goals gives a sy"
P92-1025,C92-1049,1,0.761833,"Missing"
P92-1025,J87-1002,0,0.198996,"Missing"
P92-1025,P91-1006,0,0.116677,"erative dialogues in which one agent has a domain goal and is working with another helpful, more expert agent to determine what domain actions to perform in order to accomplish this goal. Many researchers (Allen, 1979; Carberry, 1987; Goodman and Litman, 1992; Pollack, 1990; Sidner, 1985) have shown that recognition of domain plans and goals gives a system the ability to address many difficult problems in understanding. Problem-solving actions relate to how the two dialogue participants are going about building a plan to achieve the planning agent&apos;s domain goal. Ramshaw, Litman, and Wilensky (Ramshaw, 1991; Litman and Allen, 1987; Wilensky, 1981) have noted the need for recognizing problem-solving actions. Discourse actions are the communicative actions that people perform in saying something, e.g., asking a question or expressing doubt. Recognition of discourse actions provides expectations for subsequent utterances, and explains the purpose of an utterance and how it should be interpreted. Our system&apos;s knowledge about how to perform actions is contained in a library of discourse, problem-solving, and domain recipes (Pollack, 1990). Although domain recipes are not mutually known by the partici"
P92-1025,C92-1054,0,\N,Missing
P92-1025,P89-1026,0,\N,Missing
P92-1025,J86-3001,0,\N,Missing
P94-1009,P90-1012,1,0.939315,"Missing"
P94-1009,P92-1009,1,0.905095,"Missing"
P94-1009,P88-1020,0,0.171462,"Missing"
P94-1009,P91-1008,0,0.0569378,"Missing"
P94-1009,J80-3003,0,0.677671,"Missing"
P95-1019,H91-1064,0,0.260488,"ion (Birnbaum et al., 1980; Reichman, 1981; Cohen, 1987; Quilici, 1992). 2) Agents involved in collaborative negotiation are open and honest with one another; they will not deliberately present false information to other agents, present information in such a way as to mislead the other agents, or strategically hold back information from other agents for later use. This distinguishes collaborative negotiation from non-collaborative negotiation such as labor negotiation (Sycara, 1989). 3) Collaborative agents are interested in 1The notion of shared plan has been used in (Grosz and Sidner, 1990; Allen, 1991). 137 others' beliefs in order to decide whether to revise their own beliefs so as to come to agreement (Chu-Carroll and Carberry, 1995). Although agents involvedin argumentation and non-collaborative negotiation take other agents' beliefs into consideration, they do so mainly to find weak points in their opponents' beliefs and attack them to win the argument. In our earlier work, we built on Sidner's proposal/acceptance and proposal/rejection sequences (Sitnet, 1994) and developed a model tha¢ captures collaborative planning processes in a Propose-Evaluate-Modify cycle of actions (Chu-Carroll"
P95-1019,J87-1002,0,0.786824,"the conflicts by engaging in collaborative negotiation to determine what should constitute their shared plan of actions and shared beliefs. Collaborative negotiation differs from non-collaborative negotiation and argum_entation mainly in the attitude of the participants, since collaborative agents are not selfcentered, but act in a way as to benefit the agents as This material is based upon work supported by the National Science Foundation under Grant No. IRI-9122026. 136 Related W o r k Researchers have studied the analysis and generation of arguments (Birnbaum et al., 1980; Reichman, 1981; Cohen, 1987; Sycara, 1989; Quilici, 1992; Maybury, 1993); however, agents engaging in argumentative dialogues are solely interested in winning an argument and thus exhibit different behavior from collaborative agents. Sidner (1992; 1994) formulated an artificial language for modeling collaborative discourse using propo~acceptance and proposal/rejection sequences; however, her work is descriptive and does not specify response generation strategies for agents involved in collaborative interactions. Webber and Joshi (1982) have noted the importance of a cooperative system providing support for its responses"
P95-1019,P91-1007,1,0.771116,"proposal to address or how to select evidence to support the proposed modification. This paper extends that work by i ~ t i n g into the modification process a slrategy to determine the aspect of the proposal that the agent will address in her pursuit of conflict resolution, as well as a means of selecting appropriate evidence to justify the need for such modification. 4 Response Generation in Collaborative Negotiation In order to capture the agents' intentions conveyed by their utterances, our model of collaborative negotiation utilizes an enhanced version of the dialogue model described in (Lambert and Carberry, 1991) to represent the current status of the interaction. The enhanced dialogue model has four levels: the domain level which consists of the domain plan being constructed for the user's later execution, the problem-solving level which contains the actions being performed to construct the don ~ n plan, the belief level which consists of the mutual beliefs pursued during the planning process in order to further the problem-solving intentions, and the discourse level which contains the communicative actions initiated to achieve the mutual beliefs (Chu-Carroll and Carberry, 1994). This paper focuses o"
P95-1019,P86-1032,0,0.193052,"and its subaction, Modify-Node, that is responsible for the actual modification of the proposal. The applicability conditions 5 of Correct-Node specify that the action can only be invoked when _sl believes that _node is not acceptable while _s2 believes that it is (when _sl and _s2 disagree about the proposed belief represented by ..node). However, since this is a collaborative interaction, the actual modification can only be performed when both ..sl and _s2 believe that _node is not acceptable w that is, the conflict between _sl and .s2 must have been resolved. This is captured by 4A recipe (Pollack, 1986) is a template for performing actions. It contains the applicabifity conditions for performing an action, the subactions comprising the body of an action, etc. SApplicabflity conditions are conditions that must already be satisfied in order for an action to be reasonable to pursue, whereas an agent can try to achieve unsatisfied preconditions. 139 Modify-Node(..s I,..s2,.4noposed,.suxle) Specialization believe(.s 1,.-,acceptable(...node)) believe(.s2,-,acceptable(_node)) Remove-Node(_sl,_s2,_proposed,..node) Alter-Node(.s l,_s2,.proposed,.node) mod~ed(.proposed) Figure 2: The Correct-Nodeand M"
P95-1019,C92-3136,0,0.261368,"in collaborative negotiation to determine what should constitute their shared plan of actions and shared beliefs. Collaborative negotiation differs from non-collaborative negotiation and argum_entation mainly in the attitude of the participants, since collaborative agents are not selfcentered, but act in a way as to benefit the agents as This material is based upon work supported by the National Science Foundation under Grant No. IRI-9122026. 136 Related W o r k Researchers have studied the analysis and generation of arguments (Birnbaum et al., 1980; Reichman, 1981; Cohen, 1987; Sycara, 1989; Quilici, 1992; Maybury, 1993); however, agents engaging in argumentative dialogues are solely interested in winning an argument and thus exhibit different behavior from collaborative agents. Sidner (1992; 1994) formulated an artificial language for modeling collaborative discourse using propo~acceptance and proposal/rejection sequences; however, her work is descriptive and does not specify response generation strategies for agents involved in collaborative interactions. Webber and Joshi (1982) have noted the importance of a cooperative system providing support for its responses. They identified strategies"
P95-1019,P90-1010,0,0.700023,"Missing"
P95-1019,C92-1054,0,0.563068,"ollaborative agents agree on a belief relevant to the domain plan being constructed, it is irrelevant whether they agree on the evidence for that belief (Young et al., 1994). In determining whether to accept a proposed befief or evidential relationship, the evaluator first constructs an evidence set containing the system's evidence thin supports or attacks _bcl and the evidence accepted by the system that was proposed by the user as support for -bel. Each piece of evidence contains a belief _beli, and an evidential relationship supports(.beli,-bel). Following Walker's weakest link assumption (Walker, 1992) the strength of the evidence is the weaker of the strength of the belief and the strength of the evidential relationship. The evaluator then employs a simplified version of Galliers' belief revision mechanism 2 (Galliers, 1992; Logan et al., 1994) to compare the strengths of the evidence that supports and attacks _bel. If the strength of one set of evidence strongly outweighs that of the other, the decision to accept or reject.bel is easily made. However, if the difference in their strengths does not exceed a pre-determined ., ~.&quot; -~ MB~3tSt-Teaches(Smith~I)) ] a ; 1 ~q. , i[MB~J,S,O.-S~,~KS,"
P95-1019,C94-2196,0,0.0549935,"from collaborative agents. Sidner (1992; 1994) formulated an artificial language for modeling collaborative discourse using propo~acceptance and proposal/rejection sequences; however, her work is descriptive and does not specify response generation strategies for agents involved in collaborative interactions. Webber and Joshi (1982) have noted the importance of a cooperative system providing support for its responses. They identified strategies that a system can adopt in justifying its beliefs; however, they did not specify the criteria under which each of these strategies should be selected. Walker (1994) described a method of determining when to include optional warrants to justify a claim based on factors such as communication cost, inference cost, and cost of memory retrieval. However, her model focuses on determining when to include informationally redundant utterances, whereas our model determines whether or not justification is needed for a claim to be convincing and, ff so, selects appropriate evidence from the system's private beliefs to support the claim. Caswey et al. (Cawsey et al., 1993; Logan et al., 1994) introduced the idea of utilizing a belief revision mechanism (Galliers, 199"
P95-1019,C82-1066,0,0.399539,"ers have studied the analysis and generation of arguments (Birnbaum et al., 1980; Reichman, 1981; Cohen, 1987; Sycara, 1989; Quilici, 1992; Maybury, 1993); however, agents engaging in argumentative dialogues are solely interested in winning an argument and thus exhibit different behavior from collaborative agents. Sidner (1992; 1994) formulated an artificial language for modeling collaborative discourse using propo~acceptance and proposal/rejection sequences; however, her work is descriptive and does not specify response generation strategies for agents involved in collaborative interactions. Webber and Joshi (1982) have noted the importance of a cooperative system providing support for its responses. They identified strategies that a system can adopt in justifying its beliefs; however, they did not specify the criteria under which each of these strategies should be selected. Walker (1994) described a method of determining when to include optional warrants to justify a claim based on factors such as communication cost, inference cost, and cost of memory retrieval. However, her model focuses on determining when to include informationally redundant utterances, whereas our model determines whether or not ju"
P95-1019,P88-1015,0,0.190376,"address the unaccepted evidence proposed by the user to eliminate the user's justification for the belief, or both. Since collaborative agents are expected to engage in effective and efficient dialogues, the system should address the unaccepted belief that it predicts will most quickly resolve the top-level conflict. Therefore, for each unaccepted top-level belief, our process for selecting the focus of modificatkm involves two steps: identifying a candidate foci tree from the proposed belief tree, and selecting a eThis subdialogue is considered an interrupt by Whittaker, Stenton, and Walker (Whittaker and Stenton, 1988; Walker and Whittaker, 1990), initiated to negotiate the truth of a piece of information. However, the utterances they classify as interrupts include not only our negotiation subdialogues, generated for the purpose of modifying a proposal, but also clarification subdialogues, and information-sharing subdialogues (Chu-Carroll and Carberry, 1995), which we contend should be part of the evaluation process. focus from the candidate foci tree using the heuristic &quot;attack the belief(s) that will most likely resolve the conflict about the top-level belief.&quot; A candidate loci tree contains the pieces o"
P98-1084,J93-4004,0,0.0377694,"individual text plans represented as RST-style trees, and produces a smaller set of more complex trees representing integrated messages that still achieve the multiple communicative goals of the individual text plans. Domain-independent rules are used to capture strategies across domains, while the facility for addition of domain-dependent rules enables the system to be tuned to the requirements of a particular domain. The system has been tested on a corpus of critiques in the domain of trauma care. 1 Overview Many natural language systems have been developed to generate coherent text plans (Moore and Paris, 1993; Hovy, 1991; Wanner and Hovy, 1996; Zukerman and McConachy, 1995). However, none has the ability to take a set of independently generated yet inter-related text plans and produce integrated plans that realize all of the communicative goals in a concise and coherent manner. R T P I (Rule-based Text Plan Integrator) was designed to perform this task. The need for coherence requires that the system be able to * This work was supported by the National Library of Medicineunder grant R01-LM-05764-01. We thank Bonnie Webber and John Clarke for their suggestions and advice during the course of this r"
P98-1084,W96-0401,0,0.393322,"as RST-style trees, and produces a smaller set of more complex trees representing integrated messages that still achieve the multiple communicative goals of the individual text plans. Domain-independent rules are used to capture strategies across domains, while the facility for addition of domain-dependent rules enables the system to be tuned to the requirements of a particular domain. The system has been tested on a corpus of critiques in the domain of trauma care. 1 Overview Many natural language systems have been developed to generate coherent text plans (Moore and Paris, 1993; Hovy, 1991; Wanner and Hovy, 1996; Zukerman and McConachy, 1995). However, none has the ability to take a set of independently generated yet inter-related text plans and produce integrated plans that realize all of the communicative goals in a concise and coherent manner. R T P I (Rule-based Text Plan Integrator) was designed to perform this task. The need for coherence requires that the system be able to * This work was supported by the National Library of Medicineunder grant R01-LM-05764-01. We thank Bonnie Webber and John Clarke for their suggestions and advice during the course of this research. 512 identify and resolve c"
P98-2188,W95-0101,0,0.0960781,"Missing"
P98-2188,J86-3001,0,0.0647169,"ddition, our implementation can accommodate a wide variety of different types of features, including set-valued features, features that consider the context of surrounding utterances, and features that can take distant context into account. These and other attractive characteristics of TBL are discussed further in Samuel et al. (1998b). 1This condition is true only for the first utterance of a dialogue. 1151 Dialogue Act Tagging To address a significant concern in machine learning, called the sparse data problem, we must select an appropriate set of features. Researchers in discourse, such as Grosz and Sidner (1986), Lambert (1993), Hirschberg and Litman (1993), Chen (1995), Andernach (1996), Samuel (1996), and Chu-Carroll (1998) have suggested several features that might be relevant for the task of computing dialogue acts. Our system can consider the following features of an utterance: 1) the cue phrases 3 in the utterance; 2) the word n-grams 3 in the utterance; 3) the dialogue act c u e s 3 in the utterance; 4) the entire utterance for one-, two-, or three-word utterances; 5) speaker information 4 for the utter2The part-of-speech tag of a word is dependent on the word&apos;s internal features and on the su"
P98-2188,J93-3003,0,0.384147,"te a wide variety of different types of features, including set-valued features, features that consider the context of surrounding utterances, and features that can take distant context into account. These and other attractive characteristics of TBL are discussed further in Samuel et al. (1998b). 1This condition is true only for the first utterance of a dialogue. 1151 Dialogue Act Tagging To address a significant concern in machine learning, called the sparse data problem, we must select an appropriate set of features. Researchers in discourse, such as Grosz and Sidner (1986), Lambert (1993), Hirschberg and Litman (1993), Chen (1995), Andernach (1996), Samuel (1996), and Chu-Carroll (1998) have suggested several features that might be relevant for the task of computing dialogue acts. Our system can consider the following features of an utterance: 1) the cue phrases 3 in the utterance; 2) the word n-grams 3 in the utterance; 3) the dialogue act c u e s 3 in the utterance; 4) the entire utterance for one-, two-, or three-word utterances; 5) speaker information 4 for the utter2The part-of-speech tag of a word is dependent on the word&apos;s internal features and on the surrounding words; similarly, the dialogue act o"
P98-2188,E95-1037,0,0.0127146,"types of features, including set-valued features, features that consider the context of surrounding utterances, and features that can take distant context into account. These and other attractive characteristics of TBL are discussed further in Samuel et al. (1998b). 1This condition is true only for the first utterance of a dialogue. 1151 Dialogue Act Tagging To address a significant concern in machine learning, called the sparse data problem, we must select an appropriate set of features. Researchers in discourse, such as Grosz and Sidner (1986), Lambert (1993), Hirschberg and Litman (1993), Chen (1995), Andernach (1996), Samuel (1996), and Chu-Carroll (1998) have suggested several features that might be relevant for the task of computing dialogue acts. Our system can consider the following features of an utterance: 1) the cue phrases 3 in the utterance; 2) the word n-grams 3 in the utterance; 3) the dialogue act c u e s 3 in the utterance; 4) the entire utterance for one-, two-, or three-word utterances; 5) speaker information 4 for the utter2The part-of-speech tag of a word is dependent on the word&apos;s internal features and on the surrounding words; similarly, the dialogue act of an utteranc"
P98-2188,P97-1011,0,0.0375113,"Missing"
P98-2188,W97-0320,0,0.00971113,", to address limitations of TBL, we introduce a Monte Carlo strategy for training efficiently and a committee method for computing confidence measures. These ideas are combined in our working implementation, which labels held-out data as accurately as any other reported system for the dialogue act tagging task. Introduction Although machine learning approaches have achieved success in many areas of Natural Language Processing, researchers have only recently begun to investigate applying machine learning methods to discourse-level problems (Reithinger and Klesen, 1997; Di Eugenio et al., 1997; Wiebe et al., 1997; Andernach, 1996; Litman, 1994). An important task in discourse understanding is to interpret an utterance&apos;s dialogue act, which is a concise abstraction of a speaker&apos;s intention, such as SUGGEST and ACCEPT. Recognizing dialogue acts is critical for discourse-level understanding and can also be useful for other applications, such as resolving ambiguity in speech recognition. However, computing dialogue acts is a challenging task, because often a dialogue act cannot be directly inferred from a literal interpretation of an utterance. We have investigated applying Transformation-Based Learning ("
P98-2188,J95-4004,0,\N,Missing
W03-2101,J80-3003,0,0.601989,"wedges and lines by their proximity to the chart component in question. The output of the visual extraction component is an XML file that describes the chart and all of its components. 4.4 Applying Discourse Understanding Strategies Many researchers have cast the understanding of discourse and dialogue as a plan recognition problem — that is, the writer or speaker (or characters in the case of a story) has an underlying goal and a plan for accomplishing that goal, and understanding requires that the reader or listener infer the plan and in turn the goal that the plan is intended to achieve. (Perrault and Allen, 1980; Wilensky, 1983; Litman and Allen, 1987; Carberry, 1990; Charniak and Goldman, 1993; Ardisonno and Sestero, 1996) are just a few examples of such systems. Since understanding information graphics is a discourse-level problem, we are extending plan inference techniques to recognizing the intended message of an information graphic(Elzer et al., 2003) and to identifying its contribution to an extended discourse that includes both text and graphics. Planning and plan inference systems require knowledge about goals and how they can be achieved. Typically, this is provided by a library of operators"
W03-2101,W00-1438,1,0.864082,"ibutes of these highlighted items (for example, the attributes of a highlighted bar in a bar chart), which are captured in the XML represen3 Verb phrases in captions also provide evidence, but they suggest particular operators of interest rather than instantiated perceptual tasks, and thus we associate verbs with operators in the plan library. tation of the graphic, are also regarded as salient entities. Salient entities also include those that world knowledge suggests are mutually believed to be of interest to the viewing audience. We envision in the future using the notion of lexical chains(Silber and McCoy, 2000) to identify entities that the accompanying text makes particularly salient. Perceptual tasks that are instantiated with a salient entity and that can be performed on the graphic are designated salient tasks. 4.4.2 The Search Process Candidate tasks consist of the set of perceptual tasks that require the least effort and the set of salient tasks. Once the set of candidate tasks has been identified, plan inference begins. Initial candidate plans are constructed from each operator in which a candidate task appears as a subgoal; the root of the candidate plan is the goal of the operator, and its"
W03-2101,J99-1001,1,\N,Missing
W03-2101,J86-3001,0,\N,Missing
W04-1002,P99-1071,0,0.0394275,"Focused entities that appear as instantiations of parameters in perceptual or cognitive tasks serve as evidence that those tasks might be particularly salient. Similarly, verbs that appear in captions serve as evidence for the salience of particular tasks. For example, the verb beats in a caption such as “Canada Beats Europe” serves as evidence for the salience of a Recognize relative difference task. In the future, we plan to capture the influence of surrounding text by identifying the important concepts from the text using lexical chains. Lexical chains have been used in text summarization (Barzilay et al., 1999), and our linear time algorithm (Silber and McCoy, 2002) makes their computation feasible even for large texts. Whether a task is salient and the method by which it was made salient are used as evidence in our plan inference system. The graphic design makes some tasks easier than others. We use a set of rules, based on research by cognitive psychologists, to estimate the relative effort of performing different perceptual and cognitive tasks. These rules, described in (Elzer et al., 2004), have been validated by eye-tracking experiments. Since the viewer is intended to recognize the message tha"
W04-1002,J00-3005,0,0.0215232,"istical techniques and identification and extraction of key sentences from documents. However, it is widely acknowledged that to truly understand a text and produce the best summary, one must understand the document and recognize the intentions of the author. Recent work in text summarization has Delaware bankruptcy personal filings 3000 2500 2000 1500 1000 1998 1999 2000 2001 Figure 1: Graphic from a City Newspaper Median Income In thousands of 2001 dollars $15 White women 10 Black women 5 1948 60 70 80 90 01 Figure 2: Graphic from Newsweek Magazine begun to address this issue. For example, (Marcu, 2000) presents algorithms for automatically identifying the rhetorical structure of a text and argues that the hypothesized rhetorical structure can be successfully used in text summarization. Information graphics are an important component of many documents. In some cases, information graphics are stand-alone and constitute the entire document. This is the case for many graphics appearing in newspapers, such as the graphic shown in Figure 1. On the other hand, when an article is comprised of text and graphics, the graphic generally expands on the text and contributes to the discourse purpose (Gros"
W04-1002,J02-4004,1,0.835636,"eters in perceptual or cognitive tasks serve as evidence that those tasks might be particularly salient. Similarly, verbs that appear in captions serve as evidence for the salience of particular tasks. For example, the verb beats in a caption such as “Canada Beats Europe” serves as evidence for the salience of a Recognize relative difference task. In the future, we plan to capture the influence of surrounding text by identifying the important concepts from the text using lexical chains. Lexical chains have been used in text summarization (Barzilay et al., 1999), and our linear time algorithm (Silber and McCoy, 2002) makes their computation feasible even for large texts. Whether a task is salient and the method by which it was made salient are used as evidence in our plan inference system. The graphic design makes some tasks easier than others. We use a set of rules, based on research by cognitive psychologists, to estimate the relative effort of performing different perceptual and cognitive tasks. These rules, described in (Elzer et al., 2004), have been validated by eye-tracking experiments. Since the viewer is intended to recognize the message that the graphic designer wants to convey, we contend that"
W04-1002,J86-3001,0,\N,Missing
W08-1103,W96-0501,0,0.473984,"y that our system generates for the graphic in Figure 2 before the movements between classes, and Table 2 presents the summary after the movements. 5 10 percent 8 6 4 2 0 ’95 ’97 ’98 ’99 ’00 ’01 ’02 Figure 5: Graphic conveying a contrast change. likely to contribute to the descriptor than the texts at the higher levels. We developed a set of heuristics and augmentation rules for constructing the descriptor for the dependent axis and validated them on a previously unseen corpus of graphics. Realizing Summaries To realize the summaries in natural language, we use the FUF/SURGE surface realizer (Elhadad and Robin, 1996) with some changes made to address a few problems encountered with respect to the use of conjunctions and subject-ellipsises. Different strategies are defined in the system for aggregating the realizations of trees that are linked with operators. The strategy selected by the system is based on the relation (such as concession) that holds between the propositions at the root of the trees and the syntactic forms of their realization opportunities. For example, the system uses different strategies for aggregating the trees rooted by the And predicates in Figure 4, where the tree rooted by And(per"
W08-1103,J86-3001,0,0.155274,"propositions conveying the rate of increase in the graphic in Figure 2. Once the propositions to be included in the summary are identified, we assign them to one of these three classes. We hypothesize that the message-related class of propositions should be presented first since this places emphasis on the core message of the graphic. We anticipate that the user will ask follow-up questions after receiving the initial summary. Therefore, it is appropriate to close the initial summary with propositions from the computational class so that the whole graphic is in the user’s focus of attention (Grosz and Sidner, 1986). Thus we hypothesize that a good ordering of propositions in the initial summary is the message-related class, the specific class, and finally the computational class. This produces a partial ordering of the propositions to be included in the summary. Each proposition can be realized as a single sentence. For example, shows(graphic,trend) can be realized as “The graphic shows a trend” or “There is a trend in the graphic”. Consequently, a set of propositions can be viewed as a set of single sentences. Figure 3 shows the propositions in the message related class for the graphic in Figure 2, alo"
W08-1103,W07-1001,0,\N,Missing
W10-4202,W08-1103,1,0.691352,"boost factor ensures that all propositions will eventually become important enough for inclusion. 3 Application in a Particular Domain This section illustrates the application of our framework to a particular domain and how our framework facilitates flexible content selection. Our example is content selection in the SIGHT system (Elzer et al., 2007), whose goal is to provide visually impaired users with the knowledge that one would gain from viewing information graphics (such as bar charts) that appear in popular media. In the current implementation, SIGHT constructs a brief initial summary (Demir et al., 2008) that conveys the primary message of a bar chart along with its salient features. We enhanced the current SIGHT system to respond to user’s follow-up requests for more information about the graphic, where the request does not specify the kind of information that is desired. The first step in using our framework is determining the set of propositions that might be conveyed in this domain. In our earlier work (Demir et al., 2008), we identified a set of propositions that capture information that could be determined by looking at a bar chart, and for each message type defined in SIGHT, specified"
W10-4202,J97-1004,0,0.0477969,"Sripada et al., 2001) who have been observed to be tolerant of realization problems as long as the appropriate content is expressed. The NLG community has proposed various content selection approaches since early systems (Moore and Paris, 1993; McKeown, 1985) which placed emphasis on text structure and adapted planning techniques or schemas to meet discourse goals. This paper proposes a domain-independent framework which can be incorporated as a content selection component in a system whose goal is to deliver descriptive or explanatory texts, such as the ILEX (O’Donnell et al., 2001), KNIGHT (Lester and Porter, 1997), and POLIBOX (Chiarcos and Stede, 2004) systems. At the core of our framework lies a novel use of a graph-based ranking algorithm, which exploits discourse related considerations in determining what content to convey in response to a request for information. This framework provides the ability to generate successive history-aware texts and the flexibility to generate different texts with different parameter settings. One discourse consideration is the tenet that the propositions selected for inclusion in a text should be in some way related to one another. Thus, the selection process should b"
W10-4202,J93-4004,0,0.433228,"scourse history. We illustrate and evaluate this framework in an accessibility system for sight-impaired individuals. 1 Introduction Content selection is the task responsible for determining what to convey in the output of a generation system at the current exchange (Reiter and Dale, 1997). This very domain dependent task is extremely important from the perspective of users (Sripada et al., 2001) who have been observed to be tolerant of realization problems as long as the appropriate content is expressed. The NLG community has proposed various content selection approaches since early systems (Moore and Paris, 1993; McKeown, 1985) which placed emphasis on text structure and adapted planning techniques or schemas to meet discourse goals. This paper proposes a domain-independent framework which can be incorporated as a content selection component in a system whose goal is to deliver descriptive or explanatory texts, such as the ILEX (O’Donnell et al., 2001), KNIGHT (Lester and Porter, 1997), and POLIBOX (Chiarcos and Stede, 2004) systems. At the core of our framework lies a novel use of a graph-based ranking algorithm, which exploits discourse related considerations in determining what content to convey i"
W10-4202,H93-1032,0,0.1239,"tion in the text, this would introduce redundancy and should be avoided. Many systems (such as MATCH (Walker et al., 2004) and GEA (Carenini and Moore, 2006)) contain a user model which is employed to adapt content selection to the user’s preferences (Reiter and Dale, 1997). Our framework provides a facility to model a stereotypical user by incorporating the a priori importance of propositions. This facility can also be used to capture the preferences of a particular user. In a dialogue system, utterances that are generated without exploiting the previous discourse seem awkward and unnatural (Moore, 1993). Our framework takes the previous discourse into account so as to omit recently communicated propositions and to determine when repetition of a previously communicated proposition is appropriate. To our knowledge, our work is the first effort utilizing a graph-based ranking algorithm for content selection, while taking into account what information preferably should and shouldn’t be conveyed together, the a priori importance of information, and the discourse history. Our framework is a domain-independent methodology containing domain-dependent features that must be instantiated when applying"
W10-4202,W01-0802,0,\N,Missing
W11-0506,W08-1103,1,0.805862,"1) they can be integrated with the summary of a multimodal document’s text, thereby producing a richer summary of the overall document’s content; 2) they can be stored in a digital library along with the graphic itself and used to retrieve appropriate graphics in response to user queries; and 3) for individuals with sight impairments, they can be used along with a screen reader to convey not only the text of a document, but also the content of the document’s graphics. In this paper we present our work on summarizing line graphs. This builds on our previous efforts into summarizing bar charts (Demir et al., 2008; Elzer et al., 2011); however, line graphs have different messages and communicative signals than bar charts and their continuous nature requires different processing. In addition, a very different set of visual features must be taken into account in deciding the importance of including a proposition in a summary. 2 Methodology Most summarization research has focused on extractive techniques by which segments of text are extracted and put together to form the summary. 41 Proceedings of the Workshop on Automatic Summarization for Different Genres, Media, and Languages, pages 41–48, c Portland,"
W11-0506,W10-4202,1,0.83982,"ght for the associated proposition. Type 3 rules (Message Category + Visual Feature) differ only from type 2 rules in that they are restricted to a particular intended message category, rather than any line graph having the visual feature in question. For example, a proposition comparing the slope of two trends may be appropriate for a graph in the Change-trend message category, but does not make sense for a line graph with only a single trend (e.g., Rising-trend). Once all propositions have been extracted and ranked, these weights are passed along to a graphbased content selection framework (Demir et al., 2010) that iteratively selects for inclusion in the initial summary those propositions which provide the best coverage of the highest-ranked information. 4.3 Sample Rule Application Figures 1 and 4 consist of two different line graphs with the same intended message category: Changetrend. Figure 1 shows a stable trend in annual sea level difference from 1900 to 1930, followed by a rising trend through 2003, while Figure 4 shows a rising trend in Durango sales from 1997 to 1999, followed by a falling trend through 2006. Propositions associated with type 1 rules will have the same weights for both gra"
W11-0506,W96-0501,0,0.116659,"000 1999: 189,840 2006: 70,606 150,000 100,000 50,000 0 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 Figure 4: From “Chrysler: Plant had $800 million impact” in The (Wilmington) News Journal, Feb 15, 2007. “The values vary a lot...”, “The trend is unstable...”), possibly displacing a type 1 proposition that would still appear in the summary for the graph in Figure 4. 5 Future Work Once the propositions that should be included in the summary have been selected, they must be coherently organized and realized as natural language sentences. We anticipate using the FUF/SURGE surface realizer (Elhadad and Robin, 1996); our collected corpus of line graph summaries provides a large set of real-world expressions to draw from when crafting the surface realization forms our system will produce for the final-output summaries. Our summarization methodology must also be evaluated. In particular, we must evaluate the rules for identifying the additional informational propositions that are used to elaborate the overall intended message, and the quality of the summaries both in terms of content and coherence. 6 Related Work Image summarization has focused on constructing a smaller image that contains the important co"
W11-0506,P05-1028,1,0.825611,"r newspapers, generally have a communicative goal or intended message. For example, the graphic in Figure 1 is intended to convey a changing trend in sea levels — relatively flat from 1900 to 1930 and then rising from 1930 to 2003. Thus, using Clark’s view of language, information graphics are a means of communication. Research has shown that the content of information graphics in popular media is usually not repeated in the text of the accompanying article (Carberry et al., 2006). The captions of such graphics are also often uninformative or convey little of the graphic’s high-level message (Elzer et al., 2005). This contrasts with scientific documents in which graphics are often used to visualize data, with explicit references to the graphic being used to explain their content (e.g., “As shown in Fig. A...”). Information graphics in popular media contribute to the overall communicative goal of a multimodal document and should not be ignored. Our work is concerned with the summarization of information graphics from popular media. Such summaries have several major applications: 1) they can be integrated with the summary of a multimodal document’s text, thereby producing a richer summary of the overal"
W11-0506,J86-3001,0,\N,Missing
W11-2306,W08-1103,1,0.896015,"In contrast, graphs in popular media are constructed to make a point which should be obvious without complicated scientific reasoning. We are thus interested in generating a textual presentation of the content of graphs in popular media. Other research has focused on textual descriptions (e.g., Ferres et al. (2007)); however in that work the same information is included in the textual summary for each instance of a graph type (i.e., all summaries of line graphs contain the same sorts of information), and the summary does not attempt to present the overall intended message of the graph. SIGHT (Demir et al., 2008; Elzer et al., 2011) is a natural language system whose overall goal is providing blind users with interactive access to multimodal documents from electronically-available popular media sources. To date, the SIGHT project has concentrated on simple bar charts. Its user interface is implemented as a browser helper object within Internet Explorer that works with the JAWS screen reader. When the system detects a bar chart in a document being read by the user, it prompts the user to use keystrokes to request a brief summary of the graphic capturing its primary contribution to the overall communic"
W11-2306,W10-4202,1,0.838615,"o affected by certain rhetorical devices (WR ) which serve to highlight particular concepts. Being used in an idiom, or compared to another concept by means of juxtaposition suggests that a given concept may hold special significance. Finally, the weights assigned by our graph understanding system for the additional propositions identified in the graphics are incorporated into the ID of the concepts involved as WG . 59 5.3 Selecting Content for a Summary To select concepts for inclusion in the summary, the model will then be passed to a discourse-aware graph-based content selection framework (Demir et al., 2010), which selects concepts one at a time and iteratively re-weights the remaining items so as to include related concepts and avoid redundancy. This algorithm incorporates PageRank (Page et al., 1999), but with several modifications. In addition to centrality assessment based on relationships between concepts, it includes apriori importance nodes enabling us to incorporate concept completeness, number of expressions, document structure, and rhetorical devices. More importantly from a summary generation perspective, the algorithm iteratively picks concepts one at a time, and re-ranks the remainin"
W11-2306,W96-0501,0,0.0964934,"racted communicative signals serve as evidence for or against each candidate message. For Figure 2, our system produces changetrend(1997, rise, 1999, fall, 2006) as the logical representation of the most probable intended message. Since the dependent axis is often not explicitly labeled, a series of heuristics are used to identify an appropriate referent, which we term the measurement axis descriptor. In Figure 2, the measurement axis descriptor is identified as durango sales. The intended message and measurement axis descriptor are then passed to a realization component which uses FUF/SURGE (Elhadad and Robin, 1996) to generate the following initial description: This graphic conveys a changing trend in durango sales, rising from 1997 to 1999 and then falling to 2006. 3 Identifying a Relevant Paragraph In presenting a multimodal document to a user via a screen reader, if the author does not specify a reading order in the accessibility preferences, it is not entirely clear where the description of the graphical content should be given. The text of scientific articles normally makes explicit references to any graphs contained in the document; in this case, it makes sense to insert the graphical description"
W11-2306,W11-2703,1,0.803742,"Missing"
W11-2306,W10-4220,1,0.862276,"Missing"
W11-2306,A92-1027,1,0.58071,"bitrary length. This will permit the user to request a quick overview in order to decide whether to read the original document, or a more comprehensive synopsis to obtain the most important content without having to read the entire article. 5.1 Semantic Modeling of Multimodal Documents Content gathered from the article text by a semantic parser and from the information graphics by our graph understanding system is combined into a single semantic model based on typed, structured objects organized under a foundational ontology (McDonald, 2000a). For the semantic parsing of text, we use Sparser (McDonald, 1992), a bottom-up, phrase-structure-based chart parser, optimized for semantic grammars and partial parsing.3 Using a built-in model of core English grammar plus domain-specific grammars, Sparser extracts information from the text and produces categorized objects as a semantic representation (McDonald, 2000b). The intended message and salient additional propositions identified by our system for the information graphics are decomposed and added to the model constructed by Sparser.4 Model entries contain slots for attributes in the concept category’s ontology definition (fillable by other concepts o"
W11-2306,W00-0109,1,0.570812,"cepts as we wish, at any level of detail, to produce summaries of arbitrary length. This will permit the user to request a quick overview in order to decide whether to read the original document, or a more comprehensive synopsis to obtain the most important content without having to read the entire article. 5.1 Semantic Modeling of Multimodal Documents Content gathered from the article text by a semantic parser and from the information graphics by our graph understanding system is combined into a single semantic model based on typed, structured objects organized under a foundational ontology (McDonald, 2000a). For the semantic parsing of text, we use Sparser (McDonald, 1992), a bottom-up, phrase-structure-based chart parser, optimized for semantic grammars and partial parsing.3 Using a built-in model of core English grammar plus domain-specific grammars, Sparser extracts information from the text and produces categorized objects as a semantic representation (McDonald, 2000b). The intended message and salient additional propositions identified by our system for the information graphics are decomposed and added to the model constructed by Sparser.4 Model entries contain slots for attributes in the"
W11-2306,P03-1018,0,0.0339013,"ion graphics and another producing words relevant to the topics of the individual documents. Let Wg represent the word frequency vector yielding words relevant to the graphics, Wa represent the word frequency vector yielding words relevant to the document topics, and Wp represent the word frequency vector of the pseudo-relevant paragraphs. We compute Wp from the pseudo-relevant paragraphs themselves, and we estimate Wa using the word frequencies from the article text in the documents. Finally, we compute Wg by filtering-out the components of Wa from Wp . This process is related to the work by Widdows (2003) on orthogonal negation of vector spaces. The task can be formulated as follows: 1. Wp = αWa + βWg where α &gt; 0 and β &gt; 0, which means the word frequency vector for the pseudo-relevant paragraphs is a linear combination of the background (topic) word frequency vector and the graphic word vector. 2. &lt; Wa , Wg &gt;= 0 which means the background word vector is orthogonal to the graph description word vector, under the assumption that the graph description word vector is independent of the background word vector and that these two share minimal information. 3. Wg is assumed to be a unit vector, since"
W11-2703,aker-gaizauskas-2010-model,0,0.025664,"re asked to write brief summaries for a series of line graphs. While they did not release a corpus for distribution, their analysis did suggest that a graph’s visual features could be used to help select salient propositions to include in a summary. Although several corpora exist for general image descriptions, we are unaware of any other corpora of human-written summaries for information graphics. J¨orgensen (1998) collected unconstrained descriptions of pictorial images, while Hollink et al. (2004) analyzed descriptions of mental images formed by subjects to illustrate a given text passage. Aker and Gaizauskas (2010) built a corpus of human-generated captions for location-related images. Large collections of general image captions have been assembled for information retrieval tasks (Smeaton and Quigley, 1996; Tribble, 2010). Roy (2002) evaluated automatically-generated descriptions of visual scenes against human-generated descriptions. The developers of the iGraph-Lite system (Ferres et al., 2007) released a corpus of descriptions for over 500 graphs collected from Statistics Canada, but these descriptions were generated automatically by their system and not written by human authors. Additionally, the des"
W11-2703,W02-0109,0,0.0567061,"Missing"
W11-2703,W02-2113,0,0.0334835,"ons of visual scenes against human-generated descriptions. The developers of the iGraph-Lite system (Ferres et al., 2007) released a corpus of descriptions for over 500 graphs collected from Statistics Canada, but these descriptions were generated automatically by their system and not written by human authors. Additionally, the descriptions contained in their corpus focus on the quantitative data presented in the graphics rather than the high-level message, and tend to vary only slightly between graphs.4 Since using corpus texts as a “gold standard” in generation and evaluation can be tricky (Reiter and Sripada, 2002), we tried to mitigate some of the common problems, including giving participants as much time as they wanted for each summary to avoid “hurried writing.” However, as we intend to use this corpus to understand which propositions humans find salient for line graphs, as well as generat4 The iGraph-Lite system provides the same information for each instance of a graph type (i.e., all summaries of line graphs contain the same sorts of information). ing and evaluating new summaries, a larger collection of examples written by many authors for several different graphics was more desirable than a smal"
W11-2703,P06-4018,0,\N,Missing
W14-4409,W99-0108,0,0.0607496,"e at a lower grade level would not repeat the referring expression when using multiple non aggregated sentences. The propositions chosen by the content selection framework contain the information about their memberships (features such as volatility and steepness point to the segment of the graphic they belong to). This membership information is the clue used to define discourse focus. Our work follows the approach applied in the TEXT system (McKeown, 1992), in which pronouns are used in order to refer to the entity being focused in subsequent sentences. Also inspired by the work presented by (McCoy & Strube, 1999) our system makes use of other anaphoric expressions besides pronouns, such as “the trend” or “the graph”. These alternative anaphoric expressions are used to reintroduce entities when the discourse focus changes. The following example shows the use of pronouns and the reintroduction of the entity in the last set of propositions. The entities that are in focus in each sentence are underlined and the referring expressions are bolded. The image shows a line graph. The line graph presents the number of cumulative, global unredeemed frequent-flier miles. It conveys a rising trend from 1999 to 2005"
W14-4409,P05-1065,0,0.0687355,"Missing"
W14-4409,N06-1046,0,0.0166475,"ls, a sentence aggregation step is needed. The aggregation module is in charge of merging propositions that describe an entity, creating a more complex sentence that will encompass the information selected that describes the referring expression. The approach proposed by (Wilkinson, 1995) presents the aggregation process divided in two major steps: semantic grouping and sentence structuring. Although they are interdependent, both are needed in order to achieve aggregation in a text. Initiatives on automatic aggregation (or only semantic grouping) of text using learning techniques also exist. (Barzilay, 2006), (Bayyarapu, 2011), (Walker, Rambow, & Rogati, 2001) are some examples of learning aggregation rules and grouping constrains in order to aggregate text. (Demir, 2010) presents a mechanism in 4.1 Reading Level Assessment Much effort has been devoted to developing automated approaches for assessing text complexity. Some examples are the use of support vector machines (Schwarm & Ostendorf, 2005) in order to find topical texts at a given reading level. Another approach is the use of statistical language models (Collins-Thompson & Callan, 2005; Collins-Thompson & Callan, 2004) for predicting readi"
W14-4409,R11-1012,0,0.467178,"regation step is needed. The aggregation module is in charge of merging propositions that describe an entity, creating a more complex sentence that will encompass the information selected that describes the referring expression. The approach proposed by (Wilkinson, 1995) presents the aggregation process divided in two major steps: semantic grouping and sentence structuring. Although they are interdependent, both are needed in order to achieve aggregation in a text. Initiatives on automatic aggregation (or only semantic grouping) of text using learning techniques also exist. (Barzilay, 2006), (Bayyarapu, 2011), (Walker, Rambow, & Rogati, 2001) are some examples of learning aggregation rules and grouping constrains in order to aggregate text. (Demir, 2010) presents a mechanism in 4.1 Reading Level Assessment Much effort has been devoted to developing automated approaches for assessing text complexity. Some examples are the use of support vector machines (Schwarm & Ostendorf, 2005) in order to find topical texts at a given reading level. Another approach is the use of statistical language models (Collins-Thompson & Callan, 2005; Collins-Thompson & Callan, 2004) for predicting reading difficulty. The"
W14-4409,N04-1025,0,0.0709539,"Missing"
W14-4409,N07-1058,0,\N,Missing
W14-4409,N01-1003,0,\N,Missing
W14-4413,W14-4409,1,0.900363,"J. Burns, 2013). The XML representation 1 Figure 1: System Architecture http://ir.cis.udel.edu/~moraes/udgraphs 95 Proceedings of the 8th International Natural Language Generation Conference, pages 95–98, c Philadelphia, Pennsylvania, 19-21 June 2014. 2014 Association for Computational Linguistics Figure 2: Digital library screenshot where we have added summary generation functionality. 2 information about the graphic (overall value and rate change, time span of the graphic, maximum and minimum points and dates when they occur). The strategies on organizing the summaries are described in (P. Moraes, McCoy, & Carberry, 2014). The last step of the Generation Module is the aggregation of propositions into more complex sentences. This decision is usually left to the designer’s choice on how much aggregation to perform when generating text. Some systems are designed to generate simple text for people with low reading abilities (Williams & Reiter, 2005a). As stated by (Williams & Reiter, 2005b), most NLG systems available generate text for high-skilled users. Our system generates line graph summaries that fit the reading level of the article in which the line graph appears. We contend that users generally read articl"
W14-4413,W08-1103,1,0.704453,"Missing"
W14-4413,W11-2703,1,\N,Missing
W14-4413,W05-1616,0,\N,Missing
W16-6621,W02-0109,0,0.042139,"Missing"
W16-6621,W14-4409,1,0.845899,"e level of the reader and the creation of the lexicon is guided by defining a domainaware synset for description of line graphs. Other NLG systems decide on text complexity based on available scales such as the D-level sentence complexity (Covington, He, Brown, Naci, & Brown, 2006). One example is presented in (Demir, Carberry, & McCoy, 2012), where tree structures are built representing all the possible ways sentences can be aggregated and the choice of the tree attempts to balance the number of sentences, their D-level complexity, and the types of relative clauses. The work presented in (P. Moraes, McCoy, & Carberry, 2014) describe a template-based approach for creating summaries at different reading levels. It does not, however, present an adaptive approach that can be applied to the micro planning phase of any NLG system. Another area, text simplification, aims to target low-skilled readers and users with language disabilities. SkillSum (Williams & Reiter, 2004, 2005a; Williams, Reiter, & Osman, 2003) is a system which adapts its output for readers with poor literacy after assessing their reading and numeracy skills. Their results show that, for these target readers, the micro planning choices made by SkillS"
W16-6621,W03-2314,0,0.0641898,"sabilities. SkillSum (Williams & Reiter, 2004, 2005a; Williams, Reiter, & Osman, 2003) is a system which adapts its output for readers with poor literacy after assessing their reading and numeracy skills. Their results show that, for these target readers, the micro planning choices made by SkillSum enhanced readability. (Carroll et al., 1999) presents a text simplification methodology to help languageimpaired users; (Rello, Baeza-Yates, Bott, & Saggion, 2013) propose a system that uses lexical simplification to enhance readability and understandability of text for people with dyslexia; while (Siddharthan, 2003) aims to make the text easier to read for some target group (like aphasics and people with low reading ages) or easier to process by some program (like a parser or machine translation system). One of our evaluation experiments (citation suppressed for anonymity) performed with college students showed that the simplest text was rather unpleasant for them to read. We therefore propose a technique that focuses on adjusting the generated text to the reading level of the surrounding text. The closest work to the one proposed in this paper is presented in (Bateman & Paris, 1989). It p resents an app"
W16-6621,W12-2019,0,0.0274372,"lem The search space for the aggregation of propositions problem is defined as: States: A state consists of two parts: a list of unrealized propositions and the realizations performed so far (which can consist of full sentences or sentence fragments). Initial state: The initial state contains the set of all unrealized propositions. Goal 4 Learning Text Complexity Features The features to be used in the heuristic needed to be chosen based on both their effect on text complexity and their usability. The choice of features for constructing the model was made based on the work 123 3 presented by (Vajjala & Meurers, 2012) which uses features that are based on Second Language Acquisition (SLA) research combined with traditional readability features, such as word length and sentence length, in order to classify text into different grades. Their work results in classifiers that outperform previous approaches on readability classification, reaching higher classification accuracy. However, since we still need to map features back to the NLG aggregation phase, the set of features used here represents a subset of the features presented in their work. The final set of features, motivated by (Vajjala & Meurers, 2012),"
W16-6621,N01-1003,0,0.106259,"o tailoring phrasing during the generation of natural text to different types of users. It employs a technique that leverages a knowledge base in order to make decisions during text planning in a rule based fashion. This work, in contrast, generates natural text aimed at a specific reading level Related Work The approach proposed by (Wilkinson, 1995) presents the aggregation process divided into two major steps: semantic grouping and sentence structuring. Although they are interdependent, both are needed in order to achieve aggregation in a text. (Barzilay & Lapata, 2006), (Bayyarapu, 2011), (Walker, Rambow, & Rogati, 2001) are some examples of learning aggregation rules and grouping constraints in order to aggregate text. It differs from our approach in that we are considering readability constraints when making such decisions. (Elhadad, Robin, & McKeown, 1997) present work on lexical choice considering constraints regarding syntax, semantics, pragmatics, the lexicon, and the underlying domain that float from one phase to the next in the generation of text. Our work differs in that lexical items are restrained by their ap122 2 by applying a graph search that allows the automation of the aggregation of proposit"
W16-6621,R11-1012,0,0.0156581,"sents an approach to tailoring phrasing during the generation of natural text to different types of users. It employs a technique that leverages a knowledge base in order to make decisions during text planning in a rule based fashion. This work, in contrast, generates natural text aimed at a specific reading level Related Work The approach proposed by (Wilkinson, 1995) presents the aggregation process divided into two major steps: semantic grouping and sentence structuring. Although they are interdependent, both are needed in order to achieve aggregation in a text. (Barzilay & Lapata, 2006), (Bayyarapu, 2011), (Walker, Rambow, & Rogati, 2001) are some examples of learning aggregation rules and grouping constraints in order to aggregate text. It differs from our approach in that we are considering readability constraints when making such decisions. (Elhadad, Robin, & McKeown, 1997) present work on lexical choice considering constraints regarding syntax, semantics, pragmatics, the lexicon, and the underlying domain that float from one phase to the next in the generation of text. Our work differs in that lexical items are restrained by their ap122 2 by applying a graph search that allows the automati"
W16-6621,E99-1042,0,0.179408,"d approach for creating summaries at different reading levels. It does not, however, present an adaptive approach that can be applied to the micro planning phase of any NLG system. Another area, text simplification, aims to target low-skilled readers and users with language disabilities. SkillSum (Williams & Reiter, 2004, 2005a; Williams, Reiter, & Osman, 2003) is a system which adapts its output for readers with poor literacy after assessing their reading and numeracy skills. Their results show that, for these target readers, the micro planning choices made by SkillSum enhanced readability. (Carroll et al., 1999) presents a text simplification methodology to help languageimpaired users; (Rello, Baeza-Yates, Bott, & Saggion, 2013) propose a system that uses lexical simplification to enhance readability and understandability of text for people with dyslexia; while (Siddharthan, 2003) aims to make the text easier to read for some target group (like aphasics and people with low reading ages) or easier to process by some program (like a parser or machine translation system). One of our evaluation experiments (citation suppressed for anonymity) performed with college students showed that the simplest text w"
W16-6621,J12-3004,1,0.834463,"tification of grade level appropriate and domain aware lexicons. Section 6 shows some examples of summaries generated by the system. Section 7 presents the evaluations of the system and Sections 8 and 9 provide conclusions and thoughts on future work, respectively. 2 propriateness to the level of the reader and the creation of the lexicon is guided by defining a domainaware synset for description of line graphs. Other NLG systems decide on text complexity based on available scales such as the D-level sentence complexity (Covington, He, Brown, Naci, & Brown, 2006). One example is presented in (Demir, Carberry, & McCoy, 2012), where tree structures are built representing all the possible ways sentences can be aggregated and the choice of the tree attempts to balance the number of sentences, their D-level complexity, and the types of relative clauses. The work presented in (P. Moraes, McCoy, & Carberry, 2014) describe a template-based approach for creating summaries at different reading levels. It does not, however, present an adaptive approach that can be applied to the micro planning phase of any NLG system. Another area, text simplification, aims to target low-skilled readers and users with language disabilitie"
W16-6621,W05-1616,0,0.0930841,"Missing"
W16-6621,W03-2317,0,0.118829,"ng all the possible ways sentences can be aggregated and the choice of the tree attempts to balance the number of sentences, their D-level complexity, and the types of relative clauses. The work presented in (P. Moraes, McCoy, & Carberry, 2014) describe a template-based approach for creating summaries at different reading levels. It does not, however, present an adaptive approach that can be applied to the micro planning phase of any NLG system. Another area, text simplification, aims to target low-skilled readers and users with language disabilities. SkillSum (Williams & Reiter, 2004, 2005a; Williams, Reiter, & Osman, 2003) is a system which adapts its output for readers with poor literacy after assessing their reading and numeracy skills. Their results show that, for these target readers, the micro planning choices made by SkillSum enhanced readability. (Carroll et al., 1999) presents a text simplification methodology to help languageimpaired users; (Rello, Baeza-Yates, Bott, & Saggion, 2013) propose a system that uses lexical simplification to enhance readability and understandability of text for people with dyslexia; while (Siddharthan, 2003) aims to make the text easier to read for some target group (like a"
W90-0115,P88-1020,0,0.0582139,"Missing"
W93-0201,P88-1020,0,0.0342473,"Green carberry@cis.udel.edu jchu@cis.udel.edu green@cis.udel.edu Department of Computer Science University of Delaware Newark, Delaware 19716 alld Lynn Lambert lambert@pcs.cnu.edu D e p a r t m e n t of Physics and Computer Science Christopher Newport University Newport News, Virginia 23606 It is generMly agreed t h a t coherent (lis(&apos;ourse consists of segments tha,t are related to one another. A number of researchers have a,rgm~d lbr the use of rhetorica,l[(~ri75] or coherence relations [I-Iol)79], and the rhetorical relations specified by R S&apos;I? [MT87] have I)e(,~, used in structuring text [tlov88, MP90]. In this l)a.l)el&quot;, we exa.mine rh(q.ori(:al relations in the cold.~,xt of dia.logue, ra,tlmr t h a n single-speaker te×t. We argue that rea,s(millg about relational l)r()lmsit, ions is necessary but not sufficient ior structuring (lialogtm, 1)oiHt out s(,v(q&apos;al prol)h,ms of a,pplyiug RST to dialogue, a,nd argue tbr the necessity of recognizillg the intentions underlying utteratlces a,lld I,he rich relationshil)s among these intentions. Our research on recognizing expressions of (hml)t and interpreting ilMirect replies provides evidence t h a t what Moore a,nd Polla,ck call i lfformal,itmal l"
W93-0201,J92-4007,0,0.0744551,"Missing"
W94-0322,J92-4007,0,0.0168997,"to constrain the information which thereby may be selected. McKeown [McK85] uses discourse focus constraints. In [Moo89], plan selection heuristics are used that maximize the heater's presumed familiarity with the concepts in the text, prefer general-purpose to less general operators, and minimize verbosity. Maybury's [May92] system uses ""desirable"" preconditions, preconditions that are not inecessary preconditions, to prioritize alternative operators. In contrast to the above, by the use of stimulus conditions, our model is able to trigger new, opportunistic speaker goals. Moore and Pollack [MP92] show the need to distinguish the intentional and informational structure of discourse, where the latter is characterized by the 7. Conclusion An indirect answer to a Yes-No question conversationally implicates the speaker's evaluation of the truth of a questioned proposition. The generation of indirect answers is important if a dialogue system is to respond efficiently, accurately, and politely. This paper has presented the approach to generation used in our implemented system for generating and interpreting indirect answers to Yes-No questions in English. Ours is the first system to generate"
W94-0322,J93-4004,0,0.124105,"rbm's (105) and (111), respectively. 19Although it is expressed as a declarative sentence, Stenstr6m classifies (16a) as a request for confirmation, which we treat as a type of Yes-No question. 196 7th International Generation Workshop • Kennebunkport, Maine • June 21-24, 1994 sort of relations classified as subject-matter relations in RST. Note that in our interpretation component [GC94], informational relations (i.e. plausible coherence relations holding between indirect answers and candidate direct answers) are used to infer the speaker's goal to convey a particular answer. Moore and Paris [MP93] argue that it is necessary for generation systems to represent not only the speaker's top-level intentional goal, but also the intentional subgoals that a speaker hoped to achieve by use of a rhetorical relation so that, if a subgoal is not achieved, then an alternative rhetorical means can be tried. In our model, the operators used as satellites of top-level answer discourse plan operators are based on RST's subject-matter relations. The primary goals of these operators are similar to the effect fields of the corresponding RST relation definitions. As Moore and Paris argue, goals based on th"
W94-0322,J80-3003,0,0.167208,"succeed, or to avoid having to make the other request directly. Thus, a negative answer to a Yes-No question used as a prerequest may be interpreted as a refusal. To soften the refusal, the speaker may give an explanation of the negative answer, as illustrated in (1). Formally, the condition is defined by the following axiom. ((excuse-indicated s h (not ?p) ?q) <(~bel s (prerequest h s (informif s h ?p)))) This may be glossed as, s is motivated to give h an excuse q for (not p), if s suspects that h's request, (informif s h p), is a prerequest. Techniques for interpreting indirect speech acts [PA80, Hin89] can be used to determine whether the antecedent holds. Answer-ref-indicated This condition appears in Use-Elaboration, illustrated by (3), s and in Use-Contrast, illustrated by (4) .9 Table 2: Stimulus conditions of discourse plan operators 3 . a . Q: Did you have a hotel in mind? [What hotel did you have in mind?] b. c . E: [yes] ators for providing causal explanations. For example in (2), 6 which indirectly conveys a No, R gives an explanation of why R won't get a car. 2.a. q: b. R: d. actually you'll probably get a car won't you as soon as you get there can't drive There's a Holiday Inn ri"
W94-0322,J93-3002,0,0.0294512,"ioned in section 3, an indirect answer may be used to avoid performing a face-threatening act. 195 7th International Generation Workshop • Kennebunkport, Maine • June 21-24, 1994 request in (12d). (Answer-no s h (occur ( g o - p a r t y s) p a s t ) ) : Nucleus: b. 12.a. q: b. R: c. d. (inform s h (not (occur (go-party s) past))) Satellites: (Use-obstacle s h (not (occur (go-party s) past))) c ampus ? Nucleus: C. Second, stylisticgoals m a y affect the generation of indirect answers. In addition to affectingsyntactic (inform s h (not (in-state (can-sit sitter) and lexical aspects of discourse [Hovg0, MG91, DH93], stylistic goals may affect which and how much information is given. For example, elaboration can be used to make an answer more lively, as shown in (13). past))) Satellites: (Use-obstacle s h (not ( i n - s t a t e (can-sit sitter) past))) 13,a. Q: Do you have a car? b. R: [yes] c. I bought a British-racing-green Austin-Healey 3000 last week. Nucleus: d. (inform s h (in-state (sick sitter) past)) Also, extra information that entails the direct answer (e.g. repetitions and generalizations) may be given for emphasis. Further, a stylistic goal of terseness may override the stimulus conditions w"
W94-0322,P94-1009,1,0.902724,"n a full discourse plan. The leaf nodes, representing discourse acts, are numbered 1 - 8. Arcs labelled N and S lead to a nucleus or satellite, respectively. Node 8 corresponds to the direct answer. Plan pruning would process the nodes in order from 1 to 8. The maximal set :of nodes which could be pruned in Figure 3 is the set containing 2, 3, 4, 7, and 8. That is, nodes 2 - 4 might be inferrable from 1, node 7 from 5 or 6, and node 8 from 4 or 7. In the event that it is determined that no node can be pruned, the full plan would be output. Not:e that our interpretation algorithm (described in [GC94]) performs a subprocess, hypothesis generation, to recognize missing propositions other than the direct answer, i.e. the propositions at nodes 2, 3, 4, and 7. 1 Figure 3: Example of full discourse plan before pruning 11.a. Q: You went to the party, didn't you7 b. R: [no] c. [The baby sitter could not sit.] d. The baby sitter was sick. In phase one, the generator creates a discourse plan for a full answer. First, it must decide which top-level discourse plan operator to expand. Each of the top-level operators would be instantiated with the questioned proposition, (occur (go-party s) past). The"
W94-0322,E91-1033,0,0.0690135,"Missing"
W94-0322,P88-1020,0,0.0288388,"yextent-indicated, as illustrated in (9). (As noted earlier, our coherence rules for the relation cr-contrast as well as our axioms for clarify-extent-indicated make use of the notion of a salient partial ordering which was elucidated by Hirsehberg.) However, Hirschberg's model does not account for quite a variety of types of indirect answers which can be generated using the other operators in our model, nor for other motives for using Use-contrast. Rhetorical or coherence relations [Gri75b, Hal76, MT87] have been used in several text-generation systems to aid in ordering parts of a text (e.g.[Hov88]) as well as in content-planning (e.g. [McK85, MP93]). The discourse plan operators based on coherence relations in our model (i.e. the operators used as satellites of top-level operators)play a similar role in contentplanning of an indirect answer. When coherence relations are used for content-planning, it is necessary to constrain the information which thereby may be selected. McKeown [McK85] uses discourse focus constraints. In [Moo89], plan selection heuristics are used that maximize the heater's presumed familiarity with the concepts in the text, prefer general-purpose to less general ope"
