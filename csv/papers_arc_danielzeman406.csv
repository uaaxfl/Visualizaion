2021.iwpt-1.15,From Raw Text to Enhanced {U}niversal {D}ependencies: The Parsing Shared Task at {IWPT} 2021,2021,-1,-1,3,0,5827,gosse bouma,Proceedings of the 17th International Conference on Parsing Technologies and the IWPT 2021 Shared Task on Parsing into Enhanced Universal Dependencies (IWPT 2021),0,"We describe the second IWPT task on end-to-end parsing from raw text to Enhanced Universal Dependencies. We provide details about the evaluation metrics and the datasets used for training and evaluation. We compare the approaches taken by participating teams and discuss the results of the shared task, also in comparison with the first edition of this task."
2021.findings-emnlp.303,Do {UD} Trees Match Mention Spans in Coreference Annotations?,2021,-1,-1,5,0,227,martin popel,Findings of the Association for Computational Linguistics: EMNLP 2021,0,"One can find dozens of data resources for various languages in which coreference - a relation between two or more expressions that refer to the same real-world entity - is manually annotated. One could also assume that such expressions usually constitute syntactically meaningful units; however, mention spans have been annotated simply by delimiting token intervals in most coreference projects, i.e., independently of any syntactic representation. We argue that it could be advantageous to make syntactic and coreference annotations convergent in the long term. We present a pilot empirical study focused on matches and mismatches between hand-annotated linear mention spans and automatically parsed syntactic trees that follow Universal Dependencies conventions. The study covers 9 datasets for 8 different languages."
2020.wildre-1.7,{U}niversal {D}ependency Treebanks for Low-Resource {I}ndian Languages: The Case of {B}hojpuri,2020,-1,-1,2,0,1252,atul ojha,Proceedings of the WILDRE5{--} 5th Workshop on Indian Language Data: Resources and Evaluation,0,"This paper presents the first dependency treebank for Bhojpuri, a resource-poor language that belongs to the Indo-Aryan language family. The objective behind the Bhojpuri Treebank (BHTB) project is to create a substantial, syntactically annotated treebank which not only acts as a valuable resource in building language technological tools, also helps in cross-lingual learning and typological research. Currently, the treebank consists of 4,881 annotated tokens in accordance with the annotation scheme of Universal Dependencies (UD). A Bhojpuri tagger and parser were created using machine learning approach. The accuracy of the model is 57.49{\%} UAS, 45.50{\%} LAS, 79.69{\%} UPOS accuracy and 77.64{\%} XPOS accuracy. The paper describes the details of the project including a discussion on linguistic analysis and annotation process of the Bhojpuri UD treebank."
2020.udw-1.20,{U}niversal {D}ependencies for {A}lbanian,2020,-1,-1,3,0,14289,marsida toska,Proceedings of the Fourth Workshop on Universal Dependencies (UDW 2020),0,"In this paper, we introduce the first Universal Dependencies (UD) treebank for standard Albanian, consisting of 60 sentences collected from the Albanian Wikipedia, annotated with lemmas, universal part-of-speech tags, morphological features and syntactic dependencies. In addition to presenting the treebank itself, we discuss a selection of linguistic constructions in Albanian whose analysis in UD is not self-evident, including core arguments and the status of indirect objects, pronominal clitics, genitive constructions, prearticulated adjectives, and modal verbs."
2020.tlt-1.9,Estimating {POS} Annotation Consistency of Different Treebanks in a Language,2020,-1,-1,2,0,14354,akshay aggarwal,Proceedings of the 19th International Workshop on Treebanks and Linguistic Theories,0,None
2020.sigtyp-1.4,Predicting Typological Features in {WALS} using Language Embeddings and Conditional Probabilities: {{\\'U}FAL} Submission to the {SIGTYP} 2020 Shared Task,2020,-1,-1,2,0,14783,martin vastl,Proceedings of the Second Workshop on Computational Research in Linguistic Typology,0,"We present our submission to the SIGTYP 2020 Shared Task on the prediction of typological features. We submit a constrained system, predicting typological features only based on the WALS database. We investigate two approaches. The simpler of the two is a system based on estimating correlation of feature values within languages by computing conditional probabilities and mutual information. The second approach is to train a neural predictor operating on precomputed language embeddings based on WALS features. Our submitted system combines the two approaches based on their self-estimated confidence scores. We reach the accuracy of 70.7{\%} on the test data and rank first in the shared task."
2020.lrec-1.497,{U}niversal {D}ependencies v2: An Evergrowing Multilingual Treebank Collection,2020,17,3,9,0,10682,joakim nivre,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Universal Dependencies is an open community effort to create cross-linguistically consistent treebank annotation for many languages within a dependency-based lexicalist framework. The annotation consists in a linguistically motivated word segmentation; a morphological layer comprising lemmas, universal part-of-speech tags, and standardized morphological features; and a syntactic layer focusing on syntactic relations between predicates, arguments and modifiers. In this paper, we describe version 2 of the universal guidelines (UD v2), discuss the major changes from UD v1 to UD v2, and give an overview of the currently available treebanks for 90 languages."
2020.lrec-1.637,{Y}or{\\`u}b{\\'a} Dependency Treebank ({YTB}),2020,-1,-1,2,0,17922,olajide ishola,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Low-resource languages present enormous NLP opportunities as well as varying degrees of difficulties. The newly released treebank of hand-annotated parts of the Yoruba Bible provides an avenue for dependency analysis of the Yoruba language; the application of a new grammar formalism to the language. In this paper, we discuss our choice of Universal Dependencies, important dependency annotation decisions considered in the creation of the first annotation guidelines for Yoruba and results of our parsing experiments. We also lay the foundation for future incorporation of other domains with the initial test on Yoruba Wikipedia articles and highlighted future directions for the rapid expansion of the treebank."
2020.iwpt-1.16,Overview of the {IWPT} 2020 Shared Task on Parsing into Enhanced {U}niversal {D}ependencies,2020,-1,-1,3,0,5827,gosse bouma,Proceedings of the 16th International Conference on Parsing Technologies and the IWPT 2020 Shared Task on Parsing into Enhanced Universal Dependencies,0,"This overview introduces the task of parsing into enhanced universal dependencies, describes the datasets used for training and evaluation, and evaluation metrics. We outline various approaches and discuss the results of the shared task."
2020.conll-shared.1,{MRP} 2020: The Second Shared Task on Cross-Framework and Cross-Lingual Meaning Representation Parsing,2020,-1,-1,10,0,2623,stephan oepen,Proceedings of the CoNLL 2020 Shared Task: Cross-Framework Meaning Representation Parsing,0,"The 2020 Shared Task at the Conference for Computational Language Learning (CoNLL) was devoted to Meaning Representation Parsing (MRP) across frameworks and languages. Extending a similar setup from the previous year, five distinct approaches to the representation of sentence meaning in the form of directed graphs were represented in the English training and evaluation data for the task, packaged in a uniform graph abstraction and serialization; for four of these representation frameworks, additional training and evaluation data was provided for one additional language per framework. The task received submissions from eight teams, of which two do not participate in the official ranking because they arrived after the closing deadline or made use of additional training data. All technical information regarding the task, including system submissions, official results, and links to supporting resources and software are available from the task web site at: http://mrp.nlpl.eu"
2020.conll-shared.3,{FGD} at {MRP} 2020: {P}rague Tectogrammatical Graphs,2020,-1,-1,1,1,5828,daniel zeman,Proceedings of the CoNLL 2020 Shared Task: Cross-Framework Meaning Representation Parsing,0,Prague Tectogrammatical Graphs (PTG) is a meaning representation framework that originates in the tectogrammatical layer of the Prague Dependency Treebank (PDT) and is theoretically founded in Functional Generative Description of language (FGD). PTG in its present form has been prepared for the CoNLL 2020 shared task on Cross-Framework Meaning Representation Parsing (MRP). It is generated automatically from the Prague treebanks and stored in the JSON-based MRP graph interchange format. The conversion is partially lossy; in this paper we describe what part of annotation was included and how it is represented in PTG.
2020.cl-3.3,Sentence Meaning Representations Across Languages: What Can We Learn from Existing Frameworks?,2020,-1,-1,2,0,7153,zdenvek vzabokrtsky,Computational Linguistics,0,"This article gives an overview of how sentence meaning is represented in eleven deep-syntactic frameworks, ranging from those based on linguistic theories elaborated for decades to rather lightweight NLP-motivated approaches. We outline the most important characteristics of each framework and then discuss how particular language phenomena are treated across those frameworks, while trying to shed light on commonalities as well as differences."
W19-7717,Towards Deep {U}niversal {D}ependencies,2019,0,0,2,1,23458,kira droganova,"Proceedings of the Fifth International Conference on Dependency Linguistics (Depling, SyntaxFest 2019)",0,Deep Universal Dependencies is a collection of treebanks derived semi-automatically from Universal Dependencies (http://hdl.handle.net/11234/1-2988). It contains additional deep-syntactic and semantic annotations. Version of Deep UD corresponds to the version of UD it is based on. Note however that some UD treebanks have been omitted from Deep UD.
W19-4213,{CUNI}{--}{M}alta system at {SIGMORPHON} 2019 Shared Task on Morphological Analysis and Lemmatization in context: Operation-based word formation,2019,0,0,3,0.952381,24265,ronald cardenas,"Proceedings of the 16th Workshop on Computational Research in Phonetics, Phonology, and Morphology",0,"This paper presents the submission by the Charles University-University of Malta team to the SIGMORPHON 2019 Shared Task on Morphological Analysis and Lemmatization in context. We present a lemmatization model based on previous work on neural transducers (Makarov and Clematide, 2018b; Aharoni and Goldberg, 2016). The key difference is that our model transforms the whole word form in every step, instead of consuming it character by character. We propose a merging strategy inspired by Byte-Pair-Encoding that reduces the space of valid operations by merging frequent adjacent operations. The resulting operations not only encode the actions to be performed but the relative position in the word token and how characters need to be transformed. Our morphological tagger is a vanilla biLSTM tagger that operates over operation representations, encoding operations and words in a hierarchical manner. Even though relative performance according to metrics is below the baseline, experiments show that our models capture important associations between interpretable operation labels and fine-grained morpho-syntax labels."
K19-2015,{{\\'U}FAL}-{O}slo at {MRP} 2019: Garage Sale Semantic Parsing,2019,0,0,4,1,23458,kira droganova,Proceedings of the Shared Task on Cross-Framework Meaning Representation Parsing at the 2019 Conference on Natural Language Learning,0,"This paper describes the {\'U}FAL--Oslo system submission to the shared task on Cross-Framework Meaning Representation Parsing (MRP, Oepen et al. 2019). The submission is based on several third-party parsers. Within the official shared task results, the submission ranked 11th out of 13 participating systems."
W18-6004,Challenges in Converting the Index {T}homisticus Treebank into {U}niversal {D}ependencies,2018,0,1,4,0,16575,flavio cecchini,Proceedings of the Second Workshop on Universal Dependencies ({UDW} 2018),0,"This paper describes the changes applied to the original process used to convert the \textit{Index Thomisticus} Treebank, a corpus including texts in Medieval Latin by Thomas Aquinas, into the annotation style of Universal Dependencies. The changes are made both to harmonise the Universal Dependencies version of the \textit{Index Thomisticus} Treebank with the two other available Latin treebanks and to fix errors and inconsistencies resulting from the original process. The paper details the treatment of different issues in PoS tagging, lemmatisation and assignment of dependency relations. Finally, it assesses the quality of the new conversion process by providing an evaluation against a gold standard."
W18-6006,Mind the Gap: Data Enrichment in Dependency Parsing of Elliptical Constructions,2018,0,1,4,1,23458,kira droganova,Proceedings of the Second Workshop on Universal Dependencies ({UDW} 2018),0,"In this paper, we focus on parsing rare and non-trivial constructions, in particular ellipsis. We report on several experiments in enrichment of training data for this specific construction, evaluated on five languages: Czech, English, Finnish, Russian and Slovak. These data enrichment methods draw upon self-training and tri-training, combined with a stratified sampling method mimicking the structural complexity of the original treebank. In addition, using these same methods, we also demonstrate small improvements over the CoNLL-17 parsing shared task winning system for four of the five languages, not only restricted to the elliptical constructions."
W18-5815,A Morphological Analyzer for {S}hipibo-Konibo,2018,-1,-1,2,0.952381,24265,ronald cardenas,"Proceedings of the Fifteenth Workshop on Computational Research in Phonetics, Phonology, and Morphology",0,"We present a fairly complete morphological analyzer for Shipibo-Konibo, a low-resourced native language spoken in the Amazonian region of Peru. We resort to the robustness of finite-state systems in order to model the complex morphosyntax of the language. Evaluation over raw corpora shows promising coverage of grammatical phenomena, limited only by the scarce lexicon. We make this tool freely available so as to aid the production of annotated corpora and impulse further research in native languages of Peru."
L18-1290,Parse Me if You Can: Artificial Treebanks for Parsing Experiments on Elliptical Constructions,2018,0,0,2,1,23458,kira droganova,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
K18-2001,{C}o{NLL} 2018 Shared Task: Multilingual Parsing from Raw Text to {U}niversal {D}ependencies,2018,0,1,1,1,5828,daniel zeman,Proceedings of the {C}o{NLL} 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies,0,"Every year, the Conference on Computational Natural Language Learning (CoNLL) features a shared task, in which participants train and test their learning systems on the same data sets. In 2018, one of two tasks was devoted to learning dependency parsers for a large number of languages, in a real-world setting without any gold-standard annotation on test input. All test sets followed a unified annotation scheme, namely that of Universal Dependencies. This shared task constitutes a 2nd edition{---}the first one took place in 2017 (Zeman et al., 2017); the main metric from 2017 has been kept, allowing for easy comparison, also in 2018, and two new main metrics have been used. New datasets added to the Universal Dependencies collection between mid-2017 and the spring of 2018 have contributed to increased difficulty of the task this year. In this overview paper, we define the task and the updated evaluation methodology, describe data preparation, report and analyze the main results, and provide a brief categorization of the different approaches of the participating systems."
W17-6532,Core Arguments in {U}niversal {D}ependencies,2017,0,0,1,1,5828,daniel zeman,Proceedings of the Fourth International Conference on Dependency Linguistics (Depling 2017),0,None
W17-1320,{U}niversal {D}ependencies for {A}rabic,2017,19,3,3,0,14288,dima taji,Proceedings of the Third {A}rabic Natural Language Processing Workshop,0,"We describe the process of creating NUDAR, a Universal Dependency treebank for Arabic. We present the conversion from the Penn Arabic Treebank to the Universal Dependency syntactic representation through an intermediate dependency representation. We discuss the challenges faced in the conversion of the trees, the decisions we made to solve them, and the validation of our conversion. We also present initial parsing results on NUDAR."
W17-1226,"{S}lavic Forest, {N}orwegian Wood",2017,0,0,2,0.267702,14784,rudolf rosa,"Proceedings of the Fourth Workshop on {NLP} for Similar Languages, Varieties and Dialects ({V}ar{D}ial)",0,"We once had a corp, or should we say, it once had us They showed us its tags, isn{'}t it great, unified tags They asked us to parse and they told us to use everything So we looked around and we noticed there was near nothing We took other langs, bitext aligned: words one-to-one We played for two weeks, and then they said, here is the test The parser kept training till morning, just until deadline So we had to wait and hope what we get would be just fine And, when we awoke, the results were done, we saw we{'}d won So, we wrote this paper, isn{'}t it good, Norwegian wood."
W17-0406,Elliptic Constructions: Spotting Patterns in {UD} Treebanks,2017,0,1,2,1,23458,kira droganova,Proceedings of the {N}o{D}a{L}i{D}a 2017 Workshop on Universal Dependencies ({UDW} 2017),0,None
K17-3001,{C}o{NLL} 2017 Shared Task: Multilingual Parsing from Raw Text to {U}niversal {D}ependencies,2017,28,32,1,1,5828,daniel zeman,Proceedings of the {C}o{NLL} 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies,0,"The Conference on Computational Natural Language Learning (CoNLL) features a shared task, in which participants train and test their learning systems on the same data sets. In 2017, the task was devoted to learning dependency parsers for a large number of languages, in a real-world setting without any gold-standard annotation on input. All test sets followed a unified annotation scheme, namely that of Universal Dependencies. In this paper, we define the task and evaluation methodology, describe how the data sets were prepared, report and analyze the main results, and provide a brief categorization of the different approaches of the participating systems."
E17-5001,{U}niversal {D}ependencies,2017,0,3,2,0,10682,joakim nivre,Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Tutorial Abstracts,0,"Universal Dependencies (UD) is a project that seeks to develop cross-linguistically consistent treebank annotation for many languages. This tutorial gives an introduction to the UD framework and resources, from basic design principles to annotation guidelines and existing treebanks. We also discuss tools for developing and exploiting UD treebanks and survey applications of UD in NLP and linguistics."
Y16-2018,Planting Trees in the Desert: Delexicalized Tagging and Parsing Combined,2016,14,0,1,1,5828,daniel zeman,"Proceedings of the 30th Pacific Asia Conference on Language, Information and Computation: Oral Papers",0,None
L16-1015,If You {E}ven Don{'}t Have a Bit of {B}ible: Learning Delexicalized {POS} Taggers,2016,17,2,4,0,13611,zhiwei yu,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Part-of-speech (POS) induction is one of the most popular tasks in research on unsupervised NLP. Various unsupervised and semi-supervised methods have been proposed to tag an unseen language. However, many of them require some partial understanding of the target language because they rely on dictionaries or parallel corpora such as the Bible. In this paper, we propose a different method named delexicalized tagging, for which we only need a raw corpus of the target language. We transfer tagging models trained on annotated corpora of one or more resource-rich languages. We employ language-independent features such as word length, frequency, neighborhood entropy, character classes (alphabetic vs. numeric vs. punctuation) etc. We demonstrate that such features can, to certain extent, serve as predictors of the part of speech, represented by the universal POS tag."
L16-1262,{U}niversal {D}ependencies v1: A Multilingual Treebank Collection,2016,0,257,12,0,10682,joakim nivre,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Cross-linguistically consistent annotation is necessary for sound comparative evaluation and cross-lingual learning experiments. It is also useful for multilingual system development and comparative linguistic studies. Universal Dependencies is an open community effort to create cross-linguistically consistent treebank annotation for many languages within a dependency-based lexicalist framework. In this paper, we describe v1 of the universal guidelines, the underlying design principles, and the currently available treebanks for 33 languages."
L16-1630,Towards Comparability of Linguistic Graph {B}anks for Semantic Parsing,2016,20,7,4,0,2623,stephan oepen,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"We announce a new language resource for research on semantic parsing, a large, carefully curated collection of semantic dependency graphs representing multiple linguistic traditions. This resource is called SDP{\textasciitilde}2016 and provides an update and extension to previous versions used as Semantic Dependency Parsing target representations in the 2014 and 2015 Semantic Evaluation Exercises. For a common core of English text, this third edition comprises semantic dependency graphs from four distinct frameworks, packaged in a unified abstract format and aligned at the sentence and token levels. SDP 2016 is the first general release of this resource and available for licensing from the Linguistic Data Consortium in May 2016. The data is accompanied by an open-source SDP utility toolkit and system results from previous contrastive parsing evaluations against these target representations."
S15-2153,{S}em{E}val 2015 Task 18: Broad-Coverage Semantic Dependency Parsing,2015,-1,-1,4,0,2623,stephan oepen,Proceedings of the 9th International Workshop on Semantic Evaluation ({S}em{E}val 2015),0,None
W14-3326,Machine Translation of Medical Texts in the Khresmoi Project,2014,37,10,9,0,2976,ondvrej duvsek,Proceedings of the Ninth Workshop on Statistical Machine Translation,0,"This paper presents the participation of the Charles University team in the WMT 2014 Medical Translation Task. Our systems are developed within the Khresmoi project, a large integrated project aiming to deliver a multi-lingual multi-modal search and access system for biomedical information and documents. Being involved in the organization of the Medical Translation Task, our primary goal is to set up a baseline for both its subtasks (summary translation and query translation) and for all translation directions. Our systems are based on the phrasebased Moses system and standard methods for domain adaptation. The constrained/unconstrained systems differ in the training data only."
S14-2008,{S}em{E}val 2014 Task 8: Broad-Coverage Semantic Dependency Parsing,2014,30,71,4,0,2623,stephan oepen,Proceedings of the 8th International Workshop on Semantic Evaluation ({S}em{E}val 2014),0,"Task 18 at SemEval 2015 defines Broad-Coverage Semantic Dependency Parsing (SDP) as the problem of recovering sentence-internal predicatexe2x80x93argument relationships for all content words, i.e. the sema ..."
S14-2056,In-House: An Ensemble of Pre-Existing Off-the-Shelf Parsers,2014,22,5,3,0,5928,yusuke miyao,Proceedings of the 8th International Workshop on Semantic Evaluation ({S}em{E}val 2014),0,"This submission to the open track of Task 8 at SemEval 2014 seeks to connect the Task to pre-existing, xe2x80x98in-housexe2x80x99 parsing systems for the same types of target semantic dependency graphs."
bojar-etal-2014-hindencorp,{H}ind{E}n{C}orp - {H}indi-{E}nglish and {H}indi-only Corpus for Machine Translation,2014,15,30,7,0.117912,292,ondvrej bojar,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"We present HindEnCorp, a parallel corpus of Hindi and English, and HindMonoCorp, a monolingual corpus of Hindi in their release version 0.5. Both corpora were collected from web sources and preprocessed primarily for the training of statistical machine translation systems. HindEnCorp consists of 274k parallel sentences (3.9 million Hindi and 3.8 million English tokens). HindMonoCorp amounts to 787 million tokens in 44 million sentences. Both the corpora are freely available for non-commercial research and their preliminary release has been used by numerous participants of the WMT 2014 shared translation task."
rosa-etal-2014-hamledt,{H}amle{DT} 2.0: Thirty Dependency Treebanks Stanfordized,2014,30,20,5,0.267702,14784,rudolf rosa,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"We present HamleDT 2.0 (HArmonized Multi-LanguagE Dependency Treebank). HamleDT 2.0 is a collection of 30 existing treebanks harmonized into a common annotation style, the Prague Dependencies, and further transformed into Stanford Dependencies, a treebank annotation style that became popular in recent years. We use the newest basic Universal Stanford Dependencies, without added language-specific subtypes. We describe both of the annotation styles, including adjustments that were necessary to make, and provide details about the conversion process. We also discuss the differences between the two styles, evaluating their advantages and disadvantages, and note the effects of the differences on the conversion. We regard the stanfordization as generally successful, although we admit several shortcomings, especially in the distinction between direct and indirect objects, that have to be addressed in future. We release part of HamleDT 2.0 freely; we are not allowed to redistribute the whole dataset, but we do provide the conversion pipeline."
W13-2207,{CU}ni Multilingual Matrix in the {WMT} 2013 Shared Task,2013,10,3,2,0,40947,karel bilek,Proceedings of the Eighth Workshop on Statistical Machine Translation,0,"We describe our experiments with phrase-based machine translation for the WMT 2013 Shared Task. We trained one system for 18 translation directions between English or Czech on one side and English, Czech, German, Spanish, French or Russian on the other side. We describe a set of results with different training data sizes and subsets. For the pairs containing Russian, we describe a set of independent experiments with slightly different translation models."
P13-1051,Coordination Structures in Dependency Treebanks,2013,31,22,4,0,227,martin popel,Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"Paratactic syntactic structures are notoriously difficult to represent in dependency formalisms. This has painful consequences such as high frequency of parsing errors related to coordination. In other words, coordination is a pending problem in dependency analysis of natural languages. This paper tries to shed some light on this area by bringing a systematizing view of various formal means developed for encoding coordination structures. We introduce a novel taxonomy of such approaches and apply it to treebanks across a typologically diverse range of 26 languages. In addition, empirical observations on convertibility between selected styles of representations are shown too."
W12-5614,{CUNI}: Feature Selection and Error Analysis of a Transition-Based Parser,2012,4,0,1,1,5828,daniel zeman,Proceedings of the Workshop on Machine Translation and Parsing in {I}ndian Languages,0,"We describe the parsing system used at the Charles University (CUNI) for the Hindi Parsing Shared Task 2012. We used the publicly available Malt Parser, which is highly configurable. A substantial part of the paper describes the configuration that we selected. The parser performs reasonably well in identifying the head nodes. The main weakness is in labeling the dependency relations. We identify the most prominent error types, which should help to improve the parsing accuracy in future. Title and Abstract in Czech CUNI: Vxc3xbdbxc4x9br rysxc5xaf a analxc3xbdza chyb parseru zaloxc5xbeeneho na pxc5x99echodech Popisujeme system pro syntaktickou analxc3xbdzu pouxc5xbeitxc3xbd na Univerzitxc4x9b Karlovxc4x9b (CUNI) pro Hindi Parsing Shared Task 2012. Pouxc5xbeili jsme vexc5x99ejnxc4x9b dostupnxc3xbd nastroj Malt Parser, kterxc3xbd poskytuje mnoho moxc5xbenosti konfigurace. Podstatna cast clanku se zabxc3xbdva pravxc4x9b konfiguraci, kterou jsme zvolili. Parser dosahuje dobre uspxc4x9bsnosti pxc5x99i identifikaci rodicovskxc3xbdch uzlxc5xaf. Jeho hlavni slabinou je znackovani zavislostnich vztahxc5xaf. Popisujeme nejbxc4x9bxc5xbenxc4x9bjsi druhy chyb, coxc5xbe by mxc4x9blo pomoci v budoucnosti zvxc3xbdsit uspxc4x9bsnost parseru."
W12-3151,Data Issues of the Multilingual Translation Matrix,2012,8,10,1,1,5828,daniel zeman,Proceedings of the Seventh Workshop on Statistical Machine Translation,0,"We describe our experiments with phrase-based machine translation for the WMT 2012 Shared Task. We trained one system for 14 translation directions between English or Czech on one side and English, Czech, German, Spanish or French on the other side. We describe a set of results with different training data sizes and subsets."
berka-etal-2012-automatic,Automatic {MT} Error Analysis: Hjerson Helping Addicter,2012,13,9,5,0,42951,jan berka,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"We present a complex, open source tool for detailed machine translation error analysis providing the user with automatic error detection and classification, several monolingual alignment algorithms as well as with training and test corpus browsing. The tool is the result of a merge of automatic error detection and classification of Hjerson (Popovi{\'c}, 2011) and Addicter (Zeman et al., 2011) into the pipeline and web visualization of Addicter. It classifies errors into categories similar to those of Vilar et al. (2006), such as: morphological, reordering, missing words, extra words and lexical errors. The graphical user interface shows alignments in both training corpus and test data; the different classes of errors are colored. Also, the summary of errors can be displayed to provide an overall view of the MT system's weaknesses. The tool was developed in Linux, but it was tested on Windows too."
zeman-etal-2012-hamledt,{H}amle{DT}: To Parse or Not to Parse?,2012,24,34,1,1,5828,daniel zeman,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"We propose HamleDT â HArmonized Multi-LanguagE Dependency Treebank. HamleDT is a compilation of existing dependency treebanks (or dependency conversions of other treebanks), transformed so that they all conform to the same annotation style. While the license terms prevent us from directly redistributing the corpora, most of them are easily acquirable for research purposes. What we provide instead is the software that normalizes tree structures in the data obtained by the user from their original providers."
W11-2163,Hierarchical Phrase-Based {MT} at the {C}harles {U}niversity for the {WMT} 2011 Shared Task,2011,13,1,1,1,5828,daniel zeman,Proceedings of the Sixth Workshop on Statistical Machine Translation,0,"We describe our experiments with hierarchical phrase-based machine translation for the WMT 2011 Shared Task. We trained a system for all 8 translation directions between English on one side and Czech, German, Spanish or French on the other side, though we focused slightly more on the English-to-Czech direction. We provide a detailed description of our configuration and data so the results are replicable."
W10-1732,Hierarchical Phrase-Based {MT} at the {C}harles {U}niversity for the {WMT} 2010 Shared Task,2010,12,2,1,1,5828,daniel zeman,Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and {M}etrics{MATR},0,"We describe our experiments with hierarchical phrase-based machine translation for WMT 2010 Shared Task. We provide a detailed description of our configuration and data so the results are replicable. For English-to-Czech translation, we experiment with several datasets of various sizes and with various preprocessing sequences. For the other 7 translation directions, we just present the baseline results."
bojar-etal-2010-data,Data Issues in {E}nglish-to-{H}indi Machine Translation,2010,11,9,3,0.173611,292,ondvrej bojar,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"Statistical machine translation to morphologically richer languages is a challenging task and more so if the source and target languages differ in word order. Current state-of-the-art MT systems thus deliver mediocre results. Adding more parallel data often helps improve the results; if it doesn't, it may be caused by various problems such as different domains, bad alignment or noise in the new data. In this paper we evaluate the English-to-Hindi MT task from this data perspective. We discuss several available parallel data sources and provide cross-evaluation results on their combinations using two freely available statistical MT systems. We demonstrate various problems encountered in the data and describe automatic methods of data cleaning and normalization. We also show that the contents of two independently distributed data sets can unexpectedly overlap, which negatively affects translation quality. Together with the error analysis, we also present a new tool for viewing aligned corpora, which makes it easier to detect difficult parts in the data even for a developer not speaking the target language."
W09-1219,A Simple Generative Pipeline Approach to Dependency Parsing and Semantic Role Labeling,2009,7,3,1,1,5828,daniel zeman,Proceedings of the Thirteenth Conference on Computational Natural Language Learning ({C}o{NLL} 2009): Shared Task,0,"We describe our CoNLL 2009 Shared Task system in the present paper. The system includes three cascaded components: a generative dependency parser, a classifier for syntactic dependency labels and a semantic classifier. The experimental results show that the labeled macro F1 scores of our system on the joint task range from 43.50% (Chinese) to 57.95% (Czech), with an average of 51.07%."
zeman-2008-reusable,Reusable Tagset Conversion Using Tagset Drivers,2008,11,58,1,1,5828,daniel zeman,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"Part-of-speech or morphological tags are important means of annotation in a vast number of corpora. However, different sets of tags are used in different corpora, even for the same language. Tagset conversion is difficult, and solutions tend to be tailored to a particular pair of tagsets. We propose a universal approach that makes the conversion tools reusable. We also provide an indirect evaluation in the context of a parsing task."
I08-3008,Cross-Language Parser Adaptation between Related Languages,2008,17,86,1,1,5828,daniel zeman,Proceedings of the {IJCNLP}-08 Workshop on {NLP} for Less Privileged Languages,0,"The present paper describes an approach to adapting a parser to a new language. Presumably the target language is much poorer in linguistic resources than the source language. The technique has been tested on two European languages due to test data availability; however, it is easily applicable to any pair of sufficiently related languages, including some of the Indic language group. Our adaptation technique using existing annotations in the source language achieves performance equivalent to that obtained by training on 1546 trees in the target language."
W05-1518,Improving Parsing Accuracy by Combining Diverse Dependency Parsers,2005,15,61,1,1,5828,daniel zeman,Proceedings of the Ninth International Workshop on Parsing Technology,0,"This paper explores the possibilities of improving parsing results by combining outputs of several parsers. To some extent, we are porting the ideas of Henderson and Brill (1999) to the world of dependency structures. We differ from them in exploring context features more deeply. All our experiments were conducted on Czech but the method is language-independent. We were able to significantly improve over the best parsing result for the given setting, known so far. Moreover, our experiments show that even parsers far below the state of the art can contribute to the total improvement."
C02-1118,Can Subcategorization Help a Statistical Dependency Parser?,2002,22,18,1,1,5828,daniel zeman,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"Today there is a relatively large body of work on automatic acquisition of lexico-syntactical preferences (subcategorization) from corpora. Various techniques have been developed that not only produce machine-readable subcategorization dictionaries but also they are capable of weighing the various subcategorization frames probabilistically. Clearly there should be a potential to use such weighted lexical information to improve statistical parsing, though published experiments proving (or disproving) such hypothesis are comparatively rare. One experiment is described in (Carroll et al., 1998) --- they use subcategorization probabilities for ranking trees generated by unification-based phrasal grammar. The present paper, on the other hand, involves a statistical dependency parser. Although dependency and constituency parsing are of quite a different nature, we show that a subcategorization model is of much use here as well."
W01-1832,How Much Will a {RE}-Based Preprocessor Help a Statistical Parser?,2001,6,3,1,1,5828,daniel zeman,Proceedings of the Seventh International Workshop on Parsing Technologies,0,"The present paper describes experiments on combining a statistical parser with a preprocessor built of regular expressions. While the syntactic structure of a sentence may be very complex and will never be fully covered by a finite-state machine, there are phenomena such as noun phrases and simple coordinations that do quite well. Even these xe2x80x9cchunksxe2x80x9d may theoretically be unlimitedly complex but we show that in reality they rarely do. So a shallow finite state parser can be built to preprocess the input text and solve the simple chunks without introducing too many errors. We discuss one implementation of such preprocessor that is very easy to write and covers roughly 20% of input words with an accuracy of over 90%. Then we describe two ways of combining the preprocessor with a parser and show that the performance of the parser improves both in speed and accuracy."
zeman-sarkar-2000-learning,Learning Verb Subcategorization from Corpora: Counting Frame Subsets,2000,17,6,1,1,5828,daniel zeman,Proceedings of the Second International Conference on Language Resources and Evaluation ({LREC}{'}00),0,"We present some novel machine learning techniques for the identification of subcategorization information for verbs in Czech. We compare three different statistical techniques applied to this problem. We show how the learning algorithm can be used to discover previously unknown subcategorization frames from the Czech Prague Dependency Treebank. The algorithm can then be used to label dependents of a verb in the Czech treebank as either arguments or adjuncts. Using our techniques, we are able to achieve 88 % accuracy on unseen parsed text."
C00-2100,Automatic Extraction of Subcategorization Frames for {C}zech,2000,16,68,2,0,8364,anoop sarkar,{COLING} 2000 Volume 2: The 18th International Conference on Computational Linguistics,0,"We present some novel machine learning techniques for the identification of subcategorization information for verbs in Czech. We compare three different statistical techniques applied to this problem. We show how the learning algorithm can be used to discover previously unknown subcategorization frames from the Czech Prague Dependency Treebank. The algorithm can then be used to label dependents of a verb in the Czech treebank as either arguments or adjuncts. Using our techniques, we are able to achieve 88% precision on unseen parsed text."
