2020.lrec-1.407,gavrilidou-etal-2012-meta,1,0.919419,"Missing"
2020.lrec-1.407,2020.lrec-1.420,1,0.860379,"Missing"
2020.lrec-1.407,L18-1213,1,0.894888,"Missing"
2020.lrec-1.407,piperidis-etal-2014-meta,1,0.824391,"ween 2010 and 2017, supported through the EU projects T4ME, CESAR, METANET4U, META-NORD and CRACKER. One of its main goals is technology support for all European languages as well as fostering innovative research by providing strategic recommendations with regard to key research topics (Rehm and Uszkoreit, 2013). META-SHARE3 is an infrastructure that brings together providers and consumers of language data, tools and services. It is a network of repositories that store resources, documented with high-quality metadata aggregated in central inventories (Piperidis, 2012; Gavrilidou et al., 2012; Piperidis et al., 2014). CLARIN ERIC The CLARIN European Research Infrastructure for Language Resources and Technology is a legal entity set up in 2012, with 20 member countries at present.4 CLARIN makes language resources available to scholars, researchers, and students from all disciplines with a focus on the humanities and social sciences. CLARIN offers solutions and services for deploying, connecting, analyzing and sustaining digital language data and tools. Call ICT-17-2014 – “Cracking the Language Barrier” The EU call ICT-17-2014, which was informed by key META-NET results (Rehm and Uszkoreit, 2012), funded a"
2020.lrec-1.407,piperidis-2012-meta,1,0.92358,"n 34 European countries. META-NET was, between 2010 and 2017, supported through the EU projects T4ME, CESAR, METANET4U, META-NORD and CRACKER. One of its main goals is technology support for all European languages as well as fostering innovative research by providing strategic recommendations with regard to key research topics (Rehm and Uszkoreit, 2013). META-SHARE3 is an infrastructure that brings together providers and consumers of language data, tools and services. It is a network of repositories that store resources, documented with high-quality metadata aggregated in central inventories (Piperidis, 2012; Gavrilidou et al., 2012; Piperidis et al., 2014). CLARIN ERIC The CLARIN European Research Infrastructure for Language Resources and Technology is a legal entity set up in 2012, with 20 member countries at present.4 CLARIN makes language resources available to scholars, researchers, and students from all disciplines with a focus on the humanities and social sciences. CLARIN offers solutions and services for deploying, connecting, analyzing and sustaining digital language data and tools. Call ICT-17-2014 – “Cracking the Language Barrier” The EU call ICT-17-2014, which was informed by key META"
2020.lrec-1.407,L16-1251,1,0.865781,"Missing"
2020.lrec-1.407,2020.lrec-1.413,1,0.785764,"Missing"
2020.lrec-1.433,E09-2008,0,0.0177649,"uwenberg, 2011). 4 Forms with explicitly spelled long vowels, as ba-nu-u2 for banˆu ’to create’ are called plene-writing. 5 The spelling variants have been collected from Oracc. 3529 nadin ’it is being given’. The correct reading is only interpretable by the syntactic context of the word. 2.3. BabyFST BabyFST (Sahala et al., 2019 submitted) is the most comprehensive finite-state based morphological analyzer for Akkadian up-to-date. Its source code is written according to the Xerox finite-state syntax with the lexc and xfscript formalisms, and can be compiled using the Foma FiniteState tookit (Hulden, 2009) or HFST - the Helsinki Finite State Transducer toolkit (Lind´en et al., 2011). BabyFST is designed primarily for the Babylonian dialect and is capable of processing phonological words. Several Akkadian text corpora contain only the transliteration, so some robust support is needed for producing phonologically transcribed text for BabyFST to analyse. 3. Related Work To the best of our knowledge, this is the first system for automatically transcribing Akkadian cuneiform text but Smith (2007) presents a system for grapheme-to-phoneme transcription for the Elamite language, another extinct langua"
2020.lrec-1.433,W17-0504,0,0.0229124,"models like Rao et al. (2015) directly model the relation between the input grapheme sequence and output phoneme sequence which does not require string alignment. Unlike many grapheme-to-phoneme transcription settings, the transcription of cuneiform Akkadian text differs in the sense that the transcription of logograms is partly dependent on sentence context as explained in Section 2.2.. This suggests that it is beneficial to model the sentential context of the transliterated input token. In this respect, our task is related to historical text normalization where context can often be helpful. Korchagina (2017) investigates neural machine translation for historical text normalization. In contrast to token-based normalization methods applied in grapheme-to-phoneme transcription, the model here is a character-level encoder-decoder which is applied on complete sentences. This approach proved to be challenging in the context of Akkadian transcription based on our preliminary experiments. The character-based NMT model would overfit the training data possibly because of our rela6 tively small dataset.7 Instead of a full fledged NMT model, we present experiments on several more restricted ways to model the"
2020.lrec-1.433,W12-6208,0,0.0127373,". 3. Related Work To the best of our knowledge, this is the first system for automatically transcribing Akkadian cuneiform text but Smith (2007) presents a system for grapheme-to-phoneme transcription for the Elamite language, another extinct language using the cuneiform script. The system uses optimality constraints and applies the gradual learning algorithm for learning a ranking between the constraints. Many grapheme-to-phoneme transcription systems formulate the task as a probabilistic sequence model on grapheme-phoneme pairs. For example, Bisani and Ney (2008) use joint n-gram models and Novak et al. (2012) use weighted finite-state transducers. These methods rely on some alignment between the grapheme and phoneme strings because they gather statistics about symbol alignments.6 Because our strings contain logographic material which may not have a clear connection to the phonological representation, alignment is challenging. Therefore we opted for using models based on the neural encoderdecoder architecture. These models like Rao et al. (2015) directly model the relation between the input grapheme sequence and output phoneme sequence which does not require string alignment. Unlike many grapheme-t"
2020.lrec-1.433,W07-1308,0,0.0391319,"te syntax with the lexc and xfscript formalisms, and can be compiled using the Foma FiniteState tookit (Hulden, 2009) or HFST - the Helsinki Finite State Transducer toolkit (Lind´en et al., 2011). BabyFST is designed primarily for the Babylonian dialect and is capable of processing phonological words. Several Akkadian text corpora contain only the transliteration, so some robust support is needed for producing phonologically transcribed text for BabyFST to analyse. 3. Related Work To the best of our knowledge, this is the first system for automatically transcribing Akkadian cuneiform text but Smith (2007) presents a system for grapheme-to-phoneme transcription for the Elamite language, another extinct language using the cuneiform script. The system uses optimality constraints and applies the gradual learning algorithm for learning a ranking between the constraints. Many grapheme-to-phoneme transcription systems formulate the task as a probabilistic sequence model on grapheme-phoneme pairs. For example, Bisani and Ney (2008) use joint n-gram models and Novak et al. (2012) use weighted finite-state transducers. These methods rely on some alignment between the grapheme and phoneme strings because"
2020.lrec-1.479,E09-2008,0,0.201819,"Missing"
2020.lrec-1.479,C88-1064,0,0.639231,"83k as different stages of Babylonian. In total, 1.42M Akkadian and 614k Babylonian tokens have been lemmatized and POS-tagged.4 For Neo-Assyrian, the most notable collection of texts is the State Archives of Assyria online (504k tokens), initiated already in 1986 by Simo Parpola in Helsinki and later lemmatized and added to Oracc by Karen Radner and her team. Currently, none of the afore-mentioned corpora contain a morphological analysis of Akkadian beyond lemmatization and POS-tagging. 3. Description of the FST-based Computational Model of Babylonian 3.1 Previous and other relevant attempts Kataja and Koskenniemi (1988) created the first computational description of the Akkadian morphology using the two-level formalism. They handled interdigitation of verbs by intersecting two regular lexicons, of which one described the root and its affixation, and the other the pattern formalisms. As the intersection approach was highly overgenerating, Kataja and Koskenniemi experimented with constraining the morpheme combinatorics by using unification-based features. This work was, however, stated to be still in progress when their paper was published. Bamman and Andersson5 (2012) is a finite-state description of Old Assy"
2020.lrec-1.479,W02-0501,0,0.11783,"Missing"
2020.tlt-1.11,E09-2008,0,0.124005,"Missing"
2020.tlt-1.11,K18-2013,0,0.0585483,"Missing"
2020.tlt-1.11,2020.lrec-1.479,1,0.791446,"Missing"
2020.vardial-1.1,2020.vardial-1.24,0,0.254959,"Missing"
2020.vardial-1.1,2020.vardial-1.26,0,0.535455,"y stages of the COVID-19 pandemic. Lock downs and restrictive measures in many countries during this period have impacted universities and research centers worldwide causing significant disruption. We believe that this situation is very likely to have discouraged more teams to participate in this year’s evaluation campaign. 2 Team RDI Akanksha Anumit¸i CUBoulder-UBC Phlyers HeLju NRC Piyush Mishra SUKI The Linguistadors T¨ubingen UAIC UnibucKernel UPB ZHAW-InIT Total SMG ULI System Description Paper X X (Popa and S, tef˘anescu, 2020) * (Ceolin and Zhang, 2020) (Scherrer and Ljubeˇsi´c, 2020) (Bernier-Colborne and Goutte, 2020) (Mishra, 2020) (Jauhiainen et al., 2020a) X X X X X X X X X X X (C¸o¨ ltekin, 2020) (Rebeja and Cristea, 2020) (G˘aman and Ionescu, 2020a) (Zaharia et al., 2020) (Benites et al., 2020) X X X 8 7 1 11 Table 1: The teams that participated in the VarDial Evaluation Campaign 2020 along with their system description papers. *The system description paper by team CUBoulder-UBC does not appear in the VarDial workshop proceedings. CUBoulder-UBC reused a system described in Hulden et al. (2015). 4 Romanian Dialect Identification RDI 4.1 Dataset The training data is composed of news articles from the Mo"
2020.vardial-1.1,W19-1402,0,0.3829,"Missing"
2020.vardial-1.1,W18-3909,1,0.890114,"Missing"
2020.vardial-1.1,P19-1068,1,0.744799,"Commons Attribution 4.0 International License. //creativecommons.org/licenses/by/4.0/. 1 https://sites.google.com/view/vardial2020/evaluation-campaign 2 For recent surveys on these topics see Zampieri et al. (2020) and Jauhiainen et al. (2019c). License details: http: 1 Proceedings of the 7th VarDial Workshop on NLP for Similar Languages, Varieties and Dialects, pages 1–14 Barcelona, Spain (Online), December 13, 2020 2 Shared Tasks at VarDial 2020 Romanian Dialect Identification (RDI): In the Romanian Dialect Identification (RDI) shared task, we provided participants with the MOROCO data set (Butnaru and Ionescu, 2019) for training, which contains Moldavian (MD) and Romanian (RO) samples of text collected from the news domain. The task was a binary classification by dialect, in which a classification model is required to discriminate between the Moldavian (MD) and the Romanian (RO) dialects. The task was closed, therefore, participants are not allowed to use external data to train their models. The test set contained newly collected text samples from a different domain, not previously included in MOROCO, resulting in a cross-domain dialect identification task. Social Media Variety Geolocation (SMG): In cont"
2020.vardial-1.1,2020.vardial-1.25,0,0.269727,"Missing"
2020.vardial-1.1,2020.vardial-1.17,0,0.072284,"Missing"
2020.vardial-1.1,N19-1423,0,0.024395,"ainen et al. (2020b). 6.2 Participants and Approaches Unfortunately, the ULI shared task had only one team submitting results to the tracks. The NRC team submitted three runs for each of the shared task tracks. All the runs used BERT-related deep neural networks taking sequences of characters as input similar to what the NRC team used when they won the CLI shared task (Jauhiainen et al., 2019b) in the previous VarDial Evaluation Campaign (BernierColborne et al., 2019). The encoders of the networks were pre-trained on masked language modeling (MLM) and sentence pair classification (SPC) tasks (Devlin et al., 2019). The third run on each track was using only the information on the training set as opposed to the second run, in which the MLM was also done on the unlabeled test set in order to adapt the model. The first run on each track was a plurality voting ensemble of the six models used in the second and third runs of all the tracks. 6.3 Results For the baseline, we used an implementation of the HeLI method equal to the one we used when evaluating language identification methods for 285 languages (Jauhiainen et al., 2017). The baseline and the NRC teams results are listed in Tables 8, 9, and 10. Rank"
2020.vardial-1.1,2020.findings-emnlp.387,0,0.274164,"Missing"
2020.vardial-1.1,goldhahn-etal-2012-building,0,0.217587,"same data format and evaluation methodology. Both constrained and unconstrained submissions were allowed, but only one participating team made use of the latter. Uralic Language Identification (ULI): This shared task focused on discriminating between endangered languages of the Uralic group. In addition to 29 Uralic minority languages, the shared task also featured 149 non-relevant languages. For training, we provided texts from the Wanca 2016 corpora (Jauhiainen et al., 2019a) for the relevant languages while the texts for the non-relevant languages came from the Leipzig corpora collection (Goldhahn et al., 2012). The test set for the relevant languages included sentences from the forthcoming Wanca 2017 corpora (Jauhiainen et al., 2020b) that were not present in the Wanca 2016 corpora. The sentences for the non-relevant languages were from the Leipzig corpora collection. The ULI shared task was divided into three separate tracks using the same training and test data. The difference between the tracks was based on how the submissions were scored: track 1 focused on macro-averaged F-score for the 29 relevant languages, track 2 on micro-averaged F-score for the relevant languages, and track 3 on macro-av"
2020.vardial-1.1,L16-1284,1,0.891978,"Missing"
2020.vardial-1.1,2020.vardial-1.23,1,0.814174,"Missing"
2020.vardial-1.1,D18-1469,1,0.402749,"e SMG task is split into three subtasks covering different language areas: the BCMS subtask is focused on geolocated tweets published in the area of Croatia, Bosnia and Herzegovina, Montenegro and Serbia in the HBS macro-language (Ljubeˇsi´c et al., 2016); the DE-AT subtask focuses on conversations from the microblogging platform Jodel initiated in Germany and Austria, which are written in standard German but commonly contain regional and dialectal forms; the CH subtask is based on Jodel conversations initiated in Switzerland, which were found to be held majoritarily in Swiss German dialects (Hovy and Purschke, 2018). All three subtasks used the same data format and evaluation methodology. Both constrained and unconstrained submissions were allowed, but only one participating team made use of the latter. Uralic Language Identification (ULI): This shared task focused on discriminating between endangered languages of the Uralic group. In addition to 29 Uralic minority languages, the shared task also featured 149 non-relevant languages. For training, we provided texts from the Wanca 2016 corpora (Jauhiainen et al., 2019a) for the relevant languages while the texts for the non-relevant languages came from the"
2020.vardial-1.1,W17-1225,1,0.926999,"Missing"
2020.vardial-1.1,J16-3005,1,0.860747,"h quantile loss. SUKI. This approach divides each geographic area into a fixed grid with 81 areas and uses a n-gram language model to predict the most likely area (Jauhiainen et al., 2020a). The Linguistadors. These submissions are based on classic regression methods (linear regression, lasso regression, and ridge regression) and rely on TF-IDF weighted input features. UnibucKernel. The UnibucKernel team (G˘aman and Ionescu, 2020a) submitted two single systems, a character-level CNN (Zhang et al., 2015) with double regression output, and a Nu-SVR model trained on top of n-gram string kernels (Ionescu et al., 2016). The third system is an ensemble approach based on XGBoost, trained on the predictions provided by the two previously mentioned systems and an LSTMbased one. The LSTM is trained on top of fine-tuned German BERT embeddings. ZHAW-InIT. The ZHAW-InIT team (Benites et al., 2020) uses unsupervised k-means clustering to infer a set of dialect classes which are then used in a classification architecture. Their systems are based 7 either on SVMs with TF-IDF weighted word and character n-gram features, or on the HELI language modeling architecture (ZHAW-InIT (HELI)). The SVM submission to the CH subta"
2020.vardial-1.1,W17-0221,1,0.877702,"Missing"
2020.vardial-1.1,W19-1409,1,0.856366,"Missing"
2020.vardial-1.1,2020.vardial-1.21,1,0.758565,"Missing"
2020.vardial-1.1,W16-4801,1,0.731395,"Missing"
2020.vardial-1.1,2020.vardial-1.27,0,0.363938,"ock downs and restrictive measures in many countries during this period have impacted universities and research centers worldwide causing significant disruption. We believe that this situation is very likely to have discouraged more teams to participate in this year’s evaluation campaign. 2 Team RDI Akanksha Anumit¸i CUBoulder-UBC Phlyers HeLju NRC Piyush Mishra SUKI The Linguistadors T¨ubingen UAIC UnibucKernel UPB ZHAW-InIT Total SMG ULI System Description Paper X X (Popa and S, tef˘anescu, 2020) * (Ceolin and Zhang, 2020) (Scherrer and Ljubeˇsi´c, 2020) (Bernier-Colborne and Goutte, 2020) (Mishra, 2020) (Jauhiainen et al., 2020a) X X X X X X X X X X X (C¸o¨ ltekin, 2020) (Rebeja and Cristea, 2020) (G˘aman and Ionescu, 2020a) (Zaharia et al., 2020) (Benites et al., 2020) X X X 8 7 1 11 Table 1: The teams that participated in the VarDial Evaluation Campaign 2020 along with their system description papers. *The system description paper by team CUBoulder-UBC does not appear in the VarDial workshop proceedings. CUBoulder-UBC reused a system described in Hulden et al. (2015). 4 Romanian Dialect Identification RDI 4.1 Dataset The training data is composed of news articles from the Moldavian and Rom"
2020.vardial-1.1,2020.vardial-1.18,0,0.531349,"Missing"
2020.vardial-1.1,2020.vardial-1.20,0,0.189489,"Missing"
2020.vardial-1.1,L16-1641,1,0.889566,"Missing"
2020.vardial-1.1,2020.vardial-1.19,1,0.750864,"Missing"
2020.vardial-1.1,2020.vardial-1.22,0,0.515168,"Missing"
2020.vardial-1.1,W17-1201,1,0.773425,"Missing"
2020.vardial-1.16,W19-0311,0,0.0266279,"Partanen et al., 2018), Komi-Permyak, Erzya (Rueter and Tyers, 2018), Moksha, and two Karelian varieties (Pirinen, 2019). Under construction in the Language Bank of Finland is also the Parallel Bible Verses for Uralic Studies corpus (PaBiVus), which contains Bible translations from different publications.16 Especially in the context of this shared task it is important to mention previous work that has collected online texts in the minority languages spoken in Russia. At least Orekhov et al. (2016) and Krylova et al. (2015) have collected online and social media texts in various languages, and Arkhangelskiy (2019) has published corpora of this type for Uralic languages. Wanca 2017 corpora, described next, connects well to the earlier work. 3 Wanca 2017 corpora The aim of the SUKI project was to find texts written in Uralic minority languages from the Internet (Jauhiainen et al., 2015a). The set of relevant languages was determined as all the Uralic languages included in the ISO 639-3 standard except Finnish, Estonian, and Hungarian. In order to find the texts, we used an open-source web-crawler called Heritrix (Mohr et al., 2004) combined with different language identifiers we were developing during th"
2020.vardial-1.16,W17-1214,0,0.0291561,"Missing"
2020.vardial-1.16,W16-4802,0,0.0333325,"Missing"
2020.vardial-1.16,goldhahn-etal-2012-building,0,0.0312172,"more endangered Uralic languages from the Internet (Jauhiainen et al., 2015a). In this paper, we introduce the Wanca 2017 corpora which will be published in the Language Bank of Finland2 as a downloadable package as well as through the Korp3 concordance service. The Uralic Language Identification (ULI) 2020 shared task4 was organized as part of the VarDial 2020 Evaluation campaign.5 In order to create a training dataset for the shared task, we used the earlier version of the corpora, Wanca 20166 (Jauhiainen et al., 2019a), together with corpora available from the Leipzig corpora collection7 (Goldhahn et al., 2012). Different corpora from the Leipzig corpora collection and a manually verified subset of the Wanca 2017 corpora were used to create the test set for the shared task. We also performed a baseline language identification experiment for the ULI dataset using the HeLI method described by Jauhiainen et al. (2017b). In this paper, we first introduce some related work and resources for language identification and the Uralic languages in Section 2. We then describe the Wanca 2017 corpora and its creation in Section 3. 1 http://www.suki.ling.helsinki.fi/eng/project.html https://www.kielipankki.fi/lang"
2020.vardial-1.16,W15-5413,0,0.0785007,"Missing"
2020.vardial-1.16,W15-5408,1,0.882905,"Missing"
2020.vardial-1.16,W16-4820,1,0.890165,"Missing"
2020.vardial-1.16,W17-1212,1,0.84915,"Missing"
2020.vardial-1.16,W17-0221,1,0.902463,"Missing"
2020.vardial-1.16,2020.wac-1.4,1,0.812695,"Missing"
2020.vardial-1.16,2005.mtsummit-papers.11,0,0.172253,"e is also the aspect of time, as continuous use accumulates increasingly larger resources. When it comes to extinct languages, their corpora have to be considered finite. 175 2.3 Corpora for Uralic languages For the Uralic languages that are the majority language of a country, that is Finnish, Estonian, and Hungarian, many large text corpora already exist. For example, there is the Suomi 24 Corpus8 with over 250 million Finnish sentences from a social networking website available from the Language Bank of Finland, and the Europarl corpus9 with over 600,000 sentences of Hungarian and Estonian (Koehn, 2005). The Leipzig Corpora Collection10 has texts also for some of the more rare Uralic languages: Eastern Mari, Komi, Komi-Permyak, Northern Saami, Udmurt, V˜oro, and Western Mari. The Giellatekno research group has three Korp installations for Uralic languages: one11 for Saami languages, one12 for Kven, Me¨ankieli, Veps, and V˜oro, and one13 for Komi-Zyrian, Komi-Permyak, Udmurt, Moksha, Erzya, Hill Mari, and Meadow Mari. The Wanca in Korp corpora contain texts in all the aforementioned languages as well as some additional Uralic languages.14 Several endangered Uralic languages also have treebank"
2020.vardial-1.16,W15-5407,0,0.0230821,"Missing"
2020.vardial-1.16,W16-4801,0,0.0435893,"Missing"
2020.vardial-1.16,W18-6015,1,0.845824,"Komi-Permyak, Northern Saami, Udmurt, V˜oro, and Western Mari. The Giellatekno research group has three Korp installations for Uralic languages: one11 for Saami languages, one12 for Kven, Me¨ankieli, Veps, and V˜oro, and one13 for Komi-Zyrian, Komi-Permyak, Udmurt, Moksha, Erzya, Hill Mari, and Meadow Mari. The Wanca in Korp corpora contain texts in all the aforementioned languages as well as some additional Uralic languages.14 Several endangered Uralic languages also have treebanks in the Universal Dependencies project.15 These include Northern Saami (Tyers and Sheyanova, 2017), Komi-Zyrian (Partanen et al., 2018), Komi-Permyak, Erzya (Rueter and Tyers, 2018), Moksha, and two Karelian varieties (Pirinen, 2019). Under construction in the Language Bank of Finland is also the Parallel Bible Verses for Uralic Studies corpus (PaBiVus), which contains Bible translations from different publications.16 Especially in the context of this shared task it is important to mention previous work that has collected online texts in the minority languages spoken in Russia. At least Orekhov et al. (2016) and Krylova et al. (2015) have collected online and social media texts in various languages, and Arkhangelskiy (2019) h"
2020.vardial-1.16,W19-8016,0,0.0133893,"rp installations for Uralic languages: one11 for Saami languages, one12 for Kven, Me¨ankieli, Veps, and V˜oro, and one13 for Komi-Zyrian, Komi-Permyak, Udmurt, Moksha, Erzya, Hill Mari, and Meadow Mari. The Wanca in Korp corpora contain texts in all the aforementioned languages as well as some additional Uralic languages.14 Several endangered Uralic languages also have treebanks in the Universal Dependencies project.15 These include Northern Saami (Tyers and Sheyanova, 2017), Komi-Zyrian (Partanen et al., 2018), Komi-Permyak, Erzya (Rueter and Tyers, 2018), Moksha, and two Karelian varieties (Pirinen, 2019). Under construction in the Language Bank of Finland is also the Parallel Bible Verses for Uralic Studies corpus (PaBiVus), which contains Bible translations from different publications.16 Especially in the context of this shared task it is important to mention previous work that has collected online texts in the minority languages spoken in Russia. At least Orekhov et al. (2016) and Krylova et al. (2015) have collected online and social media texts in various languages, and Arkhangelskiy (2019) has published corpora of this type for Uralic languages. Wanca 2017 corpora, described next, connec"
2020.vardial-1.16,W18-0210,0,0.0261182,"and Western Mari. The Giellatekno research group has three Korp installations for Uralic languages: one11 for Saami languages, one12 for Kven, Me¨ankieli, Veps, and V˜oro, and one13 for Komi-Zyrian, Komi-Permyak, Udmurt, Moksha, Erzya, Hill Mari, and Meadow Mari. The Wanca in Korp corpora contain texts in all the aforementioned languages as well as some additional Uralic languages.14 Several endangered Uralic languages also have treebanks in the Universal Dependencies project.15 These include Northern Saami (Tyers and Sheyanova, 2017), Komi-Zyrian (Partanen et al., 2018), Komi-Permyak, Erzya (Rueter and Tyers, 2018), Moksha, and two Karelian varieties (Pirinen, 2019). Under construction in the Language Bank of Finland is also the Parallel Bible Verses for Uralic Studies corpus (PaBiVus), which contains Bible translations from different publications.16 Especially in the context of this shared task it is important to mention previous work that has collected online texts in the minority languages spoken in Russia. At least Orekhov et al. (2016) and Krylova et al. (2015) have collected online and social media texts in various languages, and Arkhangelskiy (2019) has published corpora of this type for Uralic l"
2020.vardial-1.16,2020.iwclul-1.3,1,0.769861,"nventions that make distinguishing the language of a text almost always straightforward, at least to a specialist. Such closely related languages with clearly distinct written traditions include two Komi written standards, two Mari written standards and two Mordva written standards. These differences are large enough that, from the perspective of computational linguistics, distinct infrastructure usually has to be developed for each variety, even if the actual linguistic differences would be minor. For an example of challenges in creating an infrastructure for Komi-Permyak and Komi-Zyrian see Rueter et al. (2020) and for Mordvinic languages see Rueter et al. (in press). Some of these orthographies were more successful than others, and there is large variation in when exactly the currently used systems were established and what level of stability they have. For example, the orthography created in 1986 for Nganasan was never widely used, and in the current orthography the conventions vary with author and editor (Wagner-Nagy, 2018). For languages such as Votic, the current ` orthography was developed first in the 2000s (Ernits, 2006, 3). An earlier example is Tundra Nenets, which has had the current orth"
2020.vardial-1.16,W14-3907,0,0.0533736,"Missing"
2020.vardial-1.16,W17-0607,0,0.0248411,"re Uralic languages: Eastern Mari, Komi, Komi-Permyak, Northern Saami, Udmurt, V˜oro, and Western Mari. The Giellatekno research group has three Korp installations for Uralic languages: one11 for Saami languages, one12 for Kven, Me¨ankieli, Veps, and V˜oro, and one13 for Komi-Zyrian, Komi-Permyak, Udmurt, Moksha, Erzya, Hill Mari, and Meadow Mari. The Wanca in Korp corpora contain texts in all the aforementioned languages as well as some additional Uralic languages.14 Several endangered Uralic languages also have treebanks in the Universal Dependencies project.15 These include Northern Saami (Tyers and Sheyanova, 2017), Komi-Zyrian (Partanen et al., 2018), Komi-Permyak, Erzya (Rueter and Tyers, 2018), Moksha, and two Karelian varieties (Pirinen, 2019). Under construction in the Language Bank of Finland is also the Parallel Bible Verses for Uralic Studies corpus (PaBiVus), which contains Bible translations from different publications.16 Especially in the context of this shared task it is important to mention previous work that has collected online texts in the minority languages spoken in Russia. At least Orekhov et al. (2016) and Krylova et al. (2015) have collected online and social media texts in various"
2020.vardial-1.16,W14-5307,0,0.021458,"Missing"
2020.vardial-1.16,W15-5401,0,0.0426125,"Missing"
2020.vardial-1.16,W17-1201,0,0.031691,"Missing"
2020.vardial-1.16,W18-3901,0,0.0396364,"Missing"
2020.vardial-1.21,W19-1402,0,0.29615,"Missing"
2020.vardial-1.21,W17-1214,0,0.0150953,"50 years. The methods used for the task of language identification are mostly shared with other classification tasks as almost any modern machine learning method can be trained to distinguish between different languages (Jauhiainen, 2019). Support Vector Machines (SVM) are among the most popular and successful machine learning algorithms that have been applied to language identification and have traditionally been very competetive in language identification shared tasks, winning many of them (Goutte et al., 2014; Malmasi and Dras, 2015; C¸o¨ ltekin and Rama, 2016; Malmasi and Zampieri, 2016; Bestgen, 2017; Malmasi and Zampieri, 2017; C¸o¨ ltekin et al., 2018; Wu et al., 2019). Deep learning methods have traditionally been less successful in language identification than in other classification tasks (C ¸ o¨ ltekin and Rama, 2016; Gamallo et al., 2016; Medvedeva et al., 2017). The first time a language identification shared task was won using deep learning was in the Cuneiform Language Identification (CLI) shared task we organized in 2019 (Zampieri et al., 2019; Jauhiainen et al., 2019a) when it was won by Bernier-Colborne et al. (2019) using BERT-based classifier (Devlin et al., 2018). In our s"
2020.vardial-1.21,P19-1068,0,0.209499,"between Moldavian and Romanian. Romanian and Moldavian are coupled together as dialects of the Romanian language (ron) in the ISO 639-3 standard (SIL, 2020).2 The shared task debuted as one of the tracks of the MRC shared task of the VarDial Evaluation Campaign 2019 (Zampieri et al., 2019). The aim was to maximize the macro-averaged F1 score for the two dialects. When macro-averaging, the F1 score of each individual dialect is calculated first and the result is the average of those F1 scores. The dataset of the shared task was published as the Moldavian and Romanian Dialectal Corpus (MOROCO) (Butnaru and Ionescu, 2019). The 2019 edition was officially won by Tudoreanu (2019) using two character-level neural networks which were combined as an ensemble using SVM in the manner of Stacked Generalisation (Wolpert, 1992). Some of the participants had problems producing the correct number of lines for their submissions (Zampieri et al., 2019) and produced corrected results after the end of the shared task for their system description papers (Onose et al., 2019; Wu et al., 2019). Some additional experiments using the MOROCO data have also been reported (Tudoreanu, 2019; Onose et al., 2019; G˘aman and Ionescu, 2020;"
2020.vardial-1.21,W16-4802,0,0.0172391,"as most of the methods used for it during the past 50 years. The methods used for the task of language identification are mostly shared with other classification tasks as almost any modern machine learning method can be trained to distinguish between different languages (Jauhiainen, 2019). Support Vector Machines (SVM) are among the most popular and successful machine learning algorithms that have been applied to language identification and have traditionally been very competetive in language identification shared tasks, winning many of them (Goutte et al., 2014; Malmasi and Dras, 2015; C¸o¨ ltekin and Rama, 2016; Malmasi and Zampieri, 2016; Bestgen, 2017; Malmasi and Zampieri, 2017; C¸o¨ ltekin et al., 2018; Wu et al., 2019). Deep learning methods have traditionally been less successful in language identification than in other classification tasks (C ¸ o¨ ltekin and Rama, 2016; Gamallo et al., 2016; Medvedeva et al., 2017). The first time a language identification shared task was won using deep learning was in the Cuneiform Language Identification (CLI) shared task we organized in 2019 (Zampieri et al., 2019; Jauhiainen et al., 2019a) when it was won by Bernier-Colborne et al. (2019) using BERT-based"
2020.vardial-1.21,W19-1414,0,0.058227,"Missing"
2020.vardial-1.21,W16-4822,0,0.0155281,"upport Vector Machines (SVM) are among the most popular and successful machine learning algorithms that have been applied to language identification and have traditionally been very competetive in language identification shared tasks, winning many of them (Goutte et al., 2014; Malmasi and Dras, 2015; C¸o¨ ltekin and Rama, 2016; Malmasi and Zampieri, 2016; Bestgen, 2017; Malmasi and Zampieri, 2017; C¸o¨ ltekin et al., 2018; Wu et al., 2019). Deep learning methods have traditionally been less successful in language identification than in other classification tasks (C ¸ o¨ ltekin and Rama, 2016; Gamallo et al., 2016; Medvedeva et al., 2017). The first time a language identification shared task was won using deep learning was in the Cuneiform Language Identification (CLI) shared task we organized in 2019 (Zampieri et al., 2019; Jauhiainen et al., 2019a) when it was won by Bernier-Colborne et al. (2019) using BERT-based classifier (Devlin et al., 2018). In our submissions for the shared tasks, we used language identifiers based on the product of relative frequencies we had developed for the VarDial Evaluation campaign of the previous year (Jauhiainen et al., 2019a; Jauhiainen et al., 2019b). The method is"
2020.vardial-1.21,W14-5316,0,0.121828,"Missing"
2020.vardial-1.21,L18-1550,0,0.0296499,"nd the third lists the source for the information. The methods used include SVMs, Kernel Ridge Regression (KRR), Convolutional Neural Networks (CNN), Hierarchical Attention Networks (HAN) (Yang et al., 2016), Bidirectional Gated Recurrent Units (BiGRU), Long Short-Term Memory cells (LSTM), and Recurrent Neural Networks (RNN). The MRC shared task was supposed to be closed, i.e. no task external data was to be used. However, pre-trained word vectors were used during the competition and have also been used in some of the later experiments. The pre-trained word vectors used are from Common Crawl (Grave et al., 2018), Romanian Language Corpus (CoRoLa) 2 https://iso639-3.sil.org/code/ron 221 (Mititelu et al., 2018), and the Nordic Language Processing Laboratory “NLPL” (Kutuzov et al., 2017) and they have been indicated in Table 1. Method Linear SVM classifier with LM adaptation (tearsofjoy) Stacking with 12 classifiers KRR with string kernels KRR CNN+SE with ADA activation SVM with string kernels CNN with ADA activation CNN+SE+PyNADA with ReLU and ADA activations CNN with ReLU and ADA activations Ensemble (DTeam) Neural network based on softmax loss (DTeam) CNN+SE with leaky ReLU activation HAN with FastTe"
2020.vardial-1.21,2020.vardial-1.1,1,0.758565,"Missing"
2020.vardial-1.21,D18-1469,0,0.11159,"econd track, CH, focused on Swiss German Jodel conversations from Switzerland. The third track, BCMS, featured tweets from Croatia, Bosnia and Herzegovia, Montenegro, and Serbia. All the tracks were scored using the median distance in kilometers of all the predicted locations to the actual ones. 4.1 The datasets for the shared task Before the testing period the participants were provided with training and development data for each of the tracks. The data for the DE-AT and CH tracks came from a mobile chat application called Jodel, where users can chat anonymously with others in the same area (Hovy and Purschke, 2018) while the data for the BCMS track consisted of tweets (Ljubeˇsi´c et al., 2016). The sizes of each dataset are shown in Table 8. The reason why the BCMS data is divided between many more locations than the DE-AT and CH data is that the coordinates of the locations are given in much more detail (with up to 8 decimal places in BCMS and only 2 decimal places for DE-AT and CH). Track DE-AT DE-AT DE-AT CH CH CH BCMS BCMS BCMS Set Training Development Test Training Development Test Training Development Test #Texts 336,983 46,582 48,239 22,600 3,068 3,097 320,042 39,750 39,723 Average length in toke"
2020.vardial-1.21,W15-5408,1,0.898237,"Missing"
2020.vardial-1.21,W16-4820,1,0.931271,"Missing"
2020.vardial-1.21,W18-3929,1,0.907985,"Missing"
2020.vardial-1.21,W18-3907,1,0.9262,"Missing"
2020.vardial-1.21,W19-1409,1,0.890567,"Missing"
2020.vardial-1.21,W19-1419,1,0.907996,"Missing"
2020.vardial-1.21,W17-0237,0,0.0135578,"etworks (HAN) (Yang et al., 2016), Bidirectional Gated Recurrent Units (BiGRU), Long Short-Term Memory cells (LSTM), and Recurrent Neural Networks (RNN). The MRC shared task was supposed to be closed, i.e. no task external data was to be used. However, pre-trained word vectors were used during the competition and have also been used in some of the later experiments. The pre-trained word vectors used are from Common Crawl (Grave et al., 2018), Romanian Language Corpus (CoRoLa) 2 https://iso639-3.sil.org/code/ron 221 (Mititelu et al., 2018), and the Nordic Language Processing Laboratory “NLPL” (Kutuzov et al., 2017) and they have been indicated in Table 1. Method Linear SVM classifier with LM adaptation (tearsofjoy) Stacking with 12 classifiers KRR with string kernels KRR CNN+SE with ADA activation SVM with string kernels CNN with ADA activation CNN+SE+PyNADA with ReLU and ADA activations CNN with ReLU and ADA activations Ensemble (DTeam) Neural network based on softmax loss (DTeam) CNN+SE with leaky ReLU activation HAN with FastText Common Crawl word vectors (SC-UPB) CNN+SE with ReLU activation CNN+SE CNN with characters Voting between 12 classifiers CNN with leaky ReLU activation CNN (DTeam) CNN with R"
2020.vardial-1.21,C16-1322,0,0.251327,"Missing"
2020.vardial-1.21,W15-5407,0,0.0192862,"nguage identification as well as most of the methods used for it during the past 50 years. The methods used for the task of language identification are mostly shared with other classification tasks as almost any modern machine learning method can be trained to distinguish between different languages (Jauhiainen, 2019). Support Vector Machines (SVM) are among the most popular and successful machine learning algorithms that have been applied to language identification and have traditionally been very competetive in language identification shared tasks, winning many of them (Goutte et al., 2014; Malmasi and Dras, 2015; C¸o¨ ltekin and Rama, 2016; Malmasi and Zampieri, 2016; Bestgen, 2017; Malmasi and Zampieri, 2017; C¸o¨ ltekin et al., 2018; Wu et al., 2019). Deep learning methods have traditionally been less successful in language identification than in other classification tasks (C ¸ o¨ ltekin and Rama, 2016; Gamallo et al., 2016; Medvedeva et al., 2017). The first time a language identification shared task was won using deep learning was in the Cuneiform Language Identification (CLI) shared task we organized in 2019 (Zampieri et al., 2019; Jauhiainen et al., 2019a) when it was won by Bernier-Colborne et"
2020.vardial-1.21,W16-4814,0,0.0186263,"used for it during the past 50 years. The methods used for the task of language identification are mostly shared with other classification tasks as almost any modern machine learning method can be trained to distinguish between different languages (Jauhiainen, 2019). Support Vector Machines (SVM) are among the most popular and successful machine learning algorithms that have been applied to language identification and have traditionally been very competetive in language identification shared tasks, winning many of them (Goutte et al., 2014; Malmasi and Dras, 2015; C¸o¨ ltekin and Rama, 2016; Malmasi and Zampieri, 2016; Bestgen, 2017; Malmasi and Zampieri, 2017; C¸o¨ ltekin et al., 2018; Wu et al., 2019). Deep learning methods have traditionally been less successful in language identification than in other classification tasks (C ¸ o¨ ltekin and Rama, 2016; Gamallo et al., 2016; Medvedeva et al., 2017). The first time a language identification shared task was won using deep learning was in the Cuneiform Language Identification (CLI) shared task we organized in 2019 (Zampieri et al., 2019; Jauhiainen et al., 2019a) when it was won by Bernier-Colborne et al. (2019) using BERT-based classifier (Devlin et al.,"
2020.vardial-1.21,W17-1220,0,0.0326034,"methods used for the task of language identification are mostly shared with other classification tasks as almost any modern machine learning method can be trained to distinguish between different languages (Jauhiainen, 2019). Support Vector Machines (SVM) are among the most popular and successful machine learning algorithms that have been applied to language identification and have traditionally been very competetive in language identification shared tasks, winning many of them (Goutte et al., 2014; Malmasi and Dras, 2015; C¸o¨ ltekin and Rama, 2016; Malmasi and Zampieri, 2016; Bestgen, 2017; Malmasi and Zampieri, 2017; C¸o¨ ltekin et al., 2018; Wu et al., 2019). Deep learning methods have traditionally been less successful in language identification than in other classification tasks (C ¸ o¨ ltekin and Rama, 2016; Gamallo et al., 2016; Medvedeva et al., 2017). The first time a language identification shared task was won using deep learning was in the Cuneiform Language Identification (CLI) shared task we organized in 2019 (Zampieri et al., 2019; Jauhiainen et al., 2019a) when it was won by Bernier-Colborne et al. (2019) using BERT-based classifier (Devlin et al., 2018). In our submissions for the shared ta"
2020.vardial-1.21,W16-4801,0,0.0869842,"Missing"
2020.vardial-1.21,W17-1219,0,0.0127289,"(SVM) are among the most popular and successful machine learning algorithms that have been applied to language identification and have traditionally been very competetive in language identification shared tasks, winning many of them (Goutte et al., 2014; Malmasi and Dras, 2015; C¸o¨ ltekin and Rama, 2016; Malmasi and Zampieri, 2016; Bestgen, 2017; Malmasi and Zampieri, 2017; C¸o¨ ltekin et al., 2018; Wu et al., 2019). Deep learning methods have traditionally been less successful in language identification than in other classification tasks (C ¸ o¨ ltekin and Rama, 2016; Gamallo et al., 2016; Medvedeva et al., 2017). The first time a language identification shared task was won using deep learning was in the Cuneiform Language Identification (CLI) shared task we organized in 2019 (Zampieri et al., 2019; Jauhiainen et al., 2019a) when it was won by Bernier-Colborne et al. (2019) using BERT-based classifier (Devlin et al., 2018). In our submissions for the shared tasks, we used language identifiers based on the product of relative frequencies we had developed for the VarDial Evaluation campaign of the previous year (Jauhiainen et al., 2019a; Jauhiainen et al., 2019b). The method is basically the same as Nai"
2020.vardial-1.21,L18-1189,0,0.0633412,"Missing"
2020.vardial-1.21,W19-1418,0,0.0211549,"the result is the average of those F1 scores. The dataset of the shared task was published as the Moldavian and Romanian Dialectal Corpus (MOROCO) (Butnaru and Ionescu, 2019). The 2019 edition was officially won by Tudoreanu (2019) using two character-level neural networks which were combined as an ensemble using SVM in the manner of Stacked Generalisation (Wolpert, 1992). Some of the participants had problems producing the correct number of lines for their submissions (Zampieri et al., 2019) and produced corrected results after the end of the shared task for their system description papers (Onose et al., 2019; Wu et al., 2019). Some additional experiments using the MOROCO data have also been reported (Tudoreanu, 2019; Onose et al., 2019; G˘aman and Ionescu, 2020; Georgescu et al., 2020). G˘aman and Ionescu (2020) conducted an evaluation of the data and compared the performance of several methods with the annotations done by native speakers of the dialects. They noted that the machine learning methods were superior to humans in distinguishing between the two dialects and concluded that the models were better at finding character level clues than human annotators. The results of all these experiment"
2020.vardial-1.21,W19-1422,0,0.594126,"together as dialects of the Romanian language (ron) in the ISO 639-3 standard (SIL, 2020).2 The shared task debuted as one of the tracks of the MRC shared task of the VarDial Evaluation Campaign 2019 (Zampieri et al., 2019). The aim was to maximize the macro-averaged F1 score for the two dialects. When macro-averaging, the F1 score of each individual dialect is calculated first and the result is the average of those F1 scores. The dataset of the shared task was published as the Moldavian and Romanian Dialectal Corpus (MOROCO) (Butnaru and Ionescu, 2019). The 2019 edition was officially won by Tudoreanu (2019) using two character-level neural networks which were combined as an ensemble using SVM in the manner of Stacked Generalisation (Wolpert, 1992). Some of the participants had problems producing the correct number of lines for their submissions (Zampieri et al., 2019) and produced corrected results after the end of the shared task for their system description papers (Onose et al., 2019; Wu et al., 2019). Some additional experiments using the MOROCO data have also been reported (Tudoreanu, 2019; Onose et al., 2019; G˘aman and Ionescu, 2020; Georgescu et al., 2020). G˘aman and Ionescu (2020) condu"
2020.vardial-1.21,W19-1406,0,0.0960175,"re mostly shared with other classification tasks as almost any modern machine learning method can be trained to distinguish between different languages (Jauhiainen, 2019). Support Vector Machines (SVM) are among the most popular and successful machine learning algorithms that have been applied to language identification and have traditionally been very competetive in language identification shared tasks, winning many of them (Goutte et al., 2014; Malmasi and Dras, 2015; C¸o¨ ltekin and Rama, 2016; Malmasi and Zampieri, 2016; Bestgen, 2017; Malmasi and Zampieri, 2017; C¸o¨ ltekin et al., 2018; Wu et al., 2019). Deep learning methods have traditionally been less successful in language identification than in other classification tasks (C ¸ o¨ ltekin and Rama, 2016; Gamallo et al., 2016; Medvedeva et al., 2017). The first time a language identification shared task was won using deep learning was in the Cuneiform Language Identification (CLI) shared task we organized in 2019 (Zampieri et al., 2019; Jauhiainen et al., 2019a) when it was won by Bernier-Colborne et al. (2019) using BERT-based classifier (Devlin et al., 2018). In our submissions for the shared tasks, we used language identifiers based on t"
2020.vardial-1.21,N16-1174,0,0.0194125,"thods were superior to humans in distinguishing between the two dialects and concluded that the models were better at finding character level clues than human annotators. The results of all these experiments were not available together, so we collected them in Table 1. The first column describes the method used as well as the possible MRC team name in parentheses. The second column gives the Macro F1 score and the third lists the source for the information. The methods used include SVMs, Kernel Ridge Regression (KRR), Convolutional Neural Networks (CNN), Hierarchical Attention Networks (HAN) (Yang et al., 2016), Bidirectional Gated Recurrent Units (BiGRU), Long Short-Term Memory cells (LSTM), and Recurrent Neural Networks (RNN). The MRC shared task was supposed to be closed, i.e. no task external data was to be used. However, pre-trained word vectors were used during the competition and have also been used in some of the later experiments. The pre-trained word vectors used are from Common Crawl (Grave et al., 2018), Romanian Language Corpus (CoRoLa) 2 https://iso639-3.sil.org/code/ron 221 (Mititelu et al., 2018), and the Nordic Language Processing Laboratory “NLPL” (Kutuzov et al., 2017) and they ha"
2020.vardial-1.21,W14-5307,0,0.177469,"Missing"
2020.vardial-1.21,W15-5401,0,0.106702,"Missing"
2020.vardial-1.21,W17-1201,0,0.166508,"Missing"
2020.vardial-1.21,W18-3901,0,0.0645127,"Missing"
2020.wac-1.4,P13-3002,0,0.28628,"uage of a text. Panchenko et al. (2018) built a corpus in English using the C4Corpus tool6 to find relevant pages in the Common Crawl corpus. 2.2. Schäfer and Bildhauer (2012) recommend that projects wishing to build large web corpora do not use search engine results except as seed URLs for a crawler. The results of their analysis demonstrate that simply downloading the query results with a tool such as BootCaT is not effective enough and that many sites that can be found while crawling the web intensively cannot be found through search engine queries. In addition to this, Sharoff (2006b) and Barbaresi (2013) raise the question of search engines ordering the results according to their ""relevance"" and the bias this might cause. 2.3. Crawling to Gather Texts Web crawling is the task of finding large amounts of pages on the web by extracting hyperlinks from already downloaded documents and following them (Olston and Najork, 2010). Web crawlers are used, for example, by search engines to index the web, but also for archiving pages and for data mining. According to Fletcher (2012), it is important to crawl the web if one wants to build web corpora in several languages besides English. Those who have pr"
2020.wac-1.4,baroni-bernardini-2004-bootcat,0,0.180255,"the Internet. Ghani et al. (2001) compiled a script called CorpusBuilder,7 which selects terms from two documents, one relevant and the other not, and constructs a query that uses the conjunction of the terms from the relevant document and the negation of the disjunction of the ones from the nonrelevant. The top search engine hit for the query is then downloaded, and the document assigned to either the relevant or non-relevant document set. Search engine queries were also used by Sharoff (2006a) in his corpus building strategy and by Ueyama and Baroni (2005) for building a corpus in Japanese. Baroni and Bernardini (2004) created a toolkit called BootCaT,8 which takes a small set of seed terms and uses queries produced from them to download pages with a search engine. The toolkit was tested by building corpora for English and Italian. BootCaT was also used by Baroni and Ueyama (2004), Sharoff (2006b), and Lyding et al. (2014). Scannell (2007) built a tool that resembled BootCaT. Depending on the language, the query lists were built with either word lists from a spell checker or word frequency lists. Sometimes language models of trigrams were used to make sure the language was the relevant one. With the tool, S"
2020.wac-1.4,E06-2001,0,0.57697,"006) restricted the crawler to accept only pages with metadata language codes indicating the Chinese language. After the crawl, they used the Rosette Language Identifier11 to detect the language of each page. Many researchers prefer to crawl national top-level domains where texts in the desired language are believed to be found. Then after the crawl, the language of the pages is verified with various methods. Kornai et al. (2006) applied spell checking to filter out pages that were not in Hungarian. The presence of function words has also been used as a simple form of language identification (Baroni and Kilgariff, 2006; Ferraresi et al., 2008; Baroni et al., 2009), whereas more sophisticated language identifiers were used by Pomikálek et al. (2009) and Schäfer and Bildhauer (2012). As the .es national domain was very small at the time, Boleda et al. (2006) additionally crawled pages from other domains which were located in Spain in order to build a corpus of Catalan texts. The language of the pages was then identified using a Naive Bayes classifier. named Nutch12 and identified the language of the pages with TextCat. Mon and Mikami (2011) built their own focused crawler with n-gram based language identifica"
2020.wac-1.4,W06-1704,0,0.251605,"al top-level domains where texts in the desired language are believed to be found. Then after the crawl, the language of the pages is verified with various methods. Kornai et al. (2006) applied spell checking to filter out pages that were not in Hungarian. The presence of function words has also been used as a simple form of language identification (Baroni and Kilgariff, 2006; Ferraresi et al., 2008; Baroni et al., 2009), whereas more sophisticated language identifiers were used by Pomikálek et al. (2009) and Schäfer and Bildhauer (2012). As the .es national domain was very small at the time, Boleda et al. (2006) additionally crawled pages from other domains which were located in Spain in order to build a corpus of Catalan texts. The language of the pages was then identified using a Naive Bayes classifier. named Nutch12 and identified the language of the pages with TextCat. Mon and Mikami (2011) built their own focused crawler with n-gram based language identification. The links to the subdomain of a page were only added to the outlink queue if the page itself was relevant. Suchomel and Pomikálek (2012) built SpiderLing, a web crawler with inbuilt language models. SpiderLing calculates a yield rate fo"
2020.wac-1.4,L16-1146,0,0.044385,"Missing"
2020.wac-1.4,W16-4820,1,0.833286,"Missing"
2020.wac-1.4,W17-0221,1,0.917787,"Missing"
2020.wac-1.4,W18-3929,1,0.926092,"e texts it finds for free download. Smith et al. (2013) downloaded document pairs from the Common Crawl corpus for parallel text corpora of several languages and determined the language of a document using language codes present in the URL. Kanerva et al. (2014) used the morphological analyser OMorFi4 to find Finnish sentences in the Common Crawl corpus. Using the Common Crawl corpus, Schäfer (2016) built corpora in several languages using the texrex tool5 while Habernal et al. (2016) built corpora in over 50 languages using a java library to determine the language of a text. Panchenko et al. (2018) built a corpus in English using the C4Corpus tool6 to find relevant pages in the Common Crawl corpus. 2.2. Schäfer and Bildhauer (2012) recommend that projects wishing to build large web corpora do not use search engine results except as seed URLs for a crawler. The results of their analysis demonstrate that simply downloading the query results with a tool such as BootCaT is not effective enough and that many sites that can be found while crawling the web intensively cannot be found through search engine queries. In addition to this, Sharoff (2006b) and Barbaresi (2013) raise the question of"
2020.wac-1.4,W18-3907,1,0.78335,"hives and it has been successfully used to collect text corpora by Baroni and Kilgariff (2006), Emerson and O’Neil (2006), Ferraresi et al. (2008), Baroni et al. (2009), Pomikálek et al. (2009), Schäfer and Bildhauer (2012) and Versley and Panchenko (2012). Heritrix obeys the robots.txt exclusion directives and has a system for giving precedence to specific links. Heritrix is open source and extendable, so we were also able to make custom changes to it. Jauhiainen (2010). Our language identifiers have fared very well in several shared tasks dedicated to distinguishing between close languages (Jauhiainen et al., 2018a; Jauhiainen et al., 2018b; Jauhiainen et al., 2019c). For collecting corpora in minority languages, we used an implementation of the HeLI method (Jauhiainen et al., 2016), based on which we created a language identifier service15 that takes in text and responds with a corresponding language code. Currently the language identifier in production can distinguish between c. 400 languages and dialects in out-of-domain contexts (Jauhiainen et al., 2017). At the beginning of the project, we were able to find suitable training material for 34 of the 38 Uralic languages (Jauhiainen et al., 2015a; Jau"
2020.wac-1.4,W19-1419,1,0.812361,"o download pages with a search engine. The toolkit was tested by building corpora for English and Italian. BootCaT was also used by Baroni and Ueyama (2004), Sharoff (2006b), and Lyding et al. (2014). Scannell (2007) built a tool that resembled BootCaT. Depending on the language, the query lists were built with either word lists from a spell checker or word frequency lists. Sometimes language models of trigrams were used to make sure the language was the relevant one. With the tool, Scannell built text corpora for over 400 languages, many of which were under-resourced languages. Arkhangelskiy (2019) used a similar strategy to find texts in seven minority Uralic languages from social media sites. Wagner Filho et al. (2018) also used a toolkit resembling BootCaT called Web as Corpus Toolkit9 for building a web corpus in Brazilian Portuguese. 2.3.1. Using URL to Determine a Language Baykan et al. (2008) wanted to know the language of each page before downloading. They extracted words from URLs and used various machine-learning algorithms to distinguish pages in different languages from each other. Their experiments in various languages showed, however, that English words are prominently pre"
2020.wac-1.4,W06-1701,0,0.0831693,"ey and Panchenko (2012) checked the language of each page by inspecting the character encoding and then by using a character trigram-based filter and function words. Emerson and O’Neil (2006) restricted the crawler to accept only pages with metadata language codes indicating the Chinese language. After the crawl, they used the Rosette Language Identifier11 to detect the language of each page. Many researchers prefer to crawl national top-level domains where texts in the desired language are believed to be found. Then after the crawl, the language of the pages is verified with various methods. Kornai et al. (2006) applied spell checking to filter out pages that were not in Hungarian. The presence of function words has also been used as a simple form of language identification (Baroni and Kilgariff, 2006; Ferraresi et al., 2008; Baroni et al., 2009), whereas more sophisticated language identifiers were used by Pomikálek et al. (2009) and Schäfer and Bildhauer (2012). As the .es national domain was very small at the time, Boleda et al. (2006) additionally crawled pages from other domains which were located in Spain in order to build a corpus of Catalan texts. The language of the pages was then identified"
2020.wac-1.4,1999.mtsummit-1.46,0,0.335045,"the language could also be done to a whole website at once. Originally we had published almost half a million links in Wanca. Since 2015, many automatically identified languages have been verified and, more importantly, almost 200,000 links that turned out not to be relevant have been discarded by us or the other users of the Wanca platform. By the time of the writing, Wanca contains 288,799 links that are considered to have been written in a Uralic minority language. 3.3.1. The Method Even though multilingual language identification for corpora creation purposes had been studied previously (Ludovik and Zacharski, 1999), there was no suitable off-theshelf multilingual language identifier for us to use. For our project, we developed a new language set identification method (Jauhiainen et al., 2015b) which we named MultiLI.17 The method uses a fixed size character window and, as the window slides stepwise along a text, the text of each window is identified with a language identifier. The language of the first window is stored in a variable called ""current language"" and when the language of subsequent windows has been different from the ""current language"" variable more times than a threshold, the language of th"
2020.wac-1.4,Q14-1003,0,0.0163073,"f the page was sent to be identified. If the text of the entire page was still identified as one of the small Uralic languages, the text of the page was archived. The links found on such pages were given precedence over links from other pages in the frontier queue of the crawler (Jauhiainen et al., 2015a; Jauhiainen et al., 2019a). 3.3. The texts of web pages are often multilingual (Kilgarriff and Grefenstette, 2003), especially those including minority languages (Boleda et al., 2006). Most language identification methods are, however, built for identifying the language of a monolingual text (Lui et al., 2014; Jauhiainen et al., 2015b). When a monolingual language identifier is used to identify the language of a text written in multiple languages, it might, depending on the algorithm, produce an answer unrelated to the actual languages within the text (Prager, 1999). In the Suki project, we encountered this problem in practice when we were manually verifying the languages of the web pages automatically identified to be relevant. With language set identification, we refer to the Automatic Language Identification 3.2.1. Improving Language Identification Part of the Suki project was dedicated to impr"
2020.wac-1.4,W14-0406,0,0.106966,"Missing"
2020.wac-1.4,medelyan-etal-2006-language,0,0.0719203,"tegies for doing this. They proposed prioritising links found on pages that had HTML metadata indicating the wanted language and using a threshold for how many irrelevant pages the crawler is allowed to proceed from a relevant one. Schäfer et al. (2014) recommend using the detection of frequent short words and boilerplate to optimise focused web crawling. In order to prioritise links from a page in a specific language, one needs to check the language while crawling. Many scholars have built web corpora using some kind of focused crawling technique with various language identification methods. Medelyan et al. (2006) used a web crawler 3.1.1. Choosing a Crawler Some scholars using web crawlers for collecting pages in specific languages or topics have been concerned that they download too many pages that do not contain what they are looking for (Somboonviwat et al., 2005; Suchomel and Pomikálek, 2012; Schäfer et al., 2014). Schäfer et al. (2014) tried to overcome the problem by collecting seed URLs that were as good quality as possible. Their experiments show that having good-quality seeds is not sufficient when searching for texts in a specific language in national domains containing multiple languages. S"
2020.wac-1.4,J02-3002,0,0.358871,"Missing"
2020.wac-1.4,W11-2603,0,0.0176147,"n in English, one probably ends up having many texts very quickly. With only a moderate amount of post-processing with existing tools, one can have a corpus in English (Tamura et al., 2007). Finding pages in less dominant languages is more difficult as one has to decide how to effectively find the texts in the desired languages. Building web corpora in minority languages forms a special case within the corpus creation challenge (Barbaresi, 2015, 127–129). When talking about minority languages in this article, we refer to languages that do not have their own national top-level domain (see e.g. Murphy and Stemle (2011), Schulz et al. (2013)). Searching for texts in national top-level domains is a common way of building corpora in specific languages. However, websites containing minority languages are within the same national domain as those in a majority language, hence some kind of language identification is needed. Pages in minority languages often contain links to pages written in the majority language of the country (Arkhangelskiy, 2019). So, even if one seeds a web crawler with links to pages in the desired language, one quickly ends up with many texts in a majority language. In this paper, we propose"
2020.wac-1.4,L18-1286,0,0.0133565,"net and offers the texts it finds for free download. Smith et al. (2013) downloaded document pairs from the Common Crawl corpus for parallel text corpora of several languages and determined the language of a document using language codes present in the URL. Kanerva et al. (2014) used the morphological analyser OMorFi4 to find Finnish sentences in the Common Crawl corpus. Using the Common Crawl corpus, Schäfer (2016) built corpora in several languages using the texrex tool5 while Habernal et al. (2016) built corpora in over 50 languages using a java library to determine the language of a text. Panchenko et al. (2018) built a corpus in English using the C4Corpus tool6 to find relevant pages in the Common Crawl corpus. 2.2. Schäfer and Bildhauer (2012) recommend that projects wishing to build large web corpora do not use search engine results except as seed URLs for a crawler. The results of their analysis demonstrate that simply downloading the query results with a tool such as BootCaT is not effective enough and that many sites that can be found while crawling the web intensively cannot be found through search engine queries. In addition to this, Sharoff (2006b) and Barbaresi (2013) raise the question of"
2020.wac-1.4,pomikalek-etal-2012-building,0,0.0724584,"Missing"
2020.wac-1.4,schafer-bildhauer-2012-building,0,0.440652,"parallel text corpora of several languages and determined the language of a document using language codes present in the URL. Kanerva et al. (2014) used the morphological analyser OMorFi4 to find Finnish sentences in the Common Crawl corpus. Using the Common Crawl corpus, Schäfer (2016) built corpora in several languages using the texrex tool5 while Habernal et al. (2016) built corpora in over 50 languages using a java library to determine the language of a text. Panchenko et al. (2018) built a corpus in English using the C4Corpus tool6 to find relevant pages in the Common Crawl corpus. 2.2. Schäfer and Bildhauer (2012) recommend that projects wishing to build large web corpora do not use search engine results except as seed URLs for a crawler. The results of their analysis demonstrate that simply downloading the query results with a tool such as BootCaT is not effective enough and that many sites that can be found while crawling the web intensively cannot be found through search engine queries. In addition to this, Sharoff (2006b) and Barbaresi (2013) raise the question of search engines ordering the results according to their ""relevance"" and the bias this might cause. 2.3. Crawling to Gather Texts Web craw"
2020.wac-1.4,W14-0402,0,0.0375136,"rawler assigns a score to the links harvested from a page and the links are handled according to the score they have been assigned thereafter. The idea is that pages on the Internet tend to link to other pages on the same topic (Aggarwal et al., 2001). Somboonviwat et al. (2005) suggested using focused crawling to find pages in specific languages and tested two strategies for doing this. They proposed prioritising links found on pages that had HTML metadata indicating the wanted language and using a threshold for how many irrelevant pages the crawler is allowed to proceed from a relevant one. Schäfer et al. (2014) recommend using the detection of frequent short words and boilerplate to optimise focused web crawling. In order to prioritise links from a page in a specific language, one needs to check the language while crawling. Many scholars have built web corpora using some kind of focused crawling technique with various language identification methods. Medelyan et al. (2006) used a web crawler 3.1.1. Choosing a Crawler Some scholars using web crawlers for collecting pages in specific languages or topics have been concerned that they download too many pages that do not contain what they are looking for"
2020.wac-1.4,L16-1712,0,0.0163407,"emur project’s2 ClueWeb09 corpus and then used automatic language identification to make sure the texts used were, in fact, written in English. Common Crawl Foundation3 regularly crawls the Internet and offers the texts it finds for free download. Smith et al. (2013) downloaded document pairs from the Common Crawl corpus for parallel text corpora of several languages and determined the language of a document using language codes present in the URL. Kanerva et al. (2014) used the morphological analyser OMorFi4 to find Finnish sentences in the Common Crawl corpus. Using the Common Crawl corpus, Schäfer (2016) built corpora in several languages using the texrex tool5 while Habernal et al. (2016) built corpora in over 50 languages using a java library to determine the language of a text. Panchenko et al. (2018) built a corpus in English using the C4Corpus tool6 to find relevant pages in the Common Crawl corpus. 2.2. Schäfer and Bildhauer (2012) recommend that projects wishing to build large web corpora do not use search engine results except as seed URLs for a crawler. The results of their analysis demonstrate that simply downloading the query results with a tool such as BootCaT is not effective eno"
2020.wac-1.4,P13-1135,0,0.0338137,"concentrate on how the web corpora in specific languages have been obtained. 2.1. Pre-Downloaded Web Collections Instead of collecting the texts from the Internet directly, it is possible to use pre-downloaded collections. Pomikálek et al. (2012) extracted all pages tagged as English from the 1 http://suki.ling.helsinki.fi/eng/ project.html 23 the Lemur project’s2 ClueWeb09 corpus and then used automatic language identification to make sure the texts used were, in fact, written in English. Common Crawl Foundation3 regularly crawls the Internet and offers the texts it finds for free download. Smith et al. (2013) downloaded document pairs from the Common Crawl corpus for parallel text corpora of several languages and determined the language of a document using language codes present in the URL. Kanerva et al. (2014) used the morphological analyser OMorFi4 to find Finnish sentences in the Common Crawl corpus. Using the Common Crawl corpus, Schäfer (2016) built corpora in several languages using the texrex tool5 while Habernal et al. (2016) built corpora in over 50 languages using a java library to determine the language of a text. Panchenko et al. (2018) built a corpus in English using the C4Corpus too"
2020.wac-1.4,spoustova-spousta-2012-high,0,0.0189535,"eclaration as metadata for the page itself, they are often not used, or used incorrectly (Reh˚u˘rek and Kolkus, 2009). 2 http://www.lemurproject.org/components. php 3 https://commoncrawl.org 4 http://flammie.github.io/omorfi/ 5 https://github.com/rsling/texrex 6 https://dkpro.github.io/dkpro-c4corpus/ 7 http://www.cs.cmu.edu/~TextLearning/ corpusbuilder/ 8 https://bootcat.dipintra.it 9 http://wac-tk.drni.de 10 24 https://www.mediawiki.org/wiki/TextCat 2.3.3. Language checking after Crawling Some scholars have preferred to use some kind of language checking after crawling the web for a corpus. Spoustová and Spousta (2012) and Versley and Panchenko (2012) crawled only some specific, well-chosen sites. Spoustová and Spousta (2012) then used various tools to filter out unwanted texts, whereas Versley and Panchenko (2012) checked the language of each page by inspecting the character encoding and then by using a character trigram-based filter and function words. Emerson and O’Neil (2006) restricted the crawler to accept only pages with metadata language codes indicating the Chinese language. After the crawl, they used the Rosette Language Identifier11 to detect the language of each page. Many researchers prefer to"
2020.wac-1.4,L18-1686,0,0.0169153,"aT was also used by Baroni and Ueyama (2004), Sharoff (2006b), and Lyding et al. (2014). Scannell (2007) built a tool that resembled BootCaT. Depending on the language, the query lists were built with either word lists from a spell checker or word frequency lists. Sometimes language models of trigrams were used to make sure the language was the relevant one. With the tool, Scannell built text corpora for over 400 languages, many of which were under-resourced languages. Arkhangelskiy (2019) used a similar strategy to find texts in seven minority Uralic languages from social media sites. Wagner Filho et al. (2018) also used a toolkit resembling BootCaT called Web as Corpus Toolkit9 for building a web corpus in Brazilian Portuguese. 2.3.1. Using URL to Determine a Language Baykan et al. (2008) wanted to know the language of each page before downloading. They extracted words from URLs and used various machine-learning algorithms to distinguish pages in different languages from each other. Their experiments in various languages showed, however, that English words are prominently present in the URLs of pages in many languages. According to Barbaresi (2013), in case of ""lesser-known"" languages, language ide"
2021.vardial-1.1,2020.vardial-1.26,0,0.0398438,"Missing"
2021.vardial-1.1,W19-1402,0,0.103765,"Missing"
2021.vardial-1.1,2021.vardial-1.15,0,0.0589664,"Missing"
2021.vardial-1.1,P19-1068,1,0.833848,"ntification (RDI): The 2021 Romanian Dialect Identification shared task is at the third iteration, following the 2019 Moldavian vs. Romanian Cross-Dialect Topic identification (MRC) (Zampieri et al., 2019) and the 2020 Romanian Dialect Identification (RDI) (G˘aman et al., 2020) shared tasks. The 2021 RDI shared task is formulated as a cross-domain binary classification by dialect problem, in which a classification model is required to discriminate between the Moldavian (MD) and the Romanian (RO) subdialects. This year, we provided participants with an augmented version of the MOROCO data set (Butnaru and Ionescu, 2019) for training, which contains Moldavian and Romanian samples of text collected from the news domain. Last year’s test set of tweets (G˘aman and Ionescu, 2020b) is used for validation. A new set of tweets has been collected for the 2021 shared task. The task has two formats, open and closed. In the closed format, participants are not allowed to use external data to train their models. In the open format, participants are allowed to use external resources such as unlabeled corpora, lexicons and pre-trained embeddings (e.g. BERT), but the use of additional labeled data is still not allowed. Urali"
2021.vardial-1.1,2021.vardial-1.12,0,0.478027,"nnada) grammar with English lexicon or English grammar with south Dravidian lexicons (Jose et al., 2020; Priyadharshini et al., 2020). The comments were written in the Latin Script with different types of code-mixing. The language tag of the comment were given. The challenge of the task was to identify the language of the given comment. It was 2 http://urn.fi/urn:nbn:fi: lb-2020102201 2 Team DLI RDI SMG ULI HeLju HWR LAST NAYEL NRC Phlyers SUKI UnibucKernel UPB System Description Papers (Scherrer and Ljubeˇsi´c, 2021) (Jauhiainen et al., 2021b) (Bestgen, 2021) (Bernier-Colborne et al., 2021) (Ceolin, 2021) (Jauhiainen et al., 2021a) (G˘aman et al., 2021) (Zaharia et al., 2021) Table 1: The teams that participated in the VarDial Evaluation Campaign 2021. a challenging task, since Tamil, Malayalam and Kannada are closely related languages, some of the words being common in all these languages. The participants had to train a system to identify the language of each comment. Our dataset size is 16,672 comments for training and 4,588 for testing. There were three language tags such as Tamil, Malayalam and Kannada. A new category Not in intended language was added to include comments written in a lan"
2021.vardial-1.1,2020.vardial-1.25,0,0.247563,"opment data for training and (ii) the idea of adapting the language model to the test set. The team that was ranked in the second place is UPB. Their best submission is an ensemble that comprises several deep models, including a Romanian BERT. Different from their last year’s participation (Zaharia et al., 2020), they carefully split the training set into sentences. This idea was borrowed from top-ranked teams of the 2020 RDI shared task. Phlyers ranked on the third place in the 2021 ranking, without significant differences in terms of performance with respect to their previous participation (Ceolin and Zhang, 2020). Despite having access to significantly more in-domain data compared with the previous RDI shared task, the participants were not able to report significant performance gains. Indeed, the top scoring team (C ¸ o¨ ltekin, 2020) in 2020 reached a macro F1 score of 0.7876, while the top scoring team in 2021 achieved a macro F1 score of 0.7772. Although the test sets are not identical, we 6 Social Media Variety Geolocation (SMG) 6.1 Dataset The SMG task is based on three datasets from two Social Media platforms, Jodel and Twitter. Since its first edition in 2020, the datasets have been expanded."
2021.vardial-1.1,2020.sltu-1.25,1,0.720696,"format and evaluation methodology. 4 3 Participating Teams A total of nine teams submitted runs to one or more shared tasks in this year’s VarDial evaluation campaign. In Table 1, we list the teams that participated in the shared tasks, including references to the 8 system description papers which will be published as parts of the VarDial workshop proceedings. Detailed information about the submissions in each respective task is included in the following sections of this report. 4.1 Dravidian Language Identification (DLI) Dataset The DLI task is based on three datasets from YouTube comments (Chakravarthi et al., 2020b,a; Hande et al., 2020). In the 2021 (DLI) shared task, participants have to train a model on comments written in Roman script. Our corpora contains all the three types of code-mixed sentences: InterSentential switch, Intra-Sentential switch and Tag switching. All comments were written in Roman script (Non-native script) with either one of the south Dravidian (Tamil, Malayalam, and Kannada) grammar with English lexicon or English grammar with south Dravidian lexicons (Jose et al., 2020; Priyadharshini et al., 2020). The comments were written in the Latin Script with different types of code-mi"
2021.vardial-1.1,2020.sltu-1.28,1,0.713401,"format and evaluation methodology. 4 3 Participating Teams A total of nine teams submitted runs to one or more shared tasks in this year’s VarDial evaluation campaign. In Table 1, we list the teams that participated in the shared tasks, including references to the 8 system description papers which will be published as parts of the VarDial workshop proceedings. Detailed information about the submissions in each respective task is included in the following sections of this report. 4.1 Dravidian Language Identification (DLI) Dataset The DLI task is based on three datasets from YouTube comments (Chakravarthi et al., 2020b,a; Hande et al., 2020). In the 2021 (DLI) shared task, participants have to train a model on comments written in Roman script. Our corpora contains all the three types of code-mixed sentences: InterSentential switch, Intra-Sentential switch and Tag switching. All comments were written in Roman script (Non-native script) with either one of the south Dravidian (Tamil, Malayalam, and Kannada) grammar with English lexicon or English grammar with south Dravidian lexicons (Jose et al., 2020; Priyadharshini et al., 2020). The comments were written in the Latin Script with different types of code-mi"
2021.vardial-1.1,W19-1409,1,0.900062,"Missing"
2021.vardial-1.1,W18-3929,1,0.901892,"Missing"
2021.vardial-1.1,W14-5316,0,0.049676,"Missing"
2021.vardial-1.1,2021.vardial-1.10,1,0.840728,"Missing"
2021.vardial-1.1,2020.vardial-1.21,1,0.873523,"Missing"
2021.vardial-1.1,2020.vardial-1.1,1,0.844419,"Missing"
2021.vardial-1.1,2021.vardial-1.9,1,0.849095,"Missing"
2021.vardial-1.1,2020.vardial-1.23,1,0.84553,"Missing"
2021.vardial-1.1,W17-0221,1,0.89467,"Missing"
2021.vardial-1.1,2020.peoples-1.6,1,0.765867,"logy. 4 3 Participating Teams A total of nine teams submitted runs to one or more shared tasks in this year’s VarDial evaluation campaign. In Table 1, we list the teams that participated in the shared tasks, including references to the 8 system description papers which will be published as parts of the VarDial workshop proceedings. Detailed information about the submissions in each respective task is included in the following sections of this report. 4.1 Dravidian Language Identification (DLI) Dataset The DLI task is based on three datasets from YouTube comments (Chakravarthi et al., 2020b,a; Hande et al., 2020). In the 2021 (DLI) shared task, participants have to train a model on comments written in Roman script. Our corpora contains all the three types of code-mixed sentences: InterSentential switch, Intra-Sentential switch and Tag switching. All comments were written in Roman script (Non-native script) with either one of the south Dravidian (Tamil, Malayalam, and Kannada) grammar with English lexicon or English grammar with south Dravidian lexicons (Jose et al., 2020; Priyadharshini et al., 2020). The comments were written in the Latin Script with different types of code-mixing. The language tag o"
2021.vardial-1.1,W19-1419,1,0.865245,"Missing"
2021.vardial-1.1,2021.vardial-1.14,1,0.79889,"poro movie la Enna irukunu baki ellam. 4.2 Results 4 Participants and Approaches Due to the short time between the announcement of the shared task and the submission deadline, the participation was lower than we expected. Four teams submitted results to the shared task. Bestgen (2021) proposed a logistic regression model based on n-grams of characters with maximum length as features to classify the comments. The authors achieved a high score with simple techniques. The authors also analyzed the results in detail. For more information, the reader should look at the working notes of the author. Jauhiainen et al. (2021b) submitted results using two models, a Na¨ıve Bayes (NB) classifier with adaptive language models, which was shown to obtain competitive performance in many language and dialect identification tasks, and a transformerbased model, which is widely regarded as the stateof-the-art in a number of NLP tasks. Their first Table 2: The results of all entries by the four team participating in the DLI shared task in terms of Macro-F1. Given the difficulty of the DLI 2021 task, the level of performance achieved by the systems is appreciable. Identifying the Other-language category was particularly diffi"
2021.vardial-1.1,2021.vardial-1.13,0,0.185158,"h Dravidian lexicons (Jose et al., 2020; Priyadharshini et al., 2020). The comments were written in the Latin Script with different types of code-mixing. The language tag of the comment were given. The challenge of the task was to identify the language of the given comment. It was 2 http://urn.fi/urn:nbn:fi: lb-2020102201 2 Team DLI RDI SMG ULI HeLju HWR LAST NAYEL NRC Phlyers SUKI UnibucKernel UPB System Description Papers (Scherrer and Ljubeˇsi´c, 2021) (Jauhiainen et al., 2021b) (Bestgen, 2021) (Bernier-Colborne et al., 2021) (Ceolin, 2021) (Jauhiainen et al., 2021a) (G˘aman et al., 2021) (Zaharia et al., 2021) Table 1: The teams that participated in the VarDial Evaluation Campaign 2021. a challenging task, since Tamil, Malayalam and Kannada are closely related languages, some of the words being common in all these languages. The participants had to train a system to identify the language of each comment. Our dataset size is 16,672 comments for training and 4,588 for testing. There were three language tags such as Tamil, Malayalam and Kannada. A new category Not in intended language was added to include comments written in a language other than the Dravidian languages. A sample comment from our data"
2021.vardial-1.1,W17-1201,1,0.533591,"Missing"
2021.vardial-1.1,C16-1322,1,0.889269,"Missing"
2021.vardial-1.1,W18-3901,1,0.749269,"Missing"
2021.vardial-1.1,2021.vardial-1.16,1,0.843333,"Missing"
2021.vardial-1.1,W14-5307,1,0.728758,"Missing"
2021.vardial-1.9,W16-4827,0,0.0175016,"de/ron 76 Proceedings of the 8th VarDial Workshop on NLP for Similar Languages, Varieties and Dialects, pages 76–83 April 20, 2021 ©2021 Association for Computational Linguistics 2.1 Romanian Dialect Identification 2.2 Blacklist Classifiers Blacklists are lists of words or any other character sequences which if found, rule out the language. Blacklist classifiers have been previously used in language identification by Ljubeˇsi´c et al. (2007) and Tiedemann and Ljubeˇsi´c (2012). They used a blacklist of words with frequency cut-offs to distinguish between Bosnian, Croatian, and Serbian. Later, Barbaresi (2016) and Kroon et al. (2018) experimented with blacklisting when preparing for shared task submissions, but their experiments did not improve results and were not used in the final systems. RDI 2021 is the third shared task focusing on discriminating between the Moldavian and Romanian dialects of the Romanian language (ron). It appeared for the first time as one of the tracks of the Moldavian vs. Romanian Cross-dialect Topic identification shared task (MRC) in 2019 (Zampieri et al., 2019) and as a separate task in 2020 (Gaman et al., 2020). We participated in the RDI 2020 shared task with a naive"
2021.vardial-1.9,W18-3907,1,0.883549,"Missing"
2021.vardial-1.9,P19-1068,0,0.25312,"red task focusing on discriminating between the Moldavian and Romanian dialects of the Romanian language (ron). It appeared for the first time as one of the tracks of the Moldavian vs. Romanian Cross-dialect Topic identification shared task (MRC) in 2019 (Zampieri et al., 2019) and as a separate task in 2020 (Gaman et al., 2020). We participated in the RDI 2020 shared task with a naive Bayes based dialect identifier. In our system description article for RDI 2020 (Jauhiainen et al., 2020), we provide an extensive listing of previous dialect identification experiments using the MOROCO dataset (Butnaru and Ionescu, 2019), which also functions as the training set for the shared task at hand. The highest F1 score so far presented for the MOROCO dataset, 0.962, was provided by Wu et al. (2019) using a linear SVM classifier with language model adaptation. 2.3 Language Model Adaptation In language model adaptation, the language models are dynamically modified during the identification phase using the information in the mystery text (or collection of texts) itself. Using adaptive models in language identification shared tasks has proved to be important since we introduced the first language model adaptation experim"
2021.vardial-1.9,W19-1419,1,0.769535,"Missing"
2021.vardial-1.9,2020.vardial-1.25,0,0.174373,"Macro F1 score of 0.7876, was based on a linear SVM classifier and used a language model adaptation scheme identical to the one used by Wu et al. (2019) a year earlier. In the winning system, she used only the provided targetdevelopment data for training the SVM. The best submission of the second ranked team, Anumiti (Popa and S, tef˘anescu, 2020), achieved an F1 score of 0.7752. Their best system was an ensemble of five transformer-based classifiers combined using an SVM. The classifiers used in the ensemble were multilingual BERT, XLM, XLM-R, cased Romanian BERT, and uncased Romanian BERT. Ceolin and Zhang (2020) achieved a score of 0.6661 with a multinomial naive Bayes classifier using character n-grams from five to eight. We used a naive Bayes classifier with character n-grams from four to five, obtaining a Macro F1 score of 0.6584 (Jauhiainen et al., 2020). Zaharia et al. (2020) used pre-trained Romanian BERT models and achieved an F1 score of 0.6576. The UAIC team used an ensemble of TFIDF encoders and a convolutional neural network attaining a score of 0.5553 (Rebeja and Cristea, 2020). 3 Shared Task Setup The task of the RDI 2021 was to identify the dialect, either Romanian or Moldavian from a l"
2021.vardial-1.9,2020.vardial-1.21,1,0.817952,"Missing"
2021.vardial-1.9,W16-4820,1,0.945257,"Missing"
2021.vardial-1.9,2020.vardial-1.1,1,0.913931,"Missing"
2021.vardial-1.9,W18-3928,0,0.0122196,"of the 8th VarDial Workshop on NLP for Similar Languages, Varieties and Dialects, pages 76–83 April 20, 2021 ©2021 Association for Computational Linguistics 2.1 Romanian Dialect Identification 2.2 Blacklist Classifiers Blacklists are lists of words or any other character sequences which if found, rule out the language. Blacklist classifiers have been previously used in language identification by Ljubeˇsi´c et al. (2007) and Tiedemann and Ljubeˇsi´c (2012). They used a blacklist of words with frequency cut-offs to distinguish between Bosnian, Croatian, and Serbian. Later, Barbaresi (2016) and Kroon et al. (2018) experimented with blacklisting when preparing for shared task submissions, but their experiments did not improve results and were not used in the final systems. RDI 2021 is the third shared task focusing on discriminating between the Moldavian and Romanian dialects of the Romanian language (ron). It appeared for the first time as one of the tracks of the Moldavian vs. Romanian Cross-dialect Topic identification shared task (MRC) in 2019 (Zampieri et al., 2019) and as a separate task in 2020 (Gaman et al., 2020). We participated in the RDI 2020 shared task with a naive Bayes based dialect iden"
2021.vardial-1.9,W16-4801,0,0.0564282,"Missing"
2021.vardial-1.9,2020.vardial-1.18,0,0.0592621,"Missing"
2021.vardial-1.9,W14-5307,0,0.217865,"Missing"
2021.vardial-1.9,2020.vardial-1.20,0,0.0140132,"assifiers used in the ensemble were multilingual BERT, XLM, XLM-R, cased Romanian BERT, and uncased Romanian BERT. Ceolin and Zhang (2020) achieved a score of 0.6661 with a multinomial naive Bayes classifier using character n-grams from five to eight. We used a naive Bayes classifier with character n-grams from four to five, obtaining a Macro F1 score of 0.6584 (Jauhiainen et al., 2020). Zaharia et al. (2020) used pre-trained Romanian BERT models and achieved an F1 score of 0.6576. The UAIC team used an ensemble of TFIDF encoders and a convolutional neural network attaining a score of 0.5553 (Rebeja and Cristea, 2020). 3 Shared Task Setup The task of the RDI 2021 was to identify the dialect, either Romanian or Moldavian from a line of text. The participants were provided with two sets of data, one for training and one for development. An augmented MOROCO data set (Butnaru and Ionescu, 2019) was used as the training data. The provided train.txt file included a total of 39,487 77 samples of texts from the news domain, which is 5,923 samples more than the MOROCO data set currently available on GitHub.2 The development data provided were tweets which in the RDI 2020 were used as the target development data (21"
2021.vardial-1.9,W15-5401,0,0.0577656,"Missing"
2021.vardial-1.9,C12-1160,0,0.333852,"Missing"
2021.vardial-1.9,2020.vardial-1.22,0,0.0340434,"bmission of the second ranked team, Anumiti (Popa and S, tef˘anescu, 2020), achieved an F1 score of 0.7752. Their best system was an ensemble of five transformer-based classifiers combined using an SVM. The classifiers used in the ensemble were multilingual BERT, XLM, XLM-R, cased Romanian BERT, and uncased Romanian BERT. Ceolin and Zhang (2020) achieved a score of 0.6661 with a multinomial naive Bayes classifier using character n-grams from five to eight. We used a naive Bayes classifier with character n-grams from four to five, obtaining a Macro F1 score of 0.6584 (Jauhiainen et al., 2020). Zaharia et al. (2020) used pre-trained Romanian BERT models and achieved an F1 score of 0.6576. The UAIC team used an ensemble of TFIDF encoders and a convolutional neural network attaining a score of 0.5553 (Rebeja and Cristea, 2020). 3 Shared Task Setup The task of the RDI 2021 was to identify the dialect, either Romanian or Moldavian from a line of text. The participants were provided with two sets of data, one for training and one for development. An augmented MOROCO data set (Butnaru and Ionescu, 2019) was used as the training data. The provided train.txt file included a total of 39,487 77 samples of texts fr"
2021.vardial-1.9,W17-1201,0,0.119346,"Missing"
de-smedt-etal-2014-clara,Y12-1015,0,\N,Missing
de-smedt-etal-2014-clara,W11-2153,0,\N,Missing
de-smedt-etal-2014-clara,W12-3903,0,\N,Missing
de-smedt-etal-2014-clara,W11-2605,0,\N,Missing
de-smedt-etal-2014-clara,W13-1728,0,\N,Missing
de-smedt-etal-2014-clara,R11-1041,1,\N,Missing
de-smedt-etal-2014-clara,W11-4647,0,\N,Missing
de-smedt-etal-2014-clara,W13-2907,1,\N,Missing
de-smedt-etal-2014-clara,W11-4604,1,\N,Missing
de-smedt-etal-2014-clara,P13-1054,1,\N,Missing
de-smedt-etal-2014-clara,Y12-1014,0,\N,Missing
de-smedt-etal-2014-clara,P11-3013,0,\N,Missing
de-smedt-etal-2014-clara,ramasamy-zabokrtsky-2012-prague,0,\N,Missing
de-smedt-etal-2014-clara,W13-2805,0,\N,Missing
de-smedt-etal-2014-clara,larasati-2012-identic,0,\N,Missing
de-smedt-etal-2014-clara,alonso-etal-2012-voting,1,\N,Missing
de-smedt-etal-2014-clara,W12-3410,0,\N,Missing
de-smedt-etal-2014-clara,drobac-etal-2014-heuristic,1,\N,Missing
de-smedt-etal-2014-clara,P13-2127,1,\N,Missing
de-smedt-etal-2014-clara,W11-4406,0,\N,Missing
de-smedt-etal-2014-clara,dione-2014-pruning,0,\N,Missing
de-smedt-etal-2014-clara,R11-2019,0,\N,Missing
de-smedt-etal-2014-clara,W12-6304,0,\N,Missing
de-smedt-etal-2014-clara,W14-1203,1,\N,Missing
de-smedt-etal-2014-clara,W12-5017,0,\N,Missing
de-smedt-etal-2014-clara,lis-2012-polish,0,\N,Missing
de-smedt-etal-2014-clara,W14-0808,0,\N,Missing
de-smedt-etal-2014-clara,schumann-2012-knowledge,0,\N,Missing
de-smedt-etal-2014-clara,C12-1065,1,\N,Missing
de-smedt-etal-2014-clara,dione-2012-morphological,0,\N,Missing
de-smedt-etal-2014-clara,escartin-2012-design,0,\N,Missing
de-smedt-etal-2014-clara,W12-2019,1,\N,Missing
de-smedt-etal-2014-clara,lenkiewicz-etal-2012-avatech,1,\N,Missing
de-smedt-etal-2014-clara,W11-3302,1,\N,Missing
de-smedt-etal-2014-clara,escartin-2014-chasing,0,\N,Missing
de-smedt-etal-2014-clara,W12-0503,0,\N,Missing
de-smedt-etal-2014-clara,W13-5411,1,\N,Missing
de-smedt-etal-2014-clara,gebre-etal-2012-towards,1,\N,Missing
drobac-etal-2014-heuristic,W98-1312,0,\N,Missing
drobac-etal-2014-heuristic,W13-5631,1,\N,Missing
E14-4015,D10-1095,0,0.0216271,"mber of tags in the data set and number of tags in the training set, respectively. POS tagging. Our preliminary experiments using the latest violation updates supported this. Consequently, we employ the early updates. We also provide results using the CRFsuite toolkit (Okazaki, 2007), which implements a 1storder CRF model. To best of our knowledge, CRFsuite is currently the fastest freely available CRF implementation.3 In addition to the averaged perceptron algorithm (Collins, 2002), the toolkit implements several training procedures (Nocedal, 1980; Crammer et al., 2006; Andrew and Gao, 2007; Mejer and Crammer, 2010; Shalev-Shwartz et al., 2011). We run CRFsuite using these algorithms employing their default parameters and the feature extraction scheme and stopping criterion described in Section 3.3. We then report results provided by the most accurate algorithm on each language. Experimental Setup Data For a quick overview of the data sets, see Table 1. Penn Treebank. The first data set we consider is the classic Penn Treebank. The complete treebank is divided into 25 sections of newswire text extracted from the Wall Street Journal. We split the data into training, development, and test sets using the s"
E14-4015,P04-1015,0,0.060625,"ity, firstname.lastname@aalto.fi b Department of Modern Languages, University of Helsinki, firstname.lastname@helsinki.fi Abstract quired by the stochastic gradient descent algorithm employed in ML estimation (Vishwanathan et al., 2006). Additionally, while ML and perceptron training share an identical time complexity, the perceptron is in practice faster due to sparser parameter updates. Despite its simplicity, running the perceptron algorithm can be tedious in case the data contains a large number of labels. Previously, this problem has been addressed using, for example, k-best beam search (Collins and Roark, 2004; Zhang and Clark, 2011; Huang et al., 2012) and parallelization (McDonald et al., 2010). In this work, we explore an alternative strategy, in which we modify the perceptron algorithm in spirit of the classic pseudo-likelihood approximation for ML estimation (Besag, 1975). The resulting novel algorithm has linear complexity w.r.t. the label set size and contains only a single hyper-parameter, namely, the number of passes taken over the training data set. We evaluate the algorithm, referred to as the pseudo-perceptron, empirically in POS tagging on five languages. The results suggest that the a"
E14-4015,W02-1001,0,0.871589,"l sequence labeling tasks in natural language processing, including part-of-speech (POS) tagging. In this work, we discuss accelerating the CRF model estimation in presence of a large number of labels, say, hundreds or thousands. Large label sets occur in POS tagging of morphologically rich languages (Erjavec, 2010; Haverinen et al., 2013). CRF training is most commonly associated with the (conditional) maximum likelihood (ML) criterion employed in the original work of Lafferty et al. (2001). In this work, we focus on an alternative training approach using the averaged perceptron algorithm of Collins (2002). While yielding competitive accuracy (Collins, 2002; Zhang and Clark, 2011), the perceptron algorithm avoids extensive tuning of hyper-parameters and regularization re2 2.1 Methods Pseudo-Perceptron Algorithm The (unnormalized) CRF model for input and output sequences x = (x1 , x2 , . . . , x|x |) and 74 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 74–78, c Gothenburg, Sweden, April 26-30 2014. 2014 Association for Computational Linguistics are decoded in a standard manner using the Viterbi search. The appeal of PP is that"
E14-4015,W96-0213,0,0.394504,"modified using the early update rule (Huang et al., 2012). While Huang et al. (2012) experimented with several violation-fixing methods (early, latest, maximum, hybrid), they appeared to reach termination at the same rate in 3 See benchmark results at http://www.chokkan. org/software/crfsuite/benchmark.html 76 has not increased during last three iterations. After termination, we apply the averaged parameters yielding highest performance on the development set to test instances. Test and development instances are decoded using a combination of Viterbi search and the tag dictionary approach of Ratnaparkhi (1996). In this approach, candidate tags for known word forms are limited to those observed in the training data. Meanwhile, word forms that were unseen during training consider the full label set. 3.4 method English PP PW-PP 1-best beam Pas.-Agg. Romanian PP PW-PP 1-best beam Pas.-Agg. Estonian PP PW-PP 1-best beam Pas.-Agg. Czech PP PW-PP 1-best beam Pegasos Finnish PP PW-PP 1-best beam Pas.-Agg. Software and Hardware The experiments are run on a standard desktop computer. We use our own C++-based implementation of the methods discussed in Section 2. 4 Results The obtained training times and test"
E14-4015,erjavec-2010-multext,0,0.111636,". We present experiments on five languages. Despite its heuristic nature, the algorithm provides surprisingly competetive accuracies and running times against reference methods. 1 Introduction The conditional random field (CRF) model (Lafferty et al., 2001) has been successfully applied to several sequence labeling tasks in natural language processing, including part-of-speech (POS) tagging. In this work, we discuss accelerating the CRF model estimation in presence of a large number of labels, say, hundreds or thousands. Large label sets occur in POS tagging of morphologically rich languages (Erjavec, 2010; Haverinen et al., 2013). CRF training is most commonly associated with the (conditional) maximum likelihood (ML) criterion employed in the original work of Lafferty et al. (2001). In this work, we focus on an alternative training approach using the averaged perceptron algorithm of Collins (2002). While yielding competitive accuracy (Collins, 2002; Zhang and Clark, 2011), the perceptron algorithm avoids extensive tuning of hyper-parameters and regularization re2 2.1 Methods Pseudo-Perceptron Algorithm The (unnormalized) CRF model for input and output sequences x = (x1 , x2 , . . . , x|x |) an"
E14-4015,N12-1015,0,0.0303934,"Missing"
E14-4015,J11-1005,0,0.28515,"alto.fi b Department of Modern Languages, University of Helsinki, firstname.lastname@helsinki.fi Abstract quired by the stochastic gradient descent algorithm employed in ML estimation (Vishwanathan et al., 2006). Additionally, while ML and perceptron training share an identical time complexity, the perceptron is in practice faster due to sparser parameter updates. Despite its simplicity, running the perceptron algorithm can be tedious in case the data contains a large number of labels. Previously, this problem has been addressed using, for example, k-best beam search (Collins and Roark, 2004; Zhang and Clark, 2011; Huang et al., 2012) and parallelization (McDonald et al., 2010). In this work, we explore an alternative strategy, in which we modify the perceptron algorithm in spirit of the classic pseudo-likelihood approximation for ML estimation (Besag, 1975). The resulting novel algorithm has linear complexity w.r.t. the label set size and contains only a single hyper-parameter, namely, the number of passes taken over the training data set. We evaluate the algorithm, referred to as the pseudo-perceptron, empirically in POS tagging on five languages. The results suggest that the approach can yield compe"
E14-4015,N10-1069,0,\N,Missing
kokkinakis-etal-2014-hfst,U07-1010,0,\N,Missing
kokkinakis-etal-2014-hfst,W06-0503,0,\N,Missing
kokkinakis-etal-2014-hfst,E99-1001,0,\N,Missing
kokkinakis-etal-2014-hfst,W09-1119,0,\N,Missing
kokkinakis-etal-2014-hfst,C08-1034,0,\N,Missing
kokkinakis-etal-2014-hfst,P10-1015,0,\N,Missing
kokkinakis-etal-2014-hfst,W03-0419,0,\N,Missing
kokkinakis-etal-2014-hfst,P09-3003,0,\N,Missing
kokkinakis-etal-2014-hfst,C02-1130,0,\N,Missing
kokkinakis-etal-2014-hfst,W12-5701,0,\N,Missing
kokkinakis-etal-2014-hfst,sekine-nobata-2004-definition,0,\N,Missing
kokkinakis-etal-2014-hfst,C96-1079,0,\N,Missing
kokkinakis-etal-2014-hfst,W98-1603,1,\N,Missing
niemi-linden-2012-representing,C10-1052,0,\N,Missing
niemi-linden-2012-representing,W11-4620,1,\N,Missing
P14-2043,H05-1060,0,0.0437204,"considering b = 1, 2, 4, 8, 16, 32, 64, 128 until the model accuracy does not improve by at least 0.01 (absolute). Development and test instances are decoded using Viterbi search in combination with the tag dictionary approach of Ratnaparkhi (1996). In this approach, candidate tags for known word forms are limited to those observed in the training data. Meanwhile, word forms that were unseen during training consider the full label set. 3.4 4 In this section, we compare the approach presented in Section 2 to two prior systems which attempt to utilize sub-label dependencies in a similar manner. Smith et al. (2005) use a CRF-based system for tagging Czech, in which they utilize expanded emission features similar to our (5). However, they do not utilize the full expanded transition features (6). More specifically, instead of utilizing a single chain as in our approach, Smith et al. employ five parallel structured chains. One of the chains models the sequence of word-class labels such as noun and adjective. The other four chains model gender, number, case, and lemma sequences, respectively. Therefore, in contrast to our approach, their system does not capture cross-dependencies between inflectional catego"
P14-2043,A00-1031,0,0.0409617,"uded in the CRF model using a relatively straightforward feature expansion scheme. Experiments on five languages showed that the approach can yield significant improvement in tagging accuracy given sufficiently fine-grained label sets. In future work, we aim to perform a more fine-grained error analysis to gain a better understanding where the improvement in accuracy takes place. One could also attempt to optimize the compound label splits to maximize prediction accuracy instead of applying a priori partitions. Table 2: Results. proved open-source implementation of the wellknown TnT tagger of Brants (2000). The obtained HunPos results are presented in Table 3. HunPos Eng 96.58 Rom 96.96 Est 92.76 Cze 89.57 Conclusions Fin 85.77 Table 3: Results using a generative HMM-based HunPos tagger of Halacsy et al. (2007). Acknowledgements This work was financially supported by Langnet (Finnish doctoral programme in language studies) and the Academy of Finland under the grant no 251170 (Finnish Centre of Excellence Program (2012-2017)). We would like to thank the anonymous reviewers for their useful comments. Ceau¸su (2006) uses a maximum entropy Markov model (MEMM) based system for tagging Romanian which"
P14-2043,W02-1001,0,0.622696,"er, hyphen, dash, or digit. Binary functions have a return value of either zero (inactive) or one (active). Meanwhile, the transition features 0 ) . . . 1(y = y 0 ) | {1(yi−k = yi−k i i 0 , . . . , y 0 ∈ Y , ∀k ∈ 1 . . . n} yi−k i (6) (4) capture dependencies between adjacent labels irrespective of the input x. 1. A standard CRF model incorporating (2) and (4) is denoted as CRF(n,-). 2.2.1 Expanded Feature Set Leveraging Sub-Label Dependencies The baseline feature set described above can yield a high tagging accuracy given a conveniently simple label set, exemplified by the tagging results of Collins (2002) on the Penn Treebank (Marcus et al., 1993). (Note that conditional random fields correspond to discriminatively trained hidden Markov models and Collins (2002) employs the latter terminology.) However, it does to some extent overlook some beneficial dependency information in case the labels have a rich sub-structure. In what follows, we describe expanded feature sets which explicitly model the sub-label dependencies. We begin by defining a function P(yi ) which partitions any label yi into its sub-label components and returns them in an unordered set. For example, we could define P(PRON+1+SG)"
P14-2043,J11-1005,0,0.0130834,"not report results using CRF(2,2) since, based on preliminary experiments, this model overfits on all languages. The CRF model parameters are estimated using the averaged perceptron algorithm (Collins, 2002). The model parameters are initialized with a zero vector. We evaluate the latest averaged parameters on the held-out development set after each pass over the training data and terminate training if no improvement in accuracy is obtained during three last passes. The best-performing parameters are then applied on the test instances. We accelerate the perceptron learning using beam search (Zhang and Clark, 2011). The beam width, b, is optimized separately for each language on the development sets by considering b = 1, 2, 4, 8, 16, 32, 64, 128 until the model accuracy does not improve by at least 0.01 (absolute). Development and test instances are decoded using Viterbi search in combination with the tag dictionary approach of Ratnaparkhi (1996). In this approach, candidate tags for known word forms are limited to those observed in the training data. Meanwhile, word forms that were unseen during training consider the full label set. 3.4 4 In this section, we compare the approach presented in Section 2"
P14-2043,erjavec-2010-multext,0,0.159768,"I Mikko Kurimob Department of Modern Languages, University of Helsinki, firstname.lastname@helsinki.fi Abstract 1 Krister Lindéna V+NON3SG+PRES like 2 2.1 Methods Conditional Random Fields The (unnormalized) CRF model (Lafferty et al., 2001) for a sentence x = (x1 , . . . , x|x |) and a POS sequence y = (y1 , . . . , y|x |) is defined as N+SG , ham where the compound labels PRON+1SG, V+NON3SG+PRES, and N+SG stand for pronoun first person singular, verb non-third singular present tense, and noun singular, respectively. Fine-grained labels occur frequently in morphologically complex languages (Erjavec, 2010; Haverinen et al., 2013). We propose improving tagging accuracy by utilizing dependencies within the sub-labels (PRON, 1SG, V, NON3SG, N, and SG in the above example) of the compound labels. From a technical perspective, we accomplish this by making use of the fundamental ability of the CRFs to incorporate arbitrarily defined feature functions. The newlydefined features are expected to alleviate data sparp (y |x; w) ∝ |x| Y   exp w·φ(yi−n , . . . , yi , x, i) , i=n (1) where n denotes the model order, w the model parameter vector, and φ the feature extraction function. We denote the tag set"
P14-2043,P01-1035,0,0.0792301,"Missing"
P14-2043,P07-2053,0,0.0912677,"et al. employ five parallel structured chains. One of the chains models the sequence of word-class labels such as noun and adjective. The other four chains model gender, number, case, and lemma sequences, respectively. Therefore, in contrast to our approach, their system does not capture cross-dependencies between inflectional categories, such as the dependence between the word-class and case of adjacent words. Unsurprisingly, Smith et al. fail to achieve improvement over a generative HMMbased POS tagger of Hajiˇc (2001). Meanwhile, our system outperforms the generative trigram tagger HunPos (Halácsy et al., 2007) which is an imSoftware and Hardware The experiments are run on a standard desktop computer (Intel Xeon E5450 with 3.00 GHz and 64 GB of memory). The methods discussed in Section 2 are implemented in C++. 3.5 Related Work Results The obtained tagging accuracies and training times are presented in Table 2. The times include running the averaged perceptron algorithm and evaluation of the development sets. The column labeled it. corresponds to the number of passes over the training data made by the perceptron algorithm before termination. We summarize the results as follows. First, compared to st"
P14-2043,J93-2004,0,0.0496644,"nctions have a return value of either zero (inactive) or one (active). Meanwhile, the transition features 0 ) . . . 1(y = y 0 ) | {1(yi−k = yi−k i i 0 , . . . , y 0 ∈ Y , ∀k ∈ 1 . . . n} yi−k i (6) (4) capture dependencies between adjacent labels irrespective of the input x. 1. A standard CRF model incorporating (2) and (4) is denoted as CRF(n,-). 2.2.1 Expanded Feature Set Leveraging Sub-Label Dependencies The baseline feature set described above can yield a high tagging accuracy given a conveniently simple label set, exemplified by the tagging results of Collins (2002) on the Penn Treebank (Marcus et al., 1993). (Note that conditional random fields correspond to discriminatively trained hidden Markov models and Collins (2002) employs the latter terminology.) However, it does to some extent overlook some beneficial dependency information in case the labels have a rich sub-structure. In what follows, we describe expanded feature sets which explicitly model the sub-label dependencies. We begin by defining a function P(yi ) which partitions any label yi into its sub-label components and returns them in an unordered set. For example, we could define P(PRON+1+SG) = 2. A CRF model incorporating (2), (4), a"
P14-2043,W96-0213,0,0.926591,"ure functions X with all sub-labels s ∈ S by defining the corresponding label as {χj (x, i)1(yi = yi0 ) |j ∈ 1 . . . |X |, ∀yi0 ∈ Y} , (2) where the function 1(q) returns one if and only if the proposition q is true and zero otherwise, that is  1 if yi = yi0 0 1(yi = yi ) = , (3) 0 otherwise {χj (x, i)1(s ∈ P(yi )) |∀j ∈ 1 . . . |X |, ∀s ∈ S} , (5) where 1(s ∈ P(yi )) returns one in case s is in P(yi ) and zero otherwise. Second, we exploit sublabel transitions using features |X | and X = {χj (x, i)}j=1 is the set of functions characterizing the word position i. Following the classic work of Ratnaparkhi (1996), our X comprises simple binary functions: {1(si−k ∈ P(yi−k )) . . . 1(si ∈ P(yi )) | ∀si−k , . . . , si ∈ S , ∀k ∈ 1 . . . m} . 1. Bias (always active irrespective of input). Note that we define the sub-label transitions up to order m, 1 ≤ m ≤ n, that is, an nth-order CRF model is not obliged to utilize sub-label transitions all the way up to order n. This is because employing high-order sub-label transitions may potentially cause overfitting to training data due to substantially increased number of features (equivalent to the number of model parameters, |w |= |φ|). For example, in a second-o"
rehm-etal-2014-strategic,P07-2045,0,\N,Missing
rehm-etal-2014-strategic,piperidis-etal-2014-meta,1,\N,Missing
rehm-etal-2014-strategic,piperidis-2012-meta,1,\N,Missing
vasiljevs-etal-2012-creation,steinberger-etal-2006-jrc,0,\N,Missing
vasiljevs-etal-2012-creation,W11-3314,1,\N,Missing
vasiljevs-etal-2012-creation,W11-4643,1,\N,Missing
vasiljevs-etal-2012-creation,borin-etal-2012-open,1,\N,Missing
voutilainen-etal-2012-specifying,C10-1011,0,\N,Missing
voutilainen-etal-2012-specifying,W11-4649,1,\N,Missing
W04-1808,P99-1004,0,0.0159656,"eatures. We define the dissimilarity of two words, p and q, as J(p, q) = (D(pkm) + D(qkm))/2, (1) where D(pkm) = a p(a)(log2 p(a) − log2 m(a)) and m(a) = (p(a) + q(a))/2 for any feature a. This is the symmetrically weighted case of the Jensen–Shannon divergence (Lin, 1991), also known as the information radius or the mean divergence to the mean (Dagan et al., 1999). For complete identity, J(p, p) = 0. For completely disjoint feature sets, J(p, q) = 1. The formula is symmetric but does not satisfy the triangle inequality. For speed the estimate may be calculated from the shared features alone (Lee, 1999). P After calculating all the pairwise estimates, we retained lists of the 100 most similar nouns for each of the nouns in the corpus data. No other data is used in the similarity calculations. 66 CompuTerm 2004 - 3rd International Workshop on Computational Terminology 3.3 Low-dimensional similarity measures Performing all the calculations in highdimensional feature space is time-consuming. Here we introduce a method that can be used as an approximation in low-dimensional feature space based on the initial similarity estimates. Assume that we have lists of the words that are distributionally m"
W04-1808,W03-0601,0,0.0363618,"Missing"
W09-4614,J97-2003,0,0.0922133,"Missing"
W09-4614,sjobergh-kann-2004-finding,0,0.0642318,"Missing"
W09-4615,J97-3003,0,0.0704956,"Missing"
W09-4615,P96-1043,0,0.0642601,"nce. This leads to safely extracting words that already have a number of word forms in the corpus, i.e. mid- or highfrequency words, which for all practical purposes have already been encoded and are readily available in public domain morphological descriptions like the Ispell dictionaries (Kuenning, 2007) or more advanced descriptions like the Finnish dictionary Kotimaisten kielten tutkimuskeskuksen nykysuomen sanalista (2007). It should be noted that Hammarström & al (2006) came to the conclusion that it is recommendable that a linguist writes the extraction rules. The approach suggested by Mikheev (1996, 1997) aims at solving the issue of unknown words in the context of part-of-speech taggers. However, in this context the problem is slightly easier as the guesser only needs to identify a likely part of speech and not the full inflectional paradigm of a word. He suggests an automatic way of extracting prefix and postfix patterns for guessing the part of speech. A related approach aiming at inducing paradigms for words and inflectional morphologies for 30 different languages is suggested by Wicentowski (2002). Since there is a growing body of translated text even for less studied languages, th"
W09-4615,J01-1003,0,0.0867422,"Missing"
W09-4615,N07-1048,0,0.0218906,"Missing"
W09-4615,P00-1027,0,\N,Missing
W09-4625,C94-1066,0,0.822217,"ounterparts. A very significant use is for debugging two-level grammars. Since forms are not filtered out in a conflict situation, the linguist, who is writing the two-level grammar gets a clearer picture of the way the grammar is broken. In section 5 we use a new transducer operation, weighted intersecting composition to combine a two-level lexicon and a two-level grammar. Weighted intersecting composition allows the weights in the rules to be passed to the resulting lexical transducer. The operation has been modelled on unweighted intersecting composition, which was introduced by Karttunen (Karttunen, 1994). We test our method using an example lexicon and grammar in sections 6 and 7. The example concerns gradation of stops in Finnish. The example lexicon was compiled using the open source two-level lexicon compiler HFST-L EX C 1 and the example grammar was compiled using the open source two-level grammar compiler HFSTT WOL C2 . Both compilers belong to the finite-state morphology toolkit HFST Morphology Tools 3 . 2 Rule Conflicts Rule conflicts occur when two-level rules require, that a lexical symbol is realized in two different ways in the same context. Conflict resolution is a process, which"
W11-3314,J99-4008,0,0.0197438,"sed query expansion becomes feasible. Another possible application for these resources is Machine Translation (MT). The hierarchical structure of wordnets ensures that a translation can be found (going up or down in the hierarchy) even if a precise equivalent is not present between the specific languages. During the last decades, wordnets have been developed for several languages in the Nordic and Baltic countries including Finnish, Danish, Estonian, Icelandic and Swedish. Of these wordnets, Estonian WordNet is the oldest one since it was built as part of the EuroWordNet project in the 1990s (Vossen, 1999). In contrast, most of the other wordnets have been recently initiated, e.g. the Danish wordnet has been under development since 2005 (cf. Pedersen et al., 2009). The builders of these wordnets have applied different compilation strategies: where the Danish, Icelandic and Swedish wordnets are being developed via monolingual dictionaries and corpora and subsequently linked to Princeton WordNet, the Finnish wordnet has applied the translation method by translating Princeton WordNet into Finnish for later adjustment. From the above mentioned different time perspectives and compilation, there is a"
W11-3314,varadi-etal-2008-clarin,0,0.0913447,"ted by the METANET4U project, while the METANORD project aims to establish an open linguis1 http://ec.europa.eu/information_society/activities/ict_psp/d ocuments/ict_psp_wp2010_final.pdf 2 http://www.meta-net.eu/ 107 Proceedings of Workshop on Language Resources, Technology and Services in the Sharing Paradigm, pages 107–114, Chiang Mai, Thailand, November 12, 2011. tic infrastructure in the Baltic and Nordic countries. This paper describes the key objectives and activities of the META-NORD project, presents its first results and discusses cooperation with other similar projects, e.g. CLARIN (Váradi et al., 2008). It is an integral part of the META-NET and other related initiatives like CLARIN to create a pan-European open linguistic resource exchange platform. 2 The META-NORD Project The META-NORD project focuses on 8 European languages – Danish, Estonian, Finnish, Icelandic, Latvian, Lithuanian, Norwegian and Swedish, – each with less than 10 million speakers. The project partners are University of Copenhagen, University of Tartu, University of Bergen, University of Helsinki, University of Iceland, Institute of Lithuanian Language, University of Gothenburg, and Tilde (coordinator). META-NORD contrib"
W11-4625,C04-1080,0,0.0545361,"Missing"
W11-4625,A00-1031,0,0.618951,"s t1 ..., tn ranges over all analyses of the sentence. The term p(ti |ti−1 , ti−2 ) is the standard second order HMM approximation for the probability of the tag ti . The term p(wi |ti−1 , ti , ti+1 ) conditions the probability of the word wi on its tag context. Finally the term p(wi |ti ) is the standard HMM lexical probability. In order to get the indices to match in the formula above, three additional symbols are needed, i.e. t−1 , t0 and tn+1 denote sentence boundary symbols, which are added during training and tagging for improved accuracy. Using sentence boundary symbols is adopted from Brants (2000). In order to get some estimates for the probability of tag trigrams, which did not occur in the training data, we use tag bigram p(ti |ti−1 ) and tag unigram p(ti ) models in parallel to the trigram model. Similarly we use models which assign probability p(wi |ti−1 , ti ) and p(wi |ti , ti+1 ) in order to deal with previous unseen tag trigrams and wordforms. Of course the lexical model also weights analyses of words, serving as a backup model even in the case where the tag bigrams with the wordform were previously unseen. 185 ´ Miikka Silfverberg and Krister Linden 5.1 Lexical Models For each"
W11-4625,J75-4040,0,0.815948,"Missing"
W11-4625,A88-1019,0,0.165442,"Missing"
W11-4625,W02-1001,0,0.135468,"Missing"
W11-4625,W04-1903,0,0.0375253,"Missing"
W11-4625,P08-2009,0,0.0702412,"Missing"
W11-4625,W09-4625,1,0.890444,"Missing"
W11-4625,N03-1033,0,0.200074,"Missing"
W11-4625,E95-1022,0,0.118662,"Missing"
W11-4625,2005.mtsummit-papers.11,0,0.0184772,"Missing"
W11-4625,H94-1020,0,0.355062,"Missing"
W13-5616,bhattacharyya-2010-indowordnet,0,0.0392967,"omplete or missing synsets in one or another of the wordnets (Tufis, Ion & Ide 2004). Other works included mapping algorithms for aligning, tuning and validating wordnets as presented in Daudé, Padró & Rigau 1999, & Daudé, Padró & Rigau 2003 and several others. More recent collaborative wordnet projects include MultiWordNet (http://multiwordnet.itc.it) which relates Italian and Princeton wordnets, Asian WordNet which also applies the expand method for several Asian languages through a common management interface (Robkop et al. 2010), and IndoWordNet which include a series of Indian languages (Bhattacharyya 2010). Last but not least should be mentioned a recent initiative, Open Multilingual WordNet http://casta-net.jp/~kuribayashi/multi/ which aligns wordnets available through the Global WordNet Association’s WordNet Grid (http://www.globalwordnet.org/gwa/gwa_grid.html). In contrast, several recent European wordnets that have typically been compiled on a more local basis apply the merge technique (cf. Derwojedowa 2008, Borin & Forsberg 2010, Pedersen et al. 2009) applying monolingual language resources such as existing dictionaries and corpora as the initial source. There are obvious risks related to"
W13-5616,W99-0603,0,0.160623,"Missing"
W13-5616,W11-4643,1,0.771943,"Ties (wordties.cst.dk) is a web interface developed to visualize monolingual wordnets as well as their alignments with the other wordnets, cf. Figure 1. In this browser the user can chose either of the (currently four) relevant wordnets as a source language and see how a concept is linked to its sister wordnets. Proceedings of the 19th Nordic Conference of Computational Linguistics (NODALIDA 2013); Linköping Electronic Conference Proceedings #85 [page 152 of 474] Figure 1: Introductory screen of WordTies WordTies builds on a monolingual browser, AndreOrd, which was built to browse DanNet, cf. Johannsen & Pedersen (2011). In this browser, the semantic relations are made available in a more graphical fashion compared to what is found in most other wordnet browsers which tend to focus primarily on visualizing the hyponymy structure of the wordnet. The particular choice of graph very compactly encodes large numbers of relations – each represented by its own colour – and thus gives a good overview of the general structure of the wordnet. In order to make room for all relations in the graph – also the inherited ones –, only one representative sense is visualized per synset. However, all senses are presented below"
W13-5616,W05-1715,0,0.035094,"nd the agentive role (purpose and origin). Qualia roles are encoded in DanNet in terms of relations such as used_for and made_by as well as by means of features such as SEX and CONNOTATION. DanNet is licensed under the Princeton WordNet licence. 3.5 Swedish wordnet (Swesaurus) Swesaurus (Borin & Forsberg 2010, Borin & Forsberg 2011) is a Swedish wordnet developed at Språkbanken, University of Gothenburg. It is being built by reusing lexical-semantic relations collected from a number of pre-existing, freely available lexical resources: SALDO (Borin & Forsberg 2009), SDB (Järborg 2001), Synlex (Kann & Rosell 2006), and Swedish Wiktionary. A novel feature of Swesaurus is its fuzzy synsets derived from the graded synonymy relations of Synlex. Swesaurus and several other lexical resources are available for download and inspection at http://spraakbanken.gu.se/karp. Swesaurus is an integral part of a large and diverse lexical macroresource compiled in the Swedish FrameNet++ project (Borin et al. 2010). It includes 13,724 senses and is licensed under a CC-BY license. Due to its slightly different structure, Swesaurus is currently only partly visible through WordTies. 3.6 Norwegian Wordnet A Norwegian Wordnet"
W13-5616,pedersen-etal-2010-merging,1,0.766177,"linguistic grounds (corpora and existing lexica) for that particular language. On the other hand, such wordnets typically differ so much from Princeton WordNet in structure that a merge becomes indeed very hard and extremely complex. These differences originate partly from different language cultures, partly from different levels of specialization depending on the source material used. For instance, a typical feature of wordnets based on monolingual lexica is that they adopt a perspective which is more geared towards the layman and therefore typically not so deep in taxonomical structure (cf. Pedersen et al. 2010). Proceedings of the 19th Nordic Conference of Computational Linguistics (NODALIDA 2013); Linköping Electronic Conference Proceedings #85 [page 149 of 474] 3 Status of wordnets in the Nordic and Baltic countries 3.1 About META-NORD During the last decade, linguistic resources have grown rapidly for all EU languages, including lesser-resourced languages such as the Nordic and Baltic ones. However they have typically been located in different places, have developed in different standards and in many cases were not well documented. The META-NORD project has aimed to establish an open linguistic i"
W13-5616,tufis-etal-2004-word,0,0.0851173,"Missing"
W13-5616,bel-etal-2000-simple,0,\N,Missing
W13-5619,borin-etal-2012-korp,1,0.920055,"SCARRIE lexicon, and the Lithuanian Standard language lexical database. Terminology resources, such as the Icelandic Term Bank and UHR’s Termbase for Norwegian higher education institutions, have been converted into TBX 16 format (Term Base eXchange; ISO 30042:2008; Melby 2012). Most of the corpus resources uploaded are now available in TEI-compatible formats. A specific example of how this format harmonisation has enhanced interoperability is the relative ease 17 with which the open-source Korp corpus processing and presentation platform, developed in Sweden at the University of Gothenburg (Borin et al. 2012)18, has been deployed in Finland by the University of Helsinki for their Finnish corpora 19. Content model conversion/mapping/linking, e.g., harmonising POS tagsets among corpora, or linking word senses among lexical resources with different sense granularities. The Danish STO lexicon, the Swedish lexicons developed at Språkbanken, University of Gothenburg, and Swedish corpus annotations have been partly linked to the ISOCAT DCR (Data Category Registry; ISO 12620:2009; Windhouwer and Wright 2012), although no explicit attempt has been made to use the same categories across the languages, excep"
W13-5619,borin-etal-2012-open,1,0.870902,"Missing"
W13-5619,braasch-olsen-2004-sto,1,0.846342,"Missing"
W13-5619,broeder-etal-2010-data,0,0.0283968,"Missing"
W13-5619,francopoulo-etal-2006-lexical,0,0.0900195,"Missing"
W13-5619,gavrilidou-etal-2012-meta,0,0.0140866,"talogue of the pan-European infrastructure12. Besides META-SHARE repositories, we have a natural interest to integrate into our infrastructure several existing collections and databases of specific linguistic resources, such as term banks and treebanks. These repositories are collections of language resources, where each individual resource is a candidate to be listed in the META-SHARE catalogue. This could be done manually by entering all resource descriptions in the META-SHARE editor or by exporting the metadata from the respective repository, converting it into META-SHARE compliant schema (Gavrilidou et al., 2012), and importing into META-SHARE node. However, such approaches are time-consuming and need regular manual updates. Our proposed and implemented solution for this infrastructure is to integrate complex linguistic resources or repositories of resources by adapting them to relevant data access and sharing specifications and interlinking them with META-SHARE. This means that a language resourcespecific repository could seamlessly become a part of the META-SHARE network by enabling the harvesting of metadata through the META-SHARE communication protocol and ensuring the mapping of the respective da"
W13-5619,W13-5616,1,0.879624,"Missing"
W13-5619,piperidis-2012-meta,0,0.0205972,"chnology systems make it vital to develop both an open infrastructure and a more coherent research cooperation in order to spur greater sharing and reuse of language resources. 4 The table is also available at http://www.meta-net.eu/whitepapers/key-results-and-cross-language-comparison Proceedings of the 19th Nordic Conference of Computational Linguistics (NODALIDA 2013); Linköping Electronic Conference Proceedings #85 [page 198 of 474] 3 META-SHARE infrastructure in the Baltic and Nordic countries For distribution and sharing of language resources, the distributed online platform META-SHARE (Piperidis, 2012) is used. It consists of independent META-SHARE nodes set up in different countries and interlinked into a federated repository. This freely accessible distributed online infrastructure provides facilities for describing, storing, preserving of language resources, and making them publicly available. Among various language data that can be considered useful for different purposes, META-SHARE places a strong focus on language data that are important in language technology development for building applications that are useful to EU citizens, primarily in their everyday communication and informati"
W13-5619,W11-3314,1,0.83743,"Missing"
W13-5619,varadi-etal-2008-clarin,0,0.0150457,"e often hard to find and difficult to use. Resources are dispersed among different institutions and local repositories, and they are often coded in proprietary formats lacking interoperability and uniformity. There are also restricted or unclear intellectual property rights. These factors are major stumbling blocks for the development and research of language technology. To overcome these difficulties, the Nordic and Baltic countries play a leading role in pan-European activities regarding the creation of the European open linguistic infrastructure. Major progress is achieved by the CLARIN 1 (Váradi et al., 2008) initiative creating a language resource infrastructure for research in humanities. Another complementary infrastructure is under development by the META-NET network2 focusing on the practical needs of developers, users, and researchers of multilingual resources. The Baltic and Nordic countries are active participants in both — CLARIN and META-NET — networks. Official languages of these countries (Danish, Estonian, Finnish, Icelandic, Latvian, Lithuanian, Norwegian, and Swedish), as well as other languages spoken in these countries, are under-resourced in respect to availability of at least so"
W13-5619,W01-1506,0,\N,Missing
W15-1842,P98-1013,0,0.264985,"Missing"
W15-1842,C98-1013,0,\N,Missing
W15-4806,W98-1312,0,0.160798,"me quite large. This can be a problem e.g. when analyzers are used on mobile devices where a moderate memory footprint is required. The usual way to reduce the size of FSMs is to use a minimization algorithm (Hopcroft, 1971). Minimization can have a substantial effect on the size of the FSM but, as it is only able to combine suffix-equivalent states, there may still be residual redundancy in the state space of the machine. Further size reduction can be accomplished by introducing a limited form of context-free structure into the finite-state graph using special symbols called flag diacritics (Beesley, 1998). Using flag diacritics, it is possible to combine sub-graphs which are equivalent, i.e. accept the same strings, but which are not necessarily suffix-equivalent. Flag diacritics are used to couple entrance points of the sub-graphs with appropriate exit points. During lookup, paths whose flag diacritics do not match are filtered out. Thus, the original language of the machine is preserved. Traditionally, the lexicon writer manually inserts flag diacritics into the lexicon of the morphological analyzer. There are two major problems with this approach: (1) In practice, manually inserted flag dia"
W15-4806,drobac-etal-2014-heuristic,1,0.810366,"Missing"
W15-5408,W14-5316,0,0.262853,"Missing"
W15-5408,W14-5307,0,0.233115,"Missing"
W15-5408,W15-5401,0,0.243188,"Missing"
W16-2406,P00-1037,0,0.213666,"normalization processes to the input word to make the relationship between the incorrect form and the correct form more transparent and generate a set of candidates within a certain edit distance. In addition to comparing orthographic forms, they also consider the phonetic realization of the input word and find correction candidates whose pronunciation is within a certain edit distance from the pronunciation of the input word. Related Work Spelling correction is an old NLP task. The earliest approaches used plain edit distance combined with a lexicon. The edit distance approach was refined by Brill and Moore (2000) who added weights for edit operations. These systems ignored the context of the edit operation, which can nevertheless be quite useful. Dreyer et al. (2008) investigate string-to-string translation which is a more general task than spelling correction. In order to incorporate symbol contexts into their models, they formulate stringto-string translation as a sequence labeling task. Their sequence labeling model is discriminative In recent work, Eger et al. (2016) survey four systems for string-to-string translation on spelling correction of Tweets and normalization of historical Latin text. (1"
W16-2406,vor-der-bruck-etal-2014-collex,0,0.0401661,"Missing"
W16-2406,W02-1001,0,0.117579,"d to a unique context. Therefore, the collection of contexts L  xt  R is chosen 53 in such a way that it forms a partition of Σ∗ ΣΣ∗ , where Σ is the set of all input symbols. In Section 4, we give a more detailed explanation of how these contexts are chosen. 3.2 For each context Lxt R, we include a number of back-off contexts. For example, let Σ∗ a  xt  b c Σ∗ be a context, then back-off contexts are the following contexts. Σ∗ a  xt  b Σ∗ Σ∗ a  xt  Σ∗ Σ∗  xt  Σ∗ Peceptron Tagger Our structured spelling correction system is formulated as a traditional averaged perceptron tagger (Collins, 2002) as shown in Equation 1. Given an input sequence x of length T , the model assigns a score s(·) for each output sequence y of length T as determined by the model parameters w and a vector valued feature extraction function φ. The n best normalization candidates given by the system can be extracted by finding the n highest scoring outputs y. s(x, y; w) = T X In order to ensure that no two contexts overlap, we need to modify the contexts slightly: Σ∗ a  xt  b [Σ − c] Σ∗ Σ∗ a  xt  [Σ − b] Σ∗ Σ∗ [Σ − a]  xt  Σ∗ 4.2 The structured correction system extracts unstructured and structured feature"
W16-2406,Q15-1031,0,0.0194461,"ion system, which splits the input string into character sequences, and a discriminative sequence labeling system which translates the character sequences into output symbols. DirecTL+ utilizes joint character n-grams in the discriminative sequence labeling system. (3) The AliSeTra system is based on the work of Eger (2012). Like DirecTL+, it also views string-tostring translation as a pipeline of segmentation and sequence labeling. (4) The final system surveyed by Eger et al. (2016) represents the stringto-string translation task as a series of contextual edit operations on the input string (Cotterell et al., 2015). The operations are compiled into a weighted finite-state machine. The edit operations are weighted using a probabilistic model which resembles the maximum entropy Markov model (MEMM) (McCallum et al., 2000). This system is similar to our structured system but we use a different feature set and estimate weights using the average perceptron algorithm. This avoids the well-known label bias problem (Lafferty et al., 2001) associated with MEMMs. Systems 1, 2 and 3 surveyed by Eger et al. (2016) form an interesting contrast to our systems because we do not use segmentation of the input string. In"
W16-2406,D08-1113,0,0.717392,"social media. When spelling correction is applied as a preprocessing step, performance can be better. Digitization of documents is another domain where spelling correction is useful. Digitization often aims to transform physical documents into digital representations which support free text search. This requires the use of an optical character recog51 Proceedings of the ACL Workshop on Statistical NLP and Weighted Automata, pages 51–59, c Berlin, Germany, August 12, 2016. 2016 Association for Computational Linguistics and the alignment between the input and output string is a latent variable. Dreyer et al. (2008) implement their model as a finite-state machine. This model is similar to ours but we do not treat the alignment between input and output strings as a latent variable. Instead, the training data for our model is aligned in advance. correction candidates from input strings. These substitutions and their contexts are extracted from training data. This approach was first presented by Lind´en (2006) for generating multilingual spelling variants of scientific and medical terms originating from Latin and Greek, but it also suitable for other tasks involving probabilistic string-to-string translatio"
W16-2406,P96-1031,0,0.475889,"he training data. Another parameter is lC which is the length of the maximal right-hand context. We have set the value of lC as 2 based on preliminary experiments. If xt−1 xt xt+1 ...xt+lC occurs at least nT H times in the training data, In addition, we extract the structured features 1. (yt ) 2. (yt−1 , yt ) 3. (yt−2 , yt−1 , yt ) The unstructured features are aimed at capturing the context of edit operations. Meanwhile, the structured features act as a language model. 5 Implementation This section describes the finite-state implementation of our correction systems as weighted replace rules (Mohri and Sproat, 1996). Formally, the systems can be seen as sets of weighted parallel replace rules. As explained below, we however implement them using a cascade of weighted rules for efficiency reasons. This section will also describe the combination of replace rules and lexicon which is used in some of the experiments. Σ∗ xt−1  xt  xt+1 ...xt+lC Σ∗ is chosen as context. If it occurs fewer times, each of the sub-strings xt−1 xt xt+1 ...xt+k , where 0 ≤ k &lt; nC is considered in turn. The longest one that occurs at least nT H times in the training data is used to define a context. If none of them occur more than"
W16-2406,C12-1048,0,0.0132108,"of pairs of input and output strings. In order to accelerate training, we use aligned training data (consisting of symbol pairs) instead of treating the alignment of input and output strings as a latent variable. 2010) represents the translation task as a pipeline of a string segmentation system, which splits the input string into character sequences, and a discriminative sequence labeling system which translates the character sequences into output symbols. DirecTL+ utilizes joint character n-grams in the discriminative sequence labeling system. (3) The AliSeTra system is based on the work of Eger (2012). Like DirecTL+, it also views string-tostring translation as a pipeline of segmentation and sequence labeling. (4) The final system surveyed by Eger et al. (2016) represents the stringto-string translation task as a series of contextual edit operations on the input string (Cotterell et al., 2015). The operations are compiled into a weighted finite-state machine. The edit operations are weighted using a probabilistic model which resembles the maximum entropy Markov model (MEMM) (McCallum et al., 2000). This system is similar to our structured system but we use a different feature set and estim"
W16-2406,N03-1009,0,0.0531166,"as defined by Allauzen et al. (2007). Because we use a series of compositions spanning several thousands of rule transducers for compiling the unstructured and structured feature transducers U and S, efficient determinization and minimization algorithms are crucial. The minimization algorithm presented by Mohri and Sproat (1996) is available through the HFST interface and applicable to transducers with tropical weights where the weights are non-negative. Unfortunately, the structured correction system incorporates both positive and negative weights. One solution to this problem is provided by Eisner (2003) who introduces a more general formulation of transducer minimization which is applicable to transducers with tropical weights in the entire range R ∪ {∞, −∞} and many other weight classes as well. We have, however, resorted to a simpler approach which is applicable in the special case of tropical weights. After epsilon removal and determinization but before minimization, we traverse the transitions and the final state of the transducer M once and find the minimal weight wmin . Subsequently, we increment all transition and final weights in transducer M by |wmin |which results in a transducer M"
W16-2406,P11-1038,0,0.0653367,"Missing"
W16-2406,N10-1103,0,0.0807002,"Missing"
W16-2406,C96-2105,0,0.00981383,"ted accordingly. The sole exception to this are context-free insertions that, unlike other context-free substitutions, are disallowed altoghether. u → ε::0.05 ||u The rule matches in a context where the input contains two consecutive symbols u, deletes the second of them and assigns a penalty weight of 0.05 ≈ − log(0.95). The HFST library (Lind´en et al., 2011) implements these weighted rules. The unstructured system described in Section 3.1 uses a set of mutually exclusive features as explained in Section 4.1. Conceptually, the system can therefore be seen as a set of parallel replace rules (Kempe and Karttunen, 1996) acting on the same input strings. Although this formulation is theoretically pleasing and weighted parallel replace rules are available through the HFST interface (Lind´en et al., 2011), preliminary experiments revealed that compilation of the system represented using parallel replace rules is slow in presence of training data of realistic scope. However, the subset of parallel replace rules needed in our two systems can be reformulated as normal replace rules to take advantage of a sequence of compose operations eliminating the speed issue in practice, see Section 5.3. 5.2 5.3 Cascaded Weigh"
W16-4820,K15-1005,0,0.0130163,"(2015). Automatic identification of Portuguese varieties was studied by Zampieri and Gebre (2012), whereas Zampieri et al. (2012), Zampieri (2013), Zampieri et al. (2013), and Maier and G´omez-Rodr´ıguez (2014) researched language variety identification between Spanish dialects. Discriminating between French dialects was studied by Zampieri et al. (2012) and Zampieri (2013). Arabic dialect identification was researched by Elfardy and Diab (2013), Darwish et al. (2014), Elfardy et al. (2014), Sadat et al. (2014), Salloum et al. (2014), Tillmann et al. (2014), Zaidan and Callison-Burch (2014), Al-Badrashiny et al. (2015), Malmasi et al. (2015), and Ali et al. (2016). The system description articles provided for the previous shared tasks are all relevant and references to them can be found in (Zampieri et al., 2014) and (Zampieri et al., 2015b). Detailed analysis of the previous shared task results was done by Goutte et al. (2016). 3 Methodology The basic idea of the HeLI method was first introduced in (Jauhiainen, 2010). It was also described in the proceedings of the previous task (Jauhiainen et al., 2015b). In this paper, we present the complete description of the method for the first time. First we introdu"
W16-4820,D14-1154,0,0.0232127,"languages has been researched by Ljubeˇsic et al. (2007), Tiedemann and Ljubeˇsic (2012), Ljubeˇsic and Kranjcic (2014), and Ljubeˇsic and Kranjcic (2015). Automatic identification of Portuguese varieties was studied by Zampieri and Gebre (2012), whereas Zampieri et al. (2012), Zampieri (2013), Zampieri et al. (2013), and Maier and G´omez-Rodr´ıguez (2014) researched language variety identification between Spanish dialects. Discriminating between French dialects was studied by Zampieri et al. (2012) and Zampieri (2013). Arabic dialect identification was researched by Elfardy and Diab (2013), Darwish et al. (2014), Elfardy et al. (2014), Sadat et al. (2014), Salloum et al. (2014), Tillmann et al. (2014), Zaidan and Callison-Burch (2014), Al-Badrashiny et al. (2015), Malmasi et al. (2015), and Ali et al. (2016). The system description articles provided for the previous shared tasks are all relevant and references to them can be found in (Zampieri et al., 2014) and (Zampieri et al., 2015b). Detailed analysis of the previous shared task results was done by Goutte et al. (2016). 3 Methodology The basic idea of the HeLI method was first introduced in (Jauhiainen, 2010). It was also described in the proceedi"
W16-4820,P13-2081,0,0.0285208,"hing between South-Slavic languages has been researched by Ljubeˇsic et al. (2007), Tiedemann and Ljubeˇsic (2012), Ljubeˇsic and Kranjcic (2014), and Ljubeˇsic and Kranjcic (2015). Automatic identification of Portuguese varieties was studied by Zampieri and Gebre (2012), whereas Zampieri et al. (2012), Zampieri (2013), Zampieri et al. (2013), and Maier and G´omez-Rodr´ıguez (2014) researched language variety identification between Spanish dialects. Discriminating between French dialects was studied by Zampieri et al. (2012) and Zampieri (2013). Arabic dialect identification was researched by Elfardy and Diab (2013), Darwish et al. (2014), Elfardy et al. (2014), Sadat et al. (2014), Salloum et al. (2014), Tillmann et al. (2014), Zaidan and Callison-Burch (2014), Al-Badrashiny et al. (2015), Malmasi et al. (2015), and Ali et al. (2016). The system description articles provided for the previous shared tasks are all relevant and references to them can be found in (Zampieri et al., 2014) and (Zampieri et al., 2015b). Detailed analysis of the previous shared task results was done by Goutte et al. (2016). 3 Methodology The basic idea of the HeLI method was first introduced in (Jauhiainen, 2010). It was also de"
W16-4820,W14-3911,0,0.0239851,"earched by Ljubeˇsic et al. (2007), Tiedemann and Ljubeˇsic (2012), Ljubeˇsic and Kranjcic (2014), and Ljubeˇsic and Kranjcic (2015). Automatic identification of Portuguese varieties was studied by Zampieri and Gebre (2012), whereas Zampieri et al. (2012), Zampieri (2013), Zampieri et al. (2013), and Maier and G´omez-Rodr´ıguez (2014) researched language variety identification between Spanish dialects. Discriminating between French dialects was studied by Zampieri et al. (2012) and Zampieri (2013). Arabic dialect identification was researched by Elfardy and Diab (2013), Darwish et al. (2014), Elfardy et al. (2014), Sadat et al. (2014), Salloum et al. (2014), Tillmann et al. (2014), Zaidan and Callison-Burch (2014), Al-Badrashiny et al. (2015), Malmasi et al. (2015), and Ali et al. (2016). The system description articles provided for the previous shared tasks are all relevant and references to them can be found in (Zampieri et al., 2014) and (Zampieri et al., 2015b). Detailed analysis of the previous shared task results was done by Goutte et al. (2016). 3 Methodology The basic idea of the HeLI method was first introduced in (Jauhiainen, 2010). It was also described in the proceedings of the previous tas"
W16-4820,W15-5413,0,0.221407,"ast year’s shared task, where we were in the 4th place. Instead, we made it simpler than last year, leaving out the extra discriminating features as well as the first stage of language group identification. As of this writing, we do not have much information on the nature of the language identification methods the other teams used, so we can only compare our method with the methods used in the previous task. The winner of the 2015 shared task used Support Vector Machines (SVMs), which heavily rely on finding the discriminating features (Malmasi and Dras, 2015). SVMs were also used by the NRC (Goutte and Leger, 2015) and MMS (Zampieri et al., 2015a) teams, which shared the second place last year. The language identification method we propose is generative in nature. It does not rely on finding discriminating features between languages. The language models for each language can be built without any knowledge of the other languages to be included in the repertoire of the language identifiers. This makes adding more languages to the language identifier very easy, there is no need to change the already existing models or to compare the new language with the already existing ones. It is possible that the gener"
W16-4820,L16-1284,0,0.675665,"Missing"
W16-4820,W15-5408,1,0.627633,"Missing"
W16-4820,W14-4204,0,0.0806774,"Missing"
W16-4820,W15-5407,0,0.100378,"at we did not really try to improve the system from the last year’s shared task, where we were in the 4th place. Instead, we made it simpler than last year, leaving out the extra discriminating features as well as the first stage of language group identification. As of this writing, we do not have much information on the nature of the language identification methods the other teams used, so we can only compare our method with the methods used in the previous task. The winner of the 2015 shared task used Support Vector Machines (SVMs), which heavily rely on finding the discriminating features (Malmasi and Dras, 2015). SVMs were also used by the NRC (Goutte and Leger, 2015) and MMS (Zampieri et al., 2015a) teams, which shared the second place last year. The language identification method we propose is generative in nature. It does not rely on finding discriminating features between languages. The language models for each language can be built without any knowledge of the other languages to be included in the repertoire of the language identifiers. This makes adding more languages to the language identifier very easy, there is no need to change the already existing models or to compare the new language with"
W16-4820,W16-4801,0,0.41445,"Missing"
W16-4820,W14-5904,0,0.0151478,"al. (2007), Tiedemann and Ljubeˇsic (2012), Ljubeˇsic and Kranjcic (2014), and Ljubeˇsic and Kranjcic (2015). Automatic identification of Portuguese varieties was studied by Zampieri and Gebre (2012), whereas Zampieri et al. (2012), Zampieri (2013), Zampieri et al. (2013), and Maier and G´omez-Rodr´ıguez (2014) researched language variety identification between Spanish dialects. Discriminating between French dialects was studied by Zampieri et al. (2012) and Zampieri (2013). Arabic dialect identification was researched by Elfardy and Diab (2013), Darwish et al. (2014), Elfardy et al. (2014), Sadat et al. (2014), Salloum et al. (2014), Tillmann et al. (2014), Zaidan and Callison-Burch (2014), Al-Badrashiny et al. (2015), Malmasi et al. (2015), and Ali et al. (2016). The system description articles provided for the previous shared tasks are all relevant and references to them can be found in (Zampieri et al., 2014) and (Zampieri et al., 2015b). Detailed analysis of the previous shared task results was done by Goutte et al. (2016). 3 Methodology The basic idea of the HeLI method was first introduced in (Jauhiainen, 2010). It was also described in the proceedings of the previous task (Jauhiainen et al.,"
W16-4820,P14-2125,0,0.013238,"n and Ljubeˇsic (2012), Ljubeˇsic and Kranjcic (2014), and Ljubeˇsic and Kranjcic (2015). Automatic identification of Portuguese varieties was studied by Zampieri and Gebre (2012), whereas Zampieri et al. (2012), Zampieri (2013), Zampieri et al. (2013), and Maier and G´omez-Rodr´ıguez (2014) researched language variety identification between Spanish dialects. Discriminating between French dialects was studied by Zampieri et al. (2012) and Zampieri (2013). Arabic dialect identification was researched by Elfardy and Diab (2013), Darwish et al. (2014), Elfardy et al. (2014), Sadat et al. (2014), Salloum et al. (2014), Tillmann et al. (2014), Zaidan and Callison-Burch (2014), Al-Badrashiny et al. (2015), Malmasi et al. (2015), and Ali et al. (2016). The system description articles provided for the previous shared tasks are all relevant and references to them can be found in (Zampieri et al., 2014) and (Zampieri et al., 2015b). Detailed analysis of the previous shared task results was done by Goutte et al. (2016). 3 Methodology The basic idea of the HeLI method was first introduced in (Jauhiainen, 2010). It was also described in the proceedings of the previous task (Jauhiainen et al., 2015b). In this paper,"
W16-4820,C12-1160,0,0.354116,"Missing"
W16-4820,W14-5313,0,0.0300842,"Ljubeˇsic and Kranjcic (2014), and Ljubeˇsic and Kranjcic (2015). Automatic identification of Portuguese varieties was studied by Zampieri and Gebre (2012), whereas Zampieri et al. (2012), Zampieri (2013), Zampieri et al. (2013), and Maier and G´omez-Rodr´ıguez (2014) researched language variety identification between Spanish dialects. Discriminating between French dialects was studied by Zampieri et al. (2012) and Zampieri (2013). Arabic dialect identification was researched by Elfardy and Diab (2013), Darwish et al. (2014), Elfardy et al. (2014), Sadat et al. (2014), Salloum et al. (2014), Tillmann et al. (2014), Zaidan and Callison-Burch (2014), Al-Badrashiny et al. (2015), Malmasi et al. (2015), and Ali et al. (2016). The system description articles provided for the previous shared tasks are all relevant and references to them can be found in (Zampieri et al., 2014) and (Zampieri et al., 2015b). Detailed analysis of the previous shared task results was done by Goutte et al. (2016). 3 Methodology The basic idea of the HeLI method was first introduced in (Jauhiainen, 2010). It was also described in the proceedings of the previous task (Jauhiainen et al., 2015b). In this paper, we present the complete"
W16-4820,J14-1006,0,0.0144741,"(2014), and Ljubeˇsic and Kranjcic (2015). Automatic identification of Portuguese varieties was studied by Zampieri and Gebre (2012), whereas Zampieri et al. (2012), Zampieri (2013), Zampieri et al. (2013), and Maier and G´omez-Rodr´ıguez (2014) researched language variety identification between Spanish dialects. Discriminating between French dialects was studied by Zampieri et al. (2012) and Zampieri (2013). Arabic dialect identification was researched by Elfardy and Diab (2013), Darwish et al. (2014), Elfardy et al. (2014), Sadat et al. (2014), Salloum et al. (2014), Tillmann et al. (2014), Zaidan and Callison-Burch (2014), Al-Badrashiny et al. (2015), Malmasi et al. (2015), and Ali et al. (2016). The system description articles provided for the previous shared tasks are all relevant and references to them can be found in (Zampieri et al., 2014) and (Zampieri et al., 2015b). Detailed analysis of the previous shared task results was done by Goutte et al. (2016). 3 Methodology The basic idea of the HeLI method was first introduced in (Jauhiainen, 2010). It was also described in the proceedings of the previous task (Jauhiainen et al., 2015b). In this paper, we present the complete description of the method for the"
W16-4820,W14-5307,0,0.17212,"Missing"
W16-4820,W15-5411,0,0.531237,"Missing"
W16-4820,W15-5401,0,0.273547,"Missing"
W17-0209,W16-2406,1,0.8929,"Missing"
W17-0221,D14-1069,0,0.0297589,"Missing"
W17-0221,W16-4820,1,0.433954,"Missing"
W17-0221,zampieri-gebre-2014-varclass,0,0.0367167,"Missing"
W17-0221,P12-3005,0,0.145116,"Missing"
W17-0221,Q14-1003,0,0.0271214,"after all the cleaning, the training corpora must be considered rather unclean. In our project we are interested in gathering as much of the very rare Uralic texts as possible, so we need a high recall. On the other hand, if our precision is bad, we end up with a high percentage of incorrect language labels for the rare languages. For these reasons we use the F1 -score as the main performance measure when evaluating the language identifiers. We calculate the language-level averages of recall, precision and the F1 -score. Language-level averages are referred to as macro-averages by Lui et al. (Lui et al., 2014). As the number of mystery texts for each language were identical, the macro-averaged recall equals the commonly used classification accuracy5 . The Fβ -score is based on the effectiveness measure introduced by van Rijsbergen (1979) and is calculated from the precision p and recall r, as in Equation 15  Fβ = (1 + β 2 ) pr (β 2 p) + r  3.2 The test corpora are mostly derived from the translations of the universal declaration of human rights.11 However, the test set includes languages for which no translation of the declaration is available and for these languages texts were collected from som"
W17-0221,E12-3006,0,0.018659,"Missing"
W17-0221,quasthoff-etal-2006-corpus,0,0.0617036,"Missing"
W17-0221,vatanen-etal-2010-language,0,0.0332958,"Missing"
W17-1212,W15-5408,1,0.706927,"Missing"
W17-1212,W16-4820,1,0.852741,"Missing"
W17-1212,W16-4827,0,0.050387,"The creation of the earlier DSL corpora has been described by Tan et al. (2014). This year’s training data consisted of 18,000 lines of text, excerpts of journalistic texts, for each of the 14 languages. The corresponding development set had 2,000 lines of text for each language. The task had a language selection comparable to the 1st (Zampieri et al., 2014), 2nd (Zampieri et al., For the 4th edition, we were interested in modifying the HeLI method and use the TF-IDF scores and some non-linear mappings instead of relative frequencies. We were inspired by the successful use of TF-IDF scores by Barbaresi (2016). He was able to significantly boost the accuracy of his identifier after the 3rd edition of the shared task by using the TF-IDF scores. Earlier, Brown (2014) managed to boost several language identification methods using non-linear mappings. 2 Related Work Automatic language identification of digital text has been researched for more than 50 years. The first article on the subject was written by Mustonen (1965), who used multiple discriminant anal102 Proceedings of the Fourth Workshop on NLP for Similar Languages, Varieties and Dialects, pages 102–108, c Valencia, Spain, April 3, 2017. 2017 A"
W17-1212,W14-4204,0,0.0280754,"Missing"
W17-1212,W17-1214,0,0.252655,"Missing"
W17-1212,D14-1069,0,0.39961,"stic texts, for each of the 14 languages. The corresponding development set had 2,000 lines of text for each language. The task had a language selection comparable to the 1st (Zampieri et al., 2014), 2nd (Zampieri et al., For the 4th edition, we were interested in modifying the HeLI method and use the TF-IDF scores and some non-linear mappings instead of relative frequencies. We were inspired by the successful use of TF-IDF scores by Barbaresi (2016). He was able to significantly boost the accuracy of his identifier after the 3rd edition of the shared task by using the TF-IDF scores. Earlier, Brown (2014) managed to boost several language identification methods using non-linear mappings. 2 Related Work Automatic language identification of digital text has been researched for more than 50 years. The first article on the subject was written by Mustonen (1965), who used multiple discriminant anal102 Proceedings of the Fourth Workshop on NLP for Similar Languages, Varieties and Dialects, pages 102–108, c Valencia, Spain, April 3, 2017. 2017 Association for Computational Linguistics 3 ysis to distinguish between Finnish, English and Swedish. For more of the history of automatic language identificat"
W17-1212,W16-4801,0,0.199949,"Missing"
W17-1212,L16-1284,0,0.0617378,"Missing"
W17-1212,C12-1160,0,0.073818,"Missing"
W17-1212,W14-5307,0,0.253258,"Missing"
W17-1212,W15-5401,0,0.164893,"Missing"
W17-1212,W17-1201,0,0.200569,"Missing"
W18-3907,W12-2108,0,0.0704475,"Missing"
W18-3907,W17-4408,0,0.0341301,"Missing"
W18-3907,W15-5408,1,0.923176,"Missing"
W18-3907,W16-4820,1,0.75379,"Missing"
W18-3907,W17-1212,1,0.79996,"Missing"
W18-3907,W17-0221,1,0.915772,"Missing"
W18-3907,P12-3005,0,0.041199,"nd Bosnian. 2.2 Unsupervised language model adaptation In unsupervised language model adaptation, the language models are modified while identifying the language of previously unseen and unlabeled text. The goal is to adapt the models to better suit the language or languages used in the texts to be identified in order to reach higher identification accuracy. The use of on-line language model adaptation for language identification of digital text has been very limited. Blodgett et al. (2017) experimented with a method where they first identified the language of tweets using standard langid-py (Lui and Baldwin, 2012), and then collected the tweets with high posterior probability for English. From the collected tweets they generated a second language model for English to be used by the language identifier. Language identifiers can have several language models 67 for one language, all of them providing the same classification if chosen. Their experiments produced a small increase in recall. Chen and Liu (2005) use language model adaptation with language identification of speech similarly as we are using it in the language identification of text. The language identification system used by Chen and Liu (2005)"
W18-3907,W16-4801,0,0.298203,"Missing"
W18-3907,W14-5307,0,0.363551,"Missing"
W18-3907,W15-5401,0,0.301295,"Missing"
W18-3907,W17-1201,0,0.439058,"Missing"
W18-3907,W18-3901,0,0.182798,"Missing"
W18-3915,W15-5408,1,0.910801,"Missing"
W18-3915,W16-4820,1,0.918886,"Missing"
W18-3915,W17-1212,1,0.863907,"Missing"
W18-3915,W17-0221,1,0.892551,"Missing"
W18-3915,W16-4801,0,0.172028,"Missing"
W18-3915,W06-1109,0,0.0550523,"varieties. Afrikaans is a close language to Dutch spoken in South Africa. The language identification between Afrikaans and Dutch has been examined several times in the past. Cowie et al. (1999) evaluated the common word, minimal distance, rank distance (Cavnar and Trenkle, 1994), and their own LZC methods and note that all of them were able to distinguish relatively well between the two languages. When automatically creating language trees from the universal declarations of human rights, Benedetto et al. (2002) group Afrikaans and Dutch together, with both equally related to Frisian. Singh (Singh, 2006; Singh, 2010) lists Dutch and Afrikaans as confusable languages with each other and Lui (2014) noticed that Afrikaans was confused especially with West Frisian. The latest study on Dutch language identification by van der Lee and van den Bosch (2017) led to the current shared task. 2.1 Unsupervised clustering Unsupervised clustering of text aims to form coherent groups by gathering similar texts together. One of the first unsupervised clustering approaches to language identification task was presented by Biemann and Teresniak (2005). They use the co-occurrences of words to group words togethe"
W18-3915,L16-1652,0,0.0145463,". (2018). The language identification of Dutch, its varieties and the languages close to it has been considered earlier outside the VarDial context. Trieschnigg et al. (2012) evaluated rank- and cosine-similarity (nearest neighbour and nearest prototype) based language identification methods on the Dutch Folktale Database (Meder, 2010). The version of the database they used contained 15 languages or dialects close to Dutch, as well as English. The best macro F-score for document size identifications, 0.63, was obtained by the nearest neighbor cosine similarity method trained on word unigrams. Tulkens et al. (2016) used word2vec word embeddings in dialect identification of Dutch varieties. Afrikaans is a close language to Dutch spoken in South Africa. The language identification between Afrikaans and Dutch has been examined several times in the past. Cowie et al. (1999) evaluated the common word, minimal distance, rank distance (Cavnar and Trenkle, 1994), and their own LZC methods and note that all of them were able to distinguish relatively well between the two languages. When automatically creating language trees from the universal declarations of human rights, Benedetto et al. (2002) group Afrikaans"
W18-3915,W17-1224,0,0.190477,"Missing"
W18-3915,W15-5401,0,0.133263,"Missing"
W18-3915,W17-1201,0,0.15905,"Missing"
W18-3915,W18-3901,0,0.0770263,"Missing"
W18-3929,W17-1223,0,0.127394,"Missing"
W18-3929,W17-1214,0,0.148356,"Missing"
W18-3929,W17-1221,0,0.191961,"Missing"
W18-3929,W17-1213,0,0.0532448,"Missing"
W18-3929,W17-1211,0,0.0314338,"Missing"
W18-3929,W17-1225,0,0.112053,"Missing"
W18-3929,W15-5408,1,0.888291,"Missing"
W18-3929,W16-4820,1,0.599918,"Missing"
W18-3929,W17-1212,1,0.888077,"Missing"
W18-3929,W17-0221,1,0.845892,"Missing"
W18-3929,W17-1220,0,0.312132,"Missing"
W18-3929,L16-1641,0,0.22656,"Missing"
W18-3929,D10-1112,0,0.0992241,"would be able to help us automatically decide whether we are dealing with languages or dialects. Also the methods used for dialect identification are most of the time exactly the same as for general language identification. Language identification of close languages and dialects is one of the remaining challenges of language identification research. For a recent survey on language identification and the methods used in the field, the reader is referred to an article by Jauhiainen et al. (2018). 2.1 German dialect identification The German dialect identification has earlier been considered by Scherrer and Rambow (2010), who used a lexicon of dialectal words. Hollenstein and Aepli (2015) experimented with a perplexity based language identifier using character trigrams. They reached an average F-score of 0.66 on sentence level between 5 German dialects. The results of the first shared task on German dialect identification are described by Zampieri et al. (2017). Ten teams submitted results on the task utilizing a variety of machine learning methods used This work is licensed under a Creative Commons Attribution 4.0 International Licence. creativecommons.org/licenses/by/4.0/. Licence details: http:// 254 Proce"
W18-3929,W17-1201,0,0.618705,"Missing"
W18-3929,W18-3901,0,0.418173,"Missing"
W19-1409,C88-1064,0,0.603212,"guage identification in cuneiform texts was verified. In this paper, we report some of the results from the initial experiments. To the best of our knowledge, this is the first time that automatic language identification methods have been used on cuneiform data. The methods we use for language identification utilize mainly character n-grams and their observed probabilities in text. 1 Related work 2.1 Cuneiform script and computational methods In this section, we survey some of the research where computational methods related to language identification have been used with the cuneiform script. Kataja and Koskenniemi (1988) discuss the description and computational implementation of phonology and morphology for Akkadian. They give examples of the rules in two-level formalism they used with the TWOL rule compiler (Karttunen et al., 1987). Barth´elemy (1998) developed and tested a morphological analyzer for Akkadian verbal forms. The analyzer works with Akkadian represented in Latin encoding (transcription). Tablan et al. (2006) describe their project, which aims to create a tool for automatic morphological analysis of Sumerian. 2 [https://sites.google.com/view/ vardial2019/campaign] [http://oracc.museum.upenn.edu"
W19-1409,W98-1010,0,0.0707415,"Missing"
W19-1409,N15-1167,0,0.0219928,"ures with the clustering methods. Each document was depicted as a feature vector with the length of the whole vocabulary. In K-means, the number of clusters has to be given before the algorithm is applied and Ponti et al. (2013) experimented with 2 to 15 clusters. Luo et al. (2015) describe an unsupervised Named-Entity Recognition (NER) system for transliterated Sumerian. They compared the use of different lengths of transliterated word n-grams in combination with the Decision List CoTrain algorithm, and their evaluations show that word bigrams obtain the highest F1-score. In another article (Liu et al., 2015), they describe how they managed to find unannotated personal names in a corpus and suggest that the NER system could be used as an automated tool for the annotation task. Liu et al. (2016) continue the NER research on Sumerian using a variety of supervised classification methods to detect named entities. Homburg and Chiarcos (2016) researched automated word segmentation of Akkadian cuneiform script. They used a sign list to restore CDLI3 transliterations back to cuneiform (represented as UTF-8 characters). This is the only related work we are aware of in which cuneiform texts encoded in Unico"
W19-1409,L16-1642,0,0.176485,"ognition (NER) system for transliterated Sumerian. They compared the use of different lengths of transliterated word n-grams in combination with the Decision List CoTrain algorithm, and their evaluations show that word bigrams obtain the highest F1-score. In another article (Liu et al., 2015), they describe how they managed to find unannotated personal names in a corpus and suggest that the NER system could be used as an automated tool for the annotation task. Liu et al. (2016) continue the NER research on Sumerian using a variety of supervised classification methods to detect named entities. Homburg and Chiarcos (2016) researched automated word segmentation of Akkadian cuneiform script. They used a sign list to restore CDLI3 transliterations back to cuneiform (represented as UTF-8 characters). This is the only related work we are aware of in which cuneiform texts encoded in Unicode cuneiform have been processed previous to our experiments. Pag´e-Perron et al. (2017) present a project dedicated to creating a pipeline for Sumerian texts. The pipeline is planned to take in transliterated Sumerian and to produce POS tag annotations and lemmatization as well as machine translation into English. Chiarcos et al. ("
W19-1409,W18-3929,1,0.700138,"Missing"
W19-1409,W16-4801,0,0.286649,"Missing"
W19-1409,W18-3907,1,0.895213,"Missing"
W19-1409,W16-4820,1,0.904459,"Missing"
W19-1409,W17-2202,0,0.111676,"Missing"
W19-1409,W14-5307,0,0.14085,"Missing"
W19-1409,W15-5401,0,0.15329,"Missing"
W19-1409,tablan-etal-2006-creating,0,0.564887,"and computational methods In this section, we survey some of the research where computational methods related to language identification have been used with the cuneiform script. Kataja and Koskenniemi (1988) discuss the description and computational implementation of phonology and morphology for Akkadian. They give examples of the rules in two-level formalism they used with the TWOL rule compiler (Karttunen et al., 1987). Barth´elemy (1998) developed and tested a morphological analyzer for Akkadian verbal forms. The analyzer works with Akkadian represented in Latin encoding (transcription). Tablan et al. (2006) describe their project, which aims to create a tool for automatic morphological analysis of Sumerian. 2 [https://sites.google.com/view/ vardial2019/campaign] [http://oracc.museum.upenn.edu] 89 Proceedings of VarDial, pages 89–98 c Minneapolis, MN, June 7, 2019 2019 Association for Computational Linguistics Among several languages, Rao et al. (2009) analyzed Sumerian written in cuneiform using conditional entropy to compare it with the Indus script. Normalized entropy of sign n-grams between the two scripts was used as further evidence to indicate the possible linguistic content of the texts w"
W19-1409,W17-1201,0,0.270979,"xts in well-resourced languages is not a difficult task, but it becomes increasingly more challenging when we target short, fragmentary, and multilingual texts in languages where the amount of training material is severely restricted. A separate challenge for language identification is dealing with closely related languages or with several dialects of an individual language. The challenge of discriminating between closely related languages has been investigated in a series of shared tasks that have been organized as part of VarDial workshops (Zampieri et al., 2014, 2015; Malmasi et al., 2016; Zampieri et al., 2017, 2018). 3 [https: 90 Cuneiform texts in Oracc written, and the oldest texts survive from the turn of the fourth and third millennia before the Common Era (BCE). Akkadian replaced Sumerian as the spoken language during the late third and early second millennia BCE, but Sumerian was used as a liturgical and scholarly language until the end of the cuneiform tradition at the beginning of the Common Era. Written Akkadian is known from circa 2400 BCE onwards until the first century CE. The Akkadian language had two main dialects, Assyrian and Babylonian, both of which are present in our data. Assyr"
W19-1409,W18-3901,0,0.361618,"Missing"
W19-1419,W18-3919,0,0.0143731,". A comprehensive survey of language identification in general has been published in arXiv by Jauhiainen et al. (2018d). The series of shared tasks in language identification began in 2014 with the Discriminating Between Similar languages (DSL) shared task (Zampieri et al., 2014) and similar tasks have been arranged each year since (Zampieri et al., 2015; Malmasi et al., 2016; Zampieri et al., 2017, 2018). It is notable that, so far, deep neural networks have not gained an upper hand when compared with the more linear classification methods (C¸o¨ ltekin and Rama, 2017; Medvedeva et al., 2017; Ali, 2018). 2.2 2.3 German dialect identification The GDI 2019 task was already the third of its kind (Zampieri et al., 2017, 2018). In 2017, we did not participate in the shared task, which was won using an SVM meta-classifier ensemble with words and character n-grams from one to six as features (Malmasi and Zampieri, 2017). We won the 2018 edition using the HeLI method with LM adaptation and character 4-grams as features (Jauhiainen et al., 2018b). We were the only ones employing LM adaptation and won with a wide margin to the second system which was an SVM ensemble using both character and word n-gra"
W19-1419,W18-3915,1,0.885748,"Missing"
W19-1419,W18-3925,0,0.0241542,"Missing"
W19-1419,W18-3929,1,0.762279,"Missing"
W19-1419,W17-1218,0,0.0192964,"for dialect and language variety identification. A comprehensive survey of language identification in general has been published in arXiv by Jauhiainen et al. (2018d). The series of shared tasks in language identification began in 2014 with the Discriminating Between Similar languages (DSL) shared task (Zampieri et al., 2014) and similar tasks have been arranged each year since (Zampieri et al., 2015; Malmasi et al., 2016; Zampieri et al., 2017, 2018). It is notable that, so far, deep neural networks have not gained an upper hand when compared with the more linear classification methods (C¸o¨ ltekin and Rama, 2017; Medvedeva et al., 2017; Ali, 2018). 2.2 2.3 German dialect identification The GDI 2019 task was already the third of its kind (Zampieri et al., 2017, 2018). In 2017, we did not participate in the shared task, which was won using an SVM meta-classifier ensemble with words and character n-grams from one to six as features (Malmasi and Zampieri, 2017). We won the 2018 edition using the HeLI method with LM adaptation and character 4-grams as features (Jauhiainen et al., 2018b). We were the only ones employing LM adaptation and won with a wide margin to the second system which was an SVM ensemble"
W19-1419,W18-3907,1,0.794149,"Missing"
W19-1419,Y96-1018,0,0.169346,"acro F1-score and we used it also when comparing the different methods we used with the development data. 3.1 GDI dataset Variety (code) Bern (BE) Basel (BS) Lucerne (LU) Zurich (ZH) DMT datasets Training 27,968 26,927 28,979 28,833 Development 7,381 9,462 8,650 8,086 Table 1: List of the Swiss German varieties used in the datasets distributed for the 2019 GDI shared task. The sizes are in words. The scripts commonly used in mainland China and Taiwan are different. In Taiwan, the traditional Chinese script is commonly used whereas in mainland China, the simplified version is the official one (Chen et al., 1996; Huang et al., 2000; McEnery and Xiao, 2003). In order to be able to concentrate on the non-scriptual differences of the two varieties of Mandarin Chinese, Putonghua (Mainland China) and Guoyo (Taiwan), the texts used for the DMT task had been transformed to use the same script. In the simplified track, the Taiwanese texts originally written in the traditional script had been converted into the simpliThe training, development, and test sets included two files in addition to the speech transcriptions. The first file included normalized forms for each dialectal form in the data. The second file"
W19-1419,W16-4820,1,0.796997,"Missing"
W19-1419,W00-1205,0,0.0228102,"e used it also when comparing the different methods we used with the development data. 3.1 GDI dataset Variety (code) Bern (BE) Basel (BS) Lucerne (LU) Zurich (ZH) DMT datasets Training 27,968 26,927 28,979 28,833 Development 7,381 9,462 8,650 8,086 Table 1: List of the Swiss German varieties used in the datasets distributed for the 2019 GDI shared task. The sizes are in words. The scripts commonly used in mainland China and Taiwan are different. In Taiwan, the traditional Chinese script is commonly used whereas in mainland China, the simplified version is the official one (Chen et al., 1996; Huang et al., 2000; McEnery and Xiao, 2003). In order to be able to concentrate on the non-scriptual differences of the two varieties of Mandarin Chinese, Putonghua (Mainland China) and Guoyo (Taiwan), the texts used for the DMT task had been transformed to use the same script. In the simplified track, the Taiwanese texts originally written in the traditional script had been converted into the simpliThe training, development, and test sets included two files in addition to the speech transcriptions. The first file included normalized forms for each dialectal form in the data. The second file included 400-dimens"
W19-1419,W17-1220,0,0.568789,"Missing"
W19-1419,Y08-1042,0,0.102227,"Missing"
W19-1419,W16-4801,0,0.177727,"Missing"
W19-1419,W14-5301,0,0.0172969,"already the third of its kind (Zampieri et al., 2017, 2018). In GDI 2019, the task was to distinguish between four SwissGerman dialects. The third task was that of Cuneiform Language Identification (CLI), but we did not participate in that as we were partly responsible for creating its dataset (Jauhiainen et al., 2019a). We evaluated several language identification methods using the development sets of the DMT and GDI tasks. Our best submissions were created 178 Proceedings of VarDial, pages 178–187 c Minneapolis, MN, June 7, 2019 2019 Association for Computational Linguistics 2 Related work Huang et al. (2014) show how light verbs have different distributional tendencies in Mainland and Taiwan varieties of Mandarin Chinese. Using KMeans clustering they show that the varieties can be differentiated. Xu et al. (2016) describe an approach to distinguish between several varieties of Mandarin Chinese: Mainland, Hong Kong, Taiwan, Macao, Malaysia, and Singapore. In another study (Xu et al., 2018), they used support vector machines (SVM) to distinguish between Gan Chinese dialects. In this section, we introduce some background information on previous studies in language identification in general, language"
W19-1419,W17-1219,0,0.162181,"e variety identification. A comprehensive survey of language identification in general has been published in arXiv by Jauhiainen et al. (2018d). The series of shared tasks in language identification began in 2014 with the Discriminating Between Similar languages (DSL) shared task (Zampieri et al., 2014) and similar tasks have been arranged each year since (Zampieri et al., 2015; Malmasi et al., 2016; Zampieri et al., 2017, 2018). It is notable that, so far, deep neural networks have not gained an upper hand when compared with the more linear classification methods (C¸o¨ ltekin and Rama, 2017; Medvedeva et al., 2017; Ali, 2018). 2.2 2.3 German dialect identification The GDI 2019 task was already the third of its kind (Zampieri et al., 2017, 2018). In 2017, we did not participate in the shared task, which was won using an SVM meta-classifier ensemble with words and character n-grams from one to six as features (Malmasi and Zampieri, 2017). We won the 2018 edition using the HeLI method with LM adaptation and character 4-grams as features (Jauhiainen et al., 2018b). We were the only ones employing LM adaptation and won with a wide margin to the second system which was an SVM ensemble using both character an"
W19-1419,L16-1641,0,0.100918,"Missing"
W19-1419,L18-1036,0,0.0183646,"lopment sets of the DMT and GDI tasks. Our best submissions were created 178 Proceedings of VarDial, pages 178–187 c Minneapolis, MN, June 7, 2019 2019 Association for Computational Linguistics 2 Related work Huang et al. (2014) show how light verbs have different distributional tendencies in Mainland and Taiwan varieties of Mandarin Chinese. Using KMeans clustering they show that the varieties can be differentiated. Xu et al. (2016) describe an approach to distinguish between several varieties of Mandarin Chinese: Mainland, Hong Kong, Taiwan, Macao, Malaysia, and Singapore. In another study (Xu et al., 2018), they used support vector machines (SVM) to distinguish between Gan Chinese dialects. In this section, we introduce some background information on previous studies in language identification in general, language identification in the context of Chinese and German languages, as well as LM adaptation. 2.1 Language identification in texts Language identification (LI) is the task of identifying the language of a text. The same methods which are used for LI are generally also used for dialect and language variety identification. A comprehensive survey of language identification in general has been"
W19-1419,W17-1201,0,0.455082,"plified Chinese track using again the adaptive Naive Bayes. 1 Introduction The third VarDial Evaluation Campaign (Zampieri et al., 2019) included three shared tasks on language, dialect, and language variety identification. The Discriminating between Mainland and Taiwan variation of Mandarin Chinese (DMT) concentrated on finding differences between the varieties of Mandarin Chinese written on mainland China and Taiwan. The task included two tracks, one for the simplified script and another for the traditional one. The German Dialect Identification (GDI) task was already the third of its kind (Zampieri et al., 2017, 2018). In GDI 2019, the task was to distinguish between four SwissGerman dialects. The third task was that of Cuneiform Language Identification (CLI), but we did not participate in that as we were partly responsible for creating its dataset (Jauhiainen et al., 2019a). We evaluated several language identification methods using the development sets of the DMT and GDI tasks. Our best submissions were created 178 Proceedings of VarDial, pages 178–187 c Minneapolis, MN, June 7, 2019 2019 Association for Computational Linguistics 2 Related work Huang et al. (2014) show how light verbs have differe"
W19-1419,W18-3901,0,0.105881,"Missing"
W19-1419,W14-5307,0,0.284308,"Missing"
