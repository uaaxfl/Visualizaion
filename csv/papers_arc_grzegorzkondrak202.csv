2021.semeval-1.101,{UA}lberta at {S}em{E}val-2021 Task 2: Determining Sense Synonymy via Translations,2021,-1,-1,4,1,1891,bradley hauer,Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021),0,"We describe the University of Alberta systems for the SemEval-2021 Word-in-Context (WiC) disambiguation task. We explore the use of translation information for deciding whether two different tokens of the same word correspond to the same sense of the word. Our focus is on developing principled theoretical approaches which are grounded in linguistic phenomena, leading to more explainable models. We show that translations from multiple languages can be leveraged to improve the accuracy on the WiC task."
2021.gwc-1.1,On Universal Colexifications,2021,-1,-1,3,0,1892,hongchang bao,Proceedings of the 11th Global Wordnet Conference,0,"Colexification occurs when two distinct concepts are lexified by the same word. The term covers both polysemy and homonymy. We posit and investigate the hypothesis that no pair of concepts are colexified in every language. We test our hypothesis by analyzing colexification data from BabelNet, Open Multilingual WordNet, and CLICS. The results show that our hypothesis is supported by over 99.9{\%} of colexified concept pairs in these three lexical resources."
2021.gwc-1.4,Homonymy and Polysemy Detection with Multilingual Information,2021,-1,-1,3,1,6125,amir habibi,Proceedings of the 11th Global Wordnet Conference,0,"Deciding whether a semantically ambiguous word is homonymous or polysemous is equivalent to establishing whether it has any pair of senses that are semantically unrelated. We present novel methods for this task that leverage information from multilingual lexical resources. We formally prove the theoretical properties that provide the foundation for our methods. In particular, we show how the One Homonym Per Translation hypothesis of Hauer and Kondrak (2020a) follows from the synset properties formulated by Hauer and Kondrak (2020b). Experimental evaluation shows that our approach sets a new state of the art for homonymy detection."
2020.sigmorphon-1.12,Low-Resource {G}2{P} and {P}2{G} Conversion with Synthetic Training Data,2020,-1,-1,5,1,1891,bradley hauer,"Proceedings of the 17th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology",0,"This paper presents the University of Alberta systems and results in the SIGMORPHON 2020 Task 1: Multilingual Grapheme-to-Phoneme Conversion. Following previous SIGMORPHON shared tasks, we define a low-resource setting with 100 training instances. We experiment with three transduction approaches in both standard and low-resource settings, as well as on the related task of phoneme-to-grapheme conversion. We propose a method for synthesizing training data using a combination of diverse models."
2020.semeval-1.32,{UA}lberta at {S}em{E}val-2020 Task 2: Using Translations to Predict Cross-Lingual Entailment,2020,-1,-1,5,1,1891,bradley hauer,Proceedings of the Fourteenth Workshop on Semantic Evaluation,0,"We investigate the hypothesis that translations can be used to identify cross-lingual lexical entailment. We propose novel methods that leverage parallel corpora, word embeddings, and multilingual lexical resources. Our results demonstrate that the implementation of these ideas leads to improvements in predicting entailment."
2020.emnlp-main.332,Improving Word Sense Disambiguation with Translations,2020,-1,-1,4,0,14882,yixing luan,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,"It has been conjectured that multilingual information can help monolingual word sense disambiguation (WSD). However, existing WSD systems rarely consider multilingual information, and no effective method has been proposed for improving WSD by generating translations. In this paper, we present a novel approach that improves the performance of a base WSD system using machine translation. Since our approach is language independent, we perform WSD experiments on several languages. The results demonstrate that our methods can consistently improve the performance of WSD systems, and obtain state-ofthe-art results in both English and multilingual WSD. To facilitate the use of lexical translation information, we also propose BABALIGN, an precise bitext alignment algorithm which is guided by multilingual lexical correspondences from BabelNet."
W19-4202,Cognate Projection for Low-Resource Inflection Generation,2019,0,0,5,1,1891,bradley hauer,"Proceedings of the 16th Workshop on Computational Research in Phonetics, Phonology, and Morphology",0,We propose cognate projection as a method of crosslingual transfer for inflection generation in the context of the SIGMORPHON 2019 Shared Task. The results on four language pairs show the method is effective when no low-resource training data is available.
W19-1403,Joint Approach to Deromanization of Code-mixed Texts,2019,0,0,2,0,24256,rashed riyadh,"Proceedings of the Sixth Workshop on {NLP} for Similar Languages, Varieties and Dialects",0,"The conversion of romanized texts back to the native scripts is a challenging task because of the inconsistent romanization conventions and non-standard language use. This problem is compounded by code-mixing, i.e., using words from more than one language within the same discourse. In this paper, we propose a novel approach for handling these two problems together in a single system. Our approach combines three components: language identification, back-transliteration, and sequence prediction. The results of our experiments on Bengali and Hindi datasets establish the state of the art for the task of deromanization of code-mixed texts."
W18-5805,String Transduction with Target Language Models and Insertion Handling,2018,13,0,3,1,1307,garrett nicolai,"Proceedings of the Fifteenth Workshop on Computational Research in Phonetics, Phonology, and Morphology",0,"Many character-level tasks can be framed as sequence-to-sequence transduction, where the target is a word from a natural language. We show that leveraging target language models derived from unannotated target corpora, combined with a precise alignment of the training data, yields state-of-the art results on cognate projection, inflection generation, and phoneme-to-grapheme conversion."
W18-2412,Comparison of Assorted Models for Transliteration,2018,0,0,5,0,27868,saeed najafi,Proceedings of the Seventh Named Entities Workshop,0,"We report the results of our experiments in the context of the NEWS 2018 Shared Task on Transliteration. We focus on the comparison of several diverse systems, including three neural MT models. A combination of discriminative, generative, and neural models obtains the best results on the development sets. We also put forward ideas for improving the shared task."
K18-3015,Combining Neural and Non-Neural Methods for Low-Resource Morphological Reinflection,2018,0,1,5,0,27868,saeed najafi,Proceedings of the {C}o{NLL}{--}{SIGMORPHON} 2018 Shared Task: Universal Morphological Reinflection,0,None
K17-2008,"If you can{'}t beat them, join them: the {U}niversity of {A}lberta system description",2017,2,2,5,1,1307,garrett nicolai,Proceedings of the {C}o{NLL} {SIGMORPHON} 2017 Shared Task: Universal Morphological Reinflection,0,None
E17-2034,Morphological Analysis without Expert Annotation,2017,0,0,2,1,1307,garrett nicolai,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 2, Short Papers",0,"The task of morphological analysis is to produce a complete list of lemma+tag analyses for a given word-form. We propose a discriminative string transduction approach which exploits plain inflection tables and raw text corpora, thus obviating the need for expert annotation. Experiments on four languages demonstrate that our system has much higher coverage than a hand-engineered FST analyzer, and is more accurate than a state-of-the-art morphological tagger."
E17-2098,Bootstrapping Unsupervised Bilingual Lexicon Induction,2017,10,8,3,1,1891,bradley hauer,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 2, Short Papers",0,The task of unsupervised lexicon induction is to find translation pairs across monolingual corpora. We develop a novel method that creates seed lexicons by identifying cognates in the vocabularies of related languages on the basis of their frequency and lexical similarity. We apply bidirectional bootstrapping to a method which learns a linear mapping between context-based vector spaces. Experimental results on three language pairs show consistent improvement over prior work.
D17-1267,Identifying Cognate Sets Across Dictionaries of Related Languages,2017,31,3,3,0,33188,adam arnaud,Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing,0,"We present a system for identifying cognate sets across dictionaries of related languages. The likelihood of a cognate relationship is calculated on the basis of a rich set of features that capture both phonetic and semantic similarity, as well as the presence of regular sound correspondences. The similarity scores are used to cluster words from different languages that may originate from a common proto-word. When tested on the Algonquian language family, our system detects 63{\%} of cognate sets while maintaining cluster purity of 70{\%}."
W16-2005,Morphological Reinflection via Discriminative String Transduction,2016,4,0,4,1,1307,garrett nicolai,"Proceedings of the 14th {SIGMORPHON} Workshop on Computational Research in Phonetics, Phonology, and Morphology",0,None
W16-2016,Morphological Segmentation Can Improve Syllabification,2016,0,0,3,1,1307,garrett nicolai,"Proceedings of the 14th {SIGMORPHON} Workshop on Computational Research in Phonetics, Phonology, and Morphology",0,None
Q16-1006,Decoding Anagrammed Texts Written in an Unknown Language and Script,2016,23,8,2,1,1891,bradley hauer,Transactions of the Association for Computational Linguistics,0,"Algorithmic decipherment is a prime example of a truly unsupervised problem. The first step in the decipherment process is the identification of the encrypted language. We propose three methods for determining the source language of a document enciphered with a monoalphabetic substitution cipher. The best method achieves 97{\%} accuracy on 380 languages. We then present an approach to decoding anagrammed substitution ciphers, in which the letters within words have been arbitrarily transposed. It obtains the average decryption word accuracy of 93{\%} on a set of 50 ciphertexts in 5 languages. Finally, we report the results on the Voynich manuscript, an unsolved fifteenth century cipher, which suggest Hebrew as the language of the document."
P16-1108,Leveraging Inflection Tables for Stemming and Lemmatization.,2016,18,9,2,1,1307,garrett nicolai,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"We present several methods for stemming and lemmatization based on discriminative string transduction. We exploit the paradigmatic regularity of semi-structured inflection tables to identify stems in an unsupervised manner with over 85% accuracy. Experiments on English, Dutch and German show that our stemmers substantially outperform Snowball and Morfessor, and approach the accuracy of a supervised model. Furthermore, the generated stems are more consistent than those annotated by experts. Our direct lemmatization model is more accurate than Morfette and Lemming on most datasets. Finally, we test our methods on the data from the shared task on morphological reinflection."
N16-1140,Integrating Morphological Desegmentation into Phrase-based Decoding,2016,9,0,3,1,25950,mohammad salameh,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,None
W15-3911,Multiple System Combination for Transliteration,2015,19,8,7,1,1307,garrett nicolai,Proceedings of the Fifth Named Entity Workshop,0,"We report the results of our experiments in the context of the NEWS 2015 Shared Task on Transliteration. We focus on methods of combining multiple base systems, and leveraging transliterations from multiple languages. We show error reductions over the best base system of up to 10% when using supplemental transliterations, and up to 20% when using system combination. We also discuss the quality of the shared task datasets."
W15-1518,Morpho-syntactic Regularities in Continuous Word Representations: A multilingual study.,2015,7,2,3,1,1307,garrett nicolai,Proceedings of the 1st Workshop on Vector Space Modeling for Natural Language Processing,0,"We replicate the syntactic experiments of Mikolov et al. (2013b) on English, and expand them to include morphologically complex languages. We learn vector representations for Dutch, French, German, and Spanish with the WORD2VEC tool, and investigate to what extent inflectional information is preserved across vectors. We observe that the accuracy of vectors on a set of syntactic analogies is inversely correlated with the morphological complexity of the language."
W15-1011,What Matters Most in Morphologically Segmented {SMT} Models?,2015,22,2,3,1,25950,mohammad salameh,"Proceedings of the Ninth Workshop on Syntax, Semantics and Structure in Statistical Translation",0,"Morphological segmentation is an effective strategy for addressing difficulties caused by morphological complexity. In this study, we use an English-to-Arabic test bed to determine what steps and components of a phrase-based statistical machine translation pipeline benefit the most from segmenting the target language. We test several scenarios that differ primarily in when desegmentation is applied, showing that the most important criterion for success in segmentation is to allow the system to build target words from morphemes that span phrase boundaries. We also investigate the impact of segmented and unsegmented target language models (LMs) on translation quality. We show that an unsegmented LM is helpful according to BLEU score, but also leads to a drop in the overall usage of compositional morphology, bringing it to well below the amount observed in human references."
P15-2046,A Lexicalized Tree Kernel for Open Information Extraction,2015,16,3,4,1,4212,ying xu,Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers),0,"In contrast with traditional relation extraction, which only considers a fixed set of relations, Open Information Extraction (Open IE) aims at extracting all types of relations from text. Because of data sparseness, Open IE systems typically ignore lexical information, and instead employ parse trees and Part-of-Speech (POS) tags. However, the same syntactic structure may correspond to different relations. In this paper, we propose to use a lexicalized tree kernel based on the word embeddings created by a neural network model. We show that the lexicalized tree kernel model surpasses the unlexicalized model. Experiments on three datasets indicate that our Open IE system performs better on the task of relation extraction than the stateof-the-art Open IE systems of Xu et al. (2013) and Mesquita et al. (2013)."
N15-1056,{E}nglish orthography is not {``}close to optimal{''},2015,15,0,2,1,1307,garrett nicolai,Proceedings of the 2015 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"In spite of the apparent irregularity of the English spelling system, Chomsky and Halle (1968) characterize it as xe2x80x9cnear optimalxe2x80x9d. We investigate this assertion using computational techniques and resources. We design an algorithm to generate word spellings that maximize both phonemic transparency and morphological consistency. Experimental results demonstrate that the constructed system is much closer to optimality than the traditional English orthography."
N15-1093,Inflection Generation as Discriminative String Transduction,2015,12,20,3,1,1307,garrett nicolai,Proceedings of the 2015 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"We approach the task of morphological inflection generation as discriminative string transduction. Our supervised system learns to generate word-forms from lemmas accompanied by morphological tags, and refines them by referring to the other forms within a paradigm. Results of experiments on six diverse languages with varying amounts of training data demonstrate that our approach improves the state of the art in terms of predicting inflected word-forms."
N15-1095,Joint Generation of Transliterations from Multiple Representations,2015,18,4,2,0,33931,lei yao,Proceedings of the 2015 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"Machine transliteration is often referred to as phonetic translation. We show that transliterations incorporate information from both spelling and pronunciation, and propose an effective model for joint transliteration generation from both representations. We further generalize this model to include transliterations from other languages, and enhance it with reranking and lexicon features. We demonstrate significant improvements in transliteration accuracy on several datasets."
W14-2808,10 Open Questions in Computational Morphonology,2014,22,0,1,1,1894,grzegorz kondrak,Proceedings of the 2014 Joint Meeting of {SIGMORPHON} and {SIGFSM},0,"The objective of this paper is to initiate discussion within the SIGMORPHON community around several issues that involve computational morphology, phonology, phonetics, orthography, syllabification, transliteration, machine translation, inflection generation, and native language identification."
P14-2138,Does the Phonology of {L}1 Show Up in {L}2 Texts?,2014,24,4,2,1,1307,garrett nicolai,Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"The relative frequencies of character bigrams appear to contain much information for predicting the first language (L1) of the writer of a text in another language (L2). Tsur and Rappoport (2007) interpret this fact as evidence that word choice is dictated by the phonology of L1. In order to test their hypothesis, we design an algorithm to identify the most discriminative words and the corresponding character bigrams, and perform two experiments to quantify their impact on the L1 identification task. The results strongly suggest an alternative explanation of the effectiveness of character bigrams in identifying the native language of a writer."
P14-1010,Lattice Desegmentation for Statistical Machine Translation,2014,30,5,3,1,25950,mohammad salameh,Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"Morphological segmentation is an effective sparsity reduction strategy for statistical machine translation (SMT) involving morphologically complex languages. When translating into a segmented language, an extra step is required to desegment the output; previous studies have desegmented the 1-best output from the decoder. In this paper, we expand our translation options by desegmentingn-best lists or lattices. Our novel lattice desegmentation algorithm effectively combines both segmented and desegmented views of the target language for a large subspace of possible translation outputs, which allows for inclusion of features related to the desegmentation process, as well as an unsegmented language model (LM). We investigate this technique in the context of English-to-Arabic and English-to-Finnish translation, showing significant improvements in translation quality over desegmentation of 1-best decoder outputs."
C14-1218,Solving Substitution Ciphers with Combined Language Models,2014,30,6,3,1,1891,bradley hauer,"Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: Technical Papers",0,"We propose a novel approach to deciphering short monoalphabetic ciphers that combines both character-level and word-level language models. We formulate decipherment as tree search, and use Monte Carlo Tree Search (MCTS) as a fast alternative to beam search. Our experiments show a significant improvement over the state of the art on a benchmark suite of short ciphers. Our approach can also handle ciphers without spaces and ciphers with noise, which allows us to explore its applications to unsupervised transliteration and deniable encryption."
W13-1718,Cognate and Misspelling Features for Natural Language Identification,2013,14,7,5,1,1307,garrett nicolai,Proceedings of the Eighth Workshop on Innovative Use of {NLP} for Building Educational Applications,0,"We apply Support Vector Machines to differentiate between 11 native languages in the 2013 Native Language Identification Shared Task. We expand a set of common language identification features to include cognate interference and spelling mistakes. Our best results are obtained with a classifier which includes both the cognate and the misspelling features, as well as word unigrams, word bigrams, character bigrams, and syntax production rules."
P13-1129,Identification of Speakers in Novels,2013,20,25,3,0.952381,24284,hua he,Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"Speaker identification is the task of attributing utterances to characters in a literary narrative. It is challenging to automate because the speakers of the majority of utterances are not explicitly identified in novels. In this paper, we present a supervised machine learning approach for the task that incorporates several novel features. The experimental results show that our method is more accurate and general than previous approaches to the problem."
N13-2007,Reversing Morphological Tokenization in {E}nglish-to-{A}rabic {SMT},2013,10,4,3,1,25950,mohammad salameh,Proceedings of the 2013 {NAACL} {HLT} Student Research Workshop,0,"Morphological tokenization has been used in machine translation for morphologically complex languages to reduce lexical sparsity. Unfortunately, when translating into a morphologically complex language, recombining segmented tokens to generate original word forms is not a trivial task, due to morphological, phonological and orthographic adjustments that occur during tokenization. We review a number of detokenization schemes for Arabic, such as rule-based and table-based approaches and show their limitations. We then propose a novel detokenization scheme that uses a character-level discriminative string transducer to predict the original form of a segmented word. In a comparison to a stateof-the-art approach, we demonstrate slightly better detokenization error rates, without the need for any hand-crafted rules. We also demonstrate the effectiveness of our approach in an English-to-Arabic translation task."
N13-1072,Automatic Generation of {E}nglish Respellings,2013,18,2,2,1,1891,bradley hauer,Proceedings of the 2013 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"A respelling is an alternative spelling of a word in the same writing system, intended to clarify pronunciation. We introduce the task of automatic generation of a respelling from the wordxe2x80x99s phonemic representation. Our approach combines machine learning with linguistic constraints and electronic resources. We evaluate our system both intrinsically through a human judgment experiment, and extrinsically by passing its output to a letterto-phoneme converter. The results show that the respellings generated by our system are better on average than those found on the Web, and approach the quality of respellings designed by an expert."
W12-4411,Transliteration Experiments on {C}hinese and {A}rabic,2012,7,2,1,1,1894,grzegorz kondrak,Proceedings of the 4th Named Entity Workshop ({NEWS}) 2012,0,"We report the results of our transliteration experiments with language-specific adaptations in the context of two language pairs: English to Chinese, and Arabic to English. In particular, we investigate a syllable-based Pinyin intermediate representation for Chinese, and a letter mapping for Arabic."
W12-0208,Similarity Patterns in Words (Invited talk),2012,22,0,1,1,1894,grzegorz kondrak,Proceedings of the {EACL} 2012 Joint Workshop of {LINGVIS} {\\&} {UNCLH},0,"Words are important both in historical linguistics and natural language processing. They are not indivisible abstract atoms; much can be gained by considering smaller units such as morphemes, phonemes, syllables, and letters. In this presentation, I attempt to sketch the similarity patterns among a number of diverse research projects in which I participated."
N12-1044,Leveraging supplemental representations for sequential transduction,2012,37,7,2,1,5810,aditya bhargava,Proceedings of the 2012 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"Sequential transduction tasks, such as grapheme-to-phoneme conversion and machine transliteration, are usually addressed by inducing models from sets of input-output pairs. Supplemental representations offer valuable additional information, but incorporating that information is not straightforward. We apply a unified reranking approach to both grapheme-to-phoneme conversion and machine transliteration demonstrating substantial accuracy improvements by utilizing heterogeneous transliterations and transcriptions of the input word. We describe several experiments that involve a variety of supplemental data and two state-of-the-art transduction systems, yielding error rate reductions ranging from 12% to 43%. We further apply our approach to system combination, with error rate reductions between 4% and 9%."
W11-3206,Leveraging Transliterations from Multiple Languages,2011,13,5,3,1,5810,aditya bhargava,Proceedings of the 3rd Named Entities Workshop ({NEWS} 2011),0,"While past research on machine transliteration has focused on a single transliteration task, there exist a variety of supplemental transliterations available in other languages. Given an input for English-toHindi transliteration, for example, transliterations from other languages such as Japanese or Hebrew may be helpful in the transliteration process. In this paper, we propose the application of such supplemental transliterations to English-to-Hindi machinetransliterationviaanSVMre-ranking method with features based on n-gram alignments as well as system and alignment scores. This method achieves a relative improvement of over 10% over the base system used on its own. We further apply this method to system combination, demonstrating just under 5% relative improvement."
P11-1041,How do you pronounce your name? Improving {G}2{P} with transliterations,2011,20,10,2,1,5810,aditya bhargava,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,1,"Grapheme-to-phoneme conversion (G2P) of names is an important and challenging problem. The correct pronunciation of a name is often reflected in its transliterations, which are expressed within a different phonological inventory. We investigate the problem of using transliterations to correct errors produced by state-of-the-art G2P systems. We present a novel re-ranking approach that incorporates a variety of score and n-gram features, in order to leverage transliterations from multiple languages. Our experiments demonstrate significant accuracy improvements when re-ranking is applied to n-best lists generated by three different G2P programs."
I11-1061,The application of chordal graphs to inferring phylogenetic trees of languages,2011,8,6,2,1,44769,jessica enright,Proceedings of 5th International Joint Conference on Natural Language Processing,0,"Phylogenetic methods are used to buildn evolutionary trees of languages givenn character data that may include lexical,n phonological, and morphological information. Such data rarely admits a perfectn phylogeny. We explore the use of then more permissive conservative Dollo phylogeny as an alternative or complementaryn approach. We propose a heuristic searchn algorithm based on the notion of chordaln graphs. We test this approach by generating phylogenetic trees from three datasets,n and comparing them to those produced byn other researchers."
I11-1097,Clustering Semantically Equivalent Words into Cognate Sets in Multilingual Lists,2011,20,27,2,1,1891,bradley hauer,Proceedings of 5th International Joint Conference on Natural Language Processing,0,"Word lists have become available for most of the worldxe2x80x99s languages, but only a small fraction of such lists contain cognate information. We present a machine-learning approach that automatically clusters words in multilingual word lists into cognate sets. Our method incorporates a number of diverse word similarity measures and features that encode the degree of affinity between pairs of languages. The output of the classification algorithm is then used to generate cognate groups. The results of the experiments on word lists representing several language families demonstrate the utility of the proposed approach."
W10-3708,Application of the Tightness Continuum Measure to {C}hinese Information Retrieval,2010,22,7,4,1,4212,ying xu,Proceedings of the 2010 Workshop on Multiword Expressions: from Theory to Applications,0,"Most word segmentation methods employed in Chinese Information Retrieval systems are based on a static dictionary or a model trained against a manually segmented corpus. These general segmentation approaches may not be optimal because they disregard information within semantic units. We propose a novel method for improving word-based Chinese IR, which performs segmentation according to the tightness of phrases. In order to evaluate the effectiveness of our method, we employ a new test collection of 203 queries, which include a broad distribution of phrases with different tightness values. The results of our experiments indicate that our method improves IR performance as compared with a general word segmentation approach. The experiments also demonstrate the need for the development of better evaluation corpora."
W10-2405,Transliteration Generation and Mining with Limited Training Resources,2010,17,29,7,1,45318,sittichai jiampojamarn,Proceedings of the 2010 Named Entities Workshop,0,"We present DirecTL: an online discriminative sequence prediction model based on many-to-many alignments, which is further augmented by the incorporation of joint n-gram features. Experimental results show improvement over the results achieved by DirecTL in 2009. We also explore a number of diverse resource-free and language-independent approaches to transliteration mining, which range from simple to sophisticated."
P10-1080,Letter-Phoneme Alignment: An Exploration,2010,20,24,2,1,45318,sittichai jiampojamarn,Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,1,"Letter-phoneme alignment is usually generated by a straightforward application of the EM algorithm. We explore several alternative alignment methods that employ phonetics, integer programming, and sets of constraints, and propose a novel approach of refining the EM alignment by aggregation of best alignments. We perform both intrinsic and extrinsic evaluation of the assortment of methods. We show that our proposed EM-Aggregation algorithm leads to the improvement of the state of the art in letter-to-phoneme conversion on several different data sets."
N10-1102,Language identification of names with {SVM}s,2010,9,14,2,1,5810,aditya bhargava,Human Language Technologies: The 2010 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics,0,"The task of identifying the language of text or utterances has a number of applications in natural language processing. Language identification has traditionally been approached with character-level language models. However, the language model approach crucially depends on the length of the text in question. In this paper, we consider the problem of language identification of names. We show that an approach based on SVMs with n-gram counts as features performs much better than language models. We also experiment with applying the method to pre-process transliteration data for the training of separate models."
N10-1103,Integrating Joint n-gram Features into a Discriminative Training Framework,2010,11,46,3,1,45318,sittichai jiampojamarn,Human Language Technologies: The 2010 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics,0,"Phonetic string transduction problems, such as letter-to-phoneme conversion and name transliteration, have recently received much attention in the NLP community. In the past few years, two methods have come to dominate as solutions to supervised string transduction: generative joint n-gram models, and discriminative sequence models. Both approaches benefit from their ability to consider large, flexible spans of source context when making transduction decisions. However, they encode this context in different ways, providing their respective models with different information. To combine the strengths of these two systems, we include joint n-gram features inside a state-of-the-art discriminative sequence model. We evaluate our approach on several letter-to-phoneme and transliteration data sets. Our results indicate an improvement in overall performance with respect to both the joint n-gram approach and traditional feature sets for discriminative models."
D10-1029,Predicting the Semantic Compositionality of Prefix Verbs,2010,37,3,4,0.482456,39132,shane bergsma,Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,0,"In many applications, replacing a complex word form by its stem can reduce sparsity, revealing connections in the data that would not otherwise be apparent. In this paper, we focus on prefix verbs: verbs formed by adding a prefix to an existing verb stem. A prefix verb is considered compositional if it can be decomposed into a semantically equivalent expression involving its stem. We develop a classifier to predict compositionality via a range of lexical and distributional features, including novel features derived from web-scale N-gram data. Results on a new annotated corpus show that prefix verb compositionality can be predicted with high accuracy. Our system also performs well when trained and tested on conventional morphological segmentations of prefix verbs."
W09-3504,{D}irec{TL}: a Language Independent Approach to Transliteration,2009,10,31,5,1,45318,sittichai jiampojamarn,Proceedings of the 2009 Named Entities Workshop: Shared Task on Transliteration ({NEWS} 2009),0,"We present DirecTL: an online discriminative sequence prediction model that employs a many-to-many alignment between target and source. Our system incorporates input segmentation, target character prediction, and sequence modeling in a unified dynamic programming framework. Experimental results suggest that DirecTL is able to independently discover many of the language-specific regularities in the training data."
P09-1014,A Ranking Approach to Stress Prediction for Letter-to-Phoneme Conversion,2009,30,17,4,0,30565,qing dou,Proceedings of the Joint Conference of the 47th Annual Meeting of the {ACL} and the 4th International Joint Conference on Natural Language Processing of the {AFNLP},1,"Correct stress placement is important in text-to-speech systems, in terms of both the overall accuracy and the naturalness of pronunciation. In this paper, we formulate stress assignment as a sequence prediction problem. We represent words as sequences of substrings, and use the substrings as features in a Support Vector Machine (SVM) ranker, which is trained to rank possible stress patterns. The ranking approach facilitates inclusion of arbitrary features over both the input sequence and output stress pattern. Our system advances the current state-of-the-art, predicting primary stress in English, German, and Dutch with up to 98% word accuracy on phonemes, and 96% on letters. The system is also highly accurate in predicting secondary stress. Finally, when applied in tandem with an L2P system, it substantially reduces the word error rate when predicting both phonemes and stress."
P09-1015,Reducing the Annotation Effort for Letter-to-Phoneme Conversion,2009,30,9,2,0,45319,kenneth dwyer,Proceedings of the Joint Conference of the 47th Annual Meeting of the {ACL} and the 4th International Joint Conference on Natural Language Processing of the {AFNLP},1,"Letter-to-phoneme (L2P) conversion is the process of producing a correct phoneme sequence for a word, given its letters. It is often desirable to reduce the quantity of training data --- and hence human annotation --- that is needed to train an L2P classifier for a new language. In this paper, we confront the challenge of building an accurate L2P classifier with a minimal amount of training data by combining several diverse techniques: context ordering, letter clustering, active learning, and phonetic L2P alignment. Experiments on six languages show up to 75% reduction in annotation effort."
N09-3008,Multiple Word Alignment with {P}rofile {H}idden {M}arkov {M}odels,2009,10,17,2,1,5810,aditya bhargava,"Proceedings of Human Language Technologies: The 2009 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics, Companion Volume: Student Research Workshop and Doctoral Consortium",0,"Profile hidden Markov models (Profile HMMs) are specific types of hidden Markov models used in biological sequence analysis. We propose the use of Profile HMMs for word-related tasks. We test their applicability to the tasks of multiple cognate alignment and cognate set matching, and find that they work well in general for both tasks. On the latter task, the Profile HMM method outperforms average and minimum edit distance. Given the success for these two tasks, we further discuss the potential applications of Profile HMMs to any task where consideration of a set of words is necessary."
N09-1035,On the Syllabification of Phonemes,2009,25,41,2,0,47346,susan bartlett,Proceedings of Human Language Technologies: The 2009 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics,0,"Syllables play an important role in speech synthesis and recognition. We present several different approaches to the syllabification of phonemes. We investigate approaches based on linguistic theories of syllabification, as well as a discriminative learning technique that combines Support Vector Machine and Hidden Markov Model technologies. Our experiments on English, Dutch and German demonstrate that our transparent implementation of the sonority sequencing principle is more accurate than previous implementations, and that our language-independent SVM-based approach advances the current state-of-the-art, achieving word accuracy of over 98% in English and 99% in German and Dutch."
P08-1065,Automatic Syllabification with Structured {SVM}s for Letter-to-Phoneme Conversion,2008,4,45,2,0,47346,susan bartlett,Proceedings of ACL-08: HLT,1,"We present the first English syllabification system to improve the accuracy of letter-tophoneme conversion. We propose a novel discriminative approach to automatic syllabification based on structured SVMs. In comparison with a state-of-the-art syllabification system, we reduce the syllabification word error rate for English by 33%. Our approach also performs well on other languages, comparing favorably with published results on German and Dutch."
P08-1103,Joint Processing and Discriminative Training for Letter-to-Phoneme Conversion,2008,22,68,3,1,45318,sittichai jiampojamarn,Proceedings of ACL-08: HLT,1,"We present a discriminative structureprediction model for the letter-to-phoneme task, a crucial step in text-to-speech processing. Our method encompasses three tasks that have been previously handled separately: input segmentation, phoneme prediction, and sequence modeling. The key idea is online discriminative training, which updates parameters according to a comparison of the current system output to the desired output, allowing us to train all of our components together. By folding the three steps of a pipeline approach into a unified dynamic programming framework, we are able to achieve substantial performance gains. Our results surpass the current state-of-the-art on six publicly available data sets representing four different languages."
W07-1301,Computing and Historical Phonology,2007,11,3,3,0,38842,john nerbonne,Proceedings of Ninth Meeting of the {ACL} Special Interest Group in Computational Morphology and Phonology,0,We introduce the proceedings from the workshop 'Computing and Historical Phonology: 9th Meeting of the ACL Special Interest Group for Computational Morphology and Phonology'.
W07-1317,Creating a Comparative Dictionary of {T}otonac-{T}epehua,2007,9,7,1,1,1894,grzegorz kondrak,Proceedings of Ninth Meeting of the {ACL} Special Interest Group in Computational Morphology and Phonology,0,"We apply algorithms for the identification of cognates and recurrent sound correspondences proposed by Kondrak (2002) to the Totonac-Tepehua family of indigenous languages in Mexico. We show that by combining expert linguistic knowledge with computational analysis, it is possible to quickly identify a large number of cognate sets within the family. Our objective is to provide tools for rapid construction of comparative dictionaries for relatively unfamiliar language families."
P07-1109,Bootstrapping a Stochastic Transducer for {A}rabic-{E}nglish Transliteration Extraction,2007,11,24,2,0,49180,tarek sherif,Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,1,"We propose a bootstrapping approach to training a memoriless stochastic transducer for the task of extracting transliterations from an English-Arabic bitext. The transducer learns its similarity metric from the data in the bitext, and thus can function directly on strings written in different writing scripts without any additional language knowledge. We show that this bootstrapped transducer performs as well or better than a model designed specifically to detect Arabic-English transliterations."
P07-1119,Substring-Based Transliteration,2007,9,52,2,0,49180,tarek sherif,Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,1,"Transliteration is the task of converting a word from one alphabetic script to another. We present a novel, substring-based approach to transliteration, inspired by phrasebased models of machine translation. We investigate two implementations of substringbased transliteration: a dynamic programming algorithm, and a finite-state transducer. We show that our substring-based transducer not only outperforms a state-of-the-art letterbased approach by a significant margin, but is also orders of magnitude faster."
P07-1083,Alignment-Based Discriminative String Similarity,2007,20,45,2,0.435897,39132,shane bergsma,Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,1,"A character-based measure of similarity is an important component of many natural language processing systems, including approaches to transliteration, coreference, word alignment, spelling correction, and the identication of cognates in related vocabularies. We propose an alignment-based discriminative framework for string similarity. We gather features from substring pairs consistent with a character-based alignment of the two strings. This approach achieves exceptional performance; on nine separate cognate identication experiments using six language pairs, we more than double the precision of traditional orthographic measures like Longest Common Subsequence Ratio and Dicexe2x80x99s Coefcient. We also show strong improvements over other recent discriminative and heuristic similarity functions."
N07-2008,A Fast Method for Parallel Document Identification,2007,8,11,2,1,44769,jessica enright,"Human Language Technologies 2007: The Conference of the North {A}merican Chapter of the Association for Computational Linguistics; Companion Volume, Short Papers",0,"We present a fast method to identify homogeneous parallel documents. The method is based on collecting counts of identical low-frequency words between possibly parallel documents. The candidate with the most shared low-frequency words is selected as the parallel document. The method achieved 99.96% accuracy when tested on the EUROPARL corpus of parliamentary proceedings, failing only in anomalous cases of truncated or otherwise distorted documents. While other work has shown similar performance on this type of dataset, our approach presented here is faster and does not require training. Apart from proposing an efficient method for parallel document identification in a restricted domain, this paper furnishes evidence that parliamentary proceedings may be inappropriate for testing parallel document identification systems in general."
N07-1047,Applying Many-to-Many Alignments and Hidden {M}arkov Models to Letter-to-Phoneme Conversion,2007,15,137,2,1,45318,sittichai jiampojamarn,Human Language Technologies 2007: The Conference of the North {A}merican Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference,0,"Letter-to-phoneme conversion generally requires aligned training data of letters and phonemes. Typically, the alignments are limited to one-to-one alignments. We present a novel technique of training with many-to-many alignments. A letter chunking bigram prediction manages double letters and double phonemes automatically as opposed to preprocessing with fixed lists. We also apply an HMM method in conjunction with a local classification model to predict a global phoneme sequence given a word. The many-to-many alignments result in significant improvements over the traditional one-to-one approach. Our system achieves state-of-the-art performance on several languages and data sets."
W06-3319,Biomedical Term Recognition with the Perceptron {HMM} Algorithm,2006,2,0,2,1,45318,sittichai jiampojamarn,Proceedings of the {HLT}-{NAACL} {B}io{NLP} Workshop on Linking Natural Language and Biology,0,"We propose a novel approach to the identification of biomedical terms in research publications using the Perceptron HMM algorithm. Each important term is identified and classified into a biomedical concept class. Our proposed system achieves a 68.6% F-measure based on 2,000 training Medline abstracts and 404 unseen testing Medline abstracts. The system achieves performance that is close to the state-of-the-art using only a small feature set. The Perceptron HMM algorithm provides an easy way to incorporate many potentially interdependent features."
W06-1107,Evaluation of Several Phonetic Similarity Algorithms on the Task of Cognate Identification,2006,16,38,1,1,1894,grzegorz kondrak,Proceedings of the Workshop on Linguistic Distances,0,"We investigate the problem of measuring phonetic similarity, focusing on the identification of cognates, words of the same origin in different languages. We compare representatives of two principal approaches to computing phonetic similarity: manually-designed metrics, and learning algorithms. In particular, we consider a stochastic transducer, a Pair HMM, several DBN models, and two constructed schemes. We test those approaches on the task of identifying cognates among Indoeuropean languages, both in the supervised and unsupervised context. Our results suggest that the averaged context DBN model and the Pair HMM achieve the highest accuracy given a large training set of positive examples."
W05-0606,Computing Word Similarity and Identifying Cognates with Pair Hidden {M}arkov Models,2005,24,38,2,0,50811,wesley mackay,Proceedings of the Ninth Conference on Computational Natural Language Learning ({C}o{NLL}-2005),0,"We present a system for computing similarity between pairs of words. Our system is based on Pair Hidden Markov Models, a variation on Hidden Markov Models that has been used successfully for the alignment of biological sequences. The parameters of the model are automatically learned from training data that consists of word pairs known to be similar. Our tests focus on the identification of cognates --- words of common origin in related languages. The results show that our system outperforms previously proposed techniques."
H05-1120,Learning a Spelling Error Model from Search Query Logs,2005,11,96,2,0,51125,farooq ahmad,Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing,0,"Applying the noisy channel model to search query spelling correction requires an error model and a language model. Typically, the error model relies on a weighted string edit distance measure. The weights can be learned from pairs of misspelled words and their corrections. This paper investigates using the Expectation Maximization algorithm to learn edit distance weights directly from search query logs, without relying on a corpus of paired words."
2005.mtsummit-papers.40,Cognates and Word Alignment in Bitexts,2005,-1,-1,1,1,1894,grzegorz kondrak,Proceedings of Machine Translation Summit X: Papers,0,"We evaluate several orthographic word similarity measures in the context of bitext word alignment. We investigate the relationship between the length of the words and the length of their longest common subsequence. We present an alternative to the longest common subsequence ratio (LCSR), a widely-used orthographic word similarity measure. Experiments involving identification of cognates in bitexts suggest that the alternative method outperforms LCSR. Our results also indicate that alignment links can be used as a substitute for cognates for the purpose of evaluating word similarity measures."
C04-1137,Identification of Confusable Drug Names: A New Approach and Evaluation Methodology,2004,8,50,1,1,1894,grzegorz kondrak,{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics,0,"This paper addresses the mitigation of medical errors due to the confusion of sound-alike and look-alike drug names. Our approach involves application of two new methods---one based on orthographic similarity (look-alike) and the other based on phonetic similarity (sound-alike). We present a new recall-based evaluation methodology for determining the effectiveness of different similarity measures on drug names. We show that the new orthographic measure (BI-SIM) outperforms other commonly used measures of similarity on a set containing both look-alike and sound-alike pairs, and that the feature-based phonetic approach (ALINE) outperforms orthographic approaches on a test set containing solely sound-alike confusion pairs. However, an approach that combines several different measures achieves the best results on both test sets."
N03-2016,Cognates Can Improve Statistical Translation Models,2003,7,86,1,1,1894,grzegorz kondrak,Companion Volume of the Proceedings of {HLT}-{NAACL} 2003 - Short Papers,0,We report results of experiments aimed at improving the translation quality by incorporating the cognate information into translation models. The results confirm that the cognate identification approach can improve the quality of word alignment in bitexts without the need for extra resources.
C02-1016,Determining Recurrent Sound Correspondences by Inducing Translation Models,2002,20,21,1,1,1894,grzegorz kondrak,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"I present a novel approach to the determination of recurrent sound correspondences in bilingual wordlists. The idea is to relate correspondences between sounds in wordlists to translational equivalences between words in bitexts (bilingual corpora). My method induces models of sound correspondence that are similar to models developed for statistical machine translation. The experiments show that the method is able to determine recurrent sound correspondences in bilingual wordlists in which less than 30% of the pairs are cognates. By employing the discovered correspondences, the method can identify cognates with higher accuracy than the previously reported algorithms."
N01-1014,Identifying Cognates by Phonetic and Semantic Similarity,2001,12,60,1,1,1894,grzegorz kondrak,Second Meeting of the North {A}merican Chapter of the Association for Computational Linguistics,0,"I present a method of identifying cognates in the vocabularies of related languages. I show that a measure of phonetic similarity based on multivalued features performs better than orthographic measures, such as the Longest Common Subsequence Ratio (LCSR) or Dice's coefficient. I introduce a procedure for estimating semantic similarity of glosses that employs keyword selection and WordNet. Tests performed on vocabularies of four Algonquian languages indicate that the method is capable of discovering on average nearly 75% percent of cognates at 50% precision."
J01-4008,Book Reviews: The Significance of Word Lists,2001,0,56,1,1,1894,grzegorz kondrak,Computational Linguistics,0,"Similar words for similar concepts turn up in many widely scattered languages. Some linguists say this is chance while others claim that many if not all of the world's languages descend from a single prehistoric language. Yet neither position has been analyzed or supported with statistics. Computerized statistical techniques can be used to help determine whether or not words in different languages have ancestral connections. These techniques are explained and broken down to provide the necessary principles for those linguists with no background in statistics. This methodology measures the probabilistic significance of sound correspondences between short word lists. Many rules of thumb used to obviate chance resemblance are shown to decrease the power of quantitive testing. The procedures presented here are straightforward, but the author also presents the extensive linguistic work needed to produce word lists that will not yield nonsensical results. Examples analyze 200 words in eight languages."
A00-2038,A New Algorithm for the Alignment of Phonetic Sequences,2000,15,124,1,1,1894,grzegorz kondrak,1st Meeting of the North {A}merican Chapter of the Association for Computational Linguistics,0,"Alignment of phonetic sequences is a necessary step in many applications in computational phonology. After discussing various approaches to phonetic alignment, I present a new algorithm that combines a number of techniques developed for sequence comparison with a scoring scheme for computing phonetic similarity on the basis of multivalued features. The algorithm performs better on cognate alignment, in terms of accuracy and efficiency, than other algorithms reported in the literature."
