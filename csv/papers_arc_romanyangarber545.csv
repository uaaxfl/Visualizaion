2021.bsnlp-1.15,"Slav-{NER}: the 3rd Cross-lingual Challenge on Recognition, Normalization, Classification, and Linking of Named Entities across {S}lavic Languages",2021,-1,-1,16,0,6080,jakub piskorski,Proceedings of the 8th Workshop on Balto-Slavic Natural Language Processing,0,"This paper describes Slav-NER: the 3rd Multilingual Named Entity Challenge in Slavic languages. The tasks involve recognizing mentions of named entities in Web documents, normalization of the names, and cross-lingual linking. The Challenge covers six languages and five entity types, and is organized as part of the 8th Balto-Slavic Natural Language Processing Workshop, co-located with the EACL 2021 Conference. Ten teams participated in the competition. Performance for the named entity recognition task reached 90{\%} F-measure, much higher than reported in the first edition of the Challenge. Seven teams covered all six languages, and five teams participated in the cross-lingual entity linking task. Detailed valuation information is available on the shared task web page."
2021.bea-1.15,Assessing Grammatical Correctness in Language Learning,2021,-1,-1,2,1,12233,anisia katinskaia,Proceedings of the 16th Workshop on Innovative Use of NLP for Building Educational Applications,0,"We present experiments on assessing the grammatical correctness of learners{'} answers in a language-learning System (references to the System, and the links to the released data and code are withheld for anonymity). In particular, we explore the problem of detecting alternative-correct answers: when more than one inflected form of a lemma fits syntactically and semantically in a given context. We approach the problem with the methods for grammatical error detection (GED), since we hypothesize that models for detecting grammatical mistakes can assess the correctness of potential alternative answers in a learning setting. Due to the paucity of training data, we explore the ability of pre-trained BERT to detect grammatical errors and then fine-tune it using synthetic training data. In this work, we focus on errors in inflection. Our experiments show a. that pre-trained BERT performs worse at detecting grammatical irregularities for Russian than for English; b. that fine-tuned BERT yields promising results on assessing the correctness of grammatical exercises; and c. establish a new benchmark for Russian. To further investigate its performance, we compare fine-tuned BERT with one of the state-of-the-art models for GED (Bell et al., 2019) on our dataset and RULEC-GEC (Rozovskaya and Roth, 2019). We release the manually annotated learner dataset, used for testing, for general use."
2020.lrec-1.48,Toward a Paradigm Shift in Collection of Learner Corpora,2020,0,0,3,1,12233,anisia katinskaia,Proceedings of the 12th Language Resources and Evaluation Conference,0,"We present the first version of the longitudinal Revita Learner Corpus (ReLCo), for Russian. In contrast to traditional learner corpora, ReLCo is collected and annotated fully automatically, while students perform exercises using the Revita language-learning platform. The corpus currently contains 8 422 sentences exhibiting several types of errors{---}grammatical, lexical, orthographic, etc.{---}which were committed by learners during practice and were automatically annotated by Revita. The corpus provides valuable information about patterns of learner errors and can be used as a language resource for a number of research tasks, while its creation is much cheaper and faster than for traditional learner corpora. A crucial advantage of ReLCo that it grows continually while learners practice with Revita, which opens the possibility of creating an unlimited learner resource with longitudinal data collected over time. We make the pilot version of the Russian ReLCo publicly available."
2020.lrec-1.439,Neural Disambiguation of Lemma and Part of Speech in Morphologically Rich Languages,2020,-1,-1,3,0,17587,jose quecedo,Proceedings of the 12th Language Resources and Evaluation Conference,0,"We consider the problem of disambiguating the lemma and part of speech of ambiguous words in morphologically rich languages. We propose a method for disambiguating ambiguous words in context, using a large un-annotated corpus of text, and a morphological analyser{---}with no manual disambiguation or data annotation. We assume that the morphological analyser produces multiple analyses for ambiguous words. The idea is to train recurrent neural networks on the output that the morphological analyser produces for unambiguous words. We present performance on POS and lemma disambiguation that reaches or surpasses the state of the art{---}including supervised models{---}using no manually annotated data. We evaluate the method on several morphologically rich languages."
W19-6117,Tools for supporting language learning for Sakha,2019,0,0,3,0,1382,sardana ivanova,Proceedings of the 22nd Nordic Conference on Computational Linguistics,0,"This paper presents an overview of the available linguistic resources for the Sakha language, and presents new tools for supporting language learning for Sakha. The essential resources include a morphological analyzer, digital dictionaries, and corpora of Sakha texts. Based on these resources, we implement a language-learning environment for Sakha in the Revita CALL platform. We extended an earlier, preliminary version of the morphological analyzer/transducer, built on the Apertium finite-state platform. The analyzer currently has an adequate level of coverage, between 86{\%} and 89{\%} on two Sakha corpora. Revita is a freely available online language learning platform for learners beyond the beginner level. We describe the tools for Sakha currently integrated into the Revita platform. To the best of our knowledge, at present, this is the first large-scale project undertaken to support intermediate-advanced learners of a minority Siberian language."
W19-6124,Projecting named entity recognizers without annotated or parallel corpora,2019,0,0,4,0,23701,jue hou,Proceedings of the 22nd Nordic Conference on Computational Linguistics,0,"Named entity recognition (NER) is a well-researched task in the field of NLP, which typically requires large annotated corpora for training usable models. This is a problem for languages which lack large annotated corpora, such as Finnish. We propose an approach to create a named entity recognizer with no annotated or parallel documents, by leveraging strong NER models that exist for English. We automatically gather a large amount of \textit{chronologically matched} data in two languages, then project named entity annotations from the English documents onto the Finnish ones, by resolving the matches with limited linguistic rules. We use this {``}artificially{''} annotated data to train a BiLSTM-CRF model. Our results show that this method can produce annotated instances with high precision, and the resulting model achieves state-of-the-art performance."
W19-4451,Modeling language learning using specialized Elo rating,2019,0,0,5,0,23701,jue hou,Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications,0,Automatic assessment of the proficiency levels of the learner is a critical part of Intelligent Tutoring Systems. We present methods for assessment in the context of language learning. We use a specialized Elo formula used in conjunction with educational data mining. We simultaneously obtain ratings for the proficiency of the learners and for the difficulty of the linguistic concepts that the learners are trying to master. From the same data we also learn a graph structure representing a domain model capturing the relations among the concepts. This application of Elo provides ratings for learners and concepts which correlate well with subjective proficiency levels of the learners and difficulty levels of the concepts.
W19-3709,"The Second Cross-Lingual Challenge on Recognition, Normalization, Classification, and Linking of Named Entities across {S}lavic Languages",2019,0,0,7,0,6080,jakub piskorski,Proceedings of the 7th Workshop on Balto-Slavic Natural Language Processing,0,"We describe the Second Multilingual Named Entity Challenge in Slavic languages. The task is recognizing mentions of named entities in Web documents, their normalization, and cross-lingual linking. The Challenge was organized as part of the 7th Balto-Slavic Natural Language Processing Workshop, co-located with the ACL-2019 conference. Eight teams participated in the competition, which covered four languages and five entity types. Performance for the named entity recognition task reached 90{\%} F-measure, much higher than reported in the first edition of the Challenge. Seven teams covered all four languages, and five teams participated in the cross-lingual entity linking task. Detailed evaluation information is available on the shared task web page."
W18-3008,Comparison of Representations of Named Entities for Document Classification,2018,0,1,2,1,4349,lidia pivovarova,Proceedings of The Third Workshop on Representation Learning for {NLP},0,"We explore representations for multi-word names in text classification tasks, on Reuters (RCV1) topic and sector classification. We find that: the best way to treat names is to split them into tokens and use each token as a separate feature; NEs have more impact on sector classification than topic classification; replacing NEs with entity types is not an effective strategy; representing tokens by different embeddings for proper names vs. common nouns does not improve results. We highlight the improvements over state-of-the-art results that our CNN models yield."
N18-3016,Benchmarks and models for entity-oriented polarity detection,2018,0,0,3,1,4349,lidia pivovarova,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Industry Papers)",0,"We address the problem of determining entity-oriented polarity in business news. This can be viewed as classifying the polarity of the sentiment expressed toward a given mention of a company in a news article. We present a complete, end-to-end approach to the problem. We introduce a new dataset of over 17,000 manually labeled documents, which is substantially larger than any currently available resources. We propose a benchmark solution based on convolutional neural networks for classifying entity-oriented polarity. Although our dataset is much larger than those currently available, it is small on the scale of datasets commonly used for training robust neural network models. To compensate for this, we use transfer learning{---}pre-train the model on a much larger dataset, annotated for a related but different classification task, in order to learn a good representation for business text, and then fine-tune it on the smaller polarity dataset."
L18-1644,{R}evita: a Language-learning Platform at the Intersection of {ITS} and {CALL},2018,0,0,3,1,12233,anisia katinskaia,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
W17-1412,"The First Cross-Lingual Challenge on Recognition, Normalization, and Matching of Named Entities in {S}lavic Languages",2017,24,4,5,0,6080,jakub piskorski,Proceedings of the 6th Workshop on {B}alto-{S}lavic Natural Language Processing,0,"This paper describes the outcomes of the first challenge on multilingual named entity recognition that aimed at recognizing mentions of named entities in web documents in Slavic languages, their normalization/lemmatization, and cross-language matching. It was organised in the context of the 6th Balto-Slavic Natural Language Processing Workshop, co-located with the EACL 2017 conference. Although eleven teams signed up for the evaluation, due to the complexity of the task(s) and short time available for elaborating a solution, only two teams submitted results on time. The reported evaluation figures reflect the relatively higher level of complexity of named entity-related tasks in the context of processing texts in Slavic languages. Since the duration of the challenge goes beyond the date of the publication of this paper and updated picture of the participating systems and their corresponding performance can be found on the web page of the challenge."
W17-0304,{R}evita: a system for language learning and supporting endangered languages,2017,13,0,3,1,12233,anisia katinskaia,Proceedings of the joint workshop on {NLP} for Computer Assisted Language Learning and {NLP} for Language Acquisition,0,None
S17-2143,{HCS} at {S}em{E}val-2017 Task 5: Polarity detection in business news using convolutional neural networks,2017,0,2,4,1,4349,lidia pivovarova,Proceedings of the 11th International Workshop on Semantic Evaluation ({S}em{E}val-2017),0,"Task 5 of SemEval-2017 involves fine-grained sentiment analysis on financial microblogs and news. Our solution for determining the sentiment score extends an earlier convolutional neural network for sentiment analysis in several ways. We explicitly encode a focus on a particular company, we apply a data augmentation scheme, and use a larger data collection to complement the small training data provided by the task organizers. The best results were achieved by training a model on an external dataset and then tuning it using the provided training dataset."
E17-1103,Grouping business news stories based on salience of named entities,2017,28,2,5,0,32371,llorencc escoter,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 1, Long Papers",0,"In news aggregation systems focused on broad news domains, certain stories may appear in multiple articles. Depending on the relative importance of the story, the number of versions can reach dozens or hundreds within a day. The text in these versions may be nearly identical or quite different. Linking multiple versions of a story into a single group brings several important benefits to the end-user{--}reducing the cognitive load on the reader, as well as signaling the relative importance of the story. We present a grouping algorithm, and explore several vector-based representations of input documents: from a baseline using keywords, to a method using salience{--}a measure of importance of named entities in the text. We demonstrate that features beyond keywords yield substantial improvements, verified on a manually-annotated corpus of business news stories."
W16-1905,From alignment of etymological data to phylogenetic inference via population genetics,2016,34,2,2,1,30222,javad nouri,Proceedings of the 7th Workshop on Cognitive Aspects of Computational Language Learning,0,"This paper presents a method for linking models for aligning linguistic etymological data with models for phylogenetic inference from population genetics. We begin with a large database of genetically related wordsxe2x80x94sets of cognatesxe2x80x94from languages in a language family. We process the cognate sets to obtain a complete alignment of the data. We use the alignments as input to a model developed for phylogenetic reconstruction in population genetics. This is achieved via a natural novel projection of the linguistic data onto genetic primitives. As a result, we induce phylogenies based on aligned linguistic data. We place the method in the context of those reported in the literature, and illustrate its operation on data from the Uralic language family, which results in family trees that are very close to the xe2x80x9ctruexe2x80x9d (expected) phylogenies."
L16-1495,A Novel Evaluation Method for Morphological Segmentation,2016,0,2,2,1,30222,javad nouri,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Unsupervised learning of morphological segmentation of words in a language, based only on a large corpus of words, is a challenging task. Evaluation of the learned segmentations is a challenge in itself, due to the inherent ambiguity of the segmentation task. There is no way to posit unique {``}correct{''} segmentation for a set of data in an objective way. Two models may arrive at different ways of segmenting the data, which may nonetheless both be valid. Several evaluation methods have been proposed to date, but they do not insist on consistency of the evaluated model. We introduce a new evaluation methodology, which enforces correctness of segmentation boundaries while also assuring consistency of segmentation decisions across the corpus."
K16-1014,Modeling language evolution with codes that utilize context and phonetic features,2016,15,1,2,1,30222,javad nouri,Proceedings of The 20th {SIGNLL} Conference on Computational Natural Language Learning,0,None
W15-5307,Online Extraction of {R}ussian Multiword Expressions,2015,2,0,6,1,36481,mikhail kopotev,The 5th Workshop on {B}alto-{S}lavic Natural Language Processing,0,None
W14-4207,Measuring Language Closeness by Modeling Regularity,2014,15,1,2,1,30222,javad nouri,Proceedings of the {EMNLP}{'}2014 Workshop on Language Technology for Closely Related Languages and Language Variants,0,"This paper addresses the problems of measuring similarity between languagesxe2x80x94 where the term language covers any of the senses denoted by language, dialect or linguistic variety, as defined by any theory. We argue that to devise an effective way to measure the similarity between languages one should build a probabilistic model that tries to capture as much regular correspondence between the languages as possible. This approach yields two benefits. First, given a set of language data, for any two models, this gives a way of objectively determining which model is better, i.e., which model is more likely to be accurate and informative. Second, given a model, for any two languages we can determine, in a principled way, how close they are. The better models will be better at judging similarity. We present experiments on data from three language families to support these ideas. In particular, our results demonstrate the arbitrary nature of terms such as language vs. dialect, when applied to related languages."
W13-5209,Combined analysis of news and {T}witter messages,2013,19,3,5,0,33049,mian du,"Proceedings of the Joint Workshop on {NLP}{\\&}{LOD} and {SWAIE}: Semantic Web, Linked Open Data and Information Extraction",0,"While it is widely recognized that streams of social media messages contain valuable information, such as important trends in the usersxe2x80x99 interest in consumer products and markets, uncovering such trends is problematic, due to the extreme volumes of messages in such media. In the case Twitter messages, following the interest in relation to all known products all the time is technically infeasible. IE narrows topics to search. In this paper, we present experiments on using deeper NLP-based processing of product-related events mentioned in news streams to restrict the volume of tweets that need to be considered, to make the problem more tractable. Our goal is to analyze whether such a combined approach can help reveal correlations and how they may be captured."
W13-2415,Adapting the {PULS} event extraction framework to analyze {R}ussian text,2013,19,2,3,1,4349,lidia pivovarova,Proceedings of the 4th Biennial International Workshop on {B}alto-{S}lavic Natural Language Processing,0,"This paper describes a plug-in component to extend the PULS information extraction framework to analyze Russian-language text. PULS is a comprehensive framework for information extraction (IE) that is used for analysis of news in several scenarios from English-language text and is primarily monolingual. Although monolinguality is recognized as a serious limitation, building an IE system for a new language from the bottom up is very labor-intensive. Thus, the objective of the present work is to explore whether the base framework can be extended to cover additional languages with limited effort, and to leverage the preexisting PULS modules as far as possible, in order to accelerate the development process. The component for Russian analysis is described and its performance is evaluated on two news-analysis scenarios: epidemic surveillance and cross-border security. The approach described in the paper can be generalized to a range of heavilyinflected languages."
W13-1204,Event representation across genre,2013,17,8,3,1,4349,lidia pivovarova,"Workshop on Events: Definition, Detection, Coreference, and Representation",0,"This paper describes an approach for investigating the representation of events and their distribution in a corpus. We collect and analyze statistics about subject-verb-object triplets and their content, which helps us compare corpora belonging to the same domain but to different genre/text type. We argue that event structure is strongly related to the genre of the corpus, and propose statistical properties that are able to capture these genre differences. The results obtained can be used for the improvement of Information Extraction."
W13-1011,Automatic Detection of Stable Grammatical Features in N-Grams,2013,25,1,4,1,36481,mikhail kopotev,Proceedings of the 9th Workshop on Multiword Expressions,0,"This paper presents an algorithm that allows the user to issue a query pattern, collects multi-word expressions (MWEs) that match the pattern, and then ranks them in a uniform fashion. This is achieved by quantifying the strength of all possible relations between the tokens and their features in the MWEs. The algorithm collects the frequency of morphological categories of the given pattern on a unified scale in order to choose the stable categories and their values. For every part of speech, and for all of its categories, we calculate a normalized Kullback-Leibler divergence between the categoryxe2x80x99s distribution in the pattern and its distribution in the corpus overall. Categories with the largest divergence are considered to be the most significant. The particular values of the categories are sorted according to a frequency ratio. As a result, we obtain morphosyntactic profiles of a given pattern, which includes the most stable category of the pattern, and their values."
W12-0215,Using context and phonetic features in models of etymological sound change,2012,18,6,3,1,42568,hannes wettig,Proceedings of the {EACL} 2012 Joint Workshop of {LINGVIS} {\\&} {UNCLH},0,"This paper presents a novel method for aligning etymological data, which models context-sensitive rules governing sound change, and utilizes phonetic features of the sounds. The goal is, for a given corpus of cognate sets, to find the best alignment at the sound level. We introduce an imputation procedure to compare the goodness of the resulting models, as well as the goodness of the data sets. We present evaluations to demonstrate that the new model yields improvements in performance, compared to previously reported models."
W11-4616,Relevance Prediction in Information Extraction using Discourse and Lexical Features,2011,15,6,4,1,41098,silja huttunen,Proceedings of the 18th Nordic Conference of Computational Linguistics ({NODALIDA} 2011),0,"We present on-going work on estimating the relevance of the results of an Information Extraction (IE) system. Our aim is to build a user-oriented measure of utility of the extracted factual information. We describe experiments using discourse-level features, with classifiers that learn from usersxe2x80x99 ratings of relevance of the results. Traditional criteria for evaluating the performance of IE focus on correctness of the extracted information, e.g., in terms of recall, precision and F-measure. We introduce subjective criteria for evaluating the quality of the extracted information: utility of results to the end-user. To measure utility, we use methods from text mining and linguistic analysis to identify features that are good predictors of the relevance of an event or a document to a user. We report on experiments in two real-world news domains: business activity and epidemics of infectious disease."
W11-4634,Probabilistic Models for Alignment of Etymological Data,2011,7,2,2,1,42568,hannes wettig,Proceedings of the 18th Nordic Conference of Computational Linguistics ({NODALIDA} 2011),0,"This paper introduces several models for aligning etymological data, or for finding the best alignment at the sound or symbol level, given a set of etymological data. This will provide us a means of measuring the quality of the etymological data sets in terms of their internal consistency. Since one of our main goals is to devise automatic methods for aligning the data that are as objective as possible, the models make no a priori assumptionsxe2x80x94e.g., no preference for vowel-vowel or consonantconsonant alignments. We present a baseline model and successive improvements, using data from Uralic language family."
R11-1016,{MDL}-based Models for Alignment of Etymological Data,2011,13,7,3,1,42568,hannes wettig,Proceedings of the International Conference Recent Advances in Natural Language Processing 2011,0,"We introduce several models for alignment of etymological data, that is, for finding the best alignment, given a set of etymological data, at the sound or symbol level. This is intended to obtain a means of measuring the quality of the etymological data sets, in terms of their internal consistency. One of our main goals is to devise automatic methods for aligning the data that are as objective as possible, the models make no a priori assumptionsxe2x80x94e.g., no preference for vowel-vowel or consonant-consonant alignments. We present a baseline model and several successive improvements, using data from the Uralic language family."
W10-4003,Filtering news for epidemic surveillance: towards processing more languages with fewer resources,2010,10,7,3,0,587,gael lejeune,Proceedings of the 4th Workshop on Cross Lingual Information Access,0,"Processing content for security becomes more and more important since every local danger can have global consequences. Being able to collect and analyse information in dierent languages is a great issue. This paper addresses multilingual solutions for analysis of press articles for epidemiological surveillance. The system described here relies on pragmatics and stylistics, giving up xe2x80x9cbag of sentencesxe2x80x9d approach in favour of discourse repetition patterns. It only needs light resources (compared to existing systems) in order to process new languages easily. In this paper we present here results in English, French and Chinese, three languages with quite dierent characteristics. These results show that simple rules allow selection of relevant documents in a specialized database improving the reliability of information extraction."
W10-1105,Assessment of Utility in Web Mining for the Domain of Public Health,2010,12,18,5,0,43981,peter etter,Proceedings of the {NAACL} {HLT} 2010 Second Louhi Workshop on Text and Data Mining of Health Documents,0,"This paper presents ongoing work on application of Information Extraction (IE) technology to domain of Public Health, in a real-world scenario. A central issue in IE is the quality of the results. We present two novel points. First, we distinguish the criteria for quality: the objective criteria that measure correctness of the system's analysis in traditional terms (F-measure, recall and precision), and, on the other hand, subjective criteria that measure the utility of the results to the end-user.n n Second, to obtain measures of utility, we build an environment that allows users to interact with the system by rating the analyzed content. We then build and compare several classifiers that learn from the user's responses to predict the relevance scores for new events. We conduct experiments with learning to predict relevance, and discuss the results and their implications for text mining in the domain of Public Health."
H05-2012,Extracting Information about Outbreaks of Infectious Epidemics,2005,6,19,1,1,12064,roman yangarber,Proceedings of {HLT}/{EMNLP} 2005 Interactive Demonstrations,0,"This work demonstrates the ProMED-PLUS Epidemiological Fact Base. The facts are automatically extracted from plain-text reports about outbreaks of infectious epidemics around the world. The system collects new reports, extracts new facts, and updates the database, in real time. The extracted database is available on-line through a Web server."
H05-1008,Redundancy-based Correction of Automatically Extracted Facts,2005,9,17,1,1,12064,roman yangarber,Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing,0,"The accuracy of event extraction is limited by a number of complicating factors, with errors compounded at all sages inside the Information Extraction pipeline. In this paper, we present methods for recovering automatically from errors committed in the pipeline processing. Recovery is achieved via post-processing facts aggregated over a large collection of documents, and suggesting corrections based on evidence external to the document. A further improvement is derived from propagating multiple, locally non-best slot fills through the pipeline. Evaluation shows that the global analysis is over 10 times more likely to suggest valid corrections to the local-only analysis than it is to suggest erroneous ones. This yields a substantial overall gain, with no supervised training."
P03-1044,Counter-Training in Discovery of Semantic Patterns,2003,10,118,1,1,12064,roman yangarber,Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,1,"This paper presents a method for unsupervised discovery of semantic patterns. Semantic patterns are useful for a variety of text understanding tasks, in particular for locating events in text for information extraction. The method builds upon previously described approaches to iterative unsupervised pattern acquisition. One common characteristic of prior approaches is that the output of the algorithm is a continuous stream of patterns, with gradually degrading precision.Our method differs from the previous pattern acquisition algorithms in that it introduces competition among several scenarios simultaneously. This provides natural stopping criteria for the unsupervised learners, while maintaining good precision levels at termination. We discuss the results of experiments with several scenarios, and examine different aspects of the new procedure."
huttunen-etal-2002-diversity,Diversity of Scenarios in Information extraction,2002,9,17,2,1,41098,silja huttunen,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,None
C02-1154,Unsupervised Learning of Generalized Names,2002,14,95,1,1,12064,roman yangarber,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"We present an algorithm, NOMEN, for learning generalized names in text. Examples of these are names of diseases and infectious agents, such as bacteria and viruses. These names exhibit certain properties that make their identification more complex than that of regular proper names, NOMEN uses a novel form of bootstrapping to grow sets of textual instances and of their contextual patterns. The algorithm makes use of competing evidence to boost the learning of several categories of names simultaneously. We present results of the algorithm on a large corpus. We also investigate the relative merits of several evaluation strategies."
C02-1165,Complexity of Event Structure in {IE} Scenarios,2002,10,19,2,1,41098,silja huttunen,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"This paper presents new Information Extraction scenarios which are linguistically and structurally more challenging than the traditional MUC scenarios. Traditional views on event structure and template design are not adequate for the more complex scenarios.The focus of this paper is to show the complexity of the scenarios, and propose a way to recover the structure of the event. First we identify two structural factors that contribute to the complexity of scenarios: the scattering of events in text, and inclusion relationships between events. These factors cause difficulty in representing the facts in an unambiguous way. Then we propose a modular, hierarchical representation where the information is split in atomic units represented by templates, and where the inclusion relationships between the units are indicated by links. Lastly, we discuss how we may recover this representation from text, with the help of linguistic cues linking the events."
C00-2136,Automatic Acquisition of Domain Knowledge for Information Extraction,2000,10,187,1,1,12064,roman yangarber,{COLING} 2000 Volume 2: The 18th International Conference on Computational Linguistics,0,"In developing an Information Extraction (IE) system for a new class of events or relations, one of the major tasks is identifying the many ways in which these events or relations may be expressed in text. This has generally involved the manual analysis and, in some cases, the annotation of large quantities of text involving these events. This paper presents an alternative approach, based on an automatic discovery procedure, EXDISCO, which identifies a set of relevant documents and a set of event patterns from un-annotaled text, starting from a small set of seed patterns. We evaluate EXDISCO by comparing the performance of discovered patterns against that of manually constructed systems on actual extraction tasks."
A00-1039,Unsupervised Discovery of Scenario-Level Patterns for Information Extraction,2000,15,92,1,1,12064,roman yangarber,Sixth Applied Natural Language Processing Conference,0,"Information Extraction (IE) systems are commonly based on pattern matching. Adapting an IE system to a new scenario entails the construction of a new pattern base---a time-consuming and expensive process. We have implemented a system for finding patterns automatically from un-annotated text. Starting with a small initial set of seed patterns proposed by the user, the system applies an incremental discovery procedure to identify new patterns. We present experiments with evaluations which show that the resulting patterns exhibit high precision and recall."
X98-1015,{J}apanese {IE} System and Customization Tool,1998,-1,-1,3,0,51944,chikashi nobata,"TIPSTER TEXT PROGRAM PHASE III: Proceedings of a Workshop held at Baltimore, {M}aryland, October 13-15, 1998",0,None
X98-1016,Transforming Examples into Patterns for Information Extraction,1998,10,6,1,1,12064,roman yangarber,"TIPSTER TEXT PROGRAM PHASE III: Proceedings of a Workshop held at Baltimore, {M}aryland, October 13-15, 1998",0,"Information Extraction (IE) systems today are commonly based on pattern matching. The patterns are regular expressions stored in a customizable knowledge base. Adapting an IE system to a new subject domain entails the construction of a new pattern base --- a time-consuming and expensive task. We describe a strategy for building patterns from examples. To adapt the IE system to a new domain quickly, the user chooses a set of examples in a training text, and for each example gives the logical form entries which the example induces. The system transforms these examples into patterns and then applies meta-rules to generalize these patterns."
W98-0604,Using {NOMLEX} to Produce Nominalization Patterns for Information Extraction,1998,9,33,3,0,3082,adam meyers,The Computational Treatment of Nominals,0,None
P98-2139,Deriving Transfer Rules from Dominance-Preserving Alignments,1998,9,24,2,0,3082,adam meyers,"36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 2",0,None
M98-1011,{NYU}: Description of the Proteus/{PET} System as Used for {MUC}-7 {ST},1998,0,70,1,1,12064,roman yangarber,"Seventh Message Understanding Conference ({MUC}-7): Proceedings of a Conference Held in Fairfax, Virginia, {A}pril 29 - May 1, 1998",0,None
C98-2134,Deriving Transfer Rules from Dominance-Preserving Alignments,1998,9,24,2,0,3082,adam meyers,{COLING} 1998 Volume 2: The 17th International Conference on Computational Linguistics,0,None
C96-1078,Alignment of Shared Forests for Bilingual Corpora,1996,14,56,2,0,3082,adam meyers,{COLING} 1996 Volume 1: The 16th International Conference on Computational Linguistics,0,"Research in example-based machine translation (EBMT) has been hampered by the lack of efficient tree alignment algorithms for bilingual corpora. This paper describes an alignment algorithm for EBMT whose running time is quadratic in the size of the input parse trees. The algorithm uses dynamic programming to score all possible matching nodes between structure-sharing trees or forests. We describe the algorithm, various optimizations, and our implementation."
