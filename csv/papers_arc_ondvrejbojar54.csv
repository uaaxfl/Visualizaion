2021.wat-1.1,Overview of the 8th Workshop on {A}sian Translation,2021,-1,-1,11,0,283,toshiaki nakazawa,Proceedings of the 8th Workshop on Asian Translation (WAT2021),0,"This paper presents the results of the shared tasks from the 8th workshop on Asian translation (WAT2021). For the WAT2021, 28 teams participated in the shared tasks and 24 teams submitted their translation results for the human evaluation. We also accepted 5 research papers. About 2,100 translation results were submitted to the automatic evaluation server, and selected submissions were manually evaluated."
2021.wat-1.16,{NLPH}ut{'}s Participation at {WAT}2021,2021,-1,-1,8,1,291,shantipriya parida,Proceedings of the 8th Workshop on Asian Translation (WAT2021),0,"This paper provides the description of shared tasks to the WAT 2021 by our team {``}NLPHut{''}. We have participated in the EnglishâHindi Multimodal translation task, EnglishâMalayalam Multimodal translation task, and Indic Multi-lingual translation task. We have used the state-of-the-art Transformer model with language tags in different settings for the translation task and proposed a novel {``}region-specific{''} caption generation approach using a combination of image CNN and LSTM for the Hindi and Malayalam image captioning. Our submission tops in EnglishâMalayalam Multimodal translation task (text-only translation, and Malayalam caption), and ranks second-best in EnglishâHindi Multimodal translation task (text-only translation, and Hindi caption). Our submissions have also performed well in the Indic Multilingual translation tasks."
2021.naacl-main.14,"Backtranslation Feedback Improves User Confidence in {MT}, Not Quality",2021,-1,-1,4,1,3171,vilem zouhar,Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"Translating text into a language unknown to the text{'}s author, dubbed outbound translation, is a modern need for which the user experience has significant room for improvement, beyond the basic machine translation facility. We demonstrate this by showing three ways in which user confidence in the outbound translation, as well as its overall final quality, can be affected: backward translation, quality estimation (with alignment) and source paraphrasing. In this paper, we describe an experiment on outbound translation from English to Czech and Estonian. We examine the effects of each proposed feedback module and further focus on how the quality of machine translation systems influence these findings and the user perception of success. We show that backward translation feedback has a mixed effect on the whole process: it increases user confidence in the produced translation, but not the objective quality."
2021.mtsummit-asltrw.3,Operating a Complex {SLT} System with Speakers and Human Interpreters,2021,-1,-1,1,1,292,ondvrej bojar,Proceedings of the 1st Workshop on Automatic Spoken Language Translation in Real-World Settings (ASLTRW),0,"We describe our experience with providing automatic simultaneous spoken language translation for an event with human interpreters. We provide a detailed overview of the systems we use, focusing on their interconnection and the issues it brings. We present our tools to monitor the pipeline and a web application to present the results of our SLT pipeline to the end users. Finally, we discuss various challenges we encountered, their possible solutions and we suggest improvements for future deployments."
2021.iwslt-1.1,{FINDINGS} {OF} {THE} {IWSLT} 2021 {EVALUATION} {CAMPAIGN},2021,-1,-1,2,0,832,antonios anastasopoulos,Proceedings of the 18th International Conference on Spoken Language Translation (IWSLT 2021),0,"The evaluation campaign of the International Conference on Spoken Language Translation (IWSLT 2021) featured this year four shared tasks: (i) Simultaneous speech translation, (ii) Offline speech translation, (iii) Multilingual speech translation, (iv) Low-resource speech translation. A total of 22 teams participated in at least one of the tasks. This paper describes each shared task, data and evaluation metrics, and reports results of the received submissions."
2021.humeval-1.13,Detecting Post-Edited References and Their Effect on Human Evaluation,2021,-1,-1,2,0,6020,vvera kloudova,Proceedings of the Workshop on Human Evaluation of NLP Systems (HumEval),0,"This paper provides a quick overview of possible methods how to detect that reference translations were actually created by post-editing an MT system. Two methods based on automatic metrics are presented: BLEU difference between the suspected MT and some other good MT and BLEU difference using additional references. These two methods revealed a suspicion that the WMT 2020 Czech reference is based on MT. The suspicion was confirmed in a manual analysis by finding concrete proofs of the post-editing procedure in particular sentences. Finally, a typology of post-editing changes is presented where typical errors or changes made by the post-editor or errors adopted from the MT are classified."
2021.eval4nlp-1.24,Explainable Quality Estimation: {CUNI} {E}val4{NLP} Submission,2021,-1,-1,3,1,8624,peter polak,Proceedings of the 2nd Workshop on Evaluation and Comparison of NLP Systems,0,None
2021.emnlp-main.650,Sequence Length is a Domain: Length-based Overfitting in Transformer Models,2021,-1,-1,2,0,9954,dusan varis,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"Transformer-based sequence-to-sequence architectures, while achieving state-of-the-art results on a large number of NLP tasks, can still suffer from overfitting during training. In practice, this is usually countered either by applying regularization methods (e.g. dropout, L2-regularization) or by providing huge amounts of training data. Additionally, Transformer and other architectures are known to struggle when generating very long sequences. For example, in machine translation, the neural-based systems perform worse on very long sequences when compared to the preceding phrase-based translation approaches (Koehn and Knowles, 2017). We present results which suggest that the issue might also be in the mismatch between the length distributions of the training and validation data combined with the aforementioned tendency of the neural networks to overfit to the training data. We demonstrate on a simple string editing tasks and a machine translation task that the Transformer model performance drops significantly when facing sequences of length diverging from the length distribution in the training data. Additionally, we show that the observed drop in performance is due to the hypothesis length corresponding to the lengths seen by the model during training rather than the length of the input sequence."
2021.emnlp-main.801,Neural Machine Translation Quality and Post-Editing Performance,2021,-1,-1,3,1,3171,vilem zouhar,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"We test the natural expectation that using MT in professional translation saves human processing time. The last such study was carried out by Sanchez-Torron and Koehn (2016) with phrase-based MT, artificially reducing the translation quality. In contrast, we focus on neural MT (NMT) of high quality, which has become the state-of-the-art approach since then and also got adopted by most translation companies. Through an experimental study involving over 30 professional translators for English -{\textgreater} Czech translation, we examine the relationship between NMT performance and post-editing time and quality. Across all models, we found that better MT systems indeed lead to fewer changes in the sentences in this industry setting. The relation between system quality and post-editing time is however not straightforward and, contrary to the results on phrase-based MT, BLEU is definitely not a stable predictor of the time or final output quality."
2021.eacl-demos.9,{SLTEV}: Comprehensive Evaluation of Spoken Language Translation,2021,-1,-1,2,1,11026,ebrahim ansari,Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations,0,"Automatic evaluation of Machine Translation (MT) quality has been investigated over several decades. Spoken Language Translation (SLT), esp. when simultaneous, needs to consider additional criteria and does not have a standard evaluation procedure and a widely used toolkit. To fill the gap, we develop SLTev, an open-source tool for assessing SLT in a comprehensive way. SLTev reports the quality, latency, and stability of an SLT candidate output based on the time-stamped transcript and reference translation into a target language. For quality, we rely on sacreBLEU which provides MT evaluation measures such as chrF or BLEU. For latency, we propose two new scoring techniques. For stability, we extend the previously defined measures with a normalized Flicker in our work. We also propose a new averaging of older measures. A preliminary version of SLTev was used in the IWSLT 2020 shared task. Moreover, a growing collection of test datasets directly accessible by SLTev are provided for system evaluation comparable across papers."
2021.eacl-demos.32,{ELITR} Multilingual Live Subtitling: Demo and Strategy,2021,-1,-1,1,1,292,ondvrej bojar,Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations,0,"This paper presents an automatic speech translation system aimed at live subtitling of conference presentations. We describe the overall architecture and key processing components. More importantly, we explain our strategy for building a complex system for end-users from numerous individual components, each of which has been tested only in laboratory conditions. The system is a working prototype that is routinely tested in recognizing English, Czech, and German speech and presenting it translated simultaneously into 42 target languages."
2021.acl-long.311,End-to-End Lexically Constrained Machine Translation for Morphologically Rich Languages,2021,-1,-1,4,0,5173,josef jon,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),1,"Lexically constrained machine translation allows the user to manipulate the output sentence by enforcing the presence or absence of certain words and phrases. Although current approaches can enforce terms to appear in the translation, they often struggle to make the constraint word form agree with the rest of the generated output. Our manual analysis shows that 46{\%} of the errors in the output of a baseline constrained model for English to Czech translation are related to agreement. We investigate mechanisms to allow neural machine translation to infer the correct word inflection given lemmatized constraints. In particular, we focus on methods based on training the model with constraints provided as part of the input sequence. Our experiments on English-Czech language pair show that this approach improves translation of constrained terms in both automatic and manual evaluation by reducing errors in agreement. Our approach thus eliminates inflection errors, without introducing new errors or decreasing overall quality of the translation."
2020.wmt-1.1,Findings of the 2020 Conference on Machine Translation ({WMT}20),2020,-1,-1,3,0,8740,loic barrault,Proceedings of the Fifth Conference on Machine Translation,0,"This paper presents the results of the news translation task and the similar language translation task, both organised alongside the Conference on Machine Translation (WMT) 2020. In the news task, participants were asked to build machine translation systems for any of 11 language pairs, to be evaluated on test sets consisting mainly of news stories. The task was also opened up to additional test suites to probe specific aspects of translation. In the similar language translation task, participants built machine translation systems for translating between closely related pairs of languages."
2020.wmt-1.41,{WMT}20 Document-Level Markable Error Exploration,2020,-1,-1,3,1,3171,vilem zouhar,Proceedings of the Fifth Conference on Machine Translation,0,"Even though sentence-centric metrics are used widely in machine translation evaluation, document-level performance is at least equally important for professional usage. In this paper, we bring attention to detailed document-level evaluation focused on markables (expressions bearing most of the document meaning) and the negative impact of various markable error phenomena on the translation. For an annotation experiment of two phases, we chose Czech and English documents translated by systems submitted to WMT20 News Translation Task. These documents are from the News, Audit and Lease domains. We show that the quality and also the kind of errors varies significantly among the domains. This systematic variance is in contrast to the automatic evaluation results. We inspect which specific markables are problematic for MT systems and conclude with an analysis of the effect of markable error types on the MT performance measured by humans and automatic evaluation tools."
2020.wmt-1.77,Results of the {WMT}20 Metrics Shared Task,2020,-1,-1,5,0,13911,nitika mathur,Proceedings of the Fifth Conference on Machine Translation,0,"This paper presents the results of the WMT20 Metrics Shared Task. Participants were asked to score the outputs of the translation systems competing in the WMT20 News Translation Task with automatic metrics. Ten research groups submitted 27 metrics, four of which are reference-less {``}metrics{''}. In addition, we computed five baseline metrics, including sentBLEU, BLEU, TER and using the SacreBLEU scorer. All metrics were evaluated on how well they correlate at the system-, document- and segment-level with the WMT20 official human scores. We present an extensive analysis on influence of different reference translations on metric reliability, how well automatic metrics score human translations, and we also flag major discrepancies between metric and human scores when evaluating MT systems. Finally, we investigate whether we can use automatic metrics to flag incorrect human ratings."
2020.wmt-1.133,{CUNI} Systems for the Unsupervised and Very Low Resource Translation Task in {WMT}20,2020,-1,-1,3,1,13979,ivana kvapilikova,Proceedings of the Fifth Conference on Machine Translation,0,"This paper presents a description of CUNI systems submitted to the WMT20 task on unsupervised and very low-resource supervised machine translation between German and Upper Sorbian. We experimented with training on synthetic data and pre-training on a related language pair. In the fully unsupervised scenario, we achieved 25.5 and 23.7 BLEU translating from and into Upper Sorbian, respectively. Our low-resource systems relied on transfer learning from German-Czech parallel data and achieved 57.4 BLEU and 56.1 BLEU, which is an improvement of 10 BLEU points over the baseline trained only on the available small German-Upper Sorbian parallel corpus."
2020.wildre-1.3,{O}di{E}n{C}orp 2.0: {O}dia-{E}nglish Parallel Corpus for Machine Translation,2020,-1,-1,3,1,291,shantipriya parida,Proceedings of the WILDRE5{--} 5th Workshop on Indian Language Data: Resources and Evaluation,0,"The preparation of parallel corpora is a challenging task, particularly for languages that suffer from under-representation in the digital world. In a multi-lingual country like India, the need for such parallel corpora is stringent for several low-resource languages. In this work, we provide an extended English-Odia parallel corpus, OdiEnCorp 2.0, aiming particularly at Neural Machine Translation (NMT) systems which will help translate EnglishâOdia. OdiEnCorp 2.0 includes existing English-Odia corpora and we extended the collection by several other methods of data acquisition: parallel data scraping from many websites, including Odia Wikipedia, but also optical character recognition (OCR) to extract parallel data from scanned images. Our OCR-based data extraction approach for building a parallel corpus is suitable for other low resource languages that lack in online content. The resulting OdiEnCorp 2.0 contains 98,302 sentences and 1.69 million English and 1.47 million Odia tokens. To the best of our knowledge, OdiEnCorp 2.0 is the largest Odia-English parallel corpus covering different domains and available freely for non-commercial and research purposes."
2020.wat-1.1,Overview of the 7th Workshop on {A}sian Translation,2020,-1,-1,11,0,283,toshiaki nakazawa,Proceedings of the 7th Workshop on Asian Translation,0,"This paper presents the results of the shared tasks from the 7th workshop on Asian translation (WAT2020). For the WAT2020, 20 teams participated in the shared tasks and 14 teams submitted their translation results for the human evaluation. We also received 12 research paper submissions out of which 7 were accepted. About 500 translation results were submitted to the automatic evaluation server, and selected submissions were manually evaluated."
2020.wat-1.10,{ODIANLP}{'}s Participation in {WAT}2020,2020,-1,-1,9,1,291,shantipriya parida,Proceedings of the 7th Workshop on Asian Translation,0,"This paper describes the ODIANLP submission to WAT 2020. We have participated in the English-Hindi Multimodal task and Indic task. We have used the state-of-the-art Transformer model for the translation task and InceptionResNetV2 for the Hindi Image Captioning task. Our submission tops in English-{\textgreater}Hindi Multimodal task in its track and Odia{\textless}-{\textgreater}English translation tasks. Also, our submissions performed well in the Indic Multilingual tasks."
2020.lrec-1.434,{COSTRA} 1.0: A Dataset of Complex Sentence Transformations,2020,-1,-1,2,0,17431,petra barancikova,Proceedings of the 12th Language Resources and Evaluation Conference,0,"We present COSTRA 1.0, a dataset of complex sentence transformations. The dataset is intended for the study of sentence-level embeddings beyond simple word alternations or standard paraphrasing. This first version of the dataset is limited to sentences in Czech but the construction method is universal and we plan to use it also for other languages. The dataset consist of 4,262 unique sentences with average length of 10 words, illustrating 15 types of modifications such as simplification, generalization, or formal and informal language variation. The hope is that with this dataset, we should be able to test semantic properties of sentence embeddings and perhaps even to find some topologically interesting {``}skeleton{''} in the sentence embedding space. A preliminary analysis using LASER, multi-purpose multi-lingual sentence embeddings suggests that the LASER space does not exhibit the desired properties."
2020.lrec-1.823,Two Huge Title and Keyword Generation Corpora of Research Articles,2020,48,0,2,1,18259,erion ccano,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Recent developments in sequence-to-sequence learning with neural networks have considerably improved the quality of automatically generated text summaries and document keywords, stipulating the need for even bigger training corpora. Metadata of research articles are usually easy to find online and can be used to perform research on various tasks. In this paper, we introduce two huge datasets for text summarization (OAGSX) and keyword generation (OAGKX) research, containing 34 million and 23 million records, respectively. The data were retrieved from the Open Academic Graph which is a network of research profiles and publications. We carefully processed each record and also tried several extractive and abstractive methods of both tasks to create performance baselines for other researchers. We further illustrate the performance of those methods previewing their outputs. In the near future, we would like to apply topic modeling on the two sets to derive subsets of research articles from more specific disciplines."
2020.lrec-1.860,Outbound Translation User Interface Ptakop{\\v{e}}t: A Pilot Study,2020,-1,-1,2,1,3171,vilem zouhar,Proceedings of the 12th Language Resources and Evaluation Conference,0,"It is not uncommon for Internet users to have to produce a text in a foreign language they have very little knowledge of and are unable to verify the translation quality. We call the task {``}outbound translation{''} and explore it by introducing an open-source modular system Ptakop{\v{e}}t. Its main purpose is to inspect human interaction with MT systems enhanced with additional subsystems, such as backward translation and quality estimation. We follow up with an experiment on (Czech) human annotators tasked to produce questions in a language they do not speak (German), with the help of Ptakop{\v{e}}t. We focus on three real-world use cases (communication with IT support, describing administrative issues and asking encyclopedic questions) from which we gain insight into different strategies users take when faced with outbound translation tasks. Round trip translation is known to be unreliable for evaluating MT systems but our experimental evaluation documents that it works very well for users, at least on MT systems of mid-range quality."
2020.iwslt-1.1,{FINDINGS} {OF} {THE} {IWSLT} 2020 {EVALUATION} {CAMPAIGN},2020,-1,-1,4,1,11026,ebrahim ansari,Proceedings of the 17th International Conference on Spoken Language Translation,0,"The evaluation campaign of the International Conference on Spoken Language Translation (IWSLT 2020) featured this year six challenge tracks: (i) Simultaneous speech translation, (ii) Video speech translation, (iii) Offline speech translation, (iv) Conversational speech translation, (v) Open domain translation, and (vi) Non-native speech translation. A total of teams participated in at least one of the tracks. This paper introduces each track{'}s goal, data and evaluation metrics, and reports the results of the received submissions."
2020.iwslt-1.24,{CUNI} Neural {ASR} with Phoneme-Level Intermediate Step for{\\textasciitilde}{N}on-{N}ative{\\textasciitilde}{SLT} at {IWSLT} 2020,2020,-1,-1,4,1,8624,peter polak,Proceedings of the 17th International Conference on Spoken Language Translation,0,"In this paper, we present our submission to the Non-Native Speech Translation Task for IWSLT 2020. Our main contribution is a proposed speech recognition pipeline that consists of an acoustic model and a phoneme-to-grapheme model. As an intermediate representation, we utilize phonemes. We demonstrate that the proposed pipeline surpasses commercially used automatic speech recognition (ASR) and submit it into the ASR track. We complement this ASR with off-the-shelf MT systems to take part also in the speech translation track."
2020.iwslt-1.25,{ELITR} Non-Native Speech Translation at {IWSLT} 2020,2020,-1,-1,5,1,11115,dominik machavcek,Proceedings of the 17th International Conference on Spoken Language Translation,0,"This paper is an ELITR system submission for the non-native speech translation task at IWSLT 2020. We describe systems for offline ASR, real-time ASR, and our cascaded approach to offline SLT and real-time SLT. We select our primary candidates from a pool of pre-existing systems, develop a new end-to-end general ASR system, and a hybrid ASR trained on non-native speech. The provided small validation set prevents us from carrying out a complex validation, but we submit all the unselected candidates for contrastive evaluation on the test set."
2020.iwltp-1.7,Removing {E}uropean Language Barriers with Innovative Machine Translation Technology,2020,-1,-1,14,0,11118,dario franceschini,Proceedings of the 1st International Workshop on Language Technology Platforms,0,"This paper presents our progress towards deploying a versatile communication platform in the task of highly multilingual live speech translation for conferences and remote meetings live subtitling. The platform has been designed with a focus on very low latency and high flexibility while allowing research prototypes of speech and text processing tools to be easily connected, regardless of where they physically run. We outline our architecture solution and also briefly compare it with the ELG platform. Technical details are provided on the most important components and we summarize the test deployment events we ran so far."
2020.eamt-1.3,Efficiently Reusing Old Models Across Languages via Transfer Learning,2020,-1,-1,2,1,6018,tom kocmi,Proceedings of the 22nd Annual Conference of the European Association for Machine Translation,0,"Recent progress in neural machine translation (NMT) is directed towards larger neural networks trained on an increasing amount of hardware resources. As a result, NMT models are costly to train, both financially, due to the electricity and hardware cost, and environmentally, due to the carbon footprint. It is especially true in transfer learning for its additional cost of training the {``}parent{''} model before transferring knowledge and training the desired {``}child{''} model. In this paper, we propose a simple method of re-using an already trained model for different language pairs where there is no need for modifications in model architecture. Our approach does not need a separate parent model for each investigated language pair, as it is typical in NMT transfer learning. To show the applicability of our method, we recycle a Transformer model trained by different researchers and use it to seed models for different language pairs. We achieve better translation quality and shorter convergence times than when training from random initialization."
2020.eamt-1.53,{ELITR}: {E}uropean Live Translator,2020,-1,-1,1,1,292,ondvrej bojar,Proceedings of the 22nd Annual Conference of the European Association for Machine Translation,0,"ELITR (European Live Translator) project aims to create a speech translation system for simultaneous subtitling of conferences and online meetings targetting up to 43 languages. The technology is tested by the Supreme Audit Office of the Czech Republic and by alfaviewÂ®, a German online conferencing system. Other project goals are to advance document-level and multilingual machine translation, automatic speech recognition, and automatic minuting."
2020.acl-srw.34,Unsupervised Multilingual Sentence Embeddings for Parallel Corpus Mining,2020,-1,-1,5,1,13979,ivana kvapilikova,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop,0,"Existing models of multilingual sentence embeddings require large parallel data resources which are not available for low-resource languages. We propose a novel unsupervised method to derive multilingual sentence embeddings relying only on monolingual data. We first produce a synthetic parallel corpus using unsupervised machine translation, and use it to fine-tune a pretrained cross-lingual masked language model (XLM) to derive the multilingual sentence representations. The quality of the representations is evaluated on two parallel corpus mining tasks with improvements of up to 22 F1 points over vanilla XLM. In addition, we observe that a single synthetic bilingual corpus is able to improve results for other language pairs."
W19-8630,Efficiency Metrics for Data-Driven Models: A Text Summarization Case Study,2019,32,0,2,1,18259,erion ccano,Proceedings of the 12th International Conference on Natural Language Generation,0,"Using data-driven models for solving text summarization or similar tasks has become very common in the last years. Yet most of the studies report basic accuracy scores only, and nothing is known about the ability of the proposed models to improve when trained on more data. In this paper, we define and propose three data efficiency metrics: data score efficiency, data time deficiency and overall data efficiency. We also propose a simple scheme that uses those metrics and apply it for a more comprehensive evaluation of popular methods on text summarization and title generation tasks. For the latter task, we process and release a huge collection of 35 million abstract-title pairs from scientific articles. Our results reveal that among the tested models, the Transformer is the most efficient on both tasks."
W19-5301,Findings of the 2019 Conference on Machine Translation ({WMT}19),2019,0,50,2,0,8740,loic barrault,"Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",0,"This paper presents the results of the premier shared task organized alongside the Conference on Machine Translation (WMT) 2019. Participants were asked to build machine translation systems for any of 18 language pairs, to be evaluated on a test set of news stories. The main metric for this task is human judgment of translation quality. The task was also opened up to additional test suites to probe specific aspects of translation."
W19-5302,Results of the {WMT}19 Metrics Shared Task: Segment-Level and Strong {MT} Systems Pose Big Challenges,2019,0,12,3,1,13912,qingsong ma,"Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",0,"This paper presents the results of the WMT19 Metrics Shared Task. Participants were asked to score the outputs of the translations systems competing in the WMT19 News Translation Task with automatic metrics. 13 research groups submitted 24 metrics, 10 of which are reference-less {``}metrics{''} and constitute submissions to the joint task with WMT19 Quality Estimation Task, {``}QE as a Metric{''}. In addition, we computed 11 baseline metrics, with 8 commonly applied baselines (BLEU, SentBLEU, NIST, WER, PER, TER, CDER, and chrF) and 3 reimplementations (chrF+, sacreBLEU-BLEU, and sacreBLEU-chrF). Metrics were evaluated on the system level, how well a given metric correlates with the WMT19 official manual ranking, and segment level, how well the metric correlates with human judgements of segment quality. This year, we use direct assessment (DA) as our only form of manual evaluation."
W19-5322,{CUNI} Submission for Low-Resource Languages in {WMT} News 2019,2019,0,2,2,1,6018,tom kocmi,"Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",0,"This paper describes the CUNI submission to the WMT 2019 News Translation Shared Task for the low-resource languages: Gujarati-English and Kazakh-English. We participated in both language pairs in both translation directions. Our system combines transfer learning from a different high-resource language pair followed by training on backtranslated monolingual data. Thanks to the simultaneous training in both directions, we can iterate the backtranslation process. We are using the Transformer model in a constrained submission."
W19-5323,{CUNI} Systems for the Unsupervised News Translation Task in {WMT} 2019,2019,17,1,3,1,13979,ivana kvapilikova,"Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",0,"In this paper we describe the CUNI translation system used for the unsupervised news shared task of the ACL 2019 Fourth Conference on Machine Translation (WMT19). We follow the strategy of Artetxe ae at. (2018b), creating a seed phrase-based system where the phrase table is initialized from cross-lingual embedding mappings trained on monolingual data, followed by a neural machine translation system trained on synthetic parallel data. The synthetic corpus was produced from a monolingual corpus by a tuned PBMT model refined through iterative back-translation. We further focus on the handling of named entities, i.e. the part of vocabulary where the cross-lingual embedding mapping suffers most. Our system reaches a BLEU score of 15.3 on the German-Czech WMT19 shared task."
W19-5337,{E}nglish-{C}zech Systems in {WMT}19: Document-Level Transformer,2019,15,1,4,0.491287,227,martin popel,"Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",0,"We describe our NMT systems submitted to the WMT19 shared task in EnglishâCzech news translation. Our systems are based on the Transformer model implemented in either Tensor2Tensor (T2T) or Marian framework. We aimed at improving the adequacy and coherence of translated documents by enlarging the context of the source and target. Instead of translating each sentence independently, we split the document into possibly overlapping multi-sentence segments. In case of the T2T implementation, this {``}document-level{''}-trained system achieves a +0.6 BLEU improvement (p {\textless} 0.05) relative to the same system applied on isolated sentences. To assess the potential effect document-level models might have on lexical coherence, we performed a semi-automatic analysis, which revealed only a few sentences improved in this aspect. Thus, we cannot draw any conclusions from this week evidence."
W19-5352,A Test Suite and Manual Evaluation of Document-Level {NMT} at {WMT}19,2019,14,0,5,0,16887,katevrina rysova,"Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",0,"As the quality of machine translation rises and neural machine translation (NMT) is moving from sentence to document level translations, it is becoming increasingly difficult to evaluate the output of translation systems. We provide a test suite for WMT19 aimed at assessing discourse phenomena of MT systems participating in the News Translation Task. We have manually checked the outputs and identified types of translation errors that are relevant to document-level translation."
W19-5355,{SAO} {WMT}19 Test Suite: Machine Translation of Audit Reports,2019,8,0,4,0,13864,tereza vojtvechova,"Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",0,"This paper describes a machine translation test set of documents from the auditing domain and its use as one of the {``}test suites{''} in the WMT19 News Translation Task for translation directions involving Czech, English and German. Our evaluation suggests that current MT systems optimized for the general news domain can perform quite well even in the particular domain of audit reports. The detailed manual evaluation however indicates that deep factual knowledge of the domain is necessary. For the naked eye of a non-expert, translations by many systems seem almost perfect and automatic MT evaluation with one reference is practically useless for considering these details. Furthermore, we show on a sample document from the domain of agreements that even the best systems completely fail in preserving the semantics of the agreement, namely the identity of the parties."
P19-2017,Unsupervised Pretraining for Neural Machine Translation Using Elastic Weight Consolidation,2019,0,0,2,1,25495,duvsan varivs,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop,0,"This work presents our ongoing research of unsupervised pretraining in neural machine translation (NMT). In our method, we initialize the weights of the encoder and decoder with two language models that are trained with monolingual data and then fine-tune the model on parallel data using Elastic Weight Consolidation (EWC) to avoid forgetting of the original language modeling task. We compare the regularization by EWC with the previous work that focuses on regularization by language modeling objectives. The positive result is that using EWC with the decoder achieves BLEU scores similar to the previous work. However, the model converges 2-3 times faster and does not require the original unlabeled training data during the fine-tuning stage. In contrast, the regularization using EWC is less effective if the original and new tasks are not closely related. We show that initializing the bidirectional NMT encoder with a left-to-right language model and forcing the model to remember the original left-to-right language modeling task limits the learning capacity of the encoder for the whole bidirectional context."
N19-1070,Keyphrase Generation: A Text Summarization Struggle,2019,25,4,2,1,18259,erion ccano,"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",0,"Authors{'} keyphrases assigned to scientific articles are essential for recognizing content and topic aspects. Most of the proposed supervised and unsupervised methods for keyphrase generation are unable to produce terms that are valuable but do not appear in the text. In this paper, we explore the possibility of considering the keyphrase string as an abstractive summary of the title and the abstract. First, we collect, process and release a large dataset of scientific paper metadata that contains 2.2 million records. Then we experiment with popular text summarization neural architectures. Despite using advanced deep learning models, large quantities of data and many days of computation, our systematic evaluation on four test datasets reveals that the explored text summarization methods could not produce better keyphrases than the simpler unsupervised methods, or the existing supervised ones."
D19-5201,Overview of the 6th Workshop on {A}sian Translation,2019,0,1,12,0,283,toshiaki nakazawa,Proceedings of the 6th Workshop on Asian Translation,0,"This paper presents the results of the shared tasks from the 6th workshop on Asian translation (WAT2019) including JaâEn, JaâZh scientific paper translation subtasks, JaâEn, JaâKo, JaâEn patent translation subtasks, HiâEn, MyâEn, KmâEn, TaâEn mixed domain subtasks and RuâJa news commentary translation task. For the WAT2019, 25 teams participated in the shared tasks. We also received 10 research paper submissions out of which 61 were accepted. About 400 translation results were submitted to the automatic evaluation server, and selected submis- sions were manually evaluated."
D19-5223,Idiap {NMT} System for {WAT} 2019 Multimodal Translation Task,2019,0,0,2,1,291,shantipriya parida,Proceedings of the 6th Workshop on Asian Translation,0,"This paper describes the Idiap submission to WAT 2019 for the English-Hindi Multi-Modal Translation Task. We have used the state-of-the-art Transformer model and utilized the IITB English-Hindi parallel corpus as an additional data source. Among the different tracks of the multi-modal task, we have participated in the {``}Text-Only{''} track for the evaluation and challenge test sets. Our submission tops in its track among the competitors in terms of both automatic and manual evaluation. Based on automatic scores, our text-only submission also outperforms systems that consider visual information in the {``}multi-modal translation{''} task."
W18-6401,Findings of the 2018 Conference on Machine Translation ({WMT}18),2018,0,84,1,1,292,ondvrej bojar,Proceedings of the Third Conference on Machine Translation: Shared Task Papers,0,"This paper presents the results of the premier shared task organized alongside the Conference on Machine Translation (WMT) 2018. Participants were asked to build machine translation systems for any of 7 language pairs in both directions, to be evaluated on a test set of news stories. The main metric for this task is human judgment of translation quality. This year, we also opened up the task to additional test sets to probe specific aspects of translation."
W18-6416,{CUNI} Submissions in {WMT}18,2018,-1,-1,3,1,6018,tom kocmi,Proceedings of the Third Conference on Machine Translation: Shared Task Papers,0,"We participated in the WMT 2018 shared news translation task in three language pairs: English-Estonian, English-Finnish, and English-Czech. Our main focus was the low-resource language pair of Estonian and English for which we utilized Finnish parallel data in a simple method. We first train a {``}parent model{''} for the high-resource language pair followed by adaptation on the related low-resource language pair. This approach brings a substantial performance boost over the baseline system trained only on Estonian-English parallel data. Our systems are based on the Transformer architecture. For the English to Czech translation, we have evaluated our last year models of hybrid phrase-based approach and neural machine translation mainly for comparison purposes."
W18-6432,{E}val{D} Reference-Less Discourse Evaluation for {WMT}18,2018,-1,-1,1,1,292,ondvrej bojar,Proceedings of the Third Conference on Machine Translation: Shared Task Papers,0,"We present the results of automatic evaluation of discourse in machine translation (MT) outputs using the EVALD tool. EVALD was originally designed and trained to assess the quality of \textit{human} writing, for native speakers and foreign-language learners. MT has seen a tremendous leap in translation quality at the level of sentences and it is thus interesting to see if the human-level evaluation is becoming relevant."
W18-6433,"The {WMT}{'}18 Morpheval test suites for {E}nglish-{C}zech, {E}nglish-{G}erman, {E}nglish-{F}innish and {T}urkish-{E}nglish",2018,-1,-1,4,0,23863,franck burlot,Proceedings of the Third Conference on Machine Translation: Shared Task Papers,0,"Progress in the quality of machine translation output calls for new automatic evaluation procedures and metrics. In this paper, we extend the Morpheval protocol introduced by Burlot and Yvon (2017) for the English-to-Czech and English-to-Latvian translation directions to three additional language pairs, and report its use to analyze the results of WMT 2018{'}s participants for these language pairs. Considering additional, typologically varied source and target languages also enables us to draw some generalizations regarding this morphology-oriented evaluation procedure."
W18-6434,Testsuite on {C}zech{--}{E}nglish Grammatical Contrasts,2018,0,1,2,0,16866,silvie cinkova,Proceedings of the Third Conference on Machine Translation: Shared Task Papers,0,"We present a pilot study of machine translation of selected grammatical contrasts between Czech and English in WMT18 News Translation Task. For each phenomenon, we run a dedicated test which checks if the candidate translation expresses the phenomenon as expected or not. The proposed type of analysis is not an evaluation in the strict sense because the phenomenon can be correctly translated in various ways and we anticipate only one. What is nevertheless interesting are the differences between various MT systems and the single reference translation in their general tendency in handling the given phenomenon."
W18-6450,Results of the {WMT}18 Metrics Shared Task: Both characters and embeddings achieve good performance,2018,0,20,2,1,13912,qingsong ma,Proceedings of the Third Conference on Machine Translation: Shared Task Papers,0,"This paper presents the results of the WMT18 Metrics Shared Task. We asked participants of this task to score the outputs of the MT systems involved in the WMT18 News Translation Task with automatic metrics. We collected scores of 10 metrics and 8 research groups. In addition to that, we computed scores of 8 standard metrics (BLEU, SentBLEU, chrF, NIST, WER, PER, TER and CDER) as baselines. The collected scores were evaluated in terms of system-level correlation (how well each metric{'}s scores correlate with WMT18 official manual ranking of systems) and in terms of segment-level correlation (how often a metric agrees with humans in judging the quality of a particular sentence relative to alternate outputs). This year, we employ a single kind of manual evaluation: direct assessment (DA)."
W18-6325,Trivial Transfer Learning for Low-Resource Neural Machine Translation,2018,23,4,2,1,6018,tom kocmi,Proceedings of the Third Conference on Machine Translation: Research Papers,0,"Transfer learning has been proven as an effective technique for neural machine translation under low-resource conditions. Existing methods require a common target language, language relatedness, or specific training tricks and regimes. We present a simple transfer learning method, where we first train a {``}parent{''} model for a high-resource language pair and then continue the training on a low-resource pair only by replacing the training corpus. This {``}child{''} model performs significantly better than the baseline trained for low-resource pair only. We are the first to show this for targeting different languages, and we observe the improvements even for unrelated languages with different alphabets."
W18-1816,Neural Monkey: The Current State and Beyond,2018,0,1,7,0.416667,16474,jindvrich helcl,Proceedings of the 13th Conference of the Association for Machine Translation in the {A}mericas (Volume 1: Research Track),0,None
P18-1126,Are {BLEU} and Meaning Representation in Opposition?,2018,17,0,2,0,28528,ondvrej cifka,Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"One of possible ways of obtaining continuous-space sentence representations is by training neural machine translation (NMT) systems. The recent attention mechanism however removes the single point in the neural network from which the source sentence representation can be extracted. We propose several variations of the attentive NMT architecture bringing this meeting point back. Empirical evaluation suggests that the better the translation quality, the worse the learned sentence representations serve in a wide range of classification and similarity tasks."
W17-7508,An Exploration of Word Embedding Initialization in Deep-Learning Tasks,2017,22,6,2,1,6018,tom kocmi,Proceedings of the 14th International Conference on Natural Language Processing ({ICON}-2017),0,"Word embeddings are the interface between the world of discrete units of text processing and the continuous, differentiable world of neural networks. In this work, we examine various random and pretrained initialization methods for embeddings used in deep networks and their effect on the performance on four NLP tasks with both recurrent and convolutional architectures. We confirm that pretrained embeddings are a little better than random initialization, especially considering the speed of learning. On the other hand, we do not see any significant difference between various methods of random initialization, as long as the variance is kept reasonably low. High-variance initialization prevents the network to use the space of embeddings and forces it to use other free parameters to accomplish the task. We support this hypothesis by observing the performance in learning lexical relations and by the fact that the network can learn to perform reasonably in its task even with fixed random embeddings."
W17-5715,{CUNI} {NMT} System for {WAT} 2017 Translation Tasks,2017,0,2,3,1,6018,tom kocmi,Proceedings of the 4th Workshop on {A}sian Translation ({WAT}2017),0,"The paper presents this year{'}s CUNI submissions to the WAT 2017 Translation Task focusing on the Japanese-English translation, namely Scientific papers subtask, Patents subtask and Newswire subtask. We compare two neural network architectures, the standard sequence-to-sequence with attention (Seq2Seq) and an architecture using convolutional sentence encoder (FBConv2Seq), both implemented in the NMT framework Neural Monkey that we currently participate in developing. We also compare various types of preprocessing of the source Japanese sentences and their impact on the overall results. Furthermore, we include the results of our experiments with out-of-domain data obtained by combining the corpora provided for each subtask."
W17-4717,Findings of the 2017 Conference on Machine Translation ({WMT}17),2017,0,109,1,1,292,ondvrej bojar,Proceedings of the Second Conference on Machine Translation,0,"This paper presents the results of the WMT17 shared tasks, which includedn three machine translation (MT) tasks (news, biomedical, and multimodal), two evaluation tasks (metrics and run-time estimation of MT quality), an automatic post-editing task, a neural MT training task, and a bandit learning task."
W17-4719,Findings of the {WMT} 2017 Biomedical Translation Shared Task,2017,9,7,5,0,4214,antonio yepes,Proceedings of the Second Conference on Machine Translation,0,None
W17-4720,{CUNI} submission in {WMT}17: Chimera goes neural,2017,0,1,5,1,27706,roman sudarikov,Proceedings of the Second Conference on Machine Translation,0,None
W17-4734,The {QT}21 Combined Machine Translation System for {E}nglish to {L}atvian,2017,0,0,3,0.512486,30412,janthorsten peter,Proceedings of the Second Conference on Machine Translation,0,None
W17-4755,Results of the {WMT}17 Metrics Shared Task,2017,0,26,1,1,292,ondvrej bojar,Proceedings of the Second Conference on Machine Translation,0,"This paper presents the results of then WMT17 Metrics Shared Task. We askedn participants of this task to score the outputs of the MT systems involved in then WMT17 news translation task and Neural MT training task. We collected scoresn of 14 metrics from 8 research groups. Inn addition to that, we computed scores ofn 7 standard metrics (BLEU, SentBLEU,n NIST, WER, PER, TER and CDER) asn baselines. The collected scores were evaluated in terms of system-level correlationn (how well each metricxe2x80x99s scores correlaten with WMT17 official manual ranking ofn systems) and in terms of segment leveln correlation (how often a metric agrees withn humans in judging the quality of a particular sentence).n This year, we build upon two types ofn manual judgements: direct assessmentn (DA) and HUME manual semantic judgements."
W17-4757,Results of the {WMT}17 Neural {MT} Training Task,2017,0,7,1,1,292,ondvrej bojar,Proceedings of the Second Conference on Machine Translation,0,None
W17-4769,{CUNI} Experiments for {WMT}17 Metrics Task,2017,4,0,2,0.233333,9478,david marevcek,Proceedings of the Second Conference on Machine Translation,0,None
W17-4777,{CUNI} System for {WMT}17 Automatic Post-Editing Task,2017,5,3,2,1,25495,duvsan varivs,Proceedings of the Second Conference on Machine Translation,0,None
W17-4780,Variable Mini-Batch Sizing and Pre-Trained Embeddings,2017,5,1,3,0,10900,mostafa abdou,Proceedings of the Second Conference on Machine Translation,0,None
kocmi-bojar-2017-curriculum,Curriculum Learning and Minibatch Bucketing in Neural Machine Translation,2017,14,5,2,1,6018,tom kocmi,"Proceedings of the International Conference Recent Advances in Natural Language Processing, {RANLP} 2017",0,"We examine the effects of particular orderings of sentence pairs on the on-line training of neural machine translation (NMT). We focus on two types of such orderings: (1) ensuring that each minibatch contains sentences similar in some aspect and (2) gradual inclusion of some sentence types as the training progresses (so called {``}curriculum learning{''}). In our English-to-Czech experiments, the internal homogeneity of minibatches has no effect on the training but some of our {``}curricula{''} achieve a small improvement over the baseline."
E17-2059,Producing Unseen Morphological Variants in Statistical Machine Translation,2017,0,6,3,0,5061,matthias huck,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 2, Short Papers",0,"Translating into morphologically rich languages is difficult. Although the coverage of lemmas may be reasonable, many morphological variants cannot be learned from the training data. We present a statistical translation system that is able to produce these inflected word forms. Different from most previous work, we do not separate morphological prediction from lexical choice into two consecutive steps. Our approach is novel in that it is integrated in decoding and takes advantage of context information from both the source language and the target language sides."
E17-1087,{L}anide{NN}: Multilingual Language Identification on Character Window,2017,13,5,2,1,6018,tom kocmi,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 1, Long Papers",0,"In language identification, a common first step in natural language processing, we want to automatically determine the language of some input text. Monolingual language identification assumes that the given document is written in one language. In multilingual language identification, the document is usually in two or three languages and we just want their names. We aim one step further and propose a method for textual language identification where languages can change arbitrarily and the goal is to identify the spans of each of the languages. Our method is based on Bidirectional Recurrent Neural Networks and it performs well in monolingual and multilingual language identification tasks on six datasets covering 131 languages. The method keeps the accuracy also for short documents and across domains, so it is ideal for off-the-shelf use without preparation of training data."
W16-6401,{M}oses {\\&} Treex Hybrid {MT} Systems Bestiary,2016,19,0,3,0.414887,14784,rudolf rosa,Proceedings of the 2nd Deep Machine Translation Workshop,0,None
W16-4506,Verb sense disambiguation in Machine Translation,2016,13,1,4,1,27706,roman sudarikov,Proceedings of the Sixth Workshop on Hybrid Approaches to Translation ({H}y{T}ra6),0,"We describe experiments in Machine Translation using word sense disambiguation (WSD) information. This work focuses on WSD in verbs, based on two different approaches {--} verbal patterns based on corpus pattern analysis and verbal word senses from valency frames. We evaluate several options of using verb senses in the source-language sentences as an additional factor for the Moses statistical machine translation system. Our results show a statistically significant translation quality improvement in terms of the BLEU metric for the valency frames approach, but in manual evaluation, both WSD methods bring improvements."
W16-3706,Enriching Source for {E}nglish-to-{U}rdu Machine Translation,2016,0,1,3,1,33686,bushra jawaid,Proceedings of the 6th Workshop on South and Southeast {A}sian Natural Language Processing ({WSSANLP}2016),0,"This paper focuses on the generation of case markers for free word order languages that use case markers as phrasal clitics for marking the relationship between the dependent-noun and its head. The generation of such clitics becomes essential task especially when translating from fixed word order languages where syntactic relations are identified by the positions of the dependent-nouns. To address the problem of missing markers on source-side, artificial markers are added in source to improve alignments with its target counterparts. Up to 1 BLEU point increase is observed over the baseline on different test sets for English-to-Urdu."
W16-2301,Findings of the 2016 Conference on Machine Translation,2016,113,137,1,1,292,ondvrej bojar,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,"This paper presents the results of the WMT16 shared tasks, which included five machine translation (MT) tasks (standard news, IT-domain, biomedical, multimodal, pronoun), three evaluation tasks (metrics, tuning, run-time estimation of MT quality), and an automatic post-editing task and bilingual document alignment task. This year, 102 MT systems from 24 institutions (plus 36 anonymized online systems) were submitted to the 12 translation directions in the news translation task. The IT-domain task received 31 submissions from 12 institutions in 7 directions and the Biomedical task received 15 submissions systems from 5 institutions. Evaluation was both automatic and manual (relative ranking and 100-point scale assessments). The quality estimation task had three subtasks, with a total of 14 teams, submitting 39 entries. The automatic post-editing task had a total of 6 teams, submitting 11 entries."
W16-2302,Results of the {WMT}16 Metrics Shared Task,2016,23,30,1,1,292,ondvrej bojar,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,"This paper presents the results of the WMT16 Metrics Shared Task. We asked participants of this task to score the outputs of the MT systems involved in the WMT16 Shared Translation Task. We collected scores of 16 metrics from 9 research groups. In addition to that, we computed scores of 9 standard metrics (BLEU, SentBLEU, NIST, WER, PER, TER and CDER) as baselines. The collected scores were evaluated in terms of system-level correlation (how well each metricxe2x80x99s scores correlate with WMT16 official manual ranking of systems) and in terms of segment level correlation (how often a metric agrees with humans in comparing two translations of a particular sentence). This year there are several additions to the setup: large number of language pairs (18 in total), datasets from different domains (news, IT and medical), and different kinds of judgments: relative ranking (RR), direct assessment (DA) and HUME manual semantic judgments. Finally, generation of large number of hybrid systems was trialed for provision of more conclusive system-level metric rankings."
W16-2303,Results of the {WMT}16 Tuning Shared Task,2016,22,3,4,1,33686,bushra jawaid,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,"This paper presents the results of the WMT16 Tuning Shared Task. We provided the participants of this task with a complete machine translation system and asked them to tune its internal parameters (feature weights). The tuned systems were used to translate the test set and the outputs were manually ranked for translation quality. We received 4 submissions in the Czech-English and 8 in the English-Czech translation direction. In addition, we ran 2 baseline setups, tuning the parameters with standard optimizers for BLEU score. In contrast to previous years, the tuned systems in 2016 rely on large data."
W16-2320,The {QT}21/{H}im{L} Combined Machine Translation System,2016,5,6,8,0.512486,30412,janthorsten peter,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,"This paper describes the joint submission of the QT21 and HimL projects for the Englishxe2x86x92Romanian translation task of the ACL 2016 First Conference on Machine Translation (WMT 2016). The submission is a system combination which combines twelve different statistical machine translation systems provided by the different groups (RWTH Aachen University, LMU Munich, Charles University in Prague, University of Edinburgh, University of Sheffield, Karlsruhe Institute of Technology, LIMSI, University of Amsterdam, Tilde). The systems are combined using RWTHxe2x80x99s system combination approach. The final submission shows an improvement of 1.0 BLEU compared to the best single system on newstest2016."
W16-2325,{CUNI}-{LMU} Submissions in {WMT}2016: Chimera Constrained and Beaten,2016,14,4,3,0.833333,4973,alevs tamchyna,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,"This paper describes the phrase-based systems jointly submitted by CUNI and LMU to English-Czech and English-Romanian News translation tasks of WMT16. In contrast to previous years, we strictly limited our training data to the constraint datasets, to allow for a reliable comparison with other research systems. We experiment with using several additional models in our system, including a feature-rich discriminative model of phrasal translation."
W16-2327,{E}dinburgh{'}s Statistical Machine Translation Systems for {WMT}16,2016,52,7,6,0,11121,philip williams,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,"This paper describes the University of Edinburghxe2x80x99s phrase-based and syntax-based submissions to the shared translation tasks of the ACL 2016 First Conference on Machine Translation (WMT16). We submitted five phrase-based and five syntaxbased systems for the news task, plus one phrase-based system for the biomedical task."
W16-2334,Dictionary-based Domain Adaptation of {MT} Systems without Retraining,2016,8,4,5,0.414887,14784,rudolf rosa,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,"We describe our submission to the ITdomain translation task of WMT 2016. We perform domain adaptation with dictionary data on already trained MT systems with no further retraining. We apply our approach to two conceptually different systems developed within the QTLeap project: TectoMT and Moses, as well as Chimera, their combination. In all settings, our method improves the translation quality. Moreover, the basic variant of our approach is applicable to any MT system, including a black-box one."
W16-2344,Particle Swarm Optimization Submission for {WMT}16 Tuning Task,2016,7,1,2,0,33896,viktor kocur,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,None
W16-2361,{CUNI} System for {WMT}16 Automatic Post-Editing and Multimodal Translation Tasks,2016,32,8,4,0.384615,13977,jindvrich libovicky,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,"Neural sequence to sequence learning recently became a very promising paradigm in machine translation, achieving competitive results with statistical phrase-based systems. In this system description paper, we attempt to utilize several recently published methods used for neural sequential learning in order to build systems for WMT 2016 shared tasks of Automatic Post-Editing and Multimodal Machine Translation."
W16-2371,Using Term Position Similarity and Language Modeling for Bilingual Document Alignment,2016,14,5,4,0,33905,thanh le,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,"The WMT Bilingual Document Alignment Task requires systems to assign source pages to their xe2x80x9ctranslationsxe2x80x9d, in a big space of possible pairs. We present four methods: The first one uses the term position similarity between candidate document pairs. The second method requires automatically translated versions of the target text, and matches them with the candidates. The third and fourth methods try to overcome some of the challenges presented by the nature of the corpus, by considering the string similarity of source URL and candidate URL, and combining the first two approaches."
W16-2380,Bilingual Embeddings and Word Alignments for Translation Quality Estimation,2016,19,1,2,0,33911,amal abdelsalam,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,"This paper describes our submission UFAL MULTIVEC to the WMT16 Quality Estimation Shared Task, for EnglishGerman sentence-level post-editing effort prediction and ranking. Our approach exploits the power of bilingual distributed representations, word alignments and also manual post-edits to boost the performance of the baseline QuEst set of features. Our model outperforms the baseline, as well as the winning system in WMT15, Referential Translation Machines (RTM), in both scoring and ranking sub-tasks."
P16-1161,Target-Side Context for Discriminative Models in Statistical Machine Translation,2016,18,4,3,0.833333,4973,alevs tamchyna,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"Discriminative translation models utilizing source context have been shown to help statistical machine translation performance. We propose a novel extension of this work using target context information. Surprisingly, we show that this model can be efficiently integrated directly in the decoding process. Our approach scales to large training data sizes and results in consistent improvements in translation quality on four language pairs. We also provide an analysis comparing the strengths of the baseline source-context model with our extended source-context and target-context model and we show that our extension allows us to better capture morphological coherence. Our work is freely available as part of Moses."
D16-1134,{HUME}: Human {UCCA}-Based Evaluation of Machine Translation,2016,9,11,3,0.085904,5031,alexandra birch,Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing,0,None
2016.eamt-2.1,{T}ecto{MT} {--} a deep linguistic core of the combined Cimera {MT} system,2016,-1,-1,3,0.926162,227,martin popel,Proceedings of the 19th Annual Conference of the European Association for Machine Translation: Projects/Products,0,None
W15-4103,What a Transfer-Based System Brings to the Combination with {PBMT},2015,16,3,2,0.833333,4973,alevs tamchyna,Proceedings of the Fourth Workshop on Hybrid Approaches to Translation ({H}y{T}ra),0,"We present a thorough analysis of a combination of a statistical and a transferbased system for Englishxe2x86x92Czech translation, Moses and TectoMT. We describe several techniques for inspecting such a system combination which are based both on automatic and manual evaluation. While TectoMT often produces bad translations, Moses is still able to select the good parts of them. In many cases, TectoMT provides useful novel translations which are otherwise simply unavailable to the statistical component, despite the very large training data. Our analyses confirm the expected behaviour that TectoMT helps with preserving grammatical agreements and valency requirements, but that it also improves a very diverse set of other phenomena. Interestingly, including the outputs of the transfer-based system in the phrase-based search seems to have a positive effect on the search space. Overall, we find that the components of this combination are complementary and the final system produces significantly better translations than either component by itself."
W15-3001,Findings of the 2015 Workshop on Statistical Machine Translation,2015,78,107,1,1,292,ondvrej bojar,Proceedings of the Tenth Workshop on Statistical Machine Translation,0,"This paper presents the results of the WMT15 shared tasks, which included a standard news translation task, a metrics task, a tuning task, a task for run-time estimation of machine translation quality, and an automatic post-editing task. This year, 68 machine translation systems from 24 institutions were submitted to the ten translation directions in the standard translation task. An additional 7 anonymized systems were included, and were then evaluated both automatically and manually. The quality estimation task had three subtasks, with a total of 10 teams, submitting 34 entries. The pilot automatic postediting task had a total of 4 teams, submitting 7 entries."
W15-3006,{CUNI} in {WMT}15: Chimera Strikes Again,2015,10,3,1,1,292,ondvrej bojar,Proceedings of the Tenth Workshop on Statistical Machine Translation,0,"This paper describes our WMT15 system submission for the translation task, a hybrid system for English-to-Czech translation. We repeat the successful setup from the previous two years."
W15-3031,Results of the {WMT}15 Metrics Shared Task,2015,14,30,4,0.614035,10251,milovs stanojevic,Proceedings of the Tenth Workshop on Statistical Machine Translation,0,"This paper presents the results of the WMT15 Metrics Shared Task. We asked participants of this task to score the outputs of the MT systems involved in the WMT15 Shared Translation Task. We collected scores of 46 metrics from 11 research groups. In addition to that, we computed scores of 7 standard metrics (BLEU, SentBLEU, NIST, WER, PER, TER and CDER) as baselines. The collected scores were evaluated in terms of system level correlation (how well each metricxe2x80x99s scores correlate with WMT15 official manual ranking of systems) and in terms of segment level correlation (how often a metric agrees with humans in comparing two translations of a particular sentence)."
W15-3032,Results of the {WMT}15 Tuning Shared Task,2015,17,2,3,0.614035,10251,milovs stanojevic,Proceedings of the Tenth Workshop on Statistical Machine Translation,0,"This paper presents the results of the WMT15 Tuning Shared Task. We provided the participants of this task with a complete machine translation system and asked them to tune its internal parameters (feature weights). The tuned systems were used to translate the test set and the outputs were manually ranked for translation quality. We received 4 submissions in the English-Czech and 6 in the Czech-English translation direction. In addition, we ran 3 baseline setups, tuning the parameters with standard optimizers for BLEU score."
S15-2059,{T}eam{UFAL}: {WSD}+{EL} as Document Retrieval,2015,10,0,3,0,37224,petr fanta,Proceedings of the 9th International Workshop on Semantic Evaluation ({S}em{E}val 2015),0,"This paper describes our system for SemEval2015 Task 13: Multilingual All-Words Sense Disambiguation and Entity Linking. We have participated with our system in the sub-task which aims at monolingual all-words disambiguation and entity linking. Aside from system description, we pay closer attention to the evaluation of system outputs."
W14-5808,Comparing {C}zech and {E}nglish {AMR}s,2014,17,1,2,0,17503,jan hajivc,Proceedings of Workshop on Lexical and Grammatical Resources for Language Processing,0,"This paper describes in detail the differences between Czech and English annotation using the Abstract Meaning Representation scheme, which stresses the use of ontologies (and semantically-oriented verbal lexicons) and relations based on meaning or ontological content rather than semantics or syntax. The basic xe2x80x9csloganxe2x80x9d of the AMR specification clearly states that AMR is not an interlingua, yet it is expected that many relations as well as structures constructed from these relations will be similar or even identical across languages. In our study, we have investigated 100 sentences in English and their translations into Czech, annotated manually by AMRs, with the goal to describe the differences and if possible, to classify them into two main categories: those which are merely convention differences and thus can be unified by changing such conventions in the AMR annotation guidelines, and those which are so deeply rooted in the language structure that the level of abstraction which is inherent in the current AMR scheme does not allow for such unification."
W14-5505,{E}nglish to {U}rdu Statistical Machine Translation: Establishing a Baseline,2014,14,3,3,1,33686,bushra jawaid,Proceedings of the Fifth Workshop on South and Southeast {A}sian Natural Language Processing,0,"The aim of this paper is to categorize and present the existence of resources for Englishto-Urdu machine translation (MT) and to establish an empirical baseline for this task. By doing so, we hope to set up a common ground for MT research with Urdu to allow for a congruent progress in this field. We build baseline phrase-based MT (PBMT) and hierarchical MT systems and report the results on 3 official independent test sets. On all test sets, hierarchial MT significantly outperformed PBMT. The highest single-reference BLEU score is achieved by the hierarchical system and reaches 21.58% but this figure depends on the randomly selected test set. Our manual evaluation of 175 sentences suggests that in 45% of sentences, the hierarchical MT is ranked better than the PBMT output compared to 21% of sentences where PBMT wins, the rest being equal."
W14-3302,Findings of the 2014 Workshop on Statistical Machine Translation,2014,75,148,1,1,292,ondvrej bojar,Proceedings of the Ninth Workshop on Statistical Machine Translation,0,"This paper presents the results of the WMT14 shared tasks, which included a standard news translation task, a separate medical translation task, a task for run-time estimation of machine translation quality, and a metrics task. This year, 143 machine translation systems from 23 institutions were submitted to the ten translation directions in the standard translation task. An additional 6 anonymized systems were included, and were then evaluated both automatically and manually. The quality estimation task had four subtasks, with a total of 10 teams, submitting 57 entries"
W14-3322,{CUNI} in {WMT}14: Chimera Still Awaits Bellerophon,2014,12,7,4,0.952381,4973,alevs tamchyna,Proceedings of the Ninth Workshop on Statistical Machine Translation,0,"We present our English!Czech and English!Hindi submissions for this yearxe2x80x99s WMT translation task. For English!Czech, we build upon last yearxe2x80x99s CHIMERA and evaluate several setups. English!Hindi is a new language pair for this year. We experimented with reverse self-training to acquire more (synthetic) parallel data and with modeling target-side morphology."
W14-3336,Results of the {WMT}14 Metrics Shared Task,2014,18,40,2,1,38575,matouvs machavcek,Proceedings of the Ninth Workshop on Statistical Machine Translation,0,"This paper presents the results of the WMT14 Metrics Shared Task. We asked participants of this task to score the outputs of the MT systems involved in WMT14 Shared Translation Task. We collected scores of 23 metrics from 12 research groups. In addition to that we computed scores of 6 standard metrics (BLEU, NIST, WER, PER, TER and CDER) as baselines. The collected scores were evaluated in terms of system level correlation (how well each metricxe2x80x99s scores correlate with WMT14 official manual ranking of systems) and in terms of segment level correlation (how often a metric agrees with humans in comparing two translations of a particular sentence)."
xue-etal-2014-interlingua,"Not an Interlingua, But Close: Comparison of {E}nglish {AMR}s to {C}hinese and {C}zech",2014,18,10,2,0,10294,nianwen xue,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"Abstract Meaning Representations (AMRs) are rooted, directional and labeled graphs that abstract away from morpho-syntactic idiosyncrasies such as word category (verbs and nouns), word order, and function words (determiners, some prepositions). Because these syntactic idiosyncrasies account for many of the cross-lingual differences, it would be interesting to see if this representation can serve, e.g., as a useful, minimally divergent transfer layer in machine translation. To answer this question, we have translated 100 English sentences that have existing AMRs into Chinese and Czech to create AMRs for them. A cross-linguistic comparison of English to Chinese and Czech AMRs reveals both cases where the AMRs for the language pairs align well structurally and cases of linguistic divergence. We found that the level of compatibility of AMR between English and Chinese is higher than between English and Czech. We believe this kind of comparison is beneficial to further refining the annotation standards for each of the three languages and will lead to more compatible annotation guidelines between the languages."
jawaid-etal-2014-tagged,A Tagged Corpus and a Tagger for {U}rdu,2014,6,15,3,1,33686,bushra jawaid,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"In this paper, we describe a release of a sizeable monolingual Urdu corpus automatically tagged with part-of-speech tags. We extend the work of Jawaid and Bojar (2012) who use three different taggers and then apply a voting scheme to disambiguate among the different choices suggested by each tagger. We run this complex ensemble on a large monolingual corpus and release the tagged corpus. Additionally, we use this data to train a single standalone tagger which will hopefully significantly simplify Urdu processing. The standalone tagger obtains the accuracy of 88.74{\%} on test data."
jawaid-bojar-2014-two,Two-Step Machine Translation with Lattices,2014,17,1,2,1,33686,bushra jawaid,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"The idea of two-step machine translation was introduced to divide the complexity of the search space into two independent steps: (1) lexical translation and reordering, and (2) conjugation and declination in the target language. In this paper, we extend the two-step machine translation structure by replacing state-of-the-art phrase-based machine translation with the hierarchical machine translation in the 1st step. We further extend the fixed string-based input format of the 2nd step with word lattices (Dyer et al., 2008); this provides the 2nd step with the opportunity to choose among a sample of possible reorderings instead of relying on the single best one as produced by the 1st step."
bojar-etal-2014-hindencorp,{H}ind{E}n{C}orp - {H}indi-{E}nglish and {H}indi-only Corpus for Machine Translation,2014,15,30,1,1,292,ondvrej bojar,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"We present HindEnCorp, a parallel corpus of Hindi and English, and HindMonoCorp, a monolingual corpus of Hindi in their release version 0.5. Both corpora were collected from web sources and preprocessed primarily for the training of statistical machine translation systems. HindEnCorp consists of 274k parallel sentences (3.9 million Hindi and 3.8 million English tokens). HindMonoCorp amounts to 787 million tokens in 44 million sentences. Both the corpora are freely available for non-commercial research and their preliminary release has been used by numerous participants of the WMT 2014 shared translation task."
2014.tc-1.29,{T}witter Crowd Translation {--} design and objectives,2014,-1,-1,2,0,40337,eduard vsubert,Proceedings of Translating and the Computer 36,0,None
W13-2201,Findings of the 2013 {W}orkshop on {S}tatistical {M}achine {T}ranslation,2013,86,192,1,1,292,ondvrej bojar,Proceedings of the Eighth Workshop on Statistical Machine Translation,0,"We present the results of the WMT13 shared tasks, which included a translation task, a task for run-time estimation of machine translation quality, and an unofficial metrics task. This year, 143 machine translation systems were submitted to the ten translation tasks from 23 institutions. An additional 6 anonymized systems were included, and were then evaluated both automatically and manually, in our largest manual evaluation to date. The quality estimation task had four subtasks, with a total of 14 teams, submitting 55 entries."
W13-2202,Results of the {WMT}13 Metrics Shared Task,2013,13,39,2,1,38575,matouvs machavcek,Proceedings of the Eighth Workshop on Statistical Machine Translation,0,"This paper presents the results of the WMT13 Metrics Shared Task. We asked participants of this task to score the outputs of the MT systems involved in WMT13 Shared Translation Task. We collected scores of 16 metrics from 8 research groups. In addition to that we computed scores of 5 standard metrics such as BLEU, WER, PER as baselines. Collected scores were evaluated in terms of system level correlation (how well each metricxe2x80x99s scores correlate with WMT13 official human scores) and in terms of segment level correlation (how often a metric agrees with humans in comparing two translations of a particular sentence)."
W13-2208,Chimera {--} Three Heads for {E}nglish-to-{C}zech Translation,2013,22,11,1,1,292,ondvrej bojar,Proceedings of the Eighth Workshop on Statistical Machine Translation,0,"This paper describes our WMT submissions CU-BOJAR and CU-DEPFIX, the latter dubbed xe2x80x9cCHIMERAxe2x80x9d because it combines on three diverse approaches: TectoMT, a system with transfer at the deep syntactic level of representation, factored phrase-based translation using Moses, and finally automatic rule-based correction of frequent grammatical and meaning errors. We do not use any off-the-shelf systemcombination method."
W13-2216,{P}hrase{F}ix: Statistical Post-Editing of {T}ecto{MT},2013,24,6,3,1,29927,petra galuvsvcakova,Proceedings of the Eighth Workshop on Statistical Machine Translation,0,"We present two English-to-Czech systems that took part in the WMT 2013 shared task: TECTOMT and PHRASEFIX. The former is a deep-syntactic transfer-based system, the latter is a more-or-less standard statistical post-editing (SPE) applied on top of TECTOMT. In a brief survey, we put SPE in context with other system combination techniques and evaluate SPE vs. another simple system combination technique: using synthetic parallel data from TECTOMT to train a statistical MT system (SMT). We confirm that PHRASEFIX (SPE) improves the output of TECTOMT, and we use this to analyze errors in TECTOMT. However, we also show that extending data for SMT is more effective."
W12-5611,Morphological Processing for {E}nglish-{T}amil Statistical Machine Translation,2012,15,15,2,0,42069,loganathan ramasamy,Proceedings of the Workshop on Machine Translation and Parsing in {I}ndian Languages,0,"Various experiments from literature suggest that in statistical machine translation (SMT), applying either pre-processing or post-processing to morphologically rich languages leads to better translation quality. In this work, we focus on the English-Tamil language pair. We implement suffix-separation rules for both of the languages and evaluate the impact of this preprocessing on translation quality of the phrase-based as well as hierarchical model in terms of BLEU score and a small manual evaluation. The results confirm that our simple suffix-based morphological processing helps to obtain better translation performance. A by-product of our efforts is a new parallel corpus of 190k sentence pairs gathered from the web."
W12-5011,Tagger Voting for {U}rdu,2012,6,4,2,1,33686,bushra jawaid,Proceedings of the 3rd Workshop on South and Southeast {A}sian Natural Language Processing,0,"In this paper, we focus on improving part-of-speech (POS) tagging for Urdu by using existing tools and data for the language. In our experiments, we use Humayounxe2x80x99s morphological analyzer, the POS tagging module of an Urdu Shallow Parser and our own SVM Tool tagger trained on CRULP manually annotated data. We convert the output of the taggers to a common format and more importantly unify their tagsets. On an independent test set, our tagger outperforms the other tools by far. We gain some further improvement by implementing a voting strategy that allows us to consider not only our tagger but also include suggestions by the other tools. The final tagger reaches the accuracy of 87.98%."
W12-4204,Towards a Predicate-Argument Evaluation for {MT},2012,17,9,1,1,292,ondvrej bojar,"Proceedings of the Sixth Workshop on Syntax, Semantics and Structure in Statistical Translation",0,"HMEANT (Lo and Wu, 2011a) is a manual MT evaluation technique that focuses on predicate-argument structure of the sentence. We relate HMEANT to an established linguistic theory, highlighting the possibilities of reusing existing knowledge and resources for interpreting and automating HMEANT. We apply HMEANT to a new language, Czech in particular, by evaluating a set of English-to-Czech MT systems. HMEANT proves to correlate with manual rankings at the sentence level better than a range of automatic metrics. However, the main contribution of this paper is the identification of several issues of HMEANT annotation and our proposal on how to resolve them."
W12-3105,{T}error{C}at: a Translation Error Categorization-based {MT} Quality Metric,2012,13,14,4,0,13955,mark fishel,Proceedings of the Seventh Workshop on Statistical Machine Translation,0,"We present TerrorCat, a submission to the WMT'12 metrics shared task. TerrorCat uses frequencies of automatically obtained translation error categories as base for pairwise comparison of translation hypotheses, which is in turn used to generate a score for every translation. The metric shows high overall correlation with human judgements on the system level and more modest results on the level of individual sentences."
W12-3130,Probes in a Taxonomy of Factored Phrase-Based Models,2012,24,12,1,1,292,ondvrej bojar,Proceedings of the Seventh Workshop on Statistical Machine Translation,0,We introduce a taxonomy of factored phrase-based translation scenarios and conduct a range of experiments in this taxonomy. We point out several common pitfalls when designing factored setups. The paper also describes our WMT12 submissions CU-BOJAR and CU-POOR-COMB.
W12-3148,Selecting Data for {E}nglish-to-{C}zech Machine Translation,2012,20,4,5,0.952381,4973,alevs tamchyna,Proceedings of the Seventh Workshop on Statistical Machine Translation,0,"We provide a few insights on data selection for machine translation. We evaluate the quality of the new CzEng 1.0, a parallel data source used in WMT12. We describe a simple technique for reducing out-of-vocabulary rate after phrase extraction. We discuss the benefits of tuning towards multiple reference translations for English-Czech language pair. We introduce a novel approach to data selection by full-text indexing and search: we select sentences similar to the test set from a large monolingual corpus and explore several options of incorporating them in a machine translation system. We show that this method can improve translation quality. Finally, we describe our submitted system CU-TAMCH-BOJ."
berka-etal-2012-automatic,Automatic {MT} Error Analysis: Hjerson Helping Addicter,2012,13,9,2,0,42951,jan berka,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"We present a complex, open source tool for detailed machine translation error analysis providing the user with automatic error detection and classification, several monolingual alignment algorithms as well as with training and test corpus browsing. The tool is the result of a merge of automatic error detection and classification of Hjerson (Popovi{\'c}, 2011) and Addicter (Zeman et al., 2011) into the pipeline and web visualization of Addicter. It classifies errors into categories similar to those of Vilar et al. (2006), such as: morphological, reordering, missing words, extra words and lexical errors. The graphical user interface shows alignments in both training corpus and test data; the different classes of errors are colored. Also, the summary of errors can be displayed to provide an overall view of the MT system's weaknesses. The tool was developed in Linux, but it was tested on Windows too."
fishel-etal-2012-terra,{T}erra: a Collection of Translation Error-Annotated Corpora,2012,19,13,2,0,13955,mark fishel,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"Recently the first methods of automatic diagnostics of machine translation have emerged; since this area of research is relatively young, the efforts are not coordinated. We present a collection of translation error-annotated corpora, consisting of automatically produced translations and their detailed manual translation error analysis. Using the collected corpora we evaluate the available state-of-the-art methods of MT diagnostics and assess, how well the methods perform, how they compare to each other and whether they can be useful in practice."
hajic-etal-2012-announcing,Announcing {P}rague {C}zech-{E}nglish {D}ependency {T}reebank 2.0,2012,5,27,5,0,17503,jan hajivc,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"We introduce a substantial update of the Prague Czech-English Dependency Treebank, a parallel corpus manually annotated at the deep syntactic layer of linguistic representation. The English part consists of the Wall Street Journal (WSJ) section of the Penn Treebank. The Czech part was translated from the English source sentence by sentence. This paper gives a high level overview of the underlying linguistic theory (the so-called tectogrammatical annotation) with some details of the most important features like valency annotation, ellipsis reconstruction or coreference."
bojar-etal-2012-joy,The Joy of Parallelism with {C}z{E}ng 1.0,2012,15,34,1,1,292,ondvrej bojar,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"CzEng 1.0 is an updated release of our Czech-English parallel corpus, freely available for non-commercial research or educational purposes. In this release, we approximately doubled the corpus size, reaching 15 million sentence pairs (about 200 million tokens per language). More importantly, we carefully filtered the data to reduce the amount of non-matching sentence pairs. CzEng 1.0 is automatically aligned at the level of sentences as well as words. We provide not only the plain text representation, but also automatic morphological tags, surface syntactic as well as deep syntactic dependency parse trees and automatic co-reference links in both English and Czech. This paper describes key properties of the released resource including the distribution of text domains, the corpus data formats, and a toolkit to handle the provided rich annotation. We also summarize the procedure of the rich annotation (incl. co-reference resolution) and of the automatic filtering. Finally, we provide some suggestions on exploiting such an automatically annotated sentence-parallel corpus."
W11-2101,A Grain of Salt for the {WMT} Manual Evaluation,2011,15,41,1,1,292,ondvrej bojar,Proceedings of the Sixth Workshop on Statistical Machine Translation,0,"The Workshop on Statistical Machine Translation (WMT) has become one of ACL's flagship workshops, held annually since 2006. In addition to soliciting papers from the research community, WMT also features a shared translation task for evaluating MT systems. This shared task is notable for having manual evaluation as its cornerstone. The Workshop's overview paper, playing a descriptive and administrative role, reports the main results of the evaluation without delving deep into analyzing those results. The aim of this paper is to investigate and explain some interesting idiosyncrasies in the reported results, which only become apparent when performing a more thorough analysis of the collected annotations. Our analysis sheds some light on how the reported results should (and should not) be interpreted, and also gives rise to some helpful recommendation for the organizers of WMT."
W11-2108,Approximating a Deep-Syntactic Metric for {MT} Evaluation and Tuning,2011,12,9,2,1,38575,matouvs machavcek,Proceedings of the Sixth Workshop on Statistical Machine Translation,0,"SemPOS is an automatic metric of machine translation quality for Czech and English focused on content words. It correlates well with human judgments but it is computationally costly and hard to adapt to other languages because it relies on a deep-syntactic analysis of the system output and the reference. To remedy this, we attempt at approximating SemPOS using only tagger output and a few heuristics. At a little expense in correlation to human judgments, we can evaluate MT systems much faster. Additionally, we describe our submission to the Tunable Metrics Task in WMT11."
W11-2138,Improving Translation Model by Monolingual Data,2011,14,17,1,1,292,ondvrej bojar,Proceedings of the Sixth Workshop on Statistical Machine Translation,0,We use target-side monolingual data to extend the vocabulary of the translation model in statistical machine translation. This method called reverse self-training improves the decoder's ability to produce grammatically correct translations into languages with morphology richer than the source language esp. in small-data setting. We empirically evaluate the gains for several pairs of European languages and discuss some approaches of the underlying back-off techniques needed to translate unseen forms of known words. We also provide a description of the systems we submitted to WMT11 Shared Task.
W11-2152,Two-step translation with grammatical post-processing,2011,11,17,4,0.233333,9478,david marevcek,Proceedings of the Sixth Workshop on Statistical Machine Translation,0,This paper describes an experiment in which we try to automatically correct mistakes in grammatical agreement in English to Czech MT outputs. We perform several rule-based corrections on sentences parsed to dependency trees. We prove that it is possible to improve the MT quality of majority of the systems participating in WMT shared task. We made both automatic (BLEU) and manual evaluations.
W10-1705,2010 Failures in {E}nglish-{C}zech Phrase-Based {MT},2010,19,16,1,1,292,ondvrej bojar,Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and {M}etrics{MATR},0,"The paper describes our experiments with English-Czech machine translation for WMT10 in 2010. Focusing primarily on the translation to Czech, our additions to the standard Moses phrase-based MT pipeline include two-step translation to overcome target-side data sparseness and optimization towards SemPOS, a metric better suited for evaluating Czech. Unfortunately, none of the approaches bring a significant improvement over our standard setup."
P10-2016,Tackling Sparse Data Issue in Machine Translation Evaluation,2010,9,16,1,1,292,ondvrej bojar,Proceedings of the {ACL} 2010 Conference Short Papers,0,We illustrate and explain problems of n-grams-based machine translation (MT) metrics (e.g. BLEU) when applied to morphologically rich languages such as Czech. A novel metric SemPOS based on the deep-syntactic representation of the sentence tackles the issue and retains the performance for translation to English as well.
sindlerova-bojar-2010-building,Building a Bilingual {V}al{L}ex Using Treebank Token Alignment: First Observations,2010,3,4,2,0,36955,jana vsindlerova,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"We explore the potential and limitations of a concept of building a bilingual valency lexicon based on the alignment of nodes in a parallel treebank. Our aim is to build an electronic Czech-{\textgreater}English Valency Lexicon by collecting equivalences from bilingual treebank data and storing them in two already existing electronic valency lexicons, PDT-VALLEX and Engvallex. For this task a special annotation interface has been built upon the TrEd editor, allowing quick and easy collecting of frame equivalences in either of the source lexicons. The issues encountered so far include limitations of technical character, theory-dependent limitations and limitations concerning the achievable degree of quality of human annotation. The issues of special interest for both linguists and MT specialists involved in the project include linguistically motivated non-balance between the frame equivalents, either in number or in type of valency participants. The first phases of annotation so far attest the assumption that there is a unique correspondence between the functors of the translation-equivalent frames. Also, hardly any linguistically significant non-balance between the frames has been found, which is partly promising considering the linguistic theory used and partly caused by little stylistic variety of the annotated corpus texts."
bojar-etal-2010-evaluating,Evaluating Utility of Data Sources in a Large Parallel {C}zech-{E}nglish Corpus {C}z{E}ng 0.9,2010,3,2,1,1,292,ondvrej bojar,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"CzEng 0.9 is the third release of a large parallel corpus of Czech and English. For the current release, CzEng was extended by significant amount of texts from various types of sources, including parallel web pages, electronically available books and subtitles. This paper describes and evaluates filtering techniques employed in the process in order to avoid misaligned or otherwise damaged parallel sentences in the collection. We estimate the precision and recall of two sets of filters. The first set was used to process the data before their inclusion into CzEng. The filters from the second set were newly created to improve the filtering process for future releases of CzEng. Given the overall amount and variance of sources of the data, our experiments illustrate the utility of parallel data sources with respect to extractable parallel segments. As a similar behaviour can be expected for other language pairs, our results can be interpreted as guidelines indicating which sources should other researchers exploit first."
bojar-etal-2010-data,Data Issues in {E}nglish-to-{H}indi Machine Translation,2010,11,9,1,1,292,ondvrej bojar,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"Statistical machine translation to morphologically richer languages is a challenging task and more so if the source and target languages differ in word order. Current state-of-the-art MT systems thus deliver mediocre results. Adding more parallel data often helps improve the results; if it doesn't, it may be caused by various problems such as different domains, bad alignment or noise in the new data. In this paper we evaluate the English-to-Hindi MT task from this data perspective. We discuss several available parallel data sources and provide cross-evaluation results on their combinations using two freely available statistical MT systems. We demonstrate various problems encountered in the data and describe automatic methods of data cleaning and normalization. We also show that the contents of two independently distributed data sets can unexpectedly overlap, which negatively affects translation quality. Together with the error analysis, we also present a new tool for viewing aligned corpora, which makes it easier to detect difficult parts in the data even for a developer not speaking the target language."
W09-0422,{E}nglish-{C}zech {MT} in 2008,2009,15,13,1,1,292,ondvrej bojar,Proceedings of the Fourth Workshop on Statistical Machine Translation,0,We describe two systems for English-to-Czech machine translation that took part in the WMT09 translation task. One of the systems is a tuned phrase-based system and the other one is based on a linguistically motivated analysis-transfer-synthesis approach.
2009.tc-1.3,Computer-aided translation backed by machine translation,2009,-1,-1,2,0,47450,ondvrej odchazal,Proceedings of Translating and the Computer 31,0,None
W08-0319,Phrase-Based and Deep Syntactic {E}nglish-to-{C}zech Statistical Machine Translation,2008,19,25,1,1,292,ondvrej bojar,Proceedings of the Third Workshop on Statistical Machine Translation,0,This paper describes our two contributions to WMT08 shared task: factored phrase-based model using Moses and a probabilistic tree-transfer model at a deep syntactic layer.
bojar-etal-2008-czeng,{C}z{E}ng 0.7: Parallel Corpus with Community-Supplied Translations,2008,5,8,1,1,292,ondvrej bojar,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"This paper describes CzEng 0.7, a new release of Czech-English parallel corpus freely available for research and educational purposes. We provide basic statistics of the corpus and focus on data produced by a community of volunteers. Anonymous contributors manually correct the output of a machine translation (MT) system, generating on average 2000 sentences a month, 70{\%} of which are indeed correct translations. We compare the utility of community-supplied and of professionally translated training data for a baseline English-to-Czech MT system."
W07-0735,{E}nglish-to-{C}zech Factored Machine Translation,2007,28,35,1,1,292,ondvrej bojar,Proceedings of the Second Workshop on Statistical Machine Translation,0,This paper describes experiments with English-to-Czech phrase-based machine translation. Additional annotation of input and output tokens (multiple factors) is used to explicitly model morphology. We vary the translation scenario (the setup of multiple factors) and the amount of information in the morphological tags. Experimental results demonstrate significant improvement of translation quality in terms of BLEU.
P07-2045,{M}oses: Open Source Toolkit for Statistical Machine Translation,2007,13,3819,12,0,4417,philipp koehn,Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions,0,"We describe an open-source toolkit for statistical machine translation whose novel contributions are (a) support for linguistically motivated factors, (b) confusion network decoding, and (c) efficient data formats for translation models and language models. In addition to the SMT decoder, the toolkit also includes a wide variety of tools for training, tuning and applying the system to many translation tasks."
bojar-prokopova-2006-czech,{C}zech-{E}nglish Word Alignment,2006,5,18,1,1,292,ondvrej bojar,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,We describe an experiment with Czech-English word alignment. Half a thousand sentences were manually annotated by two annotators in parallel and the most frequent reasons for disagreement are described. We evaluate the accuracy of GIZA++ alignment toolkit on the data and identify that lemmatization of the Czech part can reduce alignment error to a half. Furthermore we document that about 38{\%} of tokens difficult for GIZA++ were difficult for humans already.
I05-2031,Problems of Reusing an Existing {MT} System,2005,3,0,1,1,292,ondvrej bojar,Companion Volume to the Proceedings of Conference including Posters/Demos and tutorial abstracts,0,None
2005.mtsummit-posters.9,An {MT} System Recycled,2005,6,1,1,1,292,ondvrej bojar,Proceedings of Machine Translation Summit X: Posters,0,This paper describes an attempt to recycle parts of the Czech-to-Russian machine translation system (MT) in the new Czech-to-English MT system. The paper describes the overall architecture of the new system and the details of the modules which have been added. A special attention is paid to the problem of named entity recognition and to the method of automatic acquisition of lexico-syntactic information for the bilingual dictionary of the system.
