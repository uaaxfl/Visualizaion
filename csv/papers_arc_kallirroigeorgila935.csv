2020.lrec-1.91,Predicting Ratings of Real Dialogue Participants from Artificial Data and Ratings of Human Dialogue Observers,2020,-1,-1,1,1,16796,kallirroi georgila,Proceedings of the 12th Language Resources and Evaluation Conference,0,"We collected a corpus of dialogues in a Wizard of Oz (WOz) setting in the Internet of Things (IoT) domain. We asked users participating in these dialogues to rate the system on a number of aspects, namely, intelligence, naturalness, personality, friendliness, their enjoyment, overall quality, and whether they would recommend the system to others. Then we asked dialogue observers, i.e., Amazon Mechanical Turkers (MTurkers), to rate these dialogues on the same aspects. We also generated simulated dialogues between dialogue policies and simulated users and asked MTurkers to rate them again on the same aspects. Using linear regression, we developed dialogue evaluation functions based on features from the simulated dialogues and the MTurkers{'} ratings, the WOz dialogues and the MTurkers{'} ratings, and the WOz dialogues and the WOz participants{'} ratings. We applied all these dialogue evaluation functions to a held-out portion of our WOz dialogues, and we report results on the predictive power of these different types of dialogue evaluation functions. Our results suggest that for three conversational aspects (intelligence, naturalness, overall quality) just training evaluation functions on simulated data could be sufficient."
2020.lrec-1.797,Evaluation of Off-the-shelf Speech Recognizers Across Diverse Dialogue Domains,2020,-1,-1,1,1,16796,kallirroi georgila,Proceedings of the 12th Language Resources and Evaluation Conference,0,"We evaluate several publicly available off-the-shelf (commercial and research) automatic speech recognition (ASR) systems across diverse dialogue domains (in US-English). Our evaluation is aimed at non-experts with limited experience in speech recognition. Our goal is not only to compare a variety of ASR systems on several diverse data sets but also to measure how much ASR technology has advanced since our previous large-scale evaluations on the same data sets. Our results show that the performance of each speech recognizer can vary significantly depending on the domain. Furthermore, despite major recent progress in ASR technology, current state-of-the-art speech recognizers perform poorly in domains that require special vocabulary and language models, and under noisy conditions. We expect that our evaluation will prove useful to ASR consumers and dialogue system designers."
W18-5033,Conversational Image Editing: Incremental Intent Identification in a New Dialogue Task,2018,0,4,4,1,1597,ramesh manuvinakurike,Proceedings of the 19th Annual {SIG}dial Meeting on Discourse and Dialogue,0,"We present {``}conversational image editing{''}, a novel real-world application domain combining dialogue, visual information, and the use of computer vision. We discuss the importance of dialogue incrementality in this task, and build various models for incremental intent identification based on deep learning and traditional classification algorithms. We show how our model based on convolutional neural networks outperforms models based on random forests, long short term memory networks, and conditional random fields. By training embeddings based on image-related dialogue corpora, we outperform pre-trained out-of-the-box embeddings, for intention identification tasks. Our experiments also provide evidence that incremental intent processing may be more efficient for the user and could save time in accomplishing tasks."
W18-4701,{D}ial{E}dit: Annotations for Spoken Conversational Image Editing,2018,0,3,6,0,28126,ramesh manuvirakurike,Proceedings 14th Joint {ACL} - {ISO} Workshop on Interoperable Semantic Annotation,0,None
W18-4707,A Dialogue Annotation Scheme for Weight Management Chat using the Trans-Theoretical Model of Health Behavior Change,2018,14,0,3,0,28126,ramesh manuvirakurike,Proceedings 14th Joint {ACL} - {ISO} Workshop on Interoperable Semantic Annotation,0,In this study we collect and annotate human-human role-play dialogues in the domain of weight management. There are two roles in the conversation: the seeker who is looking for ways to lose weight and the helper who provides suggestions to help the seeker in their weight loss journey. The chat dialogues collected are then annotated with a novel annotation scheme inspired by a popular health behavior change theory called trans-theoretical model of health behavior change. We also build classifiers to automatically predict the annotation labels used in our corpus. We find that classification accuracy improves when oracle segmentations of the interlocutors' sentences are provided compared to directly classifying unsegmented sentences.
W18-4711,Towards Understanding End-of-trip Instructions in a Taxi Ride Scenario,2018,21,0,3,0,14956,deepthi karkada,Proceedings 14th Joint {ACL} - {ISO} Workshop on Interoperable Semantic Annotation,0,"We introduce a dataset containing human-authored descriptions of target locations in an end-of-trip in a taxi ride scenario. We describe our data collection method and a novel annotation scheme that supports understanding of such descriptions of target locations. Our dataset contains target location descriptions for both synthetic and real-world images as well as visual annotations (ground truth labels, dimensions of vehicles and objects, coordinates of the target location,distance and direction of the target location from vehicles and objects) that can be used in various visual and language tasks. We also perform a pilot experiment on how the corpus could be applied to visual reference resolution in this domain."
L18-1683,Edit me: A Corpus and a Framework for Understanding Natural Language Image Editing,2018,0,5,7,1,1597,ramesh manuvinakurike,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
W17-5539,Using Reinforcement Learning to Model Incrementality in a Fast-Paced Dialogue Game,2017,16,4,3,1,1597,ramesh manuvinakurike,Proceedings of the 18th Annual {SIG}dial Meeting on Discourse and Dialogue,0,"We apply Reinforcement Learning (RL) to the problem of incremental dialogue policy learning in the context of a fast-paced dialogue game. We compare the policy learned by RL with a high-performance baseline policy which has been shown to perform very efficiently (nearly as well as humans) in this dialogue game. The RL policy outperforms the baseline policy in offline simulations (based on real user data). We provide a detailed comparison of the RL policy and the baseline policy, including information about how much effort and time it took to develop each one of them. We also highlight the cases where the RL policy performs better, and show that understanding the RL policy can provide valuable insights which can inform the creation of an even better rule-based policy."
N16-3007,New Dimensions in Testimony Demonstration,2016,12,1,3,0,16785,ron artstein,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Demonstrations,0,"New Dimensions in Testimony is a prototype dialogue system that allows users to conduct a conversation with a real person who is not available for conversation in real time. Users talk to a persistent representation of Holocaust survivor Pinchas Gutter on a screen, while a dialogue agent selects appropriate responses to user utterances from a set of pre-recorded video statements, simulating a live conversation. The technology is similar to existing conversational agents, but to our knowledge this is the first system to portray a real person. The demonstration will show the system on a range of screens (from mobile phones to large TVs), and allow users to have individual conversations with Mr. Gutter."
W15-4605,Reinforcement Learning in Multi-Party Trading Dialog,2015,26,4,2,0,27167,takuya hiraoka,Proceedings of the 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"In this paper, we apply reinforcement learning (RL) to a multi-party trading scenario where the dialog system (learner) trades with one, two, or three other agents. We experiment with different RL algorithms and reward functions. The negotiation strategy of the learner is learned through simulated dialog with trader simulators. In our experiments, we evaluate how the performance of the learner varies depending on the RL algorithm used and the number of traders. Our results show that (1) even in simple multi-party trading dialog tasks, learning an effective negotiation policy is a very hard problem; and (2) the use of neural fitted Q iteration combined with an incremental reward function produces negotiation policies as effective or even better than the policies of two strong hand-crafted baselines."
W15-4613,Which Synthetic Voice Should {I} Choose for an Evocative Task?,2015,16,4,2,0,30105,eli pincus,Proceedings of the 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"We explore different evaluation methods for 4 different synthetic voices and 1 human voice. We investigate whether intelligibility, naturalness, or likability of a voice is correlated to the voicexe2x80x99s evocative function potential, a measure of the voicexe2x80x99s ability to evoke an intended reaction from the listener. We also investigate the extent to which naturalness and likability ratings vary depending on whether or not exposure to a voice is extended and continuous vs. short-term and sporadic (interleaved with other voices). Finally, we show that an automatic test can replace the standard intelligibility tests for text-to-speech (TTS) systems, which eliminates the need to hire humans to perform transcription tasks saving both time and money."
W15-4621,Reinforcement Learning of Multi-Issue Negotiation Dialogue Policies,2015,-1,-1,2,0,1448,alexandros papangelis,Proceedings of the 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,None
W15-4629,Evaluating Spoken Dialogue Processing for Time-Offset Interaction,2015,10,11,2,0,16786,david traum,Proceedings of the 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"This paper presents the first evaluation of a full automated prototype system for time-offset interaction, that is, conversation between a live person and recordings of someone who is not temporally copresent. Speech recognition reaches word error rates as low as 5% with generalpurpose language models and 19% with domain-specific models, and language understanding can identify appropriate direct responses to 60xe2x80x9066% of user utterances while keeping errors to 10xe2x80x9016% (the remainder being indirect, or off-topic responses). This is sufficient to enable a natural flow and relatively open-ended conversations, with a collection of under 2000 recorded statements."
W14-4334,A Demonstration of Dialogue Processing in {S}im{S}ensei Kiosk,2014,7,1,3,0,33320,fabrizio morbini,Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue ({SIGDIAL}),0,"This demonstration highlights the dialogue processing in SimSensei Kiosk, a virtual human dialogue system that conducts interviews related to psychological distress conditions such as depression, anxiety, and post-traumatic stress disorder (PTSD). The dialogue processing in SimSensei Kiosk allows the system to conduct coherent spoken interviews of human users that are 15-25 minutes in length, and in which users feel comfortable talking and openly sharing information. We present the design of the individual dialogue components, and show examples of natural conversation flow between the system and users, including expressions of empathy, follow-up responses and continuation prompts, and turn-taking."
P14-1047,Single-Agent vs. Multi-Agent Techniques for Concurrent Reinforcement Learning of Negotiation Dialogue Policies,2014,40,18,1,1,16796,kallirroi georgila,Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"We use single-agent and multi-agent Reinforcement Learning (RL) for learning dialogue policies in a resource allocation negotiation scenario. Two agents learn concurrently by interacting with each other without any need for simulated users (SUs) to train against or corpora to learn from. In particular, we compare the Qlearning, Policy Hill-Climbing (PHC) and Win or Learn Fast Policy Hill-Climbing (PHC-WoLF) algorithms, varying the scenario complexity (state space size), the number of training episodes, the learning rate, and the exploration rate. Our results show that generally Q-learning fails to converge whereas PHC and PHC-WoLF always converge and perform similarly. We also show that very high gradually decreasing exploration rates are required for convergence. We conclude that multiagent RL of dialogue policies is a promising alternative to using single-agent RL and SUs or learning directly from corpora."
W13-4016,Reinforcement Learning of Two-Issue Negotiation Dialogue Policies,2013,28,11,1,1,16796,kallirroi georgila,Proceedings of the {SIGDIAL} 2013 Conference,0,"We use reinforcement learning (RL) to learn a multi-issue negotiation dialogue policy. For training and evaluation, we build a hand-crafted agenda-based policy, which serves as the negotiation partner of the RL policy. Both the agendabased and the RL policies are designed to work for a large variety of negotiation settings, and perform well against negotiation partners whose behavior has not been observed before. We evaluate the two models by having them negotiate against each other under various settings. The learned model consistently outperforms the agenda-based model. We also ask human raters to rate negotiation transcripts between the RL policy and the agenda-based policy, regarding the rationality of the two negotiators. The RL policy is perceived as more rational than the agenda-based policy."
W13-4032,Verbal indicators of psychological distress in interactive dialogue with a virtual human,2013,16,28,2,0.517624,31518,david devault,Proceedings of the {SIGDIAL} 2013 Conference,0,"We explore the presence of indicators of psychological distress in the linguistic behavior of subjects in a corpus of semistructured virtual human interviews. At the level of aggregate dialogue-level features, we identify several significant differences between subjects with depression and PTSD when compared to nondistressed subjects. At a more fine-grained level, we show that significant differences can also be found among features that represent subject behavior during specific moments in the dialogues. Finally, we present statistical classification results that suggest the potential for automatic assessment of psychological distress in individual interactions with a virtual human dialogue system."
W12-1611,Reinforcement Learning of Question-Answering Dialogue Policies for Virtual Museum Guides,2012,23,24,2,0,38434,teruhisa misu,Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"We use Reinforcement Learning (RL) to learn question-answering dialogue policies for a real-world application. We analyze a corpus of interactions of museum visitors with two virtual characters that serve as guides at the Museum of Science in Boston, in order to build a realistic model of user behavior when interacting with these characters. A simulated user is built based on this model and used for learning the dialogue policy of the virtual characters using RL. Our learned policy outperforms two baselines (including the original dialogue policy that was used for collecting the corpus) in a simulation setting."
georgila-etal-2012-practical,Practical Evaluation of Human and Synthesized Speech for Virtual Human Dialogue Systems,2012,14,10,1,1,16796,kallirroi georgila,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"The current practice in virtual human dialogue systems is to use professional human recordings or limited-domain speech synthesis. Both approaches lead to good performance but at a high cost. To determine the best trade-off between performance and cost, we perform a systematic evaluation of human and synthesized voices with regard to naturalness, conversational aspect, and likability. We vary the type (in-domain vs. out-of-domain), length, and content of utterances, and take into account the age and native language of raters as well as their familiarity with speech synthesis. We present detailed results from two studies, a pilot one and one run on Amazon's Mechanical Turk. Our results suggest that a professional human voice can supersede both an amateur human voice and synthesized voices. Also, a high-quality general-purpose voice or a good limited-domain voice can perform better than amateur human recordings. We do not find any significant differences between the performance of a high-quality general-purpose voice and a limited-domain voice, both trained with speech recorded by actors. As expected, the high-quality general-purpose voice is rated higher than the limited-domain voice for out-of-domain sentences and lower for in-domain sentences. There is also a trend for long or negative-content utterances to receive lower ratings."
W11-2030,An Annotation Scheme for Cross-Cultural Argumentation and Persuasion Dialogues,2011,30,6,1,1,16796,kallirroi georgila,Proceedings of the {SIGDIAL} 2011 Conference,0,"We present a novel annotation scheme for cross-cultural argumentation and persuasion dialogues. This scheme is an adaptation of existing coding schemes on negotiation, following a review of literature on cross-cultural differences in negotiation styles. The scheme has been refined through application to coding both two-party and multi-party negotiation dialogues in three different domains, and is general enough to be applicable to different domains with few if any extensions. Dialogues annotated with the scheme have been used to successfully learn culture-specific dialogue policies for argumentation and persuasion."
W10-4321,Learning Dialogue Strategies from Older and Younger Simulated Users,2010,14,15,1,1,16796,kallirroi georgila,Proceedings of the {SIGDIAL} 2010 Conference,0,"Older adults are a challenging user group because their behaviour can be highly variable. To the best of our knowledge, this is the first study where dialogue strategies are learned and evaluated with both simulated younger users and simulated older users. The simulated users were derived from a corpus of interactions with a strict system-initiative spoken dialogue system (SDS). Learning from simulated younger users leads to a policy which is close to one of the dialogue strategies of the underlying SDS, while the simulated older users allow us to learn more flexible dialogue strategies that accommodate mixed initiative. We conclude that simulated users are a useful technique for modelling the behaviour of new user groups."
W10-4343,Cross-Domain Speech Disfluency Detection,2010,12,12,1,1,16796,kallirroi georgila,Proceedings of the {SIGDIAL} 2010 Conference,0,"We build a model for speech disfluency detection based on conditional random fields (CRFs) using the Switchboard corpus. This model is then applied to a new domain without any adaptation. We show that a technique for detecting speech disfluencies based on Integer Linear Programming (ILP) (Georgila, 2009) significantly outperforms CRFs. In particular, in terms of F-score and NIST Error Rate the absolute improvement of ILP over CRFs exceeds 20% and 25% respectively. We conclude that ILP is an approach with great potential for speech disfluency detection when there is a lack or shortage of indomain data for training."
yao-etal-2010-practical,Practical Evaluation of Speech Recognizers for Virtual Human Dialogue Systems,2010,15,8,3,0,37412,xuchen yao,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"We perform a large-scale evaluation of multiple off-the-shelf speech recognizers across diverse domains for virtual human dialogue systems. Our evaluation is aimed at speech recognition consumers and potential consumers with limited experience with readily available recognizers. We focus on practical factors to determine what levels of performance can be expected from different available recognizers in various projects featuring different types of conversational utterances. Our results show that there is no single recognizer that outperforms all other recognizers in all domains. The performance of each recognizer may vary significantly depending on the domain, the size and perplexity of the corpus, the out-of-vocabulary rate, and whether acoustic and language model adaptation has been used or not. We expect that our evaluation will prove useful to other speech recognition consumers, especially in the dialogue community, and will shed some light on the key problem in spoken dialogue systems of selecting the most suitable available speech recognition system for a particular application, and what impact training will have."
W09-3901,Evaluating the Effectiveness of Information Presentation in a Full End-To-End Dialogue System,2009,10,8,2,0,46801,taghi paksima,Proceedings of the {SIGDIAL} 2009 Conference,0,"Recent work on information presentation in dialogue systems combines user modelling (UM) and stepwise refinement through clustering and summarisation (SR) in the UMSR approach. An evaluation in which participants rated dialogue transcripts showed that UMSR presents complex trade-offs understandably, provides users with a good overview of their options, and increases users' confidence that all relevant options have been presented (Demberg and Moore, 2006). In this paper, we evaluate the effectiveness of the UMSR approach in a more realistic setting, by incorporating this information presentation technique into a full end-to-end dialogue system in the city information domain, and comparing it with the traditional approach of presenting information sequentially. Our results suggest that despite complications associated with a real dialogue system setting, the UMSR model retains its advantages."
N09-2028,Using Integer Linear Programming for Detecting Speech Disfluencies,2009,7,22,1,1,16796,kallirroi georgila,"Proceedings of Human Language Technologies: The 2009 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics, Companion Volume: Short Papers",0,"We present a novel two-stage technique for detecting speech disfluencies based on Integer Linear Programming (ILP). In the first stage we use state-of-the-art models for speech disfluency detection, in particular, hidden-event language models, maximum entropy models and conditional random fields. During testing each model proposes possible disfluency labels which are then assessed in the presence of local and global constraints using ILP. Our experimental results show that by using ILP we can improve the performance of our models with negligible cost in processing time. The less training data is available the larger the improvement due to ILP."
P08-2013,Simulating the Behaviour of Older versus Younger Users when Interacting with Spoken Dialogue Systems,2008,6,13,1,1,16796,kallirroi georgila,"Proceedings of ACL-08: HLT, Short Papers",0,"In this paper we build user simulations of older and younger adults using a corpus of interactions with a Wizard-of-Oz appointment scheduling system. We measure the quality of these models with standard metrics proposed in the literature. Our results agree with predictions based on statistical analysis of the corpus and previous findings about the diversity of older people's behaviour. Furthermore, our results show that these metrics can be a good predictor of the behaviour of different types of users, which provides evidence for the validity of current user simulation evaluation metrics."
georgila-etal-2008-fully,A Fully Annotated Corpus for Studying the Effect of Cognitive Ageing on Users{'} Interactions with Spoken Dialogue Systems,2008,24,18,1,1,16796,kallirroi georgila,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"In this paper we present a corpus of interactions of older and younger users with nine different dialogue systems. The corpus has been fully transcribed and annotated with dialogue acts and ÂInformation State UpdateÂ (ISU) representations of dialogue context. Users not only underwent a comprehensive battery of cognitive assessments, but they also rated the usability of each dialogue system on a standardised questionnaire. In this paper, we discuss the corpus collection and outline the semi-automatic methods we used for discourse-level annotations. We expect that the corpus will provide a key resource for modelling older peopleÂs interaction with spoken dialogue systems."
J08-4002,Hybrid Reinforcement/Supervised Learning of Dialogue Policies from Fixed Data Sets,2008,46,87,3,0,856,james henderson,Computational Linguistics,0,"We propose a method for learning dialogue management policies from a fixed data set. The method addresses the challenges posed by Information State Update (ISU)-based dialogue systems, which represent the state of a dialogue as a large set of features, resulting in a very large state space and a huge policy space. To address the problem that any fixed data set will only provide information about small portions of these state and policy spaces, we propose a hybrid model that combines reinforcement learning with supervised learning. The reinforcement learning is used to optimize a measure of dialogue reward, while the supervised learning is used to restrict the learned policy to the portions of these spaces for which we have data. We also use linear function approximation to address the need to generalize from a fixed amount of data to large state spaces. To demonstrate the effectiveness of this method on this challenging task, we trained this model on the COMMUNICATOR corpus, to which we have added annotations for user actions and Information States. When tested with a user simulation trained on a different part of the same data set, our hybrid model outperforms a pure supervised learning model and a pure reinforcement learning model. It also outperforms the hand-crafted systems on the COMMUNICATOR data, according to automatic evaluation measures, improving over the average COMMUNICATOR system policy by 10%. The proposed method will improve techniques for bootstrapping and automatic optimization of dialogue management policies from limited initial data sets."
E06-2009,An {ISU} Dialogue System Exhibiting Reinforcement Learning of Dialogue Policies: Generic Slot-Filling in the {TALK} In-car System,2006,5,78,2,0.313393,2551,oliver lemon,Demonstrations,0,"We demonstrate a multimodal dialogue system using reinforcement learning for in-car scenarios, developed at Edinburgh University and Cambridge University for the TALK project. This prototype is the first Information State Update (ISU) dialogue system to exhibit reinforcement learning of dialogue strategies, and also has a fragmentary clarification feature. This paper describes the main components and functionality of the system, as well as the purposes and future use of the system, and surveys the research issues involved in its construction. Evaluation of this system (i.e. comparing the baseline system with handcoded vs. learnt dialogue policies) is ongoing, and the demonstration will show both."
2005.sigdial-1.6,Quantitative Evaluation of User Simulation Techniques for Spoken Dialogue Systems,2005,9,126,2,0,47840,jost schatzmann,Proceedings of the 6th SIGdial Workshop on Discourse and Dialogue,0,None
georgila-etal-2004-graphical,A graphical Tool for Handling Rule Grammars in {J}ava Speech Grammar Format,2004,1,1,1,1,16796,kallirroi georgila,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"This paper describes a graphical tool used for generating and depicting rule grammars in the Java Speech Grammar Format (JSGF), which has been developed in the framework of the EC-funded research project GEMINI (Generic Environment for Multilingual Interactive Natural Interfaces, IST-2001-32343). A vocabulary builder component that produces the phonetic transcription of the words included in the grammar file is also incorporated into the tool. Currently, the tool supports embedded grapheme-to-phoneme conversion only for Greek in SAMPA format. However, a language-independent function is included that enables the user to write context-dependent rules for symbol conversions (both grapheme-to-phoneme and phoneme-to-grapheme). Manual vs. tool-based handling of grammars are compared and evaluated in terms of time required for grammar creation and efficiency."
georgila-etal-2000-graphical,A Graphical Parametric Language-Independent Tool for the Annotation of Speech Corpora,2000,0,1,1,1,16796,kallirroi georgila,Proceedings of the Second International Conference on Language Resources and Evaluation ({LREC}{'}00),0,None
