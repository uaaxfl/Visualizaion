2021.mtsummit-research.9,Like Chalk and Cheese? On the Effects of Translationese in {MT} Training,2021,-1,-1,2,0.299981,5046,samuel larkin,Proceedings of Machine Translation Summit XVIII: Research Track,0,We revisit the topic of translation direction in the data used for training neural machine translation systems and focusing on a real-world scenario with known translation direction and imbalances in translation direction: the Canadian Hansard. According to automatic metrics and we observe that using parallel data that was produced in the {``}matching{''} translation direction (Authentic source and translationese target) improves translation quality. In cases of data imbalance in terms of translation direction and we find that tagging of translation direction can close the performance gap. We perform a human evaluation that differs slightly from the automatic metrics and but nevertheless confirms that for this French-English dataset that is known to contain high-quality translations and authentic or tagged mixed source improves over translationese source for training.
2020.coling-main.576,Human or Neural Translation?,2020,-1,-1,6,0,206,shivendra bhardwaj,Proceedings of the 28th International Conference on Computational Linguistics,0,"Deep neural models tremendously improved machine translation. In this context, we investigate whether distinguishing machine from human translations is still feasible. We trained and applied 18 classifiers under two settings: a monolingual task, in which the classifier only looks at the translation; and a bilingual task, in which the source text is also taken into consideration. We report on extensive experiments involving 4 neural MT systems (Google Translate, DeepL, as well as two systems we trained) and varying the domain of texts. We show that the bilingual task is the easiest one and that transfer-based deep-learning classifiers perform best, with mean accuracies around 85{\%} in-domain and 75{\%} out-of-domain ."
K19-1020,Fully Unsupervised Crosslingual Semantic Textual Similarity Metric Based on {BERT} for Identifying Parallel Data,2019,0,1,2,0.147668,13775,chikiu lo,Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL),0,"We present a fully unsupervised crosslingual semantic textual similarity (STS) metric, based on contextual embeddings extracted from BERT {--} Bidirectional Encoder Representations from Transformers (Devlin et al., 2019). The goal of crosslingual STS is to measure to what degree two segments of text in different languages express the same meaning. Not only is it a key task in crosslingual natural language understanding (XLU), it is also particularly useful for identifying parallel resources for training and evaluating downstream multilingual natural language processing (NLP) applications, such as machine translation. Most previous crosslingual STS methods relied heavily on existing parallel resources, thus leading to a circular dependency problem. With the advent of massively multilingual context representation models such as BERT, which are trained on the concatenation of non-parallel data from each language, we show that the deadlock around parallel resources can be broken. We perform intrinsic evaluations on crosslingual STS data sets and extrinsic evaluations on parallel corpus filtering and human translation equivalence assessment tasks. Our results show that the unsupervised crosslingual STS metric using BERT without fine-tuning achieves performance on par with supervised or weakly supervised approaches."
W18-6480,Measuring sentence parallelism using Mahalanobis distances: The {NRC} unsupervised submissions to the {WMT}18 Parallel Corpus Filtering shared task,2018,0,1,4,0,12351,patrick littell,Proceedings of the Third Conference on Machine Translation: Shared Task Papers,0,"The WMT18 shared task on parallel corpus filtering (Koehn et al., 2018b) challenged teams to score sentence pairs from a large high-recall, low-precision web-scraped parallel corpus (Koehn et al., 2018a). Participants could use existing sample corpora (e.g. past WMT data) as a supervisory signal to learn what a {``}clean{''} corpus looks like. However, in lower-resource situations it often happens that the target corpus of the language is the \textit{only} sample of parallel text in that language. We therefore made several unsupervised entries, setting ourselves an additional constraint that we not utilize the additional clean parallel corpora. One such entry fairly consistently scored in the top ten systems in the 100M-word conditions, and for one task{---}translating the European Medicines Agency corpus (Tiedemann, 2009){---}scored among the best systems even in the 10M-word conditions."
W18-6481,Accurate semantic textual similarity for cleaning noisy parallel corpora using semantic machine translation evaluation metric: The {NRC} supervised submissions to the Parallel Corpus Filtering task,2018,0,3,2,0.173114,13775,chikiu lo,Proceedings of the Third Conference on Machine Translation: Shared Task Papers,0,"We present our semantic textual similarity approach in filtering a noisy web crawled parallel corpus using YiSi{---}a novel semantic machine translation evaluation metric. The systems mainly based on this supervised approach perform well in the WMT18 Parallel Corpus Filtering shared task (4th place in 100-million-word evaluation, 8th place in 10-million-word evaluation, and 6th place overall, out of 48 submissions). In fact, our best performing system{---}NRC-yisi-bicov is one of the only four submissions ranked top 10 in both evaluations. Our submitted systems also include some initial filtering steps for scaling down the size of the test corpus and a final redundancy removal step for better semantic and token coverage of the filtered corpus. In this paper, we also describe our unsuccessful attempt in automatically synthesizing a noisy parallel development corpus for tuning the weights to combine different parallelism and fluency features."
S16-1102,{CNRC} at {S}em{E}val-2016 Task 1: Experiments in Crosslingual Semantic Textual Similarity,2016,7,2,3,0.173114,13775,chikiu lo,Proceedings of the 10th International Workshop on Semantic Evaluation ({S}em{E}val-2016),0,None
2016.amta-users.28,Machine Translation of {C}anadian Court Decisions,2016,-1,-1,2,0,36243,lucie langlois,Conferences of the Association for Machine Translation in the Americas: MT Users' Track,0,None
S14-2030,{CNRC}-{TMT}: Second Language Writing Assistant System Description,2014,14,1,2,0.186844,653,cyril goutte,Proceedings of the 8th International Workshop on Semantic Evaluation ({S}em{E}val 2014),0,"We describe the system entered by the National Research Council Canada in the SemEval-2014 L2 writing assistant task. Our system relies on a standard Phrase-Based Statistical Machine Translation trained on generic, publicly available data. Translations are produced by taking the already translated part of the sentence as fixed context. We show that translation systems can address the L2 writing assistant task, reaching out-of-five word-based accuracy above 80 percent for 3 out of 4 language pairs. We also present a brief analysis of remaining errors."
2014.amta-researchers.6,Clean data for training statistical {MT}: the case of {MT} contamination,2014,-1,-1,1,1,5047,michel simard,Proceedings of the 11th Conference of the Association for Machine Translation in the Americas: MT Researchers Track,0,"Users of Statistical Machine Translation (SMT) sometimes turn to the Web to obtain data to train their systems. One problem with this approach is the potential for {``}MT contamination{''}: when large amounts of parallel data are collected automatically, there is a risk that a non-negligible portion consists of machine-translated text. Theoretically, using this kind of data to train SMT systems is likely to reinforce the errors committed by other systems, or even by an earlier versions of the same system. In this paper, we study the effect of MT-contaminated training data on SMT quality, by performing controlled simulations under a wide range of conditions. Our experiments highlight situations in which MT contamination can be harmful, and assess the potential of decontamination techniques."
2013.mtsummit-papers.24,{PEP}r: Post-Edit Propagation Using Phrase-based Statistical Machine Translation,2013,-1,-1,1,1,5047,michel simard,Proceedings of Machine Translation Summit XIV: Papers,0,None
W12-3156,The Trouble with {SMT} Consistency,2012,13,30,2,0,6058,marine carpuat,Proceedings of the Seventh Workshop on Statistical Machine Translation,0,"SMT typically models translation at the sentence level, ignoring wider document context. Does this hurt the consistency of translated documents? Using a phrase-based SMT system in various data conditions, we show that SMT translates documents remarkably consistently, even without document knowledge. Nevertheless, translation inconsistencies often indicate translation errors. However, unlike in human translation, these errors are rarely due to terminology inconsistency. They are more often symptoms of deeper issues with SMT models instead."
J12-2007,"Book Review: Bitext Alignment by J{\\\o}rg Tiedemann""",2012,-1,-1,1,1,5047,michel simard,Computational Linguistics,0,None
2012.amta-papers.26,A Poor Man{'}s Translation Memory Using Machine Translation Evaluation Metrics,2012,24,7,1,1,5047,michel simard,Proceedings of the 10th Conference of the Association for Machine Translation in the Americas: Research Papers,0,"We propose straightforward implementations of translation memory (TM) functionality for research purposes, using machine translation evaluation metrics as similarity functions. Experiments under various conditions demonstrate the effectiveness of the approach, but also highlight problems in evaluating the results using an MT evaluation methodology."
2009.mtsummit-papers.14,Phrase-based Machine Translation in a Computer-assisted Translation Environment,2009,-1,-1,1,1,5047,michel simard,Proceedings of Machine Translation Summit XII: Papers,0,None
W07-0724,{NRC}{`}s {PORTAGE} System for {WMT} 2007,2007,10,38,2,0,28492,nicola ueffing,Proceedings of the Second Workshop on Statistical Machine Translation,0,"We present the PORTAGE statistical machine translation system which participated in the shared task of the ACL 2007 Second Workshop on Statistical Machine Translation. The focus of this description is on improvements which were incorporated into the system over the last year. These include adapted language models, phrase table pruning, an IBM1-based decoder feature, and rescoring with posterior probabilities."
W07-0728,Rule-Based Translation with Statistical Phrase-Based Post-Editing,2007,5,109,1,1,5047,michel simard,Proceedings of the Second Workshop on Statistical Machine Translation,0,"This article describes a machine translation system based on an automatic post-editing strategy: initially translate the input text into the target-language using a rule-based MT system, then automatically post-edit the output using a statistical phrase-based system. An implementation of this approach based on the SYSTRAN and PORTAGE MT systems was used in the shared task of the Second Workshop on Statistical Machine Translation. Experimental results on the test data of the previous campaign are presented."
N07-1064,Statistical Phrase-Based Post-Editing,2007,9,114,1,1,5047,michel simard,Human Language Technologies 2007: The Conference of the North {A}merican Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference,0,"We propose to use a statistical phrasebased machine translation system in a post-editing task: the system takes as input raw machine translation output (from a commercial rule-based MT system), and produces post-edited target-language text. We report on experiments that were performed on data collected in precisely such a setting: pairs of raw MT output and their manually post-edited versions. In our evaluation, the output of our automatic post-editing (APE) system is not only better quality than the rule-based MT (both in terms of the BLEU and TER metrics), it is also better than the output of a stateof-the-art phrase-based MT system used in standalone translation mode. These results indicate that automatic post-editing constitutes a simple and efcient way of combining rule-based and statistical MT technologies."
2007.mtsummit-papers.34,Domain adaptation of {MT} systems through automatic post-editing,2007,-1,-1,3,0,33186,pierre isabelle,Proceedings of Machine Translation Summit XI: Papers,0,None
W06-3118,{PORTAGE}: with Smoothed Phrase Tables and Segment Choice Models,2006,7,10,5,0,43880,howard johnson,Proceedings on the Workshop on Statistical Machine Translation,0,Improvements to Portage and its participation in the shared task of NAACL 2006 Workshop on Statistical Machine Translation are described. Promising ideas in phrase table smoothing and global distortion using feature-rich models are discussed as well as numerous improvements in the software base.
N06-1004,Segment Choice Models: Feature-Rich Models for Global Distortion in Statistical Machine Translation,2006,15,10,3,0,17283,roland kuhn,"Proceedings of the Human Language Technology Conference of the {NAACL}, Main Conference",0,"This paper presents a new approach to distortion (phrase reordering) in phrase-based machine translation (MT). Distortion is modeled as a sequence of choices during translation. The approach yields trainable, probabilistic distortion models that are global: they assign a probability to each possible phrase reordering. These segment choice models (SCMs) can be trained on segment-aligned sentence pairs; they can be applied during decoding or rescoring. The approach yields a metric called distortion perplexity (disperp) for comparing SCMs offline on test data, analogous to perplexity for language models. A decision-tree-based SCM is tested on Chinese-to-English translation, and outperforms a baseline distortion penalty approach at the 99% confidence level."
H05-1095,Translating with Non-contiguous Phrases,2005,19,80,1,1,5047,michel simard,Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing,0,"This paper presents a phrase-based statistical machine translation method, based on non-contiguous phrases, i.e. phrases with gaps. A method for producing such phrases from a word-aligned corpora is proposed. A statistical translation model is also presented that deals such phrases, as well as a training method based on the maximization of translation accuracy, as measured with the NIST evaluation metric. Translations are produced by means of a beam-search decoder. Experimental results are presented, that demonstrate how the proposed method allows to better generalize from the training data."
2005.jeptalnrecital-long.24,Une approche {\\`a} la traduction automatique statistique par segments discontinus,2005,-1,-1,1,1,5047,michel simard,Actes de la 12{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Cet article pr{\'e}sente une m{\'e}thode de traduction automatique statistique bas{\'e}e sur des segments non-continus, c{'}est-{\`a}-dire des segments form{\'e}s de mots qui ne se pr{\'e}sentent pas n{\'e}c{\'e}ssairement de fa{\c{c}}on contigu{\""e} dans le texte. On propose une m{\'e}thode pour produire de tels segments {\`a} partir de corpus align{\'e}s au niveau des mots. On pr{\'e}sente {\'e}galement un mod{\`e}le de traduction statistique capable de tenir compte de tels segments, de m{\^e}me qu{'}une m{\'e}thode d{'}apprentissage des param{\`e}tres du mod{\`e}le visant {\`a} maximiser l{'}exactitude des traductions produites, telle que mesur{\'e}e avec la m{\'e}trique NIST. Les traductions optimales sont produites par le biais d{'}une recherche en faisceau. On pr{\'e}sente finalement des r{\'e}sultats exp{\'e}rimentaux, qui d{\'e}montrent comment la m{\'e}thode propos{\'e}e permet une meilleure g{\'e}n{\'e}ralisation {\`a} partir des donn{\'e}es d{'}entra{\^\i}nement."
W03-0304,Statistical Translation Alignment with Compositionality Constraints,2003,6,16,1,1,5047,michel simard,Proceedings of the {HLT}-{NAACL} 2003 Workshop on Building and Using Parallel Texts: Data Driven Machine Translation and Beyond,0,"This article presents a method for aligning words between translations, that imposes a compositionality constraint on alignments produced with statistical translation models. Experiments conducted within the WPT-03 shared task on word alignment demonstrate the effectiveness of the proposed approach."
W03-0313,Translation Spotting for Translation Memories,2003,16,35,1,1,5047,michel simard,Proceedings of the {HLT}-{NAACL} 2003 Workshop on Building and Using Parallel Texts: Data Driven Machine Translation and Beyond,0,"The term translation spotting (TS) refers to the task of identifying the target-language (TL) words that correspond to a given set of source-language (SL) words in a pair of text segments known to be mutual translations. This article examines this task within the context of a sub-sentential translation-memory system, i.e. a translation support tool capable of proposing translations for portions of a SL sentence, extracted from an archive of existing translations. Different methods are proposed, based on a statistical translation model. These methods take advantage of certain characteristics of the application, to produce TL segments submitted to constraints of contiguity and compositionality. Experiments show that imposing these constraints allows important gains in accuracy, with regard to the most probable alignments predicted by the model."
J03-3003,Embedding Web-Based Statistical Translation Models in Cross-Language Information Retrieval,2003,64,103,3,0,5398,wessel kraaij,Computational Linguistics,0,"Although more and more language pairs are covered by machine translation (MT) services, there are still many pairs that lack translation resources. Cross-language information retrieval (CLIR) is an application that needs translation functionality of a relatively low level of sophistication, since current models for information retrieval (IR) are still based on a bag of words. The Web provides a vast resource for the automatic construction of parallel corpora that can be used to train statistical translation models automatically. The resulting translation models can be embedded in several ways in a retrieval model. In this article, we will investigate the problem of automatically mining parallel texts from the Web and different ways of integrating the translation models within the retrieval process. Our experiments on standard test collections for CLIR show that the Web-based translation models can surpass commercial MT systems in CLIR tasks. These results open the perspective of constructing a fully automatic query translation device for CLIR at a very low cost."
2003.mtsummit-papers.15,Statistical machine translation: rapid development with limited resources,2003,-1,-1,6,0.293982,3518,george foster,Proceedings of Machine Translation Summit IX: Papers,0,"We describe an experiment in rapid development of a statistical machine translation (SMT) system from scratch, using limited resources: under this heading we include not only training data, but also computing power, linguistic knowledge, programming effort, and absolute time."
2003.jeptalnrecital-long.18,De la traduction probabiliste aux m{\\'e}moires de traduction (ou l{'}inverse),2003,12,2,2,0.507,7084,philippe langlais,Actes de la 10{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"En d{\'e}pit des travaux r{\'e}alis{\'e}s cette derni{\`e}re d{\'e}cennie dans le cadre g{\'e}n{\'e}ral de la traduction probabiliste, nous sommes toujours bien loin du jour o{\`u} un engin de traduction automatique (probabiliste ou pas) sera capable de r{\'e}pondre pleinement aux besoins d{'}un traducteur professionnel. Dans une {\'e}tude r{\'e}cente (Langlais, 2002), nous avons montr{\'e} comment un engin de traduction probabiliste pouvait b{\'e}n{\'e}ficier de ressources terminologiques ext{\'e}rieures. Dans cette {\'e}tude, nous montrons que les techniques de traduction probabiliste peuvent {\^e}tre utilis{\'e}es pour extraire des informations sous-phrastiques d{'}une m{\'e}moire de traduction. Ces informations peuvent {\`a} leur tour s{'}av{\'e}rer utiles {\`a} un engin de traduction probabiliste. Nous rapportons des r{\'e}sultats sur un corpus de test de taille importante en utilisant la m{\'e}moire de traduction d{'}un concordancier bilingue commercial."
langlais-simard-2002-merging,Merging example-based and statistical machine translation: an experiment,2002,12,17,2,0.507,7084,philippe langlais,Proceedings of the 5th Conference of the Association for Machine Translation in the Americas: Technical Papers,0,"Despite the exciting work accomplished over the past decade in the field of Statistical Machine Translation (SMT), we are still far from the point of being able to say that machine translation fully meets the needs of real-life users. In a previous study [6], we have shown how a SMT engine could benefit from terminological resources, especially when translating texts very different from those used to train the system. In the present paper, we discuss the opening of SMT to examples automatically extracted from a Translation Memory (TM). We report results on a fair-sized translation task using the database of a commercial bilingual concordancer."
2001.mtsummit-papers.60,Sub-sentential exploitation of translation memories,2001,11,21,1,1,5047,michel simard,Proceedings of Machine Translation Summit VIII,0,"Translation memory systems (TMS) are a family of computer tools whose purpose is to facilitate and encourage the re-use of existing translations. By searching a database of past translations, these systems can retrieve the translation of whole segments of text and propose them to the translator for re-use. However, the usefulness of existing TMS{'}s is limited by the nature of the text segments that that they are able to put in correspondence, generally whole sentences. This article examines the potential of a type of system that is able to recuperate the translation of sub-sentential sequences of words."
2001.jeptalnrecital-long.22,R{\\'e}cup{\\'e}ration de segments sous-phrastiques dans une m{\\'e}moire de traduction,2001,10,1,2,0.638298,7084,philippe langlais,Actes de la 8{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"L{'}utilit{\'e} des outils d{'}aide {\`a} la traduction reposant sur les m{\'e}moires de traduction est souvent limit{\'e}e par la nature des segments que celles-ci mettent en correspondance, le plus souvent des phrases enti{\`e}res. Cet article examine le potentiel d{'}un type de syst{\`e}me qui serait en mesure de r{\'e}cup{\'e}rer la traduction de s{\'e}quences de mots de longueur arbitraire."
macklovitch-etal-2000-transsearch,{T}rans{S}earch: A Free Translation Memory on the World Wide Web,2000,7,41,2,0,36244,elliott macklovitch,Proceedings of the Second International Conference on Language Resources and Evaluation ({LREC}{'}00),0,"A translation memory is an archive of existing translations, structured in such a way as to promote translation re-use. Under this broad definition, an interactive bilingual concordancing tool like the RALIxe2x80x99s TransSearch system certainly qualifies as a translation memory. This paper describes the Web-based version of TransSearch, which, for the last three years, has given Internet users access to a large English-French translation database made up of Canadian parliamentary debates. Despite the fact that the RALI has done very little to publicize the availability of TransSearch on the Web, the system has been attracting a growing and impressive number of users. We present some basic data on who is using TransSearch and how, data which was collected from the systemxe2x80x99s log file and by means of a questionnaire recently added to our Web site. We conclude with a call to the international community to help set up a network of bitextual databases like TransSearch, which translators around the world could freely access over the Web."
W99-0602,Text-Translation Alignment: Three Languages Are Better Than Two,1999,22,45,1,1,5047,michel simard,1999 Joint {SIGDAT} Conference on Empirical Methods in Natural Language Processing and Very Large Corpora,0,None
W98-1504,Automatic Insertion of Accents in {F}rench Text,1998,0,27,1,1,5047,michel simard,Proceedings of the Third Conference on Empirical Methods for Natural Language Processing,0,None
P98-1117,Methods and Practical Issues in Evaluating Alignment Techniques,1998,15,44,2,0.638298,7084,philippe langlais,"36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 1",1,"This paper describes the work achieved in the first half of a 4-year cooperative research project (ARCADE), financed by AUPELF-UREF. The project is devoted to the evaluation of parallel text alignment techniques. In its first period ARCADE ran a competition between six systems on a sentence-to-sentence alignment task which yielded two main types of results. First, a large reference bilingual corpus comprising of texts of different genres was created, each presenting various degrees of difficulty with respect to the alignment task.Second, significant methodological progress was made both on the evaluation protocols and metrics, and the algorithms used by the different systems. For the second phase, which is now underway, ARCADE has been opened to a larger number of teams who will tackle the problem of word-level alignment."
C98-1113,Methods and Practical Issues in Evaluating Alignment Techniques,1998,15,44,2,0.638298,7084,philippe langlais,{COLING} 1998 Volume 1: The 17th International Conference on Computational Linguistics,0,"This paper describes the work achieved in the first half of a 4-year cooperative research project (ARCADE), financed by AUPELF-UREF. The project is devoted to the evaluation of parallel text alignment techniques. In its first period ARCADE ran a competition between six systems on a sentence-to-sentence alignment task which yielded two main types of results. First, a large reference bilingual corpus comprising of texts of different genres was created, each presenting various degrees of difficulty with respect to the alignment task.Second, significant methodological progress was made both on the evaluation protocols and metrics, and the algorithms used by the different systems. For the second phase, which is now underway, ARCADE has been opened to a larger number of teams who will tackle the problem of word-level alignment."
1996.amta-1.14,Bilingual sentence alignment: balancing robustness and accuracy,1996,-1,-1,1,1,5047,michel simard,Conference of the Association for Machine Translation in the Americas,0,None
1992.tmi-1.7,Using cognates to align sentences in bilingual corpora,1992,-1,-1,1,1,5047,michel simard,Proceedings of the Fourth Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,None
