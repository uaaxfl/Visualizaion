2021.eacl-main.57,{CTC}-based Compression for Direct Speech Translation,2021,-1,-1,2,0,5746,marco gaido,Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume,0,"Previous studies demonstrated that a dynamic phone-informed compression of the input audio is beneficial for speech translation (ST). However, they required a dedicated model for phone recognition and did not test this solution for direct ST, in which a single model translates the input audio into the target language without intermediate representations. In this work, we propose the first method able to perform a dynamic compression of the input in direct ST models. In particular, we exploit the Connectionist Temporal Classification (CTC) to compress the input sequence according to its phonetic characteristics. Our experiments demonstrate that our solution brings a 1.3-1.5 BLEU improvement over a strong baseline on two language pairs (English-Italian and English-German), contextually reducing the memory footprint by more than 10{\%}."
2021.acl-long.224,Cascade versus Direct Speech Translation: Do the Differences Still Make a Difference?,2021,-1,-1,2,0,8246,luisa bentivogli,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),1,"Five years after the first published proofs of concept, direct approaches to speech translation (ST) are now competing with traditional cascade solutions. In light of this steady progress, can we claim that the performance gap between the two is closed? Starting from this question, we present a systematic comparison between state-of-the-art systems representative of the two paradigms. Focusing on three language directions (English-German/Italian/Spanish), we conduct automatic and manual evaluations, exploiting high-quality professional post-edits and annotations. Our multi-faceted analysis on one of the few publicly available ST benchmarks attests for the first time that: i) the gap between the two paradigms is now closed, and ii) the subtle differences observed in their behavior are not sufficient for humans neither to distinguish them nor to prefer one over the other."
C18-1054,A Comparison of Transformer and Recurrent Neural Networks on Multilingual Neural Machine Translation,2018,28,3,2,0,5082,surafel lakew,Proceedings of the 27th International Conference on Computational Linguistics,0,"Recently, neural machine translation (NMT) has been extended to multilinguality, that is to handle more than one translation direction with a single system. Multilingual NMT showed competitive performance against pure bilingual systems. Notably, in low-resource settings, it proved to work effectively and efficiently, thanks to shared representation space that is forced across languages and induces a sort of transfer-learning. Furthermore, multilingual NMT enables so-called zero-shot inference across language pairs never seen at training time. Despite the increasing interest in this framework, an in-depth analysis of what a multilingual NMT model is capable of and what it is not is still missing. Motivated by this, our work (i) provides a quantitative and comparative analysis of the translations produced by bilingual, multilingual and zero-shot systems; (ii) investigates the translation quality of two of the currently dominant neural architectures in MT, which are the Recurrent and the Transformer ones; and (iii) quantitatively explores how the closeness between languages influences the zero-shot translation. Our analysis leverages multiple professional post-edits of automatic translations by several different systems and focuses both on automatic standard metrics (BLEU and TER) and on widely used error categories, which are lexical, morphology, and word order errors."
W17-4801,Findings of the 2017 {D}isco{MT} Shared Task on Cross-lingual Pronoun Prediction,2017,0,3,6,0,4241,sharid loaiciga,Proceedings of the Third Workshop on Discourse in Machine Translation,0,"We describe the design, the setup, and the evaluation results of the DiscoMT 2017 shared task on cross-lingual pronoun prediction. The task asked participants to predict a target-language pronoun given a source-language pronoun in the context of a sentence. We further provided a lemmatized target-language human-authored translation of the source sentence, and automatic word alignments between the source sentence words and the target-language lemmata. The aim of the task was to predict, for each target-language pronoun placeholder, the word that should replace it from a small, closed set of classes, using any type of information that can be extracted from the entire document. We offered four subtasks, each for a different language pair and translation direction: English-to-French, English-to-German, German-to-English, and Spanish-to-English. Five teams participated in the shared task, making submissions for all language pairs. The evaluation results show that most participating teams outperformed two strong n-gram-based language model-based baseline systems by a sizable margin."
W16-2345,Findings of the 2016 {WMT} Shared Task on Cross-lingual Pronoun Prediction,2016,20,11,7,0,5894,liane guillou,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,"We describe the design, the evaluation setup, and the results of the 2016 WMT shared task on cross-lingual pronoun prediction. This is a classification task in which participants are asked to provi ..."
L16-1562,{WAGS}: A Beautiful {E}nglish-{I}talian Benchmark Supporting Word Alignment Evaluation on Rare Words,2016,25,0,2,0,8246,luisa bentivogli,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"This paper presents WAGS (Word Alignment Gold Standard), a novel benchmark which allows extensive evaluation of WA tools on out-of-vocabulary (OOV) and rare words. WAGS is a subset of the Common Test section of the Europarl English-Italian parallel corpus, and is specifically tailored to OOV and rare words. WAGS is composed of 6,715 sentence pairs containing 11,958 occurrences of OOV and rare words up to frequency 15 in the Europarl Training set (5,080 English words and 6,878 Italian words), representing almost 3{\%} of the whole text. Since WAGS is focused on OOV/rare words, manual alignments are provided for these words only, and not for the whole sentences. Two off-the-shelf word aligners have been evaluated on WAGS, and results have been compared to those obtained on an existing benchmark tailored to full text alignment. The results obtained confirm that WAGS is a valuable resource, which allows a statistically sound evaluation of WA systems{'} performance on OOV and rare words, as well as extensive data analyses. WAGS is publicly released under a Creative Commons Attribution license."
D16-1025,Neural versus Phrase-Based Machine Translation Quality: a Case Study,2016,29,33,3,0,8246,luisa bentivogli,Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing,0,"Within the field of Statistical Machine Translation (SMT), the neural approach (NMT) has recently emerged as the first technology able to challenge the long-standing dominance of phrase-based approaches (PBMT). In particular, at the IWSLT 2015 evaluation campaign, NMT outperformed well established state-of-the-art PBMT systems on English-German, a language pair known to be particularly hard because of morphology and syntactic differences. To understand in what respects NMT provides better translation quality than PBMT, we perform a detailed analysis of neural versus phrase-based SMT outputs, leveraging high quality post-edits performed by professional translators on the IWSLT data. For the first time, our analysis provides useful insights on what linguistic phenomena are best modeled by neural models -- such as the reordering of verbs -- while pointing out other aspects that remain to be improved."
W15-2501,Pronoun-Focused {MT} and Cross-Lingual Pronoun Prediction: Findings of the 2015 {D}isco{MT} Shared Task on Pronoun Translation,2015,48,33,6,0.163311,670,christian hardmeier,Proceedings of the Second Workshop on Discourse in Machine Translation,0,"We describe the design, the evaluation setup, and the results of the DiscoMT 2015 shared task, which included two subtasks, relevant to both the machine translation (MT) and the discourse communities: (i) pronoun-focused translation, a practical MT task, and (ii) cross-lingual pronoun prediction, a classification task that requires no specific MT expertise and is interesting as a machine learning task in its own right. We focused on the Englishxe2x80x90French language pair, for which MT output is generally of high quality, but has visible issues with pronoun translation due to differences in the pronoun systems of the two languages. Six groups participated in the pronoun-focused translation task and eight groups in the cross-lingual pronoun prediction task."
2015.iwslt-evaluation.1,The {IWSLT} 2015 Evaluation Campaign,2015,18,51,1,1,10592,mauro cettolo,Proceedings of the 12th International Workshop on Spoken Language Translation: Evaluation Campaign,0,None
C14-2028,The {M}ate{C}at Tool,2014,7,36,3,0,3526,marcello federico,"Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: System Demonstrations",0,"We present a new web-based CAT tool providing translators with a professional work environment, integrating translation memories, terminology bases, concordancers, and machine translation. The tool is completely developed as open source software and has been already successfully deployed for business, research and education. The MateCat Tool represents today probably the best available open source platform for investigating, integrating, and evaluating under realistic conditions the impact of new machine translation technology on human post-editing."
2014.iwslt-evaluation.1,Report on the 11th {IWSLT} evaluation campaign,2014,-1,-1,1,1,10592,mauro cettolo,Proceedings of the 11th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"The paper overviews the 11th evaluation campaign organized by the IWSLT workshop. The 2014 evaluation offered multiple tracks on lecture transcription and translation based on the TED Talks corpus. In particular, this year IWSLT included three automatic speech recognition tracks, on English, German and Italian, five speech translation tracks, from English to French, English to German, German to English, English to Italian, and Italian to English, and five text translation track, also from English to French, English to German, German to English, English to Italian, and Italian to English. In addition to the official tracks, speech and text translation optional tracks were offered, globally involving 12 other languages: Arabic, Spanish, Portuguese (B), Hebrew, Chinese, Polish, Persian, Slovenian, Turkish, Dutch, Romanian, Russian. Overall, 21 teams participated in the evaluation, for a total of 76 primary runs submitted. Participants were also asked to submit runs on the 2013 test set (progress test set), in order to measure the progress of systems with respect to the previous year. All runs were evaluated with objective metrics, and submissions for two of the official text translation tracks were also evaluated with human post-editing."
2014.iwslt-evaluation.7,Combined spoken language translation,2014,55,6,15,0.540541,3519,markus freitag,Proceedings of the 11th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"EU-BRIDGE is a European research project which is aimed at developing innovative speech translation technology. One of the collaborative efforts within EU-BRIDGE is to produce joint submissions of up to four different partners to the evaluation campaign at the 2014 International Workshop on Spoken Language Translation (IWSLT). We submitted combined translations to the GermanâEnglish spoken language translation (SLT) track as well as to the GermanâEnglish, EnglishâGerman and EnglishâFrench machine translation (MT) tracks. In this paper, we present the techniques which were applied by the different individual translation systems of RWTH Aachen University, the University of Edinburgh, Karlsruhe Institute of Technology, and Fondazione Bruno Kessler. We then show the combination approach developed at RWTH Aachen University which combined the individual systems. The consensus translations yield empirical gains of up to 2.3 points in BLEU and 1.2 points in TER compared to the best individual system."
2014.amta-workshop.4,Optimized {MT} online learning in computer assisted translation,2014,21,1,2,1,8880,prashant mathur,Workshop on interactive and adaptive machine translation,0,"In this paper we propose a cascading framework for optimizing online learning in machine translation for a computer assisted translation scenario. With the use of online learning, several hyperparameters associated with the learning algorithm are introduced. The number of iterations of online learning can affect the translation quality as well. We discuss these issues and propose a few approaches to optimize the hyperparameters and to find the number of iterations required for online learning. We experimentally show that optimizing hyperparameters and number of iterations in online learning yields consistent improvement against baseline results."
2014.amta-researchers.12,Online multi-user adaptive statistical machine translation,2014,-1,-1,2,1,8880,prashant mathur,Proceedings of the 11th Conference of the Association for Machine Translation in the Americas: MT Researchers Track,0,"In this paper we investigate the problem of adapting a machine translation system to the feedback provided by multiple post-editors. It is well know that translators might have very different post-editing styles and that this variability hinders the application of online learning methods, which indeed assume a homogeneous source of adaptation data. We hence propose multi-task learning to leverage bias information from each single post-editors in order to constrain the evolution of the SMT system. A new framework for significance testing with sentence level metrics is described which shows that Multi-Task learning approaches outperforms existing online learning approaches, with significant gains of 1.24 and 1.88 TER score over a strong online adaptive baseline, on a test set of post-edits produced by four translators texts and on a popular benchmark with multiple references, respectively."
2014.amta-researchers.13,The repetition rate of text as a predictor of the effectiveness of machine translation adaptation,2014,26,7,1,1,10592,mauro cettolo,Proceedings of the 11th Conference of the Association for Machine Translation in the Americas: MT Researchers Track,0,"Since the effectiveness of MT adaptation relies on the text repetitiveness, the question on how to measure repetitions in a text naturally arises. This work deals with the issue of looking for and evaluating text features that might help the prediction of the impact of MT adaptation on translation quality. In particular, the repetition rate metric, we recently proposed, is compared to other features employed in very related NLP tasks. The comparison is carried out through a regression analysis between feature values and MT performance gains by dynamically adapted versus non-adapted MT engines, on five different translation tasks. The main outcome of experiments is that the repetition rate correlates better than any other considered feature with the MT gains yielded by the online adaptation, although using all features jointly results in better predictions than with any single feature."
W13-2237,Online Learning Approaches in Computer Assisted Translation,2013,31,22,2,1,8880,prashant mathur,Proceedings of the Eighth Workshop on Statistical Machine Translation,0,"We present a novel online learning approach for statistical machine translation tailored to the computer assisted translation scenario. With the introduction of a simple online feature, we are able to adapt the translation model on the fly to the corrections made by the translators. Additionally, we do online adaption of the feature weights with a large margin algorithm. Our results show that our online adaptation technique outperforms the static phrase based statistical machine translation system by 6 BLEU points absolute, and a standard incremental adaptation approach by 2 BLEU points absolute."
2013.mtsummit-wptp.13,Issues in incremental adaptation of statistical {MT} from human post-edits,2013,19,7,1,1,10592,mauro cettolo,Proceedings of the 2nd Workshop on Post-editing Technology and Practice,0,"This work investigates a crucial aspect for the integration of MT technology into a CAT environment, that is the ability of MT systems to adapt from the user feedback. In particular, we consider the scenario of an MT system tuned for a specific translation project that after each day of work adapts from the post-edited translations created by the user. We apply and compare different state-of-the-art adaptation methods on post-edited translations generated by two professionals during two days of work with a CAT tool embedding MT suggestions. Both translators worked at the same legal document from English into Italian and German, respectively. Although exactly the same amount of translations was available each day for each language , the application of the same adaptation methods resulted in quite different outcomes. This suggests that adaptation strategies should not be applied blindly, but rather taking into account language specific issues, such as data sparsity."
2013.mtsummit-papers.4,Project Adaptation for {MT}-Enhanced Computer Assisted Translation,2013,-1,-1,1,1,10592,mauro cettolo,Proceedings of Machine Translation Summit XIV: Papers,0,None
2013.mtsummit-papers.5,Cache-based Online Adaptation for Machine Translation Enhanced Computer Assisted Translation,2013,23,36,2,0.576322,29503,nicola bertoldi,Proceedings of Machine Translation Summit XIV: Papers,0,None
2013.iwslt-evaluation.1,Report on the 10th {IWSLT} evaluation campaign,2013,-1,-1,1,1,10592,mauro cettolo,Proceedings of the 10th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"The paper overviews the tenth evaluation campaign organized by the IWSLT workshop. The 2013 evaluation offered multiple tracks on lecture transcription and translation based on the TED Talks corpus. In particular, this year IWSLT included two automatic speech recognition tracks, on English and German, three speech translation tracks, from English to French, English to German, and German to English, and three text translation track, also from English to French, English to German, and German to English. In addition to the official tracks, speech and text translation optional tracks were offered involving 12 other languages: Arabic, Spanish, Portuguese (B), Italian, Chinese, Polish, Persian, Slovenian, Turkish, Dutch, Romanian, Russian. Overall, 18 teams participated in the evaluation for a total of 217 primary runs submitted. All runs were evaluated with objective metrics on a current test set and two progress test sets, in order to compare the progresses against systems of the previous years. In addition, submissions of one of the official machine translation tracks were also evaluated with human post-editing."
2013.iwslt-evaluation.16,{EU}-{BRIDGE} {MT}: text translation of talks in the {EU}-{BRIDGE} project,2013,52,8,14,0.540541,3519,markus freitag,Proceedings of the 10th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"EU-BRIDGE1 is a European research project which is aimed at developing innovative speech translation technology. This paper describes one of the collaborative efforts within EUBRIDGE to further advance the state of the art in machine translation between two European language pairs, EnglishâFrench and GermanâEnglish. Four research institutions involved in the EU-BRIDGE project combined their individual machine translation systems and participated with a joint setup in the machine translation track of the evaluation campaign at the 2013 International Workshop on Spoken Language Translation (IWSLT). We present the methods and techniques to achieve high translation quality for text translation of talks which are applied at RWTH Aachen University, the University of Edinburgh, Karlsruhe Institute of Technology, and Fondazione Bruno Kessler. We then show how we have been able to considerably boost translation performance (as measured in terms of the metrics BLEU and TER) by means of system combination. The joint setups yield empirical gains of up to 1.4 points in BLEU and 2.8 points in TER on the IWSLT test sets compared to the best single systems."
W12-3155,Evaluating the Learning Curve of Domain Adaptive Statistical Machine Translation Systems,2012,9,6,2,0.683175,29503,nicola bertoldi,Proceedings of the Seventh Workshop on Statistical Machine Translation,0,"The new frontier of computer assisted translation technology is the effective integration of statistical MT within the translation workflow. In this respect, the SMT ability of incrementally learning from the translations produced by users plays a central role. A still open problem is the evaluation of SMT systems that evolve over time. In this paper, we propose a new metric for assessing the quality of an adaptive MT component that is derived from the theory of learning curves: the percentage slope."
federico-etal-2012-iwslt,The {IWSLT} 2011 Evaluation Campaign on Automatic Talk Translation,2012,18,30,5,0.197862,3526,marcello federico,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"We report here on the eighth evaluation campaign organized in 2011 by the IWSLT workshop series. That IWSLT 2011 evaluation focused on the automatic translation of public talks and included tracks for speech recognition, speech translation, text translation, and system combination. Unlike in previous years, all data supplied for the evaluation has been publicly released on the workshop website, and is at the disposal of researchers interested in working on our benchmarks and in comparing their results with those published at the workshop. This paper provides an overview of the IWSLT 2011 evaluation campaign, and describes the data supplied, the evaluation infrastructure made available to participants, and the subjective evaluation carried out."
2012.eamt-1.60,{WIT}3: Web Inventory of Transcribed and Translated Talks,2012,15,320,1,1,10592,mauro cettolo,Proceedings of the 16th Annual conference of the European Association for Machine Translation,0,"We describe here a Web inventory named WIT 3 that offers access to a collection of transcribed and translated talks. The core of WIT 3 is the TED Talks corpus, that basically redistributes the original content published by the TED Conference website (http://www.ted.com). Since 2007, the TED Conference, based in California, has been posting all video recordings of its talks together with subtitles in English and their translations in more than 80 languages. Aside from its cultural and social relevance, this content, which is published under the Creative Commons BYNC-ND license, also represents a precious language resource for the machine translation research community, thanks to its size, variety of topics, and covered languages. This effort repurposes the original content in a way which is more convenient for machine translation researchers."
2011.mtsummit-papers.1,Methods for Smoothing the Optimizer Instability in {SMT},2011,-1,-1,1,1,10592,mauro cettolo,Proceedings of Machine Translation Summit XIII: Papers,0,None
2011.eamt-1.34,Bootstrapping {A}rabic-{I}talian {SMT} through Comparable Texts and Pivot Translation,2011,14,6,1,1,10592,mauro cettolo,Proceedings of the 15th Annual conference of the European Association for Machine Translation,0,"This paper describes efforts towards the development of an Arabic to Italian SMT system for the news domain. Since only very little parallel data are available for this language pair, we investigated both the exploitation of comparable corpora and pivot translation. Experimental evaluation was conducted on a new benchmark developed by extending two Arabic-to-English NIST evaluation sets. Preliminary results show potentials of both approaches with respect to performance achieved by a popular state-of-the-art Web-based translation service."
N10-1064,Statistical Machine Translation of Texts with Misspelled Words,2010,18,20,2,0.791436,29503,nicola bertoldi,Human Language Technologies: The 2010 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics,0,This paper investigates the impact of misspelled words in statistical machine translation and proposes an extension of the translation engine for handling misspellings. The enhanced system decodes a word-based confusion network representing spelling variations of the input text.n n We present extensive experimental results on two translation tasks of increasing complexity which show how misspellings of different types do affect performance of a statistical machine translation decoder and to what extent our enhanced system is able to recover from such errors.
2010.iwslt-papers.3,Mining parallel fragments from comparable texts,2010,11,24,1,1,10592,mauro cettolo,Proceedings of the 7th International Workshop on Spoken Language Translation: Papers,0,"This paper proposes a novel method for exploiting comparable documents to generate parallel data for machine translation. First, each source document is paired to each sentence of the corresponding target document; second, partial phrase alignments are computed within the paired texts; finally, fragment pairs across linked phrase-pairs are extracted. The algorithm has been tested on two recent challenging news translation tasks. Results show that mining for parallel fragments is more effective than mining for parallel sentences, and that comparable in-domain texts can be more valuable than parallel out-of-domain texts."
2010.iwslt-evaluation.5,{FBK} @ {IWSLT} 2010,2010,8,4,3,0.625,369,arianna bisazza,Proceedings of the 7th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This year FBK took part in the BTEC translation task, with source languages Arabic and Turkish and target language English, and in the new TALK task, source English and target French. We worked in the framework of phrase-based statistical machine translation aiming to improve coverage of models in presence of rich morphology, on one side, and to make better use of available resources through data selection techniques. New morphological segmentation rules were developed for Turkish-English. The combination of several Turkish segmentation schemes into a lattice input led to an improvement wrt to last year. The use of additional training data was explored for Arabic-English, while on the English to French task improvement was achieved over a strong baseline by automatically selecting relevant and high quality data from the available training corpora."
2010.eamt-1.30,Online Language Model adaptation via N-gram Mixtures for Statistical Machine Translation,2010,21,4,2,0.666667,23855,german sanchistrilles,Proceedings of the 14th Annual conference of the European Association for Machine Translation,0,"The problem of language model adaptation in statistical machine translation is considered. A mixture of language models is employed, which is obtained by clustering the bilingual training data. Unsupervised clustering is guided by either the development or the test set. Different mixture weight estimation schemes are proposed and compared, at the level of either single or all source sentences. Experimental results show that, by training different specific language models weighted according to the actual input instead of using a single target language model, translation quality is improved, as measured by BLEU and TER."
2009.iwslt-papers.5,Online language model adaptation for spoken dialog translation,2009,16,8,2,0.666667,23855,german sanchistrilles,Proceedings of the 6th International Workshop on Spoken Language Translation: Papers,0,"This paper focuses on the problem of language model adaptation in the context of Chinese-English cross-lingual dialogs, as set-up by the challenge task of the IWSLT 2009 Evaluation Campaign. Mixtures of n-gram language models are investigated, which are obtained by clustering bilingual training data according to different available human annotations, respectively, at the dialog level, turn level, and dialog act level. For the latter case, clustering of IWSLT data was in fact induced through a comparable Italian-English parallel corpus provided with dialog act annotations. For the sake of adaptation, mixture weight estimation is performed either at the level of single source sentence or test set. Estimated weights are then transferred to the target language mixture model. Experimental results show that, by training different specific language models weighted according to the actual input instead of using a single target language model, significant gains in terms of perplexity and BLEU can be achieved."
2009.iwslt-evaluation.5,FBK at IWSLT 2009,2009,16,3,3,0.792073,29503,nicola bertoldi,Proceedings of the 6th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This paper reports on the participation of FBK at the IWSLT 2009 Evaluation. This year we worked on the Arabic-English and Turkish-English BTEC tasks with a special effort on linguistic preprocessing techniques involving morphological segmentation. In addition, we investigated the adaptation problem in the development of systems for the Chinese-English and English-Chinese challenge tasks; in particular, we explored different ways for clustering training data into topic or dialog-specific subsets: by producing (and combining) smaller but more focused models, we intended to make better use of the available training data, with the ultimate purpose of improving translation quality."
2008.amta-papers.3,Shallow-Syntax Phrase-Based Translation: Joint versus Factored String-to-Chunk Models,2008,-1,-1,1,1,10592,mauro cettolo,Proceedings of the 8th Conference of the Association for Machine Translation in the Americas: Research Papers,0,"This work extends phrase-based statistical MT (SMT) with shallow syntax dependencies. Two string-to-chunks translation models are proposed: a factored model, which augments phrase-based SMT with layered dependencies, and a joint model, that extends the phrase translation table with microtags, i.e. per-word projections of chunk labels. Both rely on n-gram models of target sequences with different granularity: single words, micro-tags, chunks. In particular, n-grams defined over syntactic chunks should model syntactic constraints coping with word-group movements. Experimental analysis and evaluation conducted on two popular Chinese-English tasks suggest that the shallow-syntax joint-translation model has potential to outperform state-of-the-art phrase-based translation, with a reasonable computational overhead."
W07-0712,Efficient Handling of N-gram Language Models for Statistical Machine Translation,2007,9,70,2,0.8,3526,marcello federico,Proceedings of the Second Workshop on Statistical Machine Translation,0,"Statistical machine translation, as well as other areas of human language processing, have recently pushed toward the use of large scale n-gram language models. This paper presents efficient algorithmic and architectural solutions which have been tested within the Moses decoder, an open source toolkit for statistical machine translation. Experiments are reported with a high performing baseline, trained on the Chinese-English NIST 2006 Evaluation task and running on a standard Linux 64-bit PC architecture. Comparative tests show that our representation halves the memory required by SRI LM Toolkit, at the cost of 44% slower translation speed. However, as it can take advantage of memory mapping on disk, the proposed implementation seems to scale-up much better to very large language models: decoding with a 289-million 5-gram language model runs in 2.1Gb of RAM."
2007.mtsummit-papers.15,Better n-best translations through generative n-gram language models,2007,-1,-1,3,1,4084,boxing chen,Proceedings of Machine Translation Summit XI: Papers,0,None
2007.mtsummit-papers.28,{POS}-based reordering models for statistical machine translation,2007,21,7,2,0,49423,deepa gupta,Proceedings of Machine Translation Summit XI: Papers,0,"We present a novel word reordering model for phrase-based statistical machine translation suited to cope with long-span word movements. In particular, reordering of nouns, verbs and adjectives is modeled by taking into account target-to-source word alignments and the distances between source as well as target words. The proposed model was applied as a set of additional feature functions to re-score N-best translation candidates generated by a statistical machine translation system featuring state-of-the-art lexicalized reordering models. Experiments showed relative BLEU score improvement up to 7.3% on the BTEC Japanese-to-English task, and up to 1.1% on the Europarl German-to-English task."
2007.iwslt-1.11,{FBK}@{IWSLT} 2007,2007,9,3,2,0.75,29503,nicola bertoldi,Proceedings of the Fourth International Workshop on Spoken Language Translation,0,"This paper reports on the participation of FBK (formerly ITC-irst) at the IWSLT 2007 Evaluation. FBK participated in three tasks, namely Chinese-to-English, Japanese-to-English, and Italian-to-English. With respect to last year, translation systems were developed with the Moses Toolkit and the IRSTLM library, both available as open source software. Moreover, several novel ideas were investigated: the use of confusion networks in input to manage ambiguity in punctuation, the estimation of an additional language model by means of the Google{'}s Web 1T 5-gram collection, the combination of true case and lower case language models, and finally the use of multiple phrase-tables. By working on top of a state-of-the art baseline, experiments showed that the above methods accounted for significant BLEU score improvements."
W06-2601,Maximum Entropy Tagging with Binary and Real-Valued Features,2006,8,0,3,0,49693,vanessa sandrini,Proceedings of the Workshop on Learning Structured Information in Natural Language Applications,0,None
E06-2002,A Web-based Demonstrator of a Multi-lingual Phrase-based Translation System,2006,10,3,3,0.5,5711,roldano cattoni,Demonstrations,0,"This paper describes a multi-lingual phrase-based Statistical Machine Translation system accessible by means of a Web page. The user can issue translation requests from Arabic, Chinese or Spanish into English. The same phrase-based statistical technology is employed to realize the three supported language-pairs. New language-pairs can be easily added to the demonstrator. The Web-based interface allows the use of the translation system to any computer connected to the Internet."
2006.iwslt-papers.4,Reordering rules for phrase-based statistical machine translation,2006,20,22,2,1,4084,boxing chen,Proceedings of the Third International Workshop on Spoken Language Translation: Papers,0,"This paper proposes the use of rules automatically extracted from word aligned training data to model word reordering phenomena in phrase-based statistical machine translation. Scores computed from matching rules are used as additional feature functions in the rescoring stage of the automatic translation process from various languages to English, in the ambit of a popular traveling domain task. Rules are defined either on Part-of-Speech or words. Part-ofSpeech rules are extracted from and applied to Chinese, while lexicalized rules are extracted from and applied to Chinese, Japanese and Arabic. Both Part-of-Speech and lexicalized rules yield an absolute improvement of the BLEU score of 0.4-0.9 points without affecting the NIST score, on the Chinese-to-English translation task. On other language pairs which differ a lot in the word order, the use of lexicalized rules allows to observe significant improvements as well."
2006.iwslt-evaluation.7,The {ITC}-irst {SMT} system for {IWSLT} 2006,2006,7,10,4,1,4084,boxing chen,Proceedings of the Third International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This paper reports on the participation of ITC-irst to the evaluation campaign of the International Workshop on Spoken Language Translation 2006. Our two-pass system is the evolution of the one we employed for the 2005 campaign: in the first pass, an N-best list of translations is generated for each source sentence by means of a beam-search decoder; in the second pass, N-best lists are rescored and reranked exploiting additional feature functions. Main updates brought to the 2005 system involve novel additional features which are here described. Results on development sets are analyzed and commented."
2005.iwslt-1.11,The {ITC}-irst {SMT} System for {IWSLT}-2005,2005,10,34,4,1,4084,boxing chen,Proceedings of the Second International Workshop on Spoken Language Translation,0,None
2004.iwslt-papers.2,Minimum error training of log-linear translation models,2004,13,17,1,1,10592,mauro cettolo,Proceedings of the First International Workshop on Spoken Language Translation: Papers,0,"Recent work on training of log-linear interpolation models for statistical machine translation reported performance improvements by optimizing parameters with respect to translation quality, rather than to likelihood oriented criteria. This work presents an alternative and more direct training procedure for log-linear interpolation models. In addition, we point out the subtle interaction between log-linear models and the beam search algorithm. Experimental results are reported on two Chinese-English evaluation sets, C-Star 2003 and Nist 2003, by using a statistical phrase-based model derived from Model 4. By optimizing parameters with respect to the BLUE score, performance relative improvements by 9.6% and 2.8% were achieved, respectively."
2004.iwslt-evaluation.8,The {ITC}-irst statistical machine translation system for {IWSLT}-,2004,20,19,3,0,29503,nicola bertoldi,Proceedings of the First International Workshop on Spoken Language Translation: Evaluation Campaign,0,"Focus of this paper is the system for statistical machine translation developed at ITC-irst. It has been employed in the evaluation campaign of the International Workshop on Spoken Language Translation 2004 in all the three data set conditions of the Chinese-English track. Both the statistical model underlying the system and the system architecture are presented. Moreover, details are given on how the submitted runs have been produced."
