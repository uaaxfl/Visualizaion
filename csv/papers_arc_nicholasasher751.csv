P19-1061,Data Programming for Learning Discourse Structure,2019,0,0,4,0,11200,sonia badene,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"This paper investigates the advantages and limits of data programming for the task of learning discourse structure. The data programming paradigm implemented in the Snorkel framework allows a user to label training data using expert-composed heuristics, which are then transformed via the {``}generative step{''} into probability distributions of the class labels given the training candidates. These results are later generalized using a discriminative model. Snorkel{'}s attractive promise to create a large amount of annotated data from a smaller set of training data by unifying the output of a set of heuristics has yet to be used for computationally difficult tasks, such as that of discourse attachment, in which one must decide where a given discourse unit attaches to other units in a text in order to form a coherent discourse structure. Although approaching this problem using Snorkel requires significant modifications to the structure of the heuristics, we show that weak supervision methods can be more than competitive with classical supervised learning approaches to the attachment problem."
D19-1234,Weak Supervision for Learning Discourse Structure,2019,0,0,4,0,11200,sonia badene,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),0,"This paper provides a detailed comparison of a data programming approach with (i) off-the-shelf, state-of-the-art deep learning architectures that optimize their representations (BERT) and (ii) handcrafted-feature approaches previously used in the discourse analysis literature. We compare these approaches on the task of learning discourse structure for multi-party dialogue. The data programming paradigm offered by the Snorkel framework allows a user to label training data using expert-composed heuristics, which are then transformed via the {``}generative step{''} into probability distributions of the class labels given the data. We show that on our task the generative model outperforms both deep learning architectures as well as more traditional ML approaches when learning discourse structure{---}it even outperforms the combination of deep learning methods and hand-crafted features. We also implement several strategies for {``}decoding{''} our generative model output in order to improve our results. We conclude that weak supervision methods hold great promise as a means for creating and improving data sets for discourse structure."
2019.jeptalnrecital-court.1,Analyse faiblement supervis{\\'e}e de conversation en actes de dialogue (Weakly supervised dialog act analysis),2019,-1,-1,2,0,27340,catherine thompson,Actes de la Conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles (TALN) PFIA 2019. Volume II : Articles courts,0,"Nous nous int{\'e}ressons ici {\`a} l{'}analyse de conversation par chat dans un contexte orient{\'e}-t{\^a}che avec un conseiller technique s{'}adressant {\`a} un client, o{\`u} l{'}objectif est d{'}{\'e}tiqueter les {\'e}nonc{\'e}s en actes de dialogue, pour alimenter des analyses des conversations en aval. Nous proposons une m{\'e}thode l{\'e}g{\`e}rement supervis{\'e}e {\`a} partir d{'}heuristiques simples, de quelques annotations de d{\'e}veloppement, et une m{\'e}thode d{'}ensemble sur ces r{\`e}gles qui sert {\`a} annoter automatiquement un corpus plus large de fa{\c{c}}on bruit{\'e}e qui peut servir d{'}entrainement {\`a} un mod{\`e}le supervis{\'e}. Nous comparons cette approche {\`a} une approche supervis{\'e}e classique et montrons qu{'}elle atteint des r{\'e}sultats tr{\`e}s proches, {\`a} un co{\^u}t moindre et tout en {\'e}tant plus facile {\`a} adapter {\`a} de nouvelles donn{\'e}es."
2019.jeptalnrecital-court.3,Apprentissage faiblement supervis{\\'e} de la structure discursive (Learning discourse structure using weak supervision ),2019,-1,-1,3,0,11200,sonia badene,Actes de la Conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles (TALN) PFIA 2019. Volume II : Articles courts,0,"L{'}av{\`e}nement des techniques d{'}apprentissage automatique profond a fait na{\^\i}tre un besoin {\'e}norme de donn{\'e}es d{'}entra{\^\i}nement. De telles donn{\'e}es d{'}entra{\^\i}nement sont extr{\^e}mement co{\^u}teuses {\`a} cr{\'e}er, surtout lorsqu{'}une expertise dans le domaine est requise. L{'}une de ces t{\^a}ches est l{'}apprentissage de la structure s{\'e}mantique du discours, t{\^a}che tr{\`e}s complexe avec des structures r{\'e}cursives avec des donn{\'e}es {\'e}parses, mais qui est essentielle pour extraire des informations s{\'e}mantiques profondes du texte. Nous d{\'e}crivons nos exp{\'e}rimentations sur l{'}attachement des unit{\'e}s discursives pour former une structure, en utilisant le paradigme du data programming dans lequel peu ou pas d{'}annotations sont utilis{\'e}es pour construire un ensemble de donn{\'e}es d{'}entra{\^\i}nement {``}bruit{\'e}{''}. Le corpus de dialogues utilis{\'e} illustre des contraintes {\`a} la fois linguistiques et non-linguistiques int{\'e}ressantes qui doivent {\^e}tre apprises. Nous nous concentrons sur la structure des r{\`e}gles utilis{\'e}es pour construire un mod{\`e}le g{\'e}n{\'e}ratif et montrons la comp{\'e}titivit{\'e} de notre approche par rapport {\`a} l{'}apprentissage supervis{\'e} classique."
J18-2001,A Dependency Perspective on {RST} Discourse Parsing and Evaluation,2018,28,9,3,1,24638,mathieu morey,Computational Linguistics,0,"Computational text-level discourse analysis mostly happens within Rhetorical Structure Theory (RST), whose structures have classically been presented as constituency trees, and relies on data from the RST Discourse Treebank (RST-DT); as a result, the RST discourse parsing community has largely borrowed from the syntactic constituency parsing community. The standard evaluation procedure for RST discourse parsers is thus a simplified variant of PARSEVAL, and most RST discourse parsers use techniques that originated in syntactic constituency parsing. In this article, we isolate a number of conceptual and computational problems with the constituency hypothesis. We then examine the consequences, for the implementation and evaluation of RST discourse parsers, of adopting a dependency perspective on RST structures, a view advocated so far only by a few approaches to discourse parsing. While doing that, we show the importance of the notion of headedness of RST structures. We analyze RST discourse parsing as dependency parsing by adapting to RST a recent proposal in syntactic parsing that relies on head-ordered dependency trees, a representation isomorphic to headed constituency trees. We show how to convert the original trees from the RST corpus, RST-DT, and their binarized versions used by all existing RST parsers to head-ordered dependency trees. We also propose a way to convert existing simple dependency parser output to constituent trees. This allows us to evaluate and to compare approaches from both constituent-based and dependency-based perspectives in a unified framework, using constituency and dependency metrics. We thus propose an evaluation framework to compare extant approaches easily and uniformly, something the RST parsing community has lacked up to now. We can also compare parsers{'} predictions to each other across frameworks. This allows us to characterize families of parsing strategies across the different frameworks, in particular with respect to the notion of headedness. Our experiments provide evidence for the conceptual similarities between dependency parsers and shift-reduce constituency parsers, and confirm that dependency parsing constitutes a viable approach to RST discourse parsing."
D17-1136,How much progress have we made on {RST} discourse parsing? A replication study of recent results on the {RST}-{DT},2017,0,13,3,1,24638,mathieu morey,Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing,0,"This article evaluates purported progress over the past years in RST discourse parsing. Several studies report a relative error reduction of 24 to 51{\%} on all metrics that authors attribute to the introduction of distributed representations of discourse units. We replicate the standard evaluation of 9 parsers, 5 of which use distributed representations, from 8 studies published between 2013 and 2017, using their predictions on the test set of the RST-DT. Our main finding is that most recently reported increases in RST discourse parser performance are an artefact of differences in implementations of the evaluation procedure. We evaluate all these parsers with the standard Parseval procedure to provide a more accurate picture of the actual RST discourse parsers performance in standard evaluation settings. Under this more stringent procedure, the gains attributable to distributed representations represent at most a 16{\%} relative error reduction on fully-labelled structures."
N16-1013,Integer Linear Programming for Discourse Parsing,2016,30,15,3,0,34669,jeremy perret,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"In this paper we present the first, to the best of our knowledge, discourse parser that is able to predict non-tree DAG structures. We use Integer Linear Programming (ILP) to encode both the objective function and the constraints as global decoding over local scores. Our underlying data come from multi-party chat dialogues, which require the prediction of DAGs. We use the dependency parsing paradigm, as has been done in the past (Muller et al., 2012; Li et al., 2014; Afantenos et al., 2015), but we use the underlying formal framework of SDRT and exploit SDRT's notions of left and right distributive relations. We achieve an F-measure of 0.531 for fully labeled structures which beats the previous state of the art."
L16-1167,Parallel Discourse Annotations on a Corpus of Short Texts,2016,17,10,4,0,2824,manfred stede,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"We present the first corpus of texts annotated with two alternative approaches to discourse structure, Rhetorical Structure Theory (Mann and Thompson, 1988) and Segmented Discourse Representation Theory (Asher and Lascarides, 2003). 112 short argumentative texts have been analyzed according to these two theories. Furthermore, in previous work, the same texts have already been annotated for their argumentation structure, according to the scheme of Peldszus and Stede (2013). This corpus therefore enables studies of correlations between the two accounts of discourse structure, and between discourse and argumentation. We converted the three annotation formats to a common dependency tree format that enables to compare the structures, and we describe some initial findings."
L16-1432,Discourse Structure and Dialogue Acts in Multiparty Dialogue: the {STAC} Corpus,2016,0,9,1,1,25576,nicholas asher,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"This paper describes the STAC resource, a corpus of multi-party chats annotated for discourse structure in the style of SDRT (Asher and Lascarides, 2003; Lascarides and Asher, 2009). The main goal of the STAC project is to study the discourse structure of multi-party dialogues in order to understand the linguistic strategies adopted by interlocutors to achieve their conversational goals, especially when these goals are opposed. The STAC corpus is not only a rich source of data on strategic conversation, but also the first corpus that we are aware of that provides full discourse structures for multi-party dialogues. It has other remarkable features that make it an interesting resource for other topics: interleaved threads, creative language, and interactions between linguistic and extra-linguistic contexts."
J16-4005,Integrating Type Theory and Distributional Semantics: A Case Study on Adjective{--}Noun Compositions,2016,44,4,1,1,25576,nicholas asher,Computational Linguistics,0,"In this article, we explore an integration of a formal semantic approach to lexical meaning and an approach based on distributional methods. First, we outline a formal semantic theory that aims to combine the virtues of both formal and distributional frameworks. We then proceed to develop an algebraic interpretation of that formal semantic theory and show how at least two kinds of distributional models make this interpretation concrete. Focusing on the case of adjective-noun composition, we compare several distributional models with respect to the semantic information that a formal semantic theory would need, and we show how to integrate the information provided by distributional models back into the formal semantic framework."
W15-0123,Integrating Non-Linguistic Events into Discourse Structure,2015,16,2,2,0,8848,julie hunter,Proceedings of the 11th International Conference on Computational Semantics,0,"Interpreting an utterance sometimes depends on the presence and nature of non-linguistic actions. In this paper, we motivate and develop a semantic model of embodied interaction in which the contribution that non-linguistic events make to the content of the interaction is dependent on their rhetorical connections to other actions, both linguistic and non-linguistic. We support our claims with concrete examples from a corpus of online chats, comparing annotations of the linguistic-only content against annotations in which non-linguistic events in the context are taken into account."
W15-0131,Dynamics of Public Commitments in Dialogue,2015,-1,-1,2,1,5809,antoine venant,Proceedings of the 11th International Conference on Computational Semantics,0,None
P15-1028,A Generalisation of Lexical Functions for Composition in Distributional Semantics,2015,35,6,3,0,35494,antoine bride,Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),1,"Over the last two decades, numerous algorithms have been developed that successfully capture something of the semanticsof single words by looking at their distribution in text and comparing these distributions in a vector space model. However, it is not straightforward to construct meaning representations beyond the levelof individual wordsxe2x80x93i.e. the combination of words into larger units xe2x80x93 using dis-tributional methods. Our contribution is twofold. First of all, we carry out a large-scale evaluation, comparing different composition methods within the distributional framework for the cases of both adjective-noun and noun-noun composition, makinguse of a newly developed dataset. Secondly, we propose a novel method focomposition, which generalises the approach by Baroni and Zamparelli (2010). The performance of our novel method is also evaluated on our new dataset andproves competitive with the best methods."
D15-1109,Discourse parsing for multi-party chat dialogues,2015,37,20,3,1,17571,stergos afantenos,Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,0,"In this paper we present the first ever, to the best of our knowledge, discourse parser for multi-party chat dialogues. Discourse in multi-party dialogues dramatically differs from monologues since threaded conversations are commonplace rendering prediction of the discourse structure compelling. Moreover, the fact that our data come from chats renders the use of syntactic and lexical information useless since people take great liberties in expressing themselves lexically and syntactically. We use the dependency parsing paradigm as has been done in the past (Muller et al., 2012; Li et al., 2014). We learn local probability distributions and then use MST for decoding. We achieve 0.680 F1 on unlabelled structures and 0.516 F1 on fully labeled structures which is better than many state of the art systems for monologues, despite the inherent difficulties that multi-party chat dialogues have."
F14-1022,Unsupervised extraction of semantic relations (Extraction non supervis{\\'e}e de relations s{\\'e}mantiques lexicales) [in {F}rench],2014,0,0,3,0,35871,juliette conrath,Proceedings of TALN 2014 (Volume 1: Long Papers),0,None
C14-1206,Unsupervised extraction of semantic relations using discourse cues,2014,31,7,3,0,35871,juliette conrath,"Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: Technical Papers",0,"This paper presents a knowledge base containing triples involving pairs of verbs associated with semantic or discourse relations. The relations in these triples are marked by discourse connectors between two adjacent instances of the verbs in the triple in the large French corpus, frWaC. We detail several measures that evaluate the relevance of the triples and the strength of their association. We use manual annotations to evaluate our method, and also study the coverage of our resource with respect to the discourse annotated corpus Annodis. Our positive results show the potential impact of our resource for discourse analysis tasks as well as other semantically oriented tasks like temporal and causal information extraction"
W13-4002,Expressivity and comparison of models of discourse structure,2013,25,9,2,1,5809,antoine venant,Proceedings of the {SIGDIAL} 2013 Conference,0,"Several discourse annotated corpora now exist for NLP exploitation. Nevertheless, it is not clear how these annotations compare: are they incompatible, incomparable, or do they share some inter- pretations? In this paper, we relate three types of discourse annotation as found in: (i) the RST Tree Bank corpus, (ii) SDRT corpora DISCOR and ANNODIS, and (iii) dependency tree structures. The latter have not yet been used in actual annotations, but represent elementary substructures which are interesting for automated parsing. Specifically, we discuss two ways of interpreting RST trees by taking discourse relations as semantics operators, one is fully specified, the other one underspecified. We also provide an underspecified semantic interpretation of dependency trees. We define trans- lations between RST and DT that preserve these underspecified interpretations. On this basis, we design similarity measures that quantify the loss of information implied by these translations. Over- all, these translations and metrics provide a unified framework that will hopefully enable us to take advantage of the various existing discourse annotation data that are available for automated tasks."
W13-0105,Sentiment Composition Using a Parabolic Model,2013,20,5,5,1,39990,baptiste chardon,Proceedings of the 10th International Conference on Computational Semantics ({IWCS} 2013) {--} Long Papers,0,"In this paper, we propose a computational model that accounts for the effects of negation and modality on opinion expressions. Based on linguistic experiments informed by native speakers, we distil these effects according to the type of modality and negation. The model relies on a parabolic representation where an opinion expression is represented as a point on a parabola. Negation is modelled as functions over this parabola whereas modality through a family of parabolas of different slopes; each slope corresponds to a different certainty degree. The model is evaluated using two experiments, one involving direct strength judgements on a 7-point scale and the other relying on a sentiment annotated corpus. The empirical evaluation of our model shows that it matches the way humans handle negation and modality in opinionated sentences"
D13-1035,Grounding Strategic Conversation: Using Negotiation Dialogues to Predict Trades in a Win-Lose Game,2013,28,14,2,1,41792,anais cadilhac,Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,0,This paper describes a method that predicts which trades players execute during a winlose game. Our method uses data collected from chat negotiations of the game The Settlers of Catan and exploits the conversation to construct dynamically a partial model of each playerxe2x80x99s preferences. This in turn yields equilibrium trading moves via principles from game theory. We compare our method against four baselines and show that tracking how preferences evolve through the dialogue and reasoning about equilibrium moves are both crucial to success.
W12-3802,How do Negation and Modality Impact on Opinions?,2012,27,19,5,0.519539,7013,farah benamara,Proceedings of the Workshop on Extra-Propositional Aspects of Meaning in Computational Linguistics,0,"In this paper, we propose to study the effects of negation and modality on opinion expressions. Based on linguistic experiments informed by native speakers, we distill these effects according to the type of modality and negation. We show that each type has a specific effect on the opinion expression in its scope: both on the polarity and the strength for negation, and on the strength and/or the degree of certainty for modality. The empirical results reported in this paper provide a basis for future opinion analysis systems that have to compute the sentiment orientation at the sentence or at the clause level. The methodology we used for deriving this basis was applied for French but it can be easily instantiated for other languages like English."
W12-3619,Annotating Preferences in Chats for Strategic Games,2012,8,1,2,1,41792,anais cadilhac,Proceedings of the Sixth Linguistic Annotation Workshop,0,This paper describes an annotation scheme for expressions of preferences in on-line chats concerning bargaining negotiations in the online version of the competitive game Settlers of Catan.
S12-1018,Annotating Preferences in Negotiation Dialogues,2012,17,3,2,1,41792,anais cadilhac,"*{SEM} 2012: The First Joint Conference on Lexical and Computational Semantics {--} Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation ({S}em{E}val 2012)",0,"Modeling user preferences is crucial in many real-life problems, ranging from individual and collective decision-making to strategic interactions between agents and game theory. Since agents do not come with their preferences transparently given in advance, we have only two means to determine what they are if we wish to exploit them in reasoning: we can infer them from what an agent says or from his nonlinguistic actions. In this paper, we analyze how to infer preferences from dialogue moves in actual conversations that involve bargaining or negotiation. To this end, we propose a new annotation scheme to study how preferences are linguistically expressed in two different corpus genres. This paper describes the annotation methodology and details the inter-annotator agreement study on each corpus genre. Our results show that preferences can be easily annotated by humans."
afantenos-etal-2012-empirical,An empirical resource for discovering cognitive principles of discourse organisation: the {ANNODIS} corpus,2012,35,36,2,1,17571,stergos afantenos,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"This paper describes the ANNODIS resource, a discourse-level annotated corpus for French. The corpus combines two perspectives on discourse: a bottom-up approach and a top-down approach. The bottom-up view incrementally builds a structure from elementary discourse units, while the top-down view focuses on the selective annotation of multi-level discourse structures. The corpus is composed of texts that are diversified with respect to genre, length and type of discursive organisation. The methodology followed here involves an iterative design of annotation guidelines in order to reach satisfactory inter-annotator agreement levels. This allows us to raise a few issues relevant for the comparison of such complex objects as discourse structures. The corpus also serves as a source of empirical evidence for discourse theories. We present here two first analyses taking advantage of this new annotated corpus --one that tested hypotheses on constraints governing discourse structure, and another that studied the variations in composition and signalling of multi-level discourse structures."
F12-2026,Extraction de pr{\\'e}f{\\'e}rences {\\`a} partir de dialogues de n{\\'e}gociation (Towards Preference Extraction From Negotiation Dialogues) [in {F}rench],2012,-1,-1,4,1,41792,anais cadilhac,"Proceedings of the Joint Conference JEP-TALN-RECITAL 2012, volume 2: TALN",0,None
C12-1115,Constrained Decoding for Text-Level Discourse Parsing,2012,32,30,4,0.306836,5596,philippe muller,Proceedings of {COLING} 2012,0,"This paper presents a novel approach to document-based discourse analysis by performing a global A* search over the space of possible structures while optimizing a global criterion over the set of potential coherence relations. Existing approaches to discourse analysis have so far relied on greedy search strategies or restricted themselves to sentence-level discourse parsing. Another advantage of our approach, over other global alternatives (like Maximum Spanning Tree decoding algorithms), is its flexibility in being able to integrate constraints (including linguistically motivated ones like the Right Frontier Constraint). Finally, our paper provides the first discourse parsing system for French; our evaluation is carried out on the Annodis corpus. While using a lot less training data than earlier approaches than previous work on English, our system manages to achieve state-of-the-art results, with F1-scores of 66.2 and 46.8 when compared to unlabeled and labeled reference structures."
W11-2023,Commitments to Preferences in Dialogue,2011,16,11,2,1,41792,anais cadilhac,Proceedings of the {SIGDIAL} 2011 Conference,0,"We propose a method for modelling how dialogue moves influence and are influenced by the agents' preferences. We extract constraints on preferences and dependencies among them, even when they are expressed indirectly, by exploiting discourse structure. Our method relies on a study of 20 dialogues chosen at random from the Verbmobil corpus. We then test the algorithms predictions against the judgements of naive annotators on 3 random unseen dialogues. The average annotator-algorithm agreement and the average inter-annotator agreement show that our method is reliable."
2011.jeptalnrecital-invite.2,Theorie et Praxis Une optique sur les travaux en {TAL} sur le discours et le dialogue (Theory and Praxis A view on the {NLP} works in discourse and dialogue),2011,-1,-1,1,1,25576,nicholas asher,Actes de la 18e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Conf{\\'e}rences invit{\\'e}es,0,
C10-1001,Testing {SDRT}{'}s Right Frontier,2010,20,9,2,1,17571,stergos afantenos,Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010),0,"The Right Frontier Constraint (RFC), as a constraint on the attachment of new constituents to an existing discourse structure, has important implications for the interpretation of anaphoric elements in discourse and for Machine Learning (ML) approaches to learning discourse structures. In this paper we provide strong empirical support for SDRT's version of RFC. The analysis of about 100 doubly annotated documents by five different naive annotators shows that SDRT's RFC is respected about 95% of the time. The qualitative analysis of presumed violations that we have performed shows that they are either click-errors or structural misconceptions."
2009.jeptalnrecital-court.5,{ANNODIS}: une approche outill{\\'e}e de l{'}annotation de structures discursives,2009,-1,-1,2,0,43228,mariepaule perywoodley,Actes de la 16{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles courts,0,"Le projet ANNODIS vise la construction d{'}un corpus de textes annot{\'e}s au niveau discursif ainsi que le d{\'e}veloppement d{'}outils pour l{'}annotation et l{'}exploitation de corpus. Les annotations adoptent deux points de vue compl{\'e}mentaires : une perspective ascendante part d{'}unit{\'e}s de discours minimales pour construire des structures complexes via un jeu de relations de discours ; une perspective descendante aborde le texte dans son entier et se base sur des indices pr{\'e}-identifi{\'e}s pour d{\'e}tecter des structures discursives de haut niveau. La construction du corpus est associ{\'e}e {\`a} la cr{\'e}ation de deux interfaces : la premi{\`e}re assiste l{'}annotation manuelle des relations et structures discursives en permettant une visualisation du marquage issu des pr{\'e}traitements ; une seconde sera destin{\'e}e {\`a} l{'}exploitation des annotations. Nous pr{\'e}sentons les mod{\`e}les et protocoles d{'}annotation {\'e}labor{\'e}s pour mettre en oeuvre, au travers de l{'}interface d{\'e}di{\'e}e, la campagne d{'}annotation."
W08-0104,Agreement and Disputes in Dialogue,2008,11,6,2,0,1045,alex lascarides,Proceedings of the 9th {SIG}dial Workshop on Discourse and Dialogue,0,"In this paper we define agreement in terms of shared public commitments, and implicit agreement is conditioned on the semantics of the relational speech acts (e.g., Narration, Explanation) that each agent performs. We provide a consistent interpretation of disputes, and updating a logical form with the current utterance always involves extending it and not revising it, even if the current utterance denies earlier content."
C08-2002,Distilling Opinion in Discourse: A Preliminary Study,2008,7,36,1,1,25576,nicholas asher,Coling 2008: Companion volume: Posters,0,"In this paper, we describe a preliminary study for a discourse based opinion categorization and propose a new annotation schema for a deep contextual opinion analysis using discourse relations."
P94-1006,Intentions and Information in Discourse,1994,14,8,1,1,25576,nicholas asher,32nd Annual Meeting of the Association for Computational Linguistics,1,"This paper is about the flow of inference between communicative intentions, discourse structure and the domain during discourse processing. We augment a theory of discourse interpretation with a theory of distinct mental attitudes and reasoning about them, in order to provide an account of how the attitudes interact with reasoning about discourse structure."
E93-1030,A Semantics and Pragmatics for the Pluperfect,1993,18,13,2,0.5,1045,alex lascarides,Sixth Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"We offer a semantics and pragmatics of the pluperfect in narrative discourse. We examine in a formal model of implicature, how the reader's knowledge about the discourse, Gricean-maxims and causation contribute to the meaning of the pluperfect. By placing the analysis in a theory where the interactions among these knowledge resources can be precisely computed, we overcome some problems with previous Reichenbachian approaches."
P92-1001,Inferring Discourse Relations in Context,1992,15,0,2,1,1045,alex lascarides,30th Annual Meeting of the Association for Computational Linguistics,1,"We investigate various contextual effects on text interpretation, and account for them by providing contextual constraints in a logical theory of text interpretation. On the basis of the way these constraints interact with the other knowledge sources, we draw some general conclusions about the role of domain-specific information, top-down and bottom-up discourse information flow, and the usefulness of formalisation in discourse theory."
P91-1008,Discourse Relations and Defeasible Knowledge,1991,16,105,2,1,1045,alex lascarides,29th Annual Meeting of the Association for Computational Linguistics,1,This paper presents a formal account of the temporal interpretation of text. The distinct natural interpretations of texts with similar syntax are explained in terms of defeasible rules characterising causal laws and Gricean-style pragmatic maxims. Intuitively compelling patterns of defeasible entailment that are supported by the logic in which the theory is expressed are shown to underly temporal interpretation.
C86-1127,{BUILDRS}: An Implementation of {DR} Theory and {LFG},1986,5,16,2,0,56443,hajime wada,Coling 1986 Volume 1: The 11th International Conference on Computational Linguistics,0,"This paper examines a particular PROLOG implementation of Discourse Representation theory (DR theory) constructed at the University of Texas. The implementation also contains a Lexical Functional Grammar parser that provides f-structures: these f-structures are then translated into the semantic representations posited by DR theory, structures which are known as Discourse Representation Structures (DRSs). Our program handles some linguistically interesting phenomena in English such as (i) scope ambiguities of singular quantifiers, (ii) functional control phenomena, and (iii) long distance dependencies. Finally, we have implemented an algorithm for anaphora resolution. Our goal is to use purely linguistically available information in constructing a semantic representation of discourse as far as is feasible and to forego appeals to world knowledge."
