2020.wmt-1.76,"Findings of the {WMT} 2020 Biomedical Translation Shared Task: {B}asque, {I}talian and {R}ussian as New Additional Languages",2020,-1,-1,7,0,7687,rachel bawden,Proceedings of the Fifth Conference on Machine Translation,0,"Machine translation of scientific abstracts and terminologies has the potential to support health professionals and biomedical researchers in some of their activities. In the fifth edition of the WMT Biomedical Task, we addressed a total of eight language pairs. Five language pairs were previously addressed in past editions of the shared task, namely, English/German, English/French, English/Spanish, English/Portuguese, and English/Chinese. Three additional languages pairs were also introduced this year: English/Russian, English/Italian, and English/Basque. The task addressed the evaluation of both scientific abstracts (all language pairs) and terminologies (English/Basque only). We received submissions from a total of 20 teams. For recurring language pairs, we observed an improvement in the translations in terms of automatic scores and qualitative evaluations, compared to previous years."
W13-2005,Extracting Biomedical Events and Modifications Using Subgraph Matching with Noisy Training Data,2013,21,9,2,0.747375,32906,andrew mackinlay,Proceedings of the {B}io{NLP} Shared Task 2013 Workshop,0,"The Genia Event (GE) extraction task of the BioNLP Shared Task addresses the extraction of biomedical events from the natural language text of the published literature. In our submission, we modified an existing system for learning of event patterns via dependency parse subgraphs to utilise a more accurate parser and significantly more, but noisier, training data. We explore the impact of these two aspects of the system and conclude that the change in parser limits recall to an extent that cannot be offset by the large quantities of training data. However, our extensions of the system to extract modification events shows promise."
U13-1018,Automatic Climate Classification of Environmental Science Literature,2013,-1,-1,2,0,41185,jared willett,Proceedings of the Australasian Language Technology Association Workshop 2013 ({ALTA} 2013),0,None
U12-1016,Classification of Study Region in Environmental Science Abstracts,2012,-1,-1,3,0,41185,jared willett,Proceedings of the Australasian Language Technology Association Workshop 2012,0,None
U12-1017,Overview of the {ALTA} 2012 Shared Task,2012,8,12,2,0,42589,iman amini,Proceedings of the Australasian Language Technology Association Workshop 2012,0,"The ALTA shared task ran for the third time in 2012, with the aim of bringing research students together to work on the same task and data set, and compare their methods in a current research problem. The task was based on a recent study to build classifiers for automatically labeling sentences to a pre-defined set of categories, in the domain of Evidence Based Medicine (EBM). The partaking groups demonstrated strong skills this year, outperforming our proposed benchmark systems. In this overview paper we explain the process of building the benchmark classifiers and data set, and present the submitted systems and their performance."
W10-0508,Intelligent Linux Information Access by Data Mining: the {ILIAD} Project,2010,7,8,2,0,1468,timothy baldwin,Proceedings of the {NAACL} {HLT} 2010 Workshop on Computational Linguistics in a World of Social Media,0,"We propose an alternative to conventional information retrieval over Linux forum data, based on thread-, post- and user-level analysis, interfaced with an information retrieval engine via reranking."
U10-1008,Information Extraction of Multiple Categories from Pathology Reports,2010,10,9,2,0,5287,yue li,Proceedings of the Australasian Language Technology Association Workshop 2010,0,"Pathology reports are used to store information about cells and tissues of a patient, and they are crucial to monitor the health of individuals and population groups. In this work we present an evaluation of supervised text classifi cation models for the prediction of relevant categories in pathology reports. Our aim is to integrate automatic classifi ers to improve the current workfl ow of medical experts, and we implement and evaluate different machine learning approaches for a large number of categories. Our results show that we are able to predict nominal categories with high average f-score (81.3%), and we can improve over the majority class baseline by relying on Naive Bayes and feature selection. We also fi nd that the classifi cation of numeric categories is harder, and deeper analysis would be required to predict these labels."
N10-1002,Chart Mining-based Lexical Acquisition with Precision Grammars,2010,34,4,4,0,3425,yi zhang,Human Language Technologies: The 2010 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics,0,"In this paper, we present an innovative chart mining technique for improving parse coverage based on partial parse outputs from precision grammars. The general approach of mining features from partial analyses is applicable to a range of lexical acquisition tasks, and is particularly suited to domain-specific lexical tuning and lexical acquisition using low-coverage grammars. As an illustration of the functionality of our proposed technique, we develop a lexical acquisition model for English verb particle constructions which operates over unlexicalised features mined from a partial parsing chart. The proposed technique is shown to outperform a state-of-the-art parser over the target task, despite being based on relatively simplistic features."
W09-1410,Biomedical Event Annotation with {CRF}s and Precision Grammars,2009,6,17,2,0.747375,32906,andrew mackinlay,Proceedings of the {B}io{NLP} 2009 Workshop Companion Volume for Shared Task,0,"This work describes a system for the tasks of identifying events in biomedical text and marking those that are speculative or negated. The architecture of the system relies on both Machine Learning (ML) approaches and hand-coded precision grammars. We submitted the output of our approach to the event extraction shared task at BioNLP 2009, where our methods suffered from low recall, although we were one of the few teams to provide answers for task 3."
W09-1306,Extraction of Named Entities from Tables in Gene Mutation Literature,2009,15,16,2,0,47033,wern wong,Proceedings of the {B}io{NLP} 2009 Workshop,0,"We investigate the challenge of extracting information about genetic mutations from tables, an important source of information in scientific papers. We use various machine learning algorithms and feature sets, and evaluate performance in extracting fields associated with an existing handcreated database of mutations. We then show how classifying tabular information can be leveraged for the task of named entity detection for mutations."
W08-0611,Knowledge Sources for Word Sense Disambiguation of Biomedical Text,2008,20,14,4,0,2873,mark stevenson,Proceedings of the Workshop on Current Trends in Biomedical Natural Language Processing,0,"Like text in other domains, biomedical documents contain a range of terms with more than one possible meaning. These ambiguities form a significant obstacle to the automatic processing of biomedical texts. Previous approaches to resolving this problem have made use of a variety of knowledge sources including linguistic information (from the context in which the ambiguous term is used) and domain-specific resources (such as UMLS). In this paper we compare a range of knowledge sources which have been previously used and introduce a novel one: MeSH terms. The best performance is obtained using linguistic features in combination with MeSH terms. Results from our system outperform published results for previously reported systems on a standard test set (the NLM-WSD corpus)."
P08-1037,Improving Parsing and {PP} Attachment Performance with Sense Information,2008,27,67,3,0.451483,8824,eneko agirre,Proceedings of ACL-08: HLT,1,"To date, parsers have made limited use of semantic information, but there is evidence to suggest that semantic features can enhance parse disambiguation. This paper shows that semantic classes help to obtain significant improvement in both parsing and PP attachment tasks. We devise a gold-standard sense- and parse tree-annotated dataset based on the intersection of the Penn Treebank and SemCor, and experiment with different approaches to both semantic representation and disambiguation. For the Bikel parser, we achieved a maximal error reduction rate over the baseline parser of 6.9% and 20.5%, for parsing and PP-attachment respectively, using an unsupervised WSD strategy. This demonstrates that word sense information can indeed enhance the performance of syntactic disambiguation."
I08-2108,{MRD}-based Word Sense Disambiguation: Further Extending {L}esk,2008,12,14,5,0,1468,timothy baldwin,Proceedings of the Third International Joint Conference on Natural Language Processing: Volume-{II},0,"This paper reconsiders the task of MRDbased word sense disambiguation, in extending the basic Lesk algorithm to investigate the impact onWSD performance of different tokenisation schemes, scoring mechanisms, methods of gloss extension and filtering methods. In experimentation over the Lexeed Sensebank and the Japanese Senseval2 dictionary task, we demonstrate that character bigrams with sense-sensitive gloss extension over hyponyms and hypernyms enhances WSD performance."
U07-1020,Exploring Extensions to Machine-learning based Gene Normalisation,2007,4,1,3,0,49093,benjamin goudey,Proceedings of the Australasian Language Technology Workshop 2007,0,"One of the foundational text-mining tasks in the biomedical domain is the identification of genes and protein names in journal papers. However, the ambiguous nature of gene names means that the performance of information management tasks such as query-based retrieval will suffer if gene name mentions are not explicitly mapped back to a unique identifier in order to resolve issues relating to synonymy (i.e. many different lexical forms representing the same gene) and ambiguity (i.e. many distinct genes sharing the same lexical form). This task is called gene name normalisation, and was recently investigated at the BioCreative Challenge (Hirschman et al., 2004b), a text-mining evaluation forum focusing on core biomedical text processing tasks. In this work, we present a machine learning approach to gene normalisation based on work by Crim et al. (2005). We compare this system with a number of simple dictionary lookup-based methods. We also investigate a number of novel features not used by Crim et al. (2005). Our results show that it is difficult to improve upon the original set of features used by Crim et al. We also show that for some organisims gene name normalisation can be successfully performed using simple dictionary lookup techniques."
S07-1050,{MELB}-{MKB}: Lexical Substitution system based on Relatives in Context,2007,5,11,1,1,13902,david martinez,Proceedings of the Fourth International Workshop on Semantic Evaluations ({S}em{E}val-2007),0,"In this paper we describe the MELB-MKB system, as entered in the SemEval-2007 lexical substitution task. The core of our system was the Relatives in Context unsupervised approach, which ranked the candidate substitutes by web-lookup of the word sequences built combining the target context and each substitute. Our system ranked third in the final evaluation, performing close to the top-ranked system."
S07-1076,{UBC}-{UMB}: Combining unsupervised and supervised systems for all-words {WSD},2007,5,0,1,1,13902,david martinez,Proceedings of the Fourth International Workshop on Semantic Evaluations ({S}em{E}val-2007),0,"This paper describes the joint submission of two systems to the all-words WSD sub-task of SemEval-2007 task 17. The main goal of this work was to build a competitive unsupervised system by combining heterogeneous algorithms. As a secondary goal, we explored the integration of unsupervised predictions into a supervised system by different means."
W06-3814,Evaluating and optimizing the parameters of an unsupervised graph-based {WSD} algorithm,2006,11,38,2,0.387434,8824,eneko agirre,Proceedings of {T}ext{G}raphs: the First Workshop on Graph Based Methods for Natural Language Processing,0,"Veronis (2004) has recently proposed an innovative unsupervised algorithm for word sense disambiguation based on small-world graphs called HyperLex. This paper explores two sides of the algorithm. First, we extend Veronis' work by optimizing the free parameters (on a set of words which is different to the target set). Second, given that the empirical comparison among unsupervised systems (and with respect to supervised systems) is seldom made, we used hand-tagged corpora to map the induced senses to a standard lexicon (WordNet) and a publicly available gold standard (Senseval 3 English Lexical Sample). Our results for nouns show that thanks to the optimization of parameters and the mapping method, HyperLex obtains results close to supervised systems using the same kind of bag-of-words features. Given the information loss inherent in any mapping step and the fact that the parameters were tuned for another set of words, these are very interesting results."
W06-2007,Word Sense Disambiguation Using Automatically Translated Sense Examples,2006,17,4,2,0,46478,xinglong wang,Proceedings of the Cross-Language Knowledge Induction Workshop,0,"We present an unsupervised approach to Word Sense Disambiguation (WSD). We automatically acquire English sense examples using an English-Chinese bilingual dictionary, Chinese monolingual corpora and Chinese-English machine translation software. We then train machine learning classifiers on these sense examples and test them on two gold standard English WSD datasets, one for binary and the other for fine-grained sense identification. On binary disambiguation, performance of our unsupervised system has approached that of the state-of-the-art supervised ones. On multi-way disambiguation, it has achieved a very good result that is competitive to other state-of-the-art unsupervised systems. Given the fact that our approach does not rely on manually annotated resources, such as sense-tagged data or parallel corpora, the results are very promising."
W06-1669,Two graph-based algorithms for state-of-the-art {WSD},2006,19,75,2,0.387434,8824,eneko agirre,Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,0,"This paper explores the use of two graph algorithms for unsupervised induction and tagging of nominal word senses based on corpora. Our main contribution is the optimization of the free parameters of those algorithms and its evaluation against publicly available gold standards. We present a thorough evaluation comprising supervised and unsupervised modes, and both lexical-sample and all-words tasks. The results show that, in spite of the information loss inherent to mapping the induced senses to the gold-standard, the optimization of parameters based on a small sample of nouns carries over to all nouns, performing close to supervised systems in the lexical sample task and yielding the second-best WSD systems for the Senseval-3 all-words task."
U06-1008,Word Relatives in Context for Word Sense Disambiguation,2006,20,16,1,1,13902,david martinez,Proceedings of the Australasian Language Technology Workshop 2006,0,"The current situation for Word Sense Disambiguation (WSD) is somewhat stuck due to lack of training data. We present in this paper a novel disambiguation algorithm that improves previous systems based on acquisition of examples by incorporating local context information. With a basic configuration, our method is able to obtain state-of-the-art performance. We complemented this work by evaluating other well-known methods in the same dataset, and analysing the comparative results per word. We observed that each algorithm performed better for different types of words, and each of them failed for some particular words. We proposed then a simple unsupervised voting scheme that improved significantly over single systems, achieving the best unsupervised performance on both the Senseval 2 and Senseval 3 lexical sample datasets."
W04-3204,Unsupervised {WSD} based on Automatically Retrieved Examples: The Importance of Bias,2004,17,56,2,0.712036,8824,eneko agirre,Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing,0,"This paper explores the large-scale acquisition of sense-tagged examples for Word Sense Disambiguation (WSD). We have applied the xe2x80x9cWordNet monosemous relativesxe2x80x9d method to construct automatically a web corpus that we have used to train disambiguation systems. The corpus-building process has highlighted important factors, such as the distribution of senses (bias). The corpus has been used to train WSD algorithms that include supervised methods (combining automatic and manuallytagged examples), minimally supervised (requiring sense bias information from hand-tagged corpora), and fully unsupervised. These methods were tested on the Senseval-2 lexical sample test set, and compared successfully to other systems with minimum or no supervision."
W04-0801,The {B}asque lexical-sample task,2004,4,4,4,0.712036,8824,eneko agirre,"Proceedings of {SENSEVAL}-3, the Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text",0,"In this paper we describe the Senseval 3 Basque lexical sample task. The task comprised 40 words (15 nouns, 15 verbs and 10 adjectives) selected from the Basque WordNet. 10 of the words were chosen in coordination with other lexical-sample tasks. The examples were taken from newspapers, an in-house balanced corpus and Internet texts. We additionally included a large set of untagged examples, and a lemmatised version of the data including lemma, PoS and case information. The method used to hand-tag the examples produced an inter-tagger agreement of 78.2% before arbitration. The eight competing systems attained results well above the most frequent baseline and the best system from Swarthmore College scored 70.4% recall."
W04-0813,The {B}asque Country University system: {E}nglish and {B}asque tasks,2004,10,24,2,0.712036,8824,eneko agirre,"Proceedings of {SENSEVAL}-3, the Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text",0,"Our group participated in the Basque and English lexical sample tasks in Senseval-3. A language-specific feature set was defined for Basque. Four different learning algorithms were applied, and also a method that combined their outputs. Before submission, the performance of the methods was tested for each task on the Senseval-3 training data using cross validation. Finally, two systems were submitted for each language: the best single algorithm and the best ensemble."
W04-0861,The {``}Meaning{''} system on the {E}nglish all-words task,2004,0,4,4,0,49095,luis villarejo,"Proceedings of {SENSEVAL}-3, the Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text",0,None
martinez-agirre-2004-effect,The Effect of Bias on an Automatically-built Word Sense Corpus,2004,9,6,1,1,13902,david martinez,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"The goal of this paper is to explore the large-scale automatic acquisition of sense-tagged examples to be used for Word Sense Disambiguation (WSD). We have applied the xe2x80x9cmonosemous relativesxe2x80x9d method on the Web in order to build such a resource for all nouns in WordNet. The analysis of some parameters revealed that the distribution of the word senses (bias) in the training and test corpus is a determinant factor. Provided there is a method to approximate the bias for each word sense, the results we obtained for English are comparable to the use of hand-tagged data (Semcor), which is a very interesting perspective for lesser studied languages."
W02-0801,A Multilingual Approach to Disambiguate Prepositions and Case Suffixes,2002,10,3,3,0.666667,8824,eneko agirre,Proceedings of the {ACL}-02 Workshop on Word Sense Disambiguation: Recent Successes and Future Directions,0,"This paper presents preliminary experiments in the use of translation equivalences to disambiguate prepositions or case suffixes. The core of the method is to find translations of the occurrence of the target preposition or case suffix, and assign the intersection of their set of interpretations. Given a table with prepositions and their possible interpretations, the method is fully automatic. We have tested this method on the occurrences of the Basque instrumental case -z in the definitions of a Basque dictionary, looking for the translations in the definitions from 3 Spanish and 3 English dictionaries. The results have been that we are able to disambiguate with 94.5% accuracy 2.3% of those occurrences (up to 91). The ambiguity is reduced from 7 readings down to 3.1. The results are very encouraging given the simple techniques used, and show great potential for improvement."
C02-1112,Syntactic Features for High Precision Word Sense Disambiguation,2002,15,26,1,1,13902,david martinez,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"This paper explores the contribution of a broad range of syntactic features to WSD: grammatical relations coded as the presence of adjuncts/arguments in isolation or as subcategorization frames, and instantiated grammatical relations between words. We have tested the performance of syntactic features using two different ML algorithms (Decision Lists and AdaBoost) on the Senseval-2 data. Adding syntactic features to a basic set of traditional features improves performance, especially for AdaBoost. In addition, several methods to build arbitrarily high accuracy WSD systems are also tried, showing that syntactic features allow for a precision of 86% and a coverage of 26% or 95% precision and 8% coverage."
W01-0703,Learning class-to-class selectional preferences,2001,6,68,2,1,8824,eneko agirre,Proceedings of the {ACL} 2001 Workshop on Computational Natural Language Learning ({C}on{LL}),0,"Selectional preference learning methods have usually focused on word-to-class relations, e.g., a verb selects as its subject a given nominal class. This papers extends previous statistical models to class-to-class preferences, and presents a model that learns selectional preferences for classes of verbs. The motivation is twofold: different senses of a verb may have different preferences, and some classes of verbs can share preferences. The model is tested on a word sense disambiguation task which uses subject-verb and object-verb relationships extracted from a small sense-disambiguated corpus."
S01-1002,The {B}asque Task: Did Systems Perform in the Upperbound?,2001,0,2,4,1,8824,eneko agirre,Proceedings of {SENSEVAL}-2 Second International Workshop on Evaluating Word Sense Disambiguation Systems,0,"In this paper we describe the Senseval 2 Basque lexical-sample task. The task comprised 40 words (15 nouns, 15 verbs and 10 adjectives) selected from Euskal Hiztegia, the main Basque dictionary. Most examples were taken from the Egunkaria newspaper. The method used to hand-tag the examples produced low inter-tagger agreement (75%) before arbitration. The four competing systems attained results well above the most frequent baseline and the best system scored 75% precision at 100% coverage. The paper includes an analysis of the tagging procedure used, as well as the performance of the competing systems. In particular, we argue that inter-tagger agreement is not a real upperbound for the Basque WSD task."
S01-1028,Decision Lists for {E}nglish and {B}asque,2001,5,6,1,1,13902,david martinez,Proceedings of {SENSEVAL}-2 Second International Workshop on Evaluating Word Sense Disambiguation Systems,0,"In this paper we describe the systems we developed for the English (lexical and all-words) and Basque tasks. They were all supervised systems based on Yarowsky's Decision Lists. We used Semcor for training in the English all-words task. We defined different feature sets for each language. For Basque, in order to extract all the information from the text, we defined features that have not been used before in the literature, using a morphological analyzer. We also implemented systems that selected automatically good features and were able to obtain a prefixed precision (85%) at the cost of coverage. The systems that used all the features were identified as BCU-ehu-dlist-all and the systems that selected some features as BCU-ehu-dlist-best."
W00-1702,Exploring Automatic Word Sense Disambiguation with Decision Lists and the Web,2000,18,89,2,0,8824,eneko agirre,Proceedings of the {COLING}-2000 Workshop on Semantic Annotation and Intelligent Content,0,"The most effective paradigm for word sense disambiguation, supervised learning, seems to be stuck because of the knowledge acquisition bottleneck. In this paper we take an in-depth study of the performance of decision lists on two publicly available corpora and an additional corpus automatically acquired from the Web, using the fine-grained highly polysemous senses in WordNet. Decision lists are shown a versatile state-of-the-art technique. The experiments reveal, among other facts, that SemCor can be an acceptable (0.7 precision for polysemous words) starting point for an all-words system. The results on the DSO corpus show that for some highly polysemous words 0.7 precision seems to be the current state-of-the-art limit. On the other hand, independently constructed hand-tagged corpora are not mutually useful, and a corpus automatically acquired from the Web is shown to fail."
W00-1326,One Sense per Collocation and Genre/Topic Variations,2000,16,41,1,1,13902,david martinez,2000 Joint {SIGDAT} Conference on Empirical Methods in Natural Language Processing and Very Large Corpora,0,"This paper revisits the one sense per collocation hypothesis using fine-grained sense distinctions and two different corpora. We show that the hypothesis is weaker for fine-grained sense distinctions (70% vs. 99% reported earlier on 2-way ambiguities). We also show that one sense per collocation does hold across corpora, but that collocations vary from one corpus to the other, following genre and topic variations. This explains the low results when performing word sense disambiguation across corpora. In fact, we demonstrate that when two independent corpora share a related genre/topic, the word sense disambiguation results would be better. Future work on word sense disambiguation will have to take into account genre and topic as important parameters on their models."
