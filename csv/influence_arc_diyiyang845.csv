2020.acl-main.194,N19-1078,0,0.0218968,"on models pre-trained with large amount of unlabeled data, in terms of accuracy on test sets. We further performed ablation studies to demonstrate each component’s influence on models’ final performance. Results show that our MixText method significantly outperforms baselines especially when the given labeled training data is extremely limited. 2 2.1 Related Work Pre-training and Fine-tuning Framework The pre-training and fine-tuning framework has achieved huge success on NLP applications in recent years, and has been applied to a variety of NLP tasks (Radford et al., 2018; Chen et al., 2019; Akbik et al., 2019). Howard and Ruder (2018) proposed to pre-train a language model on a large general-domain corpus and fine-tune it on the target task using some novel techniques like discriminative fine-tuning, slanted triangular learning rates, and gradual unfreezing. In this manner, such pretrained models show excellent performance even with small amounts of labeled data. Pre-training methods are often designed with different objectives such as language modeling (Peters et al., 2018; Howard and Ruder, 2018; Yang et al., 2019b) and masked language modeling (Devlin et al., 2019; Lample and Conneau, 2019). The"
2020.acl-main.194,K16-1002,0,0.0626772,"Missing"
2020.acl-main.194,N19-1363,0,0.0620517,"Missing"
2020.acl-main.194,D18-1020,0,0.282352,"ing has received much attention to utilize both labeled and unlabeled data for different learning tasks, as unlabeled data is always much easier and cheaper to collect (Chawla and Karakoulas, 2011). This work takes a closer look at semi-supervised text classification, one of the most fundamental tasks in language technology communities. Prior research on semi-supervised text classification can be categorized into several classes: (1) utilizing variational auto encoders (VAEs) to reconstruct the sentences and predicting sentence labels with latent variables learned from reconstruction such as (Chen et al., 2018; Yang et al., 2017; Gururangan et al., 2019); (2) encouraging models to output confident predictions on unlabeled data for selftraining like (Lee, 2013; Grandvalet and Bengio, 2004; Meng et al., 2018); (3) performing consistency training after adding adversarial noise (Miyato et al., 2019, 2017) or data augmentations (Xie et al., 2019); (4) large scale pretraining with unlabeld data, then finetuning with labeled data (Devlin et al., 2019). Despite the huge success of those models, most prior work utilized labeled and unlabeled data separately in a way that no supervision can transit from labe"
2020.acl-main.194,D18-1217,0,0.09749,"this manner, such pretrained models show excellent performance even with small amounts of labeled data. Pre-training methods are often designed with different objectives such as language modeling (Peters et al., 2018; Howard and Ruder, 2018; Yang et al., 2019b) and masked language modeling (Devlin et al., 2019; Lample and Conneau, 2019). Their performances are also improved with training larger models on more data (Yang et al., 2019b; Liu et al., 2019). 2.2 Semi-Supervised Learning on Text Data Semi-supervised learning has received much attention in the NLP community (Gururangan et al., 2019; Clark et al., 2018; Yang et al., 2015), as unlabeled data is often plentiful compared to labeled data. For instance, Gururangan et al. (2019); Chen et al. (2018); Yang et al. (2017) leveraged variational auto encoders (VAEs) in a form of sequenceto-sequence modeling on text classification and sequential labeling. Miyato et al. (2017) utilized adversarial and virtual adversarial training to the text domain by applying perturbations to the word embeddings. Yang et al. (2019a) took advantage of hierarchy structures to utilize supervision from higher level labels to lower level labels. Xie et al. (2019) exploited c"
2020.acl-main.194,N19-1423,0,0.610629,"ilizing variational auto encoders (VAEs) to reconstruct the sentences and predicting sentence labels with latent variables learned from reconstruction such as (Chen et al., 2018; Yang et al., 2017; Gururangan et al., 2019); (2) encouraging models to output confident predictions on unlabeled data for selftraining like (Lee, 2013; Grandvalet and Bengio, 2004; Meng et al., 2018); (3) performing consistency training after adding adversarial noise (Miyato et al., 2019, 2017) or data augmentations (Xie et al., 2019); (4) large scale pretraining with unlabeld data, then finetuning with labeled data (Devlin et al., 2019). Despite the huge success of those models, most prior work utilized labeled and unlabeled data separately in a way that no supervision can transit from labeled to unlabeled data or from unlabeled to labeled data. As a result, most semisupervised models can easily still overfit on the very limited labeled data, despite unlabeled data is 2147 Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 2147–2157 c July 5 - 10, 2020. 2020 Association for Computational Linguistics abundant. To overcome the limitations, in this work, we introduce a new data augmen"
2020.acl-main.194,P18-1128,0,0.0218044,"Missing"
2020.acl-main.194,D18-1045,0,0.0437828,"ta and perform TMix for training. Moreover, we combine TMix with additional data augmentation techniques to generate large amount of augmented data, which is a key component that makes our algorithm work well in setting with extremely limited supervision. Finally, we introduce an entropy minimization loss that encourages the model to assign sharp probabilities on unlabeled data samples, which further helps to boost performance when the number of classes C is large. The overall architecture is shown in Figure 2. We will explain each component in detail. 4.1 Data Augmentation Back translations (Edunov et al., 2018) is a common data augmentation technique and can generate diverse paraphrases while preserving the semantics of the original sentences. We utilize back translations to paraphrase the unlabeled data. For each xui in the unlabeled text set Xu , we generate K 1 Note that MixText is a semi-supervised learning framework while TMix is a data augmentation approach. 2150 Figure 2: Overall Architecture of MixText. MixText takes in labeled data and unlabeled data, conducts augmentations and predicts labels for unlabeled data, performs TMix over labeled and unlabeled data, and computes supervised loss, c"
2020.acl-main.194,P19-1590,0,0.507602,"lize both labeled and unlabeled data for different learning tasks, as unlabeled data is always much easier and cheaper to collect (Chawla and Karakoulas, 2011). This work takes a closer look at semi-supervised text classification, one of the most fundamental tasks in language technology communities. Prior research on semi-supervised text classification can be categorized into several classes: (1) utilizing variational auto encoders (VAEs) to reconstruct the sentences and predicting sentence labels with latent variables learned from reconstruction such as (Chen et al., 2018; Yang et al., 2017; Gururangan et al., 2019); (2) encouraging models to output confident predictions on unlabeled data for selftraining like (Lee, 2013; Grandvalet and Bengio, 2004; Meng et al., 2018); (3) performing consistency training after adding adversarial noise (Miyato et al., 2019, 2017) or data augmentations (Xie et al., 2019); (4) large scale pretraining with unlabeld data, then finetuning with labeled data (Devlin et al., 2019). Despite the huge success of those models, most prior work utilized labeled and unlabeled data separately in a way that no supervision can transit from labeled to unlabeled data or from unlabeled to la"
2020.acl-main.194,P18-1031,0,0.0252229,"with large amount of unlabeled data, in terms of accuracy on test sets. We further performed ablation studies to demonstrate each component’s influence on models’ final performance. Results show that our MixText method significantly outperforms baselines especially when the given labeled training data is extremely limited. 2 2.1 Related Work Pre-training and Fine-tuning Framework The pre-training and fine-tuning framework has achieved huge success on NLP applications in recent years, and has been applied to a variety of NLP tasks (Radford et al., 2018; Chen et al., 2019; Akbik et al., 2019). Howard and Ruder (2018) proposed to pre-train a language model on a large general-domain corpus and fine-tune it on the target task using some novel techniques like discriminative fine-tuning, slanted triangular learning rates, and gradual unfreezing. In this manner, such pretrained models show excellent performance even with small amounts of labeled data. Pre-training methods are often designed with different objectives such as language modeling (Peters et al., 2018; Howard and Ruder, 2018; Yang et al., 2019b) and masked language modeling (Devlin et al., 2019; Lample and Conneau, 2019). Their performances are also"
2020.acl-main.194,P19-1356,0,0.0194309,"encoder parameters θ and the classifier parameters φ to train the whole model. λ ∼ Beta(α, α), 4 λ = max(λ, 1 − λ), in which α is the hyper-parameter to control the distribution of λ. In TMix, we mix the labels in the same way as Equation 2 and then use the pairs ˜ L , y˜) as inputs for downstream applications. (h Instead of performing mixup at random input layers like Verma et al. (2019a), choosing which layer of the hidden representations to mixup is an interesting question to investigate. In our experiments, we use 12-layer BERT-base (Devlin et al., 2019) as our encoder model. Recent work (Jawahar et al., 2019) has studied what BERT learned at different layers. Specifically, the authors found {3,4,5,6,7,9,12} layers have the most representation power in BERT and each layer captures different types of information ranging from surface, syntactic to semantic level representation of text. For instance, the 9-th layer has predictive power in semantic tasks like checking random swapping of coordinated clausal conjuncts, while the 3-rd layer performs best in surface tasks like predicting sentence length. Building on those findings, we choose the layers that contain both syntactic and semantic information a"
2020.acl-main.194,S19-1020,0,0.0434228,"tly, Wei and Zou (2019) utilized synonym replacement, random insertion, random swap and random deletion for text data augmentation. Similarly, Kumar et al. (2019) proposed a new paraphrasing formulation in terms of monotone submodular function maximization to obtain highly diverse paraphrases, and Xie et al. (2019) and Chen et al. (2020) applied back translations (Sennrich et al., 2015) and word replacement to generate paraphrases on unlabeled data for consistency training. Other work which also investigates noise and its incorporation into semi-supervised named entity classification (Lakshmi Narayan et al., 2019; Nagesh and Surdeanu, 2018). 3 TMix In this section, we extend Mixup–a data augmentation method originally proposed by (Zhang et al., 2017) for images–to text modeling. The main idea of Mixup is very simple: given two labeled data points (xi , yi ) and (xj , yj ), where x can be an image and y is the one-hot representation of the label, the algorithm creates virtual training samples by linear interpolations: ˜ = mix(xi , xj ) =λxi + (1 − λ)xj , x (1) ˜ = mix(yi , yj ) =λyi + (1 − λ)yj , y (2) where λ ∈ [0, 1]. The new virtual training samples are used to train a neural network model. Mixup ca"
2020.acl-main.194,2021.ccl-1.108,0,0.0674585,"Missing"
2020.acl-main.194,P11-1015,0,0.0450826,"Data Augmentation(UDA) using pytorch by ourselves. Specifically, we used the same BERT-based-uncased model, unlabeled augment data and batch size as our MixText, used original unlabeled data to predict the labels with the same softmax sharpen temperature as our MixText and computed consistency loss between augmented unlabeled data. LMixText = LTMix + γm Lmargin . 5 Experiments 5.1 Dataset and Pre-processing We performed experiment with four English text classification benchmark datasets: AG News (Zhang et al., 2015), BPpedia (Mendes et al., 2012), Yahoo! Answers (Chang et al., 2008) and IMDB (Maas et al., 2011). We used the original test set as our test set and randomly sampled from the training set to form the training unlabeled set and development set. The dataset statistics and split information are presented in Table 1. For unlabeled data, we selected German and Russian as intermediate languages for back translations using FairSeq2 , and the random sampling temperature was 0.9. Here is an example, for a news from AG News dataset: “Oil prices rallied to a record high above $55 a bar-rel on Friday on rising fears of a winter fuel supply crunch and robust economic growth in China, the world’s numbe"
2020.acl-main.194,mendes-etal-2012-dbpedia,0,0.0241383,"o use smaller amount of unlabeled data, we implemented Unsupervised Data Augmentation(UDA) using pytorch by ourselves. Specifically, we used the same BERT-based-uncased model, unlabeled augment data and batch size as our MixText, used original unlabeled data to predict the labels with the same softmax sharpen temperature as our MixText and computed consistency loss between augmented unlabeled data. LMixText = LTMix + γm Lmargin . 5 Experiments 5.1 Dataset and Pre-processing We performed experiment with four English text classification benchmark datasets: AG News (Zhang et al., 2015), BPpedia (Mendes et al., 2012), Yahoo! Answers (Chang et al., 2008) and IMDB (Maas et al., 2011). We used the original test set as our test set and randomly sampled from the training set to form the training unlabeled set and development set. The dataset statistics and split information are presented in Table 1. For unlabeled data, we selected German and Russian as intermediate languages for back translations using FairSeq2 , and the random sampling temperature was 0.9. Here is an example, for a news from AG News dataset: “Oil prices rallied to a record high above $55 a bar-rel on Friday on rising fears of a winter fuel su"
2020.acl-main.194,C18-1196,0,0.0306063,") utilized synonym replacement, random insertion, random swap and random deletion for text data augmentation. Similarly, Kumar et al. (2019) proposed a new paraphrasing formulation in terms of monotone submodular function maximization to obtain highly diverse paraphrases, and Xie et al. (2019) and Chen et al. (2020) applied back translations (Sennrich et al., 2015) and word replacement to generate paraphrases on unlabeled data for consistency training. Other work which also investigates noise and its incorporation into semi-supervised named entity classification (Lakshmi Narayan et al., 2019; Nagesh and Surdeanu, 2018). 3 TMix In this section, we extend Mixup–a data augmentation method originally proposed by (Zhang et al., 2017) for images–to text modeling. The main idea of Mixup is very simple: given two labeled data points (xi , yi ) and (xj , yj ), where x can be an image and y is the one-hot representation of the label, the algorithm creates virtual training samples by linear interpolations: ˜ = mix(xi , xj ) =λxi + (1 − λ)xj , x (1) ˜ = mix(yi , yj ) =λyi + (1 − λ)yj , y (2) where λ ∈ [0, 1]. The new virtual training samples are used to train a neural network model. Mixup can be interpreted in differen"
2020.acl-main.194,N18-1202,0,0.0173942,"on NLP applications in recent years, and has been applied to a variety of NLP tasks (Radford et al., 2018; Chen et al., 2019; Akbik et al., 2019). Howard and Ruder (2018) proposed to pre-train a language model on a large general-domain corpus and fine-tune it on the target task using some novel techniques like discriminative fine-tuning, slanted triangular learning rates, and gradual unfreezing. In this manner, such pretrained models show excellent performance even with small amounts of labeled data. Pre-training methods are often designed with different objectives such as language modeling (Peters et al., 2018; Howard and Ruder, 2018; Yang et al., 2019b) and masked language modeling (Devlin et al., 2019; Lample and Conneau, 2019). Their performances are also improved with training larger models on more data (Yang et al., 2019b; Liu et al., 2019). 2.2 Semi-Supervised Learning on Text Data Semi-supervised learning has received much attention in the NLP community (Gururangan et al., 2019; Clark et al., 2018; Yang et al., 2015), as unlabeled data is often plentiful compared to labeled data. For instance, Gururangan et al. (2019); Chen et al. (2018); Yang et al. (2017) leveraged variational auto encoder"
2020.acl-main.194,N19-1364,1,0.818661,"been applied to a variety of NLP tasks (Radford et al., 2018; Chen et al., 2019; Akbik et al., 2019). Howard and Ruder (2018) proposed to pre-train a language model on a large general-domain corpus and fine-tune it on the target task using some novel techniques like discriminative fine-tuning, slanted triangular learning rates, and gradual unfreezing. In this manner, such pretrained models show excellent performance even with small amounts of labeled data. Pre-training methods are often designed with different objectives such as language modeling (Peters et al., 2018; Howard and Ruder, 2018; Yang et al., 2019b) and masked language modeling (Devlin et al., 2019; Lample and Conneau, 2019). Their performances are also improved with training larger models on more data (Yang et al., 2019b; Liu et al., 2019). 2.2 Semi-Supervised Learning on Text Data Semi-supervised learning has received much attention in the NLP community (Gururangan et al., 2019; Clark et al., 2018; Yang et al., 2015), as unlabeled data is often plentiful compared to labeled data. For instance, Gururangan et al. (2019); Chen et al. (2018); Yang et al. (2017) leveraged variational auto encoders (VAEs) in a form of sequenceto-sequence m"
2020.acl-main.194,P15-1161,1,0.805431,"Missing"
2020.acl-main.194,N16-1174,1,0.536118,"the-art semi-supervised learning methods on several text classification benchmarks. The improvement is especially prominent when supervision is extremely limited. We have publicly released our code at https: //github.com/GT-SALT/MixText. 1 Figure 1: TMix takes in two text samples x and x0 with labels y and y 0 , mixes their hidden states h and h0 at ˜ and then continues forlayer m with weight λ into h, ward passing to predict the mixed labels y˜. Introduction In the era of deep learning, research has achieved extremely good performance in most supervised learning settings (LeCun et al., 2015; Yang et al., 2016). However, when there is only limited labeled data, supervised deep learning models often suffer from over-fitting (Xie et al., 2019). This strong dependence on labeled data largely prevents neural network models from being applied to new settings or real-world situations due to the need of large amount of time, money, and expertise to obtain enough labeled data. As a result, semi-supervised learning has received much attention to utilize both labeled and unlabeled data for different learning tasks, as unlabeled data is always much easier and cheaper to collect (Chawla and Karakoulas, 2011). T"
2020.acl-main.194,N16-1000,0,0.237924,"Missing"
2020.acl-main.194,D19-1670,0,0.0734458,"e most input space in text is discrete, i.e., one-hot vectors instead of continues RGB values in images, and text is generally more complex in structures. 2.4 Data Augmentations for Text When labeled data is limited, data augmentation has been a useful technique to increase the amount of training data. For instance, in computer vision, images are shifted, zoomed in/out, rotated, flipped, distorted, or shaded with a hue (Perez and Wang, 2017) for training data augmentation. But it is relatively challenging to augment text data because of its complex syntactic and semantic structures. Recently, Wei and Zou (2019) utilized synonym replacement, random insertion, random swap and random deletion for text data augmentation. Similarly, Kumar et al. (2019) proposed a new paraphrasing formulation in terms of monotone submodular function maximization to obtain highly diverse paraphrases, and Xie et al. (2019) and Chen et al. (2020) applied back translations (Sennrich et al., 2015) and word replacement to generate paraphrases on unlabeled data for consistency training. Other work which also investigates noise and its incorporation into semi-supervised named entity classification (Lakshmi Narayan et al., 2019; N"
2020.acl-main.194,N03-1031,0,\N,Missing
2020.emnlp-main.113,N01-1016,0,0.382752,"ion k. 3.2.3 Sequence Tagging For the sequence tagging model, instead of using Transformer or the combination of trainable Transformer and frozen BERT as Wang et al. (2019) did, we directly adopted trainable BERT for both pretraining and fine tuning. First we got the probability of labels of each word: {h1 , h2 , . . . , hT } =BERT({w1 , w2 , . . . , wT }) pt =softmax(W ht + b) (12) Eventually, the goal of the model is to minimize the objective, the cross-entropy (CE) loss: 4 4.1 L = E(s,l) t=1 CE(lt , pt ) (13) Dataset For disfluency detection, we used English Switchboard Dataset. Similar to Charniak and Johnson (2001), we split the dataset to training set sw23[?].dps, development set sw4[5, 6, 7, 8, 9][?].dps, and test set sw4[0, 1][?].dps. Following Hough and Schlangen (2015), we lower-cased the text and removed all punctuation and partial words. For disfluency generation, all sentences with reparandum were treated as disfluent sentences. Specifically, our training set contains 29k disfluent sentences out of 173k sentences. In development set, 2k sentences in a total of 10k sentences are disfluent sentences. In test set, 1.6k sentences out of 7.9k sentences are disfluent sentences. 4.2 Evaluation To measu"
2020.emnlp-main.113,D12-1091,0,0.0210126,"Missing"
2020.emnlp-main.113,D18-1045,0,0.0211392,"that current disfluency detection models usually struggle with substitution and deletion based disfluencies, largely due to the under-representation of substitution and deletion in current training corpus. Disfluent sentences generated by random repetition or insertion rarely contain substitutions, and are thus inadequate in introducing diverse forms of disfluency. To address this gap, we propose a generation based data augmentation method to generate natural and diverse disfluent sentences to further improve the performance of disfluency detection. This method is similar to back-translation (Edunov et al., 2018), which has been shown effective as a way of data augmentation in machine translation. Different from classical neural generation models, our generation model is in a two-stage generation manner, motivated by coarse-to-fine decoding (Dong and Lapata, 2018). Specifically, given a fluent sentence as the input, in the first stage, a Planner selects the positions of where to insert reparandum; in the second stage, a Generator generates disfluent segments accordingly for the predicted areas. Compared to generic end-to-end generation, our two-stage model separates the generation task into two steps:"
2020.emnlp-main.113,E14-3013,0,0.0299684,"state-of-the-art performance by using data augmentation and BERT (Devlin et al., 2018) in a sequence tagging task, and Wang et al. (2018) obtained similar performance by using the same data augmentation methods in an encoder-decoder fashion. These aforementioned data-augmentation methods created augmented disfluent sentences only by randomly inserting or repeating ngrams. To this end, we introduce generation based data augmentation to first generate disfluencies and then use them for sequence tagging of disfluency detection. Note that there was a similar trend in grammatical error detection. Felice and Yuan (2014); Kasewa et al. (2018) generated sentences with grammatical errors to augment the training data of grammatical error detection. 3 3.1 Method Disfluency Generation Our goal is to generate a natural disfluent sentence from a fluent sentence. For this purpose, we introduced a Planner and Generator based model, as shown in Figure 2, which is described as follows. Let x = x1 , x2 , · · · , x|x |denote a fluent sentence, y = y1 , y2 , . . . , y|y |denote the corresponding disfluent sentence. We estimated p(y|x) via a two stage generation process: p(y|x) = p(y|x, a)p(a|x), (1) where a = a1 , a2 , . ."
2020.emnlp-main.113,N15-1029,0,0.365855,"Missing"
2020.emnlp-main.113,P16-1154,0,0.0758832,"Missing"
2020.emnlp-main.113,2020.acl-main.346,0,0.275501,"se-to-fine neural decoders (Dong and Lapata, 2018) for generation tasks to design our disfluency generation model. Disfluency Detection Disfluency detection models mainly fall into four categories. The first one utilizes noisy channel models (Zwarts and Johnson, 2011; Lou and Johnson, 2018), which require Tree 1451 Adjoining Grammar (TAG) based transducer in the channel model. The second category leverages phrase structure, which is often related to transitionbased parsing yet requires annotated syntactic structure (Rasooli and Tetreault, 2013; Yoshikawa et al., 2016; Wu et al., 2015; Jamshid Lou and Johnson, 2020). The third category frames the task as a sequence tagging task (Ferguson et al., 2015; Hough and Schlangen, 2015; Zayats et al., 2016; Lou and Johnson, 2018; Wang et al., 2019), and the last one employs end-to-end Encoder-Decoder models (Wang et al., 2016, 2018) to detect disfluent segments automatically. Traditional disfluency detection models often required additional features (e.g. POS tags) (Wang et al., 2017), syntactic annotations or external tools (e.g. TAG based transducer) (Lou and Johnson, 2018) for learning. Recent disfluency detection approaches leveraged neural representations an"
2020.emnlp-main.113,D18-1541,0,0.0220144,"mance by using data augmentation and BERT (Devlin et al., 2018) in a sequence tagging task, and Wang et al. (2018) obtained similar performance by using the same data augmentation methods in an encoder-decoder fashion. These aforementioned data-augmentation methods created augmented disfluent sentences only by randomly inserting or repeating ngrams. To this end, we introduce generation based data augmentation to first generate disfluencies and then use them for sequence tagging of disfluency detection. Note that there was a similar trend in grammatical error detection. Felice and Yuan (2014); Kasewa et al. (2018) generated sentences with grammatical errors to augment the training data of grammatical error detection. 3 3.1 Method Disfluency Generation Our goal is to generate a natural disfluent sentence from a fluent sentence. For this purpose, we introduced a Planner and Generator based model, as shown in Figure 2, which is described as follows. Let x = x1 , x2 , · · · , x|x |denote a fluent sentence, y = y1 , y2 , . . . , y|y |denote the corresponding disfluent sentence. We estimated p(y|x) via a two stage generation process: p(y|x) = p(y|x, a)p(a|x), (1) where a = a1 , a2 , . . . , a|a |is a decisio"
2020.emnlp-main.113,2020.acl-main.703,0,0.0870466,"Missing"
2020.emnlp-main.113,D18-1490,0,0.562117,"1: Different types of reparandum. Disfluency-Generation-and-Detection. 1 Example they they learn to share. this is just happened yesterday. it’s nothing but wood up here down here. Introduction Disfluency is a para-linguistic concept defining the interruption to the flow of speech (Kowal, 2009). As shown in Figure 1, a standard annotation of the disfluency structure indicates the reparandum (the region to repair), an optional interregnum (filled pauses, discourse cue words, etc.) and the associated repair (corrected linguistic materials) (Nakatani and Hirschberg, 1994). Disfluency detection (Lou et al., 2018; Wang et al., 2019) mainly deals with identifying and removing reparandum1 , 1 We use reparandum and disfluent segments interchangeably in this paper. since interregnum can be easily detected in that they belong to a closed set of words and phrases, e.g. “uh” “I mean” “you know” etc. The output fluent sentences from disfluency detection can serve as clean inputs for most downstream NLP tasks, like dialogue systems, question answering, and machine translation (Wang et al., 2010). Reparandum in disfluency can be categorized as repetition, deletion and substitution (McDougall and Duckworth, 2017"
2020.emnlp-main.113,D15-1166,0,0.0483138,"Missing"
2020.emnlp-main.113,P02-1040,0,0.106494,"en (2015), we lower-cased the text and removed all punctuation and partial words. For disfluency generation, all sentences with reparandum were treated as disfluent sentences. Specifically, our training set contains 29k disfluent sentences out of 173k sentences. In development set, 2k sentences in a total of 10k sentences are disfluent sentences. In test set, 1.6k sentences out of 7.9k sentences are disfluent sentences. 4.2 Evaluation To measure whether generated disfluent sentences are natural, we compared them with reference disfluent sentences based on two generation related metrics: BLEU (Papineni et al., 2002) and Sentence Accuracy, i.e. the percentage of the generated sentences that exactly match the ground-truth disfluent sentences. Furthermore, we evaluated the naturalness of model outputs according to human judgment. Due to budget issue, we only selected the model (PGNC-AD-ID) and the baseline (Insertion & Repetition) with the highest diversity based on automatic measures. For those two models, we randomly selected 100 generated disfluent sentences and they were assessed on Amazon Mechanical Turk. We elicited 3 responses per HIT. For each sentence, Natural was marked with a score of one, Unnatu"
2020.emnlp-main.113,N18-1202,0,0.00822307,"g. TAG based transducer) (Lou and Johnson, 2018) for learning. Recent disfluency detection approaches leveraged neural representations and obtained comparable results. For instance, Lou et al. (2018) adopted CNN and introduced the Auto-Correlation Operator which models more accurate word relations and similarities in order to capture “rough copies”. However, most of them still heavily depend on human-annotated data. As a result, different kinds of data augmentation approaches and pretraining have been designed to alleviate such dependence. For example, Bach and Huang (2019) incorporated ELMo (Peters et al., 2018) to sequence tagging model and Dong et al. (2019) used a pretrained denoising autoencoder to initialize the encoder-decoder model. Wang et al. (2019) achieved state-of-the-art performance by using data augmentation and BERT (Devlin et al., 2018) in a sequence tagging task, and Wang et al. (2018) obtained similar performance by using the same data augmentation methods in an encoder-decoder fashion. These aforementioned data-augmentation methods created augmented disfluent sentences only by randomly inserting or repeating ngrams. To this end, we introduce generation based data augmentation to fi"
2020.emnlp-main.113,D13-1013,0,0.0239298,"rectly used to train the disfluency detection model. We adapt multi-stage coarse-to-fine neural decoders (Dong and Lapata, 2018) for generation tasks to design our disfluency generation model. Disfluency Detection Disfluency detection models mainly fall into four categories. The first one utilizes noisy channel models (Zwarts and Johnson, 2011; Lou and Johnson, 2018), which require Tree 1451 Adjoining Grammar (TAG) based transducer in the channel model. The second category leverages phrase structure, which is often related to transitionbased parsing yet requires annotated syntactic structure (Rasooli and Tetreault, 2013; Yoshikawa et al., 2016; Wu et al., 2015; Jamshid Lou and Johnson, 2020). The third category frames the task as a sequence tagging task (Ferguson et al., 2015; Hough and Schlangen, 2015; Zayats et al., 2016; Lou and Johnson, 2018; Wang et al., 2019), and the last one employs end-to-end Encoder-Decoder models (Wang et al., 2016, 2018) to detect disfluent segments automatically. Traditional disfluency detection models often required additional features (e.g. POS tags) (Wang et al., 2017), syntactic annotations or external tools (e.g. TAG based transducer) (Lou and Johnson, 2018) for learning. R"
2020.emnlp-main.113,P17-1099,0,0.0418671,"dden vector at the j-th time step is computed by as yj ; if ai = 1, the Generator generates a sequence of words as reparandum before copying xi+1 . ¯ j = fLSTM (h ¯ j−1 , zj ) h (10) ¯0 = h ˆ |x |if we use the last hidden state where h of encoder to initialize the first state of decoder; ¯ 0 = 0 if we do not use such initialization (ID), deh creasing the decoder’s dependence on the encoder for high diversity of generated disfluent segments. ˆ and deBased on encoder’s hidden vectors h ¯ coder’s hidden vectors h, we used attention and copying mechanism to compute p(yj |y&lt;j , x, a), similarly to See et al. (2017). Alternatively, we also computed it without attention (AD) or copying 3.2 Disfluency Detection We regarded the disfluency detection task as a sequence tagging task. We denoted i-th sentence with T words as si = {wt |t = 1, . . . , T }, the input of our model is {s1 , s2 , . . . , sN }, where N is the number of sentences in the dataset. The corresponding output is {q1 , q2 , . . . , qN }, where qi is the label sequence of i-th sentence, qi = {lt |t = 1, . . . , T }. lt ∈ {I, O}, where I (O) represents that the word is in (or outside) the region of reperandum. 1453 3.2.1 Heuristic based Data Au"
2020.emnlp-main.113,C18-1299,0,0.13672,"line models. • We utilize our generation model to generate natural and diverse augmented disfluent data for the task of disfluency detection, and obtain state-of-the-art performance. We conduct thorough error analysis and discuss specific challenges faced by current approaches. 2 Related Work Disfluency Generation Betz et al. (2015) and Adell et al. (2006) used heuristic rules to generate filled pauses, repetitions in disfluent speech generation. Their works demonstrate that disfluency generation enhances the naturalness and intelligibility of speech generated by text-to-speech (TTS) systems. Wang et al. (2018) and Wang et al. (2019) randomly inserted or repeated ngrams to generate augmented disfluent sentences. Disfluent sentences generated in this method have low affinity to disfluent sentences from the benchmark dataset, and they contain few substitutions, causing limited diversity. To achieve better affinity and diversity, we design generation based data augmentation which generates natural disfluent sentences that can then be directly used to train the disfluency detection model. We adapt multi-stage coarse-to-fine neural decoders (Dong and Lapata, 2018) for generation tasks to design our disfl"
2020.emnlp-main.113,C16-1027,0,0.0133053,", 2011; Lou and Johnson, 2018), which require Tree 1451 Adjoining Grammar (TAG) based transducer in the channel model. The second category leverages phrase structure, which is often related to transitionbased parsing yet requires annotated syntactic structure (Rasooli and Tetreault, 2013; Yoshikawa et al., 2016; Wu et al., 2015; Jamshid Lou and Johnson, 2020). The third category frames the task as a sequence tagging task (Ferguson et al., 2015; Hough and Schlangen, 2015; Zayats et al., 2016; Lou and Johnson, 2018; Wang et al., 2019), and the last one employs end-to-end Encoder-Decoder models (Wang et al., 2016, 2018) to detect disfluent segments automatically. Traditional disfluency detection models often required additional features (e.g. POS tags) (Wang et al., 2017), syntactic annotations or external tools (e.g. TAG based transducer) (Lou and Johnson, 2018) for learning. Recent disfluency detection approaches leveraged neural representations and obtained comparable results. For instance, Lou et al. (2018) adopted CNN and introduced the Auto-Correlation Operator which models more accurate word relations and similarities in order to capture “rough copies”. However, most of them still heavily depen"
2020.emnlp-main.113,D17-1296,0,0.678131,"ture, which is often related to transitionbased parsing yet requires annotated syntactic structure (Rasooli and Tetreault, 2013; Yoshikawa et al., 2016; Wu et al., 2015; Jamshid Lou and Johnson, 2020). The third category frames the task as a sequence tagging task (Ferguson et al., 2015; Hough and Schlangen, 2015; Zayats et al., 2016; Lou and Johnson, 2018; Wang et al., 2019), and the last one employs end-to-end Encoder-Decoder models (Wang et al., 2016, 2018) to detect disfluent segments automatically. Traditional disfluency detection models often required additional features (e.g. POS tags) (Wang et al., 2017), syntactic annotations or external tools (e.g. TAG based transducer) (Lou and Johnson, 2018) for learning. Recent disfluency detection approaches leveraged neural representations and obtained comparable results. For instance, Lou et al. (2018) adopted CNN and introduced the Auto-Correlation Operator which models more accurate word relations and similarities in order to capture “rough copies”. However, most of them still heavily depend on human-annotated data. As a result, different kinds of data augmentation approaches and pretraining have been designed to alleviate such dependence. For examp"
2020.emnlp-main.113,P15-1048,0,0.0188659,"We adapt multi-stage coarse-to-fine neural decoders (Dong and Lapata, 2018) for generation tasks to design our disfluency generation model. Disfluency Detection Disfluency detection models mainly fall into four categories. The first one utilizes noisy channel models (Zwarts and Johnson, 2011; Lou and Johnson, 2018), which require Tree 1451 Adjoining Grammar (TAG) based transducer in the channel model. The second category leverages phrase structure, which is often related to transitionbased parsing yet requires annotated syntactic structure (Rasooli and Tetreault, 2013; Yoshikawa et al., 2016; Wu et al., 2015; Jamshid Lou and Johnson, 2020). The third category frames the task as a sequence tagging task (Ferguson et al., 2015; Hough and Schlangen, 2015; Zayats et al., 2016; Lou and Johnson, 2018; Wang et al., 2019), and the last one employs end-to-end Encoder-Decoder models (Wang et al., 2016, 2018) to detect disfluent segments automatically. Traditional disfluency detection models often required additional features (e.g. POS tags) (Wang et al., 2017), syntactic annotations or external tools (e.g. TAG based transducer) (Lou and Johnson, 2018) for learning. Recent disfluency detection approaches lev"
2020.emnlp-main.113,D16-1109,0,0.0139842,"luency detection model. We adapt multi-stage coarse-to-fine neural decoders (Dong and Lapata, 2018) for generation tasks to design our disfluency generation model. Disfluency Detection Disfluency detection models mainly fall into four categories. The first one utilizes noisy channel models (Zwarts and Johnson, 2011; Lou and Johnson, 2018), which require Tree 1451 Adjoining Grammar (TAG) based transducer in the channel model. The second category leverages phrase structure, which is often related to transitionbased parsing yet requires annotated syntactic structure (Rasooli and Tetreault, 2013; Yoshikawa et al., 2016; Wu et al., 2015; Jamshid Lou and Johnson, 2020). The third category frames the task as a sequence tagging task (Ferguson et al., 2015; Hough and Schlangen, 2015; Zayats et al., 2016; Lou and Johnson, 2018; Wang et al., 2019), and the last one employs end-to-end Encoder-Decoder models (Wang et al., 2016, 2018) to detect disfluent segments automatically. Traditional disfluency detection models often required additional features (e.g. POS tags) (Wang et al., 2017), syntactic annotations or external tools (e.g. TAG based transducer) (Lou and Johnson, 2018) for learning. Recent disfluency detecti"
2020.emnlp-main.113,P11-1071,0,0.162961,"e low affinity to disfluent sentences from the benchmark dataset, and they contain few substitutions, causing limited diversity. To achieve better affinity and diversity, we design generation based data augmentation which generates natural disfluent sentences that can then be directly used to train the disfluency detection model. We adapt multi-stage coarse-to-fine neural decoders (Dong and Lapata, 2018) for generation tasks to design our disfluency generation model. Disfluency Detection Disfluency detection models mainly fall into four categories. The first one utilizes noisy channel models (Zwarts and Johnson, 2011; Lou and Johnson, 2018), which require Tree 1451 Adjoining Grammar (TAG) based transducer in the channel model. The second category leverages phrase structure, which is often related to transitionbased parsing yet requires annotated syntactic structure (Rasooli and Tetreault, 2013; Yoshikawa et al., 2016; Wu et al., 2015; Jamshid Lou and Johnson, 2020). The third category frames the task as a sequence tagging task (Ferguson et al., 2015; Hough and Schlangen, 2015; Zayats et al., 2016; Lou and Johnson, 2018; Wang et al., 2019), and the last one employs end-to-end Encoder-Decoder models (Wang e"
2020.emnlp-main.336,P18-1063,0,0.250548,"ffectiveness of our proposed methods. (4) We conduct thorough error analyses and discuss specific challenges that current approaches faced with this task. 2 Related Work Document Summarization Document summarization has received extensive research attention, especially for abstractive summarization. For instance, Rush et al. (2015) introduced to use sequence-to-sequence models for abstractive text summarization. See et al. (2017) proposed a pointer-generator network to allow copying words from the source text to handle the OOV issue and avoid generating repeated content. Paulus et al. (2018); Chen and Bansal (2018) further utilized reinforcement learning to select the correct content needed by summarization. Large-scale pre-trained language models (Liu and Lapata, 2019; Raffel et al., 2019; Lewis et al., 2019) have also been introduced to further improve the summarization performance. Other line of work explored long-document summarization by utilizing discourse structures in text (Cohan et al., 2018), introducing hierarchical models (Fabbri et al., 2019) or modifying attention mechanisms (Beltagy et al., 2020). There are also recent studies looking at the faithfulness in 4107 Figure 1: Model architectu"
2020.emnlp-main.336,A00-2004,0,0.0608943,"Here we combine the classic topic segment 4108 Figure 2: Allowed state transitions for the HMM conversation model. Si are conversation stages, Oi are sentences’ encoded representations. Conversation stages evolve in an increasing order from 1 to n. Stage Interpretation 1 Openings 2 Intentions 3 Discussions 4 Conclusions Top Freq Words hey, hi, good, yeah,going, time need, like, think, get, want, really will, know, time, come,tomorrow, meet thanks, ok, see, great, thank, sure Table 2: The top 6 frequent words appearing in each stage and the interpretations for different stages. algorithm, C99 (Choi, 2000) that segments conversations based on inter-sentence similarities, with recent advanced sentence representations SentenceBERT (Reimers and Gurevych, 2019), to extract the topic view. Specifically, each utterance ui in a conversation C = {u1 , u2 , ..., um } is first encoded into hidden vectors via Sentence-BERT. Then the conversation C is divided into blocks Ctopic = {b1 , ..., bn } through C99, where bi is one block that contains several consecutive utterances, such as the topic view described in Table 1. versation followed by discussions of the details, and finally conclude with certain endi"
2020.emnlp-main.336,N18-2097,0,0.0251308,"ext summarization. See et al. (2017) proposed a pointer-generator network to allow copying words from the source text to handle the OOV issue and avoid generating repeated content. Paulus et al. (2018); Chen and Bansal (2018) further utilized reinforcement learning to select the correct content needed by summarization. Large-scale pre-trained language models (Liu and Lapata, 2019; Raffel et al., 2019; Lewis et al., 2019) have also been introduced to further improve the summarization performance. Other line of work explored long-document summarization by utilizing discourse structures in text (Cohan et al., 2018), introducing hierarchical models (Fabbri et al., 2019) or modifying attention mechanisms (Beltagy et al., 2020). There are also recent studies looking at the faithfulness in 4107 Figure 1: Model architecture. Different views of conversations are first extracted automatically, and then encoded through the conversation encoder (a) and combined in the multi-view decoder to generate summaries (b). In the conversation encoder, each view (consists of blocks) is encoded separately and the block’s representations Si are encoded through LSTM to represent the view. In the multi-view decoder, the model"
2020.emnlp-main.336,N16-1082,0,0.0616924,"Missing"
2020.emnlp-main.336,P19-1210,0,0.513497,"s, which refer to the way utterances are organized in order to make the conversation meaningful, enjoyable and understandable (Sacks et al., 1978), in dialogues – a key factor that differentiates dialogues from structured documents. As a way of using language socially of “doing things with words” together with other persons, the conversation has its own dynamic structures that organize utterances in certain orders to make the conversation meaningful, enjoyable, and understandable (Sacks et al., 1978). Although there are a few exceptions such as utilizing topic segmentation (Liu et al., 2019b; Li et al., 2019), dialogue acts (Goo and Chen, 2018) or key point sequence (Liu et al., 2019a), they either need 4106 Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, pages 4106–4118, c November 16–20, 2020. 2020 Association for Computational Linguistics Conversation Topic View Stage View James: Hey! I have been thinking about you : ) Greetings Hannah: Oh, that’s nice ; ) Openings James: What are you up to? Hannah: I’m about to sleep Today’s plan Intention James: I miss u. I was hoping to see you Hannah: Have to get up early for work tomorrow James: What about tomorrow?"
2020.emnlp-main.336,P04-1077,0,0.527635,"Missing"
2020.emnlp-main.336,W14-4318,0,0.0489037,"Missing"
2020.emnlp-main.336,D12-1009,0,0.207242,"l., 2019a), or only encode conversations based on their topics (Liu et al., 2019b), which fails to capture rich conversation structures in dialogues. Even one single conversation can be viewed from different perspectives, resulting in multiple conversational or discourse patterns. For instance, in Table 1, based on what topics were discussed (topic view) (Galley et al., 2003; Liu et al., 2019b; Li et al., 2019), it can be segmented into greetings, today’s plan, plan for tomorrow, plan for Saturday and pick up time; from a conversation progression perspective (stage view) (Ritter et al., 2010; Paul, 2012; Althoff et al., 2016), the same dialogue can be categorized into openings, intention, discussion, and conclusion. From a coarse perspective (global view), conversations can be treated as a whole, or each utterance can serve as one segment (discrete view). Models that only utilized a fixed topic view of the conversation (Joty et al., 2010; Liu et al., 2019b) may fail to capture its comprehensive and nuanced conversational structures, and any amount of information loss introduced by the conversation encoder may lead to larger error cascade in the decoding stage. To fill these gaps, we propose"
2020.emnlp-main.336,D15-1044,0,0.100207,"model that consists of a conversation encoder to encode different views and a multi-view decoder with multiview attention to generate dialogue summaries. (3) We perform experiments on a large-scale conversation summarization dataset, SAMSum (Gliwa et al., 2019), and demonstrate the effectiveness of our proposed methods. (4) We conduct thorough error analyses and discuss specific challenges that current approaches faced with this task. 2 Related Work Document Summarization Document summarization has received extensive research attention, especially for abstractive summarization. For instance, Rush et al. (2015) introduced to use sequence-to-sequence models for abstractive text summarization. See et al. (2017) proposed a pointer-generator network to allow copying words from the source text to handle the OOV issue and avoid generating repeated content. Paulus et al. (2018); Chen and Bansal (2018) further utilized reinforcement learning to select the correct content needed by summarization. Large-scale pre-trained language models (Liu and Lapata, 2019; Raffel et al., 2019; Lewis et al., 2019) have also been introduced to further improve the summarization performance. Other line of work explored long-do"
2020.emnlp-main.336,P17-1099,0,0.753839,"/machine are increasing exponentially in the form of textual dialogues between users and users-agents (Kester, 2004). It is challenging and time-consuming to review all the content before starting any conversations especially when the chatting history becomes very long (Gao et al., 2020). How to process and organize those interaction activities into concise and structured data, i.e. conversation summarization, becomes technically and socially important. Most existing research efforts on text summarization have been focused on single-speaker documents like news reports (Nallapati et al., 2016; See et al., 2017), scientific publications (Nikolov et al., 2018) or encyclopedia articles (Liu* et al., 2018), where structured text is usually used to elaborate a core idea in the third-person point of view, and the information flow is very clear through paragraphs or sections. Different from these structured documents, conversations are often informal, verbose and repetitive, sprinkled with false-starts, back channeling, reconfirmations, hesitations, speaker interruptions (Sacks et al., 1978) and the salient information is scattered in the whole chat, making current summarization models hard to focus on man"
2020.emnlp-main.336,P18-1062,0,0.0892263,"Missing"
2020.emnlp-main.336,D19-1298,0,0.028205,"formal language use Many conversations especially in online contexts such as Twitter/Reddit (Jackson and Moulinier, 2007), contain typos, word abbreviations, slang or emoticons/emojis, making it hard to be represented and summarized. 2. Multiple participants As shown in Figure 3, conversations with more speakers are harder to be summarized since it may require models to accurately differentiate both language styles and content from different speakers, similar to the multiple characters issue in story summarization (Zhang et al., 2019). 3. Multiple turns Similar to long document summarization (Xiao and Carenini, 2019), conversations with many utterances contain more information to be processed, thus harder to be summarized. 4. (Referral and coreference People usually refer to each other, mention others’ names or use coreference in their messages, which introduces extra difficulty to dialogue summarization, also a challenge also exists in reading comprehension (Chen et al., 2016) and document summarization (Falke et al., 2017). 5. Repetition and interruption Information is generally scattered through the whole conversation, and speakers may interrupt each other, Challenge Generic Informal language Multiple"
2020.emnlp-main.89,W13-2111,0,0.540524,") lack explicit signals for models on what to generate, which can lead to subjective content and evaluation challenges (Kry´sci´nski et al., 2019). On the other hand, data-to-text tasks that are limited to verbalizing a fully specified meaning representation (Gardent et al., 2017b) do not test a model’s ability to perform inference and thus remove a considerable amount of challenge from the task. Secondly, designing an annotation process to obtain natural but also clean targets is a significant challenge. One strategy employed by many datasets is to have annotators write targets from scratch (Banik et al., 2013; Wen et al., 2015; Gardent et al., 2017a) which can often lack variety in terms of structure and style (Gururangan et al., 2018; Poliak et al., 2018). An alternative is to pair naturally occurring text with tables (Lebret et al., 2016; Wiseman et al., 2017). While more diverse, naturally occurring targets are often noisy and contain information that cannot be inferred from the source. This can make it problematic to disentangle modeling weaknesses from data noise. In this work, we propose T OTT O, an opendomain table-to-text generation dataset that intro1173 Proceedings of the 2020 Conference"
2020.emnlp-main.89,2020.acl-main.708,0,0.215626,"nables T OTT O to maintain the varied language and structure found in natural sentences while producing cleaner targets. The technique of editing exemplar sentences has been used in semiparametric generation models (Guu et al., 2018; Pandey et al., 2018; Peng et al., 2019) and crowd-sourcing small, iterative changes to text has been shown to lead to higher-quality data and a more robust annotation process (Little et al., 2010). Perez-Beltrachini and Lapata (2018) also employed a revision strategy to construct a cleaner evaluation set for Wikibio (Lebret et al., 2016). Concurrent to this work, Chen et al. (2020) proposed LogicNLG which also uses Wikipedia tables, although omitting some of the more complex structured ones included in our dataset. Their target sentences are annotator-generated and their task is significantly more uncontrolled due to the lack of annotator highlighted cells. Annotation Process There are various existing strategies to create the reference target y. One strategy employed by many datasets is to have annotators write targets from scratch given a representation of the source (Banik et al., 2013; Wen et al., 2015; Gardent et al., 2017a). While this will result in a target that"
2020.emnlp-main.89,P19-1483,1,0.920838,"Existing data-to-text tasks have provided an important test-bed for neural generation models (Sutskever et al., 2014; Bahdanau et al., 2014). Neural models are known to be prone to hallucination, i.e., generating text that is fluent but not faithful to the source (Vinyals and Le, 2015; Koehn ∗ Work done during an internship at Google. T OTT O is available at https://github.com/ google-research-datasets/totto. 1 and Knowles, 2017; Lee et al., 2018; Tian et al., 2019) and it is often easier to assess faithfulness of the generated text when the source content is structured (Wiseman et al., 2017; Dhingra et al., 2019). Moreover, structured data can also test a model’s ability for reasoning and numerical inference (Wiseman et al., 2017) and for building representations of structured objects (Liu et al., 2018), providing an interesting complement to tasks that test these aspects in the NLU setting (Pasupat and Liang, 2015; Chen et al., 2019; Dua et al., 2019). However, constructing a data-to-text dataset can be challenging on two axes: task design and annotation process. First, tasks with open-ended output like summarization (Mani, 1999; Lebret et al., 2016; Wiseman et al., 2017) lack explicit signals for mo"
2020.emnlp-main.89,N19-1246,0,0.0250175,"ailable at https://github.com/ google-research-datasets/totto. 1 and Knowles, 2017; Lee et al., 2018; Tian et al., 2019) and it is often easier to assess faithfulness of the generated text when the source content is structured (Wiseman et al., 2017; Dhingra et al., 2019). Moreover, structured data can also test a model’s ability for reasoning and numerical inference (Wiseman et al., 2017) and for building representations of structured objects (Liu et al., 2018), providing an interesting complement to tasks that test these aspects in the NLU setting (Pasupat and Liang, 2015; Chen et al., 2019; Dua et al., 2019). However, constructing a data-to-text dataset can be challenging on two axes: task design and annotation process. First, tasks with open-ended output like summarization (Mani, 1999; Lebret et al., 2016; Wiseman et al., 2017) lack explicit signals for models on what to generate, which can lead to subjective content and evaluation challenges (Kry´sci´nski et al., 2019). On the other hand, data-to-text tasks that are limited to verbalizing a fully specified meaning representation (Gardent et al., 2017b) do not test a model’s ability to perform inference and thus remove a considerable amount of c"
2020.emnlp-main.89,P17-1017,0,0.0422605,"t to tasks that test these aspects in the NLU setting (Pasupat and Liang, 2015; Chen et al., 2019; Dua et al., 2019). However, constructing a data-to-text dataset can be challenging on two axes: task design and annotation process. First, tasks with open-ended output like summarization (Mani, 1999; Lebret et al., 2016; Wiseman et al., 2017) lack explicit signals for models on what to generate, which can lead to subjective content and evaluation challenges (Kry´sci´nski et al., 2019). On the other hand, data-to-text tasks that are limited to verbalizing a fully specified meaning representation (Gardent et al., 2017b) do not test a model’s ability to perform inference and thus remove a considerable amount of challenge from the task. Secondly, designing an annotation process to obtain natural but also clean targets is a significant challenge. One strategy employed by many datasets is to have annotators write targets from scratch (Banik et al., 2013; Wen et al., 2015; Gardent et al., 2017a) which can often lack variety in terms of structure and style (Gururangan et al., 2018; Poliak et al., 2018). An alternative is to pair naturally occurring text with tables (Lebret et al., 2016; Wiseman et al., 2017). Wh"
2020.emnlp-main.89,W17-3518,0,0.484701,"t to tasks that test these aspects in the NLU setting (Pasupat and Liang, 2015; Chen et al., 2019; Dua et al., 2019). However, constructing a data-to-text dataset can be challenging on two axes: task design and annotation process. First, tasks with open-ended output like summarization (Mani, 1999; Lebret et al., 2016; Wiseman et al., 2017) lack explicit signals for models on what to generate, which can lead to subjective content and evaluation challenges (Kry´sci´nski et al., 2019). On the other hand, data-to-text tasks that are limited to verbalizing a fully specified meaning representation (Gardent et al., 2017b) do not test a model’s ability to perform inference and thus remove a considerable amount of challenge from the task. Secondly, designing an annotation process to obtain natural but also clean targets is a significant challenge. One strategy employed by many datasets is to have annotators write targets from scratch (Banik et al., 2013; Wen et al., 2015; Gardent et al., 2017a) which can often lack variety in terms of structure and style (Gururangan et al., 2018; Poliak et al., 2018). An alternative is to pair naturally occurring text with tables (Lebret et al., 2016; Wiseman et al., 2017). Wh"
2020.emnlp-main.89,W18-6505,1,0.869327,"t h(D) be the set of 1178 header values for a given dataset D. We remove examples d from the training set where h(d) is both rare in the data as well as occurs in either the development or test sets. Specifically, Dtrain is defined as: pre-train a version of BERT on the Books corpus only, which we consider a more correct baseline. However, empirically we find that both models perform similarly in practice (Table 8). • Pointer-Generator (See et al., 2017): A Seq2Seq model with attention and copy mechanism. While originally designed for summarization it is commonly used in data-to-text as well (Gehrmann et al., 2018). • Puduppully et al. (2019): A Seq2Seq model with an explicit content selection and planning mechanism designed for data-to-text. Dtrain := {d : h(d) ∈ / (h(Ddev ) ∪ h(Dtest )) or  count h(d), Dorig-train &gt; α}. The count(h(d), Dorig-train ) function returns the number of examples in Dorig-train with header h(d). To choose the hyperparameter α we first split the test set as follows: Dtest-overlap := {d : h(d) ∈ h(Dtrain )} Dtest-nonoverlap := {d : h(d) ∈ / h(Dtrain )} The development set is analogously divided into Ddev-overlap and Ddev-nonoverlap . We then choose α = 5 so that Dtest-overlap"
2020.emnlp-main.89,N18-2017,0,0.136218,"´sci´nski et al., 2019). On the other hand, data-to-text tasks that are limited to verbalizing a fully specified meaning representation (Gardent et al., 2017b) do not test a model’s ability to perform inference and thus remove a considerable amount of challenge from the task. Secondly, designing an annotation process to obtain natural but also clean targets is a significant challenge. One strategy employed by many datasets is to have annotators write targets from scratch (Banik et al., 2013; Wen et al., 2015; Gardent et al., 2017a) which can often lack variety in terms of structure and style (Gururangan et al., 2018; Poliak et al., 2018). An alternative is to pair naturally occurring text with tables (Lebret et al., 2016; Wiseman et al., 2017). While more diverse, naturally occurring targets are often noisy and contain information that cannot be inferred from the source. This can make it problematic to disentangle modeling weaknesses from data noise. In this work, we propose T OTT O, an opendomain table-to-text generation dataset that intro1173 Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, pages 1173–1186, c November 16–20, 2020. 2020 Association for Computationa"
2020.emnlp-main.89,Q18-1031,0,0.0326281,"s a summarization problem. However, summarization is much more subjective, which can make the task underconstrained and difficult to evaluate (Kry´sci´nski et al., 2019). We place T OTT O as a middle-ground where the highlighted cells provide some guidance on the topic of the target but still leave a considerable amount of content planning to be done by the model. the table. This enables T OTT O to maintain the varied language and structure found in natural sentences while producing cleaner targets. The technique of editing exemplar sentences has been used in semiparametric generation models (Guu et al., 2018; Pandey et al., 2018; Peng et al., 2019) and crowd-sourcing small, iterative changes to text has been shown to lead to higher-quality data and a more robust annotation process (Little et al., 2010). Perez-Beltrachini and Lapata (2018) also employed a revision strategy to construct a cleaner evaluation set for Wikibio (Lebret et al., 2016). Concurrent to this work, Chen et al. (2020) proposed LogicNLG which also uses Wikipedia tables, although omitting some of the more complex structured ones included in our dataset. Their target sentences are annotator-generated and their task is significantl"
2020.emnlp-main.89,W17-3204,0,0.0768419,"Missing"
2020.emnlp-main.89,D19-1051,0,0.0497763,"Missing"
2020.emnlp-main.89,P83-1022,0,0.499371,"obtain generated targets that are natural but also faithful to the source table, we introduce a dataset construction process where annotators directly revise existing candidate sentences from Wikipedia. We present systematic analyses of our dataset and annotation process as well as results achieved by several state-of-the-art baselines. While usually fluent, existing methods often hallucinate phrases that are not supported by the table, suggesting that this dataset can serve as a useful research benchmark for high-precision conditional text generation.1 1 Introduction Data-to-text generation (Kukich, 1983; McKeown, 1992) is the task of generating a target textual description y conditioned on source content x in the form of structured data such as a table. Examples include generating sentences given biographical data (Lebret et al., 2016), textual descriptions of restaurants given meaning representations (Novikova et al., 2017), basketball game summaries given boxscore statistics (Wiseman et al., 2017), and generating fun facts from superlative tables in Wikipedia (Korn et al., 2019). Existing data-to-text tasks have provided an important test-bed for neural generation models (Sutskever et al.,"
2020.emnlp-main.89,D16-1128,0,0.109807,"yses of our dataset and annotation process as well as results achieved by several state-of-the-art baselines. While usually fluent, existing methods often hallucinate phrases that are not supported by the table, suggesting that this dataset can serve as a useful research benchmark for high-precision conditional text generation.1 1 Introduction Data-to-text generation (Kukich, 1983; McKeown, 1992) is the task of generating a target textual description y conditioned on source content x in the form of structured data such as a table. Examples include generating sentences given biographical data (Lebret et al., 2016), textual descriptions of restaurants given meaning representations (Novikova et al., 2017), basketball game summaries given boxscore statistics (Wiseman et al., 2017), and generating fun facts from superlative tables in Wikipedia (Korn et al., 2019). Existing data-to-text tasks have provided an important test-bed for neural generation models (Sutskever et al., 2014; Bahdanau et al., 2014). Neural models are known to be prone to hallucination, i.e., generating text that is fluent but not faithful to the source (Vinyals and Le, 2015; Koehn ∗ Work done during an internship at Google. T OTT O is"
2020.emnlp-main.89,P09-1011,0,0.0375768,"hful to the source (see Table 4 and the Appendix for more complex examples). Our experiments demonstrate that state-of-the-art neural models struggle to generate faithful results, despite the high quality of the training data. These results suggest that our dataset could serve as a useful benchmark for controllable data-to-text generation. 2 Related Work T OTT O differs from existing datasets in both task design and annotation process as we describe below. A summary is given in Table 2. Task Design Most existing table-to-text datasets are restricted in topic and schema such as W EATH ER G OV (Liang et al., 2009), ROBO C UP (Chen and Mooney, 2008), Rotowire (Wiseman et al., 2017, basketball), E2E (Novikova et al., 2016, 2017, restaurants), KBGen (Banik et al., 2013, biology), and Wikibio (Lebret et al., 2016, biographies). In contrast, T OTT O contains tables with various schema spanning various topical categories all over Wikipedia. Moreover, T OTT O takes a different view of content selection compared to 1174 Dataset Train Size Wikibio (Lebret et al., 2016) 583K Rotowire (Wiseman et al., 2017) 4.9K WebNLG (Gardent et al., 2017b) 25.3K E2E (Novikova et al., 2017) 50.6K LogicNLG (Chen et al., 2020) 28"
2020.emnlp-main.89,W19-5302,0,0.0175146,"odel achieves the highest BLEU. Red indicates model errors and blue denotes interesting reference language not in the model output. in the non-overlap case, where we see a moderate effect favoring the book model. model is unable to make these inferences from the simplistic source representation that we used. 9 Evaluation metrics Many of the above issues are difficult to capture with metrics like BLEU since the reference and prediction may only differ by a word but largely differ in terms of semantic meaning. This urges for better metrics possibly built on learned models (Wiseman et al., 2017; Ma et al., 2019; Sellam et al., 2020). Thus, while we have a task leaderboard, it should not be interpreted as the definitive measure of model performance. Model Errors and Challenges Table 11 shows predictions from the BERT-toBERT Books model to illustrate challenges existing models face. Hallucination The model sometimes outputs phrases such as first, winning that seem reasonable but are not faithful to the table. This hallucination phenomenon has been widely observed in other existing data-to-text datasets (Lebret et al., 2016; Wiseman et al., 2017). However, the noisy references in these datasets make it"
2020.emnlp-main.89,W17-5525,0,0.0636405,"Missing"
2020.emnlp-main.89,W16-6644,0,0.148876,"hat state-of-the-art neural models struggle to generate faithful results, despite the high quality of the training data. These results suggest that our dataset could serve as a useful benchmark for controllable data-to-text generation. 2 Related Work T OTT O differs from existing datasets in both task design and annotation process as we describe below. A summary is given in Table 2. Task Design Most existing table-to-text datasets are restricted in topic and schema such as W EATH ER G OV (Liang et al., 2009), ROBO C UP (Chen and Mooney, 2008), Rotowire (Wiseman et al., 2017, basketball), E2E (Novikova et al., 2016, 2017, restaurants), KBGen (Banik et al., 2013, biology), and Wikibio (Lebret et al., 2016, biographies). In contrast, T OTT O contains tables with various schema spanning various topical categories all over Wikipedia. Moreover, T OTT O takes a different view of content selection compared to 1174 Dataset Train Size Wikibio (Lebret et al., 2016) 583K Rotowire (Wiseman et al., 2017) 4.9K WebNLG (Gardent et al., 2017b) 25.3K E2E (Novikova et al., 2017) 50.6K LogicNLG (Chen et al., 2020) 28.5K T OTT O 120K Domain Biographies Basketball 15 DBPedia categories Restaurants Wikipedia (open-domain) Wik"
2020.emnlp-main.89,P18-1123,0,0.0215634,"problem. However, summarization is much more subjective, which can make the task underconstrained and difficult to evaluate (Kry´sci´nski et al., 2019). We place T OTT O as a middle-ground where the highlighted cells provide some guidance on the topic of the target but still leave a considerable amount of content planning to be done by the model. the table. This enables T OTT O to maintain the varied language and structure found in natural sentences while producing cleaner targets. The technique of editing exemplar sentences has been used in semiparametric generation models (Guu et al., 2018; Pandey et al., 2018; Peng et al., 2019) and crowd-sourcing small, iterative changes to text has been shown to lead to higher-quality data and a more robust annotation process (Little et al., 2010). Perez-Beltrachini and Lapata (2018) also employed a revision strategy to construct a cleaner evaluation set for Wikibio (Lebret et al., 2016). Concurrent to this work, Chen et al. (2020) proposed LogicNLG which also uses Wikipedia tables, although omitting some of the more complex structured ones included in our dataset. Their target sentences are annotator-generated and their task is significantly more uncontrolled d"
2020.emnlp-main.89,P02-1040,0,0.108003,"aseline). • BERT-to-BERT (Rothe et al., 2020): A Transformer encoder-decoder model (Vaswani et al., 2017) where the encoder and decoder are both initialized with BERT (Devlin et al., 2018). The original BERT model is pre-trained with both Wikipedia and the Books corpus (Zhu et al., 2015), the former of which contains our (unrevised) test targets. Thus, we also In all cases, the cells are linearized with row and column separator tokens. We also experiment with prepending the table metadata to the source table.6 Evaluation metrics The model output is evaluated using two automatic metrics: BLEU (Papineni et al., 2002) and PARENT (Dhingra et al., 2019). PARENT is a metric recently proposed specifically for data-to-text evaluation that takes the table into account. We modify it to make it suitable for our dataset, described in the Appendix. Human evaluation is described in § 8.2. 8.1 Results Table 8 shows our results against multiple references with the subtable input format. Both the 6 The table section text is ignored, since it is usually missing or irrelevant. 1179 Overall Model Overlap Subset Nonoverlap Subset BLEU PARENT BLEU PARENT BLEU PARENT 44.0 43.9 41.6 19.2 52.6 52.6 51.6 29.2 52.7 52.7 50.6 24.5"
2020.emnlp-main.89,P15-1142,0,0.0470512,"uring an internship at Google. T OTT O is available at https://github.com/ google-research-datasets/totto. 1 and Knowles, 2017; Lee et al., 2018; Tian et al., 2019) and it is often easier to assess faithfulness of the generated text when the source content is structured (Wiseman et al., 2017; Dhingra et al., 2019). Moreover, structured data can also test a model’s ability for reasoning and numerical inference (Wiseman et al., 2017) and for building representations of structured objects (Liu et al., 2018), providing an interesting complement to tasks that test these aspects in the NLU setting (Pasupat and Liang, 2015; Chen et al., 2019; Dua et al., 2019). However, constructing a data-to-text dataset can be challenging on two axes: task design and annotation process. First, tasks with open-ended output like summarization (Mani, 1999; Lebret et al., 2016; Wiseman et al., 2017) lack explicit signals for models on what to generate, which can lead to subjective content and evaluation challenges (Kry´sci´nski et al., 2019). On the other hand, data-to-text tasks that are limited to verbalizing a fully specified meaning representation (Gardent et al., 2017b) do not test a model’s ability to perform inference and"
2020.emnlp-main.89,N19-1263,1,0.844058,"marization is much more subjective, which can make the task underconstrained and difficult to evaluate (Kry´sci´nski et al., 2019). We place T OTT O as a middle-ground where the highlighted cells provide some guidance on the topic of the target but still leave a considerable amount of content planning to be done by the model. the table. This enables T OTT O to maintain the varied language and structure found in natural sentences while producing cleaner targets. The technique of editing exemplar sentences has been used in semiparametric generation models (Guu et al., 2018; Pandey et al., 2018; Peng et al., 2019) and crowd-sourcing small, iterative changes to text has been shown to lead to higher-quality data and a more robust annotation process (Little et al., 2010). Perez-Beltrachini and Lapata (2018) also employed a revision strategy to construct a cleaner evaluation set for Wikibio (Lebret et al., 2016). Concurrent to this work, Chen et al. (2020) proposed LogicNLG which also uses Wikipedia tables, although omitting some of the more complex structured ones included in our dataset. Their target sentences are annotator-generated and their task is significantly more uncontrolled due to the lack of an"
2020.emnlp-main.89,D15-1199,0,0.398205,"als for models on what to generate, which can lead to subjective content and evaluation challenges (Kry´sci´nski et al., 2019). On the other hand, data-to-text tasks that are limited to verbalizing a fully specified meaning representation (Gardent et al., 2017b) do not test a model’s ability to perform inference and thus remove a considerable amount of challenge from the task. Secondly, designing an annotation process to obtain natural but also clean targets is a significant challenge. One strategy employed by many datasets is to have annotators write targets from scratch (Banik et al., 2013; Wen et al., 2015; Gardent et al., 2017a) which can often lack variety in terms of structure and style (Gururangan et al., 2018; Poliak et al., 2018). An alternative is to pair naturally occurring text with tables (Lebret et al., 2016; Wiseman et al., 2017). While more diverse, naturally occurring targets are often noisy and contain information that cannot be inferred from the source. This can make it problematic to disentangle modeling weaknesses from data noise. In this work, we propose T OTT O, an opendomain table-to-text generation dataset that intro1173 Proceedings of the 2020 Conference on Empirical Meth"
2020.emnlp-main.89,D17-1239,0,0.113448,"phrases that are not supported by the table, suggesting that this dataset can serve as a useful research benchmark for high-precision conditional text generation.1 1 Introduction Data-to-text generation (Kukich, 1983; McKeown, 1992) is the task of generating a target textual description y conditioned on source content x in the form of structured data such as a table. Examples include generating sentences given biographical data (Lebret et al., 2016), textual descriptions of restaurants given meaning representations (Novikova et al., 2017), basketball game summaries given boxscore statistics (Wiseman et al., 2017), and generating fun facts from superlative tables in Wikipedia (Korn et al., 2019). Existing data-to-text tasks have provided an important test-bed for neural generation models (Sutskever et al., 2014; Bahdanau et al., 2014). Neural models are known to be prone to hallucination, i.e., generating text that is fluent but not faithful to the source (Vinyals and Le, 2015; Koehn ∗ Work done during an internship at Google. T OTT O is available at https://github.com/ google-research-datasets/totto. 1 and Knowles, 2017; Lee et al., 2018; Tian et al., 2019) and it is often easier to assess faithfulnes"
2020.emnlp-main.89,N18-1137,0,0.0181728,"highlighted cells provide some guidance on the topic of the target but still leave a considerable amount of content planning to be done by the model. the table. This enables T OTT O to maintain the varied language and structure found in natural sentences while producing cleaner targets. The technique of editing exemplar sentences has been used in semiparametric generation models (Guu et al., 2018; Pandey et al., 2018; Peng et al., 2019) and crowd-sourcing small, iterative changes to text has been shown to lead to higher-quality data and a more robust annotation process (Little et al., 2010). Perez-Beltrachini and Lapata (2018) also employed a revision strategy to construct a cleaner evaluation set for Wikibio (Lebret et al., 2016). Concurrent to this work, Chen et al. (2020) proposed LogicNLG which also uses Wikipedia tables, although omitting some of the more complex structured ones included in our dataset. Their target sentences are annotator-generated and their task is significantly more uncontrolled due to the lack of annotator highlighted cells. Annotation Process There are various existing strategies to create the reference target y. One strategy employed by many datasets is to have annotators write targets f"
2020.emnlp-main.89,S18-2023,0,0.0622913,"Missing"
2020.emnlp-main.89,2020.tacl-1.18,0,0.0606276,"refore, the task is more challenging, as the model must generate a new sentence instead of revising an existing one. 8 Details about hyperparameter settings are provided in the Appendix. Moreover, we explore different strategies of representing the source content that resemble standard linearization approaches in the literature (Lebret et al., 2016; Wiseman et al., 2017) Experiments We present baseline results on T OTT O by examining three existing state-of-the-art approaches (Note that since our tables do not have a fixed schema it is difficult to design a template baseline). • BERT-to-BERT (Rothe et al., 2020): A Transformer encoder-decoder model (Vaswani et al., 2017) where the encoder and decoder are both initialized with BERT (Devlin et al., 2018). The original BERT model is pre-trained with both Wikipedia and the Books corpus (Zhu et al., 2015), the former of which contains our (unrevised) test targets. Thus, we also In all cases, the cells are linearized with row and column separator tokens. We also experiment with prepending the table metadata to the source table.6 Evaluation metrics The model output is evaluated using two automatic metrics: BLEU (Papineni et al., 2002) and PARENT (Dhingra et"
2020.emnlp-main.89,2020.acl-main.704,1,0.851685,"highest BLEU. Red indicates model errors and blue denotes interesting reference language not in the model output. in the non-overlap case, where we see a moderate effect favoring the book model. model is unable to make these inferences from the simplistic source representation that we used. 9 Evaluation metrics Many of the above issues are difficult to capture with metrics like BLEU since the reference and prediction may only differ by a word but largely differ in terms of semantic meaning. This urges for better metrics possibly built on learned models (Wiseman et al., 2017; Ma et al., 2019; Sellam et al., 2020). Thus, while we have a task leaderboard, it should not be interpreted as the definitive measure of model performance. Model Errors and Challenges Table 11 shows predictions from the BERT-toBERT Books model to illustrate challenges existing models face. Hallucination The model sometimes outputs phrases such as first, winning that seem reasonable but are not faithful to the table. This hallucination phenomenon has been widely observed in other existing data-to-text datasets (Lebret et al., 2016; Wiseman et al., 2017). However, the noisy references in these datasets make it difficult to disentan"
2020.emnlp-main.89,P17-1099,0,\N,Missing
2020.emnlp-main.89,N19-1423,0,\N,Missing
2020.emnlp-main.89,D19-1609,0,\N,Missing
2020.emnlp-main.95,N19-4010,0,0.0216626,"Missing"
2020.emnlp-main.95,C18-1139,0,0.0115548,"cations, organizations) in unstructured text (Nadeau and Sekine, 2007), is an essential prerequisite for many NLP applications. Being one of the most fundamental and classic sequence labeling tasks in NLP, there have been extensive research from traditional statistical models like Hidden Markov Models (Zhou and Su, 2002) and Conditional Random Fields (Lafferty et al., 2001a), to neural network based models such as LSTMCRF (Lample et al., 2016a) and BLSTM-CNNCRF (Ma and Hovy, 2016), and to recent pre∗ Equal contribution. training and fine-tuning methods like ELMO (Peters et al., 2018a), Flair (Akbik et al., 2018) and BERT (Devlin et al., 2019). However, most of those models still heavily rely on abundant annotated data to yield the state-of-the-art results (Lin et al., 2020), making them hard to be applied into new domains (e.g., social media, medical context or low-resourced languages) that lack labeled data. Different kinds of data augmentation approaches have been designed to alleviate the dependency on labeled data for many NLP tasks, and can be categorized into two broad classes: (1) adversarial attacks at token-levels such as word substitutions (Kobayashi, 2018; Wei and Zou, 2019) or adding nois"
2020.emnlp-main.95,D19-5531,0,0.0377377,"Missing"
2020.emnlp-main.95,2020.acl-main.194,1,0.825902,"The former has already been used for NER but struggles to create diverse augmented samples with very few word replacements. Despite being widely utilized in many NLP tasks like text classification, the latter often fails to maintain the labels at the token-level in those paraphrased sentences, thus making it difficult to be applied to NER. We focus on another type of data augmentations called mixup (Zhang et al., 2018), which was originally proposed in computer vision and performed linear interpolations between randomly sampled image pairs to create virtual training data. Miao et al. (2020); Chen et al. (2020b) adapted the idea to textual domains and have applied it to the preliminary task of text classification. However, unlike classifications where each sentence only has one label, sequence labeling tasks such as NER usually involve multiple interrelated labels in a single sentence. As we found in empirical experiments, it is challenging to directly apply such mixup technique to sequence labeling, and improper interpolations may mislead the model. For instance, random sam1241 Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, pages 1241–1251, c November 16–20"
2020.emnlp-main.95,D18-1020,0,0.435978,"ed special tokens and non-first sub-tokens for fair comparisons. In the fully supervised setting, we followed the standard data splits shown in Table 2. In the semisupervised setting, we sampled 10,000 sentences in the training set as the unlabeled training data. We adopted FairSeq1 to implement the back translation. For CoNLL dataset, we utilized German as the intermediate language and English as the intermediate language for GermEval. 4.2 To demonstrate whether our Semi-LADA works with unlabeled data, we compared it with two recent state-of-the-art semi-supervised NER models: • VSL-GG-Hier (Chen et al., 2018) introduced a hierarchical latent variables models into semi-supervised NER learning. • MT + Noise (Lakshmi Narayan et al., 2019) explored different noise strategies including word-dropout, synonym-replace, Gaussian noise and network-dropout in a mean-teacher framework. We also compared our models with another two recent state-of-the-art NER models trained on the whole training set: • CVT (Clark et al., 2018) performed multitask learning and made use of 1 Billion Word Language Model Benchmark as the source of unlabeled data. Baselines & Model Settings Our LADA can be applied to any models in s"
2020.emnlp-main.95,2020.acl-main.529,0,0.228578,"a Beta distribution. mixup trains the neural network for image classification by minimizing the loss on the virtual examples. In experiments, the pairs of images data points (x, y) ˜ ) are randomly sampled. By assuming all and (˜ x, y the images are mapped to a low dimension manifold through a neural network, linearly interpolating them creates a virtual vicinity distribution around the original data space, thus improving the generalization performance of the classifier trained on the interpolated samples. Prior work like Snippext (Miao et al., 2020), MixText (Chen et al., 2020b) and AdvAug (Cheng et al., 2020) generalized the idea to the textual domain by proposing to interpolate in output space (Miao et al., 2020), embedding space (Cheng et al., 2020), or general hidden space (Chen et al., 2020b) of textual data and applied the technique to NLP tasks such as text classifications and machine translations and achieved significant improvements. 3 Method Based on the above interpolation based data augmentation techniques, in Section 3.1, we introduced a Local Additivity based Data Augmentation (LADA) for sequence labeling, where creating augmented samples is much more challenging. We continue to descr"
2020.emnlp-main.95,D18-1217,0,0.355734,"ediate language for GermEval. 4.2 To demonstrate whether our Semi-LADA works with unlabeled data, we compared it with two recent state-of-the-art semi-supervised NER models: • VSL-GG-Hier (Chen et al., 2018) introduced a hierarchical latent variables models into semi-supervised NER learning. • MT + Noise (Lakshmi Narayan et al., 2019) explored different noise strategies including word-dropout, synonym-replace, Gaussian noise and network-dropout in a mean-teacher framework. We also compared our models with another two recent state-of-the-art NER models trained on the whole training set: • CVT (Clark et al., 2018) performed multitask learning and made use of 1 Billion Word Language Model Benchmark as the source of unlabeled data. Baselines & Model Settings Our LADA can be applied to any models in standard sequence labeling frameworks. In this work, we applied LADA to two state-of-the-art pre-trained models to show the effectiveness: • Flair (Akbik et al., 2019): We used the pretrained Flair embeddings2 , and a multi-layer BiLSTM-CRF (Ma and Hovy, 2016) as the encoder to detect the entities. • BERT (Devlin et al., 2019): We loaded the BERT-base-multilingual-cased3 as the encoder and a linear layer to pr"
2020.emnlp-main.95,N19-1423,0,0.205874,"tructured text (Nadeau and Sekine, 2007), is an essential prerequisite for many NLP applications. Being one of the most fundamental and classic sequence labeling tasks in NLP, there have been extensive research from traditional statistical models like Hidden Markov Models (Zhou and Su, 2002) and Conditional Random Fields (Lafferty et al., 2001a), to neural network based models such as LSTMCRF (Lample et al., 2016a) and BLSTM-CNNCRF (Ma and Hovy, 2016), and to recent pre∗ Equal contribution. training and fine-tuning methods like ELMO (Peters et al., 2018a), Flair (Akbik et al., 2018) and BERT (Devlin et al., 2019). However, most of those models still heavily rely on abundant annotated data to yield the state-of-the-art results (Lin et al., 2020), making them hard to be applied into new domains (e.g., social media, medical context or low-resourced languages) that lack labeled data. Different kinds of data augmentation approaches have been designed to alleviate the dependency on labeled data for many NLP tasks, and can be categorized into two broad classes: (1) adversarial attacks at token-levels such as word substitutions (Kobayashi, 2018; Wei and Zou, 2019) or adding noise (Lakshmi Narayan et al., 2019"
2020.emnlp-main.95,W03-0426,0,0.138929,"Inter-LADA only did kNNs sampling, and it could get a better F1 score over BERT because of providing meaningful signals to training. BERT + Inter-LADA got the best F1 score with µ = 0.7 on CoNLL and µ = 0.5 on GermEval, which indicated the tradeoff between noise and diversity (kNNs sampling with lower noise and random sampling with higher diversity) was necessary for Inter-LADA. 5 5.1 Related Work Named Entity Recognition Conditional random fields (CRFs) (Lafferty et al., 2001b; Sutton et al., 2004) have been widely used for NER, until recently they have been outperformed by neural networks. Hammerton (2003) and Collobert et al. (2011) are among the first several studies to model sequence labeling using neural networks. Specifically Hammerton (2003) encoded the input sequence using a unidirectional LSTM (Hochreiter and Schmidhuber, 1997) while (Collobert et al., 2011) instead used a CNN with character level embedding to encode sentences. Ma and Hovy (2016); Lample et al. (2016b) proposed LSTM-CRFs to combine neural networks with CRFs that aim to leverage both the representation learning capabilities of neural network and structured loss from CRFs. Instead of modeling NER as a sequence modeling pr"
2020.emnlp-main.95,N18-2072,0,0.0353721,"(Peters et al., 2018a), Flair (Akbik et al., 2018) and BERT (Devlin et al., 2019). However, most of those models still heavily rely on abundant annotated data to yield the state-of-the-art results (Lin et al., 2020), making them hard to be applied into new domains (e.g., social media, medical context or low-resourced languages) that lack labeled data. Different kinds of data augmentation approaches have been designed to alleviate the dependency on labeled data for many NLP tasks, and can be categorized into two broad classes: (1) adversarial attacks at token-levels such as word substitutions (Kobayashi, 2018; Wei and Zou, 2019) or adding noise (Lakshmi Narayan et al., 2019), (2) paraphrasing at sentence-levels such as back translations (Xie et al., 2019) or submodular optimized models (Kumar et al., 2019). The former has already been used for NER but struggles to create diverse augmented samples with very few word replacements. Despite being widely utilized in many NLP tasks like text classification, the latter often fails to maintain the labels at the token-level in those paraphrased sentences, thus making it difficult to be applied to NER. We focus on another type of data augmentations called m"
2020.emnlp-main.95,S19-1020,0,0.107528,"Devlin et al., 2019). However, most of those models still heavily rely on abundant annotated data to yield the state-of-the-art results (Lin et al., 2020), making them hard to be applied into new domains (e.g., social media, medical context or low-resourced languages) that lack labeled data. Different kinds of data augmentation approaches have been designed to alleviate the dependency on labeled data for many NLP tasks, and can be categorized into two broad classes: (1) adversarial attacks at token-levels such as word substitutions (Kobayashi, 2018; Wei and Zou, 2019) or adding noise (Lakshmi Narayan et al., 2019), (2) paraphrasing at sentence-levels such as back translations (Xie et al., 2019) or submodular optimized models (Kumar et al., 2019). The former has already been used for NER but struggles to create diverse augmented samples with very few word replacements. Despite being widely utilized in many NLP tasks like text classification, the latter often fails to maintain the labels at the token-level in those paraphrased sentences, thus making it difficult to be applied to NER. We focus on another type of data augmentations called mixup (Zhang et al., 2018), which was originally proposed in compute"
2020.emnlp-main.95,N16-1030,0,0.66692,"released our code at https://github.com/GT-SALT/LADA. 1 Introduction Named Entity Recognition (NER) that aims to detect the semantic category of entities (e.g., persons, locations, organizations) in unstructured text (Nadeau and Sekine, 2007), is an essential prerequisite for many NLP applications. Being one of the most fundamental and classic sequence labeling tasks in NLP, there have been extensive research from traditional statistical models like Hidden Markov Models (Zhou and Su, 2002) and Conditional Random Fields (Lafferty et al., 2001a), to neural network based models such as LSTMCRF (Lample et al., 2016a) and BLSTM-CNNCRF (Ma and Hovy, 2016), and to recent pre∗ Equal contribution. training and fine-tuning methods like ELMO (Peters et al., 2018a), Flair (Akbik et al., 2018) and BERT (Devlin et al., 2019). However, most of those models still heavily rely on abundant annotated data to yield the state-of-the-art results (Lin et al., 2020), making them hard to be applied into new domains (e.g., social media, medical context or low-resourced languages) that lack labeled data. Different kinds of data augmentation approaches have been designed to alleviate the dependency on labeled data for many NLP"
2020.emnlp-main.95,2020.acl-main.519,0,0.024629,"llobert et al. (2011) are among the first several studies to model sequence labeling using neural networks. Specifically Hammerton (2003) encoded the input sequence using a unidirectional LSTM (Hochreiter and Schmidhuber, 1997) while (Collobert et al., 2011) instead used a CNN with character level embedding to encode sentences. Ma and Hovy (2016); Lample et al. (2016b) proposed LSTM-CRFs to combine neural networks with CRFs that aim to leverage both the representation learning capabilities of neural network and structured loss from CRFs. Instead of modeling NER as a sequence modeling problem, Li et al. (2020) converted NER into a reading comprehension task with an input sentence and a query sentence based on the entity types and achieved competitive performance. 5.2 Semi-supervised Learning for NER There has been extensive previous work (Altun et al., 2005; Søgaard, 2011; Mann and McCallum, 2010) that utilized semi-supervised learning for NER. For instance, (Zhang et al., 2017; Chen et al., 2018) applied variational autoencoders (VAEs) to semi-supervised sequence labeling; (Zhang et al., 2017) proposed to use discrete labeling sequence as latent variables while (Chen et al., 2018) used continuous"
2020.emnlp-main.95,2020.acl-main.752,0,0.0185957,"lassic sequence labeling tasks in NLP, there have been extensive research from traditional statistical models like Hidden Markov Models (Zhou and Su, 2002) and Conditional Random Fields (Lafferty et al., 2001a), to neural network based models such as LSTMCRF (Lample et al., 2016a) and BLSTM-CNNCRF (Ma and Hovy, 2016), and to recent pre∗ Equal contribution. training and fine-tuning methods like ELMO (Peters et al., 2018a), Flair (Akbik et al., 2018) and BERT (Devlin et al., 2019). However, most of those models still heavily rely on abundant annotated data to yield the state-of-the-art results (Lin et al., 2020), making them hard to be applied into new domains (e.g., social media, medical context or low-resourced languages) that lack labeled data. Different kinds of data augmentation approaches have been designed to alleviate the dependency on labeled data for many NLP tasks, and can be categorized into two broad classes: (1) adversarial attacks at token-levels such as word substitutions (Kobayashi, 2018; Wei and Zou, 2019) or adding noise (Lakshmi Narayan et al., 2019), (2) paraphrasing at sentence-levels such as back translations (Xie et al., 2019) or submodular optimized models (Kumar et al., 2019"
2020.emnlp-main.95,N19-1117,0,0.0120624,"r-LADA. The left Y axis is for CoNLL, and the right Y axis is for GermEval. Dashed lines are the F1 scores of BERT model. et al., 2018b) and BERT (Devlin et al., 2019) trained on a large amount of unlabeled data have been applied to NER and achieved reasonable performances. Our work is related to research that introduces different data augmentation techniques for NER. For example, Lakshmi Narayan et al. (2019) applied noise injection and word dropout and obtained a performance boost, Bodapati et al. (2019) varied the capitalization of words to increase the robustness to capitalization errors, Liu et al. (2019) augmented traditional models with pretraining on external knowledge bases. In contrast, our work can be viewed as data augmentation in the continuous hidden space without external resources. 5.3 Mixup-based Data Augmentation Mixup (Zhang et al., 2018) was originally proposed for image classification (Verma et al., 2018; Yun et al., 2019) as a data augmentation and regularization method , building on which Miao et al. (2020) proposed to interpolate sentences’ encoded representations with augmented sentences by tokensubstitutions for text classification. Similarly, Chen et al. (2020a) designed"
2020.emnlp-main.95,P16-1101,0,0.542099,"/GT-SALT/LADA. 1 Introduction Named Entity Recognition (NER) that aims to detect the semantic category of entities (e.g., persons, locations, organizations) in unstructured text (Nadeau and Sekine, 2007), is an essential prerequisite for many NLP applications. Being one of the most fundamental and classic sequence labeling tasks in NLP, there have been extensive research from traditional statistical models like Hidden Markov Models (Zhou and Su, 2002) and Conditional Random Fields (Lafferty et al., 2001a), to neural network based models such as LSTMCRF (Lample et al., 2016a) and BLSTM-CNNCRF (Ma and Hovy, 2016), and to recent pre∗ Equal contribution. training and fine-tuning methods like ELMO (Peters et al., 2018a), Flair (Akbik et al., 2018) and BERT (Devlin et al., 2019). However, most of those models still heavily rely on abundant annotated data to yield the state-of-the-art results (Lin et al., 2020), making them hard to be applied into new domains (e.g., social media, medical context or low-resourced languages) that lack labeled data. Different kinds of data augmentation approaches have been designed to alleviate the dependency on labeled data for many NLP tasks, and can be categorized into two"
2020.emnlp-main.95,N18-1202,0,0.101762,"of entities (e.g., persons, locations, organizations) in unstructured text (Nadeau and Sekine, 2007), is an essential prerequisite for many NLP applications. Being one of the most fundamental and classic sequence labeling tasks in NLP, there have been extensive research from traditional statistical models like Hidden Markov Models (Zhou and Su, 2002) and Conditional Random Fields (Lafferty et al., 2001a), to neural network based models such as LSTMCRF (Lample et al., 2016a) and BLSTM-CNNCRF (Ma and Hovy, 2016), and to recent pre∗ Equal contribution. training and fine-tuning methods like ELMO (Peters et al., 2018a), Flair (Akbik et al., 2018) and BERT (Devlin et al., 2019). However, most of those models still heavily rely on abundant annotated data to yield the state-of-the-art results (Lin et al., 2020), making them hard to be applied into new domains (e.g., social media, medical context or low-resourced languages) that lack labeled data. Different kinds of data augmentation approaches have been designed to alleviate the dependency on labeled data for many NLP tasks, and can be categorized into two broad classes: (1) adversarial attacks at token-levels such as word substitutions (Kobayashi, 2018; Wei"
2020.emnlp-main.95,D19-1410,0,0.0133848,"propose Inter-LADA, where we sample a different sentence from the training set to perform interpolations. 3.3 Inter-LADA Instead of interpolating within one sentence, IntraLADA samples a different sentence x0 from the training set to interpolate with x. To achieve a trade-off between noise and regularization, we sample x0 through a weighted combination of two strategies: k-nearest neighbors (kNNs) sampling and random sampling: ( µ x0 ∈ Neighbork (x), 0 k, PInter (x |x) = 1−µ (x0 , y0 ) ∈ S, |S |, (4) where µ is the weight of combining two distributions. To get the kNNs, we use sentence-BERT (Reimers and Gurevych, 2019) to map each sentence x into a hidden space, then collect each sentence’s kNNs using l2 distance. For each sentence x, we sample x0 to mix up from the kNNs with probability µ and the whole training corpus with a probability 1 − µ. When x0 is sampled from the whole training corpus, it may be unrelated to x, introducing large noise but also strong regularization on the model. When x0 is sampled from the kNNs, x0 shares similar, albeit different, context with x, thus achieving good signal to noise ratio. By treating µ as a hyper-parameter, we can control the delicate trade-off between noise and d"
2020.emnlp-main.95,P11-2009,0,0.0169918,"d a CNN with character level embedding to encode sentences. Ma and Hovy (2016); Lample et al. (2016b) proposed LSTM-CRFs to combine neural networks with CRFs that aim to leverage both the representation learning capabilities of neural network and structured loss from CRFs. Instead of modeling NER as a sequence modeling problem, Li et al. (2020) converted NER into a reading comprehension task with an input sentence and a query sentence based on the entity types and achieved competitive performance. 5.2 Semi-supervised Learning for NER There has been extensive previous work (Altun et al., 2005; Søgaard, 2011; Mann and McCallum, 2010) that utilized semi-supervised learning for NER. For instance, (Zhang et al., 2017; Chen et al., 2018) applied variational autoencoders (VAEs) to semi-supervised sequence labeling; (Zhang et al., 2017) proposed to use discrete labeling sequence as latent variables while (Chen et al., 2018) used continuous latent variables in their models. Recently, contextual representations such as ELMO (Peters 1248 Recognition (NER) with two different interpolation strategies. To utilize unlabeled data, we introduced a novel consistent training objective combined with LADA. Experime"
2020.emnlp-main.95,W03-0419,0,0.126218,"Missing"
2020.emnlp-main.95,D19-1670,0,0.0354904,"018a), Flair (Akbik et al., 2018) and BERT (Devlin et al., 2019). However, most of those models still heavily rely on abundant annotated data to yield the state-of-the-art results (Lin et al., 2020), making them hard to be applied into new domains (e.g., social media, medical context or low-resourced languages) that lack labeled data. Different kinds of data augmentation approaches have been designed to alleviate the dependency on labeled data for many NLP tasks, and can be categorized into two broad classes: (1) adversarial attacks at token-levels such as word substitutions (Kobayashi, 2018; Wei and Zou, 2019) or adding noise (Lakshmi Narayan et al., 2019), (2) paraphrasing at sentence-levels such as back translations (Xie et al., 2019) or submodular optimized models (Kumar et al., 2019). The former has already been used for NER but struggles to create diverse augmented samples with very few word replacements. Despite being widely utilized in many NLP tasks like text classification, the latter often fails to maintain the labels at the token-level in those paraphrased sentences, thus making it difficult to be applied to NER. We focus on another type of data augmentations called mixup (Zhang et al.,"
2020.emnlp-main.95,D17-1179,0,0.0202668,"roposed LSTM-CRFs to combine neural networks with CRFs that aim to leverage both the representation learning capabilities of neural network and structured loss from CRFs. Instead of modeling NER as a sequence modeling problem, Li et al. (2020) converted NER into a reading comprehension task with an input sentence and a query sentence based on the entity types and achieved competitive performance. 5.2 Semi-supervised Learning for NER There has been extensive previous work (Altun et al., 2005; Søgaard, 2011; Mann and McCallum, 2010) that utilized semi-supervised learning for NER. For instance, (Zhang et al., 2017; Chen et al., 2018) applied variational autoencoders (VAEs) to semi-supervised sequence labeling; (Zhang et al., 2017) proposed to use discrete labeling sequence as latent variables while (Chen et al., 2018) used continuous latent variables in their models. Recently, contextual representations such as ELMO (Peters 1248 Recognition (NER) with two different interpolation strategies. To utilize unlabeled data, we introduced a novel consistent training objective combined with LADA. Experiments have been conducted and proved our proposed methods’ effectiveness through comparing with several state-"
2020.emnlp-main.95,P02-1060,0,0.315174,"onducted on two NER benchmarks demonstrate the effectiveness of our methods over several strong baselines. We have publicly released our code at https://github.com/GT-SALT/LADA. 1 Introduction Named Entity Recognition (NER) that aims to detect the semantic category of entities (e.g., persons, locations, organizations) in unstructured text (Nadeau and Sekine, 2007), is an essential prerequisite for many NLP applications. Being one of the most fundamental and classic sequence labeling tasks in NLP, there have been extensive research from traditional statistical models like Hidden Markov Models (Zhou and Su, 2002) and Conditional Random Fields (Lafferty et al., 2001a), to neural network based models such as LSTMCRF (Lample et al., 2016a) and BLSTM-CNNCRF (Ma and Hovy, 2016), and to recent pre∗ Equal contribution. training and fine-tuning methods like ELMO (Peters et al., 2018a), Flair (Akbik et al., 2018) and BERT (Devlin et al., 2019). However, most of those models still heavily rely on abundant annotated data to yield the state-of-the-art results (Lin et al., 2020), making them hard to be applied into new domains (e.g., social media, medical context or low-resourced languages) that lack labeled data."
2020.evalnlgeval-1.2,W18-6537,0,0.0404837,"Missing"
2020.evalnlgeval-1.2,W19-8648,0,0.0611537,"Missing"
2020.evalnlgeval-1.2,E06-1040,0,0.388123,"Missing"
2020.evalnlgeval-1.2,Q18-1041,0,0.0976894,"l. (2018) included the human evaluation guidelines they used as an appendix, which have since been adopted by other studies (Qian et al., 2019). This example shows that guidelines for human evaluation have value: guidelines make life easier and people often adopt those that are available. As such, we make the case for increased transparency in human evaluation with respect to design details that could potentially influence results. In an effort to take preliminary steps towards human evaluation guidelines, we propose the concept of “human evaluation design statements” akin to data statements (Bender and Friedman, 2018; Gebru et al., 2020) or model cards (Mitchell et al., 2019). Determining what should be included on such statements will require additional input, perspectives, and empirical evidence. As a preliminary effort, we provide a list of design parameters that we believe could influence results and should therefore be included when describing human evaluation design setup: Question Design: Types, Scales, Wording Basic inclusions pertaining to question design are question type and corresponding scales due to the variability that can arise based on these design decisions (Novikova et al., 2018). Furth"
2020.evalnlgeval-1.2,Q18-1018,0,0.0513519,"Missing"
2020.evalnlgeval-1.2,D19-1224,0,0.0507172,"Missing"
2020.evalnlgeval-1.2,D18-1421,0,0.0268295,"ng should be viewed through a skeptical lens as though they could contain researcher imparted bias that could significantly impact results. Further, we use our demonstration of the potential for framing effects and biases in question wording as support for a call for transparency in human evaluation for NLG through the inclusion of study design details, which can aid in the development of more robust human evaluation guidelines. When guidelines exist that can reduce the complexity and time required to design human evaluation studies, they are used. For the evaluation of paraphrase generation, Li et al. (2018) included the human evaluation guidelines they used as an appendix, which have since been adopted by other studies (Qian et al., 2019). This example shows that guidelines for human evaluation have value: guidelines make life easier and people often adopt those that are available. As such, we make the case for increased transparency in human evaluation with respect to design details that could potentially influence results. In an effort to take preliminary steps towards human evaluation guidelines, we propose the concept of “human evaluation design statements” akin to data statements (Bender an"
2020.evalnlgeval-1.2,2020.acl-main.465,0,0.0282082,"Missing"
2020.evalnlgeval-1.2,D16-1230,0,0.0521029,"Missing"
2020.evalnlgeval-1.2,N19-1049,0,0.10377,"ffects, statistics regarding the number of questions per annotator should be reported to increase design transparency in terms of potential influences on variability in results. Target Criteria: Definitions It makes intuitive sense that what is actually being measured in human evaluation would influence results, and further that measuring the same or different target criteria in different studies would impact the comparability of the results. However, naming conventions and definitions are inconsistent and may exhibit significant overlap, such as with naturalness, grammaticality, and fluency (Mir et al., 2019; Novikova et al., 2018). As such, what is being measured should be compared across studies based on definition and the resulting participant understanding of the task, rather than simply based on naming convention: studies may measure the same aspect under different names or different aspects under the same name. Studies consistently reporting this detail in human evaluation is also a preliminary step towards agreed upon task definitions. Annotators: Demographics, Background, Recruitment, Compensation Understanding and reporting the details of the human factor in human evaluation is intuitive"
2020.evalnlgeval-1.2,D17-1238,0,0.0809503,"Missing"
2020.evalnlgeval-1.2,N18-2012,0,0.116933,"Missing"
2020.evalnlgeval-1.2,D19-1313,0,0.0198069,"esults. Further, we use our demonstration of the potential for framing effects and biases in question wording as support for a call for transparency in human evaluation for NLG through the inclusion of study design details, which can aid in the development of more robust human evaluation guidelines. When guidelines exist that can reduce the complexity and time required to design human evaluation studies, they are used. For the evaluation of paraphrase generation, Li et al. (2018) included the human evaluation guidelines they used as an appendix, which have since been adopted by other studies (Qian et al., 2019). This example shows that guidelines for human evaluation have value: guidelines make life easier and people often adopt those that are available. As such, we make the case for increased transparency in human evaluation with respect to design details that could potentially influence results. In an effort to take preliminary steps towards human evaluation guidelines, we propose the concept of “human evaluation design statements” akin to data statements (Bender and Friedman, 2018; Gebru et al., 2020) or model cards (Mitchell et al., 2019). Determining what should be included on such statements w"
2020.evalnlgeval-1.2,J09-4008,0,0.0836609,"Missing"
2020.evalnlgeval-1.2,2020.findings-emnlp.112,0,0.0271633,"for NLG that are biased in favor of a particular model. While these examples may at first glance seem implausible and only possible in cases of conscious (explicit) researcher bias in favor of a particular model, it is important to take into consideration the potential for researchers to possess unconscious (implicit) bias whether due to underlying expectations for a model’s performance or due to influences of publication bias. During the peer review process reviewers may default to heuristics to simplify the task of review, including rejecting papers where models do not achieve SOTA results (Rogers and Augenstein, 2020). This can implicitly motivate and incentivize researchers to show their model performs best on the gold standard of evaluation for NLG: human evaluation. We use this example to demonstrate the potential for the current lack of evaluation design details, in particular question wording, to leave the door open for results that have been subject to framing effects and bias which threatens the validity of the results. We draw attention to these effects in an effort to both increase researcher awareness to their own evaluation study design, decrease the potential for questions framed in ways in whi"
2020.findings-emnlp.116,P18-2006,0,0.0196421,"al., 2015). In the context of our dataset—a lending platform where concreteness consists mostly of demands—a lack of emotive argumentation may cause an audience to focus on demands themselves, resulting in concrete and emotionless requests. 1302 5 5.1 Improving Request Persuasiveness Predicted Average Success Rate ∆ from Original Request Editing Operations Based on the effectiveness of different persuasion patterns we discovered, this section examines improving underperforming persuasion requests by editing the persuasion strategy patterns. Here we define three editing operations: (1) Insert (Ebrahimi et al., 2018; Wallace et al., 2019) overperforming triplets into the end of less persuasive requests containing underperforming triplets. (2) Delete (Ebrahimi et al., 2018) the underperforming triplets in less persuasive requests. (3) Swap (Ebrahimi et al., 2018) underperforming triplets by first deleting the underperforming triplets and then appending overperforming triplets to the request. We also noticed that overperforming triplets were general conversation closers; their insertion at the end of requests would not alter the intent of a message. We performed editing operations to the least persuasive r"
2020.findings-emnlp.116,D16-1129,0,0.0282359,"Missing"
2020.findings-emnlp.116,P16-1150,0,0.0528239,"Missing"
2020.findings-emnlp.116,J17-1004,0,0.0693386,"Missing"
2020.findings-emnlp.116,W15-0515,0,0.0263776,"” norms by closing conversations politely are shifting importance of a request from strategy to content. Thus, content must still be optimal for a request to be persuasive. 4.2 “It’s My Money & I Need It Now.” On the contrary, if a triplet consists mostly of concreteness, it performs far below average. For instance, triplets like (Co, Co, Co) often came up in examples that were demanding as shown in Table 3. From a social science perspective, emotional appeal in arguments is key to framing aspects of a request and helps soften attention placed on facts (Walton, 1992; Macagno and Walton, 2014; Oraby et al., 2015). In the context of our dataset—a lending platform where concreteness consists mostly of demands—a lack of emotive argumentation may cause an audience to focus on demands themselves, resulting in concrete and emotionless requests. 1302 5 5.1 Improving Request Persuasiveness Predicted Average Success Rate ∆ from Original Request Editing Operations Based on the effectiveness of different persuasion patterns we discovered, this section examines improving underperforming persuasion requests by editing the persuasion strategy patterns. Here we define three editing operations: (1) Insert (Ebrahimi e"
2020.findings-emnlp.116,D19-1221,0,0.0120172,"ext of our dataset—a lending platform where concreteness consists mostly of demands—a lack of emotive argumentation may cause an audience to focus on demands themselves, resulting in concrete and emotionless requests. 1302 5 5.1 Improving Request Persuasiveness Predicted Average Success Rate ∆ from Original Request Editing Operations Based on the effectiveness of different persuasion patterns we discovered, this section examines improving underperforming persuasion requests by editing the persuasion strategy patterns. Here we define three editing operations: (1) Insert (Ebrahimi et al., 2018; Wallace et al., 2019) overperforming triplets into the end of less persuasive requests containing underperforming triplets. (2) Delete (Ebrahimi et al., 2018) the underperforming triplets in less persuasive requests. (3) Swap (Ebrahimi et al., 2018) underperforming triplets by first deleting the underperforming triplets and then appending overperforming triplets to the request. We also noticed that overperforming triplets were general conversation closers; their insertion at the end of requests would not alter the intent of a message. We performed editing operations to the least persuasive requests (974 examples)"
2020.findings-emnlp.116,N19-1364,1,0.920872,"eviations are bolded. placements for individual rhetorical strategies in a request. Other research analyzed how different persuasive strategies are more effective on specific stances and personal backgrounds (Durmus and Cardie, 2018, 2019). Introduction Persuasion has been shown as a powerful tool for catalyzing beneficial social and political changes (Hovland et al., 1953) or enforcing propaganda as a tool of warfare (Finch, 2000). Modeling persuasiveness of text has received much recent attention in the language community (Althoff et al., 2014; Tan et al., 2016; Habernal and Gurevych, 2017; Yang et al., 2019; Srinivasan et al., 2019). Numerous qualitative studies have been conducted to understand persuasion, from explorations of rhetoric in presidential campaigns (Bartels, 2006; Popkin and Popkin, 1994) to the impact of a communicator’s likability on persuasiveness (Chaiken, 1980). Studies of persuasion and argumentation that have analyzed textual level features (e.g., n-grams, independent rhetorical strategies) to gauge efficacy have also garnered recent attention (Althoff et al., 2014; Habernal and Gurevych, 2017, 2016b,a; Yang and Kraut, 2017; Yang et al., 2019). Of particular interest is Mori"
2020.findings-emnlp.212,W18-6509,0,0.0191548,"ovements on two benchmark sentiment style transfer datasets. 1 I flippin’ LOVE that movie, sweeeet! I truly enjoy that movie. we was hanging out a little. We were spending a small amount of time together. Table 1: Examples of (formal, informal) sentence pairs. Introduction Text style transfer is the task of changing the style of a sentence while preserving the content. It has many useful applications, such as changing emotion of a sentence, removing biases in natural language, and increasing politeness in text (Sennrich et al., 2016; Pryzant et al.; Rabinovich et al., 2017; Yang et al., 2019; Chen et al., 2018). There is a wide availability of “informal” data from online sources, yet current Natural Language Processing (NLP) tasks and models could not leverage or achieve good performance for such data due to informal expressions, and grammatical, spelling and semantic errors. Hence, formality style transfer, a specific style transfer task that aims to preserve the content of an informal sentence while making it semantically and grammatically correct, has recently received a growing amount of attention. Some examples are given in Table 1. The most widely-used models for formality style transfer are b"
2020.findings-emnlp.212,W17-4902,0,0.0151593,"ewhat Comprehensible, 2: Incomprehensible, 1: Incomplete. Baselines and Model Variants • NMT Multi-Task (Niu et al., 2018): Solves two tasks: monolingual formality transfer and formality-sensitive machine translation jointly using multi-task learning. • Pretrained w/ Rules (Wang et al., 2019): Uses a pre-trained OpenAI GPT-2 model and a combination of original and rule-based processed sentences to train the model. The performances for these works were taken from the respective papers. We also introduced several variants of our model for comparison: 2344 Model SimpleCopy Target Rule-based NMT (Jhamtani et al., 2017) Transformer (Vaswani et al., 2017) Hybrid Annotations (Xu et al., 2019)* NMT Multi-task (Niu et al., 2018) Pretrained w/ Rules (Wang et al., 2019) Dual Reinforcement** (Luo et al., 2019) Ours Base w/ CNN discriminator* w/ LM discriminator* w/ LM* + MMI Ours* BLEU 50.28 99.99 60.37 68.41 67.97 69.63 72.13 72.70 74.66 75.04 75.65 76.19 76.52 Content 5.54 5.22 5.38 4.93 5.33 5.35 E&M Fluency 4.79 4.62 4.51 4.33 4.69 4.81 Formality 2.31 1.97 1.67 1.82 2.30 2.38 BLEU 51.66 100.00 66.40 74.22 74.20 74.43 75.37 76.87 41.9 78.89 79.05 79.50 79.92 80.29 Content 5.54 5.29 5.64 5.06 5.35 5.42 F&R Fluenc"
2020.findings-emnlp.212,D19-1306,0,0.0373534,"Missing"
2020.findings-emnlp.212,D19-1366,0,0.0387294,"Missing"
2020.findings-emnlp.212,N16-1082,0,0.152325,"e 1: Model architecture. Here (x, y) ∈ D is a (source, target) style sentence pair with same content, and S and T are source and target styles respectively. The parameters for encoder and decoder are shared across forward and backward style transfer directions. The red arrow corresponds to the cyclic reconstruction loss. Cyclic and discriminator losses are trained on x ∈ U , unsupervised class-labeled data. trained by maximizing P (y|x), where (x, y) is a (informal, formal) sentence pair. Such models tend to generate trivial outputs, often involving highfrequency phrases in the target domain (Li et al., 2016b). Building on prior work, to introduce more diversity and connections between the input and output, we propose to maximize mutual information (MMI) between source and target styles, which take into account not only the dependency of output on input, but also the likelihood that the input corresponds to the output. While this has only been done at test-time so far, we extend this approach to train our model with MMI objective. We evaluate our proposed models that incorporate both the language model discriminators and mutual information maximization on Grammarly Yahoo Answers Corpus (GYAFC) Da"
2020.findings-emnlp.212,N16-1014,0,0.540292,"e 1: Model architecture. Here (x, y) ∈ D is a (source, target) style sentence pair with same content, and S and T are source and target styles respectively. The parameters for encoder and decoder are shared across forward and backward style transfer directions. The red arrow corresponds to the cyclic reconstruction loss. Cyclic and discriminator losses are trained on x ∈ U , unsupervised class-labeled data. trained by maximizing P (y|x), where (x, y) is a (informal, formal) sentence pair. Such models tend to generate trivial outputs, often involving highfrequency phrases in the target domain (Li et al., 2016b). Building on prior work, to introduce more diversity and connections between the input and output, we propose to maximize mutual information (MMI) between source and target styles, which take into account not only the dependency of output on input, but also the likelihood that the input corresponds to the output. While this has only been done at test-time so far, we extend this approach to train our model with MMI objective. We evaluate our proposed models that incorporate both the language model discriminators and mutual information maximization on Grammarly Yahoo Answers Corpus (GYAFC) Da"
2020.findings-emnlp.212,N18-1169,0,0.0443379,"Missing"
2020.findings-emnlp.212,P04-1077,0,0.0638594,"****. She is a clay. She is a cray ****. She is not very nice. Also, she is a mentally unstable woman. So far i haven’t heard that shes come back here (Arkansas)? I have not heard that she is in Arkansas. So far, I have not heard that she is coming back here(Arkansas). So far I have not heard that she has returned to Arkansas. So far I have not heard that she returned to Arkansas. Table 4: Some sample outputs from various models. Niu et al. (2018). We notice that BLEU does not necessarily correlate well with improved fluency, which is consistent with previous studies (Rao and Tetreault, 2018; Lin and Och, 2004). Many fluent sentences did not capture the meaning of the sentence well, which reduces BLEU. Conversely, it is possible to have high intersection with the gold label sentence but still not be fluent. Some qualitative results from our bestperforming model (by BLEU score in Table 3), Xu et al. (2019), Wang et al. (2019) and target sentences, are provided in Table 4. We observed that our model consistently generates better translations compared to the previous methods, especially in terms of dealing with proper nouns, informal phrases and grammatical mistakes. 4.6 Testing on Unsupervised data We"
2020.findings-emnlp.212,W02-0109,0,0.146885,"Missing"
2020.findings-emnlp.212,N18-1012,0,0.478733,"lding on prior work, to introduce more diversity and connections between the input and output, we propose to maximize mutual information (MMI) between source and target styles, which take into account not only the dependency of output on input, but also the likelihood that the input corresponds to the output. While this has only been done at test-time so far, we extend this approach to train our model with MMI objective. We evaluate our proposed models that incorporate both the language model discriminators and mutual information maximization on Grammarly Yahoo Answers Corpus (GYAFC) Dataset (Rao and Tetreault, 2018). Experiments showed that our simple semi-supervised formality style transfer model outperformed state-ofthe-art methods significantly, in terms of both automatic metrics (BLEU) and human evaluation. We further show that our approach can be used for unsupervised style transfer, as demonstrated by significant improvements over baselines on two sentiment style benchmarks: Yelp and Amazon Sentiment Transfer Corpus, where parallel data is not available. We have publicly released our code at https://github.com/ GT-SALT/FormalityStyleTransfer. 2 Related Works Sequence-to-Sequence Models Text style t"
2020.findings-emnlp.212,K16-1028,0,0.0709037,"Missing"
2020.findings-emnlp.212,C18-1086,0,0.271469,"Missing"
2020.findings-emnlp.212,N19-4009,0,0.0291903,"annotated informal and formal data. The detailed process of the data collection is given in the Appendix. The statistics of datasets are in Table 2. 4.2 (6) Train 52595 51967 214K 211K 270K 180K 277K 278K Pre-processing and Experiment Setup The text was pre-processed with Byte Pair Encoding(BPE) (Shibata et al., 1999) with a vocabulary size of 50,000. For pre-training, we trained the LM Discriminator with the unsupervised data with cross entropy loss. For training, we merged both datasets of GYAFC and used the training objective as described in Section 3.4 to train the model. We used Fairseq (Ott et al., 2019) library built on top of PyTorch (Paszke et al., 2019) to run our experiments. We used BART-large (Lewis et al., 2019) model pretrained on CNN-DM summarization data (Nallapati et al., 2016) for our base encoder and decoder. BART was chosen because of its bidirectional encoder which uses words from both left and right for training, as well as superior performance on text generation tasks. Its training objective of reconstruction from noisy text data fits our task well. We chose the model pre-trained on CNN-DM dataset because of the relevance of the decoder pre-trained on formal words to our tas"
2020.findings-emnlp.212,P02-1040,0,0.109258,"Missing"
2020.findings-emnlp.212,N16-1005,0,0.0309354,"d our model to unsupervised text style transfer task, and achieved significant improvements on two benchmark sentiment style transfer datasets. 1 I flippin’ LOVE that movie, sweeeet! I truly enjoy that movie. we was hanging out a little. We were spending a small amount of time together. Table 1: Examples of (formal, informal) sentence pairs. Introduction Text style transfer is the task of changing the style of a sentence while preserving the content. It has many useful applications, such as changing emotion of a sentence, removing biases in natural language, and increasing politeness in text (Sennrich et al., 2016; Pryzant et al.; Rabinovich et al., 2017; Yang et al., 2019; Chen et al., 2018). There is a wide availability of “informal” data from online sources, yet current Natural Language Processing (NLP) tasks and models could not leverage or achieve good performance for such data due to informal expressions, and grammatical, spelling and semantic errors. Hence, formality style transfer, a specific style transfer task that aims to preserve the content of an informal sentence while making it semantically and grammatically correct, has recently received a growing amount of attention. Some examples are"
2020.findings-emnlp.212,D19-1499,0,0.0727481,"Missing"
2020.findings-emnlp.212,D19-1365,0,0.124957,"Zhu et al., 2017) and text style transfer (Shang et al., 2019b; Luo et al., 2019; Logeswaran et al., 2018) to improve performance. Motivated by these work, we use language models for our discriminator, and maximize cyclic reconstruction likelihood as part of our training objective. Formality Style Transfer Grammarly (Rao and Tetreault, 2018) released a large-scale dataset for Formality Style Transfer, and tested several rulebased and deep neural networks-based baselines. CNN-based discriminators and cyclic reconstruction objective have been used (Xu et al., 2019) in a semi-supervised setting. Wang et al. (2019) used a combination of original and rule-based processed sentences to train the model. There is also evidence that using multi-task learning (Niu et al., 2018) and models pretrained on a large scale corpus (Wang et al., 2019) improve performance. This work uses a BART model (Lewis et al., 2019) pretrained on CNN-DM dataset (Nallapati et al., 2016) for our base architecture. 3 3.2 Language Model Discriminator We add a Language model(LM) based discriminator to the model. It functions as a binary classifier which scores the formality of the output generated by the decoder. It includes two languag"
2020.findings-emnlp.212,C12-1177,0,0.0284528,"bjective. Sentiment Transfer corpus (Li et al., 2018) from Yelp and Amazon was used for evaluation. The statistics are given in Table 2. The corpora include separate negative and positive sentiment data without parallel data. We followed the evaluation protocol and baselines from Li et al. (2018). In addition to BLEU, we used two additional metrics for evaluation: (1) Accuracy: The percentage of sentences successfully translated into positive, as measured by a separate pre-trained classifier. (2) G-Score: The geometric Mean of accuracy and BLEU scores. We rank our models by G-Score, following Xu et al. (2012), since there is a trade-off between accuracy and BLEU, as changing more words can get better accuracy but lower content preservation. We used the script and sentiment classifier from Li et al. (2018) to evaluate our outputs. Results were averaged for the two directions: positive-tonegative sentiment transfer and negative-to-positive sentiment transfer, with 500 sentences in the test set for each direction. We compared our results with previous state-ofthe-art approaches. Style Embedding and Multi Decoding (Fu et al., 2018) learn an embedding of the source sentence such that a decoder can use"
2020.findings-emnlp.212,N19-1364,1,0.814462,"ed significant improvements on two benchmark sentiment style transfer datasets. 1 I flippin’ LOVE that movie, sweeeet! I truly enjoy that movie. we was hanging out a little. We were spending a small amount of time together. Table 1: Examples of (formal, informal) sentence pairs. Introduction Text style transfer is the task of changing the style of a sentence while preserving the content. It has many useful applications, such as changing emotion of a sentence, removing biases in natural language, and increasing politeness in text (Sennrich et al., 2016; Pryzant et al.; Rabinovich et al., 2017; Yang et al., 2019; Chen et al., 2018). There is a wide availability of “informal” data from online sources, yet current Natural Language Processing (NLP) tasks and models could not leverage or achieve good performance for such data due to informal expressions, and grammatical, spelling and semantic errors. Hence, formality style transfer, a specific style transfer task that aims to preserve the content of an informal sentence while making it semantically and grammatically correct, has recently received a growing amount of attention. Some examples are given in Table 1. The most widely-used models for formality"
2021.acl-long.338,2020.acl-main.676,0,0.224047,"ious patterns (Tu et al., 2020; Kaushik et al., 2020), making them less generalizable to outof-domain distributions (Zhu et al., 2019; Jiang et al., 2019; Aghajanyan et al., 2020). In order to improve the generalization abilities of over-parameterized models with limited amount of task-specific data, various regularization approaches have been proposed, such as adversarial training that injects label-preserving perturbations in the input space (Zhu et al., 2019; Liu et al., 2020; Jiang et al., 2019), generating augmented data via carefully-designed rules (McCoy et al., 2019; Xie et al., 2020; Andreas, 2020; Shen et al., 2020), and annotating counterfactual examples (Goyal et al., 2019; Kaushik et al., 2020). Despite substantial improvements, these methods often require significant computational and memory overhead (Zhu et al., 2019; Liu et al., 2020; Jiang et al., 2019; Xie et al., 2020) or human annotations (Goyal et al., 2019; Kaushik et al., 2020). In this work, to alleviate the above issues, we rethink the simple and commonly-used regularization technique—dropout (Srivastava et al., 2014)— in pre-trained transformer models (Vaswani et al., 2017). With multiple self-attention heads in transf"
2021.acl-long.338,2020.acl-main.194,1,0.813868,"extra computations as the designed perturbations can be directly derived from self-attentions. 2.2 Data Augmentation Another line of work to improve the model robustness is to directly design data augmentation methods to enrich the original training set such as creating syntactically-rich examples (McCoy et al., 2019; Min et al., 2020) with specific rules, crowdsourcing counterfactual augmentation to avoid learning spurious features (Goyal et al., 2019; Kaushik et al., 2020), or combining examples in the dataset to increase compositional generalizabilities (Jia and Liang, 2016; Andreas, 2020; Chen et al., 2020b,a). However, they either require careful design (McCoy et al., 2019; Andreas, 2020) to infer labels for generated data or extensive human annotations (Goyal et al., 2019; Kaushik et al., 2020), 4381 which makes them hard to generalize to different tasks/datasets. Recently Shen et al. (2020) introduce a set of cutoff augmentation which directly creates partial views to augment the training in a more task-agnostic way. Inspired by these prior work, our HiddenCut aims at improving models’ generalization abilities to out-of-distribution via linguistic-informed strategically dropping spans of hid"
2021.acl-long.338,D18-1217,0,0.0293562,"he set of tokens to be cut based on the rankings of the absolute values of gradients they received at every layer in the backward-passing. This set would be updated during training. 3.3 Objectives During training, for an input text sequence s with a label y, we generate N augmented examples HiddenCut (s)} through perform{f1HiddenCut (s), ..., fN ing HiddenCut in pre-trained encoder f (·). The whole model g(f (·)) is then trained though several objectives including general classification loss (Lori and Laug ) on data-label pairs and consistency regularization (Ljs ) (Miyato et al., 2017, 2018; Clark et al., 2018; Xie et al., 2019; Shen et al., 2020) across different augmentations: Lori = CE(g(f (s)), y) X Laug = CE(g(fiHiddenCut (s)), y) N Ljs = X KL[p(y|g(fiHiddenCut (s))||pavg ] N where CE and KL represent the cross-entropy loss and KL-divergence respectively. pavg stands for the average predictions across the original text and all the augmented examples. Combining these three losses, our overall objective function is: (MRPC) which predict whether two given sentences are semantically equivalent; inference tasks including (i) Multi-Genre Natural Language Inference (MNLI) which classified the relatio"
2021.acl-long.338,2020.emnlp-main.398,0,0.158569,"ing state-of-the-art performances in a wide range of natural language processing tasks (Devlin et al., 2019; Liu et al., 2019; Yang et al., 2019a; Joshi et al., 2019; Sun et al., 2019; Clark et al., 2019; Lewis et al., 2020; Bao et al., 2020; He et al., 2020; Raffel et al., 2020). Despite the great success, due to the huge gap between the number of model parameters and that of task-specific data available, the majority of the information within the multi-layer self-attention networks is typically redundant and ineffectively utilized for downstream tasks (Guo et al., 2020; Gordon et al., 2020; Dalvi et al., 2020). As a result, after task-specific fine-tuning, models are very likely to overfit and make predictions based on spurious patterns (Tu et al., 2020; Kaushik et al., 2020), making them less generalizable to outof-domain distributions (Zhu et al., 2019; Jiang et al., 2019; Aghajanyan et al., 2020). In order to improve the generalization abilities of over-parameterized models with limited amount of task-specific data, various regularization approaches have been proposed, such as adversarial training that injects label-preserving perturbations in the input space (Zhu et al., 2019; Liu et al., 2020;"
2021.acl-long.338,N19-1423,0,0.194433,"strategically dropped during training. Experiments show that our HiddenCut method outperforms the state-of-the-art augmentation methods on the GLUE benchmark, and consistently exhibits superior generalization performances on out-of-distribution and challenging counterexamples. We have publicly released our code at https://github.com/ GT-SALT/HiddenCut. 1 Introduction Fine-tuning large-scale pre-trained language models (PLMs) has become a dominant paradigm in the natural language processing community, achieving state-of-the-art performances in a wide range of natural language processing tasks (Devlin et al., 2019; Liu et al., 2019; Yang et al., 2019a; Joshi et al., 2019; Sun et al., 2019; Clark et al., 2019; Lewis et al., 2020; Bao et al., 2020; He et al., 2020; Raffel et al., 2020). Despite the great success, due to the huge gap between the number of model parameters and that of task-specific data available, the majority of the information within the multi-layer self-attention networks is typically redundant and ineffectively utilized for downstream tasks (Guo et al., 2020; Gordon et al., 2020; Dalvi et al., 2020). As a result, after task-specific fine-tuning, models are very likely to overfit and ma"
2021.acl-long.338,D15-1075,0,0.0465881,"5 89.2 87.8 90.4 Similarity&Paraphrase PAWS-QQP 38.4 38.8 41.5 HANS 67.8 68.4 71.2 Inference AdvNLI (A1) 31.2 31.1 32.8 Table 2: Out-of-distribution evaluation results on 5 different challenging sets. † means our proposed method. For all the datasets, we did not use their training sets to further fine-tune the derived models from GLUE. non-entailment examples with high premisehypothesis overlap from MNLI. The latter one was created by adversarial human-and-modelin-the-loop framework (Nie et al., 2020) to create hard examples based on BERT-Large models(Devlin et al., 2019) pre-trained on SNLI (Bowman et al., 2015) and MNLI. 4.2 Baselines max number of training epochs was set to be either 5 or 10. All these hyper-parameters are shared for all the models. The HiddenCut ratio α was set 0.1 after a grid search from {0.05, 0.1, 0.2, 0.3, 0.4}. The selecting ratio β in the important sets sampling process was set 0.4 after a grid search from {0.1, 0.2, 0.4, 0.6}. The weights γ and η in our objective function were both 1. All the experiments were performed using a GeForce RTX 2080Ti. We compare our methods with several baselines: • RoBERTa (Liu et al., 2019) is used as our base model. Note that RoBERTa is regu"
2021.acl-long.338,2020.emnlp-main.95,1,0.776408,"extra computations as the designed perturbations can be directly derived from self-attentions. 2.2 Data Augmentation Another line of work to improve the model robustness is to directly design data augmentation methods to enrich the original training set such as creating syntactically-rich examples (McCoy et al., 2019; Min et al., 2020) with specific rules, crowdsourcing counterfactual augmentation to avoid learning spurious features (Goyal et al., 2019; Kaushik et al., 2020), or combining examples in the dataset to increase compositional generalizabilities (Jia and Liang, 2016; Andreas, 2020; Chen et al., 2020b,a). However, they either require careful design (McCoy et al., 2019; Andreas, 2020) to infer labels for generated data or extensive human annotations (Goyal et al., 2019; Kaushik et al., 2020), 4381 which makes them hard to generalize to different tasks/datasets. Recently Shen et al. (2020) introduce a set of cutoff augmentation which directly creates partial views to augment the training in a more task-agnostic way. Inspired by these prior work, our HiddenCut aims at improving models’ generalization abilities to out-of-distribution via linguistic-informed strategically dropping spans of hid"
2021.acl-long.338,2020.repl4nlp-1.18,0,0.0192838,"ing community, achieving state-of-the-art performances in a wide range of natural language processing tasks (Devlin et al., 2019; Liu et al., 2019; Yang et al., 2019a; Joshi et al., 2019; Sun et al., 2019; Clark et al., 2019; Lewis et al., 2020; Bao et al., 2020; He et al., 2020; Raffel et al., 2020). Despite the great success, due to the huge gap between the number of model parameters and that of task-specific data available, the majority of the information within the multi-layer self-attention networks is typically redundant and ineffectively utilized for downstream tasks (Guo et al., 2020; Gordon et al., 2020; Dalvi et al., 2020). As a result, after task-specific fine-tuning, models are very likely to overfit and make predictions based on spurious patterns (Tu et al., 2020; Kaushik et al., 2020), making them less generalizable to outof-domain distributions (Zhu et al., 2019; Jiang et al., 2019; Aghajanyan et al., 2020). In order to improve the generalization abilities of over-parameterized models with limited amount of task-specific data, various regularization approaches have been proposed, such as adversarial training that injects label-preserving perturbations in the input space (Zhu et al., 20"
2021.acl-long.338,P16-1002,0,0.0271761,"efficient way that does not require extra computations as the designed perturbations can be directly derived from self-attentions. 2.2 Data Augmentation Another line of work to improve the model robustness is to directly design data augmentation methods to enrich the original training set such as creating syntactically-rich examples (McCoy et al., 2019; Min et al., 2020) with specific rules, crowdsourcing counterfactual augmentation to avoid learning spurious features (Goyal et al., 2019; Kaushik et al., 2020), or combining examples in the dataset to increase compositional generalizabilities (Jia and Liang, 2016; Andreas, 2020; Chen et al., 2020b,a). However, they either require careful design (McCoy et al., 2019; Andreas, 2020) to infer labels for generated data or extensive human annotations (Goyal et al., 2019; Kaushik et al., 2020), 4381 which makes them hard to generalize to different tasks/datasets. Recently Shen et al. (2020) introduce a set of cutoff augmentation which directly creates partial views to augment the training in a more task-agnostic way. Inspired by these prior work, our HiddenCut aims at improving models’ generalization abilities to out-of-distribution via linguistic-informed s"
2021.acl-long.338,2021.ccl-1.108,0,0.0763265,"Missing"
2021.acl-long.338,P11-1015,0,0.0194954,") which predict the similarity ratings between two sentences, and (iii) Microsoft Research Paraphrase Corpus 4384 • Single Sentence Tasks: Models fine-tuned from SST-2 are directly evaluated on two recent challenging sentiment classification datasets: IMDB Contrast Set (Gardner et al., 2020) including 588 examples and IMDB Counterfactually Augmented Dataset (Kaushik et al., 2020) including 733 examples. Both of them were constructed by asking NLP researchers (Gardner et al., 2020) or Amazon Mechanical Turkers (Kaushik et al., 2020) to make minor edits to examples in the original IMDB dataset (Maas et al., 2011) so that the sentiment labels change while the major contents keep the same. • Similarity and Paraphrase Tasks: Models fine-tuned from QQP are directly evaluated on the recently introduced challenging paraphrase dataset PAWS-QQP (Zhang et al., 2019b) that has 669 test cases. PAWS-QQP contains sentence pairs with high word overlap but different semantic meanings created via word-swapping and back-translation from the original QQP dataset. • Inference Tasks: Models fine-tuned from MNLI are directly evaluated on two challenging NLI sets: HANS (McCoy et al., 2019) with 30,000 test cases and Advers"
2021.acl-long.338,P19-1334,0,0.140741,"fit and make predictions based on spurious patterns (Tu et al., 2020; Kaushik et al., 2020), making them less generalizable to outof-domain distributions (Zhu et al., 2019; Jiang et al., 2019; Aghajanyan et al., 2020). In order to improve the generalization abilities of over-parameterized models with limited amount of task-specific data, various regularization approaches have been proposed, such as adversarial training that injects label-preserving perturbations in the input space (Zhu et al., 2019; Liu et al., 2020; Jiang et al., 2019), generating augmented data via carefully-designed rules (McCoy et al., 2019; Xie et al., 2020; Andreas, 2020; Shen et al., 2020), and annotating counterfactual examples (Goyal et al., 2019; Kaushik et al., 2020). Despite substantial improvements, these methods often require significant computational and memory overhead (Zhu et al., 2019; Liu et al., 2020; Jiang et al., 2019; Xie et al., 2020) or human annotations (Goyal et al., 2019; Kaushik et al., 2020). In this work, to alleviate the above issues, we rethink the simple and commonly-used regularization technique—dropout (Srivastava et al., 2014)— in pre-trained transformer models (Vaswani et al., 2017). With multip"
2021.acl-long.338,2020.acl-main.212,0,0.0232024,"e its success, adversarial training often requires extensive computation overhead to calculate the perturbation directions (Shafahi et al., 2019; Zhang et al., 2019a). In contrast, our HiddenCut adds perturbations in the hidden space in a more efficient way that does not require extra computations as the designed perturbations can be directly derived from self-attentions. 2.2 Data Augmentation Another line of work to improve the model robustness is to directly design data augmentation methods to enrich the original training set such as creating syntactically-rich examples (McCoy et al., 2019; Min et al., 2020) with specific rules, crowdsourcing counterfactual augmentation to avoid learning spurious features (Goyal et al., 2019; Kaushik et al., 2020), or combining examples in the dataset to increase compositional generalizabilities (Jia and Liang, 2016; Andreas, 2020; Chen et al., 2020b,a). However, they either require careful design (McCoy et al., 2019; Andreas, 2020) to infer labels for generated data or extensive human annotations (Goyal et al., 2019; Kaushik et al., 2020), 4381 which makes them hard to generalize to different tasks/datasets. Recently Shen et al. (2020) introduce a set of cutoff"
2021.acl-long.338,D19-1445,0,0.0199398,"he feed-forward network in every transformer layer. propose to select the spans to be cut dynamically and strategically in every layer. In other words, we mask the most informative span of hidden representations in one layer to force models to discover other useful clues to make predictions instead of relying on a small set of spurious patterns. ods to find a set of tokens to be strategically cut by HiddenCut, including: Attention-based Sampling Strategy The most direct way is to define the set of tokens to be cut by utilizing attention weights assigned to tokens in the self-attention layers (Kovaleva et al., 2019). Intuitively, we can drop the spans of hidden representations that are assigned high attentions by the transformer layers. As a result, the information redundancy is alleviated and models would be encourage to attend to other important information. Specifically, we first derive the average attention for each token, ai , from the attention weights matrix A ∈ RP ×L×L after self-attention layers, where P is the number of attention heads and L is the sequence length: PP PL j ( k A[j][k][i]) ai = . P We then sample the start token hi for HiddenCut from the set that contains top βL tokens with high"
2021.acl-long.338,2020.acl-main.703,0,0.0281532,"gmentation methods on the GLUE benchmark, and consistently exhibits superior generalization performances on out-of-distribution and challenging counterexamples. We have publicly released our code at https://github.com/ GT-SALT/HiddenCut. 1 Introduction Fine-tuning large-scale pre-trained language models (PLMs) has become a dominant paradigm in the natural language processing community, achieving state-of-the-art performances in a wide range of natural language processing tasks (Devlin et al., 2019; Liu et al., 2019; Yang et al., 2019a; Joshi et al., 2019; Sun et al., 2019; Clark et al., 2019; Lewis et al., 2020; Bao et al., 2020; He et al., 2020; Raffel et al., 2020). Despite the great success, due to the huge gap between the number of model parameters and that of task-specific data available, the majority of the information within the multi-layer self-attention networks is typically redundant and ineffectively utilized for downstream tasks (Guo et al., 2020; Gordon et al., 2020; Dalvi et al., 2020). As a result, after task-specific fine-tuning, models are very likely to overfit and make predictions based on spurious patterns (Tu et al., 2020; Kaushik et al., 2020), making them less generalizable to"
2021.acl-long.338,2020.acl-main.441,0,0.472105,"g methods usually regularize models through applying perturbations to the input or hidden space (Szegedy et al., 2013; Goodfellow et al., 2014; Madry et al., 2017) with additional forward-backward passes, which influence the model’s predictions and confidence without changing human judgements. Adversarial-based approaches have been actively applied to various NLP tasks in order to improve models’ robustness and generalization abilities, such as sentence classification (Miyato et al., 2017), machine reading comprehension (MRC) (Wang and Bansal, 2018) and natural language inference (NLI) tasks (Nie et al., 2020). Despite its success, adversarial training often requires extensive computation overhead to calculate the perturbation directions (Shafahi et al., 2019; Zhang et al., 2019a). In contrast, our HiddenCut adds perturbations in the hidden space in a more efficient way that does not require extra computations as the designed perturbations can be directly derived from self-attentions. 2.2 Data Augmentation Another line of work to improve the model robustness is to directly design data augmentation methods to enrich the original training set such as creating syntactically-rich examples (McCoy et al."
2021.acl-long.338,2020.tacl-1.40,0,0.131466,"hi et al., 2019; Sun et al., 2019; Clark et al., 2019; Lewis et al., 2020; Bao et al., 2020; He et al., 2020; Raffel et al., 2020). Despite the great success, due to the huge gap between the number of model parameters and that of task-specific data available, the majority of the information within the multi-layer self-attention networks is typically redundant and ineffectively utilized for downstream tasks (Guo et al., 2020; Gordon et al., 2020; Dalvi et al., 2020). As a result, after task-specific fine-tuning, models are very likely to overfit and make predictions based on spurious patterns (Tu et al., 2020; Kaushik et al., 2020), making them less generalizable to outof-domain distributions (Zhu et al., 2019; Jiang et al., 2019; Aghajanyan et al., 2020). In order to improve the generalization abilities of over-parameterized models with limited amount of task-specific data, various regularization approaches have been proposed, such as adversarial training that injects label-preserving perturbations in the input space (Zhu et al., 2019; Liu et al., 2020; Jiang et al., 2019), generating augmented data via carefully-designed rules (McCoy et al., 2019; Xie et al., 2020; Andreas, 2020; Shen et al., 20"
2021.acl-long.338,D19-1059,1,0.886006,"Missing"
2021.acl-long.338,N19-1131,0,0.0624908,"Missing"
2021.acl-long.338,W18-5446,0,0.120839,"y introducing an attentionbased mechanism. By performing HiddenCut in the hidden space, the impact of dropped information is only mitigated rather than completely removed, avoiding injecting too much noise to the input. We further apply a Jensen-Shannon Divergence consistency regularization between the original and these augmented examples to model the consistent relations between them. To demonstrate the effectiveness of our methods, we conduct experiments to compare our HiddenCut with previous state-of-the-art data augmentation method on 8 natural language understanding tasks from the GLUE (Wang et al., 2018) benchmark for in-distribution evaluations, and 5 challenging datasets that cover single-sentence tasks, similarity and paraphrase tasks and inference tasks for out-ofdistribution evaluations. We further perform ablation studies to investigate the impact of different selecting strategies on HiddenCut’s effectiveness. Results show that our method consistently outperforms baselines, especially on out-of-distribution and challenging counterexamples. To sum up, our contributions are: • We propose a simple data augmentation method, HiddenCut, to regularize PLMs during fine-tuning by cutting contigu"
2021.acl-long.338,N18-2091,0,0.028534,"tasets. 2 2.1 Related Work Adversarial Training Adversarial training methods usually regularize models through applying perturbations to the input or hidden space (Szegedy et al., 2013; Goodfellow et al., 2014; Madry et al., 2017) with additional forward-backward passes, which influence the model’s predictions and confidence without changing human judgements. Adversarial-based approaches have been actively applied to various NLP tasks in order to improve models’ robustness and generalization abilities, such as sentence classification (Miyato et al., 2017), machine reading comprehension (MRC) (Wang and Bansal, 2018) and natural language inference (NLI) tasks (Nie et al., 2020). Despite its success, adversarial training often requires extensive computation overhead to calculate the perturbation directions (Shafahi et al., 2019; Zhang et al., 2019a). In contrast, our HiddenCut adds perturbations in the hidden space in a more efficient way that does not require extra computations as the designed perturbations can be directly derived from self-attentions. 2.2 Data Augmentation Another line of work to improve the model robustness is to directly design data augmentation methods to enrich the original training"
2021.emnlp-main.29,S19-2007,0,0.0334506,"Missing"
2021.emnlp-main.29,P19-1470,0,0.043091,"Missing"
2021.emnlp-main.29,P19-1357,0,0.0128044,"on systems (Waseem Nunes, 2018; Badjatiya et al., 2017). While prior et al., 2017; Wiegand et al., 2019), and even the efforts have focused extensively on overt abuse most advanced architectures may suffer if they have or explicit hate speech (Schmidt and Wiegand, not been trained on implicitly abusive messages 2017), recent works have started to highlight the (Caselli et al., 2020). diverse range of implicitly hateful messages that The primary challenge for statistical and neuhave previously gone unnoticed by moderators and ral classifiers is the linguistic nuance and diverresearchers alike (Jurgens et al., 2019; Waseem sity of the implicit hate class, which includes indiet al., 2017; Qian et al., 2019). Figure 1 provides rect sarcasm and humor (Waseem and Hovy, 2016; an example from each hate speech type (explicit vs. Fortuna and Nunes, 2018), euphemisms (Magu implicit). and Luo, 2018), circumlocution (Gao and Huang, Implicit hate speech is defined by coded or in2017), and other symbolic or metaphorical landirect language that disparages a person or group guage (Qian et al., 2019). The type of implicit on the basis of protected characteristics like race, hate speech also varies, from dehumanizing co"
2021.emnlp-main.29,N19-1305,1,0.904004,"l., 2019), and even the efforts have focused extensively on overt abuse most advanced architectures may suffer if they have or explicit hate speech (Schmidt and Wiegand, not been trained on implicitly abusive messages 2017), recent works have started to highlight the (Caselli et al., 2020). diverse range of implicitly hateful messages that The primary challenge for statistical and neuhave previously gone unnoticed by moderators and ral classifiers is the linguistic nuance and diverresearchers alike (Jurgens et al., 2019; Waseem sity of the implicit hate class, which includes indiet al., 2017; Qian et al., 2019). Figure 1 provides rect sarcasm and humor (Waseem and Hovy, 2016; an example from each hate speech type (explicit vs. Fortuna and Nunes, 2018), euphemisms (Magu implicit). and Luo, 2018), circumlocution (Gao and Huang, Implicit hate speech is defined by coded or in2017), and other symbolic or metaphorical landirect language that disparages a person or group guage (Qian et al., 2019). The type of implicit on the basis of protected characteristics like race, hate speech also varies, from dehumanizing com? Equal contribution. parisons (Leader Maynard and Benesch, 2016) 345 1 Introduction Proceed"
2021.emnlp-main.29,2021.naacl-main.183,1,0.754226,"h size of 2 and learning rate of 5 × 10−5 with linear warm up tively categorize hate speech and spell out more 352 References fine-grained implicit hate speech and explaining these hateful messages. Additionally, we identified eight challenges in implicit hate speech detection: coded hate symbols, discourse relations, entity framing, commonsense, metaphorical language, colloquial speech, irony, and identity term bias. To mitigate these challenges, future work could explore deciphering models for coded language (Kambhatla et al., 2018; Qian et al., 2019), lifelong learning of hateful language (Qian et al., 2021), contextualized sarcasm detection, and bias mitigation for named entities in hate speech detection systems (Xia et al., 2020) and their connection with our dataset. We demonstrate that our corpus can serve as a useful research benchmark for understanding implicit hate speech online. Our work also has implications towards the emerging directions of countering online hate speech (Citron and Norton, 2011; Mathew et al., 2019), detecting online radicalization (Ferrara et al., 2016) and modeling societal systematic racism, prejudicial expressions, and biases (Davidson et al., 2019; Manzini et al.,"
2021.emnlp-main.29,L18-1443,0,0.1583,"2017), and other symbolic or metaphorical landirect language that disparages a person or group guage (Qian et al., 2019). The type of implicit on the basis of protected characteristics like race, hate speech also varies, from dehumanizing com? Equal contribution. parisons (Leader Maynard and Benesch, 2016) 345 1 Introduction Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 345–363 c November 7–11, 2021. 2021 Association for Computational Linguistics and stereotypes (Warner and Hirschberg, 2012), to threats, intimidation, and incitement to violence (Sanguinetti et al., 2018; Fortuna and Nunes, 2018). Importantly, the field lacks a theoreticallygrounded framework and a large-scale dataset to help inform a more empirical understanding of implicit hate in all of its diverse manifestations. To fill this gap, we establish new resources to sustain research and facilitate both fine-grained classification and generative intervention strategies. Specifically, we develop a 6-class taxonomy of implicit hate speech that is grounded in the social science literature. We use this taxonomy to annotate a new Twitter dataset with broad coverage of the most prevalent hate groups i"
2021.emnlp-main.29,P19-1163,0,0.0575058,"Missing"
2021.emnlp-main.29,2020.acl-main.486,0,0.0122977,"ion Extreme class imbalance may challenge implicit hate classifiers. To address this disparity, we expand the minority classes, both with bootstrapping and out-of-domain samples. For bootstrapping, we trained a 6-way BERT classifier on the 4,153 implicit hate labels in the manner of Section 5.1 and ran it on 364,300 unlabeled tweets from our corpus. Then we randomly sampled 1,800 tweets for each of the three minority classes according to the classifications inferiority, irony, and threatening. Finally, we augmented this expansion with out-of-domain (OOD) samples from Kennedy et al. (2018) and Sap et al. (2020). By drawing both from OOD and bootstrapped in-domain samples, we sought to balance two key limitations: (1) bootstrapped samples may be inherently easier, while (2) OOD samples contain artifacts that allow models to benefit from spurious correlations. Our expert annotators labeled this data, and by adding the minority labels from this process, we improved the class balance for a total of 6,346 implicit tweets shown in the # Tweets Post Expn. column of Table 2. 4.2.4 Hate Targets and Implied Statement For each of the 6,346 implicit hate tweets, two separate annotators provided us with the mess"
2021.emnlp-main.29,W17-1101,0,0.0377639,"Missing"
2021.emnlp-main.29,2020.emnlp-main.425,0,0.0674491,"Missing"
2021.emnlp-main.29,W12-2103,0,0.314439,"2018), circumlocution (Gao and Huang, Implicit hate speech is defined by coded or in2017), and other symbolic or metaphorical landirect language that disparages a person or group guage (Qian et al., 2019). The type of implicit on the basis of protected characteristics like race, hate speech also varies, from dehumanizing com? Equal contribution. parisons (Leader Maynard and Benesch, 2016) 345 1 Introduction Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 345–363 c November 7–11, 2021. 2021 Association for Computational Linguistics and stereotypes (Warner and Hirschberg, 2012), to threats, intimidation, and incitement to violence (Sanguinetti et al., 2018; Fortuna and Nunes, 2018). Importantly, the field lacks a theoreticallygrounded framework and a large-scale dataset to help inform a more empirical understanding of implicit hate in all of its diverse manifestations. To fill this gap, we establish new resources to sustain research and facilitate both fine-grained classification and generative intervention strategies. Specifically, we develop a 6-class taxonomy of implicit hate speech that is grounded in the social science literature. We use this taxonomy to annota"
2021.emnlp-main.29,W17-3012,0,0.0128228,"inequality (Sue, 2010). Similar to Breitfeller et al. (2019), we provide a representative and domain-general typology and dataset, but ours are more representative of active hate groups in the United States, and our definitions extend to intentionally veiled acts of intimidation, threats, and abuse. 3 Taxonomy of Implicit Hate Speech Implicit hate speech is a subclass of hate speech defined by the use of coded or indirect language such as sarcasm, metaphor and circumlocution to disparage a protected group or individual, or to convey prejudicial and harmful views about them (Gao et al., 2017; Waseem et al., 2017). The NLP community has not yet confronted, in a consistent and unified manner, the multiplicity of subtle chal1 lenges that implicit hate presents for online comWe use the swear word list from https://bit.ly/2SQySZv, excluding ambiguous terms like bloody, prick, etc. munities. To this end, we introduce a new typology 346 Work Source Domain / Scope Basile et al. (2019) Twitter Burnap and Williams (2014) Davidson et al. (2017) Djuric et al. (2015) Twitter Misogynistic, anti-immigrant Lee Rigby murder Twitter Yahoo Finance Twitter Fox News Comments Stormfront Gab Compilation Yahoo + Web Twitter"
2021.emnlp-main.29,N16-2013,0,0.170451,"ert abuse most advanced architectures may suffer if they have or explicit hate speech (Schmidt and Wiegand, not been trained on implicitly abusive messages 2017), recent works have started to highlight the (Caselli et al., 2020). diverse range of implicitly hateful messages that The primary challenge for statistical and neuhave previously gone unnoticed by moderators and ral classifiers is the linguistic nuance and diverresearchers alike (Jurgens et al., 2019; Waseem sity of the implicit hate class, which includes indiet al., 2017; Qian et al., 2019). Figure 1 provides rect sarcasm and humor (Waseem and Hovy, 2016; an example from each hate speech type (explicit vs. Fortuna and Nunes, 2018), euphemisms (Magu implicit). and Luo, 2018), circumlocution (Gao and Huang, Implicit hate speech is defined by coded or in2017), and other symbolic or metaphorical landirect language that disparages a person or group guage (Qian et al., 2019). The type of implicit on the basis of protected characteristics like race, hate speech also varies, from dehumanizing com? Equal contribution. parisons (Leader Maynard and Benesch, 2016) 345 1 Introduction Proceedings of the 2021 Conference on Empirical Methods in Natural Langu"
2021.emnlp-main.29,N19-1060,0,0.0168241,"ize acts of aggression (Gubler and Kalmoe, Hate speech is pervasive in social media. Platforms 2015) and domestic terrorism (Piazza, 2020) while have responded by banning hate groups and flag- also maintaining plausible deniability for their acging abusive text (Klepper, 2020), and the research tions (Dénigot and Burnett, 2020). Because this community has developed increasingly competi- speech lacks clear lexical signals, hate groups can tive hate speech detection systems (Fortuna and evade keyword-based detection systems (Waseem Nunes, 2018; Badjatiya et al., 2017). While prior et al., 2017; Wiegand et al., 2019), and even the efforts have focused extensively on overt abuse most advanced architectures may suffer if they have or explicit hate speech (Schmidt and Wiegand, not been trained on implicitly abusive messages 2017), recent works have started to highlight the (Caselli et al., 2020). diverse range of implicitly hateful messages that The primary challenge for statistical and neuhave previously gone unnoticed by moderators and ral classifiers is the linguistic nuance and diverresearchers alike (Jurgens et al., 2019; Waseem sity of the implicit hate class, which includes indiet al., 2017; Qian et a"
2021.emnlp-main.29,2020.socialnlp-1.2,0,0.0125752,"ine-grained implicit hate speech and explaining these hateful messages. Additionally, we identified eight challenges in implicit hate speech detection: coded hate symbols, discourse relations, entity framing, commonsense, metaphorical language, colloquial speech, irony, and identity term bias. To mitigate these challenges, future work could explore deciphering models for coded language (Kambhatla et al., 2018; Qian et al., 2019), lifelong learning of hateful language (Qian et al., 2021), contextualized sarcasm detection, and bias mitigation for named entities in hate speech detection systems (Xia et al., 2020) and their connection with our dataset. We demonstrate that our corpus can serve as a useful research benchmark for understanding implicit hate speech online. Our work also has implications towards the emerging directions of countering online hate speech (Citron and Norton, 2011; Mathew et al., 2019), detecting online radicalization (Ferrara et al., 2016) and modeling societal systematic racism, prejudicial expressions, and biases (Davidson et al., 2019; Manzini et al., 2019; Blodgett et al., 2020). Ethical Considerations UN General Assembly. 1966. International covenant on civil and political"
2021.emnlp-main.29,N19-1144,0,0.0331735,"Missing"
2021.emnlp-main.530,2020.emnlp-main.95,1,0.877171,"/insertion (Wei and Zou, 2019; to substitute utterances with their paraphrases Feng et al., 2020a), token/span cutoff (Shen et al., generated based on the conversation context. 2020b); (2) paraphrasing the entire input text at To further utilize unlabeled conversations, we the sentence-level through round-trip translation combine CODA with two-stage noisy self(Sennrich et al., 2015; Xie et al., 2019; Chen training where we first pre-train the sumet al., 2020b) or syntactic manipulation (Iyyer et al., marization model on unlabeled conversations with pseudo summaries and then fine-tune it 2018; Chen et al., 2020c); and (3) adding adversaron labeled conversations. Experiments conial perturbations to the original data which dramatducted on the recent conversation summarizaically influences the model’s predictions (Jia and tion datasets demonstrate the effectiveness of Liang, 2017; Niu and Bansal, 2019; Zhang et al., our methods over several state-of-the-art data 2019). Despite the huge success, the former two augmentation baselines. We have publicly remainly perturbs sentences locally while ignoring leased our code at https://github.com/ the diverse structures and context information in GT-SALT/CODA. d"
2021.emnlp-main.530,2020.emnlp-main.336,1,0.887749,"input. esting problems in text summarization. Recently, To this end, we introduce simple and novel set neural abstractive conversation summarization has of Conversational Data Augmentation (CODA) received growing attention and achieved remark- techniques for conversation summarization guided able performances by adapting document summa- by conversation structures and context, including: rization pre-trained models and (Gliwa et al., 2019; (1) random swapping/deletion randomly swap or Yu et al., 2021) and incorporating structural infor- delete utterances in conversations to perturb the mation (Chen and Yang, 2020; Feng et al., 2020c; discourse relations, (2) dialogue-acts-guided inZhu et al., 2020a; Chen and Yang, 2021; Liu et al., sertion randomly insert utterances based on the 6605 Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 6605–6616 c November 7–11, 2021. 2021 Association for Computational Linguistics Figure 1: Examples of utilizing different CODA strategies to augment the given conversation including (1) random Swapping/Deletion where last two utterances are swapped (top), (2) dialogue-acts-based Insertion where a backchannel utterance is inserted"
2021.emnlp-main.530,2021.naacl-main.109,1,0.891192,"l abstractive conversation summarization has of Conversational Data Augmentation (CODA) received growing attention and achieved remark- techniques for conversation summarization guided able performances by adapting document summa- by conversation structures and context, including: rization pre-trained models and (Gliwa et al., 2019; (1) random swapping/deletion randomly swap or Yu et al., 2021) and incorporating structural infor- delete utterances in conversations to perturb the mation (Chen and Yang, 2020; Feng et al., 2020c; discourse relations, (2) dialogue-acts-guided inZhu et al., 2020a; Chen and Yang, 2021; Liu et al., sertion randomly insert utterances based on the 6605 Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 6605–6616 c November 7–11, 2021. 2021 Association for Computational Linguistics Figure 1: Examples of utilizing different CODA strategies to augment the given conversation including (1) random Swapping/Deletion where last two utterances are swapped (top), (2) dialogue-acts-based Insertion where a backchannel utterance is inserted after the first utterance (middle), and (3) conditional-generation-based substitution where the first utter"
2021.emnlp-main.530,2020.acl-main.194,1,0.74314,"/insertion (Wei and Zou, 2019; to substitute utterances with their paraphrases Feng et al., 2020a), token/span cutoff (Shen et al., generated based on the conversation context. 2020b); (2) paraphrasing the entire input text at To further utilize unlabeled conversations, we the sentence-level through round-trip translation combine CODA with two-stage noisy self(Sennrich et al., 2015; Xie et al., 2019; Chen training where we first pre-train the sumet al., 2020b) or syntactic manipulation (Iyyer et al., marization model on unlabeled conversations with pseudo summaries and then fine-tune it 2018; Chen et al., 2020c); and (3) adding adversaron labeled conversations. Experiments conial perturbations to the original data which dramatducted on the recent conversation summarizaically influences the model’s predictions (Jia and tion datasets demonstrate the effectiveness of Liang, 2017; Niu and Bansal, 2019; Zhang et al., our methods over several state-of-the-art data 2019). Despite the huge success, the former two augmentation baselines. We have publicly remainly perturbs sentences locally while ignoring leased our code at https://github.com/ the diverse structures and context information in GT-SALT/CODA. d"
2021.emnlp-main.530,D18-1020,0,0.028415,"models by using large amounts of unlabeled Random Swapping or Deletion Utterances data (Chapelle et al., 2009; Gururangan et al., 2019; from different speakers in conversations usually Chen et al., 2021). Unlabeled data is usually incor- follow Gricean Maxims (Dale and Reiter, 1995) porated through consistency training (Xie et al., to achieve effective communication in social situ2019; Chen et al., 2020b,a), co-training (Clark ations, which requires utterances to be related to et al., 2018), variational auto encoders (Gururangan each other orderly under the context of discourse et al., 2019; Chen et al., 2018; Yang et al., 2017) (Murray et al., 2006; Qin et al., 2017). From the or self-training (Scudder, 1965; Riloff and Wiebe, perspective of perturbing discourse relations to cre2003; Xie et al., 2020). In this work, we focus on ate augmented conversations (Gui et al., 2021), self-training, one of the most classic “pseudo-label” we introduce two simple operations to perturb the semi-supervised learning approaches (Yarowsky, discourse relations: (1) random swapping, which 1995; Riloff and Wiebe, 2003). Self-training often breaks the discourse relations by randomly swapiteratively incorporates unlab"
2021.emnlp-main.530,D18-1217,0,0.0196459,"Missing"
2021.emnlp-main.530,D18-1045,0,0.0721975,"Missing"
2021.emnlp-main.530,2020.deelio-1.4,0,0.534977,"o alleviate the need of labeled data in various supervised abstractive conversation summaNLP tasks, and can be categorized into three marization, such as random swapping/deletion jor classes: (1) manipulating words and phrases to perturb the discourse relations inside conversations, dialogue-acts-guided insertion to at the token-level like designed word replacement interrupt the development of conversations, (Kobayashi, 2018; Niu and Bansal, 2018), word and conditional-generation-based substitution deletion/swapping/insertion (Wei and Zou, 2019; to substitute utterances with their paraphrases Feng et al., 2020a), token/span cutoff (Shen et al., generated based on the conversation context. 2020b); (2) paraphrasing the entire input text at To further utilize unlabeled conversations, we the sentence-level through round-trip translation combine CODA with two-stage noisy self(Sennrich et al., 2015; Xie et al., 2019; Chen training where we first pre-train the sumet al., 2020b) or syntactic manipulation (Iyyer et al., marization model on unlabeled conversations with pseudo summaries and then fine-tune it 2018; Chen et al., 2020c); and (3) adding adversaron labeled conversations. Experiments conial perturb"
2021.emnlp-main.530,D19-5409,0,0.337151,"et al., 2019; ural text (Murray et al., 2006; Wang and Cardie, Zhu et al., 2019), especially for summarization 2013), is one of the most challenging and inter- tasks with long input. esting problems in text summarization. Recently, To this end, we introduce simple and novel set neural abstractive conversation summarization has of Conversational Data Augmentation (CODA) received growing attention and achieved remark- techniques for conversation summarization guided able performances by adapting document summa- by conversation structures and context, including: rization pre-trained models and (Gliwa et al., 2019; (1) random swapping/deletion randomly swap or Yu et al., 2021) and incorporating structural infor- delete utterances in conversations to perturb the mation (Chen and Yang, 2020; Feng et al., 2020c; discourse relations, (2) dialogue-acts-guided inZhu et al., 2020a; Chen and Yang, 2021; Liu et al., sertion randomly insert utterances based on the 6605 Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 6605–6616 c November 7–11, 2021. 2021 Association for Computational Linguistics Figure 1: Examples of utilizing different CODA strategies to augment the"
2021.emnlp-main.530,P19-1590,0,0.025777,"under the self-training framework to utilize unlabeled conversations for semi-supervised conversation summarization (Section 3.2). 3.1 CODA For a given conversation c = {u0 , ..., un } with n utterances, CODA random performs one of the conversational perturbations described below to generate augmented conversation c0 while preserving the semantic information of the global conversation. Semi-supervised learning methods can further reduce the dependency on labeled data and enhance the models by using large amounts of unlabeled Random Swapping or Deletion Utterances data (Chapelle et al., 2009; Gururangan et al., 2019; from different speakers in conversations usually Chen et al., 2021). Unlabeled data is usually incor- follow Gricean Maxims (Dale and Reiter, 1995) porated through consistency training (Xie et al., to achieve effective communication in social situ2019; Chen et al., 2020b,a), co-training (Clark ations, which requires utterances to be related to et al., 2018), variational auto encoders (Gururangan each other orderly under the context of discourse et al., 2019; Chen et al., 2018; Yang et al., 2017) (Murray et al., 2006; Qin et al., 2017). From the or self-training (Scudder, 1965; Riloff and Wie"
2021.emnlp-main.530,N18-1170,0,0.0569878,"Missing"
2021.emnlp-main.530,D17-1215,0,0.0472058,"Missing"
2021.emnlp-main.530,N18-2072,0,0.162467,"a simData augmentation, which perturbs input data ple yet effective set of Conversational Data to create additional augmented data, has been utiAugmentation (CODA) methods for semilized to alleviate the need of labeled data in various supervised abstractive conversation summaNLP tasks, and can be categorized into three marization, such as random swapping/deletion jor classes: (1) manipulating words and phrases to perturb the discourse relations inside conversations, dialogue-acts-guided insertion to at the token-level like designed word replacement interrupt the development of conversations, (Kobayashi, 2018; Niu and Bansal, 2018), word and conditional-generation-based substitution deletion/swapping/insertion (Wei and Zou, 2019; to substitute utterances with their paraphrases Feng et al., 2020a), token/span cutoff (Shen et al., generated based on the conversation context. 2020b); (2) paraphrasing the entire input text at To further utilize unlabeled conversations, we the sentence-level through round-trip translation combine CODA with two-stage noisy self(Sennrich et al., 2015; Xie et al., 2019; Chen training where we first pre-train the sumet al., 2020b) or syntactic manipulation (Iyyer et al., m"
2021.emnlp-main.530,2020.lifelongnlp-1.3,0,0.0153095,"summaries. • We demonstrate the effectiveness of our pro- 2.2 Data Augmentation for NLP posed methods through extensive experiments Data augmentation is one of the most common on two conversation summarization datasets approaches to mitigate the need for labeled data , SAMSum (Gliwa et al., 2019) and ADSC in various NLP tasks (Feng et al., 2021). The (Misra et al., 2015). augmented data is usually generated by modify6606 ing existing data points through transformations while keeping the semantic meaning unaffected like designed word/synonym replacement (Kobayashi, 2018; Niu and Bansal, 2018; Kumar et al., 2020), word deletion/swapping/insertion (Wei and Zou, 2019), token/span cutoff (Shen et al., 2020b), and paraphrasing through round-trip translation (Sennrich et al., 2015; Xie et al., 2019; Chen et al., 2020b). Even though they could be directly applied to conversation summarization settings, these prior techniques mainly modify the text locally and largely ignore the structure and context information in conversations to generate more effective and diverse augmented conversations. To this end, our CODA augmentation will perturb the conversation structures and substitute paraphrases by taking into"
2021.emnlp-main.530,2020.acl-main.703,0,0.472538,"pose a conditional generation based method to generate new utterances and substitute the original utterances. , with its architecture shown in Figure 2. We first pre-train the conditional generation model g(.; θ) which could generate an utterance ui with a masked conversation cmask = {u0 , ..., ui−1 , umask , ui+1 , ..., un } and a prompt pi i as input. Specifically, during the pre-training stage, utterance ui ∈ c is randomly sampled and substituted with <MASK&gt;. The unique tokens in ui are then randomly shuffled to form the prompt pi . We initialize the generation model g(.; θ) with BARTbase (Lewis et al., 2020), and prepend the prompt pi to the masked conversation cmask as input. The pre-training objective is: X L=− log P (ui |g(pi , cmask ; θ)) (1) During the augmentation stage, for a random utterance ui in c, we construct the cmask and pi in the same way as the pre-training stage. We employ the random sampling strategy with a tunable temperature τ to generate u0i and construct the augmented conversation c0 by substituting ui with u0i in c; τ is a hyper-parameter to control the diversities (higher temperature would result in more diverse generations while injecting more noise). In practice, we rand"
2021.emnlp-main.530,P19-1210,0,0.0283034,"ion Abstractive conversation summarization has received much attention recently. Other than directly apply document summarization models to conversational settings (Gliwa et al., 2019), models tailored for conversation are designed to achieve the state-of-the-art performances such as modeling conversations in a hierarchical way (Zhao et al., 2019; Zhu et al., 2020b). The rich structured information in conversations are also explored and leveraged such as dialogue acts (Goo and Chen, 2018), key point/entity sequences (Liu et al., 2019a; Narayan et al., 2021), topic segments (Liu et al., 2019c; Li et al., 2019), stage developments (Chen and Yang, 2020), discourse relations (Chen and Yang, 2021; Feng et al., 2020b). External information like commonsense knowledge has also been incorporated to help understand the global conversation context as well (Feng et al., 2020c). However, current summarization models still heavily rely on abundant parallel data to achieve the state-of-the-art performances (Yu et al., 2021). Little work has focused on low-resourced settings where well-annotated summaries are limited or even unavailable. To fill this gap, in this work, we introduce a set of conversational data au"
2021.emnlp-main.530,N15-1046,0,0.0277719,"e work has focused on low-resourced settings where well-annotated summaries are limited or even unavailable. To fill this gap, in this work, we introduce a set of conversational data augmentation techniques to alleviate the dependence on labeled summaries. • We demonstrate the effectiveness of our pro- 2.2 Data Augmentation for NLP posed methods through extensive experiments Data augmentation is one of the most common on two conversation summarization datasets approaches to mitigate the need for labeled data , SAMSum (Gliwa et al., 2019) and ADSC in various NLP tasks (Feng et al., 2021). The (Misra et al., 2015). augmented data is usually generated by modify6606 ing existing data points through transformations while keeping the semantic meaning unaffected like designed word/synonym replacement (Kobayashi, 2018; Niu and Bansal, 2018; Kumar et al., 2020), word deletion/swapping/insertion (Wei and Zou, 2019), token/span cutoff (Shen et al., 2020b), and paraphrasing through round-trip translation (Sennrich et al., 2015; Xie et al., 2019; Chen et al., 2020b). Even though they could be directly applied to conversation summarization settings, these prior techniques mainly modify the text locally and largely"
2021.emnlp-main.530,N06-1047,0,0.341573,"nes. We have publicly remainly perturbs sentences locally while ignoring leased our code at https://github.com/ the diverse structures and context information in GT-SALT/CODA. dialogues to create high-quality augmented conver1 Introduction sations for summarization. The third one might Abstractive conversation summarization, which tar- utilize context through additional backward passes, but often require significant amount of computagets at processing, organizing and distilling human interaction activities into short, concise and nat- tional and memory overhead (Zhang et al., 2019; ural text (Murray et al., 2006; Wang and Cardie, Zhu et al., 2019), especially for summarization 2013), is one of the most challenging and inter- tasks with long input. esting problems in text summarization. Recently, To this end, we introduce simple and novel set neural abstractive conversation summarization has of Conversational Data Augmentation (CODA) received growing attention and achieved remark- techniques for conversation summarization guided able performances by adapting document summa- by conversation structures and context, including: rization pre-trained models and (Gliwa et al., 2019; (1) random swapping/delet"
2021.emnlp-main.530,D18-1206,0,0.0644836,"Missing"
2021.emnlp-main.530,K18-1047,0,0.141938,"ation, which perturbs input data ple yet effective set of Conversational Data to create additional augmented data, has been utiAugmentation (CODA) methods for semilized to alleviate the need of labeled data in various supervised abstractive conversation summaNLP tasks, and can be categorized into three marization, such as random swapping/deletion jor classes: (1) manipulating words and phrases to perturb the discourse relations inside conversations, dialogue-acts-guided insertion to at the token-level like designed word replacement interrupt the development of conversations, (Kobayashi, 2018; Niu and Bansal, 2018), word and conditional-generation-based substitution deletion/swapping/insertion (Wei and Zou, 2019; to substitute utterances with their paraphrases Feng et al., 2020a), token/span cutoff (Shen et al., generated based on the conversation context. 2020b); (2) paraphrasing the entire input text at To further utilize unlabeled conversations, we the sentence-level through round-trip translation combine CODA with two-stage noisy self(Sennrich et al., 2015; Xie et al., 2019; Chen training where we first pre-train the sumet al., 2020b) or syntactic manipulation (Iyyer et al., marization model on unla"
2021.emnlp-main.530,D19-1132,0,0.022505,"el through round-trip translation combine CODA with two-stage noisy self(Sennrich et al., 2015; Xie et al., 2019; Chen training where we first pre-train the sumet al., 2020b) or syntactic manipulation (Iyyer et al., marization model on unlabeled conversations with pseudo summaries and then fine-tune it 2018; Chen et al., 2020c); and (3) adding adversaron labeled conversations. Experiments conial perturbations to the original data which dramatducted on the recent conversation summarizaically influences the model’s predictions (Jia and tion datasets demonstrate the effectiveness of Liang, 2017; Niu and Bansal, 2019; Zhang et al., our methods over several state-of-the-art data 2019). Despite the huge success, the former two augmentation baselines. We have publicly remainly perturbs sentences locally while ignoring leased our code at https://github.com/ the diverse structures and context information in GT-SALT/CODA. dialogues to create high-quality augmented conver1 Introduction sations for summarization. The third one might Abstractive conversation summarization, which tar- utilize context through additional backward passes, but often require significant amount of computagets at processing, organizing an"
2021.emnlp-main.530,P17-1090,0,0.0194489,"or Deletion Utterances data (Chapelle et al., 2009; Gururangan et al., 2019; from different speakers in conversations usually Chen et al., 2021). Unlabeled data is usually incor- follow Gricean Maxims (Dale and Reiter, 1995) porated through consistency training (Xie et al., to achieve effective communication in social situ2019; Chen et al., 2020b,a), co-training (Clark ations, which requires utterances to be related to et al., 2018), variational auto encoders (Gururangan each other orderly under the context of discourse et al., 2019; Chen et al., 2018; Yang et al., 2017) (Murray et al., 2006; Qin et al., 2017). From the or self-training (Scudder, 1965; Riloff and Wiebe, perspective of perturbing discourse relations to cre2003; Xie et al., 2020). In this work, we focus on ate augmented conversations (Gui et al., 2021), self-training, one of the most classic “pseudo-label” we introduce two simple operations to perturb the semi-supervised learning approaches (Yarowsky, discourse relations: (1) random swapping, which 1995; Riloff and Wiebe, 2003). Self-training often breaks the discourse relations by randomly swapiteratively incorporates unlabeled data by learning ping two utterances in one conversatio"
2021.emnlp-main.530,N19-1373,0,0.0228459,"arder perturbed conversation. • Round-trip Translation (Xie et al., 2019; Chen et al., 2020b) generate paraphrases by first translating them to an intermediate language like Romance and then translating them back. This work utilized pre-trained Marian translation model 2 to generate paraphrases. 1 https://huggingface.co/transformers/ model_doc/bart.html 2 https://huggingface.co/transformers/ model_doc/marian.html Figure 3: The average ranking every method receives from human evaluation (lower is better). 4.3 Model Settings For the dialogue acts classifier, we directly followed the settings in Raheja and Tetreault (2019) and applied the trained classifier to predict dialogue acts of utterances in SAMSum corpus. We initialized our conditional generation model with BARTbase (Lewis et al., 2020) and trained the model on SAMSum corpus. During augmentation, the sampling temperature is 0.7. α in CODA was selected from {0.1, 0.2, 0.3, 0.5}. We utilized RoBERTalarge 3 to initialize the BERT-score (rescale with baseline) (Zhang* et al., 2020) and set the filtering threshold T = 0.25. The maximum iteration for semi-CODA was set 5. For all the methods, we used BART-base to initialize the conversation summarization model"
2021.emnlp-main.530,W03-1014,0,0.301478,"), variational auto encoders (Gururangan each other orderly under the context of discourse et al., 2019; Chen et al., 2018; Yang et al., 2017) (Murray et al., 2006; Qin et al., 2017). From the or self-training (Scudder, 1965; Riloff and Wiebe, perspective of perturbing discourse relations to cre2003; Xie et al., 2020). In this work, we focus on ate augmented conversations (Gui et al., 2021), self-training, one of the most classic “pseudo-label” we introduce two simple operations to perturb the semi-supervised learning approaches (Yarowsky, discourse relations: (1) random swapping, which 1995; Riloff and Wiebe, 2003). Self-training often breaks the discourse relations by randomly swapiteratively incorporates unlabeled data by learning ping two utterances in one conversation to messes student models from pseudo labels assigned by up the logic chain of utterance, and (2) random deleteacher models. The teacher model could be the tion, which goes against the discourse requirement model trained on labeled data or the model from by randomly deleting Kr = αd ·n utterances to prolast iteration (Zhu and Goldberg, 2009). Recent vide less information in the conversations, where work showed that combining self-traini"
2021.emnlp-main.530,P13-1137,0,0.0827935,"Missing"
2021.emnlp-main.530,D19-1670,0,0.0578285,"Missing"
2021.emnlp-main.530,P95-1026,0,0.34593,"Missing"
2021.emnlp-main.530,2021.naacl-main.471,0,0.0717405,"Missing"
2021.emnlp-main.530,2020.findings-emnlp.19,0,0.33061,"and novel set neural abstractive conversation summarization has of Conversational Data Augmentation (CODA) received growing attention and achieved remark- techniques for conversation summarization guided able performances by adapting document summa- by conversation structures and context, including: rization pre-trained models and (Gliwa et al., 2019; (1) random swapping/deletion randomly swap or Yu et al., 2021) and incorporating structural infor- delete utterances in conversations to perturb the mation (Chen and Yang, 2020; Feng et al., 2020c; discourse relations, (2) dialogue-acts-guided inZhu et al., 2020a; Chen and Yang, 2021; Liu et al., sertion randomly insert utterances based on the 6605 Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 6605–6616 c November 7–11, 2021. 2021 Association for Computational Linguistics Figure 1: Examples of utilizing different CODA strategies to augment the given conversation including (1) random Swapping/Deletion where last two utterances are swapped (top), (2) dialogue-acts-based Insertion where a backchannel utterance is inserted after the first utterance (middle), and (3) conditional-generation-based substitution"
2021.emnlp-main.776,2020.emnlp-main.95,1,0.165156,"combinations latent states representations - vectors that often possess complex hierarchical geometries. of individual inputs and labels to expand the trainHowever, these operations are performed in ing distribution. Performing Mixup over the latent the Euclidean space, simplifying these reprerepresentations of inputs has led to further improvesentations, which may lead to distorted and ments, as the hidden states of deep neural networks noisy interpolations. We propose HypMix, a carry more information than raw input samples, novel model-, data-, and modality-agnostic in(Verma et al., 2019a; Chen et al., 2020a). However, terpolative data augmentation technique opermost data augmentation methods can only utilize ating in the hyperbolic space, which captures the complex geometry of input and hidden existing labeled data. state hierarchies better than its contemporaries. Semi-supervised learning methods, on the other We evaluate HypMix on benchmark and low hand, can leverage unlabeled data for training. Sevresource datasets across speech, text, and vieral semi-supervised methods use interpolation sion modalities, showing that HypMix conbased regularization methods over unlabeled samsistently outperfo"
2021.emnlp-main.776,2020.acl-main.194,1,0.136881,"combinations latent states representations - vectors that often possess complex hierarchical geometries. of individual inputs and labels to expand the trainHowever, these operations are performed in ing distribution. Performing Mixup over the latent the Euclidean space, simplifying these reprerepresentations of inputs has led to further improvesentations, which may lead to distorted and ments, as the hidden states of deep neural networks noisy interpolations. We propose HypMix, a carry more information than raw input samples, novel model-, data-, and modality-agnostic in(Verma et al., 2019a; Chen et al., 2020a). However, terpolative data augmentation technique opermost data augmentation methods can only utilize ating in the hyperbolic space, which captures the complex geometry of input and hidden existing labeled data. state hierarchies better than its contemporaries. Semi-supervised learning methods, on the other We evaluate HypMix on benchmark and low hand, can leverage unlabeled data for training. Sevresource datasets across speech, text, and vieral semi-supervised methods use interpolation sion modalities, showing that HypMix conbased regularization methods over unlabeled samsistently outperfo"
2021.emnlp-main.776,D18-1217,0,0.0265893,"(Jindal et al., 2020a; Verma et al., 2019a) perform Mixup operations over hidden state representation of input samples instead of the inputs, as highlevel representations are often low-dimensional and carry more useful information of input samples as compared to raw inputs. Latent interpolation methods have not been generalized across modalities and operate in the simplified Euclidean space which is unable to capture the complex characteristics possessed by latent state representations. Semi-supervised Learning methods leverage unlabeled data which is typically available in larger quantities (Clark et al., 2018). Consistency regularization methods for semi-supervised learning predict soft labels for unlabeled data and train models on different permutations of labeled and unlabeled data (Verma et al., 2019b; Chen et al., 2020a). Chen et al. (2020b) uses a label guessing strategy on different augmentations of unlabeled data and combines it with labeled data for training models. However, these methods perform label prediction for unlabeled data using Euclidean operations. Hyperbolic Learning has proven to be effective in representing information where relations among data points possess hierarchical and"
2021.emnlp-main.776,N19-1423,0,0.0290459,"a, and a fully supervised setup with complete training data. Speech Following previous works, we use EnvNet-v2 with strong augmentation (Tokozume et al., 2018) as our base architecture fθ (·) followed by a fully connected layer gφ (·). We modify M IX H to account for the auditory perception and amplitude of speech signals (Tokozume et al., 2018). We use Fourier and Inverse Fourier Transform to generate augmented samples. We compare H YP M IX with the current state-of-the-art method Speechmix (Jindal et al., 2020b) across multiple settings. Text Following Chen et al. (2020b), we use BERT-base (Devlin et al., 2019) as the backbone architecture (fθ (·)) for English datasets and BERTbase-arabic (Safaya et al., 2020) for the Arabic dataset. We use a two layer MLP with hidden size 128 as the classifier (gφ (·)) and generate aug(15) mented data using back-translation (Edunov et al., 9862 Speech (Error rate ↓) Model ESC-10 #Samples n 5 10 Text (Error rate ↓) Urdu SER 15 5 10 20 Vision (Error rate ↓) AG News DBPedia Arabic HS 10 200 10 200 50 100 CIFAR-10 10 100 500 CIFAR-100 10 100 500 Base Model 47.1 32.5 26.2 28.7 23.8 18.2 30.5 12.5 4.8 1.5 42.1 40.6 65.7 34.2 14.9 79.7 41.1 21.2 + E UC M IX 33.2 24.2 21.0"
2021.emnlp-main.776,W18-1708,0,0.158409,"r paraphrasing (Ku- more general hyperbolic space (Ganea et al., 2018). mar et al., 2019) individual examples. However, The interference of sound waves is hyperbolic in ∗ Equal contribution. nature, which generates hyperboloid waveforms 9858 Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 9858–9868 c November 7–11, 2021. 2021 Association for Computational Linguistics (Khan and Panigrahi, 2016). Natural language text exhibits hierarchical structure in a variety of respects and embeddings are more expressive when represented in the hyperbolic space (Dhingra et al., 2018). Data augmentation using Möbius operations over images has shown more diversification and generalization compared to Euclidean operations (Zhou et al., 2021). Performing interpolative operations over representations having complex geometry in the hyperbolic space can lead to more suitable representations for model training. Building on prior research in limited data and data augmentation studies, and the hyperbolic characteristics of speech, text, and vision, we propose H YP M IX1 : a model, data, and modality agnostic interpolative regularization method operating in the hyperbolic space. We"
2021.emnlp-main.776,D18-1045,0,0.030006,"he corresponding labels yi , yj ∼ Y , and apply H YP M IX(xi , xj ). We optimize the model using KL-divergence loss L over the model outputs and the mixed labels mix(yi , yj ), L = KL(mix(yi , yj )||gφ (H YP M IX(xi , xj ))) Speech Text Vis. Xu = {xu1 , xu2 , . . . , xuq } using a semi-supervised training strategy in the hyperbolic space (Figure 2). We first use existing data augmentation techniques across different modalities to increase the unlabeled training data Xu . For an unlabeled sample xus , we generate Z augmented samples using different augmentation methods such as backtranslation (Edunov et al., 2018) and combine them to generate unlabeled augmented sets, Xa = {Xa,1 , Xa,2 , . . . , Xa,Z |Xa,z = {xu1,z , xu2,z , . . . , xuq,z }, z ∈ [1, Z]}. Dataset Class Labels # Classes # Samples ESC-10 (2015) Sound Source 10 400 US8K (2017) Sound Source 10 8,732 Urdu SER (2018) Emotion 4 400 AG News (2018) News Topic 4 127,600 DB Pedia (2012) Wiki Topic 14 630,000 Arabic HS (2018) Hate Speech 2 3,950 CIFAR-10 (2009) Object 10 60,000 CIFAR-100 (2009) Object 100 60,000 Table 1: Datasets, tasks, # classes and # samples. 4 4.1 Experimental Setup Datasets and Preprocessing We consider benchmark and low-resou"
2021.emnlp-main.776,P19-1356,0,0.0259189,"Missing"
2021.emnlp-main.776,mendes-etal-2012-dbpedia,0,0.021693,"Missing"
2021.emnlp-main.776,2020.coling-main.611,1,0.79511,"Missing"
2021.emnlp-main.776,2020.semeval-1.271,0,0.0112577,"EnvNet-v2 with strong augmentation (Tokozume et al., 2018) as our base architecture fθ (·) followed by a fully connected layer gφ (·). We modify M IX H to account for the auditory perception and amplitude of speech signals (Tokozume et al., 2018). We use Fourier and Inverse Fourier Transform to generate augmented samples. We compare H YP M IX with the current state-of-the-art method Speechmix (Jindal et al., 2020b) across multiple settings. Text Following Chen et al. (2020b), we use BERT-base (Devlin et al., 2019) as the backbone architecture (fθ (·)) for English datasets and BERTbase-arabic (Safaya et al., 2020) for the Arabic dataset. We use a two layer MLP with hidden size 128 as the classifier (gφ (·)) and generate aug(15) mented data using back-translation (Edunov et al., 9862 Speech (Error rate ↓) Model ESC-10 #Samples n 5 10 Text (Error rate ↓) Urdu SER 15 5 10 20 Vision (Error rate ↓) AG News DBPedia Arabic HS 10 200 10 200 50 100 CIFAR-10 10 100 500 CIFAR-100 10 100 500 Base Model 47.1 32.5 26.2 28.7 23.8 18.2 30.5 12.5 4.8 1.5 42.1 40.6 65.7 34.2 14.9 79.7 41.1 21.2 + E UC M IX 33.2 24.2 21.0 18.8 16.5 13.7 25.9 11.9 3.2 1.3 41.1 39.6 64.6 32.3 14.1 78.8 40.3 20.3 + H YP M IX 30.3 22.2 19."
2021.emnlp-main.776,D19-1670,0,0.0276668,"butions can be summarized as: • We propose H YP M IX, a novel model, data, and modality agnostic interpolative regularization based data augmentation method functioning in the hyperbolic space. • We devise a novel Möbius Gyromidpoint Label Estimation (MGLE) method to predict soft labels for unlabeled data, and extend H YP M IX to a hyperbolic semi-supervised learning method. 2 Background and Related Work Data Augmentation enables use of limited training data, with approaches involving modifying the individual training instances, such as cropping (Simonyan and Zisserman, 2015) or paraphrasing (Wei and Zou, 2019; Kumar et al., 2019). Mixup techniques (Zhu et al., 2019) perform interpolation among input samples and have proven to perform better than modifying individual instances as it incorporates the prior knowledge that linear interpolations of feature vectors should lead to linear interpolations of the associated targets. Recent works (Jindal et al., 2020a; Verma et al., 2019a) perform Mixup operations over hidden state representation of input samples instead of the inputs, as highlevel representations are often low-dimensional and carry more useful information of input samples as compared to raw"
2021.findings-acl.293,N01-1016,0,0.513969,"Missing"
2021.findings-acl.293,N19-1423,0,0.0277124,"RT and T5 variants on the following two data configurations: Table 2 summarizes the key differences between D ISFL -QA and the S WITCHBOARD dataset. 3 Fluent Q Experimental Setup Models to Compare We use two different modeling approaches to answer disfluent questions in D ISFL -QA. ALL where the model is trained on all of SQ UAD-v2, including the non-answerable questions. Evaluation is done against the entire test set. ANS where the model is trained only on answerable questions from SQ UAD-v1, without the capabilities of handling non-answerable questions. 3.3 Datasets LMs for QA. We use BERT (Devlin et al., 2019) and T5 (Raffel et al., 2020) as our QA models in the standard setup which has shown to achieve state-of-the-art performance for SQ UAD. We fine-tune BERT for a span selection task, whereby predicting start and end probabilities for all the tokens in the context. T5 is finetuned under the standard text2text formulation, when given (question, passage) as input the model generates the answer as the output. For predicting <no answer>, the model was trained to generate “unknown”. Human Annotated Datasets. We use 3 datasets in our experiments: SQ UAD-v1, SQ UAD-v2, and D ISFL -QA. We split the 11,"
2021.findings-acl.293,N15-1029,0,0.0221428,"f D ISFL -QA, with a simple DQ → Q and CDQ → Q T5 task formulation. With this pipelined approach, we get further improvements with an overall F1 of 87.19 (Table 7), however, still lacking by ≈2.4 F1 points compared to the fluent dataset. This shows that such complex cases require better modeling, preferably in an end-to-end setup. 5 5.1 Related Work Disfluency Correction The most popular approach in literature poses disfluency correction as a sequence tagging task, in which the fluent version of the utterance is obtained by identifying and removing the disfluent segments (Zayats et al., 2014; Ferguson et al., 2015; Zayats et al., 2016; Lou and Johnson, 2017; Jamshid Lou and Johnson, 2020; Wang et al., 2020). . Traditional disfluency correction models use syntactic features (Honnibal and Johnson, 2014), language models (Johnson et al., 2004; Zwarts and Johnson, 2011), discourse markers (Crible, 2017), or prosody-based features for learning (Zayats and Ostendorf, 2019; Wang et al., 2017) while recent disfluency correction models largely utilize pre-trained neural representations (Lou et al., 2018). Most of these models depend on human-annotated data. As a result, recently, data augmentation techniques ha"
2021.findings-acl.293,D18-1490,0,0.0615598,"on of the utterance is obtained by identifying and removing the disfluent segments (Zayats et al., 2014; Ferguson et al., 2015; Zayats et al., 2016; Lou and Johnson, 2017; Jamshid Lou and Johnson, 2020; Wang et al., 2020). . Traditional disfluency correction models use syntactic features (Honnibal and Johnson, 2014), language models (Johnson et al., 2004; Zwarts and Johnson, 2011), discourse markers (Crible, 2017), or prosody-based features for learning (Zayats and Ostendorf, 2019; Wang et al., 2017) while recent disfluency correction models largely utilize pre-trained neural representations (Lou et al., 2018). Most of these models depend on human-annotated data. As a result, recently, data augmentation techniques have been proposed (Yang et al., 2020; McDougall and Duckworth, 2017) to alleviate the strong dependence on labeled data. However, the resulting augmented data either via heuristics (Wang et al., 2020) or generation models (Yang et al., 2020) is often limited in terms of disfluencies types and may not well capture natural disfluencies in daily conversations. 5.2 Question Answering Under Noise In the QA literature, our work is related to two threads that aim to improve robustness of QA mod"
2021.findings-acl.293,P17-2087,0,0.147877,"lexity. . . What is typically used to broadly define complexity measures? What is defined no is typically used to broadly define complexity measures? Table 1: Example passage and fluent questions from the SQ UAD dataset and their disfluent versions provided by human raters, categorized by the type of disfluency along with their estimated percentage in the D ISFL -QA dataset. writing the disfluent version of a question, we instructed raters not to include partial words or filled pauses (e.g., “um”, “uh”, “ah” etc.), as they can be detected relatively easily (Johnson and Charniak, 2004; Jamshid Lou and Johnson, 2017). Raters were shown example disfluencies from each of the categories in Table 1. On average, raters spent 2.5 minutes per question. Introduction of a disfluency increased the mean length of a question from 10.3 to 14.6 words. Human Evaluation + Re-annotation. To assess and ensure high quality of the dataset, we asked a another set of human raters the following yes/no questions: 1. Is the disfluent question consistent with respect to the fluent question? i.e., the disfluent question is semantically equivalent to the original question in that they share the same answer. 2. Is the disfluent quest"
2021.findings-acl.293,2020.acl-main.346,0,0.121747,"the Duchy of Normandy founded? When was the Duchy of Normandy offered ugh I mean founded? A DJ What is the original meaning of the word Norman? What is the English rather original meaning of the word Norman? A DV Who did Beyonc´e perform privately for in 2011? Who did Beyonc´e perform publicly oops privately for in 2011? E NT Who was a prominent Huguenot in Holland? Who was a prominent Saint Nicholas no I mean Huguenot in Holland? Table 3: Example of synthetically generated disfluent questions using the contextual heuristics. state-of-the-art BERT-based disfluency correction model by Jamshid Lou and Johnson (2020) trained on S WITCHBOARD. We also train T5 models on D ISFL -QA to prevent the distribution skew between S WITCHBOARD and D ISFL -QA, and account for new phenomena like coreferences. 3.2 Who removed [BSkyB’s] operating license no scratch that who do [they] have [their] operating license from ? Training Settings We train the BERT and T5 variants on the following two data configurations: Table 2 summarizes the key differences between D ISFL -QA and the S WITCHBOARD dataset. 3 Fluent Q Experimental Setup Models to Compare We use two different modeling approaches to answer disfluent questions in D"
2021.findings-acl.293,D17-1215,0,0.0264742,"stion Answering Under Noise In the QA literature, our work is related to two threads that aim to improve robustness of QA models: (i) QA under adversarial noise, and (ii) noise arising from speech phenomena. Prior work on adversarial QA have predominantly generated adversaries automatically (Zhao et al., 2018), which are verified by humans to ensure semantic equivalence (i.e. answer remains same after perturbation). For instance, Ribeiro et al. (2018) generated adversaries using para3316 phrasing, while Mudrakarta et al. (2018) perturbed questions based on attribution. Closest work to ours is Jia and Liang (2017), who modified SQ UAD to contain automatically generated adversarial sentence insertions. Our work is more closely related to prior work on making NLP models robust to noise arising from speech phenomena. Earlier work (Surdeanu et al., 2006; Leuski et al., 2006) have built QA models which are robust to disfluency-like phenomenon, but they were limited in the corpus complexity, domain, and scale. Recently there has been renewed interest in constructing audio enriched versions of existing NLP datasets, for example, the S POKEN -SQ UAD (Li et al., 2018) and S POKEN -C O QA (You et al., 2020) with"
2021.findings-acl.293,P04-1005,0,0.127401,"on complexity and decision tree complexity. . . What is typically used to broadly define complexity measures? What is defined no is typically used to broadly define complexity measures? Table 1: Example passage and fluent questions from the SQ UAD dataset and their disfluent versions provided by human raters, categorized by the type of disfluency along with their estimated percentage in the D ISFL -QA dataset. writing the disfluent version of a question, we instructed raters not to include partial words or filled pauses (e.g., “um”, “uh”, “ah” etc.), as they can be detected relatively easily (Johnson and Charniak, 2004; Jamshid Lou and Johnson, 2017). Raters were shown example disfluencies from each of the categories in Table 1. On average, raters spent 2.5 minutes per question. Introduction of a disfluency increased the mean length of a question from 10.3 to 14.6 words. Human Evaluation + Re-annotation. To assess and ensure high quality of the dataset, we asked a another set of human raters the following yes/no questions: 1. Is the disfluent question consistent with respect to the fluent question? i.e., the disfluent question is semantically equivalent to the original question in that they share the same a"
2021.findings-acl.293,W06-1303,0,0.0559284,"ted adversaries automatically (Zhao et al., 2018), which are verified by humans to ensure semantic equivalence (i.e. answer remains same after perturbation). For instance, Ribeiro et al. (2018) generated adversaries using para3316 phrasing, while Mudrakarta et al. (2018) perturbed questions based on attribution. Closest work to ours is Jia and Liang (2017), who modified SQ UAD to contain automatically generated adversarial sentence insertions. Our work is more closely related to prior work on making NLP models robust to noise arising from speech phenomena. Earlier work (Surdeanu et al., 2006; Leuski et al., 2006) have built QA models which are robust to disfluency-like phenomenon, but they were limited in the corpus complexity, domain, and scale. Recently there has been renewed interest in constructing audio enriched versions of existing NLP datasets, for example, the S POKEN -SQ UAD (Li et al., 2018) and S POKEN -C O QA (You et al., 2020) with the aim to show the effect of speech recognition errors on QA task. However, since collecting audio is challenging, another line of work involves testing the robustness of NLP models to ASR errors in transcribed texts containing synthetic noise using TTS → ASR"
2021.findings-acl.293,P18-2124,0,0.163885,"of using gold data for fine-tuning. We argue that we need large-scale disfluency datasets in order for NLP models to be robust to them. The dataset is publicly available at: https://github.com/ google-research-datasets/disfl-qa. 1 ♣ Shyam Upadhyay Diyi Yang ♠ Google Assistant ♢ The University of Texas at Austin ♣ Georgia Institute of Technology disfl-qa@google.com Figure 1: (a) Categories of disfluencies (Shriberg, 1994) (b) A passage and questions (qi ) from SQ UAD, along with their disfluent versions (dqi ) and predictions from a T5-QA model. question answering (QA) setting, namely SQ UAD (Rajpurkar et al., 2018), affects the prediction of a state-of-the-art T5 model (Raffel et al., 2020). For example, the original question q1 is seeking an answer about the location of Normandy. In the disfluent version dq1 (which is semantically equivalent to q1 ), the user starts asking about Norse and then corrects themselves to ask about the Normandy instead. The presence of this correctional disfluency confuses the QA model, which tend to rely on shallow textual cues from question for making predictions. 3309 Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 3309–3319 August 1–6, 2"
2021.findings-acl.293,D16-1264,0,0.0237349,"SFL -QA builds upon the existing SQ UAD-v2 dataset, a question answering dataset which contains curated paragraphs from Wikipedia and associated questions. Each question associated with the paragraph is sent for a human annotation task to add a contextual disfluency using the paragraph as a source of distractors. Finally, to ensure the quality of the dataset, a subsequent round of human evaluation with an option to re-annotate is conducted. 2.1 Source of Questions We sourced passages and questions from SQ UAD-v2 (Rajpurkar et al., 2018) development set. SQ UAD-v2 is an extension of SQ UAD-v1 (Rajpurkar et al., 2016) that contains unanswerable questions written adversarially by crowd workers to look similar to answerable ones from SQ UAD-v1. We use both answerable and unanswerable questions for each passage in the annotation task. 2.2 Annotation Task To ensure high quality of the dataset, our annotation process consists of 2 rounds of annotation: First Round of Annotation. Expert raters were shown the passage along with all the associated questions and their answers, with one of the 1 question-answer pair highlighted for annotation. The raters were instructed to use the provided context in crafting disflu"
2021.findings-acl.293,2021.eacl-main.259,0,0.0293543,"but they were limited in the corpus complexity, domain, and scale. Recently there has been renewed interest in constructing audio enriched versions of existing NLP datasets, for example, the S POKEN -SQ UAD (Li et al., 2018) and S POKEN -C O QA (You et al., 2020) with the aim to show the effect of speech recognition errors on QA task. However, since collecting audio is challenging, another line of work involves testing the robustness of NLP models to ASR errors in transcribed texts containing synthetic noise using TTS → ASR technique (Peskov et al., 2019; Peng et al., 2020; Liu et al., 2020; Ravichander et al., 2021). Our work suggests a complementary approach to data collection to surface a specific speech phenomenon that affects NLP. 6 Conclusion This work presented D ISFL -QA, a new challenge set containing contextual semantic disfluencies in a QA setting. D ISFL -QA contains diverse set of disfluencies rooted in context, particularly a large fraction of corrections and restarts, unlike prior datasets. D ISFL -QA allows one to directly quantify the effect of presence of disfluencies in a downstream task, namely QA. We analyze the performance of models under varying when subjected to disfluencies under"
2021.findings-acl.293,P18-1079,0,0.0124737,"or generation models (Yang et al., 2020) is often limited in terms of disfluencies types and may not well capture natural disfluencies in daily conversations. 5.2 Question Answering Under Noise In the QA literature, our work is related to two threads that aim to improve robustness of QA models: (i) QA under adversarial noise, and (ii) noise arising from speech phenomena. Prior work on adversarial QA have predominantly generated adversaries automatically (Zhao et al., 2018), which are verified by humans to ensure semantic equivalence (i.e. answer remains same after perturbation). For instance, Ribeiro et al. (2018) generated adversaries using para3316 phrasing, while Mudrakarta et al. (2018) perturbed questions based on attribution. Closest work to ours is Jia and Liang (2017), who modified SQ UAD to contain automatically generated adversarial sentence insertions. Our work is more closely related to prior work on making NLP models robust to noise arising from speech phenomena. Earlier work (Surdeanu et al., 2006; Leuski et al., 2006) have built QA models which are robust to disfluency-like phenomenon, but they were limited in the corpus complexity, domain, and scale. Recently there has been renewed inte"
2021.findings-acl.293,D17-1296,0,0.0206369,"popular approach in literature poses disfluency correction as a sequence tagging task, in which the fluent version of the utterance is obtained by identifying and removing the disfluent segments (Zayats et al., 2014; Ferguson et al., 2015; Zayats et al., 2016; Lou and Johnson, 2017; Jamshid Lou and Johnson, 2020; Wang et al., 2020). . Traditional disfluency correction models use syntactic features (Honnibal and Johnson, 2014), language models (Johnson et al., 2004; Zwarts and Johnson, 2011), discourse markers (Crible, 2017), or prosody-based features for learning (Zayats and Ostendorf, 2019; Wang et al., 2017) while recent disfluency correction models largely utilize pre-trained neural representations (Lou et al., 2018). Most of these models depend on human-annotated data. As a result, recently, data augmentation techniques have been proposed (Yang et al., 2020; McDougall and Duckworth, 2017) to alleviate the strong dependence on labeled data. However, the resulting augmented data either via heuristics (Wang et al., 2020) or generation models (Yang et al., 2020) is often limited in terms of disfluencies types and may not well capture natural disfluencies in daily conversations. 5.2 Question Answeri"
2021.findings-acl.293,2020.emnlp-main.113,1,0.759671,"016; Lou and Johnson, 2017; Jamshid Lou and Johnson, 2020; Wang et al., 2020). . Traditional disfluency correction models use syntactic features (Honnibal and Johnson, 2014), language models (Johnson et al., 2004; Zwarts and Johnson, 2011), discourse markers (Crible, 2017), or prosody-based features for learning (Zayats and Ostendorf, 2019; Wang et al., 2017) while recent disfluency correction models largely utilize pre-trained neural representations (Lou et al., 2018). Most of these models depend on human-annotated data. As a result, recently, data augmentation techniques have been proposed (Yang et al., 2020; McDougall and Duckworth, 2017) to alleviate the strong dependence on labeled data. However, the resulting augmented data either via heuristics (Wang et al., 2020) or generation models (Yang et al., 2020) is often limited in terms of disfluencies types and may not well capture natural disfluencies in daily conversations. 5.2 Question Answering Under Noise In the QA literature, our work is related to two threads that aim to improve robustness of QA models: (i) QA under adversarial noise, and (ii) noise arising from speech phenomena. Prior work on adversarial QA have predominantly generated adv"
2021.findings-acl.293,N19-1008,0,0.0149292,"sfluency Correction The most popular approach in literature poses disfluency correction as a sequence tagging task, in which the fluent version of the utterance is obtained by identifying and removing the disfluent segments (Zayats et al., 2014; Ferguson et al., 2015; Zayats et al., 2016; Lou and Johnson, 2017; Jamshid Lou and Johnson, 2020; Wang et al., 2020). . Traditional disfluency correction models use syntactic features (Honnibal and Johnson, 2014), language models (Johnson et al., 2004; Zwarts and Johnson, 2011), discourse markers (Crible, 2017), or prosody-based features for learning (Zayats and Ostendorf, 2019; Wang et al., 2017) while recent disfluency correction models largely utilize pre-trained neural representations (Lou et al., 2018). Most of these models depend on human-annotated data. As a result, recently, data augmentation techniques have been proposed (Yang et al., 2020; McDougall and Duckworth, 2017) to alleviate the strong dependence on labeled data. However, the resulting augmented data either via heuristics (Wang et al., 2020) or generation models (Yang et al., 2020) is often limited in terms of disfluencies types and may not well capture natural disfluencies in daily conversations."
2021.findings-acl.293,D18-1316,0,0.0120647,"h, 2017) to alleviate the strong dependence on labeled data. However, the resulting augmented data either via heuristics (Wang et al., 2020) or generation models (Yang et al., 2020) is often limited in terms of disfluencies types and may not well capture natural disfluencies in daily conversations. 5.2 Question Answering Under Noise In the QA literature, our work is related to two threads that aim to improve robustness of QA models: (i) QA under adversarial noise, and (ii) noise arising from speech phenomena. Prior work on adversarial QA have predominantly generated adversaries automatically (Zhao et al., 2018), which are verified by humans to ensure semantic equivalence (i.e. answer remains same after perturbation). For instance, Ribeiro et al. (2018) generated adversaries using para3316 phrasing, while Mudrakarta et al. (2018) perturbed questions based on attribution. Closest work to ours is Jia and Liang (2017), who modified SQ UAD to contain automatically generated adversarial sentence insertions. Our work is more closely related to prior work on making NLP models robust to noise arising from speech phenomena. Earlier work (Surdeanu et al., 2006; Leuski et al., 2006) have built QA models which a"
2021.findings-acl.293,P11-1071,0,0.0241983,"such complex cases require better modeling, preferably in an end-to-end setup. 5 5.1 Related Work Disfluency Correction The most popular approach in literature poses disfluency correction as a sequence tagging task, in which the fluent version of the utterance is obtained by identifying and removing the disfluent segments (Zayats et al., 2014; Ferguson et al., 2015; Zayats et al., 2016; Lou and Johnson, 2017; Jamshid Lou and Johnson, 2020; Wang et al., 2020). . Traditional disfluency correction models use syntactic features (Honnibal and Johnson, 2014), language models (Johnson et al., 2004; Zwarts and Johnson, 2011), discourse markers (Crible, 2017), or prosody-based features for learning (Zayats and Ostendorf, 2019; Wang et al., 2017) while recent disfluency correction models largely utilize pre-trained neural representations (Lou et al., 2018). Most of these models depend on human-annotated data. As a result, recently, data augmentation techniques have been proposed (Yang et al., 2020; McDougall and Duckworth, 2017) to alleviate the strong dependence on labeled data. However, the resulting augmented data either via heuristics (Wang et al., 2020) or generation models (Yang et al., 2020) is often limited"
2021.findings-emnlp.155,P14-1105,0,0.0582928,"Missing"
2021.findings-emnlp.155,C94-2174,0,0.196937,"e annotated spans are mostly single or short multi-word spans given the relative short context. In contrast, low agreements are obtained in the speech domain. Manual inspections reveal that our model tends to tag phrases including subjective pronouns such as “I” and “we”, which are informing signals in the Wikipedia domain for expressing subjective opinions, but under-perform in speech transcripts. 5 Related Work Detection of Subjective Bias. The study of detection of subjectivity can be dated back to 1990s, when pioneers start noticing the subjectivity genre on document level classification (Karlgren and Cutting, 1994; Kessler et al., 1997). Later, works like (Bruce and Wiebe, 1999; Hatzivassiloglou and Wiebe, 2000) bring people’s attention to the subjecHuman Evaluation. We sampled 50 sentences tivity on sentence level. There is a long line of reper corpus for human annotations. For each sen- search focusing on sentence classification utilizing tence, 3 qualified Turkers were asked to pick the methods based on linguistic features or handcrafted biased spans without length constraints. We con- rules (Riloff and Wiebe, 2003; Wiebe and Riloff, 1806 2005; Pang and Lee, 2004; Lin et al., 2011; Murray and Careni"
2021.findings-emnlp.155,P97-1005,0,0.386635,"single or short multi-word spans given the relative short context. In contrast, low agreements are obtained in the speech domain. Manual inspections reveal that our model tends to tag phrases including subjective pronouns such as “I” and “we”, which are informing signals in the Wikipedia domain for expressing subjective opinions, but under-perform in speech transcripts. 5 Related Work Detection of Subjective Bias. The study of detection of subjectivity can be dated back to 1990s, when pioneers start noticing the subjectivity genre on document level classification (Karlgren and Cutting, 1994; Kessler et al., 1997). Later, works like (Bruce and Wiebe, 1999; Hatzivassiloglou and Wiebe, 2000) bring people’s attention to the subjecHuman Evaluation. We sampled 50 sentences tivity on sentence level. There is a long line of reper corpus for human annotations. For each sen- search focusing on sentence classification utilizing tence, 3 qualified Turkers were asked to pick the methods based on linguistic features or handcrafted biased spans without length constraints. We con- rules (Riloff and Wiebe, 2003; Wiebe and Riloff, 1806 2005; Pang and Lee, 2004; Lin et al., 2011; Murray and Carenini, 2009; Yang et al.,"
2021.findings-emnlp.155,P18-1249,0,0.0578353,"Missing"
2021.findings-emnlp.155,P17-4012,0,0.0187342,"Missing"
2021.findings-emnlp.155,W04-3250,0,0.240253,"Missing"
2021.findings-emnlp.155,2020.acl-main.703,0,0.0519529,"Missing"
2021.findings-emnlp.155,N18-1169,0,0.0247776,"Missing"
2021.findings-emnlp.155,P02-1040,0,0.110798,"Missing"
2021.findings-emnlp.155,I11-1129,0,0.0347385,"ication (Karlgren and Cutting, 1994; Kessler et al., 1997). Later, works like (Bruce and Wiebe, 1999; Hatzivassiloglou and Wiebe, 2000) bring people’s attention to the subjecHuman Evaluation. We sampled 50 sentences tivity on sentence level. There is a long line of reper corpus for human annotations. For each sen- search focusing on sentence classification utilizing tence, 3 qualified Turkers were asked to pick the methods based on linguistic features or handcrafted biased spans without length constraints. We con- rules (Riloff and Wiebe, 2003; Wiebe and Riloff, 1806 2005; Pang and Lee, 2004; Lin et al., 2011; Murray and Carenini, 2009; Yang et al., 2017), then neural models (Morstatter et al., 2018; Hube and Fetahu, 2018; Pant et al., 2020; Hube and Fetahu, 2019). Work of Recasens et al. (2013) and Pryzant et al. (2020) on detecting biased language over singleword edit is closely related to our work, but we study the biased language on a broader scale to cover multi-word spans. Debiasing Generation. Generating debiased text can be viewed as a stylistic transferring task. Supervised approaches with parallel corpus have been shown to be effective across multiple styles (Xu et al., 2012; Hu et al.,"
2021.findings-emnlp.155,N18-1012,0,0.020229,", then neural models (Morstatter et al., 2018; Hube and Fetahu, 2018; Pant et al., 2020; Hube and Fetahu, 2019). Work of Recasens et al. (2013) and Pryzant et al. (2020) on detecting biased language over singleword edit is closely related to our work, but we study the biased language on a broader scale to cover multi-word spans. Debiasing Generation. Generating debiased text can be viewed as a stylistic transferring task. Supervised approaches with parallel corpus have been shown to be effective across multiple styles (Xu et al., 2012; Hu et al., 2017; Reddy and Knight, 2016; Xu et al., 2015; Rao and Tetreault, 2018). More recently, pipeline-based or stepwise approaches (Li et al., 2018; Leeftink and Spanakis, 2019; Madaan et al., 2020) focuses on first localizing the style to a fixed portion of the word, then generating replacement based on target style. Pryzant et al. (2020) adopts a similar approach by incorporating the localized style attribute into a jointembedding and enforces the text generation model to pay attention to the modifications. 6 Conclusion In this work, we contribute the first manually annotated parallel corpus of over 4,000 sentence pairs for the task of subjective bias detection. Thi"
2021.findings-emnlp.155,D15-1166,0,0.0234309,"Missing"
2021.findings-emnlp.155,P16-1101,0,0.0157453,"tion result on test set with different training data, reported on average of three runs. © means the model is further fine-tuned on Trainmanual . Model B ERT F INETUNED H IERARCHICAL macro-F1 class-level F1 F E D 33.9 39.0 41.0 56.3 22.0 24.2 62.1 20.5 35.2 61.0 26.5 35.8 Table 6: Macro and class-level F1 (Framing, Epistemological, and Demographic bias) on test set, averaged across three runs. learning inter-relations between the segment tagging and the sentence classification tasks. Biased Segment Tagging. We experiment with multiple baselines (Table 7), including (1) a BiLSTM-CNN-CRF model (Ma and Hovy, 2016), (2) a BERTAtten baseline which extracts words/phrases receiving high self-attention scores in the BERT encoder fine-tuned for the binary classification task (§3.1.1), (3) a DETECTOR model from (Pryzant et al., 2020) which labels the word with highest predicted probability, and (4) a finetune BERT tagging model in which we use the base size checkpoint as the encoder and a linear layer to predict token labels. Prior work (Recasens et al., 2013; Pryzant et al., 2020) demonstrated that linguistic features can assist in the detection of subjective bias. Thus, (5) we incorporate the linguistic fea"
2021.findings-emnlp.155,2020.acl-main.169,0,0.0127334,"ens et al. (2013) and Pryzant et al. (2020) on detecting biased language over singleword edit is closely related to our work, but we study the biased language on a broader scale to cover multi-word spans. Debiasing Generation. Generating debiased text can be viewed as a stylistic transferring task. Supervised approaches with parallel corpus have been shown to be effective across multiple styles (Xu et al., 2012; Hu et al., 2017; Reddy and Knight, 2016; Xu et al., 2015; Rao and Tetreault, 2018). More recently, pipeline-based or stepwise approaches (Li et al., 2018; Leeftink and Spanakis, 2019; Madaan et al., 2020) focuses on first localizing the style to a fixed portion of the word, then generating replacement based on target style. Pryzant et al. (2020) adopts a similar approach by incorporating the localized style attribute into a jointembedding and enforces the text generation model to pay attention to the modifications. 6 Conclusion In this work, we contribute the first manually annotated parallel corpus of over 4,000 sentence pairs for the task of subjective bias detection. This corpus covers multiple-word span annotations with fine-grained bias type on the source side and sentence level bias type"
2021.findings-emnlp.155,D09-1140,0,0.24116,"s work, we study how to detect and further mitigate biases in language. Specifically, we focus on a particular type of bias, “subjective bias”, in which the language is skewed towards an obvious feeling, with the presupposed or entailed proposition or considering opinions as truth. Contents with the subjective bias can make people be doubtful about the texts’ reliability and possibly trigger social unrest with offensive language. Prior research has used the lexical and grammatical cues like lexicon-syntactic patterns (Wiebe and Riloff, 2005; Riloff and Wiebe, 2003) or various n-gram features (Murray and Carenini, 2009; Wilson and Raaijmakers, 2008; Wiebe et al., 1999) to classify sentences as either subjective or objective. For instance, in the encyclopedia domain, Recasens et al. (2013) constructed an automatic parallel corpus from Wikipedia revisions that violate the Neutral Point of View (NPOV) policy,which advocates for “fairly presenting views with reliable sources and avoiding editor bias” and introduced the task of identifying the bias-induced word in a statement. They further uncovered two types of subjective bias through linguistic analysis, which includes framing bias such as praising or perspect"
2021.findings-emnlp.155,N19-4009,0,0.048689,"Missing"
2021.findings-emnlp.155,P04-1035,0,0.0838877,"cument level classification (Karlgren and Cutting, 1994; Kessler et al., 1997). Later, works like (Bruce and Wiebe, 1999; Hatzivassiloglou and Wiebe, 2000) bring people’s attention to the subjecHuman Evaluation. We sampled 50 sentences tivity on sentence level. There is a long line of reper corpus for human annotations. For each sen- search focusing on sentence classification utilizing tence, 3 qualified Turkers were asked to pick the methods based on linguistic features or handcrafted biased spans without length constraints. We con- rules (Riloff and Wiebe, 2003; Wiebe and Riloff, 1806 2005; Pang and Lee, 2004; Lin et al., 2011; Murray and Carenini, 2009; Yang et al., 2017), then neural models (Morstatter et al., 2018; Hube and Fetahu, 2018; Pant et al., 2020; Hube and Fetahu, 2019). Work of Recasens et al. (2013) and Pryzant et al. (2020) on detecting biased language over singleword edit is closely related to our work, but we study the biased language on a broader scale to cover multi-word spans. Debiasing Generation. Generating debiased text can be viewed as a stylistic transferring task. Supervised approaches with parallel corpus have been shown to be effective across multiple styles (Xu et al.,"
2021.findings-emnlp.155,P13-1162,0,0.302267,"towards an obvious feeling, with the presupposed or entailed proposition or considering opinions as truth. Contents with the subjective bias can make people be doubtful about the texts’ reliability and possibly trigger social unrest with offensive language. Prior research has used the lexical and grammatical cues like lexicon-syntactic patterns (Wiebe and Riloff, 2005; Riloff and Wiebe, 2003) or various n-gram features (Murray and Carenini, 2009; Wilson and Raaijmakers, 2008; Wiebe et al., 1999) to classify sentences as either subjective or objective. For instance, in the encyclopedia domain, Recasens et al. (2013) constructed an automatic parallel corpus from Wikipedia revisions that violate the Neutral Point of View (NPOV) policy,which advocates for “fairly presenting views with reliable sources and avoiding editor bias” and introduced the task of identifying the bias-induced word in a statement. They further uncovered two types of subjective bias through linguistic analysis, which includes framing bias such as praising or perspective-specific words and epistemological bias related to presupposed/entailed propositions. Pryzant et al. (2020) extended such revision corpus and further proposed to transfo"
2021.findings-emnlp.155,W16-5603,0,0.0211733,"ay and Carenini, 2009; Yang et al., 2017), then neural models (Morstatter et al., 2018; Hube and Fetahu, 2018; Pant et al., 2020; Hube and Fetahu, 2019). Work of Recasens et al. (2013) and Pryzant et al. (2020) on detecting biased language over singleword edit is closely related to our work, but we study the biased language on a broader scale to cover multi-word spans. Debiasing Generation. Generating debiased text can be viewed as a stylistic transferring task. Supervised approaches with parallel corpus have been shown to be effective across multiple styles (Xu et al., 2012; Hu et al., 2017; Reddy and Knight, 2016; Xu et al., 2015; Rao and Tetreault, 2018). More recently, pipeline-based or stepwise approaches (Li et al., 2018; Leeftink and Spanakis, 2019; Madaan et al., 2020) focuses on first localizing the style to a fixed portion of the word, then generating replacement based on target style. Pryzant et al. (2020) adopts a similar approach by incorporating the localized style attribute into a jointembedding and enforces the text generation model to pay attention to the modifications. 6 Conclusion In this work, we contribute the first manually annotated parallel corpus of over 4,000 sentence pairs for"
2021.findings-emnlp.155,W03-1014,0,0.307987,"s and keep the quality of the reference work. In this work, we study how to detect and further mitigate biases in language. Specifically, we focus on a particular type of bias, “subjective bias”, in which the language is skewed towards an obvious feeling, with the presupposed or entailed proposition or considering opinions as truth. Contents with the subjective bias can make people be doubtful about the texts’ reliability and possibly trigger social unrest with offensive language. Prior research has used the lexical and grammatical cues like lexicon-syntactic patterns (Wiebe and Riloff, 2005; Riloff and Wiebe, 2003) or various n-gram features (Murray and Carenini, 2009; Wilson and Raaijmakers, 2008; Wiebe et al., 1999) to classify sentences as either subjective or objective. For instance, in the encyclopedia domain, Recasens et al. (2013) constructed an automatic parallel corpus from Wikipedia revisions that violate the Neutral Point of View (NPOV) policy,which advocates for “fairly presenting views with reliable sources and avoiding editor bias” and introduced the task of identifying the bias-induced word in a statement. They further uncovered two types of subjective bias through linguistic analysis, wh"
2021.findings-emnlp.155,D13-1010,0,0.0783099,"Missing"
2021.findings-emnlp.155,W06-1639,0,0.168741,"te whether the phrase is supported or against the stance of the target (i.e., totally irresponsible − illustrates that the speaker uses this phrase to criticize the work of Republican Party). The extracted phrases from the speeches domain cover the signature words of the speaker without in-domain knowledge. “have a plan” is prevalent in 2020’s presidency debates and signature words “tremendous” and “very powerfully” of Donald Trump have also been captured. (3) The model can tight the connection between subjective bias with research over stance detection, especially in the formal text domains (Thomas et al., 2006; Walker et al., 2012; Chakrabarty et al., 2019; Lawrence and Reed, 2020). With our subjective bias tagger, complete verb phrases or noun phrases can be obtained, which naturally eases the extraction of topics and opinions, two necessary components for stance detection problem. For instance, “because Obamacare is no good” span can sufficiently illustrate the opinion of Trump that is against the prior healthcare policy. Meanwhile, “frustrated hypocrite” can indicate the left-wing media’s dislike of the Republican governor’s behavior. sider a span receiving more than one annotator vote the gold"
2021.findings-emnlp.155,walker-etal-2012-corpus,0,0.0396414,"is supported or against the stance of the target (i.e., totally irresponsible − illustrates that the speaker uses this phrase to criticize the work of Republican Party). The extracted phrases from the speeches domain cover the signature words of the speaker without in-domain knowledge. “have a plan” is prevalent in 2020’s presidency debates and signature words “tremendous” and “very powerfully” of Donald Trump have also been captured. (3) The model can tight the connection between subjective bias with research over stance detection, especially in the formal text domains (Thomas et al., 2006; Walker et al., 2012; Chakrabarty et al., 2019; Lawrence and Reed, 2020). With our subjective bias tagger, complete verb phrases or noun phrases can be obtained, which naturally eases the extraction of topics and opinions, two necessary components for stance detection problem. For instance, “because Obamacare is no good” span can sufficiently illustrate the opinion of Trump that is against the prior healthcare policy. Meanwhile, “frustrated hypocrite” can indicate the left-wing media’s dislike of the Republican governor’s behavior. sider a span receiving more than one annotator vote the gold label. The second col"
2021.findings-emnlp.155,P99-1032,0,0.729375,"Missing"
2021.findings-emnlp.155,J04-3002,0,0.211898,"Missing"
2021.findings-emnlp.155,H05-1044,0,0.0582223,"The state-ofthe-art baselines still struggle with multi-span deJoint Sentence Classification and Tagging. We tection, with significantly worse performance comdeploy a model to jointly learn sentence-level clas- paring to the estimated human upper bond. Thus, sification and token-level segmentation of bias. our corpus can serve as a useful research benchMore specifically, we utilize a BERT tagging model mark for future studies. Manual inspections on 6 tagging results suggest that models mainly failed I.e., lexicons of hedges (Thompson, 2005), factive verbs (Hooper, 1975), and subjective clues (Wilson et al., 2005). in detecting spans with content-dependent bias and 1804 preserving the completeness of phrases. The joint model achieves worse performance on the segment tagging task which is mainly attributed to the lower recall, while obtains a slight performance gain on the classification task. 3.3 Text Generation for Neutralizing Bias Bias neutralization can also be viewed as a text generation problem (Pryzant et al., 2020). In this section, we experiment with multiple generation baselines over W IKI B IAS, including Source Copy (directly copy input as output), LSTM and attention based seq2seq model (Lu"
2021.findings-emnlp.155,Q15-1021,1,0.782212,"ang et al., 2017), then neural models (Morstatter et al., 2018; Hube and Fetahu, 2018; Pant et al., 2020; Hube and Fetahu, 2019). Work of Recasens et al. (2013) and Pryzant et al. (2020) on detecting biased language over singleword edit is closely related to our work, but we study the biased language on a broader scale to cover multi-word spans. Debiasing Generation. Generating debiased text can be viewed as a stylistic transferring task. Supervised approaches with parallel corpus have been shown to be effective across multiple styles (Xu et al., 2012; Hu et al., 2017; Reddy and Knight, 2016; Xu et al., 2015; Rao and Tetreault, 2018). More recently, pipeline-based or stepwise approaches (Li et al., 2018; Leeftink and Spanakis, 2019; Madaan et al., 2020) focuses on first localizing the style to a fixed portion of the word, then generating replacement based on target style. Pryzant et al. (2020) adopts a similar approach by incorporating the localized style attribute into a jointembedding and enforces the text generation model to pay attention to the modifications. 6 Conclusion In this work, we contribute the first manually annotated parallel corpus of over 4,000 sentence pairs for the task of subj"
2021.findings-emnlp.155,C12-1177,1,0.58767,"Lee, 2004; Lin et al., 2011; Murray and Carenini, 2009; Yang et al., 2017), then neural models (Morstatter et al., 2018; Hube and Fetahu, 2018; Pant et al., 2020; Hube and Fetahu, 2019). Work of Recasens et al. (2013) and Pryzant et al. (2020) on detecting biased language over singleword edit is closely related to our work, but we study the biased language on a broader scale to cover multi-word spans. Debiasing Generation. Generating debiased text can be viewed as a stylistic transferring task. Supervised approaches with parallel corpus have been shown to be effective across multiple styles (Xu et al., 2012; Hu et al., 2017; Reddy and Knight, 2016; Xu et al., 2015; Rao and Tetreault, 2018). More recently, pipeline-based or stepwise approaches (Li et al., 2018; Leeftink and Spanakis, 2019; Madaan et al., 2020) focuses on first localizing the style to a fixed portion of the word, then generating replacement based on target style. Pryzant et al. (2020) adopts a similar approach by incorporating the localized style attribute into a jointembedding and enforces the text generation model to pay attention to the modifications. 6 Conclusion In this work, we contribute the first manually annotated paralle"
2021.findings-emnlp.155,D17-1213,1,0.805716,"et al., 1997). Later, works like (Bruce and Wiebe, 1999; Hatzivassiloglou and Wiebe, 2000) bring people’s attention to the subjecHuman Evaluation. We sampled 50 sentences tivity on sentence level. There is a long line of reper corpus for human annotations. For each sen- search focusing on sentence classification utilizing tence, 3 qualified Turkers were asked to pick the methods based on linguistic features or handcrafted biased spans without length constraints. We con- rules (Riloff and Wiebe, 2003; Wiebe and Riloff, 1806 2005; Pang and Lee, 2004; Lin et al., 2011; Murray and Carenini, 2009; Yang et al., 2017), then neural models (Morstatter et al., 2018; Hube and Fetahu, 2018; Pant et al., 2020; Hube and Fetahu, 2019). Work of Recasens et al. (2013) and Pryzant et al. (2020) on detecting biased language over singleword edit is closely related to our work, but we study the biased language on a broader scale to cover multi-word spans. Debiasing Generation. Generating debiased text can be viewed as a stylistic transferring task. Supervised approaches with parallel corpus have been shown to be effective across multiple styles (Xu et al., 2012; Hu et al., 2017; Reddy and Knight, 2016; Xu et al., 2015;"
2021.findings-emnlp.82,D18-1389,0,0.0231513,"3 35.1 45.9 53.7 50.9 48.7 52.3 51.3 24.6 23.8 26.2 24.9 23.3 24.9 24.8 20.6 18.0 19.3 18.0 19.3 18.4 18.4 13.6 11.1 8.8 9.9 15.5 8.9 9.4 Table 1: P OLICE V IOLENCE F RAME C ORPUS statistics. The number of articles and the breakdown of events by whether the victim was Armed, Attacking, Fleeing, had Mental Illness or was filmed on Video according to Mapping Police Violence data. Leaning is decided via Media Bias Fact Check in Section 3.3. largest available collection of crowdsourced media slant labels, and it has been used as ground truth in other recent work on news bias (Dinkov et al., 2019; Baly et al., 2018, 2019; Nadeem et al., 2019; Stefanov et al., 2020). The MBFC labels are extreme left, left, left-center, least biased, rightcenter, right, and extreme right. For our political framing analysis (Section 6), we consider a source liberal if its MBFC slant label is left or extreme left, and we consider the source conservative if its label is right or extreme right. We manually filter this polarized subset to ensure that all articles are on-topic. This led to 1,090 liberal articles and 1,002 conservative articles. 4 Media Frames Extraction We are interested in both the issue and entity frames that"
2021.findings-emnlp.82,N19-1216,0,0.0354747,"Missing"
2021.findings-emnlp.82,P13-1035,0,0.0502274,"Missing"
2021.findings-emnlp.82,P15-2072,0,0.0164428,"’s race. While the left-leaning article highlights a quote from the Edwards’ pastor, an unofficial source, the right-center article cites only official sources (namely the Chief of Police). Both mention the victim’s age and unarmed status. Schuldt et al., 2011) and policy decisions (Baumgartner et al., 2008; Dardis et al., 2008). Prior work has revealed an abundance of politically effective framing devices (Bryan et al., 2011; Gentzkow and Shapiro, 2010; Price et al., 2005; Rugg, 1941; Schuldt et al., 2011), some of which have been operationalized and measured at scale using methods from NLP (Card et al., 2015; Demszky et al., 2019; Field et al., 2018; Greene and 1 Resnik, 2009; Recasens et al., 2013; Tsur et al., Data and code available at: https://github.com/ GT-SALT/framing-police-violence 2015). While these works extensively cover issue 957 Findings of the Association for Computational Linguistics: EMNLP 2021, pages 957–976 November 7–11, 2021. ©2021 Association for Computational Linguistics frames in broad topics of political debate (e.g. immigration), they overlook a wide array of entity frames (how an individual is represented; e.g. a particular undocumented worker described as lazy), and th"
2021.findings-emnlp.82,D18-1393,0,0.0776676,"ighlights a quote from the Edwards’ pastor, an unofficial source, the right-center article cites only official sources (namely the Chief of Police). Both mention the victim’s age and unarmed status. Schuldt et al., 2011) and policy decisions (Baumgartner et al., 2008; Dardis et al., 2008). Prior work has revealed an abundance of politically effective framing devices (Bryan et al., 2011; Gentzkow and Shapiro, 2010; Price et al., 2005; Rugg, 1941; Schuldt et al., 2011), some of which have been operationalized and measured at scale using methods from NLP (Card et al., 2015; Demszky et al., 2019; Field et al., 2018; Greene and 1 Resnik, 2009; Recasens et al., 2013; Tsur et al., Data and code available at: https://github.com/ GT-SALT/framing-police-violence 2015). While these works extensively cover issue 957 Findings of the Association for Computational Linguistics: EMNLP 2021, pages 957–976 November 7–11, 2021. ©2021 Association for Computational Linguistics frames in broad topics of political debate (e.g. immigration), they overlook a wide array of entity frames (how an individual is represented; e.g. a particular undocumented worker described as lazy), and these can have huge policy implications for"
2021.findings-emnlp.82,P19-1243,0,0.0113613,"o identify personas or clusters of ings are correlated with an increase in systemic co-occurring verbs and adjective modifiers (Card and racial framing, and that increased protest ac- et al., 2016; Bamman et al., 2013; Iyyer et al., tivity Granger-causes or precedes media attention 2016; Joseph et al., 2017). Another line of work 958 Figure 2: Construction process of P OLICE V IOLENCE F RAME C ORPUS. combined psychology lexicons with distributional methods to measure implicit differences in power, sentiment, and agency attributed to male and female entities in news and film (Sap et al., 2017; Field and Tsvetkov, 2019; Field et al., 2019). Social scientists have experimentally manipulated framing devices related to police violence, including law and order, police brutality, or racial stereotypes, revealing dramatic effects on participants’ perceptions of police shootings (Fridell, 2017; Dukes and Gaither, 2017; Porter et al., 2018). Criminologists have trained coders to manually annotate on the order of 100 news articles for framing devices relevant to police use of force (Hirschfield and Simon, 2010; Ash et al., 2019). While these studies provide great theoretical insight, their manual coding schemes and"
2021.findings-emnlp.82,P14-1105,0,0.0377011,"Missing"
2021.findings-emnlp.82,N16-1180,0,0.0255391,"Missing"
2021.findings-emnlp.82,W17-2913,0,0.0366578,"ion for Computational Linguistics frames in broad topics of political debate (e.g. immigration), they overlook a wide array of entity frames (how an individual is represented; e.g. a particular undocumented worker described as lazy), and these can have huge policy implications for target populations (Schneider and Ingram, 1993). towards the victim’s race and unarmed status. 2 Related Work A large body of related work in NLP focuses on detecting stance, ideology, or political leaning (Baly et al., 2020; Bamman and Smith, 2015; Iyyer et al., In this paper, we introduce an NLP framework to 2014; Johnson et al., 2017; Preo¸tiuc-Pietro et al., understand entity framing and its relation to issue 2017; Luo et al., 2020a; Stefanov et al., 2020). framing in political news. As a case study, we conWhile we show a relationship between framing and sider news coverage of police violence. Though we political leaning, we argue that frames are often choose this domain for the stark contrast between more subtle than overt expressions of stance, and two readily-discernible entities (police and victim), cognitively more salient than other stylistic differour framing measures can also be applied to other ences in the lang"
2021.findings-emnlp.82,D17-1163,0,0.0675118,"Missing"
2021.findings-emnlp.82,P13-1162,0,0.0377675,"unofficial source, the right-center article cites only official sources (namely the Chief of Police). Both mention the victim’s age and unarmed status. Schuldt et al., 2011) and policy decisions (Baumgartner et al., 2008; Dardis et al., 2008). Prior work has revealed an abundance of politically effective framing devices (Bryan et al., 2011; Gentzkow and Shapiro, 2010; Price et al., 2005; Rugg, 1941; Schuldt et al., 2011), some of which have been operationalized and measured at scale using methods from NLP (Card et al., 2015; Demszky et al., 2019; Field et al., 2018; Greene and 1 Resnik, 2009; Recasens et al., 2013; Tsur et al., Data and code available at: https://github.com/ GT-SALT/framing-police-violence 2015). While these works extensively cover issue 957 Findings of the Association for Computational Linguistics: EMNLP 2021, pages 957–976 November 7–11, 2021. ©2021 Association for Computational Linguistics frames in broad topics of political debate (e.g. immigration), they overlook a wide array of entity frames (how an individual is represented; e.g. a particular undocumented worker described as lazy), and these can have huge policy implications for target populations (Schneider and Ingram, 1993). t"
2021.findings-emnlp.82,W19-1305,0,0.015683,"ions Theory (Haidt and Graham, 2007) (MFT) is a framework for understanding universal values that underlie human judgments of right and wrong. These values form five dichotomous pairs: care/harm, fairness/cheating, loyalty/betrayal, authority/subversion, and purity/degradation. While MFT is rooted in psychology, it has since been applied in political science to differentiate liberal and conservative thought Graham et al. (2009). We quantify the moral foundations that media invoke to frame the virtues or vices of the officer and the victim in a given report using the extended MFT dictionary of Rezapour et al. (2019). Legal Language. Similar to Ash et al. (2019), we investigate frames which emphasize legal out- 4.4 Linguistic Style comes for police conduct. To capture this frame, To supplement our understanding of overtly topical we used a public lexicon of legal terms from the entity and issue frames, we investigate two relevant Administrative Office of the U.S. Courts 2021. linguistic structures: passive verbs and modals. Official and Unofficial Sources. Many news Passive Constructions. Prior works identify accounts favor official reports which frame police framing effects that arise from passive phrase"
2021.findings-emnlp.82,2020.emnlp-main.620,0,0.0585966,"Missing"
2021.findings-emnlp.82,D17-1247,0,0.0286974,"- vised approach to identify personas or clusters of ings are correlated with an increase in systemic co-occurring verbs and adjective modifiers (Card and racial framing, and that increased protest ac- et al., 2016; Bamman et al., 2013; Iyyer et al., tivity Granger-causes or precedes media attention 2016; Joseph et al., 2017). Another line of work 958 Figure 2: Construction process of P OLICE V IOLENCE F RAME C ORPUS. combined psychology lexicons with distributional methods to measure implicit differences in power, sentiment, and agency attributed to male and female entities in news and film (Sap et al., 2017; Field and Tsvetkov, 2019; Field et al., 2019). Social scientists have experimentally manipulated framing devices related to police violence, including law and order, police brutality, or racial stereotypes, revealing dramatic effects on participants’ perceptions of police shootings (Fridell, 2017; Dukes and Gaither, 2017; Porter et al., 2018). Criminologists have trained coders to manually annotate on the order of 100 news articles for framing devices relevant to police use of force (Hirschfield and Simon, 2010; Ash et al., 2019). While these studies provide great theoretical insight, their"
2021.gem-1.10,2020.acl-main.424,0,0.0251404,"les WebNLG (Gardent et al., 2017) Produce a text that verbalises the input triples in a grammatical and natural way. en/ru 50k RDF triple en 594k Sentence Dataset CommonGEN (Lin et al., 2020) Communicative Goal Language(s) Produce a likely sentence which mentions en all of the source concepts. Czech Restaurant (Dušek and Jurˇcíˇcek, 2019) Produce a text expressing the given intent and covering the specified attributes. DART (Radev et al., 2020) WikiAuto + Turk/ASSET Communicate the same information as (Jiang et al., 2020) the source sentence using simpler words (Xu et al., 2016) and grammar. (Alva-Manchego et al., 2020) WikiLingua (Ladhak et al., 2020) *ar/cs/de/en Produce high quality summaries of an es/fr/hi/id/it *550k instructional article. ja/ko/nl/pt/ru th/tr/vi/zh Article Table 1: A description of all the datasets included in GEM. The tasks vary in communicative goal, data size, and input type. * indicates changes from the originally published dataset made for GEM. (NLU) tasks. They aggregate multiple tasks under a unified evaluation framework, which enables researchers to fairly compare their models to others. Due to the improved model comparability, benchmarks are critical in measuring modeling prog"
2021.gem-1.10,2020.acl-main.766,0,0.0426234,"sh datasets were ranked lower, with only WebNLG and MLSum among the top 15 datasets. We grouped all datasets by their high-level tasks and selected a group that would not violate the selection principles (e.g., only high-resource tasks). If two datasets fit, we picked the one with a higher interest rating. Among the 11 datasets, we have 18different languages, and the dataset sizes range from 5,000 examples to 1.5M, with most datasets between 50-150k examples. Two of them do not include English at all, which we hope reduces the dependence of the modeling approaches on anglocentric pretraining (Anastasopoulos and Neubig, 2020). The high-level tasks include Dialog, Summarization, Data-to-Text, and Simplification. About half of the datasets have multiple references and more than half had post-processing steps applied to them to ensure high data quality. 3.1 GEMifying the data We produce data cards (Bender and Friedman, 2018; Gebru et al., 2018) for all data sets in GEM, for which we developed an NLG-specific template.7 In addition to describing the data itself, the cards acknowledge potential limitations of a dataset regarding its creation process and describe its real-world use cases to ensure that the research is c"
2021.gem-1.10,W05-0909,0,0.165721,"otebook within 2-3 hours. 4.2 avoid overfitting to known metrics, we will use metrics on the test submissions that are not included in this initial writeup. Consequentially, the baseline results are an incomplete list which will be expanded upon the announcement of the test metrics. The set of metrics can be computed via the framework described at https://gem-benchmark. com/shared_task which comprises metrics in the following categories: Lexical Similarity. We include multiple “traditional” metrics as baseline metrics, notably BLEU (Papineni et al., 2002), ROUGE-1/2/L (Lin, 2004), and METEOR (Banerjee and Lavie, 2005). These metrics can often be gamed, for example, ROUGE can be improved by increased the output length of the model (Sun et al., 2019). Moreover, the reliability of these metrics depends on the quality and number of the references (Mathur et al., 2020a; Freitag et al., 2020). However, on a system-level, they still correlate well with human judgments for some tasks (Reiter, 2018). Automated Evaluation As mentioned above, GEM provides a testbed for automated metrics and can be used to popularize newly developed ones. Thus, models are evaluated via a constantly expanding list of metrics and, to 10"
2021.gem-1.10,W11-2832,0,0.0915033,"Missing"
2021.gem-1.10,2020.inlg-1.24,1,0.864971,"human evaluation standards. In recent work, Howcroft et al. (2020) investigated NLG papers from the last 2 For a more complete description of recent developments in NLG evaluation, we refer to the survey by Celikyilmaz et al. (2020). 99 twenty years and the evaluation methodologies differ drastically across papers. Moreover, in most cases, it is not even mentioned what the human evaluation aims to measure and that definitions of measures like “accuracy” or “fluency” are inconsistent. They thus suggest reporting standards for criteria and methods, following a classification system proposed by Belz et al. (2020). In addition, regularly scheduled shared tasks like WMT have lead to standardization of human evaluation setups and enabled controlled experimentation with them. GEM has the opportunity to develop reproducible standards for how human evaluation for NLG tasks beyond translation should be conducted while at the same time incorporating lessons from related work. Acting on the same need, the recently proposed GENIE (Khashabi et al., 2021) system aims to automate and standardize the human evaluation of different NLG systems, however with the contrasting goal of reducing the evaluating to a leaderb"
2021.gem-1.10,Q18-1041,0,0.236179,"han half were post-processed to improve data quality. The sizes range from 5k to 500k data points. GEM features 18 languages across all tasks and two of the datasets do not include English at all. To be able to properly assess the performance of models in a way robust to the shortcuts a model can take, we additionally introduce ten types of challenging test sets that probe for specific modeling aspects (Perez-Beltrachini and Gardent, 2017; Ribeiro et al., 2020). To ensure that research with GEM is conducted responsibly, all the datasets are documented in an NLG-specific version of data cards (Bender and Friedman, 2018; Gebru et al., 2018) we developed and for which we release a template and guide. Moreover, all submitted models will have an associated data card (Mitchell et al., 2019). This paper describes the selection and construction of the GEM datasets in support of the announcement of the shared task at ACL 2021. More detailed information can be found on our website https://gem-benchmark.com/. We propose a living benchmark called GEM (Generation, Evaluation, and Metrics) that aims to enable research on a wide range of NLG challenges. To avoid the fallacy of encouraging hill climbing on a leaderboard ("
2021.gem-1.10,W17-4755,0,0.0383891,"Missing"
2021.gem-1.10,W16-2302,0,0.0489314,"Missing"
2021.gem-1.10,N18-2097,0,0.0498492,"Missing"
2021.gem-1.10,N19-1423,0,0.0210653,"provides a testbed for automated metrics and can be used to popularize newly developed ones. Thus, models are evaluated via a constantly expanding list of metrics and, to 104 Semantic Equivalence. More recently, metrics that rely on pretrained language models have shown improved correlations with human judgments on the segment-level. We thus include BERTScore (Zhang et al., 2020b), a metric based on the similarity of sentence embeddings, and BLEURT (Sellam et al., 2020), a metric that is fine-tuned on human ratings. The reported baseline results use RoBERTa-large (Liu et al., 2019) and mBERT (Devlin et al., 2019) for BERTScore and the English-only BLEURT-base-128 for BLEURT. Probing for Faithfulness. Another approach that has shown promise in summarization. The approach relies on the insight that a reader of a reference and generated summary should be able to answer the same question, regardless of how the summary is phrased. There has been much development toward these QA-based approaches (Eyal et al., 2019; Scialom et al., 2019; Durmus et al., 2020; Wang et al., 2020, among others) and they can provide an alternative angle to model evaluation that does not highly correlate with other evaluation appr"
2021.gem-1.10,P19-1483,1,0.811795,"tions. 106 Figure 2: A screenshot of the interactive result exploration tool. [Top Left] The selection of tasks, task-groups, or individual submissions. [Top Right] The selection of metric-groups or metrics [Bottom] The parallel coordinates visualization of the selection. The selection here can be filtered by brushing over a section of an individual metric, as is shown here for BLEURT. Hovering over a line presents detailed information of the particular submission. grained and interpretable evaluation metrics, for example to measure consistency in data-to-text problems (Opitz and Frank, 2020; Dhingra et al., 2019). We are using one such metric called NUBIA (Kane et al., 2020), the NeUral Based Interchangeability Assessor, which combines multiple measures such as entailment and similarity into a decomposable and interpretable score. Diversity. As argued by Hashimoto et al. (2019) among many others, NLG models intrinsically trade off diversity and quality. A model can produce more diverse outputs through sampling but at the cost of output quality. To account for this aspect, we compute multiple diversity metrics, starting with those proposed for the analysis of the results of the E2E NLG challenge (Dusek"
2021.gem-1.10,K19-1037,0,0.027404,"Missing"
2021.gem-1.10,P17-1123,0,0.0287395,"Missing"
2021.gem-1.10,2020.acl-main.454,1,0.84177,"LEURT (Sellam et al., 2020), a metric that is fine-tuned on human ratings. The reported baseline results use RoBERTa-large (Liu et al., 2019) and mBERT (Devlin et al., 2019) for BERTScore and the English-only BLEURT-base-128 for BLEURT. Probing for Faithfulness. Another approach that has shown promise in summarization. The approach relies on the insight that a reader of a reference and generated summary should be able to answer the same question, regardless of how the summary is phrased. There has been much development toward these QA-based approaches (Eyal et al., 2019; Scialom et al., 2019; Durmus et al., 2020; Wang et al., 2020, among others) and they can provide an alternative angle to model evaluation that does not highly correlate with other evaluation approaches (Fabbri et al., 2020). While most related work on these metrics is limited to summarization, we are evaluating systems using a QA-based method called QuestEval (Scialom et al., 2021) that supports all of our tasks. In addition to QA-based evaluation, there have also been related efforts to develop more fineMetrics (Lexical Similarity and Semantic Equivalence) Dataset Model METEOR ROUGE-1 ROUGE-2 ROUGE-L BLEU BERTScore BLEURT CommonGen"
2021.gem-1.10,W19-8652,1,0.897973,"Missing"
2021.gem-1.10,C16-1191,0,0.0653297,"Missing"
2021.gem-1.10,P18-1082,0,0.0705277,"Missing"
2021.gem-1.10,W16-3622,1,0.897392,"Missing"
2021.gem-1.10,P16-2008,1,0.869379,"Missing"
2021.gem-1.10,W19-8670,1,0.884454,"Missing"
2021.gem-1.10,2020.emnlp-main.393,0,0.179031,"le to be able to address newly found limitations, and that the benchmark should focus on climbing a leaderboard. Instead, a living benchmark that can adjust its datasets and specific evaluation metrics can be much more powerful and long-lived. This can, for example, be seen in Dynabench,1 (Potts et al., 2020) which has a static evaluation, but interactively adds more test However, they also pose a risk that progress is reduced to the single number shown in a benchmark’s leaderboard and thus may encourage blindly optimizing it without regard to other considerations like model size or fairness (Ethayarajh and Jurafsky, 2020). This is especially challenging for benchmarks in NLG since, as discussed above, the performance cannot be described through a single metric and it is often not clear what metric to optimize for. This shortfall can be seen in benchmarks like DecaNLP (McCann et al., 2018) and GLGE (Liu et al., 2020a) which include NLG tasks but focus only on a single metric and, as a result, may mischaracterize a system’s performance. Moreover, an easy-to-use data infrastructure also disincentivizes researchers from interacting with 1 98 https://dynabench.org/ data through a human-in-the-loop approach. able mu"
2021.gem-1.10,N19-1395,0,0.0587235,"Missing"
2021.gem-1.10,2020.emnlp-main.751,0,0.503468,"nly on NLG can enProviding a testbed for automated evaluation. Most traditional automated metrics, such as ROUGE (Lin, 2004) and BLEU (Papineni et al., 2002), measure the n-gram overlap between a reference and the generated text. However, in most cases, there is more than one correct way to generate a text, especially in tasks with a latent content planning or selection step (Reiter and Dale, 2000). That means that a correct solution may score low on a metric. While multiple references alleviate the issue somewhat, these metrics still have a low correlation with human judgments (Reiter, 2018; Fabbri et al., 2020). To address the issue, the machine translation community has been organizing yearly metrics shared tasks which produce metrics that achieve a high correlation (Stanojevi´c et al., 2015; Bojar et al., 2016, 2017; Ma et al., 2018, 2019; Mathur et al., 2020b). The latest metrics focus on semantic equivalence instead of lexical similarity, which improves the correlations drastically. However, recent work by Fabbri et al. (2020) demonstrates that this may not hold in summarization, where the automated metric BERTScore (Zhang et al., 2020b) does not improve upon the correlation of ROUGE. Moreover,"
2021.gem-1.10,P19-1346,1,0.897232,"Missing"
2021.gem-1.10,2020.webnlg-1.7,1,0.843551,"Missing"
2021.gem-1.10,2020.findings-emnlp.195,1,0.835947,"Missing"
2021.gem-1.10,2020.emnlp-main.5,0,0.126308,"e machine translation community has been organizing yearly metrics shared tasks which produce metrics that achieve a high correlation (Stanojevi´c et al., 2015; Bojar et al., 2016, 2017; Ma et al., 2018, 2019; Mathur et al., 2020b). The latest metrics focus on semantic equivalence instead of lexical similarity, which improves the correlations drastically. However, recent work by Fabbri et al. (2020) demonstrates that this may not hold in summarization, where the automated metric BERTScore (Zhang et al., 2020b) does not improve upon the correlation of ROUGE. Moreover, Mathur et al. (2020a) and Freitag et al. (2020) find that when comparing two high-quality systems, differences according to a metric may also stem from how references are written or flaws in the metric itself.2 Given that automated metrics perform differently across tasks, setups, and languages, a multi-task NLG benchmark has the opportunity to act as a testbed to evaluate how the latest advances in automated metrics perform on these different tasks. The benchmark can facilitate this research through the release of system outputs and associated human annotations, which is what we are planning to do with GEM. Moreover, we allow the integrat"
2021.gem-1.10,2020.emnlp-main.489,0,0.0422168,"les 3 and 4. Our interactive system is centered around a parallel coordinates plot (Inselberg, 1985) which shows all results as lines through parallel axes. Every line intersects the axes at the corresponding mapped value. For instance, see the red line representing the results for task “ToTTo” of baseline “t5-small”. Filters can be applied along axes (see BLEURT axis in Figure 2) and the filtered selection is highlighted through bold lines. A selection can be a set of metrics, systems, or tasks. This style of presentation has not been used before for a benchmark. The closest prior work is by Fu et al. (2020) for namedentity recognition which allows similar filtering and sorting, but presents the results in a table. However, the parallel coordinates approach can scale to a much greater number of metrics than a table. Moreover, by using a parallel coordinates plot instead of a table, it is easy to spot patterns that span multiple metrics, systems, or tasks. For example, the highlighted line in Figure 2 uncovers that, for the T5 baseline on ToTTo, the diversity metrics score higher than other systems while scoring lower on reference-based metrics. Since we only have a single baseline for ToTTo, it i"
2021.gem-1.10,W17-3518,1,0.863605,"Missing"
2021.gem-1.10,N19-1169,1,0.923485,"eiter and Dale, 2000). These texts aim to fulfill an underlying communicative goal (e.g., to produce a summary of an article) while remaining faithful to the input information, fluent, grammatical, and natural-looking. An NLG system needs to be robust to shifts in the data distribution and be able to produce text in many different languages. Finally, it is often desired that repeated interactions with the model produce diverse outputs, for example, to explain concepts in multiple ways or to become a more interesting conversational agent. These optimization objectives can often be conflicting (Hashimoto et al., 2019) and, as a result, evaluations that focus only on a single aspect may fail to recognize the drawbacks of a particular method. To demonstrate this trade-off, consider an improvement on the CNN-DM summarization dataset (Hermann et al., 2015; Nallapati et al., 2016) measured by the ROUGE-L metWe introduce GEM, a living benchmark for natural language Generation (NLG), its Evaluation, and Metrics. Measuring progress in NLG relies on a constantly evolving ecosystem of automated metrics, datasets, and human evaluation standards. Due to this moving target, new models often still evaluate on divergent"
2021.gem-1.10,2020.ngt-1.1,0,0.0253511,"first steps toward including NLG tasks in multilingual NLU benchmarks. For example, XGLUE includes Question and News Title Generation (Liang et al., 2020). Unfortunately, XGLUE reduces the generation evaluation to BLEU-4, a metric that is inadequate for NLG (Reiter, 2018). There have also been multiple shared tasks in NLG that focus on multilingualism, for instance, the shared task on multilingual surface realization which includes eleven languages (Mille et al., 2018, 2019, 2020). The shared task on document-level generation and translation featured German and English generation challenges (Heafield et al., 2020). The WebNLG+ shared task asked participants to contribute models that can realize text in Russian and English (Ferreira et al., 2020). A benchmark that focuses only on NLG can enProviding a testbed for automated evaluation. Most traditional automated metrics, such as ROUGE (Lin, 2004) and BLEU (Papineni et al., 2002), measure the n-gram overlap between a reference and the generated text. However, in most cases, there is more than one correct way to generate a text, especially in tasks with a latent content planning or selection step (Reiter and Dale, 2000). That means that a correct solution"
2021.gem-1.10,2020.inlg-1.23,1,0.841029,"Missing"
2021.gem-1.10,D15-1229,0,0.0462438,"Missing"
2021.gem-1.10,2020.acl-main.709,1,0.887061,"Missing"
2021.gem-1.10,2020.acl-main.560,0,0.077305,"on does not consider differences between the languages that lead to higher modeling complexity, for example, a richer morphology or a flexible word-order. Still, the majority of work in NLP and almost all benchmarks exclusively focus on English (e.g., Wang et al., 2019b; Liu et al., 2020a; McCann et al., 2018). Even if multiple languages are considered, the availability of data in a language often does not represent the number of speakers of a language. This means that work on languages with little available data can potentially impact many more people than work on highly resourced languages (Joshi et al., 2020). As a result, many recent benchmarking and dataset creation efforts in NLU develop and focus on tasks that are inherently multilingual or which explore cross-lingual transfer. For example, XTREME (Hu et al., 2020) introduces a benchmark covering 40 languages across multiple NLU and retrieval tasks, XCOPA (Ponti et al., 2020) is a commonsense reasoning dataset for eleven languages, and MLQA (Lewis et al., 2020b) is a dataset for extractive question answering across seven languages. We can observe a similar recent trend in natural language generation, where MLSum (Scialom et al., 2020) and Wiki"
2021.gem-1.10,2020.evalnlgeval-1.4,0,0.0163557,"ation tool. [Top Left] The selection of tasks, task-groups, or individual submissions. [Top Right] The selection of metric-groups or metrics [Bottom] The parallel coordinates visualization of the selection. The selection here can be filtered by brushing over a section of an individual metric, as is shown here for BLEURT. Hovering over a line presents detailed information of the particular submission. grained and interpretable evaluation metrics, for example to measure consistency in data-to-text problems (Opitz and Frank, 2020; Dhingra et al., 2019). We are using one such metric called NUBIA (Kane et al., 2020), the NeUral Based Interchangeability Assessor, which combines multiple measures such as entailment and similarity into a decomposable and interpretable score. Diversity. As argued by Hashimoto et al. (2019) among many others, NLG models intrinsically trade off diversity and quality. A model can produce more diverse outputs through sampling but at the cost of output quality. To account for this aspect, we compute multiple diversity metrics, starting with those proposed for the analysis of the results of the E2E NLG challenge (Dusek et al., 2020) and by van Miltenburg et al. (2018). These inclu"
2021.gem-1.10,D18-1208,0,0.0650198,"Missing"
2021.gem-1.10,Q18-1023,0,0.0642232,"Missing"
2021.gem-1.10,2020.findings-emnlp.360,1,0.934785,"e a text that verbalises the input triples in a grammatical and natural way. en/ru 50k RDF triple en 594k Sentence Dataset CommonGEN (Lin et al., 2020) Communicative Goal Language(s) Produce a likely sentence which mentions en all of the source concepts. Czech Restaurant (Dušek and Jurˇcíˇcek, 2019) Produce a text expressing the given intent and covering the specified attributes. DART (Radev et al., 2020) WikiAuto + Turk/ASSET Communicate the same information as (Jiang et al., 2020) the source sentence using simpler words (Xu et al., 2016) and grammar. (Alva-Manchego et al., 2020) WikiLingua (Ladhak et al., 2020) *ar/cs/de/en Produce high quality summaries of an es/fr/hi/id/it *550k instructional article. ja/ko/nl/pt/ru th/tr/vi/zh Article Table 1: A description of all the datasets included in GEM. The tasks vary in communicative goal, data size, and input type. * indicates changes from the originally published dataset made for GEM. (NLU) tasks. They aggregate multiple tasks under a unified evaluation framework, which enables researchers to fairly compare their models to others. Due to the improved model comparability, benchmarks are critical in measuring modeling progress. and conducting in-depth ana"
2021.gem-1.10,D16-1128,0,0.0680679,"Missing"
2021.gem-1.10,2020.acl-main.703,0,0.214186,"esent the number of speakers of a language. This means that work on languages with little available data can potentially impact many more people than work on highly resourced languages (Joshi et al., 2020). As a result, many recent benchmarking and dataset creation efforts in NLU develop and focus on tasks that are inherently multilingual or which explore cross-lingual transfer. For example, XTREME (Hu et al., 2020) introduces a benchmark covering 40 languages across multiple NLU and retrieval tasks, XCOPA (Ponti et al., 2020) is a commonsense reasoning dataset for eleven languages, and MLQA (Lewis et al., 2020b) is a dataset for extractive question answering across seven languages. We can observe a similar recent trend in natural language generation, where MLSum (Scialom et al., 2020) and WikiLingua (Ladhak et al., 2020) were created as multilingual summarization datasets. There also have been first steps toward including NLG tasks in multilingual NLU benchmarks. For example, XGLUE includes Question and News Title Generation (Liang et al., 2020). Unfortunately, XGLUE reduces the generation evaluation to BLEU-4, a metric that is inadequate for NLG (Reiter, 2018). There have also been multiple shared"
2021.gem-1.10,2020.acl-main.653,0,0.233553,"esent the number of speakers of a language. This means that work on languages with little available data can potentially impact many more people than work on highly resourced languages (Joshi et al., 2020). As a result, many recent benchmarking and dataset creation efforts in NLU develop and focus on tasks that are inherently multilingual or which explore cross-lingual transfer. For example, XTREME (Hu et al., 2020) introduces a benchmark covering 40 languages across multiple NLU and retrieval tasks, XCOPA (Ponti et al., 2020) is a commonsense reasoning dataset for eleven languages, and MLQA (Lewis et al., 2020b) is a dataset for extractive question answering across seven languages. We can observe a similar recent trend in natural language generation, where MLSum (Scialom et al., 2020) and WikiLingua (Ladhak et al., 2020) were created as multilingual summarization datasets. There also have been first steps toward including NLG tasks in multilingual NLU benchmarks. For example, XGLUE includes Question and News Title Generation (Liang et al., 2020). Unfortunately, XGLUE reduces the generation evaluation to BLEU-4, a metric that is inadequate for NLG (Reiter, 2018). There have also been multiple shared"
2021.gem-1.10,N16-1014,0,0.0410993,"t at the cost of output quality. To account for this aspect, we compute multiple diversity metrics, starting with those proposed for the analysis of the results of the E2E NLG challenge (Dusek et al., 2020) and by van Miltenburg et al. (2018). These include the Shannon Entropy (Shannon and Weaver, 1963) over unigrams and bigrams (H1 , H2 ), the mean segmented type token ratio over segment lengths of 100 (MSTTR, Johnson, 1944), the ratio of distinct n-grams over the total number of n-grams (Distinct1,2 ), and the count of n-grams that only appear once across the entire test output (Unique1,2 , Li et al., 2016). focus of this section will be on qualitative descriptions through model cards, we also gather quantitative information that is not necessarily associated with a judgment. As part of this, we collect the number of parameters of a system, as suggested by Ethayarajh and Jurafsky (2020). For each task, we additionally report the vocabulary size over the output (|V|) and the mean output length of a system (Sun et al., 2019). 5 Results One of the central aims of GEM is to measure the progress in NLG without misrepresenting the complex interactions between the sometimes contradicting measures. We t"
2021.gem-1.10,2020.findings-emnlp.165,0,0.0883829,"Missing"
2021.gem-1.10,W04-1013,0,0.355472,"n be tested. Regular updates to the benchmark will help NLG research become more multilingual and evolve the challenge alongside models. This paper serves as the description of the data for which we are organizing a shared task at our ACL 2021 Workshop and to which we invite the entire NLG community to participate. * Correspondence to gehrmann@google.com 96 Proceedings of the 1st Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2021), pages 96–120 August 5–6, 2021. ©2021 Association for Computational Linguistics Varying experimental setups Evaluation on “solved” data ric (Lin, 2004). Since ROUGE only tests the extent to which a generated summary has a lexical overlap with a reference summary, it can erroneously produce high scores for fluent, yet meaningless and unfaithful outputs as long as many of the same words are used (Maynez et al., 2020; Gabriel et al., 2020). Moreover, ROUGE tends to favor systems that produce longer summaries (Sun et al., 2019). It is thus crucial to carefully assess the progress of NLG toward all of its goals at the same time in ways that evolve alongside the models. This is currently not the case; new models are evaluated on different datasets"
2021.gem-1.10,2020.acl-main.465,0,0.123121,"; Gebru et al., 2018) we developed and for which we release a template and guide. Moreover, all submitted models will have an associated data card (Mitchell et al., 2019). This paper describes the selection and construction of the GEM datasets in support of the announcement of the shared task at ACL 2021. More detailed information can be found on our website https://gem-benchmark.com/. We propose a living benchmark called GEM (Generation, Evaluation, and Metrics) that aims to enable research on a wide range of NLG challenges. To avoid the fallacy of encouraging hill climbing on a leaderboard (Linzen, 2020), GEM focuses on an in-depth evaluation of model outputs across human and automatic evaluation that aims to uncover shortcomings and opportunities for progress. As datasets, metrics, and models improve, the benchmark environment will improve as well, replacing “solved” tasks with more challenging ones, incorporating newly developed metrics, and addressing discovered flaws in the experimental setup, as demonstrated in Figure 1. Making all model outputs available under an open-source license will support evaluation research and integrating new metrics will, in turn, help their adoption and incre"
2021.gem-1.10,2020.tacl-1.47,0,0.129414,"ich has a static evaluation, but interactively adds more test However, they also pose a risk that progress is reduced to the single number shown in a benchmark’s leaderboard and thus may encourage blindly optimizing it without regard to other considerations like model size or fairness (Ethayarajh and Jurafsky, 2020). This is especially challenging for benchmarks in NLG since, as discussed above, the performance cannot be described through a single metric and it is often not clear what metric to optimize for. This shortfall can be seen in benchmarks like DecaNLP (McCann et al., 2018) and GLGE (Liu et al., 2020a) which include NLG tasks but focus only on a single metric and, as a result, may mischaracterize a system’s performance. Moreover, an easy-to-use data infrastructure also disincentivizes researchers from interacting with 1 98 https://dynabench.org/ data through a human-in-the-loop approach. able much richer evaluation (as described in the next sections), and promote non-English datasets. In addition, it can ensure that the datasets created for those shared tasks continue being evaluated. Increasing multilingualism of NLG research. Another potentially harmful choice by benchmark creators is t"
2021.gem-1.10,2021.ccl-1.108,0,0.0502233,"Missing"
2021.gem-1.10,W15-4640,0,0.0777152,"Missing"
2021.gem-1.10,W18-6450,0,0.0170006,"ever, in most cases, there is more than one correct way to generate a text, especially in tasks with a latent content planning or selection step (Reiter and Dale, 2000). That means that a correct solution may score low on a metric. While multiple references alleviate the issue somewhat, these metrics still have a low correlation with human judgments (Reiter, 2018; Fabbri et al., 2020). To address the issue, the machine translation community has been organizing yearly metrics shared tasks which produce metrics that achieve a high correlation (Stanojevi´c et al., 2015; Bojar et al., 2016, 2017; Ma et al., 2018, 2019; Mathur et al., 2020b). The latest metrics focus on semantic equivalence instead of lexical similarity, which improves the correlations drastically. However, recent work by Fabbri et al. (2020) demonstrates that this may not hold in summarization, where the automated metric BERTScore (Zhang et al., 2020b) does not improve upon the correlation of ROUGE. Moreover, Mathur et al. (2020a) and Freitag et al. (2020) find that when comparing two high-quality systems, differences according to a metric may also stem from how references are written or flaws in the metric itself.2 Given that automa"
2021.gem-1.10,W19-5302,0,0.0535855,"Missing"
2021.gem-1.10,2020.coling-main.420,0,0.022745,"s many of the same words are used (Maynez et al., 2020; Gabriel et al., 2020). Moreover, ROUGE tends to favor systems that produce longer summaries (Sun et al., 2019). It is thus crucial to carefully assess the progress of NLG toward all of its goals at the same time in ways that evolve alongside the models. This is currently not the case; new models are evaluated on different datasets, most of which focus only on the English language (Bender, 2019), and using these flawed metrics. Moreover, while human evaluations of generated texts can provide complementary insights to automatic evaluation (Manning et al., 2020), it can also lead to contradicting results since studies often omit crucial replication details and assume different definitions of the measured quantities (Howcroft et al., 2020). Improving Data Improving Metrics Evaluation with gameable metrics Improving Models Consistent Human Eval Non-repeatable human evaluation Figure 1: The opportunities of living benchmarks and pitfalls of evaluation. As models improve, we need consistent evaluations such that models can be compared to each other. This can only happen if we develop robust human evaluation standards and improve our automated metrics. Ot"
2021.gem-1.10,2020.acl-main.448,0,0.212993,"ere is more than one correct way to generate a text, especially in tasks with a latent content planning or selection step (Reiter and Dale, 2000). That means that a correct solution may score low on a metric. While multiple references alleviate the issue somewhat, these metrics still have a low correlation with human judgments (Reiter, 2018; Fabbri et al., 2020). To address the issue, the machine translation community has been organizing yearly metrics shared tasks which produce metrics that achieve a high correlation (Stanojevi´c et al., 2015; Bojar et al., 2016, 2017; Ma et al., 2018, 2019; Mathur et al., 2020b). The latest metrics focus on semantic equivalence instead of lexical similarity, which improves the correlations drastically. However, recent work by Fabbri et al. (2020) demonstrates that this may not hold in summarization, where the automated metric BERTScore (Zhang et al., 2020b) does not improve upon the correlation of ROUGE. Moreover, Mathur et al. (2020a) and Freitag et al. (2020) find that when comparing two high-quality systems, differences according to a metric may also stem from how references are written or flaws in the metric itself.2 Given that automated metrics perform differe"
2021.gem-1.10,2020.wmt-1.77,0,0.124839,"ere is more than one correct way to generate a text, especially in tasks with a latent content planning or selection step (Reiter and Dale, 2000). That means that a correct solution may score low on a metric. While multiple references alleviate the issue somewhat, these metrics still have a low correlation with human judgments (Reiter, 2018; Fabbri et al., 2020). To address the issue, the machine translation community has been organizing yearly metrics shared tasks which produce metrics that achieve a high correlation (Stanojevi´c et al., 2015; Bojar et al., 2016, 2017; Ma et al., 2018, 2019; Mathur et al., 2020b). The latest metrics focus on semantic equivalence instead of lexical similarity, which improves the correlations drastically. However, recent work by Fabbri et al. (2020) demonstrates that this may not hold in summarization, where the automated metric BERTScore (Zhang et al., 2020b) does not improve upon the correlation of ROUGE. Moreover, Mathur et al. (2020a) and Freitag et al. (2020) find that when comparing two high-quality systems, differences according to a metric may also stem from how references are written or flaws in the metric itself.2 Given that automated metrics perform differe"
2021.gem-1.10,2020.acl-main.173,1,0.838186,"to which we invite the entire NLG community to participate. * Correspondence to gehrmann@google.com 96 Proceedings of the 1st Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2021), pages 96–120 August 5–6, 2021. ©2021 Association for Computational Linguistics Varying experimental setups Evaluation on “solved” data ric (Lin, 2004). Since ROUGE only tests the extent to which a generated summary has a lexical overlap with a reference summary, it can erroneously produce high scores for fluent, yet meaningless and unfaithful outputs as long as many of the same words are used (Maynez et al., 2020; Gabriel et al., 2020). Moreover, ROUGE tends to favor systems that produce longer summaries (Sun et al., 2019). It is thus crucial to carefully assess the progress of NLG toward all of its goals at the same time in ways that evolve alongside the models. This is currently not the case; new models are evaluated on different datasets, most of which focus only on the English language (Bender, 2019), and using these flawed metrics. Moreover, while human evaluations of generated texts can provide complementary insights to automatic evaluation (Manning et al., 2020), it can also lead to contradicti"
2021.gem-1.10,W18-3601,1,0.834682,"where MLSum (Scialom et al., 2020) and WikiLingua (Ladhak et al., 2020) were created as multilingual summarization datasets. There also have been first steps toward including NLG tasks in multilingual NLU benchmarks. For example, XGLUE includes Question and News Title Generation (Liang et al., 2020). Unfortunately, XGLUE reduces the generation evaluation to BLEU-4, a metric that is inadequate for NLG (Reiter, 2018). There have also been multiple shared tasks in NLG that focus on multilingualism, for instance, the shared task on multilingual surface realization which includes eleven languages (Mille et al., 2018, 2019, 2020). The shared task on document-level generation and translation featured German and English generation challenges (Heafield et al., 2020). The WebNLG+ shared task asked participants to contribute models that can realize text in Russian and English (Ferreira et al., 2020). A benchmark that focuses only on NLG can enProviding a testbed for automated evaluation. Most traditional automated metrics, such as ROUGE (Lin, 2004) and BLEU (Papineni et al., 2002), measure the n-gram overlap between a reference and the generated text. However, in most cases, there is more than one correct way"
2021.gem-1.10,2020.msr-1.1,1,0.821875,"Missing"
2021.gem-1.10,C18-1147,1,0.871186,"Missing"
2021.gem-1.10,2020.emnlp-main.466,0,0.0504036,"Missing"
2021.gem-1.10,D15-1238,0,0.013053,"d this goal, GEM welcomes anyone interested in collaborating on this effort. 7.2 Personalizing and Controlling NLG GEM currently focuses on tasks that deterministically transform an input into an output. With the increasing use of NLG models in real-world applications, how to enable and evaluate personalized NLG systems (e.g., in dialect or formality) remains challenging. Several related tasks have been proposed, for example, the transfer of writing style from informal to formal (Rao and Tetreault, 2018), personalization of machine translation systems to align with particular personal traits (Mirkin and Meunier, 2015), or persona-guided response generation of dialogue systems (Zhang et al., 2018). We envision our framework to be extended (e.g., dataset, evaluation) to incorporate this line of userfocused NLG. 7.3 Regular updates to the living benchmark To activate the benefits of a living benchmark that is focused on evaluation, we commit to regular updates for GEM. We invite contributions in the form of model outputs, analyses, and metrics at any time and will automatically update the results presented on our website to incorporate them. For the updates to the dataset selection, we want to consider the in"
2021.gem-1.10,K16-1028,0,0.065799,"Missing"
2021.gem-1.10,D18-1206,1,0.894493,"Missing"
2021.gem-1.10,W17-5525,1,0.880333,"Missing"
2021.gem-1.10,P02-1040,0,0.114424,"n NLG that focus on multilingualism, for instance, the shared task on multilingual surface realization which includes eleven languages (Mille et al., 2018, 2019, 2020). The shared task on document-level generation and translation featured German and English generation challenges (Heafield et al., 2020). The WebNLG+ shared task asked participants to contribute models that can realize text in Russian and English (Ferreira et al., 2020). A benchmark that focuses only on NLG can enProviding a testbed for automated evaluation. Most traditional automated metrics, such as ROUGE (Lin, 2004) and BLEU (Papineni et al., 2002), measure the n-gram overlap between a reference and the generated text. However, in most cases, there is more than one correct way to generate a text, especially in tasks with a latent content planning or selection step (Reiter and Dale, 2000). That means that a correct solution may score low on a metric. While multiple references alleviate the issue somewhat, these metrics still have a low correlation with human judgments (Reiter, 2018; Fabbri et al., 2020). To address the issue, the machine translation community has been organizing yearly metrics shared tasks which produce metrics that achi"
2021.gem-1.10,2020.emnlp-main.89,1,0.895725,"Missing"
2021.gem-1.10,W17-3537,1,0.910798,"trics saturate, we need to evaluate them on more challenging datasets instead of continuing to move sideways on old ones. GEM aims to provide this environment for natural language generation. than half were post-processed to improve data quality. The sizes range from 5k to 500k data points. GEM features 18 languages across all tasks and two of the datasets do not include English at all. To be able to properly assess the performance of models in a way robust to the shortcuts a model can take, we additionally introduce ten types of challenging test sets that probe for specific modeling aspects (Perez-Beltrachini and Gardent, 2017; Ribeiro et al., 2020). To ensure that research with GEM is conducted responsibly, all the datasets are documented in an NLG-specific version of data cards (Bender and Friedman, 2018; Gebru et al., 2018) we developed and for which we release a template and guide. Moreover, all submitted models will have an associated data card (Mitchell et al., 2019). This paper describes the selection and construction of the GEM datasets in support of the announcement of the shared task at ACL 2021. More detailed information can be found on our website https://gem-benchmark.com/. We propose a living benchmar"
2021.gem-1.10,2020.emnlp-main.185,0,0.0484252,"Missing"
2021.gem-1.10,2021.acl-long.186,0,0.0851423,"Missing"
2021.gem-1.10,P19-1195,0,0.0585453,"Missing"
2021.gem-1.10,N18-1012,0,0.0173282,"akers of low-resourced languages through a participatory research approach, as suggested by (∀ et al., 2020). Toward this goal, GEM welcomes anyone interested in collaborating on this effort. 7.2 Personalizing and Controlling NLG GEM currently focuses on tasks that deterministically transform an input into an output. With the increasing use of NLG models in real-world applications, how to enable and evaluate personalized NLG systems (e.g., in dialect or formality) remains challenging. Several related tasks have been proposed, for example, the transfer of writing style from informal to formal (Rao and Tetreault, 2018), personalization of machine translation systems to align with particular personal traits (Mirkin and Meunier, 2015), or persona-guided response generation of dialogue systems (Zhang et al., 2018). We envision our framework to be extended (e.g., dataset, evaluation) to incorporate this line of userfocused NLG. 7.3 Regular updates to the living benchmark To activate the benefits of a living benchmark that is focused on evaluation, we commit to regular updates for GEM. We invite contributions in the form of model outputs, analyses, and metrics at any time and will automatically update the result"
2021.gem-1.10,Q19-1016,0,0.0583227,"Missing"
2021.gem-1.10,J18-3002,0,0.0872491,"for eleven languages, and MLQA (Lewis et al., 2020b) is a dataset for extractive question answering across seven languages. We can observe a similar recent trend in natural language generation, where MLSum (Scialom et al., 2020) and WikiLingua (Ladhak et al., 2020) were created as multilingual summarization datasets. There also have been first steps toward including NLG tasks in multilingual NLU benchmarks. For example, XGLUE includes Question and News Title Generation (Liang et al., 2020). Unfortunately, XGLUE reduces the generation evaluation to BLEU-4, a metric that is inadequate for NLG (Reiter, 2018). There have also been multiple shared tasks in NLG that focus on multilingualism, for instance, the shared task on multilingual surface realization which includes eleven languages (Mille et al., 2018, 2019, 2020). The shared task on document-level generation and translation featured German and English generation challenges (Heafield et al., 2020). The WebNLG+ shared task asked participants to contribute models that can realize text in Russian and English (Ferreira et al., 2020). A benchmark that focuses only on NLG can enProviding a testbed for automated evaluation. Most traditional automated"
2021.gem-1.10,2020.acl-main.442,0,0.137138,"hem on more challenging datasets instead of continuing to move sideways on old ones. GEM aims to provide this environment for natural language generation. than half were post-processed to improve data quality. The sizes range from 5k to 500k data points. GEM features 18 languages across all tasks and two of the datasets do not include English at all. To be able to properly assess the performance of models in a way robust to the shortcuts a model can take, we additionally introduce ten types of challenging test sets that probe for specific modeling aspects (Perez-Beltrachini and Gardent, 2017; Ribeiro et al., 2020). To ensure that research with GEM is conducted responsibly, all the datasets are documented in an NLG-specific version of data cards (Bender and Friedman, 2018; Gebru et al., 2018) we developed and for which we release a template and guide. Moreover, all submitted models will have an associated data card (Mitchell et al., 2019). This paper describes the selection and construction of the GEM datasets in support of the announcement of the shared task at ACL 2021. More detailed information can be found on our website https://gem-benchmark.com/. We propose a living benchmark called GEM (Generatio"
2021.gem-1.10,2020.emnlp-main.647,0,0.0370713,"Missing"
2021.gem-1.10,2021.emnlp-main.529,0,0.024648,"on the insight that a reader of a reference and generated summary should be able to answer the same question, regardless of how the summary is phrased. There has been much development toward these QA-based approaches (Eyal et al., 2019; Scialom et al., 2019; Durmus et al., 2020; Wang et al., 2020, among others) and they can provide an alternative angle to model evaluation that does not highly correlate with other evaluation approaches (Fabbri et al., 2020). While most related work on these metrics is limited to summarization, we are evaluating systems using a QA-based method called QuestEval (Scialom et al., 2021) that supports all of our tasks. In addition to QA-based evaluation, there have also been related efforts to develop more fineMetrics (Lexical Similarity and Semantic Equivalence) Dataset Model METEOR ROUGE-1 ROUGE-2 ROUGE-L BLEU BERTScore BLEURT CommonGen BART T5 0.301 0.291 63.5 64.0 32.5 29.4 55.1 54.5 27.5 26.4 0.943 0.942 -0.400 -0.412 mT5-small mT5-base mT5-large mT5-XL TGen TGen+ TGen++ 0.229 0.23 0.233 0.229 0.152 0.151 0.167 47.3 48.1 51.3 52.1 13.6 13.8 9.7 28.6 28.8 30.0 31.3 0.0 0.0 0.0 43.0 44.2 46.4 47.3 13.6 13.8 9.7 17.9 17.1 17.5 17.0 0.03 0.03 0.03 0.895 0.898 0.902 0.905 0.6"
2021.gem-1.10,D19-1320,0,0.0210218,"ence embeddings, and BLEURT (Sellam et al., 2020), a metric that is fine-tuned on human ratings. The reported baseline results use RoBERTa-large (Liu et al., 2019) and mBERT (Devlin et al., 2019) for BERTScore and the English-only BLEURT-base-128 for BLEURT. Probing for Faithfulness. Another approach that has shown promise in summarization. The approach relies on the insight that a reader of a reference and generated summary should be able to answer the same question, regardless of how the summary is phrased. There has been much development toward these QA-based approaches (Eyal et al., 2019; Scialom et al., 2019; Durmus et al., 2020; Wang et al., 2020, among others) and they can provide an alternative angle to model evaluation that does not highly correlate with other evaluation approaches (Fabbri et al., 2020). While most related work on these metrics is limited to summarization, we are evaluating systems using a QA-based method called QuestEval (Scialom et al., 2021) that supports all of our tasks. In addition to QA-based evaluation, there have also been related efforts to develop more fineMetrics (Lexical Similarity and Semantic Equivalence) Dataset Model METEOR ROUGE-1 ROUGE-2 ROUGE-L BLEU BERTSc"
2021.gem-1.10,2020.acl-main.704,1,0.824209,"er, on a system-level, they still correlate well with human judgments for some tasks (Reiter, 2018). Automated Evaluation As mentioned above, GEM provides a testbed for automated metrics and can be used to popularize newly developed ones. Thus, models are evaluated via a constantly expanding list of metrics and, to 104 Semantic Equivalence. More recently, metrics that rely on pretrained language models have shown improved correlations with human judgments on the segment-level. We thus include BERTScore (Zhang et al., 2020b), a metric based on the similarity of sentence embeddings, and BLEURT (Sellam et al., 2020), a metric that is fine-tuned on human ratings. The reported baseline results use RoBERTa-large (Liu et al., 2019) and mBERT (Devlin et al., 2019) for BERTScore and the English-only BLEURT-base-128 for BLEURT. Probing for Faithfulness. Another approach that has shown promise in summarization. The approach relies on the insight that a reader of a reference and generated summary should be able to answer the same question, regardless of how the summary is phrased. There has been much development toward these QA-based approaches (Eyal et al., 2019; Scialom et al., 2019; Durmus et al., 2020; Wang e"
2021.gem-1.10,P19-1212,0,0.0526263,"Missing"
2021.gem-1.10,P19-1646,0,0.0614703,"Missing"
2021.gem-1.10,Q16-1029,1,0.821779,"in a news article en *25k Articles WebNLG (Gardent et al., 2017) Produce a text that verbalises the input triples in a grammatical and natural way. en/ru 50k RDF triple en 594k Sentence Dataset CommonGEN (Lin et al., 2020) Communicative Goal Language(s) Produce a likely sentence which mentions en all of the source concepts. Czech Restaurant (Dušek and Jurˇcíˇcek, 2019) Produce a text expressing the given intent and covering the specified attributes. DART (Radev et al., 2020) WikiAuto + Turk/ASSET Communicate the same information as (Jiang et al., 2020) the source sentence using simpler words (Xu et al., 2016) and grammar. (Alva-Manchego et al., 2020) WikiLingua (Ladhak et al., 2020) *ar/cs/de/en Produce high quality summaries of an es/fr/hi/id/it *550k instructional article. ja/ko/nl/pt/ru th/tr/vi/zh Article Table 1: A description of all the datasets included in GEM. The tasks vary in communicative goal, data size, and input type. * indicates changes from the originally published dataset made for GEM. (NLU) tasks. They aggregate multiple tasks under a unified evaluation framework, which enables researchers to fairly compare their models to others. Due to the improved model comparability, benchmar"
2021.gem-1.10,W15-3031,0,0.06329,"Missing"
2021.gem-1.10,W19-2303,0,0.167787,"of the 1st Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2021), pages 96–120 August 5–6, 2021. ©2021 Association for Computational Linguistics Varying experimental setups Evaluation on “solved” data ric (Lin, 2004). Since ROUGE only tests the extent to which a generated summary has a lexical overlap with a reference summary, it can erroneously produce high scores for fluent, yet meaningless and unfaithful outputs as long as many of the same words are used (Maynez et al., 2020; Gabriel et al., 2020). Moreover, ROUGE tends to favor systems that produce longer summaries (Sun et al., 2019). It is thus crucial to carefully assess the progress of NLG toward all of its goals at the same time in ways that evolve alongside the models. This is currently not the case; new models are evaluated on different datasets, most of which focus only on the English language (Bender, 2019), and using these flawed metrics. Moreover, while human evaluations of generated texts can provide complementary insights to automatic evaluation (Manning et al., 2020), it can also lead to contradicting results since studies often omit crucial replication details and assume different definitions of the measured"
2021.gem-1.10,2020.nlp4convai-1.13,0,0.0861626,"Missing"
2021.gem-1.10,D16-1033,0,0.064867,"Missing"
2021.gem-1.10,2020.acl-main.450,0,0.015505,"2020), a metric that is fine-tuned on human ratings. The reported baseline results use RoBERTa-large (Liu et al., 2019) and mBERT (Devlin et al., 2019) for BERTScore and the English-only BLEURT-base-128 for BLEURT. Probing for Faithfulness. Another approach that has shown promise in summarization. The approach relies on the insight that a reader of a reference and generated summary should be able to answer the same question, regardless of how the summary is phrased. There has been much development toward these QA-based approaches (Eyal et al., 2019; Scialom et al., 2019; Durmus et al., 2020; Wang et al., 2020, among others) and they can provide an alternative angle to model evaluation that does not highly correlate with other evaluation approaches (Fabbri et al., 2020). While most related work on these metrics is limited to summarization, we are evaluating systems using a QA-based method called QuestEval (Scialom et al., 2021) that supports all of our tasks. In addition to QA-based evaluation, there have also been related efforts to develop more fineMetrics (Lexical Similarity and Semantic Equivalence) Dataset Model METEOR ROUGE-1 ROUGE-2 ROUGE-L BLEU BERTScore BLEURT CommonGen BART T5 0.301 0.291"
2021.gem-1.10,P18-1205,0,0.0245839,"nalizing and Controlling NLG GEM currently focuses on tasks that deterministically transform an input into an output. With the increasing use of NLG models in real-world applications, how to enable and evaluate personalized NLG systems (e.g., in dialect or formality) remains challenging. Several related tasks have been proposed, for example, the transfer of writing style from informal to formal (Rao and Tetreault, 2018), personalization of machine translation systems to align with particular personal traits (Mirkin and Meunier, 2015), or persona-guided response generation of dialogue systems (Zhang et al., 2018). We envision our framework to be extended (e.g., dataset, evaluation) to incorporate this line of userfocused NLG. 7.3 Regular updates to the living benchmark To activate the benefits of a living benchmark that is focused on evaluation, we commit to regular updates for GEM. We invite contributions in the form of model outputs, analyses, and metrics at any time and will automatically update the results presented on our website to incorporate them. For the updates to the dataset selection, we want to consider the input of the wider NLG research community. To do so, we will set up a yearly selec"
2021.gem-1.5,2020.acl-main.568,0,0.0362031,"th traditional generation methods for personalized response generation. R1 X R2 X R3 X G(r1 ,r2 ,r3 ) A(i,r1 ) B(j,r2 ) C(k,r3 ) r1 =1 r2 =1 r3 =1 Evaluation Metrics for Personalized Response Generation Current automatic evaluation metrics for response generation can be broadly categorized into three classes. (1) Content relatedness measures how related a generated response is with its corresponding ground-truth, with representative metrics such as BLEU (Papineni et al., 2002), NIST (Doddington, 2002), and METEOR (Lavie and Agarwal, 2007). Speaker sensitive responses evaluation model (SSREM) (Bak and Oh, 2020) enhances the relatedness score with a context-response classifier. (2) Language quality mainly refers to the fluency and diversity, where the former is measured via perplexity (Chen et al., 1998) and the latter is assessed via distinct diversity (Li et al., 2015; Yang et al., 2020) that indicates how diverse the generated responses are. (3) Style adherence aims to evaluate the adherence of the generated responses’ language style to the user’s own language style; example metrics include the average negative log-likelihood (NLL) of one poet’s generated lyrics on it’s poet specific language mode"
2021.gem-1.5,P16-1094,0,0.38511,"self-reports from users themselves (Stone et al., 1999). Although such explicit personalization information is often unavailable, content that users produce is generally ubiquitous and can indicate their preferences, personal information, styles, and knowledge in a relatively implicit but objective manner. Our work thus utilizes these posts and comments users made to learn latent representations of their personalization information. Different generation models have been designed to learn user personalization information and further impose such representation on text generation. For instance, Li et al. 2016 proposed the Speaker model based on Seq2Seq framework by introducing trainable speaker embedding for each user and feeding it to decoder at each step of decoding. However, there are always a large number of distinct users and users often participate in only a few conversations; as a result, the speaker embedding may be under-fitted given the limited data points associated with a user. Another line of research uses generative memory network (Zhang et al., 2018), Personalized response generation is essential for more human-like conversations. However, how to model user personalization informati"
2021.gem-1.5,P18-1082,0,0.0302018,"d decoder have 2 LSTM layers with hidden size of 512, while DialoGPT+TF model is based on the pre-trained medium DialoGPT model with hidden size of 1024. Any word appears more than three times were included in the vocabulary of Seq2Seq-based+TF models, and the size of the vocabulary is 30K. DialoGPT+TF model uses the pre-trained Byte-Pair-Encoding (BPE) tokenizer of size 50,257. The λ coefficient in Eq. 1 is set to 0.2. Adam (Kingma and Ba, 2014) is used as the optimizer and the learning rate was set to 1e-3 for TF-Speaker model and 1e-5 for TF-DialoGPT by grid search. Top-k (k = 2) sampling (Fan et al., 2018) was used without any re-scoring techniques to generate response at test stage. We selected models with the highest average Per-Hits@k (k = 1, 2, 3, 4, 5) on validation set. 5.4 Evaluation Metrics We evaluated different models with F1, BLEU, Distinct-N, perplexity (PPL), and our proposed PerHits@k. Here, F1 (Dinan et al., 2019) refers to the harmonic mean of precision and recall computed based on the tokens between generated and ground truth response. BLEU (Papineni et al., 2002) was first proposed for machine translation but is also widely used for evaluating response generation. Distinct-N ("
2021.gem-1.5,P13-2121,0,0.0156772,"r model are shown in Table 3. We found that both History and TF-u initialization improved Per-Hits@k over Random to some extent, suggesting that our TF module has learned some degree of user personalization in its user factor matrix U. Although TF-u had smaller Per-Hits@k improvement over Random, History+TF-u has the best Per-Hits@k, indicating that the personalization information learned by TF module is different to that from users’ posting history. Robustness of Personalization Metric To test the robustness of our Per-Hits@k metric, we trained trigram language models with the KenLM toolkit (Heafield et al., 2013) for the user specific language models used in Per-Hits@k. While GPT-2 is a transformer-based language model pretrained on large corpus and can be fine-tuned on each user’s corpus, KenLM is impossible to follow this approach because it can only be trained in an end-to-end way, i.e. language models of KenLM is directly trained on each user’s corpus. Thus we had two Per-Hits@k variants: Per-Hits@k-GPT2 (the one we used in previous sections) and Per-Hits@kKenLM. We evaluated Per-Hits@k-GPT2 and PerHits@k-KenLM for all the models we trained with different settings and plot all (Per-Hits@k-KenLM, P"
2021.gem-1.5,P02-1040,0,0.110147,"p, we propose to learn latent representation of personalized user information from users’ posts and model personalization jointly together with traditional generation methods for personalized response generation. R1 X R2 X R3 X G(r1 ,r2 ,r3 ) A(i,r1 ) B(j,r2 ) C(k,r3 ) r1 =1 r2 =1 r3 =1 Evaluation Metrics for Personalized Response Generation Current automatic evaluation metrics for response generation can be broadly categorized into three classes. (1) Content relatedness measures how related a generated response is with its corresponding ground-truth, with representative metrics such as BLEU (Papineni et al., 2002), NIST (Doddington, 2002), and METEOR (Lavie and Agarwal, 2007). Speaker sensitive responses evaluation model (SSREM) (Bak and Oh, 2020) enhances the relatedness score with a context-response classifier. (2) Language quality mainly refers to the fluency and diversity, where the former is measured via perplexity (Chen et al., 1998) and the latter is assessed via distinct diversity (Li et al., 2015; Yang et al., 2020) that indicates how diverse the generated responses are. (3) Style adherence aims to evaluate the adherence of the generated responses’ language style to the user’s own language sty"
2021.gem-1.5,E17-1101,0,0.0231089,"in them together in an end-to-end fashion. Evaluating response generation usually considers content relatedness and language quality to ensure that generated text is grammatically correct and fluent, using BLEU and Perplexity. However, evaluating personalization in personalized response generation is relatively challenging as there lacks effective metrics. 2 Related Work Personalized Response Generation Personalization has received much attention in the natural language processing community, such as personalized image captioning (Chunseong Park et al., 2017), personalized machine translation (Rabinovich et al., 2017), personalized response generation (Li et al., 2016), personalized intent classification and personalized slot tagging (Liu et al., 2016). Prior studies formulate the task of response generation as generating an output given an input text, mainly based on either the sequence-to-sequence (Seq2Seq) models (Vinyals and Le, 2015) or the pretrained models like GPT-2 (Radford et al., 2019) and BART (Lewis et al., 2019). When it comes to personalized response generation, Speaker model (Li et al., 2016) extended traditional response generation models by assigning each user with a trainable speaker ID"
2021.gem-1.5,W07-0734,0,0.0465401,"user information from users’ posts and model personalization jointly together with traditional generation methods for personalized response generation. R1 X R2 X R3 X G(r1 ,r2 ,r3 ) A(i,r1 ) B(j,r2 ) C(k,r3 ) r1 =1 r2 =1 r3 =1 Evaluation Metrics for Personalized Response Generation Current automatic evaluation metrics for response generation can be broadly categorized into three classes. (1) Content relatedness measures how related a generated response is with its corresponding ground-truth, with representative metrics such as BLEU (Papineni et al., 2002), NIST (Doddington, 2002), and METEOR (Lavie and Agarwal, 2007). Speaker sensitive responses evaluation model (SSREM) (Bak and Oh, 2020) enhances the relatedness score with a context-response classifier. (2) Language quality mainly refers to the fluency and diversity, where the former is measured via perplexity (Chen et al., 1998) and the latter is assessed via distinct diversity (Li et al., 2015; Yang et al., 2020) that indicates how diverse the generated responses are. (3) Style adherence aims to evaluate the adherence of the generated responses’ language style to the user’s own language style; example metrics include the average negative log-likelihood"
2021.gem-1.5,2020.acl-main.703,0,0.0293449,"Missing"
2021.gem-1.5,2020.emnlp-main.365,0,0.0372293,"Missing"
2021.gem-1.5,P18-1205,0,0.408474,"odels have been designed to learn user personalization information and further impose such representation on text generation. For instance, Li et al. 2016 proposed the Speaker model based on Seq2Seq framework by introducing trainable speaker embedding for each user and feeding it to decoder at each step of decoding. However, there are always a large number of distinct users and users often participate in only a few conversations; as a result, the speaker embedding may be under-fitted given the limited data points associated with a user. Another line of research uses generative memory network (Zhang et al., 2018), Personalized response generation is essential for more human-like conversations. However, how to model user personalization information with no explicit user persona descriptions or demographics still remains underinvestigated. To tackle the data sparsity problem and the huge number of users, we utilize tensor factorization to model users’ personalization information with their posting histories. Specifically, we introduce the personalized response embedding for all questionuser pairs and form them into a three-mode tensor, decomposed by Tucker decomposition. The personalized response embedd"
2021.gem-1.5,2020.acl-demos.30,0,0.206568,"idden vector of decoder at time step t is: hdt = g(hdt−1 , cdt−1 , yt∗ ), where g is the LSTM cell operation and yt∗ is the embedding of the input token at time step t. Standard Seq2Seq models are not personalized, because there is no mechanism to incorporate userspecific information into their input. Speaker Model (Li et al., 2016) alleviates this by explicitly concatenating a trainable speaker embedding vj to yt∗ for user j. Therefore, the hidden vector of decoder of Speaker model at time step t is: hdt = g(hdt−1 , cdt−1 , [yt∗ ; vj ]), 3.3 Preliminaries Transformer Language Model DialoGPT (Zhang et al., 2020) is a pre-trained conversational response generation model. Based on the architecture of GPT-2 (Radford et al., 2019), DialoGPT is trained on 147M Reddit discussions. For a question-user pair (i, j) with source input S and target response T , DialogGPT generates responses by modeling the conditional probability: Tucker Decomposition To learn latent association between users, questions and responses for personalized response generation, we choose Tucker decomposition, one widely used tensor factorization algorithm. Tucker decomposition (Tucker, 1966) decomposes a given 3-mode tensor X ∈ RI×J×K"
2021.gem-1.5,2021.naacl-main.157,1,0.869755,", 2016). Our models were based on the aforementioned baseline models by further incorporating our proposed TF module, i.e., the personalized response embedding from the TF module. DialoGPT+TF is a DialoGPT model with personalized response embedding added to each time step at the decoding stage shown in Figure 2. Seq2Seq+TF, Speaker+TF, Memory+TF, MemDataset To study the task of personalized response generation with no explicit personalization information, we used a personalized Reddit dataset PERCHAT, consisting of 200,156 responses that users posted to different questions, from r/AskReddit1 (Wu et al., 2021). Building upon Wu et al. (2021), we used active users who joined more than average discussions, and popular questions that received more comments. This led to 4724 users under 39,187 questions. These users and questions were sampled because they were active users who joined more discussions or popular questions that received more comments. We filtered all forms of url links, emails and digits into unique tokens “url”, “email” and “digit”. Replicated words and punctuation were processed to their standard forms. We sampled 3 responses for each user for users in the validation and test set, and"
2021.gem-1.5,2020.emnlp-main.113,1,0.738848,"egorized into three classes. (1) Content relatedness measures how related a generated response is with its corresponding ground-truth, with representative metrics such as BLEU (Papineni et al., 2002), NIST (Doddington, 2002), and METEOR (Lavie and Agarwal, 2007). Speaker sensitive responses evaluation model (SSREM) (Bak and Oh, 2020) enhances the relatedness score with a context-response classifier. (2) Language quality mainly refers to the fluency and diversity, where the former is measured via perplexity (Chen et al., 1998) and the latter is assessed via distinct diversity (Li et al., 2015; Yang et al., 2020) that indicates how diverse the generated responses are. (3) Style adherence aims to evaluate the adherence of the generated responses’ language style to the user’s own language style; example metrics include the average negative log-likelihood (NLL) of one poet’s generated lyrics on it’s poet specific language model (Vechtomova et al., 2018), stylistic alignment (Syed et al., 2020) that looks at the language style alignment at the surface, lexical and syntactic level, and Hits@1/N (Dinan et al., 2019) that measures how accurate the generated response can be classified to its corresponding use"
2021.hcinlp-1.8,D16-1258,0,0.0579601,"For instance, Wallace et al. (2019) invites crowd workers to generate adversarial questions that can fool their QA system, and use these questions for adversarial training. Offline feedback loop can be more robust for dialogue systems, because user feedback can be misleading so directly updating the model is risky (Kreutzer et al., 2020). Parsing and Entity Linking Besides classifying documents, recent research shows great potential of HITL approach in enhancing the performance of existing parsing and entity linking models. Advancing traditional Combinatory Categorial Grammars (CCG) parsers, He et al. (2016) crowdsource parsing tasks—a trained parser is uncertain about—to non-expert mechanical turks, by asking them simple what-questions. Also, with more strategic sampling methods to select instances to present to humans, a smaller set of feedback can quickly improve the entity linking model performance (Klie et al., 2020). 2.3 Summarization and Machine Translation Topic Modeling In addition to use HITL approach to enhancing learning low-level semantic relationships, researcher apply similar framework to topic modeling techniques that are used to analyze large document collections (Lee et al., 201"
2021.hcinlp-1.8,D19-3020,0,0.128888,"on Data Augmentation – Online Model Update Data Augmentation – Offline Model Update UPDATE Intelligent Interaction User Feedback Type – Counterfactual Example User Feedback Type – Natural Language User Feedback Type – Scaled User Feedback Type – Binary Mediums – Natural Language Interface INTERACTION Mediums – Graphical User Interface Usability Model Interpretability Model Performance Dialogue and Question Answering System GOAL Summarization and Machine Translation Topic Modeling Parsing and Entity Linking Work Text Classification TASK Godbole et al. (2004) Settles (2011) Simard et al. (2014) Karmakharm et al. (2019) Jandot et al. (2016) Kaushik et al. (2019) He et al. (2016) Klie et al. (2020) Lo and Lim (2020) Trivedi et al. (2019) Lawrence and Riezler (2018) Kim et al. (2019) Kumar et al. (2019) Smith et al. (2018) Stiennon et al. (2020) Kreutzer et al. (2018) Hancock et al. (2019) Liu et al. (2018) Li et al. (2017) Wallace et al. (2019) Table 1: Overview of representative works in HITL NLP. Each row represents one work. Works are sorted by their task types. Each column corresponds to a dimension from the four subsections (task, goal, human interaction, and feedback learning methods). 3.1 and generaliz"
2021.hcinlp-1.8,P18-1255,0,0.0597902,"Missing"
2021.hcinlp-1.8,2020.evalnlgeval-1.2,1,0.70693,"Also, some frameworks use Latent Dirichlet Allocation (LDA) to adjust sampling parameters with collected feedback in incremental iterations (Smith et al., 2018). 4.2 inconsistent, incorrect, or even misleading. Therefore, better interface design and rigorous user study to evaluate interfaces can greatly enhance the quality of feedback collection, which in turn improve the downstream task performance. To shed light on HITL NLP research from a HCI perspective, Wallace et al. (2019) explore the effect of adding model interpretation cues in the HITL interface on the quality of collected feedback; Schoch et al. (2020) investigate the impacts of question framing imposed on humans; similarly, Rao and Daum´e III (2018) study how to ask good questions to which humans are more likely to give helpful feedback. In particular, we recommend future researchers to (1) consider integrating interactive visualization techniques into human-machine interfaces; (2) conduct user study to evaluate the effectiveness of their HITL system in addition to model performance; (3) share collected human feedback data and user study protocols with the community. Model Direct Manipulation Collected numerical human feedback are usually"
2021.hcinlp-1.8,D11-1136,0,0.4438,"this section, we categorize surveyed HITL paradigms based on their corresponding tasks. 2.1 Text Classification Text classification is a classic NLP task to categorize text into different groups. Many HITL frameworks are developed for this problem, where most of them start with training a text classifier, then recruiting humans to annotate data based on the current model behavior, and eventually retraining the classifier on the larger dataset continuously. For example, Godbole et al. (2004) develop a HITL paradigm where users can interactively edit text features and label new documents. Also, Settles (2011) integrates active learning in their framework—instead of arbitrarily presenting data for users to annotate, samples are selected in a way that maximizes the expected information gain. With active learning, labelers can annotate fewer data to achieve the same model improvement of a framework using random sampling. 2.2 2.4 HITL can be used in text summarization and machine translation. For instance, Stiennon et al. (2020) collects human preferences on pairs of summaries generated by two models, then train a reward model to predict the preference. Then, this reward model is used to train a polic"
2021.hcinlp-1.8,2020.acl-main.624,0,0.0323867,"Missing"
2021.hcinlp-1.8,P19-1637,0,0.0250675,"immediate, so they are suitable for noisy feedback with complex models which takes extra processing and training time. For example, Simard et al. (2014) and Karmakharm et al. (2019) use human feedback as new class labels and span-level annotations, and retrain their models after collecting enough new data. Online Model Update is applied right after user feedback is given. This is effective for dialogue systems and conversational QA systems where recent input is crucial to machine’s reasoning (Li et al., 2017). Incremental learning technique is often used to learn augmented data in real-time (Kumar et al., 2019). It focuses on making an incremental change to current system using the newly come feedback information effectively. Interactive topic modeling systems and feature engineering systems widely use this technique. For example, 50 Kim et al. (2019) incrementally updates topic hierarchy by extending or shrinking topic tree incrementally. Also, some frameworks use Latent Dirichlet Allocation (LDA) to adjust sampling parameters with collected feedback in incremental iterations (Smith et al., 2018). 4.2 inconsistent, incorrect, or even misleading. Therefore, better interface design and rigorous user"
2021.hcinlp-1.8,Q19-1029,0,0.0572114,"t loop. 1 Model Selection Model Training Evaluation Deployment Figure 1: Collaboration between humans and models under a human-in-the-loop Natural Language Processing paradigm. Humans provide various types of feedback in different stages of the workflow to improve the model’s performance, interpretability, and usability. AI partnership that enhance model performance and build users’ trust in the NLP system. Just like traditional NLP frameworks, there is a high-dimensional design space for HITL NLP systems. For example, human feedback can come from end users (Li et al., 2017) or crowd workers (Wallace et al., 2019), and human can intervene models during training (Stiennon et al., 2020) or deployment (Hancock et al., 2019). Good HITL NLP systems need to clearly communicate to humans of what the model needs, provide intuitive interfaces to collect feedback, and effectively learn from them. Therefore, HITL NLP research spans across not only NLP and Machine Learning (ML) but also Human-computer Interaction (HCI). A meta-analysis on existing HITL NLP work focusing on bridging different research disciplines is vital to help new researchers quickly familiarize with this promising topic and recognize future res"
2021.hcinlp-1.8,N18-1187,0,0.297666,"nd implicit language human feedback to improve a machine translation model by using the feedback with reinforcement learning. Experiments show that these models have higher accuracy and better generalization. 2.5 Dialogue and Question Answering Recently, many HITL frameworks have been developed for dialogue and Question Answering (QA) systems, where the AI agent can have conversation with users. We can group these systems into two categories: online feedback loop and offline feedback loop. With online feedback loop, the system continuously uses human feedback to update the model. For example, Liu et al. (2018) collects dialogue corrections from users during deployment, and then use online reinforcement learning to improve the model. With offline feedback loop, model is updated after collecting a large set of human feedback. For instance, Wallace et al. (2019) invites crowd workers to generate adversarial questions that can fool their QA system, and use these questions for adversarial training. Offline feedback loop can be more robust for dialogue systems, because user feedback can be misleading so directly updating the model is risky (Kreutzer et al., 2020). Parsing and Entity Linking Besides class"
2021.naacl-main.109,D19-5409,0,0.250489,"tion triples (“WHO DOING - WHAT ”) in utterances through structured graphs to better encode conversations, and then designing a multi-granularity decoder to generate summaries by combining all levels of information. Experiments show that our proposed models outperform state-of-theart methods and generalize well in other domains in terms of both automatic evaluations and human judgments. We have publicly released our code at https://github.com/ GT-SALT/Structure-Aware-BART. 1 Introduction Figure 1: An example of discourse relation graph (a) and action graph (b) from one conversation in SAMSum (Gliwa et al., 2019). The annotated summary is Simon was on the phone before, so he didn’t here Helen calling. Simon will fetch Helen some tissues. Online interaction has become an indispensable component of everyday life and people are increasingly using textual conversations to exchange ideas, make plans, and share information. However, it is time-consuming to recap and grasp all the core content within every complex conversation (Gao et al., a set of inherent differences between conversations 2020; Feng et al., 2020). As a result, how to or- and documents (Gliwa et al., 2019). First, speaker ganize massive eve"
2021.naacl-main.109,2020.acl-main.457,0,0.26134,"atural, interruptions like repetitions, false-starts, and hesiconcise, and informative text, i.e., abstractive con- tations are frequent in conversations (Sacks et al., versation summarization, starts to gain importance. 1978), and key information resides in different porSignificant progress has been made on abstrac- tions of a conversation. These unstructured propertive summarization for structured document via ties pose challenges for models to focus on salient pointer generator (See et al., 2017), reinforcement contents that are necessary for generating both abmethods (Paulus et al., 2018; Huang et al., 2020a) stractive and informative summaries. Second, there and pre-trained models (Liu and Lapata, 2019; is more than one speaker in conversations and peoLewis et al., 2020; Zhang et al., 2019). Despite the ple interact with each other in different language huge success, it is challenging to directly apply doc- styles (Zhu et al., 2020b). The complex interactions ument models to summarize conversations, due to among multiple speakers make it harder for mod1380 Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologi"
2021.naacl-main.109,P17-4012,0,0.0142087,"i,0:l } and getting the utterance-attended represen• Pointer Generator (See et al., 2017): We foltation xU , multi-granularity decoder then conducts D A lowed the settings in Gliwa et al. (2019) and cross attentions over nodes {h0:m } and {h0:n } that used special tokens to separate each utterance. are encoded from graph encoders in parallel, to D obtain the discourse-attended representation x • Transformer (Vaswani et al., 2017): We and action-attended representation xA . These two trained transformer seq2seq models followattended vectors are then combined into a structureS ing the OpenNMT (Klein et al., 2017). aware representation x , through a feed-forward network for further forward passing in the decoder. To alleviate the negative impact of randomly • D-HGN (Feng et al., 2020) incorporated cominitialized graph encoders and cross attentions monsense knowledge from ConceptNet (Liu over graphs on pre-trained BART decoders at and Singh, 2004) for dialogue summarization. 1384 Model Pointer Generator (See et al., 2017) Transformer (Vaswani et al., 2017) D-HGN (Feng et al., 2020) Multi-view Seq2Seq (Chen and Yang, 2020) BART (Lewis et al., 2020) S-BART w. Discourse † S-BART w. Action † S-BART w. Disco"
2021.naacl-main.109,2020.acl-main.703,0,0.156133,", versation summarization, starts to gain importance. 1978), and key information resides in different porSignificant progress has been made on abstrac- tions of a conversation. These unstructured propertive summarization for structured document via ties pose challenges for models to focus on salient pointer generator (See et al., 2017), reinforcement contents that are necessary for generating both abmethods (Paulus et al., 2018; Huang et al., 2020a) stractive and informative summaries. Second, there and pre-trained models (Liu and Lapata, 2019; is more than one speaker in conversations and peoLewis et al., 2020; Zhang et al., 2019). Despite the ple interact with each other in different language huge success, it is challenging to directly apply doc- styles (Zhu et al., 2020b). The complex interactions ument models to summarize conversations, due to among multiple speakers make it harder for mod1380 Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 1380–1391 June 6–11, 2021. ©2021 Association for Computational Linguistics els to identify and associate speakers with correct actions so as to generate fact"
2021.naacl-main.109,P19-1210,0,0.502962,"stics: Human Language Technologies, pages 1380–1391 June 6–11, 2021. ©2021 Association for Computational Linguistics els to identify and associate speakers with correct actions so as to generate factual summaries. In order to summarize the unstructured and complex conversations, a growing body of research has been conducted, such as transferring document summarization methods to conversation settings (Shang et al., 2018; Gliwa et al., 2019), adopting hierarchical models (Zhao et al., 2019; Zhu et al., 2020b), or incorporating conversation structures like topic segmentation (Liu et al., 2019b; Li et al., 2019; Chen and Yang, 2020), dialogue acts (Goo and Chen, 2018), and conversation stages (Chen and Yang, 2020). However, current approaches still face challenges in terms of succinctness and faithfulness, as most prior studies (i) fail to explicitly model dependencies between utterances which can help identify salient portions of conversations (Bui et al., 2009), and (ii) lack structured representations (Huang et al., 2020a) to learn the associations between speakers, actions and events. We argue that these rich linguistic structures associated with conversations are key components towards generati"
2021.naacl-main.109,D19-1387,0,0.0956604,"., abstractive con- tations are frequent in conversations (Sacks et al., versation summarization, starts to gain importance. 1978), and key information resides in different porSignificant progress has been made on abstrac- tions of a conversation. These unstructured propertive summarization for structured document via ties pose challenges for models to focus on salient pointer generator (See et al., 2017), reinforcement contents that are necessary for generating both abmethods (Paulus et al., 2018; Huang et al., 2020a) stractive and informative summaries. Second, there and pre-trained models (Liu and Lapata, 2019; is more than one speaker in conversations and peoLewis et al., 2020; Zhang et al., 2019). Despite the ple interact with each other in different language huge success, it is challenging to directly apply doc- styles (Zhu et al., 2020b). The complex interactions ument models to summarize conversations, due to among multiple speakers make it harder for mod1380 Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 1380–1391 June 6–11, 2021. ©2021 Association for Computational Linguistics els to identi"
2021.naacl-main.109,P14-5010,0,0.00639207,"Missing"
2021.naacl-main.109,2020.acl-main.173,0,0.0301226,"marization Compared to extractive document summarization (Gupta and Lehal, 2010; Narayan et al., 2018; Liu and Lapata, 2019), abstractive document summarization is generally considered more challenging and has received more attention. Various methods have been designed to tackle abstractive document summarization like sequence-to-sequence models (Rush et al., 2015), pointer generators (See et al., 2017), reinforcement learning methods (Paulus et al., 2018; Huang et al., 2020a) and pre-trained models (Lewis et al., 2020; Zhang et al., 2019). To generate faithful abstractive document summaries (Maynez et al., 2020), graphbased models were introduced recently such as extracting entity types (Fernandes et al., 2018; Fan et al., 2019), leveraging knowledge graphs (Huang et al., 2020a; Zhu et al., 2020a) or designing extra fact correction modules (Dong et al., 2020). Inspired by these graph-based methods, we also construct action graphs for generating more factual conversation summaries. Conversation Summarization Extractive dialogue summarization (Murray et al., 2005) has been studied extensively via statistical machine learning methods such as skip-chain CRFs (Galley, 2006), SVM with LDA models (Wang and"
2021.naacl-main.109,N15-1046,0,0.395087,"er instead of a fixed value 1, which modulates updates from cross attentions over graphs. Training During training, we seek to minimize the cross entropy and use the teacher-forcing strategy (Bengio et al., 2015): X L=− log P (˜ yl |y&lt;l , C, G D , G A ) (7) 4 4.1 Experiments Datasets We trained and evaluated our models on a conversation summarization dataset SAMSum (Gliwa et al., 2019) covering messenger-like conversations about daily topics, such as arranging meetings and discussing events. We also showed the generalizability of our models on the Argumentative Dialogue Summary Corpus (ADSC) (Misra et al., 2015), a debate summarization corpus. The data statistics of two datasets were shown in Table 1, with the discourse relation types distributions in the Appendix. To better incorporate the information in constructed graphs, different from the traditional pretrained BART model (Lewis et al., 2020), we improve the BART transformer decoder with two extra cross attentions (Discourse Attention and Action Attention) added to each decoder layer, which attends to the encoded node representations in discourse relation graphs and action graphs. In each decoder layer, after performing the origi- 4.2 Baselines"
2021.naacl-main.109,N06-1047,0,0.902497,"itecture. Each utterance is encoded via transformer encoder; discourse relation graphs and action graphs are encoded through Graph Attention Networks (a). The multi-granularity decoder (b) then generates summaries based on all levels of encoded information including utterances, action graphs, and discourse graphs. 2018), key point sequences (Liu et al., 2019a), topic segments (Liu et al., 2019b; Li et al., 2019) and stage developments (Chen and Yang, 2020). Some recent research has also utilized discourse relations as input features in classifiers to detect important content in conversations (Murray et al., 2006; Bui et al., 2009; Qin et al., 2017). However, current models still have not explicitly utilized the dependencies between different utterances, making models hard to leverage long-range dependencies and utilize these salient utterances. Moreover, less attention has been paid to identify the actions of different speakers and how they interact with or refer to each other, leading to unfaithful summarization with incorrect references or wrong reasoning (Gliwa et al., 2019). To fill these gaps, we propose to explicitly model actions within utterances, and relations between utterances in conversat"
2021.naacl-main.109,N18-1158,0,0.0202364,"conversations for conversation summarization. (2) We design structureaware sequence-to-sequence models to combine these structured graphs and generate summaries with the help of a novel multi-granularity decoder. (3) We demonstrate the effectiveness of our proposed methods through experiments on a largescale conversation summarization dataset, SAMSum (Gliwa et al., 2019). (4) We further show that our structure-aware models can generalize well in new domains such as debate summarization. 2 Related Work Document Summarization Compared to extractive document summarization (Gupta and Lehal, 2010; Narayan et al., 2018; Liu and Lapata, 2019), abstractive document summarization is generally considered more challenging and has received more attention. Various methods have been designed to tackle abstractive document summarization like sequence-to-sequence models (Rush et al., 2015), pointer generators (See et al., 2017), reinforcement learning methods (Paulus et al., 2018; Huang et al., 2020a) and pre-trained models (Lewis et al., 2020; Zhang et al., 2019). To generate faithful abstractive document summaries (Maynez et al., 2020), graphbased models were introduced recently such as extracting entity types (Fer"
2021.naacl-main.109,P17-1090,0,0.31832,"tions between speakers, actions and events. We argue that these rich linguistic structures associated with conversations are key components towards generating abstractive and factual conversation summaries. To this end, we present a structure-aware sequence-to-sequence model, in which we equip abstractive conversation summarization models with rich conversation structures through two types of graphs: discourse relation graph and action graph. Discourse relation graphs are constructed based on dependency-based discourse relations (Kirschner et al., 2012; Stone et al., 2013; Asher et al., 2016; Qin et al., 2017) between intertwined utterances, where each Elementary Discourse Unit (EDU) is one single utterance and they are linked through 16 different types of relations (Asher et al., 2016). As shown in Figure 1(a), highly related utterances are linked based on discourse relations like Question Answer Pairs, Comment and Explanation. Explicitly modeling these utterances relations in conversations can aid models in recognizing key content for succinct and informative summarization. Action graphs are constructed as the “WHO - DOING - WHAT” triplets in conversations which express socially situated identiti"
2021.naacl-main.109,D15-1044,0,0.0605114,"thods through experiments on a largescale conversation summarization dataset, SAMSum (Gliwa et al., 2019). (4) We further show that our structure-aware models can generalize well in new domains such as debate summarization. 2 Related Work Document Summarization Compared to extractive document summarization (Gupta and Lehal, 2010; Narayan et al., 2018; Liu and Lapata, 2019), abstractive document summarization is generally considered more challenging and has received more attention. Various methods have been designed to tackle abstractive document summarization like sequence-to-sequence models (Rush et al., 2015), pointer generators (See et al., 2017), reinforcement learning methods (Paulus et al., 2018; Huang et al., 2020a) and pre-trained models (Lewis et al., 2020; Zhang et al., 2019). To generate faithful abstractive document summaries (Maynez et al., 2020), graphbased models were introduced recently such as extracting entity types (Fernandes et al., 2018; Fan et al., 2019), leveraging knowledge graphs (Huang et al., 2020a; Zhu et al., 2020a) or designing extra fact correction modules (Dong et al., 2020). Inspired by these graph-based methods, we also construct action graphs for generating more fa"
2021.naacl-main.109,P17-1099,0,0.742796,"result, how to or- and documents (Gliwa et al., 2019). First, speaker ganize massive everyday interactions into natural, interruptions like repetitions, false-starts, and hesiconcise, and informative text, i.e., abstractive con- tations are frequent in conversations (Sacks et al., versation summarization, starts to gain importance. 1978), and key information resides in different porSignificant progress has been made on abstrac- tions of a conversation. These unstructured propertive summarization for structured document via ties pose challenges for models to focus on salient pointer generator (See et al., 2017), reinforcement contents that are necessary for generating both abmethods (Paulus et al., 2018; Huang et al., 2020a) stractive and informative summaries. Second, there and pre-trained models (Liu and Lapata, 2019; is more than one speaker in conversations and peoLewis et al., 2020; Zhang et al., 2019). Despite the ple interact with each other in different language huge success, it is challenging to directly apply doc- styles (Zhu et al., 2020b). The complex interactions ument models to summarize conversations, due to among multiple speakers make it harder for mod1380 Proceedings of the 2021 Co"
2021.naacl-main.109,P18-1062,0,0.324048,"to summarize conversations, due to among multiple speakers make it harder for mod1380 Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 1380–1391 June 6–11, 2021. ©2021 Association for Computational Linguistics els to identify and associate speakers with correct actions so as to generate factual summaries. In order to summarize the unstructured and complex conversations, a growing body of research has been conducted, such as transferring document summarization methods to conversation settings (Shang et al., 2018; Gliwa et al., 2019), adopting hierarchical models (Zhao et al., 2019; Zhu et al., 2020b), or incorporating conversation structures like topic segmentation (Liu et al., 2019b; Li et al., 2019; Chen and Yang, 2020), dialogue acts (Goo and Chen, 2018), and conversation stages (Chen and Yang, 2020). However, current approaches still face challenges in terms of succinctness and faithfulness, as most prior studies (i) fail to explicitly model dependencies between utterances which can help identify salient portions of conversations (Bui et al., 2009), and (ii) lack structured representations (Huang"
2021.naacl-main.109,W13-0214,0,0.0699224,"Missing"
2021.naacl-main.109,P13-1137,0,0.263664,"Missing"
2021.naacl-main.109,2020.acl-main.451,0,0.0392191,"salient content in email conversations (McKeown et al., 2007). 3 Methods Although current attention-based neural models are To generate abstractive and factual summaries from supposed to, or might implicitly, learn certain reunstructured conversations, we propose to model lations between utterances, they often struggle to structural signals in conversations by first construct- focus on many informative utterances (Chen and ing discourse relation graphs and action graphs Yang, 2020; Song et al., 2020) and fail to address (Section 3.1), and then encoding the graphs to- long-range dependencies (Xu et al., 2020), espegether with conversations (Section 3.2) as well as cially when there are frequent interruptions. As a incorporating these different levels of information result, explicitly incorporating the discourse relain the decoding stage through a multi-granularity tions will help neural summarization models better 1382 encode the unstructured conversations and concentrate on the most salient utterances to generate more informative and less redundant summaries. To do so, we view each utterance as an EDU and use the discourse relation types defined in Asher et al. (2016). We first pre-train a discou"
2021.naacl-main.109,2020.findings-emnlp.19,0,0.779678,"ersation. These unstructured propertive summarization for structured document via ties pose challenges for models to focus on salient pointer generator (See et al., 2017), reinforcement contents that are necessary for generating both abmethods (Paulus et al., 2018; Huang et al., 2020a) stractive and informative summaries. Second, there and pre-trained models (Liu and Lapata, 2019; is more than one speaker in conversations and peoLewis et al., 2020; Zhang et al., 2019). Despite the ple interact with each other in different language huge success, it is challenging to directly apply doc- styles (Zhu et al., 2020b). The complex interactions ument models to summarize conversations, due to among multiple speakers make it harder for mod1380 Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 1380–1391 June 6–11, 2021. ©2021 Association for Computational Linguistics els to identify and associate speakers with correct actions so as to generate factual summaries. In order to summarize the unstructured and complex conversations, a growing body of research has been conducted, such as transferring document summari"
2021.naacl-main.157,2020.acl-demos.30,0,0.613045,"responses. Each submission and one of its direct comment form a (question, response) pair in our corpus, i.e., single-turn dialogues. Furthermore, we stripped away potential markdown and Html syntax tokens and replaced all forms of url links, emails, and digits in our corpus with unique tokens “url”, “email” and “digit” respectively. We also processed replicated words and punctuation to their standard form via a set of regular expressions, e.g., “coooool” is converted into “cool” and “!!!!!” to “!”. Vocabulary and Conversation Pairs. We use a vocabulary of 50,257 entries the same as Dialogpt (Zhang et al., 2020), since they pretrained their models using the full Reddit data. To avoid lengthy questions or responses, we pruned the conversation pairs based on the statistics (see Figure 3 in Appendix A). Questions that exceed 100 words and responses with over 40 words are excluded. In total, there are 1,566,653 conversation pairs. 3.1 Personalization Information To augment our dataset with personalization information, we collected three sources of user-related information: (1) user IDs which are unique usernames for their Reddit accounts; (2) comment histories, which are all the comments a user has poste"
2021.naacl-main.218,P19-1602,0,0.0282637,"previous tasks, where a memory buffer is first adopted to store seen examples from previous tasks and then the stored data is replayed with the training set for the current task. Formally, after training on task t − 1 (t ≥ 2), γ|St−1 | examples are randomly sampled from the t-th training set St−1 into the memory buffer M, where 0 ≤ γ ≤ 1 is the store ratio. Data from M is then merged with the t-th training set St when learning from task t. et al., 2020), where text hidden representations are often disentangled into sentiment (Fu et al., 2017; John et al., 2019), content (Romanov et al., 2019; Bao et al., 2019) and syntax (Bao et al., 2019) information through supervised learning from pre-defined labels (John et al., 2019) or unsupervised learning with adversarial training (Fu et al., 2017; Li et al., 2020). Building on these prior works, we differentiate task generic space from task specific space via supervision from two simple yet effective auxiliary tasks: next sentence prediction and task identifier prediction. Related Learning Paradigms There exists some other learning paradigms also dealing with multiple tasks, such as multi-task learning (Yu et al., 2020) and transfer learning (Houlsby et al"
2021.naacl-main.218,2020.coling-main.574,0,0.196344,"examples //github.com/GT-SALT/IDBR. efficiently via the constraints added on text hidden 1 Introduction space or model parameters, it generally views them as equally important and regularize them to the Computational systems in real world scenarios face changing environment frequently, and thus are of- same extent (Wang et al., 2019; Han et al., 2020), making it hard for models to differentiate informaten required to learn continually from dynamic tive representation that needs to be retained from streams of data building on what was learnt before ones that need a large degree of updates. How(Biesialska et al., 2020). For example, a tweeter ever, we argue that when learning new tasks, task classifier needs to deal with trending topics which generic information and task specific information are constantly emerging. While being an intrinsic nature of human to continually acquire and trans- should be treated differently, as these generic representation might function consistently while task fer knowledge throughout lifespans, most machine learning models often suffer from catastrophic for- specific representations might need to be changed getting: when learning on new tasks, models dra- significantly. matica"
2021.naacl-main.218,2020.acl-main.573,0,0.518441,"into two classes: purely method for continual learning on text classification. Our proposed method first disentangles replay based methods (de Masson d'Autume et al., text hidden spaces into representations that are 2019; Sun et al., 2019) where examples from previgeneric to all tasks and representations speous tasks are stored and re-trained during the learncific to each individual task, and further reguing of the new task to retain old information, and larizes these representations differently to betregularization based methods (Wang et al., 2019; ter constrain the knowledge required to genHan et al., 2020) where constraints are added on eralize. We also introduce two simple auxilmodel parameters to prevent them from changing iary tasks: next sentence prediction and task-id prediction, for learning better generic and spetoo much while learning new tasks. The former cific representation spaces. Experiments conusually stores an extensive amount of data from old ducted on large-scale benchmarks demonstrate tasks (de Masson d'Autume et al., 2019) or trains the effectiveness of our method in continual language models based on task identifiers to gentext classification tasks with various sequences era"
2021.naacl-main.218,P19-1041,0,0.106043,", 2017) is commonly used to recover knowledge from previous tasks, where a memory buffer is first adopted to store seen examples from previous tasks and then the stored data is replayed with the training set for the current task. Formally, after training on task t − 1 (t ≥ 2), γ|St−1 | examples are randomly sampled from the t-th training set St−1 into the memory buffer M, where 0 ≤ γ ≤ 1 is the store ratio. Data from M is then merged with the t-th training set St when learning from task t. et al., 2020), where text hidden representations are often disentangled into sentiment (Fu et al., 2017; John et al., 2019), content (Romanov et al., 2019; Bao et al., 2019) and syntax (Bao et al., 2019) information through supervised learning from pre-defined labels (John et al., 2019) or unsupervised learning with adversarial training (Fu et al., 2017; Li et al., 2020). Building on these prior works, we differentiate task generic space from task specific space via supervision from two simple yet effective auxiliary tasks: next sentence prediction and task identifier prediction. Related Learning Paradigms There exists some other learning paradigms also dealing with multiple tasks, such as multi-task learning (Yu"
2021.naacl-main.218,W19-4326,0,0.0183985,"fication, to better learn and constrain task generic and task specific knowledge. • We augment the regularization approach with a memory selection rule that requires only a small amount of replaying examples. • Extensive experiments conducted on five benchmark datasets demonstrate the effectiveness of our proposed methods compared to state-of-the-art baselines. 2 Related work minimize the interference between new tasks and old tasks (Rusu et al., 2016; Mallya and Lazebnik, 2018); (iv) meta-learning-based method, which directly optimizes the knowledge transfer among tasks (Riemer et al., 2019; Obamuyide and Vlachos, 2019), or learns robust data representations (Javed and White, 2019; Holla et al., 2020; Wang et al., 2020) to alleviate forgetting. Among these different approaches, replay-based methods and regularization-based methods have been widely applied to NLP tasks to enable large pre-trained models (Devlin et al., 2019; Radford et al., 2019) to continually acquire novel world knowledge from streams of textual data without forgetting the already learned knowledge. For instance, replaying examples have shown promising performance for text classification (de Masson d'Autume et al., 2019; Sun et al., 2019; H"
2021.naacl-main.218,2021.eacl-main.39,0,0.0336312,"ax (Bao et al., 2019) information through supervised learning from pre-defined labels (John et al., 2019) or unsupervised learning with adversarial training (Fu et al., 2017; Li et al., 2020). Building on these prior works, we differentiate task generic space from task specific space via supervision from two simple yet effective auxiliary tasks: next sentence prediction and task identifier prediction. Related Learning Paradigms There exists some other learning paradigms also dealing with multiple tasks, such as multi-task learning (Yu et al., 2020) and transfer learning (Houlsby et al., 2019; Pfeiffer et al., 2021). However, neither can fit in the scenario of learning multiple tasks sequentially. The former could be adapted to dynamic environments by storing all seen training data and retraining the model after the arrival of new tasks, which highly decreases efficiency and is impractical in deployment. The latter only focuses on the target tasks and ignores catastrophic forgetting on the source tasks. A more thorough discussion can be found in Biesialska et al. (2020). 3 Problem Formulation In this work, we focus on continual learning for a sequence of text classification tasks {T1 , ...Tn }, where we"
2021.naacl-main.218,N19-1088,0,0.0283085,"ularization-based method, which constrains model’s output (Li and Hoiem, 2018), hidden space (Rannen et al., 2017), or parameters (Lopez-Paz and Ranzato, 2017; Zenke et al., 2017; Aljundi Textual Information Disentanglement Our et al., 2018) from changing too much to retain work is related to information disentanglement for learned knowledge; (iii) architecture-based method, text data, which has been extensively explored where different tasks are associated with differ- in generation tasks like style transfer (Fu et al., ent components of the overall model to directly 2017; Zhao et al., 2018; Romanov et al., 2019; Li 2737 • Replay: when learning new tasks, Experience Replay (Rebuffi et al., 2017) is commonly used to recover knowledge from previous tasks, where a memory buffer is first adopted to store seen examples from previous tasks and then the stored data is replayed with the training set for the current task. Formally, after training on task t − 1 (t ≥ 2), γ|St−1 | examples are randomly sampled from the t-th training set St−1 into the memory buffer M, where 0 ≤ γ ≤ 1 is the store ratio. Data from M is then merged with the t-th training set St when learning from task t. et al., 2020), where text h"
2021.naacl-main.218,N19-1086,0,0.185499,"isentanglement based regularization can be broadly categorized into two classes: purely method for continual learning on text classification. Our proposed method first disentangles replay based methods (de Masson d'Autume et al., text hidden spaces into representations that are 2019; Sun et al., 2019) where examples from previgeneric to all tasks and representations speous tasks are stored and re-trained during the learncific to each individual task, and further reguing of the new task to retain old information, and larizes these representations differently to betregularization based methods (Wang et al., 2019; ter constrain the knowledge required to genHan et al., 2020) where constraints are added on eralize. We also introduce two simple auxilmodel parameters to prevent them from changing iary tasks: next sentence prediction and task-id prediction, for learning better generic and spetoo much while learning new tasks. The former cific representation spaces. Experiments conusually stores an extensive amount of data from old ducted on large-scale benchmarks demonstrate tasks (de Masson d'Autume et al., 2019) or trains the effectiveness of our method in continual language models based on task identifi"
2021.naacl-main.218,2020.emnlp-main.39,0,0.141681,"n approach with a memory selection rule that requires only a small amount of replaying examples. • Extensive experiments conducted on five benchmark datasets demonstrate the effectiveness of our proposed methods compared to state-of-the-art baselines. 2 Related work minimize the interference between new tasks and old tasks (Rusu et al., 2016; Mallya and Lazebnik, 2018); (iv) meta-learning-based method, which directly optimizes the knowledge transfer among tasks (Riemer et al., 2019; Obamuyide and Vlachos, 2019), or learns robust data representations (Javed and White, 2019; Holla et al., 2020; Wang et al., 2020) to alleviate forgetting. Among these different approaches, replay-based methods and regularization-based methods have been widely applied to NLP tasks to enable large pre-trained models (Devlin et al., 2019; Radford et al., 2019) to continually acquire novel world knowledge from streams of textual data without forgetting the already learned knowledge. For instance, replaying examples have shown promising performance for text classification (de Masson d'Autume et al., 2019; Sun et al., 2019; Holla et al., 2020), relation extraction (Wang et al., 2019) and question answering (de Masson d'Autume"
2021.naacl-main.49,Q18-1041,0,0.0407513,"Missing"
2021.naacl-main.49,2020.acl-main.463,0,0.47612,"in et al., 2019) and GPT-3 (Brown et al., 2020) ever, it came at the cost of ignoring essential asseemingly picked up enough language behavior to pects of human decision making, which oversimproduce natural-looking sentences that show pragplified an inherently complex matter in a way that 588 Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 588–602 June 6–11, 2021. ©2021 Association for Computational Linguistics matic constraints and interact in dialogues. However, recent work has pointed out (Bender and Koller, 2020; Bisk et al., 2020) that language is more than just words strung together: it has a social function and relates to non-linguistic context. Nonetheless, current NLP systems still largely ignore the social aspect of language. Instead, they only pay attention to what is said, not to who says it, in what context, and for which goals. We go further to argue that the simplifying focus on information content has effectively limited NLP to a narrow range of information-based applications. Consequently, NLP systems struggle with applications related to pragmatics and interaction, or when “what is said"
2021.naacl-main.49,E17-1015,1,0.931774,"er to argue that the simplifying focus on information content has effectively limited NLP to a narrow range of information-based applications. Consequently, NLP systems struggle with applications related to pragmatics and interaction, or when “what is said is not what is meant,” e.g., sarcasm, irony, deception, and any other situation that requires a “social” interpretation (Abercrombie and Hovy, 2016). This approach is especially crucial for any system related to pragmatics, such as dialogue systems, machine translation (Mirkin and Meunier, 2015), text-to-speech, and mental healthcare tools (Benton et al., 2017). Examples include conversational agents’ inconsistent personality in conducting dialogues with humans (Cercas Curry et al., 2020), the failure of machine translation systems in generating culturally appropriate and polite outputs (Jones and Irvine, 2013; Matusov, 2019; Vanmassenhove et al., 2019), or the general struggles of current systems with social intelligence (Cercas Curry and Rieser, 2018). Ultimately, the goal of NLP is to process language at a human level. However, NLP’s current approach—ignoring social factors—prevents us from reaching human-level competence and performance because"
2021.naacl-main.49,2020.emnlp-main.703,0,0.0917471,"Missing"
2021.naacl-main.49,2020.acl-main.485,0,0.058152,"Missing"
2021.naacl-main.49,D16-1120,0,0.0538966,"Missing"
2021.naacl-main.49,P16-2096,1,0.905665,"ings call for work to look at the ideology, beliefs, and culture behind language content to mitigate biases and social stereotypes beyond data-level manifestations. The fact that embeddings reflect these stereotypes, cultural beliefs, and ideologies make them also an ideal diagnostic tool for social science scholars (Garg et al., 2018; Kozlowski et al., 2018). However, it also creates fundamental biases that cannot easily be mitigated (Gonen and Goldberg, 2019), which poses severe problems for their use in predictive models. Adding cultural awareness can also help counteract the overexposure (Hovy and Spruit, 2016) to the English language (Joshi et al., 2020)6 and Anglo-Western culture. 2.7 Communicative Goal Finally, communicative goals cover what people want to achieve with their language use, e.g., information, decision making, social chitchat, negotiation, etc. SFL represents this factor as multiple metafunctions of language. Two metafunctions are of particular relevance here: the interpersonal metafunction, whereby language enables us to enact social relationships, to cooperate, form bonds, negotiate, ask for things, and instruct; and the ideational metafunction, whereby language enables us to talk"
2021.naacl-main.49,N16-1180,0,0.0447128,"Missing"
2021.naacl-main.49,N15-1185,0,0.0687439,"Missing"
2021.naacl-main.49,P19-1041,0,0.0178472,"d to be structured in ways that can trigger humor (Yang et al., 2015). People might use informal language or text with a high level of intimacy to indicate close relations (Pei and Jurgens, 2020) or reduce social distance between speakers and receivers (Bernstein, 1960; Keshavarz, 2001). Therefore, it is essential for NLP systems like text generation models to be aware of communicative goals in order to arrange word choice, and styles to form a grammatically responsible and coherent text. Ongoing research has shown that style can be controlled independently of content(Prabhumoye et al., 2018; John et al., 2019). Some of the early work on NLP (Hovy, 1987) explicitly considered communicative goals in sentence generation, albeit modeled explicitly. More recently, Sap et al. (2020) modeled speaker intent to resolve conversational implicature. and around the world, how we will equip NLP models with a grounding in social factors becomes extremely important, especially these two dimensions. Detailed modeling of these social factors is essential if NLP systems are to have any impact. It can also help avoid hegemonic approaches from assuming all conversations follow Western norms, culture, and ideology. Real"
2021.naacl-main.49,N15-1016,0,0.0142915,"c, and 2) the focus of NLP models has always been on learning applications based on text alone (amplified by the seeming ability of neural approaches to do so, see Collobert et al. (2011)). Some recent papers have commented on the artificial limitation of relying solely on text (Bender and Koller, 2020; Bisk et al., 2020), demonstrating how even large pretrained language models are essentially just mimicking people’s language use, instead of actual use. Several works have shown, though, how incorporating non-textual information can improve performance, specifically in conjunction with images (Lazaridou et al., 2015; Caglayan et al., 2019). These approaches help various tasks, from concept learning to machine translation, and improve inherently multimodal applications such as scene descriptions and image labeling. However, even including more linguistic context (i.e., text beyond the current sentence) can drastically improve performance of text classification (Yang et al., 2016) and the detection of irony (Wallace et al., 2014) and sarcasm (Abercrombie and Hovy, 2016).2 2.5 Social Norm Social norms refer to acceptable group conduct, shared understandings, or informal rules, representing speakers’ and rec"
2021.naacl-main.49,W13-2713,0,0.0311791,"said is not what is meant,” e.g., sarcasm, irony, deception, and any other situation that requires a “social” interpretation (Abercrombie and Hovy, 2016). This approach is especially crucial for any system related to pragmatics, such as dialogue systems, machine translation (Mirkin and Meunier, 2015), text-to-speech, and mental healthcare tools (Benton et al., 2017). Examples include conversational agents’ inconsistent personality in conducting dialogues with humans (Cercas Curry et al., 2020), the failure of machine translation systems in generating culturally appropriate and polite outputs (Jones and Irvine, 2013; Matusov, 2019; Vanmassenhove et al., 2019), or the general struggles of current systems with social intelligence (Cercas Curry and Rieser, 2018). Ultimately, the goal of NLP is to process language at a human level. However, NLP’s current approach—ignoring social factors—prevents us from reaching human-level competence and performance because language is more than just information content. Unless we start paying attention to the social factors of language, we are artificially limiting NLP’s potential as a field and the applications we can develop, including the performance of the applications"
2021.naacl-main.49,P16-1094,0,0.0326294,"ar-old American male after translation (Hovy et al., 2020). This effect is a big issue for any text generation, where the lack of speaker personality can create incongruous responses in conversational agents. Despite conversational agents’ recent successes (Ritter et al., 2011; Banchs and Li, 2012; Serban et al., 2016), their lack of a consistent personality is still one of the common issues in using data-driven approaches. The main reason is that these models are often trained over conversations by different people, averaging and thereby virtually ignoring individual speakers’ personalities (Li et al., 2016; Wei et al., 2017; Zhang et al., 2018; Wu et al., 2021). There have not been many attempts to make NLP systems more robust to language variation across speakers (Yang and Eisenstein, 2017), though attempts at creating personalized language technologies exist in information retrieval (Shen et al., 2005), recommender systems (Basilico and Hofmann, 2004), machine translation (Mirkin and Meunier, 2015), and language modeling (Federico, 1996). Meanwhile, various approaches have shown the positive impact of incorporating speaker characteristics into NLP applications, either as explicit features (Vo"
2021.naacl-main.49,N16-1130,1,0.890267,"Missing"
2021.naacl-main.49,2020.acl-main.560,0,0.0252698,"efs, and culture behind language content to mitigate biases and social stereotypes beyond data-level manifestations. The fact that embeddings reflect these stereotypes, cultural beliefs, and ideologies make them also an ideal diagnostic tool for social science scholars (Garg et al., 2018; Kozlowski et al., 2018). However, it also creates fundamental biases that cannot easily be mitigated (Gonen and Goldberg, 2019), which poses severe problems for their use in predictive models. Adding cultural awareness can also help counteract the overexposure (Hovy and Spruit, 2016) to the English language (Joshi et al., 2020)6 and Anglo-Western culture. 2.7 Communicative Goal Finally, communicative goals cover what people want to achieve with their language use, e.g., information, decision making, social chitchat, negotiation, etc. SFL represents this factor as multiple metafunctions of language. Two metafunctions are of particular relevance here: the interpersonal metafunction, whereby language enables us to enact social relationships, to cooperate, form bonds, negotiate, ask for things, and instruct; and the ideational metafunction, whereby language enables us to talk about inner and outer experiences, people an"
2021.naacl-main.49,jwalapuram-2017-evaluating,0,0.0149553,"parent, the conversational partner can use the resulting inconsistency to construct an alternative meaning. E.g., inferring that “Take your time, I love waiting for you” violates the maxim of quality and is probably not true lets us assume sarcasm. Gricean maxims and their selective violations can explain why “what is said is not what is meant.” This inference process is called conversational implicature, and can help explain why NLP applications struggle with tasks such as sarcasm detection or entailment. Some previous works have consequently used them to evaluate the quality of NLP systems (Jwalapuram, 2017; Qwaider et al., 2017). Building upon these two frameworks, we lay out a set of seven social factors that NLP systems need to be aware of to overcome current limitations (see Figure 2). We cover SPEAKER characteristics (Section 2.1), RECEIVER characteristics (Section 2.2), SOCIAL RELATIONS (Section 2.3), CONTEXT (Section 2.4), SOCIAL NORMS (Section 2.5), CULTURE AND IDEOLOGY Figure 2: Taxonomy of social factors (Section 2.6), and COMMUNICATIVE GOALS (Section 2.7). We first outline each factor and its relation to SFL and the cooperation principle and then discuss the associated limitations for"
2021.naacl-main.49,P18-2005,0,0.0204148,"speakers (Yang and Eisenstein, 2017), though attempts at creating personalized language technologies exist in information retrieval (Shen et al., 2005), recommender systems (Basilico and Hofmann, 2004), machine translation (Mirkin and Meunier, 2015), and language modeling (Federico, 1996). Meanwhile, various approaches have shown the positive impact of incorporating speaker characteristics into NLP applications, either as explicit features (Volkova et al., 2013), through conditional embeddings (Hovy, 2015; Lynn et al., 2017), or via neural models for multi-task learning (Benton et al., 2017; Li et al., 2018). By accounting for a speaker’s specific demographic attributes, models achieve better performance in a variety of tasks, such as sentiment analysis, user attributes, part-of-speech tagging, and response generation (Wu et al., 2021). Rashkin et al. (2016) showed the value of modelling speaker perspective to discover opinions or biases in the way things are expressed. Hovy (2016) showed that demographically-conditioned generated text also is more convincing. is talking. However, when it comes to broadcasting or highly public spaces, receivers are often “imagined” by the speaker (Litt, 2012) and"
2021.naacl-main.49,D17-1119,0,0.0222818,"ave not been many attempts to make NLP systems more robust to language variation across speakers (Yang and Eisenstein, 2017), though attempts at creating personalized language technologies exist in information retrieval (Shen et al., 2005), recommender systems (Basilico and Hofmann, 2004), machine translation (Mirkin and Meunier, 2015), and language modeling (Federico, 1996). Meanwhile, various approaches have shown the positive impact of incorporating speaker characteristics into NLP applications, either as explicit features (Volkova et al., 2013), through conditional embeddings (Hovy, 2015; Lynn et al., 2017), or via neural models for multi-task learning (Benton et al., 2017; Li et al., 2018). By accounting for a speaker’s specific demographic attributes, models achieve better performance in a variety of tasks, such as sentiment analysis, user attributes, part-of-speech tagging, and response generation (Wu et al., 2021). Rashkin et al. (2016) showed the value of modelling speaker perspective to discover opinions or biases in the way things are expressed. Hovy (2016) showed that demographically-conditioned generated text also is more convincing. is talking. However, when it comes to broadcasting or"
2021.naacl-main.49,2020.acl-main.169,0,0.0136468,"necessitates more finegrained politeness and formality levels than in Western cultures. The terms of address also vary in terms of social and age differences, i.e., inferior members address superior ones with a relationship term instead of using personal names (see also Section 2.3). In many Asian cultures, family terms like “uncle” or “big sister” are used as honorifics. While it is common amongst native speakers of North American English to use “please” in requests even to close friends, such an act would be considered awkward, if not rude, in Arabicspeaking cultures (Kádár and Mills, 2011; Madaan et al., 2020). Cultural norms can impose a hierarchy on Gricean maxims. For example, whether it is better to give made-up directions (which violates the maxim of relevance) instead of not saying anything (adhering to the maxim of quality) if you do not know the right answer. Context and social and cultural norms can combine in unexpected ways, such as in the case of Korean Airline co-pilots not correcting pilot mistakes (a social and cultural taboo in ordinary contexts), which resulted in a series of accidents. Differing perceptions of the context, respect for seniority and age, and a hierarchical communic"
2021.naacl-main.49,W19-7302,0,0.0168776,"t,” e.g., sarcasm, irony, deception, and any other situation that requires a “social” interpretation (Abercrombie and Hovy, 2016). This approach is especially crucial for any system related to pragmatics, such as dialogue systems, machine translation (Mirkin and Meunier, 2015), text-to-speech, and mental healthcare tools (Benton et al., 2017). Examples include conversational agents’ inconsistent personality in conducting dialogues with humans (Cercas Curry et al., 2020), the failure of machine translation systems in generating culturally appropriate and polite outputs (Jones and Irvine, 2013; Matusov, 2019; Vanmassenhove et al., 2019), or the general struggles of current systems with social intelligence (Cercas Curry and Rieser, 2018). Ultimately, the goal of NLP is to process language at a human level. However, NLP’s current approach—ignoring social factors—prevents us from reaching human-level competence and performance because language is more than just information content. Unless we start paying attention to the social factors of language, we are artificially limiting NLP’s potential as a field and the applications we can develop, including the performance of the applications that exist tod"
2021.naacl-main.49,D15-1238,0,0.131076,"d, not to who says it, in what context, and for which goals. We go further to argue that the simplifying focus on information content has effectively limited NLP to a narrow range of information-based applications. Consequently, NLP systems struggle with applications related to pragmatics and interaction, or when “what is said is not what is meant,” e.g., sarcasm, irony, deception, and any other situation that requires a “social” interpretation (Abercrombie and Hovy, 2016). This approach is especially crucial for any system related to pragmatics, such as dialogue systems, machine translation (Mirkin and Meunier, 2015), text-to-speech, and mental healthcare tools (Benton et al., 2017). Examples include conversational agents’ inconsistent personality in conducting dialogues with humans (Cercas Curry et al., 2020), the failure of machine translation systems in generating culturally appropriate and polite outputs (Jones and Irvine, 2013; Matusov, 2019; Vanmassenhove et al., 2019), or the general struggles of current systems with social intelligence (Cercas Curry and Rieser, 2018). Ultimately, the goal of NLP is to process language at a human level. However, NLP’s current approach—ignoring social factors—preven"
2021.naacl-main.49,J16-3007,0,0.0601436,"Missing"
2021.naacl-main.49,2021.naacl-main.191,1,0.839724,"Missing"
2021.naacl-main.49,2020.emnlp-main.428,0,0.0431348,"thegradient.pub/the-benderru le-on-naming-the-languages-we-study-an d-why-it-matters/ 594 stance, text that aims to convince others often uses various persuasion strategies (Yang et al., 2019a; Chen and Yang, 2021), argumentation techniques (Stab and Gurevych, 2014), rhetorical structures (Rapp, 2011), and the exchange of social support (Wang and Jurgens, 2018; Yang et al., 2019b). Messages trying to entertain audiences need to be structured in ways that can trigger humor (Yang et al., 2015). People might use informal language or text with a high level of intimacy to indicate close relations (Pei and Jurgens, 2020) or reduce social distance between speakers and receivers (Bernstein, 1960; Keshavarz, 2001). Therefore, it is essential for NLP systems like text generation models to be aware of communicative goals in order to arrange word choice, and styles to form a grammatically responsible and coherent text. Ongoing research has shown that style can be controlled independently of content(Prabhumoye et al., 2018; John et al., 2019). Some of the early work on NLP (Hovy, 1987) explicitly considered communicative goals in sentence generation, albeit modeled explicitly. More recently, Sap et al. (2020) modele"
2021.naacl-main.49,N12-1057,0,0.0705938,"Missing"
2021.naacl-main.49,P18-1080,0,0.0127246,"o entertain audiences need to be structured in ways that can trigger humor (Yang et al., 2015). People might use informal language or text with a high level of intimacy to indicate close relations (Pei and Jurgens, 2020) or reduce social distance between speakers and receivers (Bernstein, 1960; Keshavarz, 2001). Therefore, it is essential for NLP systems like text generation models to be aware of communicative goals in order to arrange word choice, and styles to form a grammatically responsible and coherent text. Ongoing research has shown that style can be controlled independently of content(Prabhumoye et al., 2018; John et al., 2019). Some of the early work on NLP (Hovy, 1987) explicitly considered communicative goals in sentence generation, albeit modeled explicitly. More recently, Sap et al. (2020) modeled speaker intent to resolve conversational implicature. and around the world, how we will equip NLP models with a grounding in social factors becomes extremely important, especially these two dimensions. Detailed modeling of these social factors is essential if NLP systems are to have any impact. It can also help avoid hegemonic approaches from assuming all conversations follow Western norms, culture"
2021.naacl-main.49,S17-2043,0,0.0344768,"Missing"
2021.naacl-main.49,P18-1187,0,0.024525,"Missing"
2021.naacl-main.49,D17-1244,0,0.0272402,"Missing"
2021.naacl-main.49,2020.findings-emnlp.214,1,0.828232,"Missing"
2021.naacl-main.49,P16-1030,0,0.0186618,", and language modeling (Federico, 1996). Meanwhile, various approaches have shown the positive impact of incorporating speaker characteristics into NLP applications, either as explicit features (Volkova et al., 2013), through conditional embeddings (Hovy, 2015; Lynn et al., 2017), or via neural models for multi-task learning (Benton et al., 2017; Li et al., 2018). By accounting for a speaker’s specific demographic attributes, models achieve better performance in a variety of tasks, such as sentiment analysis, user attributes, part-of-speech tagging, and response generation (Wu et al., 2021). Rashkin et al. (2016) showed the value of modelling speaker perspective to discover opinions or biases in the way things are expressed. Hovy (2016) showed that demographically-conditioned generated text also is more convincing. is talking. However, when it comes to broadcasting or highly public spaces, receivers are often “imagined” by the speaker (Litt, 2012) and are potentially numerous and invisible. This imagined audience is a speaker’s mental conceptualization of the people with whom he or she is communicating. This conceptualization of receiver characteristics influences the conversation: a speaker who calls"
2021.naacl-main.49,D11-1054,0,0.127004,"Missing"
2021.naacl-main.49,P19-1163,0,0.441364,"ic models currently fail to consider receiver characteristics. For instance, when writing to the president of a company vs. messaging your best friend, the politeness levels and register differ substantially, but current large, pretrained models cannot deal with this difference effectively (for an exception, see Fu et al. (2020)). What is more, they can generate messages that are actively hurtful to receivers (Nozza et al., 2021). In other cases like hateful-content detection (Warner and Hirschberg, 2012), a message might be toxic to outsiders but perceived as appropriate among close friends (Sap et al., 2019a). This self-reference or joking use of slurs by a group of intimates might introduce significant noise to the automatic recognition of hate speech, causing existing classifiers to fail in 2.2 Receiver many instances. Detecting such hateful or toxic speech online might require classifiers to take into Audiences that receive text from a speaker are account both content and receivers, as well as a made up of receivers, depending on the situation broader context. Receiver differences markedly and medium. The number of receivers can vary add to the complexity and difficulty in machine substantial"
2021.naacl-main.49,2020.acl-main.486,0,0.0328395,"(Pei and Jurgens, 2020) or reduce social distance between speakers and receivers (Bernstein, 1960; Keshavarz, 2001). Therefore, it is essential for NLP systems like text generation models to be aware of communicative goals in order to arrange word choice, and styles to form a grammatically responsible and coherent text. Ongoing research has shown that style can be controlled independently of content(Prabhumoye et al., 2018; John et al., 2019). Some of the early work on NLP (Hovy, 1987) explicitly considered communicative goals in sentence generation, albeit modeled explicitly. More recently, Sap et al. (2020) modeled speaker intent to resolve conversational implicature. and around the world, how we will equip NLP models with a grounding in social factors becomes extremely important, especially these two dimensions. Detailed modeling of these social factors is essential if NLP systems are to have any impact. It can also help avoid hegemonic approaches from assuming all conversations follow Western norms, culture, and ideology. Real-world interaction involves more than the exchange of information or decision making via language; it involves a wide range of aspects related to social factors and inter"
2021.naacl-main.49,D14-1006,0,0.0115222,"lay out the reasons we need them to join. However, to make it more likely that they agree, we might choose to exaggerate the expected payoff and to leave out some of the difficulties involved, which violates the maxims of quality and quantity, respectively. Applications Communicative goals shape how speakers arrange their words and styles. For in6 https://thegradient.pub/the-benderru le-on-naming-the-languages-we-study-an d-why-it-matters/ 594 stance, text that aims to convince others often uses various persuasion strategies (Yang et al., 2019a; Chen and Yang, 2021), argumentation techniques (Stab and Gurevych, 2014), rhetorical structures (Rapp, 2011), and the exchange of social support (Wang and Jurgens, 2018; Yang et al., 2019b). Messages trying to entertain audiences need to be structured in ways that can trigger humor (Yang et al., 2015). People might use informal language or text with a high level of intimacy to indicate close relations (Pei and Jurgens, 2020) or reduce social distance between speakers and receivers (Bernstein, 1960; Keshavarz, 2001). Therefore, it is essential for NLP systems like text generation models to be aware of communicative goals in order to arrange word choice, and styles"
2021.naacl-main.49,D19-1454,0,0.0650577,"Missing"
2021.naacl-main.49,P19-1164,0,0.0224983,"t of communication, rather than relying on background conversations from different communicators in different contexts. Models have mostly learned to relate words to other words. For instance, current machine translation models are trained on huge corpora of text. However, nuances in language often make it difficult to provide an accurate and di592 rect translation from one social context to another. Studies show that current popular industrial MT systems and recent state-of-the-art academic MT models are significantly prone to gender-biased translation errors for all tested target languages (Stanovsky et al., 2019; Vanmassenhove et al., 2019; Hovy et al., 2020). There is hilarious content caused by translation fails (see #translationfail on Twitter), especially when it comes to the social context or cultural-specific nuances of language. Current text generation models also usually fail to account for social context, generating text that lacks nuance. This factor is one of the most difficult ones to overcome, because 1) social context is almost always extralinguistic, and 2) the focus of NLP models has always been on learning applications based on text alone (amplified by the seeming ability of neural a"
2021.naacl-main.49,2020.acl-main.468,1,0.791046,"ll conversations follow Western norms, culture, and ideology. Real-world interaction involves more than the exchange of information or decision making via language; it involves a wide range of aspects related to social factors and interpersonal relations, reflected in rich modalities such as voice or facial expression. Though this work’s focus is on the language side, we argue that the introduced taxonomy can be beneficial in broader scenarios for next-level multi-modal models. Data, Ethics, and Privacy Our work here is related to some of the recent work on bias in NLP (Hovy and Spruit, 2016; Shah et al., 2020). On the one hand, the cooperative principle can be seen as a possible positive bias: a pre-existing expectation of how we interact, the violation of which signals an alternative approach. So far, models do not integrate this positive bias. On the other hand, work 3 Outlook and Challenges on speaker and receiver characteristics is affected by the models’ predictive biases: exaggerating Social Factors in Different NLP Tasks When or overestimating one particular group’s attributes and how, though, should we consider these various can skew the results, for example, in the case of social factors f"
2021.naacl-main.49,D19-1339,0,0.0593822,"ons Culture and ideology are probably the most complicated language constructs. Despite their substantial influence on communication interpretation and language understanding, most NLP models, like text generation or translation, have not included politeness or other similar subtle cultural signatures. A growing body of research has paid attention to the biases and cul5 https://www.cnbc.com/id/100869966 tural stereotypes encoded and amplified by current NLP models, e.g., inappropriate occupation predictions by large pretrained language models like “the black woman who worked as a babysitter” (Sheng et al., 2019). These findings call for work to look at the ideology, beliefs, and culture behind language content to mitigate biases and social stereotypes beyond data-level manifestations. The fact that embeddings reflect these stereotypes, cultural beliefs, and ideologies make them also an ideal diagnostic tool for social science scholars (Garg et al., 2018; Kozlowski et al., 2018). However, it also creates fundamental biases that cannot easily be mitigated (Gonen and Goldberg, 2019), which poses severe problems for their use in predictive models. Adding cultural awareness can also help counteract the ov"
2021.naacl-main.49,W19-6622,0,0.127332,"sm, irony, deception, and any other situation that requires a “social” interpretation (Abercrombie and Hovy, 2016). This approach is especially crucial for any system related to pragmatics, such as dialogue systems, machine translation (Mirkin and Meunier, 2015), text-to-speech, and mental healthcare tools (Benton et al., 2017). Examples include conversational agents’ inconsistent personality in conducting dialogues with humans (Cercas Curry et al., 2020), the failure of machine translation systems in generating culturally appropriate and polite outputs (Jones and Irvine, 2013; Matusov, 2019; Vanmassenhove et al., 2019), or the general struggles of current systems with social intelligence (Cercas Curry and Rieser, 2018). Ultimately, the goal of NLP is to process language at a human level. However, NLP’s current approach—ignoring social factors—prevents us from reaching human-level competence and performance because language is more than just information content. Unless we start paying attention to the social factors of language, we are artificially limiting NLP’s potential as a field and the applications we can develop, including the performance of the applications that exist today. We want to be clear that"
2021.naacl-main.49,D13-1187,0,0.0469367,"Missing"
2021.naacl-main.49,P14-2084,0,0.0244547,"language use, instead of actual use. Several works have shown, though, how incorporating non-textual information can improve performance, specifically in conjunction with images (Lazaridou et al., 2015; Caglayan et al., 2019). These approaches help various tasks, from concept learning to machine translation, and improve inherently multimodal applications such as scene descriptions and image labeling. However, even including more linguistic context (i.e., text beyond the current sentence) can drastically improve performance of text classification (Yang et al., 2016) and the detection of irony (Wallace et al., 2014) and sarcasm (Abercrombie and Hovy, 2016).2 2.5 Social Norm Social norms refer to acceptable group conduct, shared understandings, or informal rules, representing speakers’ and receivers’ basic knowledge of what others do and what others think they should and should not do (Fehr and Fischbacher, 2004), such as dining etiquette, community norms on Reddit (Chandrasekharan et al., 2018), or hierarchical greetings. Norms are therefore closely related to the factors of relation (Section 2.3) and context (Section 2.4). For instance, greet2 Note that the latter two show that human speakers depend on"
2021.naacl-main.49,D18-1004,0,0.0147831,"t choose to exaggerate the expected payoff and to leave out some of the difficulties involved, which violates the maxims of quality and quantity, respectively. Applications Communicative goals shape how speakers arrange their words and styles. For in6 https://thegradient.pub/the-benderru le-on-naming-the-languages-we-study-an d-why-it-matters/ 594 stance, text that aims to convince others often uses various persuasion strategies (Yang et al., 2019a; Chen and Yang, 2021), argumentation techniques (Stab and Gurevych, 2014), rhetorical structures (Rapp, 2011), and the exchange of social support (Wang and Jurgens, 2018; Yang et al., 2019b). Messages trying to entertain audiences need to be structured in ways that can trigger humor (Yang et al., 2015). People might use informal language or text with a high level of intimacy to indicate close relations (Pei and Jurgens, 2020) or reduce social distance between speakers and receivers (Bernstein, 1960; Keshavarz, 2001). Therefore, it is essential for NLP systems like text generation models to be aware of communicative goals in order to arrange word choice, and styles to form a grammatically responsible and coherent text. Ongoing research has shown that style can"
2021.naacl-main.49,W12-2103,0,0.0371021,"by saying things that are not true: you really do want another piece of cake). Applications Spellchecking and stylistic models currently fail to consider receiver characteristics. For instance, when writing to the president of a company vs. messaging your best friend, the politeness levels and register differ substantially, but current large, pretrained models cannot deal with this difference effectively (for an exception, see Fu et al. (2020)). What is more, they can generate messages that are actively hurtful to receivers (Nozza et al., 2021). In other cases like hateful-content detection (Warner and Hirschberg, 2012), a message might be toxic to outsiders but perceived as appropriate among close friends (Sap et al., 2019a). This self-reference or joking use of slurs by a group of intimates might introduce significant noise to the automatic recognition of hate speech, causing existing classifiers to fail in 2.2 Receiver many instances. Detecting such hateful or toxic speech online might require classifiers to take into Audiences that receive text from a speaker are account both content and receivers, as well as a made up of receivers, depending on the situation broader context. Receiver differences markedl"
2021.naacl-main.49,1983.tc-1.13,0,0.704547,"Missing"
2021.naacl-main.49,N19-1364,1,0.818548,"a project, we might adhere to the maxims of relevance and concisely lay out the reasons we need them to join. However, to make it more likely that they agree, we might choose to exaggerate the expected payoff and to leave out some of the difficulties involved, which violates the maxims of quality and quantity, respectively. Applications Communicative goals shape how speakers arrange their words and styles. For in6 https://thegradient.pub/the-benderru le-on-naming-the-languages-we-study-an d-why-it-matters/ 594 stance, text that aims to convince others often uses various persuasion strategies (Yang et al., 2019a; Chen and Yang, 2021), argumentation techniques (Stab and Gurevych, 2014), rhetorical structures (Rapp, 2011), and the exchange of social support (Wang and Jurgens, 2018; Yang et al., 2019b). Messages trying to entertain audiences need to be structured in ways that can trigger humor (Yang et al., 2015). People might use informal language or text with a high level of intimacy to indicate close relations (Pei and Jurgens, 2020) or reduce social distance between speakers and receivers (Bernstein, 1960; Keshavarz, 2001). Therefore, it is essential for NLP systems like text generation models to b"
2021.naacl-main.49,D15-1284,1,0.697397,"antity, respectively. Applications Communicative goals shape how speakers arrange their words and styles. For in6 https://thegradient.pub/the-benderru le-on-naming-the-languages-we-study-an d-why-it-matters/ 594 stance, text that aims to convince others often uses various persuasion strategies (Yang et al., 2019a; Chen and Yang, 2021), argumentation techniques (Stab and Gurevych, 2014), rhetorical structures (Rapp, 2011), and the exchange of social support (Wang and Jurgens, 2018; Yang et al., 2019b). Messages trying to entertain audiences need to be structured in ways that can trigger humor (Yang et al., 2015). People might use informal language or text with a high level of intimacy to indicate close relations (Pei and Jurgens, 2020) or reduce social distance between speakers and receivers (Bernstein, 1960; Keshavarz, 2001). Therefore, it is essential for NLP systems like text generation models to be aware of communicative goals in order to arrange word choice, and styles to form a grammatically responsible and coherent text. Ongoing research has shown that style can be controlled independently of content(Prabhumoye et al., 2018; John et al., 2019). Some of the early work on NLP (Hovy, 1987) explic"
2021.naacl-main.49,Q17-1021,0,0.0265273,"nses in conversational agents. Despite conversational agents’ recent successes (Ritter et al., 2011; Banchs and Li, 2012; Serban et al., 2016), their lack of a consistent personality is still one of the common issues in using data-driven approaches. The main reason is that these models are often trained over conversations by different people, averaging and thereby virtually ignoring individual speakers’ personalities (Li et al., 2016; Wei et al., 2017; Zhang et al., 2018; Wu et al., 2021). There have not been many attempts to make NLP systems more robust to language variation across speakers (Yang and Eisenstein, 2017), though attempts at creating personalized language technologies exist in information retrieval (Shen et al., 2005), recommender systems (Basilico and Hofmann, 2004), machine translation (Mirkin and Meunier, 2015), and language modeling (Federico, 1996). Meanwhile, various approaches have shown the positive impact of incorporating speaker characteristics into NLP applications, either as explicit features (Volkova et al., 2013), through conditional embeddings (Hovy, 2015; Lynn et al., 2017), or via neural models for multi-task learning (Benton et al., 2017; Li et al., 2018). By accounting for a"
2021.naacl-main.49,N16-1174,1,0.290556,"models are essentially just mimicking people’s language use, instead of actual use. Several works have shown, though, how incorporating non-textual information can improve performance, specifically in conjunction with images (Lazaridou et al., 2015; Caglayan et al., 2019). These approaches help various tasks, from concept learning to machine translation, and improve inherently multimodal applications such as scene descriptions and image labeling. However, even including more linguistic context (i.e., text beyond the current sentence) can drastically improve performance of text classification (Yang et al., 2016) and the detection of irony (Wallace et al., 2014) and sarcasm (Abercrombie and Hovy, 2016).2 2.5 Social Norm Social norms refer to acceptable group conduct, shared understandings, or informal rules, representing speakers’ and receivers’ basic knowledge of what others do and what others think they should and should not do (Fehr and Fischbacher, 2004), such as dining etiquette, community norms on Reddit (Chandrasekharan et al., 2018), or hierarchical greetings. Norms are therefore closely related to the factors of relation (Section 2.3) and context (Section 2.4). For instance, greet2 Note that"
2021.naacl-main.49,P18-1205,0,0.0234529,"ion (Hovy et al., 2020). This effect is a big issue for any text generation, where the lack of speaker personality can create incongruous responses in conversational agents. Despite conversational agents’ recent successes (Ritter et al., 2011; Banchs and Li, 2012; Serban et al., 2016), their lack of a consistent personality is still one of the common issues in using data-driven approaches. The main reason is that these models are often trained over conversations by different people, averaging and thereby virtually ignoring individual speakers’ personalities (Li et al., 2016; Wei et al., 2017; Zhang et al., 2018; Wu et al., 2021). There have not been many attempts to make NLP systems more robust to language variation across speakers (Yang and Eisenstein, 2017), though attempts at creating personalized language technologies exist in information retrieval (Shen et al., 2005), recommender systems (Basilico and Hofmann, 2004), machine translation (Mirkin and Meunier, 2015), and language modeling (Federico, 1996). Meanwhile, various approaches have shown the positive impact of incorporating speaker characteristics into NLP applications, either as explicit features (Volkova et al., 2013), through condition"
2021.sustainlp-1.10,2020.aacl-main.28,0,0.0301663,"Missing"
2021.sustainlp-1.10,2020.emnlp-main.54,0,0.0644881,"Missing"
2021.sustainlp-1.10,W18-2607,0,0.0282866,"cally, we match keywords in the questions and use the Spacy model (Honnibal et al., 2020) to detect subjective and objective in context sentences. 2 Once the mapped types are obtained for each SocialIQA question, we transfer such information to QA models by simply concatenating the tags to original QA examples in the format of [Context, SEP, Question, T ag, Answer] as input to a PLM for fine-tuning. 3 Although we Commonsense Categorization in NLP LoBue and Yates (2011) proposed form-based and contentbased categories for commonsense knowledge that is involved in recognizing textual entailment. Boratko et al. (2018) refined the categorization method 2 Take the fourth instance in Figure 1 as an example; we firstly match the word “need"" in question to the ""Need"" relation, then detect the name “Taylor"" is subjective in the context, so we assign “xNeed"" to this question. 3 All the tags are added into the model’s vocabulary as spe1 https://github.com/posuer/social-commonsenseknolwedge 80 use RoBERTa model in this work, our method is generic and can be applied to any PLMs. 3.2 Social Knowledge Categorization Although utilizing ATOMIC to obtain relation type is straightforward and simple, it is restricted to da"
2021.sustainlp-1.10,2020.deelio-1.9,0,0.0479513,"ocial knowledge needed by the SocialIQA task. 2 3.1 3 Methodology This section presents two approaches to model the underlying semantics and knowledge of the SocialIQA task, together with a simple yet effective method that leverages these knowledge types to improve QA models. Related Work SocialIQA Task Most previous works on SocialIQA task involve either large size of pre-trained models, and datasets (Khashabi et al., 2020; Lourie et al., 2021) or complicated models that heavily rely on external knowledge bases (Shen et al., 2020; Shwartz et al., 2020; Mitra et al., 2019; Ji et al., 2020a,b; Chang et al., 2020). Among them, UnifiedQA (Khashabi et al., 2020) achieved impressive performance by fine-tuning 11B T5 model (Raffel et al., 2019) with 17 existing QA datasets. Unlike previous efforts, our work achieves comparable performance with a relatively small model and simple knowledge extraction method that does not rely on knowledge bases nor require additional pretraining. Question Relation Type The SocialIQA dataset was derived from the ATOMIC (Sap et al., 2019a). ATOMIC is a knowledge base that focuses on everyday social commonsense knowledge organized as ten types of ifthen relations. Based on thi"
2021.sustainlp-1.10,2021.ccl-1.108,0,0.072545,"Missing"
2021.sustainlp-1.10,P11-2057,0,0.0421997,"this observation, we tag each question in SocialIQA according to its relation types in ATOMIC by conducting rule-based mapping between them. Specifically, we match keywords in the questions and use the Spacy model (Honnibal et al., 2020) to detect subjective and objective in context sentences. 2 Once the mapped types are obtained for each SocialIQA question, we transfer such information to QA models by simply concatenating the tags to original QA examples in the format of [Context, SEP, Question, T ag, Answer] as input to a PLM for fine-tuning. 3 Although we Commonsense Categorization in NLP LoBue and Yates (2011) proposed form-based and contentbased categories for commonsense knowledge that is involved in recognizing textual entailment. Boratko et al. (2018) refined the categorization method 2 Take the fourth instance in Figure 1 as an example; we firstly match the word “need"" in question to the ""Need"" relation, then detect the name “Taylor"" is subjective in the context, so we assign “xNeed"" to this question. 3 All the tags are added into the model’s vocabulary as spe1 https://github.com/posuer/social-commonsenseknolwedge 80 use RoBERTa model in this work, our method is generic and can be applied to a"
2021.sustainlp-1.10,N16-1098,0,0.0304205,"ward. Why did Tracy do this? (a) get very close to Austin (b) squeeze into the elevator ✔ (c) get flirty with Austin. Daily Events xWant Alex spilled the food she just prepared all over the floor and it made a huge mess. What will Alex want to do next? Introduction (a) taste the food (b) mop up ✔ (c) run around in the mess Knowledge, Norm, and Rules Recently, large pre-trained language models (PLMs) (Devlin et al., 2019; Raffel et al., 2019; Liu et al., 2019) have been widely used on various commonsense QA tasks such as CommonsenseQA (Malaviya et al., 2020), SocialIQA (Sap et al., 2019b), and Mostafazadeh et al. (2016); Huang et al. (2019); Boratko et al. (2020); Levesque et al. (2012); Roemmele et al. (2011). One line of work (Khashabi et al., 2020) improved the performances of these QA tasks by aggregating more QA data and using even bigger PLM T5 (Raffel et al., 2019). Other line of work tried to supplement the question context with retrieval of related knowledge from external knowledge bases (KB), or re-trained PLMs under the guidance of KBs (Shen et al., 2020; Shwartz et al., 2020; Mitra et al., 2019; Ji et al., 2020a,b). However, very little past research has paid attention to the specific question/co"
2021.sustainlp-1.10,D19-1454,0,0.18,"elevator and it was awkward. Why did Tracy do this? (a) get very close to Austin (b) squeeze into the elevator ✔ (c) get flirty with Austin. Daily Events xWant Alex spilled the food she just prepared all over the floor and it made a huge mess. What will Alex want to do next? Introduction (a) taste the food (b) mop up ✔ (c) run around in the mess Knowledge, Norm, and Rules Recently, large pre-trained language models (PLMs) (Devlin et al., 2019; Raffel et al., 2019; Liu et al., 2019) have been widely used on various commonsense QA tasks such as CommonsenseQA (Malaviya et al., 2020), SocialIQA (Sap et al., 2019b), and Mostafazadeh et al. (2016); Huang et al. (2019); Boratko et al. (2020); Levesque et al. (2012); Roemmele et al. (2011). One line of work (Khashabi et al., 2020) improved the performances of these QA tasks by aggregating more QA data and using even bigger PLM T5 (Raffel et al., 2019). Other line of work tried to supplement the question context with retrieval of related knowledge from external knowledge bases (KB), or re-trained PLMs under the guidance of KBs (Shen et al., 2020; Shwartz et al., 2020; Mitra et al., 2019; Ji et al., 2020a,b). However, very little past research has paid att"
2021.sustainlp-1.10,2020.emnlp-main.722,0,0.25481,"have been widely used on various commonsense QA tasks such as CommonsenseQA (Malaviya et al., 2020), SocialIQA (Sap et al., 2019b), and Mostafazadeh et al. (2016); Huang et al. (2019); Boratko et al. (2020); Levesque et al. (2012); Roemmele et al. (2011). One line of work (Khashabi et al., 2020) improved the performances of these QA tasks by aggregating more QA data and using even bigger PLM T5 (Raffel et al., 2019). Other line of work tried to supplement the question context with retrieval of related knowledge from external knowledge bases (KB), or re-trained PLMs under the guidance of KBs (Shen et al., 2020; Shwartz et al., 2020; Mitra et al., 2019; Ji et al., 2020a,b). However, very little past research has paid attention to the specific question/context knowledge types that are needed for these commonsense QA tasks. Therefore, in this paper, we go deeper into xNeed Taylor taught math in the schools after studying to be a teacher for 4 years. What does Taylor need to do before this? (a) get a certificate ✔ (b) teach small children (c) work in a school Figure 1: SocialIQA Examples for Social Knowledge Categories and Question Relation Type the QA task context and take a closer look at the semanti"
2021.sustainlp-1.10,2020.emnlp-main.373,0,0.0282592,"Missing"
D15-1284,W09-2004,0,0.0176664,"cation performance, but are not necessarily good classifiers. There are few existing benchmark datasets for humor recognition and most studies select negative instances specifically. For example, Mihalcea and Strapparava (2005) constructed the set of negative examples by using news title from Reuters news, proverbs and British National Corpus. (Zhang, el. al 2014) randomly sampled 1500 tweets and then asked annotators to filter out humorous tweets. Compared to humor recognition, humor generation has received quite a lot attention in the past decades(Stock and Strapparava, 2005; Ritchie, 2005; Hong and Ong, 2009). Most generation work draws on humor theories to account for humor factors, such as the Script-based Semantic Theory of Humor (Raskin, 1985; Labutov and Lipson, 2012) and employs templates to generate jokes. For example, Ozbal and Strapparava (2012) created humorous neologism using WordNet and ConceptNet. In detail, their system combined several linguistic resources to generate creative names, more specifically neologisms based on homophonic puns and metaphors. Stock and Strapparava (2005) introduced HAHACRONYM, a system (an acronym ironic re-analyzer and generator) devoted to produce humorou"
D15-1284,P11-2016,0,0.0936674,"ics. biguity, interpersonal effect and phonetic style. For each latent structure, we design a set of features to capture the potential indicators of humor. With high classification accuracy, we then extract humor anchors in sentences via a simple and effective method. Both quantitative and qualitative experimental results are provided to validate the classification and anchor extraction performance. 2 Related Work Most existing studies on humor recognition are formulated as a binary classification problem and try to recognize jokes via a set of linguistic features (Purandare and Litman, 2006; Kiddon and Brun, 2011). For example, Mihalcea and Strapparava (2005) defined three types of humorspecific stylistic features: Alliteration, Antonym and Adult Slang, and trained a classifier based on these feature representations. Similarly, Zhang and Liu (2014) designed several categories of humor-related features, derived from influential humor theories, linguistic norms, and affective dimensions, and input around fifty features into the Gradient Boosting Regression Tree model for humor recognition. Taylor and Mazlack (2004) recognized wordplay jokes based on statistical language recognition techniques, where they"
D15-1284,N15-1070,1,0.765615,"ing distance of word pairs in a sentence. • Repetition: the minimum meaning distance of word pairs in a sentence. 4.2 Ambiguity Theory Ambiguity (Bucaria, 2004), the disambiguation of words with multiple meanings (Bekinschtein et al., 2011), is a crucial component of many humor jokes (Miller and Gurevych, 2015). Humor and ambiguity often come together when a listener expects one meaning, but is forced to use another 5 https://code.google.com/p/word2vec/ We take the generic Word2Vec vectors without training new vectors for our specific domain. In addition, vectors associated with senses (Kumar Jauhar et al., 2015) might be alternative advantageous in this task. 2369 6 meaning. Ambiguity occurs when the words of the surface sentence structure can be grouped in more than one way, thus yielding more than one associated deep structures, as shown in the example below. Did you hear about the guy whose whole left side was cut off? He’s all right now. The multiple possible meanings of words provide readers with different understandings. To capture the ambiguity contained in a sentence, we utilize the lexical resource WordNet (Fellbaum, 1998) and capture the ambiguity as follows: • Sense Combination: the sense"
D15-1284,P12-2030,0,0.0360941,"stances specifically. For example, Mihalcea and Strapparava (2005) constructed the set of negative examples by using news title from Reuters news, proverbs and British National Corpus. (Zhang, el. al 2014) randomly sampled 1500 tweets and then asked annotators to filter out humorous tweets. Compared to humor recognition, humor generation has received quite a lot attention in the past decades(Stock and Strapparava, 2005; Ritchie, 2005; Hong and Ong, 2009). Most generation work draws on humor theories to account for humor factors, such as the Script-based Semantic Theory of Humor (Raskin, 1985; Labutov and Lipson, 2012) and employs templates to generate jokes. For example, Ozbal and Strapparava (2012) created humorous neologism using WordNet and ConceptNet. In detail, their system combined several linguistic resources to generate creative names, more specifically neologisms based on homophonic puns and metaphors. Stock and Strapparava (2005) introduced HAHACRONYM, a system (an acronym ironic re-analyzer and generator) devoted to produce humorous acronyms mainly by exploiting incongruity theories (Stock and Strapparava, 2003). In contrast to research on humor recognition and generation, there are few studies"
D15-1284,H05-1067,0,0.36465,"d phonetic style. For each latent structure, we design a set of features to capture the potential indicators of humor. With high classification accuracy, we then extract humor anchors in sentences via a simple and effective method. Both quantitative and qualitative experimental results are provided to validate the classification and anchor extraction performance. 2 Related Work Most existing studies on humor recognition are formulated as a binary classification problem and try to recognize jokes via a set of linguistic features (Purandare and Litman, 2006; Kiddon and Brun, 2011). For example, Mihalcea and Strapparava (2005) defined three types of humorspecific stylistic features: Alliteration, Antonym and Adult Slang, and trained a classifier based on these feature representations. Similarly, Zhang and Liu (2014) designed several categories of humor-related features, derived from influential humor theories, linguistic norms, and affective dimensions, and input around fifty features into the Gradient Boosting Regression Tree model for humor recognition. Taylor and Mazlack (2004) recognized wordplay jokes based on statistical language recognition techniques, where they learned statistical patterns of text in N-gra"
D15-1284,P15-1070,0,0.0619138,"ncongruity is hard to achieve, however, it is relatively easier to measure the semantic disconnection in a sentence. Taking advantage of Word2Vec5 , we extract two types of features to evaluate the meaning distance6 between content word pairs in a sentence (Mikolov et al., 2013): • Disconnection: the maximum meaning distance of word pairs in a sentence. • Repetition: the minimum meaning distance of word pairs in a sentence. 4.2 Ambiguity Theory Ambiguity (Bucaria, 2004), the disambiguation of words with multiple meanings (Bekinschtein et al., 2011), is a crucial component of many humor jokes (Miller and Gurevych, 2015). Humor and ambiguity often come together when a listener expects one meaning, but is forced to use another 5 https://code.google.com/p/word2vec/ We take the generic Word2Vec vectors without training new vectors for our specific domain. In addition, vectors associated with senses (Kumar Jauhar et al., 2015) might be alternative advantageous in this task. 2369 6 meaning. Ambiguity occurs when the words of the surface sentence structure can be grouped in more than one way, thus yielding more than one associated deep structures, as shown in the example below. Did you hear about the guy whose whol"
D15-1284,W06-1625,0,0.213259,"n for Computational Linguistics. biguity, interpersonal effect and phonetic style. For each latent structure, we design a set of features to capture the potential indicators of humor. With high classification accuracy, we then extract humor anchors in sentences via a simple and effective method. Both quantitative and qualitative experimental results are provided to validate the classification and anchor extraction performance. 2 Related Work Most existing studies on humor recognition are formulated as a binary classification problem and try to recognize jokes via a set of linguistic features (Purandare and Litman, 2006; Kiddon and Brun, 2011). For example, Mihalcea and Strapparava (2005) defined three types of humorspecific stylistic features: Alliteration, Antonym and Adult Slang, and trained a classifier based on these feature representations. Similarly, Zhang and Liu (2014) designed several categories of humor-related features, derived from influential humor theories, linguistic norms, and affective dimensions, and input around fifty features into the Gradient Boosting Regression Tree model for humor recognition. Taylor and Mazlack (2004) recognized wordplay jokes based on statistical language recognitio"
D15-1284,N12-2012,0,0.0706261,"First, a universal definition of humor is hard to achieve, because different people hold different understandings of even the same sentence. Second, humor is always situated in a broader context that sometimes requires a lot of external knowledge to fully understand it. For example, consider the sentence, “The one who invented the door knocker got a No Bell prize” and “Veni, Vidi, Visa: I came, I saw, I did a little shopping”. One needs a larger cultural context to figure out the subtle humorous meaning expressed in these two sentences. Last but not least, there are different types of humor (Raz, 2012), such as wordplay, irony and sarcasm, but there exist few formal taxonomies of humor characteristics. Thus it is almost impossible to design a general algorithm that can classify all the different types of humor, since even human cannot perfectly classify all of them. Although it is impossible to understand universal humor characteristics, one can still capture the possible latent structures behind humor (Bucaria, 2004; Binsted and Ritchie, 1997). In this work, we uncover several latent semantic structures behind humor, in terms of meaning incongruity, ambiguity, phonetic style and personal a"
D15-1284,W05-1614,0,0.109392,"e high classification performance, but are not necessarily good classifiers. There are few existing benchmark datasets for humor recognition and most studies select negative instances specifically. For example, Mihalcea and Strapparava (2005) constructed the set of negative examples by using news title from Reuters news, proverbs and British National Corpus. (Zhang, el. al 2014) randomly sampled 1500 tweets and then asked annotators to filter out humorous tweets. Compared to humor recognition, humor generation has received quite a lot attention in the past decades(Stock and Strapparava, 2005; Ritchie, 2005; Hong and Ong, 2009). Most generation work draws on humor theories to account for humor factors, such as the Script-based Semantic Theory of Humor (Raskin, 1985; Labutov and Lipson, 2012) and employs templates to generate jokes. For example, Ozbal and Strapparava (2012) created humorous neologism using WordNet and ConceptNet. In detail, their system combined several linguistic resources to generate creative names, more specifically neologisms based on homophonic puns and metaphors. Stock and Strapparava (2005) introduced HAHACRONYM, a system (an acronym ironic re-analyzer and generator) devot"
D15-1284,P05-3029,0,0.0413941,"r positive instances will have high classification performance, but are not necessarily good classifiers. There are few existing benchmark datasets for humor recognition and most studies select negative instances specifically. For example, Mihalcea and Strapparava (2005) constructed the set of negative examples by using news title from Reuters news, proverbs and British National Corpus. (Zhang, el. al 2014) randomly sampled 1500 tweets and then asked annotators to filter out humorous tweets. Compared to humor recognition, humor generation has received quite a lot attention in the past decades(Stock and Strapparava, 2005; Ritchie, 2005; Hong and Ong, 2009). Most generation work draws on humor theories to account for humor factors, such as the Script-based Semantic Theory of Humor (Raskin, 1985; Labutov and Lipson, 2012) and employs templates to generate jokes. For example, Ozbal and Strapparava (2012) created humorous neologism using WordNet and ConceptNet. In detail, their system combined several linguistic resources to generate creative names, more specifically neologisms based on homophonic puns and metaphors. Stock and Strapparava (2005) introduced HAHACRONYM, a system (an acronym ironic re-analyzer and g"
D15-1284,N03-1033,0,0.0277565,"occurs when the words of the surface sentence structure can be grouped in more than one way, thus yielding more than one associated deep structures, as shown in the example below. Did you hear about the guy whose whole left side was cut off? He’s all right now. The multiple possible meanings of words provide readers with different understandings. To capture the ambiguity contained in a sentence, we utilize the lexical resource WordNet (Fellbaum, 1998) and capture the ambiguity as follows: • Sense Combination: the sense combination in a sentence computed as follows: we first use a POS tagger (Toutanova et al., 2003) to identify Noun, Verb, Adj, Adv. Then we consider the possible meanings of such words {w1 , w2 · · · wk } via WordNet and Qkcalculate the sense combinations as log( i=1 nwi ). nwi is the total number of senses of word wi . • Sense Farmost: the largest Path Similarity7 of any word senses in a sentence. • Sense Closest: the smallest Path Similarity of any word senses in a sentence. 4.3 Interpersonal Effect Besides humor theories and linguistic style modeling, one important theory behind humor is its social/hostility focus, especially regarding its interpersonal effect on receivers. That is, hu"
D15-1284,P06-1134,0,0.0105404,"ds {w1 , w2 · · · wk } via WordNet and Qkcalculate the sense combinations as log( i=1 nwi ). nwi is the total number of senses of word wi . • Sense Farmost: the largest Path Similarity7 of any word senses in a sentence. • Sense Closest: the smallest Path Similarity of any word senses in a sentence. 4.3 Interpersonal Effect Besides humor theories and linguistic style modeling, one important theory behind humor is its social/hostility focus, especially regarding its interpersonal effect on receivers. That is, humor is essentially associated with sentiment (Zhang and Liu, 2014) and subjectivity (Wiebe and Mihalcea, 2006). For example, a sentence is likely to be humorous if it contains some words carrying strong sentiment, such as ‘idiot’ as follows. Your village called. They want their Idiot back. Each word is associated with positive or negative sentiments and such measurements reflect the emotion expressed by the writer. To identify the word-associated sentiment, we use the word association resource in the work by (Wilson et al., 2005), which provides annotations and clues to measure the subjectivity and sentiment associated with words. This enables us to design the following features. • Negative (Positive)"
D15-1284,H05-1044,0,0.031023,"tility focus, especially regarding its interpersonal effect on receivers. That is, humor is essentially associated with sentiment (Zhang and Liu, 2014) and subjectivity (Wiebe and Mihalcea, 2006). For example, a sentence is likely to be humorous if it contains some words carrying strong sentiment, such as ‘idiot’ as follows. Your village called. They want their Idiot back. Each word is associated with positive or negative sentiments and such measurements reflect the emotion expressed by the writer. To identify the word-associated sentiment, we use the word association resource in the work by (Wilson et al., 2005), which provides annotations and clues to measure the subjectivity and sentiment associated with words. This enables us to design the following features. • Negative (Positive) Polarity: the number of occurrences of all Negative (Positive) words. 7 Path Similarity: http://www.nltk.org/howto/ wordnet.html • Weak (Strong) Subjectivity: the number of occurrences of all Weak (Strong) Subjectivity oriented words in a sentence. It is the linguistic expression of people’s opinions, evaluations, beliefs or speculations. 4.4 Phonetic Style Many humorous texts play with sounds, creating incongruous sound"
D15-1284,P12-1074,0,\N,Missing
D15-1306,W11-0705,0,0.031656,"Missing"
D15-1306,P98-1013,0,0.0536978,"w∈W (1) For each word in a tweet, we query the external embeddings, and replace them with their knn words to create a new training instance. For example, consider the tweet “Being late is terrible” with the punctuality label, after searching for knn words for each token, we create a new training instance: “Be behind are bad” with the same label. Frame-Semantic Embeddings Although lexical (Mikolov et al., 2013a) and dependency based embeddings (Levy and Goldberg, 2014) have been studied, semantic-based embedding is still less understood. We consider the continuous embedding of semantic frames (Baker et al., 1998). To do this, we semantically parsed 3.8 million tweets using SEMAFOR (Das et al., 2010), and built a continuous bag-of-frame model to represent each semantic frame using Word2Vec3 . We then use the same data augmentation approach to create additional instances with these semantic frame embeddings. 3 https://code.google.com/p/word2vec/ Features Lexical +POS +Dependency* +Semantic Frames* Precision .341 .345 .349 .365 Recall .342 .346 .350 .367 F1 .341 .346 .350 .366 Table 4: Comparing linguistic features for categorizing annoying behaviors. The best results are highlighted in bold.* indicates"
D15-1306,N10-1138,0,0.0660896,"s in tweets, we have also extracted typed dependency triples (e.g., nsubj(hate,I)) using the MaltParser (Nivre et al., 2007). In this section, we describe our methods for the qualitative and quantitative analyses. In particular, we briefly review a supervised approach of using sparse mixed-effects topic model to visualize the topical words to analyze this behavior data. For the quantitative task of automatic categorization of tweets, we propose a novel approach to create additional training data, using continuous lexical and semantic representations. 4.1 2 • Frame-Semantics Features: SEMAFOR (Das et al., 2010) is a state-ofthe-art frame-semantics parser that produces FrameNet-style semantic annotation. We use SEMAFOR to extract frame-level semantic features. Supervised Topic Modeling To analyze the salient words for each category of annoying behaviors, we utilize SAGE (Eisenstein et al., 2011), a state-of-the-art mixed-effect topic model, which has been used in several NLP applications (Sim et al., 2012; Wang et al., 2012). SAGE is ideal for our text analytic purposes, because it is supervised, and it builds relatively clean topic models by considering the additive effects and the background distri"
D15-1306,P11-2008,0,0.074754,"Missing"
D15-1306,P11-2102,0,0.0214285,"Missing"
D15-1306,D14-1108,0,0.0915834,"Missing"
D15-1306,P14-2050,0,0.0151375,"or the k-nearest-neighbor (knn) word w for a query term using cosine sim~ and target word vectors ilarity between query Q ~ W: ~ W ~) arg max cosine(Q, w∈W (1) For each word in a tweet, we query the external embeddings, and replace them with their knn words to create a new training instance. For example, consider the tweet “Being late is terrible” with the punctuality label, after searching for knn words for each token, we create a new training instance: “Be behind are bad” with the same label. Frame-Semantic Embeddings Although lexical (Mikolov et al., 2013a) and dependency based embeddings (Levy and Goldberg, 2014) have been studied, semantic-based embedding is still less understood. We consider the continuous embedding of semantic frames (Baker et al., 1998). To do this, we semantically parsed 3.8 million tweets using SEMAFOR (Das et al., 2010), and built a continuous bag-of-frame model to represent each semantic frame using Word2Vec3 . We then use the same data augmentation approach to create additional instances with these semantic frame embeddings. 3 https://code.google.com/p/word2vec/ Features Lexical +POS +Dependency* +Semantic Frames* Precision .341 .345 .349 .365 Recall .342 .346 .350 .367 F1 .3"
D15-1306,D14-1214,0,0.0347901,"s. To the best of our knowledge, even though there have been studies on using Twitter hashtags to study language-related behaviors (Gonz´alezIb´anez et al., 2011; Bamman and Smith, 2015), Twitter NLP approaches to non-linguistic behaviors are not well studied in general. 3 The Dataset We use the Twitter corpus with 9 million sampled messages collected in prior work (Cheng et al., 2010), which includes a total of 121K users. The dataset includes latitude and longitude information. We extract 3,375 tweets1 with #petpeeve hashtags. We follow past work to annotate the tweets (Ritter et al., 2012; Li et al., 2014a): we apply the LDA clustering + human-identification approach to label the categories of the described annoying behaviors in these tweets. The human annotation process includes two stages: first, the annotators identify the 50 categories from the clustering process, and use these topics as a candi2558 1 http://www.cs.cmu.edu/˜yww/data/petpeeves.zip date label set to annotate the data; in the second stage, the categories are refined (to 60 classes) from the first pass, and the data is re-annotated with the refined human-specified category labels. Due to the complexity of this fine-grained ann"
D15-1306,P13-1018,0,0.0764148,"Missing"
D15-1306,N10-1020,0,0.0201899,"Missing"
D15-1306,D11-1141,0,0.0534446,"Missing"
D15-1306,W12-3203,0,0.0164561,"automatic categorization of tweets, we propose a novel approach to create additional training data, using continuous lexical and semantic representations. 4.1 2 • Frame-Semantics Features: SEMAFOR (Das et al., 2010) is a state-ofthe-art frame-semantics parser that produces FrameNet-style semantic annotation. We use SEMAFOR to extract frame-level semantic features. Supervised Topic Modeling To analyze the salient words for each category of annoying behaviors, we utilize SAGE (Eisenstein et al., 2011), a state-of-the-art mixed-effect topic model, which has been used in several NLP applications (Sim et al., 2012; Wang et al., 2012). SAGE is ideal for our text analytic purposes, because it is supervised, and it builds relatively clean topic models by considering the additive effects and the background distribution of words. Therefore, we can use SAGE to visualize the salient words for each category of annoying behaviors using the 3,375 #petpeeve tweets. Each tweet is treated as a document, and we use Markov Chain Monte Carlo for inference. To facilitate the geographical analysis, we use Google’s reverse geocoding service to extract the state information from coordinates, and apply SAGE for visualizati"
D15-1306,N03-1033,0,0.0559279,"Missing"
D15-1306,P10-1040,0,0.0415135,"we consider the feasibility of leveraging external resources, in particular, continuous word embeddings (Mikolov et al., 2013a) to enhance the multiclass text categorization model. Two major challenges for leveraging word embeddings for tweet classification are: 1) because word embeddings are continuous, it is difficult to fuse them with other discrete syntactic and semantic features; 2) it is not straightforward how one should transform the word-level representation to the tweet-level representation. In our preliminary experiments, we have evaluated the continuous word representation method (Turian et al., 2010), as well as incorporating neighboring words in the embeddings as additional features, but both methods fail to outperform the lexical baseline that uses only bag-of-word unigrams. To solve this problem, we propose the use of neighboring words in continuous representations to create new instances to augment the training 2559 weather rains STORM Blizzarad snowed SNOW smoking JAYECANE reggie smoking smoke smokers ungratefulness helped ungrateful clearly r them silence guilty R response conversation sending traffic cop lane pulled speed Slow showoff louis rims seein makin bag timewasting wastingm"
D15-1306,P12-1078,1,0.815117,"zation of tweets, we propose a novel approach to create additional training data, using continuous lexical and semantic representations. 4.1 2 • Frame-Semantics Features: SEMAFOR (Das et al., 2010) is a state-ofthe-art frame-semantics parser that produces FrameNet-style semantic annotation. We use SEMAFOR to extract frame-level semantic features. Supervised Topic Modeling To analyze the salient words for each category of annoying behaviors, we utilize SAGE (Eisenstein et al., 2011), a state-of-the-art mixed-effect topic model, which has been used in several NLP applications (Sim et al., 2012; Wang et al., 2012). SAGE is ideal for our text analytic purposes, because it is supervised, and it builds relatively clean topic models by considering the additive effects and the background distribution of words. Therefore, we can use SAGE to visualize the salient words for each category of annoying behaviors using the 3,375 #petpeeve tweets. Each tweet is treated as a document, and we use Markov Chain Monte Carlo for inference. To facilitate the geographical analysis, we use Google’s reverse geocoding service to extract the state information from coordinates, and apply SAGE for visualization. The categories t"
D15-1306,Q14-1034,0,0.0478993,"Missing"
D15-1306,C98-1013,0,\N,Missing
D17-1213,E12-1036,0,0.754677,"isions to collect relevant edits for sentence simplification. Max and Wisniewski (2010) constructed a corpus of rewritings that can be used for spelling errors and paraphrases (Zesch, 2012). Similarly, Zanzotto and Pennacchiotti (2010) used edits as training data for textual entailment recognition, and Recasens et al. (2013) analyzed real instances of human edits designed to remove bias from Wikipedia articles. Most of these work employed manually defined rules or filters to collect relevant edits to the NLP task at hand. Towards analyzing revisions and developing unified revision taxonomies (Bronner and Monz, 2012; Liu and Ram, 2011), Fong and Biuk-Aghai (2010) built machine learning models to distinguish between factual and fluency edits in revision histories. Faigley and Witte (1981) made a distinction between changes that affect meaning, called text-base changes and changes which do not affect meaning, called surface changes. The two categories are further divided into formal changes, meaning-preserving changes, microstructure changes and macro-structure changes. This taxonomy was later extended by Jones (2008) to take into account edit categories such as significant deletion, style, image insertion"
D17-1213,C12-1044,0,0.783679,"al., 2010), textual entailment recognition (Zanzotto and Pennacchiotti, 2010), language bias detection (Recasens et al., 2013), spelling errors and paraphrases (Zesch, 2012; Max and Wisniewski, 2010). To avoid building different approaches to extract the information needed by different NLP tasks (Ferschke et al., 2013), a unified framework to recognize edits from revisions is needed. Prior research on revision editing primarily develop syntactic edit action categories, from which they try to understand the effects of edits on meaning (Faigley and Witte, 1981; Yang et al., 2016). For instance, Daxenberger and Gurevych (2012) categorized edits based on whether edits affect the text meaning, resulting in syntactic edit categories such as file deletion, reference modification, etc. However, simply understanding the syntactic revision operation types does not provide the information we seek: why do editors do what they do? how effective are their actions? For example, syntactic edit type taxonomies cannot tell the difference between simplifying a paragraph and maliciously damaging that paragraph, since both involve deleting a sentence. In this work, we focus explicitly on revision intention. We introduce a fine-grain"
D17-1213,D13-1055,0,0.232512,"ffective are their actions? For example, syntactic edit type taxonomies cannot tell the difference between simplifying a paragraph and maliciously damaging that paragraph, since both involve deleting a sentence. In this work, we focus explicitly on revision intention. We introduce a fine-grained taxonomy of the reasons why an author in Wikipedia made an edit. Example edit intentions include copy editing, elaboration, verification, and simplification. Compared to taxonomies that either focus on low-level syntactic operations (Faigley and Witte, 1981) or that mix syntactic and semantic classes (Daxenberger and Gurevych, 2013), a clean higher-level semantic categorization enables us to easily identify textual meaning changes, and to connect revisions to “what happens in the mind of the revising author during the revision” 2000 Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 2000–2010 c Copenhagen, Denmark, September 7–11, 2017. 2017 Association for Computational Linguistics (Fitzgerald, 1987; Daxenberger, 2016). In order to capture the meaning behind edits, we worked with 13 Wikipedians to build a taxonomy that captured the meaning of an revision, which we term edit int"
D17-1213,P09-2044,0,0.072332,"ion and article quality. Specifically, we examined whether edit intentions in newcomers’ first editing sessions predict their retention, and examined how edits with different intentions lead to changes in article quality. These analyses showed that specific types of editing work were positively correlated with newcomer survival and articles in different stages of development benefited differently from different types of edits. 2 Related Work Wikipedia revision histories have been used for a wide range of NLP tasks (Yamangil and Nelken, 2008; Aji et al., 2010; Zanzotto and Pennacchiotti, 2010; Ganter and Strube, 2009; Nelken and Yamangil, 2008). For instance, Yatskar et al. (2010) used Wikipedia comments associated with revisions to collect relevant edits for sentence simplification. Max and Wisniewski (2010) constructed a corpus of rewritings that can be used for spelling errors and paraphrases (Zesch, 2012). Similarly, Zanzotto and Pennacchiotti (2010) used edits as training data for textual entailment recognition, and Recasens et al. (2013) analyzed real instances of human edits designed to remove bias from Wikipedia articles. Most of these work employed manually defined rules or filters to collect rel"
D17-1213,P11-2015,0,0.0281516,"In terms of revision intentions, Zhang and Litman (2016) incorporated both argumentative writing features and surface changes from Faigley and Witte (1981) and constructed eight categories of revision purposes, such as claims/ideas, warrant/reasoning/backing, rebuttal/reservation, organization, clarify, etc. Tan and Lee (2014) used revisions to understand statement strength in academic writings. There are multiple works on the detection of specific subsets of revision intentions in Wikipedia, such as vandalism detection where the goal is to classify revisions as vandalized or non-vandalized (Harpalani et al., 2011; Adler et al., 2011) and language bias/neutral point of view detection (Recasens et al., 2013). Instead of recognizing a specific type of revision intention each time, our work aims at designing a systematic and comprehensive edit intention taxonomy to capture intentions behind textual changes. Prior work also used edit types and intentions to better understand the process of collaborative writing, such as article quality improvement (Kittur and Kraut, 2008). For example, Liu and Ram (2011) found that Wikipedia article quality correlates with different types of contributors; similarly Yang et"
D17-1213,max-wisniewski-2010-mining,0,0.605119,"vides an amazing corpus for studying the types and effectiveness of revisions. Specifically, differences between revisions contain valuable information for modeling document quality or extracting users’ expertise, and can additionally support various natural language processing (NLP) tasks such as sentence compression (Yamangil and Nelken, 2008), lexical simplification (Yatskar et al., 2010), information retrieval (Aji et al., 2010), textual entailment recognition (Zanzotto and Pennacchiotti, 2010), language bias detection (Recasens et al., 2013), spelling errors and paraphrases (Zesch, 2012; Max and Wisniewski, 2010). To avoid building different approaches to extract the information needed by different NLP tasks (Ferschke et al., 2013), a unified framework to recognize edits from revisions is needed. Prior research on revision editing primarily develop syntactic edit action categories, from which they try to understand the effects of edits on meaning (Faigley and Witte, 1981; Yang et al., 2016). For instance, Daxenberger and Gurevych (2012) categorized edits based on whether edits affect the text meaning, resulting in syntactic edit categories such as file deletion, reference modification, etc. However, s"
D17-1213,P13-1162,0,0.38333,"revisions growing at a rate of about 2 revisions per second. This provides an amazing corpus for studying the types and effectiveness of revisions. Specifically, differences between revisions contain valuable information for modeling document quality or extracting users’ expertise, and can additionally support various natural language processing (NLP) tasks such as sentence compression (Yamangil and Nelken, 2008), lexical simplification (Yatskar et al., 2010), information retrieval (Aji et al., 2010), textual entailment recognition (Zanzotto and Pennacchiotti, 2010), language bias detection (Recasens et al., 2013), spelling errors and paraphrases (Zesch, 2012; Max and Wisniewski, 2010). To avoid building different approaches to extract the information needed by different NLP tasks (Ferschke et al., 2013), a unified framework to recognize edits from revisions is needed. Prior research on revision editing primarily develop syntactic edit action categories, from which they try to understand the effects of edits on meaning (Faigley and Witte, 1981; Yang et al., 2016). For instance, Daxenberger and Gurevych (2012) categorized edits based on whether edits affect the text meaning, resulting in syntactic edit"
D17-1213,P14-2066,0,0.631392,"multi-label classification to extract edit categories based on unparsed source text (Daxenberger and Gurevych, 2012). However, most taxonomies of edit categories contain only syntactic actions or a mixture of syntactic and semantic actions, failing to capturing the intention of revisions. In terms of revision intentions, Zhang and Litman (2016) incorporated both argumentative writing features and surface changes from Faigley and Witte (1981) and constructed eight categories of revision purposes, such as claims/ideas, warrant/reasoning/backing, rebuttal/reservation, organization, clarify, etc. Tan and Lee (2014) used revisions to understand statement strength in academic writings. There are multiple works on the detection of specific subsets of revision intentions in Wikipedia, such as vandalism detection where the goal is to classify revisions as vandalized or non-vandalized (Harpalani et al., 2011; Adler et al., 2011) and language bias/neutral point of view detection (Recasens et al., 2013). Instead of recognizing a specific type of revision intention each time, our work aims at designing a systematic and comprehensive edit intention taxonomy to capture intentions behind textual changes. Prior work"
D17-1213,P08-2035,0,0.64902,"intain a history of revisions made by millions of participants. As Wikipedia statistics as of January 2017 show, English Wikipedia has 5.3 million articles with an average of 162.89 revisions per article, with revisions growing at a rate of about 2 revisions per second. This provides an amazing corpus for studying the types and effectiveness of revisions. Specifically, differences between revisions contain valuable information for modeling document quality or extracting users’ expertise, and can additionally support various natural language processing (NLP) tasks such as sentence compression (Yamangil and Nelken, 2008), lexical simplification (Yatskar et al., 2010), information retrieval (Aji et al., 2010), textual entailment recognition (Zanzotto and Pennacchiotti, 2010), language bias detection (Recasens et al., 2013), spelling errors and paraphrases (Zesch, 2012; Max and Wisniewski, 2010). To avoid building different approaches to extract the information needed by different NLP tasks (Ferschke et al., 2013), a unified framework to recognize edits from revisions is needed. Prior research on revision editing primarily develop syntactic edit action categories, from which they try to understand the effects o"
D17-1213,N10-1056,0,0.565387,"rticipants. As Wikipedia statistics as of January 2017 show, English Wikipedia has 5.3 million articles with an average of 162.89 revisions per article, with revisions growing at a rate of about 2 revisions per second. This provides an amazing corpus for studying the types and effectiveness of revisions. Specifically, differences between revisions contain valuable information for modeling document quality or extracting users’ expertise, and can additionally support various natural language processing (NLP) tasks such as sentence compression (Yamangil and Nelken, 2008), lexical simplification (Yatskar et al., 2010), information retrieval (Aji et al., 2010), textual entailment recognition (Zanzotto and Pennacchiotti, 2010), language bias detection (Recasens et al., 2013), spelling errors and paraphrases (Zesch, 2012; Max and Wisniewski, 2010). To avoid building different approaches to extract the information needed by different NLP tasks (Ferschke et al., 2013), a unified framework to recognize edits from revisions is needed. Prior research on revision editing primarily develop syntactic edit action categories, from which they try to understand the effects of edits on meaning (Faigley and Witte, 1981; Ya"
D17-1213,E12-1054,0,0.728182,"ond. This provides an amazing corpus for studying the types and effectiveness of revisions. Specifically, differences between revisions contain valuable information for modeling document quality or extracting users’ expertise, and can additionally support various natural language processing (NLP) tasks such as sentence compression (Yamangil and Nelken, 2008), lexical simplification (Yatskar et al., 2010), information retrieval (Aji et al., 2010), textual entailment recognition (Zanzotto and Pennacchiotti, 2010), language bias detection (Recasens et al., 2013), spelling errors and paraphrases (Zesch, 2012; Max and Wisniewski, 2010). To avoid building different approaches to extract the information needed by different NLP tasks (Ferschke et al., 2013), a unified framework to recognize edits from revisions is needed. Prior research on revision editing primarily develop syntactic edit action categories, from which they try to understand the effects of edits on meaning (Faigley and Witte, 1981; Yang et al., 2016). For instance, Daxenberger and Gurevych (2012) categorized edits based on whether edits affect the text meaning, resulting in syntactic edit categories such as file deletion, reference mo"
D17-1213,N16-1168,0,0.492916,"l et al. (2006) proposed a 13-category taxonomy based on the data and performed manual annotation to compare cultural differences in the writing process in different versions of Wikipedia. Daxenberger and Gurevych (2013) introduced a finer-grained edit taxonomy, and performed multi-label classification to extract edit categories based on unparsed source text (Daxenberger and Gurevych, 2012). However, most taxonomies of edit categories contain only syntactic actions or a mixture of syntactic and semantic actions, failing to capturing the intention of revisions. In terms of revision intentions, Zhang and Litman (2016) incorporated both argumentative writing features and surface changes from Faigley and Witte (1981) and constructed eight categories of revision purposes, such as claims/ideas, warrant/reasoning/backing, rebuttal/reservation, organization, clarify, etc. Tan and Lee (2014) used revisions to understand statement strength in academic writings. There are multiple works on the detection of specific subsets of revision intentions in Wikipedia, such as vandalism detection where the goal is to classify revisions as vandalized or non-vandalized (Harpalani et al., 2011; Adler et al., 2011) and language"
L16-1206,C12-1044,0,0.327778,"te, but this information is not available for many active editors and is insufficient in explaining the nature of an editor’s work. While classification based on edit histories can be constructed for most active editors, current approaches focus on simple edit counts and access privileges fail to provide a finer grained description of the work actually performed in an edit. For example, it cannot tell the difference between an editor who copy-edits a paragraph and an editor who inserts markup or template to an article. In this work, we extend Daxenberger’s fine grained taxonomy of edit types (Daxenberger and Gurevych, 2012; Daxenberger and Gurevych, 2013) to differentiate edits and editors who occupy different editing roles. The edits are distinguished contextually in terms of the object being edited (e.g. information, template, reference, etc.) and functionally, in terms of the edit operation (e.g. insert, delete, etc.). The corpus construction will be described in detail later. Based on our corpus, we then described the development of methods for the automated measurement of these 24 edits categories revealed in users’ edits. These categories can be identified with a relatively reasonable performance by using"
L16-1206,D13-1055,0,0.215375,"available for many active editors and is insufficient in explaining the nature of an editor’s work. While classification based on edit histories can be constructed for most active editors, current approaches focus on simple edit counts and access privileges fail to provide a finer grained description of the work actually performed in an edit. For example, it cannot tell the difference between an editor who copy-edits a paragraph and an editor who inserts markup or template to an article. In this work, we extend Daxenberger’s fine grained taxonomy of edit types (Daxenberger and Gurevych, 2012; Daxenberger and Gurevych, 2013) to differentiate edits and editors who occupy different editing roles. The edits are distinguished contextually in terms of the object being edited (e.g. information, template, reference, etc.) and functionally, in terms of the edit operation (e.g. insert, delete, etc.). The corpus construction will be described in detail later. Based on our corpus, we then described the development of methods for the automated measurement of these 24 edits categories revealed in users’ edits. These categories can be identified with a relatively reasonable performance by using a multi-label classification alg"
L16-1206,P13-1071,0,0.0258381,"s essential to developing high quality articles(Kittur and Kraut, 2008). Thus, determining how contribution by different types of work and by different editors at distinct times in an article’s history influence changes in its quality is of great use to better understand the causes of quality variance in Wikipedia (De la Calzada and Dekhtyar, 2010). 3. Quality Flaw Detection: The detection and improvement of low quality information is an essential component in online production communities. Different from existing studies in quality flaw prediction (Anderka et al., 2012; Anderka et al., 2011; Ferschke et al., 2013), our taxonomy enables us to provide which specific aspects (information, reference, wikilink, template or markup, etc.) of an article needs improvement and what operations should be performed. 4. Domain Adaption: Even though the edit taxonomy introduced above is for English Wikipedia, it can be applied to other language versions of Wikipedia. For example, similar taxonomy, or even automated classification models can be transformed for another language. Beyond the context of Wikipedia, similar taxonomies can be designed for analyzing the collaboration and interaction happened in other online c"
N15-1074,D07-1109,0,0.0248264,"ver the topic-word multinomials such that similar words share similar topic distributions. Newman et al. (2011) proposed a quadratic regularizer and a convolved Dirichlet regularizer over topic-word multinomials to incorporate the correlation between words. All of these methods directly incorporate the word correlation knowledge into the topic-word distributions in a hard and topic-independent way, which ignore the fact that whether two words are correlated depends on which topic they appear in. There are several works utilizing knowledge with more complex structure to improve topic modeling. Boyd-Graber et al. (2007) incorporate the synset structure in WordNet (Miller, 1995b) into LDA for word sense disambiguation, where each topic is a random process defined over the synsets. Hu et al. (2011) proposed interactive topic modeling, which allows users to iteratively refine the discovered topics by adding constraints such as certain set of words must appear together in the same topic. Andrzejewski et al. (2011) proposed a general framework which uses first order logic to encode various domain knowledge regarding documents, topics and side information into LDA. The vast generality and expressivity of this mode"
N15-1074,P84-1044,0,0.759893,"Missing"
N15-1074,P11-1026,0,0.258424,"opic-word multinomials to incorporate the correlation between words. All of these methods directly incorporate the word correlation knowledge into the topic-word distributions in a hard and topic-independent way, which ignore the fact that whether two words are correlated depends on which topic they appear in. There are several works utilizing knowledge with more complex structure to improve topic modeling. Boyd-Graber et al. (2007) incorporate the synset structure in WordNet (Miller, 1995b) into LDA for word sense disambiguation, where each topic is a random process defined over the synsets. Hu et al. (2011) proposed interactive topic modeling, which allows users to iteratively refine the discovered topics by adding constraints such as certain set of words must appear together in the same topic. Andrzejewski et al. (2011) proposed a general framework which uses first order logic to encode various domain knowledge regarding documents, topics and side information into LDA. The vast generality and expressivity of this model makes its inference to be very hard. Chen et al. (2013) proposed a topic model to model multi-domain knowledge, where each document is an admixture of latent topics and each topi"
N15-1074,E12-1021,0,0.012615,"Missing"
N15-1074,D14-1162,0,0.104556,". Table 1: Dataset Statistics 4.1 Experiment Setup • Dataset: We use two datasets in the experiments: 20-Newsgroups2 and NIPS3 . Their statistics are summarized in Table 1. • External Knowledge: We extract word correlation knowledge from Web Eigenwords4 , where each word has a real-valued vector capturing the semantic meaning of this word based on distributional similarity. Two words are regarded as correlated if their representation vectors are similar enough. It is worth mentioning that, other sources of external word correlation knowledge, such as Word2Vec (Mikolov et al., 2013) and Glove (Pennington et al., 2014), can be readily incorporated into MRF-LDA. • Baselines: We compare our model with three baseline methods: LDA (Blei et al., 2003), DFLDA (Andrzejewski et al., 2009) and QuadLDA (Newman et al., 2011). LDA is the most widely used topic model, but it is unable to incorporate external knowledge. DF-LDA and Quad-LDA are two models designed to incorporate word correlation to improve topic modeling. DF-LDA puts a Dirichlet Forest prior over the topic-word multinomials to encode the Must-Links and Cannot-Links between words. Quad-LDA regularizes the topic-word distributions with a structured prior to"
N16-1174,P14-1062,0,0.152187,"ication is one of the fundamental task in Natural Language Processing. The goal is to assign labels to text. It has broad applications including topic labeling (Wang and Manning, 2012), sentiment classification (Maas et al., 2011; Pang and Lee, 2008), and spam detection (Sahami et al., 1998). Traditional approaches of text classification represent documents with sparse lexical features, such as n-grams, and then use a linear model or kernel methods on this representation (Wang and Manning, 2012; Joachims, 1998). More recent approaches used deep learning, such as convolutional neural networks (Blunsom et al., 2014) and recurrent neural networks based on long short-term memory (LSTM) (Hochreiter and Schmidhuber, 1997) to learn text representations. Although neural-network–based approaches to text classification have been quite effective (Kim, 2014; Zhang et al., 2015; Johnson and Zhang, 2014; Tang et al., 2015), in this paper we test the hypothesis that better representations can be obtained by incorporating knowledge of document structure in the model architecture. The intuition underlying our model is that not all parts of a document are equally relevant for answering a query and that determining the r"
N16-1174,D14-1002,1,0.0625345,"ig. 1, which is a short Yelp review where the task is to predict the rating on a scale from 1–5. Intuitively, the first and third sentence have stronger information in assisting the prediction of the rating; within these sentences, the word delicious, a-m-a-z-i-n-g contributes more in implying the positive attitude contained in this review. Attention serves two benefits: not only does it often result in better performance, but it also provides insight into which words and sentences contribute to the classification decision which can be of value in applications and analysis (Shen et al., 2014; Gao et al., 2014). The key difference to previous work is that our system uses context to discover when a sequence of tokens is relevant rather than simply filtering for (sequences of) tokens, taken out of context. To evaluate the performance of our model in comparison to other common classification architectures, we look at six data sets (§3). Our model outperforms previous approaches by a significant margin. 2 Hierarchical Attention Networks The overall architecture of the Hierarchical Attention Network (HAN) is shown in Fig. 2. It consists of several parts: a word sequence encoder, a word-level attention la"
N16-1174,D14-1181,0,0.347192,"8), and spam detection (Sahami et al., 1998). Traditional approaches of text classification represent documents with sparse lexical features, such as n-grams, and then use a linear model or kernel methods on this representation (Wang and Manning, 2012; Joachims, 1998). More recent approaches used deep learning, such as convolutional neural networks (Blunsom et al., 2014) and recurrent neural networks based on long short-term memory (LSTM) (Hochreiter and Schmidhuber, 1997) to learn text representations. Although neural-network–based approaches to text classification have been quite effective (Kim, 2014; Zhang et al., 2015; Johnson and Zhang, 2014; Tang et al., 2015), in this paper we test the hypothesis that better representations can be obtained by incorporating knowledge of document structure in the model architecture. The intuition underlying our model is that not all parts of a document are equally relevant for answering a query and that determining the relevant sections involves modeling the interactions of the words, not just their presence in isolation. Our primary contribution is a new neural architecture (§2), the Hierarchical Attention Network (HAN) that is designed to capture two"
N16-1174,P15-1107,0,0.642353,"Missing"
N16-1174,D15-1106,0,0.0757692,"nd Internet. explore the structure of a sentence and use a treestructured LSTMs for classification. There are also some works that combine LSTM and CNN structure to for sentence classification (Lai et al., 2015; Zhou et al., 2015). Tang et al. (2015) use hierarchical structure in sentiment classification. They first use a CNN or LSTM to get a sentence vector and then a bi-directional gated recurrent neural network to compose the sentence vectors to get a document vectors. There are some other works that use hierarchical structure in sequence generation (Li et al., 2015) and language modeling (Lin et al., 2015). The attention mechanism was proposed by (Bahdanau et al., 2014) in machine translation. The encoder decoder framework is used and an attention mechanism is used to select the reference words in original language for words in foreign language before translation. Xu et al. (2015) uses the attention mechanism in image caption generation to select the relevant image regions when generating words in the captions. Further uses of the attention mechanism include parsing (Vinyals et al., 2014), natural language question answering (Sukhbaatar et al., 2015; 1487 Kumar et al., 2015; Hermann et al., 201"
N16-1174,P11-1015,0,0.312116,"cocktails. ||next time I in Phoenix, I will go back here. ||Highly recommend. Figure 1: A simple example review from Yelp 2013 that consists of five sentences, delimited by period, question mark. The first and third sentence delivers stronger meaning and inside, the word delicious, a-m-a-z-i-n-g contributes the most in defining sentiment of the two sentences. Introduction Text classification is one of the fundamental task in Natural Language Processing. The goal is to assign labels to text. It has broad applications including topic labeling (Wang and Manning, 2012), sentiment classification (Maas et al., 2011; Pang and Lee, 2008), and spam detection (Sahami et al., 1998). Traditional approaches of text classification represent documents with sparse lexical features, such as n-grams, and then use a linear model or kernel methods on this representation (Wang and Manning, 2012; Joachims, 1998). More recent approaches used deep learning, such as convolutional neural networks (Blunsom et al., 2014) and recurrent neural networks based on long short-term memory (LSTM) (Hochreiter and Schmidhuber, 1997) to learn text representations. Although neural-network–based approaches to text classification have bee"
N16-1174,P14-5010,0,0.0519213,"words (average and maximum per document). LSTM takes the whole document as a single sequence and the average of the hidden states of all words is used as feature for classification. Conv-GRNN and LSTM-GRNN were proposed by (Tang et al., 2015). They also explore the hierarchical structure: a CNN or LSTM provides a sentence vector, and then a gated recurrent neural network (GRNN) combines the sentence vectors from a document level vector representation for classification. 3.3 Model configuration and training We split documents into sentences and tokenize each sentence using Stanford’s CoreNLP (Manning et al., 2014). We only retain words appearing more than 5 times in building the vocabulary and replace the words that appear 5 times with a special UNK token. We obtain the word embedding by training an unsupervised word2vec (Mikolov et al., 2013) model on the training and validation splits and then use the word embedding to initialize We . The hyper parameters of the models are tuned on the validation set. In our experiments, we set the word embedding dimension to be 200 and the GRU dimension to be 50. In this case a combination of forward and backward GRU gives us 100 dimensions for word/sentence annotat"
N16-1174,D13-1170,0,0.0565051,"ing sentences. Note that this happens in a multiclass setting, that is, detection happens before the selection of the topic! 4 Related Work Kim (2014) use neural networks for text classification. The architecture is a direct application of CNNs, as used in computer vision (LeCun et al., 1998), albeit with NLP interpretations. Johnson and Zhang (2014) explores the case of directly using a high-dimensional one hot vector as input. They find that it performs well. Unlike word level modelings, Zhang et al. (2015) apply a character-level CNN for text classification and achieve competitive results. Socher et al. (2013) use recursive neural networks for text classification. Tai et al. (2015) GT: 4 Prediction: 4 pork belly = delicious . scallops ? i do n’t . even . like . scallops , and these were a-m-a-z-i-n-g . fun and tasty cocktails . next time i ’m in phoenix , i will go back here . highly recommend . GT: 0 Prediction: 0 terrible value . ordered pasta entree . . $ 16.95 good taste but size was an appetizer size . . no salad , no bread no vegetable . this was . our and tasty cocktails . our second visit . i will not go back . Figure 5: Documents from Yelp 2013. Label 4 means star 5, label 0 means star 1."
N16-1174,P15-1150,0,0.146221,"ction happens before the selection of the topic! 4 Related Work Kim (2014) use neural networks for text classification. The architecture is a direct application of CNNs, as used in computer vision (LeCun et al., 1998), albeit with NLP interpretations. Johnson and Zhang (2014) explores the case of directly using a high-dimensional one hot vector as input. They find that it performs well. Unlike word level modelings, Zhang et al. (2015) apply a character-level CNN for text classification and achieve competitive results. Socher et al. (2013) use recursive neural networks for text classification. Tai et al. (2015) GT: 4 Prediction: 4 pork belly = delicious . scallops ? i do n’t . even . like . scallops , and these were a-m-a-z-i-n-g . fun and tasty cocktails . next time i ’m in phoenix , i will go back here . highly recommend . GT: 0 Prediction: 0 terrible value . ordered pasta entree . . $ 16.95 good taste but size was an appetizer size . . no salad , no bread no vegetable . this was . our and tasty cocktails . our second visit . i will not go back . Figure 5: Documents from Yelp 2013. Label 4 means star 5, label 0 means star 1. GT: 1 Prediction: 1 why does zebras have stripes ? what is the purpose or"
N16-1174,P14-1146,0,0.12484,"(Mikolov et al., 2013) is used as feature set. 3.2.2 SVMs SVMs-based methods are reported in (Tang et al., 2015), including SVM+Unigrams, Bigrams, Text Features, AverageSG, SSWE. In detail, Unigrams and Bigrams uses bag-of-unigrams and bagof-bigrams as features respectively. Text Features are constructed according to (Kiritchenko et al., 2014), including word and character n-grams, sentiment lexicon features etc. AverageSG constructs 200-dimensional word vectors using word2vec and the average word embeddings of each document are used. SSWE uses sentiment specific word embeddings according to (Tang et al., 2014). 3.2.3 Neural Network methods The neural network based methods are reported in (Tang et al., 2015) and (Zhang et al., 2015). CNN-word Word based CNN models like that of (Kim, 2014) are used. CNN-char Character level CNN models are reported in (Zhang et al., 2015). Data set Yelp 2013 Yelp 2014 Yelp 2015 IMDB review Yahoo Answer Amazon review classes documents average #s max #s average #w max #w vocabulary 5 5 5 10 10 5 335,018 1,125,457 1,569,264 348,415 1,450,000 3,650,000 8.9 9.2 9.0 14.0 6.4 4.9 151 151 151 148 515 99 151.6 156.9 151.9 325.6 108.4 91.9 1184 1199 1199 2802 4002 596 211,245 4"
N16-1174,D15-1167,0,0.706504,"l approaches of text classification represent documents with sparse lexical features, such as n-grams, and then use a linear model or kernel methods on this representation (Wang and Manning, 2012; Joachims, 1998). More recent approaches used deep learning, such as convolutional neural networks (Blunsom et al., 2014) and recurrent neural networks based on long short-term memory (LSTM) (Hochreiter and Schmidhuber, 1997) to learn text representations. Although neural-network–based approaches to text classification have been quite effective (Kim, 2014; Zhang et al., 2015; Johnson and Zhang, 2014; Tang et al., 2015), in this paper we test the hypothesis that better representations can be obtained by incorporating knowledge of document structure in the model architecture. The intuition underlying our model is that not all parts of a document are equally relevant for answering a query and that determining the relevant sections involves modeling the interactions of the words, not just their presence in isolation. Our primary contribution is a new neural architecture (§2), the Hierarchical Attention Network (HAN) that is designed to capture two basic insights about document structure. First, since documents"
N16-1174,P12-2018,0,0.260108,"ops, and these were a-m-a-z-i-n-g . ||fun and tasty cocktails. ||next time I in Phoenix, I will go back here. ||Highly recommend. Figure 1: A simple example review from Yelp 2013 that consists of five sentences, delimited by period, question mark. The first and third sentence delivers stronger meaning and inside, the word delicious, a-m-a-z-i-n-g contributes the most in defining sentiment of the two sentences. Introduction Text classification is one of the fundamental task in Natural Language Processing. The goal is to assign labels to text. It has broad applications including topic labeling (Wang and Manning, 2012), sentiment classification (Maas et al., 2011; Pang and Lee, 2008), and spam detection (Sahami et al., 1998). Traditional approaches of text classification represent documents with sparse lexical features, such as n-grams, and then use a linear model or kernel methods on this representation (Wang and Manning, 2012; Joachims, 1998). More recent approaches used deep learning, such as convolutional neural networks (Blunsom et al., 2014) and recurrent neural networks based on long short-term memory (LSTM) (Hochreiter and Schmidhuber, 1997) to learn text representations. Although neural-network–bas"
N16-1174,D15-1176,1,\N,Missing
N16-1174,N15-1011,0,\N,Missing
N19-1364,P18-1058,0,0.0436454,"(2017) utilized the persuasive modes—ethos, logos, pathos—to model premises and the semantic types of argument components in an online persuasive forum. While most computational argumentation focuses on the relational support structures and factual evidence to make claims, persuasion focuses more on language cues aimed at shaping, reinforcing and changing people’s opinions and beliefs. How language changes people’s attitudes and behaviors have received less attention from the computational community than argumentation, although there have been important preliminary work (Persing and Ng, 2017; Carlile et al., 2018). Farra et al., (2015) built regression models to predict essay scores based on features extracted from opinion expressions and topical elements. Chatterjee et al., (2014) used verbal descriptors and para-verbal markers of hesitation to predict speakers’ persuasiveness on website housing videos of product reviews. When looking at persuasion in the context of online forum discussions (Wei et al., 2016), Tan et al., (2016) found that on the Change My View subreddit, interaction dynamics such as the language interplay between opinion holders and other participants provides highly predictive cues"
N19-1364,W14-5908,0,0.0359094,"putational argumentation focuses on the relational support structures and factual evidence to make claims, persuasion focuses more on language cues aimed at shaping, reinforcing and changing people’s opinions and beliefs. How language changes people’s attitudes and behaviors have received less attention from the computational community than argumentation, although there have been important preliminary work (Persing and Ng, 2017; Carlile et al., 2018). Farra et al., (2015) built regression models to predict essay scores based on features extracted from opinion expressions and topical elements. Chatterjee et al., (2014) used verbal descriptors and para-verbal markers of hesitation to predict speakers’ persuasiveness on website housing videos of product reviews. When looking at persuasion in the context of online forum discussions (Wei et al., 2016), Tan et al., (2016) found that on the Change My View subreddit, interaction dynamics such as the language interplay between opinion holders and other participants provides highly predictive cues for persuasiveness. Using the same dataset, Wel et al., (2016) extracted a set of textual information and social interaction features to identify persuasive posts. Recentl"
N19-1364,W14-2106,0,0.0327216,"or Computational Linguistics show that our semi-supervised model outperforms several baselines. We then apply this automated model to unseen requests from different domains and obtain nuanced findings of the importance of different strategies on persuasion success. Our model can be useful in any situation in which we have exogenous document-level supervision, but only small amounts of expensive human-annotated sentence labels. 2 Related Work Computational argumentation has received much recent attention (Ghosh et al., 2016; Stab and Gurevych, 2017; Peldszus and Stede, 2013; Stab et al., 2018; Ghosh et al., 2014). Most work has either identified the arguments in news articles (Sardianos et al., 2015) or user-generated web content (Habernal and Gurevych, 2017; Musi et al., 2018), or classified argument components (Zhang and Litman, 2015) into claims and premises, supporting and opposing claims, or backings, rebuttals and refutations . For example, Stab and Gurevych (2014) proposed structural, lexical, syntactic and contextual features to identify convincing components of Web arguments including claim, major claim, and premise. Similarly, Zhang and Litman (2015) studied student essay revisions and class"
N19-1364,P16-1150,0,0.0244722,"7; Musi et al., 2018), or classified argument components (Zhang and Litman, 2015) into claims and premises, supporting and opposing claims, or backings, rebuttals and refutations . For example, Stab and Gurevych (2014) proposed structural, lexical, syntactic and contextual features to identify convincing components of Web arguments including claim, major claim, and premise. Similarly, Zhang and Litman (2015) studied student essay revisions and classified a set of argumentative actions associated with successful writing such as warrant/reasoning/backing, rebuttal/reservation, and claims/ideas. Habernal and Gurevych (2016) investigated the persuasiveness of arguments in any given argument pair using bidirectional LSTM. Hidey et al., (2017) utilized the persuasive modes—ethos, logos, pathos—to model premises and the semantic types of argument components in an online persuasive forum. While most computational argumentation focuses on the relational support structures and factual evidence to make claims, persuasion focuses more on language cues aimed at shaping, reinforcing and changing people’s opinions and beliefs. How language changes people’s attitudes and behaviors have received less attention from the comput"
N19-1364,J17-1004,0,0.0462079,"requests from different domains and obtain nuanced findings of the importance of different strategies on persuasion success. Our model can be useful in any situation in which we have exogenous document-level supervision, but only small amounts of expensive human-annotated sentence labels. 2 Related Work Computational argumentation has received much recent attention (Ghosh et al., 2016; Stab and Gurevych, 2017; Peldszus and Stede, 2013; Stab et al., 2018; Ghosh et al., 2014). Most work has either identified the arguments in news articles (Sardianos et al., 2015) or user-generated web content (Habernal and Gurevych, 2017; Musi et al., 2018), or classified argument components (Zhang and Litman, 2015) into claims and premises, supporting and opposing claims, or backings, rebuttals and refutations . For example, Stab and Gurevych (2014) proposed structural, lexical, syntactic and contextual features to identify convincing components of Web arguments including claim, major claim, and premise. Similarly, Zhang and Litman (2015) studied student essay revisions and classified a set of argumentative actions associated with successful writing such as warrant/reasoning/backing, rebuttal/reservation, and claims/ideas. H"
N19-1364,W17-5102,0,0.488347,"sing claims, or backings, rebuttals and refutations . For example, Stab and Gurevych (2014) proposed structural, lexical, syntactic and contextual features to identify convincing components of Web arguments including claim, major claim, and premise. Similarly, Zhang and Litman (2015) studied student essay revisions and classified a set of argumentative actions associated with successful writing such as warrant/reasoning/backing, rebuttal/reservation, and claims/ideas. Habernal and Gurevych (2016) investigated the persuasiveness of arguments in any given argument pair using bidirectional LSTM. Hidey et al., (2017) utilized the persuasive modes—ethos, logos, pathos—to model premises and the semantic types of argument components in an online persuasive forum. While most computational argumentation focuses on the relational support structures and factual evidence to make claims, persuasion focuses more on language cues aimed at shaping, reinforcing and changing people’s opinions and beliefs. How language changes people’s attitudes and behaviors have received less attention from the computational community than argumentation, although there have been important preliminary work (Persing and Ng, 2017; Carlil"
N19-1364,P14-5010,0,0.00443789,"Missing"
N19-1364,W15-0608,0,0.0135574,"suasive modes—ethos, logos, pathos—to model premises and the semantic types of argument components in an online persuasive forum. While most computational argumentation focuses on the relational support structures and factual evidence to make claims, persuasion focuses more on language cues aimed at shaping, reinforcing and changing people’s opinions and beliefs. How language changes people’s attitudes and behaviors have received less attention from the computational community than argumentation, although there have been important preliminary work (Persing and Ng, 2017; Carlile et al., 2018). Farra et al., (2015) built regression models to predict essay scores based on features extracted from opinion expressions and topical elements. Chatterjee et al., (2014) used verbal descriptors and para-verbal markers of hesitation to predict speakers’ persuasiveness on website housing videos of product reviews. When looking at persuasion in the context of online forum discussions (Wei et al., 2016), Tan et al., (2016) found that on the Change My View subreddit, interaction dynamics such as the language interplay between opinion holders and other participants provides highly predictive cues for persuasiveness. Us"
N19-1364,P16-2089,0,0.0142165,"2019, pages 3620–3630 c Minneapolis, Minnesota, June 2 - June 7, 2019. 2019 Association for Computational Linguistics show that our semi-supervised model outperforms several baselines. We then apply this automated model to unseen requests from different domains and obtain nuanced findings of the importance of different strategies on persuasion success. Our model can be useful in any situation in which we have exogenous document-level supervision, but only small amounts of expensive human-annotated sentence labels. 2 Related Work Computational argumentation has received much recent attention (Ghosh et al., 2016; Stab and Gurevych, 2017; Peldszus and Stede, 2013; Stab et al., 2018; Ghosh et al., 2014). Most work has either identified the arguments in news articles (Sardianos et al., 2015) or user-generated web content (Habernal and Gurevych, 2017; Musi et al., 2018), or classified argument components (Zhang and Litman, 2015) into claims and premises, supporting and opposing claims, or backings, rebuttals and refutations . For example, Stab and Gurevych (2014) proposed structural, lexical, syntactic and contextual features to identify convincing components of Web arguments including claim, major claim"
N19-1364,N18-1146,1,0.848177,"s highly predictive cues for persuasiveness. Using the same dataset, Wel et al., (2016) extracted a set of textual information and social interaction features to identify persuasive posts. Recently, Pryzant et al., (2017) introduced a neural network with an adversarial objective to select text features that are predictive of some outcomes but decorrelated with others and further analyzed the narratives highlighted by such text features. Further work extended the model to induce narrative persuasion lexicons predictive of enrollment from course descriptions and sales from product descriptions (Pryzant et al., 2018a), and the efficacy of search advertisements (Pryzant et al., 2018b). Similar to their settings, we use the outcomes of a persuasive description to supervise the learning of persuasion tactics, and our model can similarly induce lexicons associated with successful narrative persuasion by examining highly attentional words associated with persuasion outcomes. Our work differs both in our semisupervised method and also because we explicitly draw on the theoretical literature to model the persuasion strategy for each sentence in requests, allowing requests to have multiple persuasion strategies;"
N19-1364,P16-2032,0,0.0625096,"s people’s attitudes and behaviors have received less attention from the computational community than argumentation, although there have been important preliminary work (Persing and Ng, 2017; Carlile et al., 2018). Farra et al., (2015) built regression models to predict essay scores based on features extracted from opinion expressions and topical elements. Chatterjee et al., (2014) used verbal descriptors and para-verbal markers of hesitation to predict speakers’ persuasiveness on website housing videos of product reviews. When looking at persuasion in the context of online forum discussions (Wei et al., 2016), Tan et al., (2016) found that on the Change My View subreddit, interaction dynamics such as the language interplay between opinion holders and other participants provides highly predictive cues for persuasiveness. Using the same dataset, Wel et al., (2016) extracted a set of textual information and social interaction features to identify persuasive posts. Recently, Pryzant et al., (2017) introduced a neural network with an adversarial objective to select text features that are predictive of some outcomes but decorrelated with others and further analyzed the narratives highlighted by such tex"
N19-1364,W18-5415,0,0.0153708,"s highly predictive cues for persuasiveness. Using the same dataset, Wel et al., (2016) extracted a set of textual information and social interaction features to identify persuasive posts. Recently, Pryzant et al., (2017) introduced a neural network with an adversarial objective to select text features that are predictive of some outcomes but decorrelated with others and further analyzed the narratives highlighted by such text features. Further work extended the model to induce narrative persuasion lexicons predictive of enrollment from course descriptions and sales from product descriptions (Pryzant et al., 2018a), and the efficacy of search advertisements (Pryzant et al., 2018b). Similar to their settings, we use the outcomes of a persuasive description to supervise the learning of persuasion tactics, and our model can similarly induce lexicons associated with successful narrative persuasion by examining highly attentional words associated with persuasion outcomes. Our work differs both in our semisupervised method and also because we explicitly draw on the theoretical literature to model the persuasion strategy for each sentence in requests, allowing requests to have multiple persuasion strategies;"
N19-1364,N16-1174,1,0.694918,"Missing"
N19-1364,D14-1006,0,0.0449685,", but only small amounts of expensive human-annotated sentence labels. 2 Related Work Computational argumentation has received much recent attention (Ghosh et al., 2016; Stab and Gurevych, 2017; Peldszus and Stede, 2013; Stab et al., 2018; Ghosh et al., 2014). Most work has either identified the arguments in news articles (Sardianos et al., 2015) or user-generated web content (Habernal and Gurevych, 2017; Musi et al., 2018), or classified argument components (Zhang and Litman, 2015) into claims and premises, supporting and opposing claims, or backings, rebuttals and refutations . For example, Stab and Gurevych (2014) proposed structural, lexical, syntactic and contextual features to identify convincing components of Web arguments including claim, major claim, and premise. Similarly, Zhang and Litman (2015) studied student essay revisions and classified a set of argumentative actions associated with successful writing such as warrant/reasoning/backing, rebuttal/reservation, and claims/ideas. Habernal and Gurevych (2016) investigated the persuasiveness of arguments in any given argument pair using bidirectional LSTM. Hidey et al., (2017) utilized the persuasive modes—ethos, logos, pathos—to model premises a"
N19-1364,W15-0616,0,0.0135048,"fferent strategies on persuasion success. Our model can be useful in any situation in which we have exogenous document-level supervision, but only small amounts of expensive human-annotated sentence labels. 2 Related Work Computational argumentation has received much recent attention (Ghosh et al., 2016; Stab and Gurevych, 2017; Peldszus and Stede, 2013; Stab et al., 2018; Ghosh et al., 2014). Most work has either identified the arguments in news articles (Sardianos et al., 2015) or user-generated web content (Habernal and Gurevych, 2017; Musi et al., 2018), or classified argument components (Zhang and Litman, 2015) into claims and premises, supporting and opposing claims, or backings, rebuttals and refutations . For example, Stab and Gurevych (2014) proposed structural, lexical, syntactic and contextual features to identify convincing components of Web arguments including claim, major claim, and premise. Similarly, Zhang and Litman (2015) studied student essay revisions and classified a set of argumentative actions associated with successful writing such as warrant/reasoning/backing, rebuttal/reservation, and claims/ideas. Habernal and Gurevych (2016) investigated the persuasiveness of arguments in any"
N19-1364,C16-1246,0,0.0447825,"Missing"
N19-1364,J17-3005,0,0.021144,"30 c Minneapolis, Minnesota, June 2 - June 7, 2019. 2019 Association for Computational Linguistics show that our semi-supervised model outperforms several baselines. We then apply this automated model to unseen requests from different domains and obtain nuanced findings of the importance of different strategies on persuasion success. Our model can be useful in any situation in which we have exogenous document-level supervision, but only small amounts of expensive human-annotated sentence labels. 2 Related Work Computational argumentation has received much recent attention (Ghosh et al., 2016; Stab and Gurevych, 2017; Peldszus and Stede, 2013; Stab et al., 2018; Ghosh et al., 2014). Most work has either identified the arguments in news articles (Sardianos et al., 2015) or user-generated web content (Habernal and Gurevych, 2017; Musi et al., 2018), or classified argument components (Zhang and Litman, 2015) into claims and premises, supporting and opposing claims, or backings, rebuttals and refutations . For example, Stab and Gurevych (2014) proposed structural, lexical, syntactic and contextual features to identify convincing components of Web arguments including claim, major claim, and premise. Similarly,"
P15-1161,P13-1035,0,0.038167,"Missing"
P15-1161,P14-1035,0,0.0135673,"icular contexts. Theory on coordination in groups and organizations emphasizes role differentiation, division of labor and formal and informal management (Kittur and Kraut, 2010). However, identification of roles as such has not had a corresponding strong emphasis in the language technologies community, although there has been work on related notions. For example, there has been much previous work modeling disagreement and debate framed as stance classification (Thomas et al., 2006; Walker et al., 2012). Another similar line of work studies the identification of personas (Bamman et al., 2013; Bamman et al., 2014) in the context of a social network, e.g. celebrity, newbie, lurker, flamer, troll and ranter, etc, which evolve through user interaction (Forestier et al., 2012). What is similar between stances and personas on the one hand and roles on the other is that the unit of analysis is the person. On the other hand, they are distinct in that stances (e.g., liberal) and personas (e.g., lurker) are not typically defined in terms of what they are meant to accomplish, although they may be associated with kinds of things they do. Teamwork roles are defined in terms of what the role holder is meant to acco"
P15-1161,D14-1226,0,0.0181563,"an be used effectively to predict the teamwork outcome. An empirical evaluation applied to two Massive Open Online Course (MOOCs) datasets demonstrates that this approach yields superior performance in learning representations for predicting the teamwork outcome over several baselines. 1 Carolyn Penstein Ros´e School of Computer Science Carnegie Mellon University Pittsburgh, PA, 15213, USA cprose@cs.cmu.edu Introduction In language technologies research seeking to model conversational interactions, modeling approaches have aimed to identify conversation acts (Paul, 2012; Wallace et al., 2013; Bhatia et al., 2014) on a per turn basis, or to identify stances (Germesin and Wilson, 2009; Mukherjee et al., 2013; Piergallini et al., 2014; Hasan and Ng, 2014) that characterize the nature of a speaker’s orientation within an interaction over several turns. What neither of these two perspectives quite offer is a notion of a conversational role. And yet, conversational role is a concept with great utility in current real world applications where language technologies may be applied. Important teamwork is achieved through collaboration where discussion is an important medium We present a modeling approach that l"
P15-1161,D13-1035,0,0.0291271,"ough they may be associated with kinds of things they do. Teamwork roles are defined in terms of what the role holder is meant to accomplish. The notion of a natural outcome associated with a role suggests a modeling approach utilizing the outcome as light supervision towards identification of the latent roles. However, representations of other notions such as stances or strategies can similarly be used to predict outcomes. Cadilhac et al. maps strategies based on verbal contributions of participants in a win-lose game into a prediction of exactly which players, if any, trade with each other (Cadilhac et al., 2013). Hu et al. (Hu et al., 2009) predict the outcome of featured article nominations based on user activeness, discussion consensus and user co-review relations. In other work, the authors of (Somasundaran and Wiebe, 2009) adopt manually annotated characters and leaders to predict which participants will achieve success in online debates. The difference is the interpretation of the latent constructs. The latent construct of a role, such as team leader, is defined in terms of a distribution of characteristics that describe how that role should ideally be carried out. However, in the case of stance"
P15-1161,D14-1083,0,0.0135337,"nstrates that this approach yields superior performance in learning representations for predicting the teamwork outcome over several baselines. 1 Carolyn Penstein Ros´e School of Computer Science Carnegie Mellon University Pittsburgh, PA, 15213, USA cprose@cs.cmu.edu Introduction In language technologies research seeking to model conversational interactions, modeling approaches have aimed to identify conversation acts (Paul, 2012; Wallace et al., 2013; Bhatia et al., 2014) on a per turn basis, or to identify stances (Germesin and Wilson, 2009; Mukherjee et al., 2013; Piergallini et al., 2014; Hasan and Ng, 2014) that characterize the nature of a speaker’s orientation within an interaction over several turns. What neither of these two perspectives quite offer is a notion of a conversational role. And yet, conversational role is a concept with great utility in current real world applications where language technologies may be applied. Important teamwork is achieved through collaboration where discussion is an important medium We present a modeling approach that leverages the concept of latent conversational roles as an intermediary between observed discussions and a measure of interaction success. Whil"
P15-1161,P09-1026,0,0.0156101,"ling approach utilizing the outcome as light supervision towards identification of the latent roles. However, representations of other notions such as stances or strategies can similarly be used to predict outcomes. Cadilhac et al. maps strategies based on verbal contributions of participants in a win-lose game into a prediction of exactly which players, if any, trade with each other (Cadilhac et al., 2013). Hu et al. (Hu et al., 2009) predict the outcome of featured article nominations based on user activeness, discussion consensus and user co-review relations. In other work, the authors of (Somasundaran and Wiebe, 2009) adopt manually annotated characters and leaders to predict which participants will achieve success in online debates. The difference is the interpretation of the latent constructs. The latent construct of a role, such as team leader, is defined in terms of a distribution of characteristics that describe how that role should ideally be carried out. However, in the case of stances, the latent constructs are learned in order to distinguish one stance from another or in order to predict who will win. This approach will not necessarily offer insight into what marks the most staunch proponents of a"
P15-1161,W06-1639,0,0.0507883,"n social science fields to describe the intersection of behavioral, symbolic, and structural attributes that emerge regularly in particular contexts. Theory on coordination in groups and organizations emphasizes role differentiation, division of labor and formal and informal management (Kittur and Kraut, 2010). However, identification of roles as such has not had a corresponding strong emphasis in the language technologies community, although there has been work on related notions. For example, there has been much previous work modeling disagreement and debate framed as stance classification (Thomas et al., 2006; Walker et al., 2012). Another similar line of work studies the identification of personas (Bamman et al., 2013; Bamman et al., 2014) in the context of a social network, e.g. celebrity, newbie, lurker, flamer, troll and ranter, etc, which evolve through user interaction (Forestier et al., 2012). What is similar between stances and personas on the one hand and roles on the other is that the unit of analysis is the person. On the other hand, they are distinct in that stances (e.g., liberal) and personas (e.g., lurker) are not typically defined in terms of what they are meant to accomplish, alth"
P15-1161,P13-1165,0,0.0183751,"o Massive Open Online Course (MOOCs) datasets demonstrates that this approach yields superior performance in learning representations for predicting the teamwork outcome over several baselines. 1 Carolyn Penstein Ros´e School of Computer Science Carnegie Mellon University Pittsburgh, PA, 15213, USA cprose@cs.cmu.edu Introduction In language technologies research seeking to model conversational interactions, modeling approaches have aimed to identify conversation acts (Paul, 2012; Wallace et al., 2013; Bhatia et al., 2014) on a per turn basis, or to identify stances (Germesin and Wilson, 2009; Mukherjee et al., 2013; Piergallini et al., 2014; Hasan and Ng, 2014) that characterize the nature of a speaker’s orientation within an interaction over several turns. What neither of these two perspectives quite offer is a notion of a conversational role. And yet, conversational role is a concept with great utility in current real world applications where language technologies may be applied. Important teamwork is achieved through collaboration where discussion is an important medium We present a modeling approach that leverages the concept of latent conversational roles as an intermediary between observed discuss"
P15-1161,D12-1009,0,0.0161744,"mited sized feature vectors that can be used effectively to predict the teamwork outcome. An empirical evaluation applied to two Massive Open Online Course (MOOCs) datasets demonstrates that this approach yields superior performance in learning representations for predicting the teamwork outcome over several baselines. 1 Carolyn Penstein Ros´e School of Computer Science Carnegie Mellon University Pittsburgh, PA, 15213, USA cprose@cs.cmu.edu Introduction In language technologies research seeking to model conversational interactions, modeling approaches have aimed to identify conversation acts (Paul, 2012; Wallace et al., 2013; Bhatia et al., 2014) on a per turn basis, or to identify stances (Germesin and Wilson, 2009; Mukherjee et al., 2013; Piergallini et al., 2014; Hasan and Ng, 2014) that characterize the nature of a speaker’s orientation within an interaction over several turns. What neither of these two perspectives quite offer is a notion of a conversational role. And yet, conversational role is a concept with great utility in current real world applications where language technologies may be applied. Important teamwork is achieved through collaboration where discussion is an important"
P15-1161,E14-1012,1,0.734433,"Missing"
P15-1161,N12-1072,0,0.0182326,"ds to describe the intersection of behavioral, symbolic, and structural attributes that emerge regularly in particular contexts. Theory on coordination in groups and organizations emphasizes role differentiation, division of labor and formal and informal management (Kittur and Kraut, 2010). However, identification of roles as such has not had a corresponding strong emphasis in the language technologies community, although there has been work on related notions. For example, there has been much previous work modeling disagreement and debate framed as stance classification (Thomas et al., 2006; Walker et al., 2012). Another similar line of work studies the identification of personas (Bamman et al., 2013; Bamman et al., 2014) in the context of a social network, e.g. celebrity, newbie, lurker, flamer, troll and ranter, etc, which evolve through user interaction (Forestier et al., 2012). What is similar between stances and personas on the one hand and roles on the other is that the unit of analysis is the person. On the other hand, they are distinct in that stances (e.g., liberal) and personas (e.g., lurker) are not typically defined in terms of what they are meant to accomplish, although they may be assoc"
P15-1161,D13-1182,0,0.0220451,"feature vectors that can be used effectively to predict the teamwork outcome. An empirical evaluation applied to two Massive Open Online Course (MOOCs) datasets demonstrates that this approach yields superior performance in learning representations for predicting the teamwork outcome over several baselines. 1 Carolyn Penstein Ros´e School of Computer Science Carnegie Mellon University Pittsburgh, PA, 15213, USA cprose@cs.cmu.edu Introduction In language technologies research seeking to model conversational interactions, modeling approaches have aimed to identify conversation acts (Paul, 2012; Wallace et al., 2013; Bhatia et al., 2014) on a per turn basis, or to identify stances (Germesin and Wilson, 2009; Mukherjee et al., 2013; Piergallini et al., 2014; Hasan and Ng, 2014) that characterize the nature of a speaker’s orientation within an interaction over several turns. What neither of these two perspectives quite offer is a notion of a conversational role. And yet, conversational role is a concept with great utility in current real world applications where language technologies may be applied. Important teamwork is achieved through collaboration where discussion is an important medium We present a mo"
P15-1161,H05-1044,0,0.00709015,"on Words: counts of question related words in the posts, e.g. why, what, question, problem, how, answer, etc. 8. Discrepancy: number of occurrences of words, such as should, would, could, etc as defined in LIWC (Tausczik and Pennebaker, 2010). 9. Social Process: number of words that denote social processes and suggest human interaction, e.g. talking, sharing, etc. 10. Cognitive Process: number of occurrences of words that reflect thinking and reasoning, e.g. cause, because, thus, etc. 11-14. Polarity: four variables that measure the portion of Positive, Negative, Neutral, Both polarity words (Wilson et al., 2005) in the posts. 15-16. Subjectivity: two count variables of occurrences of Strong Subjectivity words and Weak Subjectivity words. Activities: We also introduce several variables to measure the activeness level of team members. 17-18. Messages: two variables that measure the total number of messages sent, and the number of tokens contained in the messages. 19-20. Videos: the number of videos a student has watched and total duration of watched videos. 21. Login Times: times that a student logins to the course. 4 Experiments In this section, we begin with the dataset description, and then we compa"
W14-4104,P08-2025,0,0.0201771,"t al., 2012) has focused on understanding the dynamics of the surrounding community activity, like the process through which answers and voters arrive over time. Based on understanding of such factors, a prediction can be made about the long term value for the community of a question being answered. Similarly, Agichtein and colleagues (Agichtein et al., 2009) presented a general prediction model of information seeker satisfaction in community question answering, and developed content, structure and community focused features for the question answering task. A collection of other related work (Liu and Agichtein, 2008) has developed personalized models of asker satisfaction to predict whether a particular question starter will be satisfied with the answers given 22 by others. This is solved by exploring content, structure and interaction features using standard prediction models. Work on automated question answering systems can also be seen as relevant since questions that can be answered automatically do not need a human response, and therefore might reduce the load on available human effort. Instead of predicting whether a problem is answered, strategies for predicting are explored when a question answeri"
W14-4104,W02-1033,0,0.0105395,"faction to predict whether a particular question starter will be satisfied with the answers given 22 by others. This is solved by exploring content, structure and interaction features using standard prediction models. Work on automated question answering systems can also be seen as relevant since questions that can be answered automatically do not need a human response, and therefore might reduce the load on available human effort. Instead of predicting whether a problem is answered, strategies for predicting are explored when a question answering system is likely to give an incorrect answer (Brill et al., 2002). To further understand how a question is answered, researchers (Yih et al., 2013) have studied the answer sentence selection problem for question answering and improves the model performance by using lexical semantic resources. That is, they construct semantic matches between question and answers. In terms of the extent to which the question is answered, Shah and colleagues (Shah and Pomerantz, 2010) evaluated answer quality by manually rating the quality of each answer. Then they extracted various features to train classifiers to select the best answer for that question. Liu et al. (Liu et a"
W14-4104,P13-1025,0,0.0190337,"of thread popularity. The Total UpVotes xT vt and Max UpVotes xM vt are used to represent the credit this thread has received and how others recognize the current discussion. Based on our analysis, people rarely give a downvote to others’ posts. The Question Votes xSvt indicates whether the starter formulates a problem that wins recognition from others. For Total Upvotes, we find that in resolved threads, it is 6.10 compared to 3.15 in unresolved thread. Thus, intuitively, thread popularity has the potential to give a useful prediction of thread resolveability. 4.4 Friendliness Friendliness (Danescu-Niculescu-Mizil et al., 2013; Burke and Kraut, 2008) concerns whether the current conversation is conducive for others to discuss ideas. This has not been considered in existing question answering work, and we thus discuss our operationalization of politeness here. We hypothesize that resolved threads posses more polite words, such as ’thank’. For example, a resolved thread might end with gratitude to thank others for providing help, and indeed we see this. Thus, we specify a set of observed indicators that may be useful in a latent variable model of politeness. (1) Start with Thanks: xStx , Expert Participation Who part"
W14-4104,P14-1092,0,0.0146572,"rious features to train classifiers to select the best answer for that question. Liu et al. (Liu et al., 2011) proposed to use a mutual reinforcement based propagation algorithm to predict question quality based. The model makes its prediction based on the connection between askers and topics, and how those connections predict differences in quality. The above question answering work is all about general discussion forums (Qu et al., 2009; Kabutoya et al., 2010), such as Yahoo! Answers2 . In our work, in addition to taking advantage of existing QA work, we also adopt a linguistic perspective (Jansen et al., 2014) and take semantic matching into account using a latent semantic approach. To the best of our knowledge, this is the first work on thread resolvability analysis in a MOOC context. 3 readings or lectures, students have the opportunity to initiate a thread in the course forum, in order to engage other students in the class as well as the teaching staff. For example, if a student were confused about the distinction between an argument and a parameter in Python, he/she would post the question to the variables subforum, marking it unresolved at the same time. In the ideal case, another participant"
W14-4104,P13-1171,0,0.0155598,"answers given 22 by others. This is solved by exploring content, structure and interaction features using standard prediction models. Work on automated question answering systems can also be seen as relevant since questions that can be answered automatically do not need a human response, and therefore might reduce the load on available human effort. Instead of predicting whether a problem is answered, strategies for predicting are explored when a question answering system is likely to give an incorrect answer (Brill et al., 2002). To further understand how a question is answered, researchers (Yih et al., 2013) have studied the answer sentence selection problem for question answering and improves the model performance by using lexical semantic resources. That is, they construct semantic matches between question and answers. In terms of the extent to which the question is answered, Shah and colleagues (Shah and Pomerantz, 2010) evaluated answer quality by manually rating the quality of each answer. Then they extracted various features to train classifiers to select the best answer for that question. Liu et al. (Liu et al., 2011) proposed to use a mutual reinforcement based propagation algorithm to pr"
