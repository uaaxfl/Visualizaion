W17-2315,Biomedical Event Extraction using {A}bstract {M}eaning {R}epresentation,2017,32,15,2,0,4267,sudha rao,{B}io{NLP} 2017,0,"We propose a novel, Abstract Meaning Representation (AMR) based approach to identifying molecular events/interactions in biomedical text. Our key contributions are: (1) an empirical validation of our hypothesis that an event is a subgraph of the AMR graph, (2) a neural network-based model that identifies such an event subgraph given an AMR, and (3) a distant supervision based approach to gather additional training data. We evaluate our approach on the 2013 Genia Event Extraction dataset and show promising results."
W16-5907,Unsupervised Neural Hidden {M}arkov Models,2016,26,7,4,0,9984,ke tran,Proceedings of the Workshop on Structured Prediction for {NLP},0,"In this work, we present the first results for neuralizing an Unsupervised Hidden Markov Model. We evaluate our approach on tag in- duction. Our approach outperforms existing generative models and is competitive with the state-of-the-art though with a simpler model easily extended to include additional context."
N16-1029,Name Tagging for Low-resource Incident Languages based on Expectation-driven Learning,2016,46,14,7,0,10367,boliang zhang,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"In this paper we tackle a challenging name tagging problem in an emergent setting the tagger needs to be complete within a few hours for a new incident language (IL) using very few resources. Inspired by observing how human annotators attack this challenge, we propose a new expectation-driven learning framework. In this framework we rapidly acquire, categorize, structure and zoom in on ILspecific expectations (rules, features, patterns, gazetteers, etc.) from various non-traditional sources: consulting and encoding linguistic knowledge from native speakers, mining and projecting patterns from both mono-lingual and cross-lingual corpora, and typing based on cross-lingual entity linking. We also propose a cost-aware combination approach to compose expectations. Experiments on seven low-resource languages demonstrate the effectiveness and generality of this framework: we are able to setup a name tagger for a new IL within two hours, and achieve 33.8%-65.1% F-score 1."
N16-1089,Natural Language Communication with Robots,2016,15,46,3,0,8387,yonatan bisk,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,None
L16-1067,Extracting Structured Scholarly Information from the Machine Translation Literature,2016,8,1,5,0,3377,eunsol choi,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Understanding the experimental results of a scientific paper is crucial to understanding its contribution and to comparing it with related work. We introduce a structured, queryable representation for experimental results and a baseline system that automatically populates this representation. The representation can answer compositional questions such as: {``}Which are the best published results reported on the NIST 09 Chinese to English dataset?{''} and {``}What are the most important methods for speeding up phrase-based decoding?{''} Answering such questions usually involves lengthy literature surveys. Current machine reading for academic papers does not usually consider the actual experiments, but mostly focuses on understanding abstracts. We describe annotation work to create an initial hscientific paper; experimental results representationi corpus. The corpus is composed of 67 papers which were manually annotated with a structured representation of experimental results by domain experts. Additionally, we present a baseline algorithm that characterizes the difficulty of the inference task."
D15-1136,Parsing {E}nglish into {A}bstract {M}eaning {R}epresentation Using Syntax-Based Machine Translation,2015,38,27,4,0,25437,michael pust,Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,0,"We present a parser for Abstract Meaning Representation (AMR). We treat Englishto-AMR conversion within the framework of string-to-tree, syntax-based machine translation (SBMT). To make this work, we transform the AMR structure into a form suitable for the mechanics of SBMT and useful for modeling. We introduce an AMR-specific language model and add data and features drawn from semantic resources. Our resulting AMR parser significantly improves upon state-of-the-art results."
N12-1017,{H}y{TER}: Meaning-Equivalent Semantics for Translation Evaluation,2012,16,39,2,0,3109,markus dreyer,Proceedings of the 2012 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"It is common knowledge that translation is an ambiguous, 1-to-n mapping process, but to date, our community has produced no empirical estimates of this ambiguity. We have developed an annotation tool that enables us to create representations that compactly encode an exponential number of correct translations for a sentence. Our findings show that naturally occurring sentences have billions of translations. Having access to such large sets of meaning-equivalent translations enables us to develop a new metric, HyTER, for translation accuracy. We show that our metric provides better estimates of machine and human translation accuracy than alternative evaluation metrics."
N12-1061,Automatic Parallel Fragment Extraction from Noisy Data,2012,11,12,2,1,20400,jason riesa,Proceedings of the 2012 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"We present a novel method to detect parallel fragments within noisy parallel corpora. Isolating these parallel fragments from the noisy data in which they are contained frees us from noisy alignments and stray links that can severely constrain translation-rule extraction. We do this with existing machinery, making use of an existing word alignment model for this task. We evaluate the quality and utility of the extracted data on large-scale Chinese-English and Arabic-English translation tasks and show significant improvements over a state-of-the-art baseline."
2012.amta-government.9,A New Method for Automatic Translation Scoring-{H}y{TER},2012,-1,-1,1,1,31937,daniel marcu,Proceedings of the 10th Conference of the Association for Machine Translation in the Americas: Government MT User Program,0,"It is common knowledge that translation is an ambiguous, 1-to-n mapping process, but to date, our community has produced no empirical estimates of this ambiguity. We have developed an annotation tool that enables us to create representations that compactly encode an exponential number of correct translations for a sentence. Our findings show that naturally occurring sentences have billions of translations. Having access to such large sets of meaning-equivalent translations enables us to develop a new metric, HyTER, for translation accuracy. We show that our metric provides better estimates of machine and human translation accuracy than alternative evaluation metrics using data from the most recent Open MT NIST evaluation and we discuss how HyTER representations can be used to inform a data-driven inquiry into natural language semantics."
D11-1046,Feature-Rich Language-Independent Syntax-Based Alignment for Statistical Machine Translation,2011,41,18,3,1,20400,jason riesa,Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,0,"We present an accurate word alignment algorithm that heavily exploits source and target-language syntax. Using a discriminative framework and an efficient bottom-up search algorithm, we train a model of hundreds of thousands of syntactic features. Our new model (1) helps us to very accurately model syntactic transformations between languages; (2) is language-independent; and (3) with automatic feature extraction, assists system developers in obtaining good word-alignment performance off-the-shelf when tackling new language pairs. We analyze the impact of our features, describe inference under the model, and demonstrate significant alignment and translation quality improvements over already-powerful baselines trained on very large corpora. We observe translation quality improvements corresponding to 1.0 and 1.3 BLEU for Arabic-English and Chinese-English, respectively."
2011.iwslt-keynotes.2,"Meaning-equivalent semantics forunderstanding, generation, translation, and evaluation",2011,-1,-1,1,1,31937,daniel marcu,Proceedings of the 8th International Workshop on Spoken Language Translation: Keynotes,0,None
P10-1017,Hierarchical Search for Word Alignment,2010,30,30,2,1,20400,jason riesa,Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,1,"We present a simple yet powerful hierarchical search algorithm for automatic word alignment. Our algorithm induces a forest of alignments from which we can efficiently extract a ranked k-best list. We score a given alignment within the forest with a flexible, linear discriminative model incorporating hundreds of features, and trained on a relatively small amount of annotated data. We report results on Arabic-English word alignment and translation tasks. Our model outperforms a GIZA Model-4 baseline by 6.3 points in F-measure, yielding a 1.1 Bleu score increase over a state-of-the-art syntax-based machine translation system."
J10-2004,"Re-structuring, Re-labeling, and Re-aligning for Syntax-Based Machine Translation",2010,43,44,4,1,4596,wei wang,Computational Linguistics,0,"This article shows that the structure of bilingual material from standard parsing and alignment tools is not optimal for training syntax-based statistical machine translation (SMT) systems. We present three modifications to the MT training data to improve the accuracy of a state-of-the-art syntax MT system: re-structuring changes the syntactic structure of training parse trees to enable reuse of substructures; re-labeling alters bracket labels to enrich rule application context; and re-aligning unifies word alignment across sentences to remove bad word alignments and refine good ones. Better structures, labels, and word alignments are learned by the EM algorithm. We show that each individual technique leads to improvement as measured by BLEU, and we also show that the greatest improvement is achieved by combining them. We report an overall 1.48 BLEU improvement on the NIST08 evaluation set over a strong baseline in Chinese/English translation."
2010.jec-1.1,Creating Value at the Boundary Between Humans and Machines,2010,-1,-1,1,1,31937,daniel marcu,Proceedings of the Second Joint EM+/CNGL Workshop: Bringing MT to the User: Research on Integrating MT in the Translation Industry,0,"For a long time, machine translation and professional translation vendors have had a contentious relation. However, new tools, computing platforms, and business models are changing the fundamentals of this relationship. I will review the main trends in the area while emphasizing both past causes of failure and main drivers of success."
2010.amta-government.2,Utilizing Automated Translation with Quality Scores to Increase Productivity,2010,-1,-1,1,1,31937,daniel marcu,Proceedings of the 9th Conference of the Association for Machine Translation in the Americas: Government MT User Program,0,"Automated translation can assist with a variety of translation needs in government, from speeding up access to information for intelligence work to helping human translators increase their productivity. However, government entities need to have a mechanism in place so that they know whether or not they can trust the output from automated translation solutions. In this presentation, Language Weaver will present a new capability ``TrustScore'': an automated scoring algorithm that communicates how good the automated translation is, using a meaningful metric. With this capability, each translation is automatically assigned a score from 1 to 5 in the TrustScore. A score of 1 would indicate that the translation is unintelligible; a score of 3 would indicate that meaning has been conveyed and that the translated content is actionable. A score approaching 4 or higher would indicate that meaning and nuance have been carried through. This automatic prediction of quality has been validated by testing done across significant numbers of data points in different companies and on different types of content. After outlining TrustScore, and how it works, Language Weaver will discuss how a scoring mechanism like TrustScore could be used in a translation productivity workflow in government to assist linguists with day to day translation work. This would enable them to further benefit from their investments in automated translation software. Language Weaver would also share how TrustScore is used in commercial deployments to cost effectively publish information in near real time."
2010.amta-commercial.17,Trusted Translations Deliver Compelling Results for the Travel Industry,2010,-1,-1,1,1,31937,daniel marcu,Proceedings of the 9th Conference of the Association for Machine Translation in the Americas: Commercial MT User Program,0,None
2008.amta-govandcom.18,Language Translation Solutions for Community Content,2008,-1,-1,1,1,31937,daniel marcu,Proceedings of the 8th Conference of the Association for Machine Translation in the Americas: Government and Commercial Uses of MT,0,None
J07-3002,Squibs and Discussions: Measuring Word Alignment Quality for Statistical Machine Translation,2007,23,172,2,1,3265,alexander fraser,Computational Linguistics,0,"Automatic word alignment plays a critical role in statistical machine translation. Unfortunately, the relationship between alignment quality and statistical machine translation performance has not been well understood. In the recent literature, the alignment task has frequently been decoupled from the translation task and assumptions have been made about measuring alignment quality for machine translation which, it turns out, are not justified. In particular, none of the tens of papers published over the last five years has shown that significant decreases in alignment error rate (AER) result in significant increases in translation performance. This paper explains this state of affairs and presents steps towards measuring alignment quality in a way which is predictive of statistical machine translation performance."
D07-1006,Getting the Structure Right for Word Alignment: {LEAF},2007,30,56,2,1,3265,alexander fraser,Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning ({EMNLP}-{C}o{NLL}),0,"Word alignment is the problem of annotating parallel text with translational correspondence. Previous generative word alignment models have made structural assumptions such as the 1-to-1, 1-to-N, or phrase-based consecutive word assumptions, while previous discriminative models have either made such an assumption directly or used features derived from a generative model making one of these assumptions. We present a new generative alignment model which avoids these structural limitations, and show that it is effective when trained using both unsupervised and semi-supervised training methods."
D07-1078,Binarizing Syntax Trees to Improve Syntax-Based Machine Translation Accuracy,2007,16,69,3,1,4596,wei wang,Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning ({EMNLP}-{C}o{NLL}),0,We show that phrase structures in Penn Treebank style parses are not optimal for syntaxbased machine translation. We exploit a series of binarization methods to restructure the Penn Treebank style trees such that syntactified phrases smaller than Penn Treebank constituents can be acquired and exploited in translation. We find that by employing the EM algorithm for determining the binarization of a parse tree among a set of alternative binarizations gives us the best translation result.
D07-1079,What Can Syntax-Based {MT} Learn from Phrase-Based {MT}?,2007,22,79,4,0,11017,steve deneefe,Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning ({EMNLP}-{C}o{NLL}),0,"We compare and contrast the strengths and weaknesses of a syntax-based machine translation model with a phrase-based machine translation model on several levels. We briefly describe each model, highlighting points where they differ. We include a quantitative comparison of the phrase pairs that each model has to work with, as well as the reasons why some phrase pairs are not learned by the syntax-based model. We then evaluate proposed improvements to the syntax-based extraction techniques in light of phrase pairs captured. We also compare the translation accuracy for all variations."
W06-1606,{SPMT}: Statistical Machine Translation with Syntactified Target Language Phrases,2006,16,206,1,1,31937,daniel marcu,Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,0,"We introduce SPMT, a new class of statistical Translation Models that use Syntactified target language Phrases. The SPMT models outperform a state of the art phrase-based baseline model by 2.64 Bleu points on the NIST 2003 Chinese-English test corpus and 0.28 points on a human-based quality metric that ranks translations on a scale from 1 to 5."
P06-2103,Discourse Generation Using Utility-Trained Coherence Models,2006,26,65,2,1,4002,radu soricut,Proceedings of the {COLING}/{ACL} 2006 Main Conference Poster Sessions,0,We describe a generic framework for integrating various stochastic models of discourse coherence in a manner that takes advantage of their individual strengths. An integral part of this framework are algorithms for searching and training these stochastic coherence models. We evaluate the performance of our models and algorithms and show empirically that utility-trained log-linear coherence models outperform each of the individual coherence models considered.
P06-1011,Extracting Parallel Sub-Sentential Fragments from Non-Parallel Corpora,2006,28,138,2,1,28507,dragos munteanu,Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,1,"We present a novel method for extracting parallel sub-sentential fragments from comparable, non-parallel bilingual corpora. By analyzing potentially similar sentence pairs using a signal processing-inspired approach, we detect which segments of the source sentence are translated into segments in the target sentence, and which are not. This method enables us to extract useful machine translation training data even from very non-parallel corpora, which contain no parallel sentence pairs. We evaluate the quality of the extracted data by showing that it improves the performance of a state-of-the-art statistical machine translation system."
P06-1039,{B}ayesian Query-Focused Summarization,2006,13,181,2,1,4346,hal iii,Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,1,"We present BAYESUM (for Bayesian summarization), a model for sentence extraction in query-focused summarization. BAYESUM leverages the common case in which multiple documents are relevant to a single query. Using these documents as reinforcement for query terms, BAYESUM is not afflicted by the paucity of information in short queries. We show that approximate inference in BAYESUM is possible on large data sets and results in a state-of-the-art summarization system. Furthermore, we show how BAYESUM can be understood as a justified query expansion technique in the language modeling for IR framework."
P06-1097,Semi-Supervised Training for Statistical Word Alignment,2006,443,114,2,1,3265,alexander fraser,Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,1,"We introduce a semi-supervised approach to training for statistical machine translation that alternates the traditional Expectation Maximization step that is applied on a large training corpus with a discriminative step aimed at increasing word-alignment quality on a small, manually word-aligned sub-corpus. We show that our algorithm leads not only to improved alignments but also to machine translation outputs of higher quality."
P06-1121,Scalable Inference and Training of Context-Rich Syntactic Translation Models,2006,10,416,4,0.833333,4268,michel galley,Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,1,"Statistical MT has made great progress in the last few years, but current translation models are weak on re-ordering and target language fluency. Syntactic approaches seek to remedy these problems. In this paper, we take the framework for acquiring multi-level syntactic translation rules of (Galley et al., 2004) from aligned tree-string pairs, and present two main extensions of their approach: first, instead of merely computing a single derivation that minimally explains a sentence pair, we construct a large number of derivations that include contextually richer rules, and account for multiple interpretations of unaligned words. Second, we propose probability estimates and a training procedure for weighting these rules. We contrast different approaches on real examples, show that our estimates based on multiple derivations favor phrasal re-orderings that are linguistically better motivated, and establish that our larger rules provide a 3.63 BLEU point increase over minimal rules."
P06-1139,Stochastic Language Generation Using {WIDL}-Expressions and its Application in Machine Translation and Summarization,2006,21,26,2,1,4002,radu soricut,Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,1,"We propose WIDL-expressions as a flexible formalism that facilitates the integration of a generic sentence realization system within end-to-end language processing applications. WIDL-expressions represent compactly probability distributions over finite sets of candidate realizations, and have optimal algorithms for realization via interpolation with language model probability distributions. We show the effectiveness of a WIDL-based NLG system in two sentence realization tasks: automatic translation and headline generation."
N06-1001,Capitalizing Machine Translation,2006,13,50,3,1,4596,wei wang,"Proceedings of the Human Language Technology Conference of the {NAACL}, Main Conference",0,"We present a probabilistic bilingual capitalization model for capitalizing machine translation outputs using conditional random fields. Experiments carried out on three language pairs and a variety of experiment conditions show that our model significantly outperforms a strong monolingual capitalization model baseline, especially when working with small datasets and/or European language pairs."
2006.amta-talks.1,The Potential and Limitations of {MT} Paradigm,2006,-1,-1,1,1,31937,daniel marcu,Proceedings of the 7th Conference of the Association for Machine Translation in the Americas: Invited Talks,0,None
W05-0814,{ISI}{`}s Participation in the {R}omanian-{E}nglish Alignment Task,2005,8,13,2,1,3265,alexander fraser,Proceedings of the {ACL} Workshop on Building and Using Parallel Texts,0,We discuss results on the shared task of Romanian-English word alignment. The baseline technique is that of symmetrizing two word alignments automatically generated using IBM Model 4. A simple vocabulary reduction technique results in an improvement in performance. We also report on a new alignment model and a new training algorithm based on alternating maximization of likelihood with minimization of error rate.
P05-3023,{T}ransonics: A Practical Speech-to-Speech Translator for {E}nglish-{F}arsi Medical Dialogs,2005,5,15,6,0,50887,robert belvin,Proceedings of the {ACL} Interactive Poster and Demonstration Sessions,0,"We briefly describe a two-way speech-to-speech English-Farsi translation system prototype developed for use in doctor-patient interactions. The overarching philosophy of the developers has been to create a system that enables effective communication, rather than focusing on maximizing component-level performance. The discussion focuses on the general approach and evaluation of the system by an independent government evaluation team."
P05-1009,Towards Developing Generation Algorithms for Text-to-Text Applications,2005,18,15,2,1,4002,radu soricut,Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics ({ACL}{'}05),1,"We describe a new sentence realization framework for text-to-text applications. This framework uses IDL-expressions as a representation formalism, and a generation mechanism based on algorithms for intersecting IDL-expressions with probabilistic language models. We present both theoretical and empirical results concerning the correctness and efficiency of these algorithms."
J05-4003,Improving Machine Translation Performance by Exploiting Non-Parallel Corpora,2005,37,308,2,1,28507,dragos munteanu,Computational Linguistics,0,"We present a novel method for discovering parallel sentences in comparable, non-parallel corpora. We train a maximum entropy classifier that, given a pair of sentences, can reliably determine whether or not they are translations of each other. Using this approach, we extract parallel data from large Chinese, Arabic, and English non-parallel newspaper corpora. We evaluate the quality of the extracted data by showing that it improves the performance of a state-of-the-art statistical machine translation system. We also show that a good-quality MT system can be built from scratch by starting with a very small parallel corpus (100,000 words) and exploiting a large non-parallel corpus. Thus, our method can be applied with great benefit to language pairs for which only scarce resources are available."
J05-4004,Induction of Word and Phrase Alignments for Automatic Document Summarization,2005,40,33,2,1,4346,hal iii,Computational Linguistics,0,"Current research in automatic single-document summarization is dominated by two effective, yet naive approaches: summarization by sentence extraction and headline generation via bag-of-words models. While successful in some tasks, neither of these models is able to adequately capture the large set of linguistic devices utilized by humans when they produce summaries. One possible explanation for the widespread use of these models is that good techniques have been developed to extract appropriate training data for them from existing document/abstract and document/headline corpora. We believe that future progress in automatic summarization will be driven both by the development of more sophisticated, linguistically informed models, as well as a more effective leveraging of document/abstract corpora. In order to open the doors to simultaneously achieving both of these goals, we have developed techniques for automatically producing word-to-word and phrase-to-phrase alignments between documents and their human-written abstracts. These alignments make explicit the correspondences that exist in such document/abstract pairs and create a potentially rich data source from which complex summarization algorithms may learn. This paper describes experiments we have carried out to analyze the ability of humans to perform such alignments, and based on these analyses, we describe experiments for creating them automatically. Our model for the alignment task is based on an extension of the standard hidden Markov model and learns to create alignments in a completely unsupervised fashion. We describe our model in detail and present experimental results that show that our model is able to learn to reliably identify word- and phrase-level alignments in a corpus of document, abstract pairs."
H05-2009,Translation Exercise Assistant: Automated Generation of Translation,2005,0,0,2,1,30726,jill burstein,Proceedings of {HLT}/{EMNLP} 2005 Interactive Demonstrations,0,None
H05-1013,A Large-Scale Exploration of Effective Global Features for a Joint Entity Detection and Tracking Model,2005,13,74,2,1,4346,hal iii,Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing,0,"Entity detection and tracking (EDT) is the task of identifying textual mentions of real-world entities in documents, extending the named entity detection and coreference resolution task by considering mentions other than names (pronouns, definite descriptions, etc.). Like NE tagging and coreference resolution, most solutions to the EDT task separate out the mention detection aspect from the coreference aspect. By doing so, these solutions are limited to using only local features for learning. In contrast, by modeling both aspects of the EDT task simultaneously, we are able to learn using highly complex, non-local features. We develop a new joint EDT model and explore the utility of many features, demonstrating their effectiveness on this task."
W04-3216,A Phrase-Based {HMM} Approach to Document/Abstract Alignment,2004,12,26,2,1,4346,hal iii,Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing,0,None
W04-3233,{NP} Bracketing by Maximum Entropy Tagging and {SVM} Reranking,2004,14,17,2,1,4346,hal iii,Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing,0,None
W04-1617,Language Weaver {A}rabic-{\\textgreater}{E}nglish {MT},2004,0,1,1,1,31937,daniel marcu,Proceedings of the Workshop on Computational Approaches to {A}rabic Script-based Languages,0,This presentation is primarily a demonstration of a working statistical machine translation system which translates Modern Standard Arabic into English.
W04-1016,Generic Sentence Fusion is an Ill-Defined Summarization Task,2004,11,14,2,1,4346,hal iii,Text Summarization Branches Out,0,"Abstract : We report on a series of human evaluations of the task of sentence fusion. In this task, a human is given two sentences and asked to produce a single coherent sentence that contains only the important information from the original two. Thus, this is a highly constrained summarization task. Our investigations show that even at this restricted level, there is no measurable agreement between humans regarding what information should be considered important. We further investigate the ability of separate evaluators to assess summaries, and find similarly disturbing lack of agreement."
W04-0501,(Invited presentation) The Perils and Rewards of Developing Restricted Domain Applications,2004,-1,-1,1,1,31937,daniel marcu,Proceedings of the Conference on Question Answering in Restricted Domains,0,None
N04-1024,Evaluating Multiple Aspects of Coherence in Student Essays,2004,13,87,3,0,34095,derrick higgins,Proceedings of the Human Language Technology Conference of the North {A}merican Chapter of the Association for Computational Linguistics: {HLT}-{NAACL} 2004,0,"Criterion Online Essay Evaluation Service includes a capability that labels sentences in student writing with essay-based discourse elements (e.g., thesis statements). We describe a new system that enhances Criterionxe2x80x99s capability, by evaluating multiple aspects of coherence in essays. This system identifies features of sentences based on semantic similarity measures and discourse structure. A support vector machine uses these features to capture breakdowns in coherence due to relatedness to the essay question and relatedness between discourse elements. Intra-sentential quality is evaluated with rule-based heuristics. Results indicate that the system yields higher performance than a baseline on all three aspects."
N04-1034,Improved Machine Translation Performance via Parallel Sentence Extraction from Comparable Corpora,2004,0,77,3,1,28507,dragos munteanu,Proceedings of the Human Language Technology Conference of the North {A}merican Chapter of the Association for Computational Linguistics: {HLT}-{NAACL} 2004,0,None
N04-1035,What{'}s in a translation rule?,2004,9,450,4,0.833333,4268,michel galley,Proceedings of the Human Language Technology Conference of the North {A}merican Chapter of the Association for Computational Linguistics: {HLT}-{NAACL} 2004,0,"Abstract : We propose a theory that gives formal semantics to word-level alignments defined over parallel corpora. We use our theory to introduce a linear algorithm that can be used to derive from word-aligned, parallel corpora the minimal set of syntactically motivated transformation rules that explain human translation data."
2004.iwslt-evaluation.9,The {ISI}/{USC} {MT} system,2004,2,8,3,1,47735,emil ettelaie,Proceedings of the First International Workshop on Spoken Language Translation: Evaluation Campaign,0,None
P03-1003,A Noisy-Channel Approach to Question Answering,2003,18,144,2,0,40430,abdessamad echihabi,Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,1,"We introduce a probabilistic noisy-channel model for question answering and we show how it can be exploited in the context of an end-to-end QA system. Our noisy-channel system outperforms a state-of-the-art rule-based QA system that uses similar resources. We also show that the model we propose is flexible enough to accommodate within one mathematical framework many QA-specific resources and techniques, which range from the exploitation of WordNet, structured, and semi-structured databases to reasoning, and paraphrasing."
N03-2016,Cognates Can Improve Statistical Translation Models,2003,7,86,2,0,1894,grzegorz kondrak,Companion Volume of the Proceedings of {HLT}-{NAACL} 2003 - Short Papers,0,We report results of experiments aimed at improving the translation quality by incorporating the cognate information into translation models. The results confirm that the cognate identification approach can improve the quality of word alignment in bitexts without the need for extra resources.
N03-1017,Statistical Phrase-Based Translation,2003,15,2805,3,0,4417,philipp koehn,Proceedings of the 2003 Human Language Technology Conference of the North {A}merican Chapter of the Association for Computational Linguistics,0,"We propose a new phrase-based translation model and decoding algorithm that enables us to evaluate and compare several, previously proposed phrase-based translation models. Within our framework, we carry out a large number of experiments to understand better and explain why phrase-based models out-perform word-based models. Our empirical results, which hold for all examined language pairs, suggest that the highest levels of performance can be obtained through relatively simple means: heuristic learning of phrase translations from word-based alignments and lexical weighting of phrase translations. Surprisingly, learning phrases longer than three words and learning phrases from high-accuracy word-level alignment models does not have a strong impact on performance. Learning only syntactically motivated phrases degrades the performance of our systems."
N03-1024,Syntax-based Alignment of Multiple Translations: Extracting Paraphrases and Generating New Sentences,2003,16,207,3,0,4447,bo pang,Proceedings of the 2003 Human Language Technology Conference of the North {A}merican Chapter of the Association for Computational Linguistics,0,"We describe a syntax-based algorithm that automatically builds Finite State Automata (word lattices) from semantically equivalent translation sets. These FSAs are good representations of paraphrases. They can be used to extract lexical and syntactic paraphrase pairs and to generate new, unseen sentences that express the same meaning as the sentences in the input sets. Our FSAs can also predict the correctness of alternative semantic renderings, which may be used to evaluate the quality of translations."
N03-1030,Sentence Level Discourse Parsing using Syntactic and Lexical Information,2003,18,332,2,1,4002,radu soricut,Proceedings of the 2003 Human Language Technology Conference of the North {A}merican Chapter of the Association for Computational Linguistics,0,We introduce two probabilistic models that can be used to identify elementary discourse units and build sentence-level discourse parse trees. The models use syntactic and lexical features. A discourse parsing algorithm that implements these models derives discourse parse trees with an error reduction of 18.8% over a state-of-the-art decision-based discourse parser. A set of empirical evaluations shows that our discourse parsing model is sophisticated enough to yield discourse trees at an accuracy level that matches near-human levels of performance.
2003.mtsummit-systems.2,Language Weaver: the next generation of machine translation,2003,2,1,4,0,52985,bryce benjamin,Proceedings of Machine Translation Summit IX: System Presentations,0,"We introduce a new generation of commercial translation software, based primarily on statistical learning and statistical language models."
W02-2102,The Importance of Lexicalized Syntax Models for Natural Language Generation Tasks,2002,15,15,4,1,4346,hal iii,Proceedings of the International Natural Language Generation Conference,0,"Abstract : The parsing community has long recognized the importance of lexicalized models of syntax. By contrast, these models do not appear to have had an impact on the statistical NLG community. To prove their importance in NLG, we show that a lexicalized model of syntax improves the performance of a statistical text compression system, and show results that suggest it would also improve the performances of an MT application and a pure natural language generation system."
W02-1018,"A Phrase-Based,Joint Probability Model for Statistical Machine Translation",2002,0,1,1,1,31937,daniel marcu,Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing ({EMNLP} 2002),0,"Abstract : We present a joint probability model for statistical machine translation, which automatically learns word and phrase equivalents from bilingual corpora. Translations produced with parameters estimated using the joint model are more accurate than translations produced using IBM Model 4."
W02-1037,Processing Comparable Corpora With Bilingual Suffix Trees,2002,16,17,2,1,28507,dragos munteanu,Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing ({EMNLP} 2002),0,"We introduce Bilingual Suffix Trees (BST), a data structure that is suitable for exploiting comparable corpora. We discuss algorithms that use BSTs in order to create parallel corpora and learn translations of unseen words from comparable corpora. Starting with a small bilingual dictionary that was derived automatically from a corpus of 5.000 parallel sentences, we have automatically extracted a corpus of 33.926 parallel phrases of size greater than 3, and learned 9 new word translations from a comparable corpus of 1.3M words (100.000 sentences)."
P02-1047,An Unsupervised Approach to Recognizing Discourse Relations,2002,14,317,1,1,31937,daniel marcu,Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,1,"We present an unsupervised approach to recognizing discourse relations of CONTRAST, EXPLANATION-EVIDENCE, CONDITION and ELABORATION that hold between arbitrary spans of texts. We show that discourse relation classifiers trained on examples that are automatically extracted from massive amounts of text can be used to distinguish between some of these relations with accuracies as high as 93%, even when the relations are not explicitly marked by cue phrases."
P02-1057,A Noisy-Channel Model for Document Compression,2002,14,75,2,1,4346,hal iii,Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,1,"We present a document compression system that uses a hierarchical noisy-channel model of text production. Our compression system first automatically derives the syntactic structure of each sentence and the overall discourse structure of the text given as input. The system then uses a statistical hierarchical model of text production in order to drop non-important syntactic and discourse constituents so as to generate coherent, grammatical document compressions of arbitrary length. The system outperforms both a baseline and a sentence-based compression system that operates by simplifying sequentially all sentences in a text. Our results support the claim that discourse knowledge plays an important role in document summarization."
benjamin-etal-2002-translation,Translation by the numbers: Language Weaver,2002,17,3,3,0,52985,bryce benjamin,Proceedings of the 5th Conference of the Association for Machine Translation in the Americas: System Descriptions,0,Pre-market prototype - to be available commercially in the second or third quarter of 2003.
soricut-etal-2002-using,Using a large monolingual corpus to improve translation accuracy,2002,6,45,3,1,4002,radu soricut,Proceedings of the 5th Conference of the Association for Machine Translation in the Americas: Technical Papers,0,"The existence of a phrase in a large monolingual corpus is very useful information, and so is its frequency. We introduce an alternative approach to automatic translation of phrases/sentences that operationalizes this observation. We use a statistical machine translation system to produce alternative translations and a large monolingual corpus to (re)rank these translations. Our results show that this combination yields better translations, especially when translating out-of-domain phrases/sentences. Our approach can be also used to automatically construct parallel corpora from monolingual resources."
W01-1605,Building a Discourse-Tagged Corpus in the Framework of {R}hetorical {S}tructure {T}heory,2001,48,415,2,0,53771,lynn carlson,Proceedings of the Second {SIG}dial Workshop on Discourse and Dialogue,0,"We describe our experience in developing a discourse-annotated corpus for community-wide use. Working in the framework of Rhetorical Structure Theory, we were able to create a large annotated resource with very high consistency, using a well-defined methodology and protocol. This resource is made publicly available through the Linguistic Data Consortium to enable researchers to develop empirically grounded, discourse-specific applications."
P01-1014,Towards Automatic Classification of Discourse Elements in Essays,2001,17,52,2,1,30726,jill burstein,Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics,1,"Educators are interested in essay evaluation systems that include feedback about writing features that can facilitate the essay revision process. For instance, if the thesis statement of a student's essay could be automatically identified, the student could then use this information to reflect on the thesis statement with regard to its quality, and its relationship to other discourse elements in the essay. Using a relatively small corpus of manually annotated data, we use Bayesian classification to identify thesis statements. This method yields results that are much closer to human performance than the results produced by two baseline systems."
P01-1030,Fast Decoding and Optimal Decoding for Machine Translation,2001,11,250,4,0,5732,ulrich germann,Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics,1,"A good decoding algorithm is critical to the success of any statistical machine translation system. The decoder's job is to find the translation that is most likely according to set of previously learned parameters (and a formula for combining them). Since the space of possible translations is extremely large, typical decoding algorithms are only able to examine a portion of it, thus risking to miss good solutions. In this paper, we compare the speed and output quality of a traditional stack-based decoding algorithm with two new decoders: a fast greedy decoder and a slow but optimal decoder that treats decoding as an integer-programming optimization problem."
P01-1050,Towards a Unified Approach to Memory- and Statistical-Based Machine Translation,2001,12,92,1,1,31937,daniel marcu,Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics,1,"We present a set of algorithms that enable us to translate natural language sentences by exploiting both a translation memory and a statistical-based translation model. Our results show that an automatically derived translation memory can be used within a statistical framework to often find translations of higher probability than those found using solely a statistical model. The translations produced using both the translation memory and the statistical model are significantly better than translations produced by two commercial systems: our hybrid system translated perfectly 58% of the 505 sentences in a test collection, while the commercial systems translated perfectly only 40-42% of them."
W00-1507,Benefits of Modularity in an Automated Essay Scoring System,2000,11,8,2,1,30726,jill burstein,Proceedings of the {COLING}-2000 Workshop on Using Toolsets and Architectures To Build {NLP} Systems,0,"E-rater is an operational automated essay scoring application. The system combines several NLP tools that identify linguistic features in essays for the purpose of evaluating the quality of essay text. The application currently identifies a variety of syntactic, discourse, and topical analysis features. We have maintained two clear visions of e-rater's development. First, new linguistically-based features would be added to strengthen connections between human scoring guide criteria and e-rater scores. Secondly, e-rater would be adapted to automatically provide explanatory feedback about writing quality. This paper provides two examples of the flexibility of e-rater's modular architecture for continued application development toward these goals. Specifically, we discuss a) how additional features from rhetorical parse trees were integrated into e-rater, and b) how the salience of automatically generated discourse-based essay summaries was evaluated for use as instructional feedback through the re-use of e-rater's topical analysis module."
W00-1403,An empirical study of multilingual natural language generation: What Should a Text Planner Do?,2000,19,5,1,1,31937,daniel marcu,{INLG}{'}2000 Proceedings of the First International Conference on Natural Language Generation,0,We present discourse annotation work aimed at constructing a parallel corpus of Rhetorical Structure trees for a collection of Japanese texts and their corresponding English translations. We discuss implications of our empirical findings for the task of text planning in the context of implementing multilingual natural language generation systems.
J00-3005,The rhetorical parsing of unrestricted texts: a surface-based approach,2000,59,168,1,1,31937,daniel marcu,Computational Linguistics,0,"Coherent texts are not just simple sequences of clauses and sentences, but rather complex artifacts that have highly elaborate rhetorical structure. This paper explores the extent to which well-formed rhetorical structures can be automatically derived by means of surface-form-based algorithms. These algorithms identify discourse usages of cue phrases and break sentences into clauses, hypothesize rhetorical relations that hold among textual units, and produce valid rhetorical structure trees for unrestricted natural language texts. The algorithms are empirically grounded in a corpus analysis of cue phrases and rely on a first-order formalization of rhetorical structure trees.The algorithms are evaluated both intrinsically and extrinsically. The intrinsic evaluation assesses the resemblance between automatically and manually constructed rhetorical structure trees. The extrinsic evaluation shows that automatically derived rhetorical structures can be successfully exploited in the context of text summarization."
C00-1031,An Empirical Investigation of the Relation Between Discourse Structure and Co-Reference,2000,15,16,3,1,14259,dan cristea,{COLING} 2000 Volume 1: The 18th International Conference on Computational Linguistics,0,"We compare the potential of two classes of linear and hierarchical models of discourse to determine co-reference links and resolve anaphors. The comparison uses a corpus of thirty texts, which were manually annotated for co-reference and discourse structure."
C00-1076,Extending a Formal and Computational Model of {R}hetorical {S}tructure {T}heory with Intentional Structures la {G}rosz and {S}idner,2000,7,9,1,1,31937,daniel marcu,{COLING} 2000 Volume 1: The 18th International Conference on Computational Linguistics,0,"In the last decade, members of the computational linguistics community have adopted a perspective on discourse based primarily on either Rhetorical Structure Theory or Grosz and Sidner's Theory. However, only recently, researchers have started to investigate the relationship between the two perspectives. In this paper, we use Moser and Moore's (1996) work as a departure point for extending Marcu's formalization of RST (1996). The result is a first-order axiomatization of the mathematical properties of text structures and of the relationship between the structure of text and intentions. The axiomatization enables one to use intentions for reducing the ambiguity of discourse and the structure of discourse for deriving intentional inferences."
A00-2002,The Automatic Translation of Discourse Structures,2000,13,54,1,1,31937,daniel marcu,1st Meeting of the North {A}merican Chapter of the Association for Computational Linguistics,0,"We empirically show that there are significant differences between the discourse structure of Japanese texts and the discourse structure of their corresponding English translations. To improve translation quality, we propose a computational model for rewriting discourse structures. When we train our model on a parallel corpus of manually built Japanese and English discourse structure trees, we learn to rewrite Japanese trees as trees that are closer to the natural English rendering than the original ones."
W99-0307,Experiments in Constructing a Corpus of Discourse Trees,1999,20,62,1,1,31937,daniel marcu,Towards Standards and Tools for Discourse Tagging,0,"We discuss a tagging schema and a tagging tool for labeling the rhetorical structure of texts. We also propose a statistical method for measuring agreement of hierarchical structure annotations and we discuss its strengths and weaknesses. The statistical measure we use suggests that annotators can achieve good levels of agreement on the task of determining the high-level, rhetorical structure of texts. Our empirical experiments also suggest that building discourse parsers that incrementally derive correct rhetorical structures of unrestricted texts without applying any form of backtracking is unfea-"
W99-0106,Discourse Structure and Co-Reference: An Empirical Study,1999,26,20,3,1,14259,dan cristea,The Relation of Discourse/Dialogue Structure and Reference,0,"In most cases,, the COLLECT module determines an LPA by enumerating all antecedents in a window of text that pLeced__es the anaphor under scrutiny (Hobbs, 1978; Lappin and Leass, 1994; Mitkov, 1997; Kameyama, 1997; Ge et al., 1998). This window can be as small as two or three sentences or as large as the entire preceding text. The FILTER module usually imposes semantic constraints by requiring that the anaphor and potential antecedents have the same number and gender, that selectional restrictions are obeyed, etc. The PREFERENCE module imposes preferences on potential antecedents on the basis of their grammatical roles, parallelism, frequency, proximity, etc. In some cases, anaphora resolution systems implement these modules explicitly (I-Iobbs, 1978; Lappin and Leass, 1994; Mitkov, 1997; Kameyama, 1997). In other cases, these modules are integrated by means of statistical (Ge et al., 1998) or uncertainty reasoning techniques (Mitkov, 1997)."
P99-1047,A Decision-Based Approach to Rhetorical Parsing,1999,17,66,1,1,31937,daniel marcu,Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics,1,"We present a shift-reduce rhetorical parsing algorithm that learns to construct rhetorical structures of texts from a corpus of discourse-parse action sequences. The algorithm exploits robust lexical, syntactic, and semantic knowledge sources."
W98-1124,Improving summarization through rhetorical parsing tuning,1998,20,81,1,1,31937,daniel marcu,Sixth Workshop on Very Large Corpora,0,None
W98-0301,A surface-based approach to identifying discourse markers and elementary textual units in unrestricted texts,1998,13,17,1,1,31937,daniel marcu,Discourse Relations and Discourse Markers,0,I present a surface-based algorithm that employs knowledge of cue phrase usages in order to determine automatically clause boundaries and discourse markers in unrestricted natural language texts. The knowledge was derived from a comprehensive corpus analysis.
W97-0713,From discourse structures to text summaries,1997,-1,-1,1,1,31937,daniel marcu,Intelligent Scalable Text Summarization,0,None
P97-1013,The Rhetorical Parsing of Unrestricted Natural Language Texts,1997,31,80,1,1,31937,daniel marcu,35th Annual Meeting of the Association for Computational Linguistics and 8th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,1,"We derive the rhetorical structures of texts by means of two new, surface-form-based algorithms: one that identifies discourse usages of cue phrases and breaks sentences into clauses, and one that produces valid rhetorical structure trees for unrestricted natural languages texts. The algorithms use information that was derived from a corpus analysis of cue phrases."
P95-1020,A Uniform Treatment of Pragmatic Inferences in Simple and Complex Utterances and Sequences of Utterances,1995,20,0,1,1,31937,daniel marcu,33rd Annual Meeting of the Association for Computational Linguistics,1,"Drawing appropriate defeasible inferences has been proven to be one of the most pervasive puzzles of natural language processing and a recurrent problem in pragmatics. This paper provides a theoretical framework, called stratified logic, that can accommodate defeasible pragmatic inferences. The framework yields an algorithm that computes the conversational, conventional, scalar, clausal, and normal state implicatures; and the presuppositions that are associated with utterances. The algorithm applies equally to simple and complex utterances and sequences of utterances."
