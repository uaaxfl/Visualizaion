2007.mtsummit-papers.32,J84-3009,0,0.701915,"Missing"
2016.gwc-1.19,C92-2082,0,0.148394,"ntries. Likewise, more work needs to be done to identify synsets. The word groups that we used for this study grouped morphologically similar words such as ‘gender queer’ and ‘gender-queer’. However, we did not group words like ‘agender’ and ‘genderless’ into synsets. Methods for reliably detecting synonyms of gender identity words should be developed and tested. Finally, methods also need to be developed for establishing hierarchy relations among gender identity words. Such methods may include testing established lexical patterns with English speakers who are competent with trans vocabulary (Hearst, 1992). Another approach may include leveraging the responses in question 4 of the NTDS to detect hierarchy relations. For example, if most Table 4: The ten most frequent words in the NTDS write-in fields in questions three and four participants who identify strongly as transgender also identify strongly as genderqueer but not vice versa, this could indicate that ‘genderqueer’ is a hypernym of ‘transgender’. 4.4 Future Work Wordnets have been built in some seventy different languages, and each reflects the culture of the speakers. Mapping gender identity words across languages should reveal interest"
2018.gwc-1.44,D14-1005,0,0.0222777,"t chairs often have four legs or 5 wheels; only non-default exemplars might be labeled in an ad hoc fashion as “five-legged chairs,” for example. Furthermore, the physical contexts of objects (see Figure 7) provides richer information than is found in text. In this regard, the text and 3D modalities are complementary and provide an excellent target for building multimodal distributional representations (Bruni et al., 2014). Multimodal embeddings are a promising semantic representation which has been leveraged for various Natural Language Processing and vision tasks (Silberer and Lapata, 2014; Kiela and Bottou, 2014; Lazaridou et al., 2015; Kottur et al., 2016). Another direction for future work is to leverage the object part and attributes and their correspondences to WordNet to go beyond the set of WordNet synsets and automatically induce new senses, along the lines of recent work on sense induction (Chen et al., 2015; Thomason and J. Mooney, 2017). For example, we have found that WordNet synsets do not have good coverage of some fairly modern categories of objects that we observe in Figure 7: An example of the same nightstand object (outlined in blue) in two different 3D scene contexts. A contextual e"
2018.gwc-1.44,N15-1016,0,0.0348858,"Missing"
2018.gwc-1.44,W16-3807,0,0.032934,"els. Such a link of WordNet entries to 3D data can provide much richer information than 2D image datasets. Naturally, 3D representations allow us to reason about unoccluded parts and symmetries, arrangement of objects in a physically realistic three dimensional space, and to account for empty space, a critical property of real scenes which is not observable in 2D images. Moreover, 3D representations are appropriate for computationally simulating real spaces and the actions that can be performed within them. The ability to do this is a powerful tool for investigating and understanding actions (Pustejovsky et al., 2016). Therefore, our project aims to annotate 3D models in one of the existing datasets and link them to the appropriate synset in the WordNet database at the part, attribute, and contextual level. 3 Project description Our project has so far focused on annotating part and attribute information on 3D CAD objects in SUNCG (Song et al., 2017) and linking them to the corresponding WordNet synsets. We are working with a preliminary categorization of the objects performed in prior work, which establishes their connection to WordNet synsets denoting physical objects. However, we plan to refine the granu"
2018.gwc-1.44,P14-1068,0,0.0250444,"peakers encode the fact that chairs often have four legs or 5 wheels; only non-default exemplars might be labeled in an ad hoc fashion as “five-legged chairs,” for example. Furthermore, the physical contexts of objects (see Figure 7) provides richer information than is found in text. In this regard, the text and 3D modalities are complementary and provide an excellent target for building multimodal distributional representations (Bruni et al., 2014). Multimodal embeddings are a promising semantic representation which has been leveraged for various Natural Language Processing and vision tasks (Silberer and Lapata, 2014; Kiela and Bottou, 2014; Lazaridou et al., 2015; Kottur et al., 2016). Another direction for future work is to leverage the object part and attributes and their correspondences to WordNet to go beyond the set of WordNet synsets and automatically induce new senses, along the lines of recent work on sense induction (Chen et al., 2015; Thomason and J. Mooney, 2017). For example, we have found that WordNet synsets do not have good coverage of some fairly modern categories of objects that we observe in Figure 7: An example of the same nightstand object (outlined in blue) in two different 3D scene"
2019.gwc-1.31,L16-1686,0,0.0607604,"Missing"
2019.gwc-1.31,D16-1041,0,0.0173731,"kipedia and this may require the project to adopt the more restrictive CCBY-SA license of Wikipedia. Moreover, it is not Figure 1: Screenshot of the new English WordNet interface clear how many of the entries have been reviewed by native speakers of English. Finally, a long term goal would be to introduce a principled method for introducing new synsets, which are of high quality and this would have to involve reviewing of all the links between synsets that have been introduced. It is expected that this could be achieved by a semi-automatic procedure where potential links are learnt from text (Espinosa-Anke et al., 2016) combined with a crowd-sourced reviews. Another important aspect of each synset is also its definition and as many of the definitions in WordNet are of poor quality (McCrae and Prangnawarat, 2016), it is necessary to adopt some general guidelines for writing definitions that can ensure high quality, such as those defined for ontological definitions (Sepp¨al¨a et al., 2017). Further, we will implement and further extend the validations that are available and automate the checking such that it is clear if any changes are breaking issues. In particular, we currently implement simple DTD validatio"
2019.gwc-1.31,francopoulo-etal-2006-lexical,0,0.0760954,"y of the minor errors into their own resources. 3 The Open English WordNet Project The Open English WordNet Project2 takes the form of a single Git repository, published on GitHub, and consisting for the most part of a collection of XML files describing the synsets and lexical entries in the resource. These XML files represent each of the lexicographer file sections of the original resource and a simple script is provided to stitch them together into a single XML file. The XML files are compliant with the GWC LMF model (McCrae et al., 2019)3 , which is itself based partially on the LMF model (Francopoulo et al., 2006) and in particular the WordNet (a.k.a 2 https://github.com/globalwordnet/ english-wordnet 3 https://globalwordnet.github.io/ schemas/ Kyoto) LMF variant (Soria et al., 2009). Due to its basis on LMF, a particular challenge was that the entire wordnet should be represented as a single XML document. However, due to the relative verbosity of the LMF format, the final data ended up as 97 MB, exceeding the upload limits of GitHub, so instead the single XML file was divided by lexicographer sections. Even still, this creates several very large files (over 10 MB) and this has resulted in some challen"
2019.gwc-1.31,E12-1059,0,0.150764,"Missing"
2019.gwc-1.31,N18-1014,0,0.0137142,"ordNet 2019, which has been developed by multiple people around the world through GitHub, fixes many errors in previous wordnets for English. We give some details of the changes that have been made in this version and give some perspectives about likely future changes that will be made as this project continues to evolve. 1 Introduction WordNet (Miller, 1995; Fellbaum, 1998) is one of the most widely-used language resources in natural language processing and continues to find usage in a wide variety of applications including sentiment analysis (Wang et al., 2018), natural language generation (Juraska et al., 2018) and textual entailment (Silva et al., 2018). However, in the recent few years there has been only one update since version 3.0 was released in 2006, in spite of its wide use and the interest in the data. In the meantime, a number of other wordnet teams working with the WordNet data have proposed modifications or extensions to its latest release. These two facts have provided the chief motivation for our present initiative, namely developing an opensource WordNet for English on the basis of Princeton WordNet (to be released under the name English WordNet 2019). In order to allow for meaningful"
2019.gwc-1.31,C16-1213,1,0.92792,"ton WordNet (Miller, 1995; Fellbaum, 2010) is the first wordnet for English, however it is not the only one that has been developed for this language. Moreover, it has been the case that during the development of several wordnets for other languages signficant changes and/or additions were made to the underlying structure and content of the English section of the wordnet. In at least one case, namely the development of the Polish wordnet, plWordNet, the additions to the underlying English wordnet have been so numerous that they were released as a new wordnet, enWordnet (Rudnicka et al., 2015; Maziarz et al., 2016). These involved the addition of new lemmas (over 11k), lexical units (over 11k) and synsets (7.5k). The latter were linked to WordNet 3.1 synsets via hyponymy relation. Still, no alterations to the original WordNet synsets or relations were made within this project. Currently, enWordnet is only available as part of the plWordNet project and does not constitute a ‘drop-in’ replacement for Princeton WordNet. Some projects have attempted to expand Princeton WordNet with new terminology in other directions, for example the Colloquial WordNet project (McCrae et al., 2017), has been working on addi"
2019.gwc-1.31,2018.gwc-1.8,1,0.739086,"r by providing a suitable modification, for example the example of ‘double negative’ was ‘I don’t never go’ and was updated to ‘double negative such as ‘I don’t never go” to include the lemma. 6 7 corrected to ‘certain’ https://www.sketchengine.eu/ • An issue was logged, as it was identified that this example shows a more signficant change. This was often the case when the example used a lemma or a hypernym and it was not clear if the distinction between synsets was meaningful. A third major change was to introduce new synset members based on a previously calculated WordNet-Wikipedia mapping (McCrae, 2018). In particular, if this mapping, which has already been manually verified, linked to a page title that did not match the lemma, the page title was added as a new lemma to the synset. This was, as with all changes, manually verified in its entirety before the change was made. Finally, the repository has been open to new suggestions of changes and there have been many suggestions already contributed about sporadic and various changes to the wordnet. A sample of these include: • The sense of ‘threepenny’ as a size was incorrect in the actual length in inches of a threepenny. • Grammatical errors"
2019.gwc-1.31,C12-3044,1,0.889346,"Missing"
2019.gwc-1.31,2018.gwc-1.40,1,0.702996,"ent and further extend the validations that are available and automate the checking such that it is clear if any changes are breaking issues. In particular, we currently implement simple DTD validation of the merged XML, which also catches many other issues, such as senses without synsets, but we are working to extend this validation to include issues, such as hypernyms without hyponyms, etc. In order to achieve this, it is important that strong tools are available for the creation and maintenance of the resource and it is likely that tools coming out of the ELEXIS project (Krek et al., 2018; Pedersen et al., 2018) will be adapted to this task. 6 Results for this release This release represents a mostly maintenance release where obvious errors have been fixed. In Table 2 we see that most of the updates are to the definitions and examples used to describe the synsets in English WordNet. There have also been a number of removals relative to the previous version of Princeton WordNet: mispelled lemmas were removed and replaced with a correctly spelled variant and these were counted as both a removal and addition of a lemma. Secondly, due to an issue11 two links were removed as they were deemed clearly incor"
2019.gwc-1.31,strapparava-valitutti-2004-wordnet,0,0.125518,"Missing"
2019.gwc-1.40,P13-1133,0,0.111945,"or modality-specific relations among signs. Significantly, the mapping of SignStudy and PWN provides a bridge between ASL and the worldwide wordnet community, which comprises speakers of dozens of languages working in academic and language technology settings. 1 Background and Motivation We discuss plans for developing ASLNet, the large-scale alignment of the Princeton WordNet (Miller, 1995; Fellbaum, 2010) and SignStudy (www.signstudy.org), a database of American Sign Language (ASL) signs. The popularity of the Princeton WordNet (PWN) has spawned wordnets in dozens of other spoken languages (Bond and Foster, 2013; Vossen, 2004), including those outside the Indo-European language family. Crossing modalities, ImageNet (Deng et al., 2009), a database created to support image recognition, contains thousands of images linked to PWN’s synsets. Sign languages fall squarely within the family of human languages but communicate meaning in the visual-kinesthetic modality. Aligning the synsets of PWN (and by extension those of the wordnets in other spoken languages) with ASL signs is both a logical and challenging next step. 1.1 SignStudy SignStudy (SS) is an online ASL lexical resource created and supported by S"
2019.gwc-1.40,2016.gwc-1.9,1,0.830846,"er constructions). Such mappings are likely to be challenging for reasons discussed in Section 4. V1.1 will be followed by subsequent versions that incorporate mappings for increasingly complicated aspects of ASL, particularly those that differ significantly from spoken languages. Once mapping techniques have been developed and proved viable for the core aspects of ASL, large-scale lexical expansion of ASLNet may then commence. Such work may lead to ASLNet becoming a part of the Collaborative Interlingual Index (CILI), a means of linking wordnets without depending on PWN’s semantic structure (Bond et al., 2016; Vossen et al., 2016). CILI integration may be beneficial in the face of lexical gaps as well as differences in word encoding and linking between ASL and English. It is also important to be mindful of the fact that sign languages are not universal; there exist many other sign languages distinct from ASL. As the linguistic properties of other sign languages may not be entirely identical to those of ASL, it is rewarding to develop the structure of ASLNet such that it is as general as possible with regard to sign languages so that this work may give rise to similar research opportunities with ot"
2019.gwc-1.40,shoaib-etal-2012-platform,0,0.0207588,"ant benefit of linking ASL to PWN is the immediate connection to dozens of wordnets in other languages. PWN can be thought of as the hub to which wordnets in many languages are linked. Departing from a given signed word will allow one to go from the corresponding English word to its equivalents in Spanish, Basque and Hindi, for example. Additionally, the link between PWN and ImageNet raises interesting possibilities for exploring questions of iconicity in ASL (Perniss et al., 2010). 3 Related Work We are aware of only one effort to link wordnets to a database of signs. (Prinetto et al., 2011; Shoaib et al., 2012) describe plans for developing a Sign Bank for Italian Sign Language (LIS) and its alignment to MultiWordNet (Pianta et al., 2002), a lexical database for Italian, Romanian, Spanish, Portuguese, Latin and Hebrew modeled on, and linked to an early, smaller version (1.6) of PWN that is no longer the standard for natural language processing applications. However, while the concept of LIS was developed and described in (Shoaib et al., 2012), to the best of our knowledge, the LIS Sign Bank was not in fact created. 4 Units of Meaning Both SS and PWN are databases whose atomic units are form-meaning"
2020.gebnlp-1.2,W19-3805,0,0.0359601,"Missing"
2020.gebnlp-1.2,2020.acl-main.485,0,0.148768,"Missing"
2020.gebnlp-1.2,N19-3002,0,0.0163399,"armful biases related to the intersection and interaction of these identities, without being recognized for their identities themselves. Meanwhile, approaches that study, utilize, or debias these representations, but treat race and gender as orthogonal and isolated dimensions, would be poorly adapted for these groups. Various studies have contended that because word embeddings are used as representations for text in a wide range of NLP tasks, any biases carried in the embeddings may be propagated to or even amplified in those downstream applications (Bolukbasi et al., 2016; Zhao et al., 2017; Bordia and Bowman, 2019). Certainly, this should be cause for concern, with the rising number of real-world applications and potential to impact lives. That said, we concur with Blodgett et al. (2020) that, independent of any allocational harms, the existence of these representational biases poses a critical problem in and of itself. 2 Related Work The vast majority of studies of bias in word embeddings and contextual representations have focused on binary gender in isolation (Bolukbasi et al., 2016; Zhao et al., 2017; Zhao et al., 2019; Basta et al., 2019; Bordia and Bowman, 2019; Gonen and Goldberg, 2019). This is"
2020.gebnlp-1.2,N19-1423,0,0.0211303,"tion of the conceptualization of gender and race learned by word embeddings, how these demographic dimensions relate or interact, or how bias may be embedded in gendered words such as pronouns themselves; the objective of this paper is to begin to fill in these gaps. 3 Learning Gender and Race in Word Embeddings from Names To understand how and to what extent the concepts of gender and race are learned by contextualized word embeddings, in this case study we use contextualized embeddings of African American and European American male and female names from the pretrained BERT base-cased model (Devlin et al., 2019), with the sets of popular American given names borrowed from previous studies (Tan and Celis, 2019; May et al., 2019; Caliskan et al., 2017). These sets consist of 13 names for each race-gender pair, and were selected from Greenwald et al. (1998)’s original set of names used in introducing the IAT (Caliskan et al., 2017). We base our analysis on the principal component analysis (PCA) of these names, a common approach to identifying, visualizing, and understanding dimensions of gender and race in a word embedding vector space (Bolukbasi et al., 2016; Sedoc and Ungar, 2019; Manzini et al., 2019"
2020.gebnlp-1.2,W19-3621,0,0.0223648,"al., 2017; Bordia and Bowman, 2019). Certainly, this should be cause for concern, with the rising number of real-world applications and potential to impact lives. That said, we concur with Blodgett et al. (2020) that, independent of any allocational harms, the existence of these representational biases poses a critical problem in and of itself. 2 Related Work The vast majority of studies of bias in word embeddings and contextual representations have focused on binary gender in isolation (Bolukbasi et al., 2016; Zhao et al., 2017; Zhao et al., 2019; Basta et al., 2019; Bordia and Bowman, 2019; Gonen and Goldberg, 2019). This is likely due to the advantage that gender pronouns are marked in language in a visible way that other demographic attributes are not. ‘Bias’, in these studies, is often measured as the similarity of words that are by definition gender-neutral – typically profession words – to words that are explicitly male or female gendered, such as pronouns. One popular method proposed for mitigating bias in word embeddings involves reducing the projection of gender-neutral words in the direction of a gender dimension vector defined by the difference between the vectors of ‘he’ and ‘she’ (Bolukbasi e"
2020.gebnlp-1.2,N19-1062,0,0.0400581,"Devlin et al., 2019), with the sets of popular American given names borrowed from previous studies (Tan and Celis, 2019; May et al., 2019; Caliskan et al., 2017). These sets consist of 13 names for each race-gender pair, and were selected from Greenwald et al. (1998)’s original set of names used in introducing the IAT (Caliskan et al., 2017). We base our analysis on the principal component analysis (PCA) of these names, a common approach to identifying, visualizing, and understanding dimensions of gender and race in a word embedding vector space (Bolukbasi et al., 2016; Sedoc and Ungar, 2019; Manzini et al., 2019). Figure 1 plots these names projected onto the first and second principal components of the PCA of all the names in the four sets. On inspection, the first principal component decidedly distinguishes the race of the names; all of the European American names have negative projections onto the component and all African American names, with the exception of a few male names for which racial association may have been more ambiguous, have positive projections. The second principal component appears to distinguish gender, cleanly separating the European American female names from the European Ameri"
2020.gebnlp-1.2,N19-1063,0,0.203964,"gating bias in word embeddings involves reducing the projection of gender-neutral words in the direction of a gender dimension vector defined by the difference between the vectors of ‘he’ and ‘she’ (Bolukbasi et al., 2016). Another measure of bias in word embeddings, the Word Embedding Association Test (WEAT), was introduced by Caliskan et al. (2017), adapted from the Implicit Association Test (IAT) of humans’ reaction times to pairs of words (Greenwald et al., 1998). More recently, studies have begun to factor intersectionality into their analyses of bias. Studying bias in sentence encoders, May et al. (2019) generalized the WEAT to sentence embeddings, using bleached sentence templates to test a number of hypotheses. Though several of their hypotheses are centered on gender, they also include a test of the “Angry Black Woman” stereotype and find significant evidence confirming its presence (May et al., 2019). Tan and Celis (2019) similarly build on the WEAT, extending it to contextualized word embeddings and measuring intersectional bias as the association of European American and African American male 18 Figure 1: African American (AA) and European American (EA) male and female names projected o"
2020.gebnlp-1.2,W19-3808,0,0.0182656,"BERT base-cased model (Devlin et al., 2019), with the sets of popular American given names borrowed from previous studies (Tan and Celis, 2019; May et al., 2019; Caliskan et al., 2017). These sets consist of 13 names for each race-gender pair, and were selected from Greenwald et al. (1998)’s original set of names used in introducing the IAT (Caliskan et al., 2017). We base our analysis on the principal component analysis (PCA) of these names, a common approach to identifying, visualizing, and understanding dimensions of gender and race in a word embedding vector space (Bolukbasi et al., 2016; Sedoc and Ungar, 2019; Manzini et al., 2019). Figure 1 plots these names projected onto the first and second principal components of the PCA of all the names in the four sets. On inspection, the first principal component decidedly distinguishes the race of the names; all of the European American names have negative projections onto the component and all African American names, with the exception of a few male names for which racial association may have been more ambiguous, have positive projections. The second principal component appears to distinguish gender, cleanly separating the European American female names"
2020.gebnlp-1.2,D17-1323,0,0.0285488,"may be exposed to harmful biases related to the intersection and interaction of these identities, without being recognized for their identities themselves. Meanwhile, approaches that study, utilize, or debias these representations, but treat race and gender as orthogonal and isolated dimensions, would be poorly adapted for these groups. Various studies have contended that because word embeddings are used as representations for text in a wide range of NLP tasks, any biases carried in the embeddings may be propagated to or even amplified in those downstream applications (Bolukbasi et al., 2016; Zhao et al., 2017; Bordia and Bowman, 2019). Certainly, this should be cause for concern, with the rising number of real-world applications and potential to impact lives. That said, we concur with Blodgett et al. (2020) that, independent of any allocational harms, the existence of these representational biases poses a critical problem in and of itself. 2 Related Work The vast majority of studies of bias in word embeddings and contextual representations have focused on binary gender in isolation (Bolukbasi et al., 2016; Zhao et al., 2017; Zhao et al., 2019; Basta et al., 2019; Bordia and Bowman, 2019; Gonen and"
2020.gebnlp-1.2,N19-1064,0,0.019524,"those downstream applications (Bolukbasi et al., 2016; Zhao et al., 2017; Bordia and Bowman, 2019). Certainly, this should be cause for concern, with the rising number of real-world applications and potential to impact lives. That said, we concur with Blodgett et al. (2020) that, independent of any allocational harms, the existence of these representational biases poses a critical problem in and of itself. 2 Related Work The vast majority of studies of bias in word embeddings and contextual representations have focused on binary gender in isolation (Bolukbasi et al., 2016; Zhao et al., 2017; Zhao et al., 2019; Basta et al., 2019; Bordia and Bowman, 2019; Gonen and Goldberg, 2019). This is likely due to the advantage that gender pronouns are marked in language in a visible way that other demographic attributes are not. ‘Bias’, in these studies, is often measured as the similarity of words that are by definition gender-neutral – typically profession words – to words that are explicitly male or female gendered, such as pronouns. One popular method proposed for mitigating bias in word embeddings involves reducing the projection of gender-neutral words in the direction of a gender dimension vector defi"
2021.findings-emnlp.335,P18-1249,0,0.0166254,"tic Analysis The main task of our syntactic analysis involves the VB Y CC Z detection and extraction of coordination phrases Verb Conjunction 2nd Conjunct 1st Conjunct from our corpus data. Since the COCA is provided in a raw text format, we use the Berkeley Neu(c) Verb-complement pattern. ral Parser to produce syntax trees of sentences in Figure 2: Three patterns used to detect two-termed cothe COCA. This is a state-of-the-art constituency ordination phrases in parsed COCA data. X, Y, and Z parser that generates syntax trees in the style of the may be any PTB constituent tags. Penn Treebank (Kitaev and Klein, 2018). To implement a good search algorithm for coordinations within parsed COCA data, we studied several sen- most frequent phrasal categories in the data. Once tence parse trees containing coordinations and iden- coordination phrases have been identified, we run tified three patterns in the way that the Berkeley statistical tests on the frequencies of their different Neural Parser most often represents the structure attributes, such as the categories of the conjuncts, of coordination phrases, as shown in Figure 2. the type of conjunction used, and the genre from which the coordination was found."
2021.findings-emnlp.335,J93-2004,0,0.0747772,"odge the problem of unlike coordination entirely by making the coordinating conjunction the head of its own coordination phrase (CCP). One example of such a theory is shown in (9). (9) Here, conjuncts are specifiers and complements of the head conjunction (Johannessen, 1998; Zoerner, 1995). With such a construction, the categories of the conjuncts by themselves do not pose a restriction on the possibility of coordination. Thus, such theories do not have anything to say about the LCL, but they are still problematic in that they over-generate; no combinations of categories are prohibited. riod (Marcus et al., 1993). Sentences from the PTB are already tokenized and annotated with phrase structure, unlike the COCA. However, coordination annotations in the PTB are often inconsistent, include errors, and lack internal structure in many cases. For this reason, we make use of Ficler and Goldberg’s PTB coordination annotation extension, which improves the coordination annotation in the PTB (Ficler and Goldberg, 2016). This extension provides an annotation that explicitly marks coordination phrases and the role of each element in coordination structures (i.e., conjuncts, markers, connectives, and shared element"
2021.gwc-1.8,P13-1133,0,0.0271879,"success of our procedure yet also highlights the need to supplement our mapping with the “merge” method. We outline our plans for upcoming work to remedy this, which include use of ASL free-association data. 1 Background and Motivation First proposed in 2019 by Lualdi et al., ASLNet is an effort to extend the wordnet model pioneered by the Princeton WordNet (Miller, 1995; Fellbaum, 2010) to the visual-kinesthetic realm of sign languages. This endeavor is in part inspired by the creation of wordnets in dozens of other spoken languages, including those outside the Indo-European language family (Bond and Foster, 2013; Vossen, 2004), as well as images via ImageNet (Deng et al., 2009). It is only natural to develop wordnets for sign languages like American Sign Language (ASL) as they are unique languages in their own right. There are many benefits to creating a wordnet representation of the ASL lexicon. The semantic relations encoded by a wordnet enable semanticallydriven language acquisition (Miller and Fellbaum, 1992), resulting in a powerful first-language (L1) and second-language (L2) pedagogical resource that will also contribute to ASL linguistics. Furthermore, with the Princeton WordNet (PWN) serving"
2021.gwc-1.8,2016.gwc-1.9,1,0.816407,"hers select specific semantic domains for which they will then supply any ASL signs that come to mind. While some of these will overlap with existing PWN synsets, we anticipate that others will correspond to lexical gaps in English. Second, once the mapping work reaches a stage where a large percentage of the available sign data has been mapped to PWN synsets, the remaining unmapped signs will be reviewed, as chances are high that they represent lexical gaps in English. The signs identified by these techniques will then be incorporated into ASLNet either as a Collaborative Interlingual Index (Bond et al., 2016) synset if a suitable match exists, or as a new synset. 5.2 Free Association A more involved technique to probe senses and relations unique to ASL is to perform free-association tests on native ASL speakers. The premise is that associated words may be semantically related and therefore inform “merge” ASLNet development. Free-association has been well studied for the English language (Nelson et al., 2004) and extended to PWN via studies of evocation between synsets (Boyd-Graber et al., 2006). The ASL-LEX team is currently working to collect semantic free associations from native ASL users for a"
2021.gwc-1.8,2019.gwc-1.40,1,0.762804,"rful first-language (L1) and second-language (L2) pedagogical resource that will also contribute to ASL linguistics. Furthermore, with the Princeton WordNet (PWN) serving as a hub linking multiple wordnets, connecting an ASL wordnet to PWN will bridge ASL to other languages (and ImageNet images), allowing for novel linguistic investigations. Lastly, with wordnets being invaluable to natural language processing (NLP), specifically word sense disambiguation (Navigli, 2009), an ASL wordnet will support burgeoning ASL machine translation efforts (Bragg et al., 2019). The original ASLNet proposal (Lualdi et al., 2019) examined theoretical questions and strategies for extending the wordnet model to a sign language. The findings were synthesized into a proposed roadmap for creating ASLNet via a hybrid “map” and “merge” approach. ASLNet development would start with mapping straightforward ASL lexical nouns to PWN synsets, followed by creating ASLNet synsets with ASLNet-specific relations to be merged with PWN where appropriate. In this paper, we report on the latest progress on implementing ASLNet V1.0 according to the prescription set forth by Lualdi et al. (2019). We describe the mapping procedure and evalu"
atkins-etal-2002-resources,2001.mtsummit-papers.39,1,\N,Missing
atkins-etal-2002-resources,bel-etal-2000-simple,1,\N,Missing
atkins-etal-2002-resources,calzolari-etal-2002-towards,1,\N,Missing
C04-1054,P98-1013,0,0.00222235,"ipulate both lexical databases and large collections of text collections or corpora. The strategy is to train automatic systems on large numbers of semantically annotated sentences that are naturally used and understood by human beings, and to exploit standard pattern-recognition and statistical techniques for purposes of disambiguation. Words and the representation of their senses, stored in lexical databases, can be linked for this purpose to specific occurrences in corpora. 7 Related Work Currently, several resources are being built in the spirit of this methodology. Examples are FrameNet (Baker, et al., 1998), (Baker, et al., 2003) and Penn Proposition Bank (Kingsbury and Palmer, 2002), both of which focus on word usage in general, rather than on domain-specific contexts. In contrast to our own project, neither of the mentioned resources attempts to build a corpus in a systematic way that is designed to ensure adequate coverage of some given domain. Furthermore, neither project is concerned with the questions of factuality or validation of statements. Another project with goals similar to those of MFN is the CYC (short for enCYClopedia) knowledge base, a collection of hundreds of thousands of stat"
C04-1054,A97-1055,0,0.0219637,"rates folk beliefs and expert knowledge indiscriminately, and its separate micro-theories are not designed to be consistent either with each other or with the body of established science; (iv) only a reduced part of CYC is publicly available. 8 WordNet WordNet 2.0 is a large electronic lexical database of English that has found wide acceptance in areas as diverse as artificial intelligence, natural language processing, and psychology. (Agirre and Martinez, 2000), (Al-Halimi and Kazman, 1998), (Artale, et al., 1997), (Basili et al., 1997), (Berwick, et al., 1990), (Burg and van de Riet 1998), (Cucchiarelli and Velardi 1997), (Fellbaum 1990), (Gonzalo, et al., 1998), (Harabagiu and Moldovan, 1996) Its coverage, which is comparable to that of a collegiate dictionary, extends over some 130,000 word forms. The most common application is in information technology, where it is used for information retrieval, document classification, question-answer systems, language generation, and machine translation. WordNet was originally conceived as a full-scale model of human semantic organization, and its design was guided by early experiments in artificial intelligence. (Collins and Quillian, 1969) WordNet was quickly embraced"
C04-1054,W98-0705,0,0.0115315,"nately, and its separate micro-theories are not designed to be consistent either with each other or with the body of established science; (iv) only a reduced part of CYC is publicly available. 8 WordNet WordNet 2.0 is a large electronic lexical database of English that has found wide acceptance in areas as diverse as artificial intelligence, natural language processing, and psychology. (Agirre and Martinez, 2000), (Al-Halimi and Kazman, 1998), (Artale, et al., 1997), (Basili et al., 1997), (Berwick, et al., 1990), (Burg and van de Riet 1998), (Cucchiarelli and Velardi 1997), (Fellbaum 1990), (Gonzalo, et al., 1998), (Harabagiu and Moldovan, 1996) Its coverage, which is comparable to that of a collegiate dictionary, extends over some 130,000 word forms. The most common application is in information technology, where it is used for information retrieval, document classification, question-answer systems, language generation, and machine translation. WordNet was originally conceived as a full-scale model of human semantic organization, and its design was guided by early experiments in artificial intelligence. (Collins and Quillian, 1969) WordNet was quickly embraced by the NLP community, a development that"
C04-1054,kingsbury-palmer-2002-treebank,0,0.0182172,"s or corpora. The strategy is to train automatic systems on large numbers of semantically annotated sentences that are naturally used and understood by human beings, and to exploit standard pattern-recognition and statistical techniques for purposes of disambiguation. Words and the representation of their senses, stored in lexical databases, can be linked for this purpose to specific occurrences in corpora. 7 Related Work Currently, several resources are being built in the spirit of this methodology. Examples are FrameNet (Baker, et al., 1998), (Baker, et al., 2003) and Penn Proposition Bank (Kingsbury and Palmer, 2002), both of which focus on word usage in general, rather than on domain-specific contexts. In contrast to our own project, neither of the mentioned resources attempts to build a corpus in a systematic way that is designed to ensure adequate coverage of some given domain. Furthermore, neither project is concerned with the questions of factuality or validation of statements. Another project with goals similar to those of MFN is the CYC (short for enCYClopedia) knowledge base, a collection of hundreds of thousands of statements, mostly about the external world, such as: The earth is round, Albany i"
C04-1054,C98-1013,0,\N,Missing
C04-1054,W00-1702,0,\N,Missing
de-melo-etal-2012-empirical,passonneau-etal-2010-word,1,\N,Missing
de-melo-etal-2012-empirical,W09-1127,0,\N,Missing
de-melo-etal-2012-empirical,W09-3021,1,\N,Missing
elkateb-etal-2006-building,P00-1026,0,\N,Missing
ide-etal-2008-masc,W04-0803,0,\N,Missing
ide-etal-2008-masc,W04-0811,0,\N,Missing
ide-etal-2008-masc,passonneau-etal-2006-inter,1,\N,Missing
ide-etal-2008-masc,S07-1018,1,\N,Missing
ide-etal-2008-masc,W07-1501,1,\N,Missing
ide-etal-2008-masc,S07-1048,0,\N,Missing
ide-etal-2008-masc,fillmore-etal-2004-framenet,1,\N,Missing
L16-1177,baccianella-etal-2010-sentiwordnet,0,0.100804,"Missing"
L16-1177,C10-1103,0,0.0173003,"peakers know where on the scale of “coldness” and “hotness” the relevant English adjectives fall; at least, they are likely to agree on the relative position of two adjectives. But can one empirically determines this? Our work focuses on a subset of gradable adjectives, evaluative adjectives such as “good,” “great,” “terrible” and “awful.” Our long-term objective is to generate different adjective scales in an empirical manner, which could allow the enrichment of lexical resources. Such a resource could be valuable for opinion mining, especially for the prediction of rating scores of reviews (Ifrim & Weikum, 2010) (Liu & Seneff, 2009). 2. Related Work Evaluative adjectives express a “sentiment” of the speaker/writer with respect to the entity to which the adjective is applied. Thus, “a great car” expresses a positive sentiment, while “a lousy car” expresses a negative sentiment. Sentiment Analysis is often performed with the help of a lexical resource where entries are annotated with sentiment values. For example, SentiWordNet (Baccianella et al., 2010) is the result of automatically annotating all WordNet synsets (Miller, 1995) (Fellbaum, 1998); Hu and Liu (2004) is a list of 6,800 words annotated for"
L16-1177,D09-1017,0,0.0254699,"he scale of “coldness” and “hotness” the relevant English adjectives fall; at least, they are likely to agree on the relative position of two adjectives. But can one empirically determines this? Our work focuses on a subset of gradable adjectives, evaluative adjectives such as “good,” “great,” “terrible” and “awful.” Our long-term objective is to generate different adjective scales in an empirical manner, which could allow the enrichment of lexical resources. Such a resource could be valuable for opinion mining, especially for the prediction of rating scores of reviews (Ifrim & Weikum, 2010) (Liu & Seneff, 2009). 2. Related Work Evaluative adjectives express a “sentiment” of the speaker/writer with respect to the entity to which the adjective is applied. Thus, “a great car” expresses a positive sentiment, while “a lousy car” expresses a negative sentiment. Sentiment Analysis is often performed with the help of a lexical resource where entries are annotated with sentiment values. For example, SentiWordNet (Baccianella et al., 2010) is the result of automatically annotating all WordNet synsets (Miller, 1995) (Fellbaum, 1998); Hu and Liu (2004) is a list of 6,800 words annotated for sentiment. A simple"
L16-1177,lopez-etal-2014-generating,1,0.841096,"al semantic patterns such as “X, even Y” and “If not Y, then at least X,” where Y is a more intense adjective than its scalemate. (Sheinman et al., 2013) propose a model for integrating scalar adjectives into WordNet and representing their relative ordering to one another on a scale of intensity. 3. Data and Method Our data (in French) come from the domain of cosmetics. We focus on adjectives associated with product and brand names reviews, building on previous work aimed at identifying product names, brand names, and related entities in the cosmetic domain, where we took a symbolic approach (Lopez et al., 2014). The proposed resource of scalar adjectives is developed on the basis of data that was provided by users of cosmetic products and that has been manually annotated. Our approach focuses on linguistic patterns identified in the product reviews and their associated rating scores. Briefly, our method involves four steps: 1- Acquiring reviews and associated “star” ratings for specific products. 2- Extracting short noun phrases. 3- Classifying noun phrases into predefined product aspect. 4- Constructing adjective scales. In the following, we describe the 4 steps. 1109 3.1 Collection of Data The dat"
P10-2013,W09-3021,1,0.0814968,"is an XML serialization of the LAF abstract model of annotations, which consists of a directed graph decorated with feature structures providing the annotation content. GrAF’s primary role is to serve as a “pivot” format for transducing among annotations represented in different formats. However, because the underlying data structure is a graph, the GrAF representation itself can serve as the basis for analysis via application of 3.1 WordNet Sense Annotations A focus of the MASC project is to provide corpus evidence to support an effort to harmonize sense distinctions in WordNet and FrameNet (Baker and Fellbaum, 2009), (Fellbaum and Baker, to appear). The WordNet and FrameNet teams have selected for this purpose 100 common polysemous words whose senses they will study in detail, and the MASC team is annotating occurrences of these words in the MASC. As a first step, fifty occurrences of each word are annotated using the WordNet 3.0 inventory and analyzed for problems in sense assignment, after which the WordNet team may make modifications to the inventory if needed. The revised inventory (which will be released as part of WordNet 3.1) is then used to annotate 1000 occurrences. Because of its small size, MA"
P10-2013,passonneau-etal-2010-word,1,0.87312,"Missing"
P10-2013,W07-1501,1,0.76262,"maximal benefit from the semantic information provided by these resources, the entire corpus is also annotated and manually validated for shallow parses (noun and verb chunks) and named entities (person, location, organization, date and time). Several additional types of annotation have either been contracted by the MASC project or contributed from other sources. The 220K words of MASC I and II include seventeen different types of linguistic annotation4 , shown in Table 2. All MASC annotations, whether contributed or produced in-house, are transduced to the Graph Annotation Framework (GrAF) (Ide and Suderman, 2007) defined by ISO TC37 SC4’s Linguistic Annotation Framework (LAF) (Ide and Romary, 2004). GrAF is an XML serialization of the LAF abstract model of annotations, which consists of a directed graph decorated with feature structures providing the annotation content. GrAF’s primary role is to serve as a “pivot” format for transducing among annotations represented in different formats. However, because the underlying data structure is a graph, the GrAF representation itself can serve as the basis for analysis via application of 3.1 WordNet Sense Annotations A focus of the MASC project is to provide"
P10-2013,ide-etal-2008-masc,1,0.866054,"Missing"
P10-2013,ide-etal-2010-anc2go,1,0.809614,"Missing"
P10-2013,J93-2004,0,0.0393414,"t of Computer Science Vassar College Poughkeepsie, NY, USA ide@cs.vassar.edu Collin Baker International Computer Science Institute Berkeley, California USA collinb@icsi.berkeley.edu Christiane Fellbaum Princeton University Princeton, New Jersey USA fellbaum@princeton.edu Rebecca Passonneau Columbia University New York, New York USA becky@cs.columbia.edu Abstract teen million word Open American National Corpus annotations are largely unvalidated. The most well-known multiply-annotated and validated corpus of English is the one million word Wall Street Journal corpus known as the Penn Treebank (Marcus et al., 1993), which over the years has been fully or partially annotated for several phenomena over and above the original part-of-speech tagging and phrase structure annotation. The usability of these annotations is limited, however, by the fact that many of them were produced by independent projects using their own tools and formats, making it difficult to combine them in order to study their inter-relations. More recently, the OntoNotes project (Pradhan et al., 2007) released a one million word English corpus of newswire, broadcast news, and broadcast conversation that is annotated for Penn Treebank sy"
P10-2013,W09-2402,1,0.836095,"Missing"
P10-2013,W03-0804,1,\N,Missing
pala-etal-2010-lexical,U07-1009,0,\N,Missing
pala-etal-2010-lexical,W07-1710,1,\N,Missing
passonneau-etal-2012-masc,passonneau-etal-2010-word,1,\N,Missing
passonneau-etal-2012-masc,W10-1806,1,\N,Missing
passonneau-etal-2012-masc,passonneau-etal-2006-inter,1,\N,Missing
passonneau-etal-2012-masc,passonneau-2006-measuring,1,\N,Missing
passonneau-etal-2012-masc,W09-2402,1,\N,Missing
passonneau-etal-2012-masc,N06-2015,0,\N,Missing
passonneau-etal-2012-masc,J08-4004,0,\N,Missing
passonneau-etal-2012-masc,P03-2030,1,\N,Missing
S07-1017,P98-1013,0,0.00879976,"over 8,000 synsets with over 15,000 words; about 1,400 synsets refer to Named Entities. Shallow approaches to text processing have been garnering a lot of attention recently. Specifically, shallow approaches to semantic processing are making large strides in the direction of efficiently and effectively deriving tacit semantic information from text. Semantic Role Labeling (SRL) is one such approach. With the advent of faster and powerful computers, more effective machine learning algorithms, and importantly, large data resources annotated with relevant levels of semantic information FrameNet (Baker et al., 1998) and ProbBank corpora (Palmer et al., 2005), we are seeing a surge in efficient approaches to SRL (Carreras and M`arquez, 2005). SRL is the process by which predicates and their arguments are identified and their roles defined in a sentence. To date, most of the reported SRL systems are for English. We do see some headway for other languages such as German and Chinese. The systems for the other languages follow the successful models devised for English, (Gildea and Jurafsky, 2002; Task design With the release of the AWN, we set out to design a sub-task on Arabic WSD. The 95 5 Task: Semantic Ro"
S07-1017,W05-0620,0,0.320515,"Missing"
S07-1017,J02-3001,0,0.231356,"arning algorithms, and importantly, large data resources annotated with relevant levels of semantic information FrameNet (Baker et al., 1998) and ProbBank corpora (Palmer et al., 2005), we are seeing a surge in efficient approaches to SRL (Carreras and M`arquez, 2005). SRL is the process by which predicates and their arguments are identified and their roles defined in a sentence. To date, most of the reported SRL systems are for English. We do see some headway for other languages such as German and Chinese. The systems for the other languages follow the successful models devised for English, (Gildea and Jurafsky, 2002; Task design With the release of the AWN, we set out to design a sub-task on Arabic WSD. The 95 5 Task: Semantic Role Labeling (SRL) Xue and Palmer, 2004; Pradhan et al., 2003). However, no SRL systems exist for Arabic. Challenges of Arabic for SRL Given the deep difference between such languages, this method may not be straightforward. To clarify this point, let us consider Figure 1. It illustrates a sample Arabic syntactic tree with the relevant part of speech tags and arguments defined. The sentence is                     .      ("
S07-1017,J05-1004,1,0.380781,"; about 1,400 synsets refer to Named Entities. Shallow approaches to text processing have been garnering a lot of attention recently. Specifically, shallow approaches to semantic processing are making large strides in the direction of efficiently and effectively deriving tacit semantic information from text. Semantic Role Labeling (SRL) is one such approach. With the advent of faster and powerful computers, more effective machine learning algorithms, and importantly, large data resources annotated with relevant levels of semantic information FrameNet (Baker et al., 1998) and ProbBank corpora (Palmer et al., 2005), we are seeing a surge in efficient approaches to SRL (Carreras and M`arquez, 2005). SRL is the process by which predicates and their arguments are identified and their roles defined in a sentence. To date, most of the reported SRL systems are for English. We do see some headway for other languages such as German and Chinese. The systems for the other languages follow the successful models devised for English, (Gildea and Jurafsky, 2002; Task design With the release of the AWN, we set out to design a sub-task on Arabic WSD. The 95 5 Task: Semantic Role Labeling (SRL) Xue and Palmer, 2004; Pra"
S07-1017,W04-3212,1,0.868328,"ora (Palmer et al., 2005), we are seeing a surge in efficient approaches to SRL (Carreras and M`arquez, 2005). SRL is the process by which predicates and their arguments are identified and their roles defined in a sentence. To date, most of the reported SRL systems are for English. We do see some headway for other languages such as German and Chinese. The systems for the other languages follow the successful models devised for English, (Gildea and Jurafsky, 2002; Task design With the release of the AWN, we set out to design a sub-task on Arabic WSD. The 95 5 Task: Semantic Role Labeling (SRL) Xue and Palmer, 2004; Pradhan et al., 2003). However, no SRL systems exist for Arabic. Challenges of Arabic for SRL Given the deep difference between such languages, this method may not be straightforward. To clarify this point, let us consider Figure 1. It illustrates a sample Arabic syntactic tree with the relevant part of speech tags and arguments defined. The sentence is                     .      (                  m$rwE AlAmm AlmtHdp frD mhlp nhAyp l AtAHp AlfrSp AmAm qbrS. meaning ‘The United Nations’ project imposed a final grace period as an o"
S07-1017,J98-1001,0,\N,Missing
S07-1017,C98-1013,0,\N,Missing
S10-1013,J07-4005,0,0.597125,"0.505 ±0.026 0.350 R verbs 0.450 ±0.034 0.454 ±0.034 0.291 ±0.025 0.403 ±0.033 0.293 R 0.529 ±0.021 0.521 ±0.018 0.496 ±0.019 0.462 ±0.020 0.294 R nouns 0.530 ±0.024 0.522 ±0.023 0.507 ±0.020 0.472 ±0.024 0.308 R verbs 0.528 ±0.038 0.519 ±0.035 0.468 ±0.037 0.437 ±0.035 0.257 Table 3: Overall results for the domain WSD datasets, ordered by recall. This is the only group using hand-tagged data from the target domain. Their best run ranked 1st. with two variants. In the first (IIITH1), the vertices of the graph are initialized following the ranking scores obtained from predominant senses as in (McCarthy et al., 2007). In the second (IIITH2), the graph is initialized with keyness values as in IIITTH: They presented a personalized PageRank algorithm over a graph constructed from WordNet similar to (Agirre and Soroa, 2009), 77 CFILT-2 CFILT-1 IIITH1-d.l.ppr.05 IIITH2-d.l.ppr.05 BLC20SCBG BLC20SC CFILT-3 Treematch Treematch-2 Kyoto-2 Treematch-3 RACAI-MFS UCF-WS HIT-CIR-DMFS UCF-WS-domain IIITH2-d.r.l.baseline.05 IIITH1-d.l.baseline.05 RACAI-2MFS-BOW IIITH1-d.l.ppv.05 IIITH2-d.r.l.ppv.05 UCF-WS-domain.noPropers Kyoto-1 BLC20BG NLEL-WSD-PDB RACAI-Lexical-Chains MFS NLEL-WSD Rel. Sem. Trees Rel. Sem. Trees-2 Re"
S10-1013,W04-0807,0,0.0284195,"omain for WSD in four languages (Chinese, Dutch, English, Italian). 11 teams participated, with supervised and knowledge-based systems, mainly in the English dataset. The results show that in all languages the participants where able to beat the most frequent sense heuristic as estimated from general corpora. The most successful approaches used some sort of supervision in the form of hand-tagged examples from the domain. 1 Introduction Word Sense Disambiguation (WSD) competitions have focused on general domain texts, as attested in previous Senseval and SemEval competitions (Kilgarriff, 2001; Mihalcea et al., 2004; Snyder and Palmer, 2004; Pradhan et al., 2007). Spe1 http://xmlgroup.iit.cnr.it/SemEval2010/ and http://semeval2.fbk.eu/ 2 http://www.kyoto-project.eu/ 75 Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 75–80, c Uppsala, Sweden, 15-16 July 2010. 2010 Association for Computational Linguistics independent of the application domain. The paper is structured as follows. We first present the preparation of the data. Section 3 reviews participant systems and Section 4 the results. Finally, Section 5 presents the conclusions. 2 Chinese Dutch English Italian The"
S10-1013,E09-1005,1,0.474766,".308 R verbs 0.528 ±0.038 0.519 ±0.035 0.468 ±0.037 0.437 ±0.035 0.257 Table 3: Overall results for the domain WSD datasets, ordered by recall. This is the only group using hand-tagged data from the target domain. Their best run ranked 1st. with two variants. In the first (IIITH1), the vertices of the graph are initialized following the ranking scores obtained from predominant senses as in (McCarthy et al., 2007). In the second (IIITH2), the graph is initialized with keyness values as in IIITTH: They presented a personalized PageRank algorithm over a graph constructed from WordNet similar to (Agirre and Soroa, 2009), 77 CFILT-2 CFILT-1 IIITH1-d.l.ppr.05 IIITH2-d.l.ppr.05 BLC20SCBG BLC20SC CFILT-3 Treematch Treematch-2 Kyoto-2 Treematch-3 RACAI-MFS UCF-WS HIT-CIR-DMFS UCF-WS-domain IIITH2-d.r.l.baseline.05 IIITH1-d.l.baseline.05 RACAI-2MFS-BOW IIITH1-d.l.ppv.05 IIITH2-d.r.l.ppv.05 UCF-WS-domain.noPropers Kyoto-1 BLC20BG NLEL-WSD-PDB RACAI-Lexical-Chains MFS NLEL-WSD Rel. Sem. Trees Rel. Sem. Trees-2 Rel. Cliques 0.3 0.35 0.4 0.45 0.5 0.55 Figure 1: Plot for all the systems which participated in English domain WSD. Each point correspond to one system (denoted in axis Y) according each recall and confidence"
S10-1013,S07-1016,0,0.0570391,"English, Italian). 11 teams participated, with supervised and knowledge-based systems, mainly in the English dataset. The results show that in all languages the participants where able to beat the most frequent sense heuristic as estimated from general corpora. The most successful approaches used some sort of supervision in the form of hand-tagged examples from the domain. 1 Introduction Word Sense Disambiguation (WSD) competitions have focused on general domain texts, as attested in previous Senseval and SemEval competitions (Kilgarriff, 2001; Mihalcea et al., 2004; Snyder and Palmer, 2004; Pradhan et al., 2007). Spe1 http://xmlgroup.iit.cnr.it/SemEval2010/ and http://semeval2.fbk.eu/ 2 http://www.kyoto-project.eu/ 75 Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 75–80, c Uppsala, Sweden, 15-16 July 2010. 2010 Association for Computational Linguistics independent of the application domain. The paper is structured as follows. We first present the preparation of the data. Section 3 reviews participant systems and Section 4 the results. Finally, Section 5 presents the conclusions. 2 Chinese Dutch English Italian The data made available to the participants included"
S10-1013,S07-1097,0,0.0246659,"wledge-based WSD system was based on an algorithm originally described in (Schwartz and Gomez, 2008), in which selectors are acquired from the Web via searching with local context of a given word. The sense is chosen based on the similarity or relatedness between the senses of the target word and various types of selectors. In some runs they include predominant senses(McCarthy et al., 2007). The best run ranked 13th. NLEL-WSD(-PDB): The system used for the participation is based on an ensemble of different methods using fuzzy-Borda voting. A similar system was proposed in SemEval-2007 task-7 (Buscaldi and Rosso, 2007). In this case, the component method used where the following ones: 1) Most Frequent Sense from SemCor; 2) Conceptual Density ; 3) Supervised Domain Relative Entropy classifier based on WordNet Domains; 4) Supervised Bayesian classifier based on WordNet Domains probabilities; and 5) Unsupervised Knownet-20 classifiers. The best run ranked 24th. UMCC-DLSI (Relevant): The team submitted three different runs using a knowledge-based system. The first two runs use domain vectors and the third is based on cliques, which measure how much a concept is correlated to the sentence by obtaining Relevant S"
S10-1013,W08-2114,0,0.0667055,"e was calculated analytically. The first sense baseline for each language was taken from each wordnet. The first sense baseline in English and Chinese corresponds to the most frequent sense, as estimated from out-of-domain corpora. In Dutch and Italian, it followed the intuitions of the lexicographer. Note that we don’t have the most frequent sense baseline from the domain texts, which would surely show higher results (Koeling et al., 2005). thesauri from bilingual parallel corpora. The system ranked 14. UCFWS: This knowledge-based WSD system was based on an algorithm originally described in (Schwartz and Gomez, 2008), in which selectors are acquired from the Web via searching with local context of a given word. The sense is chosen based on the similarity or relatedness between the senses of the target word and various types of selectors. In some runs they include predominant senses(McCarthy et al., 2007). The best run ranked 13th. NLEL-WSD(-PDB): The system used for the participation is based on an ensemble of different methods using fuzzy-Borda voting. A similar system was proposed in SemEval-2007 task-7 (Buscaldi and Rosso, 2007). In this case, the component method used where the following ones: 1) Most"
S10-1013,W04-0811,0,0.196041,"anguages (Chinese, Dutch, English, Italian). 11 teams participated, with supervised and knowledge-based systems, mainly in the English dataset. The results show that in all languages the participants where able to beat the most frequent sense heuristic as estimated from general corpora. The most successful approaches used some sort of supervision in the form of hand-tagged examples from the domain. 1 Introduction Word Sense Disambiguation (WSD) competitions have focused on general domain texts, as attested in previous Senseval and SemEval competitions (Kilgarriff, 2001; Mihalcea et al., 2004; Snyder and Palmer, 2004; Pradhan et al., 2007). Spe1 http://xmlgroup.iit.cnr.it/SemEval2010/ and http://semeval2.fbk.eu/ 2 http://www.kyoto-project.eu/ 75 Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 75–80, c Uppsala, Sweden, 15-16 July 2010. 2010 Association for Computational Linguistics independent of the application domain. The paper is structured as follows. We first present the preparation of the data. Section 3 reviews participant systems and Section 4 the results. Finally, Section 5 presents the conclusions. 2 Chinese Dutch English Italian The data made available to th"
S10-1013,E09-1045,0,0.0508574,"Missing"
S10-1013,vossen-etal-2008-kyoto,1,0.763195,"ses in specific domains, the context of the senses might change, and new senses and terms might be involved. Both supervised and knowledge-based systems are affected by these issues: while the first suffer from different context and sense priors, the later suffer from lack of coverage of domain-related words and information. The main goal of this task is to provide a multilingual testbed to evaluate WSD systems when faced with full-texts from a specific domain. All datasets and related information are publicly available from the task websites1 . This task was designed in the context of Kyoto (Vossen et al., 2008)2 , an Asian-European project that develops a community platform for modeling knowledge and finding facts across languages and cultures. The platform operates as a Wiki system with an ontological support that social communities can use to agree on the meaning of terms in specific domains of their interest. Kyoto focuses on the environmental domain because it poses interesting challenges for information sharing, but the techniques and platforms are Domain portability and adaptation of NLP components and Word Sense Disambiguation systems present new challenges. The difficulties found by supervis"
S10-1013,S01-1004,0,0.00916615,"the environment domain for WSD in four languages (Chinese, Dutch, English, Italian). 11 teams participated, with supervised and knowledge-based systems, mainly in the English dataset. The results show that in all languages the participants where able to beat the most frequent sense heuristic as estimated from general corpora. The most successful approaches used some sort of supervision in the form of hand-tagged examples from the domain. 1 Introduction Word Sense Disambiguation (WSD) competitions have focused on general domain texts, as attested in previous Senseval and SemEval competitions (Kilgarriff, 2001; Mihalcea et al., 2004; Snyder and Palmer, 2004; Pradhan et al., 2007). Spe1 http://xmlgroup.iit.cnr.it/SemEval2010/ and http://semeval2.fbk.eu/ 2 http://www.kyoto-project.eu/ 75 Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 75–80, c Uppsala, Sweden, 15-16 July 2010. 2010 Association for Computational Linguistics independent of the application domain. The paper is structured as follows. We first present the preparation of the data. Section 3 reviews participant systems and Section 4 the results. Finally, Section 5 presents the conclusions. 2 Chinese Dut"
S10-1013,H05-1053,0,0.486241,". Note that this method of estimating statistical significance might be more strict than other pairwise methods. We also include the results of two baselines. The random baseline was calculated analytically. The first sense baseline for each language was taken from each wordnet. The first sense baseline in English and Chinese corresponds to the most frequent sense, as estimated from out-of-domain corpora. In Dutch and Italian, it followed the intuitions of the lexicographer. Note that we don’t have the most frequent sense baseline from the domain texts, which would surely show higher results (Koeling et al., 2005). thesauri from bilingual parallel corpora. The system ranked 14. UCFWS: This knowledge-based WSD system was based on an algorithm originally described in (Schwartz and Gomez, 2008), in which selectors are acquired from the Web via searching with local context of a given word. The sense is chosen based on the similarity or relatedness between the senses of the target word and various types of selectors. In some runs they include predominant senses(McCarthy et al., 2007). The best run ranked 13th. NLEL-WSD(-PDB): The system used for the participation is based on an ensemble of different methods"
S10-1013,N09-1004,0,\N,Missing
S10-1013,W00-0901,0,\N,Missing
vossen-etal-2008-kyoto,W02-1304,1,\N,Missing
vossen-etal-2008-kyoto,W01-0703,1,\N,Missing
vossen-etal-2008-kyoto,magnini-cavaglia-2000-integrating,0,\N,Missing
vossen-etal-2008-kyoto,atserias-etal-2004-towards,1,\N,Missing
vossen-etal-2008-kyoto,soria-etal-2006-moving,1,\N,Missing
vossen-etal-2008-kyoto,chou-huang-2006-hantology,1,\N,Missing
vossen-etal-2008-kyoto,W06-1003,1,\N,Missing
W07-1409,P98-1013,0,0.0581043,"rders Y 1 This seems to be an accidental gap; WordNet contains many interlinked disease-patient noun pairs, incl. ""diabetes-diabetic,"" ""epilepsy-eplileptic,"" etc. 58 721: X works on Y → X discusses Y And one that could be is not, namely: 705: X is under a contract with Y → X cooperates with Y (not in the database) Other examples are outside the scope of DIRT&apos;s approach (i.e., “X pattern1 Y” → “X pattern2 Y”), but nonetheless the coverage is encouraging. 3.3 FrameNet In our earlier analysis, we identified knowledge about stereotypical situations and their events as important for RTE. FrameNet (Baker et al, 1998) attempts to encode this knowledge. FrameNet was used with some success in RTE2 by Burchardt and Frank (2005). FrameNet&apos;s basic unit - a Frame - is a script-like conceptual schema that refers to a situation, object, or event along with its participants (Frame Elements), identified independent of their syntactic configuration. We earlier discussed how 538.T ""...the O. J. Simpson murder trial..."" might entail 538.H ""O. J. Simpson was accused of murder."" This case applies to FrameNet’s Trial frame, which includes the Frame Elements Defendant and Charges, with Charges being defined as ""The legal l"
W07-1409,J91-1003,0,0.100568,"Missing"
W07-1409,W06-3907,0,0.0744538,"mbing, which includes sending the bomb in the mail. Thus a person could also recognize alternative verbs in 358.H as valid (e.g., ""mailed"", ""delivered"") or invalid (e.g., ""thrown at"", ""dropped on""), even 56 Some RTE3 examples contain complement-taking verbs that make an implication (either positive or negative) about the complement. For example: 668 ""A survey shows that X..."" → ""X..."" 657 ""...X was seen..."" → ""...X..."" 725 “...decided to X..."" → ""...X..."" 716 ""...have been unable to X..."" → ""...do not X"" In the first 3 the implication is positive, but in the last the implication is negative. (Nairn et al, 2006) provide a detailed analysis of this type of behavior. In fact, this notion of implicature (one part of a sentence making an implication about another part) extends beyond single verbs, and there are some more complex examples in RTE3, e.g.: 453 ""...won the battle to X..."" → ""...X..."" 784.T ""X reassures Russia it has nothing to fear..."" 784.H ""Russia fears..."" In this last example the implication behavior is quite complex: (loosely) If X reassures Y of Z, then Y is concerned about not-Z. 2.12 Metonymy/Transfer In some cases, language allows us to replace a word (sense) with a closely related w"
W07-1409,C98-1013,0,\N,Missing
W08-2205,W07-1420,0,0.0110908,"Missing"
W08-2205,P98-1013,0,0.0707153,"n exactly the right way to fire a script). Second, two new approches for amassing knowledge are available today that were not available previously, namely automated learning from corpora, and use of Web volunteers (e.g., (Chklovski, 2005)), and may be applicable to script acquisition (Script work in the ’70s typically worked with tiny databases of scripts). Finally, techniques for language processing have substantially improved, making core tasks (e.g., parsing) less problematic, and opening the possibility to easy authoring of scripts in English, followed by machine interpretation. FrameNet (Baker et al., 1998) already provides a few small scripts, but does not currently encode the complex scenarios that we would like; a vastly expanded resource would be highly useful. We are in the early stages of exploring this avenue, encoding scripts as a list of simple English sentences, which are then automatically translated to WordNet-sense tagged logic using our software. For example, a “bombing” script looks: A building is bombed by an attacker. The attacker plants the bomb in the building. 54 Clark, Fellbaum, Hobbs, Harrison, Murray, and Thompson The bomb explodes. The explosion damages or destroys the bu"
W08-2205,W07-1427,0,0.0257037,"Missing"
W08-2205,W08-2221,1,0.9137,"ng’s Language Understanding Engine, which we first describe. We then present the WordNet augmentations that we are developing, and our experience with these as well as with the DIRT paraphrase database. Augmenting WordNet for Deep Understanding of Text 47 The contribution of this paper is some preliminary insight into avenues and challenges for creating and leveraging more world knowledge, in the context of WordNet, for deeper language understanding. 2 Text Interpretation and Subsumption 2.1 Text Interpretation For text interpretation we are using BLUE, Boeing’s Language Understanding Engine (Clark and Harrison, 2008), comprising a parser, logical form (LF) generator, and final logic generator. Parsing is performed using SAPIR, a mature, bottom-up, broad coverage chart parser (Harrison and Maxwell, 1986). The parser’s cost function is biased by a database of manually and corpus-derived “tuples” (good parse fragments), as well as hand-coded preference rules. During parsing, the system also generates a logical form (LF), a semi-formal structure between a parse and full logic, loosely based on Schubert and Hwang (1993). The LF is a simplified and normalized tree structure with logic-type elements, generated b"
W08-2205,C98-1013,0,\N,Missing
W08-2205,W07-1401,0,\N,Missing
W09-2420,C08-1003,1,0.83081,"Missing"
W09-2420,W06-1615,0,0.185914,"Missing"
W09-2420,P07-1007,0,0.123157,"Missing"
W09-2420,W04-3237,0,0.0779774,"Missing"
W09-2420,P07-1033,0,0.148042,"Missing"
W09-2420,W00-1322,0,0.0374768,"Missing"
W09-2420,S01-1004,0,0.385256,"The difficulties found by supervised systems to adapt might change the way we assess the strengths and weaknesses of supervised and knowledgebased WSD systems. Unfortunately, all existing evaluation datasets for specific domains are lexical-sample corpora. With this paper we want to motivate the creation of an allwords test dataset for WSD on the environment domain in several languages, and present the overall design of this SemEval task. 1 Introduction Word Sense Disambiguation (WSD) competitions have focused on general domain texts, as attested in the last Senseval and Semeval competitions (Kilgarriff, 2001; Mihalcea et al., 2004; Pradhan et al., 2007). Specific domains pose fresh challenges to WSD systems: the context in which the senses occur might change, distributions and predominant senses vary, some words tend to occur in fewer senses in specific domains, and new senses and terms might be involved. Both supervised and knowledge-based systems are affected by these issues: while the first suffer from different context and sense priors, the later suffer from lack of coverage of domain-related words and information. 123 Domain adaptation of supervised techniques is a hot issue in Natural Langu"
W09-2420,H05-1053,0,0.676819,"ated words and information. 123 Domain adaptation of supervised techniques is a hot issue in Natural Language Processing, including Word Sense Disambiguation. Supervised Word Sense Disambiguation systems trained on general corpora are known to perform worse when applied to specific domains (Escudero et al., 2000; Mart´ınez and Agirre, 2000), and domain adaptation techniques have been proposed as a solution to this problem with mixed results. Current research on applying WSD to specific domains has been evaluated on three available lexicalsample datasets (Ng and Lee, 1996; Weeber et al., 2001; Koeling et al., 2005). This kind of dataset contains hand-labeled examples for a handful of selected target words. As the systems are evaluated on a few words, the actual performance of the systems over complete texts can not be measured. Differences in behavior of WSD systems when applied to lexical-sample and all-words datasets have been observed on previous Senseval and Semeval competitions (Kilgarriff, 2001; Mihalcea et al., 2004; Pradhan et al., 2007): supervised systems attain results on the high 80’s and beat the most frequent baseline by a large margin for lexical-sample datasets, but results on the all-wo"
W09-2420,W04-0807,0,0.189564,"ound by supervised systems to adapt might change the way we assess the strengths and weaknesses of supervised and knowledgebased WSD systems. Unfortunately, all existing evaluation datasets for specific domains are lexical-sample corpora. With this paper we want to motivate the creation of an allwords test dataset for WSD on the environment domain in several languages, and present the overall design of this SemEval task. 1 Introduction Word Sense Disambiguation (WSD) competitions have focused on general domain texts, as attested in the last Senseval and Semeval competitions (Kilgarriff, 2001; Mihalcea et al., 2004; Pradhan et al., 2007). Specific domains pose fresh challenges to WSD systems: the context in which the senses occur might change, distributions and predominant senses vary, some words tend to occur in fewer senses in specific domains, and new senses and terms might be involved. Both supervised and knowledge-based systems are affected by these issues: while the first suffer from different context and sense priors, the later suffer from lack of coverage of domain-related words and information. 123 Domain adaptation of supervised techniques is a hot issue in Natural Language Processing, includi"
W09-2420,H93-1061,0,0.37412,"cific domain. Good results in this setting would show that supervised domain adaptation is working, and that generic WSD systems can be supplemented with hand-tagged examples from the target domain. There is an additional setting, where a generic WSD system is supplemented with untagged examples from the domain. Good results in this setting would show that semi-supervised domain adaptation works, and that generic WSD systems can be supplemented with untagged examples from the target domain in order to improve their results. Most of current all-words generic supervised WSD systems take SemCor (Miller et al., 1993) as their source corpus, i.e. they are trained on SemCor examples and then applied to new examples. SemCor is the largest publicly available annotated corpus. It’s mainly a subset of the Brown Corpus, plus the novel The Red Badge of Courage. The Brown corpus is balanced, yet not from the general domain, as it comprises 500 documents drawn from different domains, each approximately 2000 words long. Although the Brown corpus is balanced, SemCor is not, as the documents were not chosen at random. 4 State-of-the-art in WSD for specific domains Initial work on domain adaptation for WSD systems show"
W09-2420,P96-1006,0,0.698695,"fer from lack of coverage of domain-related words and information. 123 Domain adaptation of supervised techniques is a hot issue in Natural Language Processing, including Word Sense Disambiguation. Supervised Word Sense Disambiguation systems trained on general corpora are known to perform worse when applied to specific domains (Escudero et al., 2000; Mart´ınez and Agirre, 2000), and domain adaptation techniques have been proposed as a solution to this problem with mixed results. Current research on applying WSD to specific domains has been evaluated on three available lexicalsample datasets (Ng and Lee, 1996; Weeber et al., 2001; Koeling et al., 2005). This kind of dataset contains hand-labeled examples for a handful of selected target words. As the systems are evaluated on a few words, the actual performance of the systems over complete texts can not be measured. Differences in behavior of WSD systems when applied to lexical-sample and all-words datasets have been observed on previous Senseval and Semeval competitions (Kilgarriff, 2001; Mihalcea et al., 2004; Pradhan et al., 2007): supervised systems attain results on the high 80’s and beat the most frequent baseline by a large margin for lexica"
W09-2420,S07-1016,0,0.278613,"ems to adapt might change the way we assess the strengths and weaknesses of supervised and knowledgebased WSD systems. Unfortunately, all existing evaluation datasets for specific domains are lexical-sample corpora. With this paper we want to motivate the creation of an allwords test dataset for WSD on the environment domain in several languages, and present the overall design of this SemEval task. 1 Introduction Word Sense Disambiguation (WSD) competitions have focused on general domain texts, as attested in the last Senseval and Semeval competitions (Kilgarriff, 2001; Mihalcea et al., 2004; Pradhan et al., 2007). Specific domains pose fresh challenges to WSD systems: the context in which the senses occur might change, distributions and predominant senses vary, some words tend to occur in fewer senses in specific domains, and new senses and terms might be involved. Both supervised and knowledge-based systems are affected by these issues: while the first suffer from different context and sense priors, the later suffer from lack of coverage of domain-related words and information. 123 Domain adaptation of supervised techniques is a hot issue in Natural Language Processing, including Word Sense Disambigu"
W09-2420,rose-etal-2002-reuters,0,0.0411856,"d a total of 192,800 occurrences of these words were tagged with WordNet 1.5 senses, more than 1,000 instances per word in average. The examples from BC comprise 78,080 occurrences of word senses, and examples from WSJ consist on 114,794 occurrences. In domain adaptation experiments, the Brown Corpus examples play the role of general corpora, and the examples from the WSJ play the role of domain-specific examples. Koeling et al. (2005) present a corpus were the examples are drawn from the balanced B NC corpus (Leech, 1992) and the S PORTS and F INANCES sections of the newswire Reuters corpus (Rose et al., 2002), comprising around 300 examples (roughly 100 from each of those corpora) for each of the 41 nouns. The nouns were selected because they were 124 salient in either the S PORTS or F INANCES domains, or because they had senses linked to those domains. The occurrences were hand-tagged with the senses from WordNet version 1.7.1 (Fellbaum, 1998). In domain adaptation experiments the B NC examples play the role of general corpora, and the F INANCES and S PORTS examples the role of two specific domain corpora. Finally, a dataset for biomedicine was developed by Weeber et al. (2001), and has been used"
W09-2420,D08-1105,0,0.0322595,"Missing"
W09-2420,W04-0811,0,\N,Missing
W09-2420,vossen-etal-2008-kyoto,1,\N,Missing
W09-2420,E09-1006,1,\N,Missing
W09-2420,E09-1005,1,\N,Missing
W09-2420,E09-1045,0,\N,Missing
W09-2420,W00-0901,0,\N,Missing
W09-2420,W00-1326,1,\N,Missing
W09-2420,J07-4005,0,\N,Missing
W09-2420,W08-2114,0,\N,Missing
W09-2420,S07-1097,0,\N,Missing
W09-3021,S07-1016,0,0.0254279,"Missing"
W09-3021,S07-1048,0,\N,Missing
W09-3021,N06-2015,0,\N,Missing
W09-3021,ide-etal-2002-american,0,\N,Missing
W10-1308,O97-1002,0,0.0474176,"h between synsets, inversely proportional to the number of nodes on the path. • “wup” (Wu and Palmer, 1994) – ratio of the depth of the Least Common Subsumer (LCS) to the depths of two synsets in the Wordnet taxonomy. • “lch” (Leacock and Chodorow, 1998) – considering the length of the shortest path between two synsets to the depth of the WordNet taxonomy. 2) Information and content based measures. • “res” (Resnik, 1995) – the informational content (IC) of a given corpus of the LCS between two synsets. • “lin” (Lin, 1997) – the ratio of the IC of the LCS to the IC of the two synsets. • “jcn” (Jiang and Conrath, 1997) – inversely proportional to the difference between the IC of the two synsets and the IC of the LCS. 1 “hso” (Hirst and St-Onge, 1998) extensively slows down the WSD process with over five context words, and thus, is not included in the experiment. 3) WordNet definition based measures. • “lesk” (Banerjee and Pedersen, 2002) – overlaps in the definitions of two synsets. • “vector” (Patwardhan and Pedersen, 2006) – cosine of the angle between the cooccurrence vector computed from the definitions around the two synsets. • “vector_pairs” – co-occurrence vectors are computed from definition pairs s"
W10-1308,P97-1009,0,0.262778,"control a vehicle,” and “fast: quickly or rapidly” via WSD. It means the sound “car – passing.wav” can be used to depict those concepts. This approach is viable because the words in the sound/image labels were shown to evoke one another based on the auditory/visual content, and their meanings can be identified by considering all the tags generated for a 63 given sound or image as a context. With the availability of large sound/image label datasets, the vocabulary created from WSD can be easily expanded. A variety of WSD methods (e.g. knowledgebased methods (Lesk, 1986), unsupervised methods (Lin, 1997), semi-supervised methods (Hearst, 1991) (Yarowsky, 1995), and supervised methods (Novischi et al., 2007)) were developed and evaluated with corpus data and other text documents like webpages. Compared to the text data that WSD methods work with, labels for sounds and images have unique characteristics. The labels are a bag of words related to the visual/auditory content; there is no syntactic or part of speech information, nor are the words necessarily contextual neighbors. For example, contexts suggest landscape senses for the word pair “bank” and “water”, whereas in an image, a person may d"
W10-1308,S07-1047,0,0.0261851,"g.wav” can be used to depict those concepts. This approach is viable because the words in the sound/image labels were shown to evoke one another based on the auditory/visual content, and their meanings can be identified by considering all the tags generated for a 63 given sound or image as a context. With the availability of large sound/image label datasets, the vocabulary created from WSD can be easily expanded. A variety of WSD methods (e.g. knowledgebased methods (Lesk, 1986), unsupervised methods (Lin, 1997), semi-supervised methods (Hearst, 1991) (Yarowsky, 1995), and supervised methods (Novischi et al., 2007)) were developed and evaluated with corpus data and other text documents like webpages. Compared to the text data that WSD methods work with, labels for sounds and images have unique characteristics. The labels are a bag of words related to the visual/auditory content; there is no syntactic or part of speech information, nor are the words necessarily contextual neighbors. For example, contexts suggest landscape senses for the word pair “bank” and “water”, whereas in an image, a person may drink water inside a bank building. Furthermore, few annotated image or sound label datasets are available"
W10-1308,W06-2501,0,0.0686095,"” (Resnik, 1995) – the informational content (IC) of a given corpus of the LCS between two synsets. • “lin” (Lin, 1997) – the ratio of the IC of the LCS to the IC of the two synsets. • “jcn” (Jiang and Conrath, 1997) – inversely proportional to the difference between the IC of the two synsets and the IC of the LCS. 1 “hso” (Hirst and St-Onge, 1998) extensively slows down the WSD process with over five context words, and thus, is not included in the experiment. 3) WordNet definition based measures. • “lesk” (Banerjee and Pedersen, 2002) – overlaps in the definitions of two synsets. • “vector” (Patwardhan and Pedersen, 2006) – cosine of the angle between the cooccurrence vector computed from the definitions around the two synsets. • “vector_pairs” – co-occurrence vectors are computed from definition pairs separately. The computation of the relatedness scores using measures listed above were carried out by codes from the WordNet::Similarity (Pedersen et al., 2004) and WordNet::SenseRelate projects (Pedersen and Kolhatkar, 2009). In contrast to WordNet::SenseRelated, which employs only one similarity measure in the WSD process, this paper proposes a strategy of having several semantic relatedness measures vote for"
W10-1308,N09-5005,0,0.0147423,"t words, and thus, is not included in the experiment. 3) WordNet definition based measures. • “lesk” (Banerjee and Pedersen, 2002) – overlaps in the definitions of two synsets. • “vector” (Patwardhan and Pedersen, 2006) – cosine of the angle between the cooccurrence vector computed from the definitions around the two synsets. • “vector_pairs” – co-occurrence vectors are computed from definition pairs separately. The computation of the relatedness scores using measures listed above were carried out by codes from the WordNet::Similarity (Pedersen et al., 2004) and WordNet::SenseRelate projects (Pedersen and Kolhatkar, 2009). In contrast to WordNet::SenseRelated, which employs only one similarity measure in the WSD process, this paper proposes a strategy of having several semantic relatedness measures vote for the best synset for each word. The voting algorithm intends to improve WSD performance by combining conclusions from various measures to eliminate a false result. Since there is no syntax among the words generated for a sound/image, they should all be considered for WSD. Thus, the width of the context window is the total number of words in the context. sets for all words in the sound/image labels. Evocation"
W10-1308,P94-1019,0,0.0342236,"labels. Considering that the evocation dataset is small in size and susceptible to noise given the method by which it was collected, we have not yet incorporated evocation into the measure-combined voting algorithm described in the Section 4. 3.2 Semantic Relatedness Measures Nine measures of semantic relatedness 1 between synsets are used in the experiment, both as contributors to the voting algorithm and as baselines for comparison, including: 1) WordNet path based measures. • “path” – shortest path length between synsets, inversely proportional to the number of nodes on the path. • “wup” (Wu and Palmer, 1994) – ratio of the depth of the Least Common Subsumer (LCS) to the depths of two synsets in the Wordnet taxonomy. • “lch” (Leacock and Chodorow, 1998) – considering the length of the shortest path between two synsets to the depth of the WordNet taxonomy. 2) Information and content based measures. • “res” (Resnik, 1995) – the informational content (IC) of a given corpus of the LCS between two synsets. • “lin” (Lin, 1997) – the ratio of the IC of the LCS to the IC of the two synsets. • “jcn” (Jiang and Conrath, 1997) – inversely proportional to the difference between the IC of the two synsets and t"
W10-1308,P95-1026,0,0.0571442,"via WSD. It means the sound “car – passing.wav” can be used to depict those concepts. This approach is viable because the words in the sound/image labels were shown to evoke one another based on the auditory/visual content, and their meanings can be identified by considering all the tags generated for a 63 given sound or image as a context. With the availability of large sound/image label datasets, the vocabulary created from WSD can be easily expanded. A variety of WSD methods (e.g. knowledgebased methods (Lesk, 1986), unsupervised methods (Lin, 1997), semi-supervised methods (Hearst, 1991) (Yarowsky, 1995), and supervised methods (Novischi et al., 2007)) were developed and evaluated with corpus data and other text documents like webpages. Compared to the text data that WSD methods work with, labels for sounds and images have unique characteristics. The labels are a bag of words related to the visual/auditory content; there is no syntactic or part of speech information, nor are the words necessarily contextual neighbors. For example, contexts suggest landscape senses for the word pair “bank” and “water”, whereas in an image, a person may drink water inside a bank building. Furthermore, few annot"
W10-1308,N04-3012,0,\N,Missing
W14-3010,P10-1041,0,0.0513688,"Missing"
W14-3010,P11-1015,0,0.0674249,"at they all have characteristics (1) - (3). We examine data with eight different adverbs (Table 1). j∈S(i) where S(i) is the set of sentences annotated by the ith Turker and psji is the percentage of Turkers who have the same annotation with the ith Turker for sentence j. |S(i) |is the cardinality of set S(i). The agreement ranges from 0.52 to 0.8. Although the annotation of some Turkers is close to that of flipping a coin, all judgments were retained and included in the results reported here. 3.1 Data We extracted sentences containing the target adverbs from a corpus of 50,000 movie reviews (Maas et al., 2011). Each sentence is extracted from a review that is labeled either “positive” or “negative” and correlated with a star rating. We 3.3 Results We report the main results. The polarity rating of a sentence j is the (un-weighted) average rating 39 Adverbs absolutely awfully enormously extremely horribly incredibly pretty seriously Avg. Pol. Change 0.2 0.6 0.2 0.2 0.2 0.2 0.2 0.4 Pol. Reversal 0/20 2/20 1/20 2/20 0/20 4/20 1/20 3/20 Table 2: Effects of adverbs on sentiment ratings. Figure 1: The polarity intensifying effects of adverbs over the sentiment categories. of the five ∑ annotators for the"
W14-3010,D09-1063,0,0.0509068,"Missing"
W14-3010,P04-1035,0,0.0133378,"entire script while retaining sentences like There is no doubt that Alfred Hitchcock was a seriously talented director. For each adverb, we retained ten sentences from positive and negative reviews each, for a total 160 sentences. We copied the original sentences, removed the adverbs without making additional alterations. Our final dataset consisted of a total of 320 sentences with 160 sentence pairs whose members were identical except for the presence or absence of the target adverbs. Below is an example of a sentence pair, where the original sentence with the adverbs was pre-classified by (Pang and Lee, 2004) as carrying positive sentiment. Table 1: Eight intensifying adverbs and their polarities in sentiment lexicons. 1. Do the adverbs we investigate carry inherent sentiment values, as postulated by some sentiment lexicons? 2. Which adverbs have the strongest sentiment intensifying effect? 1. I was absolutely delighted by the simple story and amazing animation. 3. Do some adverbs have a stronger effect on sentences with a negative polarity or on sentences with a positive polarity? 2. I was delighted by the simple story and amazing animation. 3.2 Collecting Judgments via Crowdsourcing 4. Does the"
W14-3010,P05-1017,0,0.130148,"Missing"
W14-3010,H05-1044,0,0.316818,"Missing"
W14-3010,C10-1134,0,0.0474884,"Missing"
W14-3010,P13-2148,0,0.0265957,"Missing"
W14-3010,P12-1105,1,\N,Missing
W14-3010,P13-1174,0,\N,Missing
W14-3010,esuli-sebastiani-2006-sentiwordnet,0,\N,Missing
W17-1902,Q16-1028,1,0.94593,"g, namely finding a set of unit basis vectors a1 , . . . , ak ∈ Rd s.t. ∀ w ∈ V , Method 2: Better Matching Using WSI We found through examination that the scorethreshold method we have used so far performs poorly in two main cases: (a) the word w has no candidate synset with score high-enough to clear the threshold. (b) w has multiple closely related synsets that are all correct matches but some of which have a much lower score than others. vw = k X Rwi ai + ηw , (1) i=1 Here we address both issues by using sense information found by applying a word-sense induction method first introduced in Arora et al. (2016a). We summarize their WSI-model – referred to henceforth as Linear-WSI — in Section 3.3.1. Then in Section 3.3.2 we devise a sense purification procedure for constructing a word-cluster for each induced sense of a word. Applying this procedure to construct word-cluster representations of candidates synsets provides an additional metric for the correctness of word-synset matches that can be used to devise a w-specific threshold αw to ameliorate problem (a). Meanwhile, using LinearWSI to associate similar candidate synsets of w to each other provides a way to address problem (b). We explain the"
W17-1902,P13-1133,0,0.0604716,"Missing"
W17-1902,H94-1111,0,0.405531,"eral other recent approaches. Our method exceeds the best language-specific and multi-lingual automated WordNets in F-score for both languages. The databases we construct for French and Russian, both languages without large publicly available manually constructed WordNets, will be publicly released along with the test sets. 1 Introduction A WordNet is a lexical database for languages based upon a structure introduced by the Princeton WordNet (PWN) for English in which sets of cognitive synonyms, or synsets, are interconnected with arcs standing for semantic and lexical relations between them (Fellbaum, 1972). WordNets are widely used in computational linguistics, information retrieval, and machine translation. Constructing one by hand is time-consuming and difficult, motivating a search for automated or semiautomated methods. We present an unsupervised method based on word embeddings and wordsense induction and build and evaluate WordNets for French and Russian. Our approach needs only a large unannotated corpus like Wikipedia in the 1 https://github.com/mkhodak/pawn 12 Proceedings of the 1st Workshop on Sense, Concept and Entity Representations and their Applications, pages 12–23, c Valencia, Sp"
W17-1902,W16-1204,0,0.0446546,"Missing"
W17-1902,P15-1010,0,0.0468457,"rget language words with associated d-dimensional unit word-vectors vw ∈ Rd for d  |V |(e.g. d = 300 for vocabulary size 50000) trained on a large text corpus. Each word w ∈ V also has a set of candidate synsets found by MT+PWN. We call synsets S, S 0 in PWN related, denoted S ∼ S 0 , if one is a hyponym, meronym, antonym, or attribute of the other, if they share a verb group, or S = S 0 . 3.1 3.2 Method 1: Synset Representation To improve upon this baseline we need a better vector representation of S to score S via cosine similarity with vw . Previous efforts in synset and sense embeddings (Iacobacci et al., 2015; Rothe and Sch¨utze, 2015) often use extra resources such as WordNet or BabelNet for the target language (Navigli and Ponzetto, 2012). As such databases are not always available, we propose a synset representation uS that is unsupervised, needing no extra resources beyond MT and PWN, and leverages recent work on sentence embeddings. This new representation combines embeddings of synset information given by PWN, e.g. synset relations, definitions, and example sentences. To create these embeddings we first consider the question of how to represent a list of words L as a vector in Rd . One way i"
W17-1902,W00-1318,0,0.195648,"Missing"
W17-1902,C10-2097,0,0.256392,"Missing"
W17-1902,D14-1162,0,0.0801009,"Missing"
W17-1902,P15-1173,0,0.103507,"Missing"
W17-1902,D07-1107,0,\N,Missing
W97-0206,P92-1032,0,0.034804,"Missing"
W97-0206,H94-1046,0,0.0309886,"Missing"
