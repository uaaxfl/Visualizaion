2021.mtsummit-loresmt.4,Active Learning for Massively Parallel Translation of Constrained Text into Low Resource Languages,2021,-1,-1,2,0,1269,zhong zhou,Proceedings of the 4th Workshop on Technologies for MT of Low Resource Languages (LoResMT2021),0,"We translate a closed text that is known in advance and available in many languages into a new and severely low resource language. Most human translation efforts adopt a portionbased approach to translate consecutive pages/chapters in order, which may not suit machine translation. We compare the portion-based approach that optimizes coherence of the text locally with the random sampling approach that increases coverage of the text globally. Our results show that the random sampling approach performs better. When training on a seed corpus of â¼1,000 lines from the Bible and testing on the rest of the Bible (â¼30,000 lines), random sampling gives a performance gain of +11.0 BLEU using English as a simulated low resource language, and +4.9 BLEU using Eastern Pokomchi, a Mayan language. Furthermore, we compare three ways of updating machine translation models with increasing amount of human post-edited data through iterations. We find that adding newly post-edited data to training after vocabulary update without self-supervision performs the best. We propose an algorithm for human and machine to work together seamlessly to translate a closed text into a severely low resource language."
2021.eacl-demos.32,{ELITR} Multilingual Live Subtitling: Demo and Strategy,2021,-1,-1,16,0,292,ondvrej bojar,Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations,0,"This paper presents an automatic speech translation system aimed at live subtitling of conference presentations. We describe the overall architecture and key processing components. More importantly, we explain our strategy for building a complex system for end-users from numerous individual components, each of which has been tested only in laboratory conditions. The system is a working prototype that is routinely tested in recognizing English, Czech, and German speech and presenting it translated simultaneously into 42 target languages."
2020.lrec-1.817,{D}a{CT}o{R}: A Data Collection Tool for the {RELATER} Project,2020,-1,-1,4,0,14104,juan hussain,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Collecting domain-specific data for under-resourced languages, e.g., dialects of languages, can be very expensive, potentially financially prohibitive and taking long time. Moreover, in the case of rarely written languages, the normalization of non-canonical transcription might be another time consuming but necessary task. In order to collect domain-specific data in such circumstances in a time and cost-efficient way, collecting read data of pre-prepared texts is often a viable option. In order to collect data in the domain of psychiatric diagnosis in Arabic dialects for the project RELATER, we have prepared the data collection tool DaCToR for collecting read texts by speakers in the respective countries and districts in which the dialects are spoken. In this paper we describe our tool, its purpose within the project RELATER and the dialects which we have started to collect with the tool."
2020.iwltp-1.7,Removing {E}uropean Language Barriers with Innovative Machine Translation Technology,2020,-1,-1,10,0,11118,dario franceschini,Proceedings of the 1st International Workshop on Language Technology Platforms,0,"This paper presents our progress towards deploying a versatile communication platform in the task of highly multilingual live speech translation for conferences and remote meetings live subtitling. The platform has been designed with a focus on very low latency and high flexibility while allowing research prototypes of speech and text processing tools to be easily connected, regardless of where they physically run. We outline our architecture solution and also briefly compare it with the ELG platform. Technical details are provided on the most important components and we summarize the test deployment events we ran so far."
2020.eamt-1.53,{ELITR}: {E}uropean Live Translator,2020,-1,-1,13,0,292,ondvrej bojar,Proceedings of the 22nd Annual Conference of the European Association for Machine Translation,0,"ELITR (European Live Translator) project aims to create a speech translation system for simultaneous subtitling of conferences and online meetings targetting up to 43 languages. The technology is tested by the Supreme Audit Office of the Czech Republic and by alfaviewÂ®, a German online conferencing system. Other project goals are to advance document-level and multilingual machine translation, automatic speech recognition, and automatic minuting."
Q19-1020,Attention-Passing Models for Robust and Data-Efficient End-to-End Speech Translation,2019,2,17,4,1,10828,matthias sperber,Transactions of the Association for Computational Linguistics,0,"Speech translation has traditionally been approached through cascaded models consisting of a speech recognizer trained on a corpus of transcribed speech, and a machine translation system trained on parallel texts. Several recent works have shown the feasibility of collapsing the cascade into a single, direct model that can be trained in an end-to-end fashion on a corpus of translated speech. However, experiments are inconclusive on whether the cascade or the direct model is stronger, and have only been conducted under the unrealistic assumption that both are trained on equal amounts of data, ignoring other available speech recognition and machine translation corpora. In this paper, we demonstrate that direct speech translation models require more data to perform well than cascaded models, and although they allow including auxiliary data through multi-task training, they are poor at exploiting such data, putting them at a severe disadvantage. As a remedy, we propose the use of end- to-end trainable models with two attention mechanisms, the first establishing source speech to source text alignments, the second modeling source to target text alignment. We show that such models naturally decompose into multi-task{--}trainable recognition and translation tasks and propose an attention-passing technique that alleviates error propagation issues in a previous formulation of a model with two attention stages. Our proposed model outperforms all examined baselines and is able to exploit auxiliary training data much more effectively than direct attentional models."
P19-1115,Self-Attentional Models for Lattice Inputs,2019,0,4,4,1,10828,matthias sperber,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"Lattices are an efficient and effective method to encode ambiguity of upstream systems in natural language processing tasks, for example to compactly capture multiple speech recognition hypotheses, or to represent multiple linguistic analyses. Previous work has extended recurrent neural networks to model lattice inputs and achieved improvements in various tasks, but these models suffer from very slow computation speeds. This paper extends the recently proposed paradigm of self-attention to handle lattice inputs. Self-attention is a sequence modeling technique that relates inputs to one another by computing pairwise similarities and has gained popularity for both its strong results and its computational efficiency. To extend such models to handle lattices, we introduce probabilistic reachability masks that incorporate lattice structure into the model and support lattice scores if available. We also propose a method for adapting positional embeddings to lattice structures. We apply the proposed model to a speech translation task and find that it outperforms all examined baselines while being much faster to compute than previous neural lattice models during both training and inference."
D19-5535,Incremental processing of noisy user utterances in the spoken language understanding task,2019,15,0,3,0,26594,stefan constantin,Proceedings of the 5th Workshop on Noisy User-generated Text (W-NUT 2019),0,"The state-of-the-art neural network architectures make it possible to create spoken language understanding systems with high quality and fast processing time. One major challenge for real-world applications is the high latency of these systems caused by triggered actions with high executions times. If an action can be separated into subactions, the reaction time of the systems can be improved through incremental processing of the user utterance and starting subactions while the utterance is still being uttered. In this work, we present a model-agnostic method to achieve high quality in processing incrementally produced partial utterances. Based on clean and noisy versions of the ATIS dataset, we show how to create datasets with our method to create low-latency natural language understanding components. We get improvements of up to 47.91 absolute percentage points in the metric F1-score."
W18-2606,Robust and Scalable Differentiable Neural Computer for Question Answering,2018,0,6,3,0,28407,jorg franke,Proceedings of the Workshop on Machine Reading for Question Answering,0,"Deep learning models are often not easily adaptable to new tasks and require task-specific adjustments. The differentiable neural computer (DNC), a memory-augmented neural network, is designed as a general problem solver which can be used in a wide range of tasks. But in reality, it is hard to apply this model to new tasks. We analyze the DNC and identify possible improvements within the application of question answering. This motivates a more robust and scalable DNC (rsDNC). The objective precondition is to keep the general character of this model intact while making its application more reliable and speeding up its required training time. The rsDNC is distinguished by a more robust training, a slim memory unit and a bidirectional architecture. We not only achieve new state-of-the-art performance on the bAbI task, but also minimize the performance variance between different initializations. Furthermore, we demonstrate the simplified applicability of the rsDNC to new tasks with passable results on the CNN RC task without adaptions."
L18-1318,Automated Evaluation of Out-of-Context Errors,2018,6,0,3,0,4238,patrick huber,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,"We present a new approach to evaluate computational models for the task of text understanding by the means of out-of-context error detection. Through the novel design of our automated modification process, existing large-scale data sources can be adopted for a vast number of text understanding tasks. The data is thereby altered on a semantic level, allowing models to be tested against a challenging set of modified text passages that require to comprise a broader narrative discourse. Our newly introduced task targets actual real-world problems of transcription and translation systems by inserting authentic out-of-context errors. The automated modification process is applied to the 2016 TEDTalk corpus. Entirely automating the process allows the adoption of complete datasets at low cost, facilitating supervised learning procedures and deeper networks to be trained and tested. To evaluate the quality of the modification algorithm a language model and a supervised binary classification model are trained and tested on the altered dataset. A human baseline evaluation is examined to compare the results with human performance. The outcome of the evaluation task indicates the difficulty to detect semantic errors for machine-learning algorithms and humans, showing that the errors cannot be identified when limited to a single sentence."
L18-1533,{BULB}asaa: A Bilingual Basaa-{F}rench Speech Corpus for the Evaluation of Language Documentation Tools,2018,0,1,6,0,30106,fatima hamlaoui,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
W17-4734,The {QT}21 Combined Machine Translation System for {E}nglish to {L}atvian,2017,0,0,6,0.512486,30412,janthorsten peter,Proceedings of the Second Conference on Machine Translation,0,None
W17-3202,Analyzing Neural {MT} Search and Model Performance,2017,3,1,4,0.870228,5714,jan niehues,Proceedings of the First Workshop on Neural Machine Translation,0,"In this paper, we offer an in-depth analysis about the modeling and search performance. We address the question if a more complex search algorithm is necessary. Furthermore, we investigate the question if more complex models which might only be applicable during rescoring are promising. By separating the search space and the modeling using n-best list reranking, we analyze the influence of both parts of an NMT system independently. By comparing differently performing NMT systems, we show that the better translation is already in the search space of the translation systems with less performance. This results indicate that the current search algorithms are sufficient for the NMT systems. Furthermore, we could show that even a relatively small $n$-best list of 50 hypotheses already contain notably better translations."
D17-1145,Neural Lattice-to-Sequence Models for Uncertain Inputs,2017,0,6,4,1,10828,matthias sperber,Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing,0,"The input to a neural sequence-to-sequence model is often determined by an up-stream system, e.g. a word segmenter, part of speech tagger, or speech recognizer. These up-stream models are potentially error-prone. Representing inputs through word lattices allows making this uncertainty explicit by capturing alternative sequences and their posterior probabilities in a compact form. In this work, we extend the TreeLSTM (Tai et al., 2015) into a LatticeLSTM that is able to consume word lattices, and can be used as encoder in an attentional encoder-decoder model. We integrate lattice posterior scores into this architecture by extending the TreeLSTM{'}s child-sum and forget gates and introducing a bias term into the attention mechanism. We experiment with speech translation lattices and report consistent improvements over baselines that translate either the 1-best hypothesis or the lattice without posterior scores."
W16-2320,The {QT}21/{H}im{L} Combined Machine Translation System,2016,5,6,14,0.512486,30412,janthorsten peter,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,"This paper describes the joint submission of the QT21 and HimL projects for the Englishxe2x86x92Romanian translation task of the ACL 2016 First Conference on Machine Translation (WMT 2016). The submission is a system combination which combines twelve different statistical machine translation systems provided by the different groups (RWTH Aachen University, LMU Munich, Charles University in Prague, University of Edinburgh, University of Sheffield, Karlsruhe Institute of Technology, LIMSI, University of Amsterdam, Tilde). The systems are combined using RWTHxe2x80x99s system combination approach. The final submission shows an improvement of 1.0 BLEU compared to the best single system on newstest2016."
W16-2208,Using Factored Word Representation in Neural Network Language Models,2016,19,5,4,0.965992,5714,jan niehues,"Proceedings of the First Conference on Machine Translation: Volume 1, Research Papers",0,None
N16-3017,Lecture Translator - Speech translation framework for simultaneous lecture translation,2016,11,4,11,1,30108,markus muller,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Demonstrations,0,None
L16-1293,Evaluation of the {KIT} Lecture Translation System,2016,0,2,4,1,30108,markus muller,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"To attract foreign students is among the goals of the Karlsruhe Institute of Technology (KIT). One obstacle to achieving this goal is that lectures at KIT are usually held in German which many foreign students are not sufficiently proficient in, as, e.g., opposed to English. While the students from abroad are learning German during their stay at KIT, it is challenging to become proficient enough in it in order to follow a lecture. As a solution to this problem we offer our automatic simultaneous lecture translation. It translates German lectures into English in real time. While not as good as human interpreters, the system is available at a price that KIT can afford in order to offer it in potentially all lectures. In order to assess whether the quality of the system we have conducted a user study. In this paper we present this study, the way it was conducted and its results. The results indicate that the quality of the system has passed a threshold as to be able to support students in their studies. The study has helped to identify the most crucial weaknesses of the systems and has guided us which steps to take next."
L16-1314,Optimizing Computer-Assisted Transcription Quality with Iterative User Interfaces,2016,23,2,4,1,10828,matthias sperber,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Computer-assisted transcription promises high-quality speech transcription at reduced costs. This is achieved by limiting human effort to transcribing parts for which automatic transcription quality is insufficient. Our goal is to improve the human transcription quality via appropriate user interface design. We focus on iterative interfaces that allow humans to solve tasks based on an initially given suggestion, in this case an automatic transcription. We conduct a user study that reveals considerable quality gains for three variations of iterative interfaces over a non-iterative from-scratch transcription interface. Our iterative interfaces included post-editing, confidence-enhanced post-editing, and a novel retyping interface. All three yielded similar quality on average, but we found that the proposed retyping interface was less sensitive to the difficulty of the segment, and superior when the automatic transcription of the segment contained relatively many errors. An analysis using mixed-effects models allows us to quantify these and other factors and draw conclusions over which interface design should be chosen in which circumstance."
C16-1172,Pre-Translation for Neural Machine Translation,2016,20,27,4,0.965992,5714,jan niehues,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,"Recently, the development of neural machine translation (NMT) has significantly improved the translation quality of automatic machine translation. While most sentences are more accurate and fluent than translations by statistical machine translation (SMT)-based systems, in some cases, the NMT system produces translations that have a completely different meaning. This is especially the case when rare words occur. When using statistical machine translation, it has already been shown that significant gains can be achieved by simplifying the input in a preprocessing step. A commonly used example is the pre-reordering approach. In this work, we used phrase-based machine translation to pre-translate the input into the target language. Then a neural machine translation system generates the final hypothesis using the pre-translation. Thereby, we use either only the output of the phrase-based machine translation (PBMT) system or a combination of the PBMT output and the source sentence. We evaluate the technique on the English to German translation task. Using this approach we are able to outperform the PBMT system as well as the baseline neural MT system by up to 2 BLEU points. We analyzed the influence of the quality of the initial system on the final result."
C16-1292,Lightly Supervised Quality Estimation,2016,19,1,5,1,10828,matthias sperber,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,"Evaluating the quality of output from language processing systems such as machine translation or speech recognition is an essential step in ensuring that they are sufficient for practical use. However, depending on the practical requirements, evaluation approaches can differ strongly. Often, reference-based evaluation measures (such as BLEU or WER) are appealing because they are cheap and allow rapid quantitative comparison. On the other hand, practitioners often focus on manual evaluation because they must deal with frequently changing domains and quality standards requested by customers, for which reference-based evaluation is insufficient or not possible due to missing in-domain reference data (Harris et al., 2016). In this paper, we attempt to bridge this gap by proposing a framework for lightly supervised quality estimation. We collect manually annotated scores for a small number of segments in a test corpus or document, and combine them with automatically predicted quality scores for the remaining segments to predict an overall quality estimate. An evaluation shows that our framework estimates quality more reliably than using fully automatic quality estimation approaches, while keeping annotation effort low by not requiring full references to be available for the particular domain."
W15-4917,Stripping Adjectives: Integration Techniques for Selective Stemming in {SMT} Systems,2015,25,0,3,1,36550,isabel slawik,Proceedings of the 18th Annual Conference of the {E}uropean Association for Machine Translation,0,"In this paper we present an approach to reduce data sparsity problems when translating from morphologically rich languages into less inflected languages by selectively stemming certain word types. We develop and compare three different integration strategies: replacing words with their stemmed form, combined input using alternative lattice paths for the stemmed and surface forms and a novel hidden combination strategy, where we replace the stems in the stemmed phrase table by the observed surface forms in the test data. This allows us to apply advanced models trained on the surface forms of the words. We evaluate our approach by stemming German adjectives in two Germanxe2x86x92English translation scenarios: a low-resource condition as well as a large-scale state-of-the-art translation system. We are able to improve between 0.2 and 0.4 BLEU points over our baseline and reduce the number of out-of-vocabulary words by up to 16.5%."
W15-4657,Evaluation of Crowdsourced User Input Data for Spoken Dialog Systems,2015,11,1,5,0,16728,maria schmidt,Proceedings of the 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"Using the Internet for the collection of data is quite common these days. This process is called crowdsourcing and enables the collection of large amounts of data at reasonable costs. While being an inexpensive method, this data typically is of lower quality. Filtering data sets is therefore required. The occurring errors can be classified into different groups. There are technical issues and human errors. For speech recording, technical issues could be a noisy background. Human errors arise when the task is misunderstood. We employ several techniques for recognizing errors and eliminating faulty data sets in user input data for a Spoken Dialog System (SDS). Furthermore, we compare three different kinds of questionnaires (QNRs) for a given set of seven tasks. We analyze the characteristics of the resulting data sets and give a recommendation which type of QNR might be the most suitable one for a given purpose."
W15-3008,The Karlsruhe Institute of Technology Translation Systems for the {WMT} 2015,2015,30,2,7,1,2962,eunah cho,Proceedings of the Tenth Workshop on Statistical Machine Translation,0,"In this paper, the KIT systems submitted to the Shared Translation Task are presented. We participated in two translation directions: from German to English and from English to German. Both translations are generated using phrase-based translation systems. The performance of the systems was boosted by using language models built based on different tokens such as word, part-of-speech, and automacally generated word clusters. The difference in word order between German and English is addressed by part-of-speech and syntactic tree-based reordering models. In addition to a discriminative word lexicon, we used hypothesis rescoring using the ListNet algorithm after generating the translation with the phrase-based system. We evaluated the rescoring using only the baseline features as well as using additional computational complex features."
W15-3012,The {KIT}-{LIMSI} Translation System for {WMT} 2015,2015,30,1,7,1,5767,thanhle ha,Proceedings of the Tenth Workshop on Statistical Machine Translation,0,"This paper presented the joined submission of KIT and LIMSI to the English to German translation task of WMT 2015. In this year submission, we integrated a neural network-based translation model into a phrase-based translation model by rescoring the n-best lists. Since the computation complexity is one of the main issues for continuous space models, we compared two techniques to reduce the computation cost. We investigated models using a structured output layer as well as models trained with noise contrastive estimation. Furthermore, we evaluated a new method to obtain the best log-linear combination in the rescoring phase. Using these techniques, we were able to improve the BLEU score of the baseline phrase-based system by 1.4 BLEU points."
W15-3030,{L}ist{N}et-based {MT} Rescoring,2015,21,4,4,1,5714,jan niehues,Proceedings of the Tenth Workshop on Statistical Machine Translation,0,"The log-linear combination of different features is an important component of SMT systems. It allows for the easy integartion of models into the system and is used during decoding as well as for nbest list rescoring. With the recent success of more complex models like neural network-based translation models, n-best list rescoring attracts again more attention. In this work, we present a new technique to train the log-linear model based on the ListNet algorithm. This technique scales to many features, considers the whole list and not single entries during learning and can also be applied to more complex models than a log-linear combination. Using the new learning approach, we improve the translation quality of a largescale system by 0.8 BLEU points during rescoring and generate translations which are up to 0.3 BLEU points better than other learning techniques such as MERT or MIRA."
2015.iwslt-papers.3,Source discriminative word lexicon for translation disambiguation,2015,-1,-1,3,1,36851,teresa herrmann,Proceedings of the 12th International Workshop on Spoken Language Translation: Papers,0,None
2015.iwslt-papers.6,Multifeature modular deep neural network acoustic models,2015,-1,-1,2,1,34647,kevin kilgour,Proceedings of the 12th International Workshop on Spoken Language Translation: Papers,0,None
2015.iwslt-papers.7,Using language adaptive deep neural networks for improved multilingual speech recognition,2015,-1,-1,2,0,30102,markus mueller,Proceedings of the 12th International Workshop on Spoken Language Translation: Papers,0,None
2015.iwslt-papers.8,Punctuation insertion for real-time spoken language translation,2015,-1,-1,4,1,2962,eunah cho,Proceedings of the 12th International Workshop on Spoken Language Translation: Papers,0,None
2015.iwslt-evaluation.9,The {KIT} translation systems for {IWSLT} 2015,2015,-1,-1,5,1,5767,thanhle ha,Proceedings of the 12th International Workshop on Spoken Language Translation: Evaluation Campaign,0,None
2015.iwslt-evaluation.10,The 2015 {KIT} {IWSLT} speech-to-text systems for {E}nglish and {G}erman,2015,-1,-1,6,0,30102,markus mueller,Proceedings of the 12th International Workshop on Spoken Language Translation: Evaluation Campaign,0,None
2015.eamt-1.18,Stripping Adjectives: Integration Techniques for Selective Stemming in {SMT} Systems,2015,25,0,3,1,36550,isabel slawik,Proceedings of the 18th Annual Conference of the European Association for Machine Translation,0,"In this paper we present an approach to reduce data sparsity problems when translating from morphologically rich languages into less inflected languages by selectively stemming certain word types. We develop and compare three different integration strategies: replacing words with their stemmed form, combined input using alternative lattice paths for the stemmed and surface forms and a novel hidden combination strategy, where we replace the stems in the stemmed phrase table by the observed surface forms in the test data. This allows us to apply advanced models trained on the surface forms of the words. We evaluate our approach by stemming German adjectives in two Germanxe2x86x92English translation scenarios: a low-resource condition as well as a large-scale state-of-the-art translation system. We are able to improve between 0.2 and 0.4 BLEU points over our baseline and reduce the number of out-of-vocabulary words by up to 16.5%."
W14-3307,The {KIT}-{LIMSI} Translation System for {WMT} 2014,2014,27,1,6,0.681818,14186,quoc do,Proceedings of the Ninth Workshop on Statistical Machine Translation,0,"This paper describes the joined submission of LIMSI and KIT to the Shared Translation Task for the German-toEnglish direction. The system consists of a phrase-based translation system using a pre-reordering approach. The baseline system already includes several models like conventional language models on different word factors and a discriminative word lexicon. This system is used to generate a k-best list. In a second step, the list is reranked using SOUL language and translation models (Le et al., 2011). Originally, SOUL translation models were applied to n-gram-based translation systems that use tuples as translation units instead of phrase pairs. In this article, we describe their integration into the KIT phrase-based system. Experimental results show that their use can yield significant improvements in terms of BLEU score."
W14-3310,{EU-BRIDGE} {MT}: Combined Machine Translation,2014,59,18,13,0.819672,3519,markus freitag,Proceedings of the Ninth Workshop on Statistical Machine Translation,0,"This paper describes one of the collaborative efforts within EU-BRIDGE to further advance the state of the art in machine translation between two European language pairs, Germanxe2x86x92English and Englishxe2x86x92German. Three research institutes involved in the EU-BRIDGE project combined their individual machine translation systems and participated with a joint setup in the shared translation task of the evaluation campaign at the ACL 2014 Eighth Workshop on Statistical Machine Translation (WMT 2014). We combined up to nine different machine translation engines via system combination. RWTH Aachen University, the University of Edinburgh, and Karlsruhe Institute of Technology developed several individual systems which serve as system combination input. We devoted special attention to building syntax-based systems and combining them with the phrasebased ones. The joint setups yield empirical gains of up to 1.6 points in BLEU and 1.0 points in TER on the WMT newstest2013 test set compared to the best single systems."
W14-3313,The Karlsruhe Institute of Technology Translation Systems for the {WMT} 2014,2014,24,3,8,1,36851,teresa herrmann,Proceedings of the Ninth Workshop on Statistical Machine Translation,0,"In this paper, we present the KIT systems participating in the Shared Translation Task translating between English$German and English$French. All translations are generated using phrase-based translation systems, using different kinds of word-based, part-ofspeech-based and cluster-based language models trained on the provided data. Additional models include bilingual language models, reordering models based on part-of-speech tags and syntactic parse trees, as well as a lexicalized reordering model. In order to make use of noisy web-crawled data, we apply filtering and data selection methods for language modeling. A discriminative word lexicon using source context information proved beneficial for all translation directions."
Q14-1014,Segmentation for Efficient Supervised Language Annotation with an Explicit Cost-Utility Tradeoff,2014,30,4,5,1,10828,matthias sperber,Transactions of the Association for Computational Linguistics,0,"In this paper, we study the problem of manually correcting automatic annotations of natural language in as efficient a manner as possible. We introduce a method for automatically segmenting a corpus into chunks such that many uncertain labels are grouped into the same chunk, while human supervision can be omitted altogether for other segments. A tradeoff must be found for segment sizes. Choosing short segments allows us to reduce the number of highly confident labels that are supervised by the annotator, which is useful because these labels are often already correct and supervising correct labels is a waste of effort. In contrast, long segments reduce the cognitive effort due to context switches. Our method helps find the segmentation that optimizes supervision efficiency by defining user models to predict the cost and utility of supervising each segment and solving a constrained optimization problem balancing these contradictory objectives. A user study demonstrates noticeable gains over pre-segmented, confidence-ordered baselines on two natural language processing tasks: speech transcription and word segmentation."
cho-etal-2014-corpus,A Corpus of Spontaneous Speech in Lectures: The {KIT} Lecture Corpus for Spoken Language Processing and Translation,2014,14,6,4,1,2962,eunah cho,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"With the increasing number of applications handling spontaneous speech, the needs to process spoken languages become stronger. Speech disfluency is one of the most challenging tasks to deal with in automatic speech processing. As most applications are trained with well-formed, written texts, many issues arise when processing spontaneous speech due to its distinctive characteristics. Therefore, more data with annotated speech disfluencies will help the adaptation of natural language processing applications, such as machine translation systems. In order to support this, we have annotated speech disfluencies in German lectures at KIT. In this paper we describe how we annotated the disfluencies in the data and provide detailed statistics on the size of the corpus and the speakers. Moreover, machine translation performance on a source text including disfluencies is compared to the results of the translation of a source text without different sorts of disfluencies or no disfluencies at all."
herrmann-etal-2014-manual,Manual Analysis of Structurally Informed Reordering in {G}erman-{E}nglish Machine Translation,2014,15,1,3,1,36851,teresa herrmann,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"Word reordering is a difficult task for translation. Common automatic metrics such as BLEU have problems reflecting improvements in target language word order. However, it is a crucial aspect for humans when deciding on translation quality. This paper presents a detailed analysis of a structure-aware reordering approach applied in a German-to-English phrase-based machine translation system. We compare the translation outputs of two translation systems applying reordering rules based on parts-of-speech and syntax trees on a sentence-by-sentence basis. For each sentence-pair we examine the global translation performance and classify local changes in the translated sentences. This analysis is applied to three data sets representing different genres. While the improvement in BLEU differed substantially between the data sets, the manual evaluation showed that both global translation performance as well as individual types of improvements and degradations exhibit a similar behavior throughout the three data sets. We have observed that for 55-64{\%} of the sentences with different translations, the translation produced using the tree-based reordering was considered to be the better translation. As intended by the investigated reordering model, most improvements are achieved by improving the position of the verb or being able to translate a verb that could not be translated before."
E14-4009,Tight Integration of Speech Disfluency Removal into {SMT},2014,15,4,3,1,2962,eunah cho,"Proceedings of the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics, volume 2: Short Papers",0,"Speech disfluencies are one of the main challenges of spoken language processing. Conventional disfluency detection systems deploy a hard decision, which can have a negative influence on subsequent applications such as machine translation. In this paper we suggest a novel approach in which disfluency detection is integrated into the translation process. We train a CRF model to obtain a disfluency probability for each word. The SMT decoder will then skip the potentially disfluent word based on its disfluency probability. Using the suggested scheme, the translation score of both the manual transcript and ASR output is improved by around 0.35 BLEU points compared to the CRF hard decision system."
2014.iwslt-papers.4,Machine translation of multi-party meetings: segmentation and disfluency removal strategies,2014,-1,-1,3,1,2962,eunah cho,Proceedings of the 11th International Workshop on Spoken Language Translation: Papers,0,"Translating meetings presents a challenge since multi-speaker speech shows a variety of disfluencies. In this paper we investigate the importance of transforming speech into well-written input prior to translating multi-party meetings. We first analyze the characteristics of this data and establish oracle scores. Sentence segmentation and punctuation are performed using a language model, turn information, or a monolingual translation system. Disfluencies are removed by a CRF model trained on in-domain and out-of-domain data. For comparison, we build a combined CRF model for punctuation insertion and disfluency removal. By applying these models, multi-party meetings are transformed into fluent input for machine translation. We evaluate the models with regard to translation performance and are able to achieve an improvement of 2.1 to 4.9 BLEU points depending on the availability of turn information."
2014.iwslt-papers.7,Extracting translation pairs from social network content,2014,-1,-1,4,1,40353,matthias eck,Proceedings of the 11th International Workshop on Spoken Language Translation: Papers,0,"We introduce two methods to collect additional training data for statistical machine translation systems from public social network content. The first method identifies multilingual content where the author self-translated their own post to reach additional friends, fans or customers. Once identified, we can split the post in the language segments and extract translation pairs from this content. The second methods considers web links (URLs) that users add as part of their post to point the reader to a video, article or website. If the same URL is shared from different language users, there is a chance they might give the same comment in their respective language. We use a support vector machine (SVM) as a classifier to identify true translations from all candidate pairs. We collected additional translation pairs using both methods for the language pairs Spanish-English and Portuguese-English. Testing the collected data as additional training data for statistical machine translations on in-domain test sets resulted in very significant improvements of up to 5 BLEU."
2014.iwslt-papers.10,Lexical translation model using a deep neural network architecture,2014,-1,-1,3,1,5767,thanhle ha,Proceedings of the 11th International Workshop on Spoken Language Translation: Papers,0,"In this paper we combine the advantages of a model using global source sentence contexts, the Discriminative Word Lexicon, and neural networks. By using deep neural networks instead of the linear maximum entropy model in the Discriminative Word Lexicon models, we are able to leverage dependencies between different source words due to the non-linearity. Furthermore, the models for different target words can share parameters and therefore data sparsity problems are effectively reduced. By using this approach in a state-of-the-art translation system, we can improve the performance by up to 0.5 BLEU points for three different language pairs on the TED translation task."
2014.iwslt-papers.15,Multilingual deep bottle neck features: a study on language selection and training techniques,2014,-1,-1,5,1,30108,markus muller,Proceedings of the 11th International Workshop on Spoken Language Translation: Papers,0,"Previous work has shown that training the neural networks for bottle neck feature extraction in a multilingual way can lead to improvements in word error rate and average term weighted value in a telephone key word search task. In this work we conduct a systematic study on a) which multilingual training strategy to employ, b) the effect of language selection and amount of multilingual training data used and c) how to find a suitable combination for languages. We conducted our experiment on the key word search task and the languages of the IARPA BABEL program. In a first step, we assessed the performance of a single language out of all available languages in combination with the target language. Based on these results, we then combined a multitude of languages. We also examined the influence of the amount of training data per language, as well as different techniques for combining the languages during network training. Our experiments show that data from arbitrary additional languages does not necessarily increase the performance of a system. But when combining a suitable set of languages, a significant gain in performance can be achieved."
2014.iwslt-evaluation.7,Combined spoken language translation,2014,55,6,13,0.819672,3519,markus freitag,Proceedings of the 11th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"EU-BRIDGE is a European research project which is aimed at developing innovative speech translation technology. One of the collaborative efforts within EU-BRIDGE is to produce joint submissions of up to four different partners to the evaluation campaign at the 2014 International Workshop on Spoken Language Translation (IWSLT). We submitted combined translations to the GermanâEnglish spoken language translation (SLT) track as well as to the GermanâEnglish, EnglishâGerman and EnglishâFrench machine translation (MT) tracks. In this paper, we present the techniques which were applied by the different individual translation systems of RWTH Aachen University, the University of Edinburgh, Karlsruhe Institute of Technology, and Fondazione Bruno Kessler. We then show the combination approach developed at RWTH Aachen University which combined the individual systems. The consensus translations yield empirical gains of up to 2.3 points in BLEU and 1.2 points in TER compared to the best individual system."
2014.iwslt-evaluation.9,"The 2014 {KIT} {IWSLT} speech-to-text systems for {E}nglish, {G}erman and {I}talian",2014,-1,-1,6,1,34647,kevin kilgour,Proceedings of the 11th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This paper describes our German, Italian and English Speech-to-Text (STT) systems for the 2014 IWSLT TED ASR track. Our setup uses ROVER and confusion network combination from various subsystems to achieve a good overall performance. The individual subsystems are built by using different front-ends, (e.g., MVDR-MFCC or lMel), acoustic models (GMM or modular DNN) and phone sets and by training on various subsets of the training data. Decoding is performed in two stages, where the GMM systems are adapted in an unsupervised manner on the combination of the first stage outputs using VTLN, MLLR, and cMLLR. The combination setup produces a final hypothesis that has a significantly lower WER than any of the individual subsystems."
2014.iwslt-evaluation.17,The {KIT} translation systems for {IWSLT} 2014,2014,-1,-1,8,1,36550,isabel slawik,Proceedings of the 11th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"In this paper, we present the KIT systems participating in the TED translation tasks of the IWSLT 2014 machine translation evaluation. We submitted phrase-based translation systems for all three official directions, namely EnglishâGerman, GermanâEnglish, and EnglishâFrench, as well as for the optional directions EnglishâChinese and EnglishâArabic. For the official directions we built systems both for the machine translation as well as the spoken language translation track. This year we improved our systems{'} performance over last year through n-best list rescoring using neural network-based translation and language models and novel preordering rules based on tree information of multiple syntactic levels. Furthermore, we could successfully apply a novel phrase extraction algorithm and transliteration of unknown words for Arabic. We also submitted a contrastive system for GermanâEnglish built with stemmed German adjectives. For the SLT tracks, we used a monolingual translation system to translate the lowercased ASR hypotheses with all punctuation stripped to truecased, punctuated output as a preprocessing step to our usual translation system."
2014.amta-researchers.17,Combining techniques from different {NN}-based language models for machine translation,2014,23,1,4,1,5714,jan niehues,Proceedings of the 11th Conference of the Association for Machine Translation in the Americas: MT Researchers Track,0,"This paper presents two improvements of language models based on Restricted Boltzmann Machine (RBM) for large machine translation tasks. In contrast to other continuous space approach, RBM based models can easily be integrated into the decoder and are able to directly learn a hidden representation of the n-gram. Previous work on RBM-based language models do not use a shared word representation and therefore, they might suffer of a lack of generalization for larger contexts. Moreover, since the training step is very time consuming, they are only used for quite small copora. In this work we add a shared word representation for the RBM-based language model by factorizing the weight matrix. In addition, we propose an efficient and tailored sampling algorithm that allows us to drastically speed up the training process. Experiments are carried out on two German to English translation tasks and the results show that the training time could be reduced by a factor of 10 without any drop in performance. Furthermore, the RBM-based model can also be trained on large size corpora."
W13-3204,Letter N-Gram-based Input Encoding for Continuous Space Language Models,2013,41,15,3,0,40882,henning sperr,Proceedings of the Workshop on Continuous Vector Space Models and their Compositionality,0,"We present a letter-based encoding for words in continuous space language models. We represent the words completely by letter n-grams instead of using the word index. This way, similar words will automatically have a similar representation. With this we hope to better generalize to unknown or rare words and to also capture morphological information. We show their influence in the task of machine translation using continuous space language models based on restricted Boltzmann machines. We evaluate the translation quality as well as the training time on a German-to-English translation task of TED and university lectures as well as on the news translation task translating from English to German. Using our new approach a gain in BLEU score by up to 0.4 points can be achieved."
W13-2210,The {K}arlsruhe {I}nstitute of {T}echnology Translation Systems for the {WMT} 2013,2013,14,5,7,1,2962,eunah cho,Proceedings of the Eighth Workshop on Statistical Machine Translation,0,"This paper describes the phrase-based SMT systems developed for our participation in the WMT13 Shared Translation Task. Translations for English$German and English$French were generated using a phrase-based translation system which is extended by additional models such as bilingual, fine-grained part-ofspeech (POS) and automatic cluster language models and discriminative word lexica (DWL). In addition, we combined reordering models on different sentence"
W13-2223,Joint {WMT} 2013 Submission of the {QUAERO} Project,2013,34,4,10,0.409913,27027,stephan peitz,Proceedings of the Eighth Workshop on Statistical Machine Translation,0,"This paper describes the joint submission of the QUAERO project for the German!English translation task of the ACL 2013 Eighth Workshop on Statistical Machine Translation (WMT 2013). The submission was a system combination of the output of four different translation systems provided by RWTH Aachen University, Karlsruhe Institute of Technology (KIT), LIMSI-CNRS and SYSTRAN Software, Inc. The translations were joined using the RWTHxe2x80x99s system combination approach. Experimental results show improvements of up to 1.2 points in BLEU and 1.2 points in TER compared to the best single translation."
W13-2264,An {MT} Error-Driven Discriminative Word Lexicon using Sentence Structure Features,2013,13,10,2,1,5714,jan niehues,Proceedings of the Eighth Workshop on Statistical Machine Translation,0,"The Discriminative Word Lexicon (DWL) is a maximum-entropy model that predicts the target word probability given the source sentence words. We present two ways to extend a DWL to improve its ability to model the word translation probability in a phrase-based machine translation (PBMT) system. While DWLs are able to model the global source information, they ignore the structure of the source and target sentence. We propose to include this structure by modeling the source sentence as a bag-of-n-grams and features depending on the surrounding target words. Furthermore, as the standard DWL does not get any feedback from the MT system, we change the DWL training process to explicitly focus on addressing MT errors."
W13-0805,Combining Word Reordering Methods on different Linguistic Abstraction Levels for Statistical Machine Translation,2013,21,20,3,1,36851,teresa herrmann,"Proceedings of the Seventh Workshop on Syntax, Semantics and Structure in Statistical Translation",0,"We describe a novel approach to combining lexicalized, POS-based and syntactic treebased word reordering in a phrase-based machine translation system. Our results show that each of the presented reordering methods leads to improved translation quality on its own. The strengths however can be combined to achieve further improvements. We present experiments on German-English and GermanFrench translation. We report improvements of 0.7 BLEU points by adding tree-based and lexicalized reordering. Up to 1.1 BLEU points can be gained by POS and tree-based reordering over a baseline with lexicalized reordering. A human analysis, comparing subjective translation quality as well as a detailed error analysis show the impact of our presented tree-based rules in terms of improved sentence quality and reduction of errors related to missing verbs and verb positions."
N13-1096,Measuring the Structural Importance through Rhetorical Structure Index,2013,11,1,2,0,3157,narine kokhlikyan,Proceedings of the 2013 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"In this paper, we propose a novel Rhetorical Structure Index (RSI) to measure the structural importance of a word or a phrase. Unlike TF-IDF and other content-driven measurements, RSI identifies words or phrases that are structural cues in an unstructured document. We show structurally motivated features with high RSI values are more useful than content-driven features for applications such as segmenting unstructured lecture transcripts into meaningful segments. Experiments show that using RSI significantly improves the segmentation accuracy compared to TF-IDF, a traditional content-based feature weighting scheme."
2013.iwslt-papers.6,The 2013 {KIT} Quaero speech-to-text system for {F}rench,2013,-1,-1,5,0,40356,joshua winebarger,Proceedings of the 10th International Workshop on Spoken Language Translation: Papers,0,"This paper describes our Speech-to-Text (STT) system for French, which was developed as part of our efforts in the Quaero program for the 2013 evaluation. Our STT system consists of six subsystems which were created by combining multiple complementary sources of pronunciation modeling including graphemes with various feature front-ends based on deep neural networks and tonal features. Both speaker-independent and speaker adaptively trained versions of the systems were built. The resulting systems were then combined via confusion network combination and crossadaptation. Through progressive advances and system combination we reach a word error rate (WER) of 16.5{\%} on the 2012 Quaero evaluation data."
2013.iwslt-papers.8,Incremental unsupervised training for university lecture recognition,2013,-1,-1,4,1,1582,michael heck,Proceedings of the 10th International Workshop on Spoken Language Translation: Papers,0,"In this paper we describe our work on unsupervised adaptation of the acoustic model of our simultaneous lecture translation system. We trained a speaker independent acoustic model, with which we produce automatic transcriptions of new lectures in order to improve the system for a specific lecturer. We compare our results against a model that was trained in a supervised way on an exact manual transcription. We examine four different ways of processing the decoder outputs of the automatic transcription with respect to the treatment of pronunciation variants and noise words. We will show that, instead of fixating the latter informations in the transcriptions, it is of advantage to let the Viterbi algorithm during training decide which pronunciations to use and where to insert which noise words. Further, we utilize word level posterior probabilities obtained during decoding by weighting and thresholding the words of a transcription."
2013.iwslt-papers.11,Analyzing the potential of source sentence reordering in statistical machine translation,2013,-1,-1,4,1,36851,teresa herrmann,Proceedings of the 10th International Workshop on Spoken Language Translation: Papers,0,"We analyze the performance of source sentence reordering, a common reordering approach, using oracle experiments on German-English and English-German translation. First, we show that the potential of this approach is very promising. Compared to a monotone translation, the optimally reordered source sentence leads to improvements of up to 4.6 and 6.2 BLEU points, depending on the language. Furthermore, we perform a detailed evaluation of the different aspects of the approach. We analyze the impact of the restriction of the search space by reordering lattices and we can show that using more complex rule types for reordering results in better approximation of the optimally reordered source. However, a gap of about 3 to 3.8 BLEU points remains, presenting a promising perspective for research on extending the search space through better reordering rules. When evaluating the ranking of different reordering variants, the results reveal that the search for the best path in the lattice performs very well for German-English translation. For English-German translation there is potential for an improvement of up to 1.4 BLEU points through a better ranking of the different reordering possibilities in the reordering lattice."
2013.iwslt-papers.12,{CRF}-based disfluency detection using semantic features for {G}erman to {E}nglish spoken language translation,2013,-1,-1,3,1,2962,eunah cho,Proceedings of the 10th International Workshop on Spoken Language Translation: Papers,0,"Disfluencies in speech pose severe difficulties in machine translation of spontaneous speech. This paper presents our conditional random field (CRF)-based speech disfluency detection system developed on German to improve spoken language translation performance. In order to detect speech disfluencies considering syntactics and semantics of speech utterances, we carried out a CRF-based approach using information learned from the word representation and the phrase table used for machine translation. The word representation is gained using recurrent neural networks and projected words are clustered using the k-means algorithm. Using the output from the model trained with the word representations and phrase table information, we achieve an improvement of 1.96 BLEU points on the lecture test set. By keeping or removing humanannotated disfluencies, we show an upper bound and lower bound of translation quality. In an oracle experiment we gain 3.16 BLEU points of improvement on the lecture test set, compared to the same set with all disfluencies."
2013.iwslt-papers.13,Maximum entropy language modeling for {R}ussian {ASR},2013,-1,-1,5,0,41934,evgeniy shin,Proceedings of the 10th International Workshop on Spoken Language Translation: Papers,0,"Russian is a challenging language for automatic speech recognition systems due to its rich morphology. This rich morphology stems from Russian{'}s highly inflectional nature and the frequent use of preand suffixes. Also, Russian has a very free word order, changes in which are used to reflect connotations of the sentences. Dealing with these phenomena is rather difficult for traditional n-gram models. We therefore investigate in this paper the use of a maximum entropy language model for Russian whose features are specifically designed to deal with the inflections in Russian, as well as the loose word order. We combine this with a subword based language model in order to alleviate the problem of large vocabulary sizes necessary for dealing with highly inflecting languages. Applying the maximum entropy language model during re-scoring improves the word error rate of our recognition system by 1.2{\%} absolute, while the use of the sub-word based language model reduces the vocabulary size from 120k to 40k and the OOV rate from 4.8{\%} to 2.1{\%}."
2013.iwslt-evaluation.13,The 2013 {KIT} {IWSLT} speech-to-text systems for {G}erman and {E}nglish,2013,-1,-1,12,1,34647,kevin kilgour,Proceedings of the 10th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This paper describes our English Speech-to-Text (STT) systems for the 2013 IWSLT TED ASR track. The systems consist of multiple subsystems that are combinations of different front-ends, e.g. MVDR-MFCC based and lMel based ones, GMM and NN acoustic models and different phone sets. The outputs of the subsystems are combined via confusion network combination. Decoding is done in two stages, where the systems of the second stage are adapted in an unsupervised manner on the combination of the first stage outputs using VTLN, MLLR, and cMLLR."
2013.iwslt-evaluation.16,{EU}-{BRIDGE} {MT}: text translation of talks in the {EU}-{BRIDGE} project,2013,52,8,12,0.819672,3519,markus freitag,Proceedings of the 10th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"EU-BRIDGE1 is a European research project which is aimed at developing innovative speech translation technology. This paper describes one of the collaborative efforts within EUBRIDGE to further advance the state of the art in machine translation between two European language pairs, EnglishâFrench and GermanâEnglish. Four research institutions involved in the EU-BRIDGE project combined their individual machine translation systems and participated with a joint setup in the machine translation track of the evaluation campaign at the 2013 International Workshop on Spoken Language Translation (IWSLT). We present the methods and techniques to achieve high translation quality for text translation of talks which are applied at RWTH Aachen University, the University of Edinburgh, Karlsruhe Institute of Technology, and Fondazione Bruno Kessler. We then show how we have been able to considerably boost translation performance (as measured in terms of the metrics BLEU and TER) by means of system combination. The joint setups yield empirical gains of up to 1.4 points in BLEU and 2.8 points in TER on the IWSLT test sets compared to the best single systems."
2013.iwslt-evaluation.24,The {KIT} translation systems for {IWSLT} 2013,2013,-1,-1,8,0,41933,thanle ha,Proceedings of the 10th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"In this paper, we present the KIT systems participating in all three official directions, namely EnglishâGerman, GermanâEnglish, and EnglishâFrench, in translation tasks of the IWSLT 2013 machine translation evaluation. Additionally, we present the results for our submissions to the optional directions EnglishâChinese and EnglishâArabic. We used phrase-based translation systems to generate the translations. This year, we focused on adapting the systems towards ASR input. Furthermore, we investigated different reordering models as well as an extended discriminative word lexicon. Finally, we added a data selection approach for domain adaptation."
W12-3140,Joint {WMT} 2012 Submission of the {QUAERO} Project,2012,37,5,7,0.833333,3519,markus freitag,Proceedings of the Seventh Workshop on Statistical Machine Translation,0,"This paper describes the joint QUAERO submission to the WMT 2012 machine translation evaluation. Four groups (RWTH Aachen University, Karlsruhe Institute of Technology, LIMSI-CNRS, and SYSTRAN) of the QUAERO project submitted a joint translation for the WMT Germanxe2x86x92English task. Each group translated the data sets with their own systems and finally the RWTH system combination combined these translations in our final submission. Experimental results show improvements of up to 1.7 points in Bleu and 3.4 points in Ter compared to the best single system."
W12-3144,The Karlsruhe Institute of Technology Translation Systems for the {WMT} 2012,2012,17,7,6,1,5714,jan niehues,Proceedings of the Seventh Workshop on Statistical Machine Translation,0,"This paper describes the phrase-based SMT systems developed for our participation in the WMT12 Shared Translation Task. Translations for Englishxe2x86x94German and Englishxe2x86x94French were generated using a phrase-based translation system which is extended by additional models such as bilingual, fine-grained part-of-speech (POS) and automatic cluster language models and discriminative word lexica. In addition, we explicitly handle out-of-vocabulary (OOV) words in German, if we have translations for other morphological forms of the same stem. Furthermore, we extended the POS-based reordering approach to also use information from syntactic trees."
stuker-etal-2012-kit,The {KIT} Lecture Corpus for Speech Translation,2012,8,11,6,1,5716,sebastian stuker,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"Academic lectures offer valuable content, but often do not reach their full potential audience due to the language barrier. Human translations of lectures are too expensive to be widely used. Speech translation technology can be an affordable alternative in this case. State-of-the-art speech translation systems utilize statistical models that need to be trained on large amounts of in-domain data. In order to support the KIT lecture translation project in its effort to introduce speech translation technology in KIT's lecture halls, we have collected a corpus of German lectures at KIT. In this paper we describe how we recorded the lectures and how we annotated them. We further give detailed statistics on the types of lectures in the corpus and its size. We collected the corpus with the purpose in mind that it should not just be suited for training a spoken language translation system the traditional way, but should also enable us to research techniques that enable the translation system to automatically and autonomously adapt itself to the varying topics and speakers of lectures"
2012.iwslt-papers.3,Continuous space language models using restricted Boltzmann machines,2012,20,20,2,1,5714,jan niehues,Proceedings of the 9th International Workshop on Spoken Language Translation: Papers,0,"We present a novel approach for continuous space language models in statistical machine translation by using Restricted Boltzmann Machines (RBMs). The probability of an n-gram is calculated by the free energy of the RBM instead of a feedforward neural net. Therefore, the calculation is much faster and can be integrated into the translation process instead of using the language model only in a re-ranking step. Furthermore, it is straightforward to introduce additional word factors into the language model. We observed a faster convergence in training if we include automatically generated word classes as an additional word factor. We evaluated the RBM-based language model on the German to English and English to French translation task of TED lectures. Instead of replacing the conventional n-gram-based language model, we trained the RBM-based language model on the more important but smaller in-domain data and combined them in a log-linear way. With this approach we could show improvements of about half a BLEU point on the translation task."
2012.iwslt-papers.10,Evaluation of interactive user corrections for lecture transcription,2012,19,7,4,0,43823,heinrich kolkhorst,Proceedings of the 9th International Workshop on Spoken Language Translation: Papers,0,"In this work, we present and evaluate the usage of an interactive web interface for browsing and correcting lecture transcripts. An experiment performed with potential users without transcription experience provides us with a set of example corrections. On German lecture data, user corrections greatly improve the comprehensibility of the transcripts, yet only reduce the WER to 22{\%}. The precision of user edits is relatively low at 77{\%} and errors in inflection, case and compounds were rarely corrected. Nevertheless, characteristic lecture data errors, such as highly specific terms, were typically corrected, providing valuable additional information."
2012.iwslt-papers.15,Segmentation and punctuation prediction in speech language translation using a monolingual translation system,2012,16,24,3,1,2962,eunah cho,Proceedings of the 9th International Workshop on Spoken Language Translation: Papers,0,"In spoken language translation (SLT), finding proper segmentation and reconstructing punctuation marks are not only significant but also challenging tasks. In this paper we present our recent work on speech translation quality analysis for German-English by improving sentence segmentation and punctuation. From oracle experiments, we show an upper bound of translation quality if we had human-generated segmentation and punctuation on the output stream of speech recognition systems. In our oracle experiments we gain 1.78 BLEU points of improvements on the lecture test set. We build a monolingual translation system from German to German implementing segmentation and punctuation prediction as a machine translation task. Using the monolingual translation system we get an improvement of 1.53 BLEU points on the lecture test set, which is a comparable performance against the upper bound drawn by the oracle experiments."
2012.iwslt-evaluation.10,The 2012 {KIT} and {KIT}-{NAIST} {E}nglish {ASR} systems for the {IWSLT} evaluation,2012,-1,-1,12,1,28037,christian saam,Proceedings of the 9th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This paper describes our English Speech-to-Text (STT) systems for the 2012 IWSLT TED ASR track evaluation. The systems consist of 10 subsystems that are combinations of different front-ends, e.g. MVDR based and MFCC based ones, and two different phone sets. The outputs of the subsystems are combined via confusion network combination. Decoding is done in two stages, where the systems of the second stage are adapted in an unsupervised manner on the combination of the first stage outputs using VTLN, MLLR, and cM-LLR."
2012.iwslt-evaluation.11,The {KIT}-{NAIST} (contrastive) {E}nglish {ASR} system for {IWSLT} 2012,2012,-1,-1,12,1,1582,michael heck,Proceedings of the 9th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This paper describes the KIT-NAIST (Contrastive) English speech recognition system for the IWSLT 2012 Evaluation Campaign. In particular, we participated in the ASR track of the IWSLT TED task. The system was developed by Karlsruhe Institute of Technology (KIT) and Nara Institute of Science and Technology (NAIST) teams in collaboration within the interACT project. We employ single system decoding with fully continuous and semi-continuous models, as well as a three-stage, multipass system combination framework built with the Janus Recognition Toolkit. On the IWSLT 2010 test set our single system introduced in this work achieves a WER of 17.6{\%}, and our final combination achieves a WER of 14.4{\%}."
2012.amta-papers.19,Detailed Analysis of Different Strategies for Phrase Table Adaptation in {SMT},2012,-1,-1,2,1,5714,jan niehues,Proceedings of the 10th Conference of the Association for Machine Translation in the Americas: Research Papers,0,"This paper gives a detailed analysis of different approaches to adapt a statistical machine translation system towards a target domain using small amounts of parallel in-domain data. Therefore, we investigate the differences between the approaches addressing adaptation on the two main steps of building a translation model: The candidate selection and the phrase scoring. For the latter step we characterized the differences by four key aspects. We performed experiments on two different tasks of speech translation and analyzed the influence of the different aspects on the overall translation quality. On both tasks we could show significant improvements by using the presented adaptation techniques."
W11-2124,Wider Context by Using Bilingual Language Models in Machine Translation,2011,18,60,4,1,5714,jan niehues,Proceedings of the Sixth Workshop on Statistical Machine Translation,0,"In past Evaluations for Machine Translation of European Languages, it could be shown that the translation performance of SMT systems can be increased by integrating a bilingual language model into a phrase-based SMT system. In the bilingual language model, target words with their aligned source words build the tokens of an n-gram based language model. We analyzed the effect of bilingual language models and show where they could help to better model the translation process. We could show improvements of translation quality on German-to-English and Arabic-to-English. In addition, for the Arabic-to-English task, training an extra bilingual language model on the POS tags instead of the surface word forms led to further improvements."
W11-2142,Joint {WMT} Submission of the {QUAERO} Project,2011,25,1,8,0.833333,3519,markus freitag,Proceedings of the Sixth Workshop on Statistical Machine Translation,0,"This paper describes the joint QUAERO submission to the WMT 2011 machine translation evaluation. Four groups (RWTH Aachen University, Karlsruhe Institute of Technology, LIMSI-CNRS, and SYSTRAN) of the QUAERO project submitted a joint translation for the WMT Germanxe2x86x92English task. Each group translated the data sets with their own systems. Then RWTH system combination combines these translations to a better one. In this paper, we describe the single systems of each group. Before we present the results of the system combination, we give a short description of the RWTH Aachen system combination approach."
W11-2145,The Karlsruhe Institute of Technology Translation Systems for the {WMT} 2011,2011,13,11,4,1,36851,teresa herrmann,Proceedings of the Sixth Workshop on Statistical Machine Translation,0,"This paper describes the phrase-based SMT systems developed for our participation in the WMT11 Shared Translation Task. Translations for Englishxe2x86x94German and Englishxe2x86x94French were generated using a phrase-based translation system which is extended by additional models such as bilingual and fine-grained POS language models, POS-based reordering, lattice phrase extraction and discriminative word alignment. Furthermore, we present a special filtering method for the English-French Giga corpus and the phrase scoring step in the training is parallelized."
I11-1053,{T}ri{S}: A Statistical Sentence Simplifier with Log-linear Models and Margin-based Discriminative Training,2011,36,9,4,0.595238,9067,nguyen bach,Proceedings of 5th International Joint Conference on Natural Language Processing,0,"We propose a statistical sentence simplification system with log-linear models. In contrast to state-of-the-art methods that drive sentence simplification process by hand-written linguistic rules, our method used a margin-based discriminative learning algorithm operates on a feature set. The feature set is defined on statistics of surface form as well as syntactic and dependency structures of the sentences. A stack decoding algorithm is used which allows us to efficiently generate and search simplification hypotheses. Experimental results show that the simplified text produced by the proposed system reduces 1.7 Flesch-Kincaid grade level when compared with the original text. We will show that a comparison of a state-ofthe-art rule-based system (Heilman and Smith, 2010) to the proposed system demonstrates an improvement of 0.2, 0.6, and 4.5 points in ROUGE-2, ROUGE-4, andAveF 10 , respectively."
2011.mtsummit-papers.8,Unsupervised Vocabulary Selection for Domain-Independent Simultaneous Lecture Translation,2011,13,2,3,0,44896,paul maergner,Proceedings of Machine Translation Summit XIII: Papers,0,"In this work, we propose a novel method for vocabulary selection which enables simultaneous lecture translation systems to automatically adapt to the diverse topics that occur in educational and scientific lectures. Utilizing materials that are available before the lecture begins, such as lecture slides, our proposed framework iteratively searches for related documents on the World Wide Web and generates a lecturespecific vocabulary and language model based on the resulting documents. In this paper, we introduce a novel method for vocabulary selection where we rank vocabulary that occurs in the collected documents based on a relevance score which is calculated using a combination of word features. Vocabulary selection is a critical component for topic adaptation that has typically been overlooked in prior works. On the interACT German-English simultaneous lecture translation system our proposed approach significantly improved vocabulary coverage, reducing the out-of-vocabulary rate on average by 60% and up to 84%, compared to a lectureindependent baseline. Furthermore, our approach reduced the word error rate by up to 25.3% (on average 13.2% across all lectures), compared to a lecture-independent baseline."
2011.iwslt-papers.2,The 2011 {KIT} {QUAERO} speech-to-text system for {S}panish,2011,-1,-1,5,1,34647,kevin kilgour,Proceedings of the 8th International Workshop on Spoken Language Translation: Papers,0,"This paper describes our current Spanish speech-to-text (STT) system with which we participated in the 2011 Quaero STT evaluation that is being developed within the Quaero program. The system consists of 4 separate subsystems, as well as the standard MFCC and MVDR phoneme based subsystems we included a both a phoneme and grapheme based bottleneck subsystem. We carefully evaluate the performance of each subsystem. After including several new techniques we were able to reduce the WER by over 30{\%} from 20.79{\%} to 14.53{\%}."
2011.iwslt-papers.4,Unsupervised vocabulary selection for simultaneous lecture translation,2011,13,2,4,0,44896,paul maergner,Proceedings of the 8th International Workshop on Spoken Language Translation: Papers,0,"In this work, we propose a novel method for vocabulary selection which enables simultaneous speech recognition systems for lectures to automatically adapt to the diverse topics that occur in educational and scientific lectures. Utilizing materials that are available before the lecture begins, such as lecture slides, our proposed framework iteratively searches for related documents on the World Wide Web and generates a lecture-specific vocabulary and language model based on the resulting documents. In this paper, we introduce a novel method for vocabulary selection where we rank vocabulary that occurs in the collected documents based on a relevance score which is calculated using a combination of word features. Vocabulary selection is a critical component for topic adaptation that has typically been overlooked in prior works. On the interACT German-English simultaneous lecture translation system our proposed approach significantly improved vocabulary coverage, reducing the out-of-vocabulary rate on average by 57.0{\%} and up to 84.9{\%}, compared to a lecture-independent baseline. Furthermore, our approach reduced the word error rate by up to 25.3{\%} (on average 13.2{\%} across all lectures), compared to a lectureindependent baseline."
2011.iwslt-papers.6,Using {W}ikipedia to translate domain-specific terms in {SMT},2011,22,12,2,1,5714,jan niehues,Proceedings of the 8th International Workshop on Spoken Language Translation: Papers,0,"When building a university lecture translation system, one important step is to adapt it to the target domain. One problem in this adaptation task is to acquire translations for domain specific terms. In this approach we tried to get these translations from Wikipedia, which provides articles on very specific topics in many different languages. To extract translations for the domain specific terms, we used the interlanguage links of Wikipedia . We analyzed different methods to integrate this corpus into our system and explored methods to disambiguate between different translations by using the text of the articles. In addition, we developed methods to handle different morphological forms of the specific terms in morphologically rich input languages like German. The results show that the number of out-of-vocabulary (OOV) words could be reduced by 50{\%} on computer science lectures and the translation quality could be improved by more than 1 BLEU point."
2011.iwslt-evaluation.9,The {KIT} {E}nglish-{F}rench translation systems for {IWSLT} 2011,2011,9,21,5,1,14105,mohammed mediani,Proceedings of the 8th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This paper presents the KIT system participating in the EnglishâFrench TALK Translation tasks in the framework of the IWSLT 2011 machine translation evaluation. Our system is a phrase-based translation system using POS-based reordering extended with many additional features. First of all, a special preprocessing is devoted to the Giga corpus in order to minimize the effect of the great amount of noise it contains. In addition, the system gives more importance to the in-domain data by adapting the translation and the language models as well as by using a wordcluster language model. Furthermore, the system is extended by a bilingual language model and a discriminative word lexicon. The automatic speech transcription input usually has no or wrong punctuation marks, therefore these marks were especially removed from the source training data for the SLT system training."
2011.iwslt-evaluation.12,The 2011 {KIT} {E}nglish {ASR} system for the {IWSLT} evaluation,2011,-1,-1,4,1,5716,sebastian stuker,Proceedings of the 8th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This paper describes our English Speech-to-Text (STT) system for the 2011 IWSLT ASR track. The system consists of 2 subsystems with different front-ends{---}one MVDR based, one MFCC based{---}which are combined using confusion network combination to provide a base for a second pass speaker adapted MVDR system. We demonstrate that this set-up produces competitive results on the IWSLT 2010 dev and test sets."
2011.iwslt-evaluation.15,Advances on spoken language translation in the Quaero program,2011,25,2,12,0,43221,karim boudahmane,Proceedings of the 8th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"The Quaero program is an international project promoting research and industrial innovation on technologies for automatic analysis and classification of multimedia and multilingual documents. Within the program framework, research organizations and industrial partners collaborate to develop prototypes of innovating applications and services for access and usage of multimedia data. One of the topics addressed is the translation of spoken language. Each year, a project-internal evaluation is conducted by DGA to monitor the technological advances. This work describes the design and results of the 2011 evaluation campaign. The participating partners were RWTH, KIT, LIMSI and SYSTRAN. Their approaches are compared on both ASR output and reference transcripts of speech data for the translation between French and German. The results show that the developed techniques further the state of the art and improve translation quality."
W10-1719,The Karlsruhe Institute for Technology Translation System for the {ACL}-{WMT} 2010,2010,9,7,4,1,5714,jan niehues,Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and {M}etrics{MATR},0,This paper describes our phrase-based Statistical Machine Translation (SMT) system for the WMT10 Translation Task. We submitted translations for the German to English and English to German translation tasks. Compared to state-of-the-art phrase-based systems we preformed additional preprocessing and used a discriminative word alignment approach. The word reordering was modeled using POS information and we extended the translation model with additional features.
W10-0729,Tools for Collecting Speech Corpora via {M}echanical-{T}urk,2010,4,34,4,1,23757,ian lane,Proceedings of the {NAACL} {HLT} 2010 Workshop on Creating Speech and Language Data with {A}mazon{'}s Mechanical Turk,0,"To rapidly port speech applications to new languages one of the most difficult tasks is the initial collection of sufficient speech corpora. State-of-the-art automatic speech recognition systems are typical trained on hundreds of hours of speech data. While pre-existing corpora do exist for major languages, a sufficient amount of quality speech data is not available for most world languages. While previous works have focused on the collection of translations and the transcription of audio via Mechanical-Turk mechanisms, in this paper we introduce two tools which enable the collection of speech data remotely. We then compare the quality of audio collected from paid part-time staff and unsupervised volunteers, and determine that basic user training is critical to obtain usable data."
2010.iwslt-papers.13,Real-time spoken language identification and recognition for speech-to-speech translation,2010,0,1,3,0,46612,daniel lim,Proceedings of the 7th International Workshop on Spoken Language Translation: Papers,0,None
2010.iwslt-evaluation.11,The {KIT} translation system for {IWSLT} 2010,2010,25,14,6,1,5714,jan niehues,Proceedings of the 7th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"In this paper, we present the KIT systems participating in the TED translation tasks of the IWSLT 2015 machine translation evaluation. We submitted phrase-based translation systems for three directions, namely English!German, German!English, and English!Vietnamese. For the official directions (English!German and German!English), we built systems both for the machine translation (MT) as well as the spoken language translation (SLT) tracks. This year we improved our systemsxe2x80x99 performance over last year through n-best list rescoring using neural networkbased translation and language models and novel discriminative models based on different source-side features and classification methods. For the SLT tracks, we used a monolingual translation system to translate the lowercased ASR hypotheses with all punctuation stripped to truecased, punctuated output as a preprocessing step to our usual translation system. In addition to punctuation insertion, we also trained that system for sentence boundary insertion since the SLTxe2x80x99s data this year come with no sentence boundary."
2010.eamt-1.29,Domain Adaptation in Statistical Machine Translation using Factored Translation Models,2010,17,22,2,1,5714,jan niehues,Proceedings of the 14th Annual conference of the European Association for Machine Translation,0,"In recent years the performance of SMT increased in domains with enough training data. But under real-world conditions, it is often not possible to collect enough parallel data. We propose an approach to adapt an SMT system using small amounts of parallel in-domain data by introducing the corpus identifier (corpus id) as an additional target factor. Then we added features to model the generation of the tags and features to judge a sequence of tags. Using this approach we could improve the translation performance in two domains by up to 1 BLEU point when translating from German to English."
W09-0413,"The {U}niversit{\\\a}t {K}arlsruhe Translation System for the {EACL}-{WMT} 2009""",2009,6,12,4,1,5714,jan niehues,Proceedings of the Fourth Workshop on Statistical Machine Translation,0,In this paper we describe the statistical machine translation system of the Universitat Karlsruhe developed for the translation task of the Fourth Workshop on Statistical Machine Translation. The state-of-the-art phrase-based SMT system is augmented with alternative word reordering and alignment mechanisms as well as optional phrase table modifications. We participate in the constrained condition of German-English and English-German as well as in the constrained condition of French-English and English-French.
N09-2038,Incremental Adaptation of Speech-to-Speech Translation,2009,9,11,8,0.614035,9067,nguyen bach,"Proceedings of Human Language Technologies: The 2009 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics, Companion Volume: Short Papers",0,"In building practical two-way speech-to-speech translation systems the end user will always wish to use the system in an environment different from the original training data. As with all speech systems, it is important to allow the system to adapt to the actual usage situations. This paper investigates how a speech-to-speech translation system can adapt day-to-day from collected data on day one to improve performance on day two. The platform is the CMU Iraqi-English portable two-way speech-to-speech system as developed under the DARPA TransTac program. We show how machine translation, speech recognition and overall system performance can be improved on day 2 after adapting from day 1 in both a supervised and unsupervised way."
E09-1040,End-to-End Evaluation in Simultaneous Translation,2009,14,11,6,0,27330,olivier hamon,Proceedings of the 12th Conference of the {E}uropean Chapter of the {ACL} ({EACL} 2009),0,"This paper presents the end-to-end evaluation of an automatic simultaneous translation system, built with state-of-the-art components. It shows whether, and for which situations, such a system might be advantageous when compared to a human interpreter. Using speeches in English translated into Spanish, we present the evaluation procedure and we discuss the results both for the recognition and translation components as well as for the overall system. Even if the translation process remains the Achilles' heel of the system, the results show that the system can keep at least half of the information, becoming potentially useful for final users."
eck-etal-2008-communicating,Communicating Unknown Words in Machine Translation,2008,15,12,3,1,40353,matthias eck,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"A new approach to handle unknown words in machine translation is presented. The basic idea is to find definitions for the unknown words on the source language side and translate those definitions instead. Only monolingual resources are required, which generally offer a broader coverage than bilingual resources and are available for a large number of languages. In order to use this in a machine translation system definitions are extracted automatically from online dictionaries and encyclopedias. The translated definition is then inserted and clearly marked in the original hypothesis. This is shown to lead to significant improvements in (subjective) translation quality."
2008.iwslt-papers.5,Simultaneous {G}erman-{E}nglish lecture translation.,2008,17,12,6,1,47108,muntsin kolss,Proceedings of the 5th International Workshop on Spoken Language Translation: Papers,0,"In an increasingly globalized world, situations in which people of different native tongues have to communicate with each other become more and more frequent. In many such situations, human interpreters are prohibitively expensive or simply not available. Automatic spoken language translation (SLT), as a cost-effective solution to this dilemma, has received increased attention in recent years. For a broad number of applications, including live SLT of lectures and oral presentations, these automatic systems should ideally operate in real time and with low latency. Large and highly specialized vocabularies as well as strong variations in speaking style {--} ranging from read speech to free presentations suffering from spontaneous events {--} make simultaneous SLT of lectures a challenging task. This paper presents our progress in building a simultaneous German-English lecture translation system. We emphasize some of the challenges which are particular to this language pair and propose solutions to tackle some of the problems encountered."
N07-2006,Translation Model Pruning via Usage Statistics for Statistical Machine Translation,2007,10,13,3,1,40353,matthias eck,"Human Language Technologies 2007: The Conference of the North {A}merican Chapter of the Association for Computational Linguistics; Companion Volume, Short Papers",0,We describe a new pruning approach to remove phrase pairs from translation models of statistical machine translation systems. The approach applies the original translation system to a large amount of text and calculates usage statistics for the phrase pairs. Using these statistics the relevance of each phrase pair can be estimated. The approach is tested against a strong baseline based on previous work and shows significant improvements.
2007.mtsummit-papers.22,Estimating phrase pair relevance for translation model pruning,2007,-1,-1,3,1,40353,matthias eck,Proceedings of Machine Translation Summit XI: Papers,0,None
2007.iwslt-1.4,The {CMU} {T}rans{T}ac 2007 eyes-free two-way speech-to-speech translation system,2007,17,22,8,0.784314,9067,nguyen bach,Proceedings of the Fourth International Workshop on Spoken Language Translation,0,"The paper describes our portable two-way speech-to-speech translation system using a completely eyes-free/hands-free user interface. This system translates between the language pair English and Iraqi Arabic as well as between English and Farsi, and was built within the framework of the DARPA TransTac program. The Farsi language support was developed within a 90-day period, testing our ability to rapidly support new languages. The paper gives an overview of the system{'}s components along with the individual component objective measures and a discussion of issues relevant for the overall usage of the system. We found that usability, flexibility, and robustness serve as severe constraints on system architecture and design."
2007.iwslt-1.9,The {CMU}-{UKA} statistical machine translation systems for {IWSLT} 2007,2007,19,1,9,1,23757,ian lane,Proceedings of the Fourth International Workshop on Spoken Language Translation,0,"This paper describes the CMU-UKA statistical machine translation systems submitted to the IWSLT 2007 evaluation campaign. Systems were submitted for three language-pairs: JapaneseâEnglish, ChineseâEnglish and ArabicâEnglish. All systems were based on a common phrase-based SMT (statistical machine translation) framework but for each language-pair a specific research problem was tackled. For JapaneseâEnglish we focused on two problems: first, punctuation recovery, and second, how to incorporate topic-knowledge into the translation framework. Our ChineseâEnglish submission focused on syntax-augmented SMT and for the ArabicâEnglish task we focused on incorporating morphological-decomposition into the SMT framework. This research strategy enabled us to evaluate a wide variety of approaches which proved effective for the language pairs they were evaluated on."
2006.iwslt-evaluation.19,The {UKA}/{CMU} statistical machine translation system for {IWSLT} 2006,2006,-1,-1,9,1,40353,matthias eck,Proceedings of the Third International Workshop on Spoken Language Translation: Evaluation Campaign,0,None
2006.iwslt-evaluation.20,The {CMU}-{UKA} syntax augmented machine translation system for {IWSLT}-06,2006,12,12,4,0.714286,44639,andreas zollmann,Proceedings of the Third International Workshop on Spoken Language Translation: Evaluation Campaign,0,"We present the CMU-UKA Syntax Augmented Machine Translation System that was used in the IWSLT-06 evaluation campaign. We participated in the C-Star data track using only the Full BTEC corpus, for Chinese-English translation, focusing on transcript translation. We applied techniques that produce true-cased, punctuated translations from non-punctuated Chinese transcripts, generating translations which score higher against the Official metric than against the lower-cased, punctuation removed metric. Our results demonstrate the impact of syntax and hierarchy based models for speech transcript translation."
2006.eamt-1.12,A Flexible Online Server for Machine Translation Evaluation,2006,6,3,3,1,40353,matthias eck,Proceedings of the 11th Annual conference of the European Association for Machine Translation,0,"We present an Online Server for Machine Translation Evaluation that offers improvements over the standard usage of the typical scoring scripts. Users are able to interactively define their own test sets, experiments and pre-processing steps. Several scores are automatically calculated for submitted translations and the hypotheses and scores are organized and archived for later review. The server offers a nice web based user interface."
W05-0804,Bilingual Word Spectral Clustering for Statistical Machine Translation,2005,11,9,3,0.897436,44678,bing zhao,Proceedings of the {ACL} Workshop on Building and Using Parallel Texts,0,"In this paper, a variant of a spectral clustering algorithm is proposed for bilingual word clustering. The proposed algorithm generates the two sets of clusters for both languages efficiently with high semantic correlation within monolingual clusters, and high translation quality across the clusters between two languages. Each cluster level translation is considered as a bilingual concept, which generalizes words in bilingual clusters. This scheme improves the robustness for statistical machine translation models. Two HMM-based translation models are tested to use these bilingual clusters. Improved perplexity, word alignment accuracy, and translation quality are observed in our experiments."
W05-0836,Training and Evaluating Error Minimization Decision Rules for Statistical Machine Translation,2005,9,23,3,1,44842,ashish venugopal,Proceedings of the {ACL} Workshop on Building and Using Parallel Texts,0,"Decision rules that explicitly account for non-probabilistic evaluation metrics in machine translation typically require special training, often to estimate parameters in exponential models that govern the search space and the selection of candidate translations. While the traditional Maximum A Posteriori (MAP) decision rule can be optimized as a piecewise linear function in a greedy search of the parameter space, the Minimum Bayes Risk (MBR) decision rule is not well suited to this technique, a condition that makes past results difficult to compare. We present a novel training approach for non-tractable decision rules, allowing us to compare and evaluate these and other decision rules on a large scale translation task, taking advantage of the high dimensional parameter space available to the phrase based Pharaoh decoder. This comparison is timely, and important, as decoders evolve to represent more complex search space decisions and are evaluated against innovative evaluation metrics of translation quality."
I05-3011,Learning a Log-Linear Model with Bilingual Phrase-Pair Features for Statistical Machine Translation,2005,0,7,2,0.897436,44678,bing zhao,Proceedings of the Fourth {SIGHAN} Workshop on {C}hinese Language Processing,0,None
2005.mtsummit-papers.30,Low Cost Portability for Statistical Machine Translation based on N-gram Coverage,2005,14,29,3,1,40353,matthias eck,Proceedings of Machine Translation Summit X: Papers,0,"Statistical machine translation relies heavily on the available training data. However, in some cases, it is necessary to limit the amount of training data that can be created for or actually used by the systems. To solve that problem, we introduce a weighting scheme that tries to select more informative sentences first. This selection is based on the previously unseen n-grams the sentences contain, and it allows us to sort the sentences according to their estimated importance. After sorting, we can construct smaller training corpora, and we are able to demonstrate that systems trained on much less training data show a very competitive performance compared to baseline systems using all available training data."
2005.iwslt-1.6,The {CMU} Statistical Machine Translation System for {IWSLT}2005,2005,23,22,8,1,37937,sanjika hewavitharana,Proceedings of the Second International Workshop on Spoken Language Translation,0,"In this paper we describe the CMU statistical machine translation system used in the IWSLT 2005 evaluation campaign. This system is based on phrase-to-phrase translations extracted from a bilingual corpus. We experimented with two different phrase extraction methods; PESA on-the-fly phrase extraction and alignment free extraction method. The translation model, language model and other features were combined in a log-linear model during decoding. We present our experiments on model adaptation for new data in a different domain, as well as combining different translation hypotheses to obtain better translations. We participated in the supplied data track for manual transcriptions in the translation directions: ArabicEnglish, Chinese-English, Japanese-English and KoreanEnglish. For Chinese-English direction we also worked on ASR output of the supplied data, and with additional data in unrestricted and C-STAR tracks."
2005.iwslt-1.7,Low Cost Portability for Statistical Machine Translation based on N-gram Frequency and {TF}-{IDF},2005,15,30,3,1,40353,matthias eck,Proceedings of the Second International Workshop on Spoken Language Translation,0,Statistical machine translation relies heavily on the available training data. In some cases it is necessary to limit the amount of training data that can be created for or actually used by the systems. We introduce weighting schemes which allow us to sort sentences based on the frequency of unseen n-grams. A second approach uses TF-IDF to rank the sentences. After sorting we can select smaller training corpora and we are able to show that systems trained on much less training data achieve a very competitive performance compared to baseline systems using all available training data.
2005.eamt-1.18,Augmenting a statistical translation system with a translation memory,2005,10,8,3,1,37937,sanjika hewavitharana,Proceedings of the 10th EAMT Conference: Practical applications of machine translation,0,"In this paper, we present a translation memory (TM) based system to augment a statistical translation (SMT) system. It is used for translating sentences which have close matches in the training corpus. Given a test sentence, we first extract sentence pairs from the training corpus, whose source side is similar to the test sentence. Then, the TM system modifies the translation of the sentences by a sequence of substitution, deletion and inser- tion operations, to obtain the desired result. Statistical phrase alignment model of the SMT system is used for this purpose. The system was evaluated using a corpus of Chinese- English conversational data. For close matching sentences, the translations produced by the translation memory approach were compared with the translations of the statistical decoder."
2005.eamt-1.19,Adaptation of the translation model for statistical machine translation based on information retrieval,2005,11,146,4,0,28512,almut hildebrand,Proceedings of the 10th EAMT Conference: Practical applications of machine translation,0,In this paper we present experiments concerning translation model adaptation for statistical machine translation. We develop a method to adapt translation models using in- formation retrieval. The approach selects sentences similar to the test set to form an adapted training corpus. The method allows a better use of additionally available out-of-domain training data or finds in-domain data in a mixed corpus. The adapted translation models significantly improve the translation performance compared to competitive baseline sys- tems.
W04-3227,Phrase Pair Rescoring with Term Weighting for Statistical Machine Translation,2004,19,12,4,0.897436,44678,bing zhao,Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing,0,We propose to score phrase translation pairs for statistical machine translation using term weight based models. These models employ tf.idf to encode the weights of content and non-content words in phrase translation pairs. The translation probability is then modeled by similarity functions defined in a vector space. Two similarity functions are compared. Using these models in a statistical machine translation task shows significant improvements.
N04-3010,A {T}hai Speech Translation System for Medical Dialogs,2004,4,16,6,1,14741,tanja schultz,Demonstration Papers at {HLT}-{NAACL} 2004,0,"In this paper we present our activities towards a Thai Speech-to-Speech translation system. We investigated in the design and implementation of a prototype system. For this purpose we carried out research on bootstrapping a Thai speech recognition system, developing a translation component, and building an initial Thai synthesis system using our existing tools."
N04-1036,Improving Named Entity Translation Combining Phonetic and Semantic Similarities,2004,0,36,3,1,3692,fei huang,Proceedings of the Human Language Technology Conference of the North {A}merican Chapter of the Association for Computational Linguistics: {HLT}-{NAACL} 2004,0,None
eck-etal-2004-language,Language Model Adaptation for Statistical Machine Translation Based on Information Retrieval,2004,10,66,3,1,40353,matthias eck,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,Language modeling is an important part for both speech recognition and machine translation systems. Adaptation has been successfully applied to language models for speech recognition. In this paper we present experiments concerning language model adaptation for statistical machine translation. We develop a method to adapt language models using information retrieval methods. The adapted language models drastically reduce perplexity over a general language model and we can show that it is possible to improve the translation quality of a statistical machine translation using those adapted language models instead of a general language model.
zhang-etal-2004-interpreting,Interpreting {BLEU}/{NIST} Scores: How Much Improvement do We Need to Have a Better System?,2004,4,134,3,1,7842,ying zhang,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"Automatic evaluation metrics for Machine Translation (MT) systems, such as BLEU and the related NIST metric, are becoming increasingly important in MT. Yet, their behaviors are not fully understood. In this paper, we analyze some flaws in the BLEU/NIST metrics. With a better understanding of these problems, we can better interpret the reported BLEU/NIST scores. In addition, this paper reports a novel method of calculating the confidence intervals for BLEU/NIST scores using bootstrapping. With this method, we can determine whether two MT systems are significantly different from each other."
C04-1114,Improving Statistical Machine Translation in the Medical Domain using the Unified Medical Language system,2004,11,22,3,1,40353,matthias eck,{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics,0,Texts from the medical domain are an important task for natural language processing. This paper investigates the usefulness of a large medical database (the Unified Medical Language System) for the translation of dialogues between doctors and patients using a statistical machine translation system. We are able to show that the extraction of a large dictionary and the usage of semantic type information to generalize the training data significantly improves the translation performance.
2004.iwslt-papers.6,Toward named entity extraction and translation in spoken language translation,2004,0,1,3,1,3692,fei huang,Proceedings of the First International Workshop on Spoken Language Translation: Papers,0,None
2004.iwslt-evaluation.10,The {ISL} {EDTRL} system,2004,1,4,2,0,52490,juergen reichert,Proceedings of the First International Workshop on Spoken Language Translation: Evaluation Campaign,0,"For the translation of text and speech, statistical methods on one side and interlingua based methods on the other have been used successfully. However, the former requires programming grammars for each language, plus the design of an interlingua, while the latter requires the collection of a large parallel corpus for every language pair. To alleviate these problems, we propose an approach that combines the advantages from both worlds. The proposed approach makes use of English or enriched English as an interlingua and can cascade data-driven translation systems into and from this interlingua. We show that enriching English with linguistic information that is automatically derived i only on English data performs better than pure cascaded systems."
2004.iwslt-evaluation.11,The {ISL} statistical translation system for spoken language translation,2004,7,26,4,0.923077,29364,stephan vogel,Proceedings of the First International Workshop on Spoken Language Translation: Evaluation Campaign,0,"In this paper we describe the components of our statistical machine translation system used for the spoken language translation evaluation campaign. This system is based on phrase-to-phrase translations extracted from a bilingual corpus. A new phrase alignment approaches will be introduced, which finds the target phrase by optimizing the overall word-to-word alignment for the sentence pair under the constraint that words within the source phrase are only aligned to words within the target phrase. The system will be used for Chinese-to-English translations under the small, additional and unlimited data conditions, and for the small Japanese-to-English translation track."
W03-1502,Automatic Extraction of Named Entity Translingual Equivalence Based on Multi-Feature Cost Minimization,2003,10,73,3,1,3692,fei huang,Proceedings of the {ACL} 2003 Workshop on Multilingual and Mixed-language Named Entity Recognition,0,"Translingual equivalence refers to the relationship between expressions of the same meaning from different languages. Identifying translingual equivalence of named entities (NE) can significantly contribute to multilingual natural language processing, such as crosslingual information retrieval, crosslingual information extraction and statistical machine translation. In this paper we present an integrated approach to extract NE translingual equivalence from a parallel Chinese-English corpus.Starting from a bilingual corpus where NEs are automatically tagged for each language, NE pairs are aligned in order to minimize the overall multi-feature alignment cost. An NE transliteration model is presented and iteratively trained using named entity pairs extracted from a bilingual dictionary. The transliteration cost, combined with the named entity tagging cost and word-based translation cost, constitute the multi-feature alignment cost. These features are derived from several information sources using unsupervised and partly supervised methods. A greedy search algorithm is applied to minimize the alignment cost. Experiments show that the proposed approach extracts NE translingual equivalence with 81% F-score and improves the translation score from 7.68 to 7.74."
W03-0315,Efficient Optimization for Bilingual Sentence Alignment Based on Linear Regression,2003,11,6,4,0.882353,44678,bing zhao,Proceedings of the {HLT}-{NAACL} 2003 Workshop on Building and Using Parallel Texts: Data Driven Machine Translation and Beyond,0,This paper presents a study on optimizing sentence pair alignment scores of a bilingual sentence alignment module. Five candidate scores based on perplexity and sentence length are introduced and tested. Then a linear regression model based on those candidates is proposed and trained to predict sentence pairs' alignment quality scores solicited from human subjects. Experiments are carried out on data automatically collected from Internet. The correlation between the scores generated by the linear regression model and the scores from human subjects is in the range of the inter-subject agreement score correlations. Pearson's correlation ranges from 0.53 up to 0.72 in our experiments.
P03-1041,Effective Phrase Translation Extraction from Alignment Models,2003,12,66,3,1,44842,ashish venugopal,Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,1,"Phrase level translation models are effective in improving translation quality by addressing the problem of local re-ordering across language boundaries. Methods that attempt to fundamentally modify the traditional IBM translation model to incorporate phrases typically do so at a prohibitive computational cost. We present a technique that begins with improved IBM models to create phrase level knowledge sources that effectively represent local as well as global phrasal context. Our method is robust to noisy alignments at both the sentence and corpus level, delivering high quality phrase level translation pairs that contribute to significant improvements in translation quality (as measured by the BLEU metric) over word based lexica as well as a competing alignment based method."
N03-4015,{S}peechalator: Two-Way Speech-to-Speech Translation in Your Hand,2003,2,20,1,1,5073,alex waibel,Companion Volume of the Proceedings of {HLT}-{NAACL} 2003 - Demonstrations,0,"This demonstration involves two-way automatic speech-to-speech translation on a consumer off-the-shelf PDA. This work was done as part of the DARPA-funded Babylon project, investigating better speech-to-speech translation systems for communication in the field. The development of the Speechalator software-based translation system required addressing a number of hard issues, including a new language for the team (Egyptian Arabic), close integration on a small device, computational efficiency on a limited platform, and scalable coverage for the domain."
2003.mtsummit-papers.53,The {CMU} statistical machine translation system,2003,13,114,7,0.923077,29364,stephan vogel,Proceedings of Machine Translation Summit IX: Papers,0,In this paper we describe the components of our statistical machine translation system. This system combines phrase-to-phrase translations extracted from a bilingual corpus using different alignment approaches. Special methods to extract and align named entities are used. We show how a manual lexicon can be incorporated into the statistical system in an optimized way. Experiments on Chinese-to-English and Arabic-to-English translation tasks are presented.
W02-0714,Improvements in Non-Verbal Cue Identification Using Multilingual Phone Strings,2002,5,6,5,1,14741,tanja schultz,Proceedings of the {ACL}-02 Workshop on Speech-to-Speech Translation: Algorithms and Systems,0,"Today's state-of-the-art front-ends for multilingual speech-to-speech translation systems apply monolingual speech recognizers trained for a single language and/or accent. The monolingual speech engine is usually adaptable to an unknown speaker over time using unsupervised training methods; however, if the speaker was seen during training, their specialized acoustic model will be applied, since it achieves better performance. In order to make full use of specialized acoustic models in this proposed scenario, it is necessary to automatically identify the speaker with high accuracy. Furthermore, monolingual speech recognizers currently rely on the fact that language and/or accent will be selected beforehand by the user. This requires the user's cooperation and an interface which easily allows for such selection. Both requirements are awkward and error-prone, especially when translation services are provided for many languages using small devices like PDAs or telephones. For these scenarios, front-ends are desired which automatically identify the spoken language or accent. We believe that the automatic identification of an utterance's non-verbal cues, such as language, accent and speaker, are necessary to the successful deployment of speech-to-speech translation systems."
H01-1001,Activity detection for information access to oral communication,2001,15,6,2,1,53920,klaus ries,Proceedings of the First International Conference on Human Language Technology Research,0,"Oral communication is ubiquitous and carries important information yet it is also time consuming to document. Given the development of storage media and networks one could just record and store a conversation for documentation. The question is, however, how an interesting information piece would be found in a large database. Traditional information retrieval techniques use a histogram of keywords as the document representation but oral communication may offer additional indices such as the time and place of the rejoinder and the attendance. An alternative index could be the activity such as discussing, planning, informing, story-telling, etc. This paper addresses the problem of the automatic detection of those activities in meeting situation and everyday rejoinders. Several extensions of this basic idea are being discussed and/or evaluated: Similar to activities one can define subsets of larger database and detect those automatically which is shown on a large database of TV shows. Emotions and other indices such as the dominance distribution of speakers might be available on the surface and could be used directly. Despite the small size of the databases used some results about the effectiveness of these indices can be obtained."
H01-1003,Advances in meeting recognition,2001,9,21,1,1,5073,alex waibel,Proceedings of the First International Conference on Human Language Technology Research,0,"Speech recognition has advanced considerably, but has been limited almost entirely either to situations in which close speaking microphones are natural and acceptable (telephone, dictation, command&control, etc.) or in which high-quality recordings are ensured. Furthermore, most recognition applications involve controlled recording environments, in which the user turns the recognition event on and off and speaks cooperatively for the purpose of being recognized."
H01-1007,Architecture and Design Considerations in {NESPOLE}!: a Speech Translation System for {E}-commerce Applications,2001,3,30,3,0.795455,13539,alon lavie,Proceedings of the First International Conference on Human Language Technology Research,0,"NESPOLE! is a speech-to-speech machine translation research project funded jointly by the European Commission and the US NSF. The main goal of the NESPOLE! project is to advance the state-of-the-art of speech-to-speech translation in a real-world setting of common users involved in e-commerce applications. The project is a collaboration between three European research labs (IRST in Trento Italy, ISL at University of Karlsruhe in Germany, CLIPS at UJF in Grenoble France), a US research group (ISL at Carnegie Mellon in Pittsburgh) and two industrial partners (APT - the Trentino provincial tourism bureau, and Aethra - an Italian tele-communications commercial company). The speech-to-speech translation approach taken by the project builds upon previous work that the research partners conducted within the context of the C-STAR consortium (see http://www.c-star.org). The prototype system developed in NESPOLE! is intended to provide effective multi-lingual speech-to-speech communication between all pairs of four languages (Italian, German, French and English) within broad, but yet restricted domains. The first showcase currently under development is in the domain of tourism and travel information."
H01-1048,{L}ing{W}ear: A Mobile Tourist Information System,2001,6,13,5,0,41935,christian fugen,Proceedings of the First International Conference on Human Language Technology Research,0,"In this paper, we describe LingWear, a mobile tourist information system that allows uninformed users to find their way around in foreign cities and to ask for information about sights, accommodations, and other places of interest. The user can communicate with LingWear either by means of spontaneous speech queries or via a touch screen. LingWear automatically decides whether to respond through the integrated speech synthesis or display messages. LingWear is currently available for the cities of Heidelberg and Karlsruhe. It was designed to run on wearable computer, e.g. the Xybernaut family, and is available in both Windows and Linux versions."
H01-1071,Towards Automatic Sign Translation,2001,11,28,4,0,19377,jie yang,Proceedings of the First International Conference on Human Language Technology Research,0,"Signs are everywhere in our lives. They make our lives easier when we are familiar with them. But sometimes they also pose problems. For example, a tourist might not be able to understand signs in a foreign country. In this paper, we present our efforts towards automatic sign translation. We discuss methods for automatic sign detection. We describe sign translation using example based machine translation technology. We use a user-centered approach in developing an automatic sign translation system. The approach takes advantage of human intelligence in selecting an area of interest and domain for translation if needed. A user can determine which sign is to be translated if multiple signs have been detected within the image. The selected part of the image is then processed, recognized, and translated. We have developed a prototype system that can recognize Chinese signs input from a video camera which is a common gadget for a tourist, and translate them into English text or voice stream."
ries-etal-2000-shallow,Shallow Discourse Genre Annotation in {C}all{H}ome {S}panish,2000,14,10,5,1,53920,klaus ries,Proceedings of the Second International Conference on Language Resources and Evaluation ({LREC}{'}00),0,"The classification of speech genre is not yet an established task in language technologies. However we believe that it is a task that will become fairly important as large amounts of audio (and video) data become widely available. The technological cability to easily transmit and store all human interactions in audio and video could have a radical impact on our social structure. The major open question is how this information can be used in practical and beneficial ways. As a first approach to this question we are looking at issues involving information access to databases of human-human interactions. Classification by genre is a first step in the process of retrieving a document out of a large collection. In this paper we introduce a local notion of speech activities that are exist side-by-side in conversations that belong to speech-genre: While the genre of CallHome Spanish is personal telephone calls between family members the actual instances of these calls contain activities such as storytelling, advising, interrogation and so forth. We are presenting experimental work on the detection of those activities using a variety of features. We have also observed that a limited number of distinguised activities can be defined that describes most of the activities in this database in a precise way. Proceedings of the Second International Conference On Language Ressources And Evaluation, LREC 2000, Athens, Greece, 31st May-2nd June 2000"
C00-2140,{DIASUMM}: Flexible Summarization of Spontaneous Dialogues in Unrestricted Domains,2000,27,30,2,1,24148,klaus zechner,{COLING} 2000 Volume 2: The 18th International Conference on Computational Linguistics,0,"In this paper, we present a summarization system for spontaneous dialogues which consists of a novel multi-stage architecture. It is specifically aimed at addressing issues related to the nature of the texts being spoken vs. written and being dialogical vs. monological. The system is embedded in a graphical user interface and was developed and tested on transcripts of recorded telephone conversations in English and Spanish (CALLHOME)."
A00-2025,Minimizing Word Error Rate in Textual Summaries of Spoken Language,2000,10,66,2,1,24148,klaus zechner,1st Meeting of the North {A}merican Chapter of the Association for Computational Linguistics,0,Automatic generation of text summaries for spoken language faces the problem of containing incorrect words and passages due to speech recognition errors. This paper describes comparative experiments where passages with higher speech recognizer confidence scores are favored in the ranking process. Results show that a relative word error rate reduction of over 10% can be achieved while at the same time the accuracy of the summary improves markedly.
1999.mtsummit-1.18,Translation systems under the {C}-{STAR} framework,1999,-1,-1,1,1,5073,alex waibel,Proceedings of Machine Translation Summit VII,0,"This talk will review our work on Speech Translation under the recent worldwide C-STAR demonstration. C-STAR is the Consortium for Speech Translation Advanced Research and now includes 6 partners and 20 partner/affiliate laboratories around the world. The work demonstrated concludes the second phase of the consortium, which has focused on translating conversational spontaneous speech as opposed to well formed, well structured text. As such, much of the work has focused on exploiting semantic and pragmatic constraints derived from the task domain and dialog situation to produce an understandable translation. Six partners have connected their respective systems with each other and allowed travel related spoken dialogs to provide communication between each of them. A common Interlingua representation was developed and used between the partners to make this multilingual deployment possible. The systems were also complemented by the introduction of Web based shared workspaces that allow one user in one country to communicate pictures, documents, sounds, tables, etc. to the other over the Web while referring to these documents in the dialog. Some of the partners' systems were also deployed in wearable situations, such as a traveler exploring a foreign city. In this case speech and language technology was installed on a wearable computer with a small hand-held display. It was used to provide language translation as well as human-machine information access for the purpose of navigation (using GPS localization) and tour guidance. This combination of human-machine and human-machine-human dialogs could allow a user explore a foreign environment more effectively by resorting to human-machine and human-human dialogs wherever most appropriate."
P98-2221,Modeling with Structures in Statistical Machine translation,1998,7,53,2,1,37670,yeyi wang,"36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 2",0,"Most statistical machine translation systems employ a word-based alignment model. In this paper we demonstrate that word-based alignment is a major cause of translation errors. We propose a new alignment model based on shallow phrase structures, and the structures can be automatically acquired from parallel corpus. This new model achieved over 10% error reduction for our spoken language translation task."
P98-2237,Using Chunk Based Partial Parsing of Spontaneous Speech in Unrestricted Domains for Reducing Word Error Rate in Speech Recognition,1998,6,21,2,1,24148,klaus zechner,"36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 2",0,"In this paper, we present a chunk based partial parsing system for spontaneous, conversational speech in unrestricted domains. We show that the chunk parses produced by this parsing system can be usefully applied to the task of reranking Nbest lists from a speech recognizer, using a combination of chunk-based n-gram model scores and chunk coverage scores.The input for the system is Nbest lists generated from speech recognizer lattices. The hypotheses from the Nbest lists are tagged for part of speech, cleaned up by a preprocessing pipe, parsed by a part of speech based chunk parser, and rescored using a backpropagation neural net trained on the chunk based scores. Finally, the reranked Nbest lists are generated.The results of a system evaluation are promising in that a chunk accuracy of 87.4% is achieved and the best performance on a randomly selected test set is a decrease in world error rate of 0.3 percent (absolute), measured on the new first hypotheses in the reranked Nbest lists."
P98-1075,Growing Semantic Grammars,1998,4,29,2,1,54322,marsal gavalda,"36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 1",1,"A critical path in the development of natural language understanding (NLU) modules lies in the difficulty of defining a mapping from words to semantics: Usually it takes in the order of years of highly-skilled labor to develop a semantic mapping, e.g., in the form of a semantic grammar, that is comprehensive enough for a given domain. Yet, due to the very nature of human language, such mapping invariably fail to achieve full coverage on unseen data. Acknowledging the impossibility of stating a priori all the surface forms by which a concept can be expressed, we present GSG: an empathic computer system for the rapid deployment of NLU front-ends and their dynamic customization by non-expert end-users. Given a new domain for which an NLU front-end is to be developed, two stages are involved. In the authoring stage, GSG aids the developer in the construction of a simple domain model and a kernel analysis grammar. Then, in the run-time stage, GSG provides the end-user with an interactive environment in which the kernel grammar is dynamically extended. Three learning methods are employed in the acquisition of semantic mappings from unseen data: (i) parser predictions, (ii) hidden understanding model, and (iii) end-user paraphrases. A baseline version of GSG has been implemented and preliminary experiments show promising results."
C98-2216,Modeling with Structures in Statistical Machine Translation,1998,7,53,2,1,37670,yeyi wang,{COLING} 1998 Volume 2: The 17th International Conference on Computational Linguistics,0,"Most statistical machine translation systems employ a word-based alignment model. In this paper we demonstrate that word-based alignment is a major cause of translation errors. We propose a new alignment model based on shallow phrase structures, and the structures can be automatically acquired from parallel corpus. This new model achieved over 10% error reduction for our spoken language translation task."
C98-2232,Using Chunk Based Partial Parsing of Spontaneous Speech in Unrestricted Domains for Reducing Word Error Rate in Speech Recognition,1998,6,21,2,1,24148,klaus zechner,{COLING} 1998 Volume 2: The 17th International Conference on Computational Linguistics,0,"In this paper, we present a chunk based partial parsing system for spontaneous, conversational speech in unrestricted domains. We show that the chunk parses produced by this parsing system can be usefully applied to the task of reranking Nbest lists from a speech recognizer, using a combination of chunk-based n-gram model scores and chunk coverage scores.The input for the system is Nbest lists generated from speech recognizer lattices. The hypotheses from the Nbest lists are tagged for part of speech, cleaned up by a preprocessing pipe, parsed by a part of speech based chunk parser, and rescored using a backpropagation neural net trained on the chunk based scores. Finally, the reranked Nbest lists are generated.The results of a system evaluation are promising in that a chunk accuracy of 87.4% is achieved and the best performance on a randomly selected test set is a decrease in world error rate of 0.3 percent (absolute), measured on the new first hypotheses in the reranked Nbest lists."
C98-1072,Growing Semantic Grammars,1998,4,29,2,1,54322,marsal gavalda,{COLING} 1998 Volume 1: The 17th International Conference on Computational Linguistics,0,"A critical path in the development of natural language understanding (NLU) modules lies in the difficulty of defining a mapping from words to semantics: Usually it takes in the order of years of highly-skilled labor to develop a semantic mapping, e.g., in the form of a semantic grammar, that is comprehensive enough for a given domain. Yet, due to the very nature of human language, such mapping invariably fail to achieve full coverage on unseen data. Acknowledging the impossibility of stating a priori all the surface forms by which a concept can be expressed, we present GSG: an empathic computer system for the rapid deployment of NLU front-ends and their dynamic customization by non-expert end-users. Given a new domain for which an NLU front-end is to be developed, two stages are involved. In the authoring stage, GSG aids the developer in the construction of a simple domain model and a kernel analysis grammar. Then, in the run-time stage, GSG provides the end-user with an interactive environment in which the kernel grammar is dynamically extended. Three learning methods are employed in the acquisition of semantic mappings from unseen data: (i) parser predictions, (ii) hidden understanding model, and (iii) end-user paraphrases. A baseline version of GSG has been implemented and preliminary experiments show promising results."
woszczcyna-etal-1998-modular,A modular approach to spoken language translation for large domains,1998,8,18,7,0,55460,monika woszczcyna,Proceedings of the Third Conference of the Association for Machine Translation in the Americas: Technical Papers,0,"The MT engine of the JANUS speech-to-speech translation system is designed around four main principles: 1) an interlingua approach that allows the efficient addition of new languages, 2) the use of semantic grammars that yield low cost high quality translations for limited domains, 3) modular grammars that support easy expansion into new domains, and 4) efficient integration of multiple grammars using multi-domain parse lattices and domain re-scoring. Within the framework of the C-STAR-II speech-to-speech translation effort, these principles are tested against the challenge of providing translation for a number of domains and language pairs with the additional restriction of a common interchange format."
W97-0410,Expanding the Domain of a Multi-lingual Speech-to-Speech Translation System,1997,6,7,9,1,13539,alon lavie,Spoken Language Translation,0,"JANUS is a multi-lingual speech-to-speech translation system, which has been designed to translate spontaneous spoken language in a limited domain. In this paper, we describe our recent preliminary efforts to expand the domain of coverage of the system from the rather limited Appointment Scheduling domain, to the much richer Travel Planning domain. We compare the two domains in terms of out-of-vocabulary rates and linguistic complexity. We discuss the challenges that these differences impose on our translation system and some planned changes in the design of the system. Initial evaluations on Travel Planning data are also presented."
P97-1047,Decoding Algorithm in Statistical Machine Translation,1997,7,138,2,1,37670,yeyi wang,35th Annual Meeting of the Association for Computational Linguistics and 8th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,1,Decoding algorithm is a crucial part in statistical machine translation. We describe a stack decoding algorithm in this paper. We present the hypothesis scoring method and the heuristics used in our algorithm. We report several techniques deployed to improve the performance of the decoder. We also introduce a simplified model to moderate the sparse data problem and to speed up the decoding process. We evaluate and compare these techniques/models in our statistical machine translation system.
C96-1033,{F}eas{P}ar - A Feature Structure Parser Learning to Parse Spoken Language,1996,11,7,2,0,56021,finn buo,{COLING} 1996 Volume 1: The 16th International Conference on Computational Linguistics,0,"We describe and experimentally evaluate a system, FeasPar, that learns parsing spontaneous speech. To train and run FeasPar (Feature Structure Parser), only limited handmodeled knowledge is required.The FeasPar architecture consists of neural networks and a search. The networks split the incoming sentence into chunks, which are labeled with feature values and chunk relations. Then, the search finds the most probable and consistent feature structure.FeasPar is trained, tested and evaluated with the Spontaneous Scheduling Task, and compared with a handmodeled LR-parser. The handmodeling effort for FeasPar is 2 weeks. The handmodeling effort for the LR-parser was 4 months. FeasPar performed better than the LR-parser in all six comparisons that are made."
C96-1075,Multi-lingual Translation of Spontaneously Spoken Language in a Limited Domain,1996,9,11,5,1,13539,alon lavie,{COLING} 1996 Volume 1: The 16th International Conference on Computational Linguistics,0,"JANUS is a multi-lingual speech-to-speech translation system designed to facilitate communication between two parties engaged in a spontaneous conversation in a limited domain. In an attempt to achieve both robustness and translation accuracy we use two different translation components: the GLR module, designed to be more accurate, and the Phoenix module, designed to be more robust. We analyze the strengths and weaknesses of each of the approaches and describe our work on combining them. Another recent focus has been on developing a detailed end-to-end evaluation procedure to measure the performance and effectiveness of the system. We present our most recent Spanish-to-English performance evaluation results."
1996.amta-1.30,{JANUS}: multi-lingual translation of spontaneous speech in limited domain,1996,-1,-1,3,1,13539,alon lavie,Conference of the Association for Machine Translation in the Americas,0,None
1995.tmi-1.13,Using Context in Machine Translation of Spoken Language,1995,-1,-1,7,1,17380,lori levin,Proceedings of the Sixth Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,None
1995.mtsummit-1.41,Translation and interpretation of spontaneous speech,1995,-1,-1,1,1,5073,alex waibel,Proceedings of Machine Translation Summit V,0,None
W94-0113,Recovering From Parser Failures: A Hybrid Statistical/Symbolic Approach,1994,2,8,2,0,2584,carolyn rose,The Balancing Act: Combining Symbolic and Statistical Approaches to Language,0,"W~ describe an implementation of a hybrid statistical/symbolic approach to repairing parser failures in a speech-to-speech translation system. I We describe a rnodale which takes as input a fragmented parse and reeturas a repaired meaning representation. It negotiates with the speaker about what the complete meaning of the utterance is by generating hypotheses about how to fit. the fragments of the partial parse together into a colwrcnt meaning representation. By drawing upon both statistical and symbolic information, it constrains its rcpair hypotheses to those which are both likely and meaningful. Because it updates its statistical model during use, it improves its performance over time."
1994.amta-1.31,Future Directions,1994,-1,-1,6,0,53582,joseph pentheroudakis,Proceedings of the First Conference of the Association for Machine Translation in the Americas,0,None
W93-0109,The Automatic Acquisition of Frequencies of Verb Subcategorization Frames from Tagged Corpora,1993,-1,-1,4,0,47465,akira ushioda,Acquisition of Lexical Knowledge from Text,0,None
H93-1035,Machine Translation,1993,0,0,1,1,5073,alex waibel,"{H}uman {L}anguage {T}echnology: Proceedings of a Workshop Held at Plainsboro, New Jersey, March 21-24, 1993",0,None
1993.iwpt-1.24,Frequency Estimation of Verb Subcategorization Frames Based on Syntactic and Multidimensional Statistical Analysis,1993,-1,-1,4,0,47465,akira ushioda,Proceedings of the Third International Workshop on Parsing Technologies,0,"We describe a mechanism for automatically estimating frequencies of verb subcategorization frames in a large corpus. A tagged corpus is first partially parsed to identify noun phrases and then a regular grammar is used to estimate the appropriate subcategorization frame for each verb token in the corpus. In an experiment involving the identification of six fixed subcategorization frames, our current system showed more than 80{\%} accuracy. In addition, a new statistical method enables the system to learn patterns of errors based on a set of training samples and substantially improves the accuracy of the frequency estimation."
W89-0224,A Connectionist Parser Aimed at Spoken Language,1989,0,5,2,0,9676,ajay jain,Proceedings of the First International Workshop on Parsing Technologies,0,"We describe a connectionist model which learns to parse single sentences from sequential word input. A parse in the connectionist network contains information about role assignment, prepositional attachment, relative clause structure, and subordinate clause structure. The trained network displays several interesting types of behavior. These include predictive ability, tolerance to certain corruptions of input word sequences, and some generalization capability. We report on experiments in which a small number of sentence types have been successfully learned by a network. Work is in progress on a larger database. Application of this type of connectionist model to the area of spoken language processing is discussed."
