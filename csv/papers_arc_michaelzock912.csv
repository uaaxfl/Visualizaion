W16-5308,Towards a resource based on users{'} knowledge to overcome the Tip of the Tongue problem.,2016,34,1,1,1,33495,michael zock,Proceedings of the 5th Workshop on Cognitive Aspects of the Lexicon ({C}og{AL}ex - V),0,"Language production is largely a matter of words which, in the case of access problems, can be searched for in an external resource (lexicon, thesaurus). In this kind of dialogue the user provides the momentarily available knowledge concerning the target and the system responds with the best guess(es) it can make given this input. As tip-of-the-tongue (ToT)-studies have shown, people always have some knowledge concerning the target (meaning fragments, number of syllables, ...) even if its complete form is eluding them. We will show here how to tap on this knowledge to build a resource likely to help authors (speakers/writers) to overcome the ToT-problem. Yet, before doing so we need a better understanding of the various kinds of knowledge people have when looking for a word. To this end, we asked crowdworkers to provide some cues to describe a given target and to specify then how each one of them relates to the target, in the hope that this could help others to find the elusive word. Next, we checked how well a given search strategy worked when being applied to differently built lexical networks. The results showed quite dramatic differences, which is not really surprising. After all, different networks are built for different purposes; hence each one of them is more or less suited for a given task. What was more surprising though is the fact that the relational information given by the users did not allow us to find the elusive word in WordNet better than without it."
N16-2005,Combining syntactic patterns and {W}ikipedia{'}s hierarchy of hyperlinks to extract meronym relations,2016,10,2,2,0,25569,debela gemechu,Proceedings of the {NAACL} Student Research Workshop,0,None
2016.gwc-1.61,{W}ord{N}et and beyond: the case of lexical access,2016,-1,-1,1,1,33495,michael zock,Proceedings of the 8th Global WordNet Conference (GWC),0,"For humans the main functions of a dictionary is to store information concerning words and to reveal it when needed. While readers are interested in the meaning of words, writers look for answers concerning usage, spelling, grammar or word forms (lemma). We will focus here on this latter task: help authors to find the word they are looking for, word they may know but whose form is eluding them. Put differently, we try to build a resource helping authors to overcome the tip-of-the-tongue problem (ToT). Obviously, in order to access a word, it must be stored somewhere (brain, resource). Yet this is by no means sufficient. We will illustrate this here by comparing WordNet (WN) to an equivalent lexical resource bootstrapped from Wikipedia (WiPi). Both may contain a given word, but ease and success of access may be different depending on other factors like quality of the query, proximity, type of connections, etc. Next we will show under what conditions WN is suitable for word access, and finally we will present a roadmap showing the obstacles to be overcome to build a resource allowing the text producer to find the word s/he is looking for."
W14-6706,Word storage does not guarantee accessibility (Stocker des Mots ne Garantit nullement leur Acc{\\`e}s) [in {F}rench],2014,0,0,1,1,33495,michael zock,TALN-RECITAL 2014 Workshop RLTLN 2014 : R{\\'e}seaux Lexicaux pour le TAL (RLTLN 2014 : Lexical Networks for NLP),0,None
W14-4701,The {C}og{AL}ex-{IV} Shared Task on the Lexical Access Problem,2014,40,8,2,0,20907,reinhard rapp,Proceedings of the 4th Workshop on Cognitive Aspects of the Lexicon ({C}og{AL}ex),0,"The shared task of the 4th Workshop on Cognitive Aspects of the Lexicon (CogALexIV) was devoted to a subtask of the lexical access problem, namely multi-stimulus association. In this task, participants were supposed to determine automatically an expected response based on a number of received stimulus words. We describe here the task definition, the theoretical background, the training and test data sets, and the evaluation procedure used for ranking the participating systems. We also summarize the approaches used and present the results of the evaluation. In conclusion, the outcome of the competition are a number of systems which provide very good solutions to the problem."
W14-4726,Wordfinding Problems and How to Overcome them Ultimately With the Help of a Computer,2014,41,0,1,1,33495,michael zock,Proceedings of the 4th Workshop on Cognitive Aspects of the Lexicon ({C}og{AL}ex),0,"Our ultimate goal is to help authors to find an elusive word. Whenever we need a word, we look it up in the place where it is stored, the dictionary or the mental lexicon. The question is how do we manage to find the word, and how do we succeed to do this so quickly? While these are difficult questions, I believe to have some practical answers for them. Since it is unreasonable to perform search in the entire lexicon, I suggest to start by reducing this space (step-1) and to present then the remaining candidates in a clustered and labeled form, i.e. categorial tree (step-2). The goal of this second step is to support navigation. Search space is determined by considering words directly related to the input, i.e. direct neighbors (associations/co-occurrences). To this end many resources could be used. For example, one may consider an associative network like the Edinburgh Association Thesaurus (E.A.T.). As this will still yield too many hits, I suggest to cluster and label the outputs. This labeling is crucial for navigation, as we want users to find the target quickly, rather than drown them under a huge, unstructured list of words. Note, that in order to determine properly the initial search space (step-1), we must have already well understood the input [mouse1 / mouse2 (rodent/device)], as otherwise our list will contain a lot of noise, presenting xe2x80x99cat, cheesexe2x80x99 together with xe2x80x99computer, mouse padxe2x80x99, which is not quite what we want, since some of these candidates are irrelevant, i.e. beyond the scope of the userxe2x80x99s goal."
W14-0509,How well can a corpus-derived co-occurrence network simulate human associative behavior?,2014,16,4,3,0,21395,gemma enguix,Proceedings of the 5th Workshop on Cognitive Aspects of Computational Language Learning ({C}og{ACLL}),0,"Free word associations are the words people spontaneously come up with in response to a stimulus word. Such information has been collected from test persons and stored in databases. A well known example is the Edinburgh Associative Thesaurus (EAT). We will show in this paper that this kind of knowledge can be acquired automatically from corpora, enabling the computer to produce similar associative responses as people do. While in the past test sets typically consisted of approximately 100 words, we will use here a large part of the EAT which, in total, comprises 8400 words. Apart from extending the test set, we consider different properties of words: saliency, frequency and part-of-speech. For each feature categorize our test set, and we compare the simulation results to those based on the EAT. It turns out that there are surprising similarities which supports our claim that a corpus-derived co-occurrence network can simulate human associative behavior, i.e. an important part of language acquisition and verbal behavior."
enguix-etal-2014-graph,A Graph-Based Approach for Computing Free Word Associations,2014,45,4,3,0,21395,gemma enguix,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"A graph-based algorithm is used to analyze the co-occurrences of words in the British National Corpus. It is shown that the statistical regularities detected can be exploited to predict human word associations. The corpus-derived associations are evaluated using a large test set comprising several thousand stimulus/response pairs as collected from humans. The finding is that there is a high agreement between the two types of data. The considerable size of the test set allows us to split the stimulus words into a number of classes relating to particular word properties. For example, we construct six saliency classes, and for the words in each of these classes we compare the simulation results with the human data. It turns out that for each class there is a close relationship between the performance of our system and human performance. This is also the case for classes based on two other properties of words, namely syntactic and semantic word ambiguity. We interpret these findings as evidence for the claim that human association acquisition must be based on the statistical analysis of perceived language and that when producing associations the detected statistical regularities are replicated."
Y13-2003,A Generic Cognitively Motivated Web-Environment to Help People to Become Quickly Fluent in a New Language,2013,37,0,1,1,33495,michael zock,{PACLIC} 27 Workshop on Computer-Assisted Language Learning,0,"To speak fluently is a complex skill. In order to help the learner to acquire it we propose an electronic version of an age old method: pattern drills (PD). While being highly regarded in the fifties, pattern drills have become unpopular since then. Despite certain shortcomings we do believe in the virtues of this approach, at least with regard to the memorization of basic structures and the acquisition of fluency, the skill to produce language at a 'normal' rate. Of course, the method has to be improved, and we will show here how this can be achieved. Unlike tapes or books, computers are open media, allowing for dynamic changes, taking usersxe2x80x99 performances and preferences into account. Our drill-tutor, a small webapplication still in its prototype phase, allows for this. It is a free, electronic version of pattern drills, i.e. an exercise generator, open and adaptable to the usersxe2x80x99 ever changing needs."
F13-2012,Lexical access via a simple co-occurrence network (Trouver les mots dans un simple r{\\'e}seau de co-occurrences) [in {F}rench],2013,16,1,2,0,14997,gemma belenguix,Proceedings of TALN 2013 (Volume 2: Short Papers),0,None
W12-5104,Automatic index creation to support navigation in lexical graphs encoding part{\\_}of relations,2012,35,2,1,1,33495,michael zock,Proceedings of the 3rd Workshop on Cognitive Aspects of the Lexicon,0,"We describe here the principles underlying the automatic creation of a semantic map to support navigation in a lexicon, our target group being authors (speakers, writers) rather than readers. While machines can generally access information that it has stored, this does not always hold for people. A speaker may very well know a word, yet still be (occasionally) unable to access it. To help authors to overcome word-finding problems one could add to an existing electronic resource an index based on the (age-old) notion of association. Since ideas or their expressive forms (words) are related, they may evoke each other (lemon-yellow), but the likelihood for doing so varies over time and with the context. For example, the word 'piano' may prime 'instrument' or 'weight', but which of the two gets evoked depends on the context: 'concert' vs. 'house moving'. Given this dynamic aspect of the human brain, we should build the index automatically, computing the relation of terms and their weights on the fly. This dynamic creation of the index could be done via a corpus. This latter representing ideally the dictionary users' world knowledge, and the way how the prominence of words and ideas varies over time. Another important point are link-names, i.e. the type of relationship holding between two associates: [(rose) <--color (red)]. Given the fact that any query (e.g. 'India') may yield many hits, hits whose weights may be misleading, it makes sense to group the output according to some (other) category, for example, link names (color, city_of, instrument, ...). Yet, important as they may be, links or relations are hard to extract and to name. This is why we have decided to start with a very small sub-set, meronymic-, i.e. part-of relations (x is part of y, x has y, etc.)."
2011.jeptalnrecital-long.1,"Patrons de phrase, raccourcis pour apprendre rapidement {\\`a} parler une nouvelle langue (Sentence patterns, shortcuts to quickly learn to speak a new language)",2011,-1,-1,1,1,33495,michael zock,Actes de la 18e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Nous d{\'e}crivons la cr{\'e}ation d{'}un environnement web pour aider des apprenants (adolescents ou adultes) {\`a} acqu{\'e}rir les automatismes n{\'e}cessaires pour produire {\`a} un d{\'e}bit {``}normal{''} les structures fondamentales d{'}une langue. Notre point de d{\'e}part est une base de donn{\'e}es de phrases, glan{\'e}es sur le web ou issues de livres scolaires ou de livres de phrases. Ces phrases ont {\'e}t{\'e} g{\'e}n{\'e}ralis{\'e}es (remplacement de mots par des variables) et index{\'e}es en termes de buts pour former une arborescence de patrons. Ces deux astuces permettent de motiver l{'}usage des patrons et de cr{\'e}{\'e}er des phrases structurellement identiques {\`a} celles rencontr{\'e}es, tout en {\'e}tant s{\'e}mantiquement diff{\'e}rentes. Si les notions de {`}patrons{'} ou de {`}phrases {\`a} trou implicitement typ{\'e}es{'} ne sont pas nouvelles, le fait de les avoir port{\'e}es sur ordinateur pour apprendre des langues l{'}est. Le syst{\`e}me {\'e}tant con{\c{c}}u pour {\^e}tre ouvert, il permet aux utilisateurs, concepteurs ou apprenants, des changements sur de nombreux points importants : le nom des variables, leurs valeurs, le laps de temps entre une question et sa r{\'e}ponse, etc. La version initiale a {\'e}t{\'e} d{\'e}velopp{\'e}e pour l{'}anglais et le japonais. Pour tester la g{\'e}n{\'e}ricit{\'e} de notre approche nous y avons ajout{\'e} relativement facilement le fran{\c{c}}ais et le chinois."
2011.jeptalnrecital-long.20,{\\'E}valuation et consolidation d{'}un r{\\'e}seau lexical via un outil pour retrouver le mot sur le bout de la langue (Evaluation and consolidation of a lexical network via a tool to find the word on the tip of the tongue),2011,-1,-1,4,0,32452,alain joubert,Actes de la 18e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Depuis septembre 2007, un r{\'e}seau lexical de grande taille pour le Fran{\c{c}}ais est en cours de construction {\`a} l{'}aide de m{\'e}thodes fond{\'e}es sur des formes de consensus populaire obtenu via des jeux (projet JeuxDeMots). L{'}intervention d{'}experts humains est marginale en ce qu{'}elle repr{\'e}sente moins de 0,5{\%} des relations du r{\'e}seau et se limite {\`a} des corrections, {\`a} des ajustements ainsi qu{'}{\`a} la validation des sens de termes. Pour {\'e}valuer la qualit{\'e} de cette ressource construite par des participants de jeu (utilisateurs non experts) nous adoptons une d{\'e}marche similaire {\`a} celle de sa construction, {\`a} savoir, la ressource doit {\^e}tre valid{\'e}e sur un vocabulaire de classe ouverte, par des non-experts, de fa{\c{c}}on stable (persistante dans le temps). Pour ce faire, nous proposons de v{\'e}rifier si notre ressource est capable de servir de support {\`a} la r{\'e}solution du probl{\`e}me nomm{\'e} {`}Mot sur le Bout de la Langue{'} (MBL). A l{'}instar de JeuxdeMots, l{'}outil d{\'e}velopp{\'e} peut {\^e}tre vu comme un jeu en ligne. Tout comme ce dernier, il permet d{'}acqu{\'e}rir de nouvelles relations, constituant ainsi un enrichissement de notre r{\'e}seau lexical."
W10-4005,The Noisier the Better: Identifying Multilingual Word Translations Using a Single Monolingual Corpus,2010,19,3,2,0,20907,reinhard rapp,Proceedings of the 4th Workshop on Cross Lingual Information Access,0,"The automatic generation of dictionaries from raw text has previously been based on parallel or comparable corpora. Here we describe an approach requiring only a single monolingual corpus to generate bilingual dictionaries for several language pairs. A constraint is that all language pairs have their target language in common, which needs to be the language of the underlying corpus. Our approach is based on the observation that monolingual corpora usually contain a considerable number of foreign words. As these are often explained via translations typically occurring close by, we can identify these translations by looking at the contexts of a foreign word and by computing its strongest associations from these. In this work we focus on the question what results can be expected for 20 language pairs involving five major European languages. We also compare the results for two different types of corpora, namely newsticker texts and web corpora . Our findings show that results are best if English is the source language, and that noisy web corpora are better suited for this task than well edited newsticker texts."
W10-3908,Utilizing Citations of Foreign Words in Corpus-Based Dictionary Generation,2010,13,3,2,0,20907,reinhard rapp,Proceedings of the Second Workshop on {NLP} Challenges in the Information Explosion Era ({NLPIX} 2010),0,"Previous work concerned with the identification of word translations from text collections has been either based on parallel or on comparable corpora of the respective languages. In the case of comparable corpora basic dictionaries have been necessary to form a bridge between the languages under consideration. We present here a novel approach to identify word translations from a single monolingual corpus without necessarily requiring dictionaries, although, as will be shown, a dictionary can still be useful for improving the results. Our approach is based on the observation that for various reasons monolingual corpora typically contain many foreign words (for example citations). Relying on standard newsticker texts, we will show that their cooccurrence-based associations can be successfully used to identify word translations."
W10-3411,"Lexical Access, a Search-Problem",2010,19,2,1,1,33495,michael zock,Proceedings of the 2nd Workshop on Cognitive Aspects of the Lexicon,0,"Our work is confined to word access, that is, we present here our ideas of how to improve electronic dictionaries in order to help language producers (speaker/writer) to find the word they are looking for. Our approach is based on psychological findings (representation, storage and access of information in the human mind), observed search strategies and typical navigational behavior. If one agrees with the idea that lexical access (word finding) is basically a search problem, then one may still want to find out where and how to search. While the space, i.e. the semantic map in which search takes place is a resource problem,xe2x80x94 any of the following could be used: dictionary, corpus, thesauraus, etc. or a mix of them,xe2x80x94 its exploration is typically a search problem. Important as it may be, the building of a high quality resource is not the focus of this work, we rely on an existing one, and while we are concerned with its quality, we will be mostly concerned here with search methods, in order to determine the best."
gala-etal-2010-tool,A Tool for Linking Stems and Conceptual Fragments to Enhance word Access,2010,20,4,3,0,15665,nuria gala,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"Electronic dictionaries offer many possibilities unavailable in paper dictionaries to view, display or access information. However, even these resources fall short when it comes to access words sharing semantic features and certain aspects of form: few applications offer the possibility to access a word via a morphologically or semantically related word. In this paper, we present such an application, Polymots, a lexical database for contemporary French containing 20.000 words grouped in 2.000 families. The purpose of this resource is to group words into families on the basis of shared morpho-phonological and semantic information. Words with a common stem form a family; words in a family also share a set of common conceptual fragments (in some families there is a continuity of meaning, in others meaning is distributed). With this approach, we capitalize on the bidirectional link between semantics and morpho-phonology : the user can thus access words not only on the basis of ideas, but also on the basis of formal characteristics of the word, i.e. its morphological features. The resulting lexical database should help people learn French vocabulary and assist them to find words they are looking for, going thus beyond other existing lexical resources."
2010.jeptalnrecital-long.31,Du {TAL} au {TIL},2010,-1,-1,1,1,33495,michael zock,Actes de la 17e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Historiquement deux types de traitement de la langue ont {\'e}t{\'e} {\'e}tudi{\'e}s: le traitement par le cerveau (approche psycholinguistique) et le traitement par la machine (approche TAL). Nous pensons qu{'}il y a place pour un troisi{\`e}me type: le traitement interactif de la langue (TIL), l{'}ordinateur assistant le cerveau. Ceci correspond {\`a} un besoin r{\'e}el dans la mesure o{\`u} les gens n{'}ont souvent que des connaissances partielles par rapport au probl{\`e}me {\`a} r{\'e}soudre. Le but du TIL est de construire des ponts entre ces connaissances momentan{\'e}es d{'}un utilisateur et la solution recherch{\'e}e. {\`A} l{'}aide de quelques exemples, nous essayons de montrer que ceci est non seulement faisable et souhaitable, mais {\'e}galement d{'}un co{\^u}t tr{\`e}s raisonnable."
W08-1902,Lexical access based on underspecified input,2008,38,15,1,1,33495,michael zock,Coling 2008: Proceedings of the Workshop on Cognitive Aspects of the Lexicon ({COGALEX} 2008),0,"Words play a major role in language production, hence finding them is of vital importance, be it for speaking or writing. Words are stored in a dictionary, and the general belief holds, the bigger the better. Yet, to be truly useful the resource should contain not only many entries and a lot of information concerning each one of them, but also adequate means to reveal the stored information. Information access depends crucially on the organization of the data (words) and on the navigational tools. It also depends on the grouping, ranking and indexing of the data, a factor too often overlooked.n n We will present here some preliminary results, showing how an existing electronic dictionary could be enhanced to support language producers to find the word they are looking for. To this end we have started to build a corpus-based association matrix, composed of target words and access keys (meaning elements, related concepts/words), the two being connected at their intersection in terms of weight and type of link, information used subsequently for grouping, ranking and navigation."
W08-1911,Looking up phrase rephrasings via a pivot language,2008,21,3,2,0,28247,aurelien max,Coling 2008: Proceedings of the Workshop on Cognitive Aspects of the Lexicon ({COGALEX} 2008),0,"Rephrasing text spans is a common task when revising a text. However, traditional dictionaries often cannot provide direct assistance to writers in performing this task. In this article, we describe an approach to obtain a monolingual phrase lexicon using techniques used in Statistical Machine Translation. A part to be rephrased is first translated into a pivot language, and then translated back into the original language. Models for assessing fluency, meaning preservation and lexical divergence are used to rank possible rephrasings, and their relative weight can be tuned by the user so as to better address her needs. An evaluation shows that these models can be used successfully to select rephrasings that are likely to be useful to a writer."
cristea-etal-2008-evaluate,How to Evaluate and Raise the Quality in a Collaborative Lexicographic Approach,2008,1,3,4,0,14259,dan cristea,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"This paper focuses on different aspects of collaborative work used to create the electronic version of a dictionary in paper format, edited and printed by the Romanian Academy during the last century. In order to ensure accuracy in a reasonable amount of time, collaborative proofreading of the scanned material, through an on-line interface has been initiated. The paper details the activities and the heuristics used to maximize accuracy, and to evaluate the work of anonymous contributors with diverse backgrounds. Observing the behaviour of the enterprise for a period of 6 months allows estimating the feasibility of the approach till the end of the project."
P06-1036,Enhancing Electronic Dictionaries with an Index Based on Associations,2006,21,21,2,0,5589,olivier ferret,Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,1,"A good dictionary contains not only many entries and a lot of information concerning each one of them, but also adequate means to reveal the stored information. Information access depends crucially on the quality of the index. We will present here some ideas of how a dictionary could be enhanced to support a speaker/writer to find the word s/he is looking for. To this end we suggest to add to an existing electronic resource an index based on the notion of association. We will also present preliminary work of how a subset of such associations, for example, topical associations, can be acquired by filtering a network of lexical co-occurrences extracted from a corpus."
W04-2105,Word Lookup on the Basis of Associations : from an Idea to a Roadmap,2004,23,31,1,1,33495,michael zock,Proceedings of the Workshop on Enhancing and Using Electronic Dictionaries,0,"Word access is an obligatory step in language production. In order to achieve his communicative goal, a speaker/writer needs not only to have something to say, he must also find the corresponding word(s). Yet, knowing a word, i.e. having it stored in a data-base or memory (human mind or electronic device) does not imply that one is able to access it in time. This is a clearly a case where computers (electronic dictionaries) can be of great help.n n In this paper we present our ideas of how an enhanced electronic dictionary can help people to find the word they are looking for. The yet-to-be-built resource is based on the age-old notion of association: every idea, concept or word is connected. In other words, we assume that people have a highly connected conceptuallexical network in their mind. Finding a word amounts thus to entering the network at any point by giving the word or concept coming to their mind (source word) and then following the links (associations) leading to the word they are looking for(target word).n n Obviously, in order to allow for this kind of access, the resource has to be built accordingly. This requires at least two things: (a) indexing words by the associations they evoke, (b) identification and labeling of the most frequent/useful associations. This is precisely our goal. Actually, we propose to build an associative network by enriching an existing electronic dictionary (essentially) with (syntagmatic) associations coming from a corpus, representing the average citizen's shared, basic knowledge of the world (encyclopedia). Such an enhanced electronic database resembles in many respects our mental dictionary. Combining the power of computers and the flexibility of the human mind (omnidirectional navigation and quick jumps), it emulates to some extent the latter in its capacity to navigate quickly and efficiently in a large data base.n n While the notions of association and spreading activation are fairly old, their use to support word access via computer is new. The resource still needs to be built, and this is not a trivial task. We discuss here some of the strategies and problems involved in accomplishing it with the help of people and computers (automation)."
2004.jeptalnrecital-long.18,Syst{\\`e}me d{'}aide {\\`a} l{'}acc{\\`e}s lexical : trouver le mot qu{'}on a sur le bout de la langue,2004,-1,-1,3,0,52471,gaelle lortal,Actes de la 11{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Le Mot sur le Bout de la Langue (Tip Of the Tongue en anglais), ph{\'e}nom{\`e}ne tr{\`e}s {\'e}tudi{\'e} par les psycholinguistes, nous a amen{\'e} nombre d{'}informations concernant l{'}organisation du lexique mental. Un locuteur en {\'e}tat de TOT reconna{\^\i}t instantan{\'e}ment le mot recherch{\'e} pr{\'e}sent{\'e} dans une liste. Il en conna{\^\i}t le sens, la forme, les liens avec d{'}autres mots... Nous pr{\'e}sentons ici une {\'e}tude de d{\'e}veloppement d{'}outil qui prend en compte ces sp{\'e}cificit{\'e}s, pour assister un locuteur/r{\'e}dacteur {\`a} trouver le mot qu{'}il a sur le bout de la langue. Elle consiste {\`a} recr{\'e}er le ph{\'e}nom{\`e}ne du TOT, o{\`u}, dans un contexte de production un mot, connu par le syst{\`e}me, est momentan{\'e}ment inaccessible. L{'}acc{\`e}s au mot se fait progressivement gr{\^a}ce aux informations provenant de bases de donn{\'e}es linguistiques. Ces derni{\`e}res sont essentiellement des relations de type paradigmatique et syntagmatique. Il s{'}av{\`e}re qu{'}un outil, tel que SVETLAN, capable de structurer automatiquement un dictionnaire par domaine, peut {\^e}tre avantageusement combin{\'e} {\`a} une base de donn{\'e}es riche en liens paradigmatiques comme EuroWordNet, augmentant consid{\'e}rablement les chances de trouver le mot auquel on ne peut acc{\'e}der."
W02-1118,"Sorry, What Was Your Name Again, or How to Overcome the tip-of-the tongue Problem with the Help of a Computer?",2002,30,8,1,1,33495,michael zock,{COLING}-02: {SEMANET}: Building and Using Semantic Networks,0,"A speaker or writer has to find words for expressing his thoughts. Yet, knowing a word does not guarantee its access. Who hasn't experienced the problem of looking for a word he knows, yet is unable to access (in time)? Work done by psychologists reveals that people being in this so called tip-of-the-tongue state (TOT) know a lot about the word: meaning, number of syllables, origine, etc. Speakers are generally able to recognize the word, and if they produce an erroneous word, that token shares many things with the target word (initial/final letter/phoneme, part of speech, semantic field, etc.). This being so, one might want to take advantage of the situation and build a program that assists the speaker/writer by revealing the word that's on his/her mind (tongue/pen). Three methods will be presented, the first one being implemented."
W01-0811,"Learn to Speak and to Write, Learn to Use Your Mind The Relevance of the Work of Natural Language Generation (invited talk)",2001,0,1,1,1,33495,michael zock,Proceedings of the {ACL} 2001 Eighth {E}uropean Workshop on Natural Language Generation ({EWNLG}),0,None
W98-1407,Automatic Generation of Subway Directions: Salience Gradation as a Factor Fordetermining Message and Form,1998,1,9,3,0,55107,lidia fraczak,Natural Language Generation,0,None
C96-2167,The Power of Words in Message Planning,1996,6,11,1,1,33495,michael zock,{COLING} 1996 Volume 2: The 16th International Conference on Computational Linguistics,0,"Before engaging in a conversation, a message must be planned. While there are many ways to perform this task, I believe that people do this in the following way, in particular if the message is going to be long: first an outline is planned (global, or skeleton planning), which is then filled in with details (local planning, elaboration). Planning proceeds thus from general to specific (breadth first), that is, sentences are planned incremetally by gradual refinement of some abstract thought rather than in one go (one-shot process) where every element is planned down to its last details.While global planning is largely language independent, local planning can be language dependent: the dictionary acts a mediator, interfacing language and thought. Given the fact that words can be used to specify non linguistic thought, there is feedback from the lexical to the conceptual component. This being so, dictionaries may play a fundamental role in guiding and potentially modifying non linguistic thought. If my view is correct, this could have implications on the design of generation architectures: instead of separating message planning and realization, viewing the process as being strictly sequential, we could allow for feedback loops (interleaved process), whereby the linguistic component could feed back to the conceptual component."
C96-2171,Computational Linguistics and its Use in Real World: the Case of Computer Assisted-Language Learning,1996,26,13,1,1,33495,michael zock,{COLING} 1996 Volume 2: The 16th International Conference on Computational Linguistics,0,None
C92-2073,"How to Visualize Time, Tense and Aspect?",1992,34,5,2,0,57131,gerard ligozat,{COLING} 1992 Volume 2: The 14th {I}nternational {C}onference on {C}omputational {L}inguistics,0,None
C88-2164,Language Learning as Problem Solving,1988,0,4,1,1,33495,michael zock,{C}oling {B}udapest 1988 Volume 2: {I}nternational {C}onference on {C}omputational {L}inguistics,0,"We present here a system under development, the present goals of which are to assist (a) students in inductively learning a set of rules to generate sentences in French, and (b) psychologists in gathering data on natural language learning. Instead of claimin~ an all-encompassing model or theory, we prefer to elaborate a tool, which is general and flexible enough to permit the testing of various theories. By controlling parameters such as initml knowledge, the nature and order o f the data, we can empirically determine how each parameter affects the efficiency of learning. Our ultimate goal is the modelling of human learning by machine. Learning is viewed as problem-solving, i.e. as the creation and reduction of a search-space, t~y integrating the student into the process, that is, by encouraging him to ask an expert (the system) certain kinds of questions like: can one say x ? how does one say x ? why does one say x ? we can ennance not only the efficiency of the learning, but also our understanding of the underlying processes. By having a tra.~e of the whole dialogue (what questions have been asked at, what time), Ave should be able to infer the student's learning strategies. I THE PROBLEM OF LEARNING A LANGUAGE: Language learning can be viewed as a special case of problem solving in which tlae learner tries to build and intelligently explore a hypothetical search space. If this view is correct, then two sets of questions arise immediately. On one hand one may want to know: a) what the nature of this search space is (what are the variables 9) b) how it is built (incremental learning: local vg global view), ' ' c) how it is explored (strategies: intelligent opportunistics vs systematic search). On the other hand, one may want to investigate how (i) the knowledge at the outset and (ii) the ordering of the data will affect the building and the searching of the space. Typically one does not learn from scratch, nor is it likely that one encounters either well-ordered data, or a Complete set of examples: natural learning is incremental. Obviously, these.facts imply that: * initial knowledge, in particular, knowledge of other languages may bias the kind of variables (attributes or hypotheses) constdered, i.e., included in the search space; * the order of the data (the examp es encountered by the student) may determine what rules are likely to be inferred at what moment, and finally rues are referred from mcomplete data (incremental learning). Furthermore, the same data may be characterized in different ways. That is, several equivalent descriptions may be inferred from the same data set. Whieli of these descriptions turns out to be the most adequate generally cannot be established until one knows the complete data set. Thus, rules may have to be revised in the light of new evidence. Consequently, errors are not only unavoidable parts of the learning process,but also an indispensable source of information for the learner. 2 THE PROBLEM OF TEACHING HOW TO LEARNt As we have shown, learning can be seen as searching. Actually, teaching, as well as learning, can be conceived of as problem solving or reasoning in an informatio.n-exchange environment. There is a sender, a goal, a message and a recewer. The SENDER may be a native speaker, a teacher, a parent, a book or a computer. The GOAL is the task or performance (output). In our case it is knowledge of how to produce sentences in French. The MESSAGE is the input to the learning component: examples from which the rules have to be inferred (1). The RECEIVER or learner can be any system, naturm or artlttcial, capable of perceiving, memorizing and analyzing a set of data and drawing the necessary conclusions: a child, a student, or a computer program (2). Learning occurs in various settings. Depending on the order of the examples and the control of the information flow we s eak of nator I . . . . . . p a experimental, or msmuttonal settings. Natural learning is characterized by the absence of a clearly defined learning objective (3), by noisy and heterogeneous material~ and by unordered examples. The underlying regumr:ties are thus multiple, diffuse, and hard to perceive. Experimentffl learning and teaching, on the other hand, have a ]earning objective, the material is error-free, homogeneous and coherently ordered according to some point of view (learner or teacher). Whereas experimental learning can be characterized by the following sequence: (i) encountering the data (ii) analysis, (iii) building and testing of h~,pothesis, (iv) feedback and (v) proof or aemonstration of the theo~, traditional teaching goes througfi the following stages: (i) exposition, 0i) practice, (iii) testing and (iv) evaluation. This can be schematized as follows: Teacher: sets the task and presents the learning material Student: analyzes the data; Teacher: provtdes a set of examples; Student: practices; Teacher: asks questions to test the gained knowledge; Student: answers the questions; Teacher: evaluates the answers, provides feedback (explanations) and organizes future data as a function of actual performance Student: integrates the feedback into the knowledge base and corrects misconceptions; As one can see, the information flow here is entirely teacher-controlled. He is the one who sets the task, and provides the examples and the feedback. Consequently, the teacher decides the nature and the order of the material to be learned. There are two major shortcomings in this approach. Not knowiug what information is needed by the learner, the teacher may present the wrong data. More importantly, the student is only loosely integrated in the learning process. Instead of being active, generating and testing plausible hypotheses (discovery learning), he reacts to questions, Thus, it may happen that the student perceives his task as the learning of the material rather than the learning of the underlying principles. I~norance of what or how to learn may result in (i) learning the unintended 0:) poor problem-solving skills or (iii) little transfer. As long as the learne~ does not go beyond the informaBon given (the concrete word level), he cannot transfer the gained knowledge to similar situations, because the perception of similarity presupposes abstraction. Given these criticisms, it would be useful to have a system which has the qualities mentioned above without having the drawbacks. A good learning environment should be both flexible and constraining enough: * to allow for simulation of real Communication, that is to say, to provide a setting where both participants can take the initiative and control the information-flow, * O   t ensure the learmng of the appropriate material (i.e., what to learn) as well as the necessary problem-solving skills (the methods, i.e, how to learn). A computerprogram could provide such an environment. It would offer different k!nds oi' !nformation (see below: trace-function), while answering me stuuent's questions as ne goes aJong generating and testing different sorts of hypotheses. 3 THE COGNITIVE ENGENEER'S TASK: to provide the user a friendly interface We will describe here a system under development, whose major goals are: * O '   t provide an environment whtch allows communication between a learner (student) and an expert (in our case the system); * O  '  ' t s~mulate the mformatton-processmg aspect of natural learning, i.e., the inductive learning of grammatical rules to generate sentences in French. * to allow teachers and psychologists to test various theories."
C86-1133,FROM STRUCTURE TO PROCESS: Computer-assisted teaching of various strategies for generating pronoun constructions in {F}rench:,1986,3,7,1,1,33495,michael zock,Coling 1986 Volume 1: The 11th International Conference on Computational Linguistics,0,"This paper describes an implemented tutoring system (2), designed to help students to generate clitic-constructions in French, While showing various ways of converting a given meaning structure into its corresponding surface expression, the system helps not only to discover what data to process but also how this information processing should take place. In other words, we are concerned with efficiency in verbal planning (performance).Recognizing that the same result can be obtained by various methods, the student should find out which one is best suited to the circumstances (what is known, task demands etc.). Informational states, hence the processor's needs, may vary to a great extent, as may his strategies or cognitive styles. In consequence, in order to become an efficient processor, the student has to acquire not only STRUCTURAL or RULE-KNOWLEDGE but also PROCEDURAL-KNOWLEDGE (skill).With this in mind we have designed three modules in order to foster a reflective, experimental attitude in the learner, helping him to discover insightfully the most efficient strategy."
