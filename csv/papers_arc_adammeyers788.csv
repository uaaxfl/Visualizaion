2021.nllp-1.16,Legal Terminology Extraction with the Termolator,2021,-1,-1,3,0,3080,nhi pham,Proceedings of the Natural Legal Language Processing Workshop 2021,0,"Domain-specific terminology is ubiquitous in legal documents. Despite potential utility in populating glossaries and ontologies or as arguments in information extraction and document classification tasks, there has been limited work done for legal terminology extraction. This paper describes some work to remedy this omission. In the described research, we make some modifications to the Termolator, a high-performing, open-source terminology extractor which has been tuned to scientific articles. Our changes are designed to improve the Termolator{'}s results when applied to United States Supreme Court decisions. Unaltered and using the recommended settings, the original Termolator provides a list of terminology with a precision of 23{\%} and 25{\%} for the categories of economic activity (development set) and criminal procedures (test set) respectively. These were the most frequently occurring broad issues in Washington University in St. Louis Database corpus, a database of Supreme Court decisions that have been manually classified by topic. Our contribution includes the introduction of several legal domain-specific filtration steps and changes to the web search relevance score; each incrementally improved precision culminating in a combined precision of 63{\%} and 65{\%}. We also evaluated the baseline version of the Termolator on more specific subcategories and on broad issues with fewer cases. Our results show that a narrowed scope as well as smaller document numbers significantly lower the precision. In both cases, the modifications to the Termolator improve precision."
W14-6002,Jargon-Term Extraction by Chunking,2014,20,4,1,1,3082,adam meyers,Proceedings of the {COLING} Workshop on Synchronic and Diachronic Approaches to Analyzing Technical Language,0,"NLP definitions of Terminology are usually application-dependent. IR terms are noun sequences that characterize topics. Terms can also be arguments for relations like abbreviation, definition or IS-A. In contrast, this paper explores techniques for extracting terms fitting a broader definition: noun sequences specific to topics and not well-known to naive adults. We describe a chunkingbased approach, an evaluation, and applications to non-topic-specific relation extraction."
he-meyers-2014-corpus,Corpus and Method for Identifying Citations in Non-Academic Text,2014,11,0,2,0.710492,12154,yifan he,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"We attempt to identify citations in non-academic text such as patents. Unlike academic articles which often provide bibliographies and follow consistent citation styles, non-academic text cites scientific research in a more ad-hoc manner. We manually annotate citations in 50 patents, train a CRF classifier to find new citations, and apply a reranker to incorporate non-local information. Our best system achieves 0.83 F-score on 5-fold cross validation."
meyers-etal-2014-annotating,Annotating Relations in Scientific Articles,2014,16,3,1,1,3082,adam meyers,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"Relations (ABBREVIATE, EXEMPLIFY, ORIGINATE, REL{\_}WORK, OPINION) between entities (citations, jargon, people, organizations) are annotated for PubMed scientific articles. We discuss our specifications, pre-processing and evaluation"
W13-1103,A Preliminary Study of Tweet Summarization using Information Extraction,2013,24,21,3,0,4068,wei xu,Proceedings of the Workshop on Language Analysis in Social Media,0,"Although the ideal length of summaries differs greatly from topic to topic on Twitter, previous work has only generated summaries of a pre-fixed length. In this paper, we propose an event-graph based method using information extraction techniques that is able to create summaries of variable length for different topics. In particular, we extend the Pageranklike ranking algorithm from previous work to partition event graphs and thereby detect finegrained aspects of the event to be summarized. Our preliminary results show that summaries created by our method are more concise and news-worthy than SumBasic according to human judges. We also provide a brief survey of datasets and evaluation design used in previous work to highlight the need of developing a standard evaluation for automatic tweet summarization task."
R13-1052,Towards Fine-grained Citation Function Classification,2013,15,16,3,0,1813,xiang li,Proceedings of the International Conference Recent Advances in Natural Language Processing {RANLP} 2013,0,"We look into the problem of recognizing citation functions in scientific literature, trying to reveal authorsxe2x80x99 rationale for citing a particular article. We introduce an annotation scheme to annotate citation functions in scientific papers with coarse-to-fine-grained categories, where the coarse-grained annotation roughly corresponds to citation sentiment and the finegrained annotation reveals more about citation functions. We implement a Maximum Entropy-based system trained on annotated data under this scheme to automatically classify citation functions in scientific literature. Using combined lexical and syntactic features, our system achieves the F-measure of 67%."
R13-1060,Contrasting and Corroborating Citations in Journal Articles,2013,10,6,1,1,3082,adam meyers,Proceedings of the International Conference Recent Advances in Natural Language Processing {RANLP} 2013,0,Automatic recognition of CORROBORATE and CONTRAST relations between citations may enhance citation analysis. We describe a system that identifies these citation relations using predicate/argument and discourse structures.
W11-1010,Improving {MT} Word Alignment Using Aligned Multi-Stage Parses,2011,31,1,1,1,3082,adam meyers,"Proceedings of Fifth Workshop on Syntax, Semantics and Structure in Statistical Translation",0,We use hand-coded rules and graph-aligned logical dependencies to reorder English text towards Chinese word order. We obtain a 1.5% higher F-score for Giza compared to running with unprocessed text. We describe this research and its implications for SMT.
W09-3019,Transducing Logical Relations from Automatic and Manual {GLARF},2009,16,1,1,1,3082,adam meyers,Proceedings of the Third Linguistic Annotation Workshop ({LAW} {III}),0,"GLARF relations are generated from treebank and parses for English, Chinese and Japanese. Our evaluation of system output for these input types requires consideration of multiple correct answers."
W09-2423,"Automatic Recognition of Logical Relations for {E}nglish, {C}hinese and {J}apanese in the {GLARF} Framework",2009,30,6,1,1,3082,adam meyers,Proceedings of the Workshop on Semantic Evaluations: Recent Achievements and Future Directions ({SEW}-2009),0,"We present GLARF, a framework for representing three linguistic levels and systems for generating this representation. We focus on a logical level, like LFG's F-structure, but compatible with Penn Treebanks. While less finegrained than typical semantic role labeling approaches, our logical structure has several advantages: (1) it includes all words in all sentences, regardless of part of speech or semantic domain; and (2) it is easier to produce accurately. Our systems achieve 90% for English/Japanese News and 74.5% for Chinese News -- these F-scores are nearly the same as those achieved for treebank-based parsing."
W09-1201,The {C}o{NLL}-2009 Shared Task: Syntactic and Semantic Dependencies in Multiple Languages,2009,26,269,7,0,17503,jan hajivc,Proceedings of the Thirteenth Conference on Computational Natural Language Learning ({C}o{NLL} 2009): Shared Task,0,"For the 11th straight year, the Conference on Computational Natural Language Learning has been accompanied by a shared task whose purpose is to promote natural language processing applications and evaluate them in a standard setting. In 2009, the shared task was dedicated to the joint parsing of syntactic and semantic dependencies in multiple languages. This shared task combines the shared tasks of the previous five years under a unique dependency-based formalism similar to the 2008 task. In this paper, we define the shared task, describe how the data sets were created and show their quantitative properties, report the results and summarize the approaches of the participating systems."
P09-1048,"Who, What, When, Where, Why? Comparing Multiple Approaches to the Cross-Lingual 5{W} Task",2009,23,20,10,0,43862,kristen parton,Proceedings of the Joint Conference of the 47th Annual Meeting of the {ACL} and the 4th International Joint Conference on Natural Language Processing of the {AFNLP},1,"Cross-lingual tasks are especially difficult due to the compounding effect of errors in language processing and errors in machine translation (MT). In this paper, we present an error analysis of a new cross-lingual task: the 5W task, a sentence-level understanding task which seeks to return the English 5W's (Who, What, When, Where and Why) corresponding to a Chinese sentence. We analyze systems that we developed, identifying specific problems in language processing and MT that cause errors. The best cross-lingual 5W system was still 19% worse than the best monolingual 5W system, which shows that MT significantly degrades sentence-level understanding. Neither source-language nor target-language analysis was able to circumvent problems in MT, although each approach had advantages relative to the other. A detailed error analysis across multiple systems suggests directions for future research on the problem."
N09-1017,The Role of Implicit Argumentation in Nominal {SRL},2009,16,19,3,0,37464,matthew gerber,Proceedings of Human Language Technologies: The 2009 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics,0,"Nominals frequently surface without overtly expressed arguments. In order to measure the potential benefit of nominal SRL for downstream processes, such nominals must be accounted for. In this paper, we show that a state-of-the-art nominal SRL system with an overall argument F1 of 0.76 suffers a performance loss of more than 9% when nominals with implicit arguments are included in the evaluation. We then develop a system that takes implicit argumentation into account, improving overall performance by nearly 5%. Our results indicate that the degree of implicit argumentation varies widely across nominals, making automated detection of implicit argumentation an important step for nominal SRL."
W08-2121,The {C}o{NLL} 2008 Shared Task on Joint Parsing of Syntactic and Semantic Dependencies,2008,34,372,3,0,673,mihai surdeanu,{C}o{NLL} 2008: Proceedings of the Twelfth Conference on Computational Natural Language Learning,0,"The Conference on Computational Natural Language Learning is accompanied every year by a shared task whose purpose is to promote natural language processing applications and evaluate them in a standard setting. In 2008 the shared task was dedicated to the joint parsing of syntactic and semantic dependencies. This shared task not only unifies the shared tasks of the previous four years under a unique dependency-based formalism, but also extends them significantly: this year's syntactic dependencies include more information such as named-entity boundaries; the semantic dependencies model roles of both verbal and nominal predicates. In this paper, we define the shared task and describe how the data sets were created. Furthermore, we report and analyze the results and describe the approaches of the participating systems."
W07-1529,Shared Corpora Working Group Report,2007,8,1,1,1,3082,adam meyers,Proceedings of the Linguistic Annotation Workshop,0,"We seek to identify a limited amount of representative corpora, suitable for annotation by the computational linguistics annotation community. Our hope is that a wide variety of annotation will be undertaken on the same corpora, which would facilitate: (1) the comparison of annotation schemes; (2) the merging of information represented by various annotation schemes; (3) the emergence of NLP systems that use information in multiple annotation schemes; and (4) the adoption of various types of best practice in corpus annotation. Such best practices would include: (a) clearer demarcation of phenomena being annotated; (b) the use of particular test corpora to determine whether a particular annotation task can feasibly achieve good agreement scores; (c) The use of underlying models for representing annotation content that facilitate merging, comparison, and analysis; and (d) To the extent possible, the use of common annotation categories or a mapping among categories for the same phenomenon used by different annotation groups.n n This study will focus on the problem of identifying such corpora as well as the suitability of two candidate corpora: the Open portion of the American National Corpus (Ide and Macleod, 2001; Ide and Suderman, 2004) and the Controversial portions of the WikipediaXML corpus (Denoyer and Gallinari, 2006)."
W06-0606,Annotation Compatibility Working Group Report,2006,28,2,1,1,3082,adam meyers,Proceedings of the Workshop on Frontiers in Linguistically Annotated Corpora 2006,0,"This report explores the question of compatibility between annotation projects including translating annotation formalisms to each other or to common forms. Compatibility issues are crucial for systems that use the results of multiple annotation projects. We hope that this report will begin a concerted effort in the field to track the compatibility of annotation schemes for part of speech tagging, time annotation, treebanking, role labeling and other phenomena."
W05-0301,Introduction to {F}rontiers in {C}orpus {A}nnotation {II}: {P}ie in the {S}ky,2005,16,2,1,1,3082,adam meyers,Proceedings of the Workshop on Frontiers in Corpus Annotations {II}: Pie in the Sky,0,The Frontiers in Corpus Annotation workshops are opportunities to discuss the state of the art of corpus annotation in computational linguistics. Corpus annotation has pushed the enitre field in new directions by providing new task definitions and new standards of analysis. At the first Frontiers in Corpus Annotation workshop at HLT-NAACL 2004 we compared assumptions underlying different annotation projects in light of both multilingual applications and the pursuit of merged representations that incorporate the result of various annotation projects.
W05-0302,"Merging {P}rop{B}ank, {N}om{B}ank, {T}ime{B}ank, {P}enn {D}iscourse {T}reebank and Coreference",2005,21,21,2,0,993,james pustejovsky,Proceedings of the Workshop on Frontiers in Corpus Annotations {II}: Pie in the Sky,0,"Many recent annotation efforts for English have focused on pieces of the larger problem of semantic annotation, rather than initially producing a single unified representation. This paper discusses the issues involved in merging four of these efforts into a unified linguistic structure: PropBank, NomBank, the Discourse Treebank and Coreference Annotation undertaken at the University of Essex. We discuss resolving overlapping and conflicting annotation as well as how the various annotation schemes can reinforce each other to produce a representation that is greater than the sum of its parts."
W04-2701,Introduction to Frontiers in Corpus Annotation,2004,7,0,1,1,3082,adam meyers,Proceedings of the Workshop Frontiers in Corpus Annotation at {HLT}-{NAACL} 2004,0,None
W04-2705,The {N}om{B}ank Project: An Interim Report,2004,11,245,1,1,3082,adam meyers,Proceedings of the Workshop Frontiers in Corpus Annotation at {HLT}-{NAACL} 2004,0,None
W04-0413,{NP}-External Arguments: A Study of Argument Sharing in {E}nglish,2004,9,21,1,1,3082,adam meyers,Proceedings of the Workshop on Multiword Expressions: Integrating Processing,0,"We explore some predicate-argument-structure phenomena in the context of the NomBank annotation project for English. Support verbs ( They completed the acquisition), transparent nouns ( His first batch of questions), prepositions (At Mary's request, John left the room ) and other lexical items can link arguments of a noun N to positions outside of the NP headed by N. In these examples, They is an argument of acquisition, His is an argument of questions and John left the room is an argument of request. In most cases, these NP-external arguments are linked to a multiword expression (MWE) consisting of the noun predicate and (at least) one other item: a support verb, transparent noun, preposition, etc. This paper discusses properties of these constructions and how they interact. For example, in Disney made dozens of attempts to acquire Apple, Disney is an argument of acquire, due to linking properties of the support construction make  attempt and the quantificational noun dozens."
meyers-etal-2004-cross,The Cross-Breeding of Dictionaries,2004,7,33,1,1,3082,adam meyers,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"Especially for English, the number of hand-coded electronic resources available to the Natural Language Processing Community keeps growing: annotated corpora, treebanks, lexicons, wordnets, etc. Unfortunately, initial funding for such projects is much easier to obtain than the additional funding needed to enlarge or improve upon such resources. Thus once one proves the usefulness of a resource, it is difficult to make that resource reach its full potential. We discuss techniques for combining dictionary resources and producing others by semi-automatic means. The resources we created using these techniques have become an integral part of our work on NomBank, a project with the goal of annotating noun arguments in the Penn Treebank II corpus (PTB)."
meyers-etal-2004-annotating,Annotating Noun Argument Structure for {N}om{B}ank,2004,4,83,1,1,3082,adam meyers,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"When complete, NomBank will provide annotation of noun arguments in Penn Treebank II (PTB). In PropBank, University of Pennsylvania annotators provide similar information for verbs. Given nominalization/verb mappings, the combination of NomBank and PropBank allows for generalization of arguments across parts of speech. This paper describes our annotation task including factors which make assigning role labels to noun arguments a challenging task."
C04-1109,Discriminative Slot Detection Using Kernel Methods,2004,15,8,2,0,21189,shubin zhao,{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics,0,"Most traditional information extraction approaches are generative models that assume events exist in text in certain patterns and these patterns can be regenerated in various ways. These assumptions limited the syntactic clues being considered for finding an event and confined these approaches to a particular syntactic level. This paper presents a discriminative framework based on kernel SVMs that takes into account different levels of syntactic information and automatically identifies the appropriate clues. Kernels are used to represent certain levels of syntactic structure and can be combined in principled ways as input for an SVM. We will show that by combining a low level sequence kernel with a high level kernel on a GLARF dependency graph, the new approach outperformed a good rule-based system on slot filler detection for MUC-6."
meyers-etal-2002-formal,Formal Mechanisms for Capturing Regularizations,2002,20,3,1,1,3082,adam meyers,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"While initial treebanks and treebank parsers primarily involved surface analysis, recent work focuses on predicate argument (PA) structure. PA structure provides means to regularize variants (e.g., actives/passives) of sentences so that individual patterns may have better coverage (in MT, QA, IE, etc.), offsetting the sparse data problem. We encode such PA information in the GLARF framework. Our previous work discusses procedures for producing GLARF from treebanks and parsed data. This paper shows that GLARF is particularly well-suited for capturing regularization. We discuss crucial components of GLARF and demonstrate that other frameworks would require equivalent components to adequately express regularization."
C00-1078,Chart-Based Transfer Rule Application in Machine Translation,2000,11,18,1,1,3082,adam meyers,{COLING} 2000 Volume 1: The 18th International Conference on Computational Linguistics,0,"Transfer-based Machine Translation systems require a procedure for choosing the set of transfer rules for generating a target language translation from a given source language sentence. In an MT system with many competing transfer rules, choosing the best set of transfer rules for translation may involve the evaluation of an explosive number of competing sets. We propose a solution to this problem based on current best-first chart parsing algorithms."
W98-0604,Using {NOMLEX} to Produce Nominalization Patterns for Information Extraction,1998,9,33,1,1,3082,adam meyers,The Computational Treatment of Nominals,0,None
P98-2139,Deriving Transfer Rules from Dominance-Preserving Alignments,1998,9,24,1,1,3082,adam meyers,"36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 2",0,None
C98-2134,Deriving Transfer Rules from Dominance-Preserving Alignments,1998,9,24,1,1,3082,adam meyers,{COLING} 1998 Volume 2: The 17th International Conference on Computational Linguistics,0,None
meyers-etal-1998-multilingual,A multilingual procedure for dictionary-based sentence alignment,1998,25,17,1,1,3082,adam meyers,Proceedings of the Third Conference of the Association for Machine Translation in the Americas: Technical Papers,0,"This paper describes a sentence alignment technique based on a machine readable dictionary. Alignment takes place in a single pass through the text, based on the scores of matches between pairs of source and target sentences. Pairings consisting of sets of matches are evaluated using a version of the Gale-Shapely solution to the stable marriage problem. An algorithm is described which can handle N-to-1 (or 1-to-N) matches, for n {\mbox{$\geq$}} 0, i.e., deletions, 1-to-1 (including scrambling), and 1-to-many matches. A simple frequency based method for acquiring supplemental dictionary entries is also discussed. We achieve high quality alignments using available bilingual dictionaries, both for closely related language pairs (Spanish/English) and more distantly related pairs (Japanese/English)."
C96-1078,Alignment of Shared Forests for Bilingual Corpora,1996,14,56,1,1,3082,adam meyers,{COLING} 1996 Volume 1: The 16th International Conference on Computational Linguistics,0,"Research in example-based machine translation (EBMT) has been hampered by the lack of efficient tree alignment algorithms for bilingual corpora. This paper describes an alignment algorithm for EBMT whose running time is quadratic in the size of the input parse trees. The algorithm uses dynamic programming to score all possible matching nodes between structure-sharing trees or forests. We describe the algorithm, various optimizations, and our implementation."
C96-1080,The Influence of Tagging on the Classification of Lexical Complements,1996,1,3,2,0.5,51384,catherine macleod,{COLING} 1996 Volume 1: The 16th International Conference on Computational Linguistics,0,"A large corpus (about 100 MB of text) was selected and examples of 750 frequently occurring verbs were tagged with their complement class as defined by a large computational syntactic dictionary, COMLEX Syntax. This tagging task led to the refinement of already existing classes and to the addition of classes that had previously not been defined. This has resulted in the enrichment and improvement of the original COMLEX Syntax dictionary. Tagging also provides statistical data which will allow users to select more common complements of a particular verb and ignore rare usage. We discuss below some of the problems encountered in tagging and their resolution."
H94-1003,The {C}omlex Syntax Project: The First Year,1994,7,13,3,1,51384,catherine macleod,"{H}uman {L}anguage {T}echnology: Proceedings of a Workshop held at {P}lainsboro, {N}ew {J}ersey, {M}arch 8-11, 1994",0,"We describe the design of Comlex Syntax, a computational lexicon providing detailed syntactic information for approximately 38,000 English headwords. We consider the types of errors which arise in creating such a lexicon, and how such errors can be measured and controlled."
C94-1042,Comlex Syntax: Building a Computational Lexicon,1994,8,194,3,0,10781,ralph grishman,{COLING} 1994 Volume 1: The 15th {I}nternational {C}onference on {C}omputational {L}inguistics,0,"We describe the design of Comlex Syntax, a computational lexicon providing detailed syntactic information for approximately 38,000 English headwords. We consider the types of errors which arise in creating such a lexicon, and how such errors can be measured and controlled."
P93-1014,A Unification-Based Parser for Relational Grammar,1993,11,6,2,0,52765,david johnson,31st Annual Meeting of the Association for Computational Linguistics,1,"We present an implemented unification-based parser for relational grammars developed within the stratified feature grammar (SFG) framework, which generalizes Kasper-Rounds logic to handle relational grammar analyses. We first introduce the key aspects of SFG and a lexicalized, graph-based variant of the framework suitable for implementing relational grammars. We then describe a head-driven chart parser for lexicalized SFG. The basic parsing operation is essentially ordinary feature-structure unification augmented with an operation of label unification to build the stratified features characteristic of SFG."
