1988.tmi-1.12,T87-1042,0,0.0709993,"Missing"
1988.tmi-1.12,C88-1053,1,0.844309,"can be read as argument positions relative to the predicate &apos;give&apos;. As for the (-i) labels (&quot;inverse arguments&quot;), they are a notational device that allows us to simultaneously represent predicate-argument relations as well as subordination relations. For instance the &apos;in&apos; node has two arguments: the first (-1) being the giving event, the second (2) being the location of this event. The &quot;inverse&quot; notation for the first argument is a way of making the semantic structure reminiscent of the fact that &quot;in Edmonton&quot; is syntactically a dependent of &apos;give&apos;. (For a justification of this approach, see &lt;Isabelle et al., 1988&gt;). 2. REVERSIBLE LOGIC GRAMMARS. 2.1 Goals. Consider once again the anasynt relation (for specificity, we shall discuss the source analysis/synthesis relation, but everything will apply mutatis mutandis to the target relation). The declarative reading of the anasynt_s relation is just that it is a set of triples of the form: &lt;T,SurfSyn,Sem &gt;. From a computational perspective, the challenge posed by reversibility is to write a program P having the following properties: - inputting a specific text T to the program will result in the output of every Sem such that ∃SurfSyn anasynt(T,SurfSyn,Sem)"
1988.tmi-1.12,J81-4003,0,0.209026,"Missing"
1988.tmi-1.12,E87-1027,0,0.0582897,"Missing"
1993.tmi-1.17,C88-1053,1,\N,Missing
1993.tmi-1.17,C90-3044,0,\N,Missing
1993.tmi-1.17,P91-1022,0,\N,Missing
2003.jeptalnrecital-poster.14,W00-1404,1,0.892008,"Missing"
2003.jeptalnrecital-poster.14,C02-1128,1,0.835828,"Missing"
2003.jeptalnrecital-poster.14,P98-2173,0,0.0482442,"Missing"
2005.jeptalnrecital-long.24,J93-2003,0,0.0126525,"Missing"
2005.jeptalnrecital-long.24,P01-1030,1,0.892376,"Missing"
2005.jeptalnrecital-long.24,P04-1064,1,0.882028,"Missing"
2005.jeptalnrecital-long.24,P99-1041,0,0.0877922,"Missing"
2005.jeptalnrecital-long.24,W02-1018,0,0.0264918,"Missing"
2005.jeptalnrecital-long.24,P00-1056,0,0.327309,"Missing"
2005.jeptalnrecital-long.24,J04-4002,0,0.0723566,"Missing"
2005.jeptalnrecital-long.24,W99-0604,0,0.111557,"Missing"
2005.jeptalnrecital-long.24,P03-1021,0,0.0362064,"Missing"
2005.jeptalnrecital-long.24,P02-1040,0,0.072645,"Missing"
2005.jeptalnrecital-long.24,N03-2036,0,0.0275543,"Missing"
2009.eamt-1.5,P07-1111,0,0.0306719,"from MT evaluation, in CE reference translations are not available to compute the quality estimates. Therefore, CE approaches cannot be directly compared to the several recently proposed metrics for sentence-level MT evaluation that also use machine learning algorithms and sometimes similar features to those used in CE. For example, (Kulesza and Shieber, 2004) use Support Vector Machines (SVM) with n-gram precision and other reference-based features to predict if a sentence is produced by a human translator (presumably good) or by a MT system (presumably bad) (human-likeness classification). (Albrecht and Hwa, 2007a) rely on regression-based algorithms and features, like string and syntax matching of the translation over the corresponding references, to measure the quality of sentences as a continuous score. In (Albrecht and Hwa, 2007b), pseudo-references (produced by other MT systems) are used instead of human references, but this scenario with multiple MT systems is different from that of CE. The most comprehensive study on CE at the sentence level to date is that of (Blatz et al., 2004). Multi-layer perceptrons and Naive Bayes are trained on 91 features extracted for translations tagged according to"
2009.eamt-1.5,W06-3114,0,0.0491798,"Missing"
2009.eamt-1.5,P07-1038,0,0.105762,"from MT evaluation, in CE reference translations are not available to compute the quality estimates. Therefore, CE approaches cannot be directly compared to the several recently proposed metrics for sentence-level MT evaluation that also use machine learning algorithms and sometimes similar features to those used in CE. For example, (Kulesza and Shieber, 2004) use Support Vector Machines (SVM) with n-gram precision and other reference-based features to predict if a sentence is produced by a human translator (presumably good) or by a MT system (presumably bad) (human-likeness classification). (Albrecht and Hwa, 2007a) rely on regression-based algorithms and features, like string and syntax matching of the translation over the corresponding references, to measure the quality of sentences as a continuous score. In (Albrecht and Hwa, 2007b), pseudo-references (produced by other MT systems) are used instead of human references, but this scenario with multiple MT systems is different from that of CE. The most comprehensive study on CE at the sentence level to date is that of (Blatz et al., 2004). Multi-layer perceptrons and Naive Bayes are trained on 91 features extracted for translations tagged according to"
2009.eamt-1.5,W04-3250,0,0.211486,"Missing"
2009.eamt-1.5,2004.tmi-1.8,0,0.0221387,"l score, it sould also be viewed as a proxy to some automatic or manual metric, like NIST (Doddington, 2002) or 1-5 adequacy. Other estimates include the time that would be necessary to post-edit such translation, or simply a “good” / “bad” indicator. Differently from MT evaluation, in CE reference translations are not available to compute the quality estimates. Therefore, CE approaches cannot be directly compared to the several recently proposed metrics for sentence-level MT evaluation that also use machine learning algorithms and sometimes similar features to those used in CE. For example, (Kulesza and Shieber, 2004) use Support Vector Machines (SVM) with n-gram precision and other reference-based features to predict if a sentence is produced by a human translator (presumably good) or by a MT system (presumably bad) (human-likeness classification). (Albrecht and Hwa, 2007a) rely on regression-based algorithms and features, like string and syntax matching of the translation over the corresponding references, to measure the quality of sentences as a continuous score. In (Albrecht and Hwa, 2007b), pseudo-references (produced by other MT systems) are used instead of human references, but this scenario with mu"
2009.eamt-1.5,C04-1046,0,0.931944,"ced by a human translator (presumably good) or by a MT system (presumably bad) (human-likeness classification). (Albrecht and Hwa, 2007a) rely on regression-based algorithms and features, like string and syntax matching of the translation over the corresponding references, to measure the quality of sentences as a continuous score. In (Albrecht and Hwa, 2007b), pseudo-references (produced by other MT systems) are used instead of human references, but this scenario with multiple MT systems is different from that of CE. The most comprehensive study on CE at the sentence level to date is that of (Blatz et al., 2004). Multi-layer perceptrons and Naive Bayes are trained on 91 features extracted for translations tagged according to NIST and word error rate. Scores are thresholded to label the 5th or (Quirk, 2004) uses linear regression with features similar to those used in (Blatz et al., 2004) to estimate sentence translation quality considering also a small set of translations manually labeled as correct / incorrect. Models trained on this small dataset (350 sentences) outperform those trained on a larger set of automatically labeled data. Given the small amount of manually annotated data and the fact tha"
2009.eamt-1.5,P02-1040,0,0.0980737,"system and language-pair, it is not clear how results can be generalized. The contribution of different features is not investigated. (Gamon et al., 2005) train an SVM classifier using a number of linguistic features (grammar productions, semantic relationships, etc.) extracted from machine and human translations to distinguish between human and machine translations (human-likeness classification). The predictions of SVM, when combined to a 4-gram language model score, only slightly increase the correlation with human judgements and such correlation is still lower than that achieved by BLEU (Papineni et al., 2002). Moreover, as shown in (Albrecht and Hwa, 2007a), high human-likeness does not necessarily imply good MT quality. Besides estimating the quality of machine translations directly, we use a larger set of features, which are meant to cover many more aspects of the translations. These features are all resource-independent, allowing to generalize this method across translations produced by several MT systems and for different language-pairs. Although our goal is very similar to that of (Blatz et al., 2004; Quirk, 2004), it is not possible to compare our results to these previous works, since we es"
2009.eamt-1.5,W08-0309,0,0.0199833,"Missing"
2009.eamt-1.5,2007.tmi-papers.19,0,0.0496208,"Missing"
2009.eamt-1.5,quirk-2004-training,0,0.55578,"yntax matching of the translation over the corresponding references, to measure the quality of sentences as a continuous score. In (Albrecht and Hwa, 2007b), pseudo-references (produced by other MT systems) are used instead of human references, but this scenario with multiple MT systems is different from that of CE. The most comprehensive study on CE at the sentence level to date is that of (Blatz et al., 2004). Multi-layer perceptrons and Naive Bayes are trained on 91 features extracted for translations tagged according to NIST and word error rate. Scores are thresholded to label the 5th or (Quirk, 2004) uses linear regression with features similar to those used in (Blatz et al., 2004) to estimate sentence translation quality considering also a small set of translations manually labeled as correct / incorrect. Models trained on this small dataset (350 sentences) outperform those trained on a larger set of automatically labeled data. Given the small amount of manually annotated data and the fact that translations come from a single MT system and language-pair, it is not clear how results can be generalized. The contribution of different features is not investigated. (Gamon et al., 2005) train"
2009.eamt-1.5,2005.eamt-1.35,0,0.00583991,"ime. In both cases, none of the features is found to be significantly more relevant than the others. This seems to point out that many of the features are redundant, but this aspect is not investigated. and are therefore independent on MT systems. In the remaining of this paper we first discuss the previous work on CE for MT (Section 2), to then describe our experimental setting (Section 3) and method (Section 4) and present and discuss the results obtained (Sections 5 and 6). 2 Related work Early work on CE for MT aimed at estimating the quality at the word level (Gandrabur and Foster, 2003; Ueffing and Ney, 2005; Kadri and Nie, 2006). Sentence-level CE appears to be a more natural set-up for practical applications of MT. One should consider as real-world scenario for CE an MT system in use, which would provide to the user, together with each sentence translation, an estimate of its quality. If this estimate is in the form a numerical score, it sould also be viewed as a proxy to some automatic or manual metric, like NIST (Doddington, 2002) or 1-5 adequacy. Other estimates include the time that would be necessary to post-edit such translation, or simply a “good” / “bad” indicator. Differently from MT e"
2009.eamt-1.5,2005.eamt-1.15,0,0.544236,"l the 5th or (Quirk, 2004) uses linear regression with features similar to those used in (Blatz et al., 2004) to estimate sentence translation quality considering also a small set of translations manually labeled as correct / incorrect. Models trained on this small dataset (350 sentences) outperform those trained on a larger set of automatically labeled data. Given the small amount of manually annotated data and the fact that translations come from a single MT system and language-pair, it is not clear how results can be generalized. The contribution of different features is not investigated. (Gamon et al., 2005) train an SVM classifier using a number of linguistic features (grammar productions, semantic relationships, etc.) extracted from machine and human translations to distinguish between human and machine translations (human-likeness classification). The predictions of SVM, when combined to a 4-gram language model score, only slightly increase the correlation with human judgements and such correlation is still lower than that achieved by BLEU (Papineni et al., 2002). Moreover, as shown in (Albrecht and Hwa, 2007a), high human-likeness does not necessarily imply good MT quality. Besides estimating"
2009.eamt-1.5,W03-0413,0,0.0983171,"l features except one at a time. In both cases, none of the features is found to be significantly more relevant than the others. This seems to point out that many of the features are redundant, but this aspect is not investigated. and are therefore independent on MT systems. In the remaining of this paper we first discuss the previous work on CE for MT (Section 2), to then describe our experimental setting (Section 3) and method (Section 4) and present and discuss the results obtained (Sections 5 and 6). 2 Related work Early work on CE for MT aimed at estimating the quality at the word level (Gandrabur and Foster, 2003; Ueffing and Ney, 2005; Kadri and Nie, 2006). Sentence-level CE appears to be a more natural set-up for practical applications of MT. One should consider as real-world scenario for CE an MT system in use, which would provide to the user, together with each sentence translation, an estimate of its quality. If this estimate is in the form a numerical score, it sould also be viewed as a proxy to some automatic or manual metric, like NIST (Doddington, 2002) or 1-5 adequacy. Other estimates include the time that would be necessary to post-edit such translation, or simply a “good” / “bad” indicator"
2009.eamt-1.5,I08-1042,0,\N,Missing
2009.mtsummit-papers.17,N07-2006,0,0.12505,"several important aspects relative to this prior art.1 First, rather than filtering on the basis of p-value, we filter based on a different measure of statistical dependence, namely the so-called “Noise” introduced in (Moore, 2004). This measure is in principle superior to the simpler p-value for the situation at hand: while the p-value estimates the statistical dependence between the source-phrase and the target-phrase, based on the corpus statistics associated with this individual bi-phrase, the Noise 1 There are some other approaches to pruning bi-phrases, such as the method described in (Eck et al., 2007), where pruning is determined by bi-phrase usage statistics during decoding. Here our focus is on techniques based on statistical significance tests. takes into account this pair in the context of all other bi-phrases, which is in theory better statistically motivated in the context of large bi-phrase libraries, as is the case in SMT. Second, we show that, when we distinguish different classes of bi-phrases according to their complexity (roughly, their size), then thresholding on Noise makes different predictions than when thresholding on p-value and produces better SMT results while permittin"
2009.mtsummit-papers.17,D07-1103,0,0.47127,"nguistic patterns. However such bi-phrases may also lead to larger, more combinatorial, tables: while the potential number of contiguous phrases in a sentence grows quadratically in the length of the sentence, that of non-contiguous phrases grows exponentially. It is especially important to control the proliferation of bi-phrases in this situation, in order to reduce the size of the bi-phrase table and also to improve translation performance by removing “spurious” biphrases which do not have good predictive linguistic value. Working in their case with a system based on contiguous bi-phrases, (Johnson et al., 2007) were able to prune many bi-phrases out of the table without negatively impacting the end results, while at the same time improving the decoding speed. Their approach was to assess the strength of the statistical dependence between the source and the target of the biphrase, using a “p-value” measure based on a standard independence test, and to prune from the table those bi-phrases for which this strength was below a certain threshold. We innovate on several important aspects relative to this prior art.1 First, rather than filtering on the basis of p-value, we filter based on a different measu"
2009.mtsummit-papers.17,W04-3243,0,0.570955,"pacting the end results, while at the same time improving the decoding speed. Their approach was to assess the strength of the statistical dependence between the source and the target of the biphrase, using a “p-value” measure based on a standard independence test, and to prune from the table those bi-phrases for which this strength was below a certain threshold. We innovate on several important aspects relative to this prior art.1 First, rather than filtering on the basis of p-value, we filter based on a different measure of statistical dependence, namely the so-called “Noise” introduced in (Moore, 2004). This measure is in principle superior to the simpler p-value for the situation at hand: while the p-value estimates the statistical dependence between the source-phrase and the target-phrase, based on the corpus statistics associated with this individual bi-phrase, the Noise 1 There are some other approaches to pruning bi-phrases, such as the method described in (Eck et al., 2007), where pruning is determined by bi-phrase usage statistics during decoding. Here our focus is on techniques based on statistical significance tests. takes into account this pair in the context of all other bi-phras"
2009.mtsummit-papers.17,2001.mtsummit-papers.68,0,0.021991,"e corpus. We then conducted experiments in order to assess the impact on translation performance of the pruning threshold. In Figure 3 12 BLEU 0,4 - Log (Noise) 0,38 10 0,36 8 0,34 0,32 L1(log) L2(log) L3(log) L4(log) 6 0,3 BLEU 0,28 4 0,26 0,24 2 0,22 0,2 0 50000 100000 150000 200000 250000 300000 350000 400000 Figure 3: Translation performance relative to the level of pruning. below, we illustrate the case of the U 4 − g4 table, where the horizontal axis corresponds to the number of bi-phrases that are kept, and the vertical axis to the BLEU score that is obtained by the translation system (Papineni et al., 2001). We see that by keeping only the 100000 bi-phrases with the highest association scores, we obtain performance which is almost indistinguishable from the performances obtained by keeping up to 350000 bi-phrases. Second experiment: Pruning based on Noise with several complexity classes We now move to experiments where we actually use Noise as the pruning criterion, along with several complexity classes for computing it from raw association scores. In these experiments we take as our global bi-phrase table the table U 4 − g0, corresponding to bi-phrases obtained by combinations of up to 4 cepts,"
2009.mtsummit-papers.17,H05-1095,1,0.900141,"ables in several sub-classes according to their complexity, using Noise leads to improvements in BLEU score that are unreachable using pvalue, while allowing a similar amount of pruning of the phrase tables. 1 Motivation Currently, the most widely used Statistical Machine Translation systems are so-called “phrasebased” systems; they are based on tables of “biphrases”, that is, pairs of the form &lt;source-phrase, target-phrase&gt;, which are learned automatically from bilingual corpora (see (Lopez, 2008) for an overview). While most such systems use contiguous bi-phrases, we are using one, MATRAX, (Simard et al., 2005) that employs non-contiguous bi-phrases such as &lt;ne ... plus, does not ... anymore&gt;, which are better able to generalize over certain linguistic patterns. However such bi-phrases may also lead to larger, more combinatorial, tables: while the potential number of contiguous phrases in a sentence grows quadratically in the length of the sentence, that of non-contiguous phrases grows exponentially. It is especially important to control the proliferation of bi-phrases in this situation, in order to reduce the size of the bi-phrase table and also to improve translation performance by removing “spuri"
2010.amta-papers.31,W09-1114,0,0.102244,"Missing"
2010.amta-papers.31,D08-1023,0,0.0317471,"ied mode not including a language model, or in a full mode including one, in which case a heuristic beam-search is used. While we also employ overlapping biphrases here, we perform decoding and training using a sampling approach on a set of features including a language model and a distortion model. Sampling has also been used in the synchronous grammar paradigm (hierarchical models), for the training of synchronous grammars when Bayesian priors are given (Blunsom et al., 2009) and for estimating the partition function for a model using a synchronous grammar intersected with a language model (Blunsom and Osborne, 2008). 3 3.1 Sampling For Training and Decoding Overview Algorithm 1 gives an overview of the procedure used for training and decoding. The flow for training and decoding differs only in two places, which concern loading and updating the model parameters; otherwise exactly the same code can be used. The algorithm starts by initializing each source sentence with a gloss (choosing the most likely translation per source word). If the task is decoding, a previously trained model is loaded, while for training the model parameters are initialized. Starting from the glosses, an iterative Markov-Chain Mont"
2010.amta-papers.31,P09-1088,0,0.0123533,"slation model that does not incorporate a language model or distortion. Decoding is done through dynamic programming, either in the simplified mode not including a language model, or in a full mode including one, in which case a heuristic beam-search is used. While we also employ overlapping biphrases here, we perform decoding and training using a sampling approach on a set of features including a language model and a distortion model. Sampling has also been used in the synchronous grammar paradigm (hierarchical models), for the training of synchronous grammars when Bayesian priors are given (Blunsom et al., 2009) and for estimating the partition function for a model using a synchronous grammar intersected with a language model (Blunsom and Osborne, 2008). 3 3.1 Sampling For Training and Decoding Overview Algorithm 1 gives an overview of the procedure used for training and decoding. The flow for training and decoding differs only in two places, which concern loading and updating the model parameters; otherwise exactly the same code can be used. The algorithm starts by initializing each source sentence with a gloss (choosing the most likely translation per source word). If the task is decoding, a previo"
2010.amta-papers.31,W02-1001,0,0.00506116,"candidate preferred over y 0 by the objective function, and where η is a learning rate that is set differently in different variants of the method. The translation for the next iteration is sampled according to a transition distribution Q(y 0 |y). In our case, Q(y 0 |y) is zero for translations not in the neighborhood of y, and proportional to the current learnt model probability P (y 0 |x, Θ) otherwise (normalized by the sum of all neighbor probabilities). In preliminary experiments we tried several of the possibilities provided by FACTORIE for setting the learning rate (averaged perceptron (Collins, 2002), 1 Note that, while the neighborhood is local (per-sentence), the objective score is global (corpus-wide). This corresponds to a factor model of the corpus with shared parameters for sentence factors. Figure 1: Consistent (left) and inconsistent (right) pairs of biphrases. The x-axis (y-axis) denotes positions in the source (target) sentence. The squares indicate the spans of words covered on either side by the biphrases. MIRA (Crammer and Singer, 2003) and confidence weighted updates (Dredze et al., 2008)) and found that the averaged perceptron, which amounts to setting the learning rate to"
2010.amta-papers.31,D09-1107,0,0.13334,"hm 1: Training and decoding Related Work Arun et. al (2009) use operations in a nonoverlapping phrase-based setting and traditional features to obtain random samples of alignments, where translation samples are obtained by a form of marginalization that corresponds to “forgetting” the alignment and only outputting the target string. In contrast to our work, their approach is strongly connected to the traditional phrase-based setting, and is concerned with the question of whether sampling and marginalization can reach equally good translations as dynamic programming for the same type of model. Kääriäinen (2009) has developed a system for phrase-based translations using overlapping biphrases, which allows decoding to use a representation which is consistent with that used when heuristically extracting the biphrases from bilingual data, contrary to what is the case with standard phrase-based systems. Each biphrase is a feature, and biphrase parameters are estimated on the basis of maximizing the likelihood of a large bilingual corpus relative to a simplified translation model that does not incorporate a language model or distortion. Decoding is done through dynamic programming, either in the simplifie"
2010.amta-papers.31,P07-2045,0,0.00594016,"position on target side. biphrases: Two (alignment) biphrases are consistent if the matching criterion is the same for source and target side, otherwise they are inconsistent. Existence of (partial) overlap is used as the matching criterion. A biphrase is consistent with an alignment set, if it is consistent with all biphrases in this set, see Figure 1 for an example. For weighting the biphrases we resort to a heuristic similar to the conditional link probability scoring in (Moore, 2005). However, we use weights that can be read off directly from the phrase-table as used by the popular Moses (Koehn et al., 2007) pipeline: the phrasal and lexicalized biphrase probabilities P (f |e) and P (e|f ) are multiplied instead of using P (e, f ). Additionally we normalize the biphrase weights for length (lf and le ), using the geometric mean, in order not to penalize longer biphrases. This has also the effect of increased contiguity of alignments. The resulting biphrase weight is: q lf 3.4 q Plex (e|f )Pphr (e|f ) le Plex (f |e)Pphr (f |e) Neighborhood Operators At present, four operators are used to generate a neighborhood of the current translation: 1. Remove: For each target position the word at this positio"
2010.amta-papers.31,J00-2004,0,0.0144949,"many sparse features (e.g. one binary feature per biphrase) we would expect a confidence weighting scheme to perform better. 3.3 Phrase Alignment We call a phrase alignment a set of biphrases that express correspondences between spans of words in source and target sentences. In our case a phrase alignment is used for two purposes: first, to compute some features of a translation and secondly, for constructing part of the proposal neighborhood (proposed changes to current translation). We employ a greedy phrase alignment algorithm of source and target sentences similar to Competitive Linking (Melamed, 2000): first, biphrases2 that match on both source and target side are ordered by a heuristic weight (which does not depend on the model Θ). Then, biphrases are added to the alignment set, in descending order of their weight, if they are consistent with the current alignment set. Our notion of consistency allows for overlapping 2 We use a biphrase table extracted by the heuristics in a standard run of the Moses pipeline. 2. Insert: For each target position, if the trigram at this position is not present in the language model, a random word is inserted according to the trigram language model. Figure"
2010.amta-papers.31,H05-1011,0,0.00841497,"urce span is mapped using the internal word-alignment, the leftmost by choosing the point at the corresponding relative position on target side. biphrases: Two (alignment) biphrases are consistent if the matching criterion is the same for source and target side, otherwise they are inconsistent. Existence of (partial) overlap is used as the matching criterion. A biphrase is consistent with an alignment set, if it is consistent with all biphrases in this set, see Figure 1 for an example. For weighting the biphrases we resort to a heuristic similar to the conditional link probability scoring in (Moore, 2005). However, we use weights that can be read off directly from the phrase-table as used by the popular Moses (Koehn et al., 2007) pipeline: the phrasal and lexicalized biphrase probabilities P (f |e) and P (e|f ) are multiplied instead of using P (e, f ). Additionally we normalize the biphrase weights for length (lf and le ), using the geometric mean, in order not to penalize longer biphrases. This has also the effect of increased contiguity of alignments. The resulting biphrase weight is: q lf 3.4 q Plex (e|f )Pphr (e|f ) le Plex (f |e)Pphr (f |e) Neighborhood Operators At present, four operato"
2010.amta-papers.31,P02-1040,0,\N,Missing
2010.amta-papers.31,W05-0836,0,\N,Missing
2010.amta-papers.31,P08-1024,0,\N,Missing
2010.amta-papers.31,2009.eamt-smart.4,0,\N,Missing
2010.amta-papers.31,P91-1023,0,\N,Missing
2010.amta-papers.31,W11-2130,0,\N,Missing
2010.amta-papers.31,P06-1096,0,\N,Missing
2010.eamt-1.31,N06-1003,0,0.193211,"aspects of the process that generated them, such as the appropriateness of the replacement in the context of the specific source sentence, allowing for example reach to be preferred to strike or attack in replacing hit in “We hit the city at lunch time”. Dynamic and static biphrases compete during the search for an optimal translation. At training time, standard techniques such as MERT (Minimum Error Rate Training) (Och, 2003), which attempt to maximize automatic metrics like BLEU (Papineni et al., 2002) based on a bilingual corpus, are directly applicable. However, as has been discussed in (Callison-Burch et al., 2006; Mirkin et al., 2009), such automatic measures are poor indicators of improvements in translation quality in presence of semantic modifications of the kind we are considering here. Therefore, we perform the training and evaluation on the basis of human annotations. We use a form of active learning to focus the annotation effort on a small set of candidates which are useful for the training. Sentences containing OOV words represent a fairly small fraction of the sentences to be translated2 . Thus, to avoid human annotation of a large sample with relatively few cases of OOV words, for the purpo"
2010.eamt-1.31,W08-0309,0,0.0194641,"Missing"
2010.eamt-1.31,2005.mtsummit-papers.30,0,0.0118202,"sters”, where the rank between clusters is clear, but the elements inside each cluster are considered indistinguishable. The annotators are also asked to concentrate their judgment on the portions of the sentences which are affected by the different replacements. To cover potential cases of cognates, annotators can choose the actual OOV as the best “replacement”. Active sampling In order to keep the sample of candidate translations to be annotated for a given OOV source sentence small, but still informative for training, we adopt an active learning scheme (Settles, 2010; Haffari et al., 2009; Eck et al., 2005). We do not extract a priori a sample of translation candidates for each sentence in the OOV training set and ask the annotators to work on these samples — which would mean that they might have to compare candidates that have little chance of being selected by the end-model after training. Instead, This is an iterative process, with a slice of the OOV training set selected for each iteration. When sampling candidate translations (out of a given slice of the OOV training set) to be annotated in the next iteration, we use the translations produced by the model Λ ⊕ M obtained so far, after traini"
2010.eamt-1.31,N09-1047,0,0.0131136,"in a few distinct “clusters”, where the rank between clusters is clear, but the elements inside each cluster are considered indistinguishable. The annotators are also asked to concentrate their judgment on the portions of the sentences which are affected by the different replacements. To cover potential cases of cognates, annotators can choose the actual OOV as the best “replacement”. Active sampling In order to keep the sample of candidate translations to be annotated for a given OOV source sentence small, but still informative for training, we adopt an active learning scheme (Settles, 2010; Haffari et al., 2009; Eck et al., 2005). We do not extract a priori a sample of translation candidates for each sentence in the OOV training set and ask the annotators to work on these samples — which would mean that they might have to compare candidates that have little chance of being selected by the end-model after training. Instead, This is an iterative process, with a slice of the OOV training set selected for each iteration. When sampling candidate translations (out of a given slice of the OOV training set) to be annotated in the next iteration, we use the translations produced by the model Λ ⊕ M obtained s"
2010.eamt-1.31,J10-4005,0,0.0120582,"us the annotation task on the specific problem of sentences containing OOV words, and (ii) even for these sentences, we should only hand the annotators a small, well-chosen, sample of translation candidates to assess, not an exhaustive list. Finally, we need to be careful not to bias training towards the human annotated sample in such a way that the integrated decoder becomes better on the OOV sentences, but is degraded on the “normal” sentences. We address these requirements as follows. 2 Integrated decoding The integrated decoder consists of a standard phrase-based SMT decoder (Lopez, 2008; Koehn, 2010) enhanced with the ability to add dynamic biphrases at runtime and attempting to maximize a variant of the standard “log-linear” objective function. The standard SMT decoder tries to find argmax(a,t) Λ · G(s, t, a), where Λ is a vector of weights, and G(s, t, a) a vector of features depending on the source sentence s, the target sentence t and the phrase-level alignment a. The integrated decoder tries to find argmax(a,t) Λ · G(s, t, a) + M · H(s, t, a) where M is an additional vector of weights and H(s, t, a) an additional vector of “dynamic” features associated with the dynamic biphrases and"
2010.eamt-1.31,D09-1040,0,0.228261,"al data are scarce or the text to be translated is not from the same domain as the data used to train the system. One approach consists in replacing the OOV word by a paraphrase, i.e. a word that is equivalent and known to the phrase-table. For instance, in the sentence “The police hit the protester”, if the source word “hit” is OOV, it could be replaced by its paraphrase “struck”. In previous work such paraphrases are learnt by “pivoting” through parallel texts involving multiple languages (CallisonBurch et al., 2006) or on the basis of monolingual data and distributional similarity metrics (Marton et al., 2009). Mirkin et al. (2009) go beyond the use of paraphrase to incorporate the notion of an entailed phrase, that is, a word which is implied by the OOV word, but is not necessarily equivalent to it — for example, this could result in “hit” being replaced by the entailed phrase “attacked”. Both paraphrases and entailed phrases are obtained using monolingual resources such as WordNet (Fellbaum, 1998). This approach results in higher coverage and human acceptability of the translations produced relative to approaches based only on paraphrases. In (Mirkin et al., 2009) a replacement for the OOV word i"
2010.eamt-1.31,P04-1036,0,0.029228,"he vectors of all the content words in it. 3 Technically, this ratio is only defined for π (M ) (X) 6= 0, i.e. for cases where the pair of translations differ in their M projections; in the rare instances where this might not be true, we can simply ignore the pair in the learning process. Domain similarity Score representing how well rep can replace oov in general in texts of a given domain. It is computed as the cosine similarity between the LSA vectors of the two words and is intended to give preference to replacements which correspond to more frequent senses of the OOV word in that domain (McCarthy et al., 2004). Information loss Measures the distance in WordNet’s hierarchy, denoted d, between oov and rep: 1 S(unk, sub) = 1 − ( d+1 ), where the distance between synonyms is 0, and the further the hypernym is up the hierarchy, the smaller the score. This can be considered a simple approximation to the notion of information loss, that is, the further the rep is from the oov in a hierarchy, the fewer semantic traits exist between the two, and therefore the more information is lost if we use rep. Identity Binary feature to mark the cases where the OOV is kept in the sentence, what we call an “identity” re"
2010.eamt-1.31,P09-1089,1,0.237426,"the text to be translated is not from the same domain as the data used to train the system. One approach consists in replacing the OOV word by a paraphrase, i.e. a word that is equivalent and known to the phrase-table. For instance, in the sentence “The police hit the protester”, if the source word “hit” is OOV, it could be replaced by its paraphrase “struck”. In previous work such paraphrases are learnt by “pivoting” through parallel texts involving multiple languages (CallisonBurch et al., 2006) or on the basis of monolingual data and distributional similarity metrics (Marton et al., 2009). Mirkin et al. (2009) go beyond the use of paraphrase to incorporate the notion of an entailed phrase, that is, a word which is implied by the OOV word, but is not necessarily equivalent to it — for example, this could result in “hit” being replaced by the entailed phrase “attacked”. Both paraphrases and entailed phrases are obtained using monolingual resources such as WordNet (Fellbaum, 1998). This approach results in higher coverage and human acceptability of the translations produced relative to approaches based only on paraphrases. In (Mirkin et al., 2009) a replacement for the OOV word is chosen based on a sc"
2010.eamt-1.31,P03-1021,0,0.00474717,"rapp´e) and (hit, a attaqu´e) from the static ones (struck, a frapp´e) and (attacked, a attaqu´e). Such dynamic biphrases are assigned several features that characterize different aspects of the process that generated them, such as the appropriateness of the replacement in the context of the specific source sentence, allowing for example reach to be preferred to strike or attack in replacing hit in “We hit the city at lunch time”. Dynamic and static biphrases compete during the search for an optimal translation. At training time, standard techniques such as MERT (Minimum Error Rate Training) (Och, 2003), which attempt to maximize automatic metrics like BLEU (Papineni et al., 2002) based on a bilingual corpus, are directly applicable. However, as has been discussed in (Callison-Burch et al., 2006; Mirkin et al., 2009), such automatic measures are poor indicators of improvements in translation quality in presence of semantic modifications of the kind we are considering here. Therefore, we perform the training and evaluation on the basis of human annotations. We use a form of active learning to focus the annotation effort on a small set of candidates which are useful for the training. Sentences"
2010.eamt-1.31,P02-1040,0,0.0818727,"´e) and (attacked, a attaqu´e). Such dynamic biphrases are assigned several features that characterize different aspects of the process that generated them, such as the appropriateness of the replacement in the context of the specific source sentence, allowing for example reach to be preferred to strike or attack in replacing hit in “We hit the city at lunch time”. Dynamic and static biphrases compete during the search for an optimal translation. At training time, standard techniques such as MERT (Minimum Error Rate Training) (Och, 2003), which attempt to maximize automatic metrics like BLEU (Papineni et al., 2002) based on a bilingual corpus, are directly applicable. However, as has been discussed in (Callison-Burch et al., 2006; Mirkin et al., 2009), such automatic measures are poor indicators of improvements in translation quality in presence of semantic modifications of the kind we are considering here. Therefore, we perform the training and evaluation on the basis of human annotations. We use a form of active learning to focus the annotation effort on a small set of candidates which are useful for the training. Sentences containing OOV words represent a fairly small fraction of the sentences to be"
2010.eamt-1.31,H05-1095,1,0.886826,"Missing"
2013.mtsummit-posters.8,2010.eamt-1.31,1,0.73683,"text rewritings methods is by the semantic relation between the resulting text and the original one. The source text can be paraphrased, i.e. have its meaning expressed in a different way, but it can also be generalized, e.g. by having some of its details omitted. In principle, paraphrasing is preferable, as it preserves the meaning of the source text. However, in some cases, it is preferable to have a more accurate translation with fewer details than a poor translation of the exact meaning of the original text. This was shown empirically, with human evaluators, in (Mirkin et al., 2009) and (Aziz et al., 2010) which dealt with the problem of unknown words by allowing the generation of an entailed version of the source text, and not only paraphrases of it. On a different dimension, text simplification is motivated by the need to provide easy-to-read texts system-demo paper (Mirkin et al., 2013). to poorly literate people or language learners. Simplification operations include substitution of words by simpler ones, removal of complicated syntactic structures, shortening of sentences or removal of details not necessary for understanding the core idea of the text (Feng, 2008). Semantically, text simpli"
2013.mtsummit-posters.8,C04-1046,0,0.0213322,"replaced competitor programs. In SORT, both methods were used in conjunction to suggest rewritings for sentences with low confidence estimates. 3 Confidence estimation MT systems are typically evaluated by comparing their output to reference translations. Yet, in many practical scenarios, reference translations are not available. Quality estimation, a.k.a. confidence estimation, denote methods that estimate the quality of an automated translation without depending on references. Instead, they rely on features extracted from the source, the translation, or from the translation process itself (Blatz et al., 2004; Specia et al., 2009). This is useful, for example, for identifying sentences that are suspected to be poorly translated in order to have them post-edited by human translators. Our confidence estimator is based on the system and data provided for the 2012 Quality estimation shared task (Callison-Burch et al., 2012). In this task, participants were required to estimate the quality of automated translations. Their estimations were compared to human scores of the trans259 lation which referred to the suitability of the translation for post-editing. The scores ranged from 1 to 5, where 1 correspo"
2013.mtsummit-posters.8,N06-1003,0,0.173911,"he first two authors of this paper recently presented an authoring tool that consults the MT system itself to propose phrases that can be used during composition to obtain better translations (Venkatapathy and Mirkin, 2012). All the above methods address authoring of source texts from scratch. By contrast, this paper is concerned with modifying an existing text to improve its translatability (an approach that was however mentioned as a future perspective in (Mitamura, 1999)). For the modification of existing text, another approach is to paraphrase the source or to generate entailed sentences (Callison-Burch et al., 2006; Mirkin et al., 2009; Marton et al., 2009; Aziz et al., 2010). Yet, these works focus on handling out-ofvocabulary (OOV) words, do not assess the translatability of the source sentences and do not offer an interactive solution for the author. Another way to use paraphrases for improved translation has been proposed by (Max, 2010) who paraphrases source texts to increase the number of training examples for the SMT system. A different approach is pre-ordering, a strategy used to improve translation for language pairs that have different syntactic structures (e.g. Japanese SOV and Chinese SVO)."
2013.mtsummit-posters.8,W12-3102,0,0.0626879,"Missing"
2013.mtsummit-posters.8,C00-1036,1,0.574598,"Missing"
2013.mtsummit-posters.8,W11-2148,0,0.0226406,"ific to the MT system; further, the technique does not produce fluent, readable sentences that can be validated by users, and is therefore less suitable for interactive source rewriting. (Choumane et al., 2005) propose an iterative system where the author helps the translation system “understand” a given text by tagging text positions that represent potential syntactic ambiguities. As in most cases mentioned earlier, the rules used by this method are generic and are not tailored for a specific MT system or model. Monolingual-based editing for translation is proposed in the MonoTrans2 project (Hu et al., 2011); monolingual speakers of the source and the target languages collaborate to improve the translation. Unlike our approach, here both the feed263 back for poorly translated sentences and the actual modification of the source are done by humans. 7 Conclusions We introduced an approach for interactively rewriting texts for translation under the guidance of a confidence estimator, and implemented a tool integrating two rewriting techniques. We observed that the translations of rewritings were preferred more often than those of the original source. While we focused on an interactive mode, selection"
2013.mtsummit-posters.8,W10-1736,0,0.0186092,"(OOV) words, do not assess the translatability of the source sentences and do not offer an interactive solution for the author. Another way to use paraphrases for improved translation has been proposed by (Max, 2010) who paraphrases source texts to increase the number of training examples for the SMT system. A different approach is pre-ordering, a strategy used to improve translation for language pairs that have different syntactic structures (e.g. Japanese SOV and Chinese SVO). There, the words in the source text are reordered to make their order more similar to that of the target language (Isozaki et al., 2010; Wu et al., 2011). Unlike our approach, pre-ordering is not specific to the MT system; further, the technique does not produce fluent, readable sentences that can be validated by users, and is therefore less suitable for interactive source rewriting. (Choumane et al., 2005) propose an iterative system where the author helps the translation system “understand” a given text by tagging text positions that represent potential syntactic ambiguities. As in most cases mentioned earlier, the rules used by this method are generic and are not tailored for a specific MT system or model. Monolingual-base"
2013.mtsummit-posters.8,P07-2045,0,0.00301722,"em and data provided for the 2012 Quality estimation shared task (Callison-Burch et al., 2012). In this task, participants were required to estimate the quality of automated translations. Their estimations were compared to human scores of the trans259 lation which referred to the suitability of the translation for post-editing. The scores ranged from 1 to 5, where 1 corresponds to translation that practically needs to be done from scratch, and 5 to translations that requires little to no editing. The task’s training set consisted of approximately 1800 source sentences in English, their Moses (Koehn et al., 2007) translations to Spanish and the scores given to the translations by the three judges. With this data we trained an SVM regression model using SVMlight (Joachims, 1999). Features were extracted with the task’s featureextraction baseline module. Two types of features are used in this module (i) black-box features, that do not assume access to the translation system, such as the length of the source and the target, and language model log probabilities, and (ii) glass-box features, which are extracted from the MT model itself, such as the average number of possible translations per source word. 4"
2013.mtsummit-posters.8,D09-1040,0,0.0258654,"ted an authoring tool that consults the MT system itself to propose phrases that can be used during composition to obtain better translations (Venkatapathy and Mirkin, 2012). All the above methods address authoring of source texts from scratch. By contrast, this paper is concerned with modifying an existing text to improve its translatability (an approach that was however mentioned as a future perspective in (Mitamura, 1999)). For the modification of existing text, another approach is to paraphrase the source or to generate entailed sentences (Callison-Burch et al., 2006; Mirkin et al., 2009; Marton et al., 2009; Aziz et al., 2010). Yet, these works focus on handling out-ofvocabulary (OOV) words, do not assess the translatability of the source sentences and do not offer an interactive solution for the author. Another way to use paraphrases for improved translation has been proposed by (Max, 2010) who paraphrases source texts to increase the number of training examples for the SMT system. A different approach is pre-ordering, a strategy used to improve translation for language pairs that have different syntactic structures (e.g. Japanese SOV and Chinese SVO). There, the words in the source text are re"
2013.mtsummit-posters.8,D10-1064,0,0.0184648,"existing text to improve its translatability (an approach that was however mentioned as a future perspective in (Mitamura, 1999)). For the modification of existing text, another approach is to paraphrase the source or to generate entailed sentences (Callison-Burch et al., 2006; Mirkin et al., 2009; Marton et al., 2009; Aziz et al., 2010). Yet, these works focus on handling out-ofvocabulary (OOV) words, do not assess the translatability of the source sentences and do not offer an interactive solution for the author. Another way to use paraphrases for improved translation has been proposed by (Max, 2010) who paraphrases source texts to increase the number of training examples for the SMT system. A different approach is pre-ordering, a strategy used to improve translation for language pairs that have different syntactic structures (e.g. Japanese SOV and Chinese SVO). There, the words in the source text are reordered to make their order more similar to that of the target language (Isozaki et al., 2010; Wu et al., 2011). Unlike our approach, pre-ordering is not specific to the MT system; further, the technique does not produce fluent, readable sentences that can be validated by users, and is the"
2013.mtsummit-posters.8,P09-1089,1,0.883887,"ting One way to categorize text rewritings methods is by the semantic relation between the resulting text and the original one. The source text can be paraphrased, i.e. have its meaning expressed in a different way, but it can also be generalized, e.g. by having some of its details omitted. In principle, paraphrasing is preferable, as it preserves the meaning of the source text. However, in some cases, it is preferable to have a more accurate translation with fewer details than a poor translation of the exact meaning of the original text. This was shown empirically, with human evaluators, in (Mirkin et al., 2009) and (Aziz et al., 2010) which dealt with the problem of unknown words by allowing the generation of an entailed version of the source text, and not only paraphrases of it. On a different dimension, text simplification is motivated by the need to provide easy-to-read texts system-demo paper (Mirkin et al., 2013). to poorly literate people or language learners. Simplification operations include substitution of words by simpler ones, removal of complicated syntactic structures, shortening of sentences or removal of details not necessary for understanding the core idea of the text (Feng, 2008). S"
2013.mtsummit-posters.8,P13-4015,1,0.63059,"asing is preferable, as it preserves the meaning of the source text. However, in some cases, it is preferable to have a more accurate translation with fewer details than a poor translation of the exact meaning of the original text. This was shown empirically, with human evaluators, in (Mirkin et al., 2009) and (Aziz et al., 2010) which dealt with the problem of unknown words by allowing the generation of an entailed version of the source text, and not only paraphrases of it. On a different dimension, text simplification is motivated by the need to provide easy-to-read texts system-demo paper (Mirkin et al., 2013). to poorly literate people or language learners. Simplification operations include substitution of words by simpler ones, removal of complicated syntactic structures, shortening of sentences or removal of details not necessary for understanding the core idea of the text (Feng, 2008). Semantically, text simplification techniques may fall between paraphrasing (e.g. when replacing a rare word by a more common synonym) and generalization (e.g. when dropping a dispensable modifier). In the current prototype, we implemented two rewriting techniques based on text simplification that work either at t"
2013.mtsummit-posters.8,1999.mtsummit-1.8,0,0.0848236,"e large number of cases with no clear winner, and the analysis we conducted, indicate that the user’s cognitive effort would be decreased if we displayed only those rewritings associated with a substantial improvement in confidence; due to the nature of our methods, identical or near-identical translations were frequently generated, with only marginal differences in confidence, as in the case of two source synonyms being translated to the same target word. 6 Related work One approach to produce translatable text is by enforcing the use of a “controlled language” during source text authoring. (Mitamura, 1999) discusses the design of such a language in the context of rule-based translation and proposes tools for checking source sentences; (Carbonell et al., 1997) propose an interactive tool to enforce such constraints on the source in a similar context. In the case of restricted semantic domains, (Dymetman et 262 al., 2000; Power et al., 2003) propose methods that directly generate multilingual target texts based on a semantically-guided authoring process (see also (Ranta, 2011) for a formal paradigm that may be used for similar applications). In the context of SMT, the first two authors of this pa"
2013.mtsummit-posters.8,2003.eamt-1.13,0,0.0343761,"ith only marginal differences in confidence, as in the case of two source synonyms being translated to the same target word. 6 Related work One approach to produce translatable text is by enforcing the use of a “controlled language” during source text authoring. (Mitamura, 1999) discusses the design of such a language in the context of rule-based translation and proposes tools for checking source sentences; (Carbonell et al., 1997) propose an interactive tool to enforce such constraints on the source in a similar context. In the case of restricted semantic domains, (Dymetman et 262 al., 2000; Power et al., 2003) propose methods that directly generate multilingual target texts based on a semantically-guided authoring process (see also (Ranta, 2011) for a formal paradigm that may be used for similar applications). In the context of SMT, the first two authors of this paper recently presented an authoring tool that consults the MT system itself to propose phrases that can be used during composition to obtain better translations (Venkatapathy and Mirkin, 2012). All the above methods address authoring of source texts from scratch. By contrast, this paper is concerned with modifying an existing text to impr"
2013.mtsummit-posters.8,2009.eamt-1.5,1,0.8255,"programs. In SORT, both methods were used in conjunction to suggest rewritings for sentences with low confidence estimates. 3 Confidence estimation MT systems are typically evaluated by comparing their output to reference translations. Yet, in many practical scenarios, reference translations are not available. Quality estimation, a.k.a. confidence estimation, denote methods that estimate the quality of an automated translation without depending on references. Instead, they rely on features extracted from the source, the translation, or from the translation process itself (Blatz et al., 2004; Specia et al., 2009). This is useful, for example, for identifying sentences that are suspected to be poorly translated in order to have them post-edited by human translators. Our confidence estimator is based on the system and data provided for the 2012 Quality estimation shared task (Callison-Burch et al., 2012). In this task, participants were required to estimate the quality of automated translations. Their estimations were compared to human scores of the trans259 lation which referred to the suitability of the translation for post-editing. The scores ranged from 1 to 5, where 1 corresponds to translation tha"
2013.mtsummit-posters.8,C12-3058,1,0.841521,"se an interactive tool to enforce such constraints on the source in a similar context. In the case of restricted semantic domains, (Dymetman et 262 al., 2000; Power et al., 2003) propose methods that directly generate multilingual target texts based on a semantically-guided authoring process (see also (Ranta, 2011) for a formal paradigm that may be used for similar applications). In the context of SMT, the first two authors of this paper recently presented an authoring tool that consults the MT system itself to propose phrases that can be used during composition to obtain better translations (Venkatapathy and Mirkin, 2012). All the above methods address authoring of source texts from scratch. By contrast, this paper is concerned with modifying an existing text to improve its translatability (an approach that was however mentioned as a future perspective in (Mitamura, 1999)). For the modification of existing text, another approach is to paraphrase the source or to generate entailed sentences (Callison-Burch et al., 2006; Mirkin et al., 2009; Marton et al., 2009; Aziz et al., 2010). Yet, these works focus on handling out-ofvocabulary (OOV) words, do not assess the translatability of the source sentences and do no"
2013.mtsummit-posters.8,I11-1004,0,0.0119066,"ssess the translatability of the source sentences and do not offer an interactive solution for the author. Another way to use paraphrases for improved translation has been proposed by (Max, 2010) who paraphrases source texts to increase the number of training examples for the SMT system. A different approach is pre-ordering, a strategy used to improve translation for language pairs that have different syntactic structures (e.g. Japanese SOV and Chinese SVO). There, the words in the source text are reordered to make their order more similar to that of the target language (Isozaki et al., 2010; Wu et al., 2011). Unlike our approach, pre-ordering is not specific to the MT system; further, the technique does not produce fluent, readable sentences that can be validated by users, and is therefore less suitable for interactive source rewriting. (Choumane et al., 2005) propose an iterative system where the author helps the translation system “understand” a given text by tagging text positions that represent potential syntactic ambiguities. As in most cases mentioned earlier, the rules used by this method are generic and are not tailored for a specific MT system or model. Monolingual-based editing for tran"
2013.mtsummit-posters.8,C10-1152,0,0.0430386,"ns. Clearly, this is not always the case; we leave this decision to the confidence estimation component. Sentence-level simplification (Specia, 2010) has proposed to model text simplification as an SMT task where the goal is not to translate from one language to another, but to translate texts to their simplified version in the same language. In this approach, a simplification translation model is learnt from a parallel corpus of texts and their simplified versions. Applying this method, we trained an SMT model from English to Simple English, based on the PWKP corpus generated from Wikipedia (Zhu et al., 2010); we used only alignments involving a single sentence on each side. This resulted in a phrase table containing many entries were source and target phrases are identical, but also phrase-pairs that are mapping complex phrases to their simplified counterparts, e.g.: • the traditional etymology → the name • primarily dry and secondarily cold → both cold and dry • the high mountainous alps → the alps Also, the language model was trained with Simple English sentences to encourage the generation of simpler texts. Given a source text, it is translated to its simpler version, and n-best translations a"
2014.amta-researchers.15,D11-1033,0,0.235668,"om itself. Now, Al-Onaizan & Simard (Eds.) Proceedings of AMTA 2014, vol. 1: MT Researchers Vancouver, BC © The Authors 195 sentences of the generic corpus are sorted regarding the computation of the difference between domain-specific score and generic score. At last, the best amount of the sorted data has to be determined. This best point is found by minimizing the perplexity of a development set on growing percentages of the sorted corpus. Moore and Lewis (2010) reported that the perplexity decreases when less, but more appropriate data is used. Recent works expand this approach to bitexts (Axelrod et al., 2011; Mansour et al., 2011). Approaches like corpus weighting (Shah et al., 2010) or sentence weighting (Matsoukas et al., 2009; Mansour and Ney, 2012) are not suitable to our translation task because these approaches can produce huge models by considering the whole data. 3 Cross-entropy based Data Selection versus Infrequent n-gram Recovery In this section we detail the different approaches experimented with for data selection. On one hand we process the data selection for both LM and translation model (TM) using cross-entropy. On the other hand, the infrequent n-gram recovery (Gascó et al., 2012"
2014.amta-researchers.15,2011.iwslt-evaluation.18,0,0.0595347,"og-linear or a linear approach (Foster and Kuhn, 2007; Civera and Juan, 2007). The standard log-linear model may be used to combine some domainspecific models (Koehn and Schroeder, 2007). In the same way target language models may be combined using a log-linear or a linear combination (Schwenk and Koehn, 2008). Sennrich et al. (2013) proposed to combine different specific parts of the phrase-table during translation leading to a multi-domain adaptation approach. Niehues and Waibel (2012) compared several incremental approaches, namely the backoff, the factored, the log-linear and the fill-up (Bisazza et al., 2011) techniques. These approaches aim at adapting an MT system towards a target domain using small amounts of parallel in-domain data. The main outcome of this paper is that all the approaches successfully improve the generic model and none of them is better than the others. The performances of the approaches mainly depend on their match to the specific data. 2.3 Data selection The main idea of data selection is to try to take advantage of a generic corpus by picking out a subset of training data that is most relevant to the domain of interest. Two main approaches are used to perform domain adapta"
2014.amta-researchers.15,J93-2003,0,0.0861508,"both source and target side: ¯ LM (s, t) = HLM (s) − HLM H (s) + HLMItrg (t) − HLMOˆ Isrc ˆ src O Al-Onaizan & Simard (Eds.) Proceedings of AMTA 2014, vol. 1: MT Researchers Vancouver, BC trg (t) (3) © The Authors 196 Note that since the scores in Equation 3 are computed for the source and target separately, any target sentence t0 whose cross-entropy score is similar to that of t can exchange t and have a similar score assigned to it by this method. As a result, poorly aligned data can not be detected by LM cross-entropy scoring only. 3.2 Translation Model Cross-entropy The IBM-Model 1 (M1) (Brown et al., 1993) is a model used in state-of-the-art SMT systems for a variety of applications. In this work, we apply M1 scores to achieve adaptation to some domain specific data. Mansour et al. (2011) extend the formulation by Axelrod et al. (2011), which is described in Equation (3), by adding the M1 cross-entropy score to the LM cross entropy score. The M1 cross-entropy for a sentence pair (s, t) = s1 , ..., s|s |, t1 , ..., t|t |is defined as: where ¯ M 1 (s, t) = HM 1 (t|s) − HM 1 (t|s) + HM 1 (s|t) − HM 1 (s|t) H I I ˆ ˆ O O (4)   |s| |t| X X 1 1 log  pM 1 (ti |sj ) HM 1 (t|s) = − |t| |s| j=1 i="
2014.amta-researchers.15,W07-0722,1,0.799684,"e amounts of monolingual training data translated using a completely new model. Lambert et al. (2011) enhanced this approach by using the translations of monolingual data in the target language. 2.2 Model combination and update One way to adapt MT models is to combine translation models. Models can be combined using the mixture-model approach, a log-linear combination or through incremental learning approaches. To obtain a mixture of domain-specific models trained on several different domain-specific corpora, they can be combined using a log-linear or a linear approach (Foster and Kuhn, 2007; Civera and Juan, 2007). The standard log-linear model may be used to combine some domainspecific models (Koehn and Schroeder, 2007). In the same way target language models may be combined using a log-linear or a linear combination (Schwenk and Koehn, 2008). Sennrich et al. (2013) proposed to combine different specific parts of the phrase-table during translation leading to a multi-domain adaptation approach. Niehues and Waibel (2012) compared several incremental approaches, namely the backoff, the factored, the log-linear and the fill-up (Bisazza et al., 2011) techniques. These approaches aim at adapting an MT syst"
2014.amta-researchers.15,W07-0717,0,0.0282688,"it proposes to add large amounts of monolingual training data translated using a completely new model. Lambert et al. (2011) enhanced this approach by using the translations of monolingual data in the target language. 2.2 Model combination and update One way to adapt MT models is to combine translation models. Models can be combined using the mixture-model approach, a log-linear combination or through incremental learning approaches. To obtain a mixture of domain-specific models trained on several different domain-specific corpora, they can be combined using a log-linear or a linear approach (Foster and Kuhn, 2007; Civera and Juan, 2007). The standard log-linear model may be used to combine some domainspecific models (Koehn and Schroeder, 2007). In the same way target language models may be combined using a log-linear or a linear combination (Schwenk and Koehn, 2008). Sennrich et al. (2013) proposed to combine different specific parts of the phrase-table during translation leading to a multi-domain adaptation approach. Niehues and Waibel (2012) compared several incremental approaches, namely the backoff, the factored, the log-linear and the fill-up (Bisazza et al., 2011) techniques. These approaches ai"
2014.amta-researchers.15,D08-1089,0,0.0143253,"searches for the best translation eˆI1 as defined by the I K J models hm (e1 , s1 , f1 ). It can be written as (Och and Ney, 2004) ( ˆ eˆI1 = arg max I,eI1 M X ) J λm hm (eI1 , sK 1 , f1 ) , (9) m=1 where f1J = f1 . . . fJ is the source sentence, eI1 = e1 . . . eI the target sentence and sK 1 = s1 . . . sK their phrase segmentation and alignment. The feature functions hm include translation channel models in both directions, lexical smoothing models in both directions, an n-gram language model, phrase and word penalty, a jump-distance-based distortion model, a hierarchical orientation model (Galley and Manning, 2008) and an n-gram cluster language model (Wuebker et al., 2013). The log-linear feature weights λm are optimized on a development data set with minimum error rate training (MERT) (Och, 2003). As optimization criterion we use B LEU (Papineni et al., 2001). Al-Onaizan & Simard (Eds.) Proceedings of AMTA 2014, vol. 1: MT Researchers Vancouver, BC © The Authors 199 5 Experiments In this section we describe the different experiments we made in order to compare between the approaches. 5.1 The VideoLectures.NET Repository VideoLectures.NET1 is a free and open access repository of video lectures mostly f"
2014.amta-researchers.15,P02-1023,0,0.656356,"nd, such approaches use information retrieval techniques and similarity scores. On the other hand, language models are used associated to perplexity and cross-entropy. Intuitively, seeking the data closest to the test set is related to information retrieval techniques. Lü et al. (2007) present this approach using the standard measure T F.IDF (Term Frequency – Inverse Document Frequency) to measure the similarity between the test sentences and the training sentences. This approach is based on a bag-of-words scheme. The second approach, based on language models (LMs), was originally proposed by Gao and Zhang (2002). Here, the generic corpus is scored against an LM trained on a seed of domain-specific data, and the cross-entropy is computed for each sentence. Then, the same generic corpus is scored against an LM trained on a random sample taken from itself. Now, Al-Onaizan & Simard (Eds.) Proceedings of AMTA 2014, vol. 1: MT Researchers Vancouver, BC © The Authors 195 sentences of the generic corpus are sorted regarding the computation of the difference between domain-specific score and generic score. At last, the best amount of the sorted data has to be determined. This best point is found by minimizing"
2014.amta-researchers.15,E12-1016,0,0.540022,"elrod et al., 2011; Mansour et al., 2011). Approaches like corpus weighting (Shah et al., 2010) or sentence weighting (Matsoukas et al., 2009; Mansour and Ney, 2012) are not suitable to our translation task because these approaches can produce huge models by considering the whole data. 3 Cross-entropy based Data Selection versus Infrequent n-gram Recovery In this section we detail the different approaches experimented with for data selection. On one hand we process the data selection for both LM and translation model (TM) using cross-entropy. On the other hand, the infrequent n-gram recovery (Gascó et al., 2012), is explored. 3.1 Language Model Cross-entropy The LM cross-entropy difference can be used for both monolingual data selection for LM training as described by Moore and Lewis (2010), or bilingual selection for translation model training (Axelrod et al., 2011). Given an in-domain corpus I and an out-of-domain or general-domain corpus O, first we ˆ ⊆ O of approximately the same size as I, and train the LMs LMI generate a random subset O and LMOˆ using the corresponding training data. Afterwards, each sentence o ∈ O is scored according to: HLMI (o) − HLMOˆ (o) (1) where H is the length-normalise"
2014.amta-researchers.15,N03-1017,0,0.0353971,"cross-entropy achieves the most stable results. As another important criterion for measuring translation quality in our application, we identify the number of out-ofvocabulary words. Here, infrequent n-gram recovery shows superior performance. Finally, we combine the two selection techniques in order to benefit from both their strengths. 1 Introduction With the continuous growth of available bitexts and research advances of the underlying technology, statistical machine translation (SMT) has become popular for many real world tasks. The most common approach is still the phrase-based paradigm (Koehn et al., 2003), that provides an efficient framework with good translation quality for many language pairs. This work focuses on the application of SMT to the task of translating scientific video lectures. Online scientific video lectures are becoming increasingly popular, e.g. in the context of massive open online courses (MOOCs). Being able to provide high quality automatic translations for this kind of technical talks could, e.g., prove beneficial to education at universities, Al-Onaizan & Simard (Eds.) Proceedings of AMTA 2014, vol. 1: MT Researchers Vancouver, BC © The Authors 193 sharing technical kno"
2014.amta-researchers.15,W07-0733,0,0.0273928,"anced this approach by using the translations of monolingual data in the target language. 2.2 Model combination and update One way to adapt MT models is to combine translation models. Models can be combined using the mixture-model approach, a log-linear combination or through incremental learning approaches. To obtain a mixture of domain-specific models trained on several different domain-specific corpora, they can be combined using a log-linear or a linear approach (Foster and Kuhn, 2007; Civera and Juan, 2007). The standard log-linear model may be used to combine some domainspecific models (Koehn and Schroeder, 2007). In the same way target language models may be combined using a log-linear or a linear combination (Schwenk and Koehn, 2008). Sennrich et al. (2013) proposed to combine different specific parts of the phrase-table during translation leading to a multi-domain adaptation approach. Niehues and Waibel (2012) compared several incremental approaches, namely the backoff, the factored, the log-linear and the fill-up (Bisazza et al., 2011) techniques. These approaches aim at adapting an MT system towards a target domain using small amounts of parallel in-domain data. The main outcome of this paper is"
2014.amta-researchers.15,W11-2132,1,0.895614,"involves a confidence measure in order to select the Al-Onaizan & Simard (Eds.) Proceedings of AMTA 2014, vol. 1: MT Researchers Vancouver, BC © The Authors 194 most reliable data to train a small additional phrase table (PT). The generic and the new phrase tables are used jointly for translation, which can be seen as a mixture model with one specific PT built for each test set. The lightly-supervised training approach proposed by Schwenk (2008) does not adapt the model to the test data, but it proposes to add large amounts of monolingual training data translated using a completely new model. Lambert et al. (2011) enhanced this approach by using the translations of monolingual data in the target language. 2.2 Model combination and update One way to adapt MT models is to combine translation models. Models can be combined using the mixture-model approach, a log-linear combination or through incremental learning approaches. To obtain a mixture of domain-specific models trained on several different domain-specific corpora, they can be combined using a log-linear or a linear approach (Foster and Kuhn, 2007; Civera and Juan, 2007). The standard log-linear model may be used to combine some domainspecific mode"
2014.amta-researchers.15,E12-2003,0,0.0201164,"lly transcribed and translated into several languages. In particular, 23 of these 27 lectures (16 hours) were translated into French by professional translators. 5.2 Data Our experiments are performed on the task of translating manually transcribed English video lectures into French. In addition to around 5000 sentence pairs from VideoLectures.NET, we use the parallel TED talk data provided for the shared translation task of the International Workshop on Spoken Language Translation4 as in-domain data. The general domain data consists of several corpora. The COSMAT scientific thesis abstracts (Lambert et al., 2012) and the news-commentary-v8 corpus, provided by the ACL 2013 8th Workshop on Statistical Machine Translation5 (WMT), are directly added to the baseline without instance selection due to their small size. The large corpora on which data selection is performed, are the Europarl-v7 corpus (also provided by WMT), the JRC-Acquis corpus (Steinberger et al., 2006) and the Open Subtitles corpus6 (Tiedemann, 2012). Data statistics for the complete in-domain and out-of-domain data are given in Table 1. For the development and test sets we selected four video lectures each, that were manually transcribed"
2014.amta-researchers.15,D07-1036,0,0.650913,"Missing"
2014.amta-researchers.15,2012.iwslt-papers.7,1,0.80783,"ric corpus are sorted regarding the computation of the difference between domain-specific score and generic score. At last, the best amount of the sorted data has to be determined. This best point is found by minimizing the perplexity of a development set on growing percentages of the sorted corpus. Moore and Lewis (2010) reported that the perplexity decreases when less, but more appropriate data is used. Recent works expand this approach to bitexts (Axelrod et al., 2011; Mansour et al., 2011). Approaches like corpus weighting (Shah et al., 2010) or sentence weighting (Matsoukas et al., 2009; Mansour and Ney, 2012) are not suitable to our translation task because these approaches can produce huge models by considering the whole data. 3 Cross-entropy based Data Selection versus Infrequent n-gram Recovery In this section we detail the different approaches experimented with for data selection. On one hand we process the data selection for both LM and translation model (TM) using cross-entropy. On the other hand, the infrequent n-gram recovery (Gascó et al., 2012), is explored. 3.1 Language Model Cross-entropy The LM cross-entropy difference can be used for both monolingual data selection for LM training as"
2014.amta-researchers.15,2011.iwslt-papers.5,1,0.90042,"izan & Simard (Eds.) Proceedings of AMTA 2014, vol. 1: MT Researchers Vancouver, BC © The Authors 195 sentences of the generic corpus are sorted regarding the computation of the difference between domain-specific score and generic score. At last, the best amount of the sorted data has to be determined. This best point is found by minimizing the perplexity of a development set on growing percentages of the sorted corpus. Moore and Lewis (2010) reported that the perplexity decreases when less, but more appropriate data is used. Recent works expand this approach to bitexts (Axelrod et al., 2011; Mansour et al., 2011). Approaches like corpus weighting (Shah et al., 2010) or sentence weighting (Matsoukas et al., 2009; Mansour and Ney, 2012) are not suitable to our translation task because these approaches can produce huge models by considering the whole data. 3 Cross-entropy based Data Selection versus Infrequent n-gram Recovery In this section we detail the different approaches experimented with for data selection. On one hand we process the data selection for both LM and translation model (TM) using cross-entropy. On the other hand, the infrequent n-gram recovery (Gascó et al., 2012), is explored. 3.1 Lan"
2014.amta-researchers.15,D09-1074,0,0.0228901,"95 sentences of the generic corpus are sorted regarding the computation of the difference between domain-specific score and generic score. At last, the best amount of the sorted data has to be determined. This best point is found by minimizing the perplexity of a development set on growing percentages of the sorted corpus. Moore and Lewis (2010) reported that the perplexity decreases when less, but more appropriate data is used. Recent works expand this approach to bitexts (Axelrod et al., 2011; Mansour et al., 2011). Approaches like corpus weighting (Shah et al., 2010) or sentence weighting (Matsoukas et al., 2009; Mansour and Ney, 2012) are not suitable to our translation task because these approaches can produce huge models by considering the whole data. 3 Cross-entropy based Data Selection versus Infrequent n-gram Recovery In this section we detail the different approaches experimented with for data selection. On one hand we process the data selection for both LM and translation model (TM) using cross-entropy. On the other hand, the infrequent n-gram recovery (Gascó et al., 2012), is explored. 3.1 Language Model Cross-entropy The LM cross-entropy difference can be used for both monolingual data sele"
2014.amta-researchers.15,P10-2041,0,0.494601,"cific data, and the cross-entropy is computed for each sentence. Then, the same generic corpus is scored against an LM trained on a random sample taken from itself. Now, Al-Onaizan & Simard (Eds.) Proceedings of AMTA 2014, vol. 1: MT Researchers Vancouver, BC © The Authors 195 sentences of the generic corpus are sorted regarding the computation of the difference between domain-specific score and generic score. At last, the best amount of the sorted data has to be determined. This best point is found by minimizing the perplexity of a development set on growing percentages of the sorted corpus. Moore and Lewis (2010) reported that the perplexity decreases when less, but more appropriate data is used. Recent works expand this approach to bitexts (Axelrod et al., 2011; Mansour et al., 2011). Approaches like corpus weighting (Shah et al., 2010) or sentence weighting (Matsoukas et al., 2009; Mansour and Ney, 2012) are not suitable to our translation task because these approaches can produce huge models by considering the whole data. 3 Cross-entropy based Data Selection versus Infrequent n-gram Recovery In this section we detail the different approaches experimented with for data selection. On one hand we proc"
2014.amta-researchers.15,2012.amta-papers.19,0,0.0272372,"s. To obtain a mixture of domain-specific models trained on several different domain-specific corpora, they can be combined using a log-linear or a linear approach (Foster and Kuhn, 2007; Civera and Juan, 2007). The standard log-linear model may be used to combine some domainspecific models (Koehn and Schroeder, 2007). In the same way target language models may be combined using a log-linear or a linear combination (Schwenk and Koehn, 2008). Sennrich et al. (2013) proposed to combine different specific parts of the phrase-table during translation leading to a multi-domain adaptation approach. Niehues and Waibel (2012) compared several incremental approaches, namely the backoff, the factored, the log-linear and the fill-up (Bisazza et al., 2011) techniques. These approaches aim at adapting an MT system towards a target domain using small amounts of parallel in-domain data. The main outcome of this paper is that all the approaches successfully improve the generic model and none of them is better than the others. The performances of the approaches mainly depend on their match to the specific data. 2.3 Data selection The main idea of data selection is to try to take advantage of a generic corpus by picking out"
2014.amta-researchers.15,P03-1021,0,0.035916,"ere f1J = f1 . . . fJ is the source sentence, eI1 = e1 . . . eI the target sentence and sK 1 = s1 . . . sK their phrase segmentation and alignment. The feature functions hm include translation channel models in both directions, lexical smoothing models in both directions, an n-gram language model, phrase and word penalty, a jump-distance-based distortion model, a hierarchical orientation model (Galley and Manning, 2008) and an n-gram cluster language model (Wuebker et al., 2013). The log-linear feature weights λm are optimized on a development data set with minimum error rate training (MERT) (Och, 2003). As optimization criterion we use B LEU (Papineni et al., 2001). Al-Onaizan & Simard (Eds.) Proceedings of AMTA 2014, vol. 1: MT Researchers Vancouver, BC © The Authors 199 5 Experiments In this section we describe the different experiments we made in order to compare between the approaches. 5.1 The VideoLectures.NET Repository VideoLectures.NET1 is a free and open access repository of video lectures mostly filmed by people from the Jožef Stefan Institute (JSI, Slovenia) at major conferences, summer schools, workshops and science promotional events from many fields of science. VideoLectures.N"
2014.amta-researchers.15,J04-4002,1,0.68254,"Missing"
2014.amta-researchers.15,2001.mtsummit-papers.68,0,0.0282297,"e1 . . . eI the target sentence and sK 1 = s1 . . . sK their phrase segmentation and alignment. The feature functions hm include translation channel models in both directions, lexical smoothing models in both directions, an n-gram language model, phrase and word penalty, a jump-distance-based distortion model, a hierarchical orientation model (Galley and Manning, 2008) and an n-gram cluster language model (Wuebker et al., 2013). The log-linear feature weights λm are optimized on a development data set with minimum error rate training (MERT) (Och, 2003). As optimization criterion we use B LEU (Papineni et al., 2001). Al-Onaizan & Simard (Eds.) Proceedings of AMTA 2014, vol. 1: MT Researchers Vancouver, BC © The Authors 199 5 Experiments In this section we describe the different experiments we made in order to compare between the approaches. 5.1 The VideoLectures.NET Repository VideoLectures.NET1 is a free and open access repository of video lectures mostly filmed by people from the Jožef Stefan Institute (JSI, Slovenia) at major conferences, summer schools, workshops and science promotional events from many fields of science. VideoLectures.NET has so far published more than 15K lectures, all of them reco"
2014.amta-researchers.15,2008.iwslt-papers.6,0,0.0272986,"s was first proposed by Ueffing (2006) and refined by Ueffing et al. (2007). The main idea is to filter the translations with the translated test data. This process involves a confidence measure in order to select the Al-Onaizan & Simard (Eds.) Proceedings of AMTA 2014, vol. 1: MT Researchers Vancouver, BC © The Authors 194 most reliable data to train a small additional phrase table (PT). The generic and the new phrase tables are used jointly for translation, which can be seen as a mixture model with one specific PT built for each test set. The lightly-supervised training approach proposed by Schwenk (2008) does not adapt the model to the test data, but it proposes to add large amounts of monolingual training data translated using a completely new model. Lambert et al. (2011) enhanced this approach by using the translations of monolingual data in the target language. 2.2 Model combination and update One way to adapt MT models is to combine translation models. Models can be combined using the mixture-model approach, a log-linear combination or through incremental learning approaches. To obtain a mixture of domain-specific models trained on several different domain-specific corpora, they can be co"
2014.amta-researchers.15,I08-2089,0,0.0254036,"way to adapt MT models is to combine translation models. Models can be combined using the mixture-model approach, a log-linear combination or through incremental learning approaches. To obtain a mixture of domain-specific models trained on several different domain-specific corpora, they can be combined using a log-linear or a linear approach (Foster and Kuhn, 2007; Civera and Juan, 2007). The standard log-linear model may be used to combine some domainspecific models (Koehn and Schroeder, 2007). In the same way target language models may be combined using a log-linear or a linear combination (Schwenk and Koehn, 2008). Sennrich et al. (2013) proposed to combine different specific parts of the phrase-table during translation leading to a multi-domain adaptation approach. Niehues and Waibel (2012) compared several incremental approaches, namely the backoff, the factored, the log-linear and the fill-up (Bisazza et al., 2011) techniques. These approaches aim at adapting an MT system towards a target domain using small amounts of parallel in-domain data. The main outcome of this paper is that all the approaches successfully improve the generic model and none of them is better than the others. The performances o"
2014.amta-researchers.15,P13-1082,0,0.0129827,"to combine translation models. Models can be combined using the mixture-model approach, a log-linear combination or through incremental learning approaches. To obtain a mixture of domain-specific models trained on several different domain-specific corpora, they can be combined using a log-linear or a linear approach (Foster and Kuhn, 2007; Civera and Juan, 2007). The standard log-linear model may be used to combine some domainspecific models (Koehn and Schroeder, 2007). In the same way target language models may be combined using a log-linear or a linear combination (Schwenk and Koehn, 2008). Sennrich et al. (2013) proposed to combine different specific parts of the phrase-table during translation leading to a multi-domain adaptation approach. Niehues and Waibel (2012) compared several incremental approaches, namely the backoff, the factored, the log-linear and the fill-up (Bisazza et al., 2011) techniques. These approaches aim at adapting an MT system towards a target domain using small amounts of parallel in-domain data. The main outcome of this paper is that all the approaches successfully improve the generic model and none of them is better than the others. The performances of the approaches mainly"
2014.amta-researchers.15,W10-1759,0,0.335217,"Researchers Vancouver, BC © The Authors 195 sentences of the generic corpus are sorted regarding the computation of the difference between domain-specific score and generic score. At last, the best amount of the sorted data has to be determined. This best point is found by minimizing the perplexity of a development set on growing percentages of the sorted corpus. Moore and Lewis (2010) reported that the perplexity decreases when less, but more appropriate data is used. Recent works expand this approach to bitexts (Axelrod et al., 2011; Mansour et al., 2011). Approaches like corpus weighting (Shah et al., 2010) or sentence weighting (Matsoukas et al., 2009; Mansour and Ney, 2012) are not suitable to our translation task because these approaches can produce huge models by considering the whole data. 3 Cross-entropy based Data Selection versus Infrequent n-gram Recovery In this section we detail the different approaches experimented with for data selection. On one hand we process the data selection for both LM and translation model (TM) using cross-entropy. On the other hand, the infrequent n-gram recovery (Gascó et al., 2012), is explored. 3.1 Language Model Cross-entropy The LM cross-entropy differe"
2014.amta-researchers.15,steinberger-etal-2006-jrc,0,0.286062,"Missing"
2014.amta-researchers.15,tiedemann-2012-parallel,0,0.0508334,"slation task of the International Workshop on Spoken Language Translation4 as in-domain data. The general domain data consists of several corpora. The COSMAT scientific thesis abstracts (Lambert et al., 2012) and the news-commentary-v8 corpus, provided by the ACL 2013 8th Workshop on Statistical Machine Translation5 (WMT), are directly added to the baseline without instance selection due to their small size. The large corpora on which data selection is performed, are the Europarl-v7 corpus (also provided by WMT), the JRC-Acquis corpus (Steinberger et al., 2006) and the Open Subtitles corpus6 (Tiedemann, 2012). Data statistics for the complete in-domain and out-of-domain data are given in Table 1. For the development and test sets we selected four video lectures each, that were manually transcribed and professionally translated, resulting in a total of 1013 and 1360 sentences for development and test, respectively. In addition to the target side of the bilingual data, we leverage large amounts of monolingual resources for language model training. These include the Common Crawl Corpus, the 109 French-English corpus, the UN corpus and the News Crawl articles, available from the WMT 1 http://videolect"
2014.amta-researchers.15,2006.iwslt-papers.3,0,0.0243411,"on techniques in Section 3. Section 4 gives an account of the statistical translation system used in our experiments. Finally, the experimental setup and results are discussed in Section 5 and we conclude with Section 6. 2 Domain Adaptation Domain adaptation can be performed in different ways: using lightly-supervised approaches, model combination/update or data selection. 2.1 Lightly-supervised approaches A common way to adapt a statistical machine translation model is to use lightly-supervised approaches. These approaches aim to self-enhance the translation model. This was first proposed by Ueffing (2006) and refined by Ueffing et al. (2007). The main idea is to filter the translations with the translated test data. This process involves a confidence measure in order to select the Al-Onaizan & Simard (Eds.) Proceedings of AMTA 2014, vol. 1: MT Researchers Vancouver, BC © The Authors 194 most reliable data to train a small additional phrase table (PT). The generic and the new phrase tables are used jointly for translation, which can be seen as a mixture model with one specific PT built for each test set. The lightly-supervised training approach proposed by Schwenk (2008) does not adapt the mode"
2014.amta-researchers.15,P07-1004,0,0.0256273,"ction 4 gives an account of the statistical translation system used in our experiments. Finally, the experimental setup and results are discussed in Section 5 and we conclude with Section 6. 2 Domain Adaptation Domain adaptation can be performed in different ways: using lightly-supervised approaches, model combination/update or data selection. 2.1 Lightly-supervised approaches A common way to adapt a statistical machine translation model is to use lightly-supervised approaches. These approaches aim to self-enhance the translation model. This was first proposed by Ueffing (2006) and refined by Ueffing et al. (2007). The main idea is to filter the translations with the translated test data. This process involves a confidence measure in order to select the Al-Onaizan & Simard (Eds.) Proceedings of AMTA 2014, vol. 1: MT Researchers Vancouver, BC © The Authors 194 most reliable data to train a small additional phrase table (PT). The generic and the new phrase tables are used jointly for translation, which can be seen as a mixture model with one specific PT built for each test set. The lightly-supervised training approach proposed by Schwenk (2008) does not adapt the model to the test data, but it proposes t"
2014.amta-researchers.15,C12-3061,1,0.813971,"a is selected based on infrequent n-gram recovery and part is selected with TM model cross-entropy. This way, we hope to benefit from the new information introduced by the first while reinforcing a domain-specific distribution at the same time. In practice we start with the maximum amount of data selected by infrequent n-gram recovery. On top of this, we now add increasing amounts of data selected by TM model cross-entropy, until the full general domain data has been added. 4 Statistical Translation System We use the standard phrase-based translation decoder from the open source toolkit Jane (Wuebker et al., 2012) for all translation experiments. The translation process is framed as a loglinear combination of models, which is a generalization of the source-channel paradigm introˆ duced by Brown et al. (1993). The decoder searches for the best translation eˆI1 as defined by the I K J models hm (e1 , s1 , f1 ). It can be written as (Och and Ney, 2004) ( ˆ eˆI1 = arg max I,eI1 M X ) J λm hm (eI1 , sK 1 , f1 ) , (9) m=1 where f1J = f1 . . . fJ is the source sentence, eI1 = e1 . . . eI the target sentence and sK 1 = s1 . . . sK their phrase segmentation and alignment. The feature functions hm include transl"
2014.amta-researchers.15,D13-1138,1,0.836368,"models hm (e1 , s1 , f1 ). It can be written as (Och and Ney, 2004) ( ˆ eˆI1 = arg max I,eI1 M X ) J λm hm (eI1 , sK 1 , f1 ) , (9) m=1 where f1J = f1 . . . fJ is the source sentence, eI1 = e1 . . . eI the target sentence and sK 1 = s1 . . . sK their phrase segmentation and alignment. The feature functions hm include translation channel models in both directions, lexical smoothing models in both directions, an n-gram language model, phrase and word penalty, a jump-distance-based distortion model, a hierarchical orientation model (Galley and Manning, 2008) and an n-gram cluster language model (Wuebker et al., 2013). The log-linear feature weights λm are optimized on a development data set with minimum error rate training (MERT) (Och, 2003). As optimization criterion we use B LEU (Papineni et al., 2001). Al-Onaizan & Simard (Eds.) Proceedings of AMTA 2014, vol. 1: MT Researchers Vancouver, BC © The Authors 199 5 Experiments In this section we describe the different experiments we made in order to compare between the approaches. 5.1 The VideoLectures.NET Repository VideoLectures.NET1 is a free and open access repository of video lectures mostly filmed by people from the Jožef Stefan Institute (JSI, Sloven"
2014.amta-researchers.15,P02-1040,0,\N,Missing
2014.amta-researchers.15,D08-1076,0,\N,Missing
2015.jeptalnrecital-court.11,2012.eamt-1.41,0,0.0255172,"Missing"
2015.jeptalnrecital-court.11,2011.iwslt-evaluation.19,0,0.0486811,"Missing"
2015.jeptalnrecital-court.11,eck-etal-2004-language,0,0.104851,"Missing"
2015.jeptalnrecital-court.11,eisele-chen-2010-multiun,0,0.0343007,"Missing"
2015.jeptalnrecital-court.11,P08-2015,0,0.0420752,"Missing"
2015.jeptalnrecital-court.11,2005.mtsummit-papers.11,0,0.0331485,"Missing"
2015.jeptalnrecital-court.11,P07-2045,0,0.00549968,"Missing"
2015.jeptalnrecital-court.11,E09-1056,0,0.0739427,"Missing"
2015.jeptalnrecital-court.11,P10-2041,0,0.0693623,"Missing"
2015.jeptalnrecital-court.11,W12-5701,1,0.889795,"Missing"
2015.jeptalnrecital-court.11,P02-1040,0,0.090938,"Missing"
2015.jeptalnrecital-court.11,2013.mtsummit-posters.11,0,0.0594863,"Missing"
2015.jeptalnrecital-court.11,2006.amta-papers.25,0,0.0504523,"Missing"
2015.jeptalnrecital-court.11,W13-2234,0,0.0215121,"Missing"
C00-1036,W00-1404,1,0.361901,"mber x0 such that x is smaller than x0, where x is an arbitrary number given in the context (for the sake of Universal Introduction). 3 IG : Interaction Grammars We have just described an approach to solving the limitations of usual XML tools for multilingual document authoring which originates in the tradition of constructive type-theory and mathematical proof editors. We will now sketch an approach strongly inspired by GF but which formally is more in the tradition of logic-programming based unification grammars, and which is currently under development at Xerox Research Centre Europe (see (Brun et al., 2000) for a more extended description of this project). Definite Clause Grammars, or DCG’s, (Pereira and Warren, 1980), are possibly the simplest unificationbased extension of context-free grammars, and have good reversibility properties which make them adapted both to parsing and to generation. A typical view of what a DCG rule looks like is the following:5 a(a1(B,C,...)) --> <text1>, b(B), <text2>, c(C), <text3>, ... {constraints(B,C,...)}. This rule expresses the fact that (1) some abstract structure a1(B,C,...) is in category a if the structure B is in category b, the structure C in category c,"
C00-1036,C96-1043,0,0.0364204,"thoring in which the author is guided in the specification of the document content, and where the system is responsible 4 There are authoring situations in which it may be necessary for the user to introduce new semantic labels corresponding to expressive needs not foreseen by the creator of the original DTD. To handle such situations, it is useful to view the DTD’s as open-ended objects to which new semantic labels and types can be added at authoring time. for generating from this content textual output in several languages simultaneously (see (Power and Scott, 1998; Hartley and Paris, 1997; Coch, 1996)). Now there are some obvious problems with this view, due to the current limitations of XML tools. Limitations of XML for multilingual document authoring. The first, possibly most serious, limitation originates in the fact that a standard DTD is severely restricted in the semantic dependencies it can express between two subtrees in the document structure. Thus, if in the description of a contact, a city of residence is included, one may want to constrain such an information depending on the country of residence; or, in the aircraft maintenance manual example, one might want to automatically i"
C00-1036,P98-2173,0,0.170397,"on to the enterprise of Multilingual Document Authoring in which the author is guided in the specification of the document content, and where the system is responsible 4 There are authoring situations in which it may be necessary for the user to introduce new semantic labels corresponding to expressive needs not foreseen by the creator of the original DTD. To handle such situations, it is useful to view the DTD’s as open-ended objects to which new semantic labels and types can be added at authoring time. for generating from this content textual output in several languages simultaneously (see (Power and Scott, 1998; Hartley and Paris, 1997; Coch, 1996)). Now there are some obvious problems with this view, due to the current limitations of XML tools. Limitations of XML for multilingual document authoring. The first, possibly most serious, limitation originates in the fact that a standard DTD is severely restricted in the semantic dependencies it can express between two subtrees in the document structure. Thus, if in the description of a contact, a city of residence is included, one may want to constrain such an information depending on the country of residence; or, in the aircraft maintenance manual exam"
C00-1036,C98-2168,0,\N,Missing
C00-2149,P89-1018,0,0.0401931,"ough one might think of using finite-state models for representing compactly the language associated with a collection of graphs, they do not seem as relevant as context-free models for our purposes. The reason is that the source packed representations are typically obtained as the results of chart-parsing processes. A chart used in the parsing of a context-free grammar can itself be viewed as a context-free grammar, which is a specialization of the original grammar for the string being parsed, and which directly generates the derivation trees for this string relative to the original grammar (Billot and Lang, 1989).1 The generalization of this approach to unification grammars (of the LFG or DCG type) proposed in (Dymetman, 1997) shows that, in turn, chart-parsing with these unification grammars conducts naturally to packed representations for the parse results very close to the ones we are about to introduce. Let’s consider the CFG G0 : S! SAW ON WITH D3 SAW ! D0 arg101 i1 arg202 LIGHT LIGHT ! GREEN mod27 light2 GREEN ! green17 j green27 ON ! on3 arg234 hill4 WITH ! with5 arg256 telescope6 D0 ! see0 j saw0 D3 ! mod03 D30 j mod23 D32 D30 ! mod05 j mod45 D32 ! mod05 j mod25 j mod45 Nonterminals of that gr"
C00-2149,P97-1050,0,0.0610422,"Missing"
C00-2149,P98-1060,0,0.226141,"sentence and obviate the need to list and treat all these readings in isolation of each other (as is standard in more traditional models for machine translation). In the case of parsing, and more specifically, parsing with unification-based formalisms such as LFG, techniques for producing packed structures have been in existence for some time (Maxwell and Kaplan, 1991; Maxwell and Kaplan, 1993; Maxwell and Kaplan, 1996; D¨orre, 1997; Dymetman, 1997). More recently, techniques have been appearing for the generation from packed structures (Shemtov, 1997), the transfer between packed structures (Emele and Dorna, 1998; Rayner and Bouillon, 1995), and the integration of such mechanisms into the whole translation process (Kay, 1999; Frank, 1999). This paper focuses on the problem of transfer. The method proposed is related to those of (Emele and Dorna, 1998) and (Kay, 1999). As in these approaches, we view packed representations as being descriptions of a finite collection of directed labelled graphs (similar to the functional structures of LFG), each representing a different non-ambiguous reading, which share certain subparts. Fr´ed´eric Tendeau Lernout & Hauspie Koning Albert-I laan 64 B-1780 Wemmel, Belgi"
C00-2149,1999.mtsummit-1.20,0,0.0159576,"for machine translation). In the case of parsing, and more specifically, parsing with unification-based formalisms such as LFG, techniques for producing packed structures have been in existence for some time (Maxwell and Kaplan, 1991; Maxwell and Kaplan, 1993; Maxwell and Kaplan, 1996; D¨orre, 1997; Dymetman, 1997). More recently, techniques have been appearing for the generation from packed structures (Shemtov, 1997), the transfer between packed structures (Emele and Dorna, 1998; Rayner and Bouillon, 1995), and the integration of such mechanisms into the whole translation process (Kay, 1999; Frank, 1999). This paper focuses on the problem of transfer. The method proposed is related to those of (Emele and Dorna, 1998) and (Kay, 1999). As in these approaches, we view packed representations as being descriptions of a finite collection of directed labelled graphs (similar to the functional structures of LFG), each representing a different non-ambiguous reading, which share certain subparts. Fr´ed´eric Tendeau Lernout & Hauspie Koning Albert-I laan 64 B-1780 Wemmel, Belgium Frederic.Tendeau@lhs.be The representations of (Emele and Dorna, 1998) and (Kay, 1999) are based on a notion of propositional"
C00-2149,1999.mtsummit-1.2,0,0.0134416,"nal models for machine translation). In the case of parsing, and more specifically, parsing with unification-based formalisms such as LFG, techniques for producing packed structures have been in existence for some time (Maxwell and Kaplan, 1991; Maxwell and Kaplan, 1993; Maxwell and Kaplan, 1996; D¨orre, 1997; Dymetman, 1997). More recently, techniques have been appearing for the generation from packed structures (Shemtov, 1997), the transfer between packed structures (Emele and Dorna, 1998; Rayner and Bouillon, 1995), and the integration of such mechanisms into the whole translation process (Kay, 1999; Frank, 1999). This paper focuses on the problem of transfer. The method proposed is related to those of (Emele and Dorna, 1998) and (Kay, 1999). As in these approaches, we view packed representations as being descriptions of a finite collection of directed labelled graphs (similar to the functional structures of LFG), each representing a different non-ambiguous reading, which share certain subparts. Fr´ed´eric Tendeau Lernout & Hauspie Koning Albert-I laan 64 B-1780 Wemmel, Belgium Frederic.Tendeau@lhs.be The representations of (Emele and Dorna, 1998) and (Kay, 1999) are based on a notion of"
C00-2149,J93-4001,0,0.0112331,"important aspect of such models is the ability to handle, during all the stages of the translation process, packed linguistic structures, that is, structures which factorize in a compact fashion all the different readings of a sentence and obviate the need to list and treat all these readings in isolation of each other (as is standard in more traditional models for machine translation). In the case of parsing, and more specifically, parsing with unification-based formalisms such as LFG, techniques for producing packed structures have been in existence for some time (Maxwell and Kaplan, 1991; Maxwell and Kaplan, 1993; Maxwell and Kaplan, 1996; D¨orre, 1997; Dymetman, 1997). More recently, techniques have been appearing for the generation from packed structures (Shemtov, 1997), the transfer between packed structures (Emele and Dorna, 1998; Rayner and Bouillon, 1995), and the integration of such mechanisms into the whole translation process (Kay, 1999; Frank, 1999). This paper focuses on the problem of transfer. The method proposed is related to those of (Emele and Dorna, 1998) and (Kay, 1999). As in these approaches, we view packed representations as being descriptions of a finite collection of directed la"
C00-2149,C98-1058,0,\N,Missing
C02-1128,P98-2173,0,0.251231,"he knowledge base. In this way the information implicitly encoded in a document becomes explicit in the knowledge base and can be re-exploited for simplifying the authoring of new documents. We show how a Datalog KB is sufficient for the closed-world situation, while a Description Logic KB is better-adapted to the more complex open-world situation. All along, we pay special attention to logically sound solutions and to decidability issues in the different processes. Introduction Recently there has been a surge of interest in interactive natural language generation systems (Paris et al., 1995; Power and Scott, 1998; Coch and Chevreau, 2001); such systems rely on a capability of generating a natural language text from an abstract content representation, but — contrary to traditional NLG (Natural Language Generation) systems — this representation is only partially available at the beginning of the text production process; it is then gradually completed by a human author, typically using content-selection menus correlated with regions of the evolving generated text.. One such system, MDA (Multilingual Document Authoring) (citation omitted) is based on a formal specification — using a variant of Definite Cl"
C02-1128,C98-2168,0,\N,Missing
C16-1103,D14-1179,0,0.034582,"Missing"
C16-1103,W04-3250,0,0.0349646,"Missing"
C16-1103,P98-1116,0,0.243262,"weighted finite-state automaton over character sequences. Automatic and human evaluations show improved performance over baselines on several evaluation criteria. 1 Introduction Rule-based Natural Language Generation systems (Reiter and Dale, 2000) have been quite successful but they suffer from some limitations. They require extensive human effort and tend to produce fixed, repetitive outputs, which do not closely match human-like utterances. For this reason, there has been much interest recently in developing NLG systems which are, at least partially, able to learn from human produced data (Langkilde and Knight, 1998; Belz, 2008). In the last couple of years, Neural Network (NN) based approaches have gained enormous popularity within statistical NLP generally, with applications to Machine Translation (Sutskever et al., 2014), Conversation Modelling (Vinyals and Le, 2015) and Parsing (Tai et al., 2015), to cite only a few. In particular, architectures based on Recurrent Neural Network (RNN) such as LSTMs (Hochreiter and Schmidhuber, 1997) and GRUs (Cho et al., 2014) have been succesfully used in Language Modelling tasks due to their ability to model sequential information with long-range dependencies. An R"
C16-1103,P16-1057,0,0.050126,"Missing"
C16-1103,P16-1100,0,0.130263,"accepting any substring from the dialog act such as the number “182” (bottom of the figure). The large central state is both initial and final. Differently from (Wen et al., 2015), who use a one-hot encoding for the input DA, and also add a special gate mechanism to better control the consumption of slots, here we simply treat the DA as a sequence of word tokens. Character-based model (C) Our second model is a character-based model in which both the input and the output are character strings. Such models have been used in NMT (Neural MT) to tackle the problem of rare words (Ling et al., 2015; Luong and Manning, 2016). One advantage is that they work over a small vocabulary (∼ 50 symbols), which they have each observed many times; in consequence, they have the ability to learn to map a character onto itself, if the context requires it. This copy mechanism is useful for carrying material from the original unprocessed input to the target, and, perhaps counter-intuitively, is not present in usual wordbased RNNs, which have to learn each mapping from scratch (but see fn. 3, as well as the related work section 5 below about augmenting word-level RNNs with a copy ability). Character-based model(s) with a Finite"
C16-1103,P02-1040,0,0.0947513,"∗∗ 0.846 0.530∗∗ ∗∗ 0.820 0.609∗∗ 0.973 0.778 No non-words 0.989 0.911∗∗ 0.974∗ 0.996 0.994 0.926∗∗ 0.959∗∗ 0.997 Fluency Non-redundant 0.941∗ 0.974 0.974 0.978 0.976 0.988 0.935∗∗ 0.982 Naturalness 1.841∗ 1.674∗∗ 1.756∗∗ 1.926 1.908 1.787∗∗ 1.731∗∗ 1.932 Table 2: Human evaluation of top realisation of the models. Statistical significance is computed through a pairwise difference one-tailed Student’s t-test between the model with maximum score against the others. ∗ p &lt; 0.05, ∗∗ p &lt; 0.01. 4.3 Evaluation 4.3.1 Automatic Evaluation Automatic evaluation results are shown in Table 1, using BLEU-4 (Papineni et al., 2002).7 The results are shown for the four models (WORD, C, C-NWFSA, C-WFSA) described earlier, evaluated over our test sets for Hotel (538 realisations) and Restaurant (520 realisations). 4.3.2 Manual Evaluation The automatic metrics do not always correlate with human judgement, so we also perform manual evaluation, based on the following adequacy (information conveyed) and fluency (linguistic quality) scales: 1. Adequacy: • Precision (i.e. “Correctness”) [1/0]: all information in the DA is present in the generated utterance (1=yes, 0=no). • Recall (i.e. “Completeness”) [1/0]: all information in t"
C16-1103,P15-1150,0,0.0346234,"me limitations. They require extensive human effort and tend to produce fixed, repetitive outputs, which do not closely match human-like utterances. For this reason, there has been much interest recently in developing NLG systems which are, at least partially, able to learn from human produced data (Langkilde and Knight, 1998; Belz, 2008). In the last couple of years, Neural Network (NN) based approaches have gained enormous popularity within statistical NLP generally, with applications to Machine Translation (Sutskever et al., 2014), Conversation Modelling (Vinyals and Le, 2015) and Parsing (Tai et al., 2015), to cite only a few. In particular, architectures based on Recurrent Neural Network (RNN) such as LSTMs (Hochreiter and Schmidhuber, 1997) and GRUs (Cho et al., 2014) have been succesfully used in Language Modelling tasks due to their ability to model sequential information with long-range dependencies. An RNN-based approach to NLG has been recently proposed by Wen et al. (2015) in the context of a dialog system, where the input semantic representation is a Dialog Act (DA). The decoder uses words as the units of generation. This word-based model requires pre-processing the original data by su"
C16-1103,D15-1199,0,0.142898,"Missing"
C16-1103,P16-1127,1,0.813044,"dresses, telephone numbers, etc., have to be replaced by place-holders such as REST NAME, TEL NUMBER, and the like. These entities are then re-lexicalized at the end of the decoding to form the final utterance. 2 The log-linear RNNs introduced in (Dymetman and Xiao, 2016) go beyond background-adaptor RNNs as described here: we only exploit the part of log-linear RNNs concerned with the distinction between the “background” and the “adaptor”, not the aspects having to do with log-linear features. The use of a background for supporting RNN training is also implicit in the semantic parsing paper (Xiao et al., 2016). 3 To emphasize this point, let us note that, in standard word-based seq2seq RNNs, the input and output vocabularies are totally disjoint. In order to map the input word “Ritz” into the output word “Ritz”, the RNN has to learn the mapping from scratch based on training data, and cannot rely on any a priori knowledge about the correspondence; if “Ritz” is rare (or nonexistent) in the training data, the mapping cannot be learnt reliably (or at all). By de-lexicalizing “Ritz” into the generic “HOTEL”, both in the input and output, the training is much simplified: the RNN only has to learn to map"
C16-1103,C98-1112,0,\N,Missing
C88-1053,1988.tmi-1.12,1,0.858295,"DCGlike rules which have a well-defined declarative semantics; however, we enrich these rules with control annotations which, while not affecting their semantics, provide a rule compiler with the information needed to produce both an analysis-oriented and a synthesis-oriented version of the rule. Left-recursion is elinfinated in the analysis version, and both versions typically display a different ordering of the goals. The result is that we can actually derive fairly efficient parsers and synthesizers from one and the same grammar. For furtber details on this double-compilation approach, see Dymetman & Isabelle (1988). ~.3 Checking of semantic well-formedness In order for a semantic structure built by this compositional process to be accepted as valid, it must pass a semantic well-formedness check, which involves semantic constraints and the type subsumption hierarchy. This check can be briefly described as follows: for each predicative (or functional) node pn in the semantie structure, having an1, an2.., as argument nodes, one tries to find a validating schema (see §3.3) PT(AT1,AT2,....) such that PT is a type subsuming pn, AT1 a type subsuming anl, AT2 a type subsuming an2 .... For instance, given the se"
C88-1053,C86-1025,1,0.884208,"Missing"
C88-1053,J81-4003,0,0.259881,"Missing"
C90-3017,1988.tmi-1.12,1,0.894844,"Missing"
C90-3017,C88-1053,1,0.804851,"Missing"
C90-3017,C88-2128,0,0.113801,"Missing"
C90-3017,P89-1002,0,0.487831,"Missing"
C90-3017,J81-4003,0,\N,Missing
C92-1057,1988.tmi-1.12,1,0.824627,"s, an algorithm which is able, for any offline-parsable DCGx, to decide whether a given string is accepted or not by DCG1 is said to be strongly stable [7]. Most parsing algorithms are not strongly stables, a notable exception being the ""Earley deduction"" algorithm [7], once modified according to the proposals in [10].4 Top-down implementations--and in particular the standard Prolog implementation of a DCG---are especially fragile in this respect, for they fail to terminate as soon as the grammar contains a left-recursive rule such as: vp(VP2) ~ vp(VPt),pp(PP), { combine(V P1, P P, V P2)}. In [2], automatic local transformations were performed on a DCG in order to eliminate some limited, but frequent in practice, types of left-recarsion in such a way that the resulting grammar could be directly implemented in Prolog. This initial work led us naturally to the more general question: Question: Is it possible to automatically transform an assumption that auxiliary predicates are unifications takes care of this interfering problem. aAn important cl~s of offline-parsable grammars---which we will call here the class of explicitly offline-parsable grammars--is the class of DCGs whose context"
C92-1057,P89-1029,0,0.0736068,"s"" {p(Ti', .... T~')}. SSee the Appendix for some indications on the methods used. SThus. a side-effect of the GGNF is to provide a decision procedure for the problem of knowing whether a DCG is offline-parsable or not. This is equivalent to deciding whether a eomext-free grammar is infinitely ambiguous or not, a problem the decidability of which seems to be ""quasi.folk-knowledge"", although I was innocent of this until the fact was brought to my attention by Yves Schabes, among others: the proof is more or less implicit in the usual technique to make a CFG ""cycle-free"", [1, p. 150] . See also [4] for a special case of this problem. (Caveat. The notion of ""cycle"" in ""cycle-free"" is technically different from the notion used here, which simply means: cycle in the graph associated with the relation ""callable from"". See note 10.) ACRESDE COLING-92, NAhq~S, 23-28 AO~r 1992 a l ( X ) ~ [oh], 367 If a definite program definiug these auxiliary predicates is added to the definite grammar scheme, one obtains a full-fledged definite clause grammar, which can be interpreted in the usual manner. Conversely, every definite clause g r a m m a r can be seen as the conjunction of a definite grammar sc"
C92-1057,P83-1021,0,0.0681499,"texmination, for reasons quite independent from the structure of the grammar under consideration. The AcrEs DECOLIN'G-92, NANT~.s,23-28 hOt]T 1992 366 In other words, there does not exist, in general, an algorithm for deciding whether a definil~ clause grammar DCGI accepts a string String, i.e. whether there exists some linguistic structure S such that DCG1 ""analyses String into S ' . On the other hand, ander the condition that DCCx is offline-parsable, that is, under the condition that the context-free skeleton of DCG1 is not infinitely ambiguous, then the parsing problem is indeed decidable [7]. The fact that the parsing problem with DCGt is decidable in theory should be carefully distinguished from the fact that a given algorithm for parsing is able to exploit this potentiality. A parsing algorithm for which this is the case, that is, an algorithm which is able, for any offline-parsable DCGx, to decide whether a given string is accepted or not by DCG1 is said to be strongly stable [7]. Most parsing algorithms are not strongly stables, a notable exception being the ""Earley deduction"" algorithm [7], once modified according to the proposals in [10].4 Top-down implementations--and in p"
C92-1057,P85-1018,0,0.0237541,"e parsing problem is indeed decidable [7]. The fact that the parsing problem with DCGt is decidable in theory should be carefully distinguished from the fact that a given algorithm for parsing is able to exploit this potentiality. A parsing algorithm for which this is the case, that is, an algorithm which is able, for any offline-parsable DCGx, to decide whether a given string is accepted or not by DCG1 is said to be strongly stable [7]. Most parsing algorithms are not strongly stables, a notable exception being the ""Earley deduction"" algorithm [7], once modified according to the proposals in [10].4 Top-down implementations--and in particular the standard Prolog implementation of a DCG---are especially fragile in this respect, for they fail to terminate as soon as the grammar contains a left-recursive rule such as: vp(VP2) ~ vp(VPt),pp(PP), { combine(V P1, P P, V P2)}. In [2], automatic local transformations were performed on a DCG in order to eliminate some limited, but frequent in practice, types of left-recarsion in such a way that the resulting grammar could be directly implemented in Prolog. This initial work led us naturally to the more general question: Question: Is it possible"
C94-2199,1988.tmi-1.12,1,0.837959,"Missing"
C94-2199,P83-1021,0,0.0192878,"Missing"
C94-2199,P80-1024,0,0.0439601,"Missing"
C94-2199,J92-2002,0,0.037065,"Missing"
C94-2199,C90-3017,1,\N,Missing
C94-2199,C92-1057,1,\N,Missing
C96-1044,C88-1053,1,\N,Missing
D12-1103,D11-1003,0,0.239312,"Missing"
D12-1103,W06-1673,0,0.0248388,"1 The necessity of exact sampling can be questioned in practice. Approximate sampling techniques have been developed over the last century and seem sufficient for most purposes. However, the cases where one actually knows the quality of a sampling algorithm are very rare, and it is common practice to forget about the approximation and simply treat the result of a sampler as a set of i.i.d. data. Exact sampling provides a de-facto guarantee that the samples are truly independent. This is particularly relevant when one uses a cascade of algorithms in complex NLP processing chains, as shown by (Finkel et al., 2006) in their work on linguistic annotation pipelines. Introduction In NLP, sampling is important for many real tasks, such as: (i) diversity in language generation or machine translation (proposing multiple alternatives which are not clustered around a single maximum); (ii) Bayes error minimization, for instance in Statistical Machine Translation (Kumar and Byrne, 2004); (iii) learning of parametric and non-parametric Bayesian models (Teh, 2006). However, most practical sampling algorithms are based on MCMC, i.e. they are based on local moves ∗ This work was conducted during an internship at XRCE"
D12-1103,2005.mtsummit-papers.11,0,0.182772,"Missing"
D12-1103,N04-1022,0,0.0544368,"sampler as a set of i.i.d. data. Exact sampling provides a de-facto guarantee that the samples are truly independent. This is particularly relevant when one uses a cascade of algorithms in complex NLP processing chains, as shown by (Finkel et al., 2006) in their work on linguistic annotation pipelines. Introduction In NLP, sampling is important for many real tasks, such as: (i) diversity in language generation or machine translation (proposing multiple alternatives which are not clustered around a single maximum); (ii) Bayes error minimization, for instance in Statistical Machine Translation (Kumar and Byrne, 2004); (iii) learning of parametric and non-parametric Bayesian models (Teh, 2006). However, most practical sampling algorithms are based on MCMC, i.e. they are based on local moves ∗ This work was conducted during an internship at XRCE. In this paper, we present an approach for exact decoding and sampling with an HMM whose hidden layer is a high-order language model (LM), which innovates on existing techniques in the following ways. First, it is a joint approach to sampling and optimization (i.e. decoding), which is based on introducing a simplified, “optimistic”, version q(x) of the underlying la"
D12-1103,J93-2004,0,0.0389551,"Missing"
D12-1103,P11-1008,0,0.172753,"Missing"
D12-1103,D10-1001,0,0.0320152,"alized to many others models of interest for NLP applications. One family of models is provided by agreement-based models, for example HMM+PCFG, where distribution p takes the form of a product: p(x) = pHMM (x)pPCFG (x). Even if the factors pHMM (x) and pPCFG (x) can be decoded and sampled efficiently, the product of them is intractable. Dual decomposition is a generic method that has been proposed for handling decoding (i.e. optimization) with such models, by decoupling the problem into two alternating steps that can each be handled by dynamic programming or other polynomial-time algorithms (Rush et al., 2010), an approach that has been applied to Statistical Machine Translation (phrase-based (Chang and Collins, 2011) and hierarchical (Rush and Collins, 2011)) among others. However, sampling such distributions remains a difficult problem. We are currently extending the approach described in this paper to handle such applications. Again, using ARS on a sequence of upper bounds to the target distribution, our idea is to express one of the two models as a context free grammar and incrementally compute the intersection with the second model, maintaining a good trade-off between computational tractabili"
D12-1103,P06-1124,0,0.0286258,"mples are truly independent. This is particularly relevant when one uses a cascade of algorithms in complex NLP processing chains, as shown by (Finkel et al., 2006) in their work on linguistic annotation pipelines. Introduction In NLP, sampling is important for many real tasks, such as: (i) diversity in language generation or machine translation (proposing multiple alternatives which are not clustered around a single maximum); (ii) Bayes error minimization, for instance in Statistical Machine Translation (Kumar and Byrne, 2004); (iii) learning of parametric and non-parametric Bayesian models (Teh, 2006). However, most practical sampling algorithms are based on MCMC, i.e. they are based on local moves ∗ This work was conducted during an internship at XRCE. In this paper, we present an approach for exact decoding and sampling with an HMM whose hidden layer is a high-order language model (LM), which innovates on existing techniques in the following ways. First, it is a joint approach to sampling and optimization (i.e. decoding), which is based on introducing a simplified, “optimistic”, version q(x) of the underlying language model p(x), for which it is tractable to use standard dynamic programm"
D12-1103,A00-1031,0,\N,Missing
D14-1131,W09-0437,0,0.0142068,"the leftmost uncovered source position (Lopez, 2009). This is a widely used strategy and it is in use in the Moses toolkit (Koehn et al., 2007).8 Nevertheless, the problem of finding the best 7 If d is a maximum from g and g(d) = f (d), then it is easy to show by contradiction that d is the actual maximum from f : if there existed d0 such that f (d0 ) &gt; f (d), then it follows that g(d0 ) ≥ f (d0 ) &gt; f (d) = g(d), and hence d would not be a maximum for g. 8 A distortion limit characterises a form of pruning that acts directly in the generative capacity of the model leading to induction errors (Auli et al., 2009). Limiting reordering like that lowers complexity to a polynomial function of I and an exponential function of the distortion limit. 1240 derivation under the model remains impracticable due to nonlocal parameterisation (namely, the n-gram LM component). The weighted set hD(x), f (d)i, which represents the objective, is a complex hypergraph which we cannot afford to construct. We propose to construct instead a simpler hypergraph for which optimisation by dynamic programming is feasible. This proxy rep resents the weighted set D(x), g (0) (d) , where g (0) (d) ≥ f (d) for every d ∈ D(x). Note t"
D14-1131,W13-2260,1,0.88383,"1997; Och et al., 2001), thus it is common to resort to heuristic techniques in order to find an approximation to d∗ (Koehn et al., 2003; Chiang, 2007). Evaluation exercises indicate that approximate search algorithms work well in practice (Bojar et al., 2013). The most popular algorithms provide solutions with unbounded error, thus precisely quantifying their performance requires the development of a tractable exact decoder. To date, most attempts were limited to short sentences and/or somewhat toy models trained with artificially small datasets (Germann et al., 2001; Iglesias et al., 2009; Aziz et al., 2013). Other work has employed less common approximations to the model reducing its search space complexity (Kumar et al., 2006; Chang and Collins, 2011; Rush and Collins, 2011). These do not answer whether or not current decoding algorithms perform well at real translation tasks with state-of-the-art models. We propose an exact decoder for phrase-based SMT based on a coarse-to-fine search strategy (Dymetman et al., 2012). In a nutshell, we relax the decoding problem with respect to the Language Model (LM) component. This coarse view is incrementally refined based on evidence col1237 Proceedings of"
D14-1131,J93-2003,0,0.06433,"siting groups using a priority queue: if the top group contains a single hypothesis, the hypothesis is added to the beam, otherwise the group is partitioned and the parts are pushed back to the queue. More recently, Heafield et al. (2014) applied their beam filling algorithm to phrase-based decoding. 3.2 Exact optimisation Exact optimisation for monotone translation has been done using A∗ search (Tillmann et al., 1997) and finite-state operations (Kumar et al., 2006). Och et al. (2001) design near-admissible heuristics for A∗ and decode very short sentences (614 words) for a word-based model (Brown et al., 1993) with a maximum distortion strategy (d = 3). Zaslavskiy et al. (2009) frame phrase-based decoding as an instance of a generalised Travelling Salesman Problem (TSP) and rely on robust solvers to perform decoding. In this view, a salesman graph encodes the translation options, with each node representing a biphrase. Nonoverlapping constraints are imposed by the TSP solver, rather than encoded directly in the salesman graph. They decode only short sentences (17 words on average) using a 2-gram LM due to salesman graphs growing too large.4 Chang and Collins (2011) relax phrase-based models w.r.t."
D14-1131,D12-1103,1,0.792042,"esents a left-shift. The rule N ON - ADJACENT handles the remaining cases i &gt; l provided that the expansion skips at most d input words |r − i + 1 |≤ d. In the consequent, the window C is simply updated to record the translation of the input span i..i0 . In the nonadjacent case, a gap constraint imposes that the resulting item will require skipping no more than d positions before the leftmost uncovered word is translated |i0 − l + 1 |≤ d.10 Finally, note that deductions incorporate the weighted upperbound ω(·), rather than the true LM component ψ(·).11 4.3 LM upperbound and Max-ARPA Following Carter et al. (2012) we compute an upperbound on n-gram conditional probabilities by precomputing max-backoff weights stored in a “Max-ARPA” table, an extension of the ARPA format (Jurafsky and Martin, 2000). A standard ARPA table T stores entries 10 This constraint prevents items from becoming dead-ends where incomplete derivations require a reordering step larger than d. This is known to prevent many search errors in beam search (Chang and Collins, 2011). 11 Unlike Aziz et al. (2013), rather than unigrams only, we score all n-grams within a translation rule (including incomplete ones). 1241 hZ, Z.p, Z.bi, where"
D14-1131,J07-2003,0,0.49343,"d = he1 , e2 , . . . , el i is a sequence of l steps. Under this assumption, each step is assigned the weight w(e) = Λ·hh1 (e), h2 (e), . . . , hm (e)i. The set D is typically finite, however, it contains a very large number of structures — exponential (or even factorial, see §2) with the size of x — making exhaustive enumeration prohibitively slow. Only in very restricted cases combinatorial optimisation techniques are directly applicable (Tillmann et al., 1997; Och et al., 2001), thus it is common to resort to heuristic techniques in order to find an approximation to d∗ (Koehn et al., 2003; Chiang, 2007). Evaluation exercises indicate that approximate search algorithms work well in practice (Bojar et al., 2013). The most popular algorithms provide solutions with unbounded error, thus precisely quantifying their performance requires the development of a tractable exact decoder. To date, most attempts were limited to short sentences and/or somewhat toy models trained with artificially small datasets (Germann et al., 2001; Iglesias et al., 2009; Aziz et al., 2013). Other work has employed less common approximations to the model reducing its search space complexity (Kumar et al., 2006; Chang and"
D14-1131,W13-2212,0,0.0177391,"t. the upperbound distribution) due to an extended context. LM 5 LM Experiments We used the dataset made available by the Workshop on Statistical Machine Translation (WMT) (Bojar et al., 2013) to train a German-English phrase-based system using the Moses toolkit (Koehn et al., 2007) in a standard setup. For phrase extraction, we used both Europarl (Koehn, 2005) and News Commentaries (NC) totalling about 2.2M sentences.15 For language modelling, in addition to the monolingual parts of Europarl 15 Pre-processing: tokenisation, truecasing and automatic compound-splitting (German only). Following Durrani et al. (2013), we set the maximum phrase length to 5. where w0 = λψ qLM (yγ0 ) qLM (γ0 ) Figure 4: Local intersection via LM right state refinement. The input is a hypergraph G = hV, Ei, a node v0 ∈ V singly identified by its carry [l0 , C0 , r0 , γ0 ] and a left-extension y for its LM context γE0 . The program copies most of the edges D w → v ∈ E. If a derivation goes through v0 uσ − and the string under v0 ends in yγ0 , the program refines and reweights it. and NC, we added News-2013 totalling about 25M sentences. We performed language model interpolation and batch-mira tuning (Cherry and Foster, 2012) u"
D14-1131,W12-6106,1,0.916844,"exact decoder. To date, most attempts were limited to short sentences and/or somewhat toy models trained with artificially small datasets (Germann et al., 2001; Iglesias et al., 2009; Aziz et al., 2013). Other work has employed less common approximations to the model reducing its search space complexity (Kumar et al., 2006; Chang and Collins, 2011; Rush and Collins, 2011). These do not answer whether or not current decoding algorithms perform well at real translation tasks with state-of-the-art models. We propose an exact decoder for phrase-based SMT based on a coarse-to-fine search strategy (Dymetman et al., 2012). In a nutshell, we relax the decoding problem with respect to the Language Model (LM) component. This coarse view is incrementally refined based on evidence col1237 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1237–1249, c October 25-29, 2014, Doha, Qatar. 2014 Association for Computational Linguistics lected via maximisation. A refinement increases the complexity of the model only slightly, hence dynamic programming remains feasible throughout the search until convergence. We test our decoding strategy with realistic models using stand"
D14-1131,D11-1003,0,0.642929,"ang, 2007). Evaluation exercises indicate that approximate search algorithms work well in practice (Bojar et al., 2013). The most popular algorithms provide solutions with unbounded error, thus precisely quantifying their performance requires the development of a tractable exact decoder. To date, most attempts were limited to short sentences and/or somewhat toy models trained with artificially small datasets (Germann et al., 2001; Iglesias et al., 2009; Aziz et al., 2013). Other work has employed less common approximations to the model reducing its search space complexity (Kumar et al., 2006; Chang and Collins, 2011; Rush and Collins, 2011). These do not answer whether or not current decoding algorithms perform well at real translation tasks with state-of-the-art models. We propose an exact decoder for phrase-based SMT based on a coarse-to-fine search strategy (Dymetman et al., 2012). In a nutshell, we relax the decoding problem with respect to the Language Model (LM) component. This coarse view is incrementally refined based on evidence col1237 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1237–1249, c October 25-29, 2014, Doha, Qatar. 2014 Associa"
D14-1131,P01-1030,0,0.385025,"ues are directly applicable (Tillmann et al., 1997; Och et al., 2001), thus it is common to resort to heuristic techniques in order to find an approximation to d∗ (Koehn et al., 2003; Chiang, 2007). Evaluation exercises indicate that approximate search algorithms work well in practice (Bojar et al., 2013). The most popular algorithms provide solutions with unbounded error, thus precisely quantifying their performance requires the development of a tractable exact decoder. To date, most attempts were limited to short sentences and/or somewhat toy models trained with artificially small datasets (Germann et al., 2001; Iglesias et al., 2009; Aziz et al., 2013). Other work has employed less common approximations to the model reducing its search space complexity (Kumar et al., 2006; Chang and Collins, 2011; Rush and Collins, 2011). These do not answer whether or not current decoding algorithms perform well at real translation tasks with state-of-the-art models. We propose an exact decoder for phrase-based SMT based on a coarse-to-fine search strategy (Dymetman et al., 2012). In a nutshell, we relax the decoding problem with respect to the Language Model (LM) component. This coarse view is incrementally refin"
D14-1131,N12-1047,0,0.0208928,"wing Durrani et al. (2013), we set the maximum phrase length to 5. where w0 = λψ qLM (yγ0 ) qLM (γ0 ) Figure 4: Local intersection via LM right state refinement. The input is a hypergraph G = hV, Ei, a node v0 ∈ V singly identified by its carry [l0 , C0 , r0 , γ0 ] and a left-extension y for its LM context γE0 . The program copies most of the edges D w → v ∈ E. If a derivation goes through v0 uσ − and the string under v0 ends in yγ0 , the program refines and reweights it. and NC, we added News-2013 totalling about 25M sentences. We performed language model interpolation and batch-mira tuning (Cherry and Foster, 2012) using newstest2010 (2,849 sentence pairs). For tuning we used cube pruning with a large beam size (k = 5000) and a distortion limit d = 4. Unpruned language models were trained using lmplz (Heafield et al., 2013b) which employs modified Kneser-Ney smoothing (Kneser and Ney, 1995). We report results on newstest2012. Our exact decoder produces optimal translation derivations for all the 3,003 sentences in the test set. Table 1 summarises the performance of our novel decoder for language models of order n = 3 to n = 5. For 3-gram LMs we also varied the distortion limit d (from 4 to 6). We report"
D14-1131,J99-4004,0,0.12781,"Missing"
D14-1131,P05-1033,0,0.0283693,"noverlapping constraints are imposed by the TSP solver, rather than encoded directly in the salesman graph. They decode only short sentences (17 words on average) using a 2-gram LM due to salesman graphs growing too large.4 Chang and Collins (2011) relax phrase-based models w.r.t. the non-overlapping constraints, which are replaced by soft penalties through Lagrangian multipliers, and intersect the LM component exhaustively. They do employ a maximum distortion limit (d = 4), thus the problem they tackle is no longer NP-complete. Rush and Collins (2011) relax a hierarchical phrase-based model (Chiang, 2005)5 w.r.t. the LM component. The translation forest and the language model trade their weights (through Lagrangian multipliers) so as to ensure agreement on what each component believes to be the maximum. In both approaches, when the dual converges to a compliant solution, the solution is guaranteed to be optimal. Other4 Exact decoding had been similarly addressed with Integer Linear Programming (ILP) in the context of word-based models for very short sentences using a 2-gram LM (Germann et al., 2001). Riedel and Clarke (2009) revisit that formulation and employ a cutting-plane algorithm (Dantzi"
D14-1131,N13-1116,0,0.108849,"rding to common traits and a fast-to-compute heuristic view of outside weights (cheapest way to complete a hypothesis) puts them to compete at a fairer level. Beam search exhausts a node’s possible expansions, scores them, and discards all but the k highest-scoring ones. This process is wasteful in that k is typically much smaller than the number of possible expansions. Cube pruning employs a priority queue at beam filling and computes k highscoring expansions directly in near best-first order. The parameter k is known as beam size and it controls the time-accuracy trade-off of the algorithm. Heafield et al. (2013a) move away from using the language model as a black-box and build a more involved beam filling algorithm. Even though they target approximate search, some of their ideas have interesting connections to ours (see §4). They group hypotheses that share partial language model state (Li and Khudanpur, 2008) reasoning over multiple hypotheses at once. They fill a beam in best-first order by iteratively visiting groups using a priority queue: if the top group contains a single hypothesis, the hypothesis is added to the beam, otherwise the group is partitioned and the parts are pushed back to the qu"
D14-1131,P13-2121,0,0.075138,"Missing"
D14-1131,P14-2022,0,0.0232288,"Missing"
D14-1131,P07-1019,0,0.0131256,"erised and contains all translation derivations (a translation lattice or forest), and one that re-ranks the first as a function of the interactions between translation steps. The model of translational equivalences parameterised only with φ is an instance of the former. An n-gram LM component is an instance of the latter. 2.1 Hypergraphs A backward-hypergraph, or simply hypergraph, is a generalisation of a graph where edges have multiple origins and one destination (Gallo et al., 1993). They can represent both finite-state and context-free weighted sets and they have been widely used in SMT (Huang and Chiang, 2007). A hypergraph is defined by a set of nodes (or ver3 Figure 1 can be seen as a specification for a weighted acyclic finite-state automaton whose states are indexed by [l, C, r] and transitions are labelled with biphrases. However, for generality of representation, we opt for using acyclic hypergraphs instead of automata (see §2.1). 1238 tices) V and a weighted set of edges hE, wi. An edge e connects a sequence of nodes in its tail t[e] ∈ V ∗ under a head node h[e] ∈ V and has weight w(e). A node v is a terminal node if it has no incoming edges, otherwise it is a nonterminal node. The node that"
D14-1131,E09-1044,0,0.0282357,"Missing"
D14-1131,J00-4006,0,0.0193412,"w C is simply updated to record the translation of the input span i..i0 . In the nonadjacent case, a gap constraint imposes that the resulting item will require skipping no more than d positions before the leftmost uncovered word is translated |i0 − l + 1 |≤ d.10 Finally, note that deductions incorporate the weighted upperbound ω(·), rather than the true LM component ψ(·).11 4.3 LM upperbound and Max-ARPA Following Carter et al. (2012) we compute an upperbound on n-gram conditional probabilities by precomputing max-backoff weights stored in a “Max-ARPA” table, an extension of the ARPA format (Jurafsky and Martin, 2000). A standard ARPA table T stores entries 10 This constraint prevents items from becoming dead-ends where incomplete derivations require a reordering step larger than d. This is known to prevent many search errors in beam search (Chang and Collins, 2011). 11 Unlike Aziz et al. (2013), rather than unigrams only, we score all n-grams within a translation rule (including incomplete ones). 1241 hZ, Z.p, Z.bi, where Z is an n-gram equal to the concatenation Pz of a prefix P with a word z, Z.p is the conditional probability p(z|P), and Z.b is a so-called “backoff” weight associated with Z. The condit"
D14-1131,J99-4005,0,0.273875,"m starts from its axioms and follows exhaustively deducing new items by combination of existing ones and no deduction happens twice. In Figure 1, a nonteminal item summarises partial derivation (or hypotheses). It is denoted by [C, r, γ] (also known as carry), where: C is a coverage vector, necessary to impose the non-overlapping constraint; r is the rightmost position most recently covered, necessary for the computation of δ; and γ is the last n − 1 words 1 Preventing phrases from overlapping requires an exponential number of constraints (the powerset of x) rendering the problem NP-complete (Knight, 1999). 2 Weighted logics have been extensively used to describe weighted sets (Lopez, 2009), operations over weighted sets (Chiang, 2007; Dyer and Resnik, 2010), and a variety of dynamic programming algorithms (Cohen et al., 2008).   I TEM {0, 1}I , [0, I + 1], ∆n−1 G OAL 1I , I + 1, EOS A XIOM hBOS → BOSi [0I , 0, BOS] : ψ(BOS) E XPAND   D i0 φr j 0 E j−1 − → yj xi − C, r, yj−n+1 Li0 ¯ h i k=i ck = 0 0 j C 0 , i0 , yj 0 −n+2 : w where c0k = ck if k &lt; i or k &gt; i0 else ¯ 1 0 j−1 w = φr ⊗ δ(r, i) ⊗ ψ(yjj |yj−n+1 ) ACCEPT  I  1 , r, γ r≤I [1I , I + 1, EOS] : δ(r, I + 1) ⊗ ψ(EOS|γ) Figure 1: Sp"
D14-1131,N03-1017,0,0.307503,"s independently and d = he1 , e2 , . . . , el i is a sequence of l steps. Under this assumption, each step is assigned the weight w(e) = Λ·hh1 (e), h2 (e), . . . , hm (e)i. The set D is typically finite, however, it contains a very large number of structures — exponential (or even factorial, see §2) with the size of x — making exhaustive enumeration prohibitively slow. Only in very restricted cases combinatorial optimisation techniques are directly applicable (Tillmann et al., 1997; Och et al., 2001), thus it is common to resort to heuristic techniques in order to find an approximation to d∗ (Koehn et al., 2003; Chiang, 2007). Evaluation exercises indicate that approximate search algorithms work well in practice (Bojar et al., 2013). The most popular algorithms provide solutions with unbounded error, thus precisely quantifying their performance requires the development of a tractable exact decoder. To date, most attempts were limited to short sentences and/or somewhat toy models trained with artificially small datasets (Germann et al., 2001; Iglesias et al., 2009; Aziz et al., 2013). Other work has employed less common approximations to the model reducing its search space complexity (Kumar et al., 2"
D14-1131,P07-2045,0,0.0134732,"d), for some finite t. At which point dt is the optimum derivation d∗ from f and the sequence of upperbounds provides a proof of optimality.7 4.2 Model We work with phrase-based models in a standard parameterisation (Equation 2). However, to avoid having to deal with NP-completeness, we constrain reordering to happen only within a limited window given by a notion of distortion limit. We require that the last source word covered by any biphrase must be within d words from the leftmost uncovered source position (Lopez, 2009). This is a widely used strategy and it is in use in the Moses toolkit (Koehn et al., 2007).8 Nevertheless, the problem of finding the best 7 If d is a maximum from g and g(d) = f (d), then it is easy to show by contradiction that d is the actual maximum from f : if there existed d0 such that f (d0 ) &gt; f (d), then it follows that g(d0 ) ≥ f (d0 ) &gt; f (d) = g(d), and hence d would not be a maximum for g. 8 A distortion limit characterises a form of pruning that acts directly in the generative capacity of the model leading to induction errors (Auli et al., 2009). Limiting reordering like that lowers complexity to a polynomial function of I and an exponential function of the distortion"
D14-1131,2005.mtsummit-papers.11,0,0.0460421,"NE, which instead of copying them, creates new ones headed by a refined version of v0 . Finally, R EWEIGHT continues from the refined node with reweighted copies of the edges leaving v0 . The weight update represents a change in LM probability (w.r.t. the upperbound distribution) due to an extended context. LM 5 LM Experiments We used the dataset made available by the Workshop on Statistical Machine Translation (WMT) (Bojar et al., 2013) to train a German-English phrase-based system using the Moses toolkit (Koehn et al., 2007) in a standard setup. For phrase extraction, we used both Europarl (Koehn, 2005) and News Commentaries (NC) totalling about 2.2M sentences.15 For language modelling, in addition to the monolingual parts of Europarl 15 Pre-processing: tokenisation, truecasing and automatic compound-splitting (German only). Following Durrani et al. (2013), we set the maximum phrase length to 5. where w0 = λψ qLM (yγ0 ) qLM (γ0 ) Figure 4: Local intersection via LM right state refinement. The input is a hypergraph G = hV, Ei, a node v0 ∈ V singly identified by its carry [l0 , C0 , r0 , γ0 ] and a left-extension y for its LM context γE0 . The program copies most of the edges D w → v ∈ E. If a"
D14-1131,W08-0402,0,0.0190682,"t k is typically much smaller than the number of possible expansions. Cube pruning employs a priority queue at beam filling and computes k highscoring expansions directly in near best-first order. The parameter k is known as beam size and it controls the time-accuracy trade-off of the algorithm. Heafield et al. (2013a) move away from using the language model as a black-box and build a more involved beam filling algorithm. Even though they target approximate search, some of their ideas have interesting connections to ours (see §4). They group hypotheses that share partial language model state (Li and Khudanpur, 2008) reasoning over multiple hypotheses at once. They fill a beam in best-first order by iteratively visiting groups using a priority queue: if the top group contains a single hypothesis, the hypothesis is added to the beam, otherwise the group is partitioned and the parts are pushed back to the queue. More recently, Heafield et al. (2014) applied their beam filling algorithm to phrase-based decoding. 3.2 Exact optimisation Exact optimisation for monotone translation has been done using A∗ search (Tillmann et al., 1997) and finite-state operations (Kumar et al., 2006). Och et al. (2001) design nea"
D14-1131,E09-1061,0,0.624957,"existing ones and no deduction happens twice. In Figure 1, a nonteminal item summarises partial derivation (or hypotheses). It is denoted by [C, r, γ] (also known as carry), where: C is a coverage vector, necessary to impose the non-overlapping constraint; r is the rightmost position most recently covered, necessary for the computation of δ; and γ is the last n − 1 words 1 Preventing phrases from overlapping requires an exponential number of constraints (the powerset of x) rendering the problem NP-complete (Knight, 1999). 2 Weighted logics have been extensively used to describe weighted sets (Lopez, 2009), operations over weighted sets (Chiang, 2007; Dyer and Resnik, 2010), and a variety of dynamic programming algorithms (Cohen et al., 2008).   I TEM {0, 1}I , [0, I + 1], ∆n−1 G OAL 1I , I + 1, EOS A XIOM hBOS → BOSi [0I , 0, BOS] : ψ(BOS) E XPAND   D i0 φr j 0 E j−1 − → yj xi − C, r, yj−n+1 Li0 ¯ h i k=i ck = 0 0 j C 0 , i0 , yj 0 −n+2 : w where c0k = ck if k &lt; i or k &gt; i0 else ¯ 1 0 j−1 w = φr ⊗ δ(r, i) ⊗ ψ(yjj |yj−n+1 ) ACCEPT  I  1 , r, γ r≤I [1I , I + 1, EOS] : δ(r, I + 1) ⊗ ψ(EOS|γ) Figure 1: Specification for the weighted set of translation derivations in phrase-based SMT with u"
D14-1131,W01-1408,0,0.200059,"e steps in a derivation. That is, Hk (d) = e∈d hk (e), where hk is a (local) feature function that assesses steps independently and d = he1 , e2 , . . . , el i is a sequence of l steps. Under this assumption, each step is assigned the weight w(e) = Λ·hh1 (e), h2 (e), . . . , hm (e)i. The set D is typically finite, however, it contains a very large number of structures — exponential (or even factorial, see §2) with the size of x — making exhaustive enumeration prohibitively slow. Only in very restricted cases combinatorial optimisation techniques are directly applicable (Tillmann et al., 1997; Och et al., 2001), thus it is common to resort to heuristic techniques in order to find an approximation to d∗ (Koehn et al., 2003; Chiang, 2007). Evaluation exercises indicate that approximate search algorithms work well in practice (Bojar et al., 2013). The most popular algorithms provide solutions with unbounded error, thus precisely quantifying their performance requires the development of a tractable exact decoder. To date, most attempts were limited to short sentences and/or somewhat toy models trained with artificially small datasets (Germann et al., 2001; Iglesias et al., 2009; Aziz et al., 2013). Othe"
D14-1131,P03-1021,0,0.00758593,"sk of producing a translation for an input string x = hx1 , x2 , . . . , xI i is typically associated with finding the best derivation d∗ compatible with the input under a linear model. In this view, a derivation is a structured output that represents a sequence of steps that covers the input producing a translation. Equation 1 illustrates this decoding process. d∗ = argmax f (d) d∈D(x) (1) The set D(x) is the space of all derivations compatible with x and supported by a model of translational equivalences (Lopez, 2008). The function f (d) = Λ · H(d) is a linear parameterisation of the model (Och, 2003). It assigns a real-valued score (or weight) to every derivation d ∈ D(x), where Λ ∈ Rm assigns a relative importance to different aspects of the derivation independently captured by m feature functions H(d) = hH1 (d), . . . , Hm (d)i ∈ Rm . The fully parameterised model can be seen as a discrete weighted set such that feature functions factorise P over the steps in a derivation. That is, Hk (d) = e∈d hk (e), where hk is a (local) feature function that assesses steps independently and d = he1 , e2 , . . . , el i is a sequence of l steps. Under this assumption, each step is assigned the weight"
D14-1131,D08-1012,0,0.0205634,"s incrementally refined to be closer to the goal until the maximum is found (or until the sampling performance exceeds a certain level). Figure 2 illustrates exact optimisation with OS∗ . Suppose f is a complex target goal distribution, such that we cannot optimise f , but we can assess f (d) for a given d. Let g (0) be an upperbound to f , i.e., g (0) (d) ≥ f (d) for all d ∈ D(x). Moreover, suppose that g (0) is simple enough to be optimised efficiently. The algorithm proceeds by solving d0 = argmaxd g (0) (d) and comput6 The intuition that a full intersection is wasteful is also present in (Petrov et al., 2008) in the context of approximate search. They start from a coarse distribution based on automatic word clustering which is refined in multiple passes. At each pass, hypotheses are pruned a posteriori on the basis of their marginal probabilities, and word clusters are further split. We work with upperbounds, rather than word clusters, with unpruned distributions, and perform exact optimisation. g(0) f* f1 g(1) f f0 d0 d1 d* D(x) Figure 2: Sequence of incrementally refined upperbound proposals. ing the quantity r0 = f (d0 )/g(0) (d0 ). If r0 were sufficiently close to 1, then g (0) (d0 ) would be"
D14-1131,N09-2002,0,0.0230745,"er NP-complete. Rush and Collins (2011) relax a hierarchical phrase-based model (Chiang, 2005)5 w.r.t. the LM component. The translation forest and the language model trade their weights (through Lagrangian multipliers) so as to ensure agreement on what each component believes to be the maximum. In both approaches, when the dual converges to a compliant solution, the solution is guaranteed to be optimal. Other4 Exact decoding had been similarly addressed with Integer Linear Programming (ILP) in the context of word-based models for very short sentences using a 2-gram LM (Germann et al., 2001). Riedel and Clarke (2009) revisit that formulation and employ a cutting-plane algorithm (Dantzig et al., 1954) reaching 30 words. 5 In hierarchical translation, reordering is governed by a synchronous context-free grammar and the underlying problem is no longer NP-complete. Exact decoding remains infeasible because the intersection between the translation forest and the target LM is prohibitively slow. 1239 wise, a subset of the constraints is explicitly added and the dual optimisation is repeated. They handle sentences above average length, however, resorting to compact rulesets (10 translation options per input segm"
D14-1131,P11-1008,0,0.0834511,"ercises indicate that approximate search algorithms work well in practice (Bojar et al., 2013). The most popular algorithms provide solutions with unbounded error, thus precisely quantifying their performance requires the development of a tractable exact decoder. To date, most attempts were limited to short sentences and/or somewhat toy models trained with artificially small datasets (Germann et al., 2001; Iglesias et al., 2009; Aziz et al., 2013). Other work has employed less common approximations to the model reducing its search space complexity (Kumar et al., 2006; Chang and Collins, 2011; Rush and Collins, 2011). These do not answer whether or not current decoding algorithms perform well at real translation tasks with state-of-the-art models. We propose an exact decoder for phrase-based SMT based on a coarse-to-fine search strategy (Dymetman et al., 2012). In a nutshell, we relax the decoding problem with respect to the Language Model (LM) component. This coarse view is incrementally refined based on evidence col1237 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1237–1249, c October 25-29, 2014, Doha, Qatar. 2014 Association for Computational Li"
D14-1131,P97-1037,0,0.461893,"ons factorise P over the steps in a derivation. That is, Hk (d) = e∈d hk (e), where hk is a (local) feature function that assesses steps independently and d = he1 , e2 , . . . , el i is a sequence of l steps. Under this assumption, each step is assigned the weight w(e) = Λ·hh1 (e), h2 (e), . . . , hm (e)i. The set D is typically finite, however, it contains a very large number of structures — exponential (or even factorial, see §2) with the size of x — making exhaustive enumeration prohibitively slow. Only in very restricted cases combinatorial optimisation techniques are directly applicable (Tillmann et al., 1997; Och et al., 2001), thus it is common to resort to heuristic techniques in order to find an approximation to d∗ (Koehn et al., 2003; Chiang, 2007). Evaluation exercises indicate that approximate search algorithms work well in practice (Bojar et al., 2013). The most popular algorithms provide solutions with unbounded error, thus precisely quantifying their performance requires the development of a tractable exact decoder. To date, most attempts were limited to short sentences and/or somewhat toy models trained with artificially small datasets (Germann et al., 2001; Iglesias et al., 2009; Aziz"
D14-1131,P09-1038,1,0.891528,"a single hypothesis, the hypothesis is added to the beam, otherwise the group is partitioned and the parts are pushed back to the queue. More recently, Heafield et al. (2014) applied their beam filling algorithm to phrase-based decoding. 3.2 Exact optimisation Exact optimisation for monotone translation has been done using A∗ search (Tillmann et al., 1997) and finite-state operations (Kumar et al., 2006). Och et al. (2001) design near-admissible heuristics for A∗ and decode very short sentences (614 words) for a word-based model (Brown et al., 1993) with a maximum distortion strategy (d = 3). Zaslavskiy et al. (2009) frame phrase-based decoding as an instance of a generalised Travelling Salesman Problem (TSP) and rely on robust solvers to perform decoding. In this view, a salesman graph encodes the translation options, with each node representing a biphrase. Nonoverlapping constraints are imposed by the TSP solver, rather than encoded directly in the salesman graph. They decode only short sentences (17 words on average) using a 2-gram LM due to salesman graphs growing too large.4 Chang and Collins (2011) relax phrase-based models w.r.t. the non-overlapping constraints, which are replaced by soft penalties"
D14-1131,N10-1128,0,\N,Missing
D14-1131,W13-2201,1,\N,Missing
D15-1233,W91-0104,1,0.503588,"ven an input utterance x, produce a semantic representation z, by following a number of intermediate steps where the surface form is gradually transformed into semantic structure. Such “procedural” approaches to semantic parsing are typically very hard or impossible to invert: starting from a semantic representation z, there is no simple process that is able to find an x which, when given to the parser, would produce z. Formally, a Boolean relation r(x, z) can be such that the question ?∃z r(x, z) is decidable for all x’s, while the reciprocal question ?∃x r(x, z) is undecidable for some z’s (Dymetman, 1991).1 One of the motivations for the emerging paradigm of unification grammars at the end of the eighties was the clean separation they promised between specifying well-formed linguistic structures, both on the syntactic and semantic levels, through a formal description of the relation r(x, z), and producing efficient implementations of the specification; in particular, there was much hope that such formalisms would be conductive to effective reversibility (by contrast to variable assignment, variable unification is inherently symmetrical), that is, to feasible (and if possible efficient) impleme"
D15-1233,J08-3004,0,0.137606,"have also indicated for future reference the “contextual” factors ζ, µ, that we ignore for now). The factors take as arguments three types of objects: z is a logical form, that is, a structured object which can be naturally represented as a tree, x is a surface string, and y is a latent “underlying” string that corresponds to one of a small collection of “canonical” texts for realizing the logical form z (more about that later). Each factor is realized through a weighted finite-state machine (acceptor or transducer) over strings or trees (Mohri, 2009; F¨ul¨op and Vogler, 2009; Maletti, 2010; Graehl et al., 2008). The λ factor is a string automaton that represents a standard ngram language model (typically specific to domain), in other words a probability distribution over utterances x. Symmetrically, the regular tree automaton ω represents a distribution over logical forms z, which can be seen as playing a similar role to the language model, but at the semantic level, namely telling us what are the possible/likely logical forms in a certain domain.6 The “canonical factor” κ is a weighted treeto-string transducer (Graehl et al., 2008), which implements a relation between logical forms z 6 In particula"
D15-1233,P12-1051,0,0.0159009,"al Linguistics. Tree transducers in particular have gained popularity in Statistical Machine Translation, starting with (Yamada and Knight, 2001), as described in the surveys (Maletti, 2010; Razmara, 2011). The reversibility properties of finite-state transducers have been exploited to a more limited extent, starting with applications of non-weighted string-to-string transducers to morphological analysis and generation (Beesley, 1996). Concerning the application of weighted finitestate tree machines to NLU/NLG reversibility, our proposal is strongly related on the one hand to the approach of (Jones et al., 2012), who explicitely proposes tree-to-string transducers as a tool for modelling semantic parsing and for training on semantically annotated data, and on the other hand to (Wong, 2007; Wong and Mooney, 2007), who focus more directly on the problem of inverting a semantic parser into a generator. Wong et al. do not explicitely use tree-based transducers, but rather a formalism inspired by SCFGs (synchronous context-free grammars), which essentially corresponds to a form of tree-to-string transducer. In relation to reversibility considerations, presentations in terms of synchronous formalisms have"
D15-1233,W11-2902,0,0.0141872,"), who focus more directly on the problem of inverting a semantic parser into a generator. Wong et al. do not explicitely use tree-based transducers, but rather a formalism inspired by SCFGs (synchronous context-free grammars), which essentially corresponds to a form of tree-to-string transducer. In relation to reversibility considerations, presentations in terms of synchronous formalisms have the interest that they are intrinsically symmetrical. Such formalisms have tight relations to tree-transducers (Shieber, 2004); one recently proposed generalization, “Interpreted Regular Tree Grammars” (Koller and Kuhlmann, 2011), allows 1993 multiple (possibly more than two) synchronized views of an underlying abstract derivation tree, and has the advantage of permitting a uniform treatment of strings and trees. One important aspect in which our proposal differs from these previous approaches is in proposing to decouple the “core” task of mapping logical forms to well-formed latent canonical realizations from the task of relating these realizations to actual utterances, through an additional “similarity” transducer acting as a bridge. This idea of a bridge is however close to another line of work in semantic parsing,"
D15-1233,C96-1017,0,0.0773798,"e customer’s. 5 Related work The unique formal properties of finite-state machines, which favor modular decompositions of complex tasks, have long been exploited in Computational Linguistics. Tree transducers in particular have gained popularity in Statistical Machine Translation, starting with (Yamada and Knight, 2001), as described in the surveys (Maletti, 2010; Razmara, 2011). The reversibility properties of finite-state transducers have been exploited to a more limited extent, starting with applications of non-weighted string-to-string transducers to morphological analysis and generation (Beesley, 1996). Concerning the application of weighted finitestate tree machines to NLU/NLG reversibility, our proposal is strongly related on the one hand to the approach of (Jones et al., 2012), who explicitely proposes tree-to-string transducers as a tool for modelling semantic parsing and for training on semantically annotated data, and on the other hand to (Wong, 2007; Wong and Mooney, 2007), who focus more directly on the problem of inverting a semantic parser into a generator. Wong et al. do not explicitely use tree-based transducers, but rather a formalism inspired by SCFGs (synchronous context-free"
D15-1233,P14-1133,0,0.014372,"y more than two) synchronized views of an underlying abstract derivation tree, and has the advantage of permitting a uniform treatment of strings and trees. One important aspect in which our proposal differs from these previous approaches is in proposing to decouple the “core” task of mapping logical forms to well-formed latent canonical realizations from the task of relating these realizations to actual utterances, through an additional “similarity” transducer acting as a bridge. This idea of a bridge is however close to another line of work in semantic parsing, not transducer based, namely (Berant and Liang, 2014; Wang et al., 2015). There, a simple generic grammar is used to generate canonical realizations from a repertory of possible logical forms (expressed in a variant of lambda calculus). Given an input to parse, simple heuristics are used to select a finite list of potential logical forms which are then ranked according to the (paraphrase-based) similarity of their associated canonical realization with the input. Thus in this approach, a form of generation plays an important role, not for its own sake, but as a tool for semantic parsing. 6 Conclusion Because of their unique compositional propert"
D15-1233,W03-2311,0,0.120239,"rsection) p(x).q(x), but we can in case p and q are both represented by weighted FSAs. 1991 finite-state modules, which attempts to satisfy the definition given above for probabilistic reversibility, to address the problem of robustness that we described earlier, and can also support contextual preferences. We illustrate the approach with some simple examples of human-machine dialogues (between a customer and a virtual agent), a domain for which reversibility has high relevance, due to effects such as self-monitoring (Neumann, 1998; Levelt, 1983), interleaving of understanding and generation (Otsuka and Purver, 2003), and lexical entrainment (Brennan, 1996). ω ζ  µ  z λ  κ  y σ   x Figure 1: Reversible specification through finitestate factors. The conceptual architecture is shown in Figure 1. Formally, the figure represents a probabilistic graphical model in so-called factor form, where the factors are ω, κ, σ, λ (we have also indicated for future reference the “contextual” factors ζ, µ, that we ignore for now). The factors take as arguments three types of objects: z is a logical form, that is, a structured object which can be naturally represented as a tree, x is a surface string, and y is a laten"
D15-1233,W04-3312,0,0.0136136,"on semantically annotated data, and on the other hand to (Wong, 2007; Wong and Mooney, 2007), who focus more directly on the problem of inverting a semantic parser into a generator. Wong et al. do not explicitely use tree-based transducers, but rather a formalism inspired by SCFGs (synchronous context-free grammars), which essentially corresponds to a form of tree-to-string transducer. In relation to reversibility considerations, presentations in terms of synchronous formalisms have the interest that they are intrinsically symmetrical. Such formalisms have tight relations to tree-transducers (Shieber, 2004); one recently proposed generalization, “Interpreted Regular Tree Grammars” (Koller and Kuhlmann, 2011), allows 1993 multiple (possibly more than two) synchronized views of an underlying abstract derivation tree, and has the advantage of permitting a uniform treatment of strings and trees. One important aspect in which our proposal differs from these previous approaches is in proposing to decouple the “core” task of mapping logical forms to well-formed latent canonical realizations from the task of relating these realizations to actual utterances, through an additional “similarity” transducer"
D15-1233,C90-2052,0,0.299284,"Missing"
D15-1233,P15-1129,0,0.0149644,"nized views of an underlying abstract derivation tree, and has the advantage of permitting a uniform treatment of strings and trees. One important aspect in which our proposal differs from these previous approaches is in proposing to decouple the “core” task of mapping logical forms to well-formed latent canonical realizations from the task of relating these realizations to actual utterances, through an additional “similarity” transducer acting as a bridge. This idea of a bridge is however close to another line of work in semantic parsing, not transducer based, namely (Berant and Liang, 2014; Wang et al., 2015). There, a simple generic grammar is used to generate canonical realizations from a repertory of possible logical forms (expressed in a variant of lambda calculus). Given an input to parse, simple heuristics are used to select a finite list of potential logical forms which are then ranked according to the (paraphrase-based) similarity of their associated canonical realization with the input. Thus in this approach, a form of generation plays an important role, not for its own sake, but as a tool for semantic parsing. 6 Conclusion Because of their unique compositional properties, finite-state mo"
D15-1233,N07-1022,0,0.0209631,"011). The reversibility properties of finite-state transducers have been exploited to a more limited extent, starting with applications of non-weighted string-to-string transducers to morphological analysis and generation (Beesley, 1996). Concerning the application of weighted finitestate tree machines to NLU/NLG reversibility, our proposal is strongly related on the one hand to the approach of (Jones et al., 2012), who explicitely proposes tree-to-string transducers as a tool for modelling semantic parsing and for training on semantically annotated data, and on the other hand to (Wong, 2007; Wong and Mooney, 2007), who focus more directly on the problem of inverting a semantic parser into a generator. Wong et al. do not explicitely use tree-based transducers, but rather a formalism inspired by SCFGs (synchronous context-free grammars), which essentially corresponds to a form of tree-to-string transducer. In relation to reversibility considerations, presentations in terms of synchronous formalisms have the interest that they are intrinsically symmetrical. Such formalisms have tight relations to tree-transducers (Shieber, 2004); one recently proposed generalization, “Interpreted Regular Tree Grammars” (K"
D15-1233,P01-1067,0,0.105748,"expectations of the dialogue manager about the next logical form, to be combined with the actual customer’s utterance. Symmetrically, the µ factor can be used to represent such phenomena as lexical entrainment (Brennan, 1996), where the agent’s utterance is oriented towards using similar wordings to the customer’s. 5 Related work The unique formal properties of finite-state machines, which favor modular decompositions of complex tasks, have long been exploited in Computational Linguistics. Tree transducers in particular have gained popularity in Statistical Machine Translation, starting with (Yamada and Knight, 2001), as described in the surveys (Maletti, 2010; Razmara, 2011). The reversibility properties of finite-state transducers have been exploited to a more limited extent, starting with applications of non-weighted string-to-string transducers to morphological analysis and generation (Beesley, 1996). Concerning the application of weighted finitestate tree machines to NLU/NLG reversibility, our proposal is strongly related on the one hand to the approach of (Jones et al., 2012), who explicitely proposes tree-to-string transducers as a tool for modelling semantic parsing and for training on semanticall"
D19-5617,J04-4003,0,0.0107907,"me of the most common errors that can be found in the in-domain data. Like Berard et al. (2019), we detect the errors that occur naturally in the in-domain data and then apply them to our training corpus, while respecting their natural distribution. We call this “natural noise generation” in opposition to what is done in (Sperber et al., 2017; Belinkov and Bisk, 2018; Vaibhav et al., 2019) or in Section 4.2, where the noise is more synthetic. Detecting errors We compile a general-purpose French lexicon as a transducer,7 implemented to be traversed with extended edit distance flags, similar to Mihov and Schulz (2004). Whenever a word is not found in the lexicon (which means that it is a potential spelling mistake), we look for a French word in the lexicon within a maximum edit distance of 2, with the following set of edit operations: deletion (e.g., apelle instead of appelle) (2) insertion (e.g., appercevoir instead of apercevoir) (3) constrained substitution on diacritics (e.g., mangè instead of mangé) (4) swap counted as one operation: mnager instead of manger) (5) substitution (e.g., manger) (6) repetitions (e.g., Merciiiii with a threshold of max 10 repetitions) (8) Wrong spacing around punctuation sy"
D19-5617,W18-6301,0,0.0208917,"ulary threshold to 100. Finally, unless stated otherwise, we always use the inline casing approach (see Section 4.2). This represents ≈15M sentences. This corpus is not available publicly, but the Yelp dataset (https://www. yelp.com/dataset) could be used instead. 10 i /T ) with p(wi ) = ∑|Vexp(z | 9 k=1 11 Corpora available at http://opus.nlpl.eu/ 3k translations of dishes and other food terminology http://www.gourmetpedia.eu/ 12 exp(zk /T ) 172 6.3 Model and settings For all experiments, we use the Transformer Big (Vaswani et al., 2017) as implemented in Fairseq, with the hyperparameters of Ott et al. (2018). Training is done on 8 GPUs, with accumulated gradients over 10 batches (Ott et al., 2018), and a max batch size of 3500 tokens (per GPU). We train for 20 epochs, while saving a checkpoint every 2500 updates (≈ 25 epoch on UGC) and average the 5 best checkpoints according to their perplexity on a validation set (a held-out subset of UGC). For fine-tuning, we use a fixed learning rate, and a total batch size of 3500 tokens (training on a single GPU without delayed updates). To avoid overfitting on 4SQ-PE, we do early stopping according to perplexity on 4SQ-valid.13 For each fine-tuned model we"
D19-5617,P02-1040,0,0.10888,"5.59 40.35 4SQ 31.55 31.69 Table 5: Baseline model with or without natural noise (see Section 4.3). Noised news is the same type of noise, artificially applied to news-test. Inline and factored case perform equally well, significantly better than the default (cased) model, especially on all-uppercase inputs. Lowercasing the source is a good option, but gives a slightly lower score on regular 4SQ-test.17 Finally, synthetic case noise added to the source gives surprisingly good results. It could also be combined with factored or inline case. Evaluation methodology During our work, we used BLEU (Papineni et al., 2002) on news-valid (concatenation of news-test 2012 and 2013) to ensure that our models stayed good on a more general domain, and on 4SQ-valid to measure performance on the 4SQ domain. For sake of brevity, we only give the final BLEU scores on news-test 2014 and 4SQ-test. Scores on 4SQ-valid, and MTNT-test (for comparison with Michel and Neubig, 2018; Berard et al., 2019) are given in Appendix. We evaluate “detokenized” MT outputs15 against raw (non-tokenized) references using SacreBLEU (Post, 2018).16 In addition to BLEU, we do an indirect evaluation on an Aspect-Based Sentiment Analysis (ABSA) t"
D19-5617,W19-5206,0,0.0427268,"Missing"
D19-5617,D18-1045,0,0.103412,"c Hong Kong, China, November 4, 2019. 2019 Association for Computational Linguistics www.aclweb.org/anthology/D19-56%2d Corpus 4SQ-PE 4SQ-HT 4SQ-valid 4SQ-test corpora, containing noisy sources obtained by random word or character deletions, insertions, substitutions or swaps. Recently, Vaibhav et al. (2019) proposed to use a similar technique along with noise generation through replacement of a clean source by one obtained by back-translation. We employ several well-known domain adaptation techniques: back-translation of large monolingual corpora close to the domain (Sennrich et al., 2016b; Edunov et al., 2018), fine-tuning with indomain parallel data (Luong and Manning, 2015; Freitag and Al-Onaizan, 2016; Servan et al., 2016), domain tags for knowledge transfer between domains (Kobus et al., 2017; Berard et al., 2019). Addressing the technical issues of robustness and adaptation of an NMT system is decisive for real-world deployment, but evaluation is also critical. This aspect is stressed by Levin et al. (2017) (NMT of curated hotel descriptions), who point out that automatic metrics like BLEU tend to neglect semantic differences that have a small textual footprint, but may be seriously misleading"
D19-5617,W18-6319,0,0.0174724,"ined with factored or inline case. Evaluation methodology During our work, we used BLEU (Papineni et al., 2002) on news-valid (concatenation of news-test 2012 and 2013) to ensure that our models stayed good on a more general domain, and on 4SQ-valid to measure performance on the 4SQ domain. For sake of brevity, we only give the final BLEU scores on news-test 2014 and 4SQ-test. Scores on 4SQ-valid, and MTNT-test (for comparison with Michel and Neubig, 2018; Berard et al., 2019) are given in Appendix. We evaluate “detokenized” MT outputs15 against raw (non-tokenized) references using SacreBLEU (Post, 2018).16 In addition to BLEU, we do an indirect evaluation on an Aspect-Based Sentiment Analysis (ABSA) task, a human evaluation, and a taskrelated evaluation based on polysemous words. 6.5 BLEU 4SQ 31.78 30.91 31.62 31.55 31.99 Natural noise Table 5 compares the baseline “inline case” model with the same model augmented with natural noise (Section 4.3). Performance is the same on 4SQ-test, but significantly better on news-test artificially augmented with 4SQ-like noise. Domain adaptation Table 6 shows the results of the back-translation (BT) techniques. Surprisingly, BT with beam search (BT-B) det"
D19-5617,P15-1001,0,0.0355079,"uation, wrong or non-standard capitalization (lowercase proper names, capitalized words for emphasis). Regarding domain aspects, there are polysemous words with typical specific meaning carte → map, menu; cadre → frame, executive, setting), idiomatic expressions (à tomber par terre → to die for), and venue-related named entities (La Boîte à Sardines). 4 Input Pre-proc MT output Post-proc Lowercase une honte ! une _honte _! A _dis gra ce ! A disgrace! Table 2: Capital letters break NMT. BPE segmentation and translation of capitalized or lowercase input. der. This approach is similar to that of Jean et al. (2015), who used the attention mechanism to replace output UNK symbols with the aligned word in the source. Berard et al. (2019) used the same technique to deal with emojis in the WMT robustness task. 4.2 Capital letters As shown in Table 2, capital letters are another source of confusion. HONTE and honte are considered as two different words. The former is out-of-vocabulary and is split very aggressively by BPE. This causes the MT model to hallucinate. Lowercasing A solution is to lowercase the input, both at training and at test time. However, when doing so, some information may be lost (e.g., nam"
D19-5617,C12-1149,0,0.0525953,"Missing"
D19-5617,kobus-etal-2017-domain,0,0.175033,"es obtained by random word or character deletions, insertions, substitutions or swaps. Recently, Vaibhav et al. (2019) proposed to use a similar technique along with noise generation through replacement of a clean source by one obtained by back-translation. We employ several well-known domain adaptation techniques: back-translation of large monolingual corpora close to the domain (Sennrich et al., 2016b; Edunov et al., 2018), fine-tuning with indomain parallel data (Luong and Manning, 2015; Freitag and Al-Onaizan, 2016; Servan et al., 2016), domain tags for knowledge transfer between domains (Kobus et al., 2017; Berard et al., 2019). Addressing the technical issues of robustness and adaptation of an NMT system is decisive for real-world deployment, but evaluation is also critical. This aspect is stressed by Levin et al. (2017) (NMT of curated hotel descriptions), who point out that automatic metrics like BLEU tend to neglect semantic differences that have a small textual footprint, but may be seriously misleading in practice, for instance by interpreting available parking as if it meant free parking. To mitigate this, we conduct additional evaluations of our models: human evaluation, translation acc"
D19-5617,W16-2209,0,0.0226995,"with emojis in the WMT robustness task. 4.2 Capital letters As shown in Table 2, capital letters are another source of confusion. HONTE and honte are considered as two different words. The former is out-of-vocabulary and is split very aggressively by BPE. This causes the MT model to hallucinate. Lowercasing A solution is to lowercase the input, both at training and at test time. However, when doing so, some information may be lost (e.g., named entities, acronyms, emphasis) which may result in lower translation quality. Factored translation Levin et al. (2017) do factored machine translation (Sennrich and Haddow, 2016; Garcia-Martinez et al., 2016) where a word and its case are split in two different features. For instance, HONTE becomes honte + upper. We implement this with two embedding matrices, one for words and one for case, and represent a token as the sum of the embeddings of its factors. For the target side, we follow GarciaMartinez et al. (2016) and have two softmax operations. We first predict the word in its lowercase form and then predict its case.6 The embeddings of the case and word are then summed and used as input for the next decoder step. Robustness to noise We propose solutions for deali"
D19-5617,D18-2012,0,0.0175561,"ings of its factors. For the target side, we follow GarciaMartinez et al. (2016) and have two softmax operations. We first predict the word in its lowercase form and then predict its case.6 The embeddings of the case and word are then summed and used as input for the next decoder step. Robustness to noise We propose solutions for dealing with nonstandard case, emoticons, emojis and other issues. 4.1 Uppercase UNE HONTE ! UN E _H ON TE _! A _H ON E Y ! A HONEY! Rare character placeholder We segment our training data into subwords with BPE (Sennrich et al., 2016c), implemented in SentencePiece (Kudo and Richardson, 2018). BPE can deal with rare or unseen words by splitting them into more frequent subwords but cannot deal with unseen characters.5 While this is not a problem in most tasks, 4SQ contains a lot of emojis, and sometimes symbols in other scripts (e.g., Arabic). Unicode now defines around 3k emojis, most of which are likely to be out-of-vocabulary. We replace rare characters on both sides of the training corpus by a placeholder (&lt;x&gt;); a model trained on this data is typically able to copy the placeholder at the correct position. Then, at inference time, we replace the output tokens &lt;x&gt; by the rare so"
D19-5617,N16-1005,0,0.361566,"NGT 2019), pages 168–176 c Hong Kong, China, November 4, 2019. 2019 Association for Computational Linguistics www.aclweb.org/anthology/D19-56%2d Corpus 4SQ-PE 4SQ-HT 4SQ-valid 4SQ-test corpora, containing noisy sources obtained by random word or character deletions, insertions, substitutions or swaps. Recently, Vaibhav et al. (2019) proposed to use a similar technique along with noise generation through replacement of a clean source by one obtained by back-translation. We employ several well-known domain adaptation techniques: back-translation of large monolingual corpora close to the domain (Sennrich et al., 2016b; Edunov et al., 2018), fine-tuning with indomain parallel data (Luong and Manning, 2015; Freitag and Al-Onaizan, 2016; Servan et al., 2016), domain tags for knowledge transfer between domains (Kobus et al., 2017; Berard et al., 2019). Addressing the technical issues of robustness and adaptation of an NMT system is decisive for real-world deployment, but evaluation is also critical. This aspect is stressed by Levin et al. (2017) (NMT of curated hotel descriptions), who point out that automatic metrics like BLEU tend to neglect semantic differences that have a small textual footprint, but may"
D19-5617,L18-1602,0,0.0157366,"word Cadre Cuisine Carte Table 7: Domain adaptation with 4SQ-PE fine-tuning (FT) or corpus tags. The “tag” column represents the corpus tag used at test time (if any). Meanings setting, frame, executive food, kitchen menu, card, map Table 9: French polysemous words found in 4SQ, and translation candidates in English. The most frequent meanings in 4SQ are underlined. 2. 4SQ-PE + tags is not as good as fine-tuning with 4SQ-PE. However, fine-tuned models get slightly worse results on news. Translation of polysemous words We propose to count polysemous words specific to our domain, similarly to (Lala and Specia, 2018), to measure the degree of domain adaptation. TER between the translation hypotheses and the post-edited references in 4SQ-PE reveals the most common substitutions (e.g., “card” is often replaced with “menu”, suggesting that “card” is a common mistranslation of the polysemous word “carte”). We filter this list manually to only keep words that are polysemous and that have a high frequency in the test set. Table 9 gives the 3 most frequent ones.20 Table 10 shows the accuracy of our models when translating these words. We see that the domainadapted model is better at translating domainspecific po"
D19-5617,P16-1009,0,0.400841,"NGT 2019), pages 168–176 c Hong Kong, China, November 4, 2019. 2019 Association for Computational Linguistics www.aclweb.org/anthology/D19-56%2d Corpus 4SQ-PE 4SQ-HT 4SQ-valid 4SQ-test corpora, containing noisy sources obtained by random word or character deletions, insertions, substitutions or swaps. Recently, Vaibhav et al. (2019) proposed to use a similar technique along with noise generation through replacement of a clean source by one obtained by back-translation. We employ several well-known domain adaptation techniques: back-translation of large monolingual corpora close to the domain (Sennrich et al., 2016b; Edunov et al., 2018), fine-tuning with indomain parallel data (Luong and Manning, 2015; Freitag and Al-Onaizan, 2016; Servan et al., 2016), domain tags for knowledge transfer between domains (Kobus et al., 2017; Berard et al., 2019). Addressing the technical issues of robustness and adaptation of an NMT system is decisive for real-world deployment, but evaluation is also critical. This aspect is stressed by Levin et al. (2017) (NMT of curated hotel descriptions), who point out that automatic metrics like BLEU tend to neglect semantic differences that have a small textual footprint, but may"
D19-5617,L16-1147,0,0.035688,"ion. 1 We use a temperature10 of T = 0.9 to avoid the extremely noisy output obtained with T = 1 and strike a balance between quality and diversity. 5.2 6 Experiments 6.1 Training data Fine-tuning After some initial work with the WMT 2014 data, we built a new training corpus named UGC (User Generated Content), closer to our domain, by combining: Multi UN, OpenSubtitles, Wikipedia, Books, Tatoeba, TED talks, ParaCrawl11 and Gourmet12 (See Table 3). Notably, UGC does not include Common Crawl (which contains a lot of misaligned sentences and caused hallucinations), but it includes OpenSubtitles (Lison and Tiedemann, 2016) (spoken-language, possibly closer to 4SQ). We observed an improvement of more than 1 BLEU on news-test 2014 when switching to UGC, and almost 6 BLEU on 4SQ-valid. When small amounts of in-domain parallel data are available, fine-tuning (FT) is often the preferred solution for domain adaptation (Luong and Manning, 2015; Freitag and Al-Onaizan, 2016). It consists in training a model on out-of-domain data, and then continuing its training for a few epochs on the in-domain data only. 5.3 Corpus tags Kobus et al. (2017) propose a technique for multidomain NMT, which consists in inserting a token i"
D19-5617,P12-3005,0,0.031069,"lysemous words that have a different meaning depending on the domain), which we can control at test time by manually setting the tag. Sennrich et al. (2016a) also use tags to control politeness in the model’s output. As our corpus (see Section 6.1) is not clearly divided into domains, we apply the same technique as Kobus et al. (2017) but use corpus tags (each sub-corpus has its own tag: TED, Paracrawl, etc.) which we add to each source sequence. Like in (Berard et al., 2019), the 4SQ post-edited and backtranslated data also get their own tags (PE and BT). 6.2 Pre-processing We use langid.py (Lui and Baldwin, 2012) to filter sentence pairs from UGC. We also remove duplicate sentence pairs, and lines longer than 175 words or with a length ratio greater than 1.5 (see Table 3). Then we apply SentencePiece and our rare character handling strategy (Section 4.1). We use a joined BPE model of size 32k, trained on the concatenation of both sides of the corpus, and set SentencePiece’s vocabulary threshold to 100. Finally, unless stated otherwise, we always use the inline casing approach (see Section 4.2). This represents ≈15M sentences. This corpus is not available publicly, but the Yelp dataset (https://www. ye"
D19-5617,N19-1190,0,0.0919711,"nces) to English. We believe that this resource2 will be valuable to the 1 https://foursquare.com/ https://europe.naverlabs.com/ research/natural-language-processing/ machine-translation-of-restaurant-reviews/ 2 168 Proceedings of the 3rd Workshop on Neural Generation and Translation (WNGT 2019), pages 168–176 c Hong Kong, China, November 4, 2019. 2019 Association for Computational Linguistics www.aclweb.org/anthology/D19-56%2d Corpus 4SQ-PE 4SQ-HT 4SQ-valid 4SQ-test corpora, containing noisy sources obtained by random word or character deletions, insertions, substitutions or swaps. Recently, Vaibhav et al. (2019) proposed to use a similar technique along with noise generation through replacement of a clean source by one obtained by back-translation. We employ several well-known domain adaptation techniques: back-translation of large monolingual corpora close to the domain (Sennrich et al., 2016b; Edunov et al., 2018), fine-tuning with indomain parallel data (Luong and Manning, 2015; Freitag and Al-Onaizan, 2016; Servan et al., 2016), domain tags for knowledge transfer between domains (Kobus et al., 2017; Berard et al., 2019). Addressing the technical issues of robustness and adaptation of an NMT syste"
D19-5617,2015.iwslt-evaluation.11,0,0.312325,"putational Linguistics www.aclweb.org/anthology/D19-56%2d Corpus 4SQ-PE 4SQ-HT 4SQ-valid 4SQ-test corpora, containing noisy sources obtained by random word or character deletions, insertions, substitutions or swaps. Recently, Vaibhav et al. (2019) proposed to use a similar technique along with noise generation through replacement of a clean source by one obtained by back-translation. We employ several well-known domain adaptation techniques: back-translation of large monolingual corpora close to the domain (Sennrich et al., 2016b; Edunov et al., 2018), fine-tuning with indomain parallel data (Luong and Manning, 2015; Freitag and Al-Onaizan, 2016; Servan et al., 2016), domain tags for knowledge transfer between domains (Kobus et al., 2017; Berard et al., 2019). Addressing the technical issues of robustness and adaptation of an NMT system is decisive for real-world deployment, but evaluation is also critical. This aspect is stressed by Levin et al. (2017) (NMT of curated hotel descriptions), who point out that automatic metrics like BLEU tend to neglect semantic differences that have a small textual footprint, but may be seriously misleading in practice, for instance by interpreting available parking as if"
D19-5617,D18-1050,0,0.400957,"upon the latest techniques for MT robustness. We also perform an extensive evaluation (automatic and human) that shows significant improvements over existing online systems. Finally, we propose task-specific metrics based on sentiment analysis or translation accuracy of domain-specific polysemous words. 1 2 Related work Translating restaurant reviews written by casual customers presents several challenges for NMT, in particular robustness to non-standard language and adaptation to a specific style or domain (see Section 3.2 for details). Concerning robustness to noisy user generated content, Michel and Neubig (2018) stress differences with traditional domain adaptation problems, and propose a typology of errors, many of which we also detected in the 4SQ data. They also released a dataset (MTNT), whose sources were selected from a social media (Reddit) on the basis of being especially noisy (see Appendix for a comparison with 4SQ). These sources were then translated by humans to produce a parallel corpus that can be used to engineer more robust NMT systems and to evaluate them. This corpus was the basis of the WMT 2019 MT Robustness Task (Li et al., 2019), in which Berard et al. (2019) ranked first. We us"
D19-5617,P16-1162,0,\N,Missing
D19-5617,D19-5506,0,\N,Missing
E03-2003,C00-1036,1,0.780552,"s being discussed, we developed grammars for English as well as French realization, each containing about 380 rules. it I &apos;beneficiary Project I I from .s0,-,i0sweism Report: Inarne0fGene The first step of prototype design was to specify the structure and content of the experiment reports. With the help of the grammar writers, the biological experts produced guidelines, both at the level of semantic content and of the textual expressions to be used. It was then followed by DCM formalizing these descriptions and implementing them in the MDA formalism. Details about this formalism are given in (Dymetman et al. 2000) and (Brun et al. 2000). During the formalization and implementation phase, XRCE used its previously developed methodology of first modeling the document macro-structure (similar to a DTD 8 ), then its context-free micro-structure (what types of content choices are possible at a given point in the document), and finally the dependencies between different content elements (example: some experimental observations lead to certain obligatory choices concerning the sequel of the experiment). To perform this formalization/implementation phase, a biological expert and a grammar developer worked in ta"
E03-2003,C02-1128,1,0.788367,"e written report. It was then exciting to discover that the computational model underlying MDA was very adapted, not only to the description of the written report, but also to the fine-grained fbrmalization of the experimental protocol itself In this way, we have gradually moved to a view of MDA as a convenient tool for integrating the formalization of the This difference has several decisive theoretical and practical consequences, in particular for the connection between these systems and XML-based authoring, as well as for the definability of such notions as life/death of authoring choices (Dymetman 2002). 6 http://www.xrce.xerox.com/competencies/contentanalvsis/dcm/mda.en.html 7 http://www.xrce.xerox.com/comnetencies/contentanalysis/dcm/demo/mda-demo.html 5 Start experimental protocol with its associated textual documentation. ILI&Z X-C.I Intorface for Multilingual Document Authoring File Edit - Windows Traces Ir 0 English Edda hie — P 3 The realization 3 ene nmary: of the The following figures show some screenshots of the prototype in use. The author interacts with menus associated with underlined items and may also enter free text in dedicated boxes. 8 I IffIuT&apos;ID•f I • Bactena Ifi • Expre"
E03-2003,P98-2173,0,0.0470403,"Missing"
E03-2003,W00-1404,1,\N,Missing
E03-2003,C98-2168,0,\N,Missing
E14-2013,W02-1402,0,0.054387,"ion provided by a generic MT system. 2 English Source: Farmers tend to implement a broad non-focused weed-control strategy, on the basis of broad spectrum products and mixtures of different products. Bing1 : Los agricultores tienden a aplicar una estrategia amplia para control de malezas no centrado, sobre la base de productos de amplio espectro y las mezclas de diferentes productos. Related Work There has recently been a growing interest for terminology integration into MT models. Direct integration of terminology into the SMT model has been considered, either by extending SMT training data (Carl and Langlais, 2002), or via adding an additional term indicator feature (Pinnis and Skadins, 2012; Skadins et al., 2013) into the translation model. However none of the above is possible when we deal with an external black-box MT service. (Itagaki and Aikawa, 2008) propose a postprocessing step for an MT engine, where a wrongly translated term is replaced with a userprovided term translation. The authors claim that translating the term directly often gives a different Table 1: Example of the translation produced by a generic MT model for a domain-specific document. Source term : weed-control, official Spanish te"
E14-2013,P07-2045,0,0.00396928,"n (according to the domain terminology used) and for each of those an alternative translation from the domain terminology is proposed. In our demonstration a web interface allows users to access and test the service. 4 • In a first step, the text is used as a query over the search index (in that language) in order to find a list of all the terminology elements containing a textual fragment present in the query. Proof of concept evaluation In order to evaluate the quality of locating the wrong term translation, we applied the terminology verification service to an SMT model trained with Moses (Hoang et al., 2007) on the Europarl (Koehn, 2005) corpus. This SMT model was used for translating a test set in the Agricultural domain from Spanish into English. In these settings we have access to the internal sub-phrase alignment provided by Moses, thus we know the exact location of the wrong term translation, which allows us to evaluate how good our locating technique is. The test set consists of 100 abstracts in Spanish from a bibliographical database of scientific publications in the Agriculture domain. These abstracts were translated into English with our translation • In a second step, in order to retain"
E14-2013,2005.mtsummit-papers.11,0,0.0037789,"y used) and for each of those an alternative translation from the domain terminology is proposed. In our demonstration a web interface allows users to access and test the service. 4 • In a first step, the text is used as a query over the search index (in that language) in order to find a list of all the terminology elements containing a textual fragment present in the query. Proof of concept evaluation In order to evaluate the quality of locating the wrong term translation, we applied the terminology verification service to an SMT model trained with Moses (Hoang et al., 2007) on the Europarl (Koehn, 2005) corpus. This SMT model was used for translating a test set in the Agricultural domain from Spanish into English. In these settings we have access to the internal sub-phrase alignment provided by Moses, thus we know the exact location of the wrong term translation, which allows us to evaluate how good our locating technique is. The test set consists of 100 abstracts in Spanish from a bibliographical database of scientific publications in the Agriculture domain. These abstracts were translated into English with our translation • In a second step, in order to retain only the domain terms with a"
E14-2013,itagaki-aikawa-2008-post,0,\N,Missing
H05-1095,J93-2003,0,0.00752012,"asured with the NIST evaluation metric. Translations are produced by means of a beam-search decoder. Experimental results are presented, that demonstrate how the proposed method allows to better generalize from the training data. 1 Arne Mauser RWTH Aachen University arne.mauser@rwth-aachen.de 2 Introduction Possibly the most remarkable evolution of recent years in statistical machine translation is the step from word-based models to phrase-based models (Och et al., 1999; Marcu and Wong, 2002; Yamada and Knight, 2002; Tillmann and Xia, 2003). While in traditional word-based statistical models (Brown et al., 1993) the atomic unit that translation operates on is the word, phrase-based methods acknowledge the significant role played in language by multiword expressions, thus incorporating in a statistical framework the insight behind Example-Based Machine Translation (Somers, 1999). However, Phrase-based models proposed so far only deal with multi-word units that are sequences Non-contiguous phrases Why should it be a good thing to use phrases composed of possibly non-contiguous sequences of words? In doing so we expect to improve translation quality by better accounting for additional linguistic phenome"
H05-1095,P05-1033,0,0.0570595,"ned training corpus. Our approach is based on a direct approximation of the posterior probability Pr (tI1 |sJ1 ), using a loglinear model: Pr (tI1 |sJ1 ) M X Our model currently relies on seven feature functions, which we describe here. (1) 1 1 = exp ZsJ • The compositional bi-phrase feature function hcomp : this is introduced to compensate for ! λm hm (tI1 , sJ1 ) m=1 1 In such a model, the contribution of each feature function hm is determined by the corresponding model parameter λm ; ZsJ denotes a normalization 1 constant. This type of model is now quite widely 757 Recent work from Chiang (Chiang, 2005) addresses similar concerns to those motivating our work by introducing a Synchronous CFG for bi-phrases. If on one hand SCFGs allow to better control the order of the material inserted in the gaps, on the other gap size does not seem to be taken into account, and phrase dovetailing such as the one involving “do want” and “not anymore” in Fig. 2 is disallowed. hbp ’s strong tendency to overestimate the probability of rare bi-phrases; it is computed as in equation (2), except that bi-phrase probabilities are computed based on individual word translation probabilities, somewhat as in IBM mod"
H05-1095,P01-1030,1,0.79189,"uent source phrases, as most phrases have less than 20 translations. 6.3 Experiments The parameters of the model were optimized independantly for each bi-phrase library. In all cases, we performed only 2 iterations of the training procedure, then measured the performance of the system on the test set in terms of the NIST and BLEU scores against one reference translation. As a point of comparison, we also trained an IBM-4 translation model with the GIZA++ toolkit (Och and Ney, 2000), using the combined bi-phrase building and training sets, and translated the test set using the ReWrite decoder (Germann et al., 2001)5 . Table 2 describes the various libraries that were used for our experiments, and the results obtained for each. System/library ReWrite A1 A2 -g0 A2 -g3 B 1 -g0 B1 B 2 -g0 B 2 -g3 B 1 -g1 B 1 -g2 B 1 -g3 B 1 -g4 bi-phrases 238 K 642 K 4.1 M 193 K 267 K 499 K 3.3 M 206 K 213 K 218 K 222 K NIST 6.6838 6.6695 6.7675 6.7068 6.7898 6.9172 6.7290 6.9707 6.8979 6.9406 6.9546 6.9527 BLEU 0.3324 0.3310 0.3363 0.3283 0.3369 0.3407 0.3391 0.3552 0.3441 0.3454 0.3518 0.3423 Table 2: Bi-phrase libraries and results The top part of the table presents the results for the A libraries. As can be seen, librar"
H05-1095,P04-1064,1,0.936967,"iterbi alignments, forward and reverse, enriched with alignments from the union) and then generate bi-phrases by combining together individual alignments that co-occur in the same pair of sentences. This is the strategy that is usually adopted in other phrase-based MT approaches (Zens and Ney, 2003; Och and Ney, 2004). Here, the difference is that we are not restricted to combinations that produce strictly contiguous bi-phrases. The second strategy is to rely on a wordalignment method that naturally produces many-tomany alignments between non-contiguous words, such as the method described in (Goutte et al., 2004). By means of a matrix factorization, this method produces a parallel partition of the two texts, seen as sets of word tokens. Each token therefore belongs to one, and only one, subset within this partition, and corresponding subsets in the source and target make up what are called cepts. For example, in Figure 1, these cepts are represented by the circles numbered 1, 2 and 3; each cept thus connects word tokens in the source and the target, regardless of position or contiguity. These cepts naturally constitute bi-phrases, and can be used directly to produce a biphrase library. Obviously, the"
H05-1095,W02-1018,0,0.0165656,"lso presented that deals such phrases, as well as a training method based on the maximization of translation accuracy, as measured with the NIST evaluation metric. Translations are produced by means of a beam-search decoder. Experimental results are presented, that demonstrate how the proposed method allows to better generalize from the training data. 1 Arne Mauser RWTH Aachen University arne.mauser@rwth-aachen.de 2 Introduction Possibly the most remarkable evolution of recent years in statistical machine translation is the step from word-based models to phrase-based models (Och et al., 1999; Marcu and Wong, 2002; Yamada and Knight, 2002; Tillmann and Xia, 2003). While in traditional word-based statistical models (Brown et al., 1993) the atomic unit that translation operates on is the word, phrase-based methods acknowledge the significant role played in language by multiword expressions, thus incorporating in a statistical framework the insight behind Example-Based Machine Translation (Somers, 1999). However, Phrase-based models proposed so far only deal with multi-word units that are sequences Non-contiguous phrases Why should it be a good thing to use phrases composed of possibly non-contiguous sequ"
H05-1095,P00-1056,0,0.0383638,"equivalents. While the first of these filters typically eliminates a large number of entries, the second only affects the most frequent source phrases, as most phrases have less than 20 translations. 6.3 Experiments The parameters of the model were optimized independantly for each bi-phrase library. In all cases, we performed only 2 iterations of the training procedure, then measured the performance of the system on the test set in terms of the NIST and BLEU scores against one reference translation. As a point of comparison, we also trained an IBM-4 translation model with the GIZA++ toolkit (Och and Ney, 2000), using the combined bi-phrase building and training sets, and translated the test set using the ReWrite decoder (Germann et al., 2001)5 . Table 2 describes the various libraries that were used for our experiments, and the results obtained for each. System/library ReWrite A1 A2 -g0 A2 -g3 B 1 -g0 B1 B 2 -g0 B 2 -g3 B 1 -g1 B 1 -g2 B 1 -g3 B 1 -g4 bi-phrases 238 K 642 K 4.1 M 193 K 267 K 499 K 3.3 M 206 K 213 K 218 K 222 K NIST 6.6838 6.6695 6.7675 6.7068 6.7898 6.9172 6.7290 6.9707 6.8979 6.9406 6.9546 6.9527 BLEU 0.3324 0.3310 0.3363 0.3283 0.3369 0.3407 0.3391 0.3552 0.3441 0.3454 0.3518 0.3"
H05-1095,J03-1002,0,0.00889681,"d on the first “free” position in the target language sentence, i.e. either the leftmost gap, or the right end of the sequence. Figure 2 illustrates this process with an example. To produce translations, our approach therefore relies on a collection of bi-phrases, what we call a bi-phrase library. Such a library is constructed from a corpus of existing translations, aligned at the word level. Two strategies come to mind to produce noncontiguous bi-phrases for these libraries. The first is to align the words using a “standard” word alignement technique, such as the Refined Method described in (Och and Ney, 2003) (the intersection of two IBM Viterbi alignments, forward and reverse, enriched with alignments from the union) and then generate bi-phrases by combining together individual alignments that co-occur in the same pair of sentences. This is the strategy that is usually adopted in other phrase-based MT approaches (Zens and Ney, 2003; Och and Ney, 2004). Here, the difference is that we are not restricted to combinations that produce strictly contiguous bi-phrases. The second strategy is to rely on a wordalignment method that naturally produces many-tomany alignments between non-contiguous words, su"
H05-1095,J04-4002,0,0.0387242,"ting translations, aligned at the word level. Two strategies come to mind to produce noncontiguous bi-phrases for these libraries. The first is to align the words using a “standard” word alignement technique, such as the Refined Method described in (Och and Ney, 2003) (the intersection of two IBM Viterbi alignments, forward and reverse, enriched with alignments from the union) and then generate bi-phrases by combining together individual alignments that co-occur in the same pair of sentences. This is the strategy that is usually adopted in other phrase-based MT approaches (Zens and Ney, 2003; Och and Ney, 2004). Here, the difference is that we are not restricted to combinations that produce strictly contiguous bi-phrases. The second strategy is to rely on a wordalignment method that naturally produces many-tomany alignments between non-contiguous words, such as the method described in (Goutte et al., 2004). By means of a matrix factorization, this method produces a parallel partition of the two texts, seen as sets of word tokens. Each token therefore belongs to one, and only one, subset within this partition, and corresponding subsets in the source and target make up what are called cepts. For examp"
H05-1095,W99-0604,0,0.0809757,"slation model is also presented that deals such phrases, as well as a training method based on the maximization of translation accuracy, as measured with the NIST evaluation metric. Translations are produced by means of a beam-search decoder. Experimental results are presented, that demonstrate how the proposed method allows to better generalize from the training data. 1 Arne Mauser RWTH Aachen University arne.mauser@rwth-aachen.de 2 Introduction Possibly the most remarkable evolution of recent years in statistical machine translation is the step from word-based models to phrase-based models (Och et al., 1999; Marcu and Wong, 2002; Yamada and Knight, 2002; Tillmann and Xia, 2003). While in traditional word-based statistical models (Brown et al., 1993) the atomic unit that translation operates on is the word, phrase-based methods acknowledge the significant role played in language by multiword expressions, thus incorporating in a statistical framework the insight behind Example-Based Machine Translation (Somers, 1999). However, Phrase-based models proposed so far only deal with multi-word units that are sequences Non-contiguous phrases Why should it be a good thing to use phrases composed of possib"
H05-1095,P03-1021,0,0.0338002,"guities they contain. 4 Say we have a set of source-language sentences S. For a given value of λ, we can compute the set of corresponding target-language translations T . Given a set of reference (“gold-standard”) translations R for S and a function E(T, R) which measures the “error” in T relative to R, then we can formulate the parameter estimation problem as2 : Parameter Estimation The values of the λ parameters of the log-linear model can be set so as to optimize a given criterion. For instance, one can maximize the likelyhood of some set of training sentences. Instead, and as suggested by Och (2003), we chose to maximize directly the quality of the translations produced by the system, as measured with a machine translation evaluation metric. 758 As pointed out by Och, one notable difficulty with this approach is that, because the computation of T is based on an argmax operation (see eq. 1), it is not continuous with regard to λ, and standard gradientdescent methods cannot be used to solve the optimization. Och proposes two workarounds to this problem: the first one relies on a direct optimization method derived from Powell’s algorithm; the second introduces a smoothed (continuous) versio"
H05-1095,P02-1040,0,0.111177,"to λ, and standard gradientdescent methods cannot be used to solve the optimization. Och proposes two workarounds to this problem: the first one relies on a direct optimization method derived from Powell’s algorithm; the second introduces a smoothed (continuous) version of the error function E(T, R) and then relies on a gradient-based optimization method. We have opted for this last approach. Och shows how to implement it when the error function can be computed as the sum of errors on individual sentences. Unfortunately, this is not the case for such widely used MT evaluation metrics as BLEU (Papineni et al., 2002) and NIST (Doddington, 2002). We show here how it can be done for NIST; a similar derivation is possible for BLEU. The NIST evaluation metric computes a weighted n-gram precision between T and R, multiplied by a factor B(S, T, R) that penalizes short translations. It can be formulated as: B(S, T, R) × N X n=1 P s∈S In (ts , rs ) P s∈S Cn (ts ) (3) where N is the largest n-gram considered (usually N = 4), In (ts , rs ) is a weighted count of common n-grams between the target (ts ) and reference (rs ) translations of sentence s, and Cn (ts ) is the total number of n-grams in ts . To derive a ver"
H05-1095,N03-2036,0,0.095765,"as a training method based on the maximization of translation accuracy, as measured with the NIST evaluation metric. Translations are produced by means of a beam-search decoder. Experimental results are presented, that demonstrate how the proposed method allows to better generalize from the training data. 1 Arne Mauser RWTH Aachen University arne.mauser@rwth-aachen.de 2 Introduction Possibly the most remarkable evolution of recent years in statistical machine translation is the step from word-based models to phrase-based models (Och et al., 1999; Marcu and Wong, 2002; Yamada and Knight, 2002; Tillmann and Xia, 2003). While in traditional word-based statistical models (Brown et al., 1993) the atomic unit that translation operates on is the word, phrase-based methods acknowledge the significant role played in language by multiword expressions, thus incorporating in a statistical framework the insight behind Example-Based Machine Translation (Somers, 1999). However, Phrase-based models proposed so far only deal with multi-word units that are sequences Non-contiguous phrases Why should it be a good thing to use phrases composed of possibly non-contiguous sequences of words? In doing so we expect to improve t"
H05-1095,P02-1039,1,0.503169,"ls such phrases, as well as a training method based on the maximization of translation accuracy, as measured with the NIST evaluation metric. Translations are produced by means of a beam-search decoder. Experimental results are presented, that demonstrate how the proposed method allows to better generalize from the training data. 1 Arne Mauser RWTH Aachen University arne.mauser@rwth-aachen.de 2 Introduction Possibly the most remarkable evolution of recent years in statistical machine translation is the step from word-based models to phrase-based models (Och et al., 1999; Marcu and Wong, 2002; Yamada and Knight, 2002; Tillmann and Xia, 2003). While in traditional word-based statistical models (Brown et al., 1993) the atomic unit that translation operates on is the word, phrase-based methods acknowledge the significant role played in language by multiword expressions, thus incorporating in a statistical framework the insight behind Example-Based Machine Translation (Somers, 1999). However, Phrase-based models proposed so far only deal with multi-word units that are sequences Non-contiguous phrases Why should it be a good thing to use phrases composed of possibly non-contiguous sequences of words? In doing"
H05-1095,N03-1017,0,0.183385,"rom a corpus of existing translations, aligned at the word level. Two strategies come to mind to produce noncontiguous bi-phrases for these libraries. The first is to align the words using a “standard” word alignement technique, such as the Refined Method described in (Och and Ney, 2003) (the intersection of two IBM Viterbi alignments, forward and reverse, enriched with alignments from the union) and then generate bi-phrases by combining together individual alignments that co-occur in the same pair of sentences. This is the strategy that is usually adopted in other phrase-based MT approaches (Zens and Ney, 2003; Och and Ney, 2004). Here, the difference is that we are not restricted to combinations that produce strictly contiguous bi-phrases. The second strategy is to rely on a wordalignment method that naturally produces many-tomany alignments between non-contiguous words, such as the method described in (Goutte et al., 2004). By means of a matrix factorization, this method produces a parallel partition of the two texts, seen as sets of word tokens. Each token therefore belongs to one, and only one, subset within this partition, and corresponding subsets in the source and target make up what are cal"
H05-1095,N04-1033,0,\N,Missing
K19-1084,P16-1231,0,0.0359701,"6 Related Work (Hoang et al., 2018), working in a NMT context, have a similar motivation to ours. They first train an autoregressive seq2seq model (Transformer in their case) on bilingual data, then attempt to control global properties of the generated sequences through the introduction of a priori features. They interpolate the training of the autoregressive model with training of a Moment Matching component which tries to equate the features expectations of the model with those of the data. Contrarily to our approach, they do not directly try to maximize likelihood in an integrated model. (Andor et al., 2016) consider transition-based neural networks, and contrast local to global normalization of decision sequences, showing how the global approach avoids the label bias problem in such tasks as tagging or parsing. They w(xi ) for a given N , but consistent (that is, it converges to the true E for N ! 1). Training-2 While Training-1 results in a welldefined model P (x), which may fit the data closely in principle, we should not conclude 903 Algorithm 1 Training 1: function TRAIN(D, V, T, f t, DsSize, tReg, mode) 2: r TRAIN RNN(D, V, optAdam) 3: P TRAIN GAM(r, D, V, tReg, f t) 4: if mode = ‘two stage"
P03-2017,J93-2003,0,0.00655908,"Missing"
P03-2017,1997.mtsummit-papers.1,0,0.0908424,"Missing"
P03-2017,W02-1020,0,0.0288727,"Missing"
P03-2017,E03-3006,1,0.826117,"Missing"
P03-2017,P02-1038,0,0.0228667,"Missing"
P03-2017,P98-2173,0,0.0823743,"Missing"
P03-2017,P01-1067,1,0.758419,"Missing"
P03-2017,W00-1404,1,\N,Missing
P03-2017,C98-2168,0,\N,Missing
P09-1038,2001.mtsummit-papers.68,0,0.0313755,"The x axis corresponds to the cumulative time for processing the test set; for (a) and (c), the y axis corresponds to the mean difference (over all sentences) between the lm score of the output and the lm score of the reference normalized by the sentence length N: (LM(ref)-LM(true))/N. The solid line with star marks corresponds to using beam-search with different pruning thresholds, which result in different processing times and performances. The cross corresponds to using the exact-TSP decoder (in this case the time to the optimal solution is not under the user’s control). ond score is BLEU (Papineni et al., 2001), computed between the reconstructed and the original sentences, which allows us to check how well the quality of reconstruction correlates with the internal score. The training dataset for learning the LM consists of 50000 sentences from NewsCommentary corpus (Callison-Burch et al., 2008), the test dataset for word reordering consists of 170 sentences, the average length of test sentences is equal to 17 words. Bigram based reordering. First we consider a bigram Language Model and the algorithms try to find the re-ordering that maximizes the LM score. The TSP solver used here is exact, that is"
P09-1038,J03-1005,0,0.369801,"gy to an IBM-4 model, using generic Integer Programming techniques. The paper comes close to a TSP formulation of decoding with IBM-4 models, but does not pursue this route to the end, stating that “It is difficult to convert decoding into straight TSP, but a wide range of combinatorial optimization problems (including TSP) can be expressed in the more general framework of linear integer programming”. By employing generic IP techniques, it is however impossible to rely on the variety of more efficient both exact and approximate approaches which have been designed specifically for the TSP. In (Tillmann and Ney, 2003) and (Tillmann, 2006), the authors modify a certain Dynamic Programming technique used for TSP for use with an IBM4 word-based model and a phrase-based model respectively. However, to our knowledge, none of these works has proposed a direct reformulation of these SMT models as TSP instances. We believe we are the first to do so, working in our case Related work Beam-search decoding In beam-search decoding, candidate translation prefixes are iteratively extended with new phrases. In its most widespread variant, stack decoding, prefixes obtained by consuming the same number of source words, no m"
P09-1038,W06-3602,0,0.0697138,"eneric Integer Programming techniques. The paper comes close to a TSP formulation of decoding with IBM-4 models, but does not pursue this route to the end, stating that “It is difficult to convert decoding into straight TSP, but a wide range of combinatorial optimization problems (including TSP) can be expressed in the more general framework of linear integer programming”. By employing generic IP techniques, it is however impossible to rely on the variety of more efficient both exact and approximate approaches which have been designed specifically for the TSP. In (Tillmann and Ney, 2003) and (Tillmann, 2006), the authors modify a certain Dynamic Programming technique used for TSP for use with an IBM4 word-based model and a phrase-based model respectively. However, to our knowledge, none of these works has proposed a direct reformulation of these SMT models as TSP instances. We believe we are the first to do so, working in our case Related work Beam-search decoding In beam-search decoding, candidate translation prefixes are iteratively extended with new phrases. In its most widespread variant, stack decoding, prefixes obtained by consuming the same number of source words, no matter which, are grou"
P09-1038,P01-1030,0,0.834807,"uous and informative portions that should be best translated far from the beginning. All these reasons motivate considering alternative decoding strategies. Word-based SMT and the TSP As already mentioned, the similarity between SMT decoding and TSP was recognized in (Knight, 1999), who focussed on showing that any TSP can be reformulated as a sub-class of the SMT decoding problem, proving that SMT decoding is NP-hard. Following this work, the existence of many efficient TSP algorithms then inspired certain adaptations of the underlying techniques to SMT decoding for word-based models. Thus, (Germann et al., 2001) adapt a TSP subtour elimination strategy to an IBM-4 model, using generic Integer Programming techniques. The paper comes close to a TSP formulation of decoding with IBM-4 models, but does not pursue this route to the end, stating that “It is difficult to convert decoding into straight TSP, but a wide range of combinatorial optimization problems (including TSP) can be expressed in the more general framework of linear integer programming”. By employing generic IP techniques, it is however impossible to rely on the variety of more efficient both exact and approximate approaches which have been"
P09-1038,W08-0510,0,0.027199,"beam-search make it a suboptimal choice for phrase-based decoding, and we will propose an alternative. This alternative is based on the observation that phrase-based decoding can be very naturally cast as a Traveling Salesman Problem (TSP), one of the best studied problems in combinatorial optimization. We will show that this formulation is not only a powerful conceptual device for reasoning on decoding, but is also practically convenient: in the same amount of time, off-the-shelf TSP solvers can find higher scoring solutions than the state-of-the art beam-search decoder implemented in Moses (Hoang and Koehn, 2008). 2 ever, this solution is only partially satisfactory. On the one hand, heuristics should be computationally light, much lighter than computing the actual best score itself, while, on the other hand, the heuristics should be tight, as otherwise pruning errors will ensue. There is no clear criterion to guide in this trade-off. Even when good heuristics are available, the decoder will show a bias towards putting at the beginning the translation of a certain portion of the source, either because this portion is less ambiguous (i.e. its translation has larger conditional probability) or because t"
P09-1038,J99-4005,0,0.927426,"rases in the candidate translation deviates from their order in the source sentence. Given such a model, where the λi ’s have been tuned on a development set in order to minimize some error rate (see e.g. (Lopez, 2008)), together with a library of biphrases extracted from some large training corpus, a decoder implements the actual search among alternative translations: An efficient decoding algorithm is a crucial element of any statistical machine translation system. Some researchers have noted certain similarities between SMT decoding and the famous Traveling Salesman Problem; in particular (Knight, 1999) has shown that any TSP instance can be mapped to a sub-case of a word-based SMT model, demonstrating NP-hardness of the decoding task. In this paper, we focus on the reverse mapping, showing that any phrase-based SMT decoding problem can be directly reformulated as a TSP. The transformation is very natural, deepens our understanding of the decoding problem, and allows direct use of any of the powerful existing TSP solvers for SMT decoding. We test our approach on three datasets, and compare a TSP-based decoder to the popular beam-search algorithm. In all cases, our method provides competitive"
P09-1038,N03-1017,0,0.417223,"of a word-based SMT model, demonstrating NP-hardness of the decoding task. In this paper, we focus on the reverse mapping, showing that any phrase-based SMT decoding problem can be directly reformulated as a TSP. The transformation is very natural, deepens our understanding of the decoding problem, and allows direct use of any of the powerful existing TSP solvers for SMT decoding. We test our approach on three datasets, and compare a TSP-based decoder to the popular beam-search algorithm. In all cases, our method provides competitive or better performance. 1 Introduction Phrase-based systems (Koehn et al., 2003) are probably the most widespread class of Statistical Machine Translation systems, and arguably one of the most successful. They use aligned sequences of words, called biphrases, as building blocks for translations, and score alternative candidate translations for the same source sentence based on a log-linear model of the conditional probability of target sentences given the source sentence: X 1 p(T, a|S) = λk hk (S, a, T ) (1) exp ZS (a∗ , T ∗ ) = arg max P (T, a|S). (a,T ) (2) The decoding problem (2) is a discrete optimization problem. Usually, it is very hard to find the exact optimum an"
P09-1038,P02-1040,0,\N,Missing
P09-1089,W07-0734,0,0.0147474,"ets and oceanfront homes”. Here, chalets are replaced by houses or units (depending on the model), providing a translation that would be acceptable by most readers. Other incorrect translations occurred when the unknown term was part of a phrase, for example, troughs replaced with depressions in peaks Automatic MT Evaluation Although automatic MT evaluation metrics are less appropriate for capturing the variations generated by our method, to ensure that there was no degradation in the system-level scores according to such metrics we also measured the models’ performance using BLEU and METEOR (Agarwal and Lavie, 2007). The version of METEOR we used on the target language (French) considers the stems of the words, instead of surface forms only, but does not make use of WordNet synonyms. We evaluated the performance of the top models of Table 1, as well as of a baseline SMT system that left unknown terms untranslated, on the sample of 1,014 manually annotated sentences. As shown in Table 3, all models resulted in improvement with respect to the original sentences (base797 (Dyer et al., 2008) in order to allow a compact representation of alternative inputs to an SMT system. This is an approach that we intend"
P09-1089,N06-1003,0,0.45233,"Missing"
P09-1089,W08-0309,0,0.0202988,"Missing"
P09-1089,D08-1021,0,0.0212981,"s can be exploited to validate the application of a rule to a text. In such models, an explicit Word Sense Disambiguation (WSD) is not necessarily required; rather, an implicit sense-match is sought after (Dagan et al., 2006). Within the scope of our paper, rule application is handled similarly to Lexical Substitution (McCarthy and Navigli, 2007), considering the contextual relationship between the text and the rule. However, in general, entailment rule application addresses other aspects of context matching as well (Szpektor et al., 2008). al., 2006; Cohn and Lapata, 2007; Zhao et al., 2008; Callison-Burch, 2008; Guzm´an and Garrido, 2008). The procedure to extract paraphrases in these approaches is similar to standard phrase extraction in SMT systems, and therefore a large amount of additional parallel corpus is required. Moreover, as discussed in Section 5, when unknown texts are not from the same domain as the SMT training corpus, it is likely that paraphrases found through such methods will yield misleading translations. Bond et al. (2008) use grammars to paraphrase the whole source sentence, covering aspects like word order and minor lexical variations (tenses etc.), but not content words. The p"
P09-1089,P07-1092,0,0.0147012,"mouse to mark your answers”. Context-models can be exploited to validate the application of a rule to a text. In such models, an explicit Word Sense Disambiguation (WSD) is not necessarily required; rather, an implicit sense-match is sought after (Dagan et al., 2006). Within the scope of our paper, rule application is handled similarly to Lexical Substitution (McCarthy and Navigli, 2007), considering the contextual relationship between the text and the rule. However, in general, entailment rule application addresses other aspects of context matching as well (Szpektor et al., 2008). al., 2006; Cohn and Lapata, 2007; Zhao et al., 2008; Callison-Burch, 2008; Guzm´an and Garrido, 2008). The procedure to extract paraphrases in these approaches is similar to standard phrase extraction in SMT systems, and therefore a large amount of additional parallel corpus is required. Moreover, as discussed in Section 5, when unknown texts are not from the same domain as the SMT training corpus, it is likely that paraphrases found through such methods will yield misleading translations. Bond et al. (2008) use grammars to paraphrase the whole source sentence, covering aspects like word order and minor lexical variations (t"
P09-1089,P04-1036,0,0.00728935,"e also applied several combinations of source models, such as LSA combined with LMS, to take advantage of their complementary strengths. Additionally, we assessed our method with sourceonly models, by setting the number of sentences to be selected by the source model to one (k = 1). Scoring source texts We test our proposed method using several context-models shown to perform reasonably well in previous work: • FREQ: The first model we use is a contextindependent baseline. A common useful heuristic to pick an entailment rule is to select the candidate with the highest frequency in the corpus (Mccarthy et al., 2004). In this model, a rule’s score is the normalized number of occurrences of its RHS in the training corpus, ignoring the context of the LHS. 5 5.1 Manual Evaluation To evaluate the translations produced using the various source and target models and the different rule-sets, we rely mostly on manual assessment, since automatic MT evaluation metrics like BLEU do not capture well the type of semantic variations • LSA: Latent Semantic Analysis (Deerwester et al., 1990) is a well-known method for rep2 Results http://opennlp.sourceforge.net 795 Model 1 2 3 4 5 6 7 –:SMT NB:SMT LSA:SMT NB:– LMS:LMT FR"
P09-1089,P06-1057,1,0.819303,"lment rules, i.e. rules without variables. Various resources for lexical rules are available, and the prominent one is WordNet (Fellbaum, 1998), which has been used in virtually all TE systems (Giampiccolo et al., 2007). Typically, a rule application is valid only under specific contexts. For example, mouse ⇒ rodent should not be applied to “Use the mouse to mark your answers”. Context-models can be exploited to validate the application of a rule to a text. In such models, an explicit Word Sense Disambiguation (WSD) is not necessarily required; rather, an implicit sense-match is sought after (Dagan et al., 2006). Within the scope of our paper, rule application is handled similarly to Lexical Substitution (McCarthy and Navigli, 2007), considering the contextual relationship between the text and the rule. However, in general, entailment rule application addresses other aspects of context matching as well (Szpektor et al., 2008). al., 2006; Cohn and Lapata, 2007; Zhao et al., 2008; Callison-Burch, 2008; Guzm´an and Garrido, 2008). The procedure to extract paraphrases in these approaches is similar to standard phrase extraction in SMT systems, and therefore a large amount of additional parallel corpus is"
P09-1089,D08-1022,0,0.0101575,"Missing"
P09-1089,W09-0404,0,0.0103699,"ossible, to generate more general texts for translation. Our approach, based on the textual entailment framework, considers the newly generated texts as entailed from the original one. Monolingual semantic resources such as WordNet can provide entailment rules required for both these symmetric and asymmetric entailment relations. Textual Entailment (TE) has recently become a prominent paradigm for modeling semantic inference, capturing the needs of a broad range of text understanding applications (Giampiccolo et al., 2007). Yet, its application to SMT has been so far limited to MT evaluation (Pado et al., 2009). TE defines a directional relation between two texts, where the meaning of the entailed text (hypothesis, h) can be inferred from the meaning of the entailing text, t. Under this paradigm, paraphrases are a special case of the entailment relation, when the relation is symmetric (the texts entail each other). Otherwise, we say that one text directionally entails the other. A common practice for proving (or generating) h from t is to apply entailment rules to t. An entailment rule, denoted LHS ⇒ RHS, specifies an entailment relation between two text fragments (the Left- and Right- Hand Sides),"
P09-1089,P08-1115,0,0.0258391,"he system-level scores according to such metrics we also measured the models’ performance using BLEU and METEOR (Agarwal and Lavie, 2007). The version of METEOR we used on the target language (French) considers the stems of the words, instead of surface forms only, but does not make use of WordNet synonyms. We evaluated the performance of the top models of Table 1, as well as of a baseline SMT system that left unknown terms untranslated, on the sample of 1,014 manually annotated sentences. As shown in Table 3, all models resulted in improvement with respect to the original sentences (base797 (Dyer et al., 2008) in order to allow a compact representation of alternative inputs to an SMT system. This is an approach that we intend to explore in future work, as a way to efficiently handle the different source language alternatives generated by entailment rules. However, since most current MT systems do not accept such type of inputs, we consider the results on pruning by source-side context models as broadly relevant. and troughs, a problem that also strongly affects paraphrasing. In another case, movement was the hypernym chosen to replace labor in labor movement, yielding an awkward text for translatio"
P09-1089,P02-1040,0,0.104704,"ord order and minor lexical variations (tenses etc.), but not content words. The paraphrases are added to the source side of the corpus and the corresponding target sentences are duplicated. This, however, may yield distorted probability estimates in the phrase table, since these were not computed from parallel data. The main use of monolingual paraphrases in MT to date has been for evaluation. For example, (Kauchak and Barzilay, 2006) paraphrase references to make them closer to the system translation in order to obtain more reliable results when using automatic evaluation metrics like BLEU (Papineni et al., 2002). 2.3 3 Textual Entailment and Entailment Rules Textual Entailment for Statistical Machine Translation Previous solutions for handling unknown terms in a source text s augment the SMT system’s phrase table based on multilingual corpora. This allows indirectly paraphrasing s, when the SMT system chooses to use a paraphrase included in the table and produces a translation with the corresponding target phrase for the unknown term. We propose using monolingual paraphrasing methods and resources for this task to obtain a more extensive set of rules for paraphrasing the source. These rules are then"
P09-1089,eck-etal-2008-communicating,0,0.0802498,"Missing"
P09-1089,H05-1095,1,0.693883,"setting of these experiments is described in what follows. Preliminary analysis confirmed (as expected) that readers prefer translations of paraphrases, when available, over translations of directional entailments. This consideration is therefore taken into account in the proposed method. The input is a text unit to be translated, such as a sentence or paragraph, with one or more unknown terms. For each unknown term we first fetch a list of candidate rules for paraphrasing (e.g. synonyms), where the unknown term is the LHS. For SMT data To produce sentences for our experiments, we use Matrax (Simard et al., 2005), a standard phrase-based SMT system, with the exception that it allows gaps in phrases. We use approximately 1M sentence pairs from the English-French 794 Europarl corpus for training, and then translate a test set of 5,859 English sentences from the News corpus into French. Both resources are taken from the shared translation task in WMT-2008 (Callison-Burch et al., 2008). Hence, we compare our method in a setting where the training and test data are from different domains, a common scenario in the practical use of MT systems. Of the 5,859 translated sentences, 2,494 contain unknown terms (c"
P09-1089,W07-1401,1,0.667804,"cal selection and ordering. This phenomenon is demonstrated in the following sentences, where the translation of the English sentence (1) is acceptable only when the unknown word (in bold) is replaced with a translatable paraphrase (3): candidates before supplying them to the translation engine, thus improving translation efficiency. Second, the ranking may be combined with target language information in order to choose the best translation, thus improving translation quality. We position the problem of generating alternative texts for translation within the Textual Entailment (TE) framework (Giampiccolo et al., 2007). TE provides a generic way for handling language variability, identifying when the meaning of one text is entailed by the other (i.e. the meaning of the entailed text can be inferred from the meaning of the entailing one). When the meanings of two texts are equivalent (paraphrase), entailment is mutual. Typically, a more general version of a certain text is entailed by it. Hence, through TE we can formalize the generation of both equivalent and more general texts for the source text. When possible, a paraphrase is used. Otherwise, an alternative text whose meaning is entailed by the original"
P09-1089,P08-1078,1,0.677078,"should not be applied to “Use the mouse to mark your answers”. Context-models can be exploited to validate the application of a rule to a text. In such models, an explicit Word Sense Disambiguation (WSD) is not necessarily required; rather, an implicit sense-match is sought after (Dagan et al., 2006). Within the scope of our paper, rule application is handled similarly to Lexical Substitution (McCarthy and Navigli, 2007), considering the contextual relationship between the text and the rule. However, in general, entailment rule application addresses other aspects of context matching as well (Szpektor et al., 2008). al., 2006; Cohn and Lapata, 2007; Zhao et al., 2008; Callison-Burch, 2008; Guzm´an and Garrido, 2008). The procedure to extract paraphrases in these approaches is similar to standard phrase extraction in SMT systems, and therefore a large amount of additional parallel corpus is required. Moreover, as discussed in Section 5, when unknown texts are not from the same domain as the SMT training corpus, it is likely that paraphrases found through such methods will yield misleading translations. Bond et al. (2008) use grammars to paraphrase the whole source sentence, covering aspects like word ord"
P09-1089,W06-2907,1,0.899223,"Missing"
P09-1089,E06-1006,0,0.130232,"Missing"
P09-1089,P08-1089,0,0.035166,"ers”. Context-models can be exploited to validate the application of a rule to a text. In such models, an explicit Word Sense Disambiguation (WSD) is not necessarily required; rather, an implicit sense-match is sought after (Dagan et al., 2006). Within the scope of our paper, rule application is handled similarly to Lexical Substitution (McCarthy and Navigli, 2007), considering the contextual relationship between the text and the rule. However, in general, entailment rule application addresses other aspects of context matching as well (Szpektor et al., 2008). al., 2006; Cohn and Lapata, 2007; Zhao et al., 2008; Callison-Burch, 2008; Guzm´an and Garrido, 2008). The procedure to extract paraphrases in these approaches is similar to standard phrase extraction in SMT systems, and therefore a large amount of additional parallel corpus is required. Moreover, as discussed in Section 5, when unknown texts are not from the same domain as the SMT training corpus, it is likely that paraphrases found through such methods will yield misleading translations. Bond et al. (2008) use grammars to paraphrase the whole source sentence, covering aspects like word order and minor lexical variations (tenses etc.), but no"
P09-1089,P08-2015,0,0.0376735,"Missing"
P09-1089,N06-1058,0,0.0361947,"t is likely that paraphrases found through such methods will yield misleading translations. Bond et al. (2008) use grammars to paraphrase the whole source sentence, covering aspects like word order and minor lexical variations (tenses etc.), but not content words. The paraphrases are added to the source side of the corpus and the corresponding target sentences are duplicated. This, however, may yield distorted probability estimates in the phrase table, since these were not computed from parallel data. The main use of monolingual paraphrases in MT to date has been for evaluation. For example, (Kauchak and Barzilay, 2006) paraphrase references to make them closer to the system translation in order to obtain more reliable results when using automatic evaluation metrics like BLEU (Papineni et al., 2002). 2.3 3 Textual Entailment and Entailment Rules Textual Entailment for Statistical Machine Translation Previous solutions for handling unknown terms in a source text s augment the SMT system’s phrase table based on multilingual corpora. This allows indirectly paraphrasing s, when the SMT system chooses to use a paraphrase included in the table and produces a translation with the corresponding target phrase for the"
P09-1089,P97-1017,0,0.266109,"Missing"
P09-1089,E03-1076,0,0.130127,"Missing"
P09-1089,D07-1092,0,0.0249287,"Missing"
P09-1089,S07-1009,0,0.0137349,"Missing"
P09-1089,2008.iwslt-papers.2,0,\N,Missing
P12-1003,P11-2031,0,0.0302821,"the cases where a slightly larger in-domain “seed” parallel corpus is available, we introduced an extrapolation method and a combined method yielding highprecision predictions: using models trained on up to 20K sentence pairs we can predict performance on a given test set with a root mean squared error in the order of 1 BLEU point at 75K sentence pairs, and in the order of 2-4 BLEU points at 500K. Considering that variations in the order of 1 BLEU point on a same test dataset can be observed simply due to the instability of the standard MERT parameter tuning algorithm (Foster and Kuhn, 2009; Clark et al., 2011), we believe our results to be close to what can be achieved in principle. Note that by using gold curves as labels instead of actual measures we implicitly average across many rounds of MERT (14 for each curve), greatly attenuating the impact of the instability in the optimization procedure due to randomness. Figure 4: Predicted curves in the three scenarios for Czech-English test set using the Lasso model For enabling this work we trained a multitude of instances of the same phrase-based SMT system on 30 distinct combinations of language-pair and domain, each with fourteen distinct training"
P12-1003,W09-0439,0,0.015845,"allel test dataset. For the cases where a slightly larger in-domain “seed” parallel corpus is available, we introduced an extrapolation method and a combined method yielding highprecision predictions: using models trained on up to 20K sentence pairs we can predict performance on a given test set with a root mean squared error in the order of 1 BLEU point at 75K sentence pairs, and in the order of 2-4 BLEU points at 500K. Considering that variations in the order of 1 BLEU point on a same test dataset can be observed simply due to the instability of the standard MERT parameter tuning algorithm (Foster and Kuhn, 2009; Clark et al., 2011), we believe our results to be close to what can be achieved in principle. Note that by using gold curves as labels instead of actual measures we implicitly average across many rounds of MERT (14 for each curve), greatly attenuating the impact of the instability in the optimization procedure due to randomness. Figure 4: Predicted curves in the three scenarios for Czech-English test set using the Lasso model For enabling this work we trained a multitude of instances of the same phrase-based SMT system on 30 distinct combinations of language-pair and domain, each with fourte"
P12-1003,N03-1017,0,0.0533356,"Missing"
P12-1003,P07-2045,0,0.0104276,"ee or four parameters. Curve fitting technique Given a set of observations {(x1 , y1 ), (x2 , y2 )...(xn , yn )} and a curve family F (x; θ) from Table 1, we compute a best fit θˆ where: n X θˆ = arg min [yi − F (xi ; θ)]2 , (2) θ i=1 through use of the Levenberg-Marquardt method (Mor´e, 1978) for non-linear regression. For selecting a learning curve family, and for all other experiments in this paper, we trained a large number of systems on multiple configurations of training sets and sample sizes, and tested each on multiple test sets; these are listed in Table 2. All experiments use Moses (Koehn et al., 2007). 2 Domain Europarl (Koehn, 2005) KFTT (Neubig, 2011) EMEA (Tiedemann, 2009) News (Callison-Burch et al., 2011) Source Language Fr, De, Es En Jp, En Da, De Cz,En,Fr,De,Es Target Language En Fr, De, Es En, Jp En Cz,En,Fr,De,Es # Test sets 1 XX N c∈S t∈Tc ( n 1X ˆ 2 [yi − F (xi ; θ)] n i=1 )1/2 ct where S is the set of training datasets, Tc is the set of test datasets for training configuration c, θˆ is as defined in Eq. 2, N is the total number of combinations of training configurations and test datasets, and i ranges on a grid of training subset sizes.The expressions n, xi , yi , θˆ are all lo"
P12-1003,2005.mtsummit-papers.11,0,0.223885,"Missing"
P12-1003,P02-1040,0,0.087183,"approach in this work, and obtain useful estimations for a case like SMT, where the complexity of the mapping between the input and the output prevents tight theoretical analysis. 3 Selecting a parametric family of curves The first step in our approach consists in selecting a suitable family of shapes for the learning curves that we want to produce in the two scenarios being considered. We formulate the problem as follows. For a certain bilingual test dataset d, we consider a set of observations Od = {(x1 , y1 ), (x2 , y2 )...(xn , yn )}, where yi is the performance on d (measured using BLEU (Papineni et al., 2002)) of a translation model trained on a parallel corpus of size xi . The corpus size xi is measured in terms of the number of segments (sentences) present in the parallel corpus. We consider such observations to be generated by a regression model of the form: yi = F (xi ; θ) + i 1≤i≤n (1) where F is a function depending on a vector parameter θ which depends on d, and i is Gaussian noise of constant variance. Based on our prior knowledge of the problem, we limit the search for a suitable F to families that satisfies the following conditions- monotonically increasing, concave and bounded. The fi"
P12-1003,petrov-etal-2012-universal,0,0.0251006,"5 in the monolingual corpus of both source and target languages. 5. Word-order divergence: The divergence in the word-order between the source and the target languages can be captured using the part-ofspeech (pos) tag sequences across languages. We use cross-entropy measure to capture similarity between the n-gram distributions of the pos tags in the monolingual corpora of the two languages. The order of the n-grams ranges between n = 2, 4 . . . 12 in order to account for long distance reordering between languages. The pos tags for the languages are mapped to a reduced set of twelve pos tags (Petrov et al., 2012) in order to account for differences in tagsets used across languages. These features capture our intuition that translation is going to be harder if the language in the domain is highly variable and if the source and target languages diverge more in terms of morphology and word-order. The weights wj are estimated from data. The training data for fitting these linear models is obtained in the following way. For each configuration (combination of language pair and domain) c and test set t in Table 2, a gold curve is fitted using the selected tri-parameter power-law family using a fine grid of c"
P12-1003,W08-0305,0,0.191997,"Missing"
P12-1003,D08-1078,0,\N,Missing
P13-4015,2010.eamt-1.31,1,0.717918,"Missing"
P13-4015,N06-1003,0,0.558985,"Missing"
P13-4015,C00-1036,1,0.80515,"Missing"
P13-4015,W11-2148,0,0.174407,"Missing"
P13-4015,P07-2045,0,0.00433406,"Missing"
P13-4015,D09-1040,0,0.121067,"Missing"
P13-4015,D10-1064,0,0.159453,"Missing"
P13-4015,P09-1089,1,0.920825,"Missing"
P13-4015,P98-2173,0,0.197232,"Missing"
P13-4015,2009.eamt-1.5,1,0.909098,"Missing"
P13-4015,C12-3058,1,0.646426,"Missing"
P13-4015,C10-1152,0,0.0739096,"Missing"
P13-4015,W12-3102,0,\N,Missing
P13-4015,C98-2168,0,\N,Missing
P16-1127,P14-1133,0,0.0637,"lying grammar. We also show how grammatical constraints on the derivation sequence can easily be integrated inside the RNNbased sequential predictor. Our experiments show important improvements over previous results for the same dataset, and also demonstrate the advantage of incorporating the grammatical constraints. 1 Introduction Learning to map natural language utterances (NL) to logical forms (LF), a process known as semantic parsing, has received a lot of attention recently, in particular in the context of building QuestionAnswering systems (Kwiatkowski et al., 2013; Berant et al., 2013; Berant and Liang, 2014). In this paper, we focus on such a task where the NL question may be semantically complex, leading to a logical form query with a fair amount of compositionality, in a spirit close to (Pasupat and Liang, 2015). Given the recently shown effectiveness of RNNs (Recurrent Neural Networks), in particular Long Short Term Memory (LSTM) networks (Hochreiter and Schmidhuber, 1997), for performing sequence prediction in NLP applications such as machine translation (Sutskever et al., 2014) and natural language generation (Wen et al., 2015), we try to exploit similar techniques for our task. However we o"
P16-1127,D13-1160,0,0.263199,"relative to the underlying grammar. We also show how grammatical constraints on the derivation sequence can easily be integrated inside the RNNbased sequential predictor. Our experiments show important improvements over previous results for the same dataset, and also demonstrate the advantage of incorporating the grammatical constraints. 1 Introduction Learning to map natural language utterances (NL) to logical forms (LF), a process known as semantic parsing, has received a lot of attention recently, in particular in the context of building QuestionAnswering systems (Kwiatkowski et al., 2013; Berant et al., 2013; Berant and Liang, 2014). In this paper, we focus on such a task where the NL question may be semantically complex, leading to a logical form query with a fair amount of compositionality, in a spirit close to (Pasupat and Liang, 2015). Given the recently shown effectiveness of RNNs (Recurrent Neural Networks), in particular Long Short Term Memory (LSTM) networks (Hochreiter and Schmidhuber, 1997), for performing sequence prediction in NLP applications such as machine translation (Sutskever et al., 2014) and natural language generation (Wen et al., 2015), we try to exploit similar techniques f"
P16-1127,D14-1067,0,0.0510377,"ques. Reddy et al. (2014) exploits a weak supervision signal to learn a mapping between the logical form associated by a CCG based semantic parser with the input question and the appropriate logical form in Freebase (Bollacker et al., 2008). Paraphrase-based approaches (Fader et al., 2013; Berant and Liang, 2014) generate variants of the input question using a simple hand-written grammar and then rank these using a paraphrase model. That is, in their setting, the logical form assigned to the input question is that of the generated sentence which is most similar to the input question. Finally, Bordes et al. (2014b; 2014a) learn a similarity function between a natural language question and the knowledge base formula encoding its answer. We depart from these approaches in that we learn a direct mapping between natural language questions and their corresponding logical form or equivalently, their corresponding derivation and canonical form. This simple, very direct approach to semantic parsing eschews the need for complex feature engineering and large external resources required by such paraphrase-based approaches as (Fader et al., 2013; Berant and Liang, 2014). It is conceptually simpler than the two st"
P16-1127,P13-1158,0,0.012785,"gation. 5 Related Work and Discussion In recent work on developing semantic parsers for open-domain and domain-specific question answering, various methods have been proposed to handle the mismatch between natural language questions and knowledge base representations including, graph matching, paraphrasing and embeddings techniques. Reddy et al. (2014) exploits a weak supervision signal to learn a mapping between the logical form associated by a CCG based semantic parser with the input question and the appropriate logical form in Freebase (Bollacker et al., 2008). Paraphrase-based approaches (Fader et al., 2013; Berant and Liang, 2014) generate variants of the input question using a simple hand-written grammar and then rank these using a paraphrase model. That is, in their setting, the logical form assigned to the input question is that of the generated sentence which is most similar to the input question. Finally, Bordes et al. (2014b; 2014a) learn a similarity function between a natural language question and the knowledge base formula encoding its answer. We depart from these approaches in that we learn a direct mapping between natural language questions and their corresponding logical form or equ"
P16-1127,N13-1092,0,0.019418,"Missing"
P16-1127,P82-1020,0,0.855865,"Missing"
P16-1127,D13-1161,0,0.121238,"sting of derivation steps relative to the underlying grammar. We also show how grammatical constraints on the derivation sequence can easily be integrated inside the RNNbased sequential predictor. Our experiments show important improvements over previous results for the same dataset, and also demonstrate the advantage of incorporating the grammatical constraints. 1 Introduction Learning to map natural language utterances (NL) to logical forms (LF), a process known as semantic parsing, has received a lot of attention recently, in particular in the context of building QuestionAnswering systems (Kwiatkowski et al., 2013; Berant et al., 2013; Berant and Liang, 2014). In this paper, we focus on such a task where the NL question may be semantically complex, leading to a logical form query with a fair amount of compositionality, in a spirit close to (Pasupat and Liang, 2015). Given the recently shown effectiveness of RNNs (Recurrent Neural Networks), in particular Long Short Term Memory (LSTM) networks (Hochreiter and Schmidhuber, 1997), for performing sequence prediction in NLP applications such as machine translation (Sutskever et al., 2014) and natural language generation (Wen et al., 2015), we try to exploit"
P16-1127,P15-1142,0,0.0761773,"esults for the same dataset, and also demonstrate the advantage of incorporating the grammatical constraints. 1 Introduction Learning to map natural language utterances (NL) to logical forms (LF), a process known as semantic parsing, has received a lot of attention recently, in particular in the context of building QuestionAnswering systems (Kwiatkowski et al., 2013; Berant et al., 2013; Berant and Liang, 2014). In this paper, we focus on such a task where the NL question may be semantically complex, leading to a logical form query with a fair amount of compositionality, in a spirit close to (Pasupat and Liang, 2015). Given the recently shown effectiveness of RNNs (Recurrent Neural Networks), in particular Long Short Term Memory (LSTM) networks (Hochreiter and Schmidhuber, 1997), for performing sequence prediction in NLP applications such as machine translation (Sutskever et al., 2014) and natural language generation (Wen et al., 2015), we try to exploit similar techniques for our task. However we observe that, contrary to those applications which try to predict intrinsically sequential objects (texts), our task involves producing a structured object, namely a logical form that is tree-like by nature and"
P16-1127,Q14-1030,0,0.0438488,"al knowledge, DSP-CL = Derivation Sequence using a loss function constrained by grammatical knowledge. gives small probability to ungrammatical choices, a property not shared by DSP-CL. However, a more complete understanding of the difference will need more investigation. 5 Related Work and Discussion In recent work on developing semantic parsers for open-domain and domain-specific question answering, various methods have been proposed to handle the mismatch between natural language questions and knowledge base representations including, graph matching, paraphrasing and embeddings techniques. Reddy et al. (2014) exploits a weak supervision signal to learn a mapping between the logical form associated by a CCG based semantic parser with the input question and the appropriate logical form in Freebase (Bollacker et al., 2008). Paraphrase-based approaches (Fader et al., 2013; Berant and Liang, 2014) generate variants of the input question using a simple hand-written grammar and then rank these using a paraphrase model. That is, in their setting, the logical form assigned to the input question is that of the generated sentence which is most similar to the input question. Finally, Bordes et al. (2014b; 201"
P16-1127,P15-1129,0,0.0862307,"Missing"
P16-1127,D15-1199,0,0.00681658,"ng systems (Kwiatkowski et al., 2013; Berant et al., 2013; Berant and Liang, 2014). In this paper, we focus on such a task where the NL question may be semantically complex, leading to a logical form query with a fair amount of compositionality, in a spirit close to (Pasupat and Liang, 2015). Given the recently shown effectiveness of RNNs (Recurrent Neural Networks), in particular Long Short Term Memory (LSTM) networks (Hochreiter and Schmidhuber, 1997), for performing sequence prediction in NLP applications such as machine translation (Sutskever et al., 2014) and natural language generation (Wen et al., 2015), we try to exploit similar techniques for our task. However we observe that, contrary to those applications which try to predict intrinsically sequential objects (texts), our task involves producing a structured object, namely a logical form that is tree-like by nature and also has to respect certain a priori constraints in order to be interpretable against the knowledge base. In our case, building on the work “Building a Semantic Parser Overnight” (Wang et al., 2015), which we will refer to as SPO, the LFs are generated by a grammar which is known a priori, and it is this grammar that makes"
P16-1127,P16-1004,0,\N,Missing
P16-1127,P14-2105,0,\N,Missing
P16-1127,P14-1129,0,\N,Missing
P98-1057,P98-1077,0,0.0396063,"Missing"
S16-2019,D11-1142,0,0.182196,"nalyze the benefit of adding a regularizer favoring the embeddings of entities to be orthogonal to those of relations. The main motivation comes from the observation that modifying the embeddings using prior knowledge often helps performance. The experiments show that incorporating the regularizer yields better results on a challenging question answering benchmark. 1 Introduction Having a system which is able to answer questions based on a structured knowledge base is a challenging problem. The problem has been addressed recently by researchers working on large knowledge bases such as Reverb (Fader et al., 2011) and Freebase (Bollacker et al., 2008). The creation of question answering (QA) benchmarks for these knowledge bases (KB) has a significant impact on the domain, as shown by the number of QA systems recently proposed in the literature (Berant and Liang, 2014; Berant et al., 2013; Bordes et al., 2014a; Bordes et al., 2014b; Fader et al., 2013; Fader et al., 2014; Yao and Van Durme, 2014; Yih et al., 2014; Dong et al., 2015). We identify two types of approaches for KBcentric QA systems: parsing-based approaches and information retrieval (IR) based approaches. Parsing-based approaches (Yih et al."
S16-2019,P13-1158,0,0.353924,"y, France 1 chunyang.xiao, marc.dymetman@xerox.com 2 g.bouchard@cs.ucl.ac.uk 3 claire.gardent@loria.fr Abstract called logical form. This logical form is then used to query the knowledge base and retrieve the answer. IR-based approaches try to identify the best possible match between the knowledge base and the question (Bordes et al., 2014a; Bordes et al., 2014b; Yao and Van Durme, 2014; Dong et al., 2015). In this work, we focus on the second approach, using embedding models, mainly because it is robust to invalid syntax and can exploit information of the answer. We focus on the Wikianswers (Fader et al., 2013) dataset constructed for Reverb. On Wikianswers, the underlying semantics is very simple (just one single triple). However, the task remains challenging due to the large variety of lexicalizations for the same semantics. We follow the approach of Bordes et .al (2014b) which learns the embeddings of words and KB elements. They model the semantics of natural language sentences and KB triples as the sum of the embeddings of the associated words and KB elements respectively. Despite its simplicity, this model performs surprisingly well in practice. Something even more interesting (Bordes et al., 2"
S16-2019,P14-1133,0,0.0138794,"nts show that incorporating the regularizer yields better results on a challenging question answering benchmark. 1 Introduction Having a system which is able to answer questions based on a structured knowledge base is a challenging problem. The problem has been addressed recently by researchers working on large knowledge bases such as Reverb (Fader et al., 2011) and Freebase (Bollacker et al., 2008). The creation of question answering (QA) benchmarks for these knowledge bases (KB) has a significant impact on the domain, as shown by the number of QA systems recently proposed in the literature (Berant and Liang, 2014; Berant et al., 2013; Bordes et al., 2014a; Bordes et al., 2014b; Fader et al., 2013; Fader et al., 2014; Yao and Van Durme, 2014; Yih et al., 2014; Dong et al., 2015). We identify two types of approaches for KBcentric QA systems: parsing-based approaches and information retrieval (IR) based approaches. Parsing-based approaches (Yih et al., 2014; Berant et al., 2013; Berant and Liang, 2014; Reddy et al., 2014) answer factoid questions by learning a structured representation for the sentences, 142 Proceedings of the Fifth Joint Conference on Lexical and Computational Semantics (*SEM 2016), pag"
S16-2019,D13-1160,0,0.0126868,"ing the regularizer yields better results on a challenging question answering benchmark. 1 Introduction Having a system which is able to answer questions based on a structured knowledge base is a challenging problem. The problem has been addressed recently by researchers working on large knowledge bases such as Reverb (Fader et al., 2011) and Freebase (Bollacker et al., 2008). The creation of question answering (QA) benchmarks for these knowledge bases (KB) has a significant impact on the domain, as shown by the number of QA systems recently proposed in the literature (Berant and Liang, 2014; Berant et al., 2013; Bordes et al., 2014a; Bordes et al., 2014b; Fader et al., 2013; Fader et al., 2014; Yao and Van Durme, 2014; Yih et al., 2014; Dong et al., 2015). We identify two types of approaches for KBcentric QA systems: parsing-based approaches and information retrieval (IR) based approaches. Parsing-based approaches (Yih et al., 2014; Berant et al., 2013; Berant and Liang, 2014; Reddy et al., 2014) answer factoid questions by learning a structured representation for the sentences, 142 Proceedings of the Fifth Joint Conference on Lexical and Computational Semantics (*SEM 2016), pages 142–147, Berlin, G"
S16-2019,D14-1067,0,0.123779,"er et al., 2013) dataset constructed for Reverb. On Wikianswers, the underlying semantics is very simple (just one single triple). However, the task remains challenging due to the large variety of lexicalizations for the same semantics. We follow the approach of Bordes et .al (2014b) which learns the embeddings of words and KB elements. They model the semantics of natural language sentences and KB triples as the sum of the embeddings of the associated words and KB elements respectively. Despite its simplicity, this model performs surprisingly well in practice. Something even more interesting (Bordes et al., 2014b) is that the system can have a good performance even without using a paraphrase corpus. This makes the system very attractive in practice because in many specific domains, we might have a KB but there may be no paraphrase corpus as in Wikianswers. In our work, we push the results further when learning a QA system based only on the KB. Our contribution is to introduce a new orthogonality regularizer which distinguishes entities and relations. We also investigate the tradeoff captured by the orthogonality constraints. With a synthetic example, we show that if entities and relations are indepen"
S16-2019,Q14-1030,0,0.0139472,"of question answering (QA) benchmarks for these knowledge bases (KB) has a significant impact on the domain, as shown by the number of QA systems recently proposed in the literature (Berant and Liang, 2014; Berant et al., 2013; Bordes et al., 2014a; Bordes et al., 2014b; Fader et al., 2013; Fader et al., 2014; Yao and Van Durme, 2014; Yih et al., 2014; Dong et al., 2015). We identify two types of approaches for KBcentric QA systems: parsing-based approaches and information retrieval (IR) based approaches. Parsing-based approaches (Yih et al., 2014; Berant et al., 2013; Berant and Liang, 2014; Reddy et al., 2014) answer factoid questions by learning a structured representation for the sentences, 142 Proceedings of the Fifth Joint Conference on Lexical and Computational Semantics (*SEM 2016), pages 142–147, Berlin, Germany, August 11-12, 2016. most no linguistic features such as POS tagging, parsing, etc. 2 The idea of distinguishing entities and relations in question answering can also be found in (Yih et al., 2014). However, they base their work by supposing that we can cut the sentence into “entity part” and “relation part” and then calculate the matching score. Our model does not need this cut and"
S16-2019,P15-1026,0,0.0879141,"er for question answering Chunyang Xiao1 , Guillaume Bouchard2 , Marc Dymetman1 ,Claire Gardent3 1 Xerox Research Centre Europe, Grenoble, France 2 University College London, United Kingdom 3 CNRS, LORIA, Nancy, France 1 chunyang.xiao, marc.dymetman@xerox.com 2 g.bouchard@cs.ucl.ac.uk 3 claire.gardent@loria.fr Abstract called logical form. This logical form is then used to query the knowledge base and retrieve the answer. IR-based approaches try to identify the best possible match between the knowledge base and the question (Bordes et al., 2014a; Bordes et al., 2014b; Yao and Van Durme, 2014; Dong et al., 2015). In this work, we focus on the second approach, using embedding models, mainly because it is robust to invalid syntax and can exploit information of the answer. We focus on the Wikianswers (Fader et al., 2013) dataset constructed for Reverb. On Wikianswers, the underlying semantics is very simple (just one single triple). However, the task remains challenging due to the large variety of lexicalizations for the same semantics. We follow the approach of Bordes et .al (2014b) which learns the embeddings of words and KB elements. They model the semantics of natural language sentences and KB tripl"
S16-2019,P14-2105,0,0.0156772,"ble to answer questions based on a structured knowledge base is a challenging problem. The problem has been addressed recently by researchers working on large knowledge bases such as Reverb (Fader et al., 2011) and Freebase (Bollacker et al., 2008). The creation of question answering (QA) benchmarks for these knowledge bases (KB) has a significant impact on the domain, as shown by the number of QA systems recently proposed in the literature (Berant and Liang, 2014; Berant et al., 2013; Bordes et al., 2014a; Bordes et al., 2014b; Fader et al., 2013; Fader et al., 2014; Yao and Van Durme, 2014; Yih et al., 2014; Dong et al., 2015). We identify two types of approaches for KBcentric QA systems: parsing-based approaches and information retrieval (IR) based approaches. Parsing-based approaches (Yih et al., 2014; Berant et al., 2013; Berant and Liang, 2014; Reddy et al., 2014) answer factoid questions by learning a structured representation for the sentences, 142 Proceedings of the Fifth Joint Conference on Lexical and Computational Semantics (*SEM 2016), pages 142–147, Berlin, Germany, August 11-12, 2016. most no linguistic features such as POS tagging, parsing, etc. 2 The idea of distinguishing entitie"
S16-2019,P14-1090,0,\N,Missing
specia-etal-2010-dataset,quirk-2004-training,0,\N,Missing
specia-etal-2010-dataset,W08-0332,0,\N,Missing
specia-etal-2010-dataset,P02-1040,0,\N,Missing
specia-etal-2010-dataset,W09-0401,0,\N,Missing
specia-etal-2010-dataset,H05-1095,1,\N,Missing
specia-etal-2010-dataset,W06-3118,0,\N,Missing
specia-etal-2010-dataset,D09-1107,0,\N,Missing
specia-etal-2010-dataset,2009.eamt-smart.4,0,\N,Missing
specia-etal-2010-dataset,W07-0734,0,\N,Missing
specia-etal-2010-dataset,C04-1072,0,\N,Missing
specia-etal-2010-dataset,C04-1046,0,\N,Missing
specia-etal-2010-dataset,W07-0718,0,\N,Missing
specia-etal-2010-dataset,2009.eamt-1.5,1,\N,Missing
specia-etal-2010-dataset,W08-0309,0,\N,Missing
specia-etal-2010-dataset,2005.mtsummit-papers.11,0,\N,Missing
specia-etal-2010-dataset,W04-3250,0,\N,Missing
W00-1404,C96-1043,0,0.129913,"tures: and that author choices be all under the explicit conFirst, the authoring process is monolingual, but trol of the DTD and reflected in the document structhe results are multilingual. At each point of the proture. Such a view, which is argued for in a related cess the author can view in his/her own language the paper (Dymetman et el., 2000), emphasizes the link between ~ML`d~cumeqt~a~a9ring`~aad;mu~ti~nguaL;~,~.~te~t:~s/h~hasa~u~h~rex~:~.~aa~a~d~rea~Èwhere~he ..: text authoring/generation (Power and Scott, 1998; text still needs refinement are highlighted. Menus Hartley and Paris, 1997; Coch, 1996): the choices for selecting a refinement are also presented to the made by the author are treated as a kind of inauthor is his/her own language. Thus, the author is terlingua (specific to the class of documents being always overtly working in the language s/he nows, modelled), and it is the responsibility of appropribut is implicitly building a language-independent ate ""rendering"" mechanisms to produce actual text representation of the document content. From this from these choices ill tile different languages 3 under representation, the system builds multilingual texts consideration, in any o"
W00-1404,C00-1036,1,0.412979,"Missing"
W00-1404,P98-2173,0,0.159268,"ent Authoring system has be altogether eliminated from the document content, the following main features: and that author choices be all under the explicit conFirst, the authoring process is monolingual, but trol of the DTD and reflected in the document structhe results are multilingual. At each point of the proture. Such a view, which is argued for in a related cess the author can view in his/her own language the paper (Dymetman et el., 2000), emphasizes the link between ~ML`d~cumeqt~a~a9ring`~aad;mu~ti~nguaL;~,~.~te~t:~s/h~hasa~u~h~rex~:~.~aa~a~d~rea~Èwhere~he ..: text authoring/generation (Power and Scott, 1998; text still needs refinement are highlighted. Menus Hartley and Paris, 1997; Coch, 1996): the choices for selecting a refinement are also presented to the made by the author are treated as a kind of inauthor is his/her own language. Thus, the author is terlingua (specific to the class of documents being always overtly working in the language s/he nows, modelled), and it is the responsibility of appropribut is implicitly building a language-independent ate ""rendering"" mechanisms to produce actual text representation of the document content. From this from these choices ill tile different langu"
W00-1404,C98-2168,0,\N,Missing
W08-0323,P04-1007,0,0.0355754,"Parser XIP (A¨ıt-Mokhtar et al., 2002), which is a robust dependency parser developed at the Xerox Research Centre Europe. XIP is fast (around 2000 words per second for English) and is well adapted to a situation, like the one we have here, were we need to Decoding and Training We resort to a standard reranking approach in which we produce an n-best list of MATRAX candidate translations (with n = 100 in our experiments), and then rerank this list with a linear combination of our parse-dependent features. In order to train the feature weights, we use an averaged structured perceptron approach (Roark et al., 2004), where we try to learn weights such that the first candidate to emerge is equal to the “oracle” candidate, that is, the candidate that is closest to the reference in terms of NIST score. 1.2 Coupling Features Our general approach to computing coupling features between the dependency structure of the source and that of a candidate translation produced by MATRAX is the following: we start by aligning the words between the source and the candidate translation, we parse both sides, and we count (possibly according to a weighting scheme) the number of configurations (“rectangles”) that are of the"
W08-0323,H05-1095,1,\N,Missing
W08-0407,J07-2003,0,0.234907,"08. 2008 Association for Computational Linguistics ing the n-best candidates of a baseline phrase-based system. The hope is that by doing so, we will increase the adequacy of translations, and possibly to some extent, their fluency (at least their “semantic” fluency, which is influenced by their adequacy, as opposed to their “grammatical” fluency, which would be better addressed by target-specific syntactic features than by coupling syntactic features). 1.2 Related Work There is a growing body of work on the use of syntax for improving statistical machine translation, from approaches such as (Chiang, 2007) that use “formal syntax”, that is syntactic structures for the source and target that are discovered on the basis of a bilingual corpus, but without resort to an externally motivated parser, to approaches such as (Yamada and Knight, 2001) and (Marcu et al., 2006) that use an external parser on the target only, or such as (Quirk et al., 2005) on the source only, or such as (Cowan et al., 2006) that use external parsers both on the source and on the target. Our approach is in this last category, but is distinguished from all the cited approaches by the fact that it does not try to build a targe"
W08-0407,W06-1628,0,0.0218937,"t-specific syntactic features than by coupling syntactic features). 1.2 Related Work There is a growing body of work on the use of syntax for improving statistical machine translation, from approaches such as (Chiang, 2007) that use “formal syntax”, that is syntactic structures for the source and target that are discovered on the basis of a bilingual corpus, but without resort to an externally motivated parser, to approaches such as (Yamada and Knight, 2001) and (Marcu et al., 2006) that use an external parser on the target only, or such as (Quirk et al., 2005) on the source only, or such as (Cowan et al., 2006) that use external parsers both on the source and on the target. Our approach is in this last category, but is distinguished from all the cited approaches by the fact that it does not try to build a target structure (or string) directly, but rather by using a baseline phrase-based system as a generator of candidates, and then selecting between these candidates through a discriminative procedure. Some other researchers have taken a similar line, for example (Hasan et al., 2006), which only uses a parser on the target, and attempts to improve the fluency of the translation produced, and especial"
W08-0407,W06-2606,0,0.0300785,"2006) that use an external parser on the target only, or such as (Quirk et al., 2005) on the source only, or such as (Cowan et al., 2006) that use external parsers both on the source and on the target. Our approach is in this last category, but is distinguished from all the cited approaches by the fact that it does not try to build a target structure (or string) directly, but rather by using a baseline phrase-based system as a generator of candidates, and then selecting between these candidates through a discriminative procedure. Some other researchers have taken a similar line, for example (Hasan et al., 2006), which only uses a parser on the target, and attempts to improve the fluency of the translation produced, and especially (Och et al., 2003) that reports experiments using a large number of syntactic features. In one of the experiments briefly reported, a dependency parser is used both for the source and for the target and a few features are introduced for counting the number of edges that project from the source to the target. This experiment, which as far as we know was not followed up by deeper investigations, is very similar to what we do. However we introduce and compare results for a wid"
W08-0407,2007.tmi-papers.13,0,0.0803631,"Missing"
W08-0407,W06-1606,0,0.0275748,"fluency, which is influenced by their adequacy, as opposed to their “grammatical” fluency, which would be better addressed by target-specific syntactic features than by coupling syntactic features). 1.2 Related Work There is a growing body of work on the use of syntax for improving statistical machine translation, from approaches such as (Chiang, 2007) that use “formal syntax”, that is syntactic structures for the source and target that are discovered on the basis of a bilingual corpus, but without resort to an externally motivated parser, to approaches such as (Yamada and Knight, 2001) and (Marcu et al., 2006) that use an external parser on the target only, or such as (Quirk et al., 2005) on the source only, or such as (Cowan et al., 2006) that use external parsers both on the source and on the target. Our approach is in this last category, but is distinguished from all the cited approaches by the fact that it does not try to build a target structure (or string) directly, but rather by using a baseline phrase-based system as a generator of candidates, and then selecting between these candidates through a discriminative procedure. Some other researchers have taken a similar line, for example (Hasan"
W08-0407,P05-1034,0,0.0385725,"l” fluency, which would be better addressed by target-specific syntactic features than by coupling syntactic features). 1.2 Related Work There is a growing body of work on the use of syntax for improving statistical machine translation, from approaches such as (Chiang, 2007) that use “formal syntax”, that is syntactic structures for the source and target that are discovered on the basis of a bilingual corpus, but without resort to an externally motivated parser, to approaches such as (Yamada and Knight, 2001) and (Marcu et al., 2006) that use an external parser on the target only, or such as (Quirk et al., 2005) on the source only, or such as (Cowan et al., 2006) that use external parsers both on the source and on the target. Our approach is in this last category, but is distinguished from all the cited approaches by the fact that it does not try to build a target structure (or string) directly, but rather by using a baseline phrase-based system as a generator of candidates, and then selecting between these candidates through a discriminative procedure. Some other researchers have taken a similar line, for example (Hasan et al., 2006), which only uses a parser on the target, and attempts to improve t"
W08-0407,P01-1067,0,0.0259732,"ncy (at least their “semantic” fluency, which is influenced by their adequacy, as opposed to their “grammatical” fluency, which would be better addressed by target-specific syntactic features than by coupling syntactic features). 1.2 Related Work There is a growing body of work on the use of syntax for improving statistical machine translation, from approaches such as (Chiang, 2007) that use “formal syntax”, that is syntactic structures for the source and target that are discovered on the basis of a bilingual corpus, but without resort to an externally motivated parser, to approaches such as (Yamada and Knight, 2001) and (Marcu et al., 2006) that use an external parser on the target only, or such as (Quirk et al., 2005) on the source only, or such as (Cowan et al., 2006) that use external parsers both on the source and on the target. Our approach is in this last category, but is distinguished from all the cited approaches by the fact that it does not try to build a target structure (or string) directly, but rather by using a baseline phrase-based system as a generator of candidates, and then selecting between these candidates through a discriminative procedure. Some other researchers have taken a similar"
W08-0407,H05-1095,1,\N,Missing
W10-3801,D08-1023,0,0.0172271,"we provide a self-contained description of an algorithm for performing this intersection, in the general weighted case, and where x is generalized to an arbitrary source automaton. Second, we extend this algorithm to σ-automata. The resulting weighted synchronous grammar represents, as in Hiero, the “parse forest” (or “hypergraph”) of all weighted derivations (that is of all translations) that can be built over x, but where the weights incorporate knowledge of the phrase-based component; it can therefore form the basis of a variety of dynamic programming or sampling algorithms (Chiang, 2007; Blunsom and Osborne, 2008), as is the case with standard Hiero-type representations. While in the worst case the intersected grammar can contain an exponential number of nonterminals, we argue that such combinatorial explosion will not happen in practice, and we also briefly indicate formal conditions under which it will not be allowed to happen. 2 Intersecting weighted synchronous CFG’s with weighted automata We assume that the notions of weighted finitestate automaton [W-FSA] and weighted synchronous grammar [W-SCFG] are known (for short descriptions see (Mohri et al., 1996) and (Chiang, 2006)), and we consider: 1. A"
W10-3801,J07-2003,0,0.698453,"y to the underlying intuitions behind the intersection, namely that the hierarchical model should be mainly responsible for controlling re-ordering, and the phrase-based model mainly responsible for lexical choice. Second, the transducer resulting from the operation could be large. Third, even if we could represent the phrase-based model through a finite-state transducer, intersecting this transducer with the synchronous CFG would actually be intractable in the general case, as we indicate later. Introduction Phrase-based (Och and Ney, 2004; Koehn et al., 2007) and Hierarchical (Hiero-style) (Chiang, 2007) models are two mainstream approaches for building Statistical Machine Translation systems, with different characteristics. While phrase-based systems allow a direct capture of correspondences between surface-level lexical patterns, but at the cost of a simplistic handling of re-ordering, hierarchical systems are better able to constrain re-ordering, especially for distant language pairs, but tend to produce sparser rules and often lag behind phrase-based systems for less distant language pairs. It might therefore make sense to capitalize on the complementary advantages of the two approaches b"
W10-3801,H05-1021,0,0.0339806,"ting a Hiero-style hierarchical system with a phrase-based system and present formal techniques for doing so. We model the phrase-based component by introducing a variant of weighted finite-state automata, called σ-automata, provide a self-contained description of a general algorithm for intersecting weighted synchronous context-free grammars with finite-state automata, and extend these constructs to σ-automata. We end by briefly discussing complexity properties of the presented algorithms. 1 One might try to address this issue by limiting a priori the amount of re-ordering, in the spirit of (Kumar and Byrne, 2005), which would allow to approximate a phrase-based model by a standard transducer, but this would introduce further issues. First, limiting the amount of reordering in the phrase-based model runs contrary to the underlying intuitions behind the intersection, namely that the hierarchical model should be mainly responsible for controlling re-ordering, and the phrase-based model mainly responsible for lexical choice. Second, the transducer resulting from the operation could be large. Third, even if we could represent the phrase-based model through a finite-state transducer, intersecting this trans"
W10-3801,J04-4002,0,0.0268639,"imiting the amount of reordering in the phrase-based model runs contrary to the underlying intuitions behind the intersection, namely that the hierarchical model should be mainly responsible for controlling re-ordering, and the phrase-based model mainly responsible for lexical choice. Second, the transducer resulting from the operation could be large. Third, even if we could represent the phrase-based model through a finite-state transducer, intersecting this transducer with the synchronous CFG would actually be intractable in the general case, as we indicate later. Introduction Phrase-based (Och and Ney, 2004; Koehn et al., 2007) and Hierarchical (Hiero-style) (Chiang, 2007) models are two mainstream approaches for building Statistical Machine Translation systems, with different characteristics. While phrase-based systems allow a direct capture of correspondences between surface-level lexical patterns, but at the cost of a simplistic handling of re-ordering, hierarchical systems are better able to constrain re-ordering, especially for distant language pairs, but tend to produce sparser rules and often lag behind phrase-based systems for less distant language pairs. It might therefore make sense to"
W10-3801,H05-1101,0,0.0326175,"he automata, but also by arbitrary subsets of source tokens, and this may lead in extreme cases to an exponential number of rules. Such problems however can only happen in sit0 uations where, in a nonterminal tsXst0 ,σ , the set σ is allowed to contain tokens that are “unrelated” to the token set {personnes} appearing between s and s0 in the source automaton. An illustration of such a situation is given by the following example. Suppose that the source sen13 If this condition is removed, and for the simpler case where the source (resp. target) automaton encodes a single sentence x (resp. y), (Satta and Peserico, 2005) have shown that the problem of deciding whether (x, y) is recognized by G is NP-hard relative to the sum of the sizes. A consequence is then that the grammar G0 cannot be constructed in polynomial time unless P = N P . tence contains the two tokens personnes and gens between positions i, i + 1 and j, j + 1 respectively, with i and j far from each other, that the phrase table contains the two phrase pairs (personnes, persons) and (gens, people), but that the synchronous grammar only contains the two rules X → personnes/people and Y → gens/persons, with these phrases and rules exhausting the po"
W10-3801,P07-2045,0,\N,Missing
W12-5701,W10-4006,0,\N,Missing
W12-5701,P02-1040,0,\N,Missing
W12-5701,P07-2045,0,\N,Missing
W12-5701,W10-3707,0,\N,Missing
W12-5701,E12-2006,0,\N,Missing
W12-5701,P08-1000,0,\N,Missing
W12-6106,D12-1103,1,0.603457,"presence of non-local features. • PCFG’s with transversal constraints, probabilistic unification grammars. We will not explore all of these situations here, but will concentrate on (i) decoding and sampling with high-order HMM’s, for which we provide details and experimental results, and (ii) combining a PCFG with a complex finite-state language model, which we only describe at a high-level. We hope these two illustrations will suffice to give a feeling of the power of the technique. 3.1 High-Order HMMs Note: An extended and much more detailed version of these HMM experiments is provided in [Carter et al., 2012]. The objective in our HMM experiments is to sample a word sequence with density ¯p(x) proportional to p(x) = plm (x) pobs (o|x), where plm is the probability of the sequence x under an n-gram model and pobs (o|x) is the probability of observing the noisy sequence of observations o given that the word sequence is x. Assuming that the observations depend only on the current state, this probability can be written: p(x) = ` Y i=1 i−1 plm (x i |x i−n+1 ) pobs (oi |x i ) . (1) Approach Taking a tri-gram language model for simplicity, let us define w3 (x i |x i−2 x i−1 ) = plm (x i |x i−2 x i−1 ) p"
W12-6106,D11-1003,0,0.116785,"full underlying state space. 3.2 OS∗ for intersecting PCFG’s with high-order LM’s We now move to a high-level description of the application of OS∗ to an important class of problems (including hierarchical SMT) which involve the intersection of PCFG’s with high-order language models. The study of similar “agreement-based” problems involving optimization (but not sampling) over a combination of two individual tasks have recently been the focus of a lot of attention in the NLP community, in particular with the application of dual decomposition methods [Rush et al., 2010, Rush and Collins, 2011, Chang and Collins, 2011]. We only sketch the main ideas of our approach. A standard result of formal language theory is that the intersection of a CFG with a FSA is a CFG [Bar-Hillel et al., 1961]. This construct can be generalized to the intersection of a Weighted CFG (WCFG) with a WFSA (see e.g. [Nederhof and Satta, 2003]), resulting in a WCFG. In our case, we will be interested in optimizing and sampling from the intersection p of a PCFG6 G with a complex WFSA A representing a high-order language model. For illustration purposes here, we will suppose that A is a trigram language model, but the description can be"
W12-6106,P12-1064,0,0.0141743,"text the two interesting, but apparently little known, papers [Kam and Kopec, 1996, Popat et al., 2000], discuss a technique for decoding images based on high-order language models where upper-bounds are constructed in terms of simpler variable-order models. Our application of OS∗ in section 3.1 to the problem of maximizing a high-order HMM is similar to their (also exact) technique; while this work seems to be the closest to ours, the authors do not attempt to generalize their approach to other optimization problems amenable to dynamic programming. Among NLP applications, [Kaji et al., 2010, Huang et al., 2012] are another recent approach to exact optimization for sequence labelling that also has connections to our experiments in section 3.1, but differs in particular by using a less flexible refinement scheme than our variable-order n-grams. In the NLP community again, there is currently a lot of interest for optimization methods that fall in the general category of “coarse-to-fine&quot; techniques [Petrov, 2009], which tries to guide the inference process towards promising regions that get incrementally tighter and tighter. While most of this line of research concentrates on approximate optimization,"
W12-6106,P10-1050,0,0.0183839,"ic optimization context the two interesting, but apparently little known, papers [Kam and Kopec, 1996, Popat et al., 2000], discuss a technique for decoding images based on high-order language models where upper-bounds are constructed in terms of simpler variable-order models. Our application of OS∗ in section 3.1 to the problem of maximizing a high-order HMM is similar to their (also exact) technique; while this work seems to be the closest to ours, the authors do not attempt to generalize their approach to other optimization problems amenable to dynamic programming. Among NLP applications, [Kaji et al., 2010, Huang et al., 2012] are another recent approach to exact optimization for sequence labelling that also has connections to our experiments in section 3.1, but differs in particular by using a less flexible refinement scheme than our variable-order n-grams. In the NLP community again, there is currently a lot of interest for optimization methods that fall in the general category of “coarse-to-fine&quot; techniques [Petrov, 2009], which tries to guide the inference process towards promising regions that get incrementally tighter and tighter. While most of this line of research concentrates on approx"
W12-6106,2005.mtsummit-papers.11,0,0.0603769,"Missing"
W12-6106,W03-3016,0,0.0223748,"milar “agreement-based” problems involving optimization (but not sampling) over a combination of two individual tasks have recently been the focus of a lot of attention in the NLP community, in particular with the application of dual decomposition methods [Rush et al., 2010, Rush and Collins, 2011, Chang and Collins, 2011]. We only sketch the main ideas of our approach. A standard result of formal language theory is that the intersection of a CFG with a FSA is a CFG [Bar-Hillel et al., 1961]. This construct can be generalized to the intersection of a Weighted CFG (WCFG) with a WFSA (see e.g. [Nederhof and Satta, 2003]), resulting in a WCFG. In our case, we will be interested in optimizing and sampling from the intersection p of a PCFG6 G with a complex WFSA A representing a high-order language model. For illustration purposes here, we will suppose that A is a trigram language model, but the description can be easily transposed to higher-order cases. Let us denote by x a derivation in G, and by y = y(x) the string of terminal leaves associated with x (the “yield” of the derivation x). The weighted intersection p of G and A is defined as: p(x) ≡ G(x).A(x), where A(x) is a shorthand for A( y(x)). Due to the"
W12-6106,W06-1616,0,0.0309721,"for optimization methods that fall in the general category of “coarse-to-fine&quot; techniques [Petrov, 2009], which tries to guide the inference process towards promising regions that get incrementally tighter and tighter. While most of this line of research concentrates on approximate optimization, some related approaches aim at finding an exact optimum. Thus, [Tromble and Eisner, 2006] attempt to maximize a certain objective while respecting complex hard constraints, which they do by incrementally adding those constraints that are violated by the current optimum, using finite-state techniques. [Riedel and Clarke, 2006] have a similar goal, but address it by incrementally adding ILP (Integer Linear Programming) constraints. Linear Programming techniques are also involved in the recent applications of Dual Decomposition to NLP [Rush et al., 2010, Rush and Collins, 2011], which can be applied to difficult combinations of easy problems, and often are able to find an exact optimum. None of these optimization papers, to our knowledge, attempts to extend these techniques to sampling, in contrast to what we do. Paper organization The remainder of this paper is structured as follows. In section 2, we describe the O"
W12-6106,P11-1008,0,0.441711,"concentrates on approximate optimization, some related approaches aim at finding an exact optimum. Thus, [Tromble and Eisner, 2006] attempt to maximize a certain objective while respecting complex hard constraints, which they do by incrementally adding those constraints that are violated by the current optimum, using finite-state techniques. [Riedel and Clarke, 2006] have a similar goal, but address it by incrementally adding ILP (Integer Linear Programming) constraints. Linear Programming techniques are also involved in the recent applications of Dual Decomposition to NLP [Rush et al., 2010, Rush and Collins, 2011], which can be applied to difficult combinations of easy problems, and often are able to find an exact optimum. None of these optimization papers, to our knowledge, attempts to extend these techniques to sampling, in contrast to what we do. Paper organization The remainder of this paper is structured as follows. In section 2, we describe the OS∗ algorithm, explain how it can be used for exact optimization and sampling, and show its connection to A∗ . In section 3, we first describe several NLP applications of the algorithm, then give more details on two such applications. The first one is an"
W12-6106,D10-1001,0,0.123415,"s line of research concentrates on approximate optimization, some related approaches aim at finding an exact optimum. Thus, [Tromble and Eisner, 2006] attempt to maximize a certain objective while respecting complex hard constraints, which they do by incrementally adding those constraints that are violated by the current optimum, using finite-state techniques. [Riedel and Clarke, 2006] have a similar goal, but address it by incrementally adding ILP (Integer Linear Programming) constraints. Linear Programming techniques are also involved in the recent applications of Dual Decomposition to NLP [Rush et al., 2010, Rush and Collins, 2011], which can be applied to difficult combinations of easy problems, and often are able to find an exact optimum. None of these optimization papers, to our knowledge, attempts to extend these techniques to sampling, in contrast to what we do. Paper organization The remainder of this paper is structured as follows. In section 2, we describe the OS∗ algorithm, explain how it can be used for exact optimization and sampling, and show its connection to A∗ . In section 3, we first describe several NLP applications of the algorithm, then give more details on two such applicatio"
W12-6106,N06-1054,0,0.0252718,"labelling that also has connections to our experiments in section 3.1, but differs in particular by using a less flexible refinement scheme than our variable-order n-grams. In the NLP community again, there is currently a lot of interest for optimization methods that fall in the general category of “coarse-to-fine&quot; techniques [Petrov, 2009], which tries to guide the inference process towards promising regions that get incrementally tighter and tighter. While most of this line of research concentrates on approximate optimization, some related approaches aim at finding an exact optimum. Thus, [Tromble and Eisner, 2006] attempt to maximize a certain objective while respecting complex hard constraints, which they do by incrementally adding those constraints that are violated by the current optimum, using finite-state techniques. [Riedel and Clarke, 2006] have a similar goal, but address it by incrementally adding ILP (Integer Linear Programming) constraints. Linear Programming techniques are also involved in the recent applications of Dual Decomposition to NLP [Rush et al., 2010, Rush and Collins, 2011], which can be applied to difficult combinations of easy problems, and often are able to find an exact opti"
W13-1804,N06-1045,0,0.0333541,"ses over the “max-times” 1 semiring (R∞ + , max, ·, 0, 1), they often — rather counter-intuitively — lead to combinatorial explosion when working in the sum-times semiring, even in cases where the automaton is acyclic and where the classical (unweighted) determinization of A does not explode (Buchsbaum et al., 1998).2 While the applications of determinization cited in (Mohri, 2009) to such domains as speech recognition tend to focus on the max-times semiring, we are aware of one application where determinization is based on the sum-times semiring, but in a slightly different formal situation (May and Knight, 2006). In this paper, the authors generalize the determinization technique of (Mohri, 1997) from string to tree automata, and then address the question of determinizing a weighted tree 1 This semiring is isomorphic to the more common “tropical” semiring, through a logarithmic mapping. 2 A simple example of a cyclic automaton over the sumtimes semiring which is not determinizable at all is given in (Aminof et al., 2011). Proceedings of the 11th International Conference on Finite State Methods and Natural Language Processing, pages 25–29, c St Andrews–Sctotland, July 15–17, 2013. 2013 Association for"
W13-1804,J97-2003,0,0.350133,"es” semiring Ks ≡ (R∞ + , +, ·, 0, 1), involving a generalization of the Viterbi procedure. A naive approach to the max-string problem would consist in enumerating all the paths, summing the weights of paths corresponding to the same string, and outputting the maximum string. Another, more appealing, approach consists in noting that in the case of a deterministic weighted automaton A0 , the max-string and maxpath problems coincide, and therefore in trying to determinize A, and then apply the standard Viterbi algorithm. However, while existing techniques for determinizing a weighted automaton (Mohri, 1997; Mohri, 2009) work reasonably well in some practical cases over the “max-times” 1 semiring (R∞ + , max, ·, 0, 1), they often — rather counter-intuitively — lead to combinatorial explosion when working in the sum-times semiring, even in cases where the automaton is acyclic and where the classical (unweighted) determinization of A does not explode (Buchsbaum et al., 1998).2 While the applications of determinization cited in (Mohri, 2009) to such domains as speech recognition tend to focus on the max-times semiring, we are aware of one application where determinization is based on the sum-times"
W13-1804,P07-2045,0,\N,Missing
W13-2260,W09-1114,0,0.0804647,"case for minimum error rate training (Och, 2003; Watanabe et al., 2007), minimum risk training (Smith and Eisner, 2006) and minimum risk decoding (Kumar and Byrne, 2004). Due to the additional computational challenges posed by sampling, n-best lists, a by-product of optimisation, are typically used as approximation to true probabilistic samples. A known issue with n-best lists is that they tend to be clustered around only one mode of the distribution. A more direct procedure is to attempt to directly draw samples from the underlying distribution rather than rely on n-best list approximations (Arun et al., 2009; Blunsom and Osborne, 2008). We present a method for inference in hierarchical phrase-based translation, where both optimisation and sampling are performed in a common exact inference framework related to adaptive rejection sampling. We also present a first implementation of that method along with experimental results shedding light on some fundamental issues. In hierarchical translation, inference needs to be performed over a high-complexity distribution defined by the intersection of a translation hypergraph and a target language model. We replace this intractable distribution by a sequence"
W13-2260,P89-1018,0,0.248527,"list of promising candidates. This is an approximation technique, related to beam-search, which performs well in practice, but is not guaranteed to find the actual optimum. In the approach presented here — described in detail in §3 — we do not prune the search space. While we do construct the full initial grammar G(f ), we proceed by incrementally intersecting it with simple automata associated with upperbounds of A, for which the intersection is tractable. 2.3 Earley Intersection In their classical paper Bar-Hillel et al. (1961) showed that the intersection of a CFG with a FSA is a CFG, and Billot and Lang (1989) were possibly the first to notice the connection of this construct with chart-parsing. In general, parsing with a CFG can be seen as a special case of intersection, with the input sequence represented as a “flat” (linear chain) automaton, and this insight allows to generalise various parsing algorithms to corresponding intersection algorithms. One such algorithm, for weighted context-free grammars and automata, inspired by the CKY parsing algorithm, is presented in Nederhof and Satta (2008). The algorithm that we are using is different; it is inspired by Earley parsing, and was introduced in"
W13-2260,D08-1023,0,0.114699,"ror rate training (Och, 2003; Watanabe et al., 2007), minimum risk training (Smith and Eisner, 2006) and minimum risk decoding (Kumar and Byrne, 2004). Due to the additional computational challenges posed by sampling, n-best lists, a by-product of optimisation, are typically used as approximation to true probabilistic samples. A known issue with n-best lists is that they tend to be clustered around only one mode of the distribution. A more direct procedure is to attempt to directly draw samples from the underlying distribution rather than rely on n-best list approximations (Arun et al., 2009; Blunsom and Osborne, 2008). We present a method for inference in hierarchical phrase-based translation, where both optimisation and sampling are performed in a common exact inference framework related to adaptive rejection sampling. We also present a first implementation of that method along with experimental results shedding light on some fundamental issues. In hierarchical translation, inference needs to be performed over a high-complexity distribution defined by the intersection of a translation hypergraph and a target language model. We replace this intractable distribution by a sequence of tractable upper-bounds f"
W13-2260,W12-3102,0,0.0503581,"Missing"
W13-2260,D12-1103,1,0.855206,"mples from p. In the case of optimisation, one finds the maximum x relative to q, and again computes the ratio r = p(x)/q(x). If this ratio equals 1, then it is easy to show that x is the actual maximum from p.1 Otherwise we refine the proposal in a similar way to the sampling case, continuing until we find a ratio equal to 1 (or very close to 1 if we are willing to accept an approximation to the maximum). For finite spaces X, this optimisation technique is argued to be a generalisation of A∗ . An application of the OS ∗ technique to sampling/optimisation with High-Order HMM’s is described in Carter et al. (2012) and provides background for this paper. In that work, while the highorder HMM corresponds to an intractable goal distribution, it can be upper-bounded by a sequence of tractable distributions for which optimisers and samplers can be obtained through standard dynamic programming techniques. 2.2 Hierarchical Translation An abstract formulation of the decoding process for hierarchical translation models such as that of Chiang (2007) can be expressed as a sequence of three steps. In a first step, a translation model G, represented as a weighted synchronous contextfree grammar (SCFG) (Chiang, 2005"
W13-2260,P05-1033,0,0.686456,"t al. (2012) and provides background for this paper. In that work, while the highorder HMM corresponds to an intractable goal distribution, it can be upper-bounded by a sequence of tractable distributions for which optimisers and samplers can be obtained through standard dynamic programming techniques. 2.2 Hierarchical Translation An abstract formulation of the decoding process for hierarchical translation models such as that of Chiang (2007) can be expressed as a sequence of three steps. In a first step, a translation model G, represented as a weighted synchronous contextfree grammar (SCFG) (Chiang, 2005), is applied to (in other words, intersected with) the source sentence f to produce a weighted context-free grammar G(f ) over the target language.2 In a second step, G(f ) is intersected with a weighted finitestate automaton A representing the target language model, resulting in a weighted context-free grammar G0 (f ) = G(f ) ∩ A. In a final step, a dynamic programming procedure (see §2.4) is applied to find the maximum derivation x in G0 (f ), and the sequence of leaves of yield(x) is the result translation. While this formulation gives the general principle, already mentioned in Chiang (200"
W13-2260,P10-4002,0,0.0380892,"hted finitestate automaton A representing the target language model, resulting in a weighted context-free grammar G0 (f ) = G(f ) ∩ A. In a final step, a dynamic programming procedure (see §2.4) is applied to find the maximum derivation x in G0 (f ), and the sequence of leaves of yield(x) is the result translation. While this formulation gives the general principle, already mentioned in Chiang (2007), most implementations do not exactly follow these steps or use this terminology. In practice, the closest approach to this abstract formulation is that of Dyer (2010) and the related system cdec (Dyer et al., 2010); we follow a similar approach here. 1 This is because if x0 was such that p(x0 ) &gt; p(x), then q(x0 ) ≥ p(x0 ) &gt; p(x) = q(x), and hence x would not be a maximum for q, a contradiction. 2 G(f ) is thus a compact representation of a forest over target sequences, and is equivalent to a hypergraph, using different terminology. Whatever the actual implementation chosen, all approaches face a common problem: the complexity of the intersection G0 (f ) = G(f ) ∩ A increases rapidly with the order of the language model, and can become unwieldy for moderate-length input sentences even with a bigram mode"
W13-2260,W12-6106,1,0.794456,"model. We replace this intractable distribution by a sequence of tractable upper-bounds for which exact optimisers and samplers are easy to obtain. Our experiments show that exact inference is then feasible using only a fraction of the time and space that would be required by the full intersection, without recourse to pruning techniques that only provide approximate solutions. While the current implementation is limited in the size of inputs it can handle in reasonable time, our experiments provide insights towards obtaining future speedups, while staying in the same general framework. 1 OS∗ (Dymetman et al., 2012a) is a recent approach that stresses a unified view between the two types of inference, optimisation and sampling. In this view, rather than resorting to pruning in order to cope with the tractability issues, one upperbounds the complex goal distribution with a simpler “proposal” distribution for which dynamic programming is feasible. This proposal is incrementally refined to be closer to the goal until the maximum is found, or until the sampling performance exceeds a certain level. Introduction In statistical machine translation (SMT), optimisation — the task of searching for an optimum tran"
W13-2260,P13-2121,0,0.0963369,"Missing"
W13-2260,P07-1019,0,0.0667205,", and hence x would not be a maximum for q, a contradiction. 2 G(f ) is thus a compact representation of a forest over target sequences, and is equivalent to a hypergraph, using different terminology. Whatever the actual implementation chosen, all approaches face a common problem: the complexity of the intersection G0 (f ) = G(f ) ∩ A increases rapidly with the order of the language model, and can become unwieldy for moderate-length input sentences even with a bigram model. In order to address this problem, most implementations employ variants of a technique called cube-pruning (Chiang, 2007; Huang and Chiang, 2007), where the cells constructed during the intersection process retain only a k-best list of promising candidates. This is an approximation technique, related to beam-search, which performs well in practice, but is not guaranteed to find the actual optimum. In the approach presented here — described in detail in §3 — we do not prune the search space. While we do construct the full initial grammar G(f ), we proceed by incrementally intersecting it with simple automata associated with upperbounds of A, for which the intersection is tractable. 2.3 Earley Intersection In their classical paper Bar-Hi"
W13-2260,N07-1018,0,0.037525,"ax-times semiring. Here, instead of maximising over the weights of the competing derivations rooted in the same nonterminal, one sums over these weights. By proceeding in the same bottom-up way, one ends with an accumulation of all the weights on the initial nonterminal (this can also be seen as the partition function associated with the grammar). An efficient exact sampler is then obtained by starting at the root nonterminal, randomly selecting an expansion proportionally to the weight of this expansion, and iterating in a topdown way. This process is described in more detail in section 4 of Johnson et al. (2007), for instance. 3 Approach The complexity of building the full intersection G(f ) ∩ A, when A represents a language model of order n, is related to the fact that the number of states of A grows exponentially with n, and that each nonterminal N in G(f ) tends to generate in the grammar G0 (f ) many indexed nonterminals of the form (i, N, j), where i, j are states of A and the nonterminal (i, N, j) can be interpreted as an N connecting an i state to a j state. In our approach, instead of explicitly constructing the full intersection G(f ) ∩ A, which, using the notation of §2.1, is identified wit"
W13-2260,N03-1017,0,0.0792796,"bution for which dynamic programming is feasible. This proposal is incrementally refined to be closer to the goal until the maximum is found, or until the sampling performance exceeds a certain level. Introduction In statistical machine translation (SMT), optimisation — the task of searching for an optimum translation — is performed over a high-complexity distribution defined by the intersection between a translation hypergraph and a target language model (LM). This distribution is too complex to be represented exactly and one typically resorts to approximation techniques such as beam-search (Koehn et al., 2003) and cube-pruning (Chiang, 2007), where maximisation is performed over a pruned representation of the full distribution. This paper applies the OS∗ approach to the problem of inference in hierarchical SMT (Chiang, 2007). In a nutshell, the idea is to replace the intractable problem of intersecting a contextfree grammar with a full language model by the tractable problem of intersecting it with a simplified, optimistic version of this LM which “forgets” parts of n-gram contexts, and to incrementally add more context based on evidence of the need to do so. Evidence is gathered by optimising or s"
W13-2260,P07-2045,0,0.0063725,"g in the increased number of exact samples and better acceptance rate. 10 Note that, starting from iteration one, all refinements here correspond to 2-grams (i.e. one-word contexts). This can be explained by the fact that, in sampling, lower-order refinements are those that mostly increase acceptance rate (rationale: highorder n-grams are compatible with fewer grammar rules). L1 ● ● ● ● 9 ● ● ● ● ● ● ● ● ● ● 1.0 1.5 2.0 0.1 0.2 0.3 0 1000 exact ● ● ● ● ● ● ● ● ● ● ● ● ● ● accrate ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● refinement ● ● ● ● ● ● ● ● ● 0 5 10 4 Experiments We used the Moses toolkit (Koehn et al., 2007) to extract a SCFG following Chiang (2005) from the 6th version of the Europarl collection (Koehn, 2005) (German-English portion). We trained language models using lmplz (Heafield et al., 2013) and interpolated the models trained on the English monolingual data made available by the WMT (Callison-Burch et al., 2012) (i.e. Europarl, newscommentaries, news-2012 and commoncrawl). Tuning was performed via MERT using newstest2010 as development set; test sentences were extracted from newstest2011. Finally, we restricted our SCFGs to having at most 10 target productions for a given source production"
W13-2260,2005.mtsummit-papers.11,0,0.0260972,"e, all refinements here correspond to 2-grams (i.e. one-word contexts). This can be explained by the fact that, in sampling, lower-order refinements are those that mostly increase acceptance rate (rationale: highorder n-grams are compatible with fewer grammar rules). L1 ● ● ● ● 9 ● ● ● ● ● ● ● ● ● ● 1.0 1.5 2.0 0.1 0.2 0.3 0 1000 exact ● ● ● ● ● ● ● ● ● ● ● ● ● ● accrate ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● refinement ● ● ● ● ● ● ● ● ● 0 5 10 4 Experiments We used the Moses toolkit (Koehn et al., 2007) to extract a SCFG following Chiang (2005) from the 6th version of the Europarl collection (Koehn, 2005) (German-English portion). We trained language models using lmplz (Heafield et al., 2013) and interpolated the models trained on the English monolingual data made available by the WMT (Callison-Burch et al., 2012) (i.e. Europarl, newscommentaries, news-2012 and commoncrawl). Tuning was performed via MERT using newstest2010 as development set; test sentences were extracted from newstest2011. Finally, we restricted our SCFGs to having at most 10 target productions for a given source production. Figure 3 shows some properties of the initial grammar G(f ) as a function of the input sentence length"
W13-2260,N04-1022,0,0.0704041,"Missing"
W13-2260,P03-1021,0,0.0682464,"Missing"
W13-2260,P11-1008,0,0.343513,"Missing"
W13-2260,P06-2101,0,0.0494604,"Missing"
W13-2260,D07-1080,0,0.031726,"Missing"
W13-2260,J00-4006,0,\N,Missing
W13-2260,J07-2003,0,\N,Missing
W16-1611,D14-1067,0,0.0470258,"ural Question Answering Model In a standard setting, a question to query a KB must be formal (e.g., SQL). However, because a human-like QA system should take natural questions as input, we build a neural model to translate natural questions to formal queries. This model employs an LSTM to encode a natural question into a vector. It then uses two softmax layers to predict the device name and the attribute. This model is adequate here, since we focus on the QA situation where the client asks about device specifications. For more complex cases, more advanced QA models should be considered (e.g., Bordes et al. (2014), Yih et al. (2015)). Given question w1l , the two softmax layers give us a distribution over devices pd (•|w1l ) and a distribution over attributes pa (•|w1l ). We can then compute a distribution over the set Vqa of all values found in the KB, by marginalizing over d, a: X pqa (v|w1l ) = pd (d|w1l )pa (a|w1l ), (2) 4.3 Integration We now show how we integrate the chat model with the QA model using the LSTM-based mixture-of-experts method. The intuition is the following: the chat model is in charge of generating smooth responses into which the QA model “inserts” values retrieved from the KB. I"
W16-1611,P13-1158,0,0.0120111,"e KB. Initial experiments showed that predicting values in this indirect way significantly improves the accuracy compared to employing a single softmax layer to predict values directly, because it does not require the hidden states to directly memorize the value for each device-attribute pair. Data Generation One serious difficulty is that we do not have a corpus of natural questions on which to train the QA model, so we have to resort to a method for generating virtual question/answer pairs, on which to train our QA model. However, existing corpora and methods for generating such data (e.g., Fader et al. (2013)) hardly meet our needs here. This is because our case is very different from (and somewhat more difficult than) traditional QA set-ups in which questions are independent. In our case several scenarios are possible, resulting from the chat interaction (e.g., in a chat, questions can be related as in Figure 3). We therefore propose a simple heuristic method for generating artificial QA data that can cover several scenarios. For each pair <device name, attribute&gt;, we paraphrase the device name by randomly dropping some words (e.g., “apple iphone 4” The chat model is the backbone because it gener"
W16-1611,P15-1152,0,0.391822,"ral advantages over the traditional architecture (learnability, adaptability, better approximations to human utterances), this approach is inferior in one dimension: it assumes that all the knowledge required for the next agent’s utterance has to be implicitly present in the dialogues over which the network is trained, and to then be precisely memorized by the network, while the traditional approach allows this knowledge to be dynamically accessed from external knowledge-base (KB) sources, with guaranteed accuracy. To address this issue, we propose the following approach. As in Vinyals and Le (2015), we first do train a conditional neural LM based on existing dialogues, which we call our chat model; this model can be seen as an “expert” about the conversational patterns in the dialogue, but not about its knowledge-intensive aspects. Besides, we train another model, which this time is an expert about these knowledge aspects, which we call our QA model, due to its connections to Question Answering (QA). We then combine these two expert models through an LSTM-based integration model, which at each time step, encodes the whole history into a vector and then uses a softmax layer to compute a"
W16-1611,P99-1022,0,0.164883,"These sets are significantly smaller than those extracted above. eu(k,ht ) = PK k0 =1 e u(k0 ,ht ) where [u(1, ht ), ..., u(K, ht )]T = Wht +b, W ∈ RK×dim(ht ) , b ∈ RK . The final probability of the next word is then: p(w|w1t ) = K X p(k|w1t ) pk (w|w1t ). Data (1) k=1 Our proposal can be seen as bringing together two previous lines of research within an LSTM framework. Similar to the mixture-of-experts technique of Jacobs et al. (1991), we predict a label by using a “gating” neural network to mix the predictions of different experts based on the current situation. Similar to the approach of Florian and Yarowsky (1999), we dynamically combine distributions on words to produce an integrated LM. However Florian and Yarowsky (1999) focus on the combination of topic-dependent LMs, while in our case, the components can be arbitrary distributions over words — we later use a component that produces answers to questions appearing in the text. In our case, the labels are words, the gating neural network is an LSTM that stores a representation of a long textual prefix, and the combination mechanism is trained by optimizing the 4 4.1 KB-aware Chat Model Neural Chat Model Ouur corpus is comparable to the one described"
W16-1611,P15-1128,0,0.0121103,"g Model In a standard setting, a question to query a KB must be formal (e.g., SQL). However, because a human-like QA system should take natural questions as input, we build a neural model to translate natural questions to formal queries. This model employs an LSTM to encode a natural question into a vector. It then uses two softmax layers to predict the device name and the attribute. This model is adequate here, since we focus on the QA situation where the client asks about device specifications. For more complex cases, more advanced QA models should be considered (e.g., Bordes et al. (2014), Yih et al. (2015)). Given question w1l , the two softmax layers give us a distribution over devices pd (•|w1l ) and a distribution over attributes pa (•|w1l ). We can then compute a distribution over the set Vqa of all values found in the KB, by marginalizing over d, a: X pqa (v|w1l ) = pd (d|w1l )pa (a|w1l ), (2) 4.3 Integration We now show how we integrate the chat model with the QA model using the LSTM-based mixture-of-experts method. The intuition is the following: the chat model is in charge of generating smooth responses into which the QA model “inserts” values retrieved from the KB. Ideally, we should e"
W16-1611,P16-1057,0,0.0263459,"Missing"
W17-5519,D15-1199,0,0.0436486,"eriot-Watt University proposed the E2E NLG Challenge1 and released a dataset consisting of 50K (MR, RF) pairs, MR being a slot-value Meaning Representation of a restaurant, RF (human ReFerence) being a natural language utterance rendering of that representation. The utterances were crowd-sourced based on pictorial representations of the MRs, with the intention of producing more natural and diverse utterances compared to the ones directly based on the original MRs (Novikova et al., 2016). Most of the RNN-based approaches to Natural Language Generation (NLG) that we are aware of, starting with (Wen et al., 2015), generate the output word-by-word, and resort to special delexicalization or copy mechanisms (Gu et al., 2016) to ∗ Previously Xerox Research Centre Europe. http://www.macs.hw.ac.uk/ InteractionLab/E2E/ 1 158 Proceedings of the SIGDIAL 2017 Conference, pages 158–163, c Saarbr¨ucken, Germany, 15-17 August 2017. 2017 Association for Computational Linguistics tecture based on (Bahdanau et al., 2015; Luong et al., 2015). The encoder RNN embeds each of the source words (in our case, characters) into vectors exploiting the hidden states computed by the RNN. The decoder RNN predicts the next word (r"
W17-5519,D17-1151,0,0.0275801,"simply represented as a character sequence, and the output is also generated char-by-char; this approach avoids the rare word problem, as the character vocabulary is very small. While (Goyal et al., 2016) used an additional finite-state mechanism to guide the production of well-formed (and input-motivated) character sequences, the performance of their basic char2char model was already quite good. We further explore how a recent out-of-the box seq2seq model would perform on E2E NLG Challenge, when used in a char-based mode. We choose attention-based tfseq2seq framework provided by authors of (Britz et al., 2017) (which we detail in next section). Using some standard options provided by this framework, and without any pre- or postprocessing (not even tokenization or lowercasing), we obtained results on which we conducted a small-scale human evaluation on one hundred MRs, involving two evaluators. This evaluation, on the one hand, concentrated on the linguistic quality, and on the other hand, on the semantic adequacy of the produced utterances. On the linguistic side, vast majority of the predictions were surprisingly grammatically perfect, while still being rather diverse and natural. In particular, a"
W17-5519,E17-1060,0,0.0561999,"Missing"
W17-5519,C16-1103,1,0.480278,"Missing"
W17-5519,P16-1154,0,0.0131639,"R being a slot-value Meaning Representation of a restaurant, RF (human ReFerence) being a natural language utterance rendering of that representation. The utterances were crowd-sourced based on pictorial representations of the MRs, with the intention of producing more natural and diverse utterances compared to the ones directly based on the original MRs (Novikova et al., 2016). Most of the RNN-based approaches to Natural Language Generation (NLG) that we are aware of, starting with (Wen et al., 2015), generate the output word-by-word, and resort to special delexicalization or copy mechanisms (Gu et al., 2016) to ∗ Previously Xerox Research Centre Europe. http://www.macs.hw.ac.uk/ InteractionLab/E2E/ 1 158 Proceedings of the SIGDIAL 2017 Conference, pages 158–163, c Saarbr¨ucken, Germany, 15-17 August 2017. 2017 Association for Computational Linguistics tecture based on (Bahdanau et al., 2015; Luong et al., 2015). The encoder RNN embeds each of the source words (in our case, characters) into vectors exploiting the hidden states computed by the RNN. The decoder RNN predicts the next word (resp. character) based on its current hidden state, previous character, and also based on the “context” vector c"
W17-5519,P16-2058,0,0.022866,"Missing"
W17-5519,D15-1166,0,0.0423237,"Missing"
W18-6555,C16-1103,1,0.850982,"nslation (Chung et al., 2016; Zhao and Zhang, 2016; Ling et al., 2016). Neural seq2seq approaches to Natural Language Generation (NLG) are typically wordbased, and resort to delexicalization (a process in which named entities (slot values) are replaced with special ‘placeholders’ (Wen et al., 2015)) to handle rare or unknown words (out-of-vocabulary (OOV) words, even with a large vocabulary). It can be argued that this de-lexicalization is unable to account for phenomena such as morphological agreement (gender, numbers) in the generated text (Sharma et al., 2016; Nayak et al., 2017). However, Goyal et al. (2016) and Agarwal and Dymetman (2017) employ a char-based seq2seq model where the input MR is simply represented as a character sequence, and the output is also generated char-by-char; avoiding the rare word problem, as the character vocabulary is very small. This paper describes our submission to the E2E NLG Challenge. Recently, neural seq2seq approaches have become mainstream in NLG, often resorting to pre- (respectively post-) processing delexicalization (relexicalization) steps at the word-level to handle rare words. By contrast, we train a simple character level seq2seq model, which requires n"
W18-6555,P17-1014,0,0.0314997,"1th International Natural Language Generation Conference, pages 451–456, c Tilburg, The Netherlands, November 5-8, 2018. 2018 Association for Computational Linguistics This work builds on top of the formulation of Agarwal and Dymetman (2017) and describes our submission for the E2E NLG challenge (Novikova et al., 2017). We further explore re-ranking techniques in order to identify the perfect ‘oracle prediction’ utterance. One of the strategies for reranking uses an approach similar to the ‘inverted generation’ technique of (Chisholm et al., 2017). Sennrich et al. (2015), Li et al. (2015) and Konstas et al. (2017) have also trained a reverse model for back translation in Machine Translation and NLG. A synthetic data creation technique is used by Duˇsek et al. (2017) and Logacheva and Specia (2015) but as far as we know, our protocol is novel. Our contributions in this paper and challenge can, thus, be summarized as: Encoder RNN and try to predict the character sequence of the corresponding utterances (RF) in the generation stage with the Decoder RNN. Coupled with the attention mechanism, seq2seq models have become de-facto standard in generation tasks. The encoder RNN embeds each of the source characte"
W18-6555,C16-1105,0,0.103644,"Missing"
W18-6555,W17-5519,1,0.848976,"2016; Zhao and Zhang, 2016; Ling et al., 2016). Neural seq2seq approaches to Natural Language Generation (NLG) are typically wordbased, and resort to delexicalization (a process in which named entities (slot values) are replaced with special ‘placeholders’ (Wen et al., 2015)) to handle rare or unknown words (out-of-vocabulary (OOV) words, even with a large vocabulary). It can be argued that this de-lexicalization is unable to account for phenomena such as morphological agreement (gender, numbers) in the generated text (Sharma et al., 2016; Nayak et al., 2017). However, Goyal et al. (2016) and Agarwal and Dymetman (2017) employ a char-based seq2seq model where the input MR is simply represented as a character sequence, and the output is also generated char-by-char; avoiding the rare word problem, as the character vocabulary is very small. This paper describes our submission to the E2E NLG Challenge. Recently, neural seq2seq approaches have become mainstream in NLG, often resorting to pre- (respectively post-) processing delexicalization (relexicalization) steps at the word-level to handle rare words. By contrast, we train a simple character level seq2seq model, which requires no pre/post-processing (delexical"
W18-6555,P16-2058,0,0.0207007,"en integrated in a Sequence to Sequence (Cho et al., 2014; Sutskever et al., 2014) framework have produced state-of-art results in Machine Translation (Cho et al., 2014; Sutskever et al., 2014; Bahdanau et al., 2015), Conversational Modeling (Vinyals and Le, 2015), Semantic Parsing (Xiao et al., 2016) and Natural Language Generation (Wen et al., 2015; Mei et al., 2015). While these models were initially developed to be used at word level in NLP related tasks, there has been a recent interest to use character level sequences, as in Machine Translation (Chung et al., 2016; Zhao and Zhang, 2016; Ling et al., 2016). Neural seq2seq approaches to Natural Language Generation (NLG) are typically wordbased, and resort to delexicalization (a process in which named entities (slot values) are replaced with special ‘placeholders’ (Wen et al., 2015)) to handle rare or unknown words (out-of-vocabulary (OOV) words, even with a large vocabulary). It can be argued that this de-lexicalization is unable to account for phenomena such as morphological agreement (gender, numbers) in the generated text (Sharma et al., 2016; Nayak et al., 2017). However, Goyal et al. (2016) and Agarwal and Dymetman (2017) employ a char-base"
W18-6555,W15-4907,0,0.0257359,"lds on top of the formulation of Agarwal and Dymetman (2017) and describes our submission for the E2E NLG challenge (Novikova et al., 2017). We further explore re-ranking techniques in order to identify the perfect ‘oracle prediction’ utterance. One of the strategies for reranking uses an approach similar to the ‘inverted generation’ technique of (Chisholm et al., 2017). Sennrich et al. (2015), Li et al. (2015) and Konstas et al. (2017) have also trained a reverse model for back translation in Machine Translation and NLG. A synthetic data creation technique is used by Duˇsek et al. (2017) and Logacheva and Specia (2015) but as far as we know, our protocol is novel. Our contributions in this paper and challenge can, thus, be summarized as: Encoder RNN and try to predict the character sequence of the corresponding utterances (RF) in the generation stage with the Decoder RNN. Coupled with the attention mechanism, seq2seq models have become de-facto standard in generation tasks. The encoder RNN embeds each of the source characters into vectors exploiting the hidden states computed by the RNN. The decoder RNN predicts the next character based on its current hidden state, previous character, and also the “context”"
W18-6555,D17-1151,0,0.0251516,"original MR and the MR generated by the reverse model, starting from the utterance predicted in the forward direction. 3 Experiments The updated challenge dataset comprises 50K canonically ordered and systematically structured (MR,RF) pairs, collected following the crowdsourcing protocol explained in Novikova et al. (2016). Consisting of 8 different slots (and their respective different values), note that the statistics in the test set differ significantly from the training set. We used the open source tf-seq2seq framework2 , built over TensorFlow (Abadi et al., 2016) and provided along with (Britz et al., 2017), with some standard configurations. We experimented with different numbers of layers in the encoder and decoder as well as different beam widths, while using the bi-directional encoder with an “additive” attention mechanism. In terms of BLEU, our best performing model had the following configuration: encoder 1 layer, decoder 2 layers, GRU cell, beam-width 20, length penalty 1. To avoid defining the weights when combining edit distance with the log probability of the model, we used a simplified mechanism. At the time of reranking, we choose the first output in our n-best list with zero edit di"
W18-6555,E17-1060,0,0.261283,") † Previously Xerox Research Centre Europe. 451 Proceedings of The 11th International Natural Language Generation Conference, pages 451–456, c Tilburg, The Netherlands, November 5-8, 2018. 2018 Association for Computational Linguistics This work builds on top of the formulation of Agarwal and Dymetman (2017) and describes our submission for the E2E NLG challenge (Novikova et al., 2017). We further explore re-ranking techniques in order to identify the perfect ‘oracle prediction’ utterance. One of the strategies for reranking uses an approach similar to the ‘inverted generation’ technique of (Chisholm et al., 2017). Sennrich et al. (2015), Li et al. (2015) and Konstas et al. (2017) have also trained a reverse model for back translation in Machine Translation and NLG. A synthetic data creation technique is used by Duˇsek et al. (2017) and Logacheva and Specia (2015) but as far as we know, our protocol is novel. Our contributions in this paper and challenge can, thus, be summarized as: Encoder RNN and try to predict the character sequence of the corresponding utterances (RF) in the generation stage with the Decoder RNN. Coupled with the attention mechanism, seq2seq models have become de-facto standard in"
W18-6555,W16-6644,0,0.0481957,"by an intuition that if our prediction omits some information, the reverse reconstruction of MR would also tend to omit slot-value pairs for the omitted slot values in the prediction. We then score and re-rank the top-k predictions based on a distance metric, namely the edit distance between the original MR and the MR generated by the reverse model, starting from the utterance predicted in the forward direction. 3 Experiments The updated challenge dataset comprises 50K canonically ordered and systematically structured (MR,RF) pairs, collected following the crowdsourcing protocol explained in Novikova et al. (2016). Consisting of 8 different slots (and their respective different values), note that the statistics in the test set differ significantly from the training set. We used the open source tf-seq2seq framework2 , built over TensorFlow (Abadi et al., 2016) and provided along with (Britz et al., 2017), with some standard configurations. We experimented with different numbers of layers in the encoder and decoder as well as different beam widths, while using the bi-directional encoder with an “additive” attention mechanism. In terms of BLEU, our best performing model had the following configuration: en"
W18-6555,W14-3301,0,0.0639258,"Missing"
W18-6555,D15-1199,0,0.0498892,"16; Duˇsek and Jurˇc´ıcˇ ek, 2016; Wen et al., 2015). Recurrent Neural Networks with gated cell variants such as LSTMs and GRUs (Hochreiter and Schmidhuber, 1997; Cho et al., 2014) are now extensively used to model sequential data. This class of neural networks when integrated in a Sequence to Sequence (Cho et al., 2014; Sutskever et al., 2014) framework have produced state-of-art results in Machine Translation (Cho et al., 2014; Sutskever et al., 2014; Bahdanau et al., 2015), Conversational Modeling (Vinyals and Le, 2015), Semantic Parsing (Xiao et al., 2016) and Natural Language Generation (Wen et al., 2015; Mei et al., 2015). While these models were initially developed to be used at word level in NLP related tasks, there has been a recent interest to use character level sequences, as in Machine Translation (Chung et al., 2016; Zhao and Zhang, 2016; Ling et al., 2016). Neural seq2seq approaches to Natural Language Generation (NLG) are typically wordbased, and resort to delexicalization (a process in which named entities (slot values) are replaced with special ‘placeholders’ (Wen et al., 2015)) to handle rare or unknown words (out-of-vocabulary (OOV) words, even with a large vocabulary). It can b"
W18-6555,P16-1127,1,0.840994,"om data (Mei et al., 2015; Lampouras and Vlachos, 2016; Duˇsek and Jurˇc´ıcˇ ek, 2016; Wen et al., 2015). Recurrent Neural Networks with gated cell variants such as LSTMs and GRUs (Hochreiter and Schmidhuber, 1997; Cho et al., 2014) are now extensively used to model sequential data. This class of neural networks when integrated in a Sequence to Sequence (Cho et al., 2014; Sutskever et al., 2014) framework have produced state-of-art results in Machine Translation (Cho et al., 2014; Sutskever et al., 2014; Bahdanau et al., 2015), Conversational Modeling (Vinyals and Le, 2015), Semantic Parsing (Xiao et al., 2016) and Natural Language Generation (Wen et al., 2015; Mei et al., 2015). While these models were initially developed to be used at word level in NLP related tasks, there has been a recent interest to use character level sequences, as in Machine Translation (Chung et al., 2016; Zhao and Zhang, 2016; Ling et al., 2016). Neural seq2seq approaches to Natural Language Generation (NLG) are typically wordbased, and resort to delexicalization (a process in which named entities (slot values) are replaced with special ‘placeholders’ (Wen et al., 2015)) to handle rare or unknown words (out-of-vocabulary (O"
W18-6555,P16-1160,0,\N,Missing
W18-6555,W17-5525,0,\N,Missing
W18-6555,W17-3207,0,\N,Missing
W18-6555,N16-1086,0,\N,Missing
W91-0104,C88-2128,0,0.147449,"Missing"
W91-0104,P89-1002,0,0.0124116,"to program P. Let T be a t e r m over H ; We define the specialization of r(X) on T as the relation rT(x) on H defined by: 3Or more generally, any t r a n s f o r m a t i o n exploiting theorerns provable of the: g r a m m a r . A n o t h e r instance of this technique is provided by the addition of conservative guides in [5], which &quot; s t r e n g t h e n &quot; the g r a m m a r on t h e basis of properties inferable from its &quot; ' form. 4 A n o t h e r p o p u l a r a p p r o a c h is to use a special-purpose interpreter, exploiting[ p r o p e r t i e s of the g r a m m a r known a priori. [18] and [14] use this a p p r o a c h in the case of generation (see below). : 5The description is simplified; see §3 for the exact definition. °See also [17] for a discussion of oifttine-parsability in the context of generation. def rT(~) =-- r(~) ^ x E Z where ff is the relation of subsumption. In case the t e r m T is a variable X , we say t h a t X is the trivial specialization, and we note t h a t the relation r x ( z ) is identical to the relation r ( z ) . 7This a s s u m p t i o n p e r m i t s to simplify tile exposition, b u t is n o t otherwise necessary. 21 2.1.2 Operational the b r a n c h e"
W91-0104,1988.tmi-1.12,1,0.643892,"ughly studied. 2See e.g. [7, p. 59] and section §2.1.3. See also [19] in this volume for a related approach. some 20 2 find, and go on eternally looking for new solutions. Definite programs and computation The source of this problem can be more or less severe: It m a y simply be due to the grarnmar's implementation as,a certain program, or it m a y be intrinsic to the g r a m m a r . 2.1 If it is not intrinsic to the g r a m m a r , one may a t t e m p t some kind of p r o g r a m transformation on the g r a m m a r - - f o r qnstance a local transformation as goal reordering in clause bodies [4, 16], or a global transformation as left-recursion elimination [5, 3] 3 - - i n order 'to get a parsing p r o g r a m which displays a finite behavior. 4 If such a transformation is possible in principle, we say that, intrinsically, the g r a m m a r has a finitely enumerable parsing problem. 5 One.example of a class of g r a m m a r s which respect this crucial condition is provided by offline-parsable DCGs, once compiled as definite programs (see [9]).6 D e n o t a t i o n a l and operational semantics of a definite program; c o m p l e t e and i n c o m p l e t e interpreters A definite p r o g"
W91-0104,P90-1027,0,0.0135442,"ughly studied. 2See e.g. [7, p. 59] and section §2.1.3. See also [19] in this volume for a related approach. some 20 2 find, and go on eternally looking for new solutions. Definite programs and computation The source of this problem can be more or less severe: It m a y simply be due to the grarnmar's implementation as,a certain program, or it m a y be intrinsic to the g r a m m a r . 2.1 If it is not intrinsic to the g r a m m a r , one may a t t e m p t some kind of p r o g r a m transformation on the g r a m m a r - - f o r qnstance a local transformation as goal reordering in clause bodies [4, 16], or a global transformation as left-recursion elimination [5, 3] 3 - - i n order 'to get a parsing p r o g r a m which displays a finite behavior. 4 If such a transformation is possible in principle, we say that, intrinsically, the g r a m m a r has a finitely enumerable parsing problem. 5 One.example of a class of g r a m m a r s which respect this crucial condition is provided by offline-parsable DCGs, once compiled as definite programs (see [9]).6 D e n o t a t i o n a l and operational semantics of a definite program; c o m p l e t e and i n c o m p l e t e interpreters A definite p r o g"
W91-0104,C90-3017,1,0.681034,"19] in this volume for a related approach. some 20 2 find, and go on eternally looking for new solutions. Definite programs and computation The source of this problem can be more or less severe: It m a y simply be due to the grarnmar's implementation as,a certain program, or it m a y be intrinsic to the g r a m m a r . 2.1 If it is not intrinsic to the g r a m m a r , one may a t t e m p t some kind of p r o g r a m transformation on the g r a m m a r - - f o r qnstance a local transformation as goal reordering in clause bodies [4, 16], or a global transformation as left-recursion elimination [5, 3] 3 - - i n order 'to get a parsing p r o g r a m which displays a finite behavior. 4 If such a transformation is possible in principle, we say that, intrinsically, the g r a m m a r has a finitely enumerable parsing problem. 5 One.example of a class of g r a m m a r s which respect this crucial condition is provided by offline-parsable DCGs, once compiled as definite programs (see [9]).6 D e n o t a t i o n a l and operational semantics of a definite program; c o m p l e t e and i n c o m p l e t e interpreters A definite p r o g r a m P is a finite set of clauses of the form (non-unit clauses"
W91-0104,C90-2051,0,0.0185043,"t r a n s f o r m a t i o n exploiting theorerns provable of the: g r a m m a r . A n o t h e r instance of this technique is provided by the addition of conservative guides in [5], which &quot; s t r e n g t h e n &quot; the g r a m m a r on t h e basis of properties inferable from its &quot; ' form. 4 A n o t h e r p o p u l a r a p p r o a c h is to use a special-purpose interpreter, exploiting[ p r o p e r t i e s of the g r a m m a r known a priori. [18] and [14] use this a p p r o a c h in the case of generation (see below). : 5The description is simplified; see §3 for the exact definition. °See also [17] for a discussion of oifttine-parsability in the context of generation. def rT(~) =-- r(~) ^ x E Z where ff is the relation of subsumption. In case the t e r m T is a variable X , we say t h a t X is the trivial specialization, and we note t h a t the relation r x ( z ) is identical to the relation r ( z ) . 7This a s s u m p t i o n p e r m i t s to simplify tile exposition, b u t is n o t otherwise necessary. 21 2.1.2 Operational the b r a n c h e s - - m a y b e leading to s u c c e s s - - t o the right of this branch in the search-tree [7, pp. 59-60]. By contrast, a top-down, breadth-firs"
W91-0104,W91-0110,0,0.419974,"ms exactly reflect the content of the grammar. This we will call the reversibility problem. 1We could have made s o m e o t h e r choice, for instance unification grammar formalism. The advantage of using definite programs in t h e p r e s e n t discussion is that they embody the whole unification paradigm in its purest form, that unification of terms is conceptually simpler (and less p r o n e t o misunderstandings) than unification of DAGs, and that the denotational and operational semantics of definite programs have been thoroughly studied. 2See e.g. [7, p. 59] and section §2.1.3. See also [19] in this volume for a related approach. some 20 2 find, and go on eternally looking for new solutions. Definite programs and computation The source of this problem can be more or less severe: It m a y simply be due to the grarnmar's implementation as,a certain program, or it m a y be intrinsic to the g r a m m a r . 2.1 If it is not intrinsic to the g r a m m a r , one may a t t e m p t some kind of p r o g r a m transformation on the g r a m m a r - - f o r qnstance a local transformation as goal reordering in clause bodies [4, 16], or a global transformation as left-recursion elimination [5,"
W91-0104,P83-1021,0,0.279416,"t some kind of p r o g r a m transformation on the g r a m m a r - - f o r qnstance a local transformation as goal reordering in clause bodies [4, 16], or a global transformation as left-recursion elimination [5, 3] 3 - - i n order 'to get a parsing p r o g r a m which displays a finite behavior. 4 If such a transformation is possible in principle, we say that, intrinsically, the g r a m m a r has a finitely enumerable parsing problem. 5 One.example of a class of g r a m m a r s which respect this crucial condition is provided by offline-parsable DCGs, once compiled as definite programs (see [9]).6 D e n o t a t i o n a l and operational semantics of a definite program; c o m p l e t e and i n c o m p l e t e interpreters A definite p r o g r a m P is a finite set of clauses of the form (non-unit clauses): p(T1,..., T,) p x ( T l x , . . . ,Tin,)'&quot; &quot;pro(Tin1,... ,Tmn.) or of the form (unit clauses): p(Tx,..., Tn) where the the P,Pi are predicate symbols and the Ti, T/j are terms over a certain H e r b r a n d universe of ground terms H . We will suppose that, a m o n g the predicates p defined by P , one, r, is privileged and plays the role of the &quot;main predicate&quot; in the program. We"
