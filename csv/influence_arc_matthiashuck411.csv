2010.amta-papers.32,W09-0437,0,0.0133723,"rget generation has proven very successful and robust by relying on statistics learned purely on surface forms from huge corpora. Such systems still outperform hierarchical setups in many evaluations. (Galley and Manning, 2010) even show that conventional systems can be extended in a way that they are able to make use of phrases with gaps similar to the rule set of hierarchical systems. In their experiments, a conventional system with gappy phrases and lexicalized reordering produces a significantly better output for Chinese-English than a hierarchical one without any syntactic enhancements. (Auli et al., 2009) challenge the common assumption that there are structural differences in the types of outputs the two translation approaches can produce. Analyzing the search spaces of conventional phrase-based and hierarchical systems, they find a high overlap. They argue that the main difference is in the parameterization, not in the expressiveness of the translation models. Recent research has demonstrated how two types of extended lexicon models called triplet lexicon model (we will abbreviate this simply as triplets in many cases) and discriminative word lexicon (DWL) can improve the translation results"
2010.amta-papers.32,J93-2003,0,0.0129456,"ir computational demands in training, and their final size. The experimental evaluation is presented in Section 5. We first give a characterization of the experimental setup and the main details of our systems. We then report on the different extended lexicon models we trained and proceed with a comparison of the translation results using these models in standard phrase-based and hierarchical translation. 3 Previous Work (Hasan et al., 2008) proposed triplet lexicon models for statistical machine translation for the first time. Triplet lexicon models are related to the well-known IBM-1 model (Brown et al., 1993) but extend it with a second trigger. (Hasan et al., 2008) also introduced the restrictions that are applied to triplets in this work, they did however apply the models only in an n-best list reranking framework. They evaluated their methods on a small Chinese-English and on a Spanish-English/English-Spanish task. (Hasan and Ney, 2009) investigated triplet lexicon scoring in a conventional phrase-based decoder and compared translation performance of the so-called path-constrained (or path-aligned) triplet models applied in reranking to an integrated application in search on a large-scale Chine"
2010.amta-papers.32,P05-1033,0,0.343261,"y within a local context and give reliable results as long as only information from a limited window is required. But reordering in translation between different languages, recursive embedding of subphrases, as it is common in natural language, and distant lexical interconnections are hard to model and difficult to handle in a computationally efficient way. 1 1 (Knight, 1999) proofs that the decoding problem with unrestricted reorderings is NP-complete. The hierarchical phrase-based approach to SMT promises to be able to capture translations whose scope is larger than a few consecutive words (Chiang, 2005; Chiang, 2007). By allowing gaps within bilingual phrases that are indicated by corresponding place-holders (i.e. co-indexed non-terminals), the phrase table of a hierarchical phrase-based translation (HPBT) system can be considered to be the production set of a synchronous context-free grammar. This formal grammar usually does not comply with a linguistically motivated grammar, but as the search procedure is realized as a probabilistic parser, the hierarchical phrase-based paradigm connects somewhat closer to more linguistics-related work in natural language processing than conventional phra"
2010.amta-papers.32,J07-2003,0,0.281662,"al context and give reliable results as long as only information from a limited window is required. But reordering in translation between different languages, recursive embedding of subphrases, as it is common in natural language, and distant lexical interconnections are hard to model and difficult to handle in a computationally efficient way. 1 1 (Knight, 1999) proofs that the decoding problem with unrestricted reorderings is NP-complete. The hierarchical phrase-based approach to SMT promises to be able to capture translations whose scope is larger than a few consecutive words (Chiang, 2005; Chiang, 2007). By allowing gaps within bilingual phrases that are indicated by corresponding place-holders (i.e. co-indexed non-terminals), the phrase table of a hierarchical phrase-based translation (HPBT) system can be considered to be the production set of a synchronous context-free grammar. This formal grammar usually does not comply with a linguistically motivated grammar, but as the search procedure is realized as a probabilistic parser, the hierarchical phrase-based paradigm connects somewhat closer to more linguistics-related work in natural language processing than conventional phrase-based transl"
2010.amta-papers.32,N10-1140,0,0.0226689,"02) without having to impose any hard contraints on the translation process. Bringing different lines of research together in a natural way by augmenting hierarchical translation with syntactic knowledge has primarily been done with the intent to be able to produce better structured outputs with the resulting systems. On the other hand, conventional phrase-based translation with left-to-right target generation has proven very successful and robust by relying on statistics learned purely on surface forms from huge corpora. Such systems still outperform hierarchical setups in many evaluations. (Galley and Manning, 2010) even show that conventional systems can be extended in a way that they are able to make use of phrases with gaps similar to the rule set of hierarchical systems. In their experiments, a conventional system with gappy phrases and lexicalized reordering produces a significantly better output for Chinese-English than a hierarchical one without any syntactic enhancements. (Auli et al., 2009) challenge the common assumption that there are structural differences in the types of outputs the two translation approaches can produce. Analyzing the search spaces of conventional phrase-based and hierarchi"
2010.amta-papers.32,N09-2005,1,0.784137,"sing these models in standard phrase-based and hierarchical translation. 3 Previous Work (Hasan et al., 2008) proposed triplet lexicon models for statistical machine translation for the first time. Triplet lexicon models are related to the well-known IBM-1 model (Brown et al., 1993) but extend it with a second trigger. (Hasan et al., 2008) also introduced the restrictions that are applied to triplets in this work, they did however apply the models only in an n-best list reranking framework. They evaluated their methods on a small Chinese-English and on a Spanish-English/English-Spanish task. (Hasan and Ney, 2009) investigated triplet lexicon scoring in a conventional phrase-based decoder and compared translation performance of the so-called path-constrained (or path-aligned) triplet models applied in reranking to an integrated application in search on a large-scale Chinese-English task. They did not evaluate different variants of the model. The DWL model in a variant that is trained using seen features as well as unseen features was presented by (Mauser et al., 2009). We will compare our new variant of DWL models to the model as described by them. (Mauser et al., 2009) also compared the effect of a tr"
2010.amta-papers.32,D08-1039,1,0.869383,"Missing"
2010.amta-papers.32,P07-1019,0,0.0346242,"e parallel corpus and the LDC Gigaword v4 corpus. We measured a perplexity of 96.9 on the four reference translations of MT06. 5.1.1 Hierarchical Systems The hierarchical translation system we utilize has been developed at RWTH and has recently been released as open source software (Vilar et al., 2010). It implements the hierarchical phrase-based paradigm that has been introduced by (Chiang, 2005). We performed shallow search as defined in (Iglesias et al., 2009), i.e. we did not allow substitutions of non-terminals by strings containing nonterminals again, and ran the cube pruning algorithm (Huang and Chiang, 2007) with 500-best generation. Furthermore, we configured observation histogram pruning at a value of 50. Apart from the hierarchical phrase translation model, the language model and the extended lexicon models, the log-linear model combination of our systems comprises source-to-target and targetto-source phrase translation probabilities, IBM-1 source-to-target and target-to-source lexical translation probabilities, two features that account for some control about the application of hierarchical rules as opposed to initial rules, length penalties on word and phrase level and four binary features,"
2010.amta-papers.32,E09-1044,0,0.0310373,"Missing"
2010.amta-papers.32,J99-4005,0,0.0414614,"e dependencies into account is still one of the main problems in today’s statistical machine translation (SMT). State-of-the-art systems comprise components like a phrase translation model and n-gram language models that act effectively within a local context and give reliable results as long as only information from a limited window is required. But reordering in translation between different languages, recursive embedding of subphrases, as it is common in natural language, and distant lexical interconnections are hard to model and difficult to handle in a computationally efficient way. 1 1 (Knight, 1999) proofs that the decoding problem with unrestricted reorderings is NP-complete. The hierarchical phrase-based approach to SMT promises to be able to capture translations whose scope is larger than a few consecutive words (Chiang, 2005; Chiang, 2007). By allowing gaps within bilingual phrases that are indicated by corresponding place-holders (i.e. co-indexed non-terminals), the phrase table of a hierarchical phrase-based translation (HPBT) system can be considered to be the production set of a synchronous context-free grammar. This formal grammar usually does not comply with a linguistically mo"
2010.amta-papers.32,D09-1022,1,0.908847,"translation approaches can produce. Analyzing the search spaces of conventional phrase-based and hierarchical systems, they find a high overlap. They argue that the main difference is in the parameterization, not in the expressiveness of the translation models. Recent research has demonstrated how two types of extended lexicon models called triplet lexicon model (we will abbreviate this simply as triplets in many cases) and discriminative word lexicon (DWL) can improve the translation results of conventional phrase-based systems in n-best reranking as well as directly in beam-search decoding (Mauser et al., 2009). Both of them account for global source sentence context to predict context-specific target words. Their main advantage is that they promote a better lexical selection than the baseline models alone are able to achieve. With the availability of DWL and triplet model scoring implementations in a state-of-the-art hierarchical phrase-based translation system (Vilar et al., 2010), we are now in a position to compare conventional and hierarchical phrase-based setups — either of them enriched with extended lexicon models — against each other. On the large-scale NIST Arabic-English translation task,"
2010.amta-papers.32,P02-1038,1,0.503195,"stem can be considered to be the production set of a synchronous context-free grammar. This formal grammar usually does not comply with a linguistically motivated grammar, but as the search procedure is realized as a probabilistic parser, the hierarchical phrase-based paradigm connects somewhat closer to more linguistics-related work in natural language processing than conventional phrase-based translation (PBT). Several efforts have been made recently to engineer syntactically more informed SMT systems. Appropriate models can be introduced into the log-linear framework of modern SMT systems (Och and Ney, 2002) without having to impose any hard contraints on the translation process. Bringing different lines of research together in a natural way by augmenting hierarchical translation with syntactic knowledge has primarily been done with the intent to be able to produce better structured outputs with the resulting systems. On the other hand, conventional phrase-based translation with left-to-right target generation has proven very successful and robust by relying on statistics learned purely on surface forms from huge corpora. Such systems still outperform hierarchical setups in many evaluations. (Gal"
2010.amta-papers.32,J03-1002,1,0.0125958,"gain   Nefˆ 1 ∆Gefˆ ≥ Nefˆ log − 1 (9) Nfˆ NNe Ne ). N can be calculated simply by using the counts Nefˆ, Ne and Nf computed from the corpus. It should be mentioned that this criterion can be applied only to seen pairs. In the case of unseen pairs the logarithm is undefined. + N log(1 + 5 5.1 Experiments Experimental Setup We used a training corpus of 2.5M Arabic-English sentence pairs to set up the hierarchical as well as the conventional phrase-based systems. Word alignments in both directions were produced with GIZA++ and symmetrized according to the refined method that was proposed by (Och and Ney, 2003). Arabic Sentences English 2 514 413 Running words 54 324 372 55 348 390 Vocabulary 264 528 207 780 Singletons 115 171 91 390 Table 1: Data statistics for the preprocessed ArabicEnglish parallel training corpus. Numbers have been replaced by a special category symbol. The scaling factors of the log-linear model combination have been optimized on the MT06 NIST test corpus. MT08 was employed as held-out test data. Detailed statistics about the parallel data are given in Table 1, the characteristics of the development and the test corpus are reported in Table 2. All of the configurations use the"
2010.amta-papers.32,W10-1738,1,0.909202,"iate this simply as triplets in many cases) and discriminative word lexicon (DWL) can improve the translation results of conventional phrase-based systems in n-best reranking as well as directly in beam-search decoding (Mauser et al., 2009). Both of them account for global source sentence context to predict context-specific target words. Their main advantage is that they promote a better lexical selection than the baseline models alone are able to achieve. With the availability of DWL and triplet model scoring implementations in a state-of-the-art hierarchical phrase-based translation system (Vilar et al., 2010), we are now in a position to compare conventional and hierarchical phrase-based setups — either of them enriched with extended lexicon models — against each other. On the large-scale NIST Arabic-English translation task, we show that though a gap between the BLEU scores of the baseline systems can be observed, the two paradigms perform exactly the same if triplet and DWL models are added to the setups. Hierarchical and standard phrase-based statistical machine translation currently seem to operate at a comparable level, with advantages in some points for each of them. A good parameterization"
2010.amta-papers.32,2008.iwslt-papers.8,1,0.873322,"model, the language model and the extended lexicon models, the log-linear model combination of our systems comprises source-to-target and targetto-source phrase translation probabilities, IBM-1 source-to-target and target-to-source lexical translation probabilities, two features that account for some control about the application of hierarchical rules as opposed to initial rules, length penalties on word and phrase level and four binary features, essentially simple count features. 5.1.2 Phrase-Based Systems Our standard phrase-based machine translation system operates in the way described by (Zens and Ney, 2008). Phrase translation and word lexicon models in both directions, phrase and word penalties, a binary model that indicates a source phrase Extended Lexicon Models Triplet models. We prepared several triplet models of the variant denoted as path-constrained in Section 4.1 as well as of the variant denoted as uncontrained. The number of EM iterations has been 6 in all cases. Four different path-constrained triplet models are considered, one without any count cutoff and three with cutoffs of 2, 3, and 4, respectively. Like for the word alignments used for the phrase extraction, we used symmetrized"
2010.amta-papers.32,C04-1030,1,0.893716,"Missing"
2011.eamt-1.37,2010.amta-papers.7,0,\N,Missing
2011.eamt-1.37,W10-1761,0,\N,Missing
2011.eamt-1.37,E09-1044,0,\N,Missing
2011.eamt-1.37,D09-1022,1,\N,Missing
2011.eamt-1.37,C04-1030,1,\N,Missing
2011.eamt-1.37,P10-1146,0,\N,Missing
2011.eamt-1.37,W10-1738,1,\N,Missing
2011.eamt-1.37,2008.iwslt-papers.6,0,\N,Missing
2011.eamt-1.37,J10-3008,0,\N,Missing
2011.eamt-1.37,2010.iwslt-keynotes.2,0,\N,Missing
2011.eamt-1.37,N09-1027,0,\N,Missing
2011.eamt-1.37,P07-2045,0,\N,Missing
2011.eamt-1.37,P06-1055,0,\N,Missing
2011.eamt-1.37,P05-1033,0,\N,Missing
2011.eamt-1.37,J03-1002,1,\N,Missing
2011.eamt-1.37,W09-0434,0,\N,Missing
2011.eamt-1.37,2009.mtsummit-posters.17,0,\N,Missing
2011.eamt-1.37,2010.amta-papers.33,0,\N,Missing
2011.iwslt-papers.1,E09-1044,0,\N,Missing
2011.iwslt-papers.1,D09-1022,1,\N,Missing
2011.iwslt-papers.1,J93-2003,0,\N,Missing
2011.iwslt-papers.1,W10-1738,1,\N,Missing
2011.iwslt-papers.1,P11-2080,0,\N,Missing
2011.iwslt-papers.1,N09-2005,1,\N,Missing
2011.iwslt-papers.1,W06-1607,0,\N,Missing
2011.iwslt-papers.1,P07-2045,0,\N,Missing
2011.iwslt-papers.1,P07-1020,0,\N,Missing
2011.iwslt-papers.1,N03-1017,0,\N,Missing
2011.iwslt-papers.1,P02-1038,1,\N,Missing
2011.iwslt-papers.1,J03-1002,1,\N,Missing
2011.iwslt-papers.1,P07-1019,0,\N,Missing
2011.iwslt-papers.1,D08-1039,1,\N,Missing
2011.iwslt-papers.1,N04-1021,0,\N,Missing
2011.iwslt-papers.1,N04-1033,1,\N,Missing
2011.iwslt-papers.1,J07-2003,0,\N,Missing
2011.iwslt-papers.1,2010.amta-papers.33,0,\N,Missing
2011.iwslt-papers.1,2006.iwslt-evaluation.15,1,\N,Missing
2011.iwslt-papers.1,D08-1076,0,\N,Missing
2011.iwslt-papers.1,P11-2081,0,\N,Missing
2011.iwslt-papers.1,P04-1066,0,\N,Missing
2011.iwslt-papers.8,P02-1040,0,0.0794142,"he feature set of the loglinear model of the baseline hierarchical system is augmented with additional dependency-based features that can be categorized in two groups: those associated with the tree building process and those related to the dependency LM. We study how dependency tree building features and dependency LM each perform in isolation. • Usually trigrams are used for the dependency language model. We analyze the typical dependency tree structures found in our data and, based on the findings, explore which dependency language model order is appropriate. Results are presented in B LEU [6] and T ER [7] on a NIST Chinese–English subset and on a German–French corpus. 246 submitted were Bills submitted by Brownback Bills Senator on submitted Bills were ports and immigration on on ports ports Figure 1: Dependency tree of an English sentence. 2. Related Work Besides the authors mentioned in the previous section, several other groups have introduced dependency-based extensions to their machine translation frameworks in recent years. Among them, Galley & Manning [8] perform dependency parsing during decoding by lowering the parsing time to quadratic complexity. The authors work on the"
2011.iwslt-papers.8,2006.amta-papers.25,0,0.0321392,"t of the loglinear model of the baseline hierarchical system is augmented with additional dependency-based features that can be categorized in two groups: those associated with the tree building process and those related to the dependency LM. We study how dependency tree building features and dependency LM each perform in isolation. • Usually trigrams are used for the dependency language model. We analyze the typical dependency tree structures found in our data and, based on the findings, explore which dependency language model order is appropriate. Results are presented in B LEU [6] and T ER [7] on a NIST Chinese–English subset and on a German–French corpus. 246 submitted were Bills submitted by Brownback Bills Senator on submitted Bills were ports and immigration on on ports ports Figure 1: Dependency tree of an English sentence. 2. Related Work Besides the authors mentioned in the previous section, several other groups have introduced dependency-based extensions to their machine translation frameworks in recent years. Among them, Galley & Manning [8] perform dependency parsing during decoding by lowering the parsing time to quadratic complexity. The authors work on the NIST Chinese"
2011.iwslt-papers.8,P09-1087,0,0.122997,"and, based on the findings, explore which dependency language model order is appropriate. Results are presented in B LEU [6] and T ER [7] on a NIST Chinese–English subset and on a German–French corpus. 246 submitted were Bills submitted by Brownback Bills Senator on submitted Bills were ports and immigration on on ports ports Figure 1: Dependency tree of an English sentence. 2. Related Work Besides the authors mentioned in the previous section, several other groups have introduced dependency-based extensions to their machine translation frameworks in recent years. Among them, Galley & Manning [8] perform dependency parsing during decoding by lowering the parsing time to quadratic complexity. The authors work on the NIST Chinese–English corpus and show significant improvements over the baseline. Bach et al. [9] rely on source-side dependency information for reordering information on the tree structure. Similar to lexicalized reordering models, the tree sub-structure is used to employ features in a phrase-based system, for English–Spanish and English–Iraqi. Gao et al. [10] propose soft reordering constraints based on the source-side dependency structure in a hierarchical setting with im"
2011.iwslt-papers.8,2009.mtsummit-papers.1,0,0.0788533,"re Bills submitted by Brownback Bills Senator on submitted Bills were ports and immigration on on ports ports Figure 1: Dependency tree of an English sentence. 2. Related Work Besides the authors mentioned in the previous section, several other groups have introduced dependency-based extensions to their machine translation frameworks in recent years. Among them, Galley & Manning [8] perform dependency parsing during decoding by lowering the parsing time to quadratic complexity. The authors work on the NIST Chinese–English corpus and show significant improvements over the baseline. Bach et al. [9] rely on source-side dependency information for reordering information on the tree structure. Similar to lexicalized reordering models, the tree sub-structure is used to employ features in a phrase-based system, for English–Spanish and English–Iraqi. Gao et al. [10] propose soft reordering constraints based on the source-side dependency structure in a hierarchical setting with improvements on the NIST Chinese–English task. Xie et al. [11] also work with source-side dependencies and store the reordering information for each head-dependent. They employ a dependency-to-string translation model an"
2011.iwslt-papers.8,D11-1079,0,0.0588772,"ed dependency-based extensions to their machine translation frameworks in recent years. Among them, Galley & Manning [8] perform dependency parsing during decoding by lowering the parsing time to quadratic complexity. The authors work on the NIST Chinese–English corpus and show significant improvements over the baseline. Bach et al. [9] rely on source-side dependency information for reordering information on the tree structure. Similar to lexicalized reordering models, the tree sub-structure is used to employ features in a phrase-based system, for English–Spanish and English–Iraqi. Gao et al. [10] propose soft reordering constraints based on the source-side dependency structure in a hierarchical setting with improvements on the NIST Chinese–English task. Xie et al. [11] also work with source-side dependencies and store the reordering information for each head-dependent. They employ a dependency-to-string translation model and compare its performance to a state-of-the-art hierarchical system, on the NIST Chinese–English task. Quirk & Menezes [12] present a treelet translation system with dependency projection from source to target and tree-based decoding. ? X˜1 X˜1 and immigration and w"
2011.iwslt-papers.8,D11-1020,0,0.0556656,"the parsing time to quadratic complexity. The authors work on the NIST Chinese–English corpus and show significant improvements over the baseline. Bach et al. [9] rely on source-side dependency information for reordering information on the tree structure. Similar to lexicalized reordering models, the tree sub-structure is used to employ features in a phrase-based system, for English–Spanish and English–Iraqi. Gao et al. [10] propose soft reordering constraints based on the source-side dependency structure in a hierarchical setting with improvements on the NIST Chinese–English task. Xie et al. [11] also work with source-side dependencies and store the reordering information for each head-dependent. They employ a dependency-to-string translation model and compare its performance to a state-of-the-art hierarchical system, on the NIST Chinese–English task. Quirk & Menezes [12] present a treelet translation system with dependency projection from source to target and tree-based decoding. ? X˜1 X˜1 and immigration and were immigration Figure 2: Example of a well-defined merge (left) and an illdefined merge (right). A different method is to parse the (hopefully grammatically sound) training ma"
2011.iwslt-papers.8,J07-2003,0,0.202423,"earch space, and the information to be gained from dependency tree building during decoding. The application of a non-restrictive approach together with an integrated dependency LM scoring is a novel contribution which yields significant improvements for two large-scale translation tasks for the language pairs Chinese–English and German–French. 1. Introduction String-to-dependency hierarchical machine translation employs target-side dependency features to capture syntactically motivated relations between words even across longer distances. It is based on the hierarchical phrase-based paradigm [1] and implements enhancements that allow for an integration of knowledge obtained from dependency parses of the training material. Dependency trees over translation hypotheses are built on-the-fly during the decoding process from information gathered in the training phase and stored in the phrase table. A dependency language model can be applied to rate the quality of the constructed tree structures. In initial publications on the topic [2, 3], a restriction of the phrase inventory to a subset of phrases which meet certain validity conditions concerning the dependency relations is proposed. Phr"
2011.iwslt-papers.8,P08-1066,0,0.0718468,"ency features to capture syntactically motivated relations between words even across longer distances. It is based on the hierarchical phrase-based paradigm [1] and implements enhancements that allow for an integration of knowledge obtained from dependency parses of the training material. Dependency trees over translation hypotheses are built on-the-fly during the decoding process from information gathered in the training phase and stored in the phrase table. A dependency language model can be applied to rate the quality of the constructed tree structures. In initial publications on the topic [2, 3], a restriction of the phrase inventory to a subset of phrases which meet certain validity conditions concerning the dependency relations is proposed. Phrases with dependency structures that are not suitable for the construction of a well-formed dependency tree are excluded beforehand. Additional merging constraints apply during decoding. In later works [4, 5], heuristics are proposed that enable assembling of malformed dependency structures as well, thus permitting the utilization of the full phrase inventory of the standard hierarchical approach. Validity and tree well-formedness conditions"
2011.iwslt-papers.8,2010.amta-papers.8,1,0.923934,"the decoding process from information gathered in the training phase and stored in the phrase table. A dependency language model can be applied to rate the quality of the constructed tree structures. In initial publications on the topic [2, 3], a restriction of the phrase inventory to a subset of phrases which meet certain validity conditions concerning the dependency relations is proposed. Phrases with dependency structures that are not suitable for the construction of a well-formed dependency tree are excluded beforehand. Additional merging constraints apply during decoding. In later works [4, 5], heuristics are proposed that enable assembling of malformed dependency structures as well, thus permitting the utilization of the full phrase inventory of the standard hierarchical approach. Validity and tree well-formedness conditions are modeled in a soft way as features in the log-linear model. Here, the dependency language model is however included in an n-best reranking framework only. This paper aims at filling the gap by investigating stringto-dependency hierarchical translation with and without restrictions, and by comparing dependency LM reranking methods with dependency LM scoring"
2011.iwslt-papers.8,W10-1738,1,0.889266,"the n-best hypotheses industry merging ∼2 A in the textile Constructed Tree dependency language model features based on a dependency tree built during decoding China in the textile China Figure 6: Merging two phrases with one left and two right merging errors. The dependency pointers point into other directions as the parent-dependencies. pendency language model order, and the influence of features created during the dependency tree construction. Significance levels are annotated with (*) for p &lt; .1 and with (**) for p &lt; .05. We employ RWTH’s freely available machine translation toolkit Jane [14], a hierarchical phrase-based translation system comparable to David Chiang’s Hiero [1]. The baseline setup, which is kept constant for all experiments with the same language pair, consists of the following features: 4gram language model, phrase translation probabilities (target to source and source to target), word translation lexicons, word penalty, phrase penalty, binary markers for hierarchical phrases and generic glue rules. The word alignments have been computed based on the IBM Models with GIZA++ [15]. 5.1. Chinese–English Large parts of our experiments are carried out on the NIST Chine"
2011.iwslt-papers.8,P03-1054,0,0.00837328,"se penalty, binary markers for hierarchical phrases and generic glue rules. The word alignments have been computed based on the IBM Models with GIZA++ [15]. 5.1. Chinese–English Large parts of our experiments are carried out on the NIST Chinese–English task with around 3 million parallel training sentences and 81 million running words on the target side. The NIST 2006 evaluation set (nist06) is used as a development corpus, the NIST 2008 and 2005 sets (nist08, nist05) and a concatenation of the NIST 2002 and 2004 sets (nist0204) are used as test sets. We rely on the Stanford Dependency Parser [16] to create the dependency trees during training and reranking. The parser model was trained on the Wall Street Journal corpus. 5.1.1. Parsing Dependency Tree vs. Building During Decoding First, we wanted to check whether dependency tree construction during decoding is more reliable than obtaining depenTree Features penalty features for construction errors of the dependency tree built during decoding Combinations of these are inspected, too. The results in Table 2 suggest that both the dependency tree derived from parsing the n-best lists as well as the tree built during decoding comparably imp"
2011.iwslt-papers.8,P06-1055,0,0.0162674,"task since the grammar structure is quite different and additional linguistic knowledge often helps the system to improve over the baseline. To examine if we can also obtain improvements on other language pairs, we tested the setup that proved best on the NIST Chinese–English task also on the German–French language pair. We work on the German–French translation task as defined within the Quaero project. Our parallel training corpus consists of 2 million sentences. Since the Stanford dependency parser does not provide a pre-trained model to parse French, we used the Berkeley dependency parser [17] in251 stead. The translation results are presented in Table 7. While the methods show little impact on the eval set of 2010, the translation quality on the other test set significantly improves in both B LEU and T ER when applying tree building features and dependency LM directly in decoding. Even though the performance is not improved on all test sets for the German– French task, we still consider string-to-dependency extensions to be a valuable addition to hierarchical systems even for closer-related language pairs. 6. Conclusion We have shown that information derived from dependencies can"
2012.amta-papers.8,N06-1003,0,0.0296517,"two topics: pivot translation and lightly-supervised training. Many pivot translation approaches have been proposed in the past. The vast literature on pivot translation cannot be discussed in detail here due to space contraints. Wu and Wang (2009) and Utiyama and Isahara (2007) provide good overviews of the field. More recent publications are e.g. (Cettolo et al., 2011), (Leusch et al., 2010) and (Koehn et al., 2009), to mention some. The synthetic method (Wu and Wang, 2009) comes closest to what is done by us. We would like to particularly point to the work by Cohn and Lapata (2007) and by Callison-Burch et al. (2006). Cohn et al. adopt the pivot translation by triangulation method to improve existing baselines. This idea is quite similar to our pivot lightlysupervised training approach, which employs synthetic data. Callison-Burch et al. suggest an interesting paraphrasing technique for SMT that rests upon parallel data with a pivot language. The effect should de facto be comparable. Ueffing et al. (2007) introduced semi-supervised learning methods for the effective use of monolingual data in order to improve translation quality of SMT systems. Large-scale lightly-supervised training for SMT as we define"
2012.amta-papers.8,2011.eamt-1.34,0,0.0159469,"this translation step and the French side of the EnglishFrench parallel corpus constitute an unsupervised bitext which can be used as supplementary training material for our German→French system. 2 Related Work Our method combines techniques from two topics: pivot translation and lightly-supervised training. Many pivot translation approaches have been proposed in the past. The vast literature on pivot translation cannot be discussed in detail here due to space contraints. Wu and Wang (2009) and Utiyama and Isahara (2007) provide good overviews of the field. More recent publications are e.g. (Cettolo et al., 2011), (Leusch et al., 2010) and (Koehn et al., 2009), to mention some. The synthetic method (Wu and Wang, 2009) comes closest to what is done by us. We would like to particularly point to the work by Cohn and Lapata (2007) and by Callison-Burch et al. (2006). Cohn et al. adopt the pivot translation by triangulation method to improve existing baselines. This idea is quite similar to our pivot lightlysupervised training approach, which employs synthetic data. Callison-Burch et al. suggest an interesting paraphrasing technique for SMT that rests upon parallel data with a pivot language. The effect sh"
2012.amta-papers.8,P07-1092,0,0.0464944,"ethod combines techniques from two topics: pivot translation and lightly-supervised training. Many pivot translation approaches have been proposed in the past. The vast literature on pivot translation cannot be discussed in detail here due to space contraints. Wu and Wang (2009) and Utiyama and Isahara (2007) provide good overviews of the field. More recent publications are e.g. (Cettolo et al., 2011), (Leusch et al., 2010) and (Koehn et al., 2009), to mention some. The synthetic method (Wu and Wang, 2009) comes closest to what is done by us. We would like to particularly point to the work by Cohn and Lapata (2007) and by Callison-Burch et al. (2006). Cohn et al. adopt the pivot translation by triangulation method to improve existing baselines. This idea is quite similar to our pivot lightlysupervised training approach, which employs synthetic data. Callison-Burch et al. suggest an interesting paraphrasing technique for SMT that rests upon parallel data with a pivot language. The effect should de facto be comparable. Ueffing et al. (2007) introduced semi-supervised learning methods for the effective use of monolingual data in order to improve translation quality of SMT systems. Large-scale lightly-super"
2012.amta-papers.8,W07-0717,0,0.0244497,"ing the word alignments that are produced by the decoder during the generation of the unsupervised data and using GIZA++ (Och and Ney, 2003) word alignments performs roughly equally well. Lambert et al. also propose to make use of an automatically contructed dictionary which provides unobserved morphological forms of nouns, verbs or adjectives. They achieve a gain of about 0.5 points B LEU over a competitive baseline. Another technique we employ in our experiments is the combination of multiple phrase tables. Combining multiple phrase tables has e.g. been investigated for domain adaptation by Foster and Kuhn (2007) and Koehn and Schroeder (2007) before. Huck et al. (2011) combine phrase tables from human-generated data and from unsupervised data in the context of lightly-supervised training. 3 Lightly-Supervised Training In previous lightly-supervised training scenarios, the baseline source-to-target SMT system is being augmented with additional unsupervised parallel data that is produced by automatically translating either source language monolingual data to the target language or target language monolingual data to the source language. The former is typically done with the baseline system itself, the"
2012.amta-papers.8,W11-2145,0,0.0191725,"ith the frequency-based method described in (Koehn and Knight, 2003). We apply compound splitting to German text whenever German is the source language, but not for setups where German is the target language. The unsupervised data is produced by translating the English side of the English-French 109 corpus as provided for the translation task of the Workshop on Statistical Machine Translation (WMT).4 Data statistics are given in Table 2. Some noisy parts of the raw corpus have been removed beforehand by means of an SVM classifier in a fashion comparable to the filtering technique described by Herrmann et al. (2011). The English→German SMT system with which we translate the English side of the 109 corpus to German is trained with the English-German parallel resources that have been provided for the 2011 WMT shared translation task (constrained track). Statistics of the preprocessed corpus are given in Table 3. 6 Phrase-Based Translation System We apply a phrase-based translation (PBT) system which is an in-house implementation of the stateof-the-art decoder as described by Zens and Ney (2008). A standard set of models is used, comprising phrase translation probabilities and lexical translation probabilit"
2012.amta-papers.8,W11-2211,1,0.799755,"g the generation of the unsupervised data and using GIZA++ (Och and Ney, 2003) word alignments performs roughly equally well. Lambert et al. also propose to make use of an automatically contructed dictionary which provides unobserved morphological forms of nouns, verbs or adjectives. They achieve a gain of about 0.5 points B LEU over a competitive baseline. Another technique we employ in our experiments is the combination of multiple phrase tables. Combining multiple phrase tables has e.g. been investigated for domain adaptation by Foster and Kuhn (2007) and Koehn and Schroeder (2007) before. Huck et al. (2011) combine phrase tables from human-generated data and from unsupervised data in the context of lightly-supervised training. 3 Lightly-Supervised Training In previous lightly-supervised training scenarios, the baseline source-to-target SMT system is being augmented with additional unsupervised parallel data that is produced by automatically translating either source language monolingual data to the target language or target language monolingual data to the source language. The former is typically done with the baseline system itself, the latter with a reverse (”target-to-source”) system. The rev"
2012.amta-papers.8,E03-1076,0,0.130666,"llel training corpora we utilize for an empirical evaluation of pivot lightlysupervised training on a German→French translation task. The pivot language is English. To train the German→French baseline system, we use 2.0M sentence pairs that are partly taken from the Europarl corpus (Koehn, 2005) and have partly tried in our experiments. been collected within the Quaero project.3 Statistics of the preprocessed data can be found in the direct entry of Table 6 (first three lines). The preprocessing pipeline includes splitting of German compound words with the frequency-based method described in (Koehn and Knight, 2003). We apply compound splitting to German text whenever German is the source language, but not for setups where German is the target language. The unsupervised data is produced by translating the English side of the English-French 109 corpus as provided for the translation task of the Workshop on Statistical Machine Translation (WMT).4 Data statistics are given in Table 2. Some noisy parts of the raw corpus have been removed beforehand by means of an SVM classifier in a fashion comparable to the filtering technique described by Herrmann et al. (2011). The English→German SMT system with which we"
2012.amta-papers.8,W07-0733,0,0.0322016,"t are produced by the decoder during the generation of the unsupervised data and using GIZA++ (Och and Ney, 2003) word alignments performs roughly equally well. Lambert et al. also propose to make use of an automatically contructed dictionary which provides unobserved morphological forms of nouns, verbs or adjectives. They achieve a gain of about 0.5 points B LEU over a competitive baseline. Another technique we employ in our experiments is the combination of multiple phrase tables. Combining multiple phrase tables has e.g. been investigated for domain adaptation by Foster and Kuhn (2007) and Koehn and Schroeder (2007) before. Huck et al. (2011) combine phrase tables from human-generated data and from unsupervised data in the context of lightly-supervised training. 3 Lightly-Supervised Training In previous lightly-supervised training scenarios, the baseline source-to-target SMT system is being augmented with additional unsupervised parallel data that is produced by automatically translating either source language monolingual data to the target language or target language monolingual data to the source language. The former is typically done with the baseline system itself, the latter with a reverse (”target-"
2012.amta-papers.8,P07-2045,0,0.00569146,"ervised training approach, which employs synthetic data. Callison-Burch et al. suggest an interesting paraphrasing technique for SMT that rests upon parallel data with a pivot language. The effect should de facto be comparable. Ueffing et al. (2007) introduced semi-supervised learning methods for the effective use of monolingual data in order to improve translation quality of SMT systems. Large-scale lightly-supervised training for SMT as we define it in this paper has been first carried out by Schwenk (2008). Schwenk translates a large amount of monolingual French data with an initial Moses (Koehn et al., 2007) baseline system into English. He uses the resulting unsupervised bitexts as additional training corpora to improve the baseline French→English system. With lightly-supervised training, Schwenk achieves improvements of around one point B LEU over the baseline. In a later work (Schwenk and Senellart, 2009) he applies the same method for translation model adaptation on an Arabic→French task with gains of up to 3.5 points B LEU. Li et al. (2011) present an approach that is very similar to lightly-supervised training. They conduct their experiments with a hierarchical phrase-based system and trans"
2012.amta-papers.8,2009.mtsummit-papers.7,0,0.125307,"nguage and the target language. Pivot translation employs such bitext to bridge from source to target across the pivot language, thus effectively providing source-totarget translation (Utiyama and Isahara, 2007; Wu and Wang, 2009). The method may also be advantageous in cases where many translation systems between a large number of languages are to be built. To save time and cost, it may be convenient to resort to a pivot approach and to set up 2(n − 1) systems between each of n − 1 languages and a common pivot language, instead of setting up n(n − 1) systems between all pairs of n languages (Koehn et al., 2009). We utilize the pivot translation paradigm with a different motivation in this work. We investigate a source-target language combination—German and French—that does not suffer from a lack of resources. A noticeable amount of parallel training data and monolingual target language data exists for this language pair, from which we build a well-performing German→French baseline SMT system. We however argue that our system could be improved if we were able to also deploy the extensive amount of parallel resources of both of these languages with third languages, in particular with English. English-"
2012.amta-papers.8,2005.mtsummit-papers.11,0,0.0705455,"applied to the German target-side data. texts, the source→target system does not only learn from the contents of the corpus the unsupervised data originates from, but also from bilingual information that is represented in the translation model of the pivot→source system. 5 Parallel Resources We now specify the parallel training corpora we utilize for an empirical evaluation of pivot lightlysupervised training on a German→French translation task. The pivot language is English. To train the German→French baseline system, we use 2.0M sentence pairs that are partly taken from the Europarl corpus (Koehn, 2005) and have partly tried in our experiments. been collected within the Quaero project.3 Statistics of the preprocessed data can be found in the direct entry of Table 6 (first three lines). The preprocessing pipeline includes splitting of German compound words with the frequency-based method described in (Koehn and Knight, 2003). We apply compound splitting to German text whenever German is the source language, but not for setups where German is the target language. The unsupervised data is produced by translating the English side of the English-French 109 corpus as provided for the translation t"
2012.amta-papers.8,W11-2132,0,0.126494,"d bitexts as additional training corpora to improve the baseline French→English system. With lightly-supervised training, Schwenk achieves improvements of around one point B LEU over the baseline. In a later work (Schwenk and Senellart, 2009) he applies the same method for translation model adaptation on an Arabic→French task with gains of up to 3.5 points B LEU. Li et al. (2011) present an approach that is very similar to lightly-supervised training. They conduct their experiments with a hierarchical phrase-based system and translate monolingual target language data into the source language. Lambert et al. (2011) investigate a large variety of lightly-supervised training settings on the French-English language pair in both directions. They draw some interesting conclusions, in particular that it is better to add automatically translated texts to the translation model training data which have been translated from the target to the source language (instead of from the source to the target language), and that using the word alignments that are produced by the decoder during the generation of the unsupervised data and using GIZA++ (Och and Ney, 2003) word alignments performs roughly equally well. Lambert"
2012.amta-papers.8,2010.iwslt-papers.12,1,0.812991,"nd the French side of the EnglishFrench parallel corpus constitute an unsupervised bitext which can be used as supplementary training material for our German→French system. 2 Related Work Our method combines techniques from two topics: pivot translation and lightly-supervised training. Many pivot translation approaches have been proposed in the past. The vast literature on pivot translation cannot be discussed in detail here due to space contraints. Wu and Wang (2009) and Utiyama and Isahara (2007) provide good overviews of the field. More recent publications are e.g. (Cettolo et al., 2011), (Leusch et al., 2010) and (Koehn et al., 2009), to mention some. The synthetic method (Wu and Wang, 2009) comes closest to what is done by us. We would like to particularly point to the work by Cohn and Lapata (2007) and by Callison-Burch et al. (2006). Cohn et al. adopt the pivot translation by triangulation method to improve existing baselines. This idea is quite similar to our pivot lightlysupervised training approach, which employs synthetic data. Callison-Burch et al. suggest an interesting paraphrasing technique for SMT that rests upon parallel data with a pivot language. The effect should de facto be compar"
2012.amta-papers.8,D11-1085,0,0.0185183,"ine it in this paper has been first carried out by Schwenk (2008). Schwenk translates a large amount of monolingual French data with an initial Moses (Koehn et al., 2007) baseline system into English. He uses the resulting unsupervised bitexts as additional training corpora to improve the baseline French→English system. With lightly-supervised training, Schwenk achieves improvements of around one point B LEU over the baseline. In a later work (Schwenk and Senellart, 2009) he applies the same method for translation model adaptation on an Arabic→French task with gains of up to 3.5 points B LEU. Li et al. (2011) present an approach that is very similar to lightly-supervised training. They conduct their experiments with a hierarchical phrase-based system and translate monolingual target language data into the source language. Lambert et al. (2011) investigate a large variety of lightly-supervised training settings on the French-English language pair in both directions. They draw some interesting conclusions, in particular that it is better to add automatically translated texts to the translation model training data which have been translated from the target to the source language (instead of from the"
2012.amta-papers.8,J03-1002,1,0.0180522,"ngual target language data into the source language. Lambert et al. (2011) investigate a large variety of lightly-supervised training settings on the French-English language pair in both directions. They draw some interesting conclusions, in particular that it is better to add automatically translated texts to the translation model training data which have been translated from the target to the source language (instead of from the source to the target language), and that using the word alignments that are produced by the decoder during the generation of the unsupervised data and using GIZA++ (Och and Ney, 2003) word alignments performs roughly equally well. Lambert et al. also propose to make use of an automatically contructed dictionary which provides unobserved morphological forms of nouns, verbs or adjectives. They achieve a gain of about 0.5 points B LEU over a competitive baseline. Another technique we employ in our experiments is the combination of multiple phrase tables. Combining multiple phrase tables has e.g. been investigated for domain adaptation by Foster and Kuhn (2007) and Koehn and Schroeder (2007) before. Huck et al. (2011) combine phrase tables from human-generated data and from un"
2012.amta-papers.8,P02-1040,0,0.0905698,"t set. B LEU and T ER are given in percentage. We train alignments in both directions and symmetrize them according to the refined method that was suggested by Och and Ney (2003). 7 Experiments In our experiments, we work with the standard WMT newstest sets. These sets are multi-parallel corpora. Each of the sets exists in a version in each of the three languages that are of relevance to us: German, French, English. We employ newstest2009 as development set in all setups; newstest2008, newstest2010 and newstest2011 are heldout sets and used for testing. We evaluate in truecase with the B LEU (Papineni et al., 2002) and T ER (Snover et al., 2006) measures on a single reference translation. 7.1 Systems for Producing Unsupervised Data We first measure the translation performance of two direct translation systems, a French→German system that we run on the French 109 data to produce pivot unsupervised data, and an English→German system that we run on the English 109 data to produce data for lightly-supervised training without pivot language for comparison with the pivot approach. French→German The French→German system is based on the parallel data from Table 1. Translation results are shown in Table 4. Engli"
2012.amta-papers.8,2009.mtsummit-posters.17,0,0.0630298,"the effective use of monolingual data in order to improve translation quality of SMT systems. Large-scale lightly-supervised training for SMT as we define it in this paper has been first carried out by Schwenk (2008). Schwenk translates a large amount of monolingual French data with an initial Moses (Koehn et al., 2007) baseline system into English. He uses the resulting unsupervised bitexts as additional training corpora to improve the baseline French→English system. With lightly-supervised training, Schwenk achieves improvements of around one point B LEU over the baseline. In a later work (Schwenk and Senellart, 2009) he applies the same method for translation model adaptation on an Arabic→French task with gains of up to 3.5 points B LEU. Li et al. (2011) present an approach that is very similar to lightly-supervised training. They conduct their experiments with a hierarchical phrase-based system and translate monolingual target language data into the source language. Lambert et al. (2011) investigate a large variety of lightly-supervised training settings on the French-English language pair in both directions. They draw some interesting conclusions, in particular that it is better to add automatically tra"
2012.amta-papers.8,2008.iwslt-papers.6,0,0.246176,"iangulation method to improve existing baselines. This idea is quite similar to our pivot lightlysupervised training approach, which employs synthetic data. Callison-Burch et al. suggest an interesting paraphrasing technique for SMT that rests upon parallel data with a pivot language. The effect should de facto be comparable. Ueffing et al. (2007) introduced semi-supervised learning methods for the effective use of monolingual data in order to improve translation quality of SMT systems. Large-scale lightly-supervised training for SMT as we define it in this paper has been first carried out by Schwenk (2008). Schwenk translates a large amount of monolingual French data with an initial Moses (Koehn et al., 2007) baseline system into English. He uses the resulting unsupervised bitexts as additional training corpora to improve the baseline French→English system. With lightly-supervised training, Schwenk achieves improvements of around one point B LEU over the baseline. In a later work (Schwenk and Senellart, 2009) he applies the same method for translation model adaptation on an Arabic→French task with gains of up to 3.5 points B LEU. Li et al. (2011) present an approach that is very similar to ligh"
2012.amta-papers.8,2006.amta-papers.25,0,0.0168824,"n percentage. We train alignments in both directions and symmetrize them according to the refined method that was suggested by Och and Ney (2003). 7 Experiments In our experiments, we work with the standard WMT newstest sets. These sets are multi-parallel corpora. Each of the sets exists in a version in each of the three languages that are of relevance to us: German, French, English. We employ newstest2009 as development set in all setups; newstest2008, newstest2010 and newstest2011 are heldout sets and used for testing. We evaluate in truecase with the B LEU (Papineni et al., 2002) and T ER (Snover et al., 2006) measures on a single reference translation. 7.1 Systems for Producing Unsupervised Data We first measure the translation performance of two direct translation systems, a French→German system that we run on the French 109 data to produce pivot unsupervised data, and an English→German system that we run on the English 109 data to produce data for lightly-supervised training without pivot language for comparison with the pivot approach. French→German The French→German system is based on the parallel data from Table 1. Translation results are shown in Table 4. English→German The English→German sy"
2012.amta-papers.8,P07-1004,0,0.0220326,"Koehn et al., 2009), to mention some. The synthetic method (Wu and Wang, 2009) comes closest to what is done by us. We would like to particularly point to the work by Cohn and Lapata (2007) and by Callison-Burch et al. (2006). Cohn et al. adopt the pivot translation by triangulation method to improve existing baselines. This idea is quite similar to our pivot lightlysupervised training approach, which employs synthetic data. Callison-Burch et al. suggest an interesting paraphrasing technique for SMT that rests upon parallel data with a pivot language. The effect should de facto be comparable. Ueffing et al. (2007) introduced semi-supervised learning methods for the effective use of monolingual data in order to improve translation quality of SMT systems. Large-scale lightly-supervised training for SMT as we define it in this paper has been first carried out by Schwenk (2008). Schwenk translates a large amount of monolingual French data with an initial Moses (Koehn et al., 2007) baseline system into English. He uses the resulting unsupervised bitexts as additional training corpora to improve the baseline French→English system. With lightly-supervised training, Schwenk achieves improvements of around one"
2012.amta-papers.8,N07-1061,0,0.121205,"atistical machine translation are typically applied in scenarios where no bilingual resources to build a translation system between a source and a target language exist. For many under-resourced language pairs, no humangenerated parallel data of source and target texts is available. There may however still be bitexts at hand between both the source language and a third pivot language as well as the same pivot language and the target language. Pivot translation employs such bitext to bridge from source to target across the pivot language, thus effectively providing source-totarget translation (Utiyama and Isahara, 2007; Wu and Wang, 2009). The method may also be advantageous in cases where many translation systems between a large number of languages are to be built. To save time and cost, it may be convenient to resort to a pivot approach and to set up 2(n − 1) systems between each of n − 1 languages and a common pivot language, instead of setting up n(n − 1) systems between all pairs of n languages (Koehn et al., 2009). We utilize the pivot translation paradigm with a different motivation in this work. We investigate a source-target language combination—German and French—that does not suffer from a lack of"
2012.amta-papers.8,P09-1018,0,0.336882,"on are typically applied in scenarios where no bilingual resources to build a translation system between a source and a target language exist. For many under-resourced language pairs, no humangenerated parallel data of source and target texts is available. There may however still be bitexts at hand between both the source language and a third pivot language as well as the same pivot language and the target language. Pivot translation employs such bitext to bridge from source to target across the pivot language, thus effectively providing source-totarget translation (Utiyama and Isahara, 2007; Wu and Wang, 2009). The method may also be advantageous in cases where many translation systems between a large number of languages are to be built. To save time and cost, it may be convenient to resort to a pivot approach and to set up 2(n − 1) systems between each of n − 1 languages and a common pivot language, instead of setting up n(n − 1) systems between all pairs of n languages (Koehn et al., 2009). We utilize the pivot translation paradigm with a different motivation in this work. We investigate a source-target language combination—German and French—that does not suffer from a lack of resources. A notice"
2012.amta-papers.8,2008.iwslt-papers.8,1,0.779267,"moved beforehand by means of an SVM classifier in a fashion comparable to the filtering technique described by Herrmann et al. (2011). The English→German SMT system with which we translate the English side of the 109 corpus to German is trained with the English-German parallel resources that have been provided for the 2011 WMT shared translation task (constrained track). Statistics of the preprocessed corpus are given in Table 3. 6 Phrase-Based Translation System We apply a phrase-based translation (PBT) system which is an in-house implementation of the stateof-the-art decoder as described by Zens and Ney (2008). A standard set of models is used, comprising phrase translation probabilities and lexical translation probabilities in both directions, word and phrase penalty, a distance-based distortion model, an ngram target language model and three simple countbased binary features. Parameter weights are optimized with the downhill simplex algorithm (Nelder and Mead, 1965) on the word graph. The language models in all our setups are 4grams with modified Kneser-Ney smoothing and are trained with the SRILM toolkit (Stolcke, 2002) on large collections of monolingual data. Word alignments are produced with"
2012.eamt-1.66,D10-1054,0,\N,Missing
2012.eamt-1.66,D11-1079,0,\N,Missing
2012.eamt-1.66,E09-1044,0,\N,Missing
2012.eamt-1.66,N04-4026,0,\N,Missing
2012.eamt-1.66,C04-1030,1,\N,Missing
2012.eamt-1.66,D08-1089,0,\N,Missing
2012.eamt-1.66,W10-1738,1,\N,Missing
2012.eamt-1.66,J10-3008,0,\N,Missing
2012.eamt-1.66,P07-2045,0,\N,Missing
2012.eamt-1.66,N09-1049,0,\N,Missing
2012.eamt-1.66,P05-1033,0,\N,Missing
2012.eamt-1.66,J03-1002,1,\N,Missing
2012.eamt-1.66,W06-3108,1,\N,Missing
2012.eamt-1.66,P07-1019,0,\N,Missing
2012.eamt-1.66,2011.eamt-1.37,1,\N,Missing
2012.iwslt-evaluation.7,popovic-ney-2006-pos,1,\N,Missing
2012.iwslt-evaluation.7,N04-4026,0,\N,Missing
2012.iwslt-evaluation.7,D09-1022,1,\N,Missing
2012.iwslt-evaluation.7,J93-2003,0,\N,Missing
2012.iwslt-evaluation.7,E03-1076,0,\N,Missing
2012.iwslt-evaluation.7,N04-4038,0,\N,Missing
2012.iwslt-evaluation.7,C02-1050,0,\N,Missing
2012.iwslt-evaluation.7,P02-1040,0,\N,Missing
2012.iwslt-evaluation.7,W10-1738,1,\N,Missing
2012.iwslt-evaluation.7,P12-3029,0,\N,Missing
2012.iwslt-evaluation.7,J10-3008,0,\N,Missing
2012.iwslt-evaluation.7,2010.iwslt-keynotes.2,0,\N,Missing
2012.iwslt-evaluation.7,P10-2041,0,\N,Missing
2012.iwslt-evaluation.7,P10-1049,1,\N,Missing
2012.iwslt-evaluation.7,P07-2045,0,\N,Missing
2012.iwslt-evaluation.7,P08-2030,0,\N,Missing
2012.iwslt-evaluation.7,W07-0734,0,\N,Missing
2012.iwslt-evaluation.7,2008.iwslt-papers.8,1,\N,Missing
2012.iwslt-evaluation.7,J03-1002,1,\N,Missing
2012.iwslt-evaluation.7,W06-3108,1,\N,Missing
2012.iwslt-evaluation.7,D09-1117,0,\N,Missing
2012.iwslt-evaluation.7,P07-1019,0,\N,Missing
2012.iwslt-evaluation.7,C12-3061,1,\N,Missing
2012.iwslt-evaluation.7,W06-3103,1,\N,Missing
2012.iwslt-evaluation.7,2012.iwslt-papers.18,1,\N,Missing
2012.iwslt-evaluation.7,C12-2091,1,\N,Missing
2012.iwslt-evaluation.7,2010.iwslt-papers.15,1,\N,Missing
2012.iwslt-evaluation.7,2006.iwslt-papers.1,1,\N,Missing
2012.iwslt-evaluation.7,J07-2003,0,\N,Missing
2012.iwslt-evaluation.7,2002.tmi-tutorials.2,0,\N,Missing
2012.iwslt-evaluation.7,P03-1021,0,\N,Missing
2012.iwslt-evaluation.7,2012.eamt-1.60,0,\N,Missing
2013.iwslt-evaluation.16,2012.eamt-1.60,1,0.8976,"neous speech and heterogeneous topics and styles. The 1 http://www.eu-bridge.eu task is open domain, with a wide range of heavily dissimilar subjects and jargons across talks. IWSLT subdivides the task and separately evaluates automatic transcription of talks from audio to text, speech translation of talks from audio, and text translation of talks as three different tracks [3, 4]. The training data is constrained to the corpora specified by the organizers. The supplied list of corpora comprises a large amount of publicly available monolingual and parallel training data, though, including WIT3 [5], Europarl [6], MultiUN [7], the English and French Gigaword corpora as provided by the Linguistic Data Consortium [8], and the News Crawl, 109 and News Commentary corpora from the WMT shared task training data [9]. For the two “official” language pairs [1] for translation at IWSLT 2013, English→French and German→English, these resources allow for building of systems with state-of-the-art performance by participants. The EU-BRIDGE project is funded by the European Union under the Seventh Framework Programme (FP7) [10] and brings together several project partners who have each previously been v"
2013.iwslt-evaluation.16,2005.mtsummit-papers.11,1,0.078384,"nd heterogeneous topics and styles. The 1 http://www.eu-bridge.eu task is open domain, with a wide range of heavily dissimilar subjects and jargons across talks. IWSLT subdivides the task and separately evaluates automatic transcription of talks from audio to text, speech translation of talks from audio, and text translation of talks as three different tracks [3, 4]. The training data is constrained to the corpora specified by the organizers. The supplied list of corpora comprises a large amount of publicly available monolingual and parallel training data, though, including WIT3 [5], Europarl [6], MultiUN [7], the English and French Gigaword corpora as provided by the Linguistic Data Consortium [8], and the News Crawl, 109 and News Commentary corpora from the WMT shared task training data [9]. For the two “official” language pairs [1] for translation at IWSLT 2013, English→French and German→English, these resources allow for building of systems with state-of-the-art performance by participants. The EU-BRIDGE project is funded by the European Union under the Seventh Framework Programme (FP7) [10] and brings together several project partners who have each previously been very successful"
2013.iwslt-evaluation.16,eisele-chen-2010-multiun,0,0.0452925,"ous topics and styles. The 1 http://www.eu-bridge.eu task is open domain, with a wide range of heavily dissimilar subjects and jargons across talks. IWSLT subdivides the task and separately evaluates automatic transcription of talks from audio to text, speech translation of talks from audio, and text translation of talks as three different tracks [3, 4]. The training data is constrained to the corpora specified by the organizers. The supplied list of corpora comprises a large amount of publicly available monolingual and parallel training data, though, including WIT3 [5], Europarl [6], MultiUN [7], the English and French Gigaword corpora as provided by the Linguistic Data Consortium [8], and the News Crawl, 109 and News Commentary corpora from the WMT shared task training data [9]. For the two “official” language pairs [1] for translation at IWSLT 2013, English→French and German→English, these resources allow for building of systems with state-of-the-art performance by participants. The EU-BRIDGE project is funded by the European Union under the Seventh Framework Programme (FP7) [10] and brings together several project partners who have each previously been very successful in contribut"
2013.iwslt-evaluation.16,E06-1005,1,0.921596,"e-scale evaluation campaigns like IWSLT and WMT in recent years, thereby demonstrating their ability to continuously enhance their systems and promoting progress in machine translation. Machine translation research within EU-BRIDGE has a strong focus on translation of spoken language. The IWSLT TED talks task constitutes an interesting framework for empirical testing of some of the systems for spoken language translation which are developed as part of the project. The work described here is an attempt to attain translation quality beyond strong single system performance via system combination [11]. Similar cooperative approaches based on system combination have proven to be valuable for machine translation in other projects, e.g. in the Quaero programme [12, 13]. Within EU-BRIDGE, we built combined system setups for text translation of talks from English to French as well as from German to English. We found that the combined translation engines of RWTH, UEDIN, KIT, and FBK systems are very effective. In the rest of the paper we will give some insight into the technology behind the combined engines which have been used to produce the joint EU-BRIDGE submission to the IWSLT 2013 MT track"
2013.iwslt-evaluation.16,P02-1040,0,0.0892795,"-BRIDGE submission to the IWSLT 2013 MT track. The remainder of the paper is structured as follows: We first describe the individual English→French and German→English systems by RWTH Aachen University (Section 2), the University of Edinburgh (Section 3), Karlsruhe Institute of Technology (Section 4), and Fondazione Bruno Kessler (Section 5), respectively. We then present the techniques for machine translation system combination which have been employed to obtain consensus translations from the outputs of the individual systems of the project partners (Section 6). Experimental results in B LEU [14] and T ER [15] are given in Section 7. A brief error analysis on selected examples from the test data has been conducted which we discuss in Section 8. We finally conclude the paper with Section 9. 2. RWTH Aachen University RWTH applied both the phrase-based (RWTH scss) and the hierarchical (RWTH hiero) decoder implemented in RWTH’s publicly available translation toolkit Jane [16, 17, 18, 19]. The model weights of all systems were tuned with standard Minimum Error Rate Training [20] on the provided dev2010 set. RWTH used B LEU as optimization objective. Language models were created with the SR"
2013.iwslt-evaluation.16,2006.amta-papers.25,0,0.15922,"sion to the IWSLT 2013 MT track. The remainder of the paper is structured as follows: We first describe the individual English→French and German→English systems by RWTH Aachen University (Section 2), the University of Edinburgh (Section 3), Karlsruhe Institute of Technology (Section 4), and Fondazione Bruno Kessler (Section 5), respectively. We then present the techniques for machine translation system combination which have been employed to obtain consensus translations from the outputs of the individual systems of the project partners (Section 6). Experimental results in B LEU [14] and T ER [15] are given in Section 7. A brief error analysis on selected examples from the test data has been conducted which we discuss in Section 8. We finally conclude the paper with Section 9. 2. RWTH Aachen University RWTH applied both the phrase-based (RWTH scss) and the hierarchical (RWTH hiero) decoder implemented in RWTH’s publicly available translation toolkit Jane [16, 17, 18, 19]. The model weights of all systems were tuned with standard Minimum Error Rate Training [20] on the provided dev2010 set. RWTH used B LEU as optimization objective. Language models were created with the SRILM toolkit [2"
2013.iwslt-evaluation.16,W10-1738,1,0.880309,"iques for machine translation system combination which have been employed to obtain consensus translations from the outputs of the individual systems of the project partners (Section 6). Experimental results in B LEU [14] and T ER [15] are given in Section 7. A brief error analysis on selected examples from the test data has been conducted which we discuss in Section 8. We finally conclude the paper with Section 9. 2. RWTH Aachen University RWTH applied both the phrase-based (RWTH scss) and the hierarchical (RWTH hiero) decoder implemented in RWTH’s publicly available translation toolkit Jane [16, 17, 18, 19]. The model weights of all systems were tuned with standard Minimum Error Rate Training [20] on the provided dev2010 set. RWTH used B LEU as optimization objective. Language models were created with the SRILM toolkit [21]. All RWTH systems include the standard set of models provided by Jane. For English→French, the final setups for RWTH scss and RWTH hiero differ in the amount of training data and in the choice of models. For the English→French hierarchical setup the bilingual data was limited to the in-domain WIT3 data, News Commentary, Europarl, and Common Crawl corpora. The word alignment w"
2013.iwslt-evaluation.16,popovic-ney-2006-pos,1,0.929216,"ll available parallel data and trained a word alignment with GIZA++ [24]. The same language model as in the hierarchical setup was used. RWTH applied the following supplementary features for the phrase-based system: a lexicalized reordering model [25], a discriminative word lexicon [26], a 7-gram word class language model [27], a continuous space language model [28], and a second translation model from the WIT3 portion of the training data only. For German→English, RWTH decompounded the German source in a preprocessing step [29] and applied partof-speech-based long-range verb reordering rules [30]. Both systems RWTH scss and RWTH hiero rest upon all available bilingual data and word alignment obtained with GIZA++. A language model was trained on the target side of all available bilingual data plus 12 of the Shuffled News corpus and 1 4 of the English Gigaword v3 corpus, resulting in a total of 1.7 billion running words. In both German→English systems, RWTH applied a more sophisticated discriminative phrase training method. Similar to [31], a gradient-based method is used to optimize a maximum expected B LEU objective, for which we define B LEU on the sentence level with smoothed 3-gram"
2013.iwslt-evaluation.16,P03-1021,0,0.129032,"ns from the outputs of the individual systems of the project partners (Section 6). Experimental results in B LEU [14] and T ER [15] are given in Section 7. A brief error analysis on selected examples from the test data has been conducted which we discuss in Section 8. We finally conclude the paper with Section 9. 2. RWTH Aachen University RWTH applied both the phrase-based (RWTH scss) and the hierarchical (RWTH hiero) decoder implemented in RWTH’s publicly available translation toolkit Jane [16, 17, 18, 19]. The model weights of all systems were tuned with standard Minimum Error Rate Training [20] on the provided dev2010 set. RWTH used B LEU as optimization objective. Language models were created with the SRILM toolkit [21]. All RWTH systems include the standard set of models provided by Jane. For English→French, the final setups for RWTH scss and RWTH hiero differ in the amount of training data and in the choice of models. For the English→French hierarchical setup the bilingual data was limited to the in-domain WIT3 data, News Commentary, Europarl, and Common Crawl corpora. The word alignment was created with fast align [22]. A language model was trained on the target side of all avai"
2013.iwslt-evaluation.16,P12-1031,0,0.10415,"For German→English, RWTH decompounded the German source in a preprocessing step [29] and applied partof-speech-based long-range verb reordering rules [30]. Both systems RWTH scss and RWTH hiero rest upon all available bilingual data and word alignment obtained with GIZA++. A language model was trained on the target side of all available bilingual data plus 12 of the Shuffled News corpus and 1 4 of the English Gigaword v3 corpus, resulting in a total of 1.7 billion running words. In both German→English systems, RWTH applied a more sophisticated discriminative phrase training method. Similar to [31], a gradient-based method is used to optimize a maximum expected B LEU objective, for which we define B LEU on the sentence level with smoothed 3-gram and 4gram precisions. RWTH performed discriminative training on the WIT3 portion of the training data. The German→English phrase-based system was furthermore improved by a lexicalized reordering model and 7-gram word class language model. RWTH finally applied domain adaptation by adding a second translation model to the decoder which was trained on the WIT3 portion of the data only. This second translation model was likewise improved with discri"
2013.iwslt-evaluation.16,P10-2041,0,0.0805135,"setups for RWTH scss and RWTH hiero differ in the amount of training data and in the choice of models. For the English→French hierarchical setup the bilingual data was limited to the in-domain WIT3 data, News Commentary, Europarl, and Common Crawl corpora. The word alignment was created with fast align [22]. A language model was trained on the target side of all available bilingual data plus 12 of the Shuffled News corpus and 41 of the French Gigaword Second Edition corpus. The monolingual data selection for using only parts of the corpora is based on cross-entropy difference as described in [23]. The hierarchical system was extended with a second translation model. The additional translation model was trained on the WIT3 portion of the training data only. For the English→French phrase-based setup, RWTH utilized all available parallel data and trained a word alignment with GIZA++ [24]. The same language model as in the hierarchical setup was used. RWTH applied the following supplementary features for the phrase-based system: a lexicalized reordering model [25], a discriminative word lexicon [26], a 7-gram word class language model [27], a continuous space language model [28], and a se"
2013.iwslt-evaluation.16,D08-1089,0,0.117877,"orpus. The monolingual data selection for using only parts of the corpora is based on cross-entropy difference as described in [23]. The hierarchical system was extended with a second translation model. The additional translation model was trained on the WIT3 portion of the training data only. For the English→French phrase-based setup, RWTH utilized all available parallel data and trained a word alignment with GIZA++ [24]. The same language model as in the hierarchical setup was used. RWTH applied the following supplementary features for the phrase-based system: a lexicalized reordering model [25], a discriminative word lexicon [26], a 7-gram word class language model [27], a continuous space language model [28], and a second translation model from the WIT3 portion of the training data only. For German→English, RWTH decompounded the German source in a preprocessing step [29] and applied partof-speech-based long-range verb reordering rules [30]. Both systems RWTH scss and RWTH hiero rest upon all available bilingual data and word alignment obtained with GIZA++. A language model was trained on the target side of all available bilingual data plus 12 of the Shuffled News corpus and 1 4 of"
2013.iwslt-evaluation.16,P07-2045,1,0.0125349,"EU on the sentence level with smoothed 3-gram and 4gram precisions. RWTH performed discriminative training on the WIT3 portion of the training data. The German→English phrase-based system was furthermore improved by a lexicalized reordering model and 7-gram word class language model. RWTH finally applied domain adaptation by adding a second translation model to the decoder which was trained on the WIT3 portion of the data only. This second translation model was likewise improved with discriminative phrase training. 3. University of Edinburgh UEDIN’s systems were trained using the Moses system [32], replicating the settings described in [33] developed for the 2013 Workshop on Statistical Machine Translation. The characteristics of the system include: a maximum sentence length of 80, grow-diag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM [34] used at runtime, a lexically-driven 5-gram operation sequence model [35] with four additional supportive features (two gap-based penalties, one distance-based feature and one deletion penalty), msdbidirectional-fe lexicalized reordering, sparse lexical and domain features [36], a"
2013.iwslt-evaluation.16,W13-2212,1,0.868834,"m and 4gram precisions. RWTH performed discriminative training on the WIT3 portion of the training data. The German→English phrase-based system was furthermore improved by a lexicalized reordering model and 7-gram word class language model. RWTH finally applied domain adaptation by adding a second translation model to the decoder which was trained on the WIT3 portion of the data only. This second translation model was likewise improved with discriminative phrase training. 3. University of Edinburgh UEDIN’s systems were trained using the Moses system [32], replicating the settings described in [33] developed for the 2013 Workshop on Statistical Machine Translation. The characteristics of the system include: a maximum sentence length of 80, grow-diag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM [34] used at runtime, a lexically-driven 5-gram operation sequence model [35] with four additional supportive features (two gap-based penalties, one distance-based feature and one deletion penalty), msdbidirectional-fe lexicalized reordering, sparse lexical and domain features [36], a distortion limit of 6, 100-best translation"
2013.iwslt-evaluation.16,W11-2123,0,0.0545914,"tion by adding a second translation model to the decoder which was trained on the WIT3 portion of the data only. This second translation model was likewise improved with discriminative phrase training. 3. University of Edinburgh UEDIN’s systems were trained using the Moses system [32], replicating the settings described in [33] developed for the 2013 Workshop on Statistical Machine Translation. The characteristics of the system include: a maximum sentence length of 80, grow-diag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM [34] used at runtime, a lexically-driven 5-gram operation sequence model [35] with four additional supportive features (two gap-based penalties, one distance-based feature and one deletion penalty), msdbidirectional-fe lexicalized reordering, sparse lexical and domain features [36], a distortion limit of 6, 100-best translation options, minimum Bayes risk decoding [37], cube pruning [38] with a stack size of 1000 during tuning and 5000 during testing and the no-reordering-over-punctuation heuristic. UEDIN used the compact phrase table representation by [39]. For English→German, UEDIN used a sequen"
2013.iwslt-evaluation.16,P11-1105,1,0.916011,"d on the WIT3 portion of the data only. This second translation model was likewise improved with discriminative phrase training. 3. University of Edinburgh UEDIN’s systems were trained using the Moses system [32], replicating the settings described in [33] developed for the 2013 Workshop on Statistical Machine Translation. The characteristics of the system include: a maximum sentence length of 80, grow-diag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM [34] used at runtime, a lexically-driven 5-gram operation sequence model [35] with four additional supportive features (two gap-based penalties, one distance-based feature and one deletion penalty), msdbidirectional-fe lexicalized reordering, sparse lexical and domain features [36], a distortion limit of 6, 100-best translation options, minimum Bayes risk decoding [37], cube pruning [38] with a stack size of 1000 during tuning and 5000 during testing and the no-reordering-over-punctuation heuristic. UEDIN used the compact phrase table representation by [39]. For English→German, UEDIN used a sequence model over morphological tags. The UEDIN systems were tuned on the dev"
2013.iwslt-evaluation.16,D09-1022,1,0.892821,"n for using only parts of the corpora is based on cross-entropy difference as described in [23]. The hierarchical system was extended with a second translation model. The additional translation model was trained on the WIT3 portion of the training data only. For the English→French phrase-based setup, RWTH utilized all available parallel data and trained a word alignment with GIZA++ [24]. The same language model as in the hierarchical setup was used. RWTH applied the following supplementary features for the phrase-based system: a lexicalized reordering model [25], a discriminative word lexicon [26], a 7-gram word class language model [27], a continuous space language model [28], and a second translation model from the WIT3 portion of the training data only. For German→English, RWTH decompounded the German source in a preprocessing step [29] and applied partof-speech-based long-range verb reordering rules [30]. Both systems RWTH scss and RWTH hiero rest upon all available bilingual data and word alignment obtained with GIZA++. A language model was trained on the target side of all available bilingual data plus 12 of the Shuffled News corpus and 1 4 of the English Gigaword v3 corpus, resu"
2013.iwslt-evaluation.16,2012.iwslt-papers.17,1,0.860668,"em [32], replicating the settings described in [33] developed for the 2013 Workshop on Statistical Machine Translation. The characteristics of the system include: a maximum sentence length of 80, grow-diag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM [34] used at runtime, a lexically-driven 5-gram operation sequence model [35] with four additional supportive features (two gap-based penalties, one distance-based feature and one deletion penalty), msdbidirectional-fe lexicalized reordering, sparse lexical and domain features [36], a distortion limit of 6, 100-best translation options, minimum Bayes risk decoding [37], cube pruning [38] with a stack size of 1000 during tuning and 5000 during testing and the no-reordering-over-punctuation heuristic. UEDIN used the compact phrase table representation by [39]. For English→German, UEDIN used a sequence model over morphological tags. The UEDIN systems were tuned on the dev2010 set made available for the IWSLT 2013 workshop. Tuning was performed using the k-best batch MIRA algorithm [40] with a maximum number of iterations of 25. B LEU was used as the metric to evaluate resu"
2013.iwslt-evaluation.16,D13-1138,1,0.815085,"based on cross-entropy difference as described in [23]. The hierarchical system was extended with a second translation model. The additional translation model was trained on the WIT3 portion of the training data only. For the English→French phrase-based setup, RWTH utilized all available parallel data and trained a word alignment with GIZA++ [24]. The same language model as in the hierarchical setup was used. RWTH applied the following supplementary features for the phrase-based system: a lexicalized reordering model [25], a discriminative word lexicon [26], a 7-gram word class language model [27], a continuous space language model [28], and a second translation model from the WIT3 portion of the training data only. For German→English, RWTH decompounded the German source in a preprocessing step [29] and applied partof-speech-based long-range verb reordering rules [30]. Both systems RWTH scss and RWTH hiero rest upon all available bilingual data and word alignment obtained with GIZA++. A language model was trained on the target side of all available bilingual data plus 12 of the Shuffled News corpus and 1 4 of the English Gigaword v3 corpus, resulting in a total of 1.7 billion running w"
2013.iwslt-evaluation.16,N04-1022,0,0.487773,"atistical Machine Translation. The characteristics of the system include: a maximum sentence length of 80, grow-diag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM [34] used at runtime, a lexically-driven 5-gram operation sequence model [35] with four additional supportive features (two gap-based penalties, one distance-based feature and one deletion penalty), msdbidirectional-fe lexicalized reordering, sparse lexical and domain features [36], a distortion limit of 6, 100-best translation options, minimum Bayes risk decoding [37], cube pruning [38] with a stack size of 1000 during tuning and 5000 during testing and the no-reordering-over-punctuation heuristic. UEDIN used the compact phrase table representation by [39]. For English→German, UEDIN used a sequence model over morphological tags. The UEDIN systems were tuned on the dev2010 set made available for the IWSLT 2013 workshop. Tuning was performed using the k-best batch MIRA algorithm [40] with a maximum number of iterations of 25. B LEU was used as the metric to evaluate results. While UEDIN’s main submission also includes sequence models and operation sequence m"
2013.iwslt-evaluation.16,W12-2702,0,0.051709,"cribed in [23]. The hierarchical system was extended with a second translation model. The additional translation model was trained on the WIT3 portion of the training data only. For the English→French phrase-based setup, RWTH utilized all available parallel data and trained a word alignment with GIZA++ [24]. The same language model as in the hierarchical setup was used. RWTH applied the following supplementary features for the phrase-based system: a lexicalized reordering model [25], a discriminative word lexicon [26], a 7-gram word class language model [27], a continuous space language model [28], and a second translation model from the WIT3 portion of the training data only. For German→English, RWTH decompounded the German source in a preprocessing step [29] and applied partof-speech-based long-range verb reordering rules [30]. Both systems RWTH scss and RWTH hiero rest upon all available bilingual data and word alignment obtained with GIZA++. A language model was trained on the target side of all available bilingual data plus 12 of the Shuffled News corpus and 1 4 of the English Gigaword v3 corpus, resulting in a total of 1.7 billion running words. In both German→English systems, RW"
2013.iwslt-evaluation.16,P07-1019,0,0.222647,"ranslation. The characteristics of the system include: a maximum sentence length of 80, grow-diag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM [34] used at runtime, a lexically-driven 5-gram operation sequence model [35] with four additional supportive features (two gap-based penalties, one distance-based feature and one deletion penalty), msdbidirectional-fe lexicalized reordering, sparse lexical and domain features [36], a distortion limit of 6, 100-best translation options, minimum Bayes risk decoding [37], cube pruning [38] with a stack size of 1000 during tuning and 5000 during testing and the no-reordering-over-punctuation heuristic. UEDIN used the compact phrase table representation by [39]. For English→German, UEDIN used a sequence model over morphological tags. The UEDIN systems were tuned on the dev2010 set made available for the IWSLT 2013 workshop. Tuning was performed using the k-best batch MIRA algorithm [40] with a maximum number of iterations of 25. B LEU was used as the metric to evaluate results. While UEDIN’s main submission also includes sequence models and operation sequence models over Brown wo"
2013.iwslt-evaluation.16,E03-1076,1,0.900834,"data only. For the English→French phrase-based setup, RWTH utilized all available parallel data and trained a word alignment with GIZA++ [24]. The same language model as in the hierarchical setup was used. RWTH applied the following supplementary features for the phrase-based system: a lexicalized reordering model [25], a discriminative word lexicon [26], a 7-gram word class language model [27], a continuous space language model [28], and a second translation model from the WIT3 portion of the training data only. For German→English, RWTH decompounded the German source in a preprocessing step [29] and applied partof-speech-based long-range verb reordering rules [30]. Both systems RWTH scss and RWTH hiero rest upon all available bilingual data and word alignment obtained with GIZA++. A language model was trained on the target side of all available bilingual data plus 12 of the Shuffled News corpus and 1 4 of the English Gigaword v3 corpus, resulting in a total of 1.7 billion running words. In both German→English systems, RWTH applied a more sophisticated discriminative phrase training method. Similar to [31], a gradient-based method is used to optimize a maximum expected B LEU objective"
2013.iwslt-evaluation.16,N12-1047,0,0.148125,"penalty), msdbidirectional-fe lexicalized reordering, sparse lexical and domain features [36], a distortion limit of 6, 100-best translation options, minimum Bayes risk decoding [37], cube pruning [38] with a stack size of 1000 during tuning and 5000 during testing and the no-reordering-over-punctuation heuristic. UEDIN used the compact phrase table representation by [39]. For English→German, UEDIN used a sequence model over morphological tags. The UEDIN systems were tuned on the dev2010 set made available for the IWSLT 2013 workshop. Tuning was performed using the k-best batch MIRA algorithm [40] with a maximum number of iterations of 25. B LEU was used as the metric to evaluate results. While UEDIN’s main submission also includes sequence models and operation sequence models over Brown word clusters, these setups were not finished in time for the contribution to the EU-BRIDGE system combination. language models trained on WIT3 , Europarl, News Commentary, 109 , and Common Crawl by minimizing the perplexity on the development data. For the class-based language model, KIT utilized in-domain WIT3 data with 4grams and 50 clusters. In addition, a 9-gram POS-based language model derived fr"
2013.iwslt-evaluation.16,2011.iwslt-evaluation.9,1,0.925869,"ge model derived from LIA POS tags [55] on all monolingual data was applied. KIT optimized the log-linear combination of all these models on the provided development data using Minimum Error Rate Training [20]. 4. Karlsruhe Institute of Technology The KIT translations have been generated by an in-house phrase-based translations system [41]. The models were trained on the Europarl, News Commentary, WIT3 , Common Crawl corpora for both directions and WMT 109 for English→French and the additional monolingual training data. The big noisy 109 and Crawl corpora were filtered using an SVM classifier [42]. In addition to the standard preprocessing, KIT used compound splitting [29] for the German text. In both translation directions, KIT performed reordering using two models. KIT encoded different reorderings of the source sentences in a word lattice. For the English→French system, only short-range rules [43] were used to generate these lattices. For German→English, long-range rules [44] and tree-based reordering rules [45] were used as well. The part-of-speech (POS) tags needed for these rules were generated by the TreeTagger [46] and the parse trees by the Stanford Parser [47]. In addition, K"
2013.iwslt-evaluation.16,2007.tmi-papers.21,0,0.422618,"e-based translations system [41]. The models were trained on the Europarl, News Commentary, WIT3 , Common Crawl corpora for both directions and WMT 109 for English→French and the additional monolingual training data. The big noisy 109 and Crawl corpora were filtered using an SVM classifier [42]. In addition to the standard preprocessing, KIT used compound splitting [29] for the German text. In both translation directions, KIT performed reordering using two models. KIT encoded different reorderings of the source sentences in a word lattice. For the English→French system, only short-range rules [43] were used to generate these lattices. For German→English, long-range rules [44] and tree-based reordering rules [45] were used as well. The part-of-speech (POS) tags needed for these rules were generated by the TreeTagger [46] and the parse trees by the Stanford Parser [47]. In addition, KIT scored the different reorderings of both language pairs using a lexicalized reordering model [48]. The phrase tables of the systems were trained using GIZA++ alignment for the English→French task and using a discriminative alignment [49] for the German→English task. KIT adapted the phrase table to the TED"
2013.iwslt-evaluation.16,W09-0435,1,0.918776,"Commentary, WIT3 , Common Crawl corpora for both directions and WMT 109 for English→French and the additional monolingual training data. The big noisy 109 and Crawl corpora were filtered using an SVM classifier [42]. In addition to the standard preprocessing, KIT used compound splitting [29] for the German text. In both translation directions, KIT performed reordering using two models. KIT encoded different reorderings of the source sentences in a word lattice. For the English→French system, only short-range rules [43] were used to generate these lattices. For German→English, long-range rules [44] and tree-based reordering rules [45] were used as well. The part-of-speech (POS) tags needed for these rules were generated by the TreeTagger [46] and the parse trees by the Stanford Parser [47]. In addition, KIT scored the different reorderings of both language pairs using a lexicalized reordering model [48]. The phrase tables of the systems were trained using GIZA++ alignment for the English→French task and using a discriminative alignment [49] for the German→English task. KIT adapted the phrase table to the TED domain using the back off approach and by also adapting the candidate selection"
2013.iwslt-evaluation.16,W13-0805,1,0.889592,"ra for both directions and WMT 109 for English→French and the additional monolingual training data. The big noisy 109 and Crawl corpora were filtered using an SVM classifier [42]. In addition to the standard preprocessing, KIT used compound splitting [29] for the German text. In both translation directions, KIT performed reordering using two models. KIT encoded different reorderings of the source sentences in a word lattice. For the English→French system, only short-range rules [43] were used to generate these lattices. For German→English, long-range rules [44] and tree-based reordering rules [45] were used as well. The part-of-speech (POS) tags needed for these rules were generated by the TreeTagger [46] and the parse trees by the Stanford Parser [47]. In addition, KIT scored the different reorderings of both language pairs using a lexicalized reordering model [48]. The phrase tables of the systems were trained using GIZA++ alignment for the English→French task and using a discriminative alignment [49] for the German→English task. KIT adapted the phrase table to the TED domain using the back off approach and by also adapting the candidate selection [50]. In addition to the phrase tabl"
2013.iwslt-evaluation.16,W08-1006,0,0.169177,"SVM classifier [42]. In addition to the standard preprocessing, KIT used compound splitting [29] for the German text. In both translation directions, KIT performed reordering using two models. KIT encoded different reorderings of the source sentences in a word lattice. For the English→French system, only short-range rules [43] were used to generate these lattices. For German→English, long-range rules [44] and tree-based reordering rules [45] were used as well. The part-of-speech (POS) tags needed for these rules were generated by the TreeTagger [46] and the parse trees by the Stanford Parser [47]. In addition, KIT scored the different reorderings of both language pairs using a lexicalized reordering model [48]. The phrase tables of the systems were trained using GIZA++ alignment for the English→French task and using a discriminative alignment [49] for the German→English task. KIT adapted the phrase table to the TED domain using the back off approach and by also adapting the candidate selection [50]. In addition to the phrase table probabilities, KIT modeled the translation process by a bilingual language model [51] and a discriminative word lexicon [52]. For the German→English task, a"
2013.iwslt-evaluation.16,2005.iwslt-1.8,1,0.888473,"t. In both translation directions, KIT performed reordering using two models. KIT encoded different reorderings of the source sentences in a word lattice. For the English→French system, only short-range rules [43] were used to generate these lattices. For German→English, long-range rules [44] and tree-based reordering rules [45] were used as well. The part-of-speech (POS) tags needed for these rules were generated by the TreeTagger [46] and the parse trees by the Stanford Parser [47]. In addition, KIT scored the different reorderings of both language pairs using a lexicalized reordering model [48]. The phrase tables of the systems were trained using GIZA++ alignment for the English→French task and using a discriminative alignment [49] for the German→English task. KIT adapted the phrase table to the TED domain using the back off approach and by also adapting the candidate selection [50]. In addition to the phrase table probabilities, KIT modeled the translation process by a bilingual language model [51] and a discriminative word lexicon [52]. For the German→English task, a discriminative word lexicon with source and target context features was applied, while only the source context feat"
2013.iwslt-evaluation.16,W08-0303,1,0.796238,"word lattice. For the English→French system, only short-range rules [43] were used to generate these lattices. For German→English, long-range rules [44] and tree-based reordering rules [45] were used as well. The part-of-speech (POS) tags needed for these rules were generated by the TreeTagger [46] and the parse trees by the Stanford Parser [47]. In addition, KIT scored the different reorderings of both language pairs using a lexicalized reordering model [48]. The phrase tables of the systems were trained using GIZA++ alignment for the English→French task and using a discriminative alignment [49] for the German→English task. KIT adapted the phrase table to the TED domain using the back off approach and by also adapting the candidate selection [50]. In addition to the phrase table probabilities, KIT modeled the translation process by a bilingual language model [51] and a discriminative word lexicon [52]. For the German→English task, a discriminative word lexicon with source and target context features was applied, while only the source context features were employed for the English→French task. During decoding, KIT used several language models to adapt the system to the task and to bet"
2013.iwslt-evaluation.16,2012.amta-papers.19,1,0.890564,"and tree-based reordering rules [45] were used as well. The part-of-speech (POS) tags needed for these rules were generated by the TreeTagger [46] and the parse trees by the Stanford Parser [47]. In addition, KIT scored the different reorderings of both language pairs using a lexicalized reordering model [48]. The phrase tables of the systems were trained using GIZA++ alignment for the English→French task and using a discriminative alignment [49] for the German→English task. KIT adapted the phrase table to the TED domain using the back off approach and by also adapting the candidate selection [50]. In addition to the phrase table probabilities, KIT modeled the translation process by a bilingual language model [51] and a discriminative word lexicon [52]. For the German→English task, a discriminative word lexicon with source and target context features was applied, while only the source context features were employed for the English→French task. During decoding, KIT used several language models to adapt the system to the task and to better model the sentence structure by means of class-based n-grams. For the German→English task, KIT used one language model trained on all data, an in-doma"
2013.iwslt-evaluation.16,W11-2124,1,0.885306,"ated by the TreeTagger [46] and the parse trees by the Stanford Parser [47]. In addition, KIT scored the different reorderings of both language pairs using a lexicalized reordering model [48]. The phrase tables of the systems were trained using GIZA++ alignment for the English→French task and using a discriminative alignment [49] for the German→English task. KIT adapted the phrase table to the TED domain using the back off approach and by also adapting the candidate selection [50]. In addition to the phrase table probabilities, KIT modeled the translation process by a bilingual language model [51] and a discriminative word lexicon [52]. For the German→English task, a discriminative word lexicon with source and target context features was applied, while only the source context features were employed for the English→French task. During decoding, KIT used several language models to adapt the system to the task and to better model the sentence structure by means of class-based n-grams. For the German→English task, KIT used one language model trained on all data, an in-domain language model trained only on the WIT3 corpus and one language model trained on 5 M sentences selected using cross-"
2013.iwslt-evaluation.16,W13-2264,1,0.887808,"se trees by the Stanford Parser [47]. In addition, KIT scored the different reorderings of both language pairs using a lexicalized reordering model [48]. The phrase tables of the systems were trained using GIZA++ alignment for the English→French task and using a discriminative alignment [49] for the German→English task. KIT adapted the phrase table to the TED domain using the back off approach and by also adapting the candidate selection [50]. In addition to the phrase table probabilities, KIT modeled the translation process by a bilingual language model [51] and a discriminative word lexicon [52]. For the German→English task, a discriminative word lexicon with source and target context features was applied, while only the source context features were employed for the English→French task. During decoding, KIT used several language models to adapt the system to the task and to better model the sentence structure by means of class-based n-grams. For the German→English task, KIT used one language model trained on all data, an in-domain language model trained only on the WIT3 corpus and one language model trained on 5 M sentences selected using cross-entropy difference [23]. Furthermore, K"
2013.iwslt-evaluation.16,2012.iwslt-papers.3,1,0.886049,"criminative word lexicon with source and target context features was applied, while only the source context features were employed for the English→French task. During decoding, KIT used several language models to adapt the system to the task and to better model the sentence structure by means of class-based n-grams. For the German→English task, KIT used one language model trained on all data, an in-domain language model trained only on the WIT3 corpus and one language model trained on 5 M sentences selected using cross-entropy difference [23]. Furthermore, KIT used an RBM-based language model [53] trained on the WIT3 corpus. Finally, KIT also used a classbased language model, trained on the WIT3 corpus using the MKCLS [54] algorithm to cluster the words. For the English→French translation task, KIT linearly combined the 5. Fondazione Bruno Kessler The FBK component of the system combination corresponds to the “contrastive 1” system of the official FBK submission. The FBK system was built upon a standard phrasebased system using the Moses toolkit [32], and exploited the huge amount of parallel English→French and monolingual French training data, provided by the organizers. It featured a"
2013.iwslt-evaluation.16,E99-1010,0,0.0594124,"ed for the English→French task. During decoding, KIT used several language models to adapt the system to the task and to better model the sentence structure by means of class-based n-grams. For the German→English task, KIT used one language model trained on all data, an in-domain language model trained only on the WIT3 corpus and one language model trained on 5 M sentences selected using cross-entropy difference [23]. Furthermore, KIT used an RBM-based language model [53] trained on the WIT3 corpus. Finally, KIT also used a classbased language model, trained on the WIT3 corpus using the MKCLS [54] algorithm to cluster the words. For the English→French translation task, KIT linearly combined the 5. Fondazione Bruno Kessler The FBK component of the system combination corresponds to the “contrastive 1” system of the official FBK submission. The FBK system was built upon a standard phrasebased system using the Moses toolkit [32], and exploited the huge amount of parallel English→French and monolingual French training data, provided by the organizers. It featured a statistical log-linear model including a filled-up phrase translation model [56] and lexicalized reordering models (RMs), two F"
2013.iwslt-evaluation.16,2011.iwslt-evaluation.18,1,0.928081,"el, trained on the WIT3 corpus using the MKCLS [54] algorithm to cluster the words. For the English→French translation task, KIT linearly combined the 5. Fondazione Bruno Kessler The FBK component of the system combination corresponds to the “contrastive 1” system of the official FBK submission. The FBK system was built upon a standard phrasebased system using the Moses toolkit [32], and exploited the huge amount of parallel English→French and monolingual French training data, provided by the organizers. It featured a statistical log-linear model including a filled-up phrase translation model [56] and lexicalized reordering models (RMs), two French language models (LMs), as well as distortion, word, and phrase penalties. In order to focus it on TED specific domain and genre, and to reduce the size of the system, data selection by means of IRSTLM toolkit [57] was performed on the whole parallel English→French corpus, using the WIT3 training data as in-domain data. Different amount of data are selected from each available corpora but the WIT3 data, for a total of 66 M English running words. Two TMs and two RMs were trained on WIT3 and selected data, separately, and combined using the fil"
2013.iwslt-evaluation.16,W05-0909,0,0.0593782,"es which are outputs of different translation engines. The consensus translations can be better in terms of translation quality than any of the individual hypotheses. To combine the engines of the project partners for the EU-BRIDGE joint setups, we applied a system combination implementation that has been developed at RWTH Aachen University. The basic concept of RWTH’s approach to machine translation system combination has been described by Matusov et al. [60]. This approach includes an enhanced alignment and reordering framework. Alignments between the system outputs are learned using METEOR [61]. A confusion network is then built using one of the hypotheses as “primary” hypothesis. We do not make a hard decision on which of the hypotheses to use for that, but instead combine all possible confusion networks into a single lattice. Majority voting on the generated lattice is performed using the prior probabilities for each system as well as other statistical models, e.g. a special n-gram language model which is learned on the input hypotheses. Scaling factors of the models are optimized using the Minimum Error Rate Training algorithm. The translation with the best total score within the"
2013.iwslt-evaluation.16,W12-3140,1,\N,Missing
2013.iwslt-evaluation.16,J03-1002,1,\N,Missing
2013.iwslt-evaluation.16,C12-3061,1,\N,Missing
2013.iwslt-evaluation.16,federico-etal-2012-iwslt,1,\N,Missing
2013.iwslt-evaluation.16,2011.iwslt-evaluation.1,1,\N,Missing
2013.iwslt-evaluation.16,W13-2223,1,\N,Missing
2013.iwslt-evaluation.16,N13-1073,0,\N,Missing
2014.iwslt-evaluation.6,P07-2045,1,0.0218346,"English→French, Arabic↔English, Farsi→English, Hebrew→English, Spanish↔English, and Portuguese-Brazil↔English tasks. For our SLT submissions, we experimented with comparing operation sequence models with bilingual neural network language models. For our MT submissions, we explored using unsupervised transliteration for languages which have a different script than English, in particular for Arabic, Farsi, and Hebrew. We also investigated syntax-based translation and system combination. 1. Introduction The University of Edinburgh’s translation engines are based on the open source Moses toolkit [1]. We set up phrase-based systems [2] for all SLT and MT tasks covered in this paper, and additionally a string-to-tree syntax-based system [3, 4] for the English→German MT task. The setups for our phrase-based systems have evolved from the configurations of the engines we built for last year’s IWSLT [5] and for this year’s Workshop on Statistical Machine Translation (WMT) [6]. The notable features of these systems are: • Phrase translation scores in both directions, smoothed with Good-Turing discounting • Lexical translation scores in both directions • Word and phrase penalties • Six simple co"
2014.iwslt-evaluation.6,N03-1017,1,0.0403051,"si→English, Hebrew→English, Spanish↔English, and Portuguese-Brazil↔English tasks. For our SLT submissions, we experimented with comparing operation sequence models with bilingual neural network language models. For our MT submissions, we explored using unsupervised transliteration for languages which have a different script than English, in particular for Arabic, Farsi, and Hebrew. We also investigated syntax-based translation and system combination. 1. Introduction The University of Edinburgh’s translation engines are based on the open source Moses toolkit [1]. We set up phrase-based systems [2] for all SLT and MT tasks covered in this paper, and additionally a string-to-tree syntax-based system [3, 4] for the English→German MT task. The setups for our phrase-based systems have evolved from the configurations of the engines we built for last year’s IWSLT [5] and for this year’s Workshop on Statistical Machine Translation (WMT) [6]. The notable features of these systems are: • Phrase translation scores in both directions, smoothed with Good-Turing discounting • Lexical translation scores in both directions • Word and phrase penalties • Six simple count-based binary features • Phrase l"
2014.iwslt-evaluation.6,N04-1035,0,0.251325,"we experimented with comparing operation sequence models with bilingual neural network language models. For our MT submissions, we explored using unsupervised transliteration for languages which have a different script than English, in particular for Arabic, Farsi, and Hebrew. We also investigated syntax-based translation and system combination. 1. Introduction The University of Edinburgh’s translation engines are based on the open source Moses toolkit [1]. We set up phrase-based systems [2] for all SLT and MT tasks covered in this paper, and additionally a string-to-tree syntax-based system [3, 4] for the English→German MT task. The setups for our phrase-based systems have evolved from the configurations of the engines we built for last year’s IWSLT [5] and for this year’s Workshop on Statistical Machine Translation (WMT) [6]. The notable features of these systems are: • Phrase translation scores in both directions, smoothed with Good-Turing discounting • Lexical translation scores in both directions • Word and phrase penalties • Six simple count-based binary features • Phrase length features • Distance-based distortion cost • A hierarchical lexicalized reordering model [7] • Sparse le"
2014.iwslt-evaluation.6,D08-1089,0,0.662228,"d system [3, 4] for the English→German MT task. The setups for our phrase-based systems have evolved from the configurations of the engines we built for last year’s IWSLT [5] and for this year’s Workshop on Statistical Machine Translation (WMT) [6]. The notable features of these systems are: • Phrase translation scores in both directions, smoothed with Good-Turing discounting • Lexical translation scores in both directions • Word and phrase penalties • Six simple count-based binary features • Phrase length features • Distance-based distortion cost • A hierarchical lexicalized reordering model [7] • Sparse lexical and domain indicator features [8] • Operation sequence models (OSMs) over different word representations [9, 10] • A 5-gram language model (LM) over words We typically train factored phrase-based translation models [11, 12] and also incorporate higher order n-gram LMs over word representations given by the factors. Factors can for instance be lemma, part-of-speech (POS) tag, morphological tag, or automatically learnt word classes in the manner of Brown clusters [13]. Edinburgh’s syntax-based systems have recently yielded state-of-the-art performance on English→German news tra"
2014.iwslt-evaluation.6,2012.iwslt-papers.17,1,0.922891,"setups for our phrase-based systems have evolved from the configurations of the engines we built for last year’s IWSLT [5] and for this year’s Workshop on Statistical Machine Translation (WMT) [6]. The notable features of these systems are: • Phrase translation scores in both directions, smoothed with Good-Turing discounting • Lexical translation scores in both directions • Word and phrase penalties • Six simple count-based binary features • Phrase length features • Distance-based distortion cost • A hierarchical lexicalized reordering model [7] • Sparse lexical and domain indicator features [8] • Operation sequence models (OSMs) over different word representations [9, 10] • A 5-gram language model (LM) over words We typically train factored phrase-based translation models [11, 12] and also incorporate higher order n-gram LMs over word representations given by the factors. Factors can for instance be lemma, part-of-speech (POS) tag, morphological tag, or automatically learnt word classes in the manner of Brown clusters [13]. Edinburgh’s syntax-based systems have recently yielded state-of-the-art performance on English→German news translation tasks [14, 15] but have not been applied i"
2014.iwslt-evaluation.6,P11-1105,1,0.920037,"f the engines we built for last year’s IWSLT [5] and for this year’s Workshop on Statistical Machine Translation (WMT) [6]. The notable features of these systems are: • Phrase translation scores in both directions, smoothed with Good-Turing discounting • Lexical translation scores in both directions • Word and phrase penalties • Six simple count-based binary features • Phrase length features • Distance-based distortion cost • A hierarchical lexicalized reordering model [7] • Sparse lexical and domain indicator features [8] • Operation sequence models (OSMs) over different word representations [9, 10] • A 5-gram language model (LM) over words We typically train factored phrase-based translation models [11, 12] and also incorporate higher order n-gram LMs over word representations given by the factors. Factors can for instance be lemma, part-of-speech (POS) tag, morphological tag, or automatically learnt word classes in the manner of Brown clusters [13]. Edinburgh’s syntax-based systems have recently yielded state-of-the-art performance on English→German news translation tasks [14, 15] but have not been applied in an IWSLT-style setting before. Standard features of our stringto-tree syntax-"
2014.iwslt-evaluation.6,C14-1041,1,0.826647,"f the engines we built for last year’s IWSLT [5] and for this year’s Workshop on Statistical Machine Translation (WMT) [6]. The notable features of these systems are: • Phrase translation scores in both directions, smoothed with Good-Turing discounting • Lexical translation scores in both directions • Word and phrase penalties • Six simple count-based binary features • Phrase length features • Distance-based distortion cost • A hierarchical lexicalized reordering model [7] • Sparse lexical and domain indicator features [8] • Operation sequence models (OSMs) over different word representations [9, 10] • A 5-gram language model (LM) over words We typically train factored phrase-based translation models [11, 12] and also incorporate higher order n-gram LMs over word representations given by the factors. Factors can for instance be lemma, part-of-speech (POS) tag, morphological tag, or automatically learnt word classes in the manner of Brown clusters [13]. Edinburgh’s syntax-based systems have recently yielded state-of-the-art performance on English→German news translation tasks [14, 15] but have not been applied in an IWSLT-style setting before. Standard features of our stringto-tree syntax-"
2014.iwslt-evaluation.6,D07-1091,1,0.88178,"on (WMT) [6]. The notable features of these systems are: • Phrase translation scores in both directions, smoothed with Good-Turing discounting • Lexical translation scores in both directions • Word and phrase penalties • Six simple count-based binary features • Phrase length features • Distance-based distortion cost • A hierarchical lexicalized reordering model [7] • Sparse lexical and domain indicator features [8] • Operation sequence models (OSMs) over different word representations [9, 10] • A 5-gram language model (LM) over words We typically train factored phrase-based translation models [11, 12] and also incorporate higher order n-gram LMs over word representations given by the factors. Factors can for instance be lemma, part-of-speech (POS) tag, morphological tag, or automatically learnt word classes in the manner of Brown clusters [13]. Edinburgh’s syntax-based systems have recently yielded state-of-the-art performance on English→German news translation tasks [14, 15] but have not been applied in an IWSLT-style setting before. Standard features of our stringto-tree syntax-based systems are: • Rule translation scores in both directions, smoothed with Good-Turing discounting • Lexica"
2014.iwslt-evaluation.6,2012.amta-papers.9,1,0.923939,"on (WMT) [6]. The notable features of these systems are: • Phrase translation scores in both directions, smoothed with Good-Turing discounting • Lexical translation scores in both directions • Word and phrase penalties • Six simple count-based binary features • Phrase length features • Distance-based distortion cost • A hierarchical lexicalized reordering model [7] • Sparse lexical and domain indicator features [8] • Operation sequence models (OSMs) over different word representations [9, 10] • A 5-gram language model (LM) over words We typically train factored phrase-based translation models [11, 12] and also incorporate higher order n-gram LMs over word representations given by the factors. Factors can for instance be lemma, part-of-speech (POS) tag, morphological tag, or automatically learnt word classes in the manner of Brown clusters [13]. Edinburgh’s syntax-based systems have recently yielded state-of-the-art performance on English→German news translation tasks [14, 15] but have not been applied in an IWSLT-style setting before. Standard features of our stringto-tree syntax-based systems are: • Rule translation scores in both directions, smoothed with Good-Turing discounting • Lexica"
2014.iwslt-evaluation.6,E99-1010,0,0.726319,"features • Phrase length features • Distance-based distortion cost • A hierarchical lexicalized reordering model [7] • Sparse lexical and domain indicator features [8] • Operation sequence models (OSMs) over different word representations [9, 10] • A 5-gram language model (LM) over words We typically train factored phrase-based translation models [11, 12] and also incorporate higher order n-gram LMs over word representations given by the factors. Factors can for instance be lemma, part-of-speech (POS) tag, morphological tag, or automatically learnt word classes in the manner of Brown clusters [13]. Edinburgh’s syntax-based systems have recently yielded state-of-the-art performance on English→German news translation tasks [14, 15] but have not been applied in an IWSLT-style setting before. Standard features of our stringto-tree syntax-based systems are: • Rule translation scores in both directions, smoothed with Good-Turing discounting • Lexical translation scores in both directions • Word and rule penalties • A rule rareness penalty • The monolingual PCFG probability of the tree fragment from which the rule was extracted • A 5-gram LM over words For our Spanish↔English and PortugueseBr"
2014.iwslt-evaluation.6,W12-3150,1,0.921133,"we experimented with comparing operation sequence models with bilingual neural network language models. For our MT submissions, we explored using unsupervised transliteration for languages which have a different script than English, in particular for Arabic, Farsi, and Hebrew. We also investigated syntax-based translation and system combination. 1. Introduction The University of Edinburgh’s translation engines are based on the open source Moses toolkit [1]. We set up phrase-based systems [2] for all SLT and MT tasks covered in this paper, and additionally a string-to-tree syntax-based system [3, 4] for the English→German MT task. The setups for our phrase-based systems have evolved from the configurations of the engines we built for last year’s IWSLT [5] and for this year’s Workshop on Statistical Machine Translation (WMT) [6]. The notable features of these systems are: • Phrase translation scores in both directions, smoothed with Good-Turing discounting • Lexical translation scores in both directions • Word and phrase penalties • Six simple count-based binary features • Phrase length features • Distance-based distortion cost • A hierarchical lexicalized reordering model [7] • Sparse le"
2014.iwslt-evaluation.6,W13-2221,1,0.91182,"al and domain indicator features [8] • Operation sequence models (OSMs) over different word representations [9, 10] • A 5-gram language model (LM) over words We typically train factored phrase-based translation models [11, 12] and also incorporate higher order n-gram LMs over word representations given by the factors. Factors can for instance be lemma, part-of-speech (POS) tag, morphological tag, or automatically learnt word classes in the manner of Brown clusters [13]. Edinburgh’s syntax-based systems have recently yielded state-of-the-art performance on English→German news translation tasks [14, 15] but have not been applied in an IWSLT-style setting before. Standard features of our stringto-tree syntax-based systems are: • Rule translation scores in both directions, smoothed with Good-Turing discounting • Lexical translation scores in both directions • Word and rule penalties • A rule rareness penalty • The monolingual PCFG probability of the tree fragment from which the rule was extracted • A 5-gram LM over words For our Spanish↔English and PortugueseBrazil↔English submissions, we ran the engines as described in last year’s system description paper [5]. In the following, we focus on de"
2014.iwslt-evaluation.6,2013.iwslt-evaluation.3,1,0.887168,"ansliteration for languages which have a different script than English, in particular for Arabic, Farsi, and Hebrew. We also investigated syntax-based translation and system combination. 1. Introduction The University of Edinburgh’s translation engines are based on the open source Moses toolkit [1]. We set up phrase-based systems [2] for all SLT and MT tasks covered in this paper, and additionally a string-to-tree syntax-based system [3, 4] for the English→German MT task. The setups for our phrase-based systems have evolved from the configurations of the engines we built for last year’s IWSLT [5] and for this year’s Workshop on Statistical Machine Translation (WMT) [6]. The notable features of these systems are: • Phrase translation scores in both directions, smoothed with Good-Turing discounting • Lexical translation scores in both directions • Word and phrase penalties • Six simple count-based binary features • Phrase length features • Distance-based distortion cost • A hierarchical lexicalized reordering model [7] • Sparse lexical and domain indicator features [8] • Operation sequence models (OSMs) over different word representations [9, 10] • A 5-gram language model (LM) over word"
2014.iwslt-evaluation.6,W14-3324,1,0.869051,"al and domain indicator features [8] • Operation sequence models (OSMs) over different word representations [9, 10] • A 5-gram language model (LM) over words We typically train factored phrase-based translation models [11, 12] and also incorporate higher order n-gram LMs over word representations given by the factors. Factors can for instance be lemma, part-of-speech (POS) tag, morphological tag, or automatically learnt word classes in the manner of Brown clusters [13]. Edinburgh’s syntax-based systems have recently yielded state-of-the-art performance on English→German news translation tasks [14, 15] but have not been applied in an IWSLT-style setting before. Standard features of our stringto-tree syntax-based systems are: • Rule translation scores in both directions, smoothed with Good-Turing discounting • Lexical translation scores in both directions • Word and rule penalties • A rule rareness penalty • The monolingual PCFG probability of the tree fragment from which the rule was extracted • A 5-gram LM over words For our Spanish↔English and PortugueseBrazil↔English submissions, we ran the engines as described in last year’s system description paper [5]. In the following, we focus on de"
2014.iwslt-evaluation.6,W14-3309,1,0.886786,"particular for Arabic, Farsi, and Hebrew. We also investigated syntax-based translation and system combination. 1. Introduction The University of Edinburgh’s translation engines are based on the open source Moses toolkit [1]. We set up phrase-based systems [2] for all SLT and MT tasks covered in this paper, and additionally a string-to-tree syntax-based system [3, 4] for the English→German MT task. The setups for our phrase-based systems have evolved from the configurations of the engines we built for last year’s IWSLT [5] and for this year’s Workshop on Statistical Machine Translation (WMT) [6]. The notable features of these systems are: • Phrase translation scores in both directions, smoothed with Good-Turing discounting • Lexical translation scores in both directions • Word and phrase penalties • Six simple count-based binary features • Phrase length features • Distance-based distortion cost • A hierarchical lexicalized reordering model [7] • Sparse lexical and domain indicator features [8] • Operation sequence models (OSMs) over different word representations [9, 10] • A 5-gram language model (LM) over words We typically train factored phrase-based translation models [11, 12] and"
2014.iwslt-evaluation.6,2012.eamt-1.60,0,0.0588662,"rections, smoothed with Good-Turing discounting • Lexical translation scores in both directions • Word and rule penalties • A rule rareness penalty • The monolingual PCFG probability of the tree fragment from which the rule was extracted • A 5-gram LM over words For our Spanish↔English and PortugueseBrazil↔English submissions, we ran the engines as described in last year’s system description paper [5]. In the following, we focus on describing the new systems which were developed for the rest of the tasks. Our this year’s IWSLT systems were trained using monolingual and parallel data from WIT3 [16], Europarl [17], MultiUN [18], the Gigaword corpora as provided by the Linguistic Data Consortium [19], the German Political Speeches Corpus [20], and the corpora provided for the WMT shared translation task [21]. Word alignments for the MT track systems were created by aligning the data in both directions with MGIZA++ [22] and symmetrizing the two alignments with the grow-diagfinal-and heuristic [23, 2]. Word alignments for the SLT track systems were created using fast align [24]. The SRILM toolkit [25] was employed to train 5-gram language models (LMs) with modified Kneser-Ney smoothing [26]"
2014.iwslt-evaluation.6,2005.mtsummit-papers.11,1,0.143449,"hed with Good-Turing discounting • Lexical translation scores in both directions • Word and rule penalties • A rule rareness penalty • The monolingual PCFG probability of the tree fragment from which the rule was extracted • A 5-gram LM over words For our Spanish↔English and PortugueseBrazil↔English submissions, we ran the engines as described in last year’s system description paper [5]. In the following, we focus on describing the new systems which were developed for the rest of the tasks. Our this year’s IWSLT systems were trained using monolingual and parallel data from WIT3 [16], Europarl [17], MultiUN [18], the Gigaword corpora as provided by the Linguistic Data Consortium [19], the German Political Speeches Corpus [20], and the corpora provided for the WMT shared translation task [21]. Word alignments for the MT track systems were created by aligning the data in both directions with MGIZA++ [22] and symmetrizing the two alignments with the grow-diagfinal-and heuristic [23, 2]. Word alignments for the SLT track systems were created using fast align [24]. The SRILM toolkit [25] was employed to train 5-gram language models (LMs) with modified Kneser-Ney smoothing [26]. We trained in"
2014.iwslt-evaluation.6,eisele-chen-2010-multiun,0,0.268558,"Turing discounting • Lexical translation scores in both directions • Word and rule penalties • A rule rareness penalty • The monolingual PCFG probability of the tree fragment from which the rule was extracted • A 5-gram LM over words For our Spanish↔English and PortugueseBrazil↔English submissions, we ran the engines as described in last year’s system description paper [5]. In the following, we focus on describing the new systems which were developed for the rest of the tasks. Our this year’s IWSLT systems were trained using monolingual and parallel data from WIT3 [16], Europarl [17], MultiUN [18], the Gigaword corpora as provided by the Linguistic Data Consortium [19], the German Political Speeches Corpus [20], and the corpora provided for the WMT shared translation task [21]. Word alignments for the MT track systems were created by aligning the data in both directions with MGIZA++ [22] and symmetrizing the two alignments with the grow-diagfinal-and heuristic [23, 2]. Word alignments for the SLT track systems were created using fast align [24]. The SRILM toolkit [25] was employed to train 5-gram language models (LMs) with modified Kneser-Ney smoothing [26]. We trained individual LMs o"
2014.iwslt-evaluation.6,W08-0509,0,0.134751,"ns, we ran the engines as described in last year’s system description paper [5]. In the following, we focus on describing the new systems which were developed for the rest of the tasks. Our this year’s IWSLT systems were trained using monolingual and parallel data from WIT3 [16], Europarl [17], MultiUN [18], the Gigaword corpora as provided by the Linguistic Data Consortium [19], the German Political Speeches Corpus [20], and the corpora provided for the WMT shared translation task [21]. Word alignments for the MT track systems were created by aligning the data in both directions with MGIZA++ [22] and symmetrizing the two alignments with the grow-diagfinal-and heuristic [23, 2]. Word alignments for the SLT track systems were created using fast align [24]. The SRILM toolkit [25] was employed to train 5-gram language models (LMs) with modified Kneser-Ney smoothing [26]. We trained individual LMs on each corpus and then interpolated them using weights tuned to minimize perplexity on a development set. KenLM [27] was utilized for LM scoring during decoding. Model weights for the log-linear 49 Proceedings of the 11th International Workshop on Spoken Language Translation Lake Tahoe, December"
2014.iwslt-evaluation.6,N13-1073,0,0.135113,"or the rest of the tasks. Our this year’s IWSLT systems were trained using monolingual and parallel data from WIT3 [16], Europarl [17], MultiUN [18], the Gigaword corpora as provided by the Linguistic Data Consortium [19], the German Political Speeches Corpus [20], and the corpora provided for the WMT shared translation task [21]. Word alignments for the MT track systems were created by aligning the data in both directions with MGIZA++ [22] and symmetrizing the two alignments with the grow-diagfinal-and heuristic [23, 2]. Word alignments for the SLT track systems were created using fast align [24]. The SRILM toolkit [25] was employed to train 5-gram language models (LMs) with modified Kneser-Ney smoothing [26]. We trained individual LMs on each corpus and then interpolated them using weights tuned to minimize perplexity on a development set. KenLM [27] was utilized for LM scoring during decoding. Model weights for the log-linear 49 Proceedings of the 11th International Workshop on Spoken Language Translation Lake Tahoe, December 4th and 5th, 2014 model combination [28] were optimized with batch k-best MIRA [29] to maximize B LEU [30]. Where not otherwise stated, the systems were tuned"
2014.iwslt-evaluation.6,W11-2123,0,0.137447,"[20], and the corpora provided for the WMT shared translation task [21]. Word alignments for the MT track systems were created by aligning the data in both directions with MGIZA++ [22] and symmetrizing the two alignments with the grow-diagfinal-and heuristic [23, 2]. Word alignments for the SLT track systems were created using fast align [24]. The SRILM toolkit [25] was employed to train 5-gram language models (LMs) with modified Kneser-Ney smoothing [26]. We trained individual LMs on each corpus and then interpolated them using weights tuned to minimize perplexity on a development set. KenLM [27] was utilized for LM scoring during decoding. Model weights for the log-linear 49 Proceedings of the 11th International Workshop on Spoken Language Translation Lake Tahoe, December 4th and 5th, 2014 model combination [28] were optimized with batch k-best MIRA [29] to maximize B LEU [30]. Where not otherwise stated, the systems were tuned on dev2010. Besides participating in the evaluation campaign with our individual engines, we also collaborated with partners from the EU-BRIDGE project to produce additional joint submissions. The combined systems of the University of Edinburgh, RWTH Aachen Un"
2014.iwslt-evaluation.6,P02-1038,0,0.434172,"with the grow-diagfinal-and heuristic [23, 2]. Word alignments for the SLT track systems were created using fast align [24]. The SRILM toolkit [25] was employed to train 5-gram language models (LMs) with modified Kneser-Ney smoothing [26]. We trained individual LMs on each corpus and then interpolated them using weights tuned to minimize perplexity on a development set. KenLM [27] was utilized for LM scoring during decoding. Model weights for the log-linear 49 Proceedings of the 11th International Workshop on Spoken Language Translation Lake Tahoe, December 4th and 5th, 2014 model combination [28] were optimized with batch k-best MIRA [29] to maximize B LEU [30]. Where not otherwise stated, the systems were tuned on dev2010. Besides participating in the evaluation campaign with our individual engines, we also collaborated with partners from the EU-BRIDGE project to produce additional joint submissions. The combined systems of the University of Edinburgh, RWTH Aachen University, Karlsruhe Institute of Technology, and Fondazione Bruno Kessler are described in [31]. 2. Spoken Language Translation Edinburgh’s spoken language translation system experiments set out to compare two recent stra"
2014.iwslt-evaluation.6,N12-1047,0,0.264311,"2]. Word alignments for the SLT track systems were created using fast align [24]. The SRILM toolkit [25] was employed to train 5-gram language models (LMs) with modified Kneser-Ney smoothing [26]. We trained individual LMs on each corpus and then interpolated them using weights tuned to minimize perplexity on a development set. KenLM [27] was utilized for LM scoring during decoding. Model weights for the log-linear 49 Proceedings of the 11th International Workshop on Spoken Language Translation Lake Tahoe, December 4th and 5th, 2014 model combination [28] were optimized with batch k-best MIRA [29] to maximize B LEU [30]. Where not otherwise stated, the systems were tuned on dev2010. Besides participating in the evaluation campaign with our individual engines, we also collaborated with partners from the EU-BRIDGE project to produce additional joint submissions. The combined systems of the University of Edinburgh, RWTH Aachen University, Karlsruhe Institute of Technology, and Fondazione Bruno Kessler are described in [31]. 2. Spoken Language Translation Edinburgh’s spoken language translation system experiments set out to compare two recent strands of research in terms of their performan"
2014.iwslt-evaluation.6,P02-1040,0,0.0952689,"the SLT track systems were created using fast align [24]. The SRILM toolkit [25] was employed to train 5-gram language models (LMs) with modified Kneser-Ney smoothing [26]. We trained individual LMs on each corpus and then interpolated them using weights tuned to minimize perplexity on a development set. KenLM [27] was utilized for LM scoring during decoding. Model weights for the log-linear 49 Proceedings of the 11th International Workshop on Spoken Language Translation Lake Tahoe, December 4th and 5th, 2014 model combination [28] were optimized with batch k-best MIRA [29] to maximize B LEU [30]. Where not otherwise stated, the systems were tuned on dev2010. Besides participating in the evaluation campaign with our individual engines, we also collaborated with partners from the EU-BRIDGE project to produce additional joint submissions. The combined systems of the University of Edinburgh, RWTH Aachen University, Karlsruhe Institute of Technology, and Fondazione Bruno Kessler are described in [31]. 2. Spoken Language Translation Edinburgh’s spoken language translation system experiments set out to compare two recent strands of research in terms of their performance and their properties"
2014.iwslt-evaluation.6,2014.iwslt-evaluation.7,1,0.877033,"Missing"
2014.iwslt-evaluation.6,P14-1129,0,0.129793,"rlsruhe Institute of Technology, and Fondazione Bruno Kessler are described in [31]. 2. Spoken Language Translation Edinburgh’s spoken language translation system experiments set out to compare two recent strands of research in terms of their performance and their properties in order to understand the contributions of each. The first strand of research is bilingual neural network langauge models. There has recently been a great deal of interest bilingual neural network language models as they have shown strong gains in performance for Arabic→English, and to a lesser extent for Chinese→English [32]. It is still not clear what the exact contribution of the bilinugal language model is, and there is reason to believe that its contribution may be that it allows the SMT model to overcome strong phrase pair independence assumptions. The second strand of research is operation sequence modelling [33, 34]. The integration of the OSM model into phrase-based decoding directly addresses the problem of the phrasal independence assumption by modelling the context of phrase pair translations. We aim to compare these two different approaches and combining them. As we see, combining OSM and the bilingua"
2014.iwslt-evaluation.6,P13-2071,1,0.864533,"he contributions of each. The first strand of research is bilingual neural network langauge models. There has recently been a great deal of interest bilingual neural network language models as they have shown strong gains in performance for Arabic→English, and to a lesser extent for Chinese→English [32]. It is still not clear what the exact contribution of the bilinugal language model is, and there is reason to believe that its contribution may be that it allows the SMT model to overcome strong phrase pair independence assumptions. The second strand of research is operation sequence modelling [33, 34]. The integration of the OSM model into phrase-based decoding directly addresses the problem of the phrasal independence assumption by modelling the context of phrase pair translations. We aim to compare these two different approaches and combining them. As we see, combining OSM and the bilingual NN language model slightly outperforms all other models, including the state-of-the-art OSM model, but only for English→French and only very slightly. 2.1. Baseline For the SLT track, we trained phrase-based models using Moses with mostly default settings. We further included basic sparse features [35"
2014.iwslt-evaluation.6,N13-1001,1,0.914464,"he contributions of each. The first strand of research is bilingual neural network langauge models. There has recently been a great deal of interest bilingual neural network language models as they have shown strong gains in performance for Arabic→English, and to a lesser extent for Chinese→English [32]. It is still not clear what the exact contribution of the bilinugal language model is, and there is reason to believe that its contribution may be that it allows the SMT model to overcome strong phrase pair independence assumptions. The second strand of research is operation sequence modelling [33, 34]. The integration of the OSM model into phrase-based decoding directly addresses the problem of the phrasal independence assumption by modelling the context of phrase pair translations. We aim to compare these two different approaches and combining them. As we see, combining OSM and the bilingual NN language model slightly outperforms all other models, including the state-of-the-art OSM model, but only for English→French and only very slightly. 2.1. Baseline For the SLT track, we trained phrase-based models using Moses with mostly default settings. We further included basic sparse features [35"
2014.iwslt-evaluation.6,N09-1025,0,0.0844804,"34]. The integration of the OSM model into phrase-based decoding directly addresses the problem of the phrasal independence assumption by modelling the context of phrase pair translations. We aim to compare these two different approaches and combining them. As we see, combining OSM and the bilingual NN language model slightly outperforms all other models, including the state-of-the-art OSM model, but only for English→French and only very slightly. 2.1. Baseline For the SLT track, we trained phrase-based models using Moses with mostly default settings. We further included basic sparse features [35] and we used factors. For German→English we used POS tags, morphological tags and lemmas as factors in decoding [11], and for English→German we used POS tags and morphological tags on the target side. Table 1 lists the factors used for the translation model, and the factors over which we trained OSM models. The SLT and the MT systems were trained in a similar fashion, with the main difference being that for SLT no prereordering was performed for German→English as this relies on grammatically correct test sentences, and automatic speech recognition (ASR) output, especially for German, is diffic"
2014.iwslt-evaluation.6,2006.iwslt-papers.1,0,0.165301,"ma l, pos p, morphology m) and the size of the parallel and monolingual training data in millions of words. for WMT, and the LDC Gigaword for French and English. The number of words of training data can be seen in Table 1. 2.2. Monolingual Punctuation Models One of the main challenges of spoken language translation is to overcome the mismatch in the style of data that the speech recognition systems output, and the written text that is used to train the translation model. ASR system output lacks punctuation and capitalisation and this is one of the main stylistic differences. Previous research [36, 5] suggests that it is preferrable to punctuate the text before translation, which is what we did by training a monolingual translation system for our two source languages: German and English. The “source language” of the punctuation model has punctuation and capitalisation stripped, and the “target language” is the full original written text. Our handling of punctuation uses a phrase-based translation model with no distortion or reordering, and we tuned the model to the ASR input text (dev2010 for English, and dev2012 for German) using batch MIRA and the B LEU score. After running ASR output th"
2014.iwslt-evaluation.6,D13-1106,0,0.0838934,"help even more when sequence models are applied over more general factors such as POS tags and GIZA++’s mkcls clusters [5]. For this experiment we applied the best OSM settings from last year’s IWSLT experiments which included models over words, lemmas, POS tags, and clusters depending on the language pair. See Table 1 for details. 50 Proceedings of the 11th International Workshop on Spoken Language Translation Lake Tahoe, December 4th and 5th, 2014 2.4. Bilingual Neural Network Language Model There has recently been a great deal of interest in including neural networks in machine translation [37, 38]. There is hope that neural networks provide a way to relax some of the more egregious independence assuptions made in translation models. The challenge with neural networks however, is that they are computationally very expensive, and getting them to operate at scale requires sophisticated efficiency techniques. A recent paper which was able to fully integrate a neural network which includes both source side and target side context in decoding [32], and they managed to show big improvements for a small Arabic→English task, and smaller improvements for a Chinese→English task. We implemented a"
2014.iwslt-evaluation.6,P14-1066,0,0.0858383,"help even more when sequence models are applied over more general factors such as POS tags and GIZA++’s mkcls clusters [5]. For this experiment we applied the best OSM settings from last year’s IWSLT experiments which included models over words, lemmas, POS tags, and clusters depending on the language pair. See Table 1 for details. 50 Proceedings of the 11th International Workshop on Spoken Language Translation Lake Tahoe, December 4th and 5th, 2014 2.4. Bilingual Neural Network Language Model There has recently been a great deal of interest in including neural networks in machine translation [37, 38]. There is hope that neural networks provide a way to relax some of the more egregious independence assuptions made in translation models. The challenge with neural networks however, is that they are computationally very expensive, and getting them to operate at scale requires sophisticated efficiency techniques. A recent paper which was able to fully integrate a neural network which includes both source side and target side context in decoding [32], and they managed to show big improvements for a small Arabic→English task, and smaller improvements for a Chinese→English task. We implemented a"
2014.iwslt-evaluation.6,D13-1140,0,0.162286,"-the-art translation models. We implemented a BiNNLM as a feature function inside Moses, following closely the implementation outlined in [32]. The main focus of our design is to make the Moses specific code flexible and independent of the neural network language model that would be used for scoring. As a result any NNLM could implement the interface and be used by Moses during decoding. Some features such as backoff to POS tag in case of unknown word or use of special < null > token to pad an incomplete parse in the chart decoder are made optional. Currently the implemented backends are NPLM [39] and OxLM [40]. Implementation is available for both phrase based and hierarchical Moses. For our experiments we chose NPLM to be our NNLM backend. We chose it, because it features noise contrastive estimation (NCE) which allows us to avoid having to apply softmax to normalize the outputs, as it is infeasible to do so with large vocabularies. Another benefit of NPLM is that when using NCE and a neural network with one hidden layer we can precompute the values for the first hidden layer of all vocabulary terms, similarly to what [32] do. We also modified the NPLM code a bit and used Magma enabl"
2014.iwslt-evaluation.6,E14-4029,1,0.892491,"Missing"
2014.iwslt-evaluation.6,P12-1049,0,0.0479377,"Missing"
2014.iwslt-evaluation.6,W14-3362,1,0.88321,"cal tags (the latter trained on WIT3 only). Model weights of the phrase-based in-domain system were optimized on dev2010. Syntax-based System. The contrastive 1 system is a string-to-tree translation system with similar features as the ones described in [15]. The target-side data was parsed with BitPar [48], and right binarization was applied to the parse trees. The system was adapted to the TED domain by extracting separate rule tables (from the WIT3 corpus and from the rest of the parallel data) and merging them with a fill-up technique [49]. Augmenting the system with non-syntactic phrases [50] and adding soft source syntactic constraints [51] yielded further improvements. Model weights of the syntaxbased system were optimized on a concatenation of dev2010 and dev2012. System Combination. We combined the outputs of the phrase-based primary system, the auxiliary phrase-based indomain system, and the string-to-tree syntax-based system with the MT system combination approach implemented in the Jane toolkit [52]. The parameters of the system combination were optimized on tst2012. The consensus translation produced by the system combination (syscom) was submitted as contrastive 2. 53 Pro"
2014.iwslt-evaluation.6,W14-4018,1,0.890764,"weights of the phrase-based in-domain system were optimized on dev2010. Syntax-based System. The contrastive 1 system is a string-to-tree translation system with similar features as the ones described in [15]. The target-side data was parsed with BitPar [48], and right binarization was applied to the parse trees. The system was adapted to the TED domain by extracting separate rule tables (from the WIT3 corpus and from the rest of the parallel data) and merging them with a fill-up technique [49]. Augmenting the system with non-syntactic phrases [50] and adding soft source syntactic constraints [51] yielded further improvements. Model weights of the syntaxbased system were optimized on a concatenation of dev2010 and dev2012. System Combination. We combined the outputs of the phrase-based primary system, the auxiliary phrase-based indomain system, and the string-to-tree syntax-based system with the MT system combination approach implemented in the Jane toolkit [52]. The parameters of the system combination were optimized on tst2012. The consensus translation produced by the system combination (syscom) was submitted as contrastive 2. 53 Proceedings of the 11th International Workshop on Spo"
2014.iwslt-evaluation.6,E14-2008,1,0.863115,"parate rule tables (from the WIT3 corpus and from the rest of the parallel data) and merging them with a fill-up technique [49]. Augmenting the system with non-syntactic phrases [50] and adding soft source syntactic constraints [51] yielded further improvements. Model weights of the syntaxbased system were optimized on a concatenation of dev2010 and dev2012. System Combination. We combined the outputs of the phrase-based primary system, the auxiliary phrase-based indomain system, and the string-to-tree syntax-based system with the MT system combination approach implemented in the Jane toolkit [52]. The parameters of the system combination were optimized on tst2012. The consensus translation produced by the system combination (syscom) was submitted as contrastive 2. 53 Proceedings of the 11th International Workshop on Spoken Language Translation Lake Tahoe, December 4th and 5th, 2014 4. Summary The Edinburgh submissions for IWSLT cover many language pairs and research techniques. We have implemented a bilingual neural network language model feature in Moses and have demonstrated that it can lead to state-of-the-art results for English→French. BiNNLM seems less beneficial for German→Engl"
2014.iwslt-evaluation.6,N06-2013,0,0.101422,"luster-ids. This result contradicts our findings in last year IWSLT paper [5] where we reported significant gains using class-based models on many European language pairs with English as source language. Monolingual Arabic Data. Unlike parallel data, adding Gigaword and UN monolingual data in English→Arabic translation task gave significant improvements. The gains are shown in Table 5. 3.3. German→English MT 3.2. Arabic-English MT We carried out a number of experiments for the ArabicEnglish language pair which we now discuss briefly. Tokenization. We used MADA tokenizer for source-side Arabic [43] and tried different segmentation schemes including D*, S2 and ATB. The ATB segmentation consistently outperformed other schemes. For the German→English MT task system, prereordering [46] and compound splitting [47] were applied to the German source language side in a preprocessing step. A factored translation model was employed. Source side factors are word, lemma, POS tag, and morphological tag. Target side factors are word, lemma, and POS tag. Supplementary to the features listed in Section 6, we 52 Proceedings of the 11th International Workshop on Spoken Language Translation Lake Tahoe, De"
2014.iwslt-evaluation.6,D11-1033,0,0.239047,"Missing"
2014.iwslt-evaluation.6,P05-1066,1,0.888458,"source language. Monolingual Arabic Data. Unlike parallel data, adding Gigaword and UN monolingual data in English→Arabic translation task gave significant improvements. The gains are shown in Table 5. 3.3. German→English MT 3.2. Arabic-English MT We carried out a number of experiments for the ArabicEnglish language pair which we now discuss briefly. Tokenization. We used MADA tokenizer for source-side Arabic [43] and tried different segmentation schemes including D*, S2 and ATB. The ATB segmentation consistently outperformed other schemes. For the German→English MT task system, prereordering [46] and compound splitting [47] were applied to the German source language side in a preprocessing step. A factored translation model was employed. Source side factors are word, lemma, POS tag, and morphological tag. Target side factors are word, lemma, and POS tag. Supplementary to the features listed in Section 6, we 52 Proceedings of the 11th International Workshop on Spoken Language Translation Lake Tahoe, December 4th and 5th, 2014 incorporated two additional LMs into the German→English MT system: a 7-gram LM over POS tags and a 7-gram LM over lemmas (both trained on WIT3 only). Model weight"
2014.iwslt-evaluation.6,E03-1076,1,0.855843,"Arabic Data. Unlike parallel data, adding Gigaword and UN monolingual data in English→Arabic translation task gave significant improvements. The gains are shown in Table 5. 3.3. German→English MT 3.2. Arabic-English MT We carried out a number of experiments for the ArabicEnglish language pair which we now discuss briefly. Tokenization. We used MADA tokenizer for source-side Arabic [43] and tried different segmentation schemes including D*, S2 and ATB. The ATB segmentation consistently outperformed other schemes. For the German→English MT task system, prereordering [46] and compound splitting [47] were applied to the German source language side in a preprocessing step. A factored translation model was employed. Source side factors are word, lemma, POS tag, and morphological tag. Target side factors are word, lemma, and POS tag. Supplementary to the features listed in Section 6, we 52 Proceedings of the 11th International Workshop on Spoken Language Translation Lake Tahoe, December 4th and 5th, 2014 incorporated two additional LMs into the German→English MT system: a 7-gram LM over POS tags and a 7-gram LM over lemmas (both trained on WIT3 only). Model weights were optimized on a concat"
2014.iwslt-evaluation.6,C04-1024,0,0.157242,"t2012 24.9 24.1 24.8 26.0 27.8 26.7 26.5 27.8 23.4 22.2 23.1 24.5 Table 8: Results for the English→German MT task (casesensitive B LEU scores). The contrastive 2 submission is a system combination of three systems which was tuned on tst2012. LM over Brown clusters and a 7-gram LM over morphological tags (the latter trained on WIT3 only). Model weights of the phrase-based in-domain system were optimized on dev2010. Syntax-based System. The contrastive 1 system is a string-to-tree translation system with similar features as the ones described in [15]. The target-side data was parsed with BitPar [48], and right binarization was applied to the parse trees. The system was adapted to the TED domain by extracting separate rule tables (from the WIT3 corpus and from the rest of the parallel data) and merging them with a fill-up technique [49]. Augmenting the system with non-syntactic phrases [50] and adding soft source syntactic constraints [51] yielded further improvements. Model weights of the syntaxbased system were optimized on a concatenation of dev2010 and dev2012. System Combination. We combined the outputs of the phrase-based primary system, the auxiliary phrase-based indomain system, a"
2014.iwslt-evaluation.6,J03-1002,0,\N,Missing
2014.iwslt-evaluation.6,2011.iwslt-evaluation.18,0,\N,Missing
2014.iwslt-evaluation.7,D14-1003,1,0.921764,"slation of spoken language. The IWSLT TED talks task constitutes an interesting framework for empirical testing of some of the systems for spoken language translation which are developed as part of the project. In this work, we describe the EU-BRIDGE submissions to the 2014 IWSLT translation task. This year, we combined several single systems of RWTH, UEDIN, KIT, and FBK for the German→English SLT, German→English MT, English→German MT, and English→French MT tasks. Additionally to the standard system combination pipeline presented in [1, 2], we applied a recurrent neural network rescoring step [3] for the English→French MT task. Similar cooperative approaches based on system combination have proven to be valuable for machine translation in previous joint submissions, e.g. [4, 5]. 2. RWTH Aachen University RWTH applied the identical training pipeline and models on both language pairs: The state-of-the-art phrase-based baseline systems were augmented with a hierarchical reordering model, several additional language models (LMs) and maximum expected B LEU training for phrasal, lexical and reordering models. Further, RWTH employed rescoring with novel recurrent neural language and translat"
2014.iwslt-evaluation.7,W10-1738,1,0.885248,"and maximum expected B LEU training for phrasal, lexical and reordering models. Further, RWTH employed rescoring with novel recurrent neural language and translation models. The same systems were used for the SLT track, where RWTH ad57 Proceedings of the 11th International Workshop on Spoken Language Translation Lake Tahoe, December 4th and 5th, 2014 ditionally performed punctuation prediction on the automatic transcriptions employing hierarchical phrase-based translation. Both the phrase-based and the hierarchical decoder are implemented in RWTH’s publicly available translation toolkit Jane [6, 7]. The model weights of all systems were tuned with standard Minimum Error Rate Training [8] on the provided dev2012 set. RWTH used B LEU as optimization objective. For the German→English translation direction, in a preprocessing step the German source was decompounded [9] and part-of-speech-based long-range verb reordering rules [10] were applied. RWTH’s translation systems are described in more detail in [11]. Backoff Language Models Each translation system used three backoff LMs that were estimated with the KenLM toolkit [12]: A large general domain 5-gram LM, an in-domain 5-gram LM and a 7-"
2014.iwslt-evaluation.7,P03-1021,0,0.488353,"employed rescoring with novel recurrent neural language and translation models. The same systems were used for the SLT track, where RWTH ad57 Proceedings of the 11th International Workshop on Spoken Language Translation Lake Tahoe, December 4th and 5th, 2014 ditionally performed punctuation prediction on the automatic transcriptions employing hierarchical phrase-based translation. Both the phrase-based and the hierarchical decoder are implemented in RWTH’s publicly available translation toolkit Jane [6, 7]. The model weights of all systems were tuned with standard Minimum Error Rate Training [8] on the provided dev2012 set. RWTH used B LEU as optimization objective. For the German→English translation direction, in a preprocessing step the German source was decompounded [9] and part-of-speech-based long-range verb reordering rules [10] were applied. RWTH’s translation systems are described in more detail in [11]. Backoff Language Models Each translation system used three backoff LMs that were estimated with the KenLM toolkit [12]: A large general domain 5-gram LM, an in-domain 5-gram LM and a 7-gram word class language model (wcLM). All of them used interpolated Kneser-Ney smoothing."
2014.iwslt-evaluation.7,popovic-ney-2006-pos,1,0.798687,"th and 5th, 2014 ditionally performed punctuation prediction on the automatic transcriptions employing hierarchical phrase-based translation. Both the phrase-based and the hierarchical decoder are implemented in RWTH’s publicly available translation toolkit Jane [6, 7]. The model weights of all systems were tuned with standard Minimum Error Rate Training [8] on the provided dev2012 set. RWTH used B LEU as optimization objective. For the German→English translation direction, in a preprocessing step the German source was decompounded [9] and part-of-speech-based long-range verb reordering rules [10] were applied. RWTH’s translation systems are described in more detail in [11]. Backoff Language Models Each translation system used three backoff LMs that were estimated with the KenLM toolkit [12]: A large general domain 5-gram LM, an in-domain 5-gram LM and a 7-gram word class language model (wcLM). All of them used interpolated Kneser-Ney smoothing. For the general domain LM, RWTH first selected 12 of the English Shuffled News, and 41 of the French Shuffled News as well as both the English and French Gigaword corpora by the cross-entropy difference criterion described in [13]. The selectio"
2014.iwslt-evaluation.7,P13-2121,1,0.819366,"mplemented in RWTH’s publicly available translation toolkit Jane [6, 7]. The model weights of all systems were tuned with standard Minimum Error Rate Training [8] on the provided dev2012 set. RWTH used B LEU as optimization objective. For the German→English translation direction, in a preprocessing step the German source was decompounded [9] and part-of-speech-based long-range verb reordering rules [10] were applied. RWTH’s translation systems are described in more detail in [11]. Backoff Language Models Each translation system used three backoff LMs that were estimated with the KenLM toolkit [12]: A large general domain 5-gram LM, an in-domain 5-gram LM and a 7-gram word class language model (wcLM). All of them used interpolated Kneser-Ney smoothing. For the general domain LM, RWTH first selected 12 of the English Shuffled News, and 41 of the French Shuffled News as well as both the English and French Gigaword corpora by the cross-entropy difference criterion described in [13]. The selection was then concatenated with all available remaining monolingual data and used to build and unpruned LM. The in-domain language models were estimated on the TED data only. For the word class LM, RWT"
2014.iwslt-evaluation.7,P10-2041,0,0.0916594,"rdering rules [10] were applied. RWTH’s translation systems are described in more detail in [11]. Backoff Language Models Each translation system used three backoff LMs that were estimated with the KenLM toolkit [12]: A large general domain 5-gram LM, an in-domain 5-gram LM and a 7-gram word class language model (wcLM). All of them used interpolated Kneser-Ney smoothing. For the general domain LM, RWTH first selected 12 of the English Shuffled News, and 41 of the French Shuffled News as well as both the English and French Gigaword corpora by the cross-entropy difference criterion described in [13]. The selection was then concatenated with all available remaining monolingual data and used to build and unpruned LM. The in-domain language models were estimated on the TED data only. For the word class LM, RWTH trained 200 classes on the target side of the bilingual training data using an in-house tool similar to mkcls [14]. With these class definitions, RWTH applied the technique shown in [15] to compute the wcLM on the same data as the general-domain LM. Maximum Expected B LEU Training RWTH applied discriminative training, learning three types of features under a maximum expected B LEU ob"
2014.iwslt-evaluation.7,E99-1010,0,0.0737032,"them used interpolated Kneser-Ney smoothing. For the general domain LM, RWTH first selected 12 of the English Shuffled News, and 41 of the French Shuffled News as well as both the English and French Gigaword corpora by the cross-entropy difference criterion described in [13]. The selection was then concatenated with all available remaining monolingual data and used to build and unpruned LM. The in-domain language models were estimated on the TED data only. For the word class LM, RWTH trained 200 classes on the target side of the bilingual training data using an in-house tool similar to mkcls [14]. With these class definitions, RWTH applied the technique shown in [15] to compute the wcLM on the same data as the general-domain LM. Maximum Expected B LEU Training RWTH applied discriminative training, learning three types of features under a maximum expected B LEU objective [16]. It was performed on the TED portion of the data, which is high quality in-domain data of reasonable size. This makes training feasible while at the same time providing an implicit domain adaptation effect. Similar to [16], RWTH generated 100-best lists on the training data which were used as training samples for"
2014.iwslt-evaluation.7,D13-1138,1,0.85854,"RWTH first selected 12 of the English Shuffled News, and 41 of the French Shuffled News as well as both the English and French Gigaword corpora by the cross-entropy difference criterion described in [13]. The selection was then concatenated with all available remaining monolingual data and used to build and unpruned LM. The in-domain language models were estimated on the TED data only. For the word class LM, RWTH trained 200 classes on the target side of the bilingual training data using an in-house tool similar to mkcls [14]. With these class definitions, RWTH applied the technique shown in [15] to compute the wcLM on the same data as the general-domain LM. Maximum Expected B LEU Training RWTH applied discriminative training, learning three types of features under a maximum expected B LEU objective [16]. It was performed on the TED portion of the data, which is high quality in-domain data of reasonable size. This makes training feasible while at the same time providing an implicit domain adaptation effect. Similar to [16], RWTH generated 100-best lists on the training data which were used as training samples for a gradient based update method. Leave-oneout [17] was applied to circumv"
2014.iwslt-evaluation.7,P12-1031,0,0.0125863,"lection was then concatenated with all available remaining monolingual data and used to build and unpruned LM. The in-domain language models were estimated on the TED data only. For the word class LM, RWTH trained 200 classes on the target side of the bilingual training data using an in-house tool similar to mkcls [14]. With these class definitions, RWTH applied the technique shown in [15] to compute the wcLM on the same data as the general-domain LM. Maximum Expected B LEU Training RWTH applied discriminative training, learning three types of features under a maximum expected B LEU objective [16]. It was performed on the TED portion of the data, which is high quality in-domain data of reasonable size. This makes training feasible while at the same time providing an implicit domain adaptation effect. Similar to [16], RWTH generated 100-best lists on the training data which were used as training samples for a gradient based update method. Leave-oneout [17] was applied to circumvent over-fitting. Here, RWTH followed an approach similar to [18], where each feature type was condensed into a single feature for the log-linear model combination. In the first pass, RWTH trained phrase pair and"
2014.iwslt-evaluation.7,P10-1049,1,0.833909,"the technique shown in [15] to compute the wcLM on the same data as the general-domain LM. Maximum Expected B LEU Training RWTH applied discriminative training, learning three types of features under a maximum expected B LEU objective [16]. It was performed on the TED portion of the data, which is high quality in-domain data of reasonable size. This makes training feasible while at the same time providing an implicit domain adaptation effect. Similar to [16], RWTH generated 100-best lists on the training data which were used as training samples for a gradient based update method. Leave-oneout [17] was applied to circumvent over-fitting. Here, RWTH followed an approach similar to [18], where each feature type was condensed into a single feature for the log-linear model combination. In the first pass, RWTH trained phrase pair and phrase-internal word pair features, and in the second pass a hierarchical reordering model, resulting altogether in an additional eight models for log-linear combination. Recurrent Neural Network Models All systems applied rescoring on 1000-best lists using recurrent language and translation models. The recurrency was handled with the long short-term memory (LST"
2014.iwslt-evaluation.7,D14-1132,0,0.157332,"M. Maximum Expected B LEU Training RWTH applied discriminative training, learning three types of features under a maximum expected B LEU objective [16]. It was performed on the TED portion of the data, which is high quality in-domain data of reasonable size. This makes training feasible while at the same time providing an implicit domain adaptation effect. Similar to [16], RWTH generated 100-best lists on the training data which were used as training samples for a gradient based update method. Leave-oneout [17] was applied to circumvent over-fitting. Here, RWTH followed an approach similar to [18], where each feature type was condensed into a single feature for the log-linear model combination. In the first pass, RWTH trained phrase pair and phrase-internal word pair features, and in the second pass a hierarchical reordering model, resulting altogether in an additional eight models for log-linear combination. Recurrent Neural Network Models All systems applied rescoring on 1000-best lists using recurrent language and translation models. The recurrency was handled with the long short-term memory (LSTM) architecture [19] and RWTH used a class-factored output layer for increased efficienc"
2014.iwslt-evaluation.7,2011.iwslt-papers.7,1,0.944851,"ort-term memory (LSTM) architecture [19] and RWTH used a class-factored output layer for increased efficiency as described in [20]. All neural networks were trained on the TED portion of the data with 2000 word classes. In addition to the recurrent language model (RNN-LM), RWTH applied the deep bidirectional word-based translation model (RNN-BTM) described in [3], which is capable of taking the full source context into account for each translation decision. Spoken Language Translation For the SLT task, RWTH reintroduced punctuation and case information before the actual translation similar to [21]. However, RWTH employed a hierarchical phrase-based system with a maximum of one nonterminal symbol per rule in place of a phrase-based system. A punctuation prediction system based on hierarchical translation is able to capture long-range dependencies between words and punctuation marks and is more robust for unseen word sequences. The model weights are tuned with standard MERT on 100best lists. As optimization criterion RWTH used F2 -Score rather than B LEU or W ER. More details can be found in [22]. Since punctuation predicting and recasing were applied before the actual translation, the f"
2014.iwslt-evaluation.7,2014.iwslt-papers.17,1,0.734908,"RWTH reintroduced punctuation and case information before the actual translation similar to [21]. However, RWTH employed a hierarchical phrase-based system with a maximum of one nonterminal symbol per rule in place of a phrase-based system. A punctuation prediction system based on hierarchical translation is able to capture long-range dependencies between words and punctuation marks and is more robust for unseen word sequences. The model weights are tuned with standard MERT on 100best lists. As optimization criterion RWTH used F2 -Score rather than B LEU or W ER. More details can be found in [22]. Since punctuation predicting and recasing were applied before the actual translation, the final translation systems from the MT track could be kept completely unchanged. 3. University of Edinburgh The UEDIN translation engines [23] are based on the open source Moses toolkit [24]. UEDIN set up phrase-based systems for all SLT and MT tasks covered in this paper, and additionally a string-to-tree syntax-based system [25] for the English→German MT task. The systems were trained using monolingual and parallel data from WIT3 , Europarl, MultiUN, the English and French Gigaword corpora as provided"
2014.iwslt-evaluation.7,P07-2045,1,0.0190208,"n hierarchical translation is able to capture long-range dependencies between words and punctuation marks and is more robust for unseen word sequences. The model weights are tuned with standard MERT on 100best lists. As optimization criterion RWTH used F2 -Score rather than B LEU or W ER. More details can be found in [22]. Since punctuation predicting and recasing were applied before the actual translation, the final translation systems from the MT track could be kept completely unchanged. 3. University of Edinburgh The UEDIN translation engines [23] are based on the open source Moses toolkit [24]. UEDIN set up phrase-based systems for all SLT and MT tasks covered in this paper, and additionally a string-to-tree syntax-based system [25] for the English→German MT task. The systems were trained using monolingual and parallel data from WIT3 , Europarl, MultiUN, the English and French Gigaword corpora as provided by the Linguistic Data Consortium, the German Political Speeches Corpus, and the Common Crawl, 109 , and News Commentary corpora from the WMT shared task training data. Word alignments for the MT track systems were created by aligning the data in both directions with MGIZA++ [26]"
2014.iwslt-evaluation.7,N04-1035,0,0.0565459,"equences. The model weights are tuned with standard MERT on 100best lists. As optimization criterion RWTH used F2 -Score rather than B LEU or W ER. More details can be found in [22]. Since punctuation predicting and recasing were applied before the actual translation, the final translation systems from the MT track could be kept completely unchanged. 3. University of Edinburgh The UEDIN translation engines [23] are based on the open source Moses toolkit [24]. UEDIN set up phrase-based systems for all SLT and MT tasks covered in this paper, and additionally a string-to-tree syntax-based system [25] for the English→German MT task. The systems were trained using monolingual and parallel data from WIT3 , Europarl, MultiUN, the English and French Gigaword corpora as provided by the Linguistic Data Consortium, the German Political Speeches Corpus, and the Common Crawl, 109 , and News Commentary corpora from the WMT shared task training data. Word alignments for the MT track systems were created by aligning the data in both directions with MGIZA++ [26] and symmetrizing the two trained alignments. Word alignments for the SLT track system were created using fast align [27]. The SRILM toolkit [2"
2014.iwslt-evaluation.7,W08-0509,0,0.192359,"[24]. UEDIN set up phrase-based systems for all SLT and MT tasks covered in this paper, and additionally a string-to-tree syntax-based system [25] for the English→German MT task. The systems were trained using monolingual and parallel data from WIT3 , Europarl, MultiUN, the English and French Gigaword corpora as provided by the Linguistic Data Consortium, the German Political Speeches Corpus, and the Common Crawl, 109 , and News Commentary corpora from the WMT shared task training data. Word alignments for the MT track systems were created by aligning the data in both directions with MGIZA++ [26] and symmetrizing the two trained alignments. Word alignments for the SLT track system were created using fast align [27]. The SRILM toolkit [28] was employed to train 5-gram LMs with modified Kneser-Ney smoothing [29]. UEDIN trained individual LMs on each corpus and then interpolated them using weights tuned to minimize perplexity on a development set. Common features included in the UEDIN phrase-based systems are the language model, phrase translation scores in both directions smoothed with Good-Turing discounting, lexical translation scores in both directions, word and phrase penalties, six"
2014.iwslt-evaluation.7,N13-1073,0,0.0453396,"e syntax-based system [25] for the English→German MT task. The systems were trained using monolingual and parallel data from WIT3 , Europarl, MultiUN, the English and French Gigaword corpora as provided by the Linguistic Data Consortium, the German Political Speeches Corpus, and the Common Crawl, 109 , and News Commentary corpora from the WMT shared task training data. Word alignments for the MT track systems were created by aligning the data in both directions with MGIZA++ [26] and symmetrizing the two trained alignments. Word alignments for the SLT track system were created using fast align [27]. The SRILM toolkit [28] was employed to train 5-gram LMs with modified Kneser-Ney smoothing [29]. UEDIN trained individual LMs on each corpus and then interpolated them using weights tuned to minimize perplexity on a development set. Common features included in the UEDIN phrase-based systems are the language model, phrase translation scores in both directions smoothed with Good-Turing discounting, lexical translation scores in both directions, word and phrase penalties, six simple count-based binary features, distancebased distortion costs, a hierarchical lexicalized reordering model [30], sp"
2014.iwslt-evaluation.7,C14-1041,1,0.839592,"ndividual LMs on each corpus and then interpolated them using weights tuned to minimize perplexity on a development set. Common features included in the UEDIN phrase-based systems are the language model, phrase translation scores in both directions smoothed with Good-Turing discounting, lexical translation scores in both directions, word and phrase penalties, six simple count-based binary features, distancebased distortion costs, a hierarchical lexicalized reordering model [30], sparse lexical and domain indicator features [31] and operation sequence models over different word representations [32]. Model weights were optimized with batch MIRA [33] to maximize B LEU [34]. Spoken Language Translation One of the main challenges of spoken language translation is to overcome the mismatch in the style of data that the 58 Proceedings of the 11th International Workshop on Spoken Language Translation Lake Tahoe, December 4th and 5th, 2014 speech recognition systems output, and the written text that is used to train the translation model. ASR system output lacks punctuation and capitalization, which is the main stylistic differences. Previous research [35, 21, 36] suggests that it is preferrable"
2014.iwslt-evaluation.7,N12-1047,0,0.0681194,"them using weights tuned to minimize perplexity on a development set. Common features included in the UEDIN phrase-based systems are the language model, phrase translation scores in both directions smoothed with Good-Turing discounting, lexical translation scores in both directions, word and phrase penalties, six simple count-based binary features, distancebased distortion costs, a hierarchical lexicalized reordering model [30], sparse lexical and domain indicator features [31] and operation sequence models over different word representations [32]. Model weights were optimized with batch MIRA [33] to maximize B LEU [34]. Spoken Language Translation One of the main challenges of spoken language translation is to overcome the mismatch in the style of data that the 58 Proceedings of the 11th International Workshop on Spoken Language Translation Lake Tahoe, December 4th and 5th, 2014 speech recognition systems output, and the written text that is used to train the translation model. ASR system output lacks punctuation and capitalization, which is the main stylistic differences. Previous research [35, 21, 36] suggests that it is preferrable to punctuate the text before translation, which is"
2014.iwslt-evaluation.7,P02-1040,0,0.0918061,"d to minimize perplexity on a development set. Common features included in the UEDIN phrase-based systems are the language model, phrase translation scores in both directions smoothed with Good-Turing discounting, lexical translation scores in both directions, word and phrase penalties, six simple count-based binary features, distancebased distortion costs, a hierarchical lexicalized reordering model [30], sparse lexical and domain indicator features [31] and operation sequence models over different word representations [32]. Model weights were optimized with batch MIRA [33] to maximize B LEU [34]. Spoken Language Translation One of the main challenges of spoken language translation is to overcome the mismatch in the style of data that the 58 Proceedings of the 11th International Workshop on Spoken Language Translation Lake Tahoe, December 4th and 5th, 2014 speech recognition systems output, and the written text that is used to train the translation model. ASR system output lacks punctuation and capitalization, which is the main stylistic differences. Previous research [35, 21, 36] suggests that it is preferrable to punctuate the text before translation, which is what UEDIN did by trai"
2014.iwslt-evaluation.7,2006.iwslt-papers.1,1,0.862433,"els over different word representations [32]. Model weights were optimized with batch MIRA [33] to maximize B LEU [34]. Spoken Language Translation One of the main challenges of spoken language translation is to overcome the mismatch in the style of data that the 58 Proceedings of the 11th International Workshop on Spoken Language Translation Lake Tahoe, December 4th and 5th, 2014 speech recognition systems output, and the written text that is used to train the translation model. ASR system output lacks punctuation and capitalization, which is the main stylistic differences. Previous research [35, 21, 36] suggests that it is preferrable to punctuate the text before translation, which is what UEDIN did by training a translation system on the German side of the parallel data. The “source language” of the system had punctuation and capitalization stripped, and the “target language” was the standard German parallel text. The handling of punctuation is similar to the other groups in this paper, however UEDIN used a phrase-based model with no distortion or reordering, and tuned the model to the ASR input text using batch MIRA and the B LEU score. German→English MT For the UEDIN German→English MT tas"
2014.iwslt-evaluation.7,2012.iwslt-papers.15,1,0.927241,"els over different word representations [32]. Model weights were optimized with batch MIRA [33] to maximize B LEU [34]. Spoken Language Translation One of the main challenges of spoken language translation is to overcome the mismatch in the style of data that the 58 Proceedings of the 11th International Workshop on Spoken Language Translation Lake Tahoe, December 4th and 5th, 2014 speech recognition systems output, and the written text that is used to train the translation model. ASR system output lacks punctuation and capitalization, which is the main stylistic differences. Previous research [35, 21, 36] suggests that it is preferrable to punctuate the text before translation, which is what UEDIN did by training a translation system on the German side of the parallel data. The “source language” of the system had punctuation and capitalization stripped, and the “target language” was the standard German parallel text. The handling of punctuation is similar to the other groups in this paper, however UEDIN used a phrase-based model with no distortion or reordering, and tuned the model to the ASR input text using batch MIRA and the B LEU score. German→English MT For the UEDIN German→English MT tas"
2014.iwslt-evaluation.7,P05-1066,1,0.733044,"ferrable to punctuate the text before translation, which is what UEDIN did by training a translation system on the German side of the parallel data. The “source language” of the system had punctuation and capitalization stripped, and the “target language” was the standard German parallel text. The handling of punctuation is similar to the other groups in this paper, however UEDIN used a phrase-based model with no distortion or reordering, and tuned the model to the ASR input text using batch MIRA and the B LEU score. German→English MT For the UEDIN German→English MT task system, prereordering [37] and compound splitting [38] were applied to the German source language side in a preprocessing step. A factored translation model [39] was employed. Source side factors are word, lemma, part-of-speech (POS) tag, and morphological tag. Target side factors are word, lemma, and POS tag. UEDIN incorporated two additional LMs into the German→English MT system: a 7-gram LM over POS tags (trained on WIT3 only) and a 7-gram LM over lemmas (trained on WIT3 only). Model weights were optimized on a concatenation of dev2010 and dev2012. English→French MT UEDIN contributed two phrase-based systems for the"
2014.iwslt-evaluation.7,E03-1076,1,0.858704,"xt before translation, which is what UEDIN did by training a translation system on the German side of the parallel data. The “source language” of the system had punctuation and capitalization stripped, and the “target language” was the standard German parallel text. The handling of punctuation is similar to the other groups in this paper, however UEDIN used a phrase-based model with no distortion or reordering, and tuned the model to the ASR input text using batch MIRA and the B LEU score. German→English MT For the UEDIN German→English MT task system, prereordering [37] and compound splitting [38] were applied to the German source language side in a preprocessing step. A factored translation model [39] was employed. Source side factors are word, lemma, part-of-speech (POS) tag, and morphological tag. Target side factors are word, lemma, and POS tag. UEDIN incorporated two additional LMs into the German→English MT system: a 7-gram LM over POS tags (trained on WIT3 only) and a 7-gram LM over lemmas (trained on WIT3 only). Model weights were optimized on a concatenation of dev2010 and dev2012. English→French MT UEDIN contributed two phrase-based systems for the English→French EU-BRIDGE sy"
2014.iwslt-evaluation.7,2012.amta-papers.9,1,0.84942,"arallel data. The “source language” of the system had punctuation and capitalization stripped, and the “target language” was the standard German parallel text. The handling of punctuation is similar to the other groups in this paper, however UEDIN used a phrase-based model with no distortion or reordering, and tuned the model to the ASR input text using batch MIRA and the B LEU score. German→English MT For the UEDIN German→English MT task system, prereordering [37] and compound splitting [38] were applied to the German source language side in a preprocessing step. A factored translation model [39] was employed. Source side factors are word, lemma, part-of-speech (POS) tag, and morphological tag. Target side factors are word, lemma, and POS tag. UEDIN incorporated two additional LMs into the German→English MT system: a 7-gram LM over POS tags (trained on WIT3 only) and a 7-gram LM over lemmas (trained on WIT3 only). Model weights were optimized on a concatenation of dev2010 and dev2012. English→French MT UEDIN contributed two phrase-based systems for the English→French EU-BRIDGE system combination. Both comprise Brown clusters with 200 classes as additional factors on source and target"
2014.iwslt-evaluation.7,D08-1089,0,0.176922,"ign [27]. The SRILM toolkit [28] was employed to train 5-gram LMs with modified Kneser-Ney smoothing [29]. UEDIN trained individual LMs on each corpus and then interpolated them using weights tuned to minimize perplexity on a development set. Common features included in the UEDIN phrase-based systems are the language model, phrase translation scores in both directions smoothed with Good-Turing discounting, lexical translation scores in both directions, word and phrase penalties, six simple count-based binary features, distancebased distortion costs, a hierarchical lexicalized reordering model [30], sparse lexical and domain indicator features [31] and operation sequence models over different word representations [32]. Model weights were optimized with batch MIRA [33] to maximize B LEU [34]. Spoken Language Translation One of the main challenges of spoken language translation is to overcome the mismatch in the style of data that the 58 Proceedings of the 11th International Workshop on Spoken Language Translation Lake Tahoe, December 4th and 5th, 2014 speech recognition systems output, and the written text that is used to train the translation model. ASR system output lacks punctuation a"
2014.iwslt-evaluation.7,W14-3324,1,0.784121,"ical tag. UEDIN-A was trained with all corpora, whereas for UEDIN-B the parallel training data was restricted to the indomain WIT3 corpus. Additional features of the systems are: a 5-gram LM over Brown clusters, a 7-gram LM over morphological tags (UEDIN-A: trained on all data, UEDIN-B: trained on WIT3 only), and a 7-gram LM over POS tags (UEDIN-A, not UEDIN-B). Model weights of UEDIN-B were optimized on dev2010, model weights of UEDIN-A on a concatenation of dev2010 and dev2012. Syntax-based system. UEDIN-C is a string-to-tree translation system with similar features as the ones described in [40]. The target-side data was parsed with BitPar [41], and right binarization was applied to the parse trees. The system was adapted to the TED domain by extracting separate rule tables (from the WIT3 corpus and from the rest of the parallel data) and merging them with a fill-up technique [42]. Augmenting the system with non-syntactic phrases [43] and adding soft source syntactic constraints [44] yielded further improvements. Model weights of UEDIN-C were optimized on a concatenation of dev2010 and dev2012. 4. Karlsruhe Institute of Technology The KIT translations were generated by an in-house ph"
2014.iwslt-evaluation.7,2012.iwslt-papers.17,1,0.881764,"ain 5-gram LMs with modified Kneser-Ney smoothing [29]. UEDIN trained individual LMs on each corpus and then interpolated them using weights tuned to minimize perplexity on a development set. Common features included in the UEDIN phrase-based systems are the language model, phrase translation scores in both directions smoothed with Good-Turing discounting, lexical translation scores in both directions, word and phrase penalties, six simple count-based binary features, distancebased distortion costs, a hierarchical lexicalized reordering model [30], sparse lexical and domain indicator features [31] and operation sequence models over different word representations [32]. Model weights were optimized with batch MIRA [33] to maximize B LEU [34]. Spoken Language Translation One of the main challenges of spoken language translation is to overcome the mismatch in the style of data that the 58 Proceedings of the 11th International Workshop on Spoken Language Translation Lake Tahoe, December 4th and 5th, 2014 speech recognition systems output, and the written text that is used to train the translation model. ASR system output lacks punctuation and capitalization, which is the main stylistic diff"
2014.iwslt-evaluation.7,C04-1024,0,0.0400394,"ereas for UEDIN-B the parallel training data was restricted to the indomain WIT3 corpus. Additional features of the systems are: a 5-gram LM over Brown clusters, a 7-gram LM over morphological tags (UEDIN-A: trained on all data, UEDIN-B: trained on WIT3 only), and a 7-gram LM over POS tags (UEDIN-A, not UEDIN-B). Model weights of UEDIN-B were optimized on dev2010, model weights of UEDIN-A on a concatenation of dev2010 and dev2012. Syntax-based system. UEDIN-C is a string-to-tree translation system with similar features as the ones described in [40]. The target-side data was parsed with BitPar [41], and right binarization was applied to the parse trees. The system was adapted to the TED domain by extracting separate rule tables (from the WIT3 corpus and from the rest of the parallel data) and merging them with a fill-up technique [42]. Augmenting the system with non-syntactic phrases [43] and adding soft source syntactic constraints [44] yielded further improvements. Model weights of UEDIN-C were optimized on a concatenation of dev2010 and dev2012. 4. Karlsruhe Institute of Technology The KIT translations were generated by an in-house phrasebased translations system [45]. The models wer"
2014.iwslt-evaluation.7,2011.iwslt-evaluation.18,1,0.873679,"ined on WIT3 only), and a 7-gram LM over POS tags (UEDIN-A, not UEDIN-B). Model weights of UEDIN-B were optimized on dev2010, model weights of UEDIN-A on a concatenation of dev2010 and dev2012. Syntax-based system. UEDIN-C is a string-to-tree translation system with similar features as the ones described in [40]. The target-side data was parsed with BitPar [41], and right binarization was applied to the parse trees. The system was adapted to the TED domain by extracting separate rule tables (from the WIT3 corpus and from the rest of the parallel data) and merging them with a fill-up technique [42]. Augmenting the system with non-syntactic phrases [43] and adding soft source syntactic constraints [44] yielded further improvements. Model weights of UEDIN-C were optimized on a concatenation of dev2010 and dev2012. 4. Karlsruhe Institute of Technology The KIT translations were generated by an in-house phrasebased translations system [45]. The models were trained on the Europarl, News Commentary, WIT3 , Common Crawl corpora for all directions, as well as on the additional monolingual training data. The noisy Crawl corpora were filtered using an SVM classifier [46]. In addition to the standa"
2014.iwslt-evaluation.7,W14-3362,1,0.610881,"N-A, not UEDIN-B). Model weights of UEDIN-B were optimized on dev2010, model weights of UEDIN-A on a concatenation of dev2010 and dev2012. Syntax-based system. UEDIN-C is a string-to-tree translation system with similar features as the ones described in [40]. The target-side data was parsed with BitPar [41], and right binarization was applied to the parse trees. The system was adapted to the TED domain by extracting separate rule tables (from the WIT3 corpus and from the rest of the parallel data) and merging them with a fill-up technique [42]. Augmenting the system with non-syntactic phrases [43] and adding soft source syntactic constraints [44] yielded further improvements. Model weights of UEDIN-C were optimized on a concatenation of dev2010 and dev2012. 4. Karlsruhe Institute of Technology The KIT translations were generated by an in-house phrasebased translations system [45]. The models were trained on the Europarl, News Commentary, WIT3 , Common Crawl corpora for all directions, as well as on the additional monolingual training data. The noisy Crawl corpora were filtered using an SVM classifier [46]. In addition to the standard preprocessing, KIT used compound splitting [38] for"
2014.iwslt-evaluation.7,W14-4018,1,0.774295,"ptimized on dev2010, model weights of UEDIN-A on a concatenation of dev2010 and dev2012. Syntax-based system. UEDIN-C is a string-to-tree translation system with similar features as the ones described in [40]. The target-side data was parsed with BitPar [41], and right binarization was applied to the parse trees. The system was adapted to the TED domain by extracting separate rule tables (from the WIT3 corpus and from the rest of the parallel data) and merging them with a fill-up technique [42]. Augmenting the system with non-syntactic phrases [43] and adding soft source syntactic constraints [44] yielded further improvements. Model weights of UEDIN-C were optimized on a concatenation of dev2010 and dev2012. 4. Karlsruhe Institute of Technology The KIT translations were generated by an in-house phrasebased translations system [45]. The models were trained on the Europarl, News Commentary, WIT3 , Common Crawl corpora for all directions, as well as on the additional monolingual training data. The noisy Crawl corpora were filtered using an SVM classifier [46]. In addition to the standard preprocessing, KIT used compound splitting [38] for the German text when translating from German. In t"
2014.iwslt-evaluation.7,2011.iwslt-evaluation.9,1,0.861968,"m with a fill-up technique [42]. Augmenting the system with non-syntactic phrases [43] and adding soft source syntactic constraints [44] yielded further improvements. Model weights of UEDIN-C were optimized on a concatenation of dev2010 and dev2012. 4. Karlsruhe Institute of Technology The KIT translations were generated by an in-house phrasebased translations system [45]. The models were trained on the Europarl, News Commentary, WIT3 , Common Crawl corpora for all directions, as well as on the additional monolingual training data. The noisy Crawl corpora were filtered using an SVM classifier [46]. In addition to the standard preprocessing, KIT used compound splitting [38] for the German text when translating from German. In the SLT task, KIT first recased the input and added punctuation marks to the ASR hypotheses. This was done with a monolingual translation system as shown in [36]. In all translation directions, KIT used a pre-reordering approach. Different reorderings of the source sentences were encoded in a word lattice. For the English→French system, only short-range rules were used to generate these lattices [47]. Long-range rules [48] and tree-based reordering rules [49] were"
2014.iwslt-evaluation.7,2007.tmi-papers.21,0,0.0614729,"ta. The noisy Crawl corpora were filtered using an SVM classifier [46]. In addition to the standard preprocessing, KIT used compound splitting [38] for the German text when translating from German. In the SLT task, KIT first recased the input and added punctuation marks to the ASR hypotheses. This was done with a monolingual translation system as shown in [36]. In all translation directions, KIT used a pre-reordering approach. Different reorderings of the source sentences were encoded in a word lattice. For the English→French system, only short-range rules were used to generate these lattices [47]. Long-range rules [48] and tree-based reordering rules [49] were used for German→English. The POS tags needed for these rules were generated by the TreeTagger [50] and the parse trees by the Stanford Parser [51]. In addition, for the language pairs involving German KIT applied the different reorderings of both language pairs using a lexicalized reordering model. The phrase tables of the systems were trained using GIZA++ alignment [52]. KIT adapted the phrase table to the TED domain using the backoff approach and by means of candidate selection [53]. In addition to the phrase table probabiliti"
2014.iwslt-evaluation.7,W09-0413,1,0.842557,"pora were filtered using an SVM classifier [46]. In addition to the standard preprocessing, KIT used compound splitting [38] for the German text when translating from German. In the SLT task, KIT first recased the input and added punctuation marks to the ASR hypotheses. This was done with a monolingual translation system as shown in [36]. In all translation directions, KIT used a pre-reordering approach. Different reorderings of the source sentences were encoded in a word lattice. For the English→French system, only short-range rules were used to generate these lattices [47]. Long-range rules [48] and tree-based reordering rules [49] were used for German→English. The POS tags needed for these rules were generated by the TreeTagger [50] and the parse trees by the Stanford Parser [51]. In addition, for the language pairs involving German KIT applied the different reorderings of both language pairs using a lexicalized reordering model. The phrase tables of the systems were trained using GIZA++ alignment [52]. KIT adapted the phrase table to the TED domain using the backoff approach and by means of candidate selection [53]. In addition to the phrase table probabilities, KIT modeled the tra"
2014.iwslt-evaluation.7,W13-0805,1,0.85195,"ifier [46]. In addition to the standard preprocessing, KIT used compound splitting [38] for the German text when translating from German. In the SLT task, KIT first recased the input and added punctuation marks to the ASR hypotheses. This was done with a monolingual translation system as shown in [36]. In all translation directions, KIT used a pre-reordering approach. Different reorderings of the source sentences were encoded in a word lattice. For the English→French system, only short-range rules were used to generate these lattices [47]. Long-range rules [48] and tree-based reordering rules [49] were used for German→English. The POS tags needed for these rules were generated by the TreeTagger [50] and the parse trees by the Stanford Parser [51]. In addition, for the language pairs involving German KIT applied the different reorderings of both language pairs using a lexicalized reordering model. The phrase tables of the systems were trained using GIZA++ alignment [52]. KIT adapted the phrase table to the TED domain using the backoff approach and by means of candidate selection [53]. In addition to the phrase table probabilities, KIT modeled the translation process by a bilingual langu"
2014.iwslt-evaluation.7,W08-1006,0,0.0150981,"k, KIT first recased the input and added punctuation marks to the ASR hypotheses. This was done with a monolingual translation system as shown in [36]. In all translation directions, KIT used a pre-reordering approach. Different reorderings of the source sentences were encoded in a word lattice. For the English→French system, only short-range rules were used to generate these lattices [47]. Long-range rules [48] and tree-based reordering rules [49] were used for German→English. The POS tags needed for these rules were generated by the TreeTagger [50] and the parse trees by the Stanford Parser [51]. In addition, for the language pairs involving German KIT applied the different reorderings of both language pairs using a lexicalized reordering model. The phrase tables of the systems were trained using GIZA++ alignment [52]. KIT adapted the phrase table to the TED domain using the backoff approach and by means of candidate selection [53]. In addition to the phrase table probabilities, KIT modeled the translation process by a bilingual language model [54] and a discriminative word lexicon using source context features [55]. During decoding, KIT used several LMs to adapt the system to the ta"
2014.iwslt-evaluation.7,2012.amta-papers.19,1,0.839901,"e rules were used to generate these lattices [47]. Long-range rules [48] and tree-based reordering rules [49] were used for German→English. The POS tags needed for these rules were generated by the TreeTagger [50] and the parse trees by the Stanford Parser [51]. In addition, for the language pairs involving German KIT applied the different reorderings of both language pairs using a lexicalized reordering model. The phrase tables of the systems were trained using GIZA++ alignment [52]. KIT adapted the phrase table to the TED domain using the backoff approach and by means of candidate selection [53]. In addition to the phrase table probabilities, KIT modeled the translation process by a bilingual language model [54] and a discriminative word lexicon using source context features [55]. During decoding, KIT used several LMs to adapt the system to the task and to better model the sentence structure using a class-based LM. For the German→English task, KIT used one LM trained on all data, an in-domain LM trained only on the WIT3 corpus, and one LM trained on 5M sentences selected using cross-entropy difference [13]. As classes KIT used the clusters obtained using the mkcls algorithm on the WI"
2014.iwslt-evaluation.7,W11-2124,1,0.902739,"for German→English. The POS tags needed for these rules were generated by the TreeTagger [50] and the parse trees by the Stanford Parser [51]. In addition, for the language pairs involving German KIT applied the different reorderings of both language pairs using a lexicalized reordering model. The phrase tables of the systems were trained using GIZA++ alignment [52]. KIT adapted the phrase table to the TED domain using the backoff approach and by means of candidate selection [53]. In addition to the phrase table probabilities, KIT modeled the translation process by a bilingual language model [54] and a discriminative word lexicon using source context features [55]. During decoding, KIT used several LMs to adapt the system to the task and to better model the sentence structure using a class-based LM. For the German→English task, KIT used one LM trained on all data, an in-domain LM trained only on the WIT3 corpus, and one LM trained on 5M sentences selected using cross-entropy difference [13]. As classes KIT used the clusters obtained using the mkcls algorithm on the WIT3 corpus. For German↔ English, KIT used a 9-gram LM with 100 or 1000 clusters and for the English→French MT task, a cl"
2014.iwslt-evaluation.7,W13-2264,1,0.835602,"ed by the TreeTagger [50] and the parse trees by the Stanford Parser [51]. In addition, for the language pairs involving German KIT applied the different reorderings of both language pairs using a lexicalized reordering model. The phrase tables of the systems were trained using GIZA++ alignment [52]. KIT adapted the phrase table to the TED domain using the backoff approach and by means of candidate selection [53]. In addition to the phrase table probabilities, KIT modeled the translation process by a bilingual language model [54] and a discriminative word lexicon using source context features [55]. During decoding, KIT used several LMs to adapt the system to the task and to better model the sentence structure using a class-based LM. For the German→English task, KIT used one LM trained on all data, an in-domain LM trained only on the WIT3 corpus, and one LM trained on 5M sentences selected using cross-entropy difference [13]. As classes KIT used the clusters obtained using the mkcls algorithm on the WIT3 corpus. For German↔ English, KIT used a 9-gram LM with 100 or 1000 clusters and for the English→French MT task, a cluster-based 4-gram LM was trained on 500 clusters. For English→German"
2014.iwslt-evaluation.7,2012.eamt-1.60,1,0.892622,"Missing"
2014.iwslt-evaluation.7,D11-1033,0,0.167316,"Missing"
2014.iwslt-evaluation.7,W05-0909,0,0.085167,"m multiple hypotheses which are outputs of different translation engines. The consensus translations can be better in terms of translation quality than any of the individual hypotheses. To combine the engines of the project partners for the EU-BRIDGE joint setups, we applied a system combination implementation that has been developed at RWTH Aachen University [1]. In Fig. 1 an overview is illustrated. We first address the generation of a confusion network (CN) from I input translations. For that we need a pairwise alignment between all input hypotheses. This alignment is calculated via METEOR [60]. The hypotheses are then reordered to match the word order of a selected skeleton hypothesis. Instead of using only one of the input hypothesis as skeleton, we generate I different CNs, each having one of the input systems as skeleton. The final lattice is the union of all I previous generated CNs. In Fig. 2 an example confusion network of I = 4 input translations with one skeleton translation is illustrated. Between two adjacent nodes, we always have a choice between the I different system output words. The confusion network decoding step involves determining the shortest path through the ne"
2014.iwslt-evaluation.7,2006.amta-papers.25,0,0.0356913,"andard set of models is a word penalty, a 3-gram language model trained on the input hypotheses, and for each system one binary voting feature. During decoding the binary voting feature for system i (1 ≤ i ≤ I) is 1 iff the word is from system i, otherwise 0. The M different model weights λm are trained with MERT [8]. the red cab the a a red blue green train car car Figure 2: System A: the red cab ; System B: the red train ; System C: a blue car ; System D: a green car ; Reference: the blue car . 7. Results In this section, we present our experimental results. All reported B LEU [34] and T ER [61] scores are case-sensitive with one reference. All system combination results have been generated with RWTH’s open source system combination implementation Jane [1]. German→English SLT For the German→English SLT task, we combined three different individual systems generated by UEDIN, KIT, and RWTH. Experimental results are given in Table 1. The final system combination yields improvements of 1.5 points in B LEU and 1.2 points in T ER compared to the best single system (KIT). All single systems as well as the system combination parameters were tuned on dev2012. For this year’s IWSLT SLT track,"
2014.iwslt-evaluation.7,E06-1005,1,\N,Missing
2014.iwslt-evaluation.7,P11-1105,1,\N,Missing
2014.iwslt-evaluation.7,W10-1711,1,\N,Missing
2014.iwslt-evaluation.7,2010.iwslt-evaluation.22,1,\N,Missing
2014.iwslt-evaluation.7,E14-2008,1,\N,Missing
2014.iwslt-evaluation.7,2014.iwslt-evaluation.6,1,\N,Missing
2014.iwslt-evaluation.7,J03-1002,1,\N,Missing
2014.iwslt-evaluation.7,C12-3061,1,\N,Missing
2014.iwslt-evaluation.7,2013.iwslt-evaluation.16,1,\N,Missing
2014.iwslt-evaluation.7,W14-3310,1,\N,Missing
2015.iwslt-evaluation.4,eisele-chen-2010-multiun,0,\N,Missing
2015.iwslt-evaluation.4,N04-1035,0,\N,Missing
2015.iwslt-evaluation.4,2014.iwslt-evaluation.7,1,\N,Missing
2015.iwslt-evaluation.4,W96-0213,0,\N,Missing
2015.iwslt-evaluation.4,C04-1024,0,\N,Missing
2015.iwslt-evaluation.4,J93-2003,0,\N,Missing
2015.iwslt-evaluation.4,E99-1010,0,\N,Missing
2015.iwslt-evaluation.4,D08-1089,0,\N,Missing
2015.iwslt-evaluation.4,W13-2221,0,\N,Missing
2015.iwslt-evaluation.4,P02-1040,0,\N,Missing
2015.iwslt-evaluation.4,W14-3362,1,\N,Missing
2015.iwslt-evaluation.4,D07-1091,0,\N,Missing
2015.iwslt-evaluation.4,W06-1607,0,\N,Missing
2015.iwslt-evaluation.4,P07-2045,1,\N,Missing
2015.iwslt-evaluation.4,W08-0336,0,\N,Missing
2015.iwslt-evaluation.4,N04-1022,0,\N,Missing
2015.iwslt-evaluation.4,E14-2008,1,\N,Missing
2015.iwslt-evaluation.4,N03-1017,0,\N,Missing
2015.iwslt-evaluation.4,N13-1001,0,\N,Missing
2015.iwslt-evaluation.4,P02-1038,0,\N,Missing
2015.iwslt-evaluation.4,2014.iwslt-evaluation.6,1,\N,Missing
2015.iwslt-evaluation.4,J03-1002,0,\N,Missing
2015.iwslt-evaluation.4,W13-0804,1,\N,Missing
2015.iwslt-evaluation.4,D14-1132,0,\N,Missing
2015.iwslt-evaluation.4,P06-1121,0,\N,Missing
2015.iwslt-evaluation.4,D07-1079,0,\N,Missing
2015.iwslt-evaluation.4,J10-2004,0,\N,Missing
2015.iwslt-evaluation.4,2013.iwslt-evaluation.16,1,\N,Missing
2015.iwslt-evaluation.4,2005.mtsummit-papers.11,0,\N,Missing
2015.iwslt-evaluation.4,W14-3310,1,\N,Missing
2015.iwslt-evaluation.4,W15-3001,1,\N,Missing
2015.iwslt-evaluation.4,2011.iwslt-evaluation.18,0,\N,Missing
2015.iwslt-evaluation.4,J07-2003,0,\N,Missing
2015.iwslt-evaluation.4,W15-3013,1,\N,Missing
2015.iwslt-evaluation.4,W14-4018,1,\N,Missing
2015.iwslt-evaluation.4,tiedemann-2012-parallel,0,\N,Missing
2015.iwslt-evaluation.4,W12-3150,0,\N,Missing
2015.iwslt-evaluation.4,D07-1078,0,\N,Missing
2015.iwslt-evaluation.4,W08-0509,0,\N,Missing
2015.iwslt-evaluation.4,D08-1076,0,\N,Missing
2015.iwslt-evaluation.4,W11-2107,0,\N,Missing
2015.iwslt-evaluation.4,W11-2123,0,\N,Missing
2015.iwslt-evaluation.4,N12-1047,0,\N,Missing
2015.iwslt-evaluation.4,W14-3324,1,\N,Missing
2015.iwslt-evaluation.4,2012.eamt-1.60,0,\N,Missing
2015.iwslt-evaluation.4,N13-1003,0,\N,Missing
2015.iwslt-evaluation.4,N15-1175,0,\N,Missing
2015.mtsummit-papers.19,D11-1033,0,0.07366,"Missing"
2015.mtsummit-papers.19,2010.amta-papers.16,0,0.133002,"Missing"
2015.mtsummit-papers.19,J96-1002,0,0.0774689,"f reserving the in-domain devel2 http://www.statmt.org/wmt15/translation-task.html Proceedings of MT Summit XV, vol.1: MT Researchers&apos; Track Miami, Oct 30 - Nov 3, 2015 |p. 243 opment sets for tuning source LM interpolation weights. Furthermore, we argue that source-side scores of the interpolated LMs employed in our classifier may to some extent resemble targetside scores of the interpolated LMs which are applied in the respective domain-adapted SMT systems. 5.2 Maximum Entropy Classifiers Maximum entropy text classifiers can utilize a larger number of features in order to predict the label (Berger et al., 1996). We incorporate features from single words, pairs of adjacent words, the first word of the sentence, and the last word of the sentence. The model is trained with L-BFGS (Byrd et al., 1995) and regularized using a Gaussian prior. We build maximum entropy (ME) classifiers under two different training conditions: using the MT development sets (which are rather small) as training data, and using selected other corpora as training data (which might not always exactly match what is defined as in-domain to the MT systems, as the development sets essentially constitute the domains). In a further flav"
2015.mtsummit-papers.19,W09-0432,0,0.0237446,"ch and Ney, 2002) on an in-domain development set (Pecina et al., 2012). • Model combination (of language models, translation models, or reordering models) via interpolation or other schemes, e.g. phrase table fill-up (Foster and Kuhn, 2007; Koehn and Schroeder, 2007; Nakov, 2008; Bisazza et al., 2011; Niehues and Waibel, 2012; Chen et al., 2013). • Data selection (Moore and Lewis, 2010; Axelrod et al., 2011). • Instance weighting (Matsoukas et al., 2009; Foster et al., 2010; Shah et al., 2012; Mansour and Ney, 2012). • Further exploitation of in-domain monolingual data (Ueffing et al., 2007; Bertoldi and Federico, 2009; Schwenk and Senellart, 2009; Lambert et al., 2011). • Domain-specific features, e.g. binary features indicating the provenance of phrase pairs as implemented in the open-source Moses toolkit (Durrani et al., 2013b) or “domain augmentation” (Clark et al., 2012). However, few authors have tackled the question of how to benefit from domain adaptation in scenarios where a domain label of the input is not present. An important aspect of our approach to multi-domain MT is the need for domain classification. Proceedings of MT Summit XV, vol.1: MT Researchers&apos; Track Miami, Oct 30 - Nov 3, 2015 |p. 2"
2015.mtsummit-papers.19,2011.iwslt-evaluation.18,0,0.0660573,"d English→Greek language pairs using training corpora of diverse origin, totalling tens of millions of parallel sentences. 2 Related Work A significant amount of research on domain adaptation for SMT has been conducted in recent years. Some methods which are commonly used are: • Tuning of the decoder model weights (Och and Ney, 2002) on an in-domain development set (Pecina et al., 2012). • Model combination (of language models, translation models, or reordering models) via interpolation or other schemes, e.g. phrase table fill-up (Foster and Kuhn, 2007; Koehn and Schroeder, 2007; Nakov, 2008; Bisazza et al., 2011; Niehues and Waibel, 2012; Chen et al., 2013). • Data selection (Moore and Lewis, 2010; Axelrod et al., 2011). • Instance weighting (Matsoukas et al., 2009; Foster et al., 2010; Shah et al., 2012; Mansour and Ney, 2012). • Further exploitation of in-domain monolingual data (Ueffing et al., 2007; Bertoldi and Federico, 2009; Schwenk and Senellart, 2009; Lambert et al., 2011). • Domain-specific features, e.g. binary features indicating the provenance of phrase pairs as implemented in the open-source Moses toolkit (Durrani et al., 2013b) or “domain augmentation” (Clark et al., 2012). However, fe"
2015.mtsummit-papers.19,2012.eamt-1.60,0,0.144845,"Missing"
2015.mtsummit-papers.19,2013.iwslt-evaluation.1,0,0.0173438,"e than any of the domain-adapted systems on two out of four language pairs (En→De: +0.3; En→It: -0.2; En→Pt: +0.9; En→El: -0.2). Apart from English→Portuguese, the differences are small. Multi-domain SMT clearly outperforms mixed-domain SMT for English→Portuguese (up to +1.0 on all) and English→Greek (up to +0.6 on all). The choice of the domain classifier barely matters wrt. translation quality. Due to its compact model, the MEdev classifier would for instance be a reasonable choice despite not providing the highest classification accuracy. 8 MT English→Italian: +4.3 points B LEU on tst2013 (Cettolo et al., 2013). MT English→Portuguese: +2.8 points B LEU on tst2014 (Cettolo et al., 2014). 9 http://matrix.statmt.org Proceedings of MT Summit XV, vol.1: MT Researchers&apos; Track Miami, Oct 30 - Nov 3, 2015 |p. 249 20 15 15 10 10 5 5 German 26 .3 26 BLEU 21 .9 21 .7 21 .9 22 .7 22 .5 22 .5 25 20 0 .2 26 .8 26 .8 8 30 28 . .1 .0 27 .2 27 .2 27 .0 27 .7 27 25 BLEU 25 .6 30 25 30 6 35 32 35 .6 32 . 40 .0 40 .8 Mixed-domain-tuned Multi-domain Oracle-domain 31 TED-tuned Europarl-tuned News-tuned Italian 0 Portuguese Greek Figure 1: B LEU scores on a concatenation of all test sets. Compared to oracle-domain SMT, wh"
2015.mtsummit-papers.19,N13-1114,0,0.0120964,"rpora of diverse origin, totalling tens of millions of parallel sentences. 2 Related Work A significant amount of research on domain adaptation for SMT has been conducted in recent years. Some methods which are commonly used are: • Tuning of the decoder model weights (Och and Ney, 2002) on an in-domain development set (Pecina et al., 2012). • Model combination (of language models, translation models, or reordering models) via interpolation or other schemes, e.g. phrase table fill-up (Foster and Kuhn, 2007; Koehn and Schroeder, 2007; Nakov, 2008; Bisazza et al., 2011; Niehues and Waibel, 2012; Chen et al., 2013). • Data selection (Moore and Lewis, 2010; Axelrod et al., 2011). • Instance weighting (Matsoukas et al., 2009; Foster et al., 2010; Shah et al., 2012; Mansour and Ney, 2012). • Further exploitation of in-domain monolingual data (Ueffing et al., 2007; Bertoldi and Federico, 2009; Schwenk and Senellart, 2009; Lambert et al., 2011). • Domain-specific features, e.g. binary features indicating the provenance of phrase pairs as implemented in the open-source Moses toolkit (Durrani et al., 2013b) or “domain augmentation” (Clark et al., 2012). However, few authors have tackled the question of how to"
2015.mtsummit-papers.19,N12-1047,0,0.0462838,"ty and word penalty. • Distance-based distortion cost. • A hierarchical lexicalized reordering model (Galley and Manning, 2008). • A 5-gram operation sequence model (Durrani et al., 2013a). • Seven binary features indicating absolute occurrence count classes of phrase pairs. • Sparse phrase length features. • Sparse lexical features for the top 200 words. • A 5-gram LM with modified Kneser-Ney smoothing (Kneser and Ney, 1995; Chen and Goodman, 1998). We discard singleton n-grams of order three and higher. Feature weights are optimized to maximize B LEU (Papineni et al., 2002) with batch MIRA (Cherry and Foster, 2012) on 1000-best lists. We prune the phrase table to a maximum of 100 5 http://dumps.wikimedia.org 6 https://github.com/bwbaugh/wikipedia-extractor Proceedings of MT Summit XV, vol.1: MT Researchers&apos; Track Miami, Oct 30 - Nov 3, 2015 |p. 245 best translation options per distinct source side and apply a minimum score threshold of 0.0001 on the source-to-target phrase translation probability. We use cube pruning in decoding. Pop limit and stack limit are set to 1000 for tuning and to 5000 for testing. We disallow reordering over punctuation. Furthermore, Minimum Bayes Risk decoding is employed for"
2015.mtsummit-papers.19,2012.amta-papers.4,0,0.040486,"akov, 2008; Bisazza et al., 2011; Niehues and Waibel, 2012; Chen et al., 2013). • Data selection (Moore and Lewis, 2010; Axelrod et al., 2011). • Instance weighting (Matsoukas et al., 2009; Foster et al., 2010; Shah et al., 2012; Mansour and Ney, 2012). • Further exploitation of in-domain monolingual data (Ueffing et al., 2007; Bertoldi and Federico, 2009; Schwenk and Senellart, 2009; Lambert et al., 2011). • Domain-specific features, e.g. binary features indicating the provenance of phrase pairs as implemented in the open-source Moses toolkit (Durrani et al., 2013b) or “domain augmentation” (Clark et al., 2012). However, few authors have tackled the question of how to benefit from domain adaptation in scenarios where a domain label of the input is not present. An important aspect of our approach to multi-domain MT is the need for domain classification. Proceedings of MT Summit XV, vol.1: MT Researchers&apos; Track Miami, Oct 30 - Nov 3, 2015 |p. 241 Xu et al. (2007) perform domain classification for a Chinese→English task. The domains are newswire and newsgroup. The classifiers operate on whole documents rather than on individual sentences. The authors propose two techniques for domain classification. Th"
2015.mtsummit-papers.19,N13-1001,0,0.1814,"ster and Kuhn, 2007; Koehn and Schroeder, 2007; Nakov, 2008; Bisazza et al., 2011; Niehues and Waibel, 2012; Chen et al., 2013). • Data selection (Moore and Lewis, 2010; Axelrod et al., 2011). • Instance weighting (Matsoukas et al., 2009; Foster et al., 2010; Shah et al., 2012; Mansour and Ney, 2012). • Further exploitation of in-domain monolingual data (Ueffing et al., 2007; Bertoldi and Federico, 2009; Schwenk and Senellart, 2009; Lambert et al., 2011). • Domain-specific features, e.g. binary features indicating the provenance of phrase pairs as implemented in the open-source Moses toolkit (Durrani et al., 2013b) or “domain augmentation” (Clark et al., 2012). However, few authors have tackled the question of how to benefit from domain adaptation in scenarios where a domain label of the input is not present. An important aspect of our approach to multi-domain MT is the need for domain classification. Proceedings of MT Summit XV, vol.1: MT Researchers&apos; Track Miami, Oct 30 - Nov 3, 2015 |p. 241 Xu et al. (2007) perform domain classification for a Chinese→English task. The domains are newswire and newsgroup. The classifiers operate on whole documents rather than on individual sentences. The authors prop"
2015.mtsummit-papers.19,W13-2212,1,0.871039,"Missing"
2015.mtsummit-papers.19,2011.iwslt-evaluation.1,0,0.0159256,"on political matters from parliamentary proceedings. News texts are written news articles. TED talks, Europarl, and News could be described as “genres”. We denote them as domains throughout this paper because the term “domain” is well established in related machine translation research literature and often used in a broad sense. TED talks, Europarl, and News have been highly relevant domains in recent machine translation research. The International Workshop on Spoken Language Translation1 (IWSLT) hosts a yearly open evaluation campaign which focuses on the translation of TED talks since 2011 (Federico et al., 2011). The European Parliament Proceedings Parallel Corpus (Koehn, 2005) has been an influential resource for machine translation research ever since its first release over 1 http://www.iwslt.org Proceedings of MT Summit XV, vol.1: MT Researchers&apos; Track Miami, Oct 30 - Nov 3, 2015 |p. 242 a decade ago. It is freely available and includes parallel text for 21 European languages. Test sets and training data that enables research on machine translation of texts from the News domain have regularly been released for the shared translation task of the Workshop on Statistical Machine Translation2 (WMT). T"
2015.mtsummit-papers.19,D10-1044,0,0.0372183,"in adaptation for SMT has been conducted in recent years. Some methods which are commonly used are: • Tuning of the decoder model weights (Och and Ney, 2002) on an in-domain development set (Pecina et al., 2012). • Model combination (of language models, translation models, or reordering models) via interpolation or other schemes, e.g. phrase table fill-up (Foster and Kuhn, 2007; Koehn and Schroeder, 2007; Nakov, 2008; Bisazza et al., 2011; Niehues and Waibel, 2012; Chen et al., 2013). • Data selection (Moore and Lewis, 2010; Axelrod et al., 2011). • Instance weighting (Matsoukas et al., 2009; Foster et al., 2010; Shah et al., 2012; Mansour and Ney, 2012). • Further exploitation of in-domain monolingual data (Ueffing et al., 2007; Bertoldi and Federico, 2009; Schwenk and Senellart, 2009; Lambert et al., 2011). • Domain-specific features, e.g. binary features indicating the provenance of phrase pairs as implemented in the open-source Moses toolkit (Durrani et al., 2013b) or “domain augmentation” (Clark et al., 2012). However, few authors have tackled the question of how to benefit from domain adaptation in scenarios where a domain label of the input is not present. An important aspect of our approach t"
2015.mtsummit-papers.19,W07-0717,0,0.047497,"on the English→German, English→Italian, English→Portuguese, and English→Greek language pairs using training corpora of diverse origin, totalling tens of millions of parallel sentences. 2 Related Work A significant amount of research on domain adaptation for SMT has been conducted in recent years. Some methods which are commonly used are: • Tuning of the decoder model weights (Och and Ney, 2002) on an in-domain development set (Pecina et al., 2012). • Model combination (of language models, translation models, or reordering models) via interpolation or other schemes, e.g. phrase table fill-up (Foster and Kuhn, 2007; Koehn and Schroeder, 2007; Nakov, 2008; Bisazza et al., 2011; Niehues and Waibel, 2012; Chen et al., 2013). • Data selection (Moore and Lewis, 2010; Axelrod et al., 2011). • Instance weighting (Matsoukas et al., 2009; Foster et al., 2010; Shah et al., 2012; Mansour and Ney, 2012). • Further exploitation of in-domain monolingual data (Ueffing et al., 2007; Bertoldi and Federico, 2009; Schwenk and Senellart, 2009; Lambert et al., 2011). • Domain-specific features, e.g. binary features indicating the provenance of phrase pairs as implemented in the open-source Moses toolkit (Durrani et al., 201"
2015.mtsummit-papers.19,W06-1607,0,0.0720378,"the News Crawl corpora provided for the WMT 2015 shared translation task. Plain text was obtained from the Wikipedia XML dumps with the Wikipedia Extractor6 tool. Statistics of the additional monolingual training corpora are presented in Table 2. 6.2 Machine Translation Systems Word alignments are created by aligning the data in both directions and symmetrizing the two trained alignments (Och and Ney, 2003; Koehn et al., 2003). We extract phrases up to a maximum length of five. The MT systems comprise these features: • Phrase translation log-probabilities, smoothed with Good-Turing smoothing (Foster et al., 2006), and lexical translation log-probabilities in both directions. • Phrase penalty and word penalty. • Distance-based distortion cost. • A hierarchical lexicalized reordering model (Galley and Manning, 2008). • A 5-gram operation sequence model (Durrani et al., 2013a). • Seven binary features indicating absolute occurrence count classes of phrase pairs. • Sparse phrase length features. • Sparse lexical features for the top 200 words. • A 5-gram LM with modified Kneser-Ney smoothing (Kneser and Ney, 1995; Chen and Goodman, 1998). We discard singleton n-grams of order three and higher. Feature wei"
2015.mtsummit-papers.19,D08-1089,0,0.0234049,"ual training corpora are presented in Table 2. 6.2 Machine Translation Systems Word alignments are created by aligning the data in both directions and symmetrizing the two trained alignments (Och and Ney, 2003; Koehn et al., 2003). We extract phrases up to a maximum length of five. The MT systems comprise these features: • Phrase translation log-probabilities, smoothed with Good-Turing smoothing (Foster et al., 2006), and lexical translation log-probabilities in both directions. • Phrase penalty and word penalty. • Distance-based distortion cost. • A hierarchical lexicalized reordering model (Galley and Manning, 2008). • A 5-gram operation sequence model (Durrani et al., 2013a). • Seven binary features indicating absolute occurrence count classes of phrase pairs. • Sparse phrase length features. • Sparse lexical features for the top 200 words. • A 5-gram LM with modified Kneser-Ney smoothing (Kneser and Ney, 1995; Chen and Goodman, 1998). We discard singleton n-grams of order three and higher. Feature weights are optimized to maximize B LEU (Papineni et al., 2002) with batch MIRA (Cherry and Foster, 2012) on 1000-best lists. We prune the phrase table to a maximum of 100 5 http://dumps.wikimedia.org 6 https"
2015.mtsummit-papers.19,W08-0509,0,0.0165542,"respective LM yields the maximum LM score. Overall, we end up with four variations: MEtrain Classifier trained on medium-sized training corpora with the basic set of features. MEtrain+lm Classifier trained on medium-sized training corpora with the basic set of features plus source LM indicator features. MEdev Classifier trained on the MT development sets with the basic set of features. MEdev+lm Classifier trained on the MT development sets with the basic set of features plus source LM indicator features. 6 Experimental Setup We use Moses (Koehn et al., 2007) for machine translation, MGIZA++ (Gao and Vogel, 2008) to train word alignments, KenLM (Heafield, 2011) for LM training and scoring, SRILM (Stolcke, 2002) for LM interpolation, and the Stanford Classifier3 for maximum entropy text classification. We present experimental results on English→German, English→Italian, English→Portuguese, and English→Greek translation tasks. 6.1 Training Data Our SMT systems are trained with the following bilingual corpora: • • • • • • • • TED from WIT3 (Cettolo et al., 2012) Europarl (Koehn, 2005) JRC-Acquis 3.0 (Steinberger et al., 2006) DGT’s Translation Memory (Steinberger et al., 2012) as distributed in OPUS (Tied"
2015.mtsummit-papers.19,W12-3154,1,0.854639,"the same domain which can be employed for training and tuning. The adaptation task is then defined as utilizing a small amount of in-domain training resources effectively in order to learn system parameters that are more appropriate for translating in-domain input. The in-domain training resources constitute a minor fraction of the overall training data only, the majority of which has a domain mismatch with the designated application. The downside of systems that have been highly tweaked towards the characteristics of a single domain is a diminished translation quality on out-of-domain data (Haddow and Koehn, 2012). Online translation systems, on the other hand, are usually designed for open-domain scenarios where the domain of the input text is not predefined. Being able to take advantage of the benefits of domain adaptation while not having to compromise quality on out-of-domain data would be desirable for online systems. Proceedings of MT Summit XV, vol.1: MT Researchers&apos; Track Miami, Oct 30 - Nov 3, 2015 |p. 240 A viable utilization of domain adaptation approaches in open-domain online translation systems comes in two components: • A number of different parameter sets, each tuned to optimize transla"
2015.mtsummit-papers.19,W11-2123,0,0.0283971,"e end up with four variations: MEtrain Classifier trained on medium-sized training corpora with the basic set of features. MEtrain+lm Classifier trained on medium-sized training corpora with the basic set of features plus source LM indicator features. MEdev Classifier trained on the MT development sets with the basic set of features. MEdev+lm Classifier trained on the MT development sets with the basic set of features plus source LM indicator features. 6 Experimental Setup We use Moses (Koehn et al., 2007) for machine translation, MGIZA++ (Gao and Vogel, 2008) to train word alignments, KenLM (Heafield, 2011) for LM training and scoring, SRILM (Stolcke, 2002) for LM interpolation, and the Stanford Classifier3 for maximum entropy text classification. We present experimental results on English→German, English→Italian, English→Portuguese, and English→Greek translation tasks. 6.1 Training Data Our SMT systems are trained with the following bilingual corpora: • • • • • • • • TED from WIT3 (Cettolo et al., 2012) Europarl (Koehn, 2005) JRC-Acquis 3.0 (Steinberger et al., 2006) DGT’s Translation Memory (Steinberger et al., 2012) as distributed in OPUS (Tiedemann, 2012) OPUS European Central Bank (ECB) OPU"
2015.mtsummit-papers.19,2005.mtsummit-papers.11,0,0.144636,"ews articles. TED talks, Europarl, and News could be described as “genres”. We denote them as domains throughout this paper because the term “domain” is well established in related machine translation research literature and often used in a broad sense. TED talks, Europarl, and News have been highly relevant domains in recent machine translation research. The International Workshop on Spoken Language Translation1 (IWSLT) hosts a yearly open evaluation campaign which focuses on the translation of TED talks since 2011 (Federico et al., 2011). The European Parliament Proceedings Parallel Corpus (Koehn, 2005) has been an influential resource for machine translation research ever since its first release over 1 http://www.iwslt.org Proceedings of MT Summit XV, vol.1: MT Researchers&apos; Track Miami, Oct 30 - Nov 3, 2015 |p. 242 a decade ago. It is freely available and includes parallel text for 21 European languages. Test sets and training data that enables research on machine translation of texts from the News domain have regularly been released for the shared translation task of the Workshop on Statistical Machine Translation2 (WMT). The WMT “newstest” corpora have become important test sets to measur"
2015.mtsummit-papers.19,P07-2045,1,0.0125752,"an associated source LM indicator feature fires if the respective LM yields the maximum LM score. Overall, we end up with four variations: MEtrain Classifier trained on medium-sized training corpora with the basic set of features. MEtrain+lm Classifier trained on medium-sized training corpora with the basic set of features plus source LM indicator features. MEdev Classifier trained on the MT development sets with the basic set of features. MEdev+lm Classifier trained on the MT development sets with the basic set of features plus source LM indicator features. 6 Experimental Setup We use Moses (Koehn et al., 2007) for machine translation, MGIZA++ (Gao and Vogel, 2008) to train word alignments, KenLM (Heafield, 2011) for LM training and scoring, SRILM (Stolcke, 2002) for LM interpolation, and the Stanford Classifier3 for maximum entropy text classification. We present experimental results on English→German, English→Italian, English→Portuguese, and English→Greek translation tasks. 6.1 Training Data Our SMT systems are trained with the following bilingual corpora: • • • • • • • • TED from WIT3 (Cettolo et al., 2012) Europarl (Koehn, 2005) JRC-Acquis 3.0 (Steinberger et al., 2006) DGT’s Translation Memory"
2015.mtsummit-papers.19,N03-1017,0,0.00929731,"raining corpora are presented in Table 1. For language modeling on the target side, we furthermore add monolingual corpora from recent (April 2015) Wikipedia database dumps5 and—for German—the News Crawl corpora provided for the WMT 2015 shared translation task. Plain text was obtained from the Wikipedia XML dumps with the Wikipedia Extractor6 tool. Statistics of the additional monolingual training corpora are presented in Table 2. 6.2 Machine Translation Systems Word alignments are created by aligning the data in both directions and symmetrizing the two trained alignments (Och and Ney, 2003; Koehn et al., 2003). We extract phrases up to a maximum length of five. The MT systems comprise these features: • Phrase translation log-probabilities, smoothed with Good-Turing smoothing (Foster et al., 2006), and lexical translation log-probabilities in both directions. • Phrase penalty and word penalty. • Distance-based distortion cost. • A hierarchical lexicalized reordering model (Galley and Manning, 2008). • A 5-gram operation sequence model (Durrani et al., 2013a). • Seven binary features indicating absolute occurrence count classes of phrase pairs. • Sparse phrase length features. • Sparse lexical featur"
2015.mtsummit-papers.19,W07-0733,0,0.0947904,"Missing"
2015.mtsummit-papers.19,W11-2132,0,0.289447,"et al., 2012). • Model combination (of language models, translation models, or reordering models) via interpolation or other schemes, e.g. phrase table fill-up (Foster and Kuhn, 2007; Koehn and Schroeder, 2007; Nakov, 2008; Bisazza et al., 2011; Niehues and Waibel, 2012; Chen et al., 2013). • Data selection (Moore and Lewis, 2010; Axelrod et al., 2011). • Instance weighting (Matsoukas et al., 2009; Foster et al., 2010; Shah et al., 2012; Mansour and Ney, 2012). • Further exploitation of in-domain monolingual data (Ueffing et al., 2007; Bertoldi and Federico, 2009; Schwenk and Senellart, 2009; Lambert et al., 2011). • Domain-specific features, e.g. binary features indicating the provenance of phrase pairs as implemented in the open-source Moses toolkit (Durrani et al., 2013b) or “domain augmentation” (Clark et al., 2012). However, few authors have tackled the question of how to benefit from domain adaptation in scenarios where a domain label of the input is not present. An important aspect of our approach to multi-domain MT is the need for domain classification. Proceedings of MT Summit XV, vol.1: MT Researchers&apos; Track Miami, Oct 30 - Nov 3, 2015 |p. 241 Xu et al. (2007) perform domain classification fo"
2015.mtsummit-papers.19,D08-1076,0,0.0236215,"are evaluated. The authors show that a pipeline with the SVM classifier is effective in multi-domain translation. Wang et al. (2012) distinguish generic and patent domain data in experiments on 20 language pairs. For domain classification, the authors rely on averaged perceptron classifiers with various phrase-based features. The machine translation development sets serve as training data for the classifiers. An interesting aspect of their translation experiments is that they utilize a multi-domain optimization in order to jointly tune weights for all domains in a single run of lattice MERT (Macherey et al., 2008). In a related strand of research, source-side text classifiers have recently been employed in order to detect Arabic dialects and select SMT systems accordingly (Salloum et al., 2014; Mansour et al., 2014). 3 Text Domains Our application scenario is an online translation service with the requirement to provide highquality translation not only of texts from a single domain, but of a wider range of text types. We therefore study a use case where the translation system is supposed to perform well on the following domains: TED talks, Europarl, and News. These three domains are fairly coarsegraine"
2015.mtsummit-papers.19,2014.amta-researchers.26,0,0.035468,"pairs. For domain classification, the authors rely on averaged perceptron classifiers with various phrase-based features. The machine translation development sets serve as training data for the classifiers. An interesting aspect of their translation experiments is that they utilize a multi-domain optimization in order to jointly tune weights for all domains in a single run of lattice MERT (Macherey et al., 2008). In a related strand of research, source-side text classifiers have recently been employed in order to detect Arabic dialects and select SMT systems accordingly (Salloum et al., 2014; Mansour et al., 2014). 3 Text Domains Our application scenario is an online translation service with the requirement to provide highquality translation not only of texts from a single domain, but of a wider range of text types. We therefore study a use case where the translation system is supposed to perform well on the following domains: TED talks, Europarl, and News. These three domains are fairly coarsegrained. Different documents from one of the domains are mostly not consistent regarding the covered topics. While all three domains comprise heterogeneous topics, the domains are set apart from each other by mea"
2015.mtsummit-papers.19,2012.iwslt-papers.7,0,0.0639241,"in recent years. Some methods which are commonly used are: • Tuning of the decoder model weights (Och and Ney, 2002) on an in-domain development set (Pecina et al., 2012). • Model combination (of language models, translation models, or reordering models) via interpolation or other schemes, e.g. phrase table fill-up (Foster and Kuhn, 2007; Koehn and Schroeder, 2007; Nakov, 2008; Bisazza et al., 2011; Niehues and Waibel, 2012; Chen et al., 2013). • Data selection (Moore and Lewis, 2010; Axelrod et al., 2011). • Instance weighting (Matsoukas et al., 2009; Foster et al., 2010; Shah et al., 2012; Mansour and Ney, 2012). • Further exploitation of in-domain monolingual data (Ueffing et al., 2007; Bertoldi and Federico, 2009; Schwenk and Senellart, 2009; Lambert et al., 2011). • Domain-specific features, e.g. binary features indicating the provenance of phrase pairs as implemented in the open-source Moses toolkit (Durrani et al., 2013b) or “domain augmentation” (Clark et al., 2012). However, few authors have tackled the question of how to benefit from domain adaptation in scenarios where a domain label of the input is not present. An important aspect of our approach to multi-domain MT is the need for domain cl"
2015.mtsummit-papers.19,2011.eamt-1.19,0,0.0209504,"-2012 sets (En→De) and on newstest2009 (En→It). We use newssyscomb2009 as an English→Italian News domain test set for lack of other English-Italian News test sets. Note that newssyscomb2009 is a small set of only 502 sentences. No News test data was available to us for the English→Portuguese and English→Greek language pairs, so we experiment with only two domains (TED and Europarl) on these tasks. The Portuguese TED development and test sets are Brazilian Portuguese whereas the Europarl sets are European Portuguese. The two Portuguese dialects have a number of differences in written language. Marujo et al. (2011) give a brief overview. 6.2.2 Domain-Adapted SMT For our domain adaptation experiments, we first tune the systems with the features described above on the respective in-domain development set (TED-tuned, Europarl-tuned, News-tuned). We next replace the large baseline LM with a domain-specific interpolated LM (+ LM interp.). We then add binary features indicating the provenance of phrase pairs (+ LM interp. + indicator feat.). 6.2.3 Mixed-Domain SMT We build mixed-domain SMT systems by tuning on a development corpus containing samples of texts from all domains. We include a balanced amount of d"
2015.mtsummit-papers.19,D09-1074,0,0.0508134,"ount of research on domain adaptation for SMT has been conducted in recent years. Some methods which are commonly used are: • Tuning of the decoder model weights (Och and Ney, 2002) on an in-domain development set (Pecina et al., 2012). • Model combination (of language models, translation models, or reordering models) via interpolation or other schemes, e.g. phrase table fill-up (Foster and Kuhn, 2007; Koehn and Schroeder, 2007; Nakov, 2008; Bisazza et al., 2011; Niehues and Waibel, 2012; Chen et al., 2013). • Data selection (Moore and Lewis, 2010; Axelrod et al., 2011). • Instance weighting (Matsoukas et al., 2009; Foster et al., 2010; Shah et al., 2012; Mansour and Ney, 2012). • Further exploitation of in-domain monolingual data (Ueffing et al., 2007; Bertoldi and Federico, 2009; Schwenk and Senellart, 2009; Lambert et al., 2011). • Domain-specific features, e.g. binary features indicating the provenance of phrase pairs as implemented in the open-source Moses toolkit (Durrani et al., 2013b) or “domain augmentation” (Clark et al., 2012). However, few authors have tackled the question of how to benefit from domain adaptation in scenarios where a domain label of the input is not present. An important asp"
2015.mtsummit-papers.19,P10-2041,0,0.0521304,"s of millions of parallel sentences. 2 Related Work A significant amount of research on domain adaptation for SMT has been conducted in recent years. Some methods which are commonly used are: • Tuning of the decoder model weights (Och and Ney, 2002) on an in-domain development set (Pecina et al., 2012). • Model combination (of language models, translation models, or reordering models) via interpolation or other schemes, e.g. phrase table fill-up (Foster and Kuhn, 2007; Koehn and Schroeder, 2007; Nakov, 2008; Bisazza et al., 2011; Niehues and Waibel, 2012; Chen et al., 2013). • Data selection (Moore and Lewis, 2010; Axelrod et al., 2011). • Instance weighting (Matsoukas et al., 2009; Foster et al., 2010; Shah et al., 2012; Mansour and Ney, 2012). • Further exploitation of in-domain monolingual data (Ueffing et al., 2007; Bertoldi and Federico, 2009; Schwenk and Senellart, 2009; Lambert et al., 2011). • Domain-specific features, e.g. binary features indicating the provenance of phrase pairs as implemented in the open-source Moses toolkit (Durrani et al., 2013b) or “domain augmentation” (Clark et al., 2012). However, few authors have tackled the question of how to benefit from domain adaptation in scenari"
2015.mtsummit-papers.19,W08-0320,0,0.0269359,"ortuguese, and English→Greek language pairs using training corpora of diverse origin, totalling tens of millions of parallel sentences. 2 Related Work A significant amount of research on domain adaptation for SMT has been conducted in recent years. Some methods which are commonly used are: • Tuning of the decoder model weights (Och and Ney, 2002) on an in-domain development set (Pecina et al., 2012). • Model combination (of language models, translation models, or reordering models) via interpolation or other schemes, e.g. phrase table fill-up (Foster and Kuhn, 2007; Koehn and Schroeder, 2007; Nakov, 2008; Bisazza et al., 2011; Niehues and Waibel, 2012; Chen et al., 2013). • Data selection (Moore and Lewis, 2010; Axelrod et al., 2011). • Instance weighting (Matsoukas et al., 2009; Foster et al., 2010; Shah et al., 2012; Mansour and Ney, 2012). • Further exploitation of in-domain monolingual data (Ueffing et al., 2007; Bertoldi and Federico, 2009; Schwenk and Senellart, 2009; Lambert et al., 2011). • Domain-specific features, e.g. binary features indicating the provenance of phrase pairs as implemented in the open-source Moses toolkit (Durrani et al., 2013b) or “domain augmentation” (Clark et a"
2015.mtsummit-papers.19,2012.amta-papers.19,0,0.106597,"ge pairs using training corpora of diverse origin, totalling tens of millions of parallel sentences. 2 Related Work A significant amount of research on domain adaptation for SMT has been conducted in recent years. Some methods which are commonly used are: • Tuning of the decoder model weights (Och and Ney, 2002) on an in-domain development set (Pecina et al., 2012). • Model combination (of language models, translation models, or reordering models) via interpolation or other schemes, e.g. phrase table fill-up (Foster and Kuhn, 2007; Koehn and Schroeder, 2007; Nakov, 2008; Bisazza et al., 2011; Niehues and Waibel, 2012; Chen et al., 2013). • Data selection (Moore and Lewis, 2010; Axelrod et al., 2011). • Instance weighting (Matsoukas et al., 2009; Foster et al., 2010; Shah et al., 2012; Mansour and Ney, 2012). • Further exploitation of in-domain monolingual data (Ueffing et al., 2007; Bertoldi and Federico, 2009; Schwenk and Senellart, 2009; Lambert et al., 2011). • Domain-specific features, e.g. binary features indicating the provenance of phrase pairs as implemented in the open-source Moses toolkit (Durrani et al., 2013b) or “domain augmentation” (Clark et al., 2012). However, few authors have tackled the"
2015.mtsummit-papers.19,P02-1038,0,0.261406,"cross all domains. However, a high-quality generic system with a single parameter set that does not depend on a domain label is appealing. In the empirical part of this paper, we compare multi-domain and mixed-domain SMT on the English→German, English→Italian, English→Portuguese, and English→Greek language pairs using training corpora of diverse origin, totalling tens of millions of parallel sentences. 2 Related Work A significant amount of research on domain adaptation for SMT has been conducted in recent years. Some methods which are commonly used are: • Tuning of the decoder model weights (Och and Ney, 2002) on an in-domain development set (Pecina et al., 2012). • Model combination (of language models, translation models, or reordering models) via interpolation or other schemes, e.g. phrase table fill-up (Foster and Kuhn, 2007; Koehn and Schroeder, 2007; Nakov, 2008; Bisazza et al., 2011; Niehues and Waibel, 2012; Chen et al., 2013). • Data selection (Moore and Lewis, 2010; Axelrod et al., 2011). • Instance weighting (Matsoukas et al., 2009; Foster et al., 2010; Shah et al., 2012; Mansour and Ney, 2012). • Further exploitation of in-domain monolingual data (Ueffing et al., 2007; Bertoldi and Fede"
2015.mtsummit-papers.19,J03-1002,0,0.00454929,"of all bilingual training corpora are presented in Table 1. For language modeling on the target side, we furthermore add monolingual corpora from recent (April 2015) Wikipedia database dumps5 and—for German—the News Crawl corpora provided for the WMT 2015 shared translation task. Plain text was obtained from the Wikipedia XML dumps with the Wikipedia Extractor6 tool. Statistics of the additional monolingual training corpora are presented in Table 2. 6.2 Machine Translation Systems Word alignments are created by aligning the data in both directions and symmetrizing the two trained alignments (Och and Ney, 2003; Koehn et al., 2003). We extract phrases up to a maximum length of five. The MT systems comprise these features: • Phrase translation log-probabilities, smoothed with Good-Turing smoothing (Foster et al., 2006), and lexical translation log-probabilities in both directions. • Phrase penalty and word penalty. • Distance-based distortion cost. • A hierarchical lexicalized reordering model (Galley and Manning, 2008). • A 5-gram operation sequence model (Durrani et al., 2013a). • Seven binary features indicating absolute occurrence count classes of phrase pairs. • Sparse phrase length features. •"
2015.mtsummit-papers.19,P02-1040,0,0.0960693,"ities in both directions. • Phrase penalty and word penalty. • Distance-based distortion cost. • A hierarchical lexicalized reordering model (Galley and Manning, 2008). • A 5-gram operation sequence model (Durrani et al., 2013a). • Seven binary features indicating absolute occurrence count classes of phrase pairs. • Sparse phrase length features. • Sparse lexical features for the top 200 words. • A 5-gram LM with modified Kneser-Ney smoothing (Kneser and Ney, 1995; Chen and Goodman, 1998). We discard singleton n-grams of order three and higher. Feature weights are optimized to maximize B LEU (Papineni et al., 2002) with batch MIRA (Cherry and Foster, 2012) on 1000-best lists. We prune the phrase table to a maximum of 100 5 http://dumps.wikimedia.org 6 https://github.com/bwbaugh/wikipedia-extractor Proceedings of MT Summit XV, vol.1: MT Researchers&apos; Track Miami, Oct 30 - Nov 3, 2015 |p. 245 best translation options per distinct source side and apply a minimum score threshold of 0.0001 on the source-to-target phrase translation probability. We use cube pruning in decoding. Pop limit and stack limit are set to 1000 for tuning and to 5000 for testing. We disallow reordering over punctuation. Furthermore, Mi"
2015.mtsummit-papers.19,C12-1135,0,0.0349806,"Missing"
2015.mtsummit-papers.19,2014.eamt-1.39,0,0.0710152,"Missing"
2015.mtsummit-papers.19,P14-2125,0,0.0205524,"iments on 20 language pairs. For domain classification, the authors rely on averaged perceptron classifiers with various phrase-based features. The machine translation development sets serve as training data for the classifiers. An interesting aspect of their translation experiments is that they utilize a multi-domain optimization in order to jointly tune weights for all domains in a single run of lattice MERT (Macherey et al., 2008). In a related strand of research, source-side text classifiers have recently been employed in order to detect Arabic dialects and select SMT systems accordingly (Salloum et al., 2014; Mansour et al., 2014). 3 Text Domains Our application scenario is an online translation service with the requirement to provide highquality translation not only of texts from a single domain, but of a wider range of text types. We therefore study a use case where the translation system is supposed to perform well on the following domains: TED talks, Europarl, and News. These three domains are fairly coarsegrained. Different documents from one of the domains are mostly not consistent regarding the covered topics. While all three domains comprise heterogeneous topics, the domains are set apart"
2015.mtsummit-papers.19,2009.mtsummit-posters.17,0,0.0569352,"main development set (Pecina et al., 2012). • Model combination (of language models, translation models, or reordering models) via interpolation or other schemes, e.g. phrase table fill-up (Foster and Kuhn, 2007; Koehn and Schroeder, 2007; Nakov, 2008; Bisazza et al., 2011; Niehues and Waibel, 2012; Chen et al., 2013). • Data selection (Moore and Lewis, 2010; Axelrod et al., 2011). • Instance weighting (Matsoukas et al., 2009; Foster et al., 2010; Shah et al., 2012; Mansour and Ney, 2012). • Further exploitation of in-domain monolingual data (Ueffing et al., 2007; Bertoldi and Federico, 2009; Schwenk and Senellart, 2009; Lambert et al., 2011). • Domain-specific features, e.g. binary features indicating the provenance of phrase pairs as implemented in the open-source Moses toolkit (Durrani et al., 2013b) or “domain augmentation” (Clark et al., 2012). However, few authors have tackled the question of how to benefit from domain adaptation in scenarios where a domain label of the input is not present. An important aspect of our approach to multi-domain MT is the need for domain classification. Proceedings of MT Summit XV, vol.1: MT Researchers&apos; Track Miami, Oct 30 - Nov 3, 2015 |p. 241 Xu et al. (2007) perform d"
2015.mtsummit-papers.19,2012.amta-papers.21,0,0.246487,"has been conducted in recent years. Some methods which are commonly used are: • Tuning of the decoder model weights (Och and Ney, 2002) on an in-domain development set (Pecina et al., 2012). • Model combination (of language models, translation models, or reordering models) via interpolation or other schemes, e.g. phrase table fill-up (Foster and Kuhn, 2007; Koehn and Schroeder, 2007; Nakov, 2008; Bisazza et al., 2011; Niehues and Waibel, 2012; Chen et al., 2013). • Data selection (Moore and Lewis, 2010; Axelrod et al., 2011). • Instance weighting (Matsoukas et al., 2009; Foster et al., 2010; Shah et al., 2012; Mansour and Ney, 2012). • Further exploitation of in-domain monolingual data (Ueffing et al., 2007; Bertoldi and Federico, 2009; Schwenk and Senellart, 2009; Lambert et al., 2011). • Domain-specific features, e.g. binary features indicating the provenance of phrase pairs as implemented in the open-source Moses toolkit (Durrani et al., 2013b) or “domain augmentation” (Clark et al., 2012). However, few authors have tackled the question of how to benefit from domain adaptation in scenarios where a domain label of the input is not present. An important aspect of our approach to multi-domain MT i"
2015.mtsummit-papers.19,steinberger-etal-2012-dgt,0,0.0441212,"Missing"
2015.mtsummit-papers.19,steinberger-etal-2006-jrc,0,0.0787518,"Missing"
2015.mtsummit-papers.19,tiedemann-2012-parallel,0,0.0570125,"Missing"
2015.mtsummit-papers.19,2012.amta-papers.18,0,0.0451164,"security in the area of computing. Empirical results on Chinese→English and English→Chinese tasks are presented. The authors build a Support Vector Machine (SVM) classifier using Term Frequency Inverse Sentence Frequency features over bigrams of stemmed content words. Classification is carried out on the level of individual sentences. The SVM is trained on the SMT training corpora (∼226k sentences in total). Several setups with different domain-adapted and domain-agnostic systems are evaluated. The authors show that a pipeline with the SVM classifier is effective in multi-domain translation. Wang et al. (2012) distinguish generic and patent domain data in experiments on 20 language pairs. For domain classification, the authors rely on averaged perceptron classifiers with various phrase-based features. The machine translation development sets serve as training data for the classifiers. An interesting aspect of their translation experiments is that they utilize a multi-domain optimization in order to jointly tune weights for all domains in a single run of lattice MERT (Macherey et al., 2008). In a related strand of research, source-side text classifiers have recently been employed in order to detect"
2015.mtsummit-papers.19,2007.mtsummit-papers.68,0,0.705796,"chwenk and Senellart, 2009; Lambert et al., 2011). • Domain-specific features, e.g. binary features indicating the provenance of phrase pairs as implemented in the open-source Moses toolkit (Durrani et al., 2013b) or “domain augmentation” (Clark et al., 2012). However, few authors have tackled the question of how to benefit from domain adaptation in scenarios where a domain label of the input is not present. An important aspect of our approach to multi-domain MT is the need for domain classification. Proceedings of MT Summit XV, vol.1: MT Researchers&apos; Track Miami, Oct 30 - Nov 3, 2015 |p. 241 Xu et al. (2007) perform domain classification for a Chinese→English task. The domains are newswire and newsgroup. The classifiers operate on whole documents rather than on individual sentences. The authors propose two techniques for domain classification. Their first technique is based on interpolated LMs: a general-domain LM is interpolated with LMs which were trained on in-domain development sets, resulting in a number of domain-specific interpolated LMs. The interpolation weight is heuristically chosen. The classifier computes LM perplexities over input documents and assigns the domain with the lowest per"
2020.wmt-1.1,2020.nlpcovid19-2.5,1,0.796341,"tails of the evaluation. 4.1.1 Covid Test Suite TICO-19 The TICO-19 test suite was developed to evaluate how well can MT systems handle the newlyemerged topic of COVID-19. Accurate automatic translation can play an important role in facilitating communication in order to protect at-risk populations and combat the infodemic of misinformation, as described by the World Health Organization. The test suite has no corresponding paper so its authors provided an analysis of the outcomes directly here. The submitted systems were evaluated using the test set from the recently-released TICO-19 dataset (Anastasopoulos et al., 2020). The dataset provides manually created translations of COVID19 related data. The test set consists of PubMed articles (678 sentences from 5 scientific articles), patient-medical professional conversations (104 sentences), as well as related Wikipedia articles (411 sentences), announcements (98 sentences from Wikisource), and news items (67 sentences from Wikinews), for a total of 2100 sentences. Table 15 outlines the BLEU scores by each submitted system in the English-to-X directions, also breaking down the results per domain. The analysis shows that some systems are significantly more prepar"
2020.wmt-1.1,2020.wmt-1.6,0,0.0647231,"AIP-NTT U BIQUS UEDIN UEDIN-CUNI UQAM_TAN L E VOLC T RANS W E C HAT WMTB IOMED BASELINE YOLO ZLABS - NLP Institution Air Force Research Laboratory (Gwinnup and Anderson, 2020) Independent submission (Xv, 2020) Charles University (Popel, 2020, 2018; Kocmi, 2020) Dublin City University (Parthasarathy et al., 2020) DeepMind (Yu et al., 2020) DiDi AI Labs (Chen et al., 2020b) (no associated paper) Indepdendent Submission (Kim et al., 2020) eTranslation (Oravecz et al., 2020) Facebook AI (Chen et al., 2020a) University of Groningen (Roest et al., 2020; Dhar et al., 2020) Global Tone Communication (Bei et al., 2020) University of Helsinki and Aalto University (Scherrer et al., 2020a) Huawei TSC (Wei et al., 2020a) Institute of Information Engineering, Chinese Academy of Sciences (Wei et al., 2020b) Microsoft STC India (Goyal et al., 2020) NICT-Kyoto (Marie et al., 2020) NICT-Rui (Li et al., 2020) NiuTrans (Zhang et al., 2020) National Research Council Canada (Knowles et al., 2020) OPPO (Shi et al., 2020) PROMT (Molchanov, 2020) SJTU-NICT (Li et al., 2020) Samsung Research Poland (Krubi´nski et al., 2020) TALP UPC (Escolano et al., 2020) Tencent Translation (Wu et al., 2020b) NLP Lab at Tsinghua Universit"
2020.wmt-1.1,2020.wmt-1.38,0,0.0746945,"Missing"
2020.wmt-1.1,2020.wmt-1.54,1,0.802974,"Missing"
2020.wmt-1.1,W07-0718,1,0.671054,"Missing"
2020.wmt-1.1,W08-0309,1,0.762341,"Missing"
2020.wmt-1.1,W12-3102,1,0.500805,"Missing"
2020.wmt-1.1,2020.lrec-1.461,0,0.0795779,"Missing"
2020.wmt-1.1,2012.eamt-1.60,0,0.124643,"tted systems, for those where the authors provided such details. The training corpus for Inuktitut↔English is the recently released Nunavut Hansard Inuktitut– English Parallel Corpus 3.0 (Joanis et al., 2020). For the Japanese↔English tasks, we added several freely available parallel corpora to the training data. It includes JParaCrawl v2.0 (Morishita et al., 2020), a large web-based parallel corpus, Japanese-English Subtitle Corpus (JESC) (Pryzant et al., 2017), the Kyoto Free Translation Task (KFTT) corpus (Neubig, 2011), constructed from the Kyoto-related Wikipedia articles, and TED Talks (Cettolo et al., 2012). The monolingual data we provided was similar to last year’s, with a 2019 news crawl added to all the news corpora. In addition, we provided versions of the news corpora for Czech, English and German, with both the document and paragraph structure retained. In other words, we did not apply sentence splitting to these corpora, and we retained the document boundaries and text ordering of the originals. Training, development, and test data for Pashto↔English and Khmer↔English are shared with the Parallel Corpus Filtering Shared Task (Koehn et al., 2020). The training data mostly comes from OPUS"
2020.wmt-1.1,2020.wmt-1.3,0,0.0731913,"on Machine Translation (WMT20)1 was held online with EMNLP 2020 and hosted a number of shared tasks on various aspects of machine translation. This conference built on 14 previous editions of WMT as workshops and conferences (Koehn and Monz, 2006; CallisonBurch et al., 2007, 2008, 2009, 2010, 2011, 2012; Bojar et al., 2013, 2014, 2015, 2016, 2017, 2018; Barrault et al., 2019). This year we conducted several official tasks. We report in this paper on the news and similar translation tasks. Additional shared tasks are described in separate papers in these proceedings: • automatic post-editing (Chatterjee et al., 2020) • biomedical translation (Bawden et al., 2020b) • chat translation (Farajian et al., 2020) • lifelong learning (Barrault et al., 2020) 1 Makoto Morishita NTT Santanu Pal WIPRO AI Abstract 1 Philipp Koehn JHU http://www.statmt.org/wmt20/ 1 Proceedings of the 5th Conference on Machine Translation (WMT), pages 1–55 c Online, November 19–20, 2020. 2020 Association for Computational Linguistics as “direct assessment”) that we explored in the previous years with convincing results in terms of the trade-off between annotation effort and reliable distinctions between systems. The primary objectives o"
2020.wmt-1.1,2020.wmt-1.8,0,0.0898111,"D D I D I -NLP DONG - NMT ENMT E T RANSLATION FACEBOOK AI G RONINGEN GTCOM H ELSINKI NLP H UAWEI TSC IIE M ICROSOFT STC I NDIA NICT-K YOTO NICT-RUI N IU T RANS NRC OPPO PROMT SJTU-NICT SRPOL TALP UPC T ENCENT T RANSLATION THUNLP T ILDE T OHOKU -AIP-NTT U BIQUS UEDIN UEDIN-CUNI UQAM_TAN L E VOLC T RANS W E C HAT WMTB IOMED BASELINE YOLO ZLABS - NLP Institution Air Force Research Laboratory (Gwinnup and Anderson, 2020) Independent submission (Xv, 2020) Charles University (Popel, 2020, 2018; Kocmi, 2020) Dublin City University (Parthasarathy et al., 2020) DeepMind (Yu et al., 2020) DiDi AI Labs (Chen et al., 2020b) (no associated paper) Indepdendent Submission (Kim et al., 2020) eTranslation (Oravecz et al., 2020) Facebook AI (Chen et al., 2020a) University of Groningen (Roest et al., 2020; Dhar et al., 2020) Global Tone Communication (Bei et al., 2020) University of Helsinki and Aalto University (Scherrer et al., 2020a) Huawei TSC (Wei et al., 2020a) Institute of Information Engineering, Chinese Academy of Sciences (Wei et al., 2020b) Microsoft STC India (Goyal et al., 2020) NICT-Kyoto (Marie et al., 2020) NICT-Rui (Li et al., 2020) NiuTrans (Zhang et al., 2020) National Research Council Canada (Know"
2020.wmt-1.1,2009.freeopmt-1.3,0,0.088081,"ve (CONTRASTIVE) or primary (PRIMARY), and the BLEU, RIBES and TER results. The scores are sorted by BLEU. In general, primary systems tend to be better than contrastive systems, as expected, but there are some exceptions. This year we recived major number of participants for the case of Indo-Aryan language group NUST-FJWU NUST-FJWU system is an extension of state-of-the-art Transformer model with hierarchical attention networks to incorporate contextual information. During training the model used back-translation. Prompsit This team is participating with a rulebased system based on Apertium (Forcada et al., 2009-11). Apertium is a free/open-source platform for developing rule-based machine translation systems and language technology that was first released in 2005. Apertium is hosted in Github where both language data and code are licensed under the GNU GPL. It is a research and business platform with a very active community that loves small languages. Language pairs are at a very different level of development and output quality in the platform, depending on two main variables: how much funded or in-kind effort has 32 5.4 i.e. Hindi–Marathi (in both directions). We received 22 submissions from 14 te"
2020.wmt-1.1,2020.wmt-1.80,0,0.0933589,"airs, to be evaluated on test sets consisting mainly of news stories. The task was also opened up to additional test suites to probe specific aspects of translation. In the similar language translation task, participants built machine translation systems for translating between closely related pairs of languages. Chi-kiu Lo NRC Masaaki Nagata NTT Marcos Zampieri Rochester Institute of Technology metrics (Mathur et al., 2020) parallel corpus filtering (Koehn et al., 2020) quality estimation (Specia et al., 2020a) robustness (Specia et al., 2020b) unsupervised and very low-resource translation (Fraser, 2020) In the news translation task (Section 2), participants were asked to translate a shared test set, optionally restricting themselves to the provided training data (“constrained” condition). We included 22 translation directions this year, with translation between English and each of Chinese, Czech, German and Russian, as well as French to and from German being repeated from last year, and English to and from Inuktitut, Japanese, Polish and Tamil being new for this year. Furthermore, English to and from Khmer and Pashto were included, using the same test sets as in the corpus filtering task. Th"
2020.wmt-1.1,W19-5204,0,0.0543621,"Missing"
2020.wmt-1.1,2020.emnlp-main.5,0,0.0410594,"luation of out-ofEnglish translations, HITs were generated using the same method as described for the SR+DC evaluation of into-English translations in Section 3.2.1 with minor modifications. Source-based DA allows to include human references in the evaluation as another system to provide an estimate of human performance. Human references were added to the pull of system outputs prior to sampling documents for tasks generation. If multiple references are available, which is the case for English→German (3 alternative reference translations, including 1 generated using the paraphrasing method of Freitag et al. (2020)) and English→Chinese (2 translations), each reference is assessed individually. Since the annotations are made by researchers and professional translators who ensure a betTable 11: Amount of data collected in the WMT20 manual document- and segment-level evaluation campaigns for bilingual/source-based evaluation out of English and nonEnglish pairs. et al., 2020; Laubli et al., 2020). It differs from SR+DC DA introduced in WMT19 (Bojar et al., 2019), and still used in into-English human evaluation this year, where a single segment from a document is provided on a screen at a time, followed by s"
2020.wmt-1.1,W18-3931,1,0.874637,"ese improvements to increased capacity (which allows increased sensitivity to long-range relations) of the models. 5 Similar Language Translation Most shared tasks at WMT (e.g. News, Biomedical) have historically dealt with translating texts from and to English. In recent years, we observed a growing interest in training systems to translate between languages other than English. This includes a number of papers applying MT to translate between pairs of closely-related languages, national language varieties, and dialects 27 of the same language (Zhang, 1998; Marujo et al., 2011; Hassani, 2017; Costa-jussà et al., 2018; Popovi´c et al., 2020). To address this topic, the first Similar Language Translation (SLT) shared task at WMT 2019 has been organized. It featured data from three pairs of closely-related languages from different language families: Spanish - Portuguese (Romance languages), Czech - Polish (Slavic languages), and Hindi - Nepali (IndoAryan languages). Following the success of the first SLT shared task at WMT 2019 and the interest of the community in this topic, we organize, for the second time at WMT, this shared task to evaluate the performance of state-of-the-art translation systems on trans"
2020.wmt-1.1,2020.wmt-1.18,0,0.0913945,"2020b) Microsoft STC India (Goyal et al., 2020) NICT-Kyoto (Marie et al., 2020) NICT-Rui (Li et al., 2020) NiuTrans (Zhang et al., 2020) National Research Council Canada (Knowles et al., 2020) OPPO (Shi et al., 2020) PROMT (Molchanov, 2020) SJTU-NICT (Li et al., 2020) Samsung Research Poland (Krubi´nski et al., 2020) TALP UPC (Escolano et al., 2020) Tencent Translation (Wu et al., 2020b) NLP Lab at Tsinghua University (no associated paper) Tilde (Krišlauks and Pinnis, 2020) Tohoku-AIP-NTT (Kiyono et al., 2020) Ubiqus (Hernandez and Nguyen, 2020) University of Edinburgh (Bawden et al., 2020a; Germann, 2020) University of Edinburgh and Charles University (Germann et al., 2020) Université du Québec à Montréal (no associated paper) ByteDance AI Lab (Wu et al., 2020a) WeChat (Meng et al., 2020) Baseline System from Biomedical Task (Bawden et al., 2020b) American University of Beirut (no associated paper) Zoho Corporation (no associated paper) Table 6: Participants in the shared translation task. Not all teams participated in all language pairs. The translations from the online systems were not submitted by their respective companies but were obtained by us, and are therefore anonymized in a fashion"
2020.wmt-1.1,2020.wmt-1.43,0,0.0835067,"Missing"
2020.wmt-1.1,2020.wmt-1.9,0,0.0939415,"Missing"
2020.wmt-1.1,2020.wmt-1.19,0,0.0674131,"Missing"
2020.wmt-1.1,2009.mtsummit-btm.6,0,0.103443,"Missing"
2020.wmt-1.1,W13-2305,1,0.929934,"work which can be well applied to different translation. directions. Techniques used in the submitted systems include optional multilingual pre-training (mRASP) for low resource languages, very deep Transformer or dynamic convolution models up to 50 encoder layers, iterative backtranslation, knowledge distillation, model ensemble and development set fine-tuning. The key ingredient of the process seems the strong focus on diversification of the (synthetic) training data, using multiple scalings of the Transformer model 3.1 Direct Assessment Since running a comparison of direct assessments (DA, Graham et al., 2013, 2014, 2016) and relative ranking in 2016 (Bojar et al., 2016) and verifying a high correlation of system rankings for the two methods, as well as the advantages of DA, such as quality controlled crowd-sourcing and linear growth relative to numbers of submissions, we have employed DA as the primary mechanism for evaluating systems. With DA human evaluation, 15 human assessors are asked to rate a given translation by how adequately it expresses the meaning of the corresponding reference translation or source language input on an analogue scale, which corresponds to an underlying absolute 0–100"
2020.wmt-1.1,E14-1047,1,0.888167,"Missing"
2020.wmt-1.1,2020.lrec-1.312,1,0.804196,"A screenshot of OCELoT is shown in Figure 5. For presentation of the results, systems are treated as either constrained or unconstrained, depending on whether their models were trained only on the provided data. Since we do not know how they were built, the online systems are treated as unconstrained during the automatic and human evaluations. In the rest of this section, we provide brief details of the submitted systems, for those where the authors provided such details. The training corpus for Inuktitut↔English is the recently released Nunavut Hansard Inuktitut– English Parallel Corpus 3.0 (Joanis et al., 2020). For the Japanese↔English tasks, we added several freely available parallel corpora to the training data. It includes JParaCrawl v2.0 (Morishita et al., 2020), a large web-based parallel corpus, Japanese-English Subtitle Corpus (JESC) (Pryzant et al., 2017), the Kyoto Free Translation Task (KFTT) corpus (Neubig, 2011), constructed from the Kyoto-related Wikipedia articles, and TED Talks (Cettolo et al., 2012). The monolingual data we provided was similar to last year’s, with a 2019 news crawl added to all the news corpora. In addition, we provided versions of the news corpora for Czech, Engli"
2020.wmt-1.1,2020.emnlp-main.6,1,0.839606,"shown in Table 3, where the first and second are simple merges or splits, whereas the third is a rare case of more complex reordering. We leave a detailed analysis of the translators’ treatment of paragraph-split data for future work. development set is provided, it is a mixture of both “source-original” and “target-original” texts, in order to maximise its size, although the original language is always marked in the sgm file, except for Inuktitut↔English. The consequences of directionality in test sets has been discussed recently in the literature (Freitag et al., 2019; Laubli et al., 2020; Graham et al., 2020), and the conclusion is that it can have an effect on detrimental effect on the accuracy of system evaluation. We use “source-original” parallel sentences wherever possible, on the basis that it is the more realistic scenario for practical MT usage. Exception: the test sets for the two Inuktitut↔English translation directions contain the same data, without regard to original direction. For most news text in the test and development sets, English was the original language and Inuktitut the translation, while the parliamentary data mixes the two directions. The origins of the news test documents"
2020.wmt-1.1,2020.wmt-1.11,0,0.0940191,"N GTCOM H ELSINKI NLP H UAWEI TSC IIE M ICROSOFT STC I NDIA NICT-K YOTO NICT-RUI N IU T RANS NRC OPPO PROMT SJTU-NICT SRPOL TALP UPC T ENCENT T RANSLATION THUNLP T ILDE T OHOKU -AIP-NTT U BIQUS UEDIN UEDIN-CUNI UQAM_TAN L E VOLC T RANS W E C HAT WMTB IOMED BASELINE YOLO ZLABS - NLP Institution Air Force Research Laboratory (Gwinnup and Anderson, 2020) Independent submission (Xv, 2020) Charles University (Popel, 2020, 2018; Kocmi, 2020) Dublin City University (Parthasarathy et al., 2020) DeepMind (Yu et al., 2020) DiDi AI Labs (Chen et al., 2020b) (no associated paper) Indepdendent Submission (Kim et al., 2020) eTranslation (Oravecz et al., 2020) Facebook AI (Chen et al., 2020a) University of Groningen (Roest et al., 2020; Dhar et al., 2020) Global Tone Communication (Bei et al., 2020) University of Helsinki and Aalto University (Scherrer et al., 2020a) Huawei TSC (Wei et al., 2020a) Institute of Information Engineering, Chinese Academy of Sciences (Wei et al., 2020b) Microsoft STC India (Goyal et al., 2020) NICT-Kyoto (Marie et al., 2020) NICT-Rui (Li et al., 2020) NiuTrans (Zhang et al., 2020) National Research Council Canada (Knowles et al., 2020) OPPO (Shi et al., 2020) PROMT (Molchanov, 2020) S"
2020.wmt-1.1,D19-1632,1,0.881933,"ent and paragraph structure retained. In other words, we did not apply sentence splitting to these corpora, and we retained the document boundaries and text ordering of the originals. Training, development, and test data for Pashto↔English and Khmer↔English are shared with the Parallel Corpus Filtering Shared Task (Koehn et al., 2020). The training data mostly comes from OPUS (software localization, Tatoeba, Global Voices), the Bible, and specialprepared corpora from TED Talks and the Jehova Witness web site (JW300). The development and test sets were created as part of the Flores initiative (Guzmán et al., 2019) by professional translation of Wikipedia content with careful vetting of the translations. Please refer the to the Parallel Corpus Filtering Shared Task overview paper for details on these corpora. 2.3.1 AFRL (Gwinnup and Anderson, 2020) AFRL - SYSCOMB 20 is a system combination consisting of two Marian transformer ensembles, one OpenNMT transformer system and a Moses phrase-based system. AFRL - FINETUNE is an OpenNMT transformer system fine-tuned on newstest2014-2017. 2.3.2 (Xv, 2020) ARIEL XV is a Transformer base model trained with the Sockeye sequence modeling toolkit usSome statistics ab"
2020.wmt-1.1,2020.wmt-1.12,1,0.754946,"Missing"
2020.wmt-1.1,2020.wmt-1.13,0,0.0737827,"2020b) (no associated paper) Indepdendent Submission (Kim et al., 2020) eTranslation (Oravecz et al., 2020) Facebook AI (Chen et al., 2020a) University of Groningen (Roest et al., 2020; Dhar et al., 2020) Global Tone Communication (Bei et al., 2020) University of Helsinki and Aalto University (Scherrer et al., 2020a) Huawei TSC (Wei et al., 2020a) Institute of Information Engineering, Chinese Academy of Sciences (Wei et al., 2020b) Microsoft STC India (Goyal et al., 2020) NICT-Kyoto (Marie et al., 2020) NICT-Rui (Li et al., 2020) NiuTrans (Zhang et al., 2020) National Research Council Canada (Knowles et al., 2020) OPPO (Shi et al., 2020) PROMT (Molchanov, 2020) SJTU-NICT (Li et al., 2020) Samsung Research Poland (Krubi´nski et al., 2020) TALP UPC (Escolano et al., 2020) Tencent Translation (Wu et al., 2020b) NLP Lab at Tsinghua University (no associated paper) Tilde (Krišlauks and Pinnis, 2020) Tohoku-AIP-NTT (Kiyono et al., 2020) Ubiqus (Hernandez and Nguyen, 2020) University of Edinburgh (Bawden et al., 2020a; Germann, 2020) University of Edinburgh and Charles University (Germann et al., 2020) Université du Québec à Montréal (no associated paper) ByteDance AI Lab (Wu et al., 2020a) WeChat (Meng et al"
2020.wmt-1.1,2020.wmt-1.20,0,0.057602,"Missing"
2020.wmt-1.1,2020.wmt-1.14,1,0.820019,"set, and the origlang tag indicates the original source language. 9 Team AFRL ARIEL XV CUNI DCU D EEP M IND D I D I -NLP DONG - NMT ENMT E T RANSLATION FACEBOOK AI G RONINGEN GTCOM H ELSINKI NLP H UAWEI TSC IIE M ICROSOFT STC I NDIA NICT-K YOTO NICT-RUI N IU T RANS NRC OPPO PROMT SJTU-NICT SRPOL TALP UPC T ENCENT T RANSLATION THUNLP T ILDE T OHOKU -AIP-NTT U BIQUS UEDIN UEDIN-CUNI UQAM_TAN L E VOLC T RANS W E C HAT WMTB IOMED BASELINE YOLO ZLABS - NLP Institution Air Force Research Laboratory (Gwinnup and Anderson, 2020) Independent submission (Xv, 2020) Charles University (Popel, 2020, 2018; Kocmi, 2020) Dublin City University (Parthasarathy et al., 2020) DeepMind (Yu et al., 2020) DiDi AI Labs (Chen et al., 2020b) (no associated paper) Indepdendent Submission (Kim et al., 2020) eTranslation (Oravecz et al., 2020) Facebook AI (Chen et al., 2020a) University of Groningen (Roest et al., 2020; Dhar et al., 2020) Global Tone Communication (Bei et al., 2020) University of Helsinki and Aalto University (Scherrer et al., 2020a) Huawei TSC (Wei et al., 2020a) Institute of Information Engineering, Chinese Academy of Sciences (Wei et al., 2020b) Microsoft STC India (Goyal et al., 2020) NICT-Kyoto (Mari"
2020.wmt-1.1,2020.wmt-1.39,1,0.812433,"kables was collected in the first phase of the annotation, which amounted to 4k assessments across the systems. The second annotation phase with 6.5k assessments compared markable translations, always checking outputs of all the 13 competing MT systems but still considering the document-level context of each of them. Among other things, the observations indicate that the better the system, the lower the variance in manual scores. Markables annotation then confirms that frequent errors like bad translation of a term need not be the most severe and conversely, 4.1.3 Gender Coreference and Bias (Kocmi et al., 2020) The test suite by Kocmi et al. (2020) focuses on the gender bias in professions (e.g. physician, teacher, secretary) for the translation from English into Czech, German, Polish and Russian. These nouns are ambiguous with respect to gender in English but exhibit gender in the examined target languages. The test suite is based on the fact that a pronoun referring to the ambiguous noun can reveal the gender of the noun in the English source sentence. Once disambiguated, the gender needs to be preserved in translation. To correctly translate the given noun, the translation system thus has to corr"
2020.wmt-1.1,2020.wmt-1.53,0,0.089538,"Missing"
2020.wmt-1.1,2020.wmt-1.78,1,0.815194,"rence on Machine Translation (WMT) 2020. In the news task, participants were asked to build machine translation systems for any of 11 language pairs, to be evaluated on test sets consisting mainly of news stories. The task was also opened up to additional test suites to probe specific aspects of translation. In the similar language translation task, participants built machine translation systems for translating between closely related pairs of languages. Chi-kiu Lo NRC Masaaki Nagata NTT Marcos Zampieri Rochester Institute of Technology metrics (Mathur et al., 2020) parallel corpus filtering (Koehn et al., 2020) quality estimation (Specia et al., 2020a) robustness (Specia et al., 2020b) unsupervised and very low-resource translation (Fraser, 2020) In the news translation task (Section 2), participants were asked to translate a shared test set, optionally restricting themselves to the provided training data (“constrained” condition). We included 22 translation directions this year, with translation between English and each of Chinese, Czech, German and Russian, as well as French to and from German being repeated from last year, and English to and from Inuktitut, Japanese, Polish and Tamil being new fo"
2020.wmt-1.1,W17-1208,0,0.0524248,"ttribute all these improvements to increased capacity (which allows increased sensitivity to long-range relations) of the models. 5 Similar Language Translation Most shared tasks at WMT (e.g. News, Biomedical) have historically dealt with translating texts from and to English. In recent years, we observed a growing interest in training systems to translate between languages other than English. This includes a number of papers applying MT to translate between pairs of closely-related languages, national language varieties, and dialects 27 of the same language (Zhang, 1998; Marujo et al., 2011; Hassani, 2017; Costa-jussà et al., 2018; Popovi´c et al., 2020). To address this topic, the first Similar Language Translation (SLT) shared task at WMT 2019 has been organized. It featured data from three pairs of closely-related languages from different language families: Spanish - Portuguese (Romance languages), Czech - Polish (Slavic languages), and Hindi - Nepali (IndoAryan languages). Following the success of the first SLT shared task at WMT 2019 and the interest of the community in this topic, we organize, for the second time at WMT, this shared task to evaluate the performance of state-of-the-art tr"
2020.wmt-1.1,2020.wmt-1.21,0,0.0791885,"Missing"
2020.wmt-1.1,2020.wmt-1.23,0,0.0607352,"020) Dublin City University (Parthasarathy et al., 2020) DeepMind (Yu et al., 2020) DiDi AI Labs (Chen et al., 2020b) (no associated paper) Indepdendent Submission (Kim et al., 2020) eTranslation (Oravecz et al., 2020) Facebook AI (Chen et al., 2020a) University of Groningen (Roest et al., 2020; Dhar et al., 2020) Global Tone Communication (Bei et al., 2020) University of Helsinki and Aalto University (Scherrer et al., 2020a) Huawei TSC (Wei et al., 2020a) Institute of Information Engineering, Chinese Academy of Sciences (Wei et al., 2020b) Microsoft STC India (Goyal et al., 2020) NICT-Kyoto (Marie et al., 2020) NICT-Rui (Li et al., 2020) NiuTrans (Zhang et al., 2020) National Research Council Canada (Knowles et al., 2020) OPPO (Shi et al., 2020) PROMT (Molchanov, 2020) SJTU-NICT (Li et al., 2020) Samsung Research Poland (Krubi´nski et al., 2020) TALP UPC (Escolano et al., 2020) Tencent Translation (Wu et al., 2020b) NLP Lab at Tsinghua University (no associated paper) Tilde (Krišlauks and Pinnis, 2020) Tohoku-AIP-NTT (Kiyono et al., 2020) Ubiqus (Hernandez and Nguyen, 2020) University of Edinburgh (Bawden et al., 2020a; Germann, 2020) University of Edinburgh and Charles University (Germann et al., 2"
2020.wmt-1.1,2020.wmt-1.77,1,0.84299,"slation task, both organised alongside the Conference on Machine Translation (WMT) 2020. In the news task, participants were asked to build machine translation systems for any of 11 language pairs, to be evaluated on test sets consisting mainly of news stories. The task was also opened up to additional test suites to probe specific aspects of translation. In the similar language translation task, participants built machine translation systems for translating between closely related pairs of languages. Chi-kiu Lo NRC Masaaki Nagata NTT Marcos Zampieri Rochester Institute of Technology metrics (Mathur et al., 2020) parallel corpus filtering (Koehn et al., 2020) quality estimation (Specia et al., 2020a) robustness (Specia et al., 2020b) unsupervised and very low-resource translation (Fraser, 2020) In the news translation task (Section 2), participants were asked to translate a shared test set, optionally restricting themselves to the provided training data (“constrained” condition). We included 22 translation directions this year, with translation between English and each of Chinese, Czech, German and Russian, as well as French to and from German being repeated from last year, and English to and from Inu"
2020.wmt-1.1,2020.wmt-1.24,0,0.0435945,"Missing"
2020.wmt-1.1,D18-1512,0,0.05415,"Missing"
2020.wmt-1.1,2020.wmt-1.47,1,0.740067,"Missing"
2020.wmt-1.1,W18-3601,1,0.891679,", we have employed DA as the primary mechanism for evaluating systems. With DA human evaluation, 15 human assessors are asked to rate a given translation by how adequately it expresses the meaning of the corresponding reference translation or source language input on an analogue scale, which corresponds to an underlying absolute 0–100 rating scale.5 No sentence or document length restriction is applied during manual evaluation. Direct Assessment is also employed for evaluation of video captioning systems at TRECvid (Graham et al., 2018; Awad et al., 2019) and multilingual surface realisation (Mille et al., 2018, 2019). 3.1.1 tion 2, most of our test sets do not include reversecreated sentence pairs, except when there were resource constraints on the creation of the test sets. 3.1.3 Prior to WMT19, the issue of including document context was raised within the community (Läubli et al., 2018; Toral et al., 2018) and at WMT19 a range of DA styles were subsequently tested that included document context. In WMT19, two options were run, firstly, an evaluation that included the document context “+DC” (with document context), and secondly, a variation that omitted document context “−DC” (without document con"
2020.wmt-1.1,2020.wmt-1.27,0,0.247738,"he original source language. 9 Team AFRL ARIEL XV CUNI DCU D EEP M IND D I D I -NLP DONG - NMT ENMT E T RANSLATION FACEBOOK AI G RONINGEN GTCOM H ELSINKI NLP H UAWEI TSC IIE M ICROSOFT STC I NDIA NICT-K YOTO NICT-RUI N IU T RANS NRC OPPO PROMT SJTU-NICT SRPOL TALP UPC T ENCENT T RANSLATION THUNLP T ILDE T OHOKU -AIP-NTT U BIQUS UEDIN UEDIN-CUNI UQAM_TAN L E VOLC T RANS W E C HAT WMTB IOMED BASELINE YOLO ZLABS - NLP Institution Air Force Research Laboratory (Gwinnup and Anderson, 2020) Independent submission (Xv, 2020) Charles University (Popel, 2020, 2018; Kocmi, 2020) Dublin City University (Parthasarathy et al., 2020) DeepMind (Yu et al., 2020) DiDi AI Labs (Chen et al., 2020b) (no associated paper) Indepdendent Submission (Kim et al., 2020) eTranslation (Oravecz et al., 2020) Facebook AI (Chen et al., 2020a) University of Groningen (Roest et al., 2020; Dhar et al., 2020) Global Tone Communication (Bei et al., 2020) University of Helsinki and Aalto University (Scherrer et al., 2020a) Huawei TSC (Wei et al., 2020a) Institute of Information Engineering, Chinese Academy of Sciences (Wei et al., 2020b) Microsoft STC India (Goyal et al., 2020) NICT-Kyoto (Marie et al., 2020) NICT-Rui (Li et al., 2020) NiuTrans"
2020.wmt-1.1,D19-6301,1,0.888512,"Missing"
2020.wmt-1.1,W18-6424,0,0.0431841,"(Kocmi, 2020) combines transfer learning from a high-resource language pair Czech–English into the low-resource Inuktitut-English with an additional backtranslation step. Surprising behaviour is noticed when using synthetic data, which can be possibly attributed to a narrow domain of training and test data. The system is the Transformer model in a constrained submission. 2.3.3 Charles University (CUNI) CUNI-D OC T RANSFORMER (Popel, 2020) is similar to the sentence-level version (CUNI-T2T2018, CUBBITT), but trained on sequences with multiple sentences of up to 3000 characters. CUNI-T2T-2018 (Popel, 2018), also called CUBBITT, is exactly the same system as in WMT2018. It is the Transformer model trained according to Popel and Bojar (2018) plus a novel concat-regime backtranslation with checkpoint averaging (Popel et al., 2020), tuned separately for CZ-domain and non CZ-domain articles, possibly handling also translation-direction (“translationese”) issues. For cs→en also a coreference preprocessing was used adding the female-gender CUNI-T RANSFORMER (Popel, 2020) is similar to the WMT2018 version of CUBBITT, but with 12 encoder layers instead of 6 and trained on CzEng 2.0 instead of CzEng 1.7."
2020.wmt-1.1,2020.wmt-1.25,0,0.094349,"Missing"
2020.wmt-1.1,2020.wmt-1.28,0,0.0792624,"cument in the test set, and the origlang tag indicates the original source language. 9 Team AFRL ARIEL XV CUNI DCU D EEP M IND D I D I -NLP DONG - NMT ENMT E T RANSLATION FACEBOOK AI G RONINGEN GTCOM H ELSINKI NLP H UAWEI TSC IIE M ICROSOFT STC I NDIA NICT-K YOTO NICT-RUI N IU T RANS NRC OPPO PROMT SJTU-NICT SRPOL TALP UPC T ENCENT T RANSLATION THUNLP T ILDE T OHOKU -AIP-NTT U BIQUS UEDIN UEDIN-CUNI UQAM_TAN L E VOLC T RANS W E C HAT WMTB IOMED BASELINE YOLO ZLABS - NLP Institution Air Force Research Laboratory (Gwinnup and Anderson, 2020) Independent submission (Xv, 2020) Charles University (Popel, 2020, 2018; Kocmi, 2020) Dublin City University (Parthasarathy et al., 2020) DeepMind (Yu et al., 2020) DiDi AI Labs (Chen et al., 2020b) (no associated paper) Indepdendent Submission (Kim et al., 2020) eTranslation (Oravecz et al., 2020) Facebook AI (Chen et al., 2020a) University of Groningen (Roest et al., 2020; Dhar et al., 2020) Global Tone Communication (Bei et al., 2020) University of Helsinki and Aalto University (Scherrer et al., 2020a) Huawei TSC (Wei et al., 2020a) Institute of Information Engineering, Chinese Academy of Sciences (Wei et al., 2020b) Microsoft STC India (Goyal et al., 20"
2020.wmt-1.1,2020.lrec-1.443,1,0.79707,"er their models were trained only on the provided data. Since we do not know how they were built, the online systems are treated as unconstrained during the automatic and human evaluations. In the rest of this section, we provide brief details of the submitted systems, for those where the authors provided such details. The training corpus for Inuktitut↔English is the recently released Nunavut Hansard Inuktitut– English Parallel Corpus 3.0 (Joanis et al., 2020). For the Japanese↔English tasks, we added several freely available parallel corpora to the training data. It includes JParaCrawl v2.0 (Morishita et al., 2020), a large web-based parallel corpus, Japanese-English Subtitle Corpus (JESC) (Pryzant et al., 2017), the Kyoto Free Translation Task (KFTT) corpus (Neubig, 2011), constructed from the Kyoto-related Wikipedia articles, and TED Talks (Cettolo et al., 2012). The monolingual data we provided was similar to last year’s, with a 2019 news crawl added to all the news corpora. In addition, we provided versions of the news corpora for Czech, English and German, with both the document and paragraph structure retained. In other words, we did not apply sentence splitting to these corpora, and we retained t"
2020.wmt-1.1,2020.wmt-1.48,0,0.090424,"Missing"
2020.wmt-1.1,2020.wmt-1.49,0,0.0519886,"Missing"
2020.wmt-1.1,W19-6712,0,0.0573476,"tly crawled multilingual parallel corpora from Indian government websites (Haddow and Kirefu, 2020; Siripragada et al., 2020), the Tanzil corpus (Tiedemann, 2009), the Pavlick dicParagraph-split Test Sets For the language pairs English↔Czech, English↔German and English→Chinese, we provided the translators with paragraph-split texts, instead of sentence-split texts. We did this in order to provide the translators with greater freedom and, hopefully, to improve the quality of the translation. Allowing translators to merge and split sentences removes one of the “translation shifts” identified by Popovic (2019), which can make translations create solely for MT evaluation different from translations produced for other purposes. We first show some descriptive statistics of the source texts, for Czech, English and German, in 3 Europarl Parallel Corpus Czech ↔ English German ↔ English Polish↔ English German ↔ French Sentences 645,241 1,825,745 632,435 1,801,076 Words 14,948,900 17,380,340 48,125,573 50,506,059 14,691,199 16,995,232 47,517,102 55,366,136 Distinct words 172,452 63,289 371,748 113,960 170,271 62,694 368,585 134,762 News Commentary Parallel Corpus Czech ↔ English 248,927 5,570,734 6,156,063"
2020.wmt-1.1,2020.wmt-1.26,0,0.0845151,"Missing"
2020.wmt-1.1,2020.vardial-1.10,0,0.0933804,"Missing"
2020.wmt-1.1,W18-6301,0,0.038239,"Missing"
2020.wmt-1.1,2020.wmt-1.51,0,0.0917045,"Missing"
2020.wmt-1.1,2020.wmt-1.50,1,0.78567,"Missing"
2020.wmt-1.1,2020.wmt-1.52,0,0.0485419,"Missing"
2020.wmt-1.1,P19-1164,0,0.0581517,"26 26.37 25.51 24.82 28.33 23.33 21.13 21.96 20.43 22.90 22.58 21.90 22.17 22.17 20.53 19.40 20.01 40.44 32.39 30.39 37.04 32.27 27.54 25.97 26.09 46.38 37.30 36.05 35.96 33.76 33.07 27.20 27.07 Table 15: TICO-19 test suite results on the English-to-X WMT20 translation directions. 26 4.1.5 antecedent (a less common direction of information flow), and then correctly express the noun in the target language. The success of the MT system in this test can be established automatically, whenever the gender of the target word can be automatically identified. Kocmi et al. (2020) build upon the WinoMT (Stanovsky et al., 2019) test set, which provides exactly the necessary type of sentences containing an ambiguous profession noun and a personal pronoun which unambiguously (for the human eye) refers to it based the situation described. When extending WinMT with Czech and Polish, Stanovsky et al. have to disregard some test patterns but the principle remains. The results indicate that all MT systems fail in this test, following gender bias (stereotypical patterns attributing the masculine gender to some professions and feminine gender to others) rather than the coreference link. Word Sense Disambiguation (Scherrer et"
2020.wmt-1.1,2020.wmt-1.31,0,0.0881792,"morphological segmentation of the polysynthetic Inuktitut, testing rule-based, supervised, semi-supervised as well as unsupervised word segmentation methods, (2) whether or not adding data from a related language (Greenlandic) helps, and (3) whether contextual word embeddings (XLM) improve translation. G RONINGEN - ENIU use Transformer implemented in Marian with the default setting, improving the performance also with tagged backtranslation, domain-specific data, ensembling and finetuning. 2.3.7 DONG - NMT (no associated paper) No description provided. 2.3.8 ENMT (Kim et al., 2020) Kim et al. (2020) base their approach on transferring knowledge of domain and linguistic characteristics by pre-training the encoder-decoder model with large amount of in-domain monolingual data through unsupervised and supervised prediction task. The model is then fine-tuned with parallel data and in-domain synthetic data, generated with iterative back-translation. For additional gain, final results are generated with an ensemble model and re-ranked with averaged models and language models. G RONINGEN - ENTAM (Dhar et al., 2020) study the effects of various techniques such as linguistically motivated segmenta"
2020.wmt-1.1,2020.wmt-1.32,0,0.0839317,"- NLP Institution Air Force Research Laboratory (Gwinnup and Anderson, 2020) Independent submission (Xv, 2020) Charles University (Popel, 2020, 2018; Kocmi, 2020) Dublin City University (Parthasarathy et al., 2020) DeepMind (Yu et al., 2020) DiDi AI Labs (Chen et al., 2020b) (no associated paper) Indepdendent Submission (Kim et al., 2020) eTranslation (Oravecz et al., 2020) Facebook AI (Chen et al., 2020a) University of Groningen (Roest et al., 2020; Dhar et al., 2020) Global Tone Communication (Bei et al., 2020) University of Helsinki and Aalto University (Scherrer et al., 2020a) Huawei TSC (Wei et al., 2020a) Institute of Information Engineering, Chinese Academy of Sciences (Wei et al., 2020b) Microsoft STC India (Goyal et al., 2020) NICT-Kyoto (Marie et al., 2020) NICT-Rui (Li et al., 2020) NiuTrans (Zhang et al., 2020) National Research Council Canada (Knowles et al., 2020) OPPO (Shi et al., 2020) PROMT (Molchanov, 2020) SJTU-NICT (Li et al., 2020) Samsung Research Poland (Krubi´nski et al., 2020) TALP UPC (Escolano et al., 2020) Tencent Translation (Wu et al., 2020b) NLP Lab at Tsinghua University (no associated paper) Tilde (Krišlauks and Pinnis, 2020) Tohoku-AIP-NTT (Kiyono et al., 2020) Ub"
2020.wmt-1.1,2020.wmt-1.33,0,0.080166,"Missing"
2020.wmt-1.1,2020.wmt-1.34,0,0.0803867,"Missing"
2020.wmt-1.1,2020.wmt-1.35,0,0.0951745,"ss web site (JW300). The development and test sets were created as part of the Flores initiative (Guzmán et al., 2019) by professional translation of Wikipedia content with careful vetting of the translations. Please refer the to the Parallel Corpus Filtering Shared Task overview paper for details on these corpora. 2.3.1 AFRL (Gwinnup and Anderson, 2020) AFRL - SYSCOMB 20 is a system combination consisting of two Marian transformer ensembles, one OpenNMT transformer system and a Moses phrase-based system. AFRL - FINETUNE is an OpenNMT transformer system fine-tuned on newstest2014-2017. 2.3.2 (Xv, 2020) ARIEL XV is a Transformer base model trained with the Sockeye sequence modeling toolkit usSome statistics about the training and test materials are given in Figures 1, 2, 3 and 4. 4 8 ARIEL XV https://github.com/AppraiseDev/OCELoT English I English II English III Chinese Czech German Inuktitut Japanese Polish Russian Tamil ABC News (2), All Africa (5), Brisbane Times (1), CBS LA (1), CBS News (1), CNBC (3), CNN (2), Daily Express (1), Daily Mail (2), Fox News (1), Gateway (1), Guardian (3), Huffington Post (2), London Evening Standard (2), Metro (2), NDTV (7), RTE (7), Reuters (4), STV (2), S"
2020.wmt-1.1,2020.wmt-1.55,0,0.0877526,"Missing"
2020.wmt-1.1,P17-4012,0,0.0273892,"o SJTU-NICT using large XLM model to improve NMT but the exact relation is unclear. 2.3.14 H UAWEI TSC (Wei et al., 2020a) H UAWEI TSC use Transformer-big with a further increased model size, focussing on standard techniques of careful pre-processing and filtering, back-translation and forward translation, including self-training, i.e. translating one of the sides of the original parallel data. Ensembling of individual training runs is used in the forward as well as backward translation, and single models are created from the ensembles using knowledge distillation. The submission uses THUNMT (Zhang et al., 2017) open-source engine. 2.3.19 N IU T RANS (Zhang et al., 2020) N IU T RANS gain their performance from focussed attention to six areas: (1) careful data preprocessing and filtering, (2) iterative back-translation to generate additional training data, (3) using different model architectures, such as wider and/or deeper models, relative position representation and relative length, to enhance the diversity of translations, (4) iterative knowledge distillation by in-domain monolingual data, (5) iterative finetuning for domain adaptation using small training batches, (6) rule-based post-processing of"
2020.wmt-1.1,P98-2238,0,0.590812,"and punctuation, and we tend to attribute all these improvements to increased capacity (which allows increased sensitivity to long-range relations) of the models. 5 Similar Language Translation Most shared tasks at WMT (e.g. News, Biomedical) have historically dealt with translating texts from and to English. In recent years, we observed a growing interest in training systems to translate between languages other than English. This includes a number of papers applying MT to translate between pairs of closely-related languages, national language varieties, and dialects 27 of the same language (Zhang, 1998; Marujo et al., 2011; Hassani, 2017; Costa-jussà et al., 2018; Popovi´c et al., 2020). To address this topic, the first Similar Language Translation (SLT) shared task at WMT 2019 has been organized. It featured data from three pairs of closely-related languages from different language families: Spanish - Portuguese (Romance languages), Czech - Polish (Slavic languages), and Hindi - Nepali (IndoAryan languages). Following the success of the first SLT shared task at WMT 2019 and the interest of the community in this topic, we organize, for the second time at WMT, this shared task to evaluate th"
2020.wmt-1.1,2020.wmt-1.41,1,0.814291,"Missing"
2021.mtsummit-research.15,D11-1033,0,0.11817,"Missing"
2021.mtsummit-research.15,W17-3205,0,0.0478084,"Missing"
2021.mtsummit-research.15,2016.amta-researchers.8,0,0.0794367,"Missing"
2021.mtsummit-research.15,C18-1111,0,0.0338678,"Missing"
2021.mtsummit-research.15,C14-1182,0,0.0544397,"Missing"
2021.mtsummit-research.15,P13-2119,0,0.0699272,"Missing"
2021.mtsummit-research.15,2015.mtsummit-papers.10,0,0.0372926,"Missing"
2021.mtsummit-research.15,P18-4020,0,0.024643,"Missing"
2021.mtsummit-research.15,D14-1181,0,0.0116659,"ch is widely used throughout various papers and systems with regard to domain adaptation. It is mathematically relatively inexpensive and can therefore be computed very quickly even for extensive training corpora, without the need for GPU resources. These factors make it a suitable baseline for our comparisons to neural classification systems. 2.2 CNN Classifier Convolutional neural networks (CNN) perform very well on tasks like image and sentence classification. In our case, we are classifying sentences in two classes, in-domain and outof-domain. We applied a plain vanilla system by Yoon Kim Kim (2014), which consists of a simple CNN on top of pretrained word vectors. CNNs consist of layers with convolving filters learning local features. In this architecture one layer of convolution is applied on top of word vectors trained by Mikolov et al. (2013) on Google News. This approach performed well on several sentence classification tasks (Kim, 2014). Figure 1 shows this simple model architecture. A sentence of length n (shorter sentences are padded) is represented as the concatenation of its word vectors. Similar to computer vision Proceedings of the 18th Biennial Machine Translation Summit Vir"
2021.mtsummit-research.15,W11-2132,0,0.0825917,"Missing"
2021.mtsummit-research.15,P10-2041,0,0.0472524,"data. Here we carry out a comparison between an established baseline (cross entropy) to the two different techniques based on neural networks that we have discussed (CNN and RNTN). 2.1 XenC: LM Cross-Entropy Difference Language model (LM ) cross-entropy difference scoring is a widely used technique for MT domain adaptation. The approach is implemented in the tool XenC Rousseau (2013). Here the difference between cross-entropy scores of sentences from the entire training corpus and the sentences of an in-domain corpus is computed. We applied monolingual cross-entropy difference as proposed by (Moore and Lewis, 2010), which is defined as n H(PLM ) = − 1X logPLM (wi |wi , . . . , wi−1 ) n i=1 (1) where PLM is the probability of the word wi given the words w1 to wi−1 for the language model LM . LM is estimated from the specified in-domain corpus. The formula is applied to all sentences in the training data for the NMT system, and is then interpreted as the sentence weight. XenC is not a neural system. It applies statistical computation of cross-entropy given an LM . The language model is a 4-gram model and Kneser-Ney smoothing is applied Ney et al. (1994). This approach is widely used throughout various pap"
2021.mtsummit-research.15,D13-1170,0,0.0619426,"= w · (z ◦ r) + b (5) m with ◦ being element-wise multiplication and r ∈ R a “masking” vector of bernoulli distributed random variables with probability p of being 1. Furthermore a threshold s for l2 −norms in introduced, rescaling w to ||w||2 = s if ||w||2 > s after a gradient descent step. 2.3 RNTN Classifier CNNs work on word vectors and filters, which aggregate local information within a sentence. This is less expressive than richer forms of sentence representation, e.g., parse trees, which take into account the grammatical structure. To deal with parse trees for sentiment classification (Socher et al., 2013) introduced a recursive deep model, the Recursive Neural Tensor Network (RNTN). The representations of sentences within recursive neural models apply to variable length and syntactic type and is used for classification. First, each sentence is parsed into a binary tree with leaf nodes being single words, represented by a vector. Then the parent vectors will be computed in a bottom-up fashion using compositionality functions g. The parent vectors themselves are recursively given as features to a classifier and their parents respectively. Proceedings of the 18th Biennial Machine Translation Summ"
2021.mtsummit-research.15,P03-1010,0,0.122815,"Missing"
2021.mtsummit-research.15,P17-2089,0,0.0373017,"Missing"
2021.mtsummit-research.15,C18-1269,0,0.0521397,"Missing"
2021.mtsummit-research.15,D17-1155,0,0.0485579,"Missing"
2021.mtsummit-research.15,D14-1023,0,0.0477352,"Missing"
C12-3061,J99-4005,0,\N,Missing
C12-3061,N10-1140,0,\N,Missing
C12-3061,D09-1022,1,\N,Missing
C12-3061,C04-1030,1,\N,Missing
C12-3061,W10-1738,1,\N,Missing
C12-3061,D08-1024,0,\N,Missing
C12-3061,P12-3004,0,\N,Missing
C12-3061,N09-1027,0,\N,Missing
C12-3061,P10-1049,1,\N,Missing
C12-3061,P07-2045,0,\N,Missing
C12-3061,N09-1025,0,\N,Missing
C12-3061,J06-4004,0,\N,Missing
C12-3061,N03-1017,0,\N,Missing
C12-3061,P02-1038,1,\N,Missing
C12-3061,2008.iwslt-papers.8,1,\N,Missing
C12-3061,P10-4002,0,\N,Missing
C12-3061,2008.iwslt-papers.7,1,\N,Missing
C12-3061,P07-1019,0,\N,Missing
C12-3061,P12-2006,1,\N,Missing
C12-3061,W06-3119,0,\N,Missing
C12-3061,2010.iwslt-papers.18,1,\N,Missing
C12-3061,2011.iwslt-papers.8,1,\N,Missing
C12-3061,J07-2003,0,\N,Missing
C12-3061,N10-2003,0,\N,Missing
C12-3061,D07-1080,0,\N,Missing
C12-3061,2009.eamt-1.33,1,\N,Missing
C12-3061,P03-1021,0,\N,Missing
C12-3061,2012.eamt-1.66,1,\N,Missing
E14-2008,W11-2107,0,0.0891332,"Missing"
E14-2008,D08-1011,0,0.0544777,"S*:*EPS*/-0.7 2 the:the/-0.6 comprising:comprising/-0.1 3 *EPS*:*EPS*/-0.9 an:an/-0.1 4 isolated:isolated/-0.8 *EPS*:*EPS*/-0.2 5 cdna:cdna/-1 6 *EPS*:*EPS*/-0.4 library:library/-0.6 7 Figure 1: Scored confusion network. *EPS* denotes the empty word, red arcs highlight the shortest path. ing and an additional language model. Matusov et al. (2006) proposed an alignment based on the GIZA++ toolkit which introduced word reordering not present in MSA, and Sim et al. (2007) used alignments produced by T ER scoring (Snover et al., 2006). Extensions of the last two are based on hidden Markov models (He et al., 2008), inversion transduction grammars (Karakos et al., 2008), or METEOR (Heafield and Lavie, 2010). 3 and Lavie, 2011) was originally designed to reorder a translation for scoring and has a high precision. The recall is lower because synonyms which are not in the METEOR database or punctuation marks like “!” and “?” are not aligned to each other. For our purposes, we augment the METEOR paraphrase table with entries like “.|!”, “.|?”, or “the|a”. Figure 2 shows an example METEOR hypothesis alignment. The primary hypothesis “isolated cdna lib” determines the word order. An entry “a|b” means that wor"
E14-2008,P08-2021,0,0.0487936,"-0.1 3 *EPS*:*EPS*/-0.9 an:an/-0.1 4 isolated:isolated/-0.8 *EPS*:*EPS*/-0.2 5 cdna:cdna/-1 6 *EPS*:*EPS*/-0.4 library:library/-0.6 7 Figure 1: Scored confusion network. *EPS* denotes the empty word, red arcs highlight the shortest path. ing and an additional language model. Matusov et al. (2006) proposed an alignment based on the GIZA++ toolkit which introduced word reordering not present in MSA, and Sim et al. (2007) used alignments produced by T ER scoring (Snover et al., 2006). Extensions of the last two are based on hidden Markov models (He et al., 2008), inversion transduction grammars (Karakos et al., 2008), or METEOR (Heafield and Lavie, 2010). 3 and Lavie, 2011) was originally designed to reorder a translation for scoring and has a high precision. The recall is lower because synonyms which are not in the METEOR database or punctuation marks like “!” and “?” are not aligned to each other. For our purposes, we augment the METEOR paraphrase table with entries like “.|!”, “.|?”, or “the|a”. Figure 2 shows an example METEOR hypothesis alignment. The primary hypothesis “isolated cdna lib” determines the word order. An entry “a|b” means that word “a” from a secondary hypothesis has been aligned to wo"
E14-2008,E06-1005,1,0.845972,"f the European Chapter of the Association for Computational Linguistics, pages 29–32, c Gothenburg, Sweden, April 26-30 2014. 2014 Association for Computational Linguistics *EPS*:*EPS*/-0.3 contain:contain/-0.2 will:will/-0.3 *EPS*:*EPS*/-0.7 0 1 comprise:comprise/-0.1 *EPS*:*EPS*/-0.7 2 the:the/-0.6 comprising:comprising/-0.1 3 *EPS*:*EPS*/-0.9 an:an/-0.1 4 isolated:isolated/-0.8 *EPS*:*EPS*/-0.2 5 cdna:cdna/-1 6 *EPS*:*EPS*/-0.4 library:library/-0.6 7 Figure 1: Scored confusion network. *EPS* denotes the empty word, red arcs highlight the shortest path. ing and an additional language model. Matusov et al. (2006) proposed an alignment based on the GIZA++ toolkit which introduced word reordering not present in MSA, and Sim et al. (2007) used alignments produced by T ER scoring (Snover et al., 2006). Extensions of the last two are based on hidden Markov models (He et al., 2008), inversion transduction grammars (Karakos et al., 2008), or METEOR (Heafield and Lavie, 2010). 3 and Lavie, 2011) was originally designed to reorder a translation for scoring and has a high precision. The recall is lower because synonyms which are not in the METEOR database or punctuation marks like “!” and “?” are not aligned to"
E14-2008,P03-1021,0,0.134095,"with the sentence from the primary system. During the generation of the confusion network we align the hypotheses consecutively into the confusion network via the following procedure: 4 Experimental Results All experiments are conducted on the latest official WMT system combination shared task.4 We exclusively employ resources which were permitted for the constrained track of the task in all our setups. The big LM was trained on News Commentary and Europarl data. As tuning set we used newssyscombtune2011, as test set we used newssyscombtest2011. Feature weights have been optimized with MERT (Och, 2003). Table 1 contains the empirical results (truecase). For all four language pairs we achieve improvements over the best 2011 evaluation system combination submission either in B LEU or T ER. We get the highest improvement of 0.7 points in B LEU for es→en when adding both the big LM and IBM-1 features. Adding the big LM over the baseline enhances the translation quality for all four language pairs. Adding IBM-1 lexicon models on top of the big LM is of marginal or no benefit for most language • If a word wi from hypothesis A has a relation to a word v j of the primary hypothesis, we insert it as"
E14-2008,J93-2003,0,0.0349938,"Missing"
E14-2008,2006.amta-papers.25,0,0.0233343,"contain:contain/-0.2 will:will/-0.3 *EPS*:*EPS*/-0.7 0 1 comprise:comprise/-0.1 *EPS*:*EPS*/-0.7 2 the:the/-0.6 comprising:comprising/-0.1 3 *EPS*:*EPS*/-0.9 an:an/-0.1 4 isolated:isolated/-0.8 *EPS*:*EPS*/-0.2 5 cdna:cdna/-1 6 *EPS*:*EPS*/-0.4 library:library/-0.6 7 Figure 1: Scored confusion network. *EPS* denotes the empty word, red arcs highlight the shortest path. ing and an additional language model. Matusov et al. (2006) proposed an alignment based on the GIZA++ toolkit which introduced word reordering not present in MSA, and Sim et al. (2007) used alignments produced by T ER scoring (Snover et al., 2006). Extensions of the last two are based on hidden Markov models (He et al., 2008), inversion transduction grammars (Karakos et al., 2008), or METEOR (Heafield and Lavie, 2010). 3 and Lavie, 2011) was originally designed to reorder a translation for scoring and has a high precision. The recall is lower because synonyms which are not in the METEOR database or punctuation marks like “!” and “?” are not aligned to each other. For our purposes, we augment the METEOR paraphrase table with entries like “.|!”, “.|?”, or “the|a”. Figure 2 shows an example METEOR hypothesis alignment. The primary hypothe"
E14-2008,2013.iwslt-evaluation.16,1,\N,Missing
E14-2008,W13-2223,1,\N,Missing
E14-2008,D08-1076,0,\N,Missing
E17-2059,N12-1047,0,0.0199491,"ne. We choose English→Czech as a task that is representative for machine translation from a morphologically underspecified language into a morphologically rich language. 5.1 11.8 12.7 50K pre-pruned by applying a minimum score threshold of 0.0001 on the source-to-target phrase translation probability, and the decoder loads a maximum of 100 best translation options per distinct source side. We use cube pruning in decoding. Pop limit and stack limit for cube pruning are set to 1000 for tuning and to 5000 for testing. The distortion limit is 6. Weights are tuned on newstest2013 with k-best MIRA (Cherry and Foster, 2012) over 200-best lists for 25 iterations. Translation quality is measured in B LEU (Papineni et al., 2002) on three different test sets, newstest2014, newstest2015, and newstest2016.3 Our training data amounts to around 50 million bilingual sentences overall, but we conduct sets of experiments with systems trained using different fractions of this data (50K, 500K, 5M, 50M). Whereas English→Czech has good coverage in terms of training corpora, we simulate lowand medium-resource conditions for the purpose of drawing more general conclusions. Irrespective of this, we utilize the same large LMs in a"
E17-2059,N13-1001,1,0.853824,"s using 5M training sentence pairs. Table 6: English→Czech experimental results using 50M training sentence pairs. In our baseline systems, we already draw on lemmas and morphosyntactic tags as factors on the target side, in addition to word surface forms.1 The additional target-side factors allow us to integrate features that independently model word sense (in terms of the lemma) and morphological attributes (in terms of the morphosyntactic tag). All our translation engines (cf. Section 5) incorporate ngram LMs over lemmas and over morphosyntactic tags, and an operation sequence model (OSM) (Durrani et al., 2013) with lemmas on the target side. These models counteract sparsity, and where models over surface forms fail for unseen variants, they still assign scores which are based on reliable probability estimates. When enhancing a system with synthesized phrase table entries, we add further features. Since the usual phrase translation and lexical translation log-probabilities over surface forms cannot be estimated for unseen morphological variants, but all new variants are generated from existing lemmas, we utilize the corresponding log-probabilities over target lemmas. Those can be extracted from the"
E17-2059,W10-1705,1,0.905261,"low-resource conditions, but the problem persists even with larger amounts of parallel training data. When translating into the morphologically rich language, the system fails at producing the unseen morphological variants, leading to major translation errors. Consider the Czech example in Table 1. A small parallel corpus of 50K English-Czech sentences contains only a single variant of the morphological 2 Related Work Translation into morphologically rich languages is often tackled through “two-step”, i.e., separate modules for morphological prediction and generation (Toutanova et al., 2008; Bojar and Kos, 2010; 369 Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, pages 369–375, c Valencia, Spain, April 3-7, 2017. 2017 Association for Computational Linguistics Fraser et al., 2012; Burlot et al., 2016). An important problem is that lexical choice (of the lemma) is carried out in a separate step from morphological prediction. Factored machine translation with separate translation and generation models represents a different approach, operating with a singlestep search. However, too many options in decoding cause a blow"
E17-2059,N13-1073,0,0.0371886,"t no separate generation model). The target factors are the word surface form, lemma, and a morphosyntactic tag. We use the Czech positional tagset (Hajiˇc and Hladká, 1998) which fully describes the word’s morphological attributes. On the source side we use only surface forms, except for the discriminative classifier, which includes the features as shown in Table 2. We employ corpora that have been provided for the English→Czech News translation shared task at WMT16 (Bojar et al., 2016b), including the CzEng parallel corpus (Bojar et al., 2016a). Word alignments are created using fast_align (Dyer et al., 2013) and symmetrized. We extract phrases up to a maximum length of 7. The phrase table is 3 We evaluate case-sensitive with mteval-v13a.pl -c, comparing post-processed hypotheses against the raw reference. 372 input: now , six in 10 Republicans have a favorable view of Donald Trump . baseline: ted’ , šest v 10 republikáni mají pˇríznivý výhled Donald Trump . now, six inlocation 10 Republicansnom have a_favorable outlook Donaldnom Trumpnom . + synthetic (mtu) + morph-vw: ted’ , šest do deseti republikán˚u má pˇríznivý názor na Donalda Trumpa . now, six into tengen Republicansgen have a_favorable op"
E17-2059,W11-2138,1,0.887605,"et al., 2012; Burlot et al., 2016). An important problem is that lexical choice (of the lemma) is carried out in a separate step from morphological prediction. Factored machine translation with separate translation and generation models represents a different approach, operating with a singlestep search. However, too many options in decoding cause a blow-up of the search space; and useful information is dropped when modeling source_word→target_lemma and target_lemma→target_word separately. Word forms not seen in parallel data are sometimes still available in monolingual data. Backtranslation (Bojar and Tamchyna, 2011) takes advantage of this. The monolingual target language data is lemmatized, automatically translated to the source language, and the translations are aligned with the original, inflected target corpus to produce supplementary training data. Disadvantages are both the computational expense and that the back-translated text may contain errors. Previous work on synthetic phrases by Chahuneau et al. (2013) is most similar to our work. They commit to generation of a single candidate inflection of a lemma prior to decoding, chosen only based on a hierarchical rule and source-side information, a si"
E17-2059,E12-1068,1,0.915146,"rors. Consider the Czech example in Table 1. A small parallel corpus of 50K English-Czech sentences contains only a single variant of the morphological 2 Related Work Translation into morphologically rich languages is often tackled through “two-step”, i.e., separate modules for morphological prediction and generation (Toutanova et al., 2008; Bojar and Kos, 2010; 369 Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, pages 369–375, c Valencia, Spain, April 3-7, 2017. 2017 Association for Computational Linguistics Fraser et al., 2012; Burlot et al., 2016). An important problem is that lexical choice (of the lemma) is carried out in a separate step from morphological prediction. Factored machine translation with separate translation and generation models represents a different approach, operating with a singlestep search. However, too many options in decoding cause a blow-up of the search space; and useful information is dropped when modeling source_word→target_lemma and target_lemma→target_word separately. Word forms not seen in parallel data are sometimes still available in monolingual data. Backtranslation (Bojar and Ta"
E17-2059,P98-1080,0,0.622887,"Missing"
E17-2059,D07-1091,0,0.389039,"morphological forms that are not known as translations of the source side of the phrase, we add these morphological variants as new translation options. We consider two settings: Scoring Unseen Morphological Variants Assigning dependable model scores to synthesized morphological forms is a primary challenge. During decoding, the artificially added phrase table entries compete with baseline phrases that had been directly extracted from the parallel training data. The correct choice has to be determined in search based on model scores. A phrase-based model with linguistically motivated factors (Koehn and Hoang, 2007) enables us to achieve better generalization capabilities when translating into a morphologically rich language. 370 newstest 2014 B LEU 2015 B LEU 2016 B LEU 12.4 12.2 10.8 10.6 11.8 11.8 + synthetic (word) + morph-vw-50K 13.4 13.4 11.3 11.4 12.5 12.7 + synthetic (word?) + morph-vw-50K 13.3 13.3 11.3 11.3 + synthetic (mtu) + morph-vw-50K 13.5 13.4 + synthetic (mtu?) + morph-vw-50K 13.4 13.5 system baseline 50K + morph-vw-50K 2015 B LEU 2016 B LEU 17.7 17.6 14.4 14.4 16.1 16.5 + synthetic (word) + morph-vw-500K 18.1 18.4 14.7 15.2 16.4 17.3 12.5 12.7 + synthetic (word?) + morph-vw-500K 18.0 18"
E17-2059,N03-1017,0,0.0265226,"emmas. We design techniques for generating and scoring unseen morphological variants fully integrated into phrase-based search, with the decoder being able to choose freely amongst all possible morphological variants. Empirically, we observe considerable gains in translation quality especially under medium- to low-resource conditions. Introduction Morphologically rich languages exhibit a large amount of inflected word surface forms for most lemmas, which poses difficulties to current statistical machine translation (SMT) technology. SMT systems, such as phrase-based translation (PBT) engines (Koehn et al., 2003), are trained on parallel corpora and can learn the vocabulary that is observed in the data. After training, the decoder can output words which have been seen on the target side of the corpus, but no unseen words. Sparsity of morphological variants leads to many linguistically valid morphological word forms remaining unseen in practical scenarios. This is a substantial issue under low-resource conditions, but the problem persists even with larger amounts of parallel training data. When translating into the morphologically rich language, the system fails at producing the unseen morphological va"
E17-2059,P07-2045,1,0.0312554,"f a known word, these two independent components should still be able to assign meaningful scores to the translation. Note that the features require lemmatization and tagging on both sides and a dependency parse of the source side. 5 16.1 17.3 500K 18.9 19.0 5M 20.5 20.8 50M 0 5 10 15 20 B LEU Figure 1: Visualization of the English→Czech translation quality on newstest2016, showing the benefit of our approach under different training resource conditions (50K/500K/5M/50M). Empirical Evaluation For an empirical evaluation of our technique, we build baseline phrase-based SMT engines using Moses (Koehn et al., 2007). We then enrich these baselines with linguistically motivated morphological variants that are unseen in the parallel training data, and we augment the model with the discriminative classifier to guide morphological selection during decoding. Different flavors of synthetic morphological variants are compared, each either combined with the discriminative classifier or standalone. We choose English→Czech as a task that is representative for machine translation from a morphologically underspecified language into a morphologically rich language. 5.1 11.8 12.7 50K pre-pruned by applying a minimum s"
E17-2059,P02-1040,0,0.101706,"y underspecified language into a morphologically rich language. 5.1 11.8 12.7 50K pre-pruned by applying a minimum score threshold of 0.0001 on the source-to-target phrase translation probability, and the decoder loads a maximum of 100 best translation options per distinct source side. We use cube pruning in decoding. Pop limit and stack limit for cube pruning are set to 1000 for tuning and to 5000 for testing. The distortion limit is 6. Weights are tuned on newstest2013 with k-best MIRA (Cherry and Foster, 2012) over 200-best lists for 25 iterations. Translation quality is measured in B LEU (Papineni et al., 2002) on three different test sets, newstest2014, newstest2015, and newstest2016.3 Our training data amounts to around 50 million bilingual sentences overall, but we conduct sets of experiments with systems trained using different fractions of this data (50K, 500K, 5M, 50M). Whereas English→Czech has good coverage in terms of training corpora, we simulate lowand medium-resource conditions for the purpose of drawing more general conclusions. Irrespective of this, we utilize the same large LMs in all setups, assuming that proper amounts of target language monolingual data can often be gathered, even"
E17-2059,P14-5003,0,0.110248,"Missing"
E17-2059,P16-1161,1,0.749918,"entries. For baseline phrase table entries, we retain their four baseline phrase translation and lexical translation features, meaning that features over target lemmas score synthesized entries and features over surface forms score baseline entries. The features have separate weights in the model combination. Furthermore, a binary indicator distinguishes baseline phrases from synthesized phrases. The final key to our approach is using a discriminative classifier (morph-vw, Vowpal Wabbit2 for Morphology) which can take context from both the source side and the target side into account, as in (Tamchyna et al., 2016). We design feature templates for the classifier that generalize to unseen morphological variants, as listed in Table 2. “Indicator” features are concatenations of words inside 1 But note that our factored systems operate without a division into separate translation and generation models. 2 371 https://hunch.net/~vw/ baseline + synthetic (mtu) + morph-vw the phrase, “internal” features represent each word in the phrase separately. Context features on the source side capture a fixed-sized window around the phrase. Target-side context is only to the left of the current phrase. The feature set is"
E17-2059,P08-1059,0,0.170483,"substantial issue under low-resource conditions, but the problem persists even with larger amounts of parallel training data. When translating into the morphologically rich language, the system fails at producing the unseen morphological variants, leading to major translation errors. Consider the Czech example in Table 1. A small parallel corpus of 50K English-Czech sentences contains only a single variant of the morphological 2 Related Work Translation into morphologically rich languages is often tackled through “two-step”, i.e., separate modules for morphological prediction and generation (Toutanova et al., 2008; Bojar and Kos, 2010; 369 Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, pages 369–375, c Valencia, Spain, April 3-7, 2017. 2017 Association for Computational Linguistics Fraser et al., 2012; Burlot et al., 2016). An important problem is that lexical choice (of the lemma) is carried out in a separate step from morphological prediction. Factored machine translation with separate translation and generation models represents a different approach, operating with a singlestep search. However, too many options in"
L16-1003,W09-1904,0,0.0383851,"in the highest possible general performance system (Huck et al., 2015). As expected, however, it is outperformed by using the domain-specific test set. System EN-EL EN-PT EN-IT TraMOOC Test 28.0 28.5 27.9 29.1 32.6 33.0 Table 2: BLEU scores for the initial translation prototypes 5. Size (million words) 2.7 1.5 4.8 2.4 1.3 1.5 1.4 0.2 1.7 2.3 8.7 Crowdsourcing Crowdsourcing has been employed extensively for the implementation of human intelligence natural language processing (NLP) tasks in recent years (Callison, 2009; Zaidan & Burch, 2011; Zbib et al., 2012; Ambati, 2012; Finin et al., 2010; Hsueh et al., 2009). TraMOOC involves crowdsourcing for realizing sub-goals that require human intervention in order to meet its high-quality output standards against upcoming challenges, including the large number of targeted languages, the fragmentary or weak SMT infrastructure support for the majority of the languages, and the multiple domains and text genres involved. The CrowdFlower 14 platform was chosen for the implementation of the crowdsourcing activities because of (a) its configurability, (b) its robust infrastructure, (c) its densely populated crowd channels and the evaluation and ranking process the"
L16-1003,2015.mtsummit-papers.19,1,0.892142,"i et al., 2013), binary features indicating absolute occurrence count classes of phrase pairs, sparse phrase length features, and sparse lexical features for the top-200 words. The models were optimised to maximise BLEU (Papineni et al., 2002) with batch MIRA (Cherry & Foster, 2012) on 1000-best lists. In Table 1 we compare the BLEU score performance of the systems on the TraMOOC test sets, when tuned on a mixed domain tuning set, or with the TraMOOC tuning set. The mixed tuning set includes tuning sets from TED, Europarl, and News to result in the highest possible general performance system (Huck et al., 2015). As expected, however, it is outperformed by using the domain-specific test set. System EN-EL EN-PT EN-IT TraMOOC Test 28.0 28.5 27.9 29.1 32.6 33.0 Table 2: BLEU scores for the initial translation prototypes 5. Size (million words) 2.7 1.5 4.8 2.4 1.3 1.5 1.4 0.2 1.7 2.3 8.7 Crowdsourcing Crowdsourcing has been employed extensively for the implementation of human intelligence natural language processing (NLP) tasks in recent years (Callison, 2009; Zaidan & Burch, 2011; Zbib et al., 2012; Ambati, 2012; Finin et al., 2010; Hsueh et al., 2009). TraMOOC involves crowdsourcing for realizing sub-g"
L16-1003,2005.mtsummit-papers.11,0,0.0298517,"onsist of (a) translation experts, (b) an internal group of workers with a known background in linguistics and/or translation, and (c) a group of external Table 1: Size of parallel data for all language pairs 4. Tuned Mixed Tuned TraMOOC Dev Tuned Mixed Tuned TraMOOC Dev Tuned Mixed Tuned TraMOOC Dev TraMOOC Dev 25.5 27.9 34.1 36.5 34.1 35.9 Initial Translation Results For the initial TraMOOC prototypes we focused on three language pairs: EN-IT, EN-PT and EN-EL. Phrase-based models were trained on a large amount of parallel and monolingual data, including TED (Cettolo et al., 2012), Europarl (Koehn, 2005), JRC-Acquis (Steinberger et al., 2006), various OPUS corpora (Tiedemann, 2012), WMT News Commentary and Common Crawl 12, and SETimes 10 https://www.translectures.eu/web/project-summary/ http://videolectures.net/ 12 http://www.statmt.org/wmt15/translation-task.html 11 13 14 18 http://dumps.wikimedia.org (April 2015) www.crowdflower.com contributors from the platform's crowd channels. For the latter crowd category, apart from the standard channel evaluation processes applied by the platform to isolate spammers and contributors with poor language skills, further quality assurance measures are ta"
L16-1003,P02-1040,0,0.0956189,"EN-CR EN-PL EN-IT EN-ZH (Tyers and Alperen, 2010). These were supplemented with monolingual Wikipedia corpora13 for all three target languages. The phrase-based models include many features which make them strong baselines. These models include standard features plus a hierarchical lexicalised reordering model (Galley & Manning, 2008), a 5-gram operation sequence model (Durrani et al., 2013), binary features indicating absolute occurrence count classes of phrase pairs, sparse phrase length features, and sparse lexical features for the top-200 words. The models were optimised to maximise BLEU (Papineni et al., 2002) with batch MIRA (Cherry & Foster, 2012) on 1000-best lists. In Table 1 we compare the BLEU score performance of the systems on the TraMOOC test sets, when tuned on a mixed domain tuning set, or with the TraMOOC tuning set. The mixed tuning set includes tuning sets from TED, Europarl, and News to result in the highest possible general performance system (Huck et al., 2015). As expected, however, it is outperformed by using the domain-specific test set. System EN-EL EN-PT EN-IT TraMOOC Test 28.0 28.5 27.9 29.1 32.6 33.0 Table 2: BLEU scores for the initial translation prototypes 5. Size (millio"
L16-1003,P11-1138,0,0.0602764,"Missing"
L16-1003,steinberger-etal-2006-jrc,0,0.0272335,"experts, (b) an internal group of workers with a known background in linguistics and/or translation, and (c) a group of external Table 1: Size of parallel data for all language pairs 4. Tuned Mixed Tuned TraMOOC Dev Tuned Mixed Tuned TraMOOC Dev Tuned Mixed Tuned TraMOOC Dev TraMOOC Dev 25.5 27.9 34.1 36.5 34.1 35.9 Initial Translation Results For the initial TraMOOC prototypes we focused on three language pairs: EN-IT, EN-PT and EN-EL. Phrase-based models were trained on a large amount of parallel and monolingual data, including TED (Cettolo et al., 2012), Europarl (Koehn, 2005), JRC-Acquis (Steinberger et al., 2006), various OPUS corpora (Tiedemann, 2012), WMT News Commentary and Common Crawl 12, and SETimes 10 https://www.translectures.eu/web/project-summary/ http://videolectures.net/ 12 http://www.statmt.org/wmt15/translation-task.html 11 13 14 18 http://dumps.wikimedia.org (April 2015) www.crowdflower.com contributors from the platform's crowd channels. For the latter crowd category, apart from the standard channel evaluation processes applied by the platform to isolate spammers and contributors with poor language skills, further quality assurance measures are taken like  access control using quiz da"
L16-1003,tiedemann-2012-parallel,0,0.0663706,"known background in linguistics and/or translation, and (c) a group of external Table 1: Size of parallel data for all language pairs 4. Tuned Mixed Tuned TraMOOC Dev Tuned Mixed Tuned TraMOOC Dev Tuned Mixed Tuned TraMOOC Dev TraMOOC Dev 25.5 27.9 34.1 36.5 34.1 35.9 Initial Translation Results For the initial TraMOOC prototypes we focused on three language pairs: EN-IT, EN-PT and EN-EL. Phrase-based models were trained on a large amount of parallel and monolingual data, including TED (Cettolo et al., 2012), Europarl (Koehn, 2005), JRC-Acquis (Steinberger et al., 2006), various OPUS corpora (Tiedemann, 2012), WMT News Commentary and Common Crawl 12, and SETimes 10 https://www.translectures.eu/web/project-summary/ http://videolectures.net/ 12 http://www.statmt.org/wmt15/translation-task.html 11 13 14 18 http://dumps.wikimedia.org (April 2015) www.crowdflower.com contributors from the platform's crowd channels. For the latter crowd category, apart from the standard channel evaluation processes applied by the platform to isolate spammers and contributors with poor language skills, further quality assurance measures are taken like  access control using quiz data that are far from straightforward to"
L16-1003,abdelali-etal-2014-amara,0,0.284209,"Missing"
L16-1003,D09-1030,0,0.252764,"Missing"
L16-1003,2012.eamt-1.60,0,0.0756545,"king field. The targeted crowds consist of (a) translation experts, (b) an internal group of workers with a known background in linguistics and/or translation, and (c) a group of external Table 1: Size of parallel data for all language pairs 4. Tuned Mixed Tuned TraMOOC Dev Tuned Mixed Tuned TraMOOC Dev Tuned Mixed Tuned TraMOOC Dev TraMOOC Dev 25.5 27.9 34.1 36.5 34.1 35.9 Initial Translation Results For the initial TraMOOC prototypes we focused on three language pairs: EN-IT, EN-PT and EN-EL. Phrase-based models were trained on a large amount of parallel and monolingual data, including TED (Cettolo et al., 2012), Europarl (Koehn, 2005), JRC-Acquis (Steinberger et al., 2006), various OPUS corpora (Tiedemann, 2012), WMT News Commentary and Common Crawl 12, and SETimes 10 https://www.translectures.eu/web/project-summary/ http://videolectures.net/ 12 http://www.statmt.org/wmt15/translation-task.html 11 13 14 18 http://dumps.wikimedia.org (April 2015) www.crowdflower.com contributors from the platform's crowd channels. For the latter crowd category, apart from the standard channel evaluation processes applied by the platform to isolate spammers and contributors with poor language skills, further quality a"
L16-1003,N12-1047,0,0.0685374,"Missing"
L16-1003,N13-1001,0,0.0129109,"TraMOOC’s industrial partner, Iversity, are also included since student forums will also be automatically translated for the purposes of implicit translation evaluation. Language pair EN-DE EN-BG EN-PT EN-EL EN-NL EN-CZ EN-RU EN-CR EN-PL EN-IT EN-ZH (Tyers and Alperen, 2010). These were supplemented with monolingual Wikipedia corpora13 for all three target languages. The phrase-based models include many features which make them strong baselines. These models include standard features plus a hierarchical lexicalised reordering model (Galley & Manning, 2008), a 5-gram operation sequence model (Durrani et al., 2013), binary features indicating absolute occurrence count classes of phrase pairs, sparse phrase length features, and sparse lexical features for the top-200 words. The models were optimised to maximise BLEU (Papineni et al., 2002) with batch MIRA (Cherry & Foster, 2012) on 1000-best lists. In Table 1 we compare the BLEU score performance of the systems on the TraMOOC test sets, when tuned on a mixed domain tuning set, or with the TraMOOC tuning set. The mixed tuning set includes tuning sets from TED, Europarl, and News to result in the highest possible general performance system (Huck et al., 20"
L16-1003,W10-0713,0,0.0292656,", and News to result in the highest possible general performance system (Huck et al., 2015). As expected, however, it is outperformed by using the domain-specific test set. System EN-EL EN-PT EN-IT TraMOOC Test 28.0 28.5 27.9 29.1 32.6 33.0 Table 2: BLEU scores for the initial translation prototypes 5. Size (million words) 2.7 1.5 4.8 2.4 1.3 1.5 1.4 0.2 1.7 2.3 8.7 Crowdsourcing Crowdsourcing has been employed extensively for the implementation of human intelligence natural language processing (NLP) tasks in recent years (Callison, 2009; Zaidan & Burch, 2011; Zbib et al., 2012; Ambati, 2012; Finin et al., 2010; Hsueh et al., 2009). TraMOOC involves crowdsourcing for realizing sub-goals that require human intervention in order to meet its high-quality output standards against upcoming challenges, including the large number of targeted languages, the fragmentary or weak SMT infrastructure support for the majority of the languages, and the multiple domains and text genres involved. The CrowdFlower 14 platform was chosen for the implementation of the crowdsourcing activities because of (a) its configurability, (b) its robust infrastructure, (c) its densely populated crowd channels and the evaluation an"
L16-1003,D08-1089,0,0.0114402,"ments, slides, and other course materials. The forum data of TraMOOC’s industrial partner, Iversity, are also included since student forums will also be automatically translated for the purposes of implicit translation evaluation. Language pair EN-DE EN-BG EN-PT EN-EL EN-NL EN-CZ EN-RU EN-CR EN-PL EN-IT EN-ZH (Tyers and Alperen, 2010). These were supplemented with monolingual Wikipedia corpora13 for all three target languages. The phrase-based models include many features which make them strong baselines. These models include standard features plus a hierarchical lexicalised reordering model (Galley & Manning, 2008), a 5-gram operation sequence model (Durrani et al., 2013), binary features indicating absolute occurrence count classes of phrase pairs, sparse phrase length features, and sparse lexical features for the top-200 words. The models were optimised to maximise BLEU (Papineni et al., 2002) with batch MIRA (Cherry & Foster, 2012) on 1000-best lists. In Table 1 we compare the BLEU score performance of the systems on the TraMOOC test sets, when tuned on a mixed domain tuning set, or with the TraMOOC tuning set. The mixed tuning set includes tuning sets from TED, Europarl, and News to result in the hi"
L16-1003,N12-1006,0,0.0606257,"Missing"
L16-1003,ambati-etal-2010-active,0,\N,Missing
N12-1035,J93-2003,0,0.021312,"corpus, we are able to estimate single-word based translation probabilities pRF (e|f ) by relative frequency (Koehn et al., 2003). With N (e, f ) denoting counts of aligned cooccurrences of target word e and source word f , we can compute pRF (e|f ) = P N (e, f ) . 0 e0 N (e , f ) (5) If an occurrence of e has multiple aligned source words, each of the alignment links contributes with a fractional count. We denote this model as relative frequency (RF) word lexicon. 2.2 IBM Model 1 The IBM model 1 lexicon (IBM-1) is the first and most basic one in a sequence of probabilistic generative models (Brown et al., 1993). For IBM-1, several simplifying assumptions are made, so that the probability of a target sentence eI1 given a source sentence f0J (with f0 = NULL) can be modeled as P r(eI1 |f1J ) = I X J Y 1 pibm1 (ei |fj ) . (6) (J + 1)I i=1 j=0 The parameters of IBM-1 are estimated iteratively by means of the Expectation-Maximization algorithm with maximum likelihood as training criterion. 3 Thresholding Methods (4) We introduce thresholding methods for insertion and deletion models which set thresholds based on the characteristics of the lexicon model that is applied. For all the following thresholding m"
N12-1035,P05-1033,0,0.084253,"the phrase. Related techniques have been employed before by Och et al. (2003) in an n-best reranking framework and by Mauser et al. (2006) and Zens (2008) in a standard phrase-based translation system. We propose novel thresholding methods in this work and study insertion and deletion features which are based on two different types of lexicon models. We give an extensive experimental evaluation of all these variants on the NIST Chinese→English translation task. 1 ts2tIns (α, β) = Iβ Jα X Y p(βi |αj ) < ταj  (1) i=1 j=1 Insertion and Deletion Models In hierarchical phrase-based translation (Chiang, 2005), we deal with rules X → hα, β,∼ i where hα, βi is a bilingual phrase pair that may contain symbols from a non-terminal set, i.e. α ∈ (N ∪ VF )+ and β ∈ (N ∪VE )+ , where VF and VE are the source and target vocabulary, respectively, and N is a non-terminal set which is shared by source and target. The left-hand side of the rule is a non-terminal symbol X ∈ N , and the ∼ relation denotes a oneto-one correspondence between the non-terminals in α and in β. Let Jα denote the number of terminal Here, [·] denotes a true or false statement: The result is 1 if the condition is true and 0 if the condit"
N12-1035,P07-1019,0,0.03227,"ven f . 4 Experimental Evaluation We present empirical results obtained with the different insertion and deletion model variants on the Chinese→English 2008 NIST task.2 4.1 4.2 Experimental Setup To set up our systems, we employ the open source statistical machine translation toolkit Jane (Vilar et al., 2010; Vilar et al., 2012), which is freely available for non-commercial use. Jane provides efficient C++ implementations for hierarchical phrase extraction, optimization of log-linear feature weights, and parsing-based decoding algorithms. In our experiments, we use the cube pruning algorithm (Huang and Chiang, 2007) to carry out the search. We work with a parallel training corpus of 3.0M Chinese-English sentence pairs (77.5M Chinese / 81.0M English running words). The counts for the RF lexicon models are computed from a symmetrized word alignment (Och and Ney, 2003), the IBM-1 models are produced with GIZA++. When extracting phrases, we apply several restrictions, in particular a maximum length of 10 on source and target side for lexical phrases, a length limit of five (including non-terminal symbols) for hierarchical phrases, and no more than two gaps per phrase. The models integrated into the baseline"
N12-1035,2011.iwslt-papers.1,1,0.88181,"Missing"
N12-1035,2012.eamt-1.66,1,0.872774,"Missing"
N12-1035,N03-1017,0,0.0474752,"Jα Y X   ts2tDel (α, β) = p(βi |αj ) < ταj (3) j=1 i=1 It considers an occurrence of a source word f a deletion iff no target word e exists within the phrase with p(e|f ) greater than or equal to τf . The target-to-source deletion model tt2sDel (·) correspondingly considers an occurrence of a target word e a deletion iff no source word f exists within the phrase with p(f |e) greater than or equal to τe : 2.1 Word Lexicon from Word-Aligned Data Given a word-aligned parallel training corpus, we are able to estimate single-word based translation probabilities pRF (e|f ) by relative frequency (Koehn et al., 2003). With N (e, f ) denoting counts of aligned cooccurrences of target word e and source word f , we can compute pRF (e|f ) = P N (e, f ) . 0 e0 N (e , f ) (5) If an occurrence of e has multiple aligned source words, each of the alignment links contributes with a fractional count. We denote this model as relative frequency (RF) word lexicon. 2.2 IBM Model 1 The IBM model 1 lexicon (IBM-1) is the first and most basic one in a sequence of probabilistic generative models (Brown et al., 1993). For IBM-1, several simplifying assumptions are made, so that the probability of a target sentence eI1 given"
N12-1035,J03-1002,1,0.00845144,"hine translation toolkit Jane (Vilar et al., 2010; Vilar et al., 2012), which is freely available for non-commercial use. Jane provides efficient C++ implementations for hierarchical phrase extraction, optimization of log-linear feature weights, and parsing-based decoding algorithms. In our experiments, we use the cube pruning algorithm (Huang and Chiang, 2007) to carry out the search. We work with a parallel training corpus of 3.0M Chinese-English sentence pairs (77.5M Chinese / 81.0M English running words). The counts for the RF lexicon models are computed from a symmetrized word alignment (Och and Ney, 2003), the IBM-1 models are produced with GIZA++. When extracting phrases, we apply several restrictions, in particular a maximum length of 10 on source and target side for lexical phrases, a length limit of five (including non-terminal symbols) for hierarchical phrases, and no more than two gaps per phrase. The models integrated into the baseline are: phrase translation probabilities and RF lexical translation probabilities on phrase level, each for both translation directions, length penalties on word and phrase level, binary features marking hierarchical phrases, glue rule, and rules with non-te"
N12-1035,P03-1021,0,0.0317562,"Missing"
N12-1035,P02-1040,0,0.0819074,"Missing"
N12-1035,2006.amta-papers.25,0,0.076777,"Missing"
N12-1035,W10-1738,1,0.850092,"r than the floor value are not thresholded. This variant may be considered as histogram ∞. We only apply it with RF lexicons. median τf is a median-based distinct value for each f , i.e. it is set to the value that separates the higher half of the entries from the lower half of the entries p(e|f ) for the given f . 4 Experimental Evaluation We present empirical results obtained with the different insertion and deletion model variants on the Chinese→English 2008 NIST task.2 4.1 4.2 Experimental Setup To set up our systems, we employ the open source statistical machine translation toolkit Jane (Vilar et al., 2010; Vilar et al., 2012), which is freely available for non-commercial use. Jane provides efficient C++ implementations for hierarchical phrase extraction, optimization of log-linear feature weights, and parsing-based decoding algorithms. In our experiments, we use the cube pruning algorithm (Huang and Chiang, 2007) to carry out the search. We work with a parallel training corpus of 3.0M Chinese-English sentence pairs (77.5M Chinese / 81.0M English running words). The counts for the RF lexicon models are computed from a symmetrized word alignment (Och and Ney, 2003), the IBM-1 models are produced"
N12-1035,2006.iwslt-evaluation.15,1,\N,Missing
N12-1035,D08-1076,0,\N,Missing
P19-1581,P18-1073,0,0.0253661,"xt. 2.1 Word Translation To translate source language words we use a combination of BWE based cosine and orthographic similarity. BWEs represent source and target language words in a joint space and can be built by training monolingual spaces and projecting them to the common space. Initially, a small seed lexicon was used as the bilingual signal to learn a linear mapping (Mikolov et al., 2013) which was further improved by applying orthogonal transformations only (Xing et al., 2015). Recently, various techniques were developed to build BWEs without any bilingual signal (Conneau et al., 2018; Artetxe et al., 2018). In the work of Conneau et al. (2018) adversarial training is employed to generate an initial seed lexicon of frequent words which is then used for orthogonal mapping. Even though BWEs in general are of good quality the translation of various words types, such as named entities and rare words, could be further improved by using orthographic similarity (Braune et al., 2018; Riley and Gildea, 2018; Artetxe et al., 2019). Similarly to (Braune et al., 2018), we combine the BWE based cosine and orthographic similarity of word pairs to get the translations of source words. We generate a dictionary"
P19-1581,P19-1019,0,0.0605015,"Missing"
P19-1581,Q17-1010,0,0.0446987,"), we combine the BWE based cosine and orthographic similarity of word pairs to get the translations of source words. We generate a dictionary of source-target word pairs by taking the top n most similar target words for each source using both similarity measures. We define orthographic similarity as one minus normalized Levenshtein distance. Since orthographic similarity of close words are higher than their cosine, we weight the former with 0.2 (we found this value to work well on a different task and did not tune it further). To build monolingual embeddings we use fastText’s skipgram model (Bojanowski et al., 2017) with dimension size 300 and minimum word frequency 3. For building unsupervised BWEs we use MUSE as the implementation of (Conneau et al., 2018). Note that we use unsupervised BWEs due to their good performance on the En-De language pair (see (Conneau et al., 2018)). But acquiring a small lexicon including frequent words is cheap for language pairs where unsupervised mapping has a lower performance than supervised mapping, and could be considered in future work. 2.2 NMT Fine-Tuning We mine target language sentences from a monolingual corpus which contains the translations of source OOVs. Sinc"
P19-1581,N18-2030,1,0.940825,"ikolov et al., 2013) which was further improved by applying orthogonal transformations only (Xing et al., 2015). Recently, various techniques were developed to build BWEs without any bilingual signal (Conneau et al., 2018; Artetxe et al., 2018). In the work of Conneau et al. (2018) adversarial training is employed to generate an initial seed lexicon of frequent words which is then used for orthogonal mapping. Even though BWEs in general are of good quality the translation of various words types, such as named entities and rare words, could be further improved by using orthographic similarity (Braune et al., 2018; Riley and Gildea, 2018; Artetxe et al., 2019). Similarly to (Braune et al., 2018), we combine the BWE based cosine and orthographic similarity of word pairs to get the translations of source words. We generate a dictionary of source-target word pairs by taking the top n most similar target words for each source using both similarity measures. We define orthographic similarity as one minus normalized Levenshtein distance. Since orthographic similarity of close words are higher than their cosine, we weight the former with 0.2 (we found this value to work well on a different task and did not tu"
P19-1581,W17-4713,0,0.0691799,"vocabulary. Given the sentences to translate we look for source language words not included in the parallel training set of our MT system (OOVs). We translate OOVs using BWE based dictionaries taking nbest candidates as opposed to previous work (e.g., (Luong et al., 2015)) where only the best translation is used during post-processing. In our experiments we take the 5−best predictions of our BWEs, and retrieve sentences containing these target-language predictions from a monolingual corpus. As was shown before, NMT systems can be quickly and effectively fine-tuned using just a few sentences (Farajian et al., 2017, 2018; Wuebker et al., 2018). Based on the 5−best translations of OOVs we mine sentences from target language monolingual data and generate a synthetic parallel corpus using back-translation (Sennrich et al., 2016a). We force the source-language translation of each OOV-translation-candidate to be the original OOV. We show that by using this synthetic data to fine-tune our system the translation of unseen words can be dramatically improved, despite the presence of wrong translations of each OOV in the synthetic data. We test our system on the translation of English medical terms to German and"
P19-1581,P16-1014,0,0.0157605,"se by definition source-side OOVs were not seen in the training parallel data together with their translations. In this work, we evaluate a simple approach for improving the translation of OOVs using bilingual word embeddings (BWEs), which we hope will trigger more research on this interesting problem. In previous approaches, to include words in the target sentence for which the translation is unknown the token unk is often used which can be handled by later steps. In many cases, such as named entities, it is possible to just copy the source token to the target side instead of translating it. Gulcehre et al. (2016) proposed a pointer network based (Vinyals et al., 2015) system which can learn when to translate and when to copy. On the other hand, it is not possible to always copy when the translation is unknown. If the alignment of the unk tokens to the source are known it is possible to translate source words using a large dictionary as a post-processing step. Although NMT systems do not rely on word alignments explicitly, it is possible to learn and output word alignments (Luong et al., 2015). It is also possible to use lexically-constrained decoders (Post and Vilar, 2018; Hasler et al., 2018) in orde"
P19-1581,P18-1075,1,0.911766,"e UFAL Medical Corpus (UFAL). Since the corpus is parallel, we split it and used even sentences for English and odd ones for German. We built BWEs not only on the monolingual medical data but on 5811 rare freq (Braune et al., 2018) EU+UFAL+orth (Braune et al., 2018) EU+UFAL+orth Acc1 38.6 25.9 26.3 17.5 Acc5 47.4 40.6 28.2 28.8 baseline copy fine-tuned Table 2: Medical bilingual lexicon induction results showing the quality of the BWE based dictionaries using 1-best and 5-best translations. the concatenation of all Europarl data and the monolingual medical data to improve the quality of BWEs (Hangya et al., 2018). We only mined sentences from the monolingual medical German corpus. The testing of our approach was done on the medical Health In My Language (HimL) corpora (Haddow et al., 2017) containing 1.9K sentence pairs in both development and test sets. All corpora were tokenized and truecased using Moses scripts (Koehn et al., 2007). We ran two sets of experiments. First we show the translation quality of our dictionaries by looking at the OOVs and their translations using HimL development data. Then we show translation quality improvements on the HimL test data. 3.1 OOV Translation The quality of o"
P19-1581,N18-2081,0,0.0756065,"Missing"
P19-1581,W17-4730,1,0.871614,"s of medical terms, and back-translate the rest to generate synthetic parallel data. We force the back-translation of each of the proposed target-language OOVtranslation-candidates to be the original sourcelanguage OOV. In our experiments we use an encoder-decoder NMT system (Sennrich et al., 2017) with attention, 500 dimensional embedding layer, 1024 dimensional GRU layer and we use Adam with a learning rate of 0.0001 to train the network. We apply word segmentation with BPE using 50K merge operations to the English text, and a linguistically informed pipeline to the target-side German text (Huck et al., 2017b). It is important to understand that OOVs for us are words, and we handle both the dictionary based OOV translation and sentence mining on the word level. BPEs are only used when using NMT to translate. We train two systems, one each for the forward and backward directions. We describe the used data in Section 3. During back-translation we force the OOV-translation-candidates to be back-translated to the original source-language OOV by changing the OOV-translation-candidate to a special token on the target side before translation and then substituting the special token in the source-language"
P19-1581,W17-4706,1,0.899393,"s of medical terms, and back-translate the rest to generate synthetic parallel data. We force the back-translation of each of the proposed target-language OOVtranslation-candidates to be the original sourcelanguage OOV. In our experiments we use an encoder-decoder NMT system (Sennrich et al., 2017) with attention, 500 dimensional embedding layer, 1024 dimensional GRU layer and we use Adam with a learning rate of 0.0001 to train the network. We apply word segmentation with BPE using 50K merge operations to the English text, and a linguistically informed pipeline to the target-side German text (Huck et al., 2017b). It is important to understand that OOVs for us are words, and we handle both the dictionary based OOV translation and sentence mining on the word level. BPEs are only used when using NMT to translate. We train two systems, one each for the forward and backward directions. We describe the used data in Section 3. During back-translation we force the OOV-translation-candidates to be back-translated to the original source-language OOV by changing the OOV-translation-candidate to a special token on the target side before translation and then substituting the special token in the source-language"
P19-1581,2005.mtsummit-papers.11,0,0.0159432,"polysemous words, because the input context (which often disambiguates a polysemous word) will usually be most similar to the target-language context of the correct OOV-translation-candidate. Furthermore, this also makes our approach robust against incorrect OOV-translation-candidates in the used dictionary, since they are often used in very different contexts compared to the context of the source OOV we are translating. 3 Experiments We translate medical English sentences to German. To train the baseline NMT system we used the Europarl v7 (EU) parallel dataset containing 1.9M sentence pairs (Koehn, 2005). As medical data, we took 3.1M sentences from titles of medical Wikipedia articles, medical termpairs, patents and documents from the European Medicines Agency which are part of the UFAL Medical Corpus (UFAL). Since the corpus is parallel, we split it and used even sentences for English and odd ones for German. We built BWEs not only on the monolingual medical data but on 5811 rare freq (Braune et al., 2018) EU+UFAL+orth (Braune et al., 2018) EU+UFAL+orth Acc1 38.6 25.9 26.3 17.5 Acc5 47.4 40.6 28.2 28.8 baseline copy fine-tuned Table 2: Medical bilingual lexicon induction results showing the"
P19-1581,P07-2045,0,0.00445595,"baseline copy fine-tuned Table 2: Medical bilingual lexicon induction results showing the quality of the BWE based dictionaries using 1-best and 5-best translations. the concatenation of all Europarl data and the monolingual medical data to improve the quality of BWEs (Hangya et al., 2018). We only mined sentences from the monolingual medical German corpus. The testing of our approach was done on the medical Health In My Language (HimL) corpora (Haddow et al., 2017) containing 1.9K sentence pairs in both development and test sets. All corpora were tokenized and truecased using Moses scripts (Koehn et al., 2007). We ran two sets of experiments. First we show the translation quality of our dictionaries by looking at the OOVs and their translations using HimL development data. Then we show translation quality improvements on the HimL test data. 3.1 OOV Translation The quality of our proposed method is highly dependent on that of the used dictionaries, since in order to mine useful sentences OOVs first needed to be translated correctly. Since we lack the gold translations of the OOVs, we measure the quality of the mined target language sentences using parallel data by following the approach presented fo"
P19-1581,N18-1119,0,0.0208947,"instead of translating it. Gulcehre et al. (2016) proposed a pointer network based (Vinyals et al., 2015) system which can learn when to translate and when to copy. On the other hand, it is not possible to always copy when the translation is unknown. If the alignment of the unk tokens to the source are known it is possible to translate source words using a large dictionary as a post-processing step. Although NMT systems do not rely on word alignments explicitly, it is possible to learn and output word alignments (Luong et al., 2015). It is also possible to use lexically-constrained decoders (Post and Vilar, 2018; Hasler et al., 2018) in order to force the network to output certain words or sequences. This way alignments are not needed and the system can decide the position of the constraints in the output. The disadvantage of the above methods is that the translation of words needed to be decided either as a pre- or post-processing step without the context which makes the translation of some words, such as polysemous words, difficult. In addition, lexically-constrained decoders require the target words to be observed in context at training time, or they will usually not be placed properly. In contras"
P19-1581,P18-2062,0,0.0552118,"which was further improved by applying orthogonal transformations only (Xing et al., 2015). Recently, various techniques were developed to build BWEs without any bilingual signal (Conneau et al., 2018; Artetxe et al., 2018). In the work of Conneau et al. (2018) adversarial training is employed to generate an initial seed lexicon of frequent words which is then used for orthogonal mapping. Even though BWEs in general are of good quality the translation of various words types, such as named entities and rare words, could be further improved by using orthographic similarity (Braune et al., 2018; Riley and Gildea, 2018; Artetxe et al., 2019). Similarly to (Braune et al., 2018), we combine the BWE based cosine and orthographic similarity of word pairs to get the translations of source words. We generate a dictionary of source-target word pairs by taking the top n most similar target words for each source using both similarity measures. We define orthographic similarity as one minus normalized Levenshtein distance. Since orthographic similarity of close words are higher than their cosine, we weight the former with 0.2 (we found this value to work well on a different task and did not tune it further). To build"
P19-1581,E17-3017,0,0.0195946,"-letter characters as more than one third of their characters. In addition, we also filter out translations that are stopwords. We then use the set of target language words to mine all sentences that contain any of them from the monolingual data. We filter out sentences longer than 50 tokens, since they tend to be listings of medical terms, and back-translate the rest to generate synthetic parallel data. We force the back-translation of each of the proposed target-language OOVtranslation-candidates to be the original sourcelanguage OOV. In our experiments we use an encoder-decoder NMT system (Sennrich et al., 2017) with attention, 500 dimensional embedding layer, 1024 dimensional GRU layer and we use Adam with a learning rate of 0.0001 to train the network. We apply word segmentation with BPE using 50K merge operations to the English text, and a linguistically informed pipeline to the target-side German text (Huck et al., 2017b). It is important to understand that OOVs for us are words, and we handle both the dictionary based OOV translation and sentence mining on the word level. BPEs are only used when using NMT to translate. We train two systems, one each for the forward and backward directions. We de"
P19-1581,P16-1009,0,0.271199,"ramatically improved. In our experiments we use a system trained on Europarl and mine sentences containing medical terms from monolingual data. 1 Introduction Neural machine translation (NMT) systems achieved a breakthrough in translation quality recently, by learning an end-to-end system (Sutskever et al., 2014; Bahdanau et al., 2015). However, NMT systems have low quality when translating out-of-vocabulary words (OOVs), especially because they have a fixed modest sized vocabulary due to memory limitations. By splitting words into subword units the problem of representing OOVs can be solved (Sennrich et al., 2016b) but their translation is still problematic because by definition source-side OOVs were not seen in the training parallel data together with their translations. In this work, we evaluate a simple approach for improving the translation of OOVs using bilingual word embeddings (BWEs), which we hope will trigger more research on this interesting problem. In previous approaches, to include words in the target sentence for which the translation is unknown the token unk is often used which can be handled by later steps. In many cases, such as named entities, it is possible to just copy the source t"
P19-1581,P16-1162,0,0.599446,"ramatically improved. In our experiments we use a system trained on Europarl and mine sentences containing medical terms from monolingual data. 1 Introduction Neural machine translation (NMT) systems achieved a breakthrough in translation quality recently, by learning an end-to-end system (Sutskever et al., 2014; Bahdanau et al., 2015). However, NMT systems have low quality when translating out-of-vocabulary words (OOVs), especially because they have a fixed modest sized vocabulary due to memory limitations. By splitting words into subword units the problem of representing OOVs can be solved (Sennrich et al., 2016b) but their translation is still problematic because by definition source-side OOVs were not seen in the training parallel data together with their translations. In this work, we evaluate a simple approach for improving the translation of OOVs using bilingual word embeddings (BWEs), which we hope will trigger more research on this interesting problem. In previous approaches, to include words in the target sentence for which the translation is unknown the token unk is often used which can be handled by later steps. In many cases, such as named entities, it is possible to just copy the source t"
P19-1581,P18-1072,0,0.0322542,"Missing"
P19-1581,D18-1104,0,0.150908,"ces to translate we look for source language words not included in the parallel training set of our MT system (OOVs). We translate OOVs using BWE based dictionaries taking nbest candidates as opposed to previous work (e.g., (Luong et al., 2015)) where only the best translation is used during post-processing. In our experiments we take the 5−best predictions of our BWEs, and retrieve sentences containing these target-language predictions from a monolingual corpus. As was shown before, NMT systems can be quickly and effectively fine-tuned using just a few sentences (Farajian et al., 2017, 2018; Wuebker et al., 2018). Based on the 5−best translations of OOVs we mine sentences from target language monolingual data and generate a synthetic parallel corpus using back-translation (Sennrich et al., 2016a). We force the source-language translation of each OOV-translation-candidate to be the original OOV. We show that by using this synthetic data to fine-tune our system the translation of unseen words can be dramatically improved, despite the presence of wrong translations of each OOV in the synthetic data. We test our system on the translation of English medical terms to German and show significant improvements"
P19-1581,N15-1104,0,0.0309723,"rrect, we show in our experiments that the NMT system can effectively filter out the noise in the synthetic corpus using the context. 2.1 Word Translation To translate source language words we use a combination of BWE based cosine and orthographic similarity. BWEs represent source and target language words in a joint space and can be built by training monolingual spaces and projecting them to the common space. Initially, a small seed lexicon was used as the bilingual signal to learn a linear mapping (Mikolov et al., 2013) which was further improved by applying orthogonal transformations only (Xing et al., 2015). Recently, various techniques were developed to build BWEs without any bilingual signal (Conneau et al., 2018; Artetxe et al., 2018). In the work of Conneau et al. (2018) adversarial training is employed to generate an initial seed lexicon of frequent words which is then used for orthogonal mapping. Even though BWEs in general are of good quality the translation of various words types, such as named entities and rare words, could be further improved by using orthographic similarity (Braune et al., 2018; Riley and Gildea, 2018; Artetxe et al., 2019). Similarly to (Braune et al., 2018), we comb"
W10-1711,E03-1076,0,0.129532,"Missing"
W10-1711,E06-1005,1,0.838332,"Association for Computational Linguistics Standard FA German→English BLEU # Phrases 19.7 128M 20.0 12M French→English BLEU # Phrases 25.5 225M 25.9 35M English→French BLEU # Phrases 23.7 261M 24.0 33M Table 1: BLEU scores on Test and phrase table sizes with and without forced alignment (FA). For German→English and English→French phrase table interpolation was applied. tains flexibility on the input systems. additional steps to cope with reordering between different hypotheses, and to use true casing information from the input hypotheses. The basic concept of the approach has been described by Matusov et al. (2006). Several improvements have been added later (Matusov et al., 2008). This approach includes an enhanced alignment and reordering framework. Alignments between the systems are learned by GIZA++, a one-to-one alignment is generated from the learned state occupation probabilities. From these alignments, a confusion network (CN) is then built using one of the hypotheses as “skeleton” or “primary” hypothesis. We do not make a hard decision on which of the hypotheses to use for that, but instead combine all possible CNs into a single lattice. Majority voting on the generated lattice is performed usi"
W10-1711,D09-1022,1,0.239401,"Missing"
W10-1711,popovic-ney-2006-pos,1,0.575104,"Missing"
W10-1711,2009.mtsummit-posters.17,0,0.036503,"Missing"
W10-1711,J07-2003,0,0.0508773,"etraining method and additional models were tested and investigated with respect to their effect for the different language pairs. For two of the language pairs we could improve performance by system combination. An overview of the systems and models will follow in Section 2 and 3, which describe the baseline architecture, followed by descriptions of the additional system components. Morpho-syntactic analysis and other preprocessing issues are covered by Section 4. Finally, translation results for 2.2 Hierarchical System Our hierarchical phrase-based system is similar to the one described in (Chiang, 2007). It allows for gaps in the phrases by employing a context-free grammar and a CYK-like parsing during the decoding step. It has similar features as the phrasebased system mentioned above. For some systems, we only allowed the non-terminals in hierarchical phrases to be substituted with initial phrases as in (Iglesias et al., 2009), which gave better results on some language pairs. We will refer to this as “shallow rules”. 2.3 System Combination The RWTH approach to MT system combination of the French→English systems as well as the German→English systems is a refined version of the ROVER approa"
W10-1711,P10-1049,1,0.176425,"Missing"
W10-1711,W06-3105,0,0.0459067,"Missing"
W10-1711,W06-3108,1,0.318609,"with a variant of GIZA++. Target language models are 4-gram language models trained with the SRI toolkit, using Kneser-Ney discounting with interpolation. 2.1 Phrase-Based System Our phrase-based translation system is similar to the one described in (Zens and Ney, 2008). Phrase pairs are extracted from a word-aligned bilingual corpus and their translation probability in both directions is estimated by relative frequencies. Additional models include a standard n-gram language model, phrase-level IBM1, word-, phraseand distortion-penalties and a discriminative reordering model as described in (Zens and Ney, 2006). Introduction This paper describes the statistical MT system used for our participation in the WMT 2010 shared translation task. We used it as an opportunity to incorporate novel methods which have been investigated at RWTH over the last year and which have proven to be successful in other evaluations. For all tasks we used standard alignment and training tools as well as our in-house phrasebased and hierarchical statistical MT decoders. When German was involved, morpho-syntactic preprocessing was applied. An alternative phrasetraining method and additional models were tested and investigated"
W10-1711,2008.iwslt-papers.8,1,0.0627609,"ome tasks, a system combination of the best systems was used to generate a final hypothesis. We participated in the constrained condition of GermanEnglish and French-English in each translation direction. 1 2 Translation Systems For the WMT 2010 Evaluation we used standard phrase-based and hierarchical translation systems. Alignments were trained with a variant of GIZA++. Target language models are 4-gram language models trained with the SRI toolkit, using Kneser-Ney discounting with interpolation. 2.1 Phrase-Based System Our phrase-based translation system is similar to the one described in (Zens and Ney, 2008). Phrase pairs are extracted from a word-aligned bilingual corpus and their translation probability in both directions is estimated by relative frequencies. Additional models include a standard n-gram language model, phrase-level IBM1, word-, phraseand distortion-penalties and a discriminative reordering model as described in (Zens and Ney, 2006). Introduction This paper describes the statistical MT system used for our participation in the WMT 2010 shared translation task. We used it as an opportunity to incorporate novel methods which have been investigated at RWTH over the last year and whic"
W10-1711,D08-1039,1,0.678444,"Missing"
W10-1711,W99-0604,1,\N,Missing
W10-1711,D11-1033,0,\N,Missing
W10-1711,E09-1044,0,\N,Missing
W10-1711,J93-2003,0,\N,Missing
W10-1711,N04-4015,0,\N,Missing
W10-1711,W07-0813,0,\N,Missing
W10-1711,N04-4038,0,\N,Missing
W10-1711,D08-1089,0,\N,Missing
W10-1711,P03-1054,0,\N,Missing
W10-1711,P02-1040,0,\N,Missing
W10-1711,W10-1738,1,\N,Missing
W10-1711,W06-3110,1,\N,Missing
W10-1711,J10-3008,0,\N,Missing
W10-1711,2010.iwslt-keynotes.2,0,\N,Missing
W10-1711,P10-2041,0,\N,Missing
W10-1711,N09-1027,0,\N,Missing
W10-1711,P08-2030,0,\N,Missing
W10-1711,W07-0734,0,\N,Missing
W10-1711,N06-2013,0,\N,Missing
W10-1711,N03-1017,0,\N,Missing
W10-1711,2008.iwslt-papers.7,1,\N,Missing
W10-1711,J03-1002,1,\N,Missing
W10-1711,P07-1019,0,\N,Missing
W10-1711,W06-3103,1,\N,Missing
W10-1711,P08-1066,0,\N,Missing
W10-1711,2010.iwslt-papers.15,1,\N,Missing
W10-1711,2006.iwslt-papers.1,1,\N,Missing
W10-1711,2011.iwslt-papers.1,1,\N,Missing
W10-1711,2011.iwslt-papers.7,1,\N,Missing
W10-1711,2011.iwslt-papers.8,1,\N,Missing
W10-1711,N04-1033,1,\N,Missing
W10-1711,2011.iwslt-evaluation.1,0,\N,Missing
W10-1711,W10-1747,1,\N,Missing
W10-1711,D08-1076,0,\N,Missing
W10-1711,P03-1021,0,\N,Missing
W10-1711,2011.iwslt-papers.5,1,\N,Missing
W10-1711,P08-1000,0,\N,Missing
W10-1738,N09-1025,0,0.0105103,"ly the model in search, Jane has to be run with a phrase table that contains word alignment for each phrase, too, with the exception of phrases which are composed purely of non-terminals. Jane’s phrase extraction can optionally supply this information from the training data. (Hasan et al., 2008) and (Hasan and Ney, 2009) employ similar techniques and provide some more discussion on the path-aligned variant of the model and other possible restrictions. 3.6 community. We use an in-house implementation of the method. The second one is the MIRA algorithm, first applied for machine translation in (Chiang et al., 2009). This algorithm is more adequate when the number of parameters to optimize is large. If the Numerical Recipes library (Press et al., 2002) is available, an additional general purpose optimization tool is also compiled. Using this tool a single-best optimization procedure based on the downhill simplex method (Nelder and Mead, 1965) is included. This method, however, can be considered deprecated in favour of the above mentioned methods. 3.8 If the Sun Grid Engine2 is available, all operations of Jane can be parallelized. For the extraction process, the corpus is split into chunks (the granulari"
W10-1738,J07-2003,0,0.602278,"include We also introduce a novel reordering model for the hierarchical phrase-based approach which further enhances translation performance, and analyze the effect some recent extended lexicon models have on the performance of the system. 1 Related Work • SAMT (Zollmann and Venugopal, 2006): The original version is not maintained any more and we had problems working on big corpora. A new version which requires Hadoop has just been released, however the documentation is still missing. Introduction We present a new open source toolkit for hierarchical phrase-based translation, as described in (Chiang, 2007). The hierarchical phrase model is an extension of the standard phrase model, where the phrases are allowed to have “gaps”. In this way, long-distance dependencies and reorderings can be modelled in a consistent way. As in nearly all current statistical approaches to machine translation, this model is embedded in a log-linear model combination. RWTH has been developing this tool during the last two years and it was used successfully in numerous machine translation evaluations. It is developed in C++ with special attention to clean code, extensibility and efficiency. The toolkit is available un"
W10-1738,2009.iwslt-papers.2,0,0.0337704,"provided, one would only need to implement a corresponding frontend which communicates with the translation server (which may be located on another machine). Forced Alignments Jane has also preliminary support for forced alignments between a given source and target sentence. Given a sentence in the source language and its translation in the target language, we find the best way the source sentence can be translated into the given target sentence, using the available inventory of phrases. This is needed for more advanced training approaches like the ones presented in (Blunsom et al., 2008) or (Cmejrek et al., 2009). As reported in these papers, due to the restrictions in the phrase extraction process, not all sentences in the training corpus can be aligned in this way. 3.7 Parallelized operation 3.9 Extensibility One of the goals when implementing the toolkit was to make it easy to extend it with new features. For this, an abstract class was created which we called secondary model. New models need only to derive from this class and implement the abstract methods for data reading and costs computation. This allows for an encapsulation of the computations, which can be activated and deactivated on demand."
W10-1738,N09-2005,1,0.83495,"nstrained triplets is that the first trigger f is restricted to the aligned target word e. The second trigger f 0 is allowed to move along the whole remaining source sentence. For the training of the model, we use word alignment information obtained by GIZA++ (Och and Ney, 2003). To be able to apply the model in search, Jane has to be run with a phrase table that contains word alignment for each phrase, too, with the exception of phrases which are composed purely of non-terminals. Jane’s phrase extraction can optionally supply this information from the training data. (Hasan et al., 2008) and (Hasan and Ney, 2009) employ similar techniques and provide some more discussion on the path-aligned variant of the model and other possible restrictions. 3.6 community. We use an in-house implementation of the method. The second one is the MIRA algorithm, first applied for machine translation in (Chiang et al., 2009). This algorithm is more adequate when the number of parameters to optimize is large. If the Numerical Recipes library (Press et al., 2002) is available, an additional general purpose optimization tool is also compiled. Using this tool a single-best optimization procedure based on the downhill simplex"
W10-1738,W09-0434,0,0.0264578,"Missing"
W10-1738,D08-1039,1,0.886855,"Missing"
W10-1738,P08-1024,0,0.0230148,"code in this direction is provided, one would only need to implement a corresponding frontend which communicates with the translation server (which may be located on another machine). Forced Alignments Jane has also preliminary support for forced alignments between a given source and target sentence. Given a sentence in the source language and its translation in the target language, we find the best way the source sentence can be translated into the given target sentence, using the available inventory of phrases. This is needed for more advanced training approaches like the ones presented in (Blunsom et al., 2008) or (Cmejrek et al., 2009). As reported in these papers, due to the restrictions in the phrase extraction process, not all sentences in the training corpus can be aligned in this way. 3.7 Parallelized operation 3.9 Extensibility One of the goals when implementing the toolkit was to make it easy to extend it with new features. For this, an abstract class was created which we called secondary model. New models need only to derive from this class and implement the abstract methods for data reading and costs computation. This allows for an encapsulation of the computations, which can be activated"
W10-1738,P07-1019,0,0.279989,"thods, we refer to the given literature. 3.1 Search Algorithms 3.3 The search for the best translation proceeds in two steps. First, a monolingual parsing of the input sentence is carried out using the CYK+ algorithm (Chappelier and Rajman, 1998), a generalization of the CYK algorithm which relaxes the requirement for the grammar to be in Chomsky normal form. From the CYK+ chart we extract a hypergraph representing the parsing space. In a second step the translations are generated, computing the language model scores in an integrated fashion. Both the cube pruning and cube growing algorithms (Huang and Chiang, 2007) are implemented. For the latter case, the extensions concerning the language model heuristics similar to (Vilar and Ney, 2009) have also been included. 3.2 Syntactic Features Soft syntactic features comparable to (Vilar et al., 2008) are implemented in the extraction step of the toolkit. In search, they are considered as additional feature functions of the translation rules. The decoder is able to handle an arbitrary number of non-terminal symbols. The extraction has been extended so that the extraction of SAMTrules is included (Zollmann and Venugopal, 2006) but this approach is not fully sup"
W10-1738,J93-2003,0,0.0162587,"Missing"
W10-1738,W09-0424,0,0.0228497,"stent way. As in nearly all current statistical approaches to machine translation, this model is embedded in a log-linear model combination. RWTH has been developing this tool during the last two years and it was used successfully in numerous machine translation evaluations. It is developed in C++ with special attention to clean code, extensibility and efficiency. The toolkit is available under an open source non-commercial license and downloadable from http://www.hltpr.rwth-aachen.de/jane. In this paper we give an overview of the main features of the toolkit and introduce two new ex• Joshua (Li et al., 2009): A decoder written in Java by the John Hopkins University. This project is the most similar to our own, however both were developed independently and each one has some unique features. A brief comparison between these two systems is included in Section 5.1. • Moses (Koehn et al., 2007): The de-facto standard phrase-based translation decoder has now been extended to support hierarchical translation. This is still in an experimental branch, however. 3 Features In this section we will only give a brief overview of the features implemented in Jane. For detailed explanation of previously published"
W10-1738,J97-3002,0,0.0234206,"tion information into account, i.e. it operates on sets, not on sequences or even trees. The probability of a word being part of the target sentence, given a set of source words, are decomposed into binary features, one for each source vocabulary entry. These binary features are combined in a log-linear fashion with corresponding feature weights. The discriminative word lexicon is trained independently for each target word using the L-BFGS (Byrd et al., 1995) algorithm. For regularization, Gaussian priors are utilized. DWL model probabilities are computed as be to include the ITG-Reorderings (Wu, 1997), by adding following rule S → hS ∼0 S ∼1 , S ∼1 S ∼0 i (2) We can also model other reordering constraints. As an example, phrase-level IBM reordering constraints with a window length of 1 can be included substituting the rules in Equation (1) with following rules S → hM ∼0 , M ∼0 i S → hM ∼0 S ∼1 , M ∼0 S ∼1 i S → hB ∼0 M ∼1 , M ∼1 B ∼0 i M → hX ∼0 , X ∼0 i (3) M → hM ∼0 X ∼1 , M ∼0 X ∼1 i B → hX ∼0 , X ∼0 i B → hB ∼0 X ∼1 , X ∼1 B ∼0 i In these rules we have added two additional nonterminals. The M non-terminal denotes a monotonic block and the B non-terminal a back jump. Actually both of th"
W10-1738,D09-1022,1,0.416911,"(·) of the application of a rule X → hα, βi where (α, β) is a bilingual phrase pair that may contain symbols from the non-terminal set is computed as Extended Lexicon Models We enriched Jane with the ability to score hypotheses with discriminative and trigger-based lexicon models that use global source sentence context and are capable of predicting contextspecific target words. This approach has recently been shown to improve the translation results of conventional phrase-based systems. In this section, we briefly review the basic aspects of these extended lexicon models. They are similar to (Mauser et al., 2009), and we refer there for a more detailed exposition on the training procedures and results in conventional phrase-based decoding. Note that the training for these models is not distributed together with Jane. t(α, β, f0J ) = (5)   X XX 2 − log  p(e|fj , fj 0 ) J · (J + 1) 0 e j 264 j >j with e ranging over all terminal symbols in the target part β of the rule. The second sum selects all words from the source sentence f0J (including the empty word that is denoted as f0 here). The third sum incorporates the rest of the source sentence right of the first triggering word. The order of the trig"
W10-1738,N07-1062,1,0.242945,"n Methods Two method based on n-best for minimum error rate training (MERT) of the parameters of the loglinear model are included in Jane. The first one is the procedure described in (Och, 2003), which has become a standard in the machine translation 2 265 http://www.sun.com/software/sge/ through 3.5 are implemented in this way. We thus try to achieve loose coupling in the implementation. In addition a flexible prefix tree implementation with on-demand loading capabilities is included as part of the code. This class has been used for implementing on-demand loading of phrases in the spirit of (Zens and Ney, 2007) and the on-demand n-gram format described in Section 3.2, in addition to some intermediate steps in the phrase extraction process. The code may also be reused in other, independent projects. 3.10 System Jane baseline + reordering 4.1 24.2 59.5 25.2 58.2 25.4 57.4 26.5 56.1 Europarl Data The first task is the Europarl as defined in the Quaero project. The main part of the corpus in this task consists of the Europarl corpus as used in the WMT evaluation (Callison-Burch et al., 2009), with some additional data collected in the scope of the project. We tried the reordering approach presented in S"
W10-1738,J03-1002,1,0.0139727,"triggers is not relevant because per definition p(e|f, f 0 ) = p(e|f 0 , f ), i.e. the model is symmetric. Non-terminals in β have to be skipped when the rule is scored. In Jane, we also implemented scoring for a variant of the triplet lexicon model called the pathconstrained (or path-aligned) triplet model. The characteristic of path-constrained triplets is that the first trigger f is restricted to the aligned target word e. The second trigger f 0 is allowed to move along the whole remaining source sentence. For the training of the model, we use word alignment information obtained by GIZA++ (Och and Ney, 2003). To be able to apply the model in search, Jane has to be run with a phrase table that contains word alignment for each phrase, too, with the exception of phrases which are composed purely of non-terminals. Jane’s phrase extraction can optionally supply this information from the training data. (Hasan et al., 2008) and (Hasan and Ney, 2009) employ similar techniques and provide some more discussion on the path-aligned variant of the model and other possible restrictions. 3.6 community. We use an in-house implementation of the method. The second one is the MIRA algorithm, first applied for machi"
W10-1738,W06-3119,0,0.106679,"Jane implements many features presented in previous work developed both at RWTH and other groups. As we go over the features of the system we will provide the corresponding references. Jane is not the first system of its kind, although it provides some unique features. There are other open source hierarchical decoders available. These include We also introduce a novel reordering model for the hierarchical phrase-based approach which further enhances translation performance, and analyze the effect some recent extended lexicon models have on the performance of the system. 1 Related Work • SAMT (Zollmann and Venugopal, 2006): The original version is not maintained any more and we had problems working on big corpora. A new version which requires Hadoop has just been released, however the documentation is still missing. Introduction We present a new open source toolkit for hierarchical phrase-based translation, as described in (Chiang, 2007). The hierarchical phrase model is an extension of the standard phrase model, where the phrases are allowed to have “gaps”. In this way, long-distance dependencies and reorderings can be modelled in a consistent way. As in nearly all current statistical approaches to machine tra"
W10-1738,P03-1021,0,0.035126,"ting the toolkit was to make it easy to extend it with new features. For this, an abstract class was created which we called secondary model. New models need only to derive from this class and implement the abstract methods for data reading and costs computation. This allows for an encapsulation of the computations, which can be activated and deactivated on demand. The models described in Sections 3.3 Optimization Methods Two method based on n-best for minimum error rate training (MERT) of the parameters of the loglinear model are included in Jane. The first one is the procedure described in (Och, 2003), which has become a standard in the machine translation 2 265 http://www.sun.com/software/sge/ through 3.5 are implemented in this way. We thus try to achieve loose coupling in the implementation. In addition a flexible prefix tree implementation with on-demand loading capabilities is included as part of the code. This class has been used for implementing on-demand loading of phrases in the spirit of (Zens and Ney, 2007) and the on-demand n-gram format described in Section 3.2, in addition to some intermediate steps in the phrase extraction process. The code may also be reused in other, indep"
W10-1738,P08-1066,0,0.0313191,"al feature functions of the translation rules. The decoder is able to handle an arbitrary number of non-terminal symbols. The extraction has been extended so that the extraction of SAMTrules is included (Zollmann and Venugopal, 2006) but this approach is not fully supported (there may be empty parses due to the extended number of non-terminals). We instead opted to support the generalization presented in (Venugopal et al., 2009), where the information about the new non-terminals is included as an additional feature in the log-linear model. In addition, dependency information in the spirit of (Shen et al., 2008) is included. Jane features models for string-to-dependency language models and computes various scores based on the well-formedness of the resulting dependency tree. Jane supports the Stanford parsing format,1 but can be easily extended to other parsers. Language Models Jane supports four formats for n-gram language models: • The ARPA format for language models. We use the SRI toolkit (Stolcke, 2002) to support this format. 3.4 • The binary language model format supported by the SRI toolkit. This format allows for a more efficient language model storage, which reduces loading times. In order"
W10-1738,D07-1049,0,0.0186097,"Missing"
W10-1738,N09-1027,0,0.0826285,"n included. 3.2 Syntactic Features Soft syntactic features comparable to (Vilar et al., 2008) are implemented in the extraction step of the toolkit. In search, they are considered as additional feature functions of the translation rules. The decoder is able to handle an arbitrary number of non-terminal symbols. The extraction has been extended so that the extraction of SAMTrules is included (Zollmann and Venugopal, 2006) but this approach is not fully supported (there may be empty parses due to the extended number of non-terminals). We instead opted to support the generalization presented in (Venugopal et al., 2009), where the information about the new non-terminals is included as an additional feature in the log-linear model. In addition, dependency information in the spirit of (Shen et al., 2008) is included. Jane features models for string-to-dependency language models and computes various scores based on the well-formedness of the resulting dependency tree. Jane supports the Stanford parsing format,1 but can be easily extended to other parsers. Language Models Jane supports four formats for n-gram language models: • The ARPA format for language models. We use the SRI toolkit (Stolcke, 2002) to suppor"
W10-1738,2009.eamt-1.33,1,0.841467,"t, a monolingual parsing of the input sentence is carried out using the CYK+ algorithm (Chappelier and Rajman, 1998), a generalization of the CYK algorithm which relaxes the requirement for the grammar to be in Chomsky normal form. From the CYK+ chart we extract a hypergraph representing the parsing space. In a second step the translations are generated, computing the language model scores in an integrated fashion. Both the cube pruning and cube growing algorithms (Huang and Chiang, 2007) are implemented. For the latter case, the extensions concerning the language model heuristics similar to (Vilar and Ney, 2009) have also been included. 3.2 Syntactic Features Soft syntactic features comparable to (Vilar et al., 2008) are implemented in the extraction step of the toolkit. In search, they are considered as additional feature functions of the translation rules. The decoder is able to handle an arbitrary number of non-terminal symbols. The extraction has been extended so that the extraction of SAMTrules is included (Zollmann and Venugopal, 2006) but this approach is not fully supported (there may be empty parses due to the extended number of non-terminals). We instead opted to support the generalization"
W10-1738,2008.iwslt-papers.7,1,0.842545,"n, 1998), a generalization of the CYK algorithm which relaxes the requirement for the grammar to be in Chomsky normal form. From the CYK+ chart we extract a hypergraph representing the parsing space. In a second step the translations are generated, computing the language model scores in an integrated fashion. Both the cube pruning and cube growing algorithms (Huang and Chiang, 2007) are implemented. For the latter case, the extensions concerning the language model heuristics similar to (Vilar and Ney, 2009) have also been included. 3.2 Syntactic Features Soft syntactic features comparable to (Vilar et al., 2008) are implemented in the extraction step of the toolkit. In search, they are considered as additional feature functions of the translation rules. The decoder is able to handle an arbitrary number of non-terminal symbols. The extraction has been extended so that the extraction of SAMTrules is included (Zollmann and Venugopal, 2006) but this approach is not fully supported (there may be empty parses due to the extended number of non-terminals). We instead opted to support the generalization presented in (Venugopal et al., 2009), where the information about the new non-terminals is included as an"
W10-1738,W09-0401,0,\N,Missing
W10-1738,P07-2045,0,\N,Missing
W10-1738,D08-1076,0,\N,Missing
W11-2149,P07-1019,0,0.0299407,"k. GIZA++ (Och and Ney, 2003) 2.2 Hierarchical System For the hierarchical setups described in this paper, the open source Jane toolkit (Vilar et al., 2010) was employed. Jane has been developed at RWTH and implements the hierarchical approach as introduced by Chiang (2007) with some state-of-the-art extensions. In hierarchical phrase-based translation, a weighted synchronous context-free grammar is induced from parallel text. In addition to contiguous lexical phrases, hierarchical phrases with up to two gaps are extracted. The search is typically carried out using the cube pruning algorithm (Huang and Chiang, 2007). The standard models integrated into our Jane systems are: phrase translation probabilities and lexical translation probabilities on phrase level, each for both translation directions, length 405 Proceedings of the 6th Workshop on Statistical Machine Translation, pages 405–412, c Edinburgh, Scotland, UK, July 30–31, 2011. 2011 Association for Computational Linguistics penalties on word and phrase level, three binary features marking hierarchical phrases, glue rule, and rules with non-terminals at the boundaries, sourceto-target and target-to-source phrase length ratios, four binary count feat"
W11-2149,E09-1044,0,0.039482,"Missing"
W11-2149,P03-1054,0,0.00307413,"The phrase alignment is produced by a modified version of the translation decoder. In addition to providing a statistically well-founded phrase model, this has the benefit of producing smaller phrase tables and thus allowing more rapid experiments. A detailed description of the training procedure is given in (Wuebker et al., 2010). 3.3 Soft String-to-Dependency Given a dependency tree of the target language, we are able to introduce language models that span over longer distances than the usual n-grams, as in (Shen et al., 2008). To obtain dependency structures, we apply the Stanford parser (Klein and Manning, 2003) on the target side of the training material. RWTH’s open source hierarchical translation toolkit Jane has been extended to include dependency information in the phrase table and to build dependency trees on the output hypotheses at decoding time from this information. Shen et al. (2008) use only phrases that meet certain restrictions. The first possibility is what the authors call a fixed dependency structure. With the exception of one word within this phrase, called the head, no outside word may have a dependency within this phrase. Also, all inner words may only depend on each other or on t"
W11-2149,E03-1076,0,0.0408333,"pora were used additionally. For the 109 French-English and LDC Gigaword corpora RWTH applied the data selection technique described in Section 3.1. We examined two different language models, one with LDC data and one without. Systems were optimized on the newstest2009 data set, newstest2008 was used as test set. The scores for newstest2010 are included for completeness. 5.1 Morpho-Syntactic Analysis In order to reduce the source vocabulary size for the German→English translation, the source side was preprocessed by splitting German compound words with the frequency-based method described in (Koehn and Knight, 2003). To further reduce translation complexity, we performed the long-range part-of-speech based reordering rules proposed by (Popovi´c et al., 2006). For additional experiments we used the TreeTagger (Schmid, 1995) to produce a lemmatized version of the German source. 5.2 Optimization Criterion We studied the impact of different optimization criteria on tranlsation performance. The usual practice is to optimize the scaling factors to maximize BLEU. We also experimented with two different combinations of BLEU and Translation Edit Rate (TER): TER−BLEU and TER−4BLEU. The first denotes the equally we"
W11-2149,E06-1005,1,0.834047,"rules with non-terminals at the boundaries, sourceto-target and target-to-source phrase length ratios, four binary count features and an n-gram language model. The model weights are optimized with standard MERT (Och, 2003) on 100-best lists. 2.3 System Combination System combination is used to produce consensus translations from multiple hypotheses produced with different translation engines that are better in terms of translation quality than any of the individual hypotheses. The basic concept of RWTH’s approach to machine translation system combination has been described by Matusov et al. (Matusov et al., 2006; Matusov et al., 2008). This approach includes an enhanced alignment and reordering framework. A lattice is built from the input hypotheses. The translation with the best score within the lattice according to a couple of statistical models is selected as consensus translation. 3 Translation Modeling We incorporated several novel methods into our systems for the WMT 2011 evaluation. This section provides a short survey of three of the methods which we suppose to be of particular interest. 3.1 Language Model Data Selection For the English and German language models, we applied the data selectio"
W11-2149,D09-1022,1,0.84817,"on automatically selected English data (cf. Section 3.1) from the provided resources including the 109 corpus and LDC Gigaword. The scaling factors of the log-linear model combination are optimized towards BLEU on newstest2009, newstest2010 is used as an unseen test set. 4.1 Experimental Results French→English The results for the French→English task are given in Table 3. RWTH’s three submissions – one primary and two contrastive – are labeled accordingly in the table. The first contrastive submission is a phrasebased system with a standard feature set plus an additional triplet lexicon model (Mauser et al., 2009). The triplet lexicon model was trained on in-domain news commentary data only. The second contrastive submission is a hierarchical Jane system with three syntax-based extensions: A parse match model (Vilar et al., 2008), soft syntactic labels (Stein et al., 2010), and the soft string-to-dependency extension as described in Section 3.3. The primary submission combines the phrase-based contrastive system, a hierarchical system that is very similar to the Jane contrastive submission but with a slightly worse language model, and an additional PBT system that has been trained with forced alignment"
W11-2149,P10-2041,0,0.0393086,"). This approach includes an enhanced alignment and reordering framework. A lattice is built from the input hypotheses. The translation with the best score within the lattice according to a couple of statistical models is selected as consensus translation. 3 Translation Modeling We incorporated several novel methods into our systems for the WMT 2011 evaluation. This section provides a short survey of three of the methods which we suppose to be of particular interest. 3.1 Language Model Data Selection For the English and German language models, we applied the data selection method proposed in (Moore and Lewis, 2010). Each sentence is scored by the difference in cross-entropy between a language model trained from in-domain data and a language model trained from a similar-sized sample of the out-of-domain data. As in-domain data we used the news-commentary corpus. The out-of-domain data from which the data was selected are the news crawl corpus for both languages and for English the 109 corpus and the LDC Gigaword data. We used a 3-gram trained with the SRI toolkit to compute the cross-entropy. For the news crawl corpus, only 1/8 of the sentences were discarded. Of the 109 corpus we retained 1/2 and of the"
W11-2149,J03-1002,1,0.00864889,"overview of our translation systems in Section 2. In addition to the baseline features, we adopted several novel methods, which will be presented in Section 3. Details on the respective setups and translation results for the French-English and German-English language pairs (in both translation directions) are given in Sections 4 and 5. We finally conclude the paper in Section 6. 2 Phrase-Based System Translation Systems For the WMT 2011 evaluation we utilized RWTH’s state-of-the-art phrase-based and hierarchical translation systems as well as our in-house system combination framework. GIZA++ (Och and Ney, 2003) 2.2 Hierarchical System For the hierarchical setups described in this paper, the open source Jane toolkit (Vilar et al., 2010) was employed. Jane has been developed at RWTH and implements the hierarchical approach as introduced by Chiang (2007) with some state-of-the-art extensions. In hierarchical phrase-based translation, a weighted synchronous context-free grammar is induced from parallel text. In addition to contiguous lexical phrases, hierarchical phrases with up to two gaps are extracted. The search is typically carried out using the cube pruning algorithm (Huang and Chiang, 2007). The"
W11-2149,P03-1021,0,0.00696987,"ities and lexical translation probabilities on phrase level, each for both translation directions, length 405 Proceedings of the 6th Workshop on Statistical Machine Translation, pages 405–412, c Edinburgh, Scotland, UK, July 30–31, 2011. 2011 Association for Computational Linguistics penalties on word and phrase level, three binary features marking hierarchical phrases, glue rule, and rules with non-terminals at the boundaries, sourceto-target and target-to-source phrase length ratios, four binary count features and an n-gram language model. The model weights are optimized with standard MERT (Och, 2003) on 100-best lists. 2.3 System Combination System combination is used to produce consensus translations from multiple hypotheses produced with different translation engines that are better in terms of translation quality than any of the individual hypotheses. The basic concept of RWTH’s approach to machine translation system combination has been described by Matusov et al. (Matusov et al., 2006; Matusov et al., 2008). This approach includes an enhanced alignment and reordering framework. A lattice is built from the input hypotheses. The translation with the best score within the lattice accord"
W11-2149,P08-1066,0,0.0240437,"are estimated from their relative frequencies in the phrase-aligned training data. The phrase alignment is produced by a modified version of the translation decoder. In addition to providing a statistically well-founded phrase model, this has the benefit of producing smaller phrase tables and thus allowing more rapid experiments. A detailed description of the training procedure is given in (Wuebker et al., 2010). 3.3 Soft String-to-Dependency Given a dependency tree of the target language, we are able to introduce language models that span over longer distances than the usual n-grams, as in (Shen et al., 2008). To obtain dependency structures, we apply the Stanford parser (Klein and Manning, 2003) on the target side of the training material. RWTH’s open source hierarchical translation toolkit Jane has been extended to include dependency information in the phrase table and to build dependency trees on the output hypotheses at decoding time from this information. Shen et al. (2008) use only phrases that meet certain restrictions. The first possibility is what the authors call a fixed dependency structure. With the exception of one word within this phrase, called the head, no outside word may have a d"
W11-2149,2010.amta-papers.8,1,0.791938,"t set. 4.1 Experimental Results French→English The results for the French→English task are given in Table 3. RWTH’s three submissions – one primary and two contrastive – are labeled accordingly in the table. The first contrastive submission is a phrasebased system with a standard feature set plus an additional triplet lexicon model (Mauser et al., 2009). The triplet lexicon model was trained on in-domain news commentary data only. The second contrastive submission is a hierarchical Jane system with three syntax-based extensions: A parse match model (Vilar et al., 2008), soft syntactic labels (Stein et al., 2010), and the soft string-to-dependency extension as described in Section 3.3. The primary submission combines the phrase-based contrastive system, a hierarchical system that is very similar to the Jane contrastive submission but with a slightly worse language model, and an additional PBT system that has been trained with forced alignment (Wuebker et al., 408 2010) on WMT 2010 data only. 4.2 Experimental Results English→French The results for the English→French task are given in Table 4. We likewise submitted two contrastive systems for this translation direction. The first contrastive submission"
W11-2149,2008.iwslt-papers.7,1,0.86264,"t2009, newstest2010 is used as an unseen test set. 4.1 Experimental Results French→English The results for the French→English task are given in Table 3. RWTH’s three submissions – one primary and two contrastive – are labeled accordingly in the table. The first contrastive submission is a phrasebased system with a standard feature set plus an additional triplet lexicon model (Mauser et al., 2009). The triplet lexicon model was trained on in-domain news commentary data only. The second contrastive submission is a hierarchical Jane system with three syntax-based extensions: A parse match model (Vilar et al., 2008), soft syntactic labels (Stein et al., 2010), and the soft string-to-dependency extension as described in Section 3.3. The primary submission combines the phrase-based contrastive system, a hierarchical system that is very similar to the Jane contrastive submission but with a slightly worse language model, and an additional PBT system that has been trained with forced alignment (Wuebker et al., 408 2010) on WMT 2010 data only. 4.2 Experimental Results English→French The results for the English→French task are given in Table 4. We likewise submitted two contrastive systems for this translation"
W11-2149,W10-1738,1,0.820443,"h will be presented in Section 3. Details on the respective setups and translation results for the French-English and German-English language pairs (in both translation directions) are given in Sections 4 and 5. We finally conclude the paper in Section 6. 2 Phrase-Based System Translation Systems For the WMT 2011 evaluation we utilized RWTH’s state-of-the-art phrase-based and hierarchical translation systems as well as our in-house system combination framework. GIZA++ (Och and Ney, 2003) 2.2 Hierarchical System For the hierarchical setups described in this paper, the open source Jane toolkit (Vilar et al., 2010) was employed. Jane has been developed at RWTH and implements the hierarchical approach as introduced by Chiang (2007) with some state-of-the-art extensions. In hierarchical phrase-based translation, a weighted synchronous context-free grammar is induced from parallel text. In addition to contiguous lexical phrases, hierarchical phrases with up to two gaps are extracted. The search is typically carried out using the cube pruning algorithm (Huang and Chiang, 2007). The standard models integrated into our Jane systems are: phrase translation probabilities and lexical translation probabilities on"
W11-2149,P10-1049,1,0.92613,"tasks we applied a forced alignment procedure to train the phrase translation model with the EM algorithm, similar to the one described in (DeNero et al., 2006). Here, the phrase translation probabilities are estimated from their relative frequencies in the phrase-aligned training data. The phrase alignment is produced by a modified version of the translation decoder. In addition to providing a statistically well-founded phrase model, this has the benefit of producing smaller phrase tables and thus allowing more rapid experiments. A detailed description of the training procedure is given in (Wuebker et al., 2010). 3.3 Soft String-to-Dependency Given a dependency tree of the target language, we are able to introduce language models that span over longer distances than the usual n-grams, as in (Shen et al., 2008). To obtain dependency structures, we apply the Stanford parser (Klein and Manning, 2003) on the target side of the training material. RWTH’s open source hierarchical translation toolkit Jane has been extended to include dependency information in the phrase table and to build dependency trees on the output hypotheses at decoding time from this information. Shen et al. (2008) use only phrases tha"
W11-2149,W06-3108,1,0.91274,"rdering. Further, we applied a system combination technique to create a consensus hypothesis from several different systems. 1 2.1 We applied a phrase-based translation (PBT) system similar to the one described in (Zens and Ney, 2008). Phrase pairs are extracted from a word-aligned bilingual corpus and their translation probability in both directions is estimated by relative frequencies. The standard feature set moreover includes an n-gram language model, phrase-level single-word lexicons and word-, phrase- and distortion-penalties. To lexicalize reordering, a discriminative reordering model (Zens and Ney, 2006a) is used. Parameters are optimized with the Downhill-Simplex algorithm (Nelder and Mead, 1965) on the word graph. Overview We sketch the baseline architecture of RWTH’s setups for the WMT 2011 shared translation task by providing an overview of our translation systems in Section 2. In addition to the baseline features, we adopted several novel methods, which will be presented in Section 3. Details on the respective setups and translation results for the French-English and German-English language pairs (in both translation directions) are given in Sections 4 and 5. We finally conclude the pap"
W11-2149,W06-3110,1,0.909489,"rdering. Further, we applied a system combination technique to create a consensus hypothesis from several different systems. 1 2.1 We applied a phrase-based translation (PBT) system similar to the one described in (Zens and Ney, 2008). Phrase pairs are extracted from a word-aligned bilingual corpus and their translation probability in both directions is estimated by relative frequencies. The standard feature set moreover includes an n-gram language model, phrase-level single-word lexicons and word-, phrase- and distortion-penalties. To lexicalize reordering, a discriminative reordering model (Zens and Ney, 2006a) is used. Parameters are optimized with the Downhill-Simplex algorithm (Nelder and Mead, 1965) on the word graph. Overview We sketch the baseline architecture of RWTH’s setups for the WMT 2011 shared translation task by providing an overview of our translation systems in Section 2. In addition to the baseline features, we adopted several novel methods, which will be presented in Section 3. Details on the respective setups and translation results for the French-English and German-English language pairs (in both translation directions) are given in Sections 4 and 5. We finally conclude the pap"
W11-2149,2008.iwslt-papers.8,1,0.857725,"f the EMNLP 2011 Sixth Workshop on Statistical Machine Translation. Both phrasebased and hierarchical SMT systems were trained for the constrained German-English and French-English tasks in all directions. Experiments were conducted to compare different training data sets, training methods and optimization criteria, as well as additional models on dependency structure and phrase reordering. Further, we applied a system combination technique to create a consensus hypothesis from several different systems. 1 2.1 We applied a phrase-based translation (PBT) system similar to the one described in (Zens and Ney, 2008). Phrase pairs are extracted from a word-aligned bilingual corpus and their translation probability in both directions is estimated by relative frequencies. The standard feature set moreover includes an n-gram language model, phrase-level single-word lexicons and word-, phrase- and distortion-penalties. To lexicalize reordering, a discriminative reordering model (Zens and Ney, 2006a) is used. Parameters are optimized with the Downhill-Simplex algorithm (Nelder and Mead, 1965) on the word graph. Overview We sketch the baseline architecture of RWTH’s setups for the WMT 2011 shared translation ta"
W11-2149,D07-1103,0,\N,Missing
W11-2149,W10-1723,0,\N,Missing
W11-2149,W08-0509,0,\N,Missing
W11-2149,P07-2045,0,\N,Missing
W11-2149,W10-1713,0,\N,Missing
W11-2149,2005.eamt-1.19,0,\N,Missing
W11-2211,W99-0604,1,\N,Missing
W11-2211,E09-1044,0,\N,Missing
W11-2211,W09-0424,0,\N,Missing
W11-2211,P02-1040,0,\N,Missing
W11-2211,W10-1738,1,\N,Missing
W11-2211,2008.iwslt-papers.6,0,\N,Missing
W11-2211,P10-1049,1,\N,Missing
W11-2211,P07-2045,0,\N,Missing
W11-2211,W07-0733,0,\N,Missing
W11-2211,P05-1033,0,\N,Missing
W11-2211,N03-1017,0,\N,Missing
W11-2211,J03-1002,1,\N,Missing
W11-2211,2009.iwslt-papers.4,0,\N,Missing
W11-2211,P07-1019,0,\N,Missing
W11-2211,2009.mtsummit-posters.17,0,\N,Missing
W11-2211,2010.iwslt-papers.11,1,\N,Missing
W11-2211,J07-2003,0,\N,Missing
W11-2211,D08-1076,0,\N,Missing
W11-2211,W07-0717,0,\N,Missing
W12-3140,J04-2004,0,0.0800912,"nslation model relies on a specific decomposition of the joint probability of a sentence pair P(s, t) using the n-gram assumption: a sentence pair is decomposed into a sequence of bilingual units called tuples, defining a joint segmentation of the source and target. In the approach of (Mari˜no et al., 2006), this segmentation is a by-product of source reordering which ultimately derives from initial word and phrase alignments. 2.3.1 An Overview of n-code The baseline translation model is implemented as a stochastic finite-state transducer trained using a n-gram model of (source,target) pairs (Casacuberta and Vidal, 2004). Training this model requires to reorder source sentences so as to match the target word order. This is performed by a stochastic finitestate reordering model, which uses part-of-speech information3 to generalize reordering patterns beyond lexical regularities. In addition to the translation model, eleven feature functions are combined: a target-language model; four lexicon models; two lexicalized reordering models (Tillmann, 2004) aiming at predicting the orientation of the next translation unit; a ’weak’ distance-based distortion model; and finally a wordbonus model and a tuple-bonus model"
W12-3140,J07-2003,0,0.0283293,"322–329, c Montr´eal, Canada, June 7-8, 2012. 2012 Association for Computational Linguistics set also includes an n-gram language model, phraselevel IBM-1 and word-, phrase- and distortionpenalties, which are combined in log-linear fashion. The model weights are optimized with standard Mert (Och, 2003) on 200-best lists. The optimization criterium is B LEU. 2.1.2 Hierarchical System For the hierarchical setups (HPBT) described in this paper, the open source Jane toolkit (Vilar et al., 2010) is employed. Jane has been developed at RWTH and implements the hierarchical approach as introduced by Chiang (2007) with some state-of-theart extensions. In hierarchical phrase-based translation, a weighted synchronous context-free grammar is induced from parallel text. In addition to contiguous lexical phrases, hierarchical phrases with up to two gaps are extracted. The search is typically carried out using the cube pruning algorithm (Huang and Chiang, 2007). The model weights are optimized with standard Mert (Och, 2003) on 100-best lists. The optimization criterium is 4B LEU −T ER. 2.1.3 Preprocessing In order to reduce the source vocabulary size translation, the German text was preprocessed by splitting"
W12-3140,W08-0310,1,0.935329,"Missing"
W12-3140,2010.iwslt-papers.6,0,0.0806631,"as last year5 and thus the same target language model as detailed in (Allauzen et al., 2011). For English, we took advantage of our in-house text processing tools for tokenization and detokenization steps (D´echelotte et al., 2008) and our system was built in ”true-case”. As German is morphologically more complex than English, the default policy which consists in treating each word form independently is plagued with data sparsity, which is detrimental both at training and decoding time. Thus, the German side was normalized using a specific pre-processing scheme (Allauzen et al., 2010; Durgar El-Kahlout and Yvon, 2010), which notably aims at reducing the lexical redundancy by (i) normalizing the orthography, (ii) neutralizing most inflections and (iii) splitting complex compounds. 2.4 SYSTRAN Software, Inc. Single System The data submitted by SYSTRAN were obtained by a system composed of the standard SYSTRAN MT engine in combination with a statistical post editing (SPE) component. 4 http://geek.kyloo.net/software 5 The fifth edition of the English Gigaword (LDC2011T07) was not used. 325 The SYSTRAN system is traditionally classified as a rule-based system. However, over the decades, its development has alwa"
W12-3140,P07-1019,0,0.0343944,"on criterium is B LEU. 2.1.2 Hierarchical System For the hierarchical setups (HPBT) described in this paper, the open source Jane toolkit (Vilar et al., 2010) is employed. Jane has been developed at RWTH and implements the hierarchical approach as introduced by Chiang (2007) with some state-of-theart extensions. In hierarchical phrase-based translation, a weighted synchronous context-free grammar is induced from parallel text. In addition to contiguous lexical phrases, hierarchical phrases with up to two gaps are extracted. The search is typically carried out using the cube pruning algorithm (Huang and Chiang, 2007). The model weights are optimized with standard Mert (Och, 2003) on 100-best lists. The optimization criterium is 4B LEU −T ER. 2.1.3 Preprocessing In order to reduce the source vocabulary size translation, the German text was preprocessed by splitting German compound words with the frequency-based method described in (Koehn and Knight, 2003a). To further reduce translation complexity for the phrase-based approach, we performed the long-range part-of-speech based reordering rules proposed by (Popovi´c et al., 2006). 2.1.4 Language Model For both decoders a 4-gram language model is applied. The"
W12-3140,E03-1076,0,0.55884,"ranslation, a weighted synchronous context-free grammar is induced from parallel text. In addition to contiguous lexical phrases, hierarchical phrases with up to two gaps are extracted. The search is typically carried out using the cube pruning algorithm (Huang and Chiang, 2007). The model weights are optimized with standard Mert (Och, 2003) on 100-best lists. The optimization criterium is 4B LEU −T ER. 2.1.3 Preprocessing In order to reduce the source vocabulary size translation, the German text was preprocessed by splitting German compound words with the frequency-based method described in (Koehn and Knight, 2003a). To further reduce translation complexity for the phrase-based approach, we performed the long-range part-of-speech based reordering rules proposed by (Popovi´c et al., 2006). 2.1.4 Language Model For both decoders a 4-gram language model is applied. The language model is trained on the parallel data as well as the provided News crawl, the 109 French-English, UN and LDC Gigaword Fourth Edition corpora. For the 109 French-English, UN and LDC Gigaword corpora RWTH applied the data selection technique described in (Moore and Lewis, 2010). 2.2 2.2.1 Karlsruhe Institute of Technology Single Syst"
W12-3140,W07-0732,1,0.793396,"rule-based system. However, over the decades, its development has always been driven by pragmatic considerations, progressively integrating many of the most efficient MT approaches and techniques. Nowadays, the baseline engine can be considered as a linguistic-oriented system making use of dependency analysis, general transfer rules as well as of large manually encoded dictionaries (100k 800k entries per language pair). The SYSTRAN phrase-based SPE component views the output of the rule-based system as the source language, and the (human) reference translation as the target language, see (L. Dugast and Koehn, 2007). It performs corrections and adaptions learned from the 5-gram language model trained on the parallel target-to-target corpus. Moreover, the following measures - limiting unwanted statistical effects - were applied: • Named entities, time and numeric expressions are replaced by special tokens on both sides. This usually improves word alignment, since the vocabulary size is significantly reduced. In addition, entity translation is handled more reliably by the rule-based engine. • The intersection of both vocabularies (i.e. vocabularies of the rule-based output and the reference translation) is"
W12-3140,N12-1005,1,0.858653,"bilingual pairs, which means that the underlying vocabulary can be quite large. Unfortunately, the parallel data available to train these models are typically smaller than the corresponding monolingual corpora used to train target language models. It is very likely then, that such models should face severe estimation problems. In such setting, using neural network language 3 Part-of-speech labels for English and German are computed using the TreeTagger (Schmid, 1995). 2 http://ncode.limsi.fr/ 324 model techniques seem all the more appropriate. For this study, we follow the recommendations of Le et al. (2012), who propose to factor the joint probability of a sentence pair by decomposing tuples in two (source and target) parts, and further each part in words. This yields a word factored translation model that can be estimated in a continuous space using the SOUL architecture (Le et al., 2011). The design and integration of a SOUL model for large SMT tasks is far from easy, given the computational cost of computing n-gram probabilities. The solution used here was to resort to a two pass approach: the first pass uses a conventional back-off n-gram model to produce a k-best list; in the second pass, t"
W12-3140,J06-4004,1,0.843277,"Missing"
W12-3140,E06-1005,1,0.849031,"glish LDC Gigaword corpus using KneserNey (Kneser and Ney, 1995) smoothing was added. Weights for these separate models were tuned by the Mert algorithm provided in the Moses toolkit (P. Koehn et al., 2007), using the provided news development set. 3 RWTH Aachen System Combination System combination is used to produce consensus translations from multiple hypotheses produced with different translation engines that are better in terms of translation quality than any of the individual hypotheses. The basic concept of RWTH’s approach to machine translation system combination has been described by Matusov et al. (2006; 2008). This approach includes an enhanced alignment and reordering framework. A lattice is built from the input hypotheses. The translation with the best score within the lattice according to a couple of statistical models is selected as consensus translation. 4 Experiments This year, we tried different sets of single systems for system combination. As RWTH has two different translation systems, we put the output of both systems into system combination. Although both systems have the same preprocessing and language model, their hypotheses differ because of their different decoding approach."
W12-3140,D09-1022,1,0.869178,"done using Minimum Error Rate Training as described in Venugopal et al. (2005). 2.2.3 We preprocess the training data prior to training the system, first by normalizing symbols such as 323 Translation Models The translation model is trained on the Europarl and News Commentary Corpus and the phrase table is based on a discriminative word alignment (Niehues and Vogel, 2008). In addition, the system applies a bilingual language model (Niehues et al., 2011) to extend the context of source language words available for translation. Furthermore, we use a discriminative word lexicon as introduced in (Mauser et al., 2009). The lexicon was trained and integrated into our system as described in (Mediani et al., 2011). At last, we tried to find translations for out-of-vocabulary (OOV) words by using quasimorphological operations as described in Niehues and Waibel (2011). For each OOV word, we try to find a related word that we can translate. We modify the ending letters of the OOV word and learn quasimorphological operations to be performed on the known translation of the related word to synthesize a translation for the OOV word. By this approach we were for example able to translate Kaminen into chimneys using t"
W12-3140,2011.iwslt-evaluation.9,1,0.871665,"ocess the training data prior to training the system, first by normalizing symbols such as 323 Translation Models The translation model is trained on the Europarl and News Commentary Corpus and the phrase table is based on a discriminative word alignment (Niehues and Vogel, 2008). In addition, the system applies a bilingual language model (Niehues et al., 2011) to extend the context of source language words available for translation. Furthermore, we use a discriminative word lexicon as introduced in (Mauser et al., 2009). The lexicon was trained and integrated into our system as described in (Mediani et al., 2011). At last, we tried to find translations for out-of-vocabulary (OOV) words by using quasimorphological operations as described in Niehues and Waibel (2011). For each OOV word, we try to find a related word that we can translate. We modify the ending letters of the OOV word and learn quasimorphological operations to be performed on the known translation of the related word to synthesize a translation for the OOV word. By this approach we were for example able to translate Kaminen into chimneys using the known translation Kamin # chimney. 2.2.4 Preprocessing System Overview Language Models We us"
W12-3140,P10-2041,0,0.0181873,"ound words with the frequency-based method described in (Koehn and Knight, 2003a). To further reduce translation complexity for the phrase-based approach, we performed the long-range part-of-speech based reordering rules proposed by (Popovi´c et al., 2006). 2.1.4 Language Model For both decoders a 4-gram language model is applied. The language model is trained on the parallel data as well as the provided News crawl, the 109 French-English, UN and LDC Gigaword Fourth Edition corpora. For the 109 French-English, UN and LDC Gigaword corpora RWTH applied the data selection technique described in (Moore and Lewis, 2010). 2.2 2.2.1 Karlsruhe Institute of Technology Single System quotes, dashes and apostrophes. Then smart-casing of the first words of each sentence is performed. For the German part of the training corpus we use the hunspell1 lexicon to learn a mapping from old German spelling to new German spelling to obtain a corpus with homogenous spelling. In addition, we perform compound splitting as described in (Koehn and Knight, 2003b). Finally, we remove very long sentences, empty lines, and sentences that probably are not parallel due to length mismatch. 2.2.2 The KIT system uses an in-house phrase-bas"
W12-3140,W09-0435,1,0.860476,"Preprocessing System Overview Language Models We use two 4-gram SRI language models, one trained on the News Shuffle corpus and one trained 1 http://hunspell.sourceforge.net/ on the Gigaword corpus. Furthermore, we use a 5gram cluster-based language model trained on the News Shuffle corpus. The word clusters were created using the MKCLS algorithm. We used 100 word clusters. 2.2.5 Reordering Model Reordering is performed based on part-of-speech tags obtained using the TreeTagger (Schmid, 1994). Based on these tags we learn probabilistic continuous (Rottmann and Vogel, 2007) and discontinuous (Niehues and Kolss, 2009) rules to cover short and long-range reorderings. The rules are learned from the training corpus and the alignment. In addition, we learned tree-based reordering rules. Therefore, the training corpus was parsed by the Stanford parser (Rafferty and Manning, 2008). The tree-based rules consist of the head node of a subtree and all its children as well as the new order and a probability. These rules were applied recursively. The reordering rules are applied to the source sentences and the reordered sentence variants as well as the original sequence are encoded in a word lattice which is used as i"
W12-3140,W08-0303,1,0.84967,"very long sentences, empty lines, and sentences that probably are not parallel due to length mismatch. 2.2.2 The KIT system uses an in-house phrase-based decoder (Vogel, 2003) to perform translation and optimization with regard to the B LEU score is done using Minimum Error Rate Training as described in Venugopal et al. (2005). 2.2.3 We preprocess the training data prior to training the system, first by normalizing symbols such as 323 Translation Models The translation model is trained on the Europarl and News Commentary Corpus and the phrase table is based on a discriminative word alignment (Niehues and Vogel, 2008). In addition, the system applies a bilingual language model (Niehues et al., 2011) to extend the context of source language words available for translation. Furthermore, we use a discriminative word lexicon as introduced in (Mauser et al., 2009). The lexicon was trained and integrated into our system as described in (Mediani et al., 2011). At last, we tried to find translations for out-of-vocabulary (OOV) words by using quasimorphological operations as described in Niehues and Waibel (2011). For each OOV word, we try to find a related word that we can translate. We modify the ending letters o"
W12-3140,2011.iwslt-papers.6,1,0.847434,"he Europarl and News Commentary Corpus and the phrase table is based on a discriminative word alignment (Niehues and Vogel, 2008). In addition, the system applies a bilingual language model (Niehues et al., 2011) to extend the context of source language words available for translation. Furthermore, we use a discriminative word lexicon as introduced in (Mauser et al., 2009). The lexicon was trained and integrated into our system as described in (Mediani et al., 2011). At last, we tried to find translations for out-of-vocabulary (OOV) words by using quasimorphological operations as described in Niehues and Waibel (2011). For each OOV word, we try to find a related word that we can translate. We modify the ending letters of the OOV word and learn quasimorphological operations to be performed on the known translation of the related word to synthesize a translation for the OOV word. By this approach we were for example able to translate Kaminen into chimneys using the known translation Kamin # chimney. 2.2.4 Preprocessing System Overview Language Models We use two 4-gram SRI language models, one trained on the News Shuffle corpus and one trained 1 http://hunspell.sourceforge.net/ on the Gigaword corpus. Further"
W12-3140,W11-2124,1,0.868397,"length mismatch. 2.2.2 The KIT system uses an in-house phrase-based decoder (Vogel, 2003) to perform translation and optimization with regard to the B LEU score is done using Minimum Error Rate Training as described in Venugopal et al. (2005). 2.2.3 We preprocess the training data prior to training the system, first by normalizing symbols such as 323 Translation Models The translation model is trained on the Europarl and News Commentary Corpus and the phrase table is based on a discriminative word alignment (Niehues and Vogel, 2008). In addition, the system applies a bilingual language model (Niehues et al., 2011) to extend the context of source language words available for translation. Furthermore, we use a discriminative word lexicon as introduced in (Mauser et al., 2009). The lexicon was trained and integrated into our system as described in (Mediani et al., 2011). At last, we tried to find translations for out-of-vocabulary (OOV) words by using quasimorphological operations as described in Niehues and Waibel (2011). For each OOV word, we try to find a related word that we can translate. We modify the ending letters of the OOV word and learn quasimorphological operations to be performed on the known"
W12-3140,J03-1002,1,0.00977827,"RO partner trained their systems on the parallel Europarl and News Commentary corpora. All single systems were tuned on the newstest2009 or newstest2010 development set. The newstest2011 dev set was used to train the system combination parameters. Finally, the newstest2008-newstest2010 dev sets were used to compare the results of the different system combination settings. In this Section all four different system engines are presented. 2.1 RWTH Aachen Single Systems For the WMT 2012 evaluation the RWTH utilized RWTH’s state-of-the-art phrase-based and hierarchical translation systems. GIZA++ (Och and Ney, 2003) was employed to train word alignments, language models have been created with the SRILM toolkit (Stolcke, 2002). 2.1.1 Phrase-Based System The phrase-based translation (PBT) system is similar to the one described in Zens and Ney (2008). After phrase pair extraction from the word-aligned parallel corpus, the translation probabilities are estimated by relative frequencies. The standard feature 322 Proceedings of the 7th Workshop on Statistical Machine Translation, pages 322–329, c Montr´eal, Canada, June 7-8, 2012. 2012 Association for Computational Linguistics set also includes an n-gram langu"
W12-3140,P03-1021,0,0.230828,"n (PBT) system is similar to the one described in Zens and Ney (2008). After phrase pair extraction from the word-aligned parallel corpus, the translation probabilities are estimated by relative frequencies. The standard feature 322 Proceedings of the 7th Workshop on Statistical Machine Translation, pages 322–329, c Montr´eal, Canada, June 7-8, 2012. 2012 Association for Computational Linguistics set also includes an n-gram language model, phraselevel IBM-1 and word-, phrase- and distortionpenalties, which are combined in log-linear fashion. The model weights are optimized with standard Mert (Och, 2003) on 200-best lists. The optimization criterium is B LEU. 2.1.2 Hierarchical System For the hierarchical setups (HPBT) described in this paper, the open source Jane toolkit (Vilar et al., 2010) is employed. Jane has been developed at RWTH and implements the hierarchical approach as introduced by Chiang (2007) with some state-of-theart extensions. In hierarchical phrase-based translation, a weighted synchronous context-free grammar is induced from parallel text. In addition to contiguous lexical phrases, hierarchical phrases with up to two gaps are extracted. The search is typically carried out"
W12-3140,P07-2045,0,0.00885526,"to improve word alignment. • Singleton phrase pairs are deleted from the phrase table to avoid overfitting. • Phrase pairs not containing the same number of entities on the source and the target side are also discarded. The SPE language model was trained on 2M bilingual phrases from the news/Europarl corpora, provided as training data for WMT 2012. An additional language model built from 15M phrases of the English LDC Gigaword corpus using KneserNey (Kneser and Ney, 1995) smoothing was added. Weights for these separate models were tuned by the Mert algorithm provided in the Moses toolkit (P. Koehn et al., 2007), using the provided news development set. 3 RWTH Aachen System Combination System combination is used to produce consensus translations from multiple hypotheses produced with different translation engines that are better in terms of translation quality than any of the individual hypotheses. The basic concept of RWTH’s approach to machine translation system combination has been described by Matusov et al. (2006; 2008). This approach includes an enhanced alignment and reordering framework. A lattice is built from the input hypotheses. The translation with the best score within the lattice accor"
W12-3140,W08-1006,0,0.100843,"ained on the News Shuffle corpus. The word clusters were created using the MKCLS algorithm. We used 100 word clusters. 2.2.5 Reordering Model Reordering is performed based on part-of-speech tags obtained using the TreeTagger (Schmid, 1994). Based on these tags we learn probabilistic continuous (Rottmann and Vogel, 2007) and discontinuous (Niehues and Kolss, 2009) rules to cover short and long-range reorderings. The rules are learned from the training corpus and the alignment. In addition, we learned tree-based reordering rules. Therefore, the training corpus was parsed by the Stanford parser (Rafferty and Manning, 2008). The tree-based rules consist of the head node of a subtree and all its children as well as the new order and a probability. These rules were applied recursively. The reordering rules are applied to the source sentences and the reordered sentence variants as well as the original sequence are encoded in a word lattice which is used as input to the decoder. For the test sentences, the reordering based on parts-of-speech and trees allows us to change the word order in the source sentence so that the sentence can be translated more easily. In addition, we build reordering lattices for all trainin"
W12-3140,2007.tmi-papers.21,0,0.266844,"the known translation Kamin # chimney. 2.2.4 Preprocessing System Overview Language Models We use two 4-gram SRI language models, one trained on the News Shuffle corpus and one trained 1 http://hunspell.sourceforge.net/ on the Gigaword corpus. Furthermore, we use a 5gram cluster-based language model trained on the News Shuffle corpus. The word clusters were created using the MKCLS algorithm. We used 100 word clusters. 2.2.5 Reordering Model Reordering is performed based on part-of-speech tags obtained using the TreeTagger (Schmid, 1994). Based on these tags we learn probabilistic continuous (Rottmann and Vogel, 2007) and discontinuous (Niehues and Kolss, 2009) rules to cover short and long-range reorderings. The rules are learned from the training corpus and the alignment. In addition, we learned tree-based reordering rules. Therefore, the training corpus was parsed by the Stanford parser (Rafferty and Manning, 2008). The tree-based rules consist of the head node of a subtree and all its children as well as the new order and a probability. These rules were applied recursively. The reordering rules are applied to the source sentences and the reordered sentence variants as well as the original sequence are"
W12-3140,N04-4026,0,0.0510078,"of n-code The baseline translation model is implemented as a stochastic finite-state transducer trained using a n-gram model of (source,target) pairs (Casacuberta and Vidal, 2004). Training this model requires to reorder source sentences so as to match the target word order. This is performed by a stochastic finitestate reordering model, which uses part-of-speech information3 to generalize reordering patterns beyond lexical regularities. In addition to the translation model, eleven feature functions are combined: a target-language model; four lexicon models; two lexicalized reordering models (Tillmann, 2004) aiming at predicting the orientation of the next translation unit; a ’weak’ distance-based distortion model; and finally a wordbonus model and a tuple-bonus model which compensate for the system preference for short translations. The four lexicon models are similar to the ones used in a standard phrase based system: two scores correspond to the relative frequencies of the tuples and two lexical weights estimated from the automatically generated word alignments. The weights associated to feature functions are optimally combined using a discriminative training framework (Och, 2003), using the n"
W12-3140,W05-0836,1,0.92366,"rmed. For the German part of the training corpus we use the hunspell1 lexicon to learn a mapping from old German spelling to new German spelling to obtain a corpus with homogenous spelling. In addition, we perform compound splitting as described in (Koehn and Knight, 2003b). Finally, we remove very long sentences, empty lines, and sentences that probably are not parallel due to length mismatch. 2.2.2 The KIT system uses an in-house phrase-based decoder (Vogel, 2003) to perform translation and optimization with regard to the B LEU score is done using Minimum Error Rate Training as described in Venugopal et al. (2005). 2.2.3 We preprocess the training data prior to training the system, first by normalizing symbols such as 323 Translation Models The translation model is trained on the Europarl and News Commentary Corpus and the phrase table is based on a discriminative word alignment (Niehues and Vogel, 2008). In addition, the system applies a bilingual language model (Niehues et al., 2011) to extend the context of source language words available for translation. Furthermore, we use a discriminative word lexicon as introduced in (Mauser et al., 2009). The lexicon was trained and integrated into our system a"
W12-3140,W10-1738,1,0.875756,"by relative frequencies. The standard feature 322 Proceedings of the 7th Workshop on Statistical Machine Translation, pages 322–329, c Montr´eal, Canada, June 7-8, 2012. 2012 Association for Computational Linguistics set also includes an n-gram language model, phraselevel IBM-1 and word-, phrase- and distortionpenalties, which are combined in log-linear fashion. The model weights are optimized with standard Mert (Och, 2003) on 200-best lists. The optimization criterium is B LEU. 2.1.2 Hierarchical System For the hierarchical setups (HPBT) described in this paper, the open source Jane toolkit (Vilar et al., 2010) is employed. Jane has been developed at RWTH and implements the hierarchical approach as introduced by Chiang (2007) with some state-of-theart extensions. In hierarchical phrase-based translation, a weighted synchronous context-free grammar is induced from parallel text. In addition to contiguous lexical phrases, hierarchical phrases with up to two gaps are extracted. The search is typically carried out using the cube pruning algorithm (Huang and Chiang, 2007). The model weights are optimized with standard Mert (Och, 2003) on 100-best lists. The optimization criterium is 4B LEU −T ER. 2.1.3 P"
W12-3140,2008.iwslt-papers.8,1,0.841876,"parameters. Finally, the newstest2008-newstest2010 dev sets were used to compare the results of the different system combination settings. In this Section all four different system engines are presented. 2.1 RWTH Aachen Single Systems For the WMT 2012 evaluation the RWTH utilized RWTH’s state-of-the-art phrase-based and hierarchical translation systems. GIZA++ (Och and Ney, 2003) was employed to train word alignments, language models have been created with the SRILM toolkit (Stolcke, 2002). 2.1.1 Phrase-Based System The phrase-based translation (PBT) system is similar to the one described in Zens and Ney (2008). After phrase pair extraction from the word-aligned parallel corpus, the translation probabilities are estimated by relative frequencies. The standard feature 322 Proceedings of the 7th Workshop on Statistical Machine Translation, pages 322–329, c Montr´eal, Canada, June 7-8, 2012. 2012 Association for Computational Linguistics set also includes an n-gram language model, phraselevel IBM-1 and word-, phrase- and distortionpenalties, which are combined in log-linear fashion. The model weights are optimized with standard Mert (Och, 2003) on 200-best lists. The optimization criterium is B LEU. 2."
W12-3140,W11-2135,1,\N,Missing
W12-3140,W10-1704,1,\N,Missing
W12-3140,D08-1076,0,\N,Missing
W13-0804,2010.amta-papers.7,0,\N,Missing
W13-0804,W12-3128,0,\N,Missing
W13-0804,E09-1044,0,\N,Missing
W13-0804,W05-1506,0,\N,Missing
W13-0804,J10-4005,0,\N,Missing
W13-0804,W09-0424,0,\N,Missing
W13-0804,D11-1020,0,\N,Missing
W13-0804,P02-1040,0,\N,Missing
W13-0804,W10-1738,1,\N,Missing
W13-0804,P12-3004,0,\N,Missing
W13-0804,N09-1027,0,\N,Missing
W13-0804,P07-2045,0,\N,Missing
W13-0804,D12-1107,0,\N,Missing
W13-0804,N13-1116,0,\N,Missing
W13-0804,W08-0402,0,\N,Missing
W13-0804,P05-1033,0,\N,Missing
W13-0804,P10-4002,0,\N,Missing
W13-0804,J03-1002,1,\N,Missing
W13-0804,2009.iwslt-papers.4,0,\N,Missing
W13-0804,P07-1019,0,\N,Missing
W13-0804,2011.eamt-1.37,1,\N,Missing
W13-0804,2012.eamt-1.44,0,\N,Missing
W13-0804,J07-2003,0,\N,Missing
W13-0804,W12-3150,0,\N,Missing
W13-0804,D08-1076,0,\N,Missing
W13-0804,2011.iwslt-evaluation.24,0,\N,Missing
W13-2223,W13-0805,1,0.848446,"OS) based reordering using probabilistic continuous (Rottmann and Vogel, 2007) and discontinuous (Niehues and Kolss, 2009) rules. This was learned using POS tags generated by the TreeTagger (Schmid, 1994) for short and long range reorderings respectively. In addition to this POS-based reordering, we also used tree-based reordering rules. Syntactic parse trees of the whole training corpus and the word alignment between source and target language are used to learn rules on how to reorder the constituents in a German source sentence to make it match the English target sentence word order better (Herrmann et al., 2013). The training corpus was parsed by the Stanford parser (Rafferty and Manning, 2008). The reordering rules are applied to the source sentences and the reordered sentence variants as well as the original sequence are encoded in a word lattice which is used as input to the decoder. Moreover, our reordering model was extended so that it could include the features of lexicalized reordering model. The reordering probabilities for each phrase pair are stored as well as the original position of each word in the lattice. During the decoding, the reordering origin of the words is checked along with its"
W13-2223,E03-1076,0,0.0855399,"n the parallel data as well as the provided News crawl, the 109 French-English, UN and LDC Gigaword Fourth Edition corpora. 2.2 System Overview Karlsruhe Institute of Technology Single System 2.2.1 Preprocessing The training data was preprocessed prior to the training. Symbols such as quotes, dashes and apostrophes are normalized. Then the first words of each sentence are smart-cased. For the German part of the training corpus, the hunspell2 lexicon was used, in order to learn a mapping from old German spelling to new German writing rules. Compound-splitting was also performed as described in Koehn and Knight (2003). We also removed very long sentences, empty lines, and sentences which show big mismatch on the length. 2.2.2 Filtering The web-crawled corpus was filtered using an SVM classifier as described in (Mediani et al., 2011). The lexica used in this filtering task were obtained from Giza alignments trained on the 2.2.5 Translation Models The translation model uses the parallel data of EPPS, NC, and the filtered web-crawled data. As word alignment, we used the Discriminative Word Alignment (DWA) as shown in (Niehues and Vo2 http://hunspell.sourceforge.net/ 186 gel, 2008). The phrase pairs were extra"
W13-2223,P07-2045,0,0.00527113,"ne Translation. The technique of Statistical Post-Editing (Dugast et al., 2007) is used to automatically edit the output of the rule-based system. A Statistical Post-Editing (SPE) module is generated from a bilingual corpus. It is basically a translation module by itself, however it is trained on rule-based • Phrase pairs appearing less than 2 times were pruned. The SPE language model was trained on 2M phrases from the news/europarl and CommonCrawl corpora, provided as training data for WMT 2013. Weights for these separate models were tuned by the Mert algorithm provided in the Moses toolkit (Koehn et al., 2007), using the provided news development set. 5 http://geek.kyloo.net/software 6 The fifth edition of (LDC2011T07) was not used. the English Gigaword 188 0 5:that/1 7:this/3 1 3:is/3 8:was/1 2 0:*EPS*/3 4:it/1 0:*EPS*/3 2:in/1 3 4 0:*EPS*/3 6:the/1 5 0:*EPS*/1 1:future/3 6 Figure 1: Confusion network of four different hypotheses. 3 RWTH Aachen System Combination Table 1: Comparison of single systems tuned on newstest2009 and newstest2010. The results are reported on newstest2012. System combination is used to produce consensus translations from multiple hypotheses generated with different transla"
W13-2223,J04-2004,0,0.0419685,"d a bilingual language model (Niehues et al., 2011). A Discriminative Word Lexicon (DWL) introduced in (Mauser et al., 2009) was extended so that it could take the source context also into the account. For this, we used a bag-of-ngrams instead of representing the source sentence as a bag-of-words. Filtering based on counts was then applied to the features for higher order n-grams. In addition to this, the training examples were created differently so that we only used the words that occur in the n-best list but not in the reference as negative example. a n-gram model of (source,target) pairs (Casacuberta and Vidal, 2004). Training this model requires to reorder source sentences so as to match the target word order. This is performed by a stochastic finite-state reordering model, which uses part-of-speech information4 to generalize reordering patterns beyond lexical regularities. In addition to the translation model, eleven feature functions are combined: a target-language model; four lexicon models; two lexicalized reordering models (Tillmann, 2004) aiming at predicting the orientation of the next translation unit; a ’weak’ distance-based distortion model; and finally a word-bonus model and a tuple-bonus mode"
W13-2223,W07-0734,0,0.0383886,"results are reported on newstest2012. System combination is used to produce consensus translations from multiple hypotheses generated with different translation engines. First, a word to word alignment for the given single system hypotheses is produced. In a second step a confusion network is constructed. Then, the hypothesis with the highest probability is extracted from this confusion network. For the alignment procedure, each of the given single systems generates one confusion network with its own as primary system. To this primary system all other hypotheses are aligned using the METEOR (Lavie and Agarwal, 2007) alignment and thus the primary system defines the word order. Once the alignment is given, the corresponding confusion network is constructed. An example is given in Figure 1. The final network for one source sentence is the union of all confusion networks generated from the different primary systems. That allows the system combination to select the word order from different system outputs. Before performing system combination, each translation output was normalized by tokenization and lowercasing. The output of the combination was then truecased based on the original truecased output. The mo"
W13-2223,W07-0732,0,0.0965924,"m = 10, and used k = 300. 2.3.4 translations and reference data. It applies corrections and adaptations learned from a phrase-based 5-gram language model. Using this two-step process will implicitly keep long distance relations and other constraints determined by the rule-based system while significantly improving phrasal fluency. It has the advantage that quality improvements can be achieved with very little but targeted bilingual data, thus significantly reducing training time and increasing translation performance. The basic setup of the SPE component is identical to the one described in (Dugast et al., 2007). A statistical translation model is trained on the rule-based translation of the source and the target side of the parallel corpus. Language models are trained on each target half of the parallel corpora and also on additional in-domain corpora. Moreover, the following measures - limiting unwanted statistical effects - were applied: Corpora and data pre-processing All the parallel data allowed in the constrained task are pooled together to create a single parallel corpus. This corpus is word-aligned using MGIZA++5 with default settings. For the English monolingual training data, we used the s"
W13-2223,N12-1005,0,0.0335346,"with standard n-gram translation models is that the elementary units are bilingual pairs, which means that the underlying vocabulary can be quite large, even for small translation tasks. Unfortunately, the parallel data available to train these models are typically order of magnitudes smaller than the corresponding monolingual corpora used to train target language models. It is very likely then, that such models should face severe estimation problems. In such setting, using neural network language model techniques seem all the more appropriate. For this study, we follow the recommendations of Le et al. (2012), who propose to factor the joint probability of a sentence pair by decomposing tuples in two (source and target) parts, and further each part in words. This yields a word factored translation model that LIMSI-CNRS Single System 2.3.1 System overview LIMSI’s system is built with n-code (Crego et al., 2011), an open source statistical machine translation system based on bilingual n-gram3 . In this approach, the translation model relies on a specific decomposition of the joint probability of a sentence pair using the n-gram assumption: a sentence pair is decomposed into a sequence of bilingual u"
W13-2223,2010.iwslt-papers.6,0,0.0342874,"Missing"
W13-2223,2012.iwslt-papers.7,1,0.838536,"an compound words with the frequencybased method described in (Koehn and Knight, 2003). To further reduce translation complexity for the phrase-based approach, we performed the long-range part-of-speech based reordering rules proposed by (Popovi´c et al., 2006). 2.2.3 The in-house phrase-based decoder (Vogel, 2003) is used to perform decoding. Optimization with regard to the BLEU score is done using Minimum Error Rate Training (MERT) as described in Venugopal et al. (2005). 2.1.2 Translation Model We applied filtering and weighting for domainadaptation similarly to (Mansour et al., 2011) and (Mansour and Ney, 2012). For filtering the bilingual data, a combination of LM and IBM Model 1 scores was used. In addition, we performed weighted phrase extraction by using a combined LM and IBM Model 1 weight. 2.2.4 Reordering Model We applied part-of-speech (POS) based reordering using probabilistic continuous (Rottmann and Vogel, 2007) and discontinuous (Niehues and Kolss, 2009) rules. This was learned using POS tags generated by the TreeTagger (Schmid, 1994) for short and long range reorderings respectively. In addition to this POS-based reordering, we also used tree-based reordering rules. Syntactic parse tree"
W13-2223,W08-0310,0,0.0216057,"nal in-domain corpora. Moreover, the following measures - limiting unwanted statistical effects - were applied: Corpora and data pre-processing All the parallel data allowed in the constrained task are pooled together to create a single parallel corpus. This corpus is word-aligned using MGIZA++5 with default settings. For the English monolingual training data, we used the same setup as last year6 and thus the same target language model as detailed in (Allauzen et al., 2011). For English, we also took advantage of our inhouse text processing tools for the tokenization and detokenization steps (Dchelotte et al., 2008) and our system is built in “true-case”. As German is morphologically more complex than English, the default policy which consists in treating each word form independently is plagued with data sparsity, which is detrimental both at training and decoding time. Thus, the German side was normalized using a specific pre-processing scheme (described in (Allauzen et al., 2010; Durgar ElKahlout and Yvon, 2010)), which notably aims at reducing the lexical redundancy by (i) normalizing the orthography, (ii) neutralizing most inflections and (iii) splitting complex compounds. 2.4 • Named entities are re"
W13-2223,2011.iwslt-papers.5,1,0.849659,"processed by splitting German compound words with the frequencybased method described in (Koehn and Knight, 2003). To further reduce translation complexity for the phrase-based approach, we performed the long-range part-of-speech based reordering rules proposed by (Popovi´c et al., 2006). 2.2.3 The in-house phrase-based decoder (Vogel, 2003) is used to perform decoding. Optimization with regard to the BLEU score is done using Minimum Error Rate Training (MERT) as described in Venugopal et al. (2005). 2.1.2 Translation Model We applied filtering and weighting for domainadaptation similarly to (Mansour et al., 2011) and (Mansour and Ney, 2012). For filtering the bilingual data, a combination of LM and IBM Model 1 scores was used. In addition, we performed weighted phrase extraction by using a combined LM and IBM Model 1 weight. 2.2.4 Reordering Model We applied part-of-speech (POS) based reordering using probabilistic continuous (Rottmann and Vogel, 2007) and discontinuous (Niehues and Kolss, 2009) rules. This was learned using POS tags generated by the TreeTagger (Schmid, 1994) for short and long range reorderings respectively. In addition to this POS-based reordering, we also used tree-based reordering"
W13-2223,J06-4004,0,0.0399278,"Missing"
W13-2223,D09-1022,1,0.905747,"Missing"
W13-2223,D08-1089,0,0.0206813,"Wuebker et al., 2012) which is part of RWTH’s open-source SMT toolkit Jane 2.1 1 . GIZA++ (Och and Ney, 2003) was employed to train a word alignment, language models have been created with the SRILM toolkit (Stolcke, 2002). After phrase pair extraction from the wordaligned parallel corpus, the translation probabilities are estimated by relative frequencies. The standard feature set also includes an n-gram language model, phrase-level IBM-1 and word-, phrase- and distortion-penalties, which are combined in log-linear fashion. Furthermore, we used an additional reordering model as described in (Galley and Manning, 2008). By this model six 1 http://www-i6.informatik.rwth-aachen. de/jane/ 185 Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 185–192, c Sofia, Bulgaria, August 8-9, 2013 2013 Association for Computational Linguistics additional feature are added to the log-linear combination. The model weights are optimized with standard Mert (Och, 2003a) on 200-best lists. The optimization criterion is B LEU. cleaner corpora, EPPS and NC. Assuming that this corpus is very noisy, we biased our classifier more towards precision than recall. This was realized by giving higher number of f"
W13-2223,2011.iwslt-evaluation.9,1,0.888245,"ing data was preprocessed prior to the training. Symbols such as quotes, dashes and apostrophes are normalized. Then the first words of each sentence are smart-cased. For the German part of the training corpus, the hunspell2 lexicon was used, in order to learn a mapping from old German spelling to new German writing rules. Compound-splitting was also performed as described in Koehn and Knight (2003). We also removed very long sentences, empty lines, and sentences which show big mismatch on the length. 2.2.2 Filtering The web-crawled corpus was filtered using an SVM classifier as described in (Mediani et al., 2011). The lexica used in this filtering task were obtained from Giza alignments trained on the 2.2.5 Translation Models The translation model uses the parallel data of EPPS, NC, and the filtered web-crawled data. As word alignment, we used the Discriminative Word Alignment (DWA) as shown in (Niehues and Vo2 http://hunspell.sourceforge.net/ 186 gel, 2008). The phrase pairs were extracted using different source word order suggested by the POSbased reordering models presented previously as described in (Niehues et al., 2009). In order to extend the context of source language words, we applied a bilin"
W13-2223,W09-0435,1,0.861514,"ith regard to the BLEU score is done using Minimum Error Rate Training (MERT) as described in Venugopal et al. (2005). 2.1.2 Translation Model We applied filtering and weighting for domainadaptation similarly to (Mansour et al., 2011) and (Mansour and Ney, 2012). For filtering the bilingual data, a combination of LM and IBM Model 1 scores was used. In addition, we performed weighted phrase extraction by using a combined LM and IBM Model 1 weight. 2.2.4 Reordering Model We applied part-of-speech (POS) based reordering using probabilistic continuous (Rottmann and Vogel, 2007) and discontinuous (Niehues and Kolss, 2009) rules. This was learned using POS tags generated by the TreeTagger (Schmid, 1994) for short and long range reorderings respectively. In addition to this POS-based reordering, we also used tree-based reordering rules. Syntactic parse trees of the whole training corpus and the word alignment between source and target language are used to learn rules on how to reorder the constituents in a German source sentence to make it match the English target sentence word order better (Herrmann et al., 2013). The training corpus was parsed by the Stanford parser (Rafferty and Manning, 2008). The reordering"
W13-2223,W08-0303,1,0.903038,"Missing"
W13-2223,N04-4026,0,0.016377,"y so that we only used the words that occur in the n-best list but not in the reference as negative example. a n-gram model of (source,target) pairs (Casacuberta and Vidal, 2004). Training this model requires to reorder source sentences so as to match the target word order. This is performed by a stochastic finite-state reordering model, which uses part-of-speech information4 to generalize reordering patterns beyond lexical regularities. In addition to the translation model, eleven feature functions are combined: a target-language model; four lexicon models; two lexicalized reordering models (Tillmann, 2004) aiming at predicting the orientation of the next translation unit; a ’weak’ distance-based distortion model; and finally a word-bonus model and a tuple-bonus model which compensate for the system preference for short translations. The four lexicon models are similar to the ones use in a standard phrase based system: two scores correspond to the relative frequencies of the tuples and two lexical weights estimated from the automatically generated word alignments. The weights associated to feature functions are optimally combined using a discriminative training framework (Och, 2003b). The overal"
W13-2223,W09-0413,1,0.842391,"The web-crawled corpus was filtered using an SVM classifier as described in (Mediani et al., 2011). The lexica used in this filtering task were obtained from Giza alignments trained on the 2.2.5 Translation Models The translation model uses the parallel data of EPPS, NC, and the filtered web-crawled data. As word alignment, we used the Discriminative Word Alignment (DWA) as shown in (Niehues and Vo2 http://hunspell.sourceforge.net/ 186 gel, 2008). The phrase pairs were extracted using different source word order suggested by the POSbased reordering models presented previously as described in (Niehues et al., 2009). In order to extend the context of source language words, we applied a bilingual language model (Niehues et al., 2011). A Discriminative Word Lexicon (DWL) introduced in (Mauser et al., 2009) was extended so that it could take the source context also into the account. For this, we used a bag-of-ngrams instead of representing the source sentence as a bag-of-words. Filtering based on counts was then applied to the features for higher order n-grams. In addition to this, the training examples were created differently so that we only used the words that occur in the n-best list but not in the refe"
W13-2223,W05-0836,1,0.864882,"filtering task). 2.1.1 Preprocessing In order to reduce the source vocabulary size translation, the German text was preprocessed by splitting German compound words with the frequencybased method described in (Koehn and Knight, 2003). To further reduce translation complexity for the phrase-based approach, we performed the long-range part-of-speech based reordering rules proposed by (Popovi´c et al., 2006). 2.2.3 The in-house phrase-based decoder (Vogel, 2003) is used to perform decoding. Optimization with regard to the BLEU score is done using Minimum Error Rate Training (MERT) as described in Venugopal et al. (2005). 2.1.2 Translation Model We applied filtering and weighting for domainadaptation similarly to (Mansour et al., 2011) and (Mansour and Ney, 2012). For filtering the bilingual data, a combination of LM and IBM Model 1 scores was used. In addition, we performed weighted phrase extraction by using a combined LM and IBM Model 1 weight. 2.2.4 Reordering Model We applied part-of-speech (POS) based reordering using probabilistic continuous (Rottmann and Vogel, 2007) and discontinuous (Niehues and Kolss, 2009) rules. This was learned using POS tags generated by the TreeTagger (Schmid, 1994) for short"
W13-2223,W11-2124,1,0.875547,"this filtering task were obtained from Giza alignments trained on the 2.2.5 Translation Models The translation model uses the parallel data of EPPS, NC, and the filtered web-crawled data. As word alignment, we used the Discriminative Word Alignment (DWA) as shown in (Niehues and Vo2 http://hunspell.sourceforge.net/ 186 gel, 2008). The phrase pairs were extracted using different source word order suggested by the POSbased reordering models presented previously as described in (Niehues et al., 2009). In order to extend the context of source language words, we applied a bilingual language model (Niehues et al., 2011). A Discriminative Word Lexicon (DWL) introduced in (Mauser et al., 2009) was extended so that it could take the source context also into the account. For this, we used a bag-of-ngrams instead of representing the source sentence as a bag-of-words. Filtering based on counts was then applied to the features for higher order n-grams. In addition to this, the training examples were created differently so that we only used the words that occur in the n-best list but not in the reference as negative example. a n-gram model of (source,target) pairs (Casacuberta and Vidal, 2004). Training this model r"
W13-2223,C12-3061,1,0.817205,"e of the four project partners. Each group develop and maintain their own different machine translation system. These single systems differ not only in their general approach, but also in the preprocessing of training and test data. To take advantage of these differences of each translation system, we combined all hypotheses of the different systems, using the RWTH system combination approach. This paper is structured as follows. First, the different engines of all four groups are introduced. RWTH Aachen Single System For the WMT 2013 evaluation, RWTH utilized a phrase-based decoder based on (Wuebker et al., 2012) which is part of RWTH’s open-source SMT toolkit Jane 2.1 1 . GIZA++ (Och and Ney, 2003) was employed to train a word alignment, language models have been created with the SRILM toolkit (Stolcke, 2002). After phrase pair extraction from the wordaligned parallel corpus, the translation probabilities are estimated by relative frequencies. The standard feature set also includes an n-gram language model, phrase-level IBM-1 and word-, phrase- and distortion-penalties, which are combined in log-linear fashion. Furthermore, we used an additional reordering model as described in (Galley and Manning, 2"
W13-2223,J03-1002,1,0.00903936,"translation system. These single systems differ not only in their general approach, but also in the preprocessing of training and test data. To take advantage of these differences of each translation system, we combined all hypotheses of the different systems, using the RWTH system combination approach. This paper is structured as follows. First, the different engines of all four groups are introduced. RWTH Aachen Single System For the WMT 2013 evaluation, RWTH utilized a phrase-based decoder based on (Wuebker et al., 2012) which is part of RWTH’s open-source SMT toolkit Jane 2.1 1 . GIZA++ (Och and Ney, 2003) was employed to train a word alignment, language models have been created with the SRILM toolkit (Stolcke, 2002). After phrase pair extraction from the wordaligned parallel corpus, the translation probabilities are estimated by relative frequencies. The standard feature set also includes an n-gram language model, phrase-level IBM-1 and word-, phrase- and distortion-penalties, which are combined in log-linear fashion. Furthermore, we used an additional reordering model as described in (Galley and Manning, 2008). By this model six 1 http://www-i6.informatik.rwth-aachen. de/jane/ 185 Proceedings"
W13-2223,P03-1021,0,0.694457,"models (Tillmann, 2004) aiming at predicting the orientation of the next translation unit; a ’weak’ distance-based distortion model; and finally a word-bonus model and a tuple-bonus model which compensate for the system preference for short translations. The four lexicon models are similar to the ones use in a standard phrase based system: two scores correspond to the relative frequencies of the tuples and two lexical weights estimated from the automatically generated word alignments. The weights associated to feature functions are optimally combined using a discriminative training framework (Och, 2003b). The overall search is based on a beam-search strategy on top of a dynamic programming algorithm. Reordering hypotheses are computed in a preprocessing step, making use of reordering rules built from the word reorderings introduced in the tuple extraction process. The resulting reordering hypotheses are passed to the decoder in the form of word lattices (Crego and Mario, 2006). 2.2.6 Language Models We build separate language models and combined them prior to decoding. As word-token based language models, one language model is built on EPPS, NC, and giga corpus, while another one is built u"
W13-2223,W08-1006,0,0.0614361,"and discontinuous (Niehues and Kolss, 2009) rules. This was learned using POS tags generated by the TreeTagger (Schmid, 1994) for short and long range reorderings respectively. In addition to this POS-based reordering, we also used tree-based reordering rules. Syntactic parse trees of the whole training corpus and the word alignment between source and target language are used to learn rules on how to reorder the constituents in a German source sentence to make it match the English target sentence word order better (Herrmann et al., 2013). The training corpus was parsed by the Stanford parser (Rafferty and Manning, 2008). The reordering rules are applied to the source sentences and the reordered sentence variants as well as the original sequence are encoded in a word lattice which is used as input to the decoder. Moreover, our reordering model was extended so that it could include the features of lexicalized reordering model. The reordering probabilities for each phrase pair are stored as well as the original position of each word in the lattice. During the decoding, the reordering origin of the words is checked along with its probability added as an additional score. 2.1.3 Language Model During decoding a 4-"
W13-2223,2007.tmi-papers.21,0,0.168794,") is used to perform decoding. Optimization with regard to the BLEU score is done using Minimum Error Rate Training (MERT) as described in Venugopal et al. (2005). 2.1.2 Translation Model We applied filtering and weighting for domainadaptation similarly to (Mansour et al., 2011) and (Mansour and Ney, 2012). For filtering the bilingual data, a combination of LM and IBM Model 1 scores was used. In addition, we performed weighted phrase extraction by using a combined LM and IBM Model 1 weight. 2.2.4 Reordering Model We applied part-of-speech (POS) based reordering using probabilistic continuous (Rottmann and Vogel, 2007) and discontinuous (Niehues and Kolss, 2009) rules. This was learned using POS tags generated by the TreeTagger (Schmid, 1994) for short and long range reorderings respectively. In addition to this POS-based reordering, we also used tree-based reordering rules. Syntactic parse trees of the whole training corpus and the word alignment between source and target language are used to learn rules on how to reorder the constituents in a German source sentence to make it match the English target sentence word order better (Herrmann et al., 2013). The training corpus was parsed by the Stanford parser"
W13-2223,W12-3140,1,\N,Missing
W13-2223,W11-2135,0,\N,Missing
W13-2223,W10-1704,0,\N,Missing
W13-2258,W12-3125,0,0.0598878,"ases. The only difference is that length constraints are applied to phrases, but not to blocks. Figure 1 illustrates the extraction of monotone, swap, and discontinuous orientation classes in left-to-right direction from word-aligned bilingual training samples. The right-to-left direction works analogously. p(O) = P N (O) O0 ∈{M,S,D} N (O We found that this concept can be neatly plugged into the hierarchical phrase-based translation paradigm, without having to resort to approximations in decoding, which is necessary to determine the right-to-left orientation in a standard phrase-based system (Cherry et al., 2012). To train the orientations, the extraction procedure from the standard phrase-based version of the reordering model can be used with a minor extension. The model is trained on the same word-aligned data from which the translation rules are extracted. For each training sentence, we extract all phrases of unlimited length that are consistent with the word alignment, and store their corners in a matrix. The corners are distinguished by their location: topleft, top-right, bottom-left, and bottom-right. For each bilingual phrase, we determine its left-toright and right-to-left orientation by check"
W13-2258,P05-1033,0,0.878427,"sequence and a distortion cost that is computed from the sourceside jump distances. Though the space of admissible reorderings is in most cases contrained by a maximum jump width or coverage-based restrictions (Zens et al., 2004) for efficiency reasons, the basic approach of arbitrarily jumping to uncovered positions on source side is still very permissive. Lexicalized reordering models assist the decoder in taking a good decision. Phrase-based decoding allows for a straightforward integration of lexicalized reordering models which assign Introduction In hierarchical phrase-based translation (Chiang, 2005), a probabilistic synchronous context-free grammar (SCFG) is induced from bilingual training corpora. In addition to continuous lexical phrases as in standard phrase-based translation, hierarchical phrases with usually up to two nonterminals are extracted from the word-aligned parallel training data. Hierarchical decoding is typically carried out with a parsing-based procedure. The parsing algorithm is extended to handle translation candi452 Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 452–463, c Sofia, Bulgaria, August 8-9, 2013 2013 Association for Computation"
W13-2258,J07-2003,0,0.404938,"(with 1 ≤ j1 ≤ j2 ≤ J and 1 ≤ i1 ≤ i2 ≤ I) is consistent with respect to the word alignment A ⊆ {1, ..., I} × {1, ..., J} iff (1) is engrafted into the hierarchical grammar, as well as a special glue rule S → hS ∼0 X ∼1 , S ∼0 X ∼1 i Modeling Phrase Orientation for Hierarchical Machine Translation (2) that the system can use for serial concatenation of phrases as in monotonic phrase-based translation. The initial symbol S is the start symbol of the grammar. Hierarchical search is conducted with a customized version of the CYK+ parsing algorithm (Chappelier and Rajman, 1998) and cube pruning (Chiang, 2007). A hypergraph which represents the whole parsing space is built employing CYK+. Cube pruning operates in bottom-up topological order on this hypergraph and expands at most k derivations at each hypernode. ∃(i, j) ∈ A : i1 ≤ i ≤ i2 ∧ j1 ≤ j ≤ j2 ∧ ∀(i, j) ∈ A : i1 ≤ i ≤ i2 ↔ j1 ≤ j ≤ j2 . (3) Consistency is based upon two conditions in this definition: (1.) At least one source and target position within the block must be aligned, and (2.) words from inside the source interval may only be aligned to words from inside the target interval and vice versa. These are the same conditions as those tha"
W13-2258,D08-1089,0,0.729017,"archical decoding is typically carried out with a parsing-based procedure. The parsing algorithm is extended to handle translation candi452 Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 452–463, c Sofia, Bulgaria, August 8-9, 2013 2013 Association for Computational Linguistics 2 different scores depending on how a currently translated phrase has been reordered with respect to its context. Popular lexicalized reordering models for phrase-based translation distinguish three orientation classes: monotone, swap, and discontinuous (Tillmann, 2004; Koehn et al., 2007; Galley and Manning, 2008). To obtain such a model, scores for the three classes are calculated from the counts of the respective orientation occurrences in the word-aligned training data for each extracted phrase. The left-to-right orientation of phrases during phrase-based search can be easily determined from the start and end positions of continuous phrases. Approximations may need to be adopted for the right-to-left scoring direction. The utility of phrase orientation models in standard phrase-based translation is plausible and has been empirically established in practice. In hierarchical phrase-based translation,"
W13-2258,D08-1039,1,0.911341,"Missing"
W13-2258,C10-1050,0,0.464037,"urrences in the word-aligned training data for each extracted phrase. The left-to-right orientation of phrases during phrase-based search can be easily determined from the start and end positions of continuous phrases. Approximations may need to be adopted for the right-to-left scoring direction. The utility of phrase orientation models in standard phrase-based translation is plausible and has been empirically established in practice. In hierarchical phrase-based translation, some other types of lexicalized reordering models have been investigated recently (He et al., 2010a; He et al., 2010b; Hayashi et al., 2010; Huck et al., 2012a), but in none of them are the orientation scores conditioned on the lexical identity of each phrase individually. These models are rather word-based and applied on block boundaries. Experimental results obtained with these other types of lexicalized reordering models have been very encouraging, though. There are certain reasons why assessing the adequacy of phrase reordering should be useful in hierarchical search: Outline The remainder of the paper is structured as follows: We briefly outline important related publications in the following section. We subsequently give a"
W13-2258,2007.mtsummit-tutorials.1,0,0.054362,"Missing"
W13-2258,2010.amta-papers.25,0,0.16219,"ts of the respective orientation occurrences in the word-aligned training data for each extracted phrase. The left-to-right orientation of phrases during phrase-based search can be easily determined from the start and end positions of continuous phrases. Approximations may need to be adopted for the right-to-left scoring direction. The utility of phrase orientation models in standard phrase-based translation is plausible and has been empirically established in practice. In hierarchical phrase-based translation, some other types of lexicalized reordering models have been investigated recently (He et al., 2010a; He et al., 2010b; Hayashi et al., 2010; Huck et al., 2012a), but in none of them are the orientation scores conditioned on the lexical identity of each phrase individually. These models are rather word-based and applied on block boundaries. Experimental results obtained with these other types of lexicalized reordering models have been very encouraging, though. There are certain reasons why assessing the adequacy of phrase reordering should be useful in hierarchical search: Outline The remainder of the paper is structured as follows: We briefly outline important related publications in the f"
W13-2258,D10-1054,0,0.0770109,"ts of the respective orientation occurrences in the word-aligned training data for each extracted phrase. The left-to-right orientation of phrases during phrase-based search can be easily determined from the start and end positions of continuous phrases. Approximations may need to be adopted for the right-to-left scoring direction. The utility of phrase orientation models in standard phrase-based translation is plausible and has been empirically established in practice. In hierarchical phrase-based translation, some other types of lexicalized reordering models have been investigated recently (He et al., 2010a; He et al., 2010b; Hayashi et al., 2010; Huck et al., 2012a), but in none of them are the orientation scores conditioned on the lexical identity of each phrase individually. These models are rather word-based and applied on block boundaries. Experimental results obtained with these other types of lexicalized reordering models have been very encouraging, though. There are certain reasons why assessing the adequacy of phrase reordering should be useful in hierarchical search: Outline The remainder of the paper is structured as follows: We briefly outline important related publications in the f"
W13-2258,P02-1038,1,0.659361,"checking for adjacent corners. 0) (4) σ · p(O) + N (O|α, β) . P σ + O0 ∈{M,S,D} N (O0 |f˜, e˜) (5) Here, N (O) denotes the global count and N (O|α, β) the lexicalized count for the orientation O. σ is a smoothing constant. To determine the orientation frequency for a hierarchical phrase with non-terminal symbols, the orientation counts of all those phrases are accumulated from which a sub-phrase is cut out and replaced by a non-terminal symbol to obtain this hierarchical phrase. Figure 2 gives an example. Negative logarithms of the values are used as costs in the log-linear model combination (Och and Ney, 2002). Cost 0 for all orientations is assigned to the special rules which are not extracted from the training data (initial and glue rule). p(O|α, β) = 455 source source source f4 X~0 f3 f2 f1 f4 f3 f2 X~0 f1 f4 f3 X~0 f2 f1 e1 e2 e3 X~0 e4 e1 e2 e3 X~0 e4 e1 e2 X~0 e3 e4 target target target (a) Monotone non-terminal orientation. (b) Swap non-terminal orientation. (c) Discontinuous non-terminal orientation. Figure 3: Scoring with the orientation classes monotone, swap, and discontinuous. Each picture shows exactly one hierarchical phrase. The block which replaces the non-terminal X during decoding"
W13-2258,2011.iwslt-papers.1,1,0.881651,"Missing"
W13-2258,J03-1002,1,0.0154534,"an language pair using the standard WMT3 newstest sets for development and testing. 7.1 Experimental Setup We work with a Chinese–English parallel training corpus of 3.0 M sentence pairs (77.5 M Chinese / 81.0 M English running words). To train the German→French baseline system, we use 2.0 M sentence pairs (53.1 M French / 45.8 M German running words) that are partly taken from the Europarl corpus (Koehn, 2005) and have partly been collected within the Quaero project.4 Word alignments are created by aligning the data in both directions with GIZA++5 and symmetrizing the two trained alignments (Och and Ney, 2003). When extracting phrases, we apply several restrictions, in particular a maximum length of ten on source and target side for lexical phrases, a length limit of five on source and ten on target side for hierarchical phrases (including non-terminal symbols), and no more than two non-terminals per phrase. A standard set of models is used in the baselines, comprising phrase translation probabilities and lexical translation probabilities in both directions, word and phrase penalty, binary features marking hierarchical rules, glue rule, and rules 7.2 Chinese→English Experimental Results Table 1 com"
W13-2258,P03-1021,0,0.319883,"Delayed scoring can lead to search errors; in order to keep them confined, the delayed scoring needs to be done separately for all derivations, not just for the first-best subderivations along the incoming hyperedges. 7 with non-terminals at the boundaries, three simple count-based binary features, phrase length ratios, and a language model. The language models are 4-grams with modified Kneser-Ney smoothing (Kneser and Ney, 1995; Chen and Goodman, 1998) which have been trained with the SRILM toolkit (Stolcke, 2002). Model weights are optimized against B LEU (Papineni et al., 2002) with MERT (Och, 2003) on 100-best lists. For Chinese→English we employ MT06 as development set, MT08 is used as unseen test set. For German→French we employ newstest2009 as development set, newstest2008, newstest2010, and newstest2011 are used as unseen test sets. During decoding, a maximum length constraint of ten is applied to all non-terminals except the initial symbol S . Translation quality is measured in truecase with B LEU and T ER (Snover et al., 2006). The results on MT08 are checked for statistical significance over the baseline. Confidence intervals have been computed using bootstrapping for B LEU and C"
W13-2258,2012.eamt-1.66,1,0.901944,"ligned training data for each extracted phrase. The left-to-right orientation of phrases during phrase-based search can be easily determined from the start and end positions of continuous phrases. Approximations may need to be adopted for the right-to-left scoring direction. The utility of phrase orientation models in standard phrase-based translation is plausible and has been empirically established in practice. In hierarchical phrase-based translation, some other types of lexicalized reordering models have been investigated recently (He et al., 2010a; He et al., 2010b; Hayashi et al., 2010; Huck et al., 2012a), but in none of them are the orientation scores conditioned on the lexical identity of each phrase individually. These models are rather word-based and applied on block boundaries. Experimental results obtained with these other types of lexicalized reordering models have been very encouraging, though. There are certain reasons why assessing the adequacy of phrase reordering should be useful in hierarchical search: Outline The remainder of the paper is structured as follows: We briefly outline important related publications in the following section. We subsequently give a summary of some ess"
W13-2258,P02-1040,0,0.0871338,"nd the correct actual costs added. Delayed scoring can lead to search errors; in order to keep them confined, the delayed scoring needs to be done separately for all derivations, not just for the first-best subderivations along the incoming hyperedges. 7 with non-terminals at the boundaries, three simple count-based binary features, phrase length ratios, and a language model. The language models are 4-grams with modified Kneser-Ney smoothing (Kneser and Ney, 1995; Chen and Goodman, 1998) which have been trained with the SRILM toolkit (Stolcke, 2002). Model weights are optimized against B LEU (Papineni et al., 2002) with MERT (Och, 2003) on 100-best lists. For Chinese→English we employ MT06 as development set, MT08 is used as unseen test set. For German→French we employ newstest2009 as development set, newstest2008, newstest2010, and newstest2011 are used as unseen test sets. During decoding, a maximum length constraint of ten is applied to all non-terminals except the initial symbol S . Translation quality is measured in truecase with B LEU and T ER (Snover et al., 2006). The results on MT08 are checked for statistical significance over the baseline. Confidence intervals have been computed using bootstr"
W13-2258,2006.amta-papers.25,0,0.0243919,"; Chen and Goodman, 1998) which have been trained with the SRILM toolkit (Stolcke, 2002). Model weights are optimized against B LEU (Papineni et al., 2002) with MERT (Och, 2003) on 100-best lists. For Chinese→English we employ MT06 as development set, MT08 is used as unseen test set. For German→French we employ newstest2009 as development set, newstest2008, newstest2010, and newstest2011 are used as unseen test sets. During decoding, a maximum length constraint of ten is applied to all non-terminals except the initial symbol S . Translation quality is measured in truecase with B LEU and T ER (Snover et al., 2006). The results on MT08 are checked for statistical significance over the baseline. Confidence intervals have been computed using bootstrapping for B LEU and Cochran’s approximate ratio variance for T ER (Leusch and Ney, 2009). Experiments We evaluate the effect of phrase orientation scoring in hierarchical translation on the Chinese→English 2008 NIST task2 and on the French→German language pair using the standard WMT3 newstest sets for development and testing. 7.1 Experimental Setup We work with a Chinese–English parallel training corpus of 3.0 M sentence pairs (77.5 M Chinese / 81.0 M English"
W13-2258,2010.amta-papers.8,1,0.873547,"Missing"
W13-2258,N03-1017,0,0.0994991,"Missing"
W13-2258,P07-2045,0,0.0460072,"training data. Hierarchical decoding is typically carried out with a parsing-based procedure. The parsing algorithm is extended to handle translation candi452 Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 452–463, c Sofia, Bulgaria, August 8-9, 2013 2013 Association for Computational Linguistics 2 different scores depending on how a currently translated phrase has been reordered with respect to its context. Popular lexicalized reordering models for phrase-based translation distinguish three orientation classes: monotone, swap, and discontinuous (Tillmann, 2004; Koehn et al., 2007; Galley and Manning, 2008). To obtain such a model, scores for the three classes are calculated from the counts of the respective orientation occurrences in the word-aligned training data for each extracted phrase. The left-to-right orientation of phrases during phrase-based search can be easily determined from the start and end positions of continuous phrases. Approximations may need to be adopted for the right-to-left scoring direction. The utility of phrase orientation models in standard phrase-based translation is plausible and has been empirically established in practice. In hierarchical"
W13-2258,N04-4026,0,0.178256,"aligned parallel training data. Hierarchical decoding is typically carried out with a parsing-based procedure. The parsing algorithm is extended to handle translation candi452 Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 452–463, c Sofia, Bulgaria, August 8-9, 2013 2013 Association for Computational Linguistics 2 different scores depending on how a currently translated phrase has been reordered with respect to its context. Popular lexicalized reordering models for phrase-based translation distinguish three orientation classes: monotone, swap, and discontinuous (Tillmann, 2004; Koehn et al., 2007; Galley and Manning, 2008). To obtain such a model, scores for the three classes are calculated from the counts of the respective orientation occurrences in the word-aligned training data for each extracted phrase. The left-to-right orientation of phrases during phrase-based search can be easily determined from the start and end positions of continuous phrases. Approximations may need to be adopted for the right-to-left scoring direction. The utility of phrase orientation models in standard phrase-based translation is plausible and has been empirically established in pract"
W13-2258,D09-1105,0,0.121503,"ientations. Empirical results are presented in Section 7. We conclude the paper in Section 8. 3 Related Work Hierarchical phrase-based translation was proposed by Chiang (2005). He et al. (2010a) integrated a maximum entropy based lexicalized reordering model with word- and class-based features. Different classifiers for different rule patterns are trained for their model (He et al., 2010b). A comparable discriminatively trained model which applies a single classifier for all types of rules was developed by Huck et al. (2012a). Hayashi et al. (2010) explored the word-based reordering model by Tromble and Eisner (2009) in hierarchical translation. For standard phrase-based translation, Galley and Manning (2008) introduced a hierarchical phrase orientation model. Similar to previous approaches (Tillmann, 2004; Koehn et al., 2007), it distinguishes the three orientation classes monotone, swap, and discontinuous. However, it differs in that it is not limited to model local reordering phenomena, but allows for phrases to be hierarchically combined into blocks in order to determine the orientation class. This has the advantage that probability mass is shifted from the rather uninformative default category discon"
W13-2258,2005.mtsummit-papers.11,0,0.023636,"o variance for T ER (Leusch and Ney, 2009). Experiments We evaluate the effect of phrase orientation scoring in hierarchical translation on the Chinese→English 2008 NIST task2 and on the French→German language pair using the standard WMT3 newstest sets for development and testing. 7.1 Experimental Setup We work with a Chinese–English parallel training corpus of 3.0 M sentence pairs (77.5 M Chinese / 81.0 M English running words). To train the German→French baseline system, we use 2.0 M sentence pairs (53.1 M French / 45.8 M German running words) that are partly taken from the Europarl corpus (Koehn, 2005) and have partly been collected within the Quaero project.4 Word alignments are created by aligning the data in both directions with GIZA++5 and symmetrizing the two trained alignments (Och and Ney, 2003). When extracting phrases, we apply several restrictions, in particular a maximum length of ten on source and target side for lexical phrases, a length limit of five on source and ten on target side for hierarchical phrases (including non-terminal symbols), and no more than two non-terminals per phrase. A standard set of models is used in the baselines, comprising phrase translation probabilit"
W13-2258,N09-1027,0,0.0732795,"Missing"
W13-2258,W10-1738,1,0.928383,"Missing"
W13-2258,2008.iwslt-papers.8,1,0.880264,"Missing"
W13-2258,C04-1030,1,0.828,"model is to assess the adequacy of phrase reordering during search. In standard phrase-based translation with continuous phrases only and left-to-right hypothesis generation (Koehn et al., 2003; Zens and Ney, 2008), phrase reordering is implemented by jumps within the input sentence. The choice of the best order for the target sequence is made based on the language model score of this sequence and a distortion cost that is computed from the sourceside jump distances. Though the space of admissible reorderings is in most cases contrained by a maximum jump width or coverage-based restrictions (Zens et al., 2004) for efficiency reasons, the basic approach of arbitrarily jumping to uncovered positions on source side is still very permissive. Lexicalized reordering models assist the decoder in taking a good decision. Phrase-based decoding allows for a straightforward integration of lexicalized reordering models which assign Introduction In hierarchical phrase-based translation (Chiang, 2005), a probabilistic synchronous context-free grammar (SCFG) is induced from bilingual training corpora. In addition to continuous lexical phrases as in standard phrase-based translation, hierarchical phrases with usual"
W13-2258,D09-1022,1,\N,Missing
W13-2258,D08-1076,0,\N,Missing
W14-3310,E14-2008,1,0.50059,"nburgh, Scotland † Karlsruhe Institute of Technology, Karlsruhe, Germany ∗ {freitag,peitz,wuebker,ney}@cs.rwth-aachen.de ‡ {mhuck,ndurrani,pkoehn}@inf.ed.ac.uk ‡ v1rsennr@staffmail.ed.ac.uk ‡ maria.nadejde@gmail.com,p.j.williams-2@sms.ed.ac.uk † {teresa.herrmann,eunah.cho,alex.waibel}@kit.edu ‡ Matthias Abstract joint WMT submission of three EU-BRIDGE project partners. RWTH Aachen University (RWTH), the University of Edinburgh (UEDIN) and Karlsruhe Institute of Technology (KIT) all provided several individual systems which were combined by means of the RWTH Aachen system combination approach (Freitag et al., 2014). As distinguished from our EU-BRIDGE joint submission to the IWSLT 2013 evaluation campaign (Freitag et al., 2013), we particularly focused on translation of news text (instead of talks) for WMT. Besides, we put an emphasis on engineering syntaxbased systems in order to combine them with our more established phrase-based engines. We built combined system setups for translation from German to English as well as from English to German. This paper gives some insight into the technology behind the system combination framework and the combined engines which have been used to produce the joint EU-B"
W14-3310,D08-1089,0,0.0336771,"sequence model over cluster IDs. Furthermore, it learns OSM models over POS, morph and word classes. et al., 2010; Wuebker et al., 2012). The model weights of all systems have been tuned with standard Minimum Error Rate Training (Och, 2003) on a concatenation of the newstest2011 and newstest2012 sets. RWTH used B LEU as optimization objective. Both for language model estimation and querying at decoding, the KenLM toolkit (Heafield et al., 2013) is used. All RWTH systems include the standard set of models provided by Jane. Both systems have been augmented with a hierarchical orientation model (Galley and Manning, 2008; Huck et al., 2013) and a cluster language model (Wuebker et al., 2013). The phrasebased system (RWTH scss) has been further improved by maximum expected B LEU training similar to (He and Deng, 2012). The latter has been performed on a selection from the News Commentary, Europarl and Common Crawl corpora based on language and translation model cross-entropies (Mansour et al., 2011). 3 3.2 UEDIN’s syntax-based systems (Williams et al., 2014) follow the GHKM syntax approach as proposed by Galley, Hopkins, Knight, and Marcu (Galley et al., 2004). The open source Moses implementation has been emp"
W14-3310,N04-1035,0,0.0285873,"gmented with a hierarchical orientation model (Galley and Manning, 2008; Huck et al., 2013) and a cluster language model (Wuebker et al., 2013). The phrasebased system (RWTH scss) has been further improved by maximum expected B LEU training similar to (He and Deng, 2012). The latter has been performed on a selection from the News Commentary, Europarl and Common Crawl corpora based on language and translation model cross-entropies (Mansour et al., 2011). 3 3.2 UEDIN’s syntax-based systems (Williams et al., 2014) follow the GHKM syntax approach as proposed by Galley, Hopkins, Knight, and Marcu (Galley et al., 2004). The open source Moses implementation has been employed to extract GHKM rules (Williams and Koehn, 2012). Composed rules (Galley et al., 2006) are extracted in addition to minimal rules, but only up to the following limits: at most twenty tree nodes per rule, a maximum depth of five, and a maximum size of five. Singleton hierarchical rules are dropped. The features for the syntax-based systems comprise Good-Turing-smoothed phrase translation probabilities, lexical translation probabilities in both directions, word and phrase penalty, a rule rareness penalty, a monolingual PCFG probability, an"
W14-3310,P05-1066,1,0.0515024,"employs both the phrase-based (RWTH scss) and the hierarchical (RWTH hiero) decoder implemented in RWTH’s publicly available translation toolkit Jane (Vilar 1 http://www.eu-bridge.eu 105 Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 105–113, c Baltimore, Maryland USA, June 26–27, 2014. 2014 Association for Computational Linguistics els over POS and morph sequences following Durrani et al. (2013c). The English→German system additionally comprises a target-side LM over automatically built word classes (Birch et al., 2013). UEDIN has applied syntactic prereordering (Collins et al., 2005) and compound splitting (Koehn and Knight, 2003) of the source side for the German→English system. The systems have been tuned on a very large tuning set consisting of the test sets from 2008-2012, with a total of 13,071 sentences. UEDIN used newstest2013 as held-out test set. On top of UEDIN phrase-based 1 system, UEDIN phrase-based 2 augments word classes as additional factor and learns an interpolated target sequence model over cluster IDs. Furthermore, it learns OSM models over POS, morph and word classes. et al., 2010; Wuebker et al., 2012). The model weights of all systems have been tune"
W14-3310,P06-1121,0,0.0128251,". The phrasebased system (RWTH scss) has been further improved by maximum expected B LEU training similar to (He and Deng, 2012). The latter has been performed on a selection from the News Commentary, Europarl and Common Crawl corpora based on language and translation model cross-entropies (Mansour et al., 2011). 3 3.2 UEDIN’s syntax-based systems (Williams et al., 2014) follow the GHKM syntax approach as proposed by Galley, Hopkins, Knight, and Marcu (Galley et al., 2004). The open source Moses implementation has been employed to extract GHKM rules (Williams and Koehn, 2012). Composed rules (Galley et al., 2006) are extracted in addition to minimal rules, but only up to the following limits: at most twenty tree nodes per rule, a maximum depth of five, and a maximum size of five. Singleton hierarchical rules are dropped. The features for the syntax-based systems comprise Good-Turing-smoothed phrase translation probabilities, lexical translation probabilities in both directions, word and phrase penalty, a rule rareness penalty, a monolingual PCFG probability, and a 5-gram language model. UEDIN has used the SRILM toolkit (Stolcke, 2002) to train the language model and relies on KenLM for language model"
W14-3310,P13-2071,1,0.0664637,"ction 2 EU-BRIDGE1 is a European research project which is aimed at developing innovative speech translation technology. This paper describes a RWTH Aachen University RWTH (Peitz et al., 2014) employs both the phrase-based (RWTH scss) and the hierarchical (RWTH hiero) decoder implemented in RWTH’s publicly available translation toolkit Jane (Vilar 1 http://www.eu-bridge.eu 105 Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 105–113, c Baltimore, Maryland USA, June 26–27, 2014. 2014 Association for Computational Linguistics els over POS and morph sequences following Durrani et al. (2013c). The English→German system additionally comprises a target-side LM over automatically built word classes (Birch et al., 2013). UEDIN has applied syntactic prereordering (Collins et al., 2005) and compound splitting (Koehn and Knight, 2003) of the source side for the German→English system. The systems have been tuned on a very large tuning set consisting of the test sets from 2008-2012, with a total of 13,071 sentences. UEDIN used newstest2013 as held-out test set. On top of UEDIN phrase-based 1 system, UEDIN phrase-based 2 augments word classes as additional factor and learns an interpolate"
W14-3310,2012.iwslt-papers.17,1,0.805256,".1 Syntax-based Systems Phrase-based Systems UEDIN’s phrase-based systems (Durrani et al., 2014) have been trained using the Moses toolkit (Koehn et al., 2007), replicating the settings described in (Durrani et al., 2013b). The features include: a maximum sentence length of 80, growdiag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5gram language model with KenLM (Heafield, 2011) used at runtime, a lexically-driven 5-gram operation sequence model (OSM) (Durrani et al., 2013a), msd-bidirectional-fe lexicalized reordering, sparse lexical and domain features (Hasler et al., 2012), a distortion limit of 6, a maximum phrase length of 5, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004), cube pruning (Huang and Chiang, 2007), with a stack size of 1000 during tuning and 5000 during testing and the no-reordering-overpunctuation heuristic. UEDIN uses POS and morphological target sequence models built on the indomain subset of the parallel corpus using KneserNey smoothed 7-gram models as additional factors in phrase translation models (Koehn and Hoang, 2007). UEDIN has furthermore built OSM mod106 model. The monolingual part of those parallel"
W14-3310,W13-2212,1,0.898684,"ction 2 EU-BRIDGE1 is a European research project which is aimed at developing innovative speech translation technology. This paper describes a RWTH Aachen University RWTH (Peitz et al., 2014) employs both the phrase-based (RWTH scss) and the hierarchical (RWTH hiero) decoder implemented in RWTH’s publicly available translation toolkit Jane (Vilar 1 http://www.eu-bridge.eu 105 Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 105–113, c Baltimore, Maryland USA, June 26–27, 2014. 2014 Association for Computational Linguistics els over POS and morph sequences following Durrani et al. (2013c). The English→German system additionally comprises a target-side LM over automatically built word classes (Birch et al., 2013). UEDIN has applied syntactic prereordering (Collins et al., 2005) and compound splitting (Koehn and Knight, 2003) of the source side for the German→English system. The systems have been tuned on a very large tuning set consisting of the test sets from 2008-2012, with a total of 13,071 sentences. UEDIN used newstest2013 as held-out test set. On top of UEDIN phrase-based 1 system, UEDIN phrase-based 2 augments word classes as additional factor and learns an interpolate"
W14-3310,P12-1031,0,0.00714997,"um Error Rate Training (Och, 2003) on a concatenation of the newstest2011 and newstest2012 sets. RWTH used B LEU as optimization objective. Both for language model estimation and querying at decoding, the KenLM toolkit (Heafield et al., 2013) is used. All RWTH systems include the standard set of models provided by Jane. Both systems have been augmented with a hierarchical orientation model (Galley and Manning, 2008; Huck et al., 2013) and a cluster language model (Wuebker et al., 2013). The phrasebased system (RWTH scss) has been further improved by maximum expected B LEU training similar to (He and Deng, 2012). The latter has been performed on a selection from the News Commentary, Europarl and Common Crawl corpora based on language and translation model cross-entropies (Mansour et al., 2011). 3 3.2 UEDIN’s syntax-based systems (Williams et al., 2014) follow the GHKM syntax approach as proposed by Galley, Hopkins, Knight, and Marcu (Galley et al., 2004). The open source Moses implementation has been employed to extract GHKM rules (Williams and Koehn, 2012). Composed rules (Galley et al., 2006) are extracted in addition to minimal rules, but only up to the following limits: at most twenty tree nodes"
W14-3310,P13-2121,1,0.0604984,"Missing"
W14-3310,W14-3309,1,0.840972,"btained high sentence-level B LEU scores when being translated with a baseline phrasebased system, and each contain less than 30 words for more rapid tuning. Decoding for the syntaxbased systems is carried out with cube pruning using Moses’ hierarchical decoder (Hoang et al., 2009). UEDIN’s German→English syntax-based setup is a string-to-tree system with compound splitting University of Edinburgh UEDIN contributed phrase-based and syntaxbased systems to both the German→English and the English→German joint submission. 3.1 Syntax-based Systems Phrase-based Systems UEDIN’s phrase-based systems (Durrani et al., 2014) have been trained using the Moses toolkit (Koehn et al., 2007), replicating the settings described in (Durrani et al., 2013b). The features include: a maximum sentence length of 80, growdiag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5gram language model with KenLM (Heafield, 2011) used at runtime, a lexically-driven 5-gram operation sequence model (OSM) (Durrani et al., 2013a), msd-bidirectional-fe lexicalized reordering, sparse lexical and domain features (Hasler et al., 2012), a distortion limit of 6, a maximum phrase length of 5, 100-best translatio"
W14-3310,W11-2123,0,0.00995075,"a string-to-tree system with compound splitting University of Edinburgh UEDIN contributed phrase-based and syntaxbased systems to both the German→English and the English→German joint submission. 3.1 Syntax-based Systems Phrase-based Systems UEDIN’s phrase-based systems (Durrani et al., 2014) have been trained using the Moses toolkit (Koehn et al., 2007), replicating the settings described in (Durrani et al., 2013b). The features include: a maximum sentence length of 80, growdiag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5gram language model with KenLM (Heafield, 2011) used at runtime, a lexically-driven 5-gram operation sequence model (OSM) (Durrani et al., 2013a), msd-bidirectional-fe lexicalized reordering, sparse lexical and domain features (Hasler et al., 2012), a distortion limit of 6, a maximum phrase length of 5, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004), cube pruning (Huang and Chiang, 2007), with a stack size of 1000 during tuning and 5000 during testing and the no-reordering-overpunctuation heuristic. UEDIN uses POS and morphological target sequence models built on the indomain subset of the parallel corpus"
W14-3310,W06-1607,0,0.0222136,"., 2013). It uses a modified syntactic label set, target-side compound splitting, and additional syntactic constraints. UEDIN GHKM S2T (BitPar): A string-to-tree system trained with target-side syntactic annotation obtained with BitPar (Schmid, 2004). The word alignment for German→English is generated using the GIZA++ toolkit (Och and Ney, 2003). For English→German, KIT uses discriminative word alignment (Niehues and Vogel, 2008). Phrase extraction and scoring is done using the Moses toolkit (Koehn et al., 2007). Phrase pair probabilities are computed using modified KneserNey smoothing as in (Foster et al., 2006). UEDIN GHKM S2T (Stanford): A string-totree system trained with target-side syntactic annotation obtained with the German Stanford Parser (Rafferty and Manning, 2008a). In both systems KIT applies short-range reorderings (Rottmann and Vogel, 2007) and longrange reorderings (Niehues and Kolss, 2009) based on POS tags (Schmid, 1994) to perform source sentence reordering according to the target language word order. The long-range reordering rules are applied to the training corpus to create reordering lattices to extract the phrases for the translation model. In addition, a tree-based reordering"
W14-3310,W13-0805,1,0.0274022,"GHKM S2T (Stanford): A string-totree system trained with target-side syntactic annotation obtained with the German Stanford Parser (Rafferty and Manning, 2008a). In both systems KIT applies short-range reorderings (Rottmann and Vogel, 2007) and longrange reorderings (Niehues and Kolss, 2009) based on POS tags (Schmid, 1994) to perform source sentence reordering according to the target language word order. The long-range reordering rules are applied to the training corpus to create reordering lattices to extract the phrases for the translation model. In addition, a tree-based reordering model (Herrmann et al., 2013) trained on syntactic parse trees (Rafferty and Manning, 2008b; Klein and Manning, 2003) as well as a lexicalized reordering model (Koehn et al., 2005) are applied. UEDIN GHKM S2T (Berkeley): A string-totree system trained with target-side syntactic annotation obtained with the German Berkeley Parser (Petrov and Klein, 2007; Petrov and Klein, 2008). UEDIN GHKM T2S (Berkeley): A tree-tostring system trained with source-side syntactic annotation obtained with the English Berkeley Parser (Petrov et al., 2006). UEDIN GHKM S2S (Berkeley): A string-tostring system. The extraction is GHKMbased with s"
W14-3310,2011.iwslt-papers.5,1,0.681344,"rying at decoding, the KenLM toolkit (Heafield et al., 2013) is used. All RWTH systems include the standard set of models provided by Jane. Both systems have been augmented with a hierarchical orientation model (Galley and Manning, 2008; Huck et al., 2013) and a cluster language model (Wuebker et al., 2013). The phrasebased system (RWTH scss) has been further improved by maximum expected B LEU training similar to (He and Deng, 2012). The latter has been performed on a selection from the News Commentary, Europarl and Common Crawl corpora based on language and translation model cross-entropies (Mansour et al., 2011). 3 3.2 UEDIN’s syntax-based systems (Williams et al., 2014) follow the GHKM syntax approach as proposed by Galley, Hopkins, Knight, and Marcu (Galley et al., 2004). The open source Moses implementation has been employed to extract GHKM rules (Williams and Koehn, 2012). Composed rules (Galley et al., 2006) are extracted in addition to minimal rules, but only up to the following limits: at most twenty tree nodes per rule, a maximum depth of five, and a maximum size of five. Singleton hierarchical rules are dropped. The features for the syntax-based systems comprise Good-Turing-smoothed phrase t"
W14-3310,2009.iwslt-papers.4,1,0.346713,"bility, and a 5-gram language model. UEDIN has used the SRILM toolkit (Stolcke, 2002) to train the language model and relies on KenLM for language model scoring during decoding. Model weights are optimized to maximize B LEU. 2000 sentences from the newstest2008-2012 sets have been selected as a development set. The selected sentences obtained high sentence-level B LEU scores when being translated with a baseline phrasebased system, and each contain less than 30 words for more rapid tuning. Decoding for the syntaxbased systems is carried out with cube pruning using Moses’ hierarchical decoder (Hoang et al., 2009). UEDIN’s German→English syntax-based setup is a string-to-tree system with compound splitting University of Edinburgh UEDIN contributed phrase-based and syntaxbased systems to both the German→English and the English→German joint submission. 3.1 Syntax-based Systems Phrase-based Systems UEDIN’s phrase-based systems (Durrani et al., 2014) have been trained using the Moses toolkit (Koehn et al., 2007), replicating the settings described in (Durrani et al., 2013b). The features include: a maximum sentence length of 80, growdiag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser"
W14-3310,D09-1022,1,0.0473567,"ingle generic nonterminal instead of syntactic ones, plus rules that have been added from plain phrase-based extraction (Huck et al., 2014). 4 Language models are trained with the SRILM toolkit (Stolcke, 2002) and use modified KneserNey smoothing. Both systems utilize a language model based on automatically learned word classes using the MKCLS algorithm (Och, 1999). The English→German system comprises language models based on fine-grained part-ofspeech tags (Schmid and Laws, 2008). In addition, a bilingual language model (Niehues et al., 2011) is used as well as a discriminative word lexicon (Mauser et al., 2009) using source context to guide the word choices in the target sentence. Karlsruhe Institute of Technology The KIT translations (Herrmann et al., 2014) are generated by an in-house phrase-based translations system (Vogel, 2003). The provided News Commentary, Europarl, and Common Crawl parallel corpora are used for training the translation 107 dividual system engines have been optimized on different test sets which partially or fully include newstest2011 or newstest2012. System combination weights are either optimized on newstest2011 or newstest2012. We kept newstest2013 as an unseen test set wh"
W14-3310,P07-1019,0,0.0254758,"he settings described in (Durrani et al., 2013b). The features include: a maximum sentence length of 80, growdiag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5gram language model with KenLM (Heafield, 2011) used at runtime, a lexically-driven 5-gram operation sequence model (OSM) (Durrani et al., 2013a), msd-bidirectional-fe lexicalized reordering, sparse lexical and domain features (Hasler et al., 2012), a distortion limit of 6, a maximum phrase length of 5, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004), cube pruning (Huang and Chiang, 2007), with a stack size of 1000 during tuning and 5000 during testing and the no-reordering-overpunctuation heuristic. UEDIN uses POS and morphological target sequence models built on the indomain subset of the parallel corpus using KneserNey smoothed 7-gram models as additional factors in phrase translation models (Koehn and Hoang, 2007). UEDIN has furthermore built OSM mod106 model. The monolingual part of those parallel corpora, the News Shuffle corpus for both directions and additionally the Gigaword corpus for German→English are used as monolingual training data for the different language mod"
W14-3310,2011.iwslt-evaluation.9,1,0.882056,"n, UEDIN has trained various string-to-tree GHKM syntax systems which differ with respect to the syntactic annotation. A tree-to-string system and a string-to-string system (with rules that are not syntactically decorated) have been trained as well. The English→German UEDIN GHKM system names in Table 3 denote: Compound splitting (Koehn and Knight, 2003) is performed on the source side of the corpus for German→English translation before training. In order to improve the quality of the web-crawled Common Crawl corpus, noisy sentence pairs are filtered out using an SVM classifier as described by Mediani et al. (2011). UEDIN GHKM S2T (ParZu): A string-to-tree system trained with target-side syntactic annotation obtained with ParZu (Sennrich et al., 2013). It uses a modified syntactic label set, target-side compound splitting, and additional syntactic constraints. UEDIN GHKM S2T (BitPar): A string-to-tree system trained with target-side syntactic annotation obtained with BitPar (Schmid, 2004). The word alignment for German→English is generated using the GIZA++ toolkit (Och and Ney, 2003). For English→German, KIT uses discriminative word alignment (Niehues and Vogel, 2008). Phrase extraction and scoring is d"
W14-3310,W13-2258,1,0.0602517,"r IDs. Furthermore, it learns OSM models over POS, morph and word classes. et al., 2010; Wuebker et al., 2012). The model weights of all systems have been tuned with standard Minimum Error Rate Training (Och, 2003) on a concatenation of the newstest2011 and newstest2012 sets. RWTH used B LEU as optimization objective. Both for language model estimation and querying at decoding, the KenLM toolkit (Heafield et al., 2013) is used. All RWTH systems include the standard set of models provided by Jane. Both systems have been augmented with a hierarchical orientation model (Galley and Manning, 2008; Huck et al., 2013) and a cluster language model (Wuebker et al., 2013). The phrasebased system (RWTH scss) has been further improved by maximum expected B LEU training similar to (He and Deng, 2012). The latter has been performed on a selection from the News Commentary, Europarl and Common Crawl corpora based on language and translation model cross-entropies (Mansour et al., 2011). 3 3.2 UEDIN’s syntax-based systems (Williams et al., 2014) follow the GHKM syntax approach as proposed by Galley, Hopkins, Knight, and Marcu (Galley et al., 2004). The open source Moses implementation has been employed to extract GHK"
W14-3310,P10-2041,0,0.0226125,"for tuning the system combination or any of the individual systems. In total, the English→German system uses the following language models: two 4-gram wordbased language models trained on the parallel data and the filtered Common Crawl data separately, two 5-gram POS-based language models trained on the same data as the word-based language models, and a 4-gram cluster-based language model trained on 1,000 MKCLS word classes. The German→English system uses a 4-gram word-based language model trained on all monolingual data and an additional language model trained on automatically selected data (Moore and Lewis, 2010). Again, a 4-gram cluster-based language model trained on 1000 MKCLS word classes is applied. 5 6.1 The automatic scores of all individual systems as well as of our final system combination submission are given in Table 1. KIT, UEDIN and RWTH are each providing one individual phrasebased system output. RWTH (hiero) and UEDIN (GHKM) are providing additional systems based on the hierarchical translation model and a stringto-tree syntax model. The pairwise difference of the single system performances is up to 1.3 points in B LEU and 2.5 points in T ER. For German→English, our system combination p"
W14-3310,W14-3362,1,0.700694,"ned with the German Berkeley Parser (Petrov and Klein, 2007; Petrov and Klein, 2008). UEDIN GHKM T2S (Berkeley): A tree-tostring system trained with source-side syntactic annotation obtained with the English Berkeley Parser (Petrov et al., 2006). UEDIN GHKM S2S (Berkeley): A string-tostring system. The extraction is GHKMbased with syntactic target-side annotation from the German Berkeley Parser, but we strip off the syntactic labels. The final grammar contains rules with a single generic nonterminal instead of syntactic ones, plus rules that have been added from plain phrase-based extraction (Huck et al., 2014). 4 Language models are trained with the SRILM toolkit (Stolcke, 2002) and use modified KneserNey smoothing. Both systems utilize a language model based on automatically learned word classes using the MKCLS algorithm (Och, 1999). The English→German system comprises language models based on fine-grained part-ofspeech tags (Schmid and Laws, 2008). In addition, a bilingual language model (Niehues et al., 2011) is used as well as a discriminative word lexicon (Mauser et al., 2009) using source context to guide the word choices in the target sentence. Karlsruhe Institute of Technology The KIT trans"
W14-3310,W09-0435,0,0.00463497,"erated using the GIZA++ toolkit (Och and Ney, 2003). For English→German, KIT uses discriminative word alignment (Niehues and Vogel, 2008). Phrase extraction and scoring is done using the Moses toolkit (Koehn et al., 2007). Phrase pair probabilities are computed using modified KneserNey smoothing as in (Foster et al., 2006). UEDIN GHKM S2T (Stanford): A string-totree system trained with target-side syntactic annotation obtained with the German Stanford Parser (Rafferty and Manning, 2008a). In both systems KIT applies short-range reorderings (Rottmann and Vogel, 2007) and longrange reorderings (Niehues and Kolss, 2009) based on POS tags (Schmid, 1994) to perform source sentence reordering according to the target language word order. The long-range reordering rules are applied to the training corpus to create reordering lattices to extract the phrases for the translation model. In addition, a tree-based reordering model (Herrmann et al., 2013) trained on syntactic parse trees (Rafferty and Manning, 2008b; Klein and Manning, 2003) as well as a lexicalized reordering model (Koehn et al., 2005) are applied. UEDIN GHKM S2T (Berkeley): A string-totree system trained with target-side syntactic annotation obtained"
W14-3310,P03-1054,0,0.00425242,"ion obtained with the German Stanford Parser (Rafferty and Manning, 2008a). In both systems KIT applies short-range reorderings (Rottmann and Vogel, 2007) and longrange reorderings (Niehues and Kolss, 2009) based on POS tags (Schmid, 1994) to perform source sentence reordering according to the target language word order. The long-range reordering rules are applied to the training corpus to create reordering lattices to extract the phrases for the translation model. In addition, a tree-based reordering model (Herrmann et al., 2013) trained on syntactic parse trees (Rafferty and Manning, 2008b; Klein and Manning, 2003) as well as a lexicalized reordering model (Koehn et al., 2005) are applied. UEDIN GHKM S2T (Berkeley): A string-totree system trained with target-side syntactic annotation obtained with the German Berkeley Parser (Petrov and Klein, 2007; Petrov and Klein, 2008). UEDIN GHKM T2S (Berkeley): A tree-tostring system trained with source-side syntactic annotation obtained with the English Berkeley Parser (Petrov et al., 2006). UEDIN GHKM S2S (Berkeley): A string-tostring system. The extraction is GHKMbased with syntactic target-side annotation from the German Berkeley Parser, but we strip off the sy"
W14-3310,W08-0303,0,0.0192279,"sing an SVM classifier as described by Mediani et al. (2011). UEDIN GHKM S2T (ParZu): A string-to-tree system trained with target-side syntactic annotation obtained with ParZu (Sennrich et al., 2013). It uses a modified syntactic label set, target-side compound splitting, and additional syntactic constraints. UEDIN GHKM S2T (BitPar): A string-to-tree system trained with target-side syntactic annotation obtained with BitPar (Schmid, 2004). The word alignment for German→English is generated using the GIZA++ toolkit (Och and Ney, 2003). For English→German, KIT uses discriminative word alignment (Niehues and Vogel, 2008). Phrase extraction and scoring is done using the Moses toolkit (Koehn et al., 2007). Phrase pair probabilities are computed using modified KneserNey smoothing as in (Foster et al., 2006). UEDIN GHKM S2T (Stanford): A string-totree system trained with target-side syntactic annotation obtained with the German Stanford Parser (Rafferty and Manning, 2008a). In both systems KIT applies short-range reorderings (Rottmann and Vogel, 2007) and longrange reorderings (Niehues and Kolss, 2009) based on POS tags (Schmid, 1994) to perform source sentence reordering according to the target language word ord"
W14-3310,D07-1091,1,0.0290057,"2013a), msd-bidirectional-fe lexicalized reordering, sparse lexical and domain features (Hasler et al., 2012), a distortion limit of 6, a maximum phrase length of 5, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004), cube pruning (Huang and Chiang, 2007), with a stack size of 1000 during tuning and 5000 during testing and the no-reordering-overpunctuation heuristic. UEDIN uses POS and morphological target sequence models built on the indomain subset of the parallel corpus using KneserNey smoothed 7-gram models as additional factors in phrase translation models (Koehn and Hoang, 2007). UEDIN has furthermore built OSM mod106 model. The monolingual part of those parallel corpora, the News Shuffle corpus for both directions and additionally the Gigaword corpus for German→English are used as monolingual training data for the different language models. Optimization is done with Minimum Error Rate Training as described in (Venugopal et al., 2005), using newstest2012 and newstest2013 as development and test data respectively. on the German source-language side and syntactic annotation from the Berkeley Parser (Petrov et al., 2006) on the English target-language side. For English→"
W14-3310,E03-1076,1,0.31096,"the hierarchical (RWTH hiero) decoder implemented in RWTH’s publicly available translation toolkit Jane (Vilar 1 http://www.eu-bridge.eu 105 Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 105–113, c Baltimore, Maryland USA, June 26–27, 2014. 2014 Association for Computational Linguistics els over POS and morph sequences following Durrani et al. (2013c). The English→German system additionally comprises a target-side LM over automatically built word classes (Birch et al., 2013). UEDIN has applied syntactic prereordering (Collins et al., 2005) and compound splitting (Koehn and Knight, 2003) of the source side for the German→English system. The systems have been tuned on a very large tuning set consisting of the test sets from 2008-2012, with a total of 13,071 sentences. UEDIN used newstest2013 as held-out test set. On top of UEDIN phrase-based 1 system, UEDIN phrase-based 2 augments word classes as additional factor and learns an interpolated target sequence model over cluster IDs. Furthermore, it learns OSM models over POS, morph and word classes. et al., 2010; Wuebker et al., 2012). The model weights of all systems have been tuned with standard Minimum Error Rate Training (Och"
W14-3310,W11-2124,1,0.0228284,"trip off the syntactic labels. The final grammar contains rules with a single generic nonterminal instead of syntactic ones, plus rules that have been added from plain phrase-based extraction (Huck et al., 2014). 4 Language models are trained with the SRILM toolkit (Stolcke, 2002) and use modified KneserNey smoothing. Both systems utilize a language model based on automatically learned word classes using the MKCLS algorithm (Och, 1999). The English→German system comprises language models based on fine-grained part-ofspeech tags (Schmid and Laws, 2008). In addition, a bilingual language model (Niehues et al., 2011) is used as well as a discriminative word lexicon (Mauser et al., 2009) using source context to guide the word choices in the target sentence. Karlsruhe Institute of Technology The KIT translations (Herrmann et al., 2014) are generated by an in-house phrase-based translations system (Vogel, 2003). The provided News Commentary, Europarl, and Common Crawl parallel corpora are used for training the translation 107 dividual system engines have been optimized on different test sets which partially or fully include newstest2011 or newstest2012. System combination weights are either optimized on news"
W14-3310,2005.iwslt-1.8,1,0.035532,"2008a). In both systems KIT applies short-range reorderings (Rottmann and Vogel, 2007) and longrange reorderings (Niehues and Kolss, 2009) based on POS tags (Schmid, 1994) to perform source sentence reordering according to the target language word order. The long-range reordering rules are applied to the training corpus to create reordering lattices to extract the phrases for the translation model. In addition, a tree-based reordering model (Herrmann et al., 2013) trained on syntactic parse trees (Rafferty and Manning, 2008b; Klein and Manning, 2003) as well as a lexicalized reordering model (Koehn et al., 2005) are applied. UEDIN GHKM S2T (Berkeley): A string-totree system trained with target-side syntactic annotation obtained with the German Berkeley Parser (Petrov and Klein, 2007; Petrov and Klein, 2008). UEDIN GHKM T2S (Berkeley): A tree-tostring system trained with source-side syntactic annotation obtained with the English Berkeley Parser (Petrov et al., 2006). UEDIN GHKM S2S (Berkeley): A string-tostring system. The extraction is GHKMbased with syntactic target-side annotation from the German Berkeley Parser, but we strip off the syntactic labels. The final grammar contains rules with a single"
W14-3310,J03-1002,1,0.0147027,"of the web-crawled Common Crawl corpus, noisy sentence pairs are filtered out using an SVM classifier as described by Mediani et al. (2011). UEDIN GHKM S2T (ParZu): A string-to-tree system trained with target-side syntactic annotation obtained with ParZu (Sennrich et al., 2013). It uses a modified syntactic label set, target-side compound splitting, and additional syntactic constraints. UEDIN GHKM S2T (BitPar): A string-to-tree system trained with target-side syntactic annotation obtained with BitPar (Schmid, 2004). The word alignment for German→English is generated using the GIZA++ toolkit (Och and Ney, 2003). For English→German, KIT uses discriminative word alignment (Niehues and Vogel, 2008). Phrase extraction and scoring is done using the Moses toolkit (Koehn et al., 2007). Phrase pair probabilities are computed using modified KneserNey smoothing as in (Foster et al., 2006). UEDIN GHKM S2T (Stanford): A string-totree system trained with target-side syntactic annotation obtained with the German Stanford Parser (Rafferty and Manning, 2008a). In both systems KIT applies short-range reorderings (Rottmann and Vogel, 2007) and longrange reorderings (Niehues and Kolss, 2009) based on POS tags (Schmid,"
W14-3310,E99-1010,0,0.0419329,"l., 2006). UEDIN GHKM S2S (Berkeley): A string-tostring system. The extraction is GHKMbased with syntactic target-side annotation from the German Berkeley Parser, but we strip off the syntactic labels. The final grammar contains rules with a single generic nonterminal instead of syntactic ones, plus rules that have been added from plain phrase-based extraction (Huck et al., 2014). 4 Language models are trained with the SRILM toolkit (Stolcke, 2002) and use modified KneserNey smoothing. Both systems utilize a language model based on automatically learned word classes using the MKCLS algorithm (Och, 1999). The English→German system comprises language models based on fine-grained part-ofspeech tags (Schmid and Laws, 2008). In addition, a bilingual language model (Niehues et al., 2011) is used as well as a discriminative word lexicon (Mauser et al., 2009) using source context to guide the word choices in the target sentence. Karlsruhe Institute of Technology The KIT translations (Herrmann et al., 2014) are generated by an in-house phrase-based translations system (Vogel, 2003). The provided News Commentary, Europarl, and Common Crawl parallel corpora are used for training the translation 107 div"
W14-3310,P07-2045,1,0.0154876,"th a baseline phrasebased system, and each contain less than 30 words for more rapid tuning. Decoding for the syntaxbased systems is carried out with cube pruning using Moses’ hierarchical decoder (Hoang et al., 2009). UEDIN’s German→English syntax-based setup is a string-to-tree system with compound splitting University of Edinburgh UEDIN contributed phrase-based and syntaxbased systems to both the German→English and the English→German joint submission. 3.1 Syntax-based Systems Phrase-based Systems UEDIN’s phrase-based systems (Durrani et al., 2014) have been trained using the Moses toolkit (Koehn et al., 2007), replicating the settings described in (Durrani et al., 2013b). The features include: a maximum sentence length of 80, growdiag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5gram language model with KenLM (Heafield, 2011) used at runtime, a lexically-driven 5-gram operation sequence model (OSM) (Durrani et al., 2013a), msd-bidirectional-fe lexicalized reordering, sparse lexical and domain features (Hasler et al., 2012), a distortion limit of 6, a maximum phrase length of 5, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004),"
W14-3310,P03-1021,0,0.0102254,"03) of the source side for the German→English system. The systems have been tuned on a very large tuning set consisting of the test sets from 2008-2012, with a total of 13,071 sentences. UEDIN used newstest2013 as held-out test set. On top of UEDIN phrase-based 1 system, UEDIN phrase-based 2 augments word classes as additional factor and learns an interpolated target sequence model over cluster IDs. Furthermore, it learns OSM models over POS, morph and word classes. et al., 2010; Wuebker et al., 2012). The model weights of all systems have been tuned with standard Minimum Error Rate Training (Och, 2003) on a concatenation of the newstest2011 and newstest2012 sets. RWTH used B LEU as optimization objective. Both for language model estimation and querying at decoding, the KenLM toolkit (Heafield et al., 2013) is used. All RWTH systems include the standard set of models provided by Jane. Both systems have been augmented with a hierarchical orientation model (Galley and Manning, 2008; Huck et al., 2013) and a cluster language model (Wuebker et al., 2013). The phrasebased system (RWTH scss) has been further improved by maximum expected B LEU training similar to (He and Deng, 2012). The latter has"
W14-3310,W14-3317,1,0.820032,"ty, the University of Edinburgh, and Karlsruhe Institute of Technology developed several individual systems which serve as system combination input. We devoted special attention to building syntax-based systems and combining them with the phrasebased ones. The joint setups yield empirical gains of up to 1.6 points in B LEU and 1.0 points in T ER on the WMT newstest2013 test set compared to the best single systems. 1 Introduction 2 EU-BRIDGE1 is a European research project which is aimed at developing innovative speech translation technology. This paper describes a RWTH Aachen University RWTH (Peitz et al., 2014) employs both the phrase-based (RWTH scss) and the hierarchical (RWTH hiero) decoder implemented in RWTH’s publicly available translation toolkit Jane (Vilar 1 http://www.eu-bridge.eu 105 Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 105–113, c Baltimore, Maryland USA, June 26–27, 2014. 2014 Association for Computational Linguistics els over POS and morph sequences following Durrani et al. (2013c). The English→German system additionally comprises a target-side LM over automatically built word classes (Birch et al., 2013). UEDIN has applied syntactic prereordering"
W14-3310,N04-1022,0,0.063305,"it (Koehn et al., 2007), replicating the settings described in (Durrani et al., 2013b). The features include: a maximum sentence length of 80, growdiag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5gram language model with KenLM (Heafield, 2011) used at runtime, a lexically-driven 5-gram operation sequence model (OSM) (Durrani et al., 2013a), msd-bidirectional-fe lexicalized reordering, sparse lexical and domain features (Hasler et al., 2012), a distortion limit of 6, a maximum phrase length of 5, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004), cube pruning (Huang and Chiang, 2007), with a stack size of 1000 during tuning and 5000 during testing and the no-reordering-overpunctuation heuristic. UEDIN uses POS and morphological target sequence models built on the indomain subset of the parallel corpus using KneserNey smoothed 7-gram models as additional factors in phrase translation models (Koehn and Hoang, 2007). UEDIN has furthermore built OSM mod106 model. The monolingual part of those parallel corpora, the News Shuffle corpus for both directions and additionally the Gigaword corpus for German→English are used as monolingual train"
W14-3310,W10-1738,1,0.159493,"Missing"
W14-3310,W08-1005,0,0.0331415,"nce reordering according to the target language word order. The long-range reordering rules are applied to the training corpus to create reordering lattices to extract the phrases for the translation model. In addition, a tree-based reordering model (Herrmann et al., 2013) trained on syntactic parse trees (Rafferty and Manning, 2008b; Klein and Manning, 2003) as well as a lexicalized reordering model (Koehn et al., 2005) are applied. UEDIN GHKM S2T (Berkeley): A string-totree system trained with target-side syntactic annotation obtained with the German Berkeley Parser (Petrov and Klein, 2007; Petrov and Klein, 2008). UEDIN GHKM T2S (Berkeley): A tree-tostring system trained with source-side syntactic annotation obtained with the English Berkeley Parser (Petrov et al., 2006). UEDIN GHKM S2S (Berkeley): A string-tostring system. The extraction is GHKMbased with syntactic target-side annotation from the German Berkeley Parser, but we strip off the syntactic labels. The final grammar contains rules with a single generic nonterminal instead of syntactic ones, plus rules that have been added from plain phrase-based extraction (Huck et al., 2014). 4 Language models are trained with the SRILM toolkit (Stolcke, 2"
W14-3310,P06-1055,0,0.0182004,"dditional factors in phrase translation models (Koehn and Hoang, 2007). UEDIN has furthermore built OSM mod106 model. The monolingual part of those parallel corpora, the News Shuffle corpus for both directions and additionally the Gigaword corpus for German→English are used as monolingual training data for the different language models. Optimization is done with Minimum Error Rate Training as described in (Venugopal et al., 2005), using newstest2012 and newstest2013 as development and test data respectively. on the German source-language side and syntactic annotation from the Berkeley Parser (Petrov et al., 2006) on the English target-language side. For English→German, UEDIN has trained various string-to-tree GHKM syntax systems which differ with respect to the syntactic annotation. A tree-to-string system and a string-to-string system (with rules that are not syntactically decorated) have been trained as well. The English→German UEDIN GHKM system names in Table 3 denote: Compound splitting (Koehn and Knight, 2003) is performed on the source side of the corpus for German→English translation before training. In order to improve the quality of the web-crawled Common Crawl corpus, noisy sentence pairs ar"
W14-3310,W12-3150,1,0.544959,"uster language model (Wuebker et al., 2013). The phrasebased system (RWTH scss) has been further improved by maximum expected B LEU training similar to (He and Deng, 2012). The latter has been performed on a selection from the News Commentary, Europarl and Common Crawl corpora based on language and translation model cross-entropies (Mansour et al., 2011). 3 3.2 UEDIN’s syntax-based systems (Williams et al., 2014) follow the GHKM syntax approach as proposed by Galley, Hopkins, Knight, and Marcu (Galley et al., 2004). The open source Moses implementation has been employed to extract GHKM rules (Williams and Koehn, 2012). Composed rules (Galley et al., 2006) are extracted in addition to minimal rules, but only up to the following limits: at most twenty tree nodes per rule, a maximum depth of five, and a maximum size of five. Singleton hierarchical rules are dropped. The features for the syntax-based systems comprise Good-Turing-smoothed phrase translation probabilities, lexical translation probabilities in both directions, word and phrase penalty, a rule rareness penalty, a monolingual PCFG probability, and a 5-gram language model. UEDIN has used the SRILM toolkit (Stolcke, 2002) to train the language model a"
W14-3310,W08-1006,0,0.0232292,"e system trained with target-side syntactic annotation obtained with BitPar (Schmid, 2004). The word alignment for German→English is generated using the GIZA++ toolkit (Och and Ney, 2003). For English→German, KIT uses discriminative word alignment (Niehues and Vogel, 2008). Phrase extraction and scoring is done using the Moses toolkit (Koehn et al., 2007). Phrase pair probabilities are computed using modified KneserNey smoothing as in (Foster et al., 2006). UEDIN GHKM S2T (Stanford): A string-totree system trained with target-side syntactic annotation obtained with the German Stanford Parser (Rafferty and Manning, 2008a). In both systems KIT applies short-range reorderings (Rottmann and Vogel, 2007) and longrange reorderings (Niehues and Kolss, 2009) based on POS tags (Schmid, 1994) to perform source sentence reordering according to the target language word order. The long-range reordering rules are applied to the training corpus to create reordering lattices to extract the phrases for the translation model. In addition, a tree-based reordering model (Herrmann et al., 2013) trained on syntactic parse trees (Rafferty and Manning, 2008b; Klein and Manning, 2003) as well as a lexicalized reordering model (Koeh"
W14-3310,W14-3324,1,0.0949085,"Missing"
W14-3310,2007.tmi-papers.21,0,0.125992,", 2004). The word alignment for German→English is generated using the GIZA++ toolkit (Och and Ney, 2003). For English→German, KIT uses discriminative word alignment (Niehues and Vogel, 2008). Phrase extraction and scoring is done using the Moses toolkit (Koehn et al., 2007). Phrase pair probabilities are computed using modified KneserNey smoothing as in (Foster et al., 2006). UEDIN GHKM S2T (Stanford): A string-totree system trained with target-side syntactic annotation obtained with the German Stanford Parser (Rafferty and Manning, 2008a). In both systems KIT applies short-range reorderings (Rottmann and Vogel, 2007) and longrange reorderings (Niehues and Kolss, 2009) based on POS tags (Schmid, 1994) to perform source sentence reordering according to the target language word order. The long-range reordering rules are applied to the training corpus to create reordering lattices to extract the phrases for the translation model. In addition, a tree-based reordering model (Herrmann et al., 2013) trained on syntactic parse trees (Rafferty and Manning, 2008b; Klein and Manning, 2003) as well as a lexicalized reordering model (Koehn et al., 2005) are applied. UEDIN GHKM S2T (Berkeley): A string-totree system tra"
W14-3310,C12-3061,1,0.125144,"013). UEDIN has applied syntactic prereordering (Collins et al., 2005) and compound splitting (Koehn and Knight, 2003) of the source side for the German→English system. The systems have been tuned on a very large tuning set consisting of the test sets from 2008-2012, with a total of 13,071 sentences. UEDIN used newstest2013 as held-out test set. On top of UEDIN phrase-based 1 system, UEDIN phrase-based 2 augments word classes as additional factor and learns an interpolated target sequence model over cluster IDs. Furthermore, it learns OSM models over POS, morph and word classes. et al., 2010; Wuebker et al., 2012). The model weights of all systems have been tuned with standard Minimum Error Rate Training (Och, 2003) on a concatenation of the newstest2011 and newstest2012 sets. RWTH used B LEU as optimization objective. Both for language model estimation and querying at decoding, the KenLM toolkit (Heafield et al., 2013) is used. All RWTH systems include the standard set of models provided by Jane. Both systems have been augmented with a hierarchical orientation model (Galley and Manning, 2008; Huck et al., 2013) and a cluster language model (Wuebker et al., 2013). The phrasebased system (RWTH scss) has"
W14-3310,C08-1098,0,0.00933067,"target-side annotation from the German Berkeley Parser, but we strip off the syntactic labels. The final grammar contains rules with a single generic nonterminal instead of syntactic ones, plus rules that have been added from plain phrase-based extraction (Huck et al., 2014). 4 Language models are trained with the SRILM toolkit (Stolcke, 2002) and use modified KneserNey smoothing. Both systems utilize a language model based on automatically learned word classes using the MKCLS algorithm (Och, 1999). The English→German system comprises language models based on fine-grained part-ofspeech tags (Schmid and Laws, 2008). In addition, a bilingual language model (Niehues et al., 2011) is used as well as a discriminative word lexicon (Mauser et al., 2009) using source context to guide the word choices in the target sentence. Karlsruhe Institute of Technology The KIT translations (Herrmann et al., 2014) are generated by an in-house phrase-based translations system (Vogel, 2003). The provided News Commentary, Europarl, and Common Crawl parallel corpora are used for training the translation 107 dividual system engines have been optimized on different test sets which partially or fully include newstest2011 or newst"
W14-3310,D13-1138,1,0.0721313,", morph and word classes. et al., 2010; Wuebker et al., 2012). The model weights of all systems have been tuned with standard Minimum Error Rate Training (Och, 2003) on a concatenation of the newstest2011 and newstest2012 sets. RWTH used B LEU as optimization objective. Both for language model estimation and querying at decoding, the KenLM toolkit (Heafield et al., 2013) is used. All RWTH systems include the standard set of models provided by Jane. Both systems have been augmented with a hierarchical orientation model (Galley and Manning, 2008; Huck et al., 2013) and a cluster language model (Wuebker et al., 2013). The phrasebased system (RWTH scss) has been further improved by maximum expected B LEU training similar to (He and Deng, 2012). The latter has been performed on a selection from the News Commentary, Europarl and Common Crawl corpora based on language and translation model cross-entropies (Mansour et al., 2011). 3 3.2 UEDIN’s syntax-based systems (Williams et al., 2014) follow the GHKM syntax approach as proposed by Galley, Hopkins, Knight, and Marcu (Galley et al., 2004). The open source Moses implementation has been employed to extract GHKM rules (Williams and Koehn, 2012). Composed rules ("
W14-3310,C04-1024,0,0.0194264,"f the corpus for German→English translation before training. In order to improve the quality of the web-crawled Common Crawl corpus, noisy sentence pairs are filtered out using an SVM classifier as described by Mediani et al. (2011). UEDIN GHKM S2T (ParZu): A string-to-tree system trained with target-side syntactic annotation obtained with ParZu (Sennrich et al., 2013). It uses a modified syntactic label set, target-side compound splitting, and additional syntactic constraints. UEDIN GHKM S2T (BitPar): A string-to-tree system trained with target-side syntactic annotation obtained with BitPar (Schmid, 2004). The word alignment for German→English is generated using the GIZA++ toolkit (Och and Ney, 2003). For English→German, KIT uses discriminative word alignment (Niehues and Vogel, 2008). Phrase extraction and scoring is done using the Moses toolkit (Koehn et al., 2007). Phrase pair probabilities are computed using modified KneserNey smoothing as in (Foster et al., 2006). UEDIN GHKM S2T (Stanford): A string-totree system trained with target-side syntactic annotation obtained with the German Stanford Parser (Rafferty and Manning, 2008a). In both systems KIT applies short-range reorderings (Rottman"
W14-3310,R13-1079,1,0.28133,"stem and a string-to-string system (with rules that are not syntactically decorated) have been trained as well. The English→German UEDIN GHKM system names in Table 3 denote: Compound splitting (Koehn and Knight, 2003) is performed on the source side of the corpus for German→English translation before training. In order to improve the quality of the web-crawled Common Crawl corpus, noisy sentence pairs are filtered out using an SVM classifier as described by Mediani et al. (2011). UEDIN GHKM S2T (ParZu): A string-to-tree system trained with target-side syntactic annotation obtained with ParZu (Sennrich et al., 2013). It uses a modified syntactic label set, target-side compound splitting, and additional syntactic constraints. UEDIN GHKM S2T (BitPar): A string-to-tree system trained with target-side syntactic annotation obtained with BitPar (Schmid, 2004). The word alignment for German→English is generated using the GIZA++ toolkit (Och and Ney, 2003). For English→German, KIT uses discriminative word alignment (Niehues and Vogel, 2008). Phrase extraction and scoring is done using the Moses toolkit (Koehn et al., 2007). Phrase pair probabilities are computed using modified KneserNey smoothing as in (Foster e"
W14-3310,N07-1051,0,\N,Missing
W14-3310,W05-0836,1,\N,Missing
W14-3310,W05-0909,0,\N,Missing
W14-3310,N13-1001,1,\N,Missing
W14-3310,2010.iwslt-evaluation.11,1,\N,Missing
W14-3310,2013.iwslt-evaluation.16,1,\N,Missing
W14-3310,W13-2213,1,\N,Missing
W14-3310,W14-3313,1,\N,Missing
W14-3310,W11-2145,1,\N,Missing
W14-3310,2013.iwslt-evaluation.3,1,\N,Missing
W14-3324,D10-1063,0,0.0712692,"rench and Czech1 . We also experimented with random subsets of size 2,000. For the filtering technique, we make the assumption that finding suitable weights for all the feature functions requires the optimizer to see a range of feature values and to see hypotheses that can partially match the reference translations in order to rank the hypotheses. For example, if a Table 1: Parameter settings for rule composition. Further to the restrictions on rule composition, fully non-lexical unary rules were eliminated using the method described in Chung et al. (2011) and rules with scope greater than 3 (Hopkins and Langmead, 2010) were pruned from the translation grammar. Scope pruning makes parsing tractable without the need for grammar binarization. 2.3 Language Model We used all available monolingual data to train 5-gram language models. Language models for each monolingual corpus were trained using the SRILM toolkit (Stolcke, 2002) with modified Kneser-Ney smoothing (Chen and Goodman, 1998) and then interpolated using weights tuned to minimize perplexity on the development set. 2.4 Tuning Feature Functions Our feature functions are unchanged from the previous two years. They include the n-gram lan1 For Russian and"
W14-3324,N12-1047,0,0.0432105,"ons: • p (C, β |α, ∼) and p (α |C, β, ∼), the direct and indirect translation probabilities. • plex (β |α) and plex (α |β), the direct and indirect lexical weights (Koehn et al., 2003). • ppcfg (π), the monolingual PCFG probability of the tree fragment π from which the rule was extracted. • exp(−1/count(r)), a rule rareness penalty. • exp(1), a rule penalty. The main grammar and glue grammars have distinct penalty features. Value 5 20 5 2.5 The feature weights were tuned using the Moses implementation of MERT (Och, 2003) for all systems except English-to-German, for which we used k-best MIRA (Cherry and Foster, 2012) due to the larger number of features. We used tuning sentences drawn from all of the previous years’ test sets (except newstest2013, which was used as the development test set). In order to speed up the tuning process, we used subsets of the full tuning sets with sentence pairs up to length 30 (Max-30) and further applied a filtering technique to reduce the tuning set size to 2,000 sentence pairs for the language pairs involving German, French and Czech1 . We also experimented with random subsets of size 2,000. For the filtering technique, we make the assumption that finding suitable weights"
W14-3324,N03-1017,1,0.0126398,"ngs shown in Table 1, which were chosen empirically during the development of last years’ systems: Parameter Rule depth Node count Rule size C → hα, β, ∼i where C is a target-side non-terminal label, α is a string of source terminals and non-terminals, β is a string of target terminals and non-terminals, and ∼ is a one-to-one correspondence between source and target non-terminals, we score the rule according to the following functions: • p (C, β |α, ∼) and p (α |C, β, ∼), the direct and indirect translation probabilities. • plex (β |α) and plex (α |β), the direct and indirect lexical weights (Koehn et al., 2003). • ppcfg (π), the monolingual PCFG probability of the tree fragment π from which the rule was extracted. • exp(−1/count(r)), a rule rareness penalty. • exp(1), a rule penalty. The main grammar and glue grammars have distinct penalty features. Value 5 20 5 2.5 The feature weights were tuned using the Moses implementation of MERT (Och, 2003) for all systems except English-to-German, for which we used k-best MIRA (Cherry and Foster, 2012) due to the larger number of features. We used tuning sentences drawn from all of the previous years’ test sets (except newstest2013, which was used as the deve"
W14-3324,P11-2072,0,0.0390442,"sentence pairs for the language pairs involving German, French and Czech1 . We also experimented with random subsets of size 2,000. For the filtering technique, we make the assumption that finding suitable weights for all the feature functions requires the optimizer to see a range of feature values and to see hypotheses that can partially match the reference translations in order to rank the hypotheses. For example, if a Table 1: Parameter settings for rule composition. Further to the restrictions on rule composition, fully non-lexical unary rules were eliminated using the method described in Chung et al. (2011) and rules with scope greater than 3 (Hopkins and Langmead, 2010) were pruned from the translation grammar. Scope pruning makes parsing tractable without the need for grammar binarization. 2.3 Language Model We used all available monolingual data to train 5-gram language models. Language models for each monolingual corpus were trained using the SRILM toolkit (Stolcke, 2002) with modified Kneser-Ney smoothing (Chen and Goodman, 1998) and then interpolated using weights tuned to minimize perplexity on the development set. 2.4 Tuning Feature Functions Our feature functions are unchanged from the"
W14-3324,P07-2045,1,0.0160827,"of the parser. For the English-German system we used the default Moses tokenization scheme, which is similar to that of the German parsers. For the systems that translate into English, we used the Berkeley parser (Petrov et al., 2006; Petrov and Klein, 2007) to parse the target-side of the training corpus. As we will describe in Section 3, we tried a variety of parsers for German. We did not perform any corpus filtering other than the standard Moses method, which removes As last year (Nadejde et al., 2013), our systems are based on the string-to-tree pipeline implemented in the Moses toolkit (Koehn et al., 2007). We paid particular attention to the production of grammatical German, trying various parsers and incorporating target-side compound splitting and morphosyntactic constraints; for Hindi and Russian, we employed the new Moses transliteration model to handle out-of-vocabulary words; and for German to English, we experimented with tree binarization, obtaining good results from right binarization. We also present our first syntax-based results for French-English, the scale of which defeated us 207 Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 207–214, c Baltimore, Ma"
W14-3324,E14-4029,1,0.429224,"o English results on the devtest (newsdev2013) and test (newstest2014) sets. • passive clauses are not allowed to have accusative objects. 210 system baseline devtest 86,341,766 test 88,657,327 (OOV) input words are therefore a comparatively large source of translation error: in the devtest set (newsdev2014) and filtered test set (newstest2014) the average OOV rates are 1.08 and 1.16 unknown words per sentence, respectively. Assuming a significant fraction of OOV words to be named entities and thus amenable to transliteration, we applied the post-processing transliteration method described in Durrani et al. (2014) and implemented in Moses. In brief, this is an unsupervised method that i) uses EM to induce a corpus of transliteration examples from the parallel training data; ii) learns a monotone character-level phrasebased SMT model from the transliteration corpus; and iii) substitutes transliterations for OOVs in the system output by using the monolingual language model and other features to select between transliteration candidates.5 Table 10 shows B LEU scores with and without transliteration on the devtest and filtered test sets. Due to a bug in the submitted system, the language model trained on t"
W14-3324,W13-2221,1,0.776308,", we used the Moses tokenizer’s -penn option, which uses a tokenization scheme that more closely matches that of the parser. For the English-German system we used the default Moses tokenization scheme, which is similar to that of the German parsers. For the systems that translate into English, we used the Berkeley parser (Petrov et al., 2006; Petrov and Klein, 2007) to parse the target-side of the training corpus. As we will describe in Section 3, we tried a variety of parsers for German. We did not perform any corpus filtering other than the standard Moses method, which removes As last year (Nadejde et al., 2013), our systems are based on the string-to-tree pipeline implemented in the Moses toolkit (Koehn et al., 2007). We paid particular attention to the production of grammatical German, trying various parsers and incorporating target-side compound splitting and morphosyntactic constraints; for Hindi and Russian, we employed the new Moses transliteration model to handle out-of-vocabulary words; and for German to English, we experimented with tree binarization, obtaining good results from right binarization. We also present our first syntax-based results for French-English, the scale of which defeated"
W14-3324,N13-1073,0,0.0302293,"lative clauses must contain a relative (or interrogative) pronoun in their first constituent. Table 4 shows B LEU scores with systems trained with different parsers, and for our extensions of the baseline system. 4 Czech to English For Czech to English we used the core setup described in Section 2 without modification. Table 5 shows the B LEU scores. system baseline B LEU devtest test 24.8 27.0 Table 5: Czech to English results on the devtest (newstest2013) and test (newstest2014) sets. 5 French to English For French to English, alignment of the parallel corpus was performed using fast_align (Dyer et al., 2013) instead of MGIZA++ due to the large volume of parallel data. Table 6 shows B LEU scores for the system and Table 7 shows the resulting grammar sizes after filtering for the evaluation sets. • correct subcategorization of auxiliary/modal verbs in regards to the inflection of the full verb. system baseline B LEU devtest test 29.4 32.3 Table 6: French to English results on the devtest (newsdev2013) and test (newstest2014) sets. • passive clauses are not allowed to have accusative objects. 210 system baseline devtest 86,341,766 test 88,657,327 (OOV) input words are therefore a comparatively large"
W14-3324,W14-3310,1,0.0748258,"of Informatics, University of Edinburgh 2 Center for Speech and Language Processing, The Johns Hopkins University Abstract last year. This year we were able to train a system using all available training data, a task that was made considerably easier through principled filtering of the tuning set. Although our system was not ready in time for human evaluation, we present B LEU scores in this paper. In addition to the five single-system submissions described here, we also contributed our English-German and German-English systems for use in the collaborative EU-BRIDGE system combination effort (Freitag et al., 2014). This paper is organised as follows. In Section 2 we describe the core setup that is common to all systems. In subsequent sections we describe language-pair specific variations and extensions. For each language pair, we present results for both the development test set (newstest2013 in most cases) and for the filtered test set (newstest2014) that was provided after the system submission deadline. We refer to these as ‘devtest’ and ‘test’, respectively. This paper describes the string-to-tree systems built at the University of Edinburgh for the WMT 2014 shared translation task. We developed sy"
W14-3324,J03-1002,0,0.00637422,"he form sentence pairs with dubious length ratios and sentence pairs where parsing fails for the target-side sentence. 2.2 Translation Model Our translation grammar is a synchronous contextfree grammar (SCFG) with phrase-structure labels on the target side and the generic non-terminal label X on the source side. The grammar was extracted from the wordaligned parallel data using the Moses implementation (Williams and Koehn, 2012) of the GHKM algorithm (Galley et al., 2004; Galley et al., 2006). For word alignment we used MGIZA++ (Gao and Vogel, 2008), a multi-threaded implementation of GIZA++ (Och and Ney, 2003). Minimal GHKM rules were composed into larger rules subject to parameterized restrictions on size defined in terms of the resulting target tree fragment. A good choice of parameter settings depends on the annotation style of the target-side parse trees. We used the settings shown in Table 1, which were chosen empirically during the development of last years’ systems: Parameter Rule depth Node count Rule size C → hα, β, ∼i where C is a target-side non-terminal label, α is a string of source terminals and non-terminals, β is a string of target terminals and non-terminals, and ∼ is a one-to-one"
W14-3324,P03-1021,0,0.00672489,"source and target non-terminals, we score the rule according to the following functions: • p (C, β |α, ∼) and p (α |C, β, ∼), the direct and indirect translation probabilities. • plex (β |α) and plex (α |β), the direct and indirect lexical weights (Koehn et al., 2003). • ppcfg (π), the monolingual PCFG probability of the tree fragment π from which the rule was extracted. • exp(−1/count(r)), a rule rareness penalty. • exp(1), a rule penalty. The main grammar and glue grammars have distinct penalty features. Value 5 20 5 2.5 The feature weights were tuned using the Moses implementation of MERT (Och, 2003) for all systems except English-to-German, for which we used k-best MIRA (Cherry and Foster, 2012) due to the larger number of features. We used tuning sentences drawn from all of the previous years’ test sets (except newstest2013, which was used as the development test set). In order to speed up the tuning process, we used subsets of the full tuning sets with sentence pairs up to length 30 (Max-30) and further applied a filtering technique to reduce the tuning set size to 2,000 sentence pairs for the language pairs involving German, French and Czech1 . We also experimented with random subsets"
W14-3324,W10-1734,0,0.0101538,"cht Figure 1: Syntactic representation of split compound Bundesberufungsgericht (Engl: federal appeals court). B LEU devtest test 19.0 18.3 19.3 18.6 19.5 18.6 19.6 19.1 19.8 19.1 19.9 19.2 20.0 19.8 20.2 20.1 Table 4: English to German translation results on devtest (newstest2013) and test (newstest2014) sets. We discriminatively learn non-terminal labels for unknown words using sparse features, rather than estimating a probability distribution of nonterminal labels from singleton statistics in the training corpus. We perform target-side compound splitting, using a hybrid method described by Fritzinger and Fraser (2010) that combines a finite-state morphology and corpus statistics. As finite-state morphology analyzer, we use Zmorge (Sennrich and Kunz, 2014). An original contribution of our experiments is a syntactic representation of split compounds which eliminates typical problems with target-side compound splitting, namely erroneous reorderings and compound merging. We represent split compounds as a syntactic tree with the last segment as head, preceded by a modifier. A modifier consists of an optional modifier, a segment and a (possibly empty) joining element. An example is shown in Figure 1. This hierar"
W14-3324,N04-1035,0,0.0656309,"s word count, and various scores for the synchronous derivation. Each grammar rule has a number of precomputed scores. For a grammar rule r of the form sentence pairs with dubious length ratios and sentence pairs where parsing fails for the target-side sentence. 2.2 Translation Model Our translation grammar is a synchronous contextfree grammar (SCFG) with phrase-structure labels on the target side and the generic non-terminal label X on the source side. The grammar was extracted from the wordaligned parallel data using the Moses implementation (Williams and Koehn, 2012) of the GHKM algorithm (Galley et al., 2004; Galley et al., 2006). For word alignment we used MGIZA++ (Gao and Vogel, 2008), a multi-threaded implementation of GIZA++ (Och and Ney, 2003). Minimal GHKM rules were composed into larger rules subject to parameterized restrictions on size defined in terms of the resulting target tree fragment. A good choice of parameter settings depends on the annotation style of the target-side parse trees. We used the settings shown in Table 1, which were chosen empirically during the development of last years’ systems: Parameter Rule depth Node count Rule size C → hα, β, ∼i where C is a target-side non-t"
W14-3324,W08-1005,0,0.0619769,"e 19.2 19.2 19.1 19.4 De-En 26.9 27.0 27.2 27.0 Table 3: B LEU results on devtest and test sets with different tuning sets: Full, Max-30, filtered subsets of Max-30 and average of three random subsets of Max-30 (size of filtered/random subsets: 2,000). 3 English to German We use the projective output of the dependency parser ParZu (Sennrich et al., 2013) for the syntactic annotation of our primary submission. Contrastive systems were built with other parsers: BitPar (Schmid, 2004), the German Stanford Parser (Rafferty and Manning, 2008), and the German Berkeley Parser (Petrov and Klein, 2007; Petrov and Klein, 2008). The set of syntactic labels provided by ParZu has been refined to reduce overgeneralization phenomena. Specifically, we disambiguate the labels ROOT (used for the root of a sentence, but also commas, punctuation marks, and sentence fragments), KON and CJ (coordinations of different constituents), and GMOD (pre- or postmodifying genitive modifier). 2 These can be arbitrary tokens that do not match any reference token. 3 For random subsets from the full tuning set the performance was similar but resulted in standard deviations of up to 0.36 across three random sets. 4 Note however that due to"
W14-3324,P06-1121,0,0.026303,"ious scores for the synchronous derivation. Each grammar rule has a number of precomputed scores. For a grammar rule r of the form sentence pairs with dubious length ratios and sentence pairs where parsing fails for the target-side sentence. 2.2 Translation Model Our translation grammar is a synchronous contextfree grammar (SCFG) with phrase-structure labels on the target side and the generic non-terminal label X on the source side. The grammar was extracted from the wordaligned parallel data using the Moses implementation (Williams and Koehn, 2012) of the GHKM algorithm (Galley et al., 2004; Galley et al., 2006). For word alignment we used MGIZA++ (Gao and Vogel, 2008), a multi-threaded implementation of GIZA++ (Och and Ney, 2003). Minimal GHKM rules were composed into larger rules subject to parameterized restrictions on size defined in terms of the resulting target tree fragment. A good choice of parameter settings depends on the annotation style of the target-side parse trees. We used the settings shown in Table 1, which were chosen empirically during the development of last years’ systems: Parameter Rule depth Node count Rule size C → hα, β, ∼i where C is a target-side non-terminal label, α is a"
W14-3324,P06-1055,0,0.08415,"German • Czech-English • French-English 2 2.1 • German-English • Hindi-English • Russian-English System Overview Pre-processing The training data was normalized using the WMT normalize-punctuation.perl script then tokenized and truecased. Where the target language was English, we used the Moses tokenizer’s -penn option, which uses a tokenization scheme that more closely matches that of the parser. For the English-German system we used the default Moses tokenization scheme, which is similar to that of the German parsers. For the systems that translate into English, we used the Berkeley parser (Petrov et al., 2006; Petrov and Klein, 2007) to parse the target-side of the training corpus. As we will describe in Section 3, we tried a variety of parsers for German. We did not perform any corpus filtering other than the standard Moses method, which removes As last year (Nadejde et al., 2013), our systems are based on the string-to-tree pipeline implemented in the Moses toolkit (Koehn et al., 2007). We paid particular attention to the production of grammatical German, trying various parsers and incorporating target-side compound splitting and morphosyntactic constraints; for Hindi and Russian, we employed th"
W14-3324,W08-0509,0,0.0379218,"ule has a number of precomputed scores. For a grammar rule r of the form sentence pairs with dubious length ratios and sentence pairs where parsing fails for the target-side sentence. 2.2 Translation Model Our translation grammar is a synchronous contextfree grammar (SCFG) with phrase-structure labels on the target side and the generic non-terminal label X on the source side. The grammar was extracted from the wordaligned parallel data using the Moses implementation (Williams and Koehn, 2012) of the GHKM algorithm (Galley et al., 2004; Galley et al., 2006). For word alignment we used MGIZA++ (Gao and Vogel, 2008), a multi-threaded implementation of GIZA++ (Och and Ney, 2003). Minimal GHKM rules were composed into larger rules subject to parameterized restrictions on size defined in terms of the resulting target tree fragment. A good choice of parameter settings depends on the annotation style of the target-side parse trees. We used the settings shown in Table 1, which were chosen empirically during the development of last years’ systems: Parameter Rule depth Node count Rule size C → hα, β, ∼i where C is a target-side non-terminal label, α is a string of source terminals and non-terminals, β is a strin"
W14-3324,C04-1024,0,0.606547,"t En-De De-En 19.9 26.7 19.8 26.2 19.8 26.2 19.7 26.4 Tuning set Full Max-30 Filtered Random Cs-En 27.5 27.2 27.5 27.3 test En-De 19.2 19.2 19.1 19.4 De-En 26.9 27.0 27.2 27.0 Table 3: B LEU results on devtest and test sets with different tuning sets: Full, Max-30, filtered subsets of Max-30 and average of three random subsets of Max-30 (size of filtered/random subsets: 2,000). 3 English to German We use the projective output of the dependency parser ParZu (Sennrich et al., 2013) for the syntactic annotation of our primary submission. Contrastive systems were built with other parsers: BitPar (Schmid, 2004), the German Stanford Parser (Rafferty and Manning, 2008), and the German Berkeley Parser (Petrov and Klein, 2007; Petrov and Klein, 2008). The set of syntactic labels provided by ParZu has been refined to reduce overgeneralization phenomena. Specifically, we disambiguate the labels ROOT (used for the root of a sentence, but also commas, punctuation marks, and sentence fragments), KON and CJ (coordinations of different constituents), and GMOD (pre- or postmodifying genitive modifier). 2 These can be arbitrary tokens that do not match any reference token. 3 For random subsets from the full tuni"
W14-3324,sennrich-kunz-2014-zmorge,1,0.826405,"18.6 19.5 18.6 19.6 19.1 19.8 19.1 19.9 19.2 20.0 19.8 20.2 20.1 Table 4: English to German translation results on devtest (newstest2013) and test (newstest2014) sets. We discriminatively learn non-terminal labels for unknown words using sparse features, rather than estimating a probability distribution of nonterminal labels from singleton statistics in the training corpus. We perform target-side compound splitting, using a hybrid method described by Fritzinger and Fraser (2010) that combines a finite-state morphology and corpus statistics. As finite-state morphology analyzer, we use Zmorge (Sennrich and Kunz, 2014). An original contribution of our experiments is a syntactic representation of split compounds which eliminates typical problems with target-side compound splitting, namely erroneous reorderings and compound merging. We represent split compounds as a syntactic tree with the last segment as head, preceded by a modifier. A modifier consists of an optional modifier, a segment and a (possibly empty) joining element. An example is shown in Figure 1. This hierarchical representation ensures that compounds can be easily merged in post-processing (by removing the spaces and special characters around j"
W14-3324,R13-1079,1,0.108908,"ble 2: Size of full tuning sets and with sentence length up to 30. Tuning set Full Max-30 Filtered Random Cs-En 25.1 24.7 24.9 24.8 devtest En-De De-En 19.9 26.7 19.8 26.2 19.8 26.2 19.7 26.4 Tuning set Full Max-30 Filtered Random Cs-En 27.5 27.2 27.5 27.3 test En-De 19.2 19.2 19.1 19.4 De-En 26.9 27.0 27.2 27.0 Table 3: B LEU results on devtest and test sets with different tuning sets: Full, Max-30, filtered subsets of Max-30 and average of three random subsets of Max-30 (size of filtered/random subsets: 2,000). 3 English to German We use the projective output of the dependency parser ParZu (Sennrich et al., 2013) for the syntactic annotation of our primary submission. Contrastive systems were built with other parsers: BitPar (Schmid, 2004), the German Stanford Parser (Rafferty and Manning, 2008), and the German Berkeley Parser (Petrov and Klein, 2007; Petrov and Klein, 2008). The set of syntactic labels provided by ParZu has been refined to reduce overgeneralization phenomena. Specifically, we disambiguate the labels ROOT (used for the root of a sentence, but also commas, punctuation marks, and sentence fragments), KON and CJ (coordinations of different constituents), and GMOD (pre- or postmodifying g"
W14-3324,D07-1078,0,0.252787,"ystem after filtering for the devtest (newstest2013) and test (newstest2014) sets. 6 German to English German compounds were split using the script provided with Moses. For training the primary system, the target parse trees were restructured before rule extraction by right binarization. Since binarization strategies increase the tree depth and number of nodes by adding virtual non-terminals, we increased the extraction parameters to: Rule Depth = 7, Node Count = 100, Rule Size = 7. A thorough investigation of binarization methods for restructuring Penn Treebank style trees was carried out by Wang et al. (2007). Table 8 shows B LEU scores for the baseline system and two systems employing different binarization strategies. Table 9 shows the resulting grammar sizes after filtering for the evaluation sets. Results on the development set showed no improvement when left binarization was used for restructuring the trees, although the grammar size increased significantly. system baseline + right binarization (primary) + left binarization system baseline + transliteration (submission) + transliteration (fixed) B LEU devtest test 26.2 27.2 26.8 28.2 26.3 - Table 10: Hindi to English results with and without"
W14-3324,W13-2230,0,0.0742053,"ender Voice Definiteness Aspect Case 7 3 3 3 3 7 3 7 3 3 Data sparsity issues for this language pair are exacerbated by the rich inflectional morphology of Russian. Many Russian word forms express grammatical distinctions that are either absent from English translations (like grammatical gender) or are expressed by different means (like grammatical function being expressed through syntactic configuration rather than case). We adopt the widelyused approach of simplifying morphologicallycomplex source forms to remove distinctions that we believe to be redundant. Our method is similar to that of Weller et al. (2013) except that ours is much more conservative (in their experiments, Weller et al. (2013) found morphological reduction to harm translation indicating that useful information was likely to have been discarded). Table 11: Feature values that are retained (3) or deleted (7) during morphological reduction of Russian. We used TreeTagger (Schmid, 1994) to obtain a lemma-tag pair for each Russian word. The tag specifies the word class and various morphosyntactic feature values. For example, the adjective республиканская (‘republican’) gets the lemmatag pair республиканский + Afpfsnf, where the code A"
W14-3324,W11-2126,1,0.895685,"present split compounds as a syntactic tree with the last segment as head, preceded by a modifier. A modifier consists of an optional modifier, a segment and a (possibly empty) joining element. An example is shown in Figure 1. This hierarchical representation ensures that compounds can be easily merged in post-processing (by removing the spaces and special characters around joining elements), and that no segments are placed outside of a compound in the translation. We use unification-based constraints to model morphological agreement within German noun phrases, and between subjects and verbs (Williams and Koehn, 2011). Additionally, we add constraints that operate on the internal tree structure of the translation hypotheses, to enforce several syntactic constraints that were frequently violated in the baseline system: • relative clauses must contain a relative (or interrogative) pronoun in their first constituent. Table 4 shows B LEU scores with systems trained with different parsers, and for our extensions of the baseline system. 4 Czech to English For Czech to English we used the core setup described in Section 2 without modification. Table 5 shows the B LEU scores. system baseline B LEU devtest test 24."
W14-3324,W12-3150,1,0.794398,"probability of the derivation’s target yield, its word count, and various scores for the synchronous derivation. Each grammar rule has a number of precomputed scores. For a grammar rule r of the form sentence pairs with dubious length ratios and sentence pairs where parsing fails for the target-side sentence. 2.2 Translation Model Our translation grammar is a synchronous contextfree grammar (SCFG) with phrase-structure labels on the target side and the generic non-terminal label X on the source side. The grammar was extracted from the wordaligned parallel data using the Moses implementation (Williams and Koehn, 2012) of the GHKM algorithm (Galley et al., 2004; Galley et al., 2006). For word alignment we used MGIZA++ (Gao and Vogel, 2008), a multi-threaded implementation of GIZA++ (Och and Ney, 2003). Minimal GHKM rules were composed into larger rules subject to parameterized restrictions on size defined in terms of the resulting target tree fragment. A good choice of parameter settings depends on the annotation style of the target-side parse trees. We used the settings shown in Table 1, which were chosen empirically during the development of last years’ systems: Parameter Rule depth Node count Rule size C"
W14-3324,N07-1051,0,\N,Missing
W14-3324,Q15-1013,1,\N,Missing
W14-3324,W08-1006,0,\N,Missing
W14-3324,D09-1108,0,\N,Missing
W14-3324,E99-1010,0,\N,Missing
W14-3324,N13-3005,0,\N,Missing
W14-3324,N09-2019,0,\N,Missing
W14-3324,P13-2121,1,\N,Missing
W14-3324,P03-2041,0,\N,Missing
W14-3324,W05-0904,0,\N,Missing
W14-3324,herrmann-etal-2014-manual,0,\N,Missing
W14-3324,D14-1082,0,\N,Missing
W14-3324,W15-1004,0,\N,Missing
W14-3324,D15-1248,1,\N,Missing
W14-3324,P14-2024,0,\N,Missing
W14-3324,P14-1129,0,\N,Missing
W14-3324,J07-2003,0,\N,Missing
W14-3324,vilar-etal-2006-error,0,\N,Missing
W14-3324,W14-4018,1,\N,Missing
W14-3324,2014.eamt-1.38,0,\N,Missing
W14-3324,D13-1140,0,\N,Missing
W14-3362,2012.eamt-1.44,0,0.0176638,"93 5.4 SPMT Model 2 rules. Special additional rules allow for combination of those non-syntactic lefthand side non-terminals with genuine syntactic non-terminals on the right-hand sides of other rules during decoding. Another line of research took the hierarchical phrase-based model (Chiang, 2005; Chiang, 2007) as a starting point and extended it with syntactic enhancements. In their SAMT system, Zollmann and Venugopal (2006) labeled the non-terminals of the hierarchical model with composite symbols derived from the syntactic tree annotation. Similar methods have been applied with CCG labels (Almaghout et al., 2012). Venugopal et al. (2009) and Stein et al. (2010) keep the grammar of the non-terminals of the hierarchical model unlabeled and apply the syntactic information in a separate model. Other authors added features which fire for phrases complying with certain syntactic properties while retaining all phrase pairs of the hierarchical model (Marton and Resnik, 2008; Vilar et al., 2008). In a tree-to-tree translation setting, Chiang (2010) proposed techniques to soften the syntactic constraints. A fuzzy approach with complex non-terminal symbols as in SAMT is employed to overcome the limitations durin"
W14-3362,D07-1079,0,0.213723,"hypotheses that make use of the alternative segmentations and translation options provided through non-syntactic phrases. The search space is more diverse, and in some cases all hypotheses from purely syntax-based derivations score worse than a translation that applies one or more non-syntactic phrases. We empirically demonstrate that this technique can lead to substantial gains in translation quality. Our syntactic translation models conform to the GHKM syntax approach as proposed by Galley, Hopkins, Knight, and Marcu (Galley et al., 2004) with composed rules as in (Galley et al., 2006) and (DeNeefe et al., 2007). State-of-theart GHKM string-to-tree systems have recently shown very competitive performance in public We present an effective technique to easily augment GHKM-style syntax-based machine translation systems (Galley et al., 2006) with phrase pairs that do not comply with any syntactic well-formedness constraints. Non-syntactic phrase pairs are distinguished from syntactic ones in order to avoid harming effects. We apply our technique in state-of-the-art string-totree and tree-to-string setups. For tree-tostring translation, we furthermore investigate novel approaches for translating with sour"
W14-3362,W09-0432,0,0.0268617,"ree-to-tree translation setting, Chiang (2010) proposed techniques to soften the syntactic constraints. A fuzzy approach with complex non-terminal symbols as in SAMT is employed to overcome the limitations during phrase extraction. In decoding, substitutions of non-terminals are not restricted to matching ones. Any lefthand side non-terminal can substitute any righthand side non-terminal. The decoder decides on the best derivation based on the tuned weights of a large number of binary features. Joining phrase inventories that come from multiple origins is a common method in domain adaptation (Bertoldi and Federico, 2009; Niehues and Waibel, 2012) but has also been applied in the contexts of lightly-supervised training (Schwenk, 2008; Huck et al., 2011) and of forced alignment training (Wuebker et al., 2010). For our purposes, we apply a fill-up method in the manner of the one that has been shown to perform well for domain adaptation in earlier work (Bisazza et al., 2011). Previous research that resembles our work most has been presented by Liu et al. (2006) and by Hanneman and Lavie (2009). Liu et al. (2006) allow for application of nonsyntactic phrase pairs in their tree-to-string alignment template (TAT) s"
W14-3362,W08-0306,0,0.0204307,"ation. 6 Related Work Issues with overly restrictive syntactic grammars for statistical machine translation, inadequate syntactic parses, and insufficient coverage have been tackled from several different directions in the literature. A proposed approach to attain better syntactic phrase inventories is to restructure the syntactic parse trees in a preprocessing step (Wang et al., 2007; Wang et al., 2010; Burkett and Klein, 2012). This line of research aims at rearranging parse trees in a way that makes them a better fit for the requirements of the bilingual downstream application. Conversely, Fossum et al. (2008) retain the structure of the parse trees and modify the word alignments. Marcu et al. (2006) relax syntactic phrase extraction constraints in their SPMT Model 2 to allow for phrases that do not match the span of one single constituent in the parse tree. SPMT Model 2 rules are created from spans that are consistent with the word alignment and covered by multiple constituents such that the union of the constituents matches the span. Pseudo non-syntactic nonterminals are introduced for the left-hand sides of 494 phrases are not summed up to obtain new estimates. • Non-syntactic phrase pairs are d"
W14-3362,2011.iwslt-evaluation.18,0,0.484519,"he set BP is extracted from all training instances, and phrase translation probabilities are computed separately from those in the syntactic phrase inventory. • Non-syntactic phrases are converted to rules by providing a special left-hand side nonterminal X. • A phrase table fill-up method is applied to enhance the syntactic phrase inventory with entries from the non-syntactic phrase inventory. Non-syntactic rules are only added to the final grammar if no syntactic rule with the same (source and target) right-hand side is present. This method is inspired by previous work in domain adaptation (Bisazza et al., 2011). • The glue grammar is extended with a new glue rule X, Q → hX ∼0 X ∼1 , Q∼0 X ∼1 i that enables the system to make use of nonsyntactic rules in decoding. • A binary feature is added to the log-linear model (Och and Ney, 2002) to distinguish non-syntactic rules from syntactic ones, and to be able to assign a tuned weight to the nonsyntactic part of the grammar. 2 http://www.statmt.org/wmt14/ translation-task.html 3 We remove grammatical case and function information from the annotation obtained with BitPar. 489 system dev B LEU T ER phrase-based + lexicalized reordering 33.0 34.2 48.8 48.1 st"
W14-3362,D08-1089,0,0.15454,"red in truecase with B LEU and T ER (Snover et al., 2006).4 We apply a phrase length limit of five when extracting non-syntactic phrases for the fill-up of syntactic phrase tables. 5.2 Translation Results Table 1 comprises the results of our empirical evaluation of the translation quality achieved by the different systems. 5.2.1 Phrase-based Baselines We set up two phrase-based baselines for comparison. Their set of models is the same as for the syntax-based baselines, with the exception of the PCFG probability. One of the phrase-based systems moreover utilizes a lexicalized reordering model (Galley and Manning, 2008). No nonstandard advanced features (like an operation sequence model or class-based LMs) are engrafted. The maximum phrase length is five, search is carried out with cube pruning at a k-best limit of 1000. A maximum number of 100 translation options per source side are taken into account. 5.2.2 String-to-String Contrastive System A further contrastive experiment is done with a string-to-string system. The extraction method for this string-to-string system is GHKM syntaxdirected with syntactic target-side annotation from BitPar, as in the string-to-tree setup. We actually extract the same rules"
W14-3362,N04-1035,0,0.887783,"derivations which resort to both types of phrases. Such derivations yield hypotheses that make use of the alternative segmentations and translation options provided through non-syntactic phrases. The search space is more diverse, and in some cases all hypotheses from purely syntax-based derivations score worse than a translation that applies one or more non-syntactic phrases. We empirically demonstrate that this technique can lead to substantial gains in translation quality. Our syntactic translation models conform to the GHKM syntax approach as proposed by Galley, Hopkins, Knight, and Marcu (Galley et al., 2004) with composed rules as in (Galley et al., 2006) and (DeNeefe et al., 2007). State-of-theart GHKM string-to-tree systems have recently shown very competitive performance in public We present an effective technique to easily augment GHKM-style syntax-based machine translation systems (Galley et al., 2006) with phrase pairs that do not comply with any syntactic well-formedness constraints. Non-syntactic phrase pairs are distinguished from syntactic ones in order to avoid harming effects. We apply our technique in state-of-the-art string-totree and tree-to-string setups. For tree-tostring transla"
W14-3362,D12-1079,0,0.0188008,"f nonsyntactic rules into hierarchical rules (other than the glue rules) but did not see improvements with it as yet. Furthermore, efficiency concerns become more relevant in such an implementation. 6 Related Work Issues with overly restrictive syntactic grammars for statistical machine translation, inadequate syntactic parses, and insufficient coverage have been tackled from several different directions in the literature. A proposed approach to attain better syntactic phrase inventories is to restructure the syntactic parse trees in a preprocessing step (Wang et al., 2007; Wang et al., 2010; Burkett and Klein, 2012). This line of research aims at rearranging parse trees in a way that makes them a better fit for the requirements of the bilingual downstream application. Conversely, Fossum et al. (2008) retain the structure of the parse trees and modify the word alignments. Marcu et al. (2006) relax syntactic phrase extraction constraints in their SPMT Model 2 to allow for phrases that do not match the span of one single constituent in the parse tree. SPMT Model 2 rules are created from spans that are consistent with the word alignment and covered by multiple constituents such that the union of the constitu"
W14-3362,W08-0509,0,0.0304451,"sing and cube pruning (Hoang et al., 2009). ∧ ∀(i, j) ∈ A : i1 ≤ i ≤ i2 ↔ j1 ≤ j ≤ j2 Experimental Setup We work with an English–German parallel training corpus of around 4.5 M sentence pairs (after corpus cleaning). The parallel data originates from three different sources which have been eligible for the constrained track of the ACL 2014 Ninth Workshop on Statistical Machine Translation shared translation task: Europarl (Koehn, 2005), News Commentary, and the Common Crawl corpus as provided on the WMT website. Word alignments are created by aligning the data in both directions with MGIZA++ (Gao and Vogel, 2008) and symmetrizing the two trained alignments (Och and Ney, 2003; Koehn et al., 2003). For string-to-tree translation, we parse the German target side with BitPar (Schmid, 2004).3 For tree-to-string translation, we parse the English source side of the parallel data with the English Berkeley Parser (Petrov et al., 2006). When extracting syntactic phrases, we impose several restrictions for composed rules, in particular a maximum number of twenty tree nodes per rule, a maximum depth of five, and a maximum size of five. We discard rules with non-terminals on their right-hand side if they are singl"
W14-3362,N12-1047,0,0.0487444,"he rule was extracted (Williams et al., 2014). Phrase translation probabilities are smoothed via Good-Turing smoothing. The language model (LM) is a large interpolated 5-gram LM with modified Kneser-Ney smoothing (Kneser and Ney, 1995; Chen and Goodman, 1998). The target side of the parallel corpus and the monolingual German News Crawl corpora are employed as training data. We use the SRILM toolkit (Stolcke, 2002) to train the LM and rely on KenLM (Heafield, 2011) for language model scoring during decoding. Model weights are optimized to maximize B LEU (Papineni et al., 2002) with batch MIRA (Cherry and Foster, 2012) on 1000-best lists. We selected 2000 sentences from the newstest20082012 sets as a development set. The selected sentences obtained high sentence-level B LEU scores when being translated with a baseline phrasebased system, and do each contain less than 30 words for more rapid tuning. newstest2013 and newstest2014 are used as unseen test sets. Translation quality is measured in truecase with B LEU and T ER (Snover et al., 2006).4 We apply a phrase length limit of five when extracting non-syntactic phrases for the fill-up of syntactic phrase tables. 5.2 Translation Results Table 1 comprises the"
W14-3362,W09-2301,0,0.0810515,"f binary features. Joining phrase inventories that come from multiple origins is a common method in domain adaptation (Bertoldi and Federico, 2009; Niehues and Waibel, 2012) but has also been applied in the contexts of lightly-supervised training (Schwenk, 2008; Huck et al., 2011) and of forced alignment training (Wuebker et al., 2010). For our purposes, we apply a fill-up method in the manner of the one that has been shown to perform well for domain adaptation in earlier work (Bisazza et al., 2011). Previous research that resembles our work most has been presented by Liu et al. (2006) and by Hanneman and Lavie (2009). Liu et al. (2006) allow for application of nonsyntactic phrase pairs in their tree-to-string alignment template (TAT) system. The translation probabilities for the non-syntactic phrases are obtained from a standard phrase-based extraction Discussion A drawback of our method is that it increases the size of the synchronous context-free grammar massively. Most phrase pairs from standard phrase-based extraction are actually not present in the GHKM rule set, even with composed rules. A large fraction of the extracted non-syntactic phrases is such added to the phrase inventory through phrase tabl"
W14-3362,P05-1033,0,0.498759,"ystems utilize linguistic information that is obtained by parsing the training data. In tree-to-string translation, source-side syntactic tree annotation is employed, while string-to-tree translation exploits target-side syntax. The syntactic parse tree annotation constrains phrase extraction to syntactically well-formed phrase pairs: spans of syntactic phrases must match constituents in the parse tree. Standard phrase-based and hierarchical phrasebased statistical machine translation systems, in contrast, allow all phrase pairs that are consistent with the word alignment (Koehn et al., 2003; Chiang, 2005). A restriction of the phrase inventory to syntactically well-formed phrase pairs entails that possibly valuable information from the training data remains disregarded. While we would expect phrase pairs that are not linguistically motivated to be less reliable, discarding them altogether might be an overly harsh decision. The quality of an inventory of syntactic phrases depends heavily on the tree 486 Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 486–498, c Baltimore, Maryland USA, June 26–27, 2014. 2014 Association for Computational Linguistics to-tree). A synta"
W14-3362,W11-2123,0,0.0256518,"word and phrase penalty, an n-gram language model, a rule rareness penalty, and the monolingual PCFG probability of the tree fragment from which the rule was extracted (Williams et al., 2014). Phrase translation probabilities are smoothed via Good-Turing smoothing. The language model (LM) is a large interpolated 5-gram LM with modified Kneser-Ney smoothing (Kneser and Ney, 1995; Chen and Goodman, 1998). The target side of the parallel corpus and the monolingual German News Crawl corpora are employed as training data. We use the SRILM toolkit (Stolcke, 2002) to train the LM and rely on KenLM (Heafield, 2011) for language model scoring during decoding. Model weights are optimized to maximize B LEU (Papineni et al., 2002) with batch MIRA (Cherry and Foster, 2012) on 1000-best lists. We selected 2000 sentences from the newstest20082012 sets as a development set. The selected sentences obtained high sentence-level B LEU scores when being translated with a baseline phrasebased system, and do each contain less than 30 words for more rapid tuning. newstest2013 and newstest2014 are used as unseen test sets. Translation quality is measured in truecase with B LEU and T ER (Snover et al., 2006).4 We apply a"
W14-3362,J07-2003,0,0.580655,"and NE denote the source and target non-terminal vocabulary, respectively. The non-terminals on the source side and on the target side of rules are linked in a one-toone correspondence. The ∼ relation defines this one-to-one correspondence. The left-hand side of the rule is a pair of source and target nonterminals, A ∈ NF and B ∈ NE . Decoding is typically carried out with a parsingbased algorithm, in our case a customized version of CYK+ (Chappelier and Rajman, 1998). The parsing algorithm is extended to handle translation candidates and to incorporate language model scores via cube pruning (Chiang, 2007). evaluation campaigns (Nadejde et al., 2013; Bojar et al., 2013). We apply the GHKM approach not only in a string-to-tree setting as in previous work, but employ it to build tree-to-string systems as well. We conduct tree-to-string translation with text input and additionally adopt translation with tree input and input tree constraints as suggested for hierarchical translation by Hoang and Koehn (2010). We also implement translation with tree input and feature-driven soft tree matching. The effect of augmenting the systems with nonsyntactic phrases is evaluated for all variants. 2 Outline The"
W14-3362,W10-1761,1,0.925206,"thm, in our case a customized version of CYK+ (Chappelier and Rajman, 1998). The parsing algorithm is extended to handle translation candidates and to incorporate language model scores via cube pruning (Chiang, 2007). evaluation campaigns (Nadejde et al., 2013; Bojar et al., 2013). We apply the GHKM approach not only in a string-to-tree setting as in previous work, but employ it to build tree-to-string systems as well. We conduct tree-to-string translation with text input and additionally adopt translation with tree input and input tree constraints as suggested for hierarchical translation by Hoang and Koehn (2010). We also implement translation with tree input and feature-driven soft tree matching. The effect of augmenting the systems with nonsyntactic phrases is evaluated for all variants. 2 Outline The remainder of the paper is structured as follows: We review some of the basics of syntaxbased translation in the next section (Section 3) and sketch the characteristics of our GHKM string-to-tree and tree-to-string translation frameworks. In Section 4, we describe our technique to augment GHKM-style syntax-based systems with phrase pairs that do not comply with any syntactic well-formedness constraints."
W14-3362,P10-1146,0,0.0207005,"-terminals of the hierarchical model with composite symbols derived from the syntactic tree annotation. Similar methods have been applied with CCG labels (Almaghout et al., 2012). Venugopal et al. (2009) and Stein et al. (2010) keep the grammar of the non-terminals of the hierarchical model unlabeled and apply the syntactic information in a separate model. Other authors added features which fire for phrases complying with certain syntactic properties while retaining all phrase pairs of the hierarchical model (Marton and Resnik, 2008; Vilar et al., 2008). In a tree-to-tree translation setting, Chiang (2010) proposed techniques to soften the syntactic constraints. A fuzzy approach with complex non-terminal symbols as in SAMT is employed to overcome the limitations during phrase extraction. In decoding, substitutions of non-terminals are not restricted to matching ones. Any lefthand side non-terminal can substitute any righthand side non-terminal. The decoder decides on the best derivation based on the tuned weights of a large number of binary features. Joining phrase inventories that come from multiple origins is a common method in domain adaptation (Bertoldi and Federico, 2009; Niehues and Waibe"
W14-3362,2009.iwslt-papers.4,1,0.883828,"obey the following procedure: 5.1 Empirical Evaluation We evaluate the effect of augmenting GHKM syntax-based translation systems—both string-totree and tree-to-string—with non-syntactic phrase pairs on the English→German language pair using the standard newstest sets of the Workshop on Statistical Machine Translation (WMT) for testing.2 The experiments are conducted with the openBP( f1J , eI1 , A) = source Moses implementations of GHKM rule exn j2 i2 traction (Williams and Koehn, 2012) and decoding h f j1 , ei1 i : ∃(i, j) ∈ A : i1 ≤ i ≤ i2 ∧ j1 ≤ j ≤ j2 o with CYK+ parsing and cube pruning (Hoang et al., 2009). ∧ ∀(i, j) ∈ A : i1 ≤ i ≤ i2 ↔ j1 ≤ j ≤ j2 Experimental Setup We work with an English–German parallel training corpus of around 4.5 M sentence pairs (after corpus cleaning). The parallel data originates from three different sources which have been eligible for the constrained track of the ACL 2014 Ninth Workshop on Statistical Machine Translation shared translation task: Europarl (Koehn, 2005), News Commentary, and the Common Crawl corpus as provided on the WMT website. Word alignments are created by aligning the data in both directions with MGIZA++ (Gao and Vogel, 2008) and symmetrizing the"
W14-3362,P02-1038,0,0.497403,"eft-hand side nonterminal X. • A phrase table fill-up method is applied to enhance the syntactic phrase inventory with entries from the non-syntactic phrase inventory. Non-syntactic rules are only added to the final grammar if no syntactic rule with the same (source and target) right-hand side is present. This method is inspired by previous work in domain adaptation (Bisazza et al., 2011). • The glue grammar is extended with a new glue rule X, Q → hX ∼0 X ∼1 , Q∼0 X ∼1 i that enables the system to make use of nonsyntactic rules in decoding. • A binary feature is added to the log-linear model (Och and Ney, 2002) to distinguish non-syntactic rules from syntactic ones, and to be able to assign a tuned weight to the nonsyntactic part of the grammar. 2 http://www.statmt.org/wmt14/ translation-task.html 3 We remove grammatical case and function information from the annotation obtained with BitPar. 489 system dev B LEU T ER phrase-based + lexicalized reordering 33.0 34.2 48.8 48.1 string-to-string (syntax-directed extraction) + non-syntactic phrases 32.6 33.4 49.4 49.0 string-to-tree + non-syntactic phrases 33.6 34.3 48.7 48.0 tree-to-string + non-syntactic phrases 34.0 33.9 48.5 48.4 + input tree constrai"
W14-3362,W11-2211,1,0.849754,"al symbols as in SAMT is employed to overcome the limitations during phrase extraction. In decoding, substitutions of non-terminals are not restricted to matching ones. Any lefthand side non-terminal can substitute any righthand side non-terminal. The decoder decides on the best derivation based on the tuned weights of a large number of binary features. Joining phrase inventories that come from multiple origins is a common method in domain adaptation (Bertoldi and Federico, 2009; Niehues and Waibel, 2012) but has also been applied in the contexts of lightly-supervised training (Schwenk, 2008; Huck et al., 2011) and of forced alignment training (Wuebker et al., 2010). For our purposes, we apply a fill-up method in the manner of the one that has been shown to perform well for domain adaptation in earlier work (Bisazza et al., 2011). Previous research that resembles our work most has been presented by Liu et al. (2006) and by Hanneman and Lavie (2009). Liu et al. (2006) allow for application of nonsyntactic phrase pairs in their tree-to-string alignment template (TAT) system. The translation probabilities for the non-syntactic phrases are obtained from a standard phrase-based extraction Discussion A dr"
W14-3362,J03-1002,0,0.0100869,"≤ i2 ↔ j1 ≤ j ≤ j2 Experimental Setup We work with an English–German parallel training corpus of around 4.5 M sentence pairs (after corpus cleaning). The parallel data originates from three different sources which have been eligible for the constrained track of the ACL 2014 Ninth Workshop on Statistical Machine Translation shared translation task: Europarl (Koehn, 2005), News Commentary, and the Common Crawl corpus as provided on the WMT website. Word alignments are created by aligning the data in both directions with MGIZA++ (Gao and Vogel, 2008) and symmetrizing the two trained alignments (Och and Ney, 2003; Koehn et al., 2003). For string-to-tree translation, we parse the German target side with BitPar (Schmid, 2004).3 For tree-to-string translation, we parse the English source side of the parallel data with the English Berkeley Parser (Petrov et al., 2006). When extracting syntactic phrases, we impose several restrictions for composed rules, in particular a maximum number of twenty tree nodes per rule, a maximum depth of five, and a maximum size of five. We discard rules with non-terminals on their right-hand side if they are singletons in the training data. Only the 100 best translation optio"
W14-3362,W99-0604,0,0.190978,"1: the highlighted phrase pair halso wanted, wollten auchi cannot be extracted from this training instance for string-to-tree translation. The described techniques for GHKM string-totree translation can be adjusted for tree-to-string translation in a straightforward manner. Rules are extracted from training instances which consist of a source sentence along with its constituent parse tree, a target sentence, and a word alignment matrix. We omit the details. 488 In the standard phrase-based approach, in contrast, all continuous phrases that are consistent with the word alignment are extracted (Och et al., 1999; Och, 2002). The set of continuous bilingual phrases BP( f1J , eI1 , A), given a training instance comprising a source sentence f1J , a target sentence eI1 , and a word alignment A ⊆ {1, ..., I}×{1, ..., J}, is defined as follows: 5 Consistency for continuous phrases is based upon merely two constraints in this definition: (1.) At least one source and target position within the phrase must be aligned, and (2.) words from inside the source phrase may only be aligned to words from inside the target phrase and vice versa. The highlighted phrase pair from the example does not violate these constr"
W14-3362,N03-1017,1,0.112598,"achine translation systems utilize linguistic information that is obtained by parsing the training data. In tree-to-string translation, source-side syntactic tree annotation is employed, while string-to-tree translation exploits target-side syntax. The syntactic parse tree annotation constrains phrase extraction to syntactically well-formed phrase pairs: spans of syntactic phrases must match constituents in the parse tree. Standard phrase-based and hierarchical phrasebased statistical machine translation systems, in contrast, allow all phrase pairs that are consistent with the word alignment (Koehn et al., 2003; Chiang, 2005). A restriction of the phrase inventory to syntactically well-formed phrase pairs entails that possibly valuable information from the training data remains disregarded. While we would expect phrase pairs that are not linguistically motivated to be less reliable, discarding them altogether might be an overly harsh decision. The quality of an inventory of syntactic phrases depends heavily on the tree 486 Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 486–498, c Baltimore, Maryland USA, June 26–27, 2014. 2014 Association for Computational Linguistics to"
W14-3362,2005.mtsummit-papers.11,1,0.115944,"source Moses implementations of GHKM rule exn j2 i2 traction (Williams and Koehn, 2012) and decoding h f j1 , ei1 i : ∃(i, j) ∈ A : i1 ≤ i ≤ i2 ∧ j1 ≤ j ≤ j2 o with CYK+ parsing and cube pruning (Hoang et al., 2009). ∧ ∀(i, j) ∈ A : i1 ≤ i ≤ i2 ↔ j1 ≤ j ≤ j2 Experimental Setup We work with an English–German parallel training corpus of around 4.5 M sentence pairs (after corpus cleaning). The parallel data originates from three different sources which have been eligible for the constrained track of the ACL 2014 Ninth Workshop on Statistical Machine Translation shared translation task: Europarl (Koehn, 2005), News Commentary, and the Common Crawl corpus as provided on the WMT website. Word alignments are created by aligning the data in both directions with MGIZA++ (Gao and Vogel, 2008) and symmetrizing the two trained alignments (Och and Ney, 2003; Koehn et al., 2003). For string-to-tree translation, we parse the German target side with BitPar (Schmid, 2004).3 For tree-to-string translation, we parse the English source side of the parallel data with the English Berkeley Parser (Petrov et al., 2006). When extracting syntactic phrases, we impose several restrictions for composed rules, in particula"
W14-3362,P02-1040,0,0.0918955,"bility of the tree fragment from which the rule was extracted (Williams et al., 2014). Phrase translation probabilities are smoothed via Good-Turing smoothing. The language model (LM) is a large interpolated 5-gram LM with modified Kneser-Ney smoothing (Kneser and Ney, 1995; Chen and Goodman, 1998). The target side of the parallel corpus and the monolingual German News Crawl corpora are employed as training data. We use the SRILM toolkit (Stolcke, 2002) to train the LM and rely on KenLM (Heafield, 2011) for language model scoring during decoding. Model weights are optimized to maximize B LEU (Papineni et al., 2002) with batch MIRA (Cherry and Foster, 2012) on 1000-best lists. We selected 2000 sentences from the newstest20082012 sets as a development set. The selected sentences obtained high sentence-level B LEU scores when being translated with a baseline phrasebased system, and do each contain less than 30 words for more rapid tuning. newstest2013 and newstest2014 are used as unseen test sets. Translation quality is measured in truecase with B LEU and T ER (Snover et al., 2006).4 We apply a phrase length limit of five when extracting non-syntactic phrases for the fill-up of syntactic phrase tables. 5.2"
W14-3362,P06-1055,0,0.0261399,"track of the ACL 2014 Ninth Workshop on Statistical Machine Translation shared translation task: Europarl (Koehn, 2005), News Commentary, and the Common Crawl corpus as provided on the WMT website. Word alignments are created by aligning the data in both directions with MGIZA++ (Gao and Vogel, 2008) and symmetrizing the two trained alignments (Och and Ney, 2003; Koehn et al., 2003). For string-to-tree translation, we parse the German target side with BitPar (Schmid, 2004).3 For tree-to-string translation, we parse the English source side of the parallel data with the English Berkeley Parser (Petrov et al., 2006). When extracting syntactic phrases, we impose several restrictions for composed rules, in particular a maximum number of twenty tree nodes per rule, a maximum depth of five, and a maximum size of five. We discard rules with non-terminals on their right-hand side if they are singletons in the training data. Only the 100 best translation options per distinct source side with respect to the weighted phrase-level model scores are loaded by the decoder. The decoder is configured with a maximum chart span of 25 and a rule limit of 100. A standard set of models is used in the baselines, comprising p"
W14-3362,P06-1077,0,0.184599,"ights of a large number of binary features. Joining phrase inventories that come from multiple origins is a common method in domain adaptation (Bertoldi and Federico, 2009; Niehues and Waibel, 2012) but has also been applied in the contexts of lightly-supervised training (Schwenk, 2008; Huck et al., 2011) and of forced alignment training (Wuebker et al., 2010). For our purposes, we apply a fill-up method in the manner of the one that has been shown to perform well for domain adaptation in earlier work (Bisazza et al., 2011). Previous research that resembles our work most has been presented by Liu et al. (2006) and by Hanneman and Lavie (2009). Liu et al. (2006) allow for application of nonsyntactic phrase pairs in their tree-to-string alignment template (TAT) system. The translation probabilities for the non-syntactic phrases are obtained from a standard phrase-based extraction Discussion A drawback of our method is that it increases the size of the synchronous context-free grammar massively. Most phrase pairs from standard phrase-based extraction are actually not present in the GHKM rule set, even with composed rules. A large fraction of the extracted non-syntactic phrases is such added to the phr"
W14-3362,C04-1024,0,0.244259,"ce pairs (after corpus cleaning). The parallel data originates from three different sources which have been eligible for the constrained track of the ACL 2014 Ninth Workshop on Statistical Machine Translation shared translation task: Europarl (Koehn, 2005), News Commentary, and the Common Crawl corpus as provided on the WMT website. Word alignments are created by aligning the data in both directions with MGIZA++ (Gao and Vogel, 2008) and symmetrizing the two trained alignments (Och and Ney, 2003; Koehn et al., 2003). For string-to-tree translation, we parse the German target side with BitPar (Schmid, 2004).3 For tree-to-string translation, we parse the English source side of the parallel data with the English Berkeley Parser (Petrov et al., 2006). When extracting syntactic phrases, we impose several restrictions for composed rules, in particular a maximum number of twenty tree nodes per rule, a maximum depth of five, and a maximum size of five. We discard rules with non-terminals on their right-hand side if they are singletons in the training data. Only the 100 best translation options per distinct source side with respect to the weighted phrase-level model scores are loaded by the decoder. The"
W14-3362,W06-1606,0,0.0259403,"ne translation, inadequate syntactic parses, and insufficient coverage have been tackled from several different directions in the literature. A proposed approach to attain better syntactic phrase inventories is to restructure the syntactic parse trees in a preprocessing step (Wang et al., 2007; Wang et al., 2010; Burkett and Klein, 2012). This line of research aims at rearranging parse trees in a way that makes them a better fit for the requirements of the bilingual downstream application. Conversely, Fossum et al. (2008) retain the structure of the parse trees and modify the word alignments. Marcu et al. (2006) relax syntactic phrase extraction constraints in their SPMT Model 2 to allow for phrases that do not match the span of one single constituent in the parse tree. SPMT Model 2 rules are created from spans that are consistent with the word alignment and covered by multiple constituents such that the union of the constituents matches the span. Pseudo non-syntactic nonterminals are introduced for the left-hand sides of 494 phrases are not summed up to obtain new estimates. • Non-syntactic phrase pairs are distinguished from syntactic ones with an additional feature. pipeline. A non-syntactic phras"
W14-3362,2008.iwslt-papers.6,0,0.0274629,"plex non-terminal symbols as in SAMT is employed to overcome the limitations during phrase extraction. In decoding, substitutions of non-terminals are not restricted to matching ones. Any lefthand side non-terminal can substitute any righthand side non-terminal. The decoder decides on the best derivation based on the tuned weights of a large number of binary features. Joining phrase inventories that come from multiple origins is a common method in domain adaptation (Bertoldi and Federico, 2009; Niehues and Waibel, 2012) but has also been applied in the contexts of lightly-supervised training (Schwenk, 2008; Huck et al., 2011) and of forced alignment training (Wuebker et al., 2010). For our purposes, we apply a fill-up method in the manner of the one that has been shown to perform well for domain adaptation in earlier work (Bisazza et al., 2011). Previous research that resembles our work most has been presented by Liu et al. (2006) and by Hanneman and Lavie (2009). Liu et al. (2006) allow for application of nonsyntactic phrase pairs in their tree-to-string alignment template (TAT) system. The translation probabilities for the non-syntactic phrases are obtained from a standard phrase-based extrac"
W14-3362,P08-1114,0,0.0221182,"tic enhancements. In their SAMT system, Zollmann and Venugopal (2006) labeled the non-terminals of the hierarchical model with composite symbols derived from the syntactic tree annotation. Similar methods have been applied with CCG labels (Almaghout et al., 2012). Venugopal et al. (2009) and Stein et al. (2010) keep the grammar of the non-terminals of the hierarchical model unlabeled and apply the syntactic information in a separate model. Other authors added features which fire for phrases complying with certain syntactic properties while retaining all phrase pairs of the hierarchical model (Marton and Resnik, 2008; Vilar et al., 2008). In a tree-to-tree translation setting, Chiang (2010) proposed techniques to soften the syntactic constraints. A fuzzy approach with complex non-terminal symbols as in SAMT is employed to overcome the limitations during phrase extraction. In decoding, substitutions of non-terminals are not restricted to matching ones. Any lefthand side non-terminal can substitute any righthand side non-terminal. The decoder decides on the best derivation based on the tuned weights of a large number of binary features. Joining phrase inventories that come from multiple origins is a common"
W14-3362,2006.amta-papers.25,0,0.070592,"nd rely on KenLM (Heafield, 2011) for language model scoring during decoding. Model weights are optimized to maximize B LEU (Papineni et al., 2002) with batch MIRA (Cherry and Foster, 2012) on 1000-best lists. We selected 2000 sentences from the newstest20082012 sets as a development set. The selected sentences obtained high sentence-level B LEU scores when being translated with a baseline phrasebased system, and do each contain less than 30 words for more rapid tuning. newstest2013 and newstest2014 are used as unseen test sets. Translation quality is measured in truecase with B LEU and T ER (Snover et al., 2006).4 We apply a phrase length limit of five when extracting non-syntactic phrases for the fill-up of syntactic phrase tables. 5.2 Translation Results Table 1 comprises the results of our empirical evaluation of the translation quality achieved by the different systems. 5.2.1 Phrase-based Baselines We set up two phrase-based baselines for comparison. Their set of models is the same as for the syntax-based baselines, with the exception of the PCFG probability. One of the phrase-based systems moreover utilizes a lexicalized reordering model (Galley and Manning, 2008). No nonstandard advanced featur"
W14-3362,W13-2221,1,0.859277,"on-terminal vocabulary, respectively. The non-terminals on the source side and on the target side of rules are linked in a one-toone correspondence. The ∼ relation defines this one-to-one correspondence. The left-hand side of the rule is a pair of source and target nonterminals, A ∈ NF and B ∈ NE . Decoding is typically carried out with a parsingbased algorithm, in our case a customized version of CYK+ (Chappelier and Rajman, 1998). The parsing algorithm is extended to handle translation candidates and to incorporate language model scores via cube pruning (Chiang, 2007). evaluation campaigns (Nadejde et al., 2013; Bojar et al., 2013). We apply the GHKM approach not only in a string-to-tree setting as in previous work, but employ it to build tree-to-string systems as well. We conduct tree-to-string translation with text input and additionally adopt translation with tree input and input tree constraints as suggested for hierarchical translation by Hoang and Koehn (2010). We also implement translation with tree input and feature-driven soft tree matching. The effect of augmenting the systems with nonsyntactic phrases is evaluated for all variants. 2 Outline The remainder of the paper is structured as fol"
W14-3362,2010.amta-papers.8,0,0.0314091,"llow for combination of those non-syntactic lefthand side non-terminals with genuine syntactic non-terminals on the right-hand sides of other rules during decoding. Another line of research took the hierarchical phrase-based model (Chiang, 2005; Chiang, 2007) as a starting point and extended it with syntactic enhancements. In their SAMT system, Zollmann and Venugopal (2006) labeled the non-terminals of the hierarchical model with composite symbols derived from the syntactic tree annotation. Similar methods have been applied with CCG labels (Almaghout et al., 2012). Venugopal et al. (2009) and Stein et al. (2010) keep the grammar of the non-terminals of the hierarchical model unlabeled and apply the syntactic information in a separate model. Other authors added features which fire for phrases complying with certain syntactic properties while retaining all phrase pairs of the hierarchical model (Marton and Resnik, 2008; Vilar et al., 2008). In a tree-to-tree translation setting, Chiang (2010) proposed techniques to soften the syntactic constraints. A fuzzy approach with complex non-terminal symbols as in SAMT is employed to overcome the limitations during phrase extraction. In decoding, substitutions o"
W14-3362,N09-1027,0,0.0197082,". Special additional rules allow for combination of those non-syntactic lefthand side non-terminals with genuine syntactic non-terminals on the right-hand sides of other rules during decoding. Another line of research took the hierarchical phrase-based model (Chiang, 2005; Chiang, 2007) as a starting point and extended it with syntactic enhancements. In their SAMT system, Zollmann and Venugopal (2006) labeled the non-terminals of the hierarchical model with composite symbols derived from the syntactic tree annotation. Similar methods have been applied with CCG labels (Almaghout et al., 2012). Venugopal et al. (2009) and Stein et al. (2010) keep the grammar of the non-terminals of the hierarchical model unlabeled and apply the syntactic information in a separate model. Other authors added features which fire for phrases complying with certain syntactic properties while retaining all phrase pairs of the hierarchical model (Marton and Resnik, 2008; Vilar et al., 2008). In a tree-to-tree translation setting, Chiang (2010) proposed techniques to soften the syntactic constraints. A fuzzy approach with complex non-terminal symbols as in SAMT is employed to overcome the limitations during phrase extraction. In d"
W14-3362,2008.iwslt-papers.7,0,0.0193742,"r SAMT system, Zollmann and Venugopal (2006) labeled the non-terminals of the hierarchical model with composite symbols derived from the syntactic tree annotation. Similar methods have been applied with CCG labels (Almaghout et al., 2012). Venugopal et al. (2009) and Stein et al. (2010) keep the grammar of the non-terminals of the hierarchical model unlabeled and apply the syntactic information in a separate model. Other authors added features which fire for phrases complying with certain syntactic properties while retaining all phrase pairs of the hierarchical model (Marton and Resnik, 2008; Vilar et al., 2008). In a tree-to-tree translation setting, Chiang (2010) proposed techniques to soften the syntactic constraints. A fuzzy approach with complex non-terminal symbols as in SAMT is employed to overcome the limitations during phrase extraction. In decoding, substitutions of non-terminals are not restricted to matching ones. Any lefthand side non-terminal can substitute any righthand side non-terminal. The decoder decides on the best derivation based on the tuned weights of a large number of binary features. Joining phrase inventories that come from multiple origins is a common method in domain adap"
W14-3362,D07-1078,0,0.162882,"Missing"
W14-3362,J10-2004,0,0.183007,"ows for embedding of nonsyntactic rules into hierarchical rules (other than the glue rules) but did not see improvements with it as yet. Furthermore, efficiency concerns become more relevant in such an implementation. 6 Related Work Issues with overly restrictive syntactic grammars for statistical machine translation, inadequate syntactic parses, and insufficient coverage have been tackled from several different directions in the literature. A proposed approach to attain better syntactic phrase inventories is to restructure the syntactic parse trees in a preprocessing step (Wang et al., 2007; Wang et al., 2010; Burkett and Klein, 2012). This line of research aims at rearranging parse trees in a way that makes them a better fit for the requirements of the bilingual downstream application. Conversely, Fossum et al. (2008) retain the structure of the parse trees and modify the word alignments. Marcu et al. (2006) relax syntactic phrase extraction constraints in their SPMT Model 2 to allow for phrases that do not match the span of one single constituent in the parse tree. SPMT Model 2 rules are created from spans that are consistent with the word alignment and covered by multiple constituents such that"
W14-3362,W12-3150,1,0.87546,"from the example does not violate these constraints. In order to augment our GHKM syntax-based systems with non-syntactic phrases, we obey the following procedure: 5.1 Empirical Evaluation We evaluate the effect of augmenting GHKM syntax-based translation systems—both string-totree and tree-to-string—with non-syntactic phrase pairs on the English→German language pair using the standard newstest sets of the Workshop on Statistical Machine Translation (WMT) for testing.2 The experiments are conducted with the openBP( f1J , eI1 , A) = source Moses implementations of GHKM rule exn j2 i2 traction (Williams and Koehn, 2012) and decoding h f j1 , ei1 i : ∃(i, j) ∈ A : i1 ≤ i ≤ i2 ∧ j1 ≤ j ≤ j2 o with CYK+ parsing and cube pruning (Hoang et al., 2009). ∧ ∀(i, j) ∈ A : i1 ≤ i ≤ i2 ↔ j1 ≤ j ≤ j2 Experimental Setup We work with an English–German parallel training corpus of around 4.5 M sentence pairs (after corpus cleaning). The parallel data originates from three different sources which have been eligible for the constrained track of the ACL 2014 Ninth Workshop on Statistical Machine Translation shared translation task: Europarl (Koehn, 2005), News Commentary, and the Common Crawl corpus as provided on the WMT websi"
W14-3362,W14-3324,1,0.7738,"Missing"
W14-3362,P10-1049,0,0.0435401,"itations during phrase extraction. In decoding, substitutions of non-terminals are not restricted to matching ones. Any lefthand side non-terminal can substitute any righthand side non-terminal. The decoder decides on the best derivation based on the tuned weights of a large number of binary features. Joining phrase inventories that come from multiple origins is a common method in domain adaptation (Bertoldi and Federico, 2009; Niehues and Waibel, 2012) but has also been applied in the contexts of lightly-supervised training (Schwenk, 2008; Huck et al., 2011) and of forced alignment training (Wuebker et al., 2010). For our purposes, we apply a fill-up method in the manner of the one that has been shown to perform well for domain adaptation in earlier work (Bisazza et al., 2011). Previous research that resembles our work most has been presented by Liu et al. (2006) and by Hanneman and Lavie (2009). Liu et al. (2006) allow for application of nonsyntactic phrase pairs in their tree-to-string alignment template (TAT) system. The translation probabilities for the non-syntactic phrases are obtained from a standard phrase-based extraction Discussion A drawback of our method is that it increases the size of th"
W14-3362,W06-3119,0,0.0266323,"y statistics for the different English→German translation systems. “hier.” denotes hierarchical phrases, i.e. rules with non-terminals on their right-hand side, “lexical” denotes continuous phrases. 493 5.4 SPMT Model 2 rules. Special additional rules allow for combination of those non-syntactic lefthand side non-terminals with genuine syntactic non-terminals on the right-hand sides of other rules during decoding. Another line of research took the hierarchical phrase-based model (Chiang, 2005; Chiang, 2007) as a starting point and extended it with syntactic enhancements. In their SAMT system, Zollmann and Venugopal (2006) labeled the non-terminals of the hierarchical model with composite symbols derived from the syntactic tree annotation. Similar methods have been applied with CCG labels (Almaghout et al., 2012). Venugopal et al. (2009) and Stein et al. (2010) keep the grammar of the non-terminals of the hierarchical model unlabeled and apply the syntactic information in a separate model. Other authors added features which fire for phrases complying with certain syntactic properties while retaining all phrase pairs of the hierarchical model (Marton and Resnik, 2008; Vilar et al., 2008). In a tree-to-tree trans"
W14-3362,P06-1121,0,\N,Missing
W14-3362,W13-2201,1,\N,Missing
W14-4018,J07-2003,0,0.21977,"orkshop on Syntax, Semantics and Structure in Statistical Translation, pages 148–156, c October 25, 2014, Doha, Qatar. 2014 Association for Computational Linguistics one correspondence. The ∼ relation defines this one-to-one correspondence. The left-hand side of the rule is a pair of source and target nonterminals, A ∈ NF and B ∈ NE . Decoding is typically carried out with a parsingbased algorithm, in our case a customized version of CYK+ (Chappelier and Rajman, 1998). The parsing algorithm is extended to handle translation candidates and to incorporate language model scores via cube pruning (Chiang, 2007). this paradigm have recently been among the topranked submissions to public evaluation campaigns (Williams et al., 2014; Bojar et al., 2014). Our soft source syntactic constraints features borrow ideas from Marton and Resnik (2008) who proposed a comparable approach for hierarchical machine translation. The major difference is that the features of Marton and Resnik (2008) are only based on the labels from the input trees as seen in tuning and decoding. They penalize violations of constituent boundaries but do not employ syntactic parse annotation of the source side of the training data. We, i"
W14-4018,D07-1079,0,0.569203,"ntax-based (i.e., hierarchical) and linguistically syntax-based statistical machine translation has demonstrated that significant quality gains can be achieved via integration of syntactic information as features in a non-obtrusive manner, rather than as hard constraints. We implemented two feature-based extensions for a GHKM-style string-to-tree translation system (Galley et al., 2004): 3 Related Work Our syntactic translation model conforms to the GHKM syntax approach as proposed by Galley, Hopkins, Knight, and Marcu (Galley et al., 2004) with composed rules as in (Galley et al., 2006) and (DeNeefe et al., 2007). Systems based on 148 Proceedings of SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 148–156, c October 25, 2014, Doha, Qatar. 2014 Association for Computational Linguistics one correspondence. The ∼ relation defines this one-to-one correspondence. The left-hand side of the rule is a pair of source and target nonterminals, A ∈ NF and B ∈ NE . Decoding is typically carried out with a parsingbased algorithm, in our case a customized version of CYK+ (Chappelier and Rajman, 1998). The parsing algorithm is extended to handle translation candidates and t"
W14-4018,P06-1121,0,0.861703,"search in both formally syntax-based (i.e., hierarchical) and linguistically syntax-based statistical machine translation has demonstrated that significant quality gains can be achieved via integration of syntactic information as features in a non-obtrusive manner, rather than as hard constraints. We implemented two feature-based extensions for a GHKM-style string-to-tree translation system (Galley et al., 2004): 3 Related Work Our syntactic translation model conforms to the GHKM syntax approach as proposed by Galley, Hopkins, Knight, and Marcu (Galley et al., 2004) with composed rules as in (Galley et al., 2006) and (DeNeefe et al., 2007). Systems based on 148 Proceedings of SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 148–156, c October 25, 2014, Doha, Qatar. 2014 Association for Computational Linguistics one correspondence. The ∼ relation defines this one-to-one correspondence. The left-hand side of the rule is a pair of source and target nonterminals, A ∈ NF and B ∈ NE . Decoding is typically carried out with a parsingbased algorithm, in our case a customized version of CYK+ (Chappelier and Rajman, 1998). The parsing algorithm is extended to handle t"
W14-4018,W08-0509,0,0.117113,"ict than the first one and give the system a more detailed clue about the magnitude of mismatch. 6.2 7.1 We work with an English–German parallel training corpus of around 4.5 M sentence pairs (after corpus cleaning). The parallel data originates from three different sources which have been eligible for the constrained track of the ACL 2014 Ninth Workshop on Statistical Machine Translation shared translation task: Europarl (Koehn, 2005), News Commentary, and the Common Crawl corpus as provided on the WMT website. Word alignments are created by aligning the data in both directions with MGIZA++ (Gao and Vogel, 2008) and symmetrizing the two trained alignments (Och and Ney, 2003; Koehn et al., 2003). The German target side training data is parsed with BitPar (Schmid, 2004). We remove grammatical case and function information from the annotation obtained with BitPar and apply right binarization of the German parse trees prior to rule extraction (Wang et al., 2007; Wang et al., 2010; Nadejde et al., 2013). For the soft source syntactic constraints, we parse the English source side of the parallel data with the English Berkeley Parser (Petrov et al., 2006) and produce composite SAMT-style labels as discussed"
W14-4018,W11-2123,0,0.0267157,"test2008-2012 sets is used as development set. model, a rule rareness penalty, and the monolingual PCFG probability of the tree fragment from which the rule was extracted (Williams et al., 2014). Rule translation probabilities are smoothed via Good-Turing smoothing. The language model (LM) is a large interpolated 5-gram LM with modified Kneser-Ney smoothing (Kneser and Ney, 1995; Chen and Goodman, 1998). The target side of the parallel corpus and the monolingual German News Crawl corpora are employed as training data. We use the SRILM toolkit (Stolcke, 2002) to train the LM and rely on KenLM (Heafield, 2011) for language model scoring during decoding. Model weights are optimized to maximize B LEU (Papineni et al., 2002) with batch MIRA (Cherry and Foster, 2012) on 1000-best lists. We selected 2000 sentences from the newstest20082012 sets as a development set. The selected sentences obtained high sentence-level B LEU scores when being translated with a baseline phrasebased system, and do each contain less than 30 words for more rapid tuning. newstest2013 and newstest2014 are used as unseen test sets. Translation quality is measured in truecase with B LEU and T ER (Snover et al., 2006).5 7.2 7.2.1"
W14-4018,2009.iwslt-papers.4,1,0.876407,"hat depend on the identity of labels within this set. All sparse features for source labels outside of the core set are inactive. 7 Experimental Setup Experiments We empirically evaluate the effectiveness of preference grammars and soft source syntactic constraints for GHKM translation on the English→German language pair using the standard newstest sets of the Workshop on Statistical Machine Translation (WMT) for testing.4 The experiments are conducted with the open-source Moses implementations of GHKM rule extraction (Williams and Koehn, 2012) and decoding with CYK+ parsing and cube pruning (Hoang et al., 2009). 4 http://www.statmt.org/wmt14/ translation-task.html 152 system GHKM string-to-tree baseline + soft source syntactic constraints + sparse features + sparse features (core = non-composite) + sparse features (core = dev-min-occ100) + sparse features (core = dev-min-occ1000) + hard source syntactic constraints string-to-string (GHKM syntax-directed rule extraction) + preference grammar + soft source syntactic constraints + drop derivations with tsyn (d) = 0 dev B LEU T ER 34.7 47.3 35.1 47.0 35.8 46.5 35.4 46.8 35.6 46.7 35.4 46.9 34.6 47.4 33.8 48.0 33.9 47.7 34.6 47.0 34.0 47.5 newstest2013 B"
W14-4018,D13-1053,0,0.0405122,"or hierarchical machine translation. The major difference is that the features of Marton and Resnik (2008) are only based on the labels from the input trees as seen in tuning and decoding. They penalize violations of constituent boundaries but do not employ syntactic parse annotation of the source side of the training data. We, in contrast, equip the rules with latent source label properties, allowing for features that can check for conformance of input tree labels and source labels that have been seen in training. Other groups have applied similar techniques to a string-to-dependency system (Huang et al., 2013) and—like in our work—a GHKM stringto-tree system (Zhang et al., 2011). Both Huang et al. (2013) and Zhang et al. (2011) store source labels as additional information with the rules. They however investigate somewhat different feature functions than we do. Marton and Resnik (2008) evaluated their method on the NIST Chinese→English and Arabic→English tasks. Huang et al. (2013) and Zhang et al. (2011) present results on the NIST Chinese→English task. We focus our attention on a very different task: English→German. 4 4.1 GHKM String-to-Tree Translation In GHKM string-to-tree translation (Galley e"
W14-4018,N12-1047,0,0.169755,"the rule was extracted (Williams et al., 2014). Rule translation probabilities are smoothed via Good-Turing smoothing. The language model (LM) is a large interpolated 5-gram LM with modified Kneser-Ney smoothing (Kneser and Ney, 1995; Chen and Goodman, 1998). The target side of the parallel corpus and the monolingual German News Crawl corpora are employed as training data. We use the SRILM toolkit (Stolcke, 2002) to train the LM and rely on KenLM (Heafield, 2011) for language model scoring during decoding. Model weights are optimized to maximize B LEU (Papineni et al., 2002) with batch MIRA (Cherry and Foster, 2012) on 1000-best lists. We selected 2000 sentences from the newstest20082012 sets as a development set. The selected sentences obtained high sentence-level B LEU scores when being translated with a baseline phrasebased system, and do each contain less than 30 words for more rapid tuning. newstest2013 and newstest2014 are used as unseen test sets. Translation quality is measured in truecase with B LEU and T ER (Snover et al., 2006).5 7.2 7.2.1 Soft Source Syntactic Constraints Adding the three dense soft source syntactic constraints features from Section 6.1 improves the baseline scores by 0.3 poi"
W14-4018,N03-1017,1,0.0302173,"f mismatch. 6.2 7.1 We work with an English–German parallel training corpus of around 4.5 M sentence pairs (after corpus cleaning). The parallel data originates from three different sources which have been eligible for the constrained track of the ACL 2014 Ninth Workshop on Statistical Machine Translation shared translation task: Europarl (Koehn, 2005), News Commentary, and the Common Crawl corpus as provided on the WMT website. Word alignments are created by aligning the data in both directions with MGIZA++ (Gao and Vogel, 2008) and symmetrizing the two trained alignments (Och and Ney, 2003; Koehn et al., 2003). The German target side training data is parsed with BitPar (Schmid, 2004). We remove grammatical case and function information from the annotation obtained with BitPar and apply right binarization of the German parse trees prior to rule extraction (Wang et al., 2007; Wang et al., 2010; Nadejde et al., 2013). For the soft source syntactic constraints, we parse the English source side of the parallel data with the English Berkeley Parser (Petrov et al., 2006) and produce composite SAMT-style labels as discussed in Section 6. When extracting syntactic rules, we impose several restrictions for c"
W14-4018,P07-2045,1,0.0133524,"of the rule have matches. • A binary feature that fires if a rule is applied which does not possess any source syntactic label vector with a match of the label for the left-hand side non-terminal. This feature penalizes left-hand side mismatches. • A count feature that for each rule application adds a cost equal to the number of right-hand side non-terminals that do not have a match with a corresponding input label in any of the source syntactic label vectors. This feature penalizes right-hand side mismatches. 3 Specifically, we apply relax-parse - -SAMT 2 as implemented in the Moses toolkit (Koehn et al., 2007). 151 The second and third feature are less strict than the first one and give the system a more detailed clue about the magnitude of mismatch. 6.2 7.1 We work with an English–German parallel training corpus of around 4.5 M sentence pairs (after corpus cleaning). The parallel data originates from three different sources which have been eligible for the constrained track of the ACL 2014 Ninth Workshop on Statistical Machine Translation shared translation task: Europarl (Koehn, 2005), News Commentary, and the Common Crawl corpus as provided on the WMT website. Word alignments are created by alig"
W14-4018,N09-1027,0,0.0680691,"rules in the glue grammar are of the following form: Initial rule: X, Q → h<s> X ∼0 , <s> Q∼0 i Glue rules: X, Q → hX ∼0 X ∼1 , Q∼0 B∼1 i for all B ∈ NE Final rule: X, Q → hX ∼0 </s>, Q∼0 </s>i Top rules: X, Q → h<s> X ∼0 </s>, <s> B ∼0 n hsyn (d) = tˆsyn (d) + ∑ hsyn (d j ) . </s>i In this equation, tˆsyn (d) is a simple auxiliary function: ( logtsyn (d) if tsyn (d) 6= 0 tˆsyn (d) = (2) 0 otherwise for all B ∈ NE 5 Preference Grammars Preference grammars store a set of implicit label vectors as additional information with each SCFG rule, along with their relative frequencies given the rule. Venugopal et al. (2009) have introduced this technique for hierarchical phrase-based translation. The implicit label set refines the label set of the underlying synchronous context-free grammar. We apply this idea to GHKM translation by not decorating the target-side non-terminals of the extracted GHKM rules with syntactic labels, but with a single generic label. The (explicit) target non-terminal vocabulary NE thus also contains only the generic non-terminal symbol X, just like the source non-terminal vocabulary NF . The extraction method remains syntax-directed and is still guided by the syntactic annotation over"
W14-4018,2005.mtsummit-papers.11,1,0.0517676,"-hand side mismatches. 3 Specifically, we apply relax-parse - -SAMT 2 as implemented in the Moses toolkit (Koehn et al., 2007). 151 The second and third feature are less strict than the first one and give the system a more detailed clue about the magnitude of mismatch. 6.2 7.1 We work with an English–German parallel training corpus of around 4.5 M sentence pairs (after corpus cleaning). The parallel data originates from three different sources which have been eligible for the constrained track of the ACL 2014 Ninth Workshop on Statistical Machine Translation shared translation task: Europarl (Koehn, 2005), News Commentary, and the Common Crawl corpus as provided on the WMT website. Word alignments are created by aligning the data in both directions with MGIZA++ (Gao and Vogel, 2008) and symmetrizing the two trained alignments (Och and Ney, 2003; Koehn et al., 2003). The German target side training data is parsed with BitPar (Schmid, 2004). We remove grammatical case and function information from the annotation obtained with BitPar and apply right binarization of the German parse trees prior to rule extraction (Wang et al., 2007; Wang et al., 2010; Nadejde et al., 2013). For the soft source syn"
W14-4018,P08-1114,0,0.0213265,"one correspondence. The left-hand side of the rule is a pair of source and target nonterminals, A ∈ NF and B ∈ NE . Decoding is typically carried out with a parsingbased algorithm, in our case a customized version of CYK+ (Chappelier and Rajman, 1998). The parsing algorithm is extended to handle translation candidates and to incorporate language model scores via cube pruning (Chiang, 2007). this paradigm have recently been among the topranked submissions to public evaluation campaigns (Williams et al., 2014; Bojar et al., 2014). Our soft source syntactic constraints features borrow ideas from Marton and Resnik (2008) who proposed a comparable approach for hierarchical machine translation. The major difference is that the features of Marton and Resnik (2008) are only based on the labels from the input trees as seen in tuning and decoding. They penalize violations of constituent boundaries but do not employ syntactic parse annotation of the source side of the training data. We, in contrast, equip the rules with latent source label properties, allowing for features that can check for conformance of input tree labels and source labels that have been seen in training. Other groups have applied similar techniqu"
W14-4018,D07-1078,0,0.520276,"Missing"
W14-4018,W13-2221,1,0.808679,"hared translation task: Europarl (Koehn, 2005), News Commentary, and the Common Crawl corpus as provided on the WMT website. Word alignments are created by aligning the data in both directions with MGIZA++ (Gao and Vogel, 2008) and symmetrizing the two trained alignments (Och and Ney, 2003; Koehn et al., 2003). The German target side training data is parsed with BitPar (Schmid, 2004). We remove grammatical case and function information from the annotation obtained with BitPar and apply right binarization of the German parse trees prior to rule extraction (Wang et al., 2007; Wang et al., 2010; Nadejde et al., 2013). For the soft source syntactic constraints, we parse the English source side of the parallel data with the English Berkeley Parser (Petrov et al., 2006) and produce composite SAMT-style labels as discussed in Section 6. When extracting syntactic rules, we impose several restrictions for composed rules, in particular a maximum number of 100 tree nodes per rule, a maximum depth of seven, and a maximum size of seven. We discard rules with non-terminals on their right-hand side if they are singletons in the training data. For efficiency reasons, we also enforce a limit on the number of label vect"
W14-4018,J10-2004,0,0.0429484,"chine Translation shared translation task: Europarl (Koehn, 2005), News Commentary, and the Common Crawl corpus as provided on the WMT website. Word alignments are created by aligning the data in both directions with MGIZA++ (Gao and Vogel, 2008) and symmetrizing the two trained alignments (Och and Ney, 2003; Koehn et al., 2003). The German target side training data is parsed with BitPar (Schmid, 2004). We remove grammatical case and function information from the annotation obtained with BitPar and apply right binarization of the German parse trees prior to rule extraction (Wang et al., 2007; Wang et al., 2010; Nadejde et al., 2013). For the soft source syntactic constraints, we parse the English source side of the parallel data with the English Berkeley Parser (Petrov et al., 2006) and produce composite SAMT-style labels as discussed in Section 6. When extracting syntactic rules, we impose several restrictions for composed rules, in particular a maximum number of 100 tree nodes per rule, a maximum depth of seven, and a maximum size of seven. We discard rules with non-terminals on their right-hand side if they are singletons in the training data. For efficiency reasons, we also enforce a limit on t"
W14-4018,J03-1002,0,0.0062763,"out the magnitude of mismatch. 6.2 7.1 We work with an English–German parallel training corpus of around 4.5 M sentence pairs (after corpus cleaning). The parallel data originates from three different sources which have been eligible for the constrained track of the ACL 2014 Ninth Workshop on Statistical Machine Translation shared translation task: Europarl (Koehn, 2005), News Commentary, and the Common Crawl corpus as provided on the WMT website. Word alignments are created by aligning the data in both directions with MGIZA++ (Gao and Vogel, 2008) and symmetrizing the two trained alignments (Och and Ney, 2003; Koehn et al., 2003). The German target side training data is parsed with BitPar (Schmid, 2004). We remove grammatical case and function information from the annotation obtained with BitPar and apply right binarization of the German parse trees prior to rule extraction (Wang et al., 2007; Wang et al., 2010; Nadejde et al., 2013). For the soft source syntactic constraints, we parse the English source side of the parallel data with the English Berkeley Parser (Petrov et al., 2006) and produce composite SAMT-style labels as discussed in Section 6. When extracting syntactic rules, we impose sever"
W14-4018,W12-3150,1,0.830324,"such a core set is specified, then only those sparse features are active that depend on the identity of labels within this set. All sparse features for source labels outside of the core set are inactive. 7 Experimental Setup Experiments We empirically evaluate the effectiveness of preference grammars and soft source syntactic constraints for GHKM translation on the English→German language pair using the standard newstest sets of the Workshop on Statistical Machine Translation (WMT) for testing.4 The experiments are conducted with the open-source Moses implementations of GHKM rule extraction (Williams and Koehn, 2012) and decoding with CYK+ parsing and cube pruning (Hoang et al., 2009). 4 http://www.statmt.org/wmt14/ translation-task.html 152 system GHKM string-to-tree baseline + soft source syntactic constraints + sparse features + sparse features (core = non-composite) + sparse features (core = dev-min-occ100) + sparse features (core = dev-min-occ1000) + hard source syntactic constraints string-to-string (GHKM syntax-directed rule extraction) + preference grammar + soft source syntactic constraints + drop derivations with tsyn (d) = 0 dev B LEU T ER 34.7 47.3 35.1 47.0 35.8 46.5 35.4 46.8 35.6 46.7 35.4"
W14-4018,P02-1040,0,0.0923949,"bability of the tree fragment from which the rule was extracted (Williams et al., 2014). Rule translation probabilities are smoothed via Good-Turing smoothing. The language model (LM) is a large interpolated 5-gram LM with modified Kneser-Ney smoothing (Kneser and Ney, 1995; Chen and Goodman, 1998). The target side of the parallel corpus and the monolingual German News Crawl corpora are employed as training data. We use the SRILM toolkit (Stolcke, 2002) to train the LM and rely on KenLM (Heafield, 2011) for language model scoring during decoding. Model weights are optimized to maximize B LEU (Papineni et al., 2002) with batch MIRA (Cherry and Foster, 2012) on 1000-best lists. We selected 2000 sentences from the newstest20082012 sets as a development set. The selected sentences obtained high sentence-level B LEU scores when being translated with a baseline phrasebased system, and do each contain less than 30 words for more rapid tuning. newstest2013 and newstest2014 are used as unseen test sets. Translation quality is measured in truecase with B LEU and T ER (Snover et al., 2006).5 7.2 7.2.1 Soft Source Syntactic Constraints Adding the three dense soft source syntactic constraints features from Section 6"
W14-4018,W14-3324,1,0.771058,"Missing"
W14-4018,P06-1055,0,0.117397,"y aligning the data in both directions with MGIZA++ (Gao and Vogel, 2008) and symmetrizing the two trained alignments (Och and Ney, 2003; Koehn et al., 2003). The German target side training data is parsed with BitPar (Schmid, 2004). We remove grammatical case and function information from the annotation obtained with BitPar and apply right binarization of the German parse trees prior to rule extraction (Wang et al., 2007; Wang et al., 2010; Nadejde et al., 2013). For the soft source syntactic constraints, we parse the English source side of the parallel data with the English Berkeley Parser (Petrov et al., 2006) and produce composite SAMT-style labels as discussed in Section 6. When extracting syntactic rules, we impose several restrictions for composed rules, in particular a maximum number of 100 tree nodes per rule, a maximum depth of seven, and a maximum size of seven. We discard rules with non-terminals on their right-hand side if they are singletons in the training data. For efficiency reasons, we also enforce a limit on the number of label vectors that are stored as additional properties. Label vectors are only stored if they occur at least as often as the 50th most frequent label vector of the"
W14-4018,D11-1019,0,0.0567444,"features of Marton and Resnik (2008) are only based on the labels from the input trees as seen in tuning and decoding. They penalize violations of constituent boundaries but do not employ syntactic parse annotation of the source side of the training data. We, in contrast, equip the rules with latent source label properties, allowing for features that can check for conformance of input tree labels and source labels that have been seen in training. Other groups have applied similar techniques to a string-to-dependency system (Huang et al., 2013) and—like in our work—a GHKM stringto-tree system (Zhang et al., 2011). Both Huang et al. (2013) and Zhang et al. (2011) store source labels as additional information with the rules. They however investigate somewhat different feature functions than we do. Marton and Resnik (2008) evaluated their method on the NIST Chinese→English and Arabic→English tasks. Huang et al. (2013) and Zhang et al. (2011) present results on the NIST Chinese→English task. We focus our attention on a very different task: English→German. 4 4.1 GHKM String-to-Tree Translation In GHKM string-to-tree translation (Galley et al., 2004; Galley et al., 2006; DeNeefe et al., 2007), rules are ext"
W14-4018,C04-1024,0,0.248432,"ound 4.5 M sentence pairs (after corpus cleaning). The parallel data originates from three different sources which have been eligible for the constrained track of the ACL 2014 Ninth Workshop on Statistical Machine Translation shared translation task: Europarl (Koehn, 2005), News Commentary, and the Common Crawl corpus as provided on the WMT website. Word alignments are created by aligning the data in both directions with MGIZA++ (Gao and Vogel, 2008) and symmetrizing the two trained alignments (Och and Ney, 2003; Koehn et al., 2003). The German target side training data is parsed with BitPar (Schmid, 2004). We remove grammatical case and function information from the annotation obtained with BitPar and apply right binarization of the German parse trees prior to rule extraction (Wang et al., 2007; Wang et al., 2010; Nadejde et al., 2013). For the soft source syntactic constraints, we parse the English source side of the parallel data with the English Berkeley Parser (Petrov et al., 2006) and produce composite SAMT-style labels as discussed in Section 6. When extracting syntactic rules, we impose several restrictions for composed rules, in particular a maximum number of 100 tree nodes per rule, a"
W14-4018,W06-3119,0,0.0454667,"of the stringto-tree system remains untouched. The target nonterminals of the SCFG stay syntactified, and the source non-terminal vocabulary is not extended beyond the single generic non-terminal. Source-side syntactic labels are an additional latent property of the rules. We obtain this property by parsing the source side of the training data and collecting the source labels that cover the sourceside span of non-terminals during GHKM rule extraction. As the source-side span is frequently not covered by a constituent in the syntactic parse tree, we employ the composite symbols as suggested by Zollmann and Venugopal (2006) for the SAMT system.3 In cases where a span is still not covered by a symbol, we nevertheless memorize a sourceside syntactic label vector but indicate the failure for the uncovered non-terminal with a special label. The set of source label vectors that are seen with a rule during extraction is stored with it in the rule table as an additional property. This information can be used to implement feature-based soft source syntactic constraints. Table 1 shows an example of a set of source label vectors stored with a grammar rule. The first element of each vector is an implicit sourcesyntactic la"
W14-4018,2006.amta-papers.25,0,0.0274879,"nd rely on KenLM (Heafield, 2011) for language model scoring during decoding. Model weights are optimized to maximize B LEU (Papineni et al., 2002) with batch MIRA (Cherry and Foster, 2012) on 1000-best lists. We selected 2000 sentences from the newstest20082012 sets as a development set. The selected sentences obtained high sentence-level B LEU scores when being translated with a baseline phrasebased system, and do each contain less than 30 words for more rapid tuning. newstest2013 and newstest2014 are used as unseen test sets. Translation quality is measured in truecase with B LEU and T ER (Snover et al., 2006).5 7.2 7.2.1 Soft Source Syntactic Constraints Adding the three dense soft source syntactic constraints features from Section 6.1 improves the baseline scores by 0.3 points B LEU and 0.6 points T ER on newstest2013 and by 0.3 points B LEU and 0.7 points T ER on newstest2014. Somewhat surprisingly, the sparse features from Section 6.2 do not boost translation quality further on any of the two test sets. We observe a considerable improvement on the development set, but it does not carry over to the test sets. We attributed this to an overfitting effect. Our source-side soft syntactic label set o"
W14-4018,2010.amta-papers.8,0,0.0347156,"inally, the function th (Y |d) is defined as th (Y |d) = Feature Computation ∑ Two features are added to the log-linear model combination in order to rate the syntactic wellformedness of derivations. The first feature is similar to the one suggested by Venugopal et al. (2009) and computes a score based on the relative frequencies of implicit label vectors of those rules which are involved in the derivation. The second s∈Sn+1 :s[1]=Y n+1 ! p(s|r) · ∏ ph (s[k]|dk−1 ) k=2 . (5) Note that the denominator in Equation (4) thus equals tsyn (d). 2 Our notational conventions roughly follow the ones by Stein et al. (2010). 150 source label vector (IN+NP, NN, NN) (IN+NP, NNP, NNP) (IN++NP, NNS, NNS) (IN+NP, NP, NP) (PP//SBAR, NP, NP) This concludes the formal specification of the first features. The second feature hauxSyn (d) penalizes rule applications in cases where tsyn (d) evaluates to 0: ( 0 if tsyn (d) 6= 0 hauxSyn (d) = (6) 1 otherwise Table 1: The set of source label vectors (along with their frequencies in the training data) for the rule X, PP-MO → hbetween X ∼1 and X ∼0 , zwischen NN ∼0 und NN ∼1 i. The overall rule frequency is 15. Its intuition is that rule applications that do not contribute to hsy"
W14-4018,N04-1035,0,\N,Missing
W14-4018,W14-3302,1,\N,Missing
W15-3001,W05-0909,0,0.0473932,"asks 1 and 2 provide the same dataset with English-Spanish translations generated by the statistical machine translation (SMT) system, while Task 3 provides two different datasets, for two language pairs: English-German (EN-DE) and German-English (DE-EN) translations taken from all participating systems in WMT13 (Bojar et al., 2013). These datasets were annotated with different labels for quality: for Tasks 1 and 2, the labels were automatically derived from the post-editing of the machine translation output, while for Task 3, scores were computed based on reference translations using Meteor (Banerjee and Lavie, 2005). Any external resource, including additional quality estimation training data, could be used by participants (no distinction between open and close tracks was made). As presented in Section 4.1, participants were also provided with a baseline set of features for each task, and a software package to extract these and other quality estimation features and perform model learning, with suggested methods for all levels of prediction. Participants, described in Section 4.2, could submit up to two systems for each task. Data used to build MT systems or internal system information (such as model scor"
W15-3001,2011.mtsummit-papers.35,0,0.348896,"Missing"
W15-3001,W13-2241,1,0.851171,"Missing"
W15-3001,P13-2097,1,0.801912,"Missing"
W15-3001,W13-2242,0,0.0386206,"Missing"
W15-3001,W14-3339,0,0.0452066,"Missing"
W15-3001,W15-3035,0,0.054515,"Missing"
W15-3001,W11-2103,1,0.524514,"Missing"
W15-3001,W13-2201,1,0.499374,"Missing"
W15-3001,W14-3302,1,0.498006,"Missing"
W15-3001,W14-3340,1,0.54686,"Missing"
W15-3001,W15-3007,0,0.0166876,"Missing"
W15-3001,W15-3006,1,0.827804,"Missing"
W15-3001,W07-0718,1,0.664541,"om 24 institutions were submitted to the ten translation directions in the standard translation task. An additional 7 anonymized systems were included, and were then evaluated both automatically and manually. The quality estimation task had three subtasks, with a total of 10 teams, submitting 34 entries. The pilot automatic postediting task had a total of 4 teams, submitting 7 entries. 1 Introduction We present the results of the shared tasks of the Workshop on Statistical Machine Translation (WMT) held at EMNLP 2015. This workshop builds on eight previous WMT workshops (Koehn and Monz, 2006; Callison-Burch et al., 2007, 2008, 2009, 2010, 2011, 2012; Bojar et al., 2013, 2014). This year we conducted five official tasks: a translation task, a quality estimation task, a metrics task, a tuning task1 , and a automatic postediting task. In the translation task (§2), participants were asked to translate a shared test set, optionally restricting themselves to the provided training data. We held ten translation tasks this year, between English and each of Czech, French, German, Finnish, and Russian. The Finnish translation 1 The metrics and tuning tasks are reported in separate papers (Stanojevi´c et al., 2015a,b)."
W15-3001,2014.amta-researchers.13,0,0.0200349,"Missing"
W15-3001,W08-0309,1,0.406319,"2. machine translation and automatic evaluation or prediction of translation quality. 2 Overview of the Translation Task The recurring task of the workshop examines translation between English and other languages. As in the previous years, the other languages include German, French, Czech and Russian. Finnish replaced Hindi as the special language this year. Finnish is a lesser resourced language compared to the other languages and has challenging morphological properties. Finnish represents also a different language family that we had not tackled since we included Hungarian in 2008 and 2009 (Callison-Burch et al., 2008, 2009). We created a test set for each language pair by translating newspaper articles and provided training data, except for French, where the test set was drawn from user-generated comments on the news articles. 2.1 2.3 We received 68 submissions from 24 institutions. The participating institutions and their entry names are listed in Table 2; each system did not necessarily appear in all translation tasks. We also included 1 commercial off-the-shelf MT system and 6 online statistical MT systems, which we anonymized. For presentation of the results, systems are treated as either constrained"
W15-3001,W15-3025,1,0.914094,"teps aimed at removing duplicates and those triplets in which any of the elements (source, target, post-edition) was either too long or too short compared to the others, or included tags or special problematic symbols. The main reason for random sampling was to induce some homogeneity across the three datasets and, in turn, Automatic Post-editing Task This year WMT hosted for the first time a shared task on automatic post-editing (APE) for machine translation. The task requires to automatically correct the errors present in a machine translated text. As pointed out in Parton et al. (2012) and Chatterjee et al. (2015b), from the application point of view, APE components would make it possible to: • Improve MT output by exploiting information unavailable to the decoder, or by per22 The original triplets were provided by Unbabel (https: //unbabel.com/). 28 in terms of Translation Error Rate (TER) (Snover et al., 2006a), an evaluation metric commonly used in MT-related tasks (e.g. in quality estimation) to measure the minimum edit distance between an automatic translation and a reference translation.23 Systems are ranked based on the average TER calculated on the test set by using the TERcom24 software: lowe"
W15-3001,W10-1703,1,0.163282,"Missing"
W15-3001,P15-2026,1,0.797338,"teps aimed at removing duplicates and those triplets in which any of the elements (source, target, post-edition) was either too long or too short compared to the others, or included tags or special problematic symbols. The main reason for random sampling was to induce some homogeneity across the three datasets and, in turn, Automatic Post-editing Task This year WMT hosted for the first time a shared task on automatic post-editing (APE) for machine translation. The task requires to automatically correct the errors present in a machine translated text. As pointed out in Parton et al. (2012) and Chatterjee et al. (2015b), from the application point of view, APE components would make it possible to: • Improve MT output by exploiting information unavailable to the decoder, or by per22 The original triplets were provided by Unbabel (https: //unbabel.com/). 28 in terms of Translation Error Rate (TER) (Snover et al., 2006a), an evaluation metric commonly used in MT-related tasks (e.g. in quality estimation) to measure the minimum edit distance between an automatic translation and a reference translation.23 Systems are ranked based on the average TER calculated on the test set by using the TERcom24 software: lowe"
W15-3001,W12-3102,1,0.571688,"ator agreement, both for inter- and intra-annotator agreement scores. not included to make the graphs viewable). The plots cleary suggest that a fair comparison of systems of different kinds cannot rely on automatic scores. Rule-based systems receive a much lower BLEU score than statistical systems (see for instance English–German, e.g., PROMT- RULE). The same is true to a lesser degree for statistical syntax-based systems (see English–German, UEDIN - SYNTAX ) and online systems that were not tuned to the shared task (see Czech–English, CU TECTO vs. the cluster of tuning task systems TT*). 4 (Callison-Burch et al., 2012; Bojar et al., 2013, 2014), with tasks including both sentence and word-level estimation, using new training and test datasets, and an additional task: document-level prediction. The goals of this year’s shared task were: • Advance work on sentence- and wordlevel quality estimation by providing larger datasets. • Investigate the effectiveness of quality labels, features and learning methods for documentlevel prediction. Quality Estimation Task • Explore differences between sentence-level and document-level prediction. The fourth edition of the WMT shared task on quality estimation (QE) of mac"
W15-3001,W15-3008,0,0.0135172,"secondary key. The results for the scoring variant are presented in Table 9, sorted from best to worst by using the MAE metric scores as primary key and the RMSE metric scores as secondary key. Pearson’s r coefficients for all systems against HTER is given in Table 10. As discussed in (Graham, 2015), the results according to this metric can rank participating systems differently. In particular, we note the SHEF/GP submission, are which is deemed significantly worse than the baseline system according to MAE, but substantially better than the baseline according to Pearson’s correlation. Graham (2015) argues that the use of MAE as evaluation score for quality estimation tasks is inadequate, as MAE is very sensitive to variance. This means that a system that outputs predictions with high variance is more likely to have high MAE score, even if the distribution follows that of the true labels. Interestingly, according to Pearson’s correlation, the systems are • Source sentence (English). • Automatic translation (Spanish). • Manual post-edition of the automatic translation. • Word-level binary (“OK”/“BAD”) labelling of the automatic translation. The binary labels for the datasets were acquired"
W15-3001,W09-0401,1,0.251315,"Missing"
W15-3001,W15-3009,0,0.0460438,"Missing"
W15-3001,W15-3010,0,0.035772,"Missing"
W15-3001,P10-4002,0,0.00861255,"t sentences and number of punctuation marks in source and target sentences. All other features were averaged. The implementation for document-level feature extraction is available in Q U E ST ++ (Specia et al., 2015).12 These features were then used to train a SVR algorithm with RBF kernel using the SCIKIT- LEARN toolkit. The γ,  and C parameters were optimised via grid search with 5-fold cross validation on the training set. • Source token aligned to the target token, its left and right contexts of one word. The alignments were produced with the force align.py script, which is part of cdec (Dyer et al., 2010). It allows to align new parallel data with a pre-trained alignment model built with the cdec word aligner (fast align). The alignment model was trained on the Europarl corpus (Koehn, 2005). • Boolean dictionary features: whether target token is a stopword, a punctuation mark, a proper noun, a number. 4.2 Participants Table 7 lists all participating teams submitting systems to any of the tasks. Each team was allowed up to two submissions for each task and language pair. In the descriptions below, participation in specific tasks is denoted by a task identifier. • Target language model features:"
W15-3001,W15-3011,0,0.0373266,"Missing"
W15-3001,W15-3036,0,0.0738999,"Missing"
W15-3001,W15-3012,0,0.0168435,"secondary key. The results for the scoring variant are presented in Table 9, sorted from best to worst by using the MAE metric scores as primary key and the RMSE metric scores as secondary key. Pearson’s r coefficients for all systems against HTER is given in Table 10. As discussed in (Graham, 2015), the results according to this metric can rank participating systems differently. In particular, we note the SHEF/GP submission, are which is deemed significantly worse than the baseline system according to MAE, but substantially better than the baseline according to Pearson’s correlation. Graham (2015) argues that the use of MAE as evaluation score for quality estimation tasks is inadequate, as MAE is very sensitive to variance. This means that a system that outputs predictions with high variance is more likely to have high MAE score, even if the distribution follows that of the true labels. Interestingly, according to Pearson’s correlation, the systems are • Source sentence (English). • Automatic translation (Spanish). • Manual post-edition of the automatic translation. • Word-level binary (“OK”/“BAD”) labelling of the automatic translation. The binary labels for the datasets were acquired"
W15-3001,W15-4903,0,0.0623526,"Missing"
W15-3001,W15-3013,1,0.843414,"Missing"
W15-3001,W11-2123,0,0.0240468,"27,101 5,966 8,816 SRC 13,701 3,765 5,307 Lemmas TGT PE 7,624 7,689 2,810 2,819 3,778 3,814 Table 18: Data statistics. and classifying each word of a sentence as good or bad. An automatic translation to be post-edited is first decoded by our SPE system, then fed into one of the classifiers identified as SVM180feat and RNN. The HTER estimator selects the translation with the lower score while the binary word-level classifier selects the translation with the fewer amount of bad tags. The official evaluation of the shared task show an advantage of the RNN approach compared to SVM. KenLM toolkit (Heafield, 2011) for standard ngram modeling with an n-gram length of 5. Finally, the APE system was tuned on the development set, optimizing TER with Minimum Error Rate Training (Och, 2003). The results of this additional term of comparison, computed for both evaluation modalities (case sensitive/insensitive), are also reported in Tables 20 and 21. For each submitted run, the statistical significance of performance differences with respect to the baseline and the re-implementation of Simard et al. (2007) is calculated with the bootstrap test (Koehn, 2004). 5.2 FBK. The two runs submitted by FBK (Chatterjee e"
W15-3001,W08-0509,0,0.0268564,"ere collected by means of a crowdsourcing platform developed by the data provider. Monolingual translation as another term of comparison. To get further insights about the progress with respect to previous APE methods, participants’ results are also analysed with respect to another term of comparison: a reimplementation of the state-of-the-art approach firstly proposed by Simard et al. (2007).27 For this purpose, a phrase-based SMT system based on Moses (Koehn et al., 2007) is used. Translation and reordering models were estimated following the Moses protocol with default setup using MGIZA++ (Gao and Vogel, 2008) for word alignment. For language modeling we used the Test data (1, 817 instances) consists of (source, target) pairs having similar characteristics of those in the training set. Human post-editions of the test target instances were left apart to measure system performance. The data creation procedure adopted, as well as the origin and the domain of the texts pose specific challenges to the participating systems. As discussed in Section 5.4, the results of this pilot task can be partially explained in light of such challenges. This dataset, however, has three major advantages that made it sui"
W15-3001,W15-3014,0,0.0344469,"Missing"
W15-3001,P15-1174,0,0.0105686,"415 for test. Since no human annotation exists for the quality of entire paragraphs (or documents), Meteor against reference translations was used as quality label for this task. Meteor was calculated using its implementation within the Asyia toolkit, with the following settings: exact match, tokenised and case insensitive (Gim´enez and M`arquez, 2010). guage pairs. All systems were significantly better than the baseline. However, the difference between the baseline system and all submissions was much lower in the scoring evaluation than in the ranking evaluation. Following the suggestion in (Graham, 2015), Table 16 shows an alternative ranking of systems considering Pearson’s r correlation results. The alternative ranking differs from the official ranking in terms of MAE: for EN-DE, RTMDCU/RTM-FS-SVR is no longer in the winning group, while for DE-EN, USHEF/QUEST-DISCBO and USAAR-USHEF/BFF did not show statistically significant difference against the baseline. However, as with Task 1 these results are the same as the official ones in terms of DeltaAvg. 4.6 Discussion In what follows, we discuss the main findings of this year’s shared task based on the goals we had previously identified for it."
W15-3001,W04-3250,1,0.485885,"f the RNN approach compared to SVM. KenLM toolkit (Heafield, 2011) for standard ngram modeling with an n-gram length of 5. Finally, the APE system was tuned on the development set, optimizing TER with Minimum Error Rate Training (Och, 2003). The results of this additional term of comparison, computed for both evaluation modalities (case sensitive/insensitive), are also reported in Tables 20 and 21. For each submitted run, the statistical significance of performance differences with respect to the baseline and the re-implementation of Simard et al. (2007) is calculated with the bootstrap test (Koehn, 2004). 5.2 FBK. The two runs submitted by FBK (Chatterjee et al., 2015a) are based on combining the statistical phrase-based post-editing approach proposed by Simard et al. (2007) and its most significant variant proposed by B´echara et al. (2011). The APE systems are built-in an incremental manner. At each stage of the APE pipeline, the best configuration of a component is decided and then used in the next stage. The APE pipeline begins with the selection of the best language model from several language models trained on different types and quantities of data. The next stage addresses the possible"
W15-3001,2005.mtsummit-papers.11,1,0.0759255,"(Specia et al., 2015).12 These features were then used to train a SVR algorithm with RBF kernel using the SCIKIT- LEARN toolkit. The γ,  and C parameters were optimised via grid search with 5-fold cross validation on the training set. • Source token aligned to the target token, its left and right contexts of one word. The alignments were produced with the force align.py script, which is part of cdec (Dyer et al., 2010). It allows to align new parallel data with a pre-trained alignment model built with the cdec word aligner (fast align). The alignment model was trained on the Europarl corpus (Koehn, 2005). • Boolean dictionary features: whether target token is a stopword, a punctuation mark, a proper noun, a number. 4.2 Participants Table 7 lists all participating teams submitting systems to any of the tasks. Each team was allowed up to two submissions for each task and language pair. In the descriptions below, participation in specific tasks is denoted by a task identifier. • Target language model features: – The order of the highest order n-gram which starts or ends with the target token. – Backoff behaviour of the n-grams (ti−2 , ti−1 , ti ), (ti−1 , ti , ti+1 ), (ti , ti+1 , ti+2 ), where"
W15-3001,W15-3039,1,0.80659,"Missing"
W15-3001,J10-4005,0,0.0619684,"Missing"
W15-3001,J82-2005,0,0.818658,"Missing"
W15-3001,W14-3342,0,0.0353204,"t although the system is referred to as “baseline”, it is in fact a strong system. It has proved robust across a range of language pairs, MT systems, and text domains for predicting various forms of post-editing effort (Callison-Burch et al., 2012; Bojar et al., 2013, 2014). Word-level baseline system: For Task 2, the baseline features were extracted with the M AR MOT tool9 . For the baseline system we used a number of features that have been found the most informative in previous research on word-level quality estimation. Our baseline set of features is loosely based on the one described in (Luong et al., 2014). It contains the following 25 features: Baseline systems Sentence-level baseline system: For Task 1, Q U E ST7 (Specia et al., 2013) was used to extract 17 MT system-independent features from the source and translation (target) files and parallel corpora: • Word count in the source and target sentences, source and target token count ratio. Although these features are sentence-level (i.e. their values will be the same for all words in a sentence), but the length of a sentence might influence the probability of a word being incorrect. • Number of tokens in the source and target sentences. • Ave"
W15-3001,W13-2248,0,0.0824189,"Missing"
W15-3001,W06-3114,1,0.427665,"translation systems from 24 institutions were submitted to the ten translation directions in the standard translation task. An additional 7 anonymized systems were included, and were then evaluated both automatically and manually. The quality estimation task had three subtasks, with a total of 10 teams, submitting 34 entries. The pilot automatic postediting task had a total of 4 teams, submitting 7 entries. 1 Introduction We present the results of the shared tasks of the Workshop on Statistical Machine Translation (WMT) held at EMNLP 2015. This workshop builds on eight previous WMT workshops (Koehn and Monz, 2006; Callison-Burch et al., 2007, 2008, 2009, 2010, 2011, 2012; Bojar et al., 2013, 2014). This year we conducted five official tasks: a translation task, a quality estimation task, a metrics task, a tuning task1 , and a automatic postediting task. In the translation task (§2), participants were asked to translate a shared test set, optionally restricting themselves to the provided training data. We held ten translation tasks this year, between English and each of Czech, French, German, Finnish, and Russian. The Finnish translation 1 The metrics and tuning tasks are reported in separate papers (S"
W15-3001,W15-3015,0,0.0443946,"Missing"
W15-3001,W15-3016,0,0.0442638,"Missing"
W15-3001,W15-3037,0,0.0800739,"Missing"
W15-3001,P03-1021,0,0.0587969,"utomatic translation to be post-edited is first decoded by our SPE system, then fed into one of the classifiers identified as SVM180feat and RNN. The HTER estimator selects the translation with the lower score while the binary word-level classifier selects the translation with the fewer amount of bad tags. The official evaluation of the shared task show an advantage of the RNN approach compared to SVM. KenLM toolkit (Heafield, 2011) for standard ngram modeling with an n-gram length of 5. Finally, the APE system was tuned on the development set, optimizing TER with Minimum Error Rate Training (Och, 2003). The results of this additional term of comparison, computed for both evaluation modalities (case sensitive/insensitive), are also reported in Tables 20 and 21. For each submitted run, the statistical significance of performance differences with respect to the baseline and the re-implementation of Simard et al. (2007) is calculated with the bootstrap test (Koehn, 2004). 5.2 FBK. The two runs submitted by FBK (Chatterjee et al., 2015a) are based on combining the statistical phrase-based post-editing approach proposed by Simard et al. (2007) and its most significant variant proposed by B´echara"
W15-3001,padro-stanilovsky-2012-freeling,0,0.011024,"o rankings are not identical, none of the systems was particularly penalized by the case sensitive evaluation. Indeed, individual differences in the two modes are always close to the same value (∼ 0.7 TER difference) measured for the two baselines. USAAR-SAPE. The USAAR-SAPE system (Pal et al., 2015b) is designed with three basic components: corpus preprocessing, hybrid word alignment and a state-of-the-art phrase-based SMT system integrated with the hybrid word alignment. The preprocessing of the training corpus is carried out by stemming the Spanish MT output and the PE data using Freeling (Padr and Stanilovsky, 2012). The hybrid word alignment method combines different kinds of word alignment: GIZA++ word alignment with the 31 ID Baseline FBK Primary LIMSI Primary USAAR-SAPE LIMSI Contrastive Abu-MaTran Primary FBK Contrastive (Simard et al., 2007) Abu-MaTran Contrastive Avg. TER 22.913 23.228 23.331 23.426 23.573 23.639 23.649 23.839 24.715 ID Baseline LIMSI Primary FBK Primary USAAR-SAPE Abu-MaTran Primary LIMSI Contrastive FBK Contrastive (Simard et al., 2007) Abu-MaTran Contrastive Table 20: Official results for the WMT15 Automatic Post-editing task – average TER (↓) case sensitive. Table 21: Official"
W15-3001,W15-3038,0,0.0668224,"Missing"
W15-3001,W13-2814,0,0.0155219,"ject (Prompsit) Fondazione Bruno Kessler, Italy (Chatterjee et al., 2015a) Laboratoire d’Informatique pour la M´ecanique et les Sciences de l’Ing´enieur, France (Wisniewski et al., 2015) Saarland University, Germany & Jadavpur University, India (Pal et al., 2015b) Table 19: Participants in the WMT15 Automatic Post-editing pilot task. grow-diag-final-and (GDFA) heuristic (Koehn, 2010), SymGiza++ (Junczys-Dowmunt and Szal, 2011), the Berkeley aligner (Liang et al., 2006), and the edit distance-based aligners (Snover et al., 2006a; Lavie and Agarwal, 2007). These different word alignment tables (Pal et al., 2013) are combined by a mathematical union method. For the phrase-based SMT system various maximum phrase lengths for the translation model and n–gram settings for the language model are used. The best results in terms of BLEU (Papineni et al., 2002) score are achieved by a maximum phrase length of 7 for the translation model and a 5-gram language model. the model. These features measure the similarity and the reliability of the translation options and help to improve the precision of the resulting APE system. LIMSI. For the first edition of the APE shared task LIMSI submitted two systems (Wisniews"
W15-3001,W07-0734,0,0.0277649,"Abu-MaTran FBK LIMSI USAAR-SAPE Participating team Abu-MaTran Project (Prompsit) Fondazione Bruno Kessler, Italy (Chatterjee et al., 2015a) Laboratoire d’Informatique pour la M´ecanique et les Sciences de l’Ing´enieur, France (Wisniewski et al., 2015) Saarland University, Germany & Jadavpur University, India (Pal et al., 2015b) Table 19: Participants in the WMT15 Automatic Post-editing pilot task. grow-diag-final-and (GDFA) heuristic (Koehn, 2010), SymGiza++ (Junczys-Dowmunt and Szal, 2011), the Berkeley aligner (Liang et al., 2006), and the edit distance-based aligners (Snover et al., 2006a; Lavie and Agarwal, 2007). These different word alignment tables (Pal et al., 2013) are combined by a mathematical union method. For the phrase-based SMT system various maximum phrase lengths for the translation model and n–gram settings for the language model are used. The best results in terms of BLEU (Papineni et al., 2002) score are achieved by a maximum phrase length of 7 for the translation model and a 5-gram language model. the model. These features measure the similarity and the reliability of the translation options and help to improve the precision of the resulting APE system. LIMSI. For the first edition of"
W15-3001,W15-3017,0,0.0328586,"Missing"
W15-3001,W15-3026,0,0.0488223,"Missing"
W15-3001,W15-3040,1,0.889327,"HIDDEN Participating team Dublin City University, Ireland and University of Sheffield, UK (Logacheva et al., 2015) Heidelberg University, Germany (Kreutzer et al., 2015) Lorraine Laboratory of Research in Computer Science and its Applications, France (Langlois, 2015) Dublin City University, Ireland (Bicici et al., 2015) Shenyang Aerospace University, China (Shang et al., 2015) University of Sheffield Team 1, UK (Shah et al., 2015) Alicant University, Spain (Espl`a-Gomis et al., 2015a) Ghent University, Belgium (Tezcan et al., 2015) University of Sheffield, UK and Saarland University, Germany (Scarton et al., 2015a) University of Sheffield, UK (Scarton et al., 2015a) Undisclosed Table 7: Participants in the WMT15 quality estimation shared task. one from the official training data. Pseudoreferences were produced by three online systems. These features measure the intersection between n-gram sets of the target sentence and of the pseudo-references. Three sets of features were extracted from each online system, and a fourth feature was extracted measuring the inter-agreement among the three online systems and the target system. and fine-tuned for the quality estimation classification task by back-propagat"
W15-3001,W15-4916,1,0.80858,"Missing"
W15-3001,P02-1040,0,0.108957,"ndia (Pal et al., 2015b) Table 19: Participants in the WMT15 Automatic Post-editing pilot task. grow-diag-final-and (GDFA) heuristic (Koehn, 2010), SymGiza++ (Junczys-Dowmunt and Szal, 2011), the Berkeley aligner (Liang et al., 2006), and the edit distance-based aligners (Snover et al., 2006a; Lavie and Agarwal, 2007). These different word alignment tables (Pal et al., 2013) are combined by a mathematical union method. For the phrase-based SMT system various maximum phrase lengths for the translation model and n–gram settings for the language model are used. The best results in terms of BLEU (Papineni et al., 2002) score are achieved by a maximum phrase length of 7 for the translation model and a 5-gram language model. the model. These features measure the similarity and the reliability of the translation options and help to improve the precision of the resulting APE system. LIMSI. For the first edition of the APE shared task LIMSI submitted two systems (Wisniewski et al., 2015). The first one is based on the approach of Simard et al. (2007) and considers the APE task as a monolingual translation between a translation hypothesis and its post-edition. This straightforward approach does not succeed in imp"
W15-3001,2012.eamt-1.34,0,0.0799883,"Missing"
W15-3001,W15-3023,0,0.0267499,"Missing"
W15-3001,W15-3018,0,0.0412931,"Missing"
W15-3001,W15-3041,1,0.847113,"Missing"
W15-3001,potet-etal-2012-collection,0,0.011237,"Missing"
W15-3001,W15-3042,0,0.0858502,"Missing"
W15-3001,W15-3019,0,0.0362545,"Missing"
W15-3001,N07-1064,0,0.644928,"nsitive) are reported in Tables 20 and 21. • The target (TGT) is a tokenized Spanish translation of the source, produced by an unknown MT system; • The human post-edition (PE) is a manuallyrevised version of the target. PEs were collected by means of a crowdsourcing platform developed by the data provider. Monolingual translation as another term of comparison. To get further insights about the progress with respect to previous APE methods, participants’ results are also analysed with respect to another term of comparison: a reimplementation of the state-of-the-art approach firstly proposed by Simard et al. (2007).27 For this purpose, a phrase-based SMT system based on Moses (Koehn et al., 2007) is used. Translation and reordering models were estimated following the Moses protocol with default setup using MGIZA++ (Gao and Vogel, 2008) for word alignment. For language modeling we used the Test data (1, 817 instances) consists of (source, target) pairs having similar characteristics of those in the training set. Human post-editions of the test target instances were left apart to measure system performance. The data creation procedure adopted, as well as the origin and the domain of the texts pose specifi"
W15-3001,W15-3022,0,0.0629217,"Missing"
W15-3001,P15-4020,1,0.0689693,"://github.com/lspecia/quest 14 http://scikit-learn.org/ https://github.com/qe-team/marmot • Target token, its left and right contexts of one word. Document-level baseline system: For Task 3, the baseline features for sentence-level prediction were used. These are aggregated by summing or averaging their values for the entire document. Features that were summed: number of tokens in the source and target sentences and number of punctuation marks in source and target sentences. All other features were averaged. The implementation for document-level feature extraction is available in Q U E ST ++ (Specia et al., 2015).12 These features were then used to train a SVR algorithm with RBF kernel using the SCIKIT- LEARN toolkit. The γ,  and C parameters were optimised via grid search with 5-fold cross validation on the training set. • Source token aligned to the target token, its left and right contexts of one word. The alignments were produced with the force align.py script, which is part of cdec (Dyer et al., 2010). It allows to align new parallel data with a pre-trained alignment model built with the cdec word aligner (fast align). The alignment model was trained on the Europarl corpus (Koehn, 2005). • Boole"
W15-3001,W15-3027,0,0.0625354,"Missing"
W15-3001,P13-4014,1,0.762876,"Missing"
W15-3001,2013.mtsummit-papers.15,0,0.055239,"these rules is based on an analysis of the most frequent error corrections and aims at: i) predicting word case; ii) predicting exclamation and interrogation marks; and iii) predicting verbal endings. Experiments with this approach show that this system also hurts translation quality. An in-depth analysis revealed that this negative result is mainly explained by two reasons: i) most of the post-edition operations are nearly unique, which makes very difficult to generalize from a small amount of data; and ii) even when they are not, the high variability of post-editing, already pointed out by Wisniewski et al. (2013), results in predicting legitimate corrections that have not been made by the annotators, therefore preventing from improving over the baseline. 5.3 Results The official results achieved by the participating systems are reported in Tables 20 and 21. The seven runs submitted are sorted based on the average TER they achieve on test data. Table 20 shows the results computed in case sensitive mode, while Table 21 provides scores computed in the case insensitive mode. Both rankings reveal an unexpected outcome: none of the submitted runs was able to beat the baselines (i.e. average TER scores of 22"
W15-3001,W15-3032,1,0.810291,"Missing"
W15-3001,W15-3031,1,0.376914,"Missing"
W15-3001,W15-3020,1,0.808362,"Missing"
W15-3001,W15-3043,0,0.0443554,"Missing"
W15-3001,W15-3021,0,0.038175,"Missing"
W15-3001,P07-2045,1,\N,Missing
W15-3001,W15-3004,0,\N,Missing
W15-3001,2015.eamt-1.4,0,\N,Missing
W15-3001,N06-1014,0,\N,Missing
W15-3001,2015.eamt-1.17,1,\N,Missing
W15-3001,2012.iwslt-papers.12,0,\N,Missing
W15-3013,D14-1132,0,0.0417768,"igated sparse lexicalized reordering features (Section 2.4) on the German-English language pair in both translation directions. Two methods for learning the weights of the sparse lexicalized reordering feature set have been compared: (1.) direct tuning in MIRA along with all other features in the model combination (sparse LR (MIRA)), and (2.) separate optimization with stochastic gradient descent (SGD) with a maximum expected B LEU objective (sparse LR (SGD)). For the latter variant, we used the MT tuning set for training (13 573 sentence pairs) and otherwise followed the approach outlined by Auli et al. (2014). We tuned the baseline feature weights with MIRA before SGD training and ran two final MIRA iterations after it. SGD training was stopped after 80 epochs. Empirical results for the German-English language pair are presented in Table 5. We observe minor gains of up to +0.2 points B LEU. The results are not consistent in the two translation directions: The MIRA-trained variant seems to perform better when translating from German, the SGD-trained variant when translating to German. However, in both cases the baseline score is almost identical to the best results with sparse lexicalized reorderin"
W15-3013,D11-1033,0,0.0915467,"Missing"
W15-3013,N12-1047,0,0.185989,"Missing"
W15-3013,N13-1003,0,0.0324335,"a to train 5gram language models with modified Kneser-Ney smoothing (Chen and Goodman, 1998). Typically, language models for each monolingual corpus were first trained using either KenLM (Heafield et al., 2013) or the SRILM toolkit (Stolcke, 2002) and then linearly interpolated using weights tuned to minimize perplexity on the development set. 3.4 Sparse Lexicalized Reordering Baseline Features We follow the standard approach to SMT of scoring translation hypotheses using a weighted linear combination of features. The core features of our We implemented sparse lexicalized reordering features (Cherry, 2013) in Moses and evaluated 127 Baseline (no clusters) Comprehensive setup w/o sparse features w/o language model w/o reordering model w/o operation sequence model de-en 28.0 28.5 (+.5) 28.2 (–.3) 28.3 (–.2) 28.5 (±.0) 28.3 (–.2) en-de 20.5 20.5 (±.0) 20.4 (–.1) 20.5 (±.0) 20.5 (±.0) 20.3 (–.1) cs-en 29.1 29.7 (+.6) 29.6 (–.1) 29.5 (–.2) 29.7 (±.0) en-cs 21.2 21.8 (+.6) 21.7 (–.1) 21.4 (–.4) 21.8 (±.0) 21.7 (–.1) ru-en 31.8 32.3 (+.5) 32.2 (–.1) 31.5 (–.8) 32.3 (±.0) 32.0 (–.3) en-ru 29.1 29.7 (+.6) 30.0 (+.3) 29.2 (–.6) 29.8 (+.1) 29.5 (–.2) avg ∆ +.5 –.2 –.4 ±.0 –.2 Table 1: Use of additional fe"
W15-3013,P05-1066,1,0.679903,"the OPUS (Tiedemann, 2012) par129 4.3 System Baseline Submitted BiLM source & combined & NPLM Czech↔English The development of the Czech↔English systems followed the ideas in Section 2.3, i.e., with a focus on word classes (50, 200, 600 classes) for all component models. We combined the test sets from 2008 to 2012 for tuning. No neural language model or bilingual language model was used. 4.4 Table 4: Experimental results (cased B LEU) for English→Russian averaged over newstest2013 and newstest2014. Russian↔English From German. For translation from German, we applied syntactic pre-reordering (Collins et al., 2005) and compound splitting (Koehn and Knight, 2003) in a preprocessing step on the source side. A rich set of translation factors was exploited in addition to word surface forms: Och clusters (50 classes), morphological tags, partof-speech tags, and word stems on the German side (Schmid, 2000), as well as Och clusters (50 classes), part-of-speech tags (Ratnaparkhi, 1996), and word stems (Porter, 1980) on the English side. The factors were utilized in the translation model and in OSMs. The lexicalized reordering model was trained on stems. Individual 7gram Och cluster LMs were trained with KenLM’s"
W15-3013,2014.iwslt-evaluation.7,1,0.858337,"mission we tested bilingual LMs on the French↔English tasks and on English→Russian task. For French↔English, we had resource issues4 in training such large Introduction The Edinburgh/JHU phrase-based translation systems for our participation in the WMT 2015 shared translation task1 are based on the open source Moses toolkit (Koehn et al., 2007). We built upon Edinburgh’s strong baselines from WMT submissions in previous years (Durrani et al., 2014a) as well as our recent research within the framework of other evaluation campaigns and projects such as IWSLT2 and EU-BRIDGE3 (Birch et al., 2014; Freitag et al., 2014a; Freitag et al., 2014b). We first discuss novel features that we integrated into our systems for the 2015 Edinburgh/JHU submission. Next we give a general system overview with details on our training pipeline and decoder configuration. We finally present empirical results for the individual language pairs and translation directions. 1 http://www.statmt.org/wmt15/ http://workshop2014.iwslt.org 3 http://www.eu-bridge.eu 4 These can now be addressed using the -mmap option to create a binarized version of the corpus which is then memory-mapped. 2 126 Proceedings of the Tenth Workshop on Statisti"
W15-3013,P14-1129,0,0.0621031,"Missing"
W15-3013,P13-2071,1,0.880126,"-based feature functions are used in all cases. B LEU scores on newstest2014 are reported. 4 model are a 5-gram LM score, phrase translation and lexical translation scores, word and phrase penalties, and a linear distortion score. The phrase translation probabilities are smoothed with GoodTuring smoothing (Foster et al., 2006). We used the hierarchical lexicalized reordering model (Galley and Manning, 2008) with 4 possible orientations (monotone, swap, discontinuous left and discontinuous right) in both left-to-right and rightto-left direction. We also used the operation sequence model (OSM) (Durrani et al., 2013) with 4 count based supportive features. We further employed domain indicator features (marking which training corpus each phrase pair was found in), binary phrase count indicator features, sparse phrase length features, and sparse source word deletion, target word insertion, and word translation features (limited to the top K words in each language, typically with K = 50). 3.5 In this section we describe peculiarities of individual systems and present experimental results. 4.1 French↔English Our submitted systems for the French-English language pair are quite similar for the two translation d"
W15-3013,D08-1089,0,0.29008,"ature functions based on Och clusters (see Section 2.3). The last four lines refer to ablation studies where one of the sets of clustered feature functions is removed from the comprehensive setup. Note that the word-based feature functions are used in all cases. B LEU scores on newstest2014 are reported. 4 model are a 5-gram LM score, phrase translation and lexical translation scores, word and phrase penalties, and a linear distortion score. The phrase translation probabilities are smoothed with GoodTuring smoothing (Foster et al., 2006). We used the hierarchical lexicalized reordering model (Galley and Manning, 2008) with 4 possible orientations (monotone, swap, discontinuous left and discontinuous right) in both left-to-right and rightto-left direction. We also used the operation sequence model (OSM) (Durrani et al., 2013) with 4 count based supportive features. We further employed domain indicator features (marking which training corpus each phrase pair was found in), binary phrase count indicator features, sparse phrase length features, and sparse source word deletion, target word insertion, and word translation features (limited to the top K words in each language, typically with K = 50). 3.5 In this"
W15-3013,W08-0509,0,0.0395025,"morphological tags, and basically no additional gains were observed due to the class based feature functions. 2.4 3 3.1 System Overview Preprocessing The training data was preprocessed using scripts from the Moses toolkit. We first normalized the data using the normalize-punctuation.perl script, then performed tokenization (using the -a option), and then truecasing. We did not perform any corpus filtering other than the standard Moses method, which removes sentence pairs with extreme length ratios. 3.2 Word Alignment For word alignment we used either fast_align (Dyer et al., 2013) or MGIZA++ (Gao and Vogel, 2008), followed by the standard grow-diag-final-and symmetrization heuristic. An empirical comparison of fast_align and MGIZA++ on the FinnishEnglish and English-Russian language pairs using the constrained data sets did not reveal any significant difference. 3.3 Language Model We used all available monolingual data to train 5gram language models with modified Kneser-Ney smoothing (Chen and Goodman, 1998). Typically, language models for each monolingual corpus were first trained using either KenLM (Heafield et al., 2013) or the SRILM toolkit (Stolcke, 2002) and then linearly interpolated using weig"
W15-3013,W14-3309,1,0.921919,"at test time the alignment is supplied by the decoder. The bilingual LM is trained using a feedforward neural network and we use the NPLM toolkit for this. Prior to submission we tested bilingual LMs on the French↔English tasks and on English→Russian task. For French↔English, we had resource issues4 in training such large Introduction The Edinburgh/JHU phrase-based translation systems for our participation in the WMT 2015 shared translation task1 are based on the open source Moses toolkit (Koehn et al., 2007). We built upon Edinburgh’s strong baselines from WMT submissions in previous years (Durrani et al., 2014a) as well as our recent research within the framework of other evaluation campaigns and projects such as IWSLT2 and EU-BRIDGE3 (Birch et al., 2014; Freitag et al., 2014a; Freitag et al., 2014b). We first discuss novel features that we integrated into our systems for the 2015 Edinburgh/JHU submission. Next we give a general system overview with details on our training pipeline and decoder configuration. We finally present empirical results for the individual language pairs and translation directions. 1 http://www.statmt.org/wmt15/ http://workshop2014.iwslt.org 3 http://www.eu-bridge.eu 4 These"
W15-3013,P13-2121,1,0.902744,"Missing"
W15-3013,P07-1019,0,0.0483912,"ed language models, we tested with 50 Och clusters, 200 Och clusters, and with both class-based LMs. For the bilingual LM, we created both “combined” (a 5-gram on the target and a 9-gram on the source) and “source” (1-gram on the target and 15-gram on Tuning Since our feature set (generally around 500 to 1000 features) was too large for MERT, we used k-best batch MIRA for tuning (Cherry and Foster, 2012). To speed up tuning we applied threshold pruning to the phrase table, based on the direct translation model probability. 3.6 Experimental Results Decoding In decoding we applied cube pruning (Huang and Chiang, 2007) with a stack size of 5000 (reduced to 1000 for tuning), Minimum Bayes Risk decoding (Kumar and Byrne, 2004), a maximum phrase length of 5, a distortion limit of 6, 100best translation options and the no-reorderingover-punctuation heuristic (Koehn and Haddow, 2009). 128 System Baseline Submitted 50 classes 200 classes 50+200 classes BiLM combined BiLM source & combined NPLM fr-en 33.0 32.7 32.8 32.9 32.9 32.9 33.2 33.0 System Baseline Submitted Without OPUS 50 classes 200 classes 50+200 classes BiLM combined BiLM source & combined NPLM en-fr 33.5 33.6 33.8 33.9 33.7 33.6 33.5 34.2 Table 2: Com"
W15-3013,E14-4029,1,0.939408,"at test time the alignment is supplied by the decoder. The bilingual LM is trained using a feedforward neural network and we use the NPLM toolkit for this. Prior to submission we tested bilingual LMs on the French↔English tasks and on English→Russian task. For French↔English, we had resource issues4 in training such large Introduction The Edinburgh/JHU phrase-based translation systems for our participation in the WMT 2015 shared translation task1 are based on the open source Moses toolkit (Koehn et al., 2007). We built upon Edinburgh’s strong baselines from WMT submissions in previous years (Durrani et al., 2014a) as well as our recent research within the framework of other evaluation campaigns and projects such as IWSLT2 and EU-BRIDGE3 (Birch et al., 2014; Freitag et al., 2014a; Freitag et al., 2014b). We first discuss novel features that we integrated into our systems for the 2015 Edinburgh/JHU submission. Next we give a general system overview with details on our training pipeline and decoder configuration. We finally present empirical results for the individual language pairs and translation directions. 1 http://www.statmt.org/wmt15/ http://workshop2014.iwslt.org 3 http://www.eu-bridge.eu 4 These"
W15-3013,N13-1073,0,0.0525479,"ure functions based on POS and morphological tags, and basically no additional gains were observed due to the class based feature functions. 2.4 3 3.1 System Overview Preprocessing The training data was preprocessed using scripts from the Moses toolkit. We first normalized the data using the normalize-punctuation.perl script, then performed tokenization (using the -a option), and then truecasing. We did not perform any corpus filtering other than the standard Moses method, which removes sentence pairs with extreme length ratios. 3.2 Word Alignment For word alignment we used either fast_align (Dyer et al., 2013) or MGIZA++ (Gao and Vogel, 2008), followed by the standard grow-diag-final-and symmetrization heuristic. An empirical comparison of fast_align and MGIZA++ on the FinnishEnglish and English-Russian language pairs using the constrained data sets did not reveal any significant difference. 3.3 Language Model We used all available monolingual data to train 5gram language models with modified Kneser-Ney smoothing (Chen and Goodman, 1998). Typically, language models for each monolingual corpus were first trained using either KenLM (Heafield et al., 2013) or the SRILM toolkit (Stolcke, 2002) and then"
W15-3013,E03-1076,1,0.79605,"Baseline Submitted BiLM source & combined & NPLM Czech↔English The development of the Czech↔English systems followed the ideas in Section 2.3, i.e., with a focus on word classes (50, 200, 600 classes) for all component models. We combined the test sets from 2008 to 2012 for tuning. No neural language model or bilingual language model was used. 4.4 Table 4: Experimental results (cased B LEU) for English→Russian averaged over newstest2013 and newstest2014. Russian↔English From German. For translation from German, we applied syntactic pre-reordering (Collins et al., 2005) and compound splitting (Koehn and Knight, 2003) in a preprocessing step on the source side. A rich set of translation factors was exploited in addition to word surface forms: Och clusters (50 classes), morphological tags, partof-speech tags, and word stems on the German side (Schmid, 2000), as well as Och clusters (50 classes), part-of-speech tags (Ratnaparkhi, 1996), and word stems (Porter, 1980) on the English side. The factors were utilized in the translation model and in OSMs. The lexicalized reordering model was trained on stems. Individual 7gram Och cluster LMs were trained with KenLM’s --discount_fallback --prune '0 0 1' parameters,"
W15-3013,P07-2045,1,0.00919205,"gned source token. At training time, the aligned source token is found from the automatic alignment, and at test time the alignment is supplied by the decoder. The bilingual LM is trained using a feedforward neural network and we use the NPLM toolkit for this. Prior to submission we tested bilingual LMs on the French↔English tasks and on English→Russian task. For French↔English, we had resource issues4 in training such large Introduction The Edinburgh/JHU phrase-based translation systems for our participation in the WMT 2015 shared translation task1 are based on the open source Moses toolkit (Koehn et al., 2007). We built upon Edinburgh’s strong baselines from WMT submissions in previous years (Durrani et al., 2014a) as well as our recent research within the framework of other evaluation campaigns and projects such as IWSLT2 and EU-BRIDGE3 (Birch et al., 2014; Freitag et al., 2014a; Freitag et al., 2014b). We first discuss novel features that we integrated into our systems for the 2015 Edinburgh/JHU submission. Next we give a general system overview with details on our training pipeline and decoder configuration. We finally present empirical results for the individual language pairs and translation d"
W15-3013,W06-1607,0,0.204091,"29.8 (+.1) 29.5 (–.2) avg ∆ +.5 –.2 –.4 ±.0 –.2 Table 1: Use of additional feature functions based on Och clusters (see Section 2.3). The last four lines refer to ablation studies where one of the sets of clustered feature functions is removed from the comprehensive setup. Note that the word-based feature functions are used in all cases. B LEU scores on newstest2014 are reported. 4 model are a 5-gram LM score, phrase translation and lexical translation scores, word and phrase penalties, and a linear distortion score. The phrase translation probabilities are smoothed with GoodTuring smoothing (Foster et al., 2006). We used the hierarchical lexicalized reordering model (Galley and Manning, 2008) with 4 possible orientations (monotone, swap, discontinuous left and discontinuous right) in both left-to-right and rightto-left direction. We also used the operation sequence model (OSM) (Durrani et al., 2013) with 4 count based supportive features. We further employed domain indicator features (marking which training corpus each phrase pair was found in), binary phrase count indicator features, sparse phrase length features, and sparse source word deletion, target word insertion, and word translation features"
W15-3013,W14-3310,1,0.838548,"mission we tested bilingual LMs on the French↔English tasks and on English→Russian task. For French↔English, we had resource issues4 in training such large Introduction The Edinburgh/JHU phrase-based translation systems for our participation in the WMT 2015 shared translation task1 are based on the open source Moses toolkit (Koehn et al., 2007). We built upon Edinburgh’s strong baselines from WMT submissions in previous years (Durrani et al., 2014a) as well as our recent research within the framework of other evaluation campaigns and projects such as IWSLT2 and EU-BRIDGE3 (Birch et al., 2014; Freitag et al., 2014a; Freitag et al., 2014b). We first discuss novel features that we integrated into our systems for the 2015 Edinburgh/JHU submission. Next we give a general system overview with details on our training pipeline and decoder configuration. We finally present empirical results for the individual language pairs and translation directions. 1 http://www.statmt.org/wmt15/ http://workshop2014.iwslt.org 3 http://www.eu-bridge.eu 4 These can now be addressed using the -mmap option to create a binarized version of the corpus which is then memory-mapped. 2 126 Proceedings of the Tenth Workshop on Statisti"
W15-3013,P10-2041,0,0.0404632,"Missing"
W15-3013,E99-1010,0,0.349917,"Missing"
W15-3013,2014.amta-researchers.3,0,0.061645,"rved a small improvement in translation performance. 2.3 Comprehensive Use of Word Classes In Edinburgh’s submission from the previous year, we used automatically generated word classes in additional language models and in additional operation sequence models (Durrani et al., 2014b). This year, we pushed the use of word classes into the remaining feature functions: the reordering model and the sparse word features. We generated Och clusters (Och, 1999) — a variant of Brown clusters — using mkcls. We have to choose a hyper parameter: the number of clusters. Our experiments and also prior work (Stewart et al., 2014) suggest that instead of committing to a single value, it is beneficial to use multiple numbers and use them in multiple feature functions concurrently. We used 50, 200, 600, and 2000 clusters, hence having 4 additional interpolated language models, 4 additional operation sequence models, 4 additional lexicalized reordering models, and 4 additional sets of sparse features. The feature functions for word classes were trained exactly the same way as the corresponding feature functions for words. For instance, this means that the word class language model required training of individual models on"
W15-3013,tiedemann-2012-parallel,0,0.0549009,"ploying dropout to prevent overfitting (Srivastava et al., 2014), enabling us to train the models for at least 2 epochs. We note that, as with French↔English, our application of bilingual LM did not result in significant improvement. Finnish and English are quite distantly related, but we can speculate that using words as a representation for Finnish is not appropriate. The NPLM, however, offers modest (+0.4) improvements over the baseline in both directions. Finnish↔English For the Finnish-English language pair we built systems using only the constrained data, and systems using all the OPUS (Tiedemann, 2012) par129 4.3 System Baseline Submitted BiLM source & combined & NPLM Czech↔English The development of the Czech↔English systems followed the ideas in Section 2.3, i.e., with a focus on word classes (50, 200, 600 classes) for all component models. We combined the test sets from 2008 to 2012 for tuning. No neural language model or bilingual language model was used. 4.4 Table 4: Experimental results (cased B LEU) for English→Russian averaged over newstest2013 and newstest2014. Russian↔English From German. For translation from German, we applied syntactic pre-reordering (Collins et al., 2005) and c"
W15-3013,D13-1140,0,0.0464299,"n of the University of Edinburgh and the Johns Hopkins University for the shared translation task of the EMNLP 2015 Tenth Workshop on Statistical Machine Translation (WMT 2015). We set up phrase-based statistical machine translation systems for all ten language pairs of this year’s evaluation campaign, which are English paired with Czech, Finnish, French, German, and Russian in both translation directions. 2.1 Neural Network LM with NPLM For some language pairs (notably French↔English and Finnish↔English) we experimented with feed-forward neural network language models using the NPLM toolkit (Vaswani et al., 2013). This toolkit enables such language models to be trained efficiently on large datasets, and provides a querying API which is fast enough to be used during decoding. NPLM is fully integrated into Moses, including appropriate wrapper scripts for training the language models within the Moses experiment management system. Novel research directions we investigated include: neural network language models and bilingual neural network language models, a comprehensive use of word classes, and sparse lexicalized reordering features. 1 Novel Methods 2.2 Bilingual Neural Network LM We also experimented w"
W15-3013,W15-3024,1,0.849652,"not the English. In fact French→English was the only language pair where NPLM did not improve B LEU after building the LM on all data. It is possible that the limited morphology of English means that the improved generalisation of the NPLM is not as helpful, and also that the conventional n-gram LM is already strong for this language pair. 4.2 fi-en 19.6 19.7 17.0 19.4 19.8 19.7 19.1 19.1 20.0 allel data. Our baselines include this extra data, but we also show results just using the constrained parallel data. We did not employ the morphological splitting as in Edinburgh’s syntax-based system (Williams et al., 2015) and consequently the English→Finnish systems performed poorly in development and we did not submit a phrase-based system for this pair. Our development setup was similar to French↔English; we used the newsdev2015 for tuning and test during system development (in 2-fold cross-validation) then for the submission and subsequent experiments we used the whole of newsdev2015 for tuning. Also in common with our work on French↔English, we performed several post-submission experiments to examine the effect of class-based language models, bilingual LM and NPLM. We show the results in Table 3. For train"
W15-3013,W09-0429,1,\N,Missing
W15-3013,N04-1022,0,\N,Missing
W15-3013,2014.iwslt-evaluation.6,1,\N,Missing
W15-3013,C14-1041,1,\N,Missing
W15-3013,W14-3324,1,\N,Missing
W15-3024,D14-1082,0,0.137464,"Missing"
W15-3024,P14-1129,0,0.137886,"Missing"
W15-3024,N13-1073,0,0.0469731,"2.1 Introduction 2.2 System Overview Pre-processing The training data was pre-processed using scripts from the Moses toolkit. We first normalized the data using the normalize-punctuation.perl script then performed tokenization, parsing, and truecasing. To parse the English data, we used the Berkeley parser (Petrov et al., 2006; Petrov and Klein, 2007). To parse the German data, we used the ParZu dependency parser (Sennrich et al., 2013). Word Alignment For word alignment we used either MGIZA++ (Gao and Vogel, 2008), a multi-threaded implementation of GIZA++ (Och and Ney, 2003), or fast_align (Dyer et al., 2013). In preliminary experiments, we found that the tree-to-string systems were particularly sensitive to the choice of word aligner, echoing a previous observation by Neubig and Duh (2014). See the individual treeto-string system descriptions in Section 3. This year’s WMT shared translation task featured five language pairs: English paired with Czech, Finnish, French, German, and Russian. We built syntax-based systems in both translation directions for all language pairs except English-French. For English → German, we continued to develop our string-to-tree system, which has proven highly competi"
W15-3024,P03-2041,0,0.147009,"Missing"
W15-3024,W15-1004,0,0.0358237,"Missing"
W15-3024,P06-1121,0,0.275709,"Missing"
W15-3024,W13-2221,1,0.922677,"Missing"
W15-3024,W08-0509,0,0.0425569,"e our English-German system; and source-side morphological segmentation of Finnish using Morfessor. 2.1 Introduction 2.2 System Overview Pre-processing The training data was pre-processed using scripts from the Moses toolkit. We first normalized the data using the normalize-punctuation.perl script then performed tokenization, parsing, and truecasing. To parse the English data, we used the Berkeley parser (Petrov et al., 2006; Petrov and Klein, 2007). To parse the German data, we used the ParZu dependency parser (Sennrich et al., 2013). Word Alignment For word alignment we used either MGIZA++ (Gao and Vogel, 2008), a multi-threaded implementation of GIZA++ (Och and Ney, 2003), or fast_align (Dyer et al., 2013). In preliminary experiments, we found that the tree-to-string systems were particularly sensitive to the choice of word aligner, echoing a previous observation by Neubig and Duh (2014). See the individual treeto-string system descriptions in Section 3. This year’s WMT shared translation task featured five language pairs: English paired with Czech, Finnish, French, German, and Russian. We built syntax-based systems in both translation directions for all language pairs except English-French. For En"
W15-3024,P14-2024,0,0.0198394,"tion.perl script then performed tokenization, parsing, and truecasing. To parse the English data, we used the Berkeley parser (Petrov et al., 2006; Petrov and Klein, 2007). To parse the German data, we used the ParZu dependency parser (Sennrich et al., 2013). Word Alignment For word alignment we used either MGIZA++ (Gao and Vogel, 2008), a multi-threaded implementation of GIZA++ (Och and Ney, 2003), or fast_align (Dyer et al., 2013). In preliminary experiments, we found that the tree-to-string systems were particularly sensitive to the choice of word aligner, echoing a previous observation by Neubig and Duh (2014). See the individual treeto-string system descriptions in Section 3. This year’s WMT shared translation task featured five language pairs: English paired with Czech, Finnish, French, German, and Russian. We built syntax-based systems in both translation directions for all language pairs except English-French. For English → German, we continued to develop our string-to-tree system, which has proven highly competitive in previous years. Additions this year included the use of a dependency language model, an alternative tuning metric, and soft source-syntactic constraints. For translation from En"
W15-3024,P05-1013,0,0.0872144,"Missing"
W15-3024,P13-2121,1,0.887764,"Missing"
W15-3024,J03-1002,0,0.0231219,"tation of Finnish using Morfessor. 2.1 Introduction 2.2 System Overview Pre-processing The training data was pre-processed using scripts from the Moses toolkit. We first normalized the data using the normalize-punctuation.perl script then performed tokenization, parsing, and truecasing. To parse the English data, we used the Berkeley parser (Petrov et al., 2006; Petrov and Klein, 2007). To parse the German data, we used the ParZu dependency parser (Sennrich et al., 2013). Word Alignment For word alignment we used either MGIZA++ (Gao and Vogel, 2008), a multi-threaded implementation of GIZA++ (Och and Ney, 2003), or fast_align (Dyer et al., 2013). In preliminary experiments, we found that the tree-to-string systems were particularly sensitive to the choice of word aligner, echoing a previous observation by Neubig and Duh (2014). See the individual treeto-string system descriptions in Section 3. This year’s WMT shared translation task featured five language pairs: English paired with Czech, Finnish, French, German, and Russian. We built syntax-based systems in both translation directions for all language pairs except English-French. For English → German, we continued to develop our string-to-tree syst"
W15-3024,herrmann-etal-2014-manual,0,0.0544561,"Missing"
W15-3024,E99-1010,0,0.163731,"Missing"
W15-3024,D10-1063,0,0.128747,"Missing"
W15-3024,P03-1021,0,0.122835,"Missing"
W15-3024,W14-4018,1,0.8972,"Missing"
W15-3024,N03-1017,1,0.0581822,"Missing"
W15-3024,P06-1055,0,0.105477,"ared translation task. We developed systems for all language pairs except French-English. This year we focused on: translation out of English using tree-to-string models; continuing to improve our English-German system; and source-side morphological segmentation of Finnish using Morfessor. 2.1 Introduction 2.2 System Overview Pre-processing The training data was pre-processed using scripts from the Moses toolkit. We first normalized the data using the normalize-punctuation.perl script then performed tokenization, parsing, and truecasing. To parse the English data, we used the Berkeley parser (Petrov et al., 2006; Petrov and Klein, 2007). To parse the German data, we used the ParZu dependency parser (Sennrich et al., 2013). Word Alignment For word alignment we used either MGIZA++ (Gao and Vogel, 2008), a multi-threaded implementation of GIZA++ (Och and Ney, 2003), or fast_align (Dyer et al., 2013). In preliminary experiments, we found that the tree-to-string systems were particularly sensitive to the choice of word aligner, echoing a previous observation by Neubig and Duh (2014). See the individual treeto-string system descriptions in Section 3. This year’s WMT shared translation task featured five la"
W15-3024,W05-0904,0,0.182994,"Missing"
W15-3024,D15-1248,1,0.828811,"Missing"
W15-3024,D14-2005,1,0.826874,"Missing"
W15-3024,R13-1079,1,0.817325,"d on: translation out of English using tree-to-string models; continuing to improve our English-German system; and source-side morphological segmentation of Finnish using Morfessor. 2.1 Introduction 2.2 System Overview Pre-processing The training data was pre-processed using scripts from the Moses toolkit. We first normalized the data using the normalize-punctuation.perl script then performed tokenization, parsing, and truecasing. To parse the English data, we used the Berkeley parser (Petrov et al., 2006; Petrov and Klein, 2007). To parse the German data, we used the ParZu dependency parser (Sennrich et al., 2013). Word Alignment For word alignment we used either MGIZA++ (Gao and Vogel, 2008), a multi-threaded implementation of GIZA++ (Och and Ney, 2003), or fast_align (Dyer et al., 2013). In preliminary experiments, we found that the tree-to-string systems were particularly sensitive to the choice of word aligner, echoing a previous observation by Neubig and Duh (2014). See the individual treeto-string system descriptions in Section 3. This year’s WMT shared translation task featured five language pairs: English paired with Czech, Finnish, French, German, and Russian. We built syntax-based systems in"
W15-3024,W14-4011,1,0.893791,"Missing"
W15-3024,Q15-1013,1,0.867045,"Missing"
W15-3024,N13-3005,0,0.0310419,"Missing"
W15-3024,D13-1140,0,0.162963,"Missing"
W15-3024,vilar-etal-2006-error,0,0.110074,"Missing"
W15-3024,W12-3150,1,0.927673,"Missing"
W15-3024,W14-3324,1,0.644531,"oft source-syntactic constraints. For translation from English into Czech, Finnish, and Russian, we built STSG-based treeto-string systems. Support for this type of model is a recent addition to the Moses toolkit. In previous years, our systems have all used string-to-tree models and have only translated into English and German. For Finnish → English, we experimented with unsupervised morphological segmentation using Morfessor 2.0 (Virpioja et al., 2013). For the remaining systems (Czech → English, German → English, and Russian → English), our systems were essentially the same as last year’s (Williams et al., 2014) except for the addition of this year’s training data. 2.3 Language Model We used all available monolingual data to train one interpolated 5-gram language model for each system. Using either lmplz (Heafield et al., 2013) or the SRILM toolkit (Stolcke, 2002), we first trained an individual language model for each of the supplied monolingual training corpora. These models all used modified Kneser-Ney smoothing (Chen and Goodman, 1998). We then interpolated the individual models using SRILM, providing the target-side of the system’s tuning set (Section 2.7) for perplexity-based weight optimizatio"
W16-2301,W13-3520,0,0.0148252,"Missing"
W16-2301,2011.mtsummit-papers.35,0,0.440323,"Missing"
W16-2301,W15-3001,1,0.419439,"Missing"
W16-2301,W16-2305,0,0.0273073,"Missing"
W16-2301,L16-1662,0,0.00889007,"introduce a new set of features for the sentence-Level QE task. The features extracted include three alignment-based features, three bilingual embedding-based features, two embeddingbased features constrained on alignment links, as well as a set of 74 bigrams used as boolean features. The set of bigrams represents the most frequent bigrams in translations that have changed after the post-edition, and they are compiled by aligning translations to their post-editions provided in the WMT QE datasets. To produce these features, GIZA++ (Och and Ney, 2003) was used for word alignment and Multivec (Berard et al., 2016) was used for the bilingual model, which jointly learns distributed representations for source and target languages using a parallel corpus. To build the bilingual model, domain-specific data compiled from the resources made available for the WMT 16 IT-Domain shared task was used. As prediction model, a Linear Regression model using scikit-learn was built using a combination of QuEst++ baseline features and the new features proposed. tional features for both tasks. UNBABEL (Task 2): Two systems were submitted for the word-level task. UNBABEL 2 linear is a feature-based linear sequential model."
W16-2301,W11-2101,1,0.851508,"Missing"
W16-2301,W16-2306,0,0.0263259,"Missing"
W16-2301,W16-2382,0,0.0451767,"Missing"
W16-2301,W16-2302,1,0.346609,"Missing"
W16-2301,W16-2307,1,0.756182,"Missing"
W16-2301,W16-2308,0,0.0373021,"Missing"
W16-2301,buck-etal-2014-n,0,0.0150538,"Missing"
W16-2301,W13-2201,1,0.287085,"Missing"
W16-2301,W14-3302,1,0.399147,"Missing"
W16-2301,W14-3340,1,0.419045,"Missing"
W16-2301,W07-0718,1,0.759293,"oth automatically and manually. The human evaluation (§3) involves asking human judges to rank sentences output by anonymized systems. We obtained large numbers of rankings from researchers who contributed The quality estimation task had three subtasks, with a total of 14 teams, submitting 39 entries. The automatic post-editing task had a total of 6 teams, submitting 11 entries. 1 Introduction We present the results of the shared tasks of the First Conference on Statistical Machine Translation (WMT) held at ACL 2016. This conference builds on nine previous WMT workshops (Koehn and Monz, 2006; Callison-Burch et al., 2007, 2008, 2009, 2010, 2011, 2012; Bojar et al., 2013, 2014, 2015). 131 Proceedings of the First Conference on Machine Translation, Volume 2: Shared Task Papers, pages 131–198, c Berlin, Germany, August 11-12, 2016. 2016 Association for Computational Linguistics to refine evaluation and estimation methodologies for machine translation. As before, all of the data, translations, and collected human judgments are publicly available.1 We hope these datasets serve as a valuable resource for research into statistical machine translation and automatic evaluation or prediction of translation quality. New"
W16-2301,W15-3025,1,0.888663,"used for the Task 2p. The submissions to the word-level task are modified in order to comply with the phrase-level task. sequences. Nevertheless, it is worth noticing the phraselevel QE systems introduced a number of interesting strategies that allowed them to outperform a strong baseline phrase-level model. Finally, we recall that the evaluation metric – word-level F1 mult – has difficulties to distinguish phrase-level systems. This suggests that we may need to find a different metric for evaluation of the phrase-level task, with phrase-level F1 -mult one of the candidates. 7 pointed out by Chatterjee et al. (2015b), from the application point of view the task is motivated by its possible uses to: • Improve MT output by exploiting information unavailable to the decoder, or by performing deeper text analysis that is too expensive at the decoding stage; • Cope with systematic errors of an MT system whose decoding process is not accessible; • Provide professional translators with improved MT output quality to reduce (human) post-editing effort; Automatic Post-editing Task This year WMT hosted the second round of the shared task on MT automatic post-editing (APE), which consists in automatically correcting"
W16-2301,P15-2026,1,0.895785,"used for the Task 2p. The submissions to the word-level task are modified in order to comply with the phrase-level task. sequences. Nevertheless, it is worth noticing the phraselevel QE systems introduced a number of interesting strategies that allowed them to outperform a strong baseline phrase-level model. Finally, we recall that the evaluation metric – word-level F1 mult – has difficulties to distinguish phrase-level systems. This suggests that we may need to find a different metric for evaluation of the phrase-level task, with phrase-level F1 -mult one of the candidates. 7 pointed out by Chatterjee et al. (2015b), from the application point of view the task is motivated by its possible uses to: • Improve MT output by exploiting information unavailable to the decoder, or by performing deeper text analysis that is too expensive at the decoding stage; • Cope with systematic errors of an MT system whose decoding process is not accessible; • Provide professional translators with improved MT output quality to reduce (human) post-editing effort; Automatic Post-editing Task This year WMT hosted the second round of the shared task on MT automatic post-editing (APE), which consists in automatically correcting"
W16-2301,W08-0309,1,0.809107,"Missing"
W16-2301,W16-2309,0,0.0305938,"Missing"
W16-2301,W10-1703,1,0.312318,"Missing"
W16-2301,W16-2336,0,0.0356983,"Missing"
W16-2301,W12-3102,1,0.235434,"ir native language. Consequently, health professionals may use the translated information to make clinical decisions impacting patients care. It is vital that translation systems do not contribute to the dissemination of incorrect clinical information. Therefore, the evaluation of biomedical translation systems should include an assessment at the document level indicating whether a translation conveyed erroneous clinical information. 6 Quality Estimation The fifth edition of the WMT shared task on quality estimation (QE) of machine translation (MT) builds on the previous editions of the task (Callison-Burch et al., 2012; Bojar et al., 2013, 2014, 2015), with “traditional” tasks at sentence and word levels, a new task for entire documents quality prediction, and a variant of the word-level task: phrase-level estimation. The goals of this year’s shared task were: • To advance work on sentence and wordlevel quality estimation by providing domainspecific, larger and professionally annotated datasets. • To analyse the effectiveness of different types of quality labels provided by humans for longer texts in document-level prediction. • To investigate quality estimation at a new level of granularity: phrases. Plan"
W16-2301,W16-2330,0,0.0328047,"Missing"
W16-2301,W16-2310,1,0.835279,"Missing"
W16-2301,W11-2103,1,0.65163,"Missing"
W16-2301,W16-2331,0,0.0203904,"cance test results for pairs of systems competing in the news domain translation task (en-ru), where a green cell denotes a significantly higher DA adequacy score for the system in a given row over the system in a given column. cs-en fi-en tr-en de-en ru-en ro-en 0.997 0.996 0.988 0.964 0.961 0.920 en-ru 0.975 DA Correlation with RR Table 11: Correlation between overall DA standardized mean adequacy scores and RR Trueskill scores. 150 4 IT Translation Task from the QTLeap project: HF&FCUL for Portuguese, UPV/EHU for Spanish and Basque, IICT-BAS for Bulgarian, CUNI for Czech and UG for Dutch). Duma and Menzel (2016) describe UHDS- DOC 2 VEC and UHBS- LMI (University of Hamburg). Pahari et al. (2016) describe JU-USAAR (Jadavpur University & Saarland University). Cuong et al. (2016) describe ILLC-U VA-S CORPIO (University of Amsterdam). IILC-U VA-DS is based on Hoang and Sima’an (2014). PROMT-RULE - BASED and PROMT-H YBRID systems were submitted by the PROMT LLC company and they are not described in any paper. QTL -M OSES is the standard Moses setup (MERT-tuned on the in-domain training data, but otherwise without any domain-adaptation) and serves as a baseline. The IT-domain translation task introduced th"
W16-2301,W15-3009,1,0.788321,"Missing"
W16-2301,P15-1174,1,0.28154,"endently inserted in another part of this sentence, i.e. to correct an unrelated error. The statistics of the datasets are outlined in Table 20. Evaluation Evaluation was performed against the true HTER label and/or ranking, using the following metrics: • Scoring: Pearson’s r correlation score (primary metric, official score for ranking submissions), Mean Average Error (MAE) and Root Mean Squared Error (RMSE). • Ranking: Spearman’s ρ rank correlation and DeltaAvg. Statistical significance on Pearson r and Spearman rho was computed using the William’s test, following the approach suggested in (Graham, 2015). Results Table 19 summarises the results for Task 1, ranking participating systems best to worst using Pearson’s r correlation as primary key. Spearman’s ρ correlation scores should be used to rank systems according to the ranking variant. We note that three systems have not submitted results ranking evaluation variant. 6.4 Task 2: Predicting word-level quality The goal of this task is to evaluate the extent to which we can detect word-level errors in MT output. Various classes of errors can be found in translations, but for this task we consider all error types together, aiming at making a b"
W16-2301,W16-2311,0,0.0122367,"016) PROMT Automated Translation Solutions (Molchanov and Bykov, 2016) QT21 System Combination (Peter et al., 2016b) RWTH Aachen (Peter et al., 2016a) ¨ TUBITAK (Bektas¸ et al., 2016) University of Edinburgh (Sennrich et al., 2016) University of Edinburgh (Williams et al., 2016) UEDIN - SYNTAX UEDIN - LMU UH -* USFD - RESCORING UUT YSDA ONLINE -[ A , B , F, G ] University of Edinburgh / University of Munich (Huck et al., 2016) University of Helsinki (Tiedemann et al., 2016) University of Sheffield (Blain et al., 2016) Uppsala University (Tiedemann et al., 2016) Yandex School of Data Analysis (Dvorkovich et al., 2016) Four online statistical machine translation systems Table 2: Participants in the shared translation task. Not all teams participated in all language pairs. The translations from the commercial and online systems were not submitted by their respective companies but were obtained by us, and are therefore anonymized in a fashion consistent with previous years of the workshop. 136 Figure 2: Screenshot of the Appraise interface used in the human evaluation campaign. The annotator is presented with a source segment, a reference translation, and up to five outputs from competing systems (anonymized"
W16-2301,W13-2305,1,0.509145,"Missing"
W16-2301,W15-3036,0,0.0603245,"Missing"
W16-2301,E14-1047,1,0.831614,"Missing"
W16-2301,W16-2378,0,0.168663,"ts for pairs of systems competing in the news domain translation task (en-ru), where a green cell denotes a significantly higher DA adequacy score for the system in a given row over the system in a given column. cs-en fi-en tr-en de-en ru-en ro-en 0.997 0.996 0.988 0.964 0.961 0.920 en-ru 0.975 DA Correlation with RR Table 11: Correlation between overall DA standardized mean adequacy scores and RR Trueskill scores. 150 4 IT Translation Task from the QTLeap project: HF&FCUL for Portuguese, UPV/EHU for Spanish and Basque, IICT-BAS for Bulgarian, CUNI for Czech and UG for Dutch). Duma and Menzel (2016) describe UHDS- DOC 2 VEC and UHBS- LMI (University of Hamburg). Pahari et al. (2016) describe JU-USAAR (Jadavpur University & Saarland University). Cuong et al. (2016) describe ILLC-U VA-S CORPIO (University of Amsterdam). IILC-U VA-DS is based on Hoang and Sima’an (2014). PROMT-RULE - BASED and PROMT-H YBRID systems were submitted by the PROMT LLC company and they are not described in any paper. QTL -M OSES is the standard Moses setup (MERT-tuned on the in-domain training data, but otherwise without any domain-adaptation) and serves as a baseline. The IT-domain translation task introduced th"
W16-2301,W11-2123,0,0.0116622,"s were also evaluated against a reimplementation of the approach firstly proposed by Simard et al. (2007).36 Last year, in fact, this statistical post-editing approach represented the common backbone of all submissions (this is also reflected by the close results achieved by participants in the pilot task). For this purpose, a phrasebased SMT system based on Moses (Koehn et al., 2007) was used. Translation and reordering models were estimated following the Moses protocol with default setup using MGIZA++ (Gao and Vogel, 2008) for word alignment. For language modeling we used the KenLM toolkit (Heafield, 2011) for standard n-gram modeling with an n-gram length of 5. Finally, the APE system was tuned on Adam Mickiewicz University. This system is among the very first ones exploring the application of neural translation models to the APE task. In particular, it investigates the following aspects: i) the use of artificially-created postedited data to train the neural models, ii) the loglinear combination of monolingual and bilingual models in an ensemble-like manner, iii) the addition of task-specific features in the log-linear model to control the final output quality. Concerning the data, in addition"
W16-2301,W16-2384,0,0.0416841,"Missing"
W16-2301,W13-0805,0,0.0110515,"of words in the reference. Lower TER values indicate lower distance from the reference as a proxy for higher MT quality. 33 http://www.cs.umd.edu/˜snover/tercom/ 34 https://github.com/moses-smt/mosesdecoder/ blob/master/scripts/generic/multi-bleu.perl 27 The source sentences (together with their reference translations which were not used for the task) were provided by TAUS (https://www.taus.net/) and originally come from a unique IT vendor. 28 It consists of a phrase-based machine translation system leveraging generic and in-domain parallel training data and using a pre-reordering technique (Herrmann et al., 2013). It takes also advantages of POS and word class-based language models. 29 German native speakers working at Text&Form https: //www.textform.com/. 176 Train (12,000) Dev (1,000) Test (2,000) SRC 201,505 17,827 31,477 Tokens TGT 210,573 19,355 34,332 PE 214,720 19,763 35,276 Table 31: Types SRC TGT 9,328 14,185 2,931 3,333 3,908 4,695 Data statistics. APE@WMT15 APE@WMT16 (EN-ES, news, crowd) (EN-DE, IT, prof.) SRC 2.905 6.616 TGT 3.312 8.845 PE 3.085 8.245 Table 32: Repetition Rate (RR) of the WMT15 (EnglishSpanish, news domain, crowdsourced post-edits) and WMT16 (English-German, IT domain, pro"
W16-2301,W16-2315,1,0.824148,"Missing"
W16-2301,P07-2045,1,0.017773,"gets unmodified.35 Baseline results are reported in Table 34. 7.2 Participants Monolingual translation as another term of comparison. To get some insights about the progress with respect to the first pilot task, participating systems were also evaluated against a reimplementation of the approach firstly proposed by Simard et al. (2007).36 Last year, in fact, this statistical post-editing approach represented the common backbone of all submissions (this is also reflected by the close results achieved by participants in the pilot task). For this purpose, a phrasebased SMT system based on Moses (Koehn et al., 2007) was used. Translation and reordering models were estimated following the Moses protocol with default setup using MGIZA++ (Gao and Vogel, 2008) for word alignment. For language modeling we used the KenLM toolkit (Heafield, 2011) for standard n-gram modeling with an n-gram length of 5. Finally, the APE system was tuned on Adam Mickiewicz University. This system is among the very first ones exploring the application of neural translation models to the APE task. In particular, it investigates the following aspects: i) the use of artificially-created postedited data to train the neural models, ii)"
W16-2301,W16-2337,0,0.0376798,"Missing"
W16-2301,W16-2303,1,0.821661,"Missing"
W16-2301,L16-1582,1,0.790825,"Missing"
W16-2301,W16-2385,0,0.0304494,"Missing"
W16-2301,P16-2095,1,0.885979,"e package to extract these and other quality estimation features and perform model learning, with suggested methods for all levels of prediction. Participants, described in Section 6.2, could submit up to two systems for each task. Data used to build MT systems or internal system information (such as model scores or n-best lists) were made available on request for Tasks 1 and 2. 6.1 The γ,  and C parameters were optimised via grid search with 5-fold cross validation on the training set. Word-level baseline system: For Tasks 2 and 2p, the baseline features were extracted with the Marmot tool (Logacheva et al., 2016b). For the baseline system we used a number of features that have been found the most informative in previous research on word-level QE. Our baseline set of features is loosely based on the one described in (Luong et al., 2014). It contains the following 22 features: • Word count in the source and target sentences, source and target token count ratio. Although these features are sentence-level (i.e. their values will be the same for all words in a sentence), the length of a sentence might influence the probability of a word being wrong. Baseline systems Sentence-level baseline system: For Tas"
W16-2301,W15-3037,0,0.00849978,"stems were submitted for the word-level task. UNBABEL 2 linear is a feature-based linear sequential model. It uses the baseline features provided by the shared task organisers (with slight changes) conjoined with individual labels and pairs of consecutive labels. It also uses various syntactic dependency-based features (dependency relations, heads, and second-order structures like siblings and grandparents). The syntactic dependencies are predicted with TurboParser trained on the TIGER German treebank. UNBABEL 2 ensemble uses a stacked architecture, inspired by the last year’s QUETCH+ system (Kreutzer et al., 2015), which combines three neural systems: one feedforward and two recurrent ones. The predictions of these systems are added as additional features in the linear system above. The following external resources were used: part-of-speech tags and extra syntactic dependency information obtained with TurboTagger and TurboParser (Martins et al., 2013), trained on the Penn Treebank (for English) and on the version of the German TIGER corpus used in the SPMRL shared task (Seddah et al., 2014) for German. For the neural models, pretrained word embeddings from Polyglot (AlRfou et al., 2013) and those produ"
W16-2301,W14-3342,0,0.0237077,"Data used to build MT systems or internal system information (such as model scores or n-best lists) were made available on request for Tasks 1 and 2. 6.1 The γ,  and C parameters were optimised via grid search with 5-fold cross validation on the training set. Word-level baseline system: For Tasks 2 and 2p, the baseline features were extracted with the Marmot tool (Logacheva et al., 2016b). For the baseline system we used a number of features that have been found the most informative in previous research on word-level QE. Our baseline set of features is loosely based on the one described in (Luong et al., 2014). It contains the following 22 features: • Word count in the source and target sentences, source and target token count ratio. Although these features are sentence-level (i.e. their values will be the same for all words in a sentence), the length of a sentence might influence the probability of a word being wrong. Baseline systems Sentence-level baseline system: For Task 1, QuEst++13 (Specia et al., 2015) was used to extract 17 features from the SMT source/target language training corpus: • Number of tokens in source & target sentences. • Target token, its left and right contexts of one word."
W16-2301,W16-2318,0,0.0145349,"Missing"
W16-2301,N06-1014,0,0.0215966,"d on n previous translation and reordering decisions. This technique is able to model both local and long-range reorderings that are quite useful when dealing with the German language. To improve the capability of choosing the correct edit to process, eight new features are added to the loglinear model. These features capture the cost of deleting a phrase and different information on possible gaps in reordering operations. The monolingual alignments between the MT outputs and their post-edits are computed using different methods based on TER, METEOR (Snover et al., 2006) and Berkeley Aligner (Liang et al., 2006). Only the task data is used for these submissions. 7.3 179 TER/BLEU results ID AMU Primary AMU Contrastive FBK Contrastive FBK Primary USAAR Primary USAAR Constrastive CUNI Primary (Simard et al., 2007) Baseline DCU Contrastive JUSAAR Primary JUSAAR Contrastive DCU Primary Avg. TER 21.52 23.06 23.92 23.94 24.14 24.14 24.31 24.64 24.76 26.79 26.92 26.97 28.97 BLEU 67.65 66.09 64.75 64.75 64.10 64.00 63.32 63.47 62.11 58.60 59.44 59.18 55.19 tained this year by the top runs can only be reached by moving from the basic statistical MT backbone shared by all last year’s participants to new and mor"
W16-2301,P13-2109,0,0.0179517,"eads, and second-order structures like siblings and grandparents). The syntactic dependencies are predicted with TurboParser trained on the TIGER German treebank. UNBABEL 2 ensemble uses a stacked architecture, inspired by the last year’s QUETCH+ system (Kreutzer et al., 2015), which combines three neural systems: one feedforward and two recurrent ones. The predictions of these systems are added as additional features in the linear system above. The following external resources were used: part-of-speech tags and extra syntactic dependency information obtained with TurboTagger and TurboParser (Martins et al., 2013), trained on the Penn Treebank (for English) and on the version of the German TIGER corpus used in the SPMRL shared task (Seddah et al., 2014) for German. For the neural models, pretrained word embeddings from Polyglot (AlRfou et al., 2013) and those produced with a neural MT system (Bahdanau et al., 2014) were used. UGENT-LT3 (Task 1, Task 2): The submissions for the word-level task use 41 features in combination with the baseline feature set to train binary classifiers. The 41 additional features attempt to capture accuracy errors (concerned with the meaning transfer from the source to targe"
W16-2301,W16-2387,0,0.0253511,"Missing"
W16-2301,W16-2317,0,0.0414065,"Missing"
W16-2301,N13-1090,0,0.00833788,"Missing"
W16-2301,2015.iwslt-papers.4,1,0.737239,"Missing"
W16-2301,W16-2319,0,0.0339318,"Missing"
W16-2301,W16-2386,1,0.814188,"e package to extract these and other quality estimation features and perform model learning, with suggested methods for all levels of prediction. Participants, described in Section 6.2, could submit up to two systems for each task. Data used to build MT systems or internal system information (such as model scores or n-best lists) were made available on request for Tasks 1 and 2. 6.1 The γ,  and C parameters were optimised via grid search with 5-fold cross validation on the training set. Word-level baseline system: For Tasks 2 and 2p, the baseline features were extracted with the Marmot tool (Logacheva et al., 2016b). For the baseline system we used a number of features that have been found the most informative in previous research on word-level QE. Our baseline set of features is loosely based on the one described in (Luong et al., 2014). It contains the following 22 features: • Word count in the source and target sentences, source and target token count ratio. Although these features are sentence-level (i.e. their values will be the same for all words in a sentence), the length of a sentence might influence the probability of a word being wrong. Baseline systems Sentence-level baseline system: For Tas"
W16-2301,L16-1470,1,0.826657,"Missing"
W16-2301,P03-1021,0,0.0340784,"7 Tokens TGT 210,573 19,355 34,332 PE 214,720 19,763 35,276 Table 31: Types SRC TGT 9,328 14,185 2,931 3,333 3,908 4,695 Data statistics. APE@WMT15 APE@WMT16 (EN-ES, news, crowd) (EN-DE, IT, prof.) SRC 2.905 6.616 TGT 3.312 8.845 PE 3.085 8.245 Table 32: Repetition Rate (RR) of the WMT15 (EnglishSpanish, news domain, crowdsourced post-edits) and WMT16 (English-German, IT domain, professional posteditors) APE Task data. 7.1.3 PE 16,388 3,506 5,047 SRC 5,628 1,922 2,479 Lemmas TGT PE 11,418 13,244 2,686 2,806 3,753 4,050 the development set, optimizing TER/BLEU with Minimum Error Rate Training (Och, 2003). The results of this additional term of comparison are also reported in Table 34. For each submitted run, the statistical significance of performance differences with respect to the baselines and the re-implementation of Simard et al. (2007) was calculated with the bootstrap test (Koehn, 2004). Baseline The official baseline results are the TER and BLEU scores calculated by comparing the raw MT output with the human post-edits. In practice, the baseline APE system is a system that leaves all the test targets unmodified.35 Baseline results are reported in Table 34. 7.2 Participants Monolingual"
W16-2301,W16-2338,0,0.0374669,"Missing"
W16-2301,J03-1002,0,0.0268639,"word alignments and bilingual distributed representations to introduce a new set of features for the sentence-Level QE task. The features extracted include three alignment-based features, three bilingual embedding-based features, two embeddingbased features constrained on alignment links, as well as a set of 74 bigrams used as boolean features. The set of bigrams represents the most frequent bigrams in translations that have changed after the post-edition, and they are compiled by aligning translations to their post-editions provided in the WMT QE datasets. To produce these features, GIZA++ (Och and Ney, 2003) was used for word alignment and Multivec (Berard et al., 2016) was used for the bilingual model, which jointly learns distributed representations for source and target languages using a parallel corpus. To build the bilingual model, domain-specific data compiled from the resources made available for the WMT 16 IT-Domain shared task was used. As prediction model, a Linear Regression model using scikit-learn was built using a combination of QuEst++ baseline features and the new features proposed. tional features for both tasks. UNBABEL (Task 2): Two systems were submitted for the word-level tas"
W16-2301,W16-2321,0,0.0372138,"Missing"
W16-2301,W16-2388,1,0.748184,"Missing"
W16-2301,W16-2333,0,0.0259256,"Missing"
W16-2301,W15-3026,0,0.0339859,"Missing"
W16-2301,W16-2379,1,0.819672,"Missing"
W16-2301,W16-2334,1,0.811656,"Missing"
W16-2301,P02-1040,0,0.105557,", eventually, make the APE task more feasible by automatic systems. Other changes concern the language combination and the evaluation mode. As regards the languages, we moved from English-Spanish to English-German, which is one of the language pairs covered by the QT21 Project26 that supported data collection and post-editing. Concerning the evaluation, we changed from TER scores computed both in case-sensitive and caseinsensitive mode to a single ranking based on case sensitive measurements. Besides these changes the new round of the APE task included some extensions in the evaluation. BLEU (Papineni et al., 2002) has been introduced as a secondary evaluation metric to measure the improvements over the rough MT output. In addition, to gain further insights on final output quality, a subset of the outputs of the submitted systems has also been manually evaluated. Based on these changes and extensions, the goals of this year’s shared task were to: i) improve and stabilize the evaluation framework in view of future rounds, ii) analyze the effect on task 26 feasibility of data coming from a narrow domain, iii) analyze the effect of post-edits collected from professional translators, iv) analyze how humans"
W16-2301,W16-2389,0,0.0210658,"Missing"
W16-2301,W16-2390,0,0.0283246,"Missing"
W16-2301,W16-2322,0,0.0139204,"ng and evaluating the manual translations has settled into the following pattern. We ask human annotators to rank the outputs of five systems. From these rankings, we produce pairwise translation comparisons, and then evaluate them with a version of the TrueSkill algorithm adapted to our task. We refer to this approach (described in Section 3.4) as the relative ranking approach (RR), so named because the pairwise comparisons denote only relative ability between a pair of systems, and cannot be used to infer their absolute quality. These results are used to produce the official ranking for the WMT 2016 tasks. However, work in evaluation over the past few years has provided fresh insight into ways to collect direct assessments (DA) of machine translation quality. In this setting, annotators are asked to provide an assessment of the direct quality of the output of a system relative to a reference translation. In order to evaluate the potential of this approach for future WMT evaluations, we conducted a direct assessment evaluation in parallel. This evaluation, together with a comparison of the official results, is described in Section 3.5. 2.3 3.1 2.2 Training data As in past years we provide"
W16-2301,W16-2392,1,0.772695,"Missing"
W16-2301,L16-1649,1,0.704564,"): one for the 17 baseline features and another for the 500 features from the embeddings. Since each kernel has its own set of hyperparameters, the full model can leverage the contributions from the two different sets. The second system (GRAPH-DISC) combines the baseline features with discourse-aware features. The discourse aware features are the same as the ones used by Scarton et al. (2015a) plus Latent Semantic Analysis (LSA) cohesion features (Scarton and Specia, 2014), number of subtrees and height of the Rhetorical Structure Theory (RST) tree and entity graph-based coherence scores (Sim Smith et al., 2016). Discourseaware and RST tree features were extracted only for English (tools are only available for this language), LSA features were extracted for both languages, and entity graph-based coherence scores were extracted for the target language only (Spanish), as the source documents are expected to be coherent. This QE model was trained with an SVR algorithm. YSDA (Task 1): The YSDA submission is based on a simple idea that the more complex the sentence is the more difficult it is to translate. For this purpose, it uses information provided by syntactic parsing (information from parsing trees,"
W16-2301,W16-2391,1,0.796337,"Missing"
W16-2301,2014.eamt-1.21,1,0.643048,"e extracted by averaging word embeddings in the document. The GP model was trained with two Rational Quadratic kernels (Rasmussen and Williams, 2006): one for the 17 baseline features and another for the 500 features from the embeddings. Since each kernel has its own set of hyperparameters, the full model can leverage the contributions from the two different sets. The second system (GRAPH-DISC) combines the baseline features with discourse-aware features. The discourse aware features are the same as the ones used by Scarton et al. (2015a) plus Latent Semantic Analysis (LSA) cohesion features (Scarton and Specia, 2014), number of subtrees and height of the Rhetorical Structure Theory (RST) tree and entity graph-based coherence scores (Sim Smith et al., 2016). Discourseaware and RST tree features were extracted only for English (tools are only available for this language), LSA features were extracted for both languages, and entity graph-based coherence scores were extracted for the target language only (Spanish), as the source documents are expected to be coherent. This QE model was trained with an SVR algorithm. YSDA (Task 1): The YSDA submission is based on a simple idea that the more complex the sentence"
W16-2301,W15-3040,1,0.909092,"on-word corpus,18 with a vocabulary size of 527K words. Document embeddings are extracted by averaging word embeddings in the document. The GP model was trained with two Rational Quadratic kernels (Rasmussen and Williams, 2006): one for the 17 baseline features and another for the 500 features from the embeddings. Since each kernel has its own set of hyperparameters, the full model can leverage the contributions from the two different sets. The second system (GRAPH-DISC) combines the baseline features with discourse-aware features. The discourse aware features are the same as the ones used by Scarton et al. (2015a) plus Latent Semantic Analysis (LSA) cohesion features (Scarton and Specia, 2014), number of subtrees and height of the Rhetorical Structure Theory (RST) tree and entity graph-based coherence scores (Sim Smith et al., 2016). Discourseaware and RST tree features were extracted only for English (tools are only available for this language), LSA features were extracted for both languages, and entity graph-based coherence scores were extracted for the target language only (Spanish), as the source documents are expected to be coherent. This QE model was trained with an SVR algorithm. YSDA (Task 1)"
W16-2301,2006.amta-papers.25,0,0.850121,"ombinations of several features. A regression model was training to predict BLEU as target metric instead HTER. The machine learning pipeline uses an SVR with RBF kernel to predict BLEU scores, followed by a linear SVR to predict HTER scores from BLEU scores. As external resources, the system uses a syntactic parser, pseudo-references and back-translation from web-scale MT system, and a web-scale language model. 6.3 Task 1: Predicting sentence-level quality This task consists in scoring (and ranking) translation sentences according to the percentage of their words that need to be fixed. HTER (Snover et al., 2006) is used as quality score, i.e. the minimum edit distance between the machine translation and its manually post-edited version in [0,1]. As in previous years, two variants of the results could be submitted: • Scoring: An absolute HTER score for each sentence translation, to be interpreted as an error metric: lower scores mean better translations. • Ranking: A ranking of sentence translations for all source sentences from best to worst. For this variant, it does not matter how the ranking is produced (from HTER predictions or by other means). The reference ranking is defined based on the true H"
W16-2301,W15-4916,1,0.824025,"Missing"
W16-2301,W16-2346,1,0.0602876,"Missing"
W16-2301,W16-2325,1,0.816227,"Missing"
W16-2301,W16-2393,0,0.033041,"Missing"
W16-2301,W16-2326,0,0.0221449,"Missing"
W16-2301,W16-2327,1,0.737603,"Missing"
W16-2301,W16-2328,0,0.0403946,"Missing"
W16-2301,C00-2137,0,0.0384283,"Missing"
W16-2301,D07-1091,1,\N,Missing
W16-2301,W09-0401,1,\N,Missing
W16-2301,P11-1105,0,\N,Missing
W16-2301,N07-1064,0,\N,Missing
W16-2301,W04-3250,1,\N,Missing
W16-2301,P15-4020,1,\N,Missing
W16-2301,W16-2377,1,\N,Missing
W16-2301,aziz-etal-2012-pet,1,\N,Missing
W16-2301,2012.eamt-1.31,0,\N,Missing
W16-2301,C14-1182,0,\N,Missing
W16-2301,W16-2316,0,\N,Missing
W16-2301,W16-2332,1,\N,Missing
W16-2301,W16-2320,1,\N,Missing
W16-2301,W16-2335,0,\N,Missing
W16-2301,W16-2329,0,\N,Missing
W16-2301,W16-2383,0,\N,Missing
W16-2301,W16-2381,1,\N,Missing
W16-2301,W16-2312,0,\N,Missing
W16-2301,P16-1162,1,\N,Missing
W16-2301,W13-2243,1,\N,Missing
W16-2301,W08-0509,0,\N,Missing
W16-2301,2015.eamt-1.17,1,\N,Missing
W16-2301,W14-6111,0,\N,Missing
W16-2301,2012.tc-1.5,1,\N,Missing
W16-2301,W16-2347,1,\N,Missing
W16-2301,W16-2314,0,\N,Missing
W16-2315,J07-2003,0,0.142484,"erarchical grammar that the system can use for serial concatenation of phrases as in monotonic phrase-based translation. In the Moses implementation, the decoder internally adds a sentence start terminal symbol &lt;s> and a sentence end terminal symbol &lt;/s> to the input before and after each sentence, respectively. Therefore, two more special rules S → h&lt;s>, &lt;s>i S → hS∼0 &lt;/s>, S∼0 &lt;/s>i 2.1 (2) are included which allow the decoder to finalize its translations. Hierarchical search is conducted with a customized version of the CYK+ parsing algorithm (Chappelier and Rajman, 1998) and cube pruning (Chiang, 2007). A hypergraph which represents the whole parsing space is built employing CYK+. Cube pruning operates in bottom-up topological order on this hypergraph and expands at most k derivations at each hypernode. All our experiments are run with the open source Moses implementation (Hoang et al., 2009) of the hierarchical phrase-based translation paradigm. 2 (1) System Overview Hierarchical Phrase-Based Translation In hierarchical phrase-based translation, a probabilistic synchronous context-free grammar is induced from bilingual training corpora. In addition to continuous lexical phrases as in stand"
W16-2315,W06-1607,0,0.0385299,"ted weight. Baseline Setup The features of our plain hierarchical phrase-based baseline are: CommonCrawl LM training data. A large Romanian CommonCrawl corpus has been released for the constrained track of the WMT16 shared task for machine translation of news. In our system, we utilize this corpus by adding it to the training data of the background LM. We append it to the concatenation of news2015, Europarl, and SETimes2 data and estimate a bigger background LM. • Rule translation log-probabilities in both target-to-source and source-to-target direction, smoothed with Good-Turing discounting (Foster et al., 2006). • Lexical translation log-probabilities in both target-to-source and source-to-target direction. • Seven binary features indicating absolute occurrence count classes of translation rules (with count classes 1, 2, 3, 4, 5-6, 7-10, >10). 6 Pruned individual LMs are trained with KenLM’s --prune '0 0 1' parameters. Weights for linear LM interpolation are optimized on newsdev2016_1. 313 Pruned vs. unpruned LMs. We compare pruned and unpruned language models. In the pruned versions of the models, singleton n-grams of order three and higher are discarded, whereas all n-grams are kept in the unprune"
W16-2315,W16-2304,0,0.12408,"cted from the parallel training corpus. Extracted rules of a standard hierarchical grammar are of the form X → hα, β ,∼ i where hα, β i 2.2 Data and Preprocessing Our system is trained using only permissible Romanian monolingual and English–Romanian parallel corpora provided by the organizers of the WMT16 shared task for machine translation of news: Europarl (Koehn, 2005), SETimes2 (Tyers and Alperen, 2010), News Crawl articles from 2015 (denoted as news2015 hereafter), and CommonCrawl (Buck et al., 2014). The target side of the data is preprocessed with tokro, LIMSI’s tokenizer for Romanian (Allauzen et al., 2016).5 The English source side is tokenized using the tokenizer.perl script from the Moses toolkit. Romanian and English sentences are both frequent-cased (with Moses’ truecase.perl). 5 https://perso.limsi.fr/aufrant/ software/tokro 312 • An indicator feature that fires on applications of the glue rule. • Word penalty. • Rule penalty. • A 5-gram language model. We split the development set newsdev2016 into two halves (newsdev2016_1 with the first 1000 sentences and newsdev2016_2 with the last 999 sentences). During the system building process, we measure progress by evaluating on newsdev2016_2 as"
W16-2315,2011.iwslt-evaluation.18,0,0.0230414,"e compare pruned and unpruned language models. In the pruned versions of the models, singleton n-grams of order three and higher are discarded, whereas all n-grams are kept in the unpruned versions. We follow the approach outlined by Huck et al. (2011) to augment the system with the synthetic parallel data. A foreground phrase table extracted from the human-generated parallel data is filled up with entries from a background phrase table extracted from the synthetic parallel data. An entry from the background table is only added if the foreground table does not already contain a similar entry (Bisazza et al., 2011). A binary feature distinguishes background phrases from foreground phrases. For the background phrase table, we extract only lexical phrases (i.e., phrases without non-terminals on their right-hand side) from the synthetic parallel data, no hierarchical phrases. The phrase length for entries of the background table is restricted to a maximum number of five terminal symbols on the source side. Lexical scores over the phrases extracted from synthetic data are calculated with a lexicon model learned from the human-generated parallel data, as proposed by Huck and Ney (2012). More hierarchical rul"
W16-2315,E14-2008,1,0.83418,"malized as a synchronous context-free grammar. We integrate several non-standard enhancements into our hierarchical phrase-based system and empirically evaluate their impact on translation quality. Our system is furthermore one component in a combination of systems by members of the HimL project and another EU-funded project, QT21.3 Measured in B LEU (Papineni et al., 2002), the QT21/HimL submission yields top translation quality amongst the shared task submissions.4 The QT21/HimL submission highlights the continued success of system combinations based on the Jane machine translation toolkit (Freitag et al., 2014a) in open evaluation campaigns (Freitag et al., 2013; Freitag et al., 2014b; Freitag et al., 2014c). A description of the QT21/HimL combined submission is given by Peter et al. (2016). This paper describes the hierarchical phrase-based machine translation system built jointly by the University of Edinburgh and the University of Munich (LMU) for the shared translation task at the ACL 2016 First Conference on Machine Translation (WMT16). The WMT16 Edinburgh/LMU system was trained for translation of news domain texts from English into Romanian. We participated in the shared task for machine tran"
W16-2315,J93-2003,0,0.0655029,"Missing"
W16-2315,W14-3310,1,0.882823,"malized as a synchronous context-free grammar. We integrate several non-standard enhancements into our hierarchical phrase-based system and empirically evaluate their impact on translation quality. Our system is furthermore one component in a combination of systems by members of the HimL project and another EU-funded project, QT21.3 Measured in B LEU (Papineni et al., 2002), the QT21/HimL submission yields top translation quality amongst the shared task submissions.4 The QT21/HimL submission highlights the continued success of system combinations based on the Jane machine translation toolkit (Freitag et al., 2014a) in open evaluation campaigns (Freitag et al., 2013; Freitag et al., 2014b; Freitag et al., 2014c). A description of the QT21/HimL combined submission is given by Peter et al. (2016). This paper describes the hierarchical phrase-based machine translation system built jointly by the University of Edinburgh and the University of Munich (LMU) for the shared translation task at the ACL 2016 First Conference on Machine Translation (WMT16). The WMT16 Edinburgh/LMU system was trained for translation of news domain texts from English into Romanian. We participated in the shared task for machine tran"
W16-2315,buck-etal-2014-n,0,0.0874284,"Missing"
W16-2315,2014.iwslt-evaluation.7,1,0.880814,"malized as a synchronous context-free grammar. We integrate several non-standard enhancements into our hierarchical phrase-based system and empirically evaluate their impact on translation quality. Our system is furthermore one component in a combination of systems by members of the HimL project and another EU-funded project, QT21.3 Measured in B LEU (Papineni et al., 2002), the QT21/HimL submission yields top translation quality amongst the shared task submissions.4 The QT21/HimL submission highlights the continued success of system combinations based on the Jane machine translation toolkit (Freitag et al., 2014a) in open evaluation campaigns (Freitag et al., 2013; Freitag et al., 2014b; Freitag et al., 2014c). A description of the QT21/HimL combined submission is given by Peter et al. (2016). This paper describes the hierarchical phrase-based machine translation system built jointly by the University of Edinburgh and the University of Munich (LMU) for the shared translation task at the ACL 2016 First Conference on Machine Translation (WMT16). The WMT16 Edinburgh/LMU system was trained for translation of news domain texts from English into Romanian. We participated in the shared task for machine tran"
W16-2315,N12-1047,0,0.074748,"; Koehn et al., 2003) to the two trained alignments. We extract synchronous context-free grammar rules that are consistent with the symmetrized word alignment from the parallel training data. We train 5-gram language models (LMs) with modified Kneser-Ney smoothing (Kneser and Ney, 1995; Chen and Goodman, 1998). KenLM (Heafield, 2011) is employed for LM training and scoring, and SRILM (Stolcke, 2002) for linear LM interpolation. Our translation model incorporates a number of different features in a log-linear combination (Och and Ney, 2002). We tune the feature weights with batch k-best M IRA (Cherry and Foster, 2012) to maximize B LEU (Papineni et al., 2002) on a development set. We run M IRA for 25 iterations on 200-best lists. 2.4 2.5 Enhancements We now describe modifications that we apply on top of the baseline. The results of the empirical evaluation will be given in Section 3. Linear LM interpolation vs. individual LMs as features in the log-linear combination. Rather than employing a linearly interpolated LM, we integrate the individual LMs trained over the separate corpora (news2015, Europarl, SETimes2) directly into the log-linear feature combination of the system and let M IRA optimize their wei"
W16-2315,D08-1089,0,0.0533428,"f words covered by non-terminals at extraction time. Phrase orientation model. We implemented a feature in Moses that resembles the phrase orientation model for hierarchical machine translation as described by Huck et al. (2013). The Huck et al. (2013) implementation had been released as part of the Jane toolkit (Vilar et al., 2010; Vilar et al., 2012; Huck et al., 2012). Our new Moses implementation technically operates in almost the same manner, except for minor implementation differences. Similarly to the type of lexicalized reordering models that are in common use in phrase-based systems (Galley and Manning, 2008), our model estimates the probabilities of orientation classes for each phrase (or: rule) from the training data. We use three orientation classes: monotone, swap, and discontinuous.7 Larger development data. Since no dedicated unseen test set was available during system building, newsdev2016 was split into its first half (newsdev2016_1) and its second half (newsdev2016_2) so that we could tune on the first half and keep the second half untouched for evaluating progress in translation quality with the various enhancements. For the final system (our primary submission), we took the best configu"
W16-2315,W08-0509,0,0.0437082,"_1 is utilized for tuning. 2.3 We discard rules with non-terminals on their right-hand side if they are singletons in the training data. The baseline language model is a linear interpolation of three 5-gram LMs trained over the Romanian news2015, Europarl, and SETimes2 training data, respectively, with pruning of singleton n-grams of order three and higher.6 We run the Moses chart-based decoder with cube pruning, configured at a maximum chart span of 25 and otherwise default settings. Training and Tuning We create word alignments by aligning the bilingual data in both directions with MGIZA++ (Gao and Vogel, 2008). We use a sequence of IBM word alignment models (Brown et al., 1993) with five iterations of EM training (Dempster et al., 1977) of Model 1, three iterations of Model 3, and three iterations of Model 4. After EM, we obtain a symmetrized alignment by applying the grow-diag-final-and heuristic (Och and Ney, 2003; Koehn et al., 2003) to the two trained alignments. We extract synchronous context-free grammar rules that are consistent with the symmetrized word alignment from the parallel training data. We train 5-gram language models (LMs) with modified Kneser-Ney smoothing (Kneser and Ney, 1995;"
W16-2315,2005.mtsummit-papers.11,0,0.104257,"S is the start symbol of the grammar. The generic non-terminal X is used as a placeholder for the gaps within the right-hand side of hierarchical translation rules as well as on all left-hand sides of the translation rules that are extracted from the parallel training corpus. Extracted rules of a standard hierarchical grammar are of the form X → hα, β ,∼ i where hα, β i 2.2 Data and Preprocessing Our system is trained using only permissible Romanian monolingual and English–Romanian parallel corpora provided by the organizers of the WMT16 shared task for machine translation of news: Europarl (Koehn, 2005), SETimes2 (Tyers and Alperen, 2010), News Crawl articles from 2015 (denoted as news2015 hereafter), and CommonCrawl (Buck et al., 2014). The target side of the data is preprocessed with tokro, LIMSI’s tokenizer for Romanian (Allauzen et al., 2016).5 The English source side is tokenized using the tokenizer.perl script from the Moses toolkit. Romanian and English sentences are both frequent-cased (with Moses’ truecase.perl). 5 https://perso.limsi.fr/aufrant/ software/tokro 312 • An indicator feature that fires on applications of the glue rule. • Word penalty. • Rule penalty. • A 5-gram language"
W16-2315,W15-3013,1,0.839627,"h machine-translated English counterparts is utilized for lightly-supervised training (Schwenk, 2008) of our English→Romanian hierarchical system. 7 Using Moses’ Experiment Management System (EMS) (Koehn, 2010), the phrase orientation model for hierarchical machine translation can be activated by simply adding a line phrase-orientation = true to the [TRAINING] section of the EMS configuration file. 8 Whenever available, we typically attempt to use large development sets (in the order of a few thousand sentences), e.g. for Edinburgh’s phrase-based systems for the German– English language pair (Haddow et al., 2015). 314 en→ro newsdev2016_1 newsdev2016_2 newstest2016 baseline with interpolated LM over news2015, Europarl, SETimes2 + three individual LMs (replacing the interpolated LM) + background LM over concatenation of news2015, Europarl, SETimes2 + CommonCrawl LM training data in background LM + all LMs unpruned + more hierarchical rules + phrase orientation model + lightly-supervised training (contrastive submission system) + tuning on full newsdev2016 (primary submission system) 22.1 21.6 22.2 23.1 23.4 23.1 24.4 24.8 24.5 26.6 26.6 27.1 28.3 28.6 29.0 29.5 30.2 30.9 23.0 22.9 23.3 24.4 24.4 24.7 25"
W16-2315,P02-1038,0,0.264252,"lignment by applying the grow-diag-final-and heuristic (Och and Ney, 2003; Koehn et al., 2003) to the two trained alignments. We extract synchronous context-free grammar rules that are consistent with the symmetrized word alignment from the parallel training data. We train 5-gram language models (LMs) with modified Kneser-Ney smoothing (Kneser and Ney, 1995; Chen and Goodman, 1998). KenLM (Heafield, 2011) is employed for LM training and scoring, and SRILM (Stolcke, 2002) for linear LM interpolation. Our translation model incorporates a number of different features in a log-linear combination (Och and Ney, 2002). We tune the feature weights with batch k-best M IRA (Cherry and Foster, 2012) to maximize B LEU (Papineni et al., 2002) on a development set. We run M IRA for 25 iterations on 200-best lists. 2.4 2.5 Enhancements We now describe modifications that we apply on top of the baseline. The results of the empirical evaluation will be given in Section 3. Linear LM interpolation vs. individual LMs as features in the log-linear combination. Rather than employing a linearly interpolated LM, we integrate the individual LMs trained over the separate corpora (news2015, Europarl, SETimes2) directly into th"
W16-2315,W11-2123,0,0.0606968,"alignment models (Brown et al., 1993) with five iterations of EM training (Dempster et al., 1977) of Model 1, three iterations of Model 3, and three iterations of Model 4. After EM, we obtain a symmetrized alignment by applying the grow-diag-final-and heuristic (Och and Ney, 2003; Koehn et al., 2003) to the two trained alignments. We extract synchronous context-free grammar rules that are consistent with the symmetrized word alignment from the parallel training data. We train 5-gram language models (LMs) with modified Kneser-Ney smoothing (Kneser and Ney, 1995; Chen and Goodman, 1998). KenLM (Heafield, 2011) is employed for LM training and scoring, and SRILM (Stolcke, 2002) for linear LM interpolation. Our translation model incorporates a number of different features in a log-linear combination (Och and Ney, 2002). We tune the feature weights with batch k-best M IRA (Cherry and Foster, 2012) to maximize B LEU (Papineni et al., 2002) on a development set. We run M IRA for 25 iterations on 200-best lists. 2.4 2.5 Enhancements We now describe modifications that we apply on top of the baseline. The results of the empirical evaluation will be given in Section 3. Linear LM interpolation vs. individual"
W16-2315,J03-1002,0,0.0115423,"singleton n-grams of order three and higher.6 We run the Moses chart-based decoder with cube pruning, configured at a maximum chart span of 25 and otherwise default settings. Training and Tuning We create word alignments by aligning the bilingual data in both directions with MGIZA++ (Gao and Vogel, 2008). We use a sequence of IBM word alignment models (Brown et al., 1993) with five iterations of EM training (Dempster et al., 1977) of Model 1, three iterations of Model 3, and three iterations of Model 4. After EM, we obtain a symmetrized alignment by applying the grow-diag-final-and heuristic (Och and Ney, 2003; Koehn et al., 2003) to the two trained alignments. We extract synchronous context-free grammar rules that are consistent with the symmetrized word alignment from the parallel training data. We train 5-gram language models (LMs) with modified Kneser-Ney smoothing (Kneser and Ney, 1995; Chen and Goodman, 1998). KenLM (Heafield, 2011) is employed for LM training and scoring, and SRILM (Stolcke, 2002) for linear LM interpolation. Our translation model incorporates a number of different features in a log-linear combination (Och and Ney, 2002). We tune the feature weights with batch k-best M IRA ("
W16-2315,2009.iwslt-papers.4,0,0.0920231,"sentence, respectively. Therefore, two more special rules S → h&lt;s>, &lt;s>i S → hS∼0 &lt;/s>, S∼0 &lt;/s>i 2.1 (2) are included which allow the decoder to finalize its translations. Hierarchical search is conducted with a customized version of the CYK+ parsing algorithm (Chappelier and Rajman, 1998) and cube pruning (Chiang, 2007). A hypergraph which represents the whole parsing space is built employing CYK+. Cube pruning operates in bottom-up topological order on this hypergraph and expands at most k derivations at each hypernode. All our experiments are run with the open source Moses implementation (Hoang et al., 2009) of the hierarchical phrase-based translation paradigm. 2 (1) System Overview Hierarchical Phrase-Based Translation In hierarchical phrase-based translation, a probabilistic synchronous context-free grammar is induced from bilingual training corpora. In addition to continuous lexical phrases as in standard phrase-based translation, hierarchical phrases with (usually) up to two non-terminals are extracted from the word-aligned parallel training data. The non-terminal set of a standard hierarchical grammar comprises two symbols which are shared by source and target: the initial symbol S and one"
W16-2315,P02-1040,0,0.0975049,"erarchical phrase-based translation (Chiang, 2005) for English→Romanian, a statistical machine translation paradigm that is closely related to phrasebased translation, but allows for phrases with gaps. Conceptionally, the translation model is formalized as a synchronous context-free grammar. We integrate several non-standard enhancements into our hierarchical phrase-based system and empirically evaluate their impact on translation quality. Our system is furthermore one component in a combination of systems by members of the HimL project and another EU-funded project, QT21.3 Measured in B LEU (Papineni et al., 2002), the QT21/HimL submission yields top translation quality amongst the shared task submissions.4 The QT21/HimL submission highlights the continued success of system combinations based on the Jane machine translation toolkit (Freitag et al., 2014a) in open evaluation campaigns (Freitag et al., 2013; Freitag et al., 2014b; Freitag et al., 2014c). A description of the QT21/HimL combined submission is given by Peter et al. (2016). This paper describes the hierarchical phrase-based machine translation system built jointly by the University of Edinburgh and the University of Munich (LMU) for the shar"
W16-2315,2012.amta-papers.8,1,0.924532,"ain a similar entry (Bisazza et al., 2011). A binary feature distinguishes background phrases from foreground phrases. For the background phrase table, we extract only lexical phrases (i.e., phrases without non-terminals on their right-hand side) from the synthetic parallel data, no hierarchical phrases. The phrase length for entries of the background table is restricted to a maximum number of five terminal symbols on the source side. Lexical scores over the phrases extracted from synthetic data are calculated with a lexicon model learned from the human-generated parallel data, as proposed by Huck and Ney (2012). More hierarchical rules. The baseline synchronous context-free grammar rules in the phrase table are extracted from the parallel training data with Moses’ default settings: a maximum of five symbols on the source side, a maximum span of ten words, and no right-hand side non-terminal at gaps that cover only a single word on the source side. We allow for extraction of more hierarchical rules by applying less strict rule extraction constraints: a maximum of ten symbols on the source side, a maximum span of twenty words, and no lower limit to the amount of words covered by non-terminals at extra"
W16-2315,W11-2211,1,0.857685,"exploring non-standard enhancements and non-default configuration settings such as: • Individual language models as features, rather than a single linearly interpolated language model; and another background language model estimated over concatenated corpora. • Large CommonCrawl language model training data. • Unpruned language models. • More hierarchical rules than in default systems, by means of imposing less strict extraction constraints. • A phrase orientation model for hierarchical translation (Huck et al., 2013). • Lightly-supervised training (Schwenk, 2008; Schwenk and Senellart, 2009; Huck et al., 2011). • Larger development data for tuning. S → hS∼0 X ∼1 , S∼0 X ∼1 i is incorporated into the hierarchical grammar that the system can use for serial concatenation of phrases as in monotonic phrase-based translation. In the Moses implementation, the decoder internally adds a sentence start terminal symbol &lt;s> and a sentence end terminal symbol &lt;/s> to the input before and after each sentence, respectively. Therefore, two more special rules S → h&lt;s>, &lt;s>i S → hS∼0 &lt;/s>, S∼0 &lt;/s>i 2.1 (2) are included which allow the decoder to finalize its translations. Hierarchical search is conducted with a cus"
W16-2315,2009.mtsummit-posters.17,0,0.0231433,"with a focus of interest on exploring non-standard enhancements and non-default configuration settings such as: • Individual language models as features, rather than a single linearly interpolated language model; and another background language model estimated over concatenated corpora. • Large CommonCrawl language model training data. • Unpruned language models. • More hierarchical rules than in default systems, by means of imposing less strict extraction constraints. • A phrase orientation model for hierarchical translation (Huck et al., 2013). • Lightly-supervised training (Schwenk, 2008; Schwenk and Senellart, 2009; Huck et al., 2011). • Larger development data for tuning. S → hS∼0 X ∼1 , S∼0 X ∼1 i is incorporated into the hierarchical grammar that the system can use for serial concatenation of phrases as in monotonic phrase-based translation. In the Moses implementation, the decoder internally adds a sentence start terminal symbol &lt;s> and a sentence end terminal symbol &lt;/s> to the input before and after each sentence, respectively. Therefore, two more special rules S → h&lt;s>, &lt;s>i S → hS∼0 &lt;/s>, S∼0 &lt;/s>i 2.1 (2) are included which allow the decoder to finalize its translations. Hierarchical search is"
W16-2315,W13-2258,1,0.952949,"nting the particularities of our hierarchical phrase-based system, with a focus of interest on exploring non-standard enhancements and non-default configuration settings such as: • Individual language models as features, rather than a single linearly interpolated language model; and another background language model estimated over concatenated corpora. • Large CommonCrawl language model training data. • Unpruned language models. • More hierarchical rules than in default systems, by means of imposing less strict extraction constraints. • A phrase orientation model for hierarchical translation (Huck et al., 2013). • Lightly-supervised training (Schwenk, 2008; Schwenk and Senellart, 2009; Huck et al., 2011). • Larger development data for tuning. S → hS∼0 X ∼1 , S∼0 X ∼1 i is incorporated into the hierarchical grammar that the system can use for serial concatenation of phrases as in monotonic phrase-based translation. In the Moses implementation, the decoder internally adds a sentence start terminal symbol &lt;s> and a sentence end terminal symbol &lt;/s> to the input before and after each sentence, respectively. Therefore, two more special rules S → h&lt;s>, &lt;s>i S → hS∼0 &lt;/s>, S∼0 &lt;/s>i 2.1 (2) are included wh"
W16-2315,2008.iwslt-papers.6,0,0.0482276,"e-based system, with a focus of interest on exploring non-standard enhancements and non-default configuration settings such as: • Individual language models as features, rather than a single linearly interpolated language model; and another background language model estimated over concatenated corpora. • Large CommonCrawl language model training data. • Unpruned language models. • More hierarchical rules than in default systems, by means of imposing less strict extraction constraints. • A phrase orientation model for hierarchical translation (Huck et al., 2013). • Lightly-supervised training (Schwenk, 2008; Schwenk and Senellart, 2009; Huck et al., 2011). • Larger development data for tuning. S → hS∼0 X ∼1 , S∼0 X ∼1 i is incorporated into the hierarchical grammar that the system can use for serial concatenation of phrases as in monotonic phrase-based translation. In the Moses implementation, the decoder internally adds a sentence start terminal symbol &lt;s> and a sentence end terminal symbol &lt;/s> to the input before and after each sentence, respectively. Therefore, two more special rules S → h&lt;s>, &lt;s>i S → hS∼0 &lt;/s>, S∼0 &lt;/s>i 2.1 (2) are included which allow the decoder to finalize its translat"
W16-2315,2015.mtsummit-papers.19,1,0.913146,"making documents originally written in English available to a large community of speakers in their native language, Romanian. Applications are for instance in the health care sector, where, as part of the Health in my Language project (HimL), several project partners intend to make public health information available in a wider variety of languages.2 The WMT task provides an interesting test bed for English→Romanian machine translation, though adaptation towards the specific domain (consumer health for HimL, rather than news) is also an important aspect that has to be considered in practice (Huck et al., 2015). We investigate the effectiveness of hierarchical phrase-based translation (Chiang, 2005) for English→Romanian, a statistical machine translation paradigm that is closely related to phrasebased translation, but allows for phrases with gaps. Conceptionally, the translation model is formalized as a synchronous context-free grammar. We integrate several non-standard enhancements into our hierarchical phrase-based system and empirically evaluate their impact on translation quality. Our system is furthermore one component in a combination of systems by members of the HimL project and another EU-fu"
W16-2315,N03-1017,0,0.0312287,"f order three and higher.6 We run the Moses chart-based decoder with cube pruning, configured at a maximum chart span of 25 and otherwise default settings. Training and Tuning We create word alignments by aligning the bilingual data in both directions with MGIZA++ (Gao and Vogel, 2008). We use a sequence of IBM word alignment models (Brown et al., 1993) with five iterations of EM training (Dempster et al., 1977) of Model 1, three iterations of Model 3, and three iterations of Model 4. After EM, we obtain a symmetrized alignment by applying the grow-diag-final-and heuristic (Och and Ney, 2003; Koehn et al., 2003) to the two trained alignments. We extract synchronous context-free grammar rules that are consistent with the symmetrized word alignment from the parallel training data. We train 5-gram language models (LMs) with modified Kneser-Ney smoothing (Kneser and Ney, 1995; Chen and Goodman, 1998). KenLM (Heafield, 2011) is employed for LM training and scoring, and SRILM (Stolcke, 2002) for linear LM interpolation. Our translation model incorporates a number of different features in a log-linear combination (Och and Ney, 2002). We tune the feature weights with batch k-best M IRA (Cherry and Foster, 20"
W16-2315,W10-1738,1,0.878506,"on-terminal at gaps that cover only a single word on the source side. We allow for extraction of more hierarchical rules by applying less strict rule extraction constraints: a maximum of ten symbols on the source side, a maximum span of twenty words, and no lower limit to the amount of words covered by non-terminals at extraction time. Phrase orientation model. We implemented a feature in Moses that resembles the phrase orientation model for hierarchical machine translation as described by Huck et al. (2013). The Huck et al. (2013) implementation had been released as part of the Jane toolkit (Vilar et al., 2010; Vilar et al., 2012; Huck et al., 2012). Our new Moses implementation technically operates in almost the same manner, except for minor implementation differences. Similarly to the type of lexicalized reordering models that are in common use in phrase-based systems (Galley and Manning, 2008), our model estimates the probabilities of orientation classes for each phrase (or: rule) from the training data. We use three orientation classes: monotone, swap, and discontinuous.7 Larger development data. Since no dedicated unseen test set was available during system building, newsdev2016 was split into"
W16-2315,W16-2327,1,0.705098,"Missing"
W16-2315,P05-1033,0,\N,Missing
W16-2315,2013.iwslt-evaluation.16,1,\N,Missing
W16-2315,W16-2320,1,\N,Missing
W16-2320,W16-2304,1,0.833347,"factored word representation of the source and the target. On the source side we use the word surface form and two automatic word classes using 100 and 1,000 classes. On the Romanian side, we add the POS information as an additional word factor. 2 3.2 Preprocessing The data provided for the task was preprocessed once, by LIMSI, and shared with all the participants, in order to ensure consistency between systems. On the English side, preprocessing consists of tokenizing and truecasing using the Moses toolkit (Koehn et al., 2007). On the Romanian side, the data is tokenized using LIMSI’s tokro (Allauzen et al., 2016), a rulebased tokenizer that mainly normalizes diacritics and splits punctuation and clitics. This data is truecased in the same way as the English side. In addition, the Romanian sentences are also tagged, lemmatized, and chunked using the TTL tagger (Tufis¸ et al., 2008). 3 The LIMSI system uses NCODE (Crego et al., 2011), which implements the bilingual n-gram approach to SMT (Casacuberta and Vidal, 2004; Crego and Mari˜no, 2006; Mari˜no et al., 2006) that is closely related to the standard phrase-based approach (Zens et al., 2002). In this framework, translation is divided into two steps. T"
W16-2320,W05-0909,0,0.583183,"ions from multiple hypotheses which are obtained from different translation approaches, i.e., the systems described in the previous section. A system combination implementation developed at RWTH Aachen University (Freitag et al., 2014a) is used to combine the outputs of the different engines. The consensus translations outperform the individual hypotheses in terms of translation quality. The first step in system combination is the generation of confusion networks (CN) from I input translation hypotheses. We need pairwise alignments between the input hypotheses, which are obtained from METEOR (Banerjee and Lavie, 2005). The hypotheses are then reordered to match a selected skeleton hypothesis in terms of word ordering. We generate I different CNs, each having one of the input systems as the skeleton hypothesis, and the final lattice is the union of all I generated CNs. In Figure 1 an example of a confusion network with I = 4 input translations is depicted. Decoding of a confusion network finds the best path in the network. Each arc is assigned a score of a linear model combination of M different models, which includes word penalty, 3-gram language model trained on the input hypotheses, a binary primary syst"
W16-2320,P13-2071,1,0.873371,"odel trained on all available data. Words in the Common Crawl dataset that appear fewer than 500 times were replaced by UNK, and all singleton ngrams of order 3 or higher were pruned. We also use a 7-gram class-based language model, trained on the same data. 512 word Edinburgh Phrase-based System Edinburgh’s phrase-based system is built using the Moses toolkit, with fast align (Dyer et al., 2013) for word alignment, and KenLM (Heafield et al., 2013) for language model training. In our Moses setup, we use hierarchical lexicalized reordering (Galley and Manning, 2008), operation sequence model (Durrani et al., 2013), domain indicator features, and binned phrase count features. We use all available parallel data for the translation model, and all available Romanian text for the language model. We use two different 5-gram language models; one built from all the monolingual target text concatenated, without pruning, and one 3 USFD Phrase-based System 4 http://www.quest.dcs.shef.ac.uk/ quest_files/features_blackbox_baseline_ 17 https://github.com/rsennrich/nematus 348 the large building the large home a big huge house house a newsdev2016/1 and newsdev2016/2. The first part was used as development set while t"
W16-2320,D15-1129,1,0.847985,"training and evaluation. The language model uses 3 stacked LSTM layers, with 350 nodes each. The BJM has a projection layer, and computes a forLMU The LMU system integrates a discriminative rule selection model into a hierarchical SMT system, as described in (Tamchyna et al., 2014). The rule selection model is implemented using the highspeed classifier Vowpal Wabbit2 which is fully integrated in Moses’ hierarchical decoder. During decoding, the rule selection model is called at each rule application with syntactic context information as feature templates. The features are the same as used by Braune et al. (2015) in their string-to-tree system, including both lexical and soft source syntax features. The translation model features comprise the standard hierarchical features (Chiang, 2005) with an additional feature for the rule selection model (Braune et al., 2016). Before training, we reduce the number of translation rules using significance testing (Johnson et al., 2007). To extract the features of the rule selection model, we parse the English part of our 2 http://hunch.net/˜vw/ (VW). Implemented by John Langford and many others. 346 URLs, e-mail addresses, etc.). During translation a rule-based loc"
W16-2320,N13-1073,0,0.034805,"preordering model of (de Gispert et al., 2015). The preordering model is trained for 30 iterations on the full MGIZA-aligned training data. We use two language models, built using KenLM. The first is a 5-gram language model trained on all available data. Words in the Common Crawl dataset that appear fewer than 500 times were replaced by UNK, and all singleton ngrams of order 3 or higher were pruned. We also use a 7-gram class-based language model, trained on the same data. 512 word Edinburgh Phrase-based System Edinburgh’s phrase-based system is built using the Moses toolkit, with fast align (Dyer et al., 2013) for word alignment, and KenLM (Heafield et al., 2013) for language model training. In our Moses setup, we use hierarchical lexicalized reordering (Galley and Manning, 2008), operation sequence model (Durrani et al., 2013), domain indicator features, and binned phrase count features. We use all available parallel data for the translation model, and all available Romanian text for the language model. We use two different 5-gram language models; one built from all the monolingual target text concatenated, without pruning, and one 3 USFD Phrase-based System 4 http://www.quest.dcs.shef.ac.uk/ ques"
W16-2320,J04-2004,0,0.0194677,"en systems. On the English side, preprocessing consists of tokenizing and truecasing using the Moses toolkit (Koehn et al., 2007). On the Romanian side, the data is tokenized using LIMSI’s tokro (Allauzen et al., 2016), a rulebased tokenizer that mainly normalizes diacritics and splits punctuation and clitics. This data is truecased in the same way as the English side. In addition, the Romanian sentences are also tagged, lemmatized, and chunked using the TTL tagger (Tufis¸ et al., 2008). 3 The LIMSI system uses NCODE (Crego et al., 2011), which implements the bilingual n-gram approach to SMT (Casacuberta and Vidal, 2004; Crego and Mari˜no, 2006; Mari˜no et al., 2006) that is closely related to the standard phrase-based approach (Zens et al., 2002). In this framework, translation is divided into two steps. To translate a source sentence into a target sentence, the source sentence is first reordered according to a set of rewriting rules so as to reproduce the target word order. This generates a word lattice containing the most promising source permutations, which is then translated. Since the translation step is monotonic, this approach is able to rely on the n-gram assumption to decompose the joint probabilit"
W16-2320,2011.mtsummit-papers.30,0,0.020392,"-based System The RWTH hierarchical setup uses the open source translation toolkit Jane 2.3 (Vilar et al., 2010). Hierarchical phrase-based translation (HPBT) (Chiang, 2007) induces a weighted synchronous context-free grammar from parallel text. In addition to the contiguous lexical phrases, as used in phrase-based translation (PBT), hierarchical phrases with up to two gaps are also extracted. Our baseline model contains models with phrase translation probabilities and lexical smoothing probabilities in both translation directions, word and phrase penalty, and enhanced low frequency features (Chen et al., 2011). It also contains binary features to distinguish between hierarchical and non-hierarchical phrases, the glue rule, and rules with non-terminals at the boundaries. We use the cube pruning algorithm (Huang and Chiang, 2007) for decoding. The system uses three backoff language models (LM) that are estimated with the KenLM toolkit (Heafield et al., 2013) and are integrated into the decoder as separate models in the log-linear combination: a full 4-gram LM (trained on all data), a limited 5-gram LM (trained only on in-domain data), and a 7-gram word class language model (wcLM) (Wuebker et al., 201"
W16-2320,N12-1047,0,0.591808,"rescoring. The phrase-based system is trained on all available parallel training data. The phrase 345 more specifically its implementation in XenC (Rousseau, 2013). As a result, one third of the initial corpus is removed. Finally, we make a linear interpolation of these models, using the SRILM toolkit (Stolcke, 2002). 3.3 training data using the Berkeley parser (Petrov et al., 2006). For model prediction during tuning and decoding, we use parsed versions of the development and test sets. We train the rule selection model using VW and tune the weights of the translation model using batch MIRA (Cherry and Foster, 2012). The 5-gram language model is trained using KenLM (Heafield et al., 2013) on the Romanian part of the Common Crawl corpus concatenated with the Romanian part of the training data. LMU-CUNI The LMU-CUNI contribution is a constrained Moses phrase-based system. It uses a simple factored setting: our phrase table produces not only the target surface form but also its lemma and morphological tag. On the input, we include lemmas, POS tags and information from dependency parses (lemma of the parent node and syntactic relation), all encoded as additional factors. The main difference from a standard p"
W16-2320,E14-2008,1,0.72015,"tems are combined using RWTH’s system combination approach. The final submission shows an improvement of 1.0 B LEU compared to the best single system on newstest2016. 1 Introduction Quality Translation 21 (QT21) is a European machine translation research project with the aim 1 http://www.statmt.org/wmt16/ translation-task.html 344 Proceedings of the First Conference on Machine Translation, Volume 2: Shared Task Papers, pages 344–355, c Berlin, Germany, August 11-12, 2016. 2016 Association for Computational Linguistics mented in Jane, RWTH’s open source statistical machine translation toolkit (Freitag et al., 2014a). The Jane system combination is a mature implementation which previously has been successfully employed in other collaborative projects and for different language pairs (Freitag et al., 2013; Freitag et al., 2014b; Freitag et al., 2014c). In the remainder of the paper, we present the technical details of the QT21/HimL combined machine translation system and the experimental results obtained with it. The paper is structured as follows: We describe the common preprocessing used for most of the individual engines in Section 2. Section 3 covers the characteristics of the different individual en"
W16-2320,P05-1033,0,0.151933,"ative rule selection model into a hierarchical SMT system, as described in (Tamchyna et al., 2014). The rule selection model is implemented using the highspeed classifier Vowpal Wabbit2 which is fully integrated in Moses’ hierarchical decoder. During decoding, the rule selection model is called at each rule application with syntactic context information as feature templates. The features are the same as used by Braune et al. (2015) in their string-to-tree system, including both lexical and soft source syntax features. The translation model features comprise the standard hierarchical features (Chiang, 2005) with an additional feature for the rule selection model (Braune et al., 2016). Before training, we reduce the number of translation rules using significance testing (Johnson et al., 2007). To extract the features of the rule selection model, we parse the English part of our 2 http://hunch.net/˜vw/ (VW). Implemented by John Langford and many others. 346 URLs, e-mail addresses, etc.). During translation a rule-based localisation feature is applied. ward recurrent state encoding the source and target history, a backward recurrent state encoding the source future, and a third LSTM layer to combin"
W16-2320,J07-2003,0,0.558191,"this model is to better condition lexical choices by using the source context and to improve morphological and topical coherence by modeling the (limited left-hand side) target context. We also take advantage of the target factors by using a 7-gram language model trained on sequences of Romanian morphological tags. Finally, our system also uses a standard lexicalized reordering model. 3.4 3.5 RWTH Aachen University: Hierarchical Phrase-based System The RWTH hierarchical setup uses the open source translation toolkit Jane 2.3 (Vilar et al., 2010). Hierarchical phrase-based translation (HPBT) (Chiang, 2007) induces a weighted synchronous context-free grammar from parallel text. In addition to the contiguous lexical phrases, as used in phrase-based translation (PBT), hierarchical phrases with up to two gaps are also extracted. Our baseline model contains models with phrase translation probabilities and lexical smoothing probabilities in both translation directions, word and phrase penalty, and enhanced low frequency features (Chen et al., 2011). It also contains binary features to distinguish between hierarchical and non-hierarchical phrases, the glue rule, and rules with non-terminals at the bou"
W16-2320,W14-3310,1,0.909876,"tems are combined using RWTH’s system combination approach. The final submission shows an improvement of 1.0 B LEU compared to the best single system on newstest2016. 1 Introduction Quality Translation 21 (QT21) is a European machine translation research project with the aim 1 http://www.statmt.org/wmt16/ translation-task.html 344 Proceedings of the First Conference on Machine Translation, Volume 2: Shared Task Papers, pages 344–355, c Berlin, Germany, August 11-12, 2016. 2016 Association for Computational Linguistics mented in Jane, RWTH’s open source statistical machine translation toolkit (Freitag et al., 2014a). The Jane system combination is a mature implementation which previously has been successfully employed in other collaborative projects and for different language pairs (Freitag et al., 2013; Freitag et al., 2014b; Freitag et al., 2014c). In the remainder of the paper, we present the technical details of the QT21/HimL combined machine translation system and the experimental results obtained with it. The paper is structured as follows: We describe the common preprocessing used for most of the individual engines in Section 2. Section 3 covers the characteristics of the different individual en"
W16-2320,D14-1179,0,0.0138582,"Missing"
W16-2320,2014.iwslt-evaluation.7,1,0.925781,"tems are combined using RWTH’s system combination approach. The final submission shows an improvement of 1.0 B LEU compared to the best single system on newstest2016. 1 Introduction Quality Translation 21 (QT21) is a European machine translation research project with the aim 1 http://www.statmt.org/wmt16/ translation-task.html 344 Proceedings of the First Conference on Machine Translation, Volume 2: Shared Task Papers, pages 344–355, c Berlin, Germany, August 11-12, 2016. 2016 Association for Computational Linguistics mented in Jane, RWTH’s open source statistical machine translation toolkit (Freitag et al., 2014a). The Jane system combination is a mature implementation which previously has been successfully employed in other collaborative projects and for different language pairs (Freitag et al., 2013; Freitag et al., 2014b; Freitag et al., 2014c). In the remainder of the paper, we present the technical details of the QT21/HimL combined machine translation system and the experimental results obtained with it. The paper is structured as follows: We describe the common preprocessing used for most of the individual engines in Section 2. Section 3 covers the characteristics of the different individual en"
W16-2320,D08-1089,0,0.0211464,", built using KenLM. The first is a 5-gram language model trained on all available data. Words in the Common Crawl dataset that appear fewer than 500 times were replaced by UNK, and all singleton ngrams of order 3 or higher were pruned. We also use a 7-gram class-based language model, trained on the same data. 512 word Edinburgh Phrase-based System Edinburgh’s phrase-based system is built using the Moses toolkit, with fast align (Dyer et al., 2013) for word alignment, and KenLM (Heafield et al., 2013) for language model training. In our Moses setup, we use hierarchical lexicalized reordering (Galley and Manning, 2008), operation sequence model (Durrani et al., 2013), domain indicator features, and binned phrase count features. We use all available parallel data for the translation model, and all available Romanian text for the language model. We use two different 5-gram language models; one built from all the monolingual target text concatenated, without pruning, and one 3 USFD Phrase-based System 4 http://www.quest.dcs.shef.ac.uk/ quest_files/features_blackbox_baseline_ 17 https://github.com/rsennrich/nematus 348 the large building the large home a big huge house house a newsdev2016/1 and newsdev2016/2. T"
W16-2320,N15-1105,0,0.046766,"Missing"
W16-2320,W08-0509,0,0.06624,"probability 0.2, and also drop out full words with probability 0.1. We clip the gradient norm to 1.0 (Pascanu et al., 2013). We train the models with Adadelta (Zeiler, 2012), reshuffling the training corpus between epochs. We validate the model every 10 000 minibatches via B LEU on a validation set, and perform early stopping on B LEU. Decoding is performed with beam search with a beam size of 12. A more detailed description of the system, and more experimental results, can be found in (Sennrich et al., 2016a). 3.10 3.11 USFD’s phrase-based system is built using the Moses toolkit, with MGIZA (Gao and Vogel, 2008) for word alignment and KenLM (Heafield et al., 2013) for language model training. We use all available parallel data for the translation model. A single 5-gram language model is built using all the target side of the parallel data and a subpart of the monolingual Romanian corpora selected with Xenc-v2 (Rousseau, 2013). For the latter we use all the parallel data as in-domain data and the first half of newsdev2016 as development set. The feature weights are tuned with MERT (Och, 2003) on the first half of newsdev2016. The system produces distinct 1000-best lists, for which we extend the featur"
W16-2320,W16-2315,1,0.820309,"vs et al., 2012) that features language-specific data filtering and cleaning modules. Tilde’s system was trained on all available parallel data. Two language models are trained using KenLM (Heafield, 2011): 1) a 5-gram model using the Europarl and SETimes2 corpora, and 2) a 3-gram model using the Common Crawl corpus. We also apply a custom tokenization tool that takes into account specifics of the Romanian language and handles non-translatable entities (e.g., file paths, 347 up with entries from a background phrase table extracted from the automatically produced News Crawl 2015 parallel data. Huck et al. (2016) give a more in-depth description of the Edinburgh/LMU hierarchical machine translation system, along with detailed experimental results. 3.9 built from only News Crawl 2015, with singleton 3-grams and above pruned out. The weights of all these features and models are tuned with k-best MIRA (Cherry and Foster, 2012) on first the half of newsdev2016. In decoding, we use MBR (Kumar and Byrne, 2004), cube-pruning (Huang and Chiang, 2007) with a pop-limit of 5000, and the Moses ”monotone at punctuation” switch (to prevent reordering across punctuation) (Koehn and Haddow, 2009). Edinburgh Neural Sy"
W16-2320,D07-1103,0,0.032902,"bbit2 which is fully integrated in Moses’ hierarchical decoder. During decoding, the rule selection model is called at each rule application with syntactic context information as feature templates. The features are the same as used by Braune et al. (2015) in their string-to-tree system, including both lexical and soft source syntax features. The translation model features comprise the standard hierarchical features (Chiang, 2005) with an additional feature for the rule selection model (Braune et al., 2016). Before training, we reduce the number of translation rules using significance testing (Johnson et al., 2007). To extract the features of the rule selection model, we parse the English part of our 2 http://hunch.net/˜vw/ (VW). Implemented by John Langford and many others. 346 URLs, e-mail addresses, etc.). During translation a rule-based localisation feature is applied. ward recurrent state encoding the source and target history, a backward recurrent state encoding the source future, and a third LSTM layer to combine them. All layers have 350 nodes. The neural networks are implemented using an extension of the RWTHLM toolkit (Sundermeyer et al., 2014b). The parameter weights are optimized with MERT ("
W16-2320,W14-3360,0,0.0191919,"NMT system on newsdev2016/2, but lags behind on newstest2016. Removing the by itself weakest system shows a slight degradation on newsdev2016/2 and newstest2016, hinting that it still provides valuable information. Table 2 shows a comparison between all systems by scoring the translation output against each other in T ER and B LEU. We see that the neural networks outputs differ the most from all the other systems. Figure 1: System A: the large building; System B: the large home; System C: a big house; System D: a huge house; Reference: the big house. classes were generated using the method of Green et al. (2014). 4 System Combination System combination produces consensus translations from multiple hypotheses which are obtained from different translation approaches, i.e., the systems described in the previous section. A system combination implementation developed at RWTH Aachen University (Freitag et al., 2014a) is used to combine the outputs of the different engines. The consensus translations outperform the individual hypotheses in terms of translation quality. The first step in system combination is the generation of confusion networks (CN) from I input translation hypotheses. We need pairwise alig"
W16-2320,P07-2045,1,0.010375,", 2015) as well as neural network language and translation models. These models use a factored word representation of the source and the target. On the source side we use the word surface form and two automatic word classes using 100 and 1,000 classes. On the Romanian side, we add the POS information as an additional word factor. 2 3.2 Preprocessing The data provided for the task was preprocessed once, by LIMSI, and shared with all the participants, in order to ensure consistency between systems. On the English side, preprocessing consists of tokenizing and truecasing using the Moses toolkit (Koehn et al., 2007). On the Romanian side, the data is tokenized using LIMSI’s tokro (Allauzen et al., 2016), a rulebased tokenizer that mainly normalizes diacritics and splits punctuation and clitics. This data is truecased in the same way as the English side. In addition, the Romanian sentences are also tagged, lemmatized, and chunked using the TTL tagger (Tufis¸ et al., 2008). 3 The LIMSI system uses NCODE (Crego et al., 2011), which implements the bilingual n-gram approach to SMT (Casacuberta and Vidal, 2004; Crego and Mari˜no, 2006; Mari˜no et al., 2006) that is closely related to the standard phrase-based"
W16-2320,P13-2121,0,0.0645203,"Missing"
W16-2320,W11-2123,0,0.124165,"nslation is divided into two steps. To translate a source sentence into a target sentence, the source sentence is first reordered according to a set of rewriting rules so as to reproduce the target word order. This generates a word lattice containing the most promising source permutations, which is then translated. Since the translation step is monotonic, this approach is able to rely on the n-gram assumption to decompose the joint probability of a sentence pair into a sequence of bilingual units called tuples. We train three Romanian 4-gram language models, pruning all singletons with KenLM (Heafield, 2011). We use the in-domain monolingual corpus, the Romanian side of the parallel corpora and a subset of the (out-of-domain) Common Crawl corpus as training data. We select indomain sentences from the latter using the MooreLewis (Moore and Lewis, 2010) filtering method, Translation Systems Each group contributed one or more systems. In this section the systems are presented in alphabetic order. 3.1 LIMSI KIT The KIT system consists of a phrase-based machine translation system using additional models in rescoring. The phrase-based system is trained on all available parallel training data. The phras"
W16-2320,N04-1022,0,0.037676,"f the Romanian language and handles non-translatable entities (e.g., file paths, 347 up with entries from a background phrase table extracted from the automatically produced News Crawl 2015 parallel data. Huck et al. (2016) give a more in-depth description of the Edinburgh/LMU hierarchical machine translation system, along with detailed experimental results. 3.9 built from only News Crawl 2015, with singleton 3-grams and above pruned out. The weights of all these features and models are tuned with k-best MIRA (Cherry and Foster, 2012) on first the half of newsdev2016. In decoding, we use MBR (Kumar and Byrne, 2004), cube-pruning (Huang and Chiang, 2007) with a pop-limit of 5000, and the Moses ”monotone at punctuation” switch (to prevent reordering across punctuation) (Koehn and Haddow, 2009). Edinburgh Neural System Edinburgh’s neural machine translation system is an attentional encoder-decoder (Bahdanau et al., 2015), which we train with nematus.3 We use byte-pair-encoding (BPE) to achieve openvocabulary translation with a fixed vocabulary of subword symbols (Sennrich et al., 2016c). We produce additional parallel training data by automatically translating the monolingual Romanian News Crawl 2015 corpu"
W16-2320,2015.iwslt-papers.3,1,0.744353,"g. It uses two word-based n-gram language models and three additional non-word language models. Two of them are automatic word class-based (Och, 1999) language models, using 100 and 1,000 word classes. In addition, we use a POS-based language model. During decoding, we use a discriminative word lexicon (Niehues and Waibel, 2013) as well. We rescore the system output using a 300-best list. The weights are optimized on the concatenation of the development data and the SETimes2 dev set using the ListNet algorithm (Niehues et al., 2015). In rescoring, we add the source discriminative word lexica (Herrmann et al., 2015) as well as neural network language and translation models. These models use a factored word representation of the source and the target. On the source side we use the word surface form and two automatic word classes using 100 and 1,000 classes. On the Romanian side, we add the POS information as an additional word factor. 2 3.2 Preprocessing The data provided for the task was preprocessed once, by LIMSI, and shared with all the participants, in order to ensure consistency between systems. On the English side, preprocessing consists of tokenizing and truecasing using the Moses toolkit (Koehn e"
W16-2320,J06-4004,0,0.106202,"Missing"
W16-2320,2009.iwslt-papers.4,0,0.0984189,"target history, a backward recurrent state encoding the source future, and a third LSTM layer to combine them. All layers have 350 nodes. The neural networks are implemented using an extension of the RWTHLM toolkit (Sundermeyer et al., 2014b). The parameter weights are optimized with MERT (Och, 2003) towards the B LEU metric. 3.6 3.8 The UEDIN-LMU HPBT system is a hierarchical phrase-based machine translation system (Chiang, 2005) built jointly by the University of Edinburgh and LMU Munich. The system is based on the open source Moses implementation of the hierarchical phrase-based paradigm (Hoang et al., 2009). In addition to a set of standard features in a log-linear combination, a number of non-standard enhancements are employed to achieve improved translation quality. Specifically, we integrate individual language models trained over the separate corpora (News Crawl 2015, Europarl, SETimes2) directly into the log-linear combination of the system and let MIRA (Cherry and Foster, 2012) optimize their weights along with all other features in tuning, rather than relying on a single linearly interpolated language model. We add another background language model estimated over a concatenation of all Ro"
W16-2320,P10-2041,0,0.0238386,"ontaining the most promising source permutations, which is then translated. Since the translation step is monotonic, this approach is able to rely on the n-gram assumption to decompose the joint probability of a sentence pair into a sequence of bilingual units called tuples. We train three Romanian 4-gram language models, pruning all singletons with KenLM (Heafield, 2011). We use the in-domain monolingual corpus, the Romanian side of the parallel corpora and a subset of the (out-of-domain) Common Crawl corpus as training data. We select indomain sentences from the latter using the MooreLewis (Moore and Lewis, 2010) filtering method, Translation Systems Each group contributed one or more systems. In this section the systems are presented in alphabetic order. 3.1 LIMSI KIT The KIT system consists of a phrase-based machine translation system using additional models in rescoring. The phrase-based system is trained on all available parallel training data. The phrase 345 more specifically its implementation in XenC (Rousseau, 2013). As a result, one third of the initial corpus is removed. Finally, we make a linear interpolation of these models, using the SRILM toolkit (Stolcke, 2002). 3.3 training data using"
W16-2320,P07-1019,0,0.236745,"grammar from parallel text. In addition to the contiguous lexical phrases, as used in phrase-based translation (PBT), hierarchical phrases with up to two gaps are also extracted. Our baseline model contains models with phrase translation probabilities and lexical smoothing probabilities in both translation directions, word and phrase penalty, and enhanced low frequency features (Chen et al., 2011). It also contains binary features to distinguish between hierarchical and non-hierarchical phrases, the glue rule, and rules with non-terminals at the boundaries. We use the cube pruning algorithm (Huang and Chiang, 2007) for decoding. The system uses three backoff language models (LM) that are estimated with the KenLM toolkit (Heafield et al., 2013) and are integrated into the decoder as separate models in the log-linear combination: a full 4-gram LM (trained on all data), a limited 5-gram LM (trained only on in-domain data), and a 7-gram word class language model (wcLM) (Wuebker et al., 2013) trained on all data and with a output vocabulary of 143K words. The system produces 1000-best lists which are reranked using a LSTM-based (Hochreiter and Schmidhuber, 1997; Gers et al., 2000; Gers et al., 2003) language"
W16-2320,2012.amta-papers.19,1,0.778005,"common preprocessing used for most of the individual engines in Section 2. Section 3 covers the characteristics of the different individual engines, followed by a brief overview of our system combination approach (Section 4). We then summarize our empirical results in Section 5, showing that we achieve better translation quality than with any individual engine. Finally, in Section 6, we provide a statistical analysis of certain linguistic phenomena, specifically the prediction precision on morphological attributes. We conclude the paper with Section 7. table is adapted to the SETimes2 corpus (Niehues and Waibel, 2012). The system uses a prereordering technique (Rottmann and Vogel, 2007) in combination with lexical reordering. It uses two word-based n-gram language models and three additional non-word language models. Two of them are automatic word class-based (Och, 1999) language models, using 100 and 1,000 word classes. In addition, we use a POS-based language model. During decoding, we use a discriminative word lexicon (Niehues and Waibel, 2013) as well. We rescore the system output using a 300-best list. The weights are optimized on the concatenation of the development data and the SETimes2 dev set usin"
W16-2320,W11-2211,1,0.902733,"ty words, and no lower limit to the amount of words covered by right-hand side non-terminals at extraction time. We discard rules with non-terminals on their right-hand side if they are singletons in the training data. In order to promote better reordering decisions, we implemented a feature in Moses that resembles the phrase orientation model for hierarchical machine translation as described by Huck et al. (2013) and extend our system with it. The model scores orientation classes (monotone, swap, discontinuous) for each rule application in decoding. We finally follow the approach outlined by Huck et al. (2011) for lightly-supervised training of hierarchical systems. We automatically translate parts (1.2M sentences) of the monolingual Romanian News Crawl 2015 corpus to English with a Romanian→English phrase-based statistical machine translation system (Williams et al., 2016). The foreground phrase table extracted from the human-generated parallel data is filled RWTH Neural System The second system provided by the RWTH is an attention-based recurrent neural network similar to (Bahdanau et al., 2015). The implementation is based on Blocks (van Merri¨enboer et al., 2015) and Theano (Bergstra et al., 20"
W16-2320,W13-2264,1,0.852517,"stic phenomena, specifically the prediction precision on morphological attributes. We conclude the paper with Section 7. table is adapted to the SETimes2 corpus (Niehues and Waibel, 2012). The system uses a prereordering technique (Rottmann and Vogel, 2007) in combination with lexical reordering. It uses two word-based n-gram language models and three additional non-word language models. Two of them are automatic word class-based (Och, 1999) language models, using 100 and 1,000 word classes. In addition, we use a POS-based language model. During decoding, we use a discriminative word lexicon (Niehues and Waibel, 2013) as well. We rescore the system output using a 300-best list. The weights are optimized on the concatenation of the development data and the SETimes2 dev set using the ListNet algorithm (Niehues et al., 2015). In rescoring, we add the source discriminative word lexica (Herrmann et al., 2015) as well as neural network language and translation models. These models use a factored word representation of the source and the target. On the source side we use the word surface form and two automatic word classes using 100 and 1,000 classes. On the Romanian side, we add the POS information as an additio"
W16-2320,W13-2258,1,0.869431,"extraction, we impose less strict extraction constraints than the Moses defaults. We extract more hierarchical rules by allowing for a maximum of ten symbols on the source side, a maximum span of twenty words, and no lower limit to the amount of words covered by right-hand side non-terminals at extraction time. We discard rules with non-terminals on their right-hand side if they are singletons in the training data. In order to promote better reordering decisions, we implemented a feature in Moses that resembles the phrase orientation model for hierarchical machine translation as described by Huck et al. (2013) and extend our system with it. The model scores orientation classes (monotone, swap, discontinuous) for each rule application in decoding. We finally follow the approach outlined by Huck et al. (2011) for lightly-supervised training of hierarchical systems. We automatically translate parts (1.2M sentences) of the monolingual Romanian News Crawl 2015 corpus to English with a Romanian→English phrase-based statistical machine translation system (Williams et al., 2016). The foreground phrase table extracted from the human-generated parallel data is filled RWTH Neural System The second system prov"
W16-2320,E99-1010,0,0.040797,"ion 5, showing that we achieve better translation quality than with any individual engine. Finally, in Section 6, we provide a statistical analysis of certain linguistic phenomena, specifically the prediction precision on morphological attributes. We conclude the paper with Section 7. table is adapted to the SETimes2 corpus (Niehues and Waibel, 2012). The system uses a prereordering technique (Rottmann and Vogel, 2007) in combination with lexical reordering. It uses two word-based n-gram language models and three additional non-word language models. Two of them are automatic word class-based (Och, 1999) language models, using 100 and 1,000 word classes. In addition, we use a POS-based language model. During decoding, we use a discriminative word lexicon (Niehues and Waibel, 2013) as well. We rescore the system output using a 300-best list. The weights are optimized on the concatenation of the development data and the SETimes2 dev set using the ListNet algorithm (Niehues et al., 2015). In rescoring, we add the source discriminative word lexica (Herrmann et al., 2015) as well as neural network language and translation models. These models use a factored word representation of the source and th"
W16-2320,P03-1021,0,0.501814,". To extract the features of the rule selection model, we parse the English part of our 2 http://hunch.net/˜vw/ (VW). Implemented by John Langford and many others. 346 URLs, e-mail addresses, etc.). During translation a rule-based localisation feature is applied. ward recurrent state encoding the source and target history, a backward recurrent state encoding the source future, and a third LSTM layer to combine them. All layers have 350 nodes. The neural networks are implemented using an extension of the RWTHLM toolkit (Sundermeyer et al., 2014b). The parameter weights are optimized with MERT (Och, 2003) towards the B LEU metric. 3.6 3.8 The UEDIN-LMU HPBT system is a hierarchical phrase-based machine translation system (Chiang, 2005) built jointly by the University of Edinburgh and LMU Munich. The system is based on the open source Moses implementation of the hierarchical phrase-based paradigm (Hoang et al., 2009). In addition to a set of standard features in a log-linear combination, a number of non-standard enhancements are employed to achieve improved translation quality. Specifically, we integrate individual language models trained over the separate corpora (News Crawl 2015, Europarl, SE"
W16-2320,D14-1003,1,0.932306,"with the KenLM toolkit (Heafield et al., 2013) and are integrated into the decoder as separate models in the log-linear combination: a full 4-gram LM (trained on all data), a limited 5-gram LM (trained only on in-domain data), and a 7-gram word class language model (wcLM) (Wuebker et al., 2013) trained on all data and with a output vocabulary of 143K words. The system produces 1000-best lists which are reranked using a LSTM-based (Hochreiter and Schmidhuber, 1997; Gers et al., 2000; Gers et al., 2003) language model (Sundermeyer et al., 2012) and a LSTM-based bidirectional joined model (BJM) (Sundermeyer et al., 2014a). The models have a class-factored output layer (Goodman, 2001; Morin and Bengio, 2005) to speed up training and evaluation. The language model uses 3 stacked LSTM layers, with 350 nodes each. The BJM has a projection layer, and computes a forLMU The LMU system integrates a discriminative rule selection model into a hierarchical SMT system, as described in (Tamchyna et al., 2014). The rule selection model is implemented using the highspeed classifier Vowpal Wabbit2 which is fully integrated in Moses’ hierarchical decoder. During decoding, the rule selection model is called at each rule appli"
W16-2320,P06-1055,0,0.0121776,"anslation Systems Each group contributed one or more systems. In this section the systems are presented in alphabetic order. 3.1 LIMSI KIT The KIT system consists of a phrase-based machine translation system using additional models in rescoring. The phrase-based system is trained on all available parallel training data. The phrase 345 more specifically its implementation in XenC (Rousseau, 2013). As a result, one third of the initial corpus is removed. Finally, we make a linear interpolation of these models, using the SRILM toolkit (Stolcke, 2002). 3.3 training data using the Berkeley parser (Petrov et al., 2006). For model prediction during tuning and decoding, we use parsed versions of the development and test sets. We train the rule selection model using VW and tune the weights of the translation model using batch MIRA (Cherry and Foster, 2012). The 5-gram language model is trained using KenLM (Heafield et al., 2013) on the Romanian part of the Common Crawl corpus concatenated with the Romanian part of the training data. LMU-CUNI The LMU-CUNI contribution is a constrained Moses phrase-based system. It uses a simple factored setting: our phrase table produces not only the target surface form but als"
W16-2320,2007.tmi-papers.21,0,0.0230136,"n 2. Section 3 covers the characteristics of the different individual engines, followed by a brief overview of our system combination approach (Section 4). We then summarize our empirical results in Section 5, showing that we achieve better translation quality than with any individual engine. Finally, in Section 6, we provide a statistical analysis of certain linguistic phenomena, specifically the prediction precision on morphological attributes. We conclude the paper with Section 7. table is adapted to the SETimes2 corpus (Niehues and Waibel, 2012). The system uses a prereordering technique (Rottmann and Vogel, 2007) in combination with lexical reordering. It uses two word-based n-gram language models and three additional non-word language models. Two of them are automatic word class-based (Och, 1999) language models, using 100 and 1,000 word classes. In addition, we use a POS-based language model. During decoding, we use a discriminative word lexicon (Niehues and Waibel, 2013) as well. We rescore the system output using a 300-best list. The weights are optimized on the concatenation of the development data and the SETimes2 dev set using the ListNet algorithm (Niehues et al., 2015). In rescoring, we add t"
W16-2320,P16-1161,1,0.729045,"omanian part of the training data. LMU-CUNI The LMU-CUNI contribution is a constrained Moses phrase-based system. It uses a simple factored setting: our phrase table produces not only the target surface form but also its lemma and morphological tag. On the input, we include lemmas, POS tags and information from dependency parses (lemma of the parent node and syntactic relation), all encoded as additional factors. The main difference from a standard phrasebased setup is the addition of a feature-rich discriminative translation model which is conditioned on both source- and target-side context (Tamchyna et al., 2016). The motivation for using this model is to better condition lexical choices by using the source context and to improve morphological and topical coherence by modeling the (limited left-hand side) target context. We also take advantage of the target factors by using a 7-gram language model trained on sequences of Romanian morphological tags. Finally, our system also uses a standard lexicalized reordering model. 3.4 3.5 RWTH Aachen University: Hierarchical Phrase-based System The RWTH hierarchical setup uses the open source translation toolkit Jane 2.3 (Vilar et al., 2010). Hierarchical phrase-"
W16-2320,tufis-etal-2008-racais,0,0.107217,"Missing"
W16-2320,P16-1009,1,0.78198,"and models are tuned with k-best MIRA (Cherry and Foster, 2012) on first the half of newsdev2016. In decoding, we use MBR (Kumar and Byrne, 2004), cube-pruning (Huang and Chiang, 2007) with a pop-limit of 5000, and the Moses ”monotone at punctuation” switch (to prevent reordering across punctuation) (Koehn and Haddow, 2009). Edinburgh Neural System Edinburgh’s neural machine translation system is an attentional encoder-decoder (Bahdanau et al., 2015), which we train with nematus.3 We use byte-pair-encoding (BPE) to achieve openvocabulary translation with a fixed vocabulary of subword symbols (Sennrich et al., 2016c). We produce additional parallel training data by automatically translating the monolingual Romanian News Crawl 2015 corpus into English (Sennrich et al., 2016b), which we combine with the original parallel data in a 1-to-1 ratio. We use minibatches of size 80, a maximum sentence length of 50, word embeddings of size 500, and hidden layers of size 1024. We apply dropout to all layers (Gal, 2015), with dropout probability 0.2, and also drop out full words with probability 0.1. We clip the gradient norm to 1.0 (Pascanu et al., 2013). We train the models with Adadelta (Zeiler, 2012), reshufflin"
W16-2320,P12-3008,0,0.0597108,"Missing"
W16-2320,P16-1162,1,0.259658,"and models are tuned with k-best MIRA (Cherry and Foster, 2012) on first the half of newsdev2016. In decoding, we use MBR (Kumar and Byrne, 2004), cube-pruning (Huang and Chiang, 2007) with a pop-limit of 5000, and the Moses ”monotone at punctuation” switch (to prevent reordering across punctuation) (Koehn and Haddow, 2009). Edinburgh Neural System Edinburgh’s neural machine translation system is an attentional encoder-decoder (Bahdanau et al., 2015), which we train with nematus.3 We use byte-pair-encoding (BPE) to achieve openvocabulary translation with a fixed vocabulary of subword symbols (Sennrich et al., 2016c). We produce additional parallel training data by automatically translating the monolingual Romanian News Crawl 2015 corpus into English (Sennrich et al., 2016b), which we combine with the original parallel data in a 1-to-1 ratio. We use minibatches of size 80, a maximum sentence length of 50, word embeddings of size 500, and hidden layers of size 1024. We apply dropout to all layers (Gal, 2015), with dropout probability 0.2, and also drop out full words with probability 0.1. We clip the gradient norm to 1.0 (Pascanu et al., 2013). We train the models with Adadelta (Zeiler, 2012), reshufflin"
W16-2320,W10-1738,1,0.885055,"rget-side context (Tamchyna et al., 2016). The motivation for using this model is to better condition lexical choices by using the source context and to improve morphological and topical coherence by modeling the (limited left-hand side) target context. We also take advantage of the target factors by using a 7-gram language model trained on sequences of Romanian morphological tags. Finally, our system also uses a standard lexicalized reordering model. 3.4 3.5 RWTH Aachen University: Hierarchical Phrase-based System The RWTH hierarchical setup uses the open source translation toolkit Jane 2.3 (Vilar et al., 2010). Hierarchical phrase-based translation (HPBT) (Chiang, 2007) induces a weighted synchronous context-free grammar from parallel text. In addition to the contiguous lexical phrases, as used in phrase-based translation (PBT), hierarchical phrases with up to two gaps are also extracted. Our baseline model contains models with phrase translation probabilities and lexical smoothing probabilities in both translation directions, word and phrase penalty, and enhanced low frequency features (Chen et al., 2011). It also contains binary features to distinguish between hierarchical and non-hierarchical ph"
W16-2320,P15-4020,1,0.815128,"data for the translation model. A single 5-gram language model is built using all the target side of the parallel data and a subpart of the monolingual Romanian corpora selected with Xenc-v2 (Rousseau, 2013). For the latter we use all the parallel data as in-domain data and the first half of newsdev2016 as development set. The feature weights are tuned with MERT (Och, 2003) on the first half of newsdev2016. The system produces distinct 1000-best lists, for which we extend the feature set with the 17 baseline black-box features from sentencelevel Quality Estimation (QE) produced with Quest++4 (Specia et al., 2015). The 1000-best lists are then reranked and the top-best hypothesis extracted using the nbest rescorer available within the Moses toolkit. 3.12 UvA We use a phrase-based machine translation system (Moses) with a distortion limit of 6 and lexicalized reordering. Before translation, the English source side is preordered using the neural preordering model of (de Gispert et al., 2015). The preordering model is trained for 30 iterations on the full MGIZA-aligned training data. We use two language models, built using KenLM. The first is a 5-gram language model trained on all available data. Words in"
W16-2320,W16-2327,1,0.84726,"Missing"
W16-2320,D13-1138,1,0.859072,"(Chen et al., 2011). It also contains binary features to distinguish between hierarchical and non-hierarchical phrases, the glue rule, and rules with non-terminals at the boundaries. We use the cube pruning algorithm (Huang and Chiang, 2007) for decoding. The system uses three backoff language models (LM) that are estimated with the KenLM toolkit (Heafield et al., 2013) and are integrated into the decoder as separate models in the log-linear combination: a full 4-gram LM (trained on all data), a limited 5-gram LM (trained only on in-domain data), and a 7-gram word class language model (wcLM) (Wuebker et al., 2013) trained on all data and with a output vocabulary of 143K words. The system produces 1000-best lists which are reranked using a LSTM-based (Hochreiter and Schmidhuber, 1997; Gers et al., 2000; Gers et al., 2003) language model (Sundermeyer et al., 2012) and a LSTM-based bidirectional joined model (BJM) (Sundermeyer et al., 2014a). The models have a class-factored output layer (Goodman, 2001; Morin and Bengio, 2005) to speed up training and evaluation. The language model uses 3 stacked LSTM layers, with 350 nodes each. The BJM has a projection layer, and computes a forLMU The LMU system integra"
W16-2320,2002.tmi-tutorials.2,0,0.0608664,"omanian side, the data is tokenized using LIMSI’s tokro (Allauzen et al., 2016), a rulebased tokenizer that mainly normalizes diacritics and splits punctuation and clitics. This data is truecased in the same way as the English side. In addition, the Romanian sentences are also tagged, lemmatized, and chunked using the TTL tagger (Tufis¸ et al., 2008). 3 The LIMSI system uses NCODE (Crego et al., 2011), which implements the bilingual n-gram approach to SMT (Casacuberta and Vidal, 2004; Crego and Mari˜no, 2006; Mari˜no et al., 2006) that is closely related to the standard phrase-based approach (Zens et al., 2002). In this framework, translation is divided into two steps. To translate a source sentence into a target sentence, the source sentence is first reordered according to a set of rewriting rules so as to reproduce the target word order. This generates a word lattice containing the most promising source permutations, which is then translated. Since the translation step is monotonic, this approach is able to rely on the n-gram assumption to decompose the joint probability of a sentence pair into a sequence of bilingual units called tuples. We train three Romanian 4-gram language models, pruning all"
W16-2327,J07-2003,0,0.787531,"dual monolingual corpora, we first used lmplz (Heafield et al., 2013) to train count-based 5-gram language models with modified Kneser-Ney smoothing (Chen and Goodman, 1998). We then used the SRILM toolkit (Stolcke, 2002) to linearly interpolate the models http://ufal.mff.cuni.cz/treex 399 Proceedings of the First Conference on Machine Translation, Volume 2: Shared Task Papers, pages 399–410, c Berlin, Germany, August 11-12, 2016. 2016 Association for Computational Linguistics 2.6 using weights tuned to minimize perplexity on the development set. In decoding we applied cube pruning (Huang and Chiang, 2007) with a stack size of 5000 (reduced to 1000 for tuning), Minimum Bayes Risk decoding (Kumar and Byrne, 2004), a maximum phrase length of 5, a distortion limit of 6, 100best translation options and the no-reorderingover-punctuation heuristic (Koehn and Haddow, 2009). CommonCrawl LMs Our CommonCrawl language models were trained in the same way as the individual corpus-specific standard models, but were not linearly-interpolated with other LMs. Instead, the log probabilities of CommonCrawl LMs were added as separate features of the systems’ linear models. 3 Neural LMs For some of our phrase-based"
W16-2327,P11-2072,0,0.0157943,"ubject to restrictions on the size of the resulting tree fragment. We used the settings shown in Table 4, which were chosen empirically during the development of 2013’s systems (Nadejde et al., 2013). parameter rule depth node count rule size Syntax-based System Overview For all syntax-based systems, we used a string-totree model based on a synchronous context-free grammar (SCFG) with linguistically-motivated labels on the target side. 4.1 Preprocessing binarized 7 30 7 Further to the restrictions on rule composition, fully non-lexical unary rules were eliminated using the method described in Chung et al. (2011) and rules with scope greater than 3 (Hopkins and Langmead, 2010) were pruned from the translation grammar. Scope pruning makes parsing tractable without the need for grammar binarization. 4.5 Word Alignment Baseline Features Our core set of string-to-tree feature functions is unchanged from previous years. It includes the ngram language model’s log probability for the target string, the target word count, the rule count, and several pre-computed rule-specific scores. The rule-specific scores were: the direct and indirect translation probabilities; the direct and indirect lexical weights (Koeh"
W16-2327,P05-1066,0,0.077238,"s representing the decoding search space) on a concatenation of newssyscomb2009 and newstest2008–2012. BLEU 26.8 26.2 25.6 26.4 26.6 26.5 3.5 Table 2: Effect of each of the language models used in the English→Romanian system. The experiments are not cumulative, so we first try pruning the “all” language model, then go back to the unpruned version and remove each LM in turn, observing the effect. The submitted system used all four LMs, and the scores shown are uncased B LEU scores on newstest2016. 3.4 German→English For phrase-based translation from German, we applied syntactic pre-reordering (Collins et al., 2005) and compound splitting (Koehn and Knight, 2003) in a preprocessing step on the source side. The operation sequence model for the German→English phrase-based system was unpruned. We integrated three language models: an unpruned LM over all English data except the CommonCrawl monolingual corpus; a pruned LM over CommonCrawl; and a pruned LM over the monolingual News Crawl 2015 corpus. In addition to lexical smoothing with the standard lexicon models, we utilized a source-to-target IBM Model 1 (Brown et al., 1993) for sentence-level lexical scoring in a similar manner as described by Huck et al."
W16-2327,P14-1129,0,0.035129,"on limit of 6, 100best translation options and the no-reorderingover-punctuation heuristic (Koehn and Haddow, 2009). CommonCrawl LMs Our CommonCrawl language models were trained in the same way as the individual corpus-specific standard models, but were not linearly-interpolated with other LMs. Instead, the log probabilities of CommonCrawl LMs were added as separate features of the systems’ linear models. 3 Neural LMs For some of our phrase-based systems we experimented with feed-forward neural network language models, both trained on target n-grams only, and on “joint” or “bilingual” ngrams (Devlin et al., 2014; Le et al., 2012). For training these models we used the NPLM toolkit (Vaswani et al., 2013), for which we have now implemented gradient clipping to address numerical issues often encountered during training. 2.4 3.1 Phrase-based Experiments Finnish→English Similar to last year (Haddow et al., 2015), we built an unconstrained system for Finnish→English using data extracted from OPUS (Tiedemann, 2012). Our parallel training set was the same as we used previously, but the language model training set was extended with the addition of the news2015 monolingual corpus and the large WMT16 English Co"
W16-2327,P13-2071,0,0.020975,"a weighted linear combination of features. The core features of our model are a 5-gram LM score (i.e. log probability), phrase translation and lexical translation scores, word and phrase penalties, and a linear distortion score. The phrase translation probabilities are smoothed with Good-Turing smoothing (Foster et al., 2006). We used the hierarchical lexicalized reordering model (Galley and Manning, 2008) with 4 possible orientations (monotone, swap, discontinuous left and discontinuous right) in both left-to-right and right-to-left direction. We also used the operation sequence model (OSM) (Durrani et al., 2013) with 4 count based supportive features. We further employed domain indicator features (marking which training corpus each phrase pair was found in), binary phrase count indicator features, sparse phrase length features, and sparse source word deletion, target word insertion, and word translation features (limited to the top K words in each language, typically with K = 50). 2.5 Decoding Tuning Since our feature set (generally around 500 to 1000 features) was too large for MERT, we used k-best batch MIRA for tuning (Cherry and Foster, 2012). To speed up tuning we applied threshold pruning to th"
W16-2327,J93-2003,0,0.052624,"Missing"
W16-2327,D14-1082,0,0.163978,"ram Neural Network language model (NPLM) (Vaswani et al., 2013), a relational dependency language model (RDLM) (Sennrich, 2015), and soft source-syntactic constraints (Huck et al., 2014). The parameters of the model are tuned towards the linear interpolation of B LEU and the syntactic metric HWCM (Liu and Gildea, 2005; Sennrich, 2015). Trees are transformed through binarization and a hierarchical representation of morphologically complex words (Sennrich and Haddow, 2015). For the soft source-syntactic constraints, we annotate the source text with the Stanford Neural Network dependency parser (Chen and Manning, 2014), along with heuristic projectivization (Nivre and Nilsson, 2005). Results are shown in Table 8. We report results of last year’s system (Williams et al., 2015), which was ranked (joint) first at WMT 15. Our improvements this year stem from particle verb restructuring (Sennrich and Haddow, 2015), and the use of the new monolingual News Crawl 2015 corpus for In 4 cases, the system with constraints delivered much better translation, and three of those were overall improvement of the sentence structure. In 41 cases, the area was better for various reasons. Most frequently (16 cases), this was ind"
W16-2327,N13-1073,0,0.099487,"Missing"
W16-2327,N12-1047,0,0.356006,"rection. We also used the operation sequence model (OSM) (Durrani et al., 2013) with 4 count based supportive features. We further employed domain indicator features (marking which training corpus each phrase pair was found in), binary phrase count indicator features, sparse phrase length features, and sparse source word deletion, target word insertion, and word translation features (limited to the top K words in each language, typically with K = 50). 2.5 Decoding Tuning Since our feature set (generally around 500 to 1000 features) was too large for MERT, we used k-best batch MIRA for tuning (Cherry and Foster, 2012). To speed up tuning we applied threshold pruning to the phrase table, based on the direct translation model probability. 400 are quite understandable, e.g. source yös Intian on sanottu olevan kiinnostunut puolustusyhteistyösopimuksesta Japanin kanssa. base India is also said to be interested in puolustusyhteistyösopimuksesta with Japan. bpe India is also said to be interested in defence cooperation agreement with Japan. reference India is also reportedly hoping for a deal on defence collaboration between the two nations. However applying BPE to Finnish can also result in some rather odd trans"
W16-2327,W06-1607,0,0.0250361,"ts here, we used 100,000 BPE merges to create the model. Applying BPE to Finnish→English was clearly effective at addressing the unknown word problem, and in many cases the resulting translations Baseline Features We follow the standard approach to SMT of scoring translation hypotheses using a weighted linear combination of features. The core features of our model are a 5-gram LM score (i.e. log probability), phrase translation and lexical translation scores, word and phrase penalties, and a linear distortion score. The phrase translation probabilities are smoothed with Good-Turing smoothing (Foster et al., 2006). We used the hierarchical lexicalized reordering model (Galley and Manning, 2008) with 4 possible orientations (monotone, swap, discontinuous left and discontinuous right) in both left-to-right and right-to-left direction. We also used the operation sequence model (OSM) (Durrani et al., 2013) with 4 count based supportive features. We further employed domain indicator features (marking which training corpus each phrase pair was found in), binary phrase count indicator features, sparse phrase length features, and sparse source word deletion, target word insertion, and word translation features"
W16-2327,D10-1063,0,0.0144921,"fragment. We used the settings shown in Table 4, which were chosen empirically during the development of 2013’s systems (Nadejde et al., 2013). parameter rule depth node count rule size Syntax-based System Overview For all syntax-based systems, we used a string-totree model based on a synchronous context-free grammar (SCFG) with linguistically-motivated labels on the target side. 4.1 Preprocessing binarized 7 30 7 Further to the restrictions on rule composition, fully non-lexical unary rules were eliminated using the method described in Chung et al. (2011) and rules with scope greater than 3 (Hopkins and Langmead, 2010) were pruned from the translation grammar. Scope pruning makes parsing tractable without the need for grammar binarization. 4.5 Word Alignment Baseline Features Our core set of string-to-tree feature functions is unchanged from previous years. It includes the ngram language model’s log probability for the target string, the target word count, the rule count, and several pre-computed rule-specific scores. The rule-specific scores were: the direct and indirect translation probabilities; the direct and indirect lexical weights (Koehn et al., 2003); the monolingual PCFG probability of the tree fra"
W16-2327,P07-1019,0,0.0831252,"For individual monolingual corpora, we first used lmplz (Heafield et al., 2013) to train count-based 5-gram language models with modified Kneser-Ney smoothing (Chen and Goodman, 1998). We then used the SRILM toolkit (Stolcke, 2002) to linearly interpolate the models http://ufal.mff.cuni.cz/treex 399 Proceedings of the First Conference on Machine Translation, Volume 2: Shared Task Papers, pages 399–410, c Berlin, Germany, August 11-12, 2016. 2016 Association for Computational Linguistics 2.6 using weights tuned to minimize perplexity on the development set. In decoding we applied cube pruning (Huang and Chiang, 2007) with a stack size of 5000 (reduced to 1000 for tuning), Minimum Bayes Risk decoding (Kumar and Byrne, 2004), a maximum phrase length of 5, a distortion limit of 6, 100best translation options and the no-reorderingover-punctuation heuristic (Koehn and Haddow, 2009). CommonCrawl LMs Our CommonCrawl language models were trained in the same way as the individual corpus-specific standard models, but were not linearly-interpolated with other LMs. Instead, the log probabilities of CommonCrawl LMs were added as separate features of the systems’ linear models. 3 Neural LMs For some of our phrase-based"
W16-2327,P06-1121,0,0.0809512,"Missing"
W16-2327,2015.iwslt-evaluation.4,1,0.850731,"ms are given in Table 3. English→German For the English→German phrase-based system, we exploited several translation factors in addition to word surface forms, in particular: Och clusters (with 50 classes) and part-of-speech tags (Ratnaparkhi, 1996) on the English side, as well as Och clusters (50 classes), morphological tags, and part-of-speech tags on the German side (Schmid, 2000). Recent experiments for our IWSLT 2015 phrase-based system have reconfirmed that English→German translation quality can benefit from these factors when supplementary models over factored representations are used (Huck and Birch, 2015). For WMT16, we utilized the factors in the translation model, in operation sequence models, and in language models (for linearly interpolated 7-gram LMs over Och clusters and morphological tags). Sparse source word deletion, target word insertion, and word translation features were integrated over the top 200 word surface forms and over selected factors (source and target Och clusters, source part-of-speech tags and target morphological tags). An unpruned 5-gram LM over words that was trained on all German data except the CommonCrawl monolingual corpus was supplemented by a separate pruned LM"
W16-2327,N04-1035,0,0.0743322,"pus was made up of three parts: all the English monolingual medical data from WMT14 medical, WMT16 biomedical and EMEA (11M sentences); all the English LDC GigaWord data (180M sentences); and all the English general domain data from WMT16 (240M sentences). We used the monolingual data to build three different language models which were then linearly interpolated. System tuning was with the SCIELO development data provided for the biomedical task. 4 4.4 SCFG rules were extracted from the word-aligned parallel data using the Moses implementation (Williams and Koehn, 2012) of the GHKM algorithm (Galley et al., 2004, 2006). Minimal GHKM rules were composed into larger rules subject to restrictions on the size of the resulting tree fragment. We used the settings shown in Table 4, which were chosen empirically during the development of 2013’s systems (Nadejde et al., 2013). parameter rule depth node count rule size Syntax-based System Overview For all syntax-based systems, we used a string-totree model based on a synchronous context-free grammar (SCFG) with linguistically-motivated labels on the target side. 4.1 Preprocessing binarized 7 30 7 Further to the restrictions on rule composition, fully non-lexic"
W16-2327,W14-4018,1,0.849099,"s, improving overall sentence structure on average. Crazy Reordering 3 Table 7: Manual evaluation of translations as proposed by the English→Czech system with unification constraints vs. the same system without constraints. 5.2 English→German This year’s string-to-tree submission for English→German is similar to last year’s system (Williams et al., 2015). In addition to the baseline feature functions, it contains count-based 5-gram Neural Network language model (NPLM) (Vaswani et al., 2013), a relational dependency language model (RDLM) (Sennrich, 2015), and soft source-syntactic constraints (Huck et al., 2014). The parameters of the model are tuned towards the linear interpolation of B LEU and the syntactic metric HWCM (Liu and Gildea, 2005; Sennrich, 2015). Trees are transformed through binarization and a hierarchical representation of morphologically complex words (Sennrich and Haddow, 2015). For the soft source-syntactic constraints, we annotate the source text with the Stanford Neural Network dependency parser (Chen and Manning, 2014), along with heuristic projectivization (Nivre and Nilsson, 2005). Results are shown in Table 8. We report results of last year’s system (Williams et al., 2015), w"
W16-2327,D08-1089,0,0.179545,"Missing"
W16-2327,W08-0509,0,0.143531,"Missing"
W16-2327,2011.iwslt-papers.1,1,0.855699,"al., 2005) and compound splitting (Koehn and Knight, 2003) in a preprocessing step on the source side. The operation sequence model for the German→English phrase-based system was unpruned. We integrated three language models: an unpruned LM over all English data except the CommonCrawl monolingual corpus; a pruned LM over CommonCrawl; and a pruned LM over the monolingual News Crawl 2015 corpus. In addition to lexical smoothing with the standard lexicon models, we utilized a source-to-target IBM Model 1 (Brown et al., 1993) for sentence-level lexical scoring in a similar manner as described by Huck et al. (2011) for hierarchical systems. We tuned on the concatenation of newssyscomb2009 and newstest2008–2012. Unlike last year’s system (Haddow et al., 2015)—and different from the inverse translation direction (English→German)—we refrained from using any factors and instead set up a system that operates over surface form word representations only. In relation to last year’s system, we were able to maintain high translation quality as measured in B LEU despite the abandonment of factors. However, we suspect that human judgment scores may suffer a bit from the abandonment of a factored model. We decided t"
W16-2327,N10-1129,0,0.0414698,"Missing"
W16-2327,W15-3013,1,0.881832,"Missing"
W16-2327,E03-1076,0,0.0923236,"concatenation of newssyscomb2009 and newstest2008–2012. BLEU 26.8 26.2 25.6 26.4 26.6 26.5 3.5 Table 2: Effect of each of the language models used in the English→Romanian system. The experiments are not cumulative, so we first try pruning the “all” language model, then go back to the unpruned version and remove each LM in turn, observing the effect. The submitted system used all four LMs, and the scores shown are uncased B LEU scores on newstest2016. 3.4 German→English For phrase-based translation from German, we applied syntactic pre-reordering (Collins et al., 2005) and compound splitting (Koehn and Knight, 2003) in a preprocessing step on the source side. The operation sequence model for the German→English phrase-based system was unpruned. We integrated three language models: an unpruned LM over all English data except the CommonCrawl monolingual corpus; a pruned LM over CommonCrawl; and a pruned LM over the monolingual News Crawl 2015 corpus. In addition to lexical smoothing with the standard lexicon models, we utilized a source-to-target IBM Model 1 (Brown et al., 1993) for sentence-level lexical scoring in a similar manner as described by Huck et al. (2011) for hierarchical systems. We tuned on th"
W16-2327,N03-1017,0,0.0439096,"011) and rules with scope greater than 3 (Hopkins and Langmead, 2010) were pruned from the translation grammar. Scope pruning makes parsing tractable without the need for grammar binarization. 4.5 Word Alignment Baseline Features Our core set of string-to-tree feature functions is unchanged from previous years. It includes the ngram language model’s log probability for the target string, the target word count, the rule count, and several pre-computed rule-specific scores. The rule-specific scores were: the direct and indirect translation probabilities; the direct and indirect lexical weights (Koehn et al., 2003); the monolingual PCFG probability of the tree fragment from which the rule was extracted; and a rule As in the phrase-based models, we used fast_align for word alignment and the grow-diag-final-and heuristic for symmetrization. 4.3 unbinarized 5 20 5 Table 4: Parameter settings for rule composition. The parameters were relaxed for systems that used binarization to allow for the increase in tree node density. Except for English-Czech, which we describe separately in Section 5.1, preprocessing was similar to the phrase-based systems (Section 2.3). To parse the target-side of the training data,"
W16-2327,N04-1022,0,0.115351,"anguage models with modified Kneser-Ney smoothing (Chen and Goodman, 1998). We then used the SRILM toolkit (Stolcke, 2002) to linearly interpolate the models http://ufal.mff.cuni.cz/treex 399 Proceedings of the First Conference on Machine Translation, Volume 2: Shared Task Papers, pages 399–410, c Berlin, Germany, August 11-12, 2016. 2016 Association for Computational Linguistics 2.6 using weights tuned to minimize perplexity on the development set. In decoding we applied cube pruning (Huang and Chiang, 2007) with a stack size of 5000 (reduced to 1000 for tuning), Minimum Bayes Risk decoding (Kumar and Byrne, 2004), a maximum phrase length of 5, a distortion limit of 6, 100best translation options and the no-reorderingover-punctuation heuristic (Koehn and Haddow, 2009). CommonCrawl LMs Our CommonCrawl language models were trained in the same way as the individual corpus-specific standard models, but were not linearly-interpolated with other LMs. Instead, the log probabilities of CommonCrawl LMs were added as separate features of the systems’ linear models. 3 Neural LMs For some of our phrase-based systems we experimented with feed-forward neural network language models, both trained on target n-grams on"
W16-2327,N12-1005,0,0.0147426,"t translation options and the no-reorderingover-punctuation heuristic (Koehn and Haddow, 2009). CommonCrawl LMs Our CommonCrawl language models were trained in the same way as the individual corpus-specific standard models, but were not linearly-interpolated with other LMs. Instead, the log probabilities of CommonCrawl LMs were added as separate features of the systems’ linear models. 3 Neural LMs For some of our phrase-based systems we experimented with feed-forward neural network language models, both trained on target n-grams only, and on “joint” or “bilingual” ngrams (Devlin et al., 2014; Le et al., 2012). For training these models we used the NPLM toolkit (Vaswani et al., 2013), for which we have now implemented gradient clipping to address numerical issues often encountered during training. 2.4 3.1 Phrase-based Experiments Finnish→English Similar to last year (Haddow et al., 2015), we built an unconstrained system for Finnish→English using data extracted from OPUS (Tiedemann, 2012). Our parallel training set was the same as we used previously, but the language model training set was extended with the addition of the news2015 monolingual corpus and the large WMT16 English CommonCrawl corpus."
W16-2327,W05-0904,0,0.0750355,"e English→Czech system with unification constraints vs. the same system without constraints. 5.2 English→German This year’s string-to-tree submission for English→German is similar to last year’s system (Williams et al., 2015). In addition to the baseline feature functions, it contains count-based 5-gram Neural Network language model (NPLM) (Vaswani et al., 2013), a relational dependency language model (RDLM) (Sennrich, 2015), and soft source-syntactic constraints (Huck et al., 2014). The parameters of the model are tuned towards the linear interpolation of B LEU and the syntactic metric HWCM (Liu and Gildea, 2005; Sennrich, 2015). Trees are transformed through binarization and a hierarchical representation of morphologically complex words (Sennrich and Haddow, 2015). For the soft source-syntactic constraints, we annotate the source text with the Stanford Neural Network dependency parser (Chen and Manning, 2014), along with heuristic projectivization (Nivre and Nilsson, 2005). Results are shown in Table 8. We report results of last year’s system (Williams et al., 2015), which was ranked (joint) first at WMT 15. Our improvements this year stem from particle verb restructuring (Sennrich and Haddow, 2015)"
W16-2327,H05-1066,0,0.0224782,"s. We used randomly-chosen subsets of the previous years’ test data to speed up decoding. 5 5.1 system baseline + constraints HimL1 23.3 23.6 B LEU HimL2 Khresmoi 18.6 20.4 18.8 20.7 Table 5: Translation results on the development system for English→Czech with unification-based constraints. Cased B LEU scores are shown. They are averaged over three tuning runs (note that baseline weights are reused in the experiments with constraints). Syntax-based Experiments English→Czech For English→Czech, we used Treex to preprocess and parse the Czech-side of the training data. Treex uses the MST parser (McDonald et al., 2005), which produces dependency graphs with non-projective arcs. In order to extract SCFG rules, we first applied the following conversion process: i) the dependency graphs were projectivized using the Malt Parser, which implements the method described in Nivre and Nilsson (2005) (we used the ‘Head’ encoding scheme); ii) the projective dependency graphs were converted to CFG trees. In addition, we reduced the complex positional tags to simple POS tags by discarding the morphological attributes. The CFG trees were not binarized. We also experimented with unificationbased agreement and case governme"
W16-2327,W13-2221,1,0.819391,"e used the monolingual data to build three different language models which were then linearly interpolated. System tuning was with the SCIELO development data provided for the biomedical task. 4 4.4 SCFG rules were extracted from the word-aligned parallel data using the Moses implementation (Williams and Koehn, 2012) of the GHKM algorithm (Galley et al., 2004, 2006). Minimal GHKM rules were composed into larger rules subject to restrictions on the size of the resulting tree fragment. We used the settings shown in Table 4, which were chosen empirically during the development of 2013’s systems (Nadejde et al., 2013). parameter rule depth node count rule size Syntax-based System Overview For all syntax-based systems, we used a string-totree model based on a synchronous context-free grammar (SCFG) with linguistically-motivated labels on the target side. 4.1 Preprocessing binarized 7 30 7 Further to the restrictions on rule composition, fully non-lexical unary rules were eliminated using the method described in Chung et al. (2011) and rules with scope greater than 3 (Hopkins and Langmead, 2010) were pruned from the translation grammar. Scope pruning makes parsing tractable without the need for grammar binar"
W16-2327,W14-4011,1,0.900492,"Missing"
W16-2327,P05-1013,0,0.487034,"ased constraints. Cased B LEU scores are shown. They are averaged over three tuning runs (note that baseline weights are reused in the experiments with constraints). Syntax-based Experiments English→Czech For English→Czech, we used Treex to preprocess and parse the Czech-side of the training data. Treex uses the MST parser (McDonald et al., 2005), which produces dependency graphs with non-projective arcs. In order to extract SCFG rules, we first applied the following conversion process: i) the dependency graphs were projectivized using the Malt Parser, which implements the method described in Nivre and Nilsson (2005) (we used the ‘Head’ encoding scheme); ii) the projective dependency graphs were converted to CFG trees. In addition, we reduced the complex positional tags to simple POS tags by discarding the morphological attributes. The CFG trees were not binarized. We also experimented with unificationbased agreement and case government constraints (Williams and Koehn, 2011; Williams, 2014). Specifically, our constraints were designed to enforce: i) case, gender, and number agreement between nouns and pre-nominal adjectival modifiers; ii) number and person agreement between subjects and verbs; iii) case a"
W16-2327,Q15-1013,1,0.838097,"hypothesis better in a surprisingly larger span of words, improving overall sentence structure on average. Crazy Reordering 3 Table 7: Manual evaluation of translations as proposed by the English→Czech system with unification constraints vs. the same system without constraints. 5.2 English→German This year’s string-to-tree submission for English→German is similar to last year’s system (Williams et al., 2015). In addition to the baseline feature functions, it contains count-based 5-gram Neural Network language model (NPLM) (Vaswani et al., 2013), a relational dependency language model (RDLM) (Sennrich, 2015), and soft source-syntactic constraints (Huck et al., 2014). The parameters of the model are tuned towards the linear interpolation of B LEU and the syntactic metric HWCM (Liu and Gildea, 2005; Sennrich, 2015). Trees are transformed through binarization and a hierarchical representation of morphologically complex words (Sennrich and Haddow, 2015). For the soft source-syntactic constraints, we annotate the source text with the Stanford Neural Network dependency parser (Chen and Manning, 2014), along with heuristic projectivization (Nivre and Nilsson, 2005). Results are shown in Table 8. We repo"
W16-2327,P03-1021,0,0.0414024,"translation task. We used two test sets from the HimL project and the Khresmoi test set. Results with and without constraints are shown in Table 5. We used hard constraints and reused the baseline weights (re-tuning did not appear to give additional gains). rareness penalty. 4.6 Decoding Decoding for the string-to-tree models is based on Sennrich’s (2014) recursive variant of the CYK+ parsing algorithm combined with LM integration via cube pruning (Chiang, 2007). 4.7 Tuning The feature weights for the English→Czech and Finnish→English systems were tuned using the Moses implementation of MERT (Och, 2003). For the remaining systems we used k-best MIRA (Cherry and Foster, 2012) due to the use of sparse features. We used randomly-chosen subsets of the previous years’ test data to speed up decoding. 5 5.1 system baseline + constraints HimL1 23.3 23.6 B LEU HimL2 Khresmoi 18.6 20.4 18.8 20.7 Table 5: Translation results on the development system for English→Czech with unification-based constraints. Cased B LEU scores are shown. They are averaged over three tuning runs (note that baseline weights are reused in the experiments with constraints). Syntax-based Experiments English→Czech For English→Cze"
W16-2327,D15-1248,1,0.87645,"for English→German is similar to last year’s system (Williams et al., 2015). In addition to the baseline feature functions, it contains count-based 5-gram Neural Network language model (NPLM) (Vaswani et al., 2013), a relational dependency language model (RDLM) (Sennrich, 2015), and soft source-syntactic constraints (Huck et al., 2014). The parameters of the model are tuned towards the linear interpolation of B LEU and the syntactic metric HWCM (Liu and Gildea, 2005; Sennrich, 2015). Trees are transformed through binarization and a hierarchical representation of morphologically complex words (Sennrich and Haddow, 2015). For the soft source-syntactic constraints, we annotate the source text with the Stanford Neural Network dependency parser (Chen and Manning, 2014), along with heuristic projectivization (Nivre and Nilsson, 2005). Results are shown in Table 8. We report results of last year’s system (Williams et al., 2015), which was ranked (joint) first at WMT 15. Our improvements this year stem from particle verb restructuring (Sennrich and Haddow, 2015), and the use of the new monolingual News Crawl 2015 corpus for In 4 cases, the system with constraints delivered much better translation, and three of thos"
W16-2327,P06-1055,0,0.0370971,"ility of the tree fragment from which the rule was extracted; and a rule As in the phrase-based models, we used fast_align for word alignment and the grow-diag-final-and heuristic for symmetrization. 4.3 unbinarized 5 20 5 Table 4: Parameter settings for rule composition. The parameters were relaxed for systems that used binarization to allow for the increase in tree node density. Except for English-Czech, which we describe separately in Section 5.1, preprocessing was similar to the phrase-based systems (Section 2.3). To parse the target-side of the training data, we used the Berkeley parser (Petrov et al., 2006; Petrov and Klein, 2007) for English, and the ParZu dependency parser (Sennrich et al., 2013) for German. Except where stated otherwise, we right-binarized the trees after parsing to increase rule coverage. 4.2 Rule Extraction Language Models As in the phrase-based systems (Section 2.3), we used linearly-interpolated language models as standard, with some systems adding Common403 In preliminary experiments we used a smaller training set, comprising 2 million sentence pairs sampled from OPUS and monolingual data from last year’s WMT translation task. We used two test sets from the HimL project"
W16-2327,P16-1162,1,0.597202,"rm any corpus filtering other than the standard Moses method, which removes sentence pairs with extreme length ratios, and sentences longer than 80 tokens. Introduction Edinburgh’s submissions to the WMT 2016 news translation task fall into two distinct groups: neural translation systems and statistical translation systems. In this paper, we describe the statistical systems, which includes a mix of phrase-based and syntax-based approaches. We also include a brief description of our phrase-based submission to the WMT16 biomedical translation task. Our neural systems are described separately in Sennrich et al. (2016a). In most cases, our statistical systems build on last year’s, incorporating recent modelling refinements and adding this year’s new training data. For Romanian—a new language this year—we paid particular attention to language-specific processing of diacritics. For English→Czech, we experimented with a string-to-tree system, first using Treex1 (formerly TectoMT; Popel and Žabokrtský, 2010) to produce Czech dependency parses, then converting them to constituency representation and extracting GHKM rules. In the next two sections, we describe the phrasebased systems, first describing the core s"
W16-2327,W11-2126,1,0.846339,"dependency graphs with non-projective arcs. In order to extract SCFG rules, we first applied the following conversion process: i) the dependency graphs were projectivized using the Malt Parser, which implements the method described in Nivre and Nilsson (2005) (we used the ‘Head’ encoding scheme); ii) the projective dependency graphs were converted to CFG trees. In addition, we reduced the complex positional tags to simple POS tags by discarding the morphological attributes. The CFG trees were not binarized. We also experimented with unificationbased agreement and case government constraints (Williams and Koehn, 2011; Williams, 2014). Specifically, our constraints were designed to enforce: i) case, gender, and number agreement between nouns and pre-nominal adjectival modifiers; ii) number and person agreement between subjects and verbs; iii) case agreement between prepositions and nouns; iv) use of nominative case for subject nouns. For every Czech word in the training data, we obtained a set of morphological analyses using MorphoDiTa (Straková et al., 2014). From these analyses, we constructed a lexicon of feature structures. For constraint extraction, we used handwritten rules along the lines of those d"
W16-2327,R13-1079,1,0.855359,"ased models, we used fast_align for word alignment and the grow-diag-final-and heuristic for symmetrization. 4.3 unbinarized 5 20 5 Table 4: Parameter settings for rule composition. The parameters were relaxed for systems that used binarization to allow for the increase in tree node density. Except for English-Czech, which we describe separately in Section 5.1, preprocessing was similar to the phrase-based systems (Section 2.3). To parse the target-side of the training data, we used the Berkeley parser (Petrov et al., 2006; Petrov and Klein, 2007) for English, and the ParZu dependency parser (Sennrich et al., 2013) for German. Except where stated otherwise, we right-binarized the trees after parsing to increase rule coverage. 4.2 Rule Extraction Language Models As in the phrase-based systems (Section 2.3), we used linearly-interpolated language models as standard, with some systems adding Common403 In preliminary experiments we used a smaller training set, comprising 2 million sentence pairs sampled from OPUS and monolingual data from last year’s WMT translation task. We used two test sets from the HimL project and the Khresmoi test set. Results with and without constraints are shown in Table 5. We used"
W16-2327,W12-3150,1,0.844228,"M sentences of parallel data. Our monolingual corpus was made up of three parts: all the English monolingual medical data from WMT14 medical, WMT16 biomedical and EMEA (11M sentences); all the English LDC GigaWord data (180M sentences); and all the English general domain data from WMT16 (240M sentences). We used the monolingual data to build three different language models which were then linearly interpolated. System tuning was with the SCIELO development data provided for the biomedical task. 4 4.4 SCFG rules were extracted from the word-aligned parallel data using the Moses implementation (Williams and Koehn, 2012) of the GHKM algorithm (Galley et al., 2004, 2006). Minimal GHKM rules were composed into larger rules subject to restrictions on the size of the resulting tree fragment. We used the settings shown in Table 4, which were chosen empirically during the development of 2013’s systems (Nadejde et al., 2013). parameter rule depth node count rule size Syntax-based System Overview For all syntax-based systems, we used a string-totree model based on a synchronous context-free grammar (SCFG) with linguistically-motivated labels on the target side. 4.1 Preprocessing binarized 7 30 7 Further to the restri"
W16-2327,W14-3324,1,0.800794,"Missing"
W16-2327,W15-3024,1,0.879589,"rder. Since the hard unification constraints effectively only avoid some of the possible translations (i.e. reduce the search space), we conclude that having to obey mere agreement constraints helps to select a hypothesis better in a surprisingly larger span of words, improving overall sentence structure on average. Crazy Reordering 3 Table 7: Manual evaluation of translations as proposed by the English→Czech system with unification constraints vs. the same system without constraints. 5.2 English→German This year’s string-to-tree submission for English→German is similar to last year’s system (Williams et al., 2015). In addition to the baseline feature functions, it contains count-based 5-gram Neural Network language model (NPLM) (Vaswani et al., 2013), a relational dependency language model (RDLM) (Sennrich, 2015), and soft source-syntactic constraints (Huck et al., 2014). The parameters of the model are tuned towards the linear interpolation of B LEU and the syntactic metric HWCM (Liu and Gildea, 2005; Sennrich, 2015). Trees are transformed through binarization and a hierarchical representation of morphologically complex words (Sennrich and Haddow, 2015). For the soft source-syntactic constraints, we a"
W16-2327,P14-5003,0,0.0285107,"Missing"
W16-2327,tiedemann-2012-parallel,0,0.108338,". 3 Neural LMs For some of our phrase-based systems we experimented with feed-forward neural network language models, both trained on target n-grams only, and on “joint” or “bilingual” ngrams (Devlin et al., 2014; Le et al., 2012). For training these models we used the NPLM toolkit (Vaswani et al., 2013), for which we have now implemented gradient clipping to address numerical issues often encountered during training. 2.4 3.1 Phrase-based Experiments Finnish→English Similar to last year (Haddow et al., 2015), we built an unconstrained system for Finnish→English using data extracted from OPUS (Tiedemann, 2012). Our parallel training set was the same as we used previously, but the language model training set was extended with the addition of the news2015 monolingual corpus and the large WMT16 English CommonCrawl corpus. We used newsdev2015 for tuning, and newsdev2015 for testing during system development. One clear problem that we noted with our submission from last year was the large number of OOVs, which were then copied directly into the English output. This is undoubtedly due to the agglutinative nature of Finnish, and probably was the cause of our system being poorly judged by human evaluators,"
W16-2327,D13-1140,0,0.194779,"(Koehn and Haddow, 2009). CommonCrawl LMs Our CommonCrawl language models were trained in the same way as the individual corpus-specific standard models, but were not linearly-interpolated with other LMs. Instead, the log probabilities of CommonCrawl LMs were added as separate features of the systems’ linear models. 3 Neural LMs For some of our phrase-based systems we experimented with feed-forward neural network language models, both trained on target n-grams only, and on “joint” or “bilingual” ngrams (Devlin et al., 2014; Le et al., 2012). For training these models we used the NPLM toolkit (Vaswani et al., 2013), for which we have now implemented gradient clipping to address numerical issues often encountered during training. 2.4 3.1 Phrase-based Experiments Finnish→English Similar to last year (Haddow et al., 2015), we built an unconstrained system for Finnish→English using data extracted from OPUS (Tiedemann, 2012). Our parallel training set was the same as we used previously, but the language model training set was extended with the addition of the news2015 monolingual corpus and the large WMT16 English CommonCrawl corpus. We used newsdev2015 for tuning, and newsdev2015 for testing during system d"
W16-2327,N07-1051,0,\N,Missing
W16-2327,W09-0429,1,\N,Missing
W16-2327,P05-1045,0,\N,Missing
W16-2327,P13-2121,0,\N,Missing
W17-4706,E17-2059,1,0.80988,"Missing"
W17-4706,2005.mtsummit-papers.11,0,0.172732,"Missing"
W17-4706,W10-1705,0,0.0891085,"ask. We note that our system was ranked first in the human evaluation of the news task, despite having a lower B LEU score than Edinburgh’s submission. B LEU, which tries to automatically predict how humans will evaluate quality, may unfairly penalize approaches like ours, but more study is needed. 4 Related Work The SMT literature has a wide diversity of approaches in dealing with translation to morphologically rich languages. One common theme is modeling the relationship between lemmas and surface forms using morphological knowledge, e.g., (Toutanova and Suzuki, 2007; Koehn and Hoang, 2007; Bojar and Kos, 2010; Fraser et al., 2012; Weller et al., 2013; Tamchyna et al., 2016; Huck et al., 2017b). This problem has been studied for NMT by Tamchyna et al. (2017), and it would be interesting to compare with their approach. Our work is closer in spirit to previous work on integrating morphological segmentation into SMT. Some examples of early work here include work on Arabic (Lee et al., 2003) and Czech (Goldwater and McClosky, 2005). More recent work includes work on Arabic, such as (Habash, 2007), and work on Turkish (Oflazer and Durgar El-Kahlout, 2007; Yeniterzi and Oflazer, 2010). Unsupervised morph"
W17-4706,D07-1091,0,0.0240877,"the news translation task. We note that our system was ranked first in the human evaluation of the news task, despite having a lower B LEU score than Edinburgh’s submission. B LEU, which tries to automatically predict how humans will evaluate quality, may unfairly penalize approaches like ours, but more study is needed. 4 Related Work The SMT literature has a wide diversity of approaches in dealing with translation to morphologically rich languages. One common theme is modeling the relationship between lemmas and surface forms using morphological knowledge, e.g., (Toutanova and Suzuki, 2007; Koehn and Hoang, 2007; Bojar and Kos, 2010; Fraser et al., 2012; Weller et al., 2013; Tamchyna et al., 2016; Huck et al., 2017b). This problem has been studied for NMT by Tamchyna et al. (2017), and it would be interesting to compare with their approach. Our work is closer in spirit to previous work on integrating morphological segmentation into SMT. Some examples of early work here include work on Arabic (Lee et al., 2003) and Czech (Goldwater and McClosky, 2005). More recent work includes work on Arabic, such as (Habash, 2007), and work on Turkish (Oflazer and Durgar El-Kahlout, 2007; Yeniterzi and Oflazer, 2010"
W17-4706,P07-2045,0,0.00473,"5.9 60.9 60.7 60.3 60.0 59.8 59.8 59.9 25.2 25.6 25.5 26.0 25.8 25.9 25.5 60.9 60.9 60.6 60.1 60.2 60.6 60.3 phrase-based (Huck et al., 2015) 22.6 – 22.1 – Table 6: English→German experimental results on Europarl (case-sensitive B LEU and T ER). 3 3.1 Machine Translation Experiments Experimental Setup We conduct an empirical evaluation using encoder-decoder NMT with attention and gated recurrent units as implemented in Nematus (Sennrich et al., 2017). We train and test on English–German Europarl data (Koehn, 2005). The data is tokenized and frequent-cased using scripts from the Moses toolkit (Koehn et al., 2007). Sentences with length >50 after tokenization are excluded from the training corpus, all other sentences (1.7 M) are considered in training under every word segmentation scheme. We set the amount of merge operations for BPE to 50K. Corpus statistics of the German data after different preprocessings are given in Table 5. On the English source side, we apply BPE separately, also with 50K merge operations. For comparison, we build a setup denoted as top 50K voc. (source & target) where we train on the tokenized corpus without any segmentation, limiting the vocabulary to the 50K most frequent wor"
W17-4706,E14-1061,1,0.86134,"ng morphological segmentation into SMT. Some examples of early work here include work on Arabic (Lee et al., 2003) and Czech (Goldwater and McClosky, 2005). More recent work includes work on Arabic, such as (Habash, 2007), and work on Turkish (Oflazer and Durgar El-Kahlout, 2007; Yeniterzi and Oflazer, 2010). Unsupervised morphological splitting, using, e.g., Morfessor has also been tried, particularly for dealing with agglutinative languages (Virpioja et al., 2007). Our work is motivated by the same linguistic observations as theirs. Other studies, e.g., (Popovi´c et al., 2006; Stymne, 2008; Cap et al., 2014), model German compounds by splitting them into single simple words in the SMT training data, and then predicting where to merge simple words as a postprocessing step (after SMT decoding). This has similarities to our use of compound splitting and markers in NMT. 5 Conclusion Linguistically motivated target-side word segmentation improves neural machine translation into an inflected and compounding language. The system can learn linguistic word formation processes from the segmented data. For German, we have shown that cascading of suffix splitting—or suffix splitting and compound splitting—wi"
W17-4706,E12-1068,1,0.854517,"system was ranked first in the human evaluation of the news task, despite having a lower B LEU score than Edinburgh’s submission. B LEU, which tries to automatically predict how humans will evaluate quality, may unfairly penalize approaches like ours, but more study is needed. 4 Related Work The SMT literature has a wide diversity of approaches in dealing with translation to morphologically rich languages. One common theme is modeling the relationship between lemmas and surface forms using morphological knowledge, e.g., (Toutanova and Suzuki, 2007; Koehn and Hoang, 2007; Bojar and Kos, 2010; Fraser et al., 2012; Weller et al., 2013; Tamchyna et al., 2016; Huck et al., 2017b). This problem has been studied for NMT by Tamchyna et al. (2017), and it would be interesting to compare with their approach. Our work is closer in spirit to previous work on integrating morphological segmentation into SMT. Some examples of early work here include work on Arabic (Lee et al., 2003) and Czech (Goldwater and McClosky, 2005). More recent work includes work on Arabic, such as (Habash, 2007), and work on Turkish (Oflazer and Durgar El-Kahlout, 2007; Yeniterzi and Oflazer, 2010). Unsupervised morphological splitting, u"
W17-4706,E03-1076,0,0.269925,"rd. For these relationships our approach may be able to automatically and cheaply add (weak) POS information, which might improve translation quality, but this will require further investigation in future work. We would also like to study the relationship between stemming quality and resulting NMT translation quality. Weissweiler and Fraser (2017) have introduced a new stemmer of German and showed that it performs better than Snowball using comparison with gold standards. This may serve as an interesting starting point. BPE word segmentation operates bottom-up from characters to larger units. Koehn and Knight (2003) have proposed a frequency-based word segmentation method that starts from the other end, top-down inspecting full words and looking into whether they are composed of parts which are proper words themselves. Any composed word is segmented into parts such that the geometric mean of word frequencies of its parts (counted in the original corpus) is maximized. This technique represents a suitable approach for compound splitting in natural language processing applications. It has been successfully applied in numerous statistical machine translation systems, mostly on the source language side, but s"
W17-4706,H05-1085,0,0.0191425,"rich languages. One common theme is modeling the relationship between lemmas and surface forms using morphological knowledge, e.g., (Toutanova and Suzuki, 2007; Koehn and Hoang, 2007; Bojar and Kos, 2010; Fraser et al., 2012; Weller et al., 2013; Tamchyna et al., 2016; Huck et al., 2017b). This problem has been studied for NMT by Tamchyna et al. (2017), and it would be interesting to compare with their approach. Our work is closer in spirit to previous work on integrating morphological segmentation into SMT. Some examples of early work here include work on Arabic (Lee et al., 2003) and Czech (Goldwater and McClosky, 2005). More recent work includes work on Arabic, such as (Habash, 2007), and work on Turkish (Oflazer and Durgar El-Kahlout, 2007; Yeniterzi and Oflazer, 2010). Unsupervised morphological splitting, using, e.g., Morfessor has also been tried, particularly for dealing with agglutinative languages (Virpioja et al., 2007). Our work is motivated by the same linguistic observations as theirs. Other studies, e.g., (Popovi´c et al., 2006; Stymne, 2008; Cap et al., 2014), model German compounds by splitting them into single simple words in the SMT training data, and then predicting where to merge simple wo"
W17-4706,P16-1160,0,0.0307758,"4 There is also starting to be interest in alternatives to BPE in NMT. The Google NMT system (Wu et al., 2016) used wordpiece splitting, which is similar to but different from BPE and would be interesting to evaluate in future work. Ataman et al. (2017) considered both supervised and unsupervised splitting of agglutinative morphemes in Turkish, which is closely related to our ideas. An important difference here is that Turkish is an agglutinative language, while German has fusional inflection and very productive compounding. We are also excited about early work on character-based NMT such as (Lee et al., 2016), which may eventually replace segmentation models like those in our work (or also replace BPE when linguistically aware segmentation is not available). However, at the current stage of research character-based approaches require very long training times and extensive optimization of hyperparameters to make them work, and still do not seem to be able to produce state-of-theart translation quality on a wide range of tasks. More research is needed in making characterbased NMT robust and accessible to many research groups. tems have each learned to translate in different ways, based on the respec"
W17-4706,2007.mtsummit-papers.29,0,0.111134,"urface forms using morphological knowledge, e.g., (Toutanova and Suzuki, 2007; Koehn and Hoang, 2007; Bojar and Kos, 2010; Fraser et al., 2012; Weller et al., 2013; Tamchyna et al., 2016; Huck et al., 2017b). This problem has been studied for NMT by Tamchyna et al. (2017), and it would be interesting to compare with their approach. Our work is closer in spirit to previous work on integrating morphological segmentation into SMT. Some examples of early work here include work on Arabic (Lee et al., 2003) and Czech (Goldwater and McClosky, 2005). More recent work includes work on Arabic, such as (Habash, 2007), and work on Turkish (Oflazer and Durgar El-Kahlout, 2007; Yeniterzi and Oflazer, 2010). Unsupervised morphological splitting, using, e.g., Morfessor has also been tried, particularly for dealing with agglutinative languages (Virpioja et al., 2007). Our work is motivated by the same linguistic observations as theirs. Other studies, e.g., (Popovi´c et al., 2006; Stymne, 2008; Cap et al., 2014), model German compounds by splitting them into single simple words in the SMT training data, and then predicting where to merge simple words as a postprocessing step (after SMT decoding). This has simila"
W17-4706,P03-1051,0,0.0457279,"anslation to morphologically rich languages. One common theme is modeling the relationship between lemmas and surface forms using morphological knowledge, e.g., (Toutanova and Suzuki, 2007; Koehn and Hoang, 2007; Bojar and Kos, 2010; Fraser et al., 2012; Weller et al., 2013; Tamchyna et al., 2016; Huck et al., 2017b). This problem has been studied for NMT by Tamchyna et al. (2017), and it would be interesting to compare with their approach. Our work is closer in spirit to previous work on integrating morphological segmentation into SMT. Some examples of early work here include work on Arabic (Lee et al., 2003) and Czech (Goldwater and McClosky, 2005). More recent work includes work on Arabic, such as (Habash, 2007), and work on Turkish (Oflazer and Durgar El-Kahlout, 2007; Yeniterzi and Oflazer, 2010). Unsupervised morphological splitting, using, e.g., Morfessor has also been tried, particularly for dealing with agglutinative languages (Virpioja et al., 2007). Our work is motivated by the same linguistic observations as theirs. Other studies, e.g., (Popovi´c et al., 2006; Stymne, 2008; Cap et al., 2014), model German compounds by splitting them into single simple words in the SMT training data, and"
W17-4706,2015.mtsummit-papers.19,1,0.909261,"Missing"
W17-4706,W07-0704,0,0.0265695,"Missing"
W17-4706,W17-4730,1,0.835218,"parameters to make them work, and still do not seem to be able to produce state-of-theart translation quality on a wide range of tasks. More research is needed in making characterbased NMT robust and accessible to many research groups. tems have each learned to translate in different ways, based on the respective segmentation of the training data. Our cascaded suffix + compound + BPE target word segmentation strategy was employed for LMU Munich’s participation in the WMT17 shared tasks on machine translation of news and of biomedical texts. We refer the reader to the system description paper (Huck et al., 2017a), where we include some interesting translation examples from the news translation task. We note that our system was ranked first in the human evaluation of the news task, despite having a lower B LEU score than Edinburgh’s submission. B LEU, which tries to automatically predict how humans will evaluate quality, may unfairly penalize approaches like ours, but more study is needed. 4 Related Work The SMT literature has a wide diversity of approaches in dealing with translation to morphologically rich languages. One common theme is modeling the relationship between lemmas and surface forms usi"
W17-4706,P02-1040,0,0.102024,"ntences after tokenization but before segmentation, which affects all setups equally. No sentences are discarded after that stage (Nematus’ maxlen > longest sequence in data). We configure dimensions of 500 for the embeddings and 1024 for the hidden layer. We train with the Adam optimizer (Kingma and Ba, 2015), a learning rate of 0.0001, batch size of 50, and dropout with probability 0.2 applied to the hidden layer.3 We validate on the test2006 set after every 10 000 updates and do early stopping when the validation cost has not decreased for ten epochs. We evaluate case-sensitive with B LEU (Papineni et al., 2002) and T ER (Snover et al., 2006), computed over postprocessed hypotheses against the raw references with mteval-v13a and tercom.7.25, respectively. Table 5: Target-side training corpus statistics. System test2007 test2008 B LEU T ER B LEU T ER top 50K voc. (source & target) BPE compound + BPE suffix + BPE suffix + compound + BPE suffix + prefix + compound + BPE suffix + prefix + compound, 50K 25.5 25.8 25.9 26.3 26.2 26.1 25.9 60.9 60.7 60.3 60.0 59.8 59.8 59.9 25.2 25.6 25.5 26.0 25.8 25.9 25.5 60.9 60.9 60.6 60.1 60.2 60.6 60.3 phrase-based (Huck et al., 2015) 22.6 – 22.1 – Table 6: English→G"
W17-4706,W17-4704,1,0.854893,"Missing"
W17-4706,N07-1007,0,0.0165009,"ng translation examples from the news translation task. We note that our system was ranked first in the human evaluation of the news task, despite having a lower B LEU score than Edinburgh’s submission. B LEU, which tries to automatically predict how humans will evaluate quality, may unfairly penalize approaches like ours, but more study is needed. 4 Related Work The SMT literature has a wide diversity of approaches in dealing with translation to morphologically rich languages. One common theme is modeling the relationship between lemmas and surface forms using morphological knowledge, e.g., (Toutanova and Suzuki, 2007; Koehn and Hoang, 2007; Bojar and Kos, 2010; Fraser et al., 2012; Weller et al., 2013; Tamchyna et al., 2016; Huck et al., 2017b). This problem has been studied for NMT by Tamchyna et al. (2017), and it would be interesting to compare with their approach. Our work is closer in spirit to previous work on integrating morphological segmentation into SMT. Some examples of early work here include work on Arabic (Lee et al., 2003) and Czech (Goldwater and McClosky, 2005). More recent work includes work on Arabic, such as (Habash, 2007), and work on Turkish (Oflazer and Durgar El-Kahlout, 2007; Yeni"
W17-4706,E17-3017,0,0.0519559,"ource & target) BPE compound + BPE suffix + BPE suffix + compound + BPE suffix + prefix + compound + BPE suffix + prefix + compound, 50K 25.5 25.8 25.9 26.3 26.2 26.1 25.9 60.9 60.7 60.3 60.0 59.8 59.8 59.9 25.2 25.6 25.5 26.0 25.8 25.9 25.5 60.9 60.9 60.6 60.1 60.2 60.6 60.3 phrase-based (Huck et al., 2015) 22.6 – 22.1 – Table 6: English→German experimental results on Europarl (case-sensitive B LEU and T ER). 3 3.1 Machine Translation Experiments Experimental Setup We conduct an empirical evaluation using encoder-decoder NMT with attention and gated recurrent units as implemented in Nematus (Sennrich et al., 2017). We train and test on English–German Europarl data (Koehn, 2005). The data is tokenized and frequent-cased using scripts from the Moses toolkit (Koehn et al., 2007). Sentences with length >50 after tokenization are excluded from the training corpus, all other sentences (1.7 M) are considered in training under every word segmentation scheme. We set the amount of merge operations for BPE to 50K. Corpus statistics of the German data after different preprocessings are given in Table 5. On the English source side, we apply BPE separately, also with 50K merge operations. For comparison, we build a"
W17-4706,2007.mtsummit-papers.65,0,0.0294509,"or NMT by Tamchyna et al. (2017), and it would be interesting to compare with their approach. Our work is closer in spirit to previous work on integrating morphological segmentation into SMT. Some examples of early work here include work on Arabic (Lee et al., 2003) and Czech (Goldwater and McClosky, 2005). More recent work includes work on Arabic, such as (Habash, 2007), and work on Turkish (Oflazer and Durgar El-Kahlout, 2007; Yeniterzi and Oflazer, 2010). Unsupervised morphological splitting, using, e.g., Morfessor has also been tried, particularly for dealing with agglutinative languages (Virpioja et al., 2007). Our work is motivated by the same linguistic observations as theirs. Other studies, e.g., (Popovi´c et al., 2006; Stymne, 2008; Cap et al., 2014), model German compounds by splitting them into single simple words in the SMT training data, and then predicting where to merge simple words as a postprocessing step (after SMT decoding). This has similarities to our use of compound splitting and markers in NMT. 5 Conclusion Linguistically motivated target-side word segmentation improves neural machine translation into an inflected and compounding language. The system can learn linguistic word form"
W17-4706,P13-1058,1,0.826422,"rst in the human evaluation of the news task, despite having a lower B LEU score than Edinburgh’s submission. B LEU, which tries to automatically predict how humans will evaluate quality, may unfairly penalize approaches like ours, but more study is needed. 4 Related Work The SMT literature has a wide diversity of approaches in dealing with translation to morphologically rich languages. One common theme is modeling the relationship between lemmas and surface forms using morphological knowledge, e.g., (Toutanova and Suzuki, 2007; Koehn and Hoang, 2007; Bojar and Kos, 2010; Fraser et al., 2012; Weller et al., 2013; Tamchyna et al., 2016; Huck et al., 2017b). This problem has been studied for NMT by Tamchyna et al. (2017), and it would be interesting to compare with their approach. Our work is closer in spirit to previous work on integrating morphological segmentation into SMT. Some examples of early work here include work on Arabic (Lee et al., 2003) and Czech (Goldwater and McClosky, 2005). More recent work includes work on Arabic, such as (Habash, 2007), and work on Turkish (Oflazer and Durgar El-Kahlout, 2007; Yeniterzi and Oflazer, 2010). Unsupervised morphological splitting, using, e.g., Morfessor"
W17-4706,P16-1162,0,0.162103,"n of morphosyntax, narrowing down its capabilities at modeling inflection and compounding. BPE also has no guidelines for splitting words into syllables. This way no phonetic or semantic substructures are taken into account. Therefore BPE splits often appear arbitrary to the human reader, since it appears frequently that subword units ignore syllable boundaries entirely. Word Segmentation Strategies Byte Pair Encoding A technique in the manner of the Byte Pair Encoding (BPE) compression algorithm (Gage, 1994) can be adopted in order to segment words into smaller subword units, as suggested by Sennrich et al. (2016b). The BPE word segmenter conceptionally proceeds by first splitting all words in the whole corpus into individual characters. The most frequent adjacent pairs of symbols are then consecutively merged, until a specified limit of merge operations has been reached. Merge operations are not applied across word boundaries. The merge operations learned on a training corpus can be stored and applied to other data, such as test sets. Nevertheless, NMT systems incorporating BPE word segmentation have achieved top translation quality in recent shared tasks (Sennrich et al., 2016a; Bojar et al., 2016)."
W17-4706,2006.amta-papers.25,0,0.0235575,"fore segmentation, which affects all setups equally. No sentences are discarded after that stage (Nematus’ maxlen > longest sequence in data). We configure dimensions of 500 for the embeddings and 1024 for the hidden layer. We train with the Adam optimizer (Kingma and Ba, 2015), a learning rate of 0.0001, batch size of 50, and dropout with probability 0.2 applied to the hidden layer.3 We validate on the test2006 set after every 10 000 updates and do early stopping when the validation cost has not decreased for ten epochs. We evaluate case-sensitive with B LEU (Papineni et al., 2002) and T ER (Snover et al., 2006), computed over postprocessed hypotheses against the raw references with mteval-v13a and tercom.7.25, respectively. Table 5: Target-side training corpus statistics. System test2007 test2008 B LEU T ER B LEU T ER top 50K voc. (source & target) BPE compound + BPE suffix + BPE suffix + compound + BPE suffix + prefix + compound + BPE suffix + prefix + compound, 50K 25.5 25.8 25.9 26.3 26.2 26.1 25.9 60.9 60.7 60.3 60.0 59.8 59.8 59.9 25.2 25.6 25.5 26.0 25.8 25.9 25.5 60.9 60.9 60.6 60.1 60.2 60.6 60.3 phrase-based (Huck et al., 2015) 22.6 – 22.1 – Table 6: English→German experimental results on E"
W17-4706,P10-1047,0,0.0160882,"2007; Koehn and Hoang, 2007; Bojar and Kos, 2010; Fraser et al., 2012; Weller et al., 2013; Tamchyna et al., 2016; Huck et al., 2017b). This problem has been studied for NMT by Tamchyna et al. (2017), and it would be interesting to compare with their approach. Our work is closer in spirit to previous work on integrating morphological segmentation into SMT. Some examples of early work here include work on Arabic (Lee et al., 2003) and Czech (Goldwater and McClosky, 2005). More recent work includes work on Arabic, such as (Habash, 2007), and work on Turkish (Oflazer and Durgar El-Kahlout, 2007; Yeniterzi and Oflazer, 2010). Unsupervised morphological splitting, using, e.g., Morfessor has also been tried, particularly for dealing with agglutinative languages (Virpioja et al., 2007). Our work is motivated by the same linguistic observations as theirs. Other studies, e.g., (Popovi´c et al., 2006; Stymne, 2008; Cap et al., 2014), model German compounds by splitting them into single simple words in the SMT training data, and then predicting where to merge simple words as a postprocessing step (after SMT decoding). This has similarities to our use of compound splitting and markers in NMT. 5 Conclusion Linguistically"
W17-4706,W16-2323,0,\N,Missing
W17-4706,P16-1161,1,\N,Missing
W17-4706,Q17-1026,0,\N,Missing
W17-4717,W17-4758,0,0.0835228,"ese submissions investigate alternative machine learning models for the prediction of the HTER score on the sentencelevel task. Instead of directly predicting the HTER score, the systems use a single-layer perceptron with four outputs that jointly predict the number of each of the four distinct post-editing operations that are then used to calculate the HTER score. This also gives the possibility to correct invalid (e.g. negative) predicted values prior to the calculation of the HTER score. The two submissions use the baseline features and the EnglishGerman submission also uses features from (Avramidis, 2017a). JXNU (T1): The JXNU submissions use features extracted from a neural network, including embedding features and cross-entropy features of the source sentences and their machine translations. The sentence embedding features are extracted through global average pooling from word embedding, which are trained using the WORD 2 VEC toolkit. The sentence cross-entropy features are calculated by a recurrent neural network language model. They experimented with different sentence embedding dimensions of the source sentences and translation outputs, as well as different sizes of the training corpus."
W17-4717,W17-4772,0,0.0310859,"Missing"
W17-4717,W17-4759,0,0.0327025,"Missing"
W17-4717,L16-1356,1,0.770826,"or BAD. The ﬁrst two matrices are built from 300 dimension word vectors computed with pretrained in-domain word embeddings. They train their model over 100 iterations with the l2 norm as regulariser and using the forward-backward splitting algorithm (FOBOS) (Duchi and Singer, 2009) as optimisation method. They report results considering the word and its context versus the word in isolation, as well as variants with and without the gold labels at training time. Finally, for the phrase-level task, SHEF made use of predictions generated by BMAPS for task 2 and the phrase labelling approaches in (Blain et al., 2016). These approaches use the number of BAD word-level predictions in a phrase: an optimistic version labels the phrase as OK if at least half of the words in it are predicted to be OK, and a superpessimistic version labels the phrase as BAD if any word is in is predicted to be BAD. UHH (T1): The UHH-STK submission is based on sequence and tree kernels applied on the source and target input data for predicting the HTER score. The kernels use a backtranslation of the MT output into the source language as an additional input data representation. Further hand-crafted features were deﬁned in the form"
W17-4717,W17-4760,1,0.841464,"Missing"
W17-4717,W17-4755,1,0.0393895,"nd Conference on Statistical Machine Translation (WMT) held at EMNLP 2017. This conference builds on eleven previous editions of WMT as workshops and conference (Koehn and Monz, 2006; Callison-Burch et al., 2007, 2008, 2009, 2010, 2011, 2012; Bojar et al., 2013, 2014, 2015, 2016a). This year we conducted several ofﬁcial tasks. We report in this paper on three tasks: • news translation (Section 2, Section 3) • quality estimation (Section 4) • automatic post-editing (Section 5) The conference featured additional shared tasks that are described in separate papers in these proceedings: • metrics (Bojar et al., 2017a) • multimodal machine translation and multilingual image description (Elliott et al., 2017) • biomedical translation (Jimeno Yepes et al., 2017) In the news translation task (Section 2), participants were asked to translate a shared test set, optionally restricting themselves to the provided training data (constraint condition). We held 14 translation tasks this year, between English and each of Chinese, Czech, German, Finnish, Latvian, Russian, and Turkish. The Latvian and Chinese translation tasks were new this year. Latvian is a lesser resourced data condition on challenging language pair"
W17-4717,W07-0718,1,0.696979,") • bandit learning (Sokolov et al., 2017) This paper presents the results of the WMT17 shared tasks, which included three machine translation (MT) tasks (news, biomedical, and multimodal), two evaluation tasks (metrics and run-time estimation of MT quality), an automatic post-editing task, a neural MT training task, and a bandit learning task. 1 Introduction We present the results of the shared tasks of the Second Conference on Statistical Machine Translation (WMT) held at EMNLP 2017. This conference builds on eleven previous editions of WMT as workshops and conference (Koehn and Monz, 2006; Callison-Burch et al., 2007, 2008, 2009, 2010, 2011, 2012; Bojar et al., 2013, 2014, 2015, 2016a). This year we conducted several ofﬁcial tasks. We report in this paper on three tasks: • news translation (Section 2, Section 3) • quality estimation (Section 4) • automatic post-editing (Section 5) The conference featured additional shared tasks that are described in separate papers in these proceedings: • metrics (Bojar et al., 2017a) • multimodal machine translation and multilingual image description (Elliott et al., 2017) • biomedical translation (Jimeno Yepes et al., 2017) In the news translation task (Section 2), part"
W17-4717,W08-0309,1,0.537902,"Missing"
W17-4717,W10-1703,1,0.603181,"Missing"
W17-4717,W12-3102,1,0.508067,"Missing"
W17-4717,W17-4761,0,0.0349831,"Missing"
W17-4717,W17-4723,0,0.0362034,"Missing"
W17-4717,W17-4724,1,0.839009,"Missing"
W17-4717,W11-2103,1,0.744276,"Missing"
W17-4717,W17-4773,1,0.839713,"Missing"
W17-4717,W15-3025,1,0.905105,"Instead of predicting the HTER score, the systems attempted to predict the number of each of the four postediting operations (add, replace, shift, delete) at the sentence level. However, this did not lead to positive results. In future editions of the task, we plan to make this detailed post-editing information available again and suggest clear ways of using it. 5 Automatic Post-editing Task The WMT shared task on MT automatic postediting (APE), this year at its third round at WMT, aims to evaluate systems for the automatic correction of errors in a machine translated text. As pointed out by (Chatterjee et al., 2015b), from the application point of view the task is motivated by its possible uses to: • Improve MT output by exploiting information unavailable to the decoder, or by performing deeper text analysis that is too expensive at the decoding stage; • Cope with systematic errors of an MT system whose decoding process is not accessible; • Provide professional translators with improved MT output quality to reduce (human) post-editing effort; • Adapt the output of a general-purpose MT system to the lexicon/style requested in a speciﬁc application domain. The third round of the APE task proposed to parti"
W17-4717,W17-4718,1,0.0662673,"builds on eleven previous editions of WMT as workshops and conference (Koehn and Monz, 2006; Callison-Burch et al., 2007, 2008, 2009, 2010, 2011, 2012; Bojar et al., 2013, 2014, 2015, 2016a). This year we conducted several ofﬁcial tasks. We report in this paper on three tasks: • news translation (Section 2, Section 3) • quality estimation (Section 4) • automatic post-editing (Section 5) The conference featured additional shared tasks that are described in separate papers in these proceedings: • metrics (Bojar et al., 2017a) • multimodal machine translation and multilingual image description (Elliott et al., 2017) • biomedical translation (Jimeno Yepes et al., 2017) In the news translation task (Section 2), participants were asked to translate a shared test set, optionally restricting themselves to the provided training data (constraint condition). We held 14 translation tasks this year, between English and each of Chinese, Czech, German, Finnish, Latvian, Russian, and Turkish. The Latvian and Chinese translation tasks were new this year. Latvian is a lesser resourced data condition on challenging language pair. Chinese allowed us to co-operate with an ongoing evaluation campaign on Asian languages org"
W17-4717,W17-4725,0,0.0391077,"Missing"
W17-4717,W08-0509,0,0.00859402,"l post-editors) and WMT17 DE-EN (German-English, pharmacological domain, professional post-editors) APE task data. TER BLEU APE15 23.84 n/a APE16 24.76 62.11 APE17 EN-DE 24.48 62.49 APE17 DE-EN 15.55 79.54 Table 26: Translation quality (TER/BLEU of TGT and proportion of TGTs with TER=0) of the WMT15, WMT16, WMT17 EN-DE and WMT17 DE-EN data. Figure 7: TER distribution over the EN-DE test set Figure 8: TER distribution over the DE-EN test set TERcom27 software: lower average TER scores correspond to higher ranks. BLEU was computed using the multi-bleu.perl package28 available in MOSES. MGIZA++ (Gao and Vogel, 2008) for word alignment. For language modeling we used the KenLM toolkit (Heaﬁeld, 2011) for standard n-gram modeling with an n-gram length of 5. Finally, the system was tuned on the development set, optimizing TER/BLEU with Minimum Error Rate Training (Och, 2003). The results of this additional term of comparison are also reported in Tables 28-29. For each submitted run, the statistical signiﬁcance of performance differences with respect to the baseline and our re-implementation of Simard et al. (2007) was calculated with the bootstrap test (Koehn, 2004). 5.1.3 Baselines Also this year, the ofﬁci"
W17-4717,W17-4726,0,0.0387381,"Missing"
W17-4717,W13-2305,1,0.899702,"(RR) approach, so named because the pairwise comparisons denote only relative ability between a pair of systems, and cannot be used to infer absolute quality. For example, RR can be used to discover which systems perform better than others, but RR does not provide any information about the absolute quality of system translations, i.e. it provides no information about how far a given system is from producing perfect output according to a human user. Work on evaluation over the past few years has provided fresh insight into ways to collect direct assessments (DA) of machine translation quality (Graham et al., 2013, 2014, 2016), and last year’s evaluation campaign included parallel assessment of a subset of News task language pairs evaluated with RR and DA. DA has some clear advantages over RR, namely the evaluation of absolute translation quality and the ability to carry out evaluations through quality controlled crowd-sourcing. As established last year (Bojar et al., 2016a), DA results (via crowd-sourcing) and RR results (produced by researchers) correlate strongly, with Pearson correlation ranging from 0.920 to 0.997 across several source languages into English and at 0.975 for English-to-Russian (th"
W17-4717,E14-1047,1,0.508986,"Missing"
W17-4717,N15-1124,1,0.658439,"Missing"
W17-4717,W13-0805,0,0.0140095,"ely contain 25,000 and 1,000 triplets, while the test set consists of 2,000 instances. Table 24 provides some basic statistics about the data (the same used for the sentence-level quality estimation task), which has been released by the European Project QT21 (Specia et al., 2017b).25 In addition, Tables 25 and 26 provide a view of the data from a task difﬁculty standpoint. Table 25 shows the repetition rate (RR) values of the data sets released in the three rounds 24 We used phrase-based MT systems trained with generic and in-domain parallel training data, leveraging prereordering techniques (Herrmann et al., 2013), and taking advantage of POS and word class-based language models. 25 For both language directions, the source sentences and reference translations were provided by TAUS (https://www.taus.net/). 197 EN-DE Train (23,000) Dev (1,000) Test (2,000) DE-EN Train (25,000) Dev (1,000) Test (2,000) SRC Tokens TGT PE SRC Types TGT PE SRC Lemmas TGT PE 384448 17827 65120 403306 19355 69812 411246 19763 71483 18220 2931 8061 27382 3333 9765 31652 3506 10502 10946 1922 2626 21959 2686 3976 25550 2806 4282 437833 17578 35087 453096 18130 36082 456163 18313 36480 29745 4426 6987 19866 3583 5391 19172 3642 5"
W17-4717,W17-4775,0,0.0513454,"Missing"
W17-4717,W17-4730,1,0.829861,"Missing"
W17-4717,W17-4731,0,0.029579,"Missing"
W17-4717,W17-4727,0,0.046917,"Missing"
W17-4717,W16-2378,0,0.0869978,"a manuallyrevised version of the target, done by professional translators. Test data consists of (source, target) pairs having similar characteristics of those in the training set. Human post-edits of the test target instances were left apart to measure system performance. English-German data were drawn from the Information Technology (IT) domain. Training and test sets respectively contain 11,000 and 2,000 triplets. The data released for the 2016 round of the task (15,000 instances) and the artiﬁcially generated post-editing triplets (4 million instances) used by last year’s winning system (Junczys-Dowmunt and Grundkiewicz, 2016) were also provided as additional training material. German-English data were drawn from the Pharmacological domain. Training and development sets respectively contain 25,000 and 1,000 triplets, while the test set consists of 2,000 instances. Table 24 provides some basic statistics about the data (the same used for the sentence-level quality estimation task), which has been released by the European Project QT21 (Specia et al., 2017b).25 In addition, Tables 25 and 26 provide a view of the data from a task difﬁculty standpoint. Table 25 shows the repetition rate (RR) values of the data sets rele"
W17-4717,W11-2123,0,0.00943973,"-editors) APE task data. TER BLEU APE15 23.84 n/a APE16 24.76 62.11 APE17 EN-DE 24.48 62.49 APE17 DE-EN 15.55 79.54 Table 26: Translation quality (TER/BLEU of TGT and proportion of TGTs with TER=0) of the WMT15, WMT16, WMT17 EN-DE and WMT17 DE-EN data. Figure 7: TER distribution over the EN-DE test set Figure 8: TER distribution over the DE-EN test set TERcom27 software: lower average TER scores correspond to higher ranks. BLEU was computed using the multi-bleu.perl package28 available in MOSES. MGIZA++ (Gao and Vogel, 2008) for word alignment. For language modeling we used the KenLM toolkit (Heaﬁeld, 2011) for standard n-gram modeling with an n-gram length of 5. Finally, the system was tuned on the development set, optimizing TER/BLEU with Minimum Error Rate Training (Och, 2003). The results of this additional term of comparison are also reported in Tables 28-29. For each submitted run, the statistical signiﬁcance of performance differences with respect to the baseline and our re-implementation of Simard et al. (2007) was calculated with the bootstrap test (Koehn, 2004). 5.1.3 Baselines Also this year, the ofﬁcial baseline results are the TER and BLEU scores calculated by comparing the raw MT o"
W17-4717,I17-1013,0,0.0334345,"Missing"
W17-4717,W16-2384,0,0.0137431,"features are calculated by a recurrent neural network language model. They experimented with different sentence embedding dimensions of the source sentences and translation outputs, as well as different sizes of the training corpus. The experimental results show that the neural network features lead to signiﬁcant improvements over the baseline, and that combining the neural network features with baseline features leads to further improvement. POSTECH (T1, T2, T3): POSTECH’s submissions to the sentence/word/phrase-level QE tasks are based on predictor-estimator architecture (Kim et al., 2017; Kim and Lee, 2016), which is the two-stage end-to-end ID CDACM DCU DFKI JXNU POSTECH RTM SHEF UHH Unbabel Participating team Centre for Development of Advanced Computing, India (Patel and M, 2016) Dublin City University (Hokamp, 2017) German Research Centre for Artiﬁcial Intelligence, Germany (Avramidis, 2017b) Jiangxi Normal University, China (Chen et al., 2017) Pohang University of Science and Technology, Republic of Korea (Kim et al., 2017) Referential Translation Machines, Turkey (Bic¸ici, 2017) University of Shefﬁeld, UK (Blain et al., 2017; Paetzold and Specia, 2017) University of Hamburg, Germany (Duma a"
W17-4717,W17-4763,0,0.0300648,"ence cross-entropy features are calculated by a recurrent neural network language model. They experimented with different sentence embedding dimensions of the source sentences and translation outputs, as well as different sizes of the training corpus. The experimental results show that the neural network features lead to signiﬁcant improvements over the baseline, and that combining the neural network features with baseline features leads to further improvement. POSTECH (T1, T2, T3): POSTECH’s submissions to the sentence/word/phrase-level QE tasks are based on predictor-estimator architecture (Kim et al., 2017; Kim and Lee, 2016), which is the two-stage end-to-end ID CDACM DCU DFKI JXNU POSTECH RTM SHEF UHH Unbabel Participating team Centre for Development of Advanced Computing, India (Patel and M, 2016) Dublin City University (Hokamp, 2017) German Research Centre for Artiﬁcial Intelligence, Germany (Avramidis, 2017b) Jiangxi Normal University, China (Chen et al., 2017) Pohang University of Science and Technology, Republic of Korea (Kim et al., 2017) Referential Translation Machines, Turkey (Bic¸ici, 2017) University of Shefﬁeld, UK (Blain et al., 2017; Paetzold and Specia, 2017) University of Hamb"
W17-4717,W04-3250,1,0.380171,"age28 available in MOSES. MGIZA++ (Gao and Vogel, 2008) for word alignment. For language modeling we used the KenLM toolkit (Heaﬁeld, 2011) for standard n-gram modeling with an n-gram length of 5. Finally, the system was tuned on the development set, optimizing TER/BLEU with Minimum Error Rate Training (Och, 2003). The results of this additional term of comparison are also reported in Tables 28-29. For each submitted run, the statistical signiﬁcance of performance differences with respect to the baseline and our re-implementation of Simard et al. (2007) was calculated with the bootstrap test (Koehn, 2004). 5.1.3 Baselines Also this year, the ofﬁcial baseline results are the TER and BLEU scores calculated by comparing the raw MT output with the human post-edits. In practice, the baseline APE system is a “donothing” system that leaves all the test targets unmodiﬁed. Baseline results, the same shown in Table 26, are also reported in Tables 28-29 for comparison with participants’ submissions. In continuity with the previous rounds, we used as additional term of comparison a reimplementation of the method ﬁrstly proposed by Simard et al. (2007). It relies on a phrasebased post-editing approach to t"
W17-4717,P07-2045,1,0.0149362,"t with the human post-edits. In practice, the baseline APE system is a “donothing” system that leaves all the test targets unmodiﬁed. Baseline results, the same shown in Table 26, are also reported in Tables 28-29 for comparison with participants’ submissions. In continuity with the previous rounds, we used as additional term of comparison a reimplementation of the method ﬁrstly proposed by Simard et al. (2007). It relies on a phrasebased post-editing approach to the task, which represented the common backbone of APE systems before the spread of neural solutions. The system is based on Moses (Koehn et al., 2007); translation and reordering models were estimated following the Moses protocol with default setup using 27 http://www.cs.umd.edu/˜snover/tercom/ https://github.com/moses-smt/mosesdecoder/ blob/master/scripts/generic/multi-bleu.perl 28 5.2 Participants Seven teams participated in the English-German task by submitting a total of ﬁfteen runs. Two of them also participated in the German-English task with ﬁve submitted runs. Participants are listed in Table 27, and a short description of their systems is provided in the following. Adam Mickiewicz University. AMU’s (ENDE) participation explores and"
W17-4717,C14-1017,0,0.0141812,"ord embeddings approach used by (Scarton et al., 2016) for document-level QE. Here in-domain word embeddings are used instead of embeddings obtained general purpose data (same as in task 2, below). Word embeddings were averaged to generate a single vector for each sentence. Source and target word embeddings were then concatenated with the baseline features and given to an SVM regressor for model building. For the word-level task SHEF investigated a new approach based on predicting the strength of the lexical relationships between the source and target sentences (BMAPS). Following the work by (Madhyastha et al., 2014), a bilinear model is trained from three matrices corresponding to the training data, the development set and a “truth” matrix between them, which is built from the word alignments and the gold labels to indicate which lexical items form a pair, and whether or not their lexical relation is OK or BAD. The ﬁrst two matrices are built from 300 dimension word vectors computed with pretrained in-domain word embeddings. They train their model over 100 iterations with the l2 norm as regulariser and using the forward-backward splitting algorithm (FOBOS) (Duchi and Singer, 2009) as optimisation method."
W17-4717,Q17-1015,0,0.0112193,"ID CDACM DCU DFKI JXNU POSTECH RTM SHEF UHH Unbabel Participating team Centre for Development of Advanced Computing, India (Patel and M, 2016) Dublin City University (Hokamp, 2017) German Research Centre for Artiﬁcial Intelligence, Germany (Avramidis, 2017b) Jiangxi Normal University, China (Chen et al., 2017) Pohang University of Science and Technology, Republic of Korea (Kim et al., 2017) Referential Translation Machines, Turkey (Bic¸ici, 2017) University of Shefﬁeld, UK (Blain et al., 2017; Paetzold and Specia, 2017) University of Hamburg, Germany (Duma and Menzel, 2017) Unbabel, Portugal (Martins et al., 2017b) Table 10: Participants in the WMT17 quality estimation shared task. neural QE model. The predictor-estimator architecture consists of two types of stacked neural network models: 1) a word prediction model based on bidirectional and bilingual recurrent neural network language model trained on additional large-scale parallel corpora and 2) a neural quality estimation model trained on quality-annotated noisy parallel corpora. To jointly learn the two-stage model, a stack propagation method was applied (Zhang and Weiss, 2016). In addition, a “multilevel model” was developed where a task-speciﬁc"
W17-4717,W16-2387,0,0.0126259,"the SMT parallel corps. These features were used to train a Support Vector Regression (SVR) algorithm using a Radial Basis Function (RBF) kernel within the SCIKITLEARN toolkit.13 The γ, � and C parameters were optimised via grid search with 5-fold cross validation on the training set, resulting in γ=0.01, � = 0.0825, C = 20. This baseline system has proved robust across a range of language pairs, MT systems, and text domains for predicting various In addition to that, 6 new features were included which contain combinations of other features, and which proved useful in (Kreutzer et al., 2015; Martins et al., 2016): 12 https://github.com/ghpaetzold/ questplusplus 13 http://scikit-learn.org/ 184 • • • • Target word + left context. Target word + right context. Target word + aligned source word. POS of target word + POS of aligned source word. • Target word + left context + source word. • Target word + right context + source word. • Punctuation features: The baseline system models the task as a sequence prediction problem using the LinearChain Conditional Random Fields (CRF) algorithm within the CRFSuite tool (Okazaki, 2007). The model was trained using passive-aggressive optimisation algorithm. We note th"
W17-4717,W17-4764,0,0.0178514,"ID CDACM DCU DFKI JXNU POSTECH RTM SHEF UHH Unbabel Participating team Centre for Development of Advanced Computing, India (Patel and M, 2016) Dublin City University (Hokamp, 2017) German Research Centre for Artiﬁcial Intelligence, Germany (Avramidis, 2017b) Jiangxi Normal University, China (Chen et al., 2017) Pohang University of Science and Technology, Republic of Korea (Kim et al., 2017) Referential Translation Machines, Turkey (Bic¸ici, 2017) University of Shefﬁeld, UK (Blain et al., 2017; Paetzold and Specia, 2017) University of Hamburg, Germany (Duma and Menzel, 2017) Unbabel, Portugal (Martins et al., 2017b) Table 10: Participants in the WMT17 quality estimation shared task. neural QE model. The predictor-estimator architecture consists of two types of stacked neural network models: 1) a word prediction model based on bidirectional and bilingual recurrent neural network language model trained on additional large-scale parallel corpora and 2) a neural quality estimation model trained on quality-annotated noisy parallel corpora. To jointly learn the two-stage model, a stack propagation method was applied (Zhang and Weiss, 2016). In addition, a “multilevel model” was developed where a task-speciﬁc"
W17-4717,W06-3114,1,0.104699,"g (Bojar et al., 2017b) • bandit learning (Sokolov et al., 2017) This paper presents the results of the WMT17 shared tasks, which included three machine translation (MT) tasks (news, biomedical, and multimodal), two evaluation tasks (metrics and run-time estimation of MT quality), an automatic post-editing task, a neural MT training task, and a bandit learning task. 1 Introduction We present the results of the shared tasks of the Second Conference on Statistical Machine Translation (WMT) held at EMNLP 2017. This conference builds on eleven previous editions of WMT as workshops and conference (Koehn and Monz, 2006; Callison-Burch et al., 2007, 2008, 2009, 2010, 2011, 2012; Bojar et al., 2013, 2014, 2015, 2016a). This year we conducted several ofﬁcial tasks. We report in this paper on three tasks: • news translation (Section 2, Section 3) • quality estimation (Section 4) • automatic post-editing (Section 5) The conference featured additional shared tasks that are described in separate papers in these proceedings: • metrics (Bojar et al., 2017a) • multimodal machine translation and multilingual image description (Elliott et al., 2017) • biomedical translation (Jimeno Yepes et al., 2017) In the news trans"
W17-4717,P03-1021,0,0.144477,"ed better than monolingual models. The code for these models is freely available.15 DCU (T2): DCU’s submission is an ensemble of neural MT systems with different input factors, designed to jointly tackle both the automatic post-editing and word-level QE. 15 https://github.com/patelrajnath/rnn4nlp 186 Word-level features which have proven effective for QE, such as part-of-speech tags and dependency labels are included as input factors to NMT systems. NMT systems using different input representations are ensembled together in a log-linear model which is tuned for the F1 -mult metric using MERT (Och, 2003). The output of the ensemble is a pseudo-reference that is then TER aligned with the original MT to obtain OK/BAD tags for each word in the MT hypothesis. DFKI (T1): These submissions investigate alternative machine learning models for the prediction of the HTER score on the sentencelevel task. Instead of directly predicting the HTER score, the systems use a single-layer perceptron with four outputs that jointly predict the number of each of the four distinct post-editing operations that are then used to calculate the HTER score. This also gives the possibility to correct invalid (e.g. negativ"
W17-4717,W15-3037,0,0.0138062,"n in the source side of the SMT parallel corps. These features were used to train a Support Vector Regression (SVR) algorithm using a Radial Basis Function (RBF) kernel within the SCIKITLEARN toolkit.13 The γ, � and C parameters were optimised via grid search with 5-fold cross validation on the training set, resulting in γ=0.01, � = 0.0825, C = 20. This baseline system has proved robust across a range of language pairs, MT systems, and text domains for predicting various In addition to that, 6 new features were included which contain combinations of other features, and which proved useful in (Kreutzer et al., 2015; Martins et al., 2016): 12 https://github.com/ghpaetzold/ questplusplus 13 http://scikit-learn.org/ 184 • • • • Target word + left context. Target word + right context. Target word + aligned source word. POS of target word + POS of aligned source word. • Target word + left context + source word. • Target word + right context + source word. • Punctuation features: The baseline system models the task as a sequence prediction problem using the LinearChain Conditional Random Fields (CRF) algorithm within the CRFSuite tool (Okazaki, 2007). The model was trained using passive-aggressive optimisatio"
W17-4717,P16-1160,0,0.0330991,"t attention (looking at information anywhere in the source sequence during decoding) and hard monotonic attention (looking at one encoder state at a time from left to right, thus being more conservative and faithful to the original input), which are combined in different ways in the case of multi-source models. The artiﬁcial data provided by JunczysDowmunt and Grundkiewicz (2016) are used to boost performance by increasing the size of the corpus used for training. Univerzita Karlova v Praze. CUNI’s (EN-DE) system is based on the character-to-character neural network architecture described in (Lee et al., 2016). This architecture was compared with the standard neural network architecture proposed by Bahdanau et al. (2014) which uses byte-pair encoding (Sennrich et al., 2015) for generating translation tokens. During the experiments, two setups have been compared for each architecture: i) a single encoder with SRC and MT sentences concatenated, and ii) a two-encoder system, where each SRC and MT sentence is fed to a separate encoder. The submitted system uses the two-encoder architecture with a character-level encoder and decoder. The initial state of the decoder is a weighted combination of the ﬁnal"
W17-4717,W17-4733,0,0.0368107,"Missing"
W17-4717,W17-4765,1,0.786172,"Missing"
W17-4717,L16-1582,1,0.768758,"T 183 translations labelled with task-speciﬁc labels. Participants were also provided with a baseline set of features for each task, and a software package to extract these and other quality estimation features and perform model learning (Section 4.1). Participants (Section 4.2) could submit up to two systems for each task. A discussion on the main goals and ﬁndings from this year’s task is given in Section 4.7. 4.1 Baseline systems forms of post-editing effort (2012; 2013; 2014; 2015; 2016a). Word-level baseline system: For Task 2, the baseline features were extracted with the M AR MOT tool (Logacheva et al., 2016). These are 28 features that have been deemed the most informative in previous research on word-level QE. 22 of them were taken from the feature set described in (Luong et al., 2014), and had also been used as a baseline feature set at WMT16: Sentence-level baseline system: For Task 1, Q U E ST ++12 (2015) was used to extract 17 MT system-independent features from the source and translation (target) ﬁles and parallel corpora: • Word count in the source and target sentences, and source and target token count ratio. Although these features are sentencelevel (i.e. their values will be the same fo"
W17-4717,C16-1241,0,0.0353857,"Missing"
W17-4717,W14-3342,0,0.0181229,"lity estimation features and perform model learning (Section 4.1). Participants (Section 4.2) could submit up to two systems for each task. A discussion on the main goals and ﬁndings from this year’s task is given in Section 4.7. 4.1 Baseline systems forms of post-editing effort (2012; 2013; 2014; 2015; 2016a). Word-level baseline system: For Task 2, the baseline features were extracted with the M AR MOT tool (Logacheva et al., 2016). These are 28 features that have been deemed the most informative in previous research on word-level QE. 22 of them were taken from the feature set described in (Luong et al., 2014), and had also been used as a baseline feature set at WMT16: Sentence-level baseline system: For Task 1, Q U E ST ++12 (2015) was used to extract 17 MT system-independent features from the source and translation (target) ﬁles and parallel corpora: • Word count in the source and target sentences, and source and target token count ratio. Although these features are sentencelevel (i.e. their values will be the same for all words in a sentence), the length of a sentence might inﬂuence the probability of a word being wrong. • Target token, its left and right contexts of 1 word. • Source word aligne"
W17-4717,P16-2046,0,0.0171489,"Missing"
W17-4717,W16-2379,0,0.0228966,"Missing"
W17-4717,P02-1040,0,0.119222,"Missing"
W17-4717,W16-2389,0,0.038207,"Missing"
W17-4717,W17-4736,0,0.0268357,"Missing"
W17-4717,W17-4737,0,0.0383776,"Missing"
W17-4717,W17-4738,0,0.0427074,"Missing"
W17-4717,W14-3301,1,0.655758,"Missing"
W17-4717,W16-2391,1,0.761669,"target sentences into sequences of character embeddings, and then passes them through a series of deep parallel stacked convolution/max pooling layers. The baseline features are provided through a multi-layer perceptron, 187 and then concatenated with the characterlevel information. Finally, the concatenation is passed onto another multi-layer perceptron and the very last layer outputs HTER values. The two submissions differ in the the use of standard (CNN+BASE-Single) and multi-task learning (CNN+BASE-Multi) for training. The QUEST-EMB submission follows the word embeddings approach used by (Scarton et al., 2016) for document-level QE. Here in-domain word embeddings are used instead of embeddings obtained general purpose data (same as in task 2, below). Word embeddings were averaged to generate a single vector for each sentence. Source and target word embeddings were then concatenated with the baseline features and given to an SVM regressor for model building. For the word-level task SHEF investigated a new approach based on predicting the strength of the lexical relationships between the source and target sentences (BMAPS). Following the work by (Madhyastha et al., 2014), a bilinear model is trained"
W17-4717,W16-2323,1,0.349233,"theses. Concatenated source + MT hypothesis are also used as an input representation for some models. The system makes extensive use of the synthetic training data provided by Junczys-Dowmunt and Grundkiewicz (2016), as well as min-risk training for ﬁne-tuning (Shen et al., 2016). The neural systems, which use different input representations but share the same output vocabulary, are then ensembled together in a loglinear model which is tuned for the TER metric using MERT. Fondazione Bruno Kessler. FBK’s (EN-DE & DE-EN) submission extends the existing NMT implementation in the Nematus toolkit (Sennrich et al., 2016) to train an ensemble of multi-source neural APE systems. Building on previous participations based on the phrase-based paradigm (Chatterjee et al., 2015a, 2016), and similar to (Libovick´y et al., 2016), such systems jointly learn from source and target information in order to increase robustness and precision of the automatic corrections. The n-best hypotheses produced by 200 this ensemble are further re-ranked using features based on the edit distance between the original MT output and each APE hypothesis, as well as other statistical models (n-gram language model and operation sequence mod"
W17-4717,P16-1159,0,0.0156896,"different input factors, designed to jointly tackle both the APE task and the Word-Level QE task. Word-Level features which have proven effective for QE, such as word-alignments, partof-speech tags, and dependency labels, are included as input factors to neural machine translation systems, which are trained to output PostEdited MT hypotheses. Concatenated source + MT hypothesis are also used as an input representation for some models. The system makes extensive use of the synthetic training data provided by Junczys-Dowmunt and Grundkiewicz (2016), as well as min-risk training for ﬁne-tuning (Shen et al., 2016). The neural systems, which use different input representations but share the same output vocabulary, are then ensembled together in a loglinear model which is tuned for the TER metric using MERT. Fondazione Bruno Kessler. FBK’s (EN-DE & DE-EN) submission extends the existing NMT implementation in the Nematus toolkit (Sennrich et al., 2016) to train an ensemble of multi-source neural APE systems. Building on previous participations based on the phrase-based paradigm (Chatterjee et al., 2015a, 2016), and similar to (Libovick´y et al., 2016), such systems jointly learn from source and target inf"
W17-4717,2006.amta-papers.25,0,0.817721,"trast to last year, we also provide datasets for two language pairs. The structure used for the data have been the same since WMT15. Each data instance consists of (i) a source sentence, (ii) its automatic translation into the target language, (iii) the manually post-edited version of the automatic translation, (iv) a free reference translation of the source sentence. Post-edits are used to extract labels for the 4.4 Task 1: Predicting sentence-level quality This task consists in scoring (and ranking) translation sentences according to the proportion of their words that need to be ﬁxed. HTER (Snover et al., 2006b) is used as quality score, i.e. the minimum edit distance between the machine translation and its manually post-edited version. Labels HTER labels were computed using the TERCOM tool16 with default settings (tokenised, case insensitive, exact matching only), with scores capped to 1. 188 16 http://www.cs.umd.edu/˜snover/tercom/ Evaluation Evaluation was performed against the true HTER label and/or ranking, using the following metrics: with an edit operation: insertion, deletion, substitution or no edit (correct word). We mark each edited word as BAD, and the remainingn as OK. • Scoring: Pears"
W17-4717,W17-4756,0,0.0529328,"Missing"
W17-4717,P15-4020,1,0.738308,"Missing"
W17-4717,P13-4014,1,0.634274,"Missing"
W17-4717,W17-4720,1,0.830567,"Missing"
W17-4717,W17-4776,0,0.0596806,"Missing"
W17-4717,W17-4777,1,0.832756,"Missing"
W17-4717,W17-4742,0,0.0342495,"Missing"
W17-4717,W17-4744,0,0.0607458,"Missing"
W17-4717,C00-2137,0,0.0420443,"ch edited word as BAD, and the remainingn as OK. • Scoring: Pearson’s r correlation score (primary metric, ofﬁcial score for ranking submissions), Mean Average Error (MAE) and Root Mean Squared Error (RMSE). Evaluation Analogously to the last year’s task, the primary evaluation metric is the multiplication of F1 -scores for the OK and BAD classes, denoted as F1 -mult. Unlike previously used F1 BAD score this metric is not biased towards “pessimistic” labellings. We also report F1 -scores for individual classes for completeness. We test the signiﬁcance of the results using randomisation tests (Yeh, 2000) with Bonferroni correction (Abdi, 2007). • Ranking: Spearman’s ρ rank correlation and DeltaAvg. Statistical signiﬁcance on Pearson r was computed using the William’s test.17 Results Tables 13 and 14 summarise the results for Task 1 on German–English and English– German datasets, respectively, ranking participating systems best to worst using Pearson’s r correlation as primary key. Spearman’s ρ correlation scores should be used to rank systems for the ranking variant. The top three systems are the same for both datasets, and the ranking of systems according to their performance is similar for"
W17-4717,W17-4745,1,0.825998,"Missing"
W17-4717,P16-1147,0,0.0102821,"Missing"
W17-4730,D15-1129,1,0.826054,"T setup only. In the human evaluation the LMU Munich primary system is ranked first (Bojar et al., 2017). http://www.statmt.org/wmt17/ 315 Proceedings of the Conference on Machine Translation (WMT), Volume 2: Shared Task Papers, pages 315–322 c Copenhagen, Denmark, September 711, 2017. 2017 Association for Computational Linguistics focusing on investigating linguistically informed methods that improve machine translation into target languages which exhibit a more complex morphosyntax than English (Huck et al., 2017b; Tamchyna et al., 2016a; Ramm and Fraser, 2016; Weller-Di Marco et al., 2016; Braune et al., 2015; Cap et al., 2014a; Fraser et al., 2012). We are taking advantage of our group’s longstanding experience regarding handling of complex morphosyntax in SMT, now enriching NMT with novel techniques that specifically tackle target-side morphosyntax. In the following section of this paper (Section 2), we sketch our linguistically motivated target word segmentation technique. Then we describe how we trained and configured our neural machine translation systems (Section 3). Before concluding the paper, we present empirical results on the two translation tasks, which involve machine translation of n"
W17-4730,E14-1061,1,0.828521,"human evaluation the LMU Munich primary system is ranked first (Bojar et al., 2017). http://www.statmt.org/wmt17/ 315 Proceedings of the Conference on Machine Translation (WMT), Volume 2: Shared Task Papers, pages 315–322 c Copenhagen, Denmark, September 711, 2017. 2017 Association for Computational Linguistics focusing on investigating linguistically informed methods that improve machine translation into target languages which exhibit a more complex morphosyntax than English (Huck et al., 2017b; Tamchyna et al., 2016a; Ramm and Fraser, 2016; Weller-Di Marco et al., 2016; Braune et al., 2015; Cap et al., 2014a; Fraser et al., 2012). We are taking advantage of our group’s longstanding experience regarding handling of complex morphosyntax in SMT, now enriching NMT with novel techniques that specifically tackle target-side morphosyntax. In the following section of this paper (Section 2), we sketch our linguistically motivated target word segmentation technique. Then we describe how we trained and configured our neural machine translation systems (Section 3). Before concluding the paper, we present empirical results on the two translation tasks, which involve machine translation of news articles and o"
W17-4730,W13-2213,1,0.857637,"machine translation shared tasks in recent years (Bojar et al., 2016, 2015, 2014, 2013), competing (and also collaborating) internationally in an open evaluation campaign with other leading research labs from both academia and industry. Research on various different types of machine translation models has previously been conducted at LMU. Core SMT paradigms for LMU’s past shared task participations include phrase-based models (Cap et al., 2015, 2014b; Weller et al., 2013; Sajjad et al., 2013), hierarchical phrasebased models (Huck et al., 2016; Peter et al., 2016), operation sequence models (Durrani et al., 2013), and hybrids of statistical approaches with rule-based and deep syntactic components (Tamchyna et al., 2016b). At this year’s EMNLP 2017 Second Conference on Machine Translation (WMT17),1 LMU participated in two shared tasks: the shared task 1 2 Our LMU Munich primary system is ranked second in B LEU on the submission website, http://matrix. statmt.org/matrix/systems_list/1869, being outpaced by Edinburgh’s WMT17 NMT setup only. In the human evaluation the LMU Munich primary system is ranked first (Bojar et al., 2017). http://www.statmt.org/wmt17/ 315 Proceedings of the Conference on Machine"
W17-4730,E12-1068,1,0.864452,"e LMU Munich primary system is ranked first (Bojar et al., 2017). http://www.statmt.org/wmt17/ 315 Proceedings of the Conference on Machine Translation (WMT), Volume 2: Shared Task Papers, pages 315–322 c Copenhagen, Denmark, September 711, 2017. 2017 Association for Computational Linguistics focusing on investigating linguistically informed methods that improve machine translation into target languages which exhibit a more complex morphosyntax than English (Huck et al., 2017b; Tamchyna et al., 2016a; Ramm and Fraser, 2016; Weller-Di Marco et al., 2016; Braune et al., 2015; Cap et al., 2014a; Fraser et al., 2012). We are taking advantage of our group’s longstanding experience regarding handling of complex morphosyntax in SMT, now enriching NMT with novel techniques that specifically tackle target-side morphosyntax. In the following section of this paper (Section 2), we sketch our linguistically motivated target word segmentation technique. Then we describe how we trained and configured our neural machine translation systems (Section 3). Before concluding the paper, we present empirical results on the two translation tasks, which involve machine translation of news articles and of health information te"
W17-4730,E14-2008,1,0.829296,"ed model from the preceding step, and optimize on only the small Devsets2008-14 corpus. 4. Right-to-left reranking. We rerank an nbest list from the system in the preceding step with a right-to-left (r2l) model, where the order of the target sequence is reversed. Liu et al. (2016) have proposed right-to-left reranking for NMT. Earlier work by Freitag et al. (2013) had already established that reverse word order models can be beneficial in phrase-based and hierarchical phrase-based translation. Freitag et al. (2013) utilized reverse word order models by means of a system combination framework (Freitag et al., 2014), though. splitting and compound splitting, but to omit prefix splitting. The English source side is simply BPEsegmented. 3 Neural Translation System Setup We utilize the Nematus implementation (Sennrich et al., 2017) to build encoder-decoder NMT systems with attention and gated recurrent units. We configure dimensions of 500 for the embeddings and 1024 for the hidden layer. We train with the Adam optimizer (Kingma and Ba, 2015), a learning rate of 0.0001, batch size of 50, and dropout with probability 0.2 applied to the hidden layer, but not to source, target, and embeddings. We validate ever"
W17-4730,E03-1076,0,0.212051,"es that specifically tackle target-side morphosyntax. In the following section of this paper (Section 2), we sketch our linguistically motivated target word segmentation technique. Then we describe how we trained and configured our neural machine translation systems (Section 3). Before concluding the paper, we present empirical results on the two translation tasks, which involve machine translation of news articles and of health information texts (Section 4). 2 off. It otherwise behaves just like the Snowball stemming algorithm. 2. Next we apply the empirical compound splitter as described by Koehn and Knight (2003) and as implemented in the Perl script which is part of the Moses toolkit (Koehn et al., 2007). We choose a fairly aggressive configuration of the compound splitter4 in order to reduce the vocabulary size more than with its parameters as typically chosen for previous phrase-based translation setups in which German compound splitting was used. 3. Since the vocabulary size is still a bit large after suffix splitting and compound splitting, we adopt segmentation using the Byte Pair Encoding (BPE) technique (Gage, 1994; Sennrich et al., 2016c) on top of the other two word splitters. This last step"
W17-4730,2015.mtsummit-papers.19,1,0.84912,"ystem to suppress UNK tokens in inference at test time. For the shared task on machine translation of news (Bojar et al., 2017), we successively improved our initial baseline by incrementally applying the following steps: 1. Adding the News Commentary (NC) and Common Crawl (CC) parallel training data as provided for WMT17 by the organizers of the news translation shared task. We initialize the optimization on the larger corpus with the Europarl-trained baseline model. 5 http://data.statmt.org/rsennrich/ wmt16_backtranslations/en-de/ 317 system this seems to be mostly due to a domain mismatch (Huck et al., 2015). Once we add in the News Commentary and Common Crawl parallel data, we are able to massively improve the translation quality, by around six to seven B LEU points. Synthetic data gives us a boost of about another two B LEU points. After fine-tuning on Devsets200814 towards news articles, we observe a further gain of 0.4 B LEU on newstest2015 but no gain on newstest2016. Reranking with a right-to-left model is effective on all test sets again, with improvements in the range of 0.4 to 1.1 B LEU. Two LMU submissions have been judged by humans in the manual evaluation for the WMT17 news translatio"
W17-4730,W11-2132,0,0.130804,"suffix 1. First we apply a suffix splitter that separates common German morphological suffixes from the word stems. We modified the German Snowball stemming algorithm from NLTK3 for that purpose. Rather than stripping suffixes, our modified code splits them 3 http://www.nltk.org/_modules/nltk/ stem/snowball.html 4 -min-size 4 -min-count 2 -max-count 999999999 316 2. Adding synthetic training data. The use of automatically translated monolingual data as a supplementary training resource has proved to be effective in SMT for phrase-based, hierarchical, and neural systems (Ueffing et al., 2007; Lambert et al., 2011; Huck et al., 2011; Huck and Ney, 2012; Sennrich et al., 2016b). Sennrich et al. have publicly shared their backtranslations of monolingual WMT News Crawl corpora, which they created for their WMT16 participation (Sennrich et al., 2016a). We exploit the full amount of backtranslations of German data into English.5 We concatenate the synthetic data and the human-generated parallel training data (Europarl + NC + CC). The optimization is initialized with the pre-trained model from the preceding step. 3. Fine-tuning towards the domain of news articles. We employ the newstest development sets from"
W17-4730,W16-2315,1,0.869018,"omanian, Russian, or French. LMU has frequently participated in WMT machine translation shared tasks in recent years (Bojar et al., 2016, 2015, 2014, 2013), competing (and also collaborating) internationally in an open evaluation campaign with other leading research labs from both academia and industry. Research on various different types of machine translation models has previously been conducted at LMU. Core SMT paradigms for LMU’s past shared task participations include phrase-based models (Cap et al., 2015, 2014b; Weller et al., 2013; Sajjad et al., 2013), hierarchical phrasebased models (Huck et al., 2016; Peter et al., 2016), operation sequence models (Durrani et al., 2013), and hybrids of statistical approaches with rule-based and deep syntactic components (Tamchyna et al., 2016b). At this year’s EMNLP 2017 Second Conference on Machine Translation (WMT17),1 LMU participated in two shared tasks: the shared task 1 2 Our LMU Munich primary system is ranked second in B LEU on the submission website, http://matrix. statmt.org/matrix/systems_list/1869, being outpaced by Edinburgh’s WMT17 NMT setup only. In the human evaluation the LMU Munich primary system is ranked first (Bojar et al., 2017). htt"
W17-4730,N16-1046,0,0.0814608,"Missing"
W17-4730,2012.amta-papers.8,1,0.824358,"er that separates common German morphological suffixes from the word stems. We modified the German Snowball stemming algorithm from NLTK3 for that purpose. Rather than stripping suffixes, our modified code splits them 3 http://www.nltk.org/_modules/nltk/ stem/snowball.html 4 -min-size 4 -min-count 2 -max-count 999999999 316 2. Adding synthetic training data. The use of automatically translated monolingual data as a supplementary training resource has proved to be effective in SMT for phrase-based, hierarchical, and neural systems (Ueffing et al., 2007; Lambert et al., 2011; Huck et al., 2011; Huck and Ney, 2012; Sennrich et al., 2016b). Sennrich et al. have publicly shared their backtranslations of monolingual WMT News Crawl corpora, which they created for their WMT16 participation (Sennrich et al., 2016a). We exploit the full amount of backtranslations of German data into English.5 We concatenate the synthetic data and the human-generated parallel training data (Europarl + NC + CC). The optimization is initialized with the pre-trained model from the preceding step. 3. Fine-tuning towards the domain of news articles. We employ the newstest development sets from the years 2008 to 2014 as a training c"
W17-4730,W17-4706,1,0.915939,"bsite, http://matrix. statmt.org/matrix/systems_list/1869, being outpaced by Edinburgh’s WMT17 NMT setup only. In the human evaluation the LMU Munich primary system is ranked first (Bojar et al., 2017). http://www.statmt.org/wmt17/ 315 Proceedings of the Conference on Machine Translation (WMT), Volume 2: Shared Task Papers, pages 315–322 c Copenhagen, Denmark, September 711, 2017. 2017 Association for Computational Linguistics focusing on investigating linguistically informed methods that improve machine translation into target languages which exhibit a more complex morphosyntax than English (Huck et al., 2017b; Tamchyna et al., 2016a; Ramm and Fraser, 2016; Weller-Di Marco et al., 2016; Braune et al., 2015; Cap et al., 2014a; Fraser et al., 2012). We are taking advantage of our group’s longstanding experience regarding handling of complex morphosyntax in SMT, now enriching NMT with novel techniques that specifically tackle target-side morphosyntax. In the following section of this paper (Section 2), we sketch our linguistically motivated target word segmentation technique. Then we describe how we trained and configured our neural machine translation systems (Section 3). Before concluding the paper"
W17-4730,P02-1040,0,0.0995222,"translation (Sutskever et al., 2014; Bahdanau et al., 2014) are now largely successful for many language pairs and domains. This has for instance become apparent with the University of Edinburgh’s excellent results in the WMT16 news translation shared task with neural systems (Sennrich et al., 2016a), which outperformed most other submitted systems, including Edinburgh’s own traditional SMT engines (Williams et al., 2016). LMU’s English→German neural machine translation systems confirm this trend. We have achieved competitive performance—in terms of translation quality as measured with B LEU (Papineni et al., 2002)—in both shared tasks that we participated in.2 A unique characteristic of the LMU English→German NMT systems is a linguistically informed, cascaded word segmentation technique that we developed and applied to the German target language side of the training data. Amongst other aspects, SMT research at LMU is This paper describes the LMU Munich English→German machine translation systems. We participated with neural translation engines in the WMT17 shared task on machine translation of news, as well as in the biomedical translation task. LMU Munich’s systems deliver competitive machine translati"
W17-4730,E17-2059,1,0.710966,"Missing"
W17-4730,W11-2211,1,0.819082,"ply a suffix splitter that separates common German morphological suffixes from the word stems. We modified the German Snowball stemming algorithm from NLTK3 for that purpose. Rather than stripping suffixes, our modified code splits them 3 http://www.nltk.org/_modules/nltk/ stem/snowball.html 4 -min-size 4 -min-count 2 -max-count 999999999 316 2. Adding synthetic training data. The use of automatically translated monolingual data as a supplementary training resource has proved to be effective in SMT for phrase-based, hierarchical, and neural systems (Ueffing et al., 2007; Lambert et al., 2011; Huck et al., 2011; Huck and Ney, 2012; Sennrich et al., 2016b). Sennrich et al. have publicly shared their backtranslations of monolingual WMT News Crawl corpora, which they created for their WMT16 participation (Sennrich et al., 2016a). We exploit the full amount of backtranslations of German data into English.5 We concatenate the synthetic data and the human-generated parallel training data (Europarl + NC + CC). The optimization is initialized with the pre-trained model from the preceding step. 3. Fine-tuning towards the domain of news articles. We employ the newstest development sets from the years 2008 to"
W17-4730,W16-2203,1,0.845551,"ems_list/1869, being outpaced by Edinburgh’s WMT17 NMT setup only. In the human evaluation the LMU Munich primary system is ranked first (Bojar et al., 2017). http://www.statmt.org/wmt17/ 315 Proceedings of the Conference on Machine Translation (WMT), Volume 2: Shared Task Papers, pages 315–322 c Copenhagen, Denmark, September 711, 2017. 2017 Association for Computational Linguistics focusing on investigating linguistically informed methods that improve machine translation into target languages which exhibit a more complex morphosyntax than English (Huck et al., 2017b; Tamchyna et al., 2016a; Ramm and Fraser, 2016; Weller-Di Marco et al., 2016; Braune et al., 2015; Cap et al., 2014a; Fraser et al., 2012). We are taking advantage of our group’s longstanding experience regarding handling of complex morphosyntax in SMT, now enriching NMT with novel techniques that specifically tackle target-side morphosyntax. In the following section of this paper (Section 2), we sketch our linguistically motivated target word segmentation technique. Then we describe how we trained and configured our neural machine translation systems (Section 3). Before concluding the paper, we present empirical results on the two transl"
W17-4730,2005.mtsummit-papers.11,0,0.349352,"Missing"
W17-4730,W13-2228,1,0.875938,"Missing"
W17-4730,E17-3017,0,0.0582441,"e the order of the target sequence is reversed. Liu et al. (2016) have proposed right-to-left reranking for NMT. Earlier work by Freitag et al. (2013) had already established that reverse word order models can be beneficial in phrase-based and hierarchical phrase-based translation. Freitag et al. (2013) utilized reverse word order models by means of a system combination framework (Freitag et al., 2014), though. splitting and compound splitting, but to omit prefix splitting. The English source side is simply BPEsegmented. 3 Neural Translation System Setup We utilize the Nematus implementation (Sennrich et al., 2017) to build encoder-decoder NMT systems with attention and gated recurrent units. We configure dimensions of 500 for the embeddings and 1024 for the hidden layer. We train with the Adam optimizer (Kingma and Ba, 2015), a learning rate of 0.0001, batch size of 50, and dropout with probability 0.2 applied to the hidden layer, but not to source, target, and embeddings. We validate every 10 000 updates and do early stopping when the validation cost has not decreased over ten consecutive control points. Our initial baseline NMT system is trained using only data from the Europarl corpus (Koehn, 2005)"
W17-4730,W16-2205,1,0.890776,"Missing"
W17-4730,W16-2327,1,0.829844,"additional parallel training data from the in-domain sections of the UFAL Medical Corpus v.1.0. We have trained neural machine translation (NMT) models this year. Neural network models for machine translation (Sutskever et al., 2014; Bahdanau et al., 2014) are now largely successful for many language pairs and domains. This has for instance become apparent with the University of Edinburgh’s excellent results in the WMT16 news translation shared task with neural systems (Sennrich et al., 2016a), which outperformed most other submitted systems, including Edinburgh’s own traditional SMT engines (Williams et al., 2016). LMU’s English→German neural machine translation systems confirm this trend. We have achieved competitive performance—in terms of translation quality as measured with B LEU (Papineni et al., 2002)—in both shared tasks that we participated in.2 A unique characteristic of the LMU English→German NMT systems is a linguistically informed, cascaded word segmentation technique that we developed and applied to the German target language side of the training data. Amongst other aspects, SMT research at LMU is This paper describes the LMU Munich English→German machine translation systems. We participat"
W17-4730,P16-1009,0,0.436137,"for the biomedical task builds upon our news task system, but was domain-adapted towards the medical domain via the usage of additional parallel training data from the in-domain sections of the UFAL Medical Corpus v.1.0. We have trained neural machine translation (NMT) models this year. Neural network models for machine translation (Sutskever et al., 2014; Bahdanau et al., 2014) are now largely successful for many language pairs and domains. This has for instance become apparent with the University of Edinburgh’s excellent results in the WMT16 news translation shared task with neural systems (Sennrich et al., 2016a), which outperformed most other submitted systems, including Edinburgh’s own traditional SMT engines (Williams et al., 2016). LMU’s English→German neural machine translation systems confirm this trend. We have achieved competitive performance—in terms of translation quality as measured with B LEU (Papineni et al., 2002)—in both shared tasks that we participated in.2 A unique characteristic of the LMU English→German NMT systems is a linguistically informed, cascaded word segmentation technique that we developed and applied to the German target language side of the training data. Amongst other"
W17-4730,P16-1162,0,0.691355,"for the biomedical task builds upon our news task system, but was domain-adapted towards the medical domain via the usage of additional parallel training data from the in-domain sections of the UFAL Medical Corpus v.1.0. We have trained neural machine translation (NMT) models this year. Neural network models for machine translation (Sutskever et al., 2014; Bahdanau et al., 2014) are now largely successful for many language pairs and domains. This has for instance become apparent with the University of Edinburgh’s excellent results in the WMT16 news translation shared task with neural systems (Sennrich et al., 2016a), which outperformed most other submitted systems, including Edinburgh’s own traditional SMT engines (Williams et al., 2016). LMU’s English→German neural machine translation systems confirm this trend. We have achieved competitive performance—in terms of translation quality as measured with B LEU (Papineni et al., 2002)—in both shared tasks that we participated in.2 A unique characteristic of the LMU English→German NMT systems is a linguistically informed, cascaded word segmentation technique that we developed and applied to the German target language side of the training data. Amongst other"
W17-4730,P16-1161,1,0.885485,"Missing"
W17-4730,W16-2325,1,0.841956,"o collaborating) internationally in an open evaluation campaign with other leading research labs from both academia and industry. Research on various different types of machine translation models has previously been conducted at LMU. Core SMT paradigms for LMU’s past shared task participations include phrase-based models (Cap et al., 2015, 2014b; Weller et al., 2013; Sajjad et al., 2013), hierarchical phrasebased models (Huck et al., 2016; Peter et al., 2016), operation sequence models (Durrani et al., 2013), and hybrids of statistical approaches with rule-based and deep syntactic components (Tamchyna et al., 2016b). At this year’s EMNLP 2017 Second Conference on Machine Translation (WMT17),1 LMU participated in two shared tasks: the shared task 1 2 Our LMU Munich primary system is ranked second in B LEU on the submission website, http://matrix. statmt.org/matrix/systems_list/1869, being outpaced by Edinburgh’s WMT17 NMT setup only. In the human evaluation the LMU Munich primary system is ranked first (Bojar et al., 2017). http://www.statmt.org/wmt17/ 315 Proceedings of the Conference on Machine Translation (WMT), Volume 2: Shared Task Papers, pages 315–322 c Copenhagen, Denmark, September 711, 2017. 2"
W17-4730,P07-2045,0,\N,Missing
W17-4730,W14-3305,1,\N,Missing
W17-4730,W15-3007,1,\N,Missing
W17-4730,W16-2323,0,\N,Missing
W17-4730,W17-4717,1,\N,Missing
W18-1805,P17-1080,0,0.0221371,"ck et al., 2017b,a). Not all prior research on MRLs in traditional phrase-based MT can be readily transferred to NMT. One of the most promising attemps to date is following the theme of two-step MT. A second-step module generates inﬂections from lemmas and morphological tags. The ﬁrst-step NMT module outputs interleaved sequences of such lemmas and their respective tags (Burlot et al., 2016, 2017; Tamchyna et al., 2017). Research on how to best model morphology with neural networks is ongoing, in MT and in other areas of NLP (Botha and Blunsom, 2014; Ebert et al., 2016; Vania and Lopez, 2017; Belinkov et al., 2017; Garc´ıa-Mart´ınez et al., 2016; Garc´ıa-Mart´ınez et al., 2017; Burlot and Yvon, 2017). 2.2 Morphological Tagging of Lemmas: Utility and Limitations Morphological tagging is the task of marking up each token in an input sequence with the corresponding morphological features which describe its inﬂectional properties. In the case of morphologically poor languages, a word can usually be described sufﬁciently using information about its POS tag (Mueller et al., 2013). MRLs require a more detailed analysis. The term MRL refers to a language where word shapes encode a consistent number of syntacti"
W18-1805,W07-0735,0,0.134385,"problem and counteract data sparsity. Arabic is a prominent example of a language that typically undergoes heavy morphosyntactic analysis and preprocessing on the source side (Lee, 2004; Habash and Sadat, 2006; Hasan et al., 2011). Proceedings of AMTA 2018, vol. 1: MT Research Track Boston, March 17 - 21, 2018 |Page 40 Target-side MRL. The more challenging question of how to tackle rich morphology on the target side has undergone quite some research. Factored phrase-based models (Koehn and Hoang, 2007) can be used to produce inﬂected output via a separate decoding path and a generation step (Bojar, 2007). The blow-up of the search space can make such models impractical. Backoff techniques (Koehn and Haddow, 2012) or ﬂat factored models with supplementary features over lemmas and linguistic annotation (Stymne et al., 2008; Huck and Birch, 2015) are more tractable alternatives. Phrase-based translation models, accompanied with n-gram language models, have a relatively limited local view. Some morphological phenomena go beyond local context and require agreement across long distances. In syntax-based systems with a chart-based decoding procedure, engineering adequate agreement constraints is mor"
W18-1805,W10-1705,0,0.0195291,"studied by Minkov et al. (2007). We differ in two ways: (1.) we implement a state-of-the-art neural tagger, rather than a Maximum Entropy Markov model, and (2.) we predict rich morphological POS, rather than surface forms. Studying the prediction of morphologically rich POS given lemmas is an interesting problem in its own right. It has implications for NLP applications involving the generation of MRL sentences including machine translation. A concrete application is to apply it in an end-to-end MT system. Similar morphological prediction systems have been applied by Toutanova et al. (2008), Bojar and Kos (2010) and Fraser et al. (2012) in phrase-based SMT. A pipeline of such a system is depicted in Figure 1. Given the promising results in this initial study, we plan to combine our tagger with a standard neural machine translation model, resulting in a multi-task system which produces pairs of lemmas and morphologically rich POS tags. An important beneﬁt of such a system over previous approaches which produce such pairs directly using a standard NMT model (e.g., Tamchyna et al. (2017)) is that we will be able to train it in a multi-task fashion, where some Proceedings of AMTA 2018, vol. 1: MT Researc"
W18-1805,W17-4703,0,0.0363397,"Missing"
W18-1805,W17-4705,0,0.0532634,"Missing"
W18-1805,D13-1174,0,0.0241702,"guage models, have a relatively limited local view. Some morphological phenomena go beyond local context and require agreement across long distances. In syntax-based systems with a chart-based decoding procedure, engineering adequate agreement constraints is more viable (Williams and Koehn, 2011, 2014). Pursuing a different idea, Avramidis and Koehn (2008) and Daiber and Sima’an (2015) have attempted to annotate input sentences beforehand with morphological features that are exhibited by the target-side MRL, thus taking the burden of the inﬂection selection away from the phrase-based decoder. Chahuneau et al. (2013) and Huck et al. (2017c), on the other hand, have speciﬁcally looked into how to produce unseen morphological variants without resorting to a factored generation step. To that end, they augment their phrase tables with synthetic entries. Other researchers have proposed two-step approaches to MT into MRLs, where the output of the ﬁrst step (the actual translation) lacks certain morphological features of the MRL, which in turn have to be predicted by a separate module in a second step in order to end up with inﬂected target language sentences (Toutanova et al., 2008; Fraser et al., 2012). Slight"
W18-1805,P11-1004,0,0.0199609,"nto MRLs, where the output of the ﬁrst step (the actual translation) lacks certain morphological features of the MRL, which in turn have to be predicted by a separate module in a second step in order to end up with inﬂected target language sentences (Toutanova et al., 2008; Fraser et al., 2012). Slightly less supervision might be required by another technique for tackling rich morphology on the target side: word segmentation, and subsequent modeling on a subword level. Inﬂected target words in the training data can e.g. be segmented into stems and morphological afﬁxes (Fishel and Kirik, 2010; Clifton and Sarkar, 2011; Passban et al., 2017). The segmentation of output hypotheses of the MT system needs to be reverted in postprocessing. In modern neural machine translation engines, word segmentation by means of a Byte Pair Encoding (BPE) style algorithm is a common trick to shrink the vocabulary size (Sennrich et al., 2016). Recent research has shown that NMT of MRLs beneﬁts from word segmentation techniques that are linguistically more informed than plain BPE (Ataman et al., 2017; Pinnis et al., 2017; Huck et al., 2017b,a). Not all prior research on MRLs in traditional phrase-based MT can be readily transfe"
W18-1805,N15-1140,0,0.0247419,"Missing"
W18-1805,2015.mtsummit-papers.22,0,0.037757,"Missing"
W18-1805,D16-1071,0,0.0588349,"Missing"
W18-1805,fishel-kirik-2010-linguistically,0,0.027136,"-step approaches to MT into MRLs, where the output of the ﬁrst step (the actual translation) lacks certain morphological features of the MRL, which in turn have to be predicted by a separate module in a second step in order to end up with inﬂected target language sentences (Toutanova et al., 2008; Fraser et al., 2012). Slightly less supervision might be required by another technique for tackling rich morphology on the target side: word segmentation, and subsequent modeling on a subword level. Inﬂected target words in the training data can e.g. be segmented into stems and morphological afﬁxes (Fishel and Kirik, 2010; Clifton and Sarkar, 2011; Passban et al., 2017). The segmentation of output hypotheses of the MT system needs to be reverted in postprocessing. In modern neural machine translation engines, word segmentation by means of a Byte Pair Encoding (BPE) style algorithm is a common trick to shrink the vocabulary size (Sennrich et al., 2016). Recent research has shown that NMT of MRLs beneﬁts from word segmentation techniques that are linguistically more informed than plain BPE (Ataman et al., 2017; Pinnis et al., 2017; Huck et al., 2017b,a). Not all prior research on MRLs in traditional phrase-based"
W18-1805,P16-5005,0,0.0489311,"Missing"
W18-1805,H05-1085,0,0.0299749,"erpart is morphologically underspeciﬁed, which complicates both statistical modeling and search. Data-driven approaches over MRLs furthermore suffer eminently from data sparsity issues under mediumto low-resource conditions. Many inﬂected forms are observed rarely. Source-side MRL. Rich morphology on the source side can to some extent be tackled via preprocessing. Syntactic and morphological analyzers can be employed, based on which a source sentence representation can be constructed which is more appropriate as the input to a translation system (Popovi´c and Ney, 2004; Popovi´c et al., 2005; Goldwater and McClosky, 2005). E.g., certain morphological features of the source words may be dismissed beforehand. Non-reversible modiﬁcations are uncritical on the source side and can potentially alleviate the modeling problem and counteract data sparsity. Arabic is a prominent example of a language that typically undergoes heavy morphosyntactic analysis and preprocessing on the source side (Lee, 2004; Habash and Sadat, 2006; Hasan et al., 2011). Proceedings of AMTA 2018, vol. 1: MT Research Track Boston, March 17 - 21, 2018 |Page 40 Target-side MRL. The more challenging question of how to tackle rich morphology on the"
W18-1805,N06-2013,0,0.0131544,"be employed, based on which a source sentence representation can be constructed which is more appropriate as the input to a translation system (Popovi´c and Ney, 2004; Popovi´c et al., 2005; Goldwater and McClosky, 2005). E.g., certain morphological features of the source words may be dismissed beforehand. Non-reversible modiﬁcations are uncritical on the source side and can potentially alleviate the modeling problem and counteract data sparsity. Arabic is a prominent example of a language that typically undergoes heavy morphosyntactic analysis and preprocessing on the source side (Lee, 2004; Habash and Sadat, 2006; Hasan et al., 2011). Proceedings of AMTA 2018, vol. 1: MT Research Track Boston, March 17 - 21, 2018 |Page 40 Target-side MRL. The more challenging question of how to tackle rich morphology on the target side has undergone quite some research. Factored phrase-based models (Koehn and Hoang, 2007) can be used to produce inﬂected output via a separate decoding path and a generation step (Bojar, 2007). The blow-up of the search space can make such models impractical. Backoff techniques (Koehn and Haddow, 2012) or ﬂat factored models with supplementary features over lemmas and linguistic annotati"
W18-1805,2015.iwslt-evaluation.4,1,0.86099,"oceedings of AMTA 2018, vol. 1: MT Research Track Boston, March 17 - 21, 2018 |Page 40 Target-side MRL. The more challenging question of how to tackle rich morphology on the target side has undergone quite some research. Factored phrase-based models (Koehn and Hoang, 2007) can be used to produce inﬂected output via a separate decoding path and a generation step (Bojar, 2007). The blow-up of the search space can make such models impractical. Backoff techniques (Koehn and Haddow, 2012) or ﬂat factored models with supplementary features over lemmas and linguistic annotation (Stymne et al., 2008; Huck and Birch, 2015) are more tractable alternatives. Phrase-based translation models, accompanied with n-gram language models, have a relatively limited local view. Some morphological phenomena go beyond local context and require agreement across long distances. In syntax-based systems with a chart-based decoding procedure, engineering adequate agreement constraints is more viable (Williams and Koehn, 2011, 2014). Pursuing a different idea, Avramidis and Koehn (2008) and Daiber and Sima’an (2015) have attempted to annotate input sentences beforehand with morphological features that are exhibited by the target-si"
W18-1805,W17-4730,1,0.910587,"ely limited local view. Some morphological phenomena go beyond local context and require agreement across long distances. In syntax-based systems with a chart-based decoding procedure, engineering adequate agreement constraints is more viable (Williams and Koehn, 2011, 2014). Pursuing a different idea, Avramidis and Koehn (2008) and Daiber and Sima’an (2015) have attempted to annotate input sentences beforehand with morphological features that are exhibited by the target-side MRL, thus taking the burden of the inﬂection selection away from the phrase-based decoder. Chahuneau et al. (2013) and Huck et al. (2017c), on the other hand, have speciﬁcally looked into how to produce unseen morphological variants without resorting to a factored generation step. To that end, they augment their phrase tables with synthetic entries. Other researchers have proposed two-step approaches to MT into MRLs, where the output of the ﬁrst step (the actual translation) lacks certain morphological features of the MRL, which in turn have to be predicted by a separate module in a second step in order to end up with inﬂected target language sentences (Toutanova et al., 2008; Fraser et al., 2012). Slightly less supervision mi"
W18-1805,W17-4706,1,0.908664,"ely limited local view. Some morphological phenomena go beyond local context and require agreement across long distances. In syntax-based systems with a chart-based decoding procedure, engineering adequate agreement constraints is more viable (Williams and Koehn, 2011, 2014). Pursuing a different idea, Avramidis and Koehn (2008) and Daiber and Sima’an (2015) have attempted to annotate input sentences beforehand with morphological features that are exhibited by the target-side MRL, thus taking the burden of the inﬂection selection away from the phrase-based decoder. Chahuneau et al. (2013) and Huck et al. (2017c), on the other hand, have speciﬁcally looked into how to produce unseen morphological variants without resorting to a factored generation step. To that end, they augment their phrase tables with synthetic entries. Other researchers have proposed two-step approaches to MT into MRLs, where the output of the ﬁrst step (the actual translation) lacks certain morphological features of the MRL, which in turn have to be predicted by a separate module in a second step in order to end up with inﬂected target language sentences (Toutanova et al., 2008; Fraser et al., 2012). Slightly less supervision mi"
W18-1805,E17-2059,1,0.637994,"ely limited local view. Some morphological phenomena go beyond local context and require agreement across long distances. In syntax-based systems with a chart-based decoding procedure, engineering adequate agreement constraints is more viable (Williams and Koehn, 2011, 2014). Pursuing a different idea, Avramidis and Koehn (2008) and Daiber and Sima’an (2015) have attempted to annotate input sentences beforehand with morphological features that are exhibited by the target-side MRL, thus taking the burden of the inﬂection selection away from the phrase-based decoder. Chahuneau et al. (2013) and Huck et al. (2017c), on the other hand, have speciﬁcally looked into how to produce unseen morphological variants without resorting to a factored generation step. To that end, they augment their phrase tables with synthetic entries. Other researchers have proposed two-step approaches to MT into MRLs, where the output of the ﬁrst step (the actual translation) lacks certain morphological features of the MRL, which in turn have to be predicted by a separate module in a second step in order to end up with inﬂected target language sentences (Toutanova et al., 2008; Fraser et al., 2012). Slightly less supervision mi"
W18-1805,2005.mtsummit-papers.11,0,0.216382,"nd-to-end NLP system that involves our tagger, one would typically strive for a good match between the training data of the tagger and the training data of the other components, so as to achieve ideal interaction between them. But corpora that are manually annotated with lemma and ﬁne-grained POS will rarely ever be at hand for most tasks. Common practice in most practical scenarios would be to synthetically annotate the task-speciﬁc training corpus. We follow this real-world rationale and work with synthetic annotation in our study. Data and preprocessing. We train on the Europarl v7 corpus (Koehn, 2005). The conventional Europarl test sets (test2006, test2007, test2008) that had been released for the WMT shared task are used for development and testing.1 Our main tagging evaluation results will be reported on test2007, which we abbreviate as test in most tables, while test2006 serves as our dev set. The corpora are tokenized and frequent-cased using scripts from the Moses toolkit.2 They are then annotated with lemmas, POS tags, and morphological tags with the pretrained tagging model for German provided by the M AR M OT toolkit.3 M AR M OT is a CRF-based tagger with a reported accuracy of 97"
W18-1805,2012.amta-papers.9,0,0.045504,"dergoes heavy morphosyntactic analysis and preprocessing on the source side (Lee, 2004; Habash and Sadat, 2006; Hasan et al., 2011). Proceedings of AMTA 2018, vol. 1: MT Research Track Boston, March 17 - 21, 2018 |Page 40 Target-side MRL. The more challenging question of how to tackle rich morphology on the target side has undergone quite some research. Factored phrase-based models (Koehn and Hoang, 2007) can be used to produce inﬂected output via a separate decoding path and a generation step (Bojar, 2007). The blow-up of the search space can make such models impractical. Backoff techniques (Koehn and Haddow, 2012) or ﬂat factored models with supplementary features over lemmas and linguistic annotation (Stymne et al., 2008; Huck and Birch, 2015) are more tractable alternatives. Phrase-based translation models, accompanied with n-gram language models, have a relatively limited local view. Some morphological phenomena go beyond local context and require agreement across long distances. In syntax-based systems with a chart-based decoding procedure, engineering adequate agreement constraints is more viable (Williams and Koehn, 2011, 2014). Pursuing a different idea, Avramidis and Koehn (2008) and Daiber and"
W18-1805,D07-1091,0,0.0452999,"forehand. Non-reversible modiﬁcations are uncritical on the source side and can potentially alleviate the modeling problem and counteract data sparsity. Arabic is a prominent example of a language that typically undergoes heavy morphosyntactic analysis and preprocessing on the source side (Lee, 2004; Habash and Sadat, 2006; Hasan et al., 2011). Proceedings of AMTA 2018, vol. 1: MT Research Track Boston, March 17 - 21, 2018 |Page 40 Target-side MRL. The more challenging question of how to tackle rich morphology on the target side has undergone quite some research. Factored phrase-based models (Koehn and Hoang, 2007) can be used to produce inﬂected output via a separate decoding path and a generation step (Bojar, 2007). The blow-up of the search space can make such models impractical. Backoff techniques (Koehn and Haddow, 2012) or ﬂat factored models with supplementary features over lemmas and linguistic annotation (Stymne et al., 2008; Huck and Birch, 2015) are more tractable alternatives. Phrase-based translation models, accompanied with n-gram language models, have a relatively limited local view. Some morphological phenomena go beyond local context and require agreement across long distances. In synta"
W18-1805,D15-1025,0,0.0526097,"Missing"
W18-1805,N16-1030,0,0.0327702,"ree features described above. The one-hot vector representations are then projected into real-valued dense vector representations (embeddings). The lemma, the capitalization, and the sufﬁx embeddings are then concatenated in order to obtain a single vector representation for each input symbol. The central body of the architecture are three stacked bidirectional recurrent layers, using GRUs as recurrent cells. The choice of bidirectional recurrent layers over traditional feedforward layer was motivated by the promising results obtained in other labeling tasks, such as named entity recognition (Lample et al., 2016). The use of GRUs was preferred over LSTMs because their simpler internal structure allows for faster training, showing comparable results in preliminary experiments. Inspired by Heigold et al. (2016), we add skip connections between the ﬁrst and the third bidirectional recurrent layer to allow for direct propagation of information between layers at different levels of depth. At the top of the architecture, a time-distributed densely-connected layer produces one |T |-dimensional vector per time step, where |T |is the tagset size. Finally, the output label at each time step is given by a softma"
W18-1805,N04-4015,0,0.0738797,"lyzers can be employed, based on which a source sentence representation can be constructed which is more appropriate as the input to a translation system (Popovi´c and Ney, 2004; Popovi´c et al., 2005; Goldwater and McClosky, 2005). E.g., certain morphological features of the source words may be dismissed beforehand. Non-reversible modiﬁcations are uncritical on the source side and can potentially alleviate the modeling problem and counteract data sparsity. Arabic is a prominent example of a language that typically undergoes heavy morphosyntactic analysis and preprocessing on the source side (Lee, 2004; Habash and Sadat, 2006; Hasan et al., 2011). Proceedings of AMTA 2018, vol. 1: MT Research Track Boston, March 17 - 21, 2018 |Page 40 Target-side MRL. The more challenging question of how to tackle rich morphology on the target side has undergone quite some research. Factored phrase-based models (Koehn and Hoang, 2007) can be used to produce inﬂected output via a separate decoding path and a generation step (Bojar, 2007). The blow-up of the search space can make such models impractical. Backoff techniques (Koehn and Haddow, 2012) or ﬂat factored models with supplementary features over lemmas"
W18-1805,D13-1032,0,0.0667204,"Missing"
W18-1805,D15-1272,1,0.910056,"Missing"
W18-1805,W17-4708,0,0.0222711,"ed by Costa-Juss`a and Escolano (2016) would not generalize to other language pairs. 6 Conclusion This work introduces a system for morphological tagging over lemmatized (that is, completely unspeciﬁed) input sequences. A detailed intrinsic and extrinsic evaluation showed that our language independent tagger reaches a very high performance by jointly predicting up to 8 morphological features, leading up to 678 possible combinations (considering POS+morph labels). As a next step we will explore the implementation of a a multi-task system which produces pairs of lemmas and morphological labels. Niehues and Cho (2017) explored a multi-task NMT system producing coarse POS labels for the source language as well as words in the target language. We will instead produce lemmas in the target language, and at the same time use our tagger component to produce rich target POS. By giving our tagger access to the source sentences, we will overcome the limitations in our currently semantically underspeciﬁed representation, where, e.g., plural is not marked. Importantly, we will be able to train this system in a multitask fashion, where some training examples contain source language text (from parallel data), while oth"
W18-1805,P02-1040,0,0.102891,"al., 2017). We train and test on the English–German Europarl data. In the NMT systems’ training corpus, words are tokenized and frequent-cased, then segmented via byte-pair-encoding (BPE) (Sennrich et al., 2016) with 50K merge operations; likewise for lemmas, but with BPE operations extracted from the lemmatized data. We conﬁgure dimensions of 500 for the embeddings and 1024 for the hidden layer. We train with the Adam optimizer, a learning rate of 0.0001, batch size of 50, and dropout with probability 0.2 applied to the hidden layer. Translation quality is measured case-sensitive with B LEU (Papineni et al., 2002). In Table 7, we use B LEU computed on lemmas (Lemma-B LEU), to show that we get a small gain in lexical choice (of the lemma) in the pipelined approach, where the NMT engine is trained to produce lemmas. However, the B LEU scores over fully inﬂected words in Table 8 suggest that a simple pipelined approach is not sufﬁcient for end-to-end MT. We looked at the MT output and saw that it was mostly coherent, but there was confusion on features like number, tense, and mood. The slightly improved lexical choice of the lemma does not compensate for the loss that derives from the inherent limitations"
W18-1805,popovic-ney-2004-towards,0,0.148929,"Missing"
W18-1805,W05-0806,0,0.120155,"Missing"
W18-1805,E17-3017,0,0.0333304,"Missing"
W18-1805,P16-1162,0,0.246992,"upervision might be required by another technique for tackling rich morphology on the target side: word segmentation, and subsequent modeling on a subword level. Inﬂected target words in the training data can e.g. be segmented into stems and morphological afﬁxes (Fishel and Kirik, 2010; Clifton and Sarkar, 2011; Passban et al., 2017). The segmentation of output hypotheses of the MT system needs to be reverted in postprocessing. In modern neural machine translation engines, word segmentation by means of a Byte Pair Encoding (BPE) style algorithm is a common trick to shrink the vocabulary size (Sennrich et al., 2016). Recent research has shown that NMT of MRLs beneﬁts from word segmentation techniques that are linguistically more informed than plain BPE (Ataman et al., 2017; Pinnis et al., 2017; Huck et al., 2017b,a). Not all prior research on MRLs in traditional phrase-based MT can be readily transferred to NMT. One of the most promising attemps to date is following the theme of two-step MT. A second-step module generates inﬂections from lemmas and morphological tags. The ﬁrst-step NMT module outputs interleaved sequences of such lemmas and their respective tags (Burlot et al., 2016, 2017; Tamchyna et al"
W18-1805,W08-0317,0,0.0311946,"san et al., 2011). Proceedings of AMTA 2018, vol. 1: MT Research Track Boston, March 17 - 21, 2018 |Page 40 Target-side MRL. The more challenging question of how to tackle rich morphology on the target side has undergone quite some research. Factored phrase-based models (Koehn and Hoang, 2007) can be used to produce inﬂected output via a separate decoding path and a generation step (Bojar, 2007). The blow-up of the search space can make such models impractical. Backoff techniques (Koehn and Haddow, 2012) or ﬂat factored models with supplementary features over lemmas and linguistic annotation (Stymne et al., 2008; Huck and Birch, 2015) are more tractable alternatives. Phrase-based translation models, accompanied with n-gram language models, have a relatively limited local view. Some morphological phenomena go beyond local context and require agreement across long distances. In syntax-based systems with a chart-based decoding procedure, engineering adequate agreement constraints is more viable (Williams and Koehn, 2011, 2014). Pursuing a different idea, Avramidis and Koehn (2008) and Daiber and Sima’an (2015) have attempted to annotate input sentences beforehand with morphological features that are exh"
W18-1805,W17-4704,1,0.890649,"Missing"
W18-1805,P08-1059,0,0.138821,"This task was previously studied by Minkov et al. (2007). We differ in two ways: (1.) we implement a state-of-the-art neural tagger, rather than a Maximum Entropy Markov model, and (2.) we predict rich morphological POS, rather than surface forms. Studying the prediction of morphologically rich POS given lemmas is an interesting problem in its own right. It has implications for NLP applications involving the generation of MRL sentences including machine translation. A concrete application is to apply it in an end-to-end MT system. Similar morphological prediction systems have been applied by Toutanova et al. (2008), Bojar and Kos (2010) and Fraser et al. (2012) in phrase-based SMT. A pipeline of such a system is depicted in Figure 1. Given the promising results in this initial study, we plan to combine our tagger with a standard neural machine translation model, resulting in a multi-task system which produces pairs of lemmas and morphologically rich POS tags. An important beneﬁt of such a system over previous approaches which produce such pairs directly using a standard NMT model (e.g., Tamchyna et al. (2017)) is that we will be able to train it in a multi-task fashion, where some Proceedings of AMTA 20"
W18-1805,P17-1184,0,0.0149416,"Pinnis et al., 2017; Huck et al., 2017b,a). Not all prior research on MRLs in traditional phrase-based MT can be readily transferred to NMT. One of the most promising attemps to date is following the theme of two-step MT. A second-step module generates inﬂections from lemmas and morphological tags. The ﬁrst-step NMT module outputs interleaved sequences of such lemmas and their respective tags (Burlot et al., 2016, 2017; Tamchyna et al., 2017). Research on how to best model morphology with neural networks is ongoing, in MT and in other areas of NLP (Botha and Blunsom, 2014; Ebert et al., 2016; Vania and Lopez, 2017; Belinkov et al., 2017; Garc´ıa-Mart´ınez et al., 2016; Garc´ıa-Mart´ınez et al., 2017; Burlot and Yvon, 2017). 2.2 Morphological Tagging of Lemmas: Utility and Limitations Morphological tagging is the task of marking up each token in an input sequence with the corresponding morphological features which describe its inﬂectional properties. In the case of morphologically poor languages, a word can usually be described sufﬁciently using information about its POS tag (Mueller et al., 2013). MRLs require a more detailed analysis. The term MRL refers to a language where word shapes encode a consis"
W18-1805,W11-2126,0,0.0207826,"-up of the search space can make such models impractical. Backoff techniques (Koehn and Haddow, 2012) or ﬂat factored models with supplementary features over lemmas and linguistic annotation (Stymne et al., 2008; Huck and Birch, 2015) are more tractable alternatives. Phrase-based translation models, accompanied with n-gram language models, have a relatively limited local view. Some morphological phenomena go beyond local context and require agreement across long distances. In syntax-based systems with a chart-based decoding procedure, engineering adequate agreement constraints is more viable (Williams and Koehn, 2011, 2014). Pursuing a different idea, Avramidis and Koehn (2008) and Daiber and Sima’an (2015) have attempted to annotate input sentences beforehand with morphological features that are exhibited by the target-side MRL, thus taking the burden of the inﬂection selection away from the phrase-based decoder. Chahuneau et al. (2013) and Huck et al. (2017c), on the other hand, have speciﬁcally looked into how to produce unseen morphological variants without resorting to a factored generation step. To that end, they augment their phrase tables with synthetic entries. Other researchers have proposed two"
W18-1805,W14-1005,0,0.0606081,"Missing"
W18-6428,Q17-1010,0,0.299394,"sentence we induce its translation: where λ is a weighting constant and orth(w1 , w2 ) is the normalized Levenshtein distance of words w1 and w2 . As a contrastive set of experiments we added light supervision during the training of bilingual word embeddings in order to show performance differences compared to the fully unsupervised setup. To map monolingual spaces we used orthogonal mapping (Xing et al., 2015) with a seed lexicon of of 5000 word pairs, which was used as a baseline in (Conneau et al., 2017) as well. 2.1 Technical Details To train monolingual word embeddings we used fasttext (Bojanowski et al., 2017) which employs subword information for better quality representations. We used 512 dimensional embeddings and default values for the rest of the parameters. For both unsupervised and lightly supervised mapping we used MUSE (Conneau et al., 2017) with default parameters. We fine-tuned λ on the test set of WMT 2017 and used the method of (Mikolov et al., 2013) to mine frequent bigrams. trwbw (ws ) = arg max cos(e(ws ), e(w)) w∈Vt where e(w) is the vector representation of word w, cos(x, y) is the cosine similarity of two vectors and Vt is the target vocabulary. One problem with the approach aris"
W18-6428,N12-1047,0,0.0167383,"bw” experiment from Table 1. We use the Moses decoder to perform monotonic word-by-word translation without a language model (LM) or any other feature functions except for the single translation model (TM) score that we obtain from the cosine similarities. If we add a 4-gram LM and heuristically weight the LM feature function with a scaling factor of 0.1 and the TM with 0.9 (second line in Table 2), the translation quality improves by more than 2.5 BLEU points in both of the two translation directions. By using a small parallel development set (newstest2016) to tune the two weights with MIRA (Cherry and Foster, 2012) (third line), we barely improve over our guessed scaling factors of 0.1 for the LM and 0.9 for the TM. Optimized scaling factors are however more relevant when we allow for reordering (fourth line), since we then activate a third feature function, namely a distance-based distortion cost. This adds another scaling factor, and a good informed guess of reasonable values for three weights becomes increasingly difficult. Activated reordering with tuned weights boosts our translation quality further. We can go beyond simple word-by-word translation if we add our BWE bigrams to the TM, thus also ena"
W18-6428,W17-4730,1,0.775314,"n and Language Processing participated in the WMT 2018 news translation shared task for English↔German translation. Specifically, we participated in the unsupervised learning task which focuses on training MT models without access to any parallel data. The team has a strong track record at previous WMT shared tasks (Bojar et al., 2017, 2016, 2015, 2014, 2013) working on SMT systems (Cap et al., 2014, 2015; Weller et al., 2013; Sajjad et al., 2013; Huck et al., 2016; Peter et al., 2016; Tamchyna et al., 2016) and proposed a top scoring linguistically informed neural machine translation system (Huck et al., 2017) based on human evaluation at WMT17. Neural machine translation (NMT) is state-ofthe-art in automatic translation. Attention-based neural sequence-to-sequence models (Bahdanau et al., 2015) have been established as the basis for most recent work in MT and furthermore, have been used to obtain best scoring systems at WMT in recent years (Bojar et al., 2017, 2016). Previous work and the best scoring systems at WMT also showed that NMT can be scaled to millions of sentence pairs and even achieve human parity (Hassan et al., 2018). However, this comes The systems we use for our submissions are bas"
W18-6428,W16-2315,1,0.718664,"translated data based on bilingual word embeddings, denoising and on-the-fly backtranslation. 1 Introduction The LMU Munich’s Center for Information and Language Processing participated in the WMT 2018 news translation shared task for English↔German translation. Specifically, we participated in the unsupervised learning task which focuses on training MT models without access to any parallel data. The team has a strong track record at previous WMT shared tasks (Bojar et al., 2017, 2016, 2015, 2014, 2013) working on SMT systems (Cap et al., 2014, 2015; Weller et al., 2013; Sajjad et al., 2013; Huck et al., 2016; Peter et al., 2016; Tamchyna et al., 2016) and proposed a top scoring linguistically informed neural machine translation system (Huck et al., 2017) based on human evaluation at WMT17. Neural machine translation (NMT) is state-ofthe-art in automatic translation. Attention-based neural sequence-to-sequence models (Bahdanau et al., 2015) have been established as the basis for most recent work in MT and furthermore, have been used to obtain best scoring systems at WMT in recent years (Bojar et al., 2017, 2016). Previous work and the best scoring systems at WMT also showed that NMT can be scaled"
W18-6428,W18-6446,1,0.842817,"ram language model. The backbone of the unsupervised NMT methods is denoising and onthe-fly backtranslation which enable a standard NMT architecture to be trained by only leveraging monolingual data. The model for our submission is mostly based on the work of Lample et al. (2018b). Additionally, we explore how word-byword translated data based on BWEs can be utilized to improve the initial training and experiment with different ways of producing these translations. We also show that disabling denoising in the last stages of learning can provide for further improvements. We refer the reader to Huck et al. (2018) for our supervised systems for news and biomedical translation. 513 Proceedings of the Third Conference on Machine Translation (WMT), Volume 2: Shared Task Papers, pages 513–521 c Belgium, Brussels, October 31 - Novermber 1, 2018. 2018 Association for Computational Linguistics https://doi.org/10.18653/v1/W18-64055 To further improve the quality of our algorithm, we exploited orthographic similarity of words. Braune et al. (2018) showed that the performance of inducing word translations can be significantly improved using orthography. Following the approach there, we obtained improvements, esp"
W18-6428,P07-2045,0,0.0187359,"e. By training bilingual word embeddings on this data we automatically allow the word-by-word algorithm to translate compound words to bigrams and vice-versa. 3 Unsupervised Phrase-based Translation We have investigated unsupervised phrase-based translation (PBT). The results have been worse than with the neural model in our experiments. In this section, we therefore only give a short outline of the methods which we have explored in that area. By means of a straightforward format conversion of the BWE lexicon, we can create a wordbased “phrase table” that can be loaded into the Moses decoder (Koehn et al., 2007). The cosine similarities from the BWE model become feature scores in the phrase table. Note that we refrained from normalizing the cosine similarities, but wrote their values directly to the table. 514 The model proposed in Lample et al. (2018b) consists of two main components, a denoising and a translation component. The denoising part acts as a language model and is trained to produce fluent output in a given language based on a noisy version of the input. We follow the implementation of Artetxe et al. (2018) where the noisy version of the input sentence is obtained by making random swaps o"
W18-6428,N15-1104,0,0.0355326,"mbeddings, trained in an unsupervised fashion, to jump-start both of our systems. As our baseline system we produce word-byword translations relying only on the embeddings. For each word ws in the source sentence we induce its translation: where λ is a weighting constant and orth(w1 , w2 ) is the normalized Levenshtein distance of words w1 and w2 . As a contrastive set of experiments we added light supervision during the training of bilingual word embeddings in order to show performance differences compared to the fully unsupervised setup. To map monolingual spaces we used orthogonal mapping (Xing et al., 2015) with a seed lexicon of of 5000 word pairs, which was used as a baseline in (Conneau et al., 2017) as well. 2.1 Technical Details To train monolingual word embeddings we used fasttext (Bojanowski et al., 2017) which employs subword information for better quality representations. We used 512 dimensional embeddings and default values for the rest of the parameters. For both unsupervised and lightly supervised mapping we used MUSE (Conneau et al., 2017) with default parameters. We fine-tuned λ on the test set of WMT 2017 and used the method of (Mikolov et al., 2013) to mine frequent bigrams. trwb"
W18-6428,W17-3204,0,0.0283197,"Missing"
W18-6428,J82-2005,0,0.777273,"Missing"
W18-6428,P02-1040,0,0.109099,"5 We also apply BPE splitting on this data before using it in training. After a certain number of iterations, we stop with the training of the initial model and “unplug” two components of the previous training procedure. Namely, we remove the word-by-word translated data since this is useful to jump-start the learning, but later presumably will impede learning more nuanced translations. We also observe better results if we disable the denoising component and continue the training by only doing onthe-fly backtranslation. This improved results on both translation directions by more than 1 BLEU (Papineni et al., 2002). However, in subsequent experiments we observed that this can also lead to unstable learning and decrease the performance since bad translation decisions can be reinforced. As a result, the final training procedure should be carefully controlled. As mentioned in Section 2, the model has problems translating named entities. This stems from the fact that it is dependent on BWEs, where two different named entities often mistakenly have similar representations, causing confusion. Following the improvements the word-by-word translation obtained by using orthographic similarity, we also try trainin"
W18-6428,W13-2228,1,0.765538,"as using word-by-word translated data based on bilingual word embeddings, denoising and on-the-fly backtranslation. 1 Introduction The LMU Munich’s Center for Information and Language Processing participated in the WMT 2018 news translation shared task for English↔German translation. Specifically, we participated in the unsupervised learning task which focuses on training MT models without access to any parallel data. The team has a strong track record at previous WMT shared tasks (Bojar et al., 2017, 2016, 2015, 2014, 2013) working on SMT systems (Cap et al., 2014, 2015; Weller et al., 2013; Sajjad et al., 2013; Huck et al., 2016; Peter et al., 2016; Tamchyna et al., 2016) and proposed a top scoring linguistically informed neural machine translation system (Huck et al., 2017) based on human evaluation at WMT17. Neural machine translation (NMT) is state-ofthe-art in automatic translation. Attention-based neural sequence-to-sequence models (Bahdanau et al., 2015) have been established as the basis for most recent work in MT and furthermore, have been used to obtain best scoring systems at WMT in recent years (Bojar et al., 2017, 2016). Previous work and the best scoring systems at WMT also showed that"
W18-6428,W16-2325,1,0.835038,"d embeddings, denoising and on-the-fly backtranslation. 1 Introduction The LMU Munich’s Center for Information and Language Processing participated in the WMT 2018 news translation shared task for English↔German translation. Specifically, we participated in the unsupervised learning task which focuses on training MT models without access to any parallel data. The team has a strong track record at previous WMT shared tasks (Bojar et al., 2017, 2016, 2015, 2014, 2013) working on SMT systems (Cap et al., 2014, 2015; Weller et al., 2013; Sajjad et al., 2013; Huck et al., 2016; Peter et al., 2016; Tamchyna et al., 2016) and proposed a top scoring linguistically informed neural machine translation system (Huck et al., 2017) based on human evaluation at WMT17. Neural machine translation (NMT) is state-ofthe-art in automatic translation. Attention-based neural sequence-to-sequence models (Bahdanau et al., 2015) have been established as the basis for most recent work in MT and furthermore, have been used to obtain best scoring systems at WMT in recent years (Bojar et al., 2017, 2016). Previous work and the best scoring systems at WMT also showed that NMT can be scaled to millions of sentence pairs and even achie"
W18-6428,W13-2230,1,0.856869,"osed techniques such as using word-by-word translated data based on bilingual word embeddings, denoising and on-the-fly backtranslation. 1 Introduction The LMU Munich’s Center for Information and Language Processing participated in the WMT 2018 news translation shared task for English↔German translation. Specifically, we participated in the unsupervised learning task which focuses on training MT models without access to any parallel data. The team has a strong track record at previous WMT shared tasks (Bojar et al., 2017, 2016, 2015, 2014, 2013) working on SMT systems (Cap et al., 2014, 2015; Weller et al., 2013; Sajjad et al., 2013; Huck et al., 2016; Peter et al., 2016; Tamchyna et al., 2016) and proposed a top scoring linguistically informed neural machine translation system (Huck et al., 2017) based on human evaluation at WMT17. Neural machine translation (NMT) is state-ofthe-art in automatic translation. Attention-based neural sequence-to-sequence models (Bahdanau et al., 2015) have been established as the basis for most recent work in MT and furthermore, have been used to obtain best scoring systems at WMT in recent years (Bojar et al., 2017, 2016). Previous work and the best scoring systems at"
W18-6446,P13-1141,0,0.0165164,"18. 2018 Association for Computational Linguistics https://doi.org/10.18653/v1/W18-64073 single hidden layer. We configure dimensions of 500 for the embeddings and 1024 for the hidden layer. We train with the Adam optimizer (Kingma and Ba, 2015), a learning rate of 0.0001, batch size of 50, and dropout with probability 0.2 applied to the hidden layer, but not to source, target, and embeddings. We validate every 10 000 updates and do early stopping when the validation cost has not decreased over ten consecutive control points. from their respective meaning in out-of-domain corpora) are common (Carpuat et al., 2013; Irvine et al., 2013). Domain adaptation of conventional phrasebased machine translation systems is a wellexplored research area. Several different effective solutions which may be used in order to domain-adapt a phrase-based system have been proposed in the literature. (Inter alia, cf. Huck et al. (2015) for a few interesting empirical results and a list of some major bibliographic references.) Machine translation in academic research labs and also in industry is however going through a paradigm shift away from phrase-based technology and on towards artificial neural network models. Neural m"
W18-6446,W18-1805,1,0.839485,"on machine translation of news (Huck et al., 2017a). At WMT17, LMU’s primary submission was ranked first in the human evaluation (Bojar et al., 2017a). We presume that the high human rating of LMU’s WMT17 submission can mostly be attributed to our efforts toward better word segmentation. We anticipate similar benefits in the medical domain. Dedicated methods that tackle rich target-side morphology have also shown good results in phrase-based translation systems previously (Huck et al., 2017c). Future work on neural machine translation could for instance follow a two-step prediction paradigm (Conforti et al., 2018), or improve over our current version of linguistically informed word segmentation by means of a better linguistic analysis (Weissweiler and Fraser, 2017). In the present work, the linguistically informed word segmentation is not only employed on the target side for English→German machine translation, but in German→English systems also on the source language side. The English language side is always simply BPE-segmented. We learn the compound split model and the BPE merge operations from Europarl and use this word segmentation and vocabulary for all corpora. 5 5.1 5.2 English→German Transforme"
W18-6446,2005.mtsummit-papers.11,0,0.151966,"texts. The types of medical texts that we consider range from health information leaflets to professional biomedical research articles. Some of our latest research towards medical domain adapation of neural translation systems is inspired by the “fine-tuning” approach in combination with high-quality in-domain data. Specifically, we conducted successive optimization runs to domain-adapt a neural translation model. The 2 Domain Adaptation Medical texts differ in their style and in their topics from the typical content of many widely used training corpora, such as the parallel Europarl corpus (Koehn, 2005) or most of the large monolingual corpora that are distributed for the WMT shared task on machine translation of news (Bojar et al., 2018, 2017a, 2016, 2015). Medical documents also often contain a large amount of domain-specific technical terms in their vocabulary. Furthermore, sense shifts of words (away 1 http://www.statmt.org/wmt18/ biomedical-translation-task.html 2 http://www.statmt.org/wmt18/ translation-task.html 3 http://www.himl.eu 4 LMU’s unsupervised machine translation system for the news task is described in a separate paper (Stojanovski et al., 2018). 648 Proceedings of the Thir"
W18-6446,E03-1076,0,0.0910321,"development, as stated in the table. As a last step, we apply n-best list reranking (n = 50) with a rightto-left NMT model (“r2l reranking”). Ensembling did not yield any clear gains, so we deployed single models for English→German. The bottom row of Table 1 contains the B LEU scores of our last year’s primary system (Huck et al., 2017a) for the WMT17 biomedical task (Yepes et al., 2017). We improve over it by more than three points. ball stemming algorithm that separtates suffixes from the word stem, rather than stripping them. 2. Next we apply the empirical compound splitter as described by Koehn and Knight (2003). 3. We finally apply the Byte Pair Encoding (BPE) technique (Sennrich et al., 2016b) on top of the suffix-split and compound-split data in order to further reduce the vocabulary size. Special marker symbols allow us to revert the segmentation in postprocessing when German is the target language. Our linguistically informed word segmentation was already used on the target language side for LMU’s participation in the WMT17 shared task on machine translation of news (Huck et al., 2017a). At WMT17, LMU’s primary submission was ranked first in the human evaluation (Bojar et al., 2017a). We presume"
W18-6446,E17-3017,0,0.393967,"optimization run the parameters are initialized with the trained model parameters from the previous optimization. A crucial aspect is the availability of high-quality indomain training data, or alternatively, the collection thereof. If a general-domain or out-of-domain neural model from a first optimization run already exists, then fine-tuning allows for quick adjustment of the model to a specific domain by means of a short continued optimization on an in-domain corpus, most often with less data than in the first run. 3 3.1 3.2 Transformer We use the Sockeye implementation of the Transformer (Hieber et al., 2017). For the German→English translation direction we train small Transformer models and for English→German big models as outlined in Vaswani et al. (2017). All models have six encoder and decoder layers. The size of the layers and the embeddings is 512 for the small models and 1024 for the big ones. The dimensionality of the feed-forward networks is 2048 (small) and 4096 (big). We use 8 attention heads for the small and 16 for the big models. The models are trained with the Adam optimizer with an initial learning rate of 0.0002. The learning rate is reduced by a factor of 0.7 if not improved for"
W18-6446,2015.mtsummit-papers.19,1,0.910911,"probability 0.2 applied to the hidden layer, but not to source, target, and embeddings. We validate every 10 000 updates and do early stopping when the validation cost has not decreased over ten consecutive control points. from their respective meaning in out-of-domain corpora) are common (Carpuat et al., 2013; Irvine et al., 2013). Domain adaptation of conventional phrasebased machine translation systems is a wellexplored research area. Several different effective solutions which may be used in order to domain-adapt a phrase-based system have been proposed in the literature. (Inter alia, cf. Huck et al. (2015) for a few interesting empirical results and a list of some major bibliographic references.) Machine translation in academic research labs and also in industry is however going through a paradigm shift away from phrase-based technology and on towards artificial neural network models. Neural machine translation (Sutskever et al., 2014; Bahdanau et al., 2014) is the new state of the art for basically all medium- to highresource language pairs since around two to three years. The paradigm shift poses new challenges in domain adaptation, since most known techniques are rather specific to the phras"
W18-6446,W11-2132,0,0.114925,"stem, but participated with our system from WMT17 (Bojar et al., 2017a). The system was trained under “constrained” conditions, employing only permissible resources as defined by the shared task organizers. Huck et al. (2017a) provide a detailed description, along with experimental results. In short, we conducted the following steps in an incremental training regime (with consecutive optimizations, in a similar manner as presented above for the HimL Y3 system): 1. Optimize a Europarl baseline model. 2. Add News Commentary and Common Crawl. 3. Add synthetic training data (Ueffing et al., 2007; Lambert et al., 2011; Huck et al., 2011; Huck and Ney, 2012; Sennrich et al., 2016a). 4. Fine-tune towards the domain of news articles. For that purpose, several newstest development sets are employed as a training corpus. The learning rate is decreased. 5. Rerank n-best list with a right-to-left neural model (Liu et al., 2016), which is trained for reverse word order (Freitag et al., 2013). German→English Transformer System Our German→English Transformer model is an ensemble of three separate models, like in the English→German translation direction. We use the same training corpus, but with source and target sid"
W18-6446,W17-4730,1,0.398125,"Matthias Huck and Dario Stojanovski and Viktor Hangya and Alexander Fraser Center for Information and Language Processing LMU Munich Munich, Germany {mhuck,stojanovski,hangyav,fraser}@cis.lmu.de Abstract model was eventually deployed as the core component of the final English→German HimL translation engine in year 3 of the project (Y3). In this paper, we give a brief technical overview of the HimL Y3 engine’s neural translation model for English→German. We will show by how much the translation quality of medical texts improves compared to our previous year’s WMT17 biomedical task submission (Huck et al., 2017a). We then proceed to compare with a Transformer model (Vaswani et al., 2017) that we have trained after the end of the HimL project. We find that the Transformer model performs even better than the HimL Y3 engine, which was based on Nematus (Sennrich et al., 2017) with a single hidden layer. The good result encouraged us to try out the Transformer in the other translation direction, German→English. We will also report the German→English results. In addition to the English–German biomedical task, LMU Munich has participated in the WMT18 English–German news translation task (Bojar et al., 2018"
W18-6446,N16-1046,0,0.0395691,"Missing"
W18-6446,2012.amta-papers.8,1,0.776451,"om WMT17 (Bojar et al., 2017a). The system was trained under “constrained” conditions, employing only permissible resources as defined by the shared task organizers. Huck et al. (2017a) provide a detailed description, along with experimental results. In short, we conducted the following steps in an incremental training regime (with consecutive optimizations, in a similar manner as presented above for the HimL Y3 system): 1. Optimize a Europarl baseline model. 2. Add News Commentary and Common Crawl. 3. Add synthetic training data (Ueffing et al., 2007; Lambert et al., 2011; Huck et al., 2011; Huck and Ney, 2012; Sennrich et al., 2016a). 4. Fine-tune towards the domain of news articles. For that purpose, several newstest development sets are employed as a training corpus. The learning rate is decreased. 5. Rerank n-best list with a right-to-left neural model (Liu et al., 2016), which is trained for reverse word order (Freitag et al., 2013). German→English Transformer System Our German→English Transformer model is an ensemble of three separate models, like in the English→German translation direction. We use the same training corpus, but with source and target side switched. The preprocessing remains t"
W18-6446,P02-1040,0,0.103687,"ecture is flat, it has only one 649 tuning” (Section 2). First, we train a model on parallel corpora from the WMT news task. We then successively refine the model and adapt it to the medical domain. Consecutive optimization runs are initialized with the respective previous model parameters. For each refinement step, we replace the training data, first with larger corpora, then with corpora that better match the domain. The HimL tuning sets are used for validation, and we test separately on the Cochrane and NHS24 parts of the HimL devtest set.5 The translation quality (in case-sensitive B LEU (Papineni et al., 2002)) of different system setups after several development stages is presented in the top section of Table 1. WMT_parallel denotes the Europarl, News Commentary, and Common Crawl parallel training data as provided for WMT17 by the organizers of the news translation shared task. WMT_backtranslated_news_crawl denotes Edinburgh’s backtranslations of monolingual WMT News Crawl corpora from WMT16.6 Y3_base_general_data is a large collection of English–German bitext used in the HimL project. Cochrane-selected and NHS24-selected denote synthetic data mixes from HimL whose content is automatically filtere"
W18-6446,W17-4706,1,0.315058,"Matthias Huck and Dario Stojanovski and Viktor Hangya and Alexander Fraser Center for Information and Language Processing LMU Munich Munich, Germany {mhuck,stojanovski,hangyav,fraser}@cis.lmu.de Abstract model was eventually deployed as the core component of the final English→German HimL translation engine in year 3 of the project (Y3). In this paper, we give a brief technical overview of the HimL Y3 engine’s neural translation model for English→German. We will show by how much the translation quality of medical texts improves compared to our previous year’s WMT17 biomedical task submission (Huck et al., 2017a). We then proceed to compare with a Transformer model (Vaswani et al., 2017) that we have trained after the end of the HimL project. We find that the Transformer model performs even better than the HimL Y3 engine, which was based on Nematus (Sennrich et al., 2017) with a single hidden layer. The good result encouraged us to try out the Transformer in the other translation direction, German→English. We will also report the German→English results. In addition to the English–German biomedical task, LMU Munich has participated in the WMT18 English–German news translation task (Bojar et al., 2018"
W18-6446,E17-2059,1,0.900188,"Missing"
W18-6446,P16-1009,0,0.161609,"n = 50) with a rightto-left NMT model (“r2l reranking”). Ensembling did not yield any clear gains, so we deployed single models for English→German. The bottom row of Table 1 contains the B LEU scores of our last year’s primary system (Huck et al., 2017a) for the WMT17 biomedical task (Yepes et al., 2017). We improve over it by more than three points. ball stemming algorithm that separtates suffixes from the word stem, rather than stripping them. 2. Next we apply the empirical compound splitter as described by Koehn and Knight (2003). 3. We finally apply the Byte Pair Encoding (BPE) technique (Sennrich et al., 2016b) on top of the suffix-split and compound-split data in order to further reduce the vocabulary size. Special marker symbols allow us to revert the segmentation in postprocessing when German is the target language. Our linguistically informed word segmentation was already used on the target language side for LMU’s participation in the WMT17 shared task on machine translation of news (Huck et al., 2017a). At WMT17, LMU’s primary submission was ranked first in the human evaluation (Bojar et al., 2017a). We presume that the high human rating of LMU’s WMT17 submission can mostly be attributed to o"
W18-6446,P16-1162,0,0.307933,"n = 50) with a rightto-left NMT model (“r2l reranking”). Ensembling did not yield any clear gains, so we deployed single models for English→German. The bottom row of Table 1 contains the B LEU scores of our last year’s primary system (Huck et al., 2017a) for the WMT17 biomedical task (Yepes et al., 2017). We improve over it by more than three points. ball stemming algorithm that separtates suffixes from the word stem, rather than stripping them. 2. Next we apply the empirical compound splitter as described by Koehn and Knight (2003). 3. We finally apply the Byte Pair Encoding (BPE) technique (Sennrich et al., 2016b) on top of the suffix-split and compound-split data in order to further reduce the vocabulary size. Special marker symbols allow us to revert the segmentation in postprocessing when German is the target language. Our linguistically informed word segmentation was already used on the target language side for LMU’s participation in the WMT17 shared task on machine translation of news (Huck et al., 2017a). At WMT17, LMU’s primary submission was ranked first in the human evaluation (Bojar et al., 2017a). We presume that the high human rating of LMU’s WMT17 submission can mostly be attributed to o"
W18-6446,W18-6428,1,0.842817,"ra, such as the parallel Europarl corpus (Koehn, 2005) or most of the large monolingual corpora that are distributed for the WMT shared task on machine translation of news (Bojar et al., 2018, 2017a, 2016, 2015). Medical documents also often contain a large amount of domain-specific technical terms in their vocabulary. Furthermore, sense shifts of words (away 1 http://www.statmt.org/wmt18/ biomedical-translation-task.html 2 http://www.statmt.org/wmt18/ translation-task.html 3 http://www.himl.eu 4 LMU’s unsupervised machine translation system for the news task is described in a separate paper (Stojanovski et al., 2018). 648 Proceedings of the Third Conference on Machine Translation (WMT), Volume 2: Shared Task Papers, pages 648–654 c Belgium, Brussels, October 31 - Novermber 1, 2018. 2018 Association for Computational Linguistics https://doi.org/10.18653/v1/W18-64073 single hidden layer. We configure dimensions of 500 for the embeddings and 1024 for the hidden layer. We train with the Adam optimizer (Kingma and Ba, 2015), a learning rate of 0.0001, batch size of 50, and dropout with probability 0.2 applied to the hidden layer, but not to source, target, and embeddings. We validate every 10 000 updates and d"
W19-1425,P15-2044,0,0.0486182,"Missing"
W19-1425,J93-2003,0,0.0754235,"Missing"
W19-1425,Q16-1022,0,0.0464809,"Missing"
W19-1425,W03-0407,0,0.249056,"Missing"
W19-1425,D17-2008,0,0.0393799,"Missing"
W19-1425,N13-1073,0,0.0320339,".3 The idea of the cross-lingual transfer is to project tags from the annotated part of the parallel corpus to its unlabeled translation to produce training data for the under-resourced language. The success of cross-lingual transfer depends not only on the quality of the source language annotation, but also on the reliability of the annotation projection. We rely on standard statistical word alignment algorithms (Brown et al., 1993) as the basis of POS annotation projection from Russian to Ukrainian. The parallel corpus is aligned with fast align,10 an unsupervised word aligner introduced by Dyer et al. (2013). For phrasebased machine translation, the two alignment directions (forward and reverse) are typically combined to a symmetrized alignment. But for annotation projection, it is more convenient to use one-directional alignment with one Ukrainian token never being aligned to multiple tokens on the Russian side. The annotation projection across the alignment then becomes straightforward.11 No disambiguation heuristics are necessary, which could be a source of additional errors.12 The BLSTM tagger supervised with goldstandard Ukrainian annotation (Section 5.2.1) outperforms the cross-lingual tran"
W19-1425,L18-1344,0,0.0160892,"ing, annotation projection has been successfully applied to other tasks such as named entity recognition (Yarowsky et al., 2001; Enghoff et al., 2018), word sense tagging (Bentivogli et al., 2004), semantic role labeling (Pado and Lapata, 2005, 2009; van der Plas et al., 2011; Aminian et al., 2017), or dependency parsing (Hwa et al., 2005; Tiedemann, 2014; Rasooli and Collins, 2015; Agi´c et al., 2016; Aufrant et al., 2016). Kim et al. (2011) presented an integration into a full pipeline for information extraction. Open-source software tools for annotation projection are now available online (Akbik and Vollgraf, 2018, 2017). 3 Methods Research questions. We ask two central research questions in this work, one for each of the considered scenarios: Low-resource scenario: When the amount of hand-labeled training data is small for the targeted language, how effectively can we further improve the tagger by employing auxiliary resources? Specifically, how helpful is the use of additional unlabeled corpora (self-training) and corpora in a different language (multilingual learning)? Zero-resource scenario: When there isn’t any hand-labeled training data available for the targeted language, how effectively can we"
W19-1425,W18-6125,0,0.0365398,"Missing"
W19-1425,I17-2003,0,0.0204776,"et al. (2018). We follow up on this line of research with our work. original idea and reaffirms the efficacy of annotation projection also with a state-of-the-art neural sequence tagging model (Wang et al., 2015) and on the modern universal POS-annotation scheme (Petrov et al., 2012). Since 2001, in addition to POS-tagging, annotation projection has been successfully applied to other tasks such as named entity recognition (Yarowsky et al., 2001; Enghoff et al., 2018), word sense tagging (Bentivogli et al., 2004), semantic role labeling (Pado and Lapata, 2005, 2009; van der Plas et al., 2011; Aminian et al., 2017), or dependency parsing (Hwa et al., 2005; Tiedemann, 2014; Rasooli and Collins, 2015; Agi´c et al., 2016; Aufrant et al., 2016). Kim et al. (2011) presented an integration into a full pipeline for information extraction. Open-source software tools for annotation projection are now available online (Akbik and Vollgraf, 2018, 2017). 3 Methods Research questions. We ask two central research questions in this work, one for each of the considered scenarios: Low-resource scenario: When the amount of hand-labeled training data is small for the targeted language, how effectively can we further improv"
W19-1425,K16-1018,0,0.0772158,"POS-tagging was first explored by Yarowsky and Ngai (2001) for crosslingual transfer from English to French. Our basic approach shares much of Yarowsky and Ngai’s 223 Proceedings of VarDial, pages 223–233 c Minneapolis, MN, June 7, 2019 2019 Association for Computational Linguistics language-specific component integrated with another cross-lingually shared component. We are however not aware of many prior studies that systematically explore annotation projection for cross-lingual transfer in neural POS-tagging of living spoken languages. Steps in this direction have been taken only lately by Fang and Cohn (2016), Plank and Agi´c (2018) and Anastasopoulos et al. (2018). We follow up on this line of research with our work. original idea and reaffirms the efficacy of annotation projection also with a state-of-the-art neural sequence tagging model (Wang et al., 2015) and on the modern universal POS-annotation scheme (Petrov et al., 2012). Since 2001, in addition to POS-tagging, annotation projection has been successfully applied to other tasks such as named entity recognition (Yarowsky et al., 2001; Enghoff et al., 2018), word sense tagging (Bentivogli et al., 2004), semantic role labeling (Pado and Lapa"
W19-1425,C18-1214,0,0.024249,"gai (2001) for crosslingual transfer from English to French. Our basic approach shares much of Yarowsky and Ngai’s 223 Proceedings of VarDial, pages 223–233 c Minneapolis, MN, June 7, 2019 2019 Association for Computational Linguistics language-specific component integrated with another cross-lingually shared component. We are however not aware of many prior studies that systematically explore annotation projection for cross-lingual transfer in neural POS-tagging of living spoken languages. Steps in this direction have been taken only lately by Fang and Cohn (2016), Plank and Agi´c (2018) and Anastasopoulos et al. (2018). We follow up on this line of research with our work. original idea and reaffirms the efficacy of annotation projection also with a state-of-the-art neural sequence tagging model (Wang et al., 2015) and on the modern universal POS-annotation scheme (Petrov et al., 2012). Since 2001, in addition to POS-tagging, annotation projection has been successfully applied to other tasks such as named entity recognition (Yarowsky et al., 2001; Enghoff et al., 2018), word sense tagging (Bentivogli et al., 2004), semantic role labeling (Pado and Lapata, 2005, 2009; van der Plas et al., 2011; Aminian et al."
W19-1425,C16-1012,0,0.0201308,"ection also with a state-of-the-art neural sequence tagging model (Wang et al., 2015) and on the modern universal POS-annotation scheme (Petrov et al., 2012). Since 2001, in addition to POS-tagging, annotation projection has been successfully applied to other tasks such as named entity recognition (Yarowsky et al., 2001; Enghoff et al., 2018), word sense tagging (Bentivogli et al., 2004), semantic role labeling (Pado and Lapata, 2005, 2009; van der Plas et al., 2011; Aminian et al., 2017), or dependency parsing (Hwa et al., 2005; Tiedemann, 2014; Rasooli and Collins, 2015; Agi´c et al., 2016; Aufrant et al., 2016). Kim et al. (2011) presented an integration into a full pipeline for information extraction. Open-source software tools for annotation projection are now available online (Akbik and Vollgraf, 2018, 2017). 3 Methods Research questions. We ask two central research questions in this work, one for each of the considered scenarios: Low-resource scenario: When the amount of hand-labeled training data is small for the targeted language, how effectively can we further improve the tagger by employing auxiliary resources? Specifically, how helpful is the use of additional unlabeled corpora (self-traini"
W19-1425,P16-1101,0,0.0322322,"the works of Wisniewski et al. (2014), examining annotation projection for a CRF tagging model (Lavergne et al., 2010) on living spoken languages, and of Agi´c et al. (2015). Meyer (2011) tags Old Russian via annotation projection from modern Russian translations. Sukhareva et al. (2017) POStag the extinct Hittite language through projection from German. Recent related work on neural POS-tagging has mostly focused on robustness through character-level modeling (Heigold et al., 2016, 2018; dos Santos and Zadrozny, 2014; Labeau et al., 2015) or on architectural improvements (Huang et al., 2015; Ma and Hovy, 2016; Yasunaga et al., 2018). Kim et al. (2017) have proposed an interesting neural tagging architecture that allows for multilingual learning with a Neural tagging model. Depending on the context, the part-of-speech of a word may vary. E.g., the English word “green” takes a different POS (adjective, noun, verb) in each of the following three sentences: The recipe requires green mangoes. She took 63 shots to reach the green. How can we green our campus? The need to resolve such ambiguities is one of the challenges in POS-tagging, and is the reason why the task requires sequence labeling instead of"
W19-1425,de-marneffe-etal-2014-universal,0,0.0252309,"Missing"
W19-1425,D17-1302,0,0.0442782,"ining annotation projection for a CRF tagging model (Lavergne et al., 2010) on living spoken languages, and of Agi´c et al. (2015). Meyer (2011) tags Old Russian via annotation projection from modern Russian translations. Sukhareva et al. (2017) POStag the extinct Hittite language through projection from German. Recent related work on neural POS-tagging has mostly focused on robustness through character-level modeling (Heigold et al., 2016, 2018; dos Santos and Zadrozny, 2014; Labeau et al., 2015) or on architectural improvements (Huang et al., 2015; Ma and Hovy, 2016; Yasunaga et al., 2018). Kim et al. (2017) have proposed an interesting neural tagging architecture that allows for multilingual learning with a Neural tagging model. Depending on the context, the part-of-speech of a word may vary. E.g., the English word “green” takes a different POS (adjective, noun, verb) in each of the following three sentences: The recipe requires green mangoes. She took 63 shots to reach the green. How can we green our campus? The need to resolve such ambiguities is one of the challenges in POS-tagging, and is the reason why the task requires sequence labeling instead of just a simple dictionary lookup. Another c"
W19-1425,de-marneffe-etal-2006-generating,0,0.041623,"Missing"
W19-1425,I11-1083,0,0.0246701,"e-of-the-art neural sequence tagging model (Wang et al., 2015) and on the modern universal POS-annotation scheme (Petrov et al., 2012). Since 2001, in addition to POS-tagging, annotation projection has been successfully applied to other tasks such as named entity recognition (Yarowsky et al., 2001; Enghoff et al., 2018), word sense tagging (Bentivogli et al., 2004), semantic role labeling (Pado and Lapata, 2005, 2009; van der Plas et al., 2011; Aminian et al., 2017), or dependency parsing (Hwa et al., 2005; Tiedemann, 2014; Rasooli and Collins, 2015; Agi´c et al., 2016; Aufrant et al., 2016). Kim et al. (2011) presented an integration into a full pipeline for information extraction. Open-source software tools for annotation projection are now available online (Akbik and Vollgraf, 2018, 2017). 3 Methods Research questions. We ask two central research questions in this work, one for each of the considered scenarios: Low-resource scenario: When the amount of hand-labeled training data is small for the targeted language, how effectively can we further improve the tagger by employing auxiliary resources? Specifically, how helpful is the use of additional unlabeled corpora (self-training) and corpora in"
W19-1425,W08-1301,0,0.0683455,"Missing"
W19-1425,D15-1025,0,0.0739305,"Missing"
W19-1425,N06-1020,0,0.101571,"at, a tagger for the resource-poor language can be trained on the target side of the parallel corpus with its associated projected automatic sourceside annotation. This provides another solution in the case of a complete lack of gold-standard training data, the zero-resource scenario. Given sufficient amount of labeled data, it is possible to build high-performance tools with direct supervision, but since there are languages that do not have enough suitable data to train a model, it is reasonable to employ semi-supervised methods. Those include self-training, which was previously discussed by McClosky et al. (2006), inter alia. Self-training requires labeled and unlabeled data and can be applied to low-resource languages. “Semi-supervised and unsupervised methods are important because good labeled data is expensive, whereas there is no shortage of unlabeled data” (McClosky et al., 2006). 3.2 Multilingual Learning The multilingual learning method is suitable for under-resourced languages with little annotated data. The training set is enlarged through the texts of a related language. The idea is to shuffle original Ukrainian training sentences with the Russian labeled data to get more annotated texts. 3."
W19-1425,N16-1121,0,0.0208622,"beled corpora (self-training) and corpora in a different language (multilingual learning)? Zero-resource scenario: When there isn’t any hand-labeled training data available for the targeted language, how effectively can we harness knowledge from annotated corpora in a different, but related language? Specifically, is tagging quality close to supervised low-resource conditions attainable with either a plain foreign-language tagging model (zero-shot tagging) or via annotation projection from a foreign language (cross-lingual transfer)? To avoid unnecessarily noisy data, unlike previous authors, Lacroix et al. (2016) did not apply heuristics to fix certain word alignment links that pose difficulties to annotation projection. They demonstrated that it is simpler and more effective to ignore unaligned words as well as many-tomany alignments. In our work, we likewise settle on a simple technique based on a one-directional word alignment. Xi and Hwa (2005) have combined projected POS-annotation with a small manually annotated corpus in a low-resource scenario. Newer research on annotation projection for POS-tagging has looked at historical languages (Meyer, 2011; ¨ Sukhareva et al., 2017) and sign language (O"
W19-1425,W15-1834,0,0.057528,"Missing"
W19-1425,H05-1108,0,0.0625267,"d Cohn (2016), Plank and Agi´c (2018) and Anastasopoulos et al. (2018). We follow up on this line of research with our work. original idea and reaffirms the efficacy of annotation projection also with a state-of-the-art neural sequence tagging model (Wang et al., 2015) and on the modern universal POS-annotation scheme (Petrov et al., 2012). Since 2001, in addition to POS-tagging, annotation projection has been successfully applied to other tasks such as named entity recognition (Yarowsky et al., 2001; Enghoff et al., 2018), word sense tagging (Bentivogli et al., 2004), semantic role labeling (Pado and Lapata, 2005, 2009; van der Plas et al., 2011; Aminian et al., 2017), or dependency parsing (Hwa et al., 2005; Tiedemann, 2014; Rasooli and Collins, 2015; Agi´c et al., 2016; Aufrant et al., 2016). Kim et al. (2011) presented an integration into a full pipeline for information extraction. Open-source software tools for annotation projection are now available online (Akbik and Vollgraf, 2018, 2017). 3 Methods Research questions. We ask two central research questions in this work, one for each of the considered scenarios: Low-resource scenario: When the amount of hand-labeled training data is small for the"
W19-1425,P10-1052,0,0.0933039,"Missing"
W19-1425,petrov-etal-2012-universal,0,0.456498,"another cross-lingually shared component. We are however not aware of many prior studies that systematically explore annotation projection for cross-lingual transfer in neural POS-tagging of living spoken languages. Steps in this direction have been taken only lately by Fang and Cohn (2016), Plank and Agi´c (2018) and Anastasopoulos et al. (2018). We follow up on this line of research with our work. original idea and reaffirms the efficacy of annotation projection also with a state-of-the-art neural sequence tagging model (Wang et al., 2015) and on the modern universal POS-annotation scheme (Petrov et al., 2012). Since 2001, in addition to POS-tagging, annotation projection has been successfully applied to other tasks such as named entity recognition (Yarowsky et al., 2001; Enghoff et al., 2018), word sense tagging (Bentivogli et al., 2004), semantic role labeling (Pado and Lapata, 2005, 2009; van der Plas et al., 2011; Aminian et al., 2017), or dependency parsing (Hwa et al., 2005; Tiedemann, 2014; Rasooli and Collins, 2015; Agi´c et al., 2016; Aufrant et al., 2016). Kim et al. (2011) presented an integration into a full pipeline for information extraction. Open-source software tools for annotation"
W19-1425,D18-1061,0,0.0919547,"Missing"
W19-1425,P16-2067,0,0.0894869,"Missing"
W19-1425,D14-1187,0,0.189103,"Missing"
W19-1425,P11-2052,0,0.0610042,"Missing"
W19-1425,H05-1107,0,0.0445223,"pervised low-resource conditions attainable with either a plain foreign-language tagging model (zero-shot tagging) or via annotation projection from a foreign language (cross-lingual transfer)? To avoid unnecessarily noisy data, unlike previous authors, Lacroix et al. (2016) did not apply heuristics to fix certain word alignment links that pose difficulties to annotation projection. They demonstrated that it is simpler and more effective to ignore unaligned words as well as many-tomany alignments. In our work, we likewise settle on a simple technique based on a one-directional word alignment. Xi and Hwa (2005) have combined projected POS-annotation with a small manually annotated corpus in a low-resource scenario. Newer research on annotation projection for POS-tagging has looked at historical languages (Meyer, 2011; ¨ Sukhareva et al., 2017) and sign language (Ostling et al., 2015). Notable exceptions are the works of Wisniewski et al. (2014), examining annotation projection for a CRF tagging model (Lavergne et al., 2010) on living spoken languages, and of Agi´c et al. (2015). Meyer (2011) tags Old Russian via annotation projection from modern Russian translations. Sukhareva et al. (2017) POStag t"
W19-1425,N01-1026,0,0.419985,"ted language). To better understand this scenario, we compare it with the lowresource scenario (i.e., availability of a small POSlabeled training corpus). We thoroughly compare four techniques, including: zero-shot tagging and cross-lingual annotation projection from a linguistically related higher-resource language (for the zero-resource scenario), as well as selftraining and multilingual learning (for the lowresource scenario). A controlled experimental design is established for our study. We aim for immediate compara2 Related Work Annotation projection for POS-tagging was first explored by Yarowsky and Ngai (2001) for crosslingual transfer from English to French. Our basic approach shares much of Yarowsky and Ngai’s 223 Proceedings of VarDial, pages 223–233 c Minneapolis, MN, June 7, 2019 2019 Association for Computational Linguistics language-specific component integrated with another cross-lingually shared component. We are however not aware of many prior studies that systematically explore annotation projection for cross-lingual transfer in neural POS-tagging of living spoken languages. Steps in this direction have been taken only lately by Fang and Cohn (2016), Plank and Agi´c (2018) and Anastasopo"
W19-1425,D15-1039,0,0.0221195,"a and reaffirms the efficacy of annotation projection also with a state-of-the-art neural sequence tagging model (Wang et al., 2015) and on the modern universal POS-annotation scheme (Petrov et al., 2012). Since 2001, in addition to POS-tagging, annotation projection has been successfully applied to other tasks such as named entity recognition (Yarowsky et al., 2001; Enghoff et al., 2018), word sense tagging (Bentivogli et al., 2004), semantic role labeling (Pado and Lapata, 2005, 2009; van der Plas et al., 2011; Aminian et al., 2017), or dependency parsing (Hwa et al., 2005; Tiedemann, 2014; Rasooli and Collins, 2015; Agi´c et al., 2016; Aufrant et al., 2016). Kim et al. (2011) presented an integration into a full pipeline for information extraction. Open-source software tools for annotation projection are now available online (Akbik and Vollgraf, 2018, 2017). 3 Methods Research questions. We ask two central research questions in this work, one for each of the considered scenarios: Low-resource scenario: When the amount of hand-labeled training data is small for the targeted language, how effectively can we further improve the tagger by employing auxiliary resources? Specifically, how helpful is the use o"
W19-1425,H01-1035,0,0.192274,"fer in neural POS-tagging of living spoken languages. Steps in this direction have been taken only lately by Fang and Cohn (2016), Plank and Agi´c (2018) and Anastasopoulos et al. (2018). We follow up on this line of research with our work. original idea and reaffirms the efficacy of annotation projection also with a state-of-the-art neural sequence tagging model (Wang et al., 2015) and on the modern universal POS-annotation scheme (Petrov et al., 2012). Since 2001, in addition to POS-tagging, annotation projection has been successfully applied to other tasks such as named entity recognition (Yarowsky et al., 2001; Enghoff et al., 2018), word sense tagging (Bentivogli et al., 2004), semantic role labeling (Pado and Lapata, 2005, 2009; van der Plas et al., 2011; Aminian et al., 2017), or dependency parsing (Hwa et al., 2005; Tiedemann, 2014; Rasooli and Collins, 2015; Agi´c et al., 2016; Aufrant et al., 2016). Kim et al. (2011) presented an integration into a full pipeline for information extraction. Open-source software tools for annotation projection are now available online (Akbik and Vollgraf, 2018, 2017). 3 Methods Research questions. We ask two central research questions in this work, one for each"
W19-1425,W96-0213,0,0.831596,": punctuation SYM: symbol X: other We utilize a Bidirectional Long Short-Term Memory (BLSTM) neural network model (Hochreiter and Schmidhuber, 1997) to build our sequence taggers. BLSTMs are recurrent neural networks (RNNs) that are capable of learning long-term dependencies, taking into account both the previous and the following context. RNNs generally show great results at processing sequential data. They are widely adopted in natural language processing, including the POS-tagging task (Wang et al., 2015). Other statistical sequence labeling methods, such as maximum entropy tagging models (Ratnaparkhi, 1996) or conditional random fields (Lafferty et al., 2001; Lavergne et al., 2010), are nowadays often outperformed by neural network methods (Collobert et al., 2011). 3.1 Table 1: Universal Dependencies tags. are not strong enough to be able to use a model trained for Russian to tag Ukrainian sentences (Section 5.2.4). 3.4 Self-Training The cross-lingual transfer approach relies on the availability of cross-lingual supervision and is suitable for languages that do not have any annotated data, but for which there is an available parallel corpus with a high-resource language. A POS-tagger for the hig"
W19-1425,N18-1089,0,0.0230428,"wski et al. (2014), examining annotation projection for a CRF tagging model (Lavergne et al., 2010) on living spoken languages, and of Agi´c et al. (2015). Meyer (2011) tags Old Russian via annotation projection from modern Russian translations. Sukhareva et al. (2017) POStag the extinct Hittite language through projection from German. Recent related work on neural POS-tagging has mostly focused on robustness through character-level modeling (Heigold et al., 2016, 2018; dos Santos and Zadrozny, 2014; Labeau et al., 2015) or on architectural improvements (Huang et al., 2015; Ma and Hovy, 2016; Yasunaga et al., 2018). Kim et al. (2017) have proposed an interesting neural tagging architecture that allows for multilingual learning with a Neural tagging model. Depending on the context, the part-of-speech of a word may vary. E.g., the English word “green” takes a different POS (adjective, noun, verb) in each of the following three sentences: The recipe requires green mangoes. She took 63 shots to reach the green. How can we green our campus? The need to resolve such ambiguities is one of the challenges in POS-tagging, and is the reason why the task requires sequence labeling instead of just a simple dictionar"
W19-1425,W17-2213,0,0.205784,"Missing"
W19-5301,W19-5424,1,0.858444,"Missing"
W19-5301,W19-5306,0,0.248769,"al., 2019) University of Kyoto (Cromieres and Kurohashi, 2019) Lingua Custodia (Burlot, 2019) LIUM (Bougares et al., 2019) LMU Munich (Stojanovski and Fraser, 2019; Stojanovski et al., 2019) MLLP, Technical University of Valencia (Iranzo-Sánchez et al., 2019) Microsoft Translator (Junczys-Dowmunt, 2019) Microsoft Research Asia (Xia et al., 2019) Northeastern University / NiuTrans Co., Ltd. (Li et al., 2019a) National Institute of Information and Communications Technology (Dabre et al., 2019; Marie et al., 2019b) National Research Council of Canada (Littell et al., 2019) Bo˘gaziçi University (Biçici, 2019) PROMT LLC (Molchanov, 2019) University of Groningen (Toral et al., 2019) RWTH Aachen (Rosendahl et al., 2019) TALP Research Center, Universitat Politècnica de Catalunya (Casas et al., 2019) University of Tartu (Tättar et al., 2019) Tilde (Pinnis et al., 2019) Universitat d’Alacant (Sánchez-Cartagena et al., 2019) University of Cambridge (Stahlberg et al., 2019) Saarland University, DFKI (España-Bonet and Ruiter, 2019) University of Edinburgh (Bawden et al., 2019a) University of Maryland (Briakou and Carpuat, 2019) (no associated paper) University of Sydney (Ding and Tao, 2019) (no associated"
W19-5301,D18-1549,0,0.116951,"s are available for this system. 2.5.7 BASELINE - RE - RERANK (no associated CUNI-T RANSFORMER -T2T2018 (Popel, 2018) is the exact same system as used last year. paper) BASELINE - RE - RERANK is a standard Transformer, with corpus filtering, pre-processing, postprocessing, averaging and ensembling as well as n-best list reranking. 2.5.8 CUNI-T RANSFORMER -M ARIAN (Popel et al., 2019) is a “reimplementation” of the last year’s system (Popel, 2018) in Marian (JunczysDowmunt et al., 2018). CA I RE (Liu et al., 2019) CUNI-U NSUPERVISED -NER- POST (Kvapilíková et al., 2019) follows the strategy of Artetxe et al. (2018), creating a seed phrase-based system where the phrase table is initialized from cross-lingual embedding mappings trained on monolingual data, followed by a neural machine translation system trained on synthetic parallel corpus. The synthetic corpus is produced by the seed phrase-based MT system or by a such a model refined through iterative back-translation. CUNI-U NSUPERVISED -NER- POST further focuses on the handling of named entities, i.e. the part of vocabulary where the cross-lingual embedding mapping suffer most. CA I RE is a hybrid system that took part only in the unsupervised track."
W19-5301,D18-1332,0,0.0215805,"et al., 2018). For English↔Gujarati, synthetic parallel data from two sources, backtranslation and pivoting through Hindi, is produced using unsupervised and semi-supervised NMT models, pre-trained using a cross-lingual language objective (Lample and Conneau, 2019) For German→English, the impact of vast amounts of back-translated training data on translation quality is studied, and some additional insights are gained over (Edunov et al., 2018). Towards the end of training, for German→English and Chinese↔English, the mini-batch size was increased up to fifty-fold by delaying gradient updates (Bogoychev et al., 2018) as an alternative to learning rate cooldown (Smith, 2018). For Chinese↔English, a comparison of different segmentation strategies showed that character-based decoding was superior to the translation of subwords when translating into Chinese. Pre-processing strategies were also investigated for English→Czech, showing that preprocessing can be simplified without loss to MT quality. UEDIN’s main findings on the Chinese↔English translation task are that character-level model on the Chinese side can be used when translating into Chinese to improve the BLEU score. The same does not hold when transl"
W19-5301,W19-5351,0,0.0505622,"Missing"
W19-5301,W19-5423,0,0.0419015,"Missing"
W19-5301,W18-6412,1,0.856623,"Missing"
W19-5301,W19-5305,0,0.0496912,"Missing"
W19-5301,W12-3102,1,0.474924,"Missing"
W19-5301,W19-5310,0,0.0432396,"Missing"
W19-5301,W19-5425,0,0.0236032,"ys-Dowmunt et al., 2018) and Phrase-based machine translation system (implemented with Moses) and for the Spanish-Portuguese task. The system combination included features formerly presented in (Marie and Fujita, 2018), including scores left-to-right and right-to-left, sentence level translation probabilities and language model scores. Also authors provide contrastive results with an unsupervised phrase-based MT system which achieves quite close results to their primary system. Authors associate high performance of the unsupervised system to the language similarity. Incomslav: Team INCOMSLAV (Chen and Avgustinova, 2019) by Saarlad University participated in the Czech to Polish translation task only. The team’s primary submission builds on a transformer-based NMT baseline with back translation which has been submitted one of their contrastive submission. Incomslav’s primary system is a phoneme-based system re-scored using their NMT baseline. A second contrastive submission builds our phrase-based SMT system combined with a joint BPE model. NITS-CNLP: The NITS-CNLP team (Laskar et al., 2019) by the National Institute of Technology Silchar in India submitted results to the HI-NE translation task in both directi"
W19-5301,W07-0718,1,0.530103,"ojar Charles University Yvette Graham Barry Haddow Dublin City University University of Edinburgh Philipp Koehn JHU / University of Edinburgh Mathias Müller University of Zurich Marta R. Costa-jussà Christian Federmann UPC Microsoft Cloud + AI Shervin Malmasi Harvard Medical School Santanu Pal Saarland University Matt Post JHU Abstract Introduction The Fourth Conference on Machine Translation (WMT) held at ACL 20191 hosts a number of shared tasks on various aspects of machine translation. This conference builds on 13 previous editions of WMT as workshops and conferences (Koehn and Monz, 2006; Callison-Burch et al., 2007, 2008, 2009, 2010, 2011, 2012; Bojar et al., 2013, 2014, 2015, 2016, 2017, 2018). This year we conducted several official tasks. We report in this paper on the news and similar translation tasks. Additional shared tasks are described in separate papers in these proceedings: • biomedical translation (Bawden et al., 2019b) • automatic post-editing (Chatterjee et al., 2019) • metrics (Ma et al., 2019) • quality estimation (Fonseca et al., 2019) • parallel corpus filtering (Koehn et al., 2019) • robustness (Li et al., 2019b) In the news translation task (Section 2), participants were asked to tra"
W19-5301,P16-2058,1,0.819865,"ipated with the Transformer (Vaswani et al., 2017) implemented in the OpenNMT toolkit. They focused on word segmentation methods and compared a cognate-aware segmentation method, Cognate Morfessor (Grönroos et al., 2018), with character segmentation and unsupervised segmentation methods. As primary submission they submitted this Cognate Morfessor that optimizes subword segmentations consistently for cognates. They participated for all translation directions in Spanish-Portuguese and Czech-Polish, and this Cognate Morfessor performed better for Czech-Polish, while characterbased segmentations (Costa-jussà and Fonollosa, 2016), while much more inefficient, were superior for Spanish-Portuguese. UPC-TALP: The UPC-TALP team (Biesialska et al., 2019) by the Universitat Politècnica de Catalunya submitted a Transformer (implemented with Fairseq (Ott et al., 2019)) for the Czechto-Polish task and a Phrase-based system (implemented with Moses (Koehn et al., 2007)) for Spanish-to-Portuguese. They tested adding monolingual data to the NMT system by copying the same data on the source and target sides, with negative results. Also, their system combination based on sentence-level BLEU in back-translation 5.4 Conclusion of Simi"
W19-5301,W08-0309,1,0.659809,"Missing"
W19-5301,W18-3931,1,0.820211,"or they use English as a pivot language to translate between resource-poorer languages. The interest in English is reflected, for example, in the WMT translation tasks (e.g. News, Biomedical) which have always included language pairs in which texts are translated to and/or from English. With the widespread use of MT technology, there is more and more interest in training systems to translate between languages other than English. One evidence of this is the need of directly translating between pairs of similar languages, varieties, and dialects (Zhang, 1998; Marujo et al., 2011; Hassani, 2017; Costa-jussà et al., 2018). The main challenge is to take advantage of the similarity between languages to overcome the limitation given the low amount of available parallel data to produce an accurate output. Given the interest of the community in this topic we organize, for the first time at WMT, a shared task on ""Similar Language Translation"" to evaluate the performance of state-of-the-art translation systems on translating between pairs of languages from the same language family. We provide participants with training and testing data from three language pairs: Spanish - Portuguese (Romance languages), Czech - Polis"
W19-5301,W19-5312,0,0.0773587,"Missing"
W19-5301,W19-5313,0,0.0931699,"University (Marchisio et al., 2019) (no associated paper) University of Saarland (Mondal et al., 2019) Kingsoft AI (Guo et al., 2019) University of Kyoto (Cromieres and Kurohashi, 2019) Lingua Custodia (Burlot, 2019) LIUM (Bougares et al., 2019) LMU Munich (Stojanovski and Fraser, 2019; Stojanovski et al., 2019) MLLP, Technical University of Valencia (Iranzo-Sánchez et al., 2019) Microsoft Translator (Junczys-Dowmunt, 2019) Microsoft Research Asia (Xia et al., 2019) Northeastern University / NiuTrans Co., Ltd. (Li et al., 2019a) National Institute of Information and Communications Technology (Dabre et al., 2019; Marie et al., 2019b) National Research Council of Canada (Littell et al., 2019) Bo˘gaziçi University (Biçici, 2019) PROMT LLC (Molchanov, 2019) University of Groningen (Toral et al., 2019) RWTH Aachen (Rosendahl et al., 2019) TALP Research Center, Universitat Politècnica de Catalunya (Casas et al., 2019) University of Tartu (Tättar et al., 2019) Tilde (Pinnis et al., 2019) Universitat d’Alacant (Sánchez-Cartagena et al., 2019) University of Cambridge (Stahlberg et al., 2019) Saarland University, DFKI (España-Bonet and Ruiter, 2019) University of Edinburgh (Bawden et al., 2019a) University of"
W19-5301,W19-5314,0,0.0200465,"Bo˘gaziçi University (Biçici, 2019) PROMT LLC (Molchanov, 2019) University of Groningen (Toral et al., 2019) RWTH Aachen (Rosendahl et al., 2019) TALP Research Center, Universitat Politècnica de Catalunya (Casas et al., 2019) University of Tartu (Tättar et al., 2019) Tilde (Pinnis et al., 2019) Universitat d’Alacant (Sánchez-Cartagena et al., 2019) University of Cambridge (Stahlberg et al., 2019) Saarland University, DFKI (España-Bonet and Ruiter, 2019) University of Edinburgh (Bawden et al., 2019a) University of Maryland (Briakou and Carpuat, 2019) (no associated paper) University of Sydney (Ding and Tao, 2019) (no associated paper) 8 participated in all language pairs. The translations from the Table 5: Participants in the shared translation task. Not all teams online systems were not submitted by their respective companies but were obtained by us, and are therefore anonymized in a fashion consistent with previous years of the workshop. 2.5.6 BTRANS only the middle sentence was considered for the final translation hypothesis, otherwise shorter context of two sentences or just a single sentence was used. Unfortunately, no details are available for this system. 2.5.7 BASELINE - RE - RERANK (no associ"
W19-5301,D18-1045,0,0.0285693,"xt was morphologically segmented with Apertium. The UEDIN systems are supervised NMT systems based on the transformer architecture and trained using Marian (Junczys-Dowmunt et al., 2018). For English↔Gujarati, synthetic parallel data from two sources, backtranslation and pivoting through Hindi, is produced using unsupervised and semi-supervised NMT models, pre-trained using a cross-lingual language objective (Lample and Conneau, 2019) For German→English, the impact of vast amounts of back-translated training data on translation quality is studied, and some additional insights are gained over (Edunov et al., 2018). Towards the end of training, for German→English and Chinese↔English, the mini-batch size was increased up to fifty-fold by delaying gradient updates (Bogoychev et al., 2018) as an alternative to learning rate cooldown (Smith, 2018). For Chinese↔English, a comparison of different segmentation strategies showed that character-based decoding was superior to the translation of subwords when translating into Chinese. Pre-processing strategies were also investigated for English→Czech, showing that preprocessing can be simplified without loss to MT quality. UEDIN’s main findings on the Chinese↔Engl"
W19-5301,W18-6410,0,0.0193718,"ormance can be found in Hindi-Nepali (both directions), where the best performing system is around 50 BLEU (53 for Hindi-to-Nepali and 49.1 for Nepali-toHindi), and the lowest entry is 1.4 for Hindi-toNepali and 0 for Nepali-to-Hindi. The lowest variance is for Polish-to-Czech and it may be because only two teams participated. UHelsinki: The University of Helsinki team (Scherrer et al., 2019) participated with the Transformer (Vaswani et al., 2017) implemented in the OpenNMT toolkit. They focused on word segmentation methods and compared a cognate-aware segmentation method, Cognate Morfessor (Grönroos et al., 2018), with character segmentation and unsupervised segmentation methods. As primary submission they submitted this Cognate Morfessor that optimizes subword segmentations consistently for cognates. They participated for all translation directions in Spanish-Portuguese and Czech-Polish, and this Cognate Morfessor performed better for Czech-Polish, while characterbased segmentations (Costa-jussà and Fonollosa, 2016), while much more inefficient, were superior for Spanish-Portuguese. UPC-TALP: The UPC-TALP team (Biesialska et al., 2019) by the Universitat Politècnica de Catalunya submitted a Transform"
W19-5301,W19-5317,0,0.114089,"ed paper) (Liu et al., 2019) Charles University (Popel et al., 2019; Kocmi and Bojar, 2019) and (Kvapilíková et al., 2019) Kumamoto University, Telkom University, Indonesian Institute of Sciences (Budiwati et al., 2019) DFKI (Zhang and van Genabith, 2019) eTranslation (Oravecz et al., 2019) Facebook AI Research (Ng et al., 2019) GTCOM (Bei et al., 2019) University of Helsinki (Talman et al., 2019) IIIT Hyderabad (Goyal and Sharma, 2019) IIT Patna (Sen et al., 2019) Johns Hopkins University (Marchisio et al., 2019) (no associated paper) University of Saarland (Mondal et al., 2019) Kingsoft AI (Guo et al., 2019) University of Kyoto (Cromieres and Kurohashi, 2019) Lingua Custodia (Burlot, 2019) LIUM (Bougares et al., 2019) LMU Munich (Stojanovski and Fraser, 2019; Stojanovski et al., 2019) MLLP, Technical University of Valencia (Iranzo-Sánchez et al., 2019) Microsoft Translator (Junczys-Dowmunt, 2019) Microsoft Research Asia (Xia et al., 2019) Northeastern University / NiuTrans Co., Ltd. (Li et al., 2019a) National Institute of Information and Communications Technology (Dabre et al., 2019; Marie et al., 2019b) National Research Council of Canada (Littell et al., 2019) Bo˘gaziçi University (Biçici, 201"
W19-5301,W19-5315,0,0.0266353,"Missing"
W19-5301,W19-5318,0,0.198338,"ance of the systems when translating from French to German seems to heavily depend on the 7 http://data.statmt.org/wmt19/ translation-task/dev.tgz 6 Systems MSRA.MADL eTranslation LIUM MLLP-UPV onlineA TartuNLP onlineB onlineY onlineG onlineX FULL 47.3 45.4 43.7 41.5 40.8 39.2 39.1 39.0 38.5 38.1 source FR 38.3 37.4 37.5 36.4 35.4 34.8 35.3 34.7 34.6 35.6 source DE 50.0 47.8 45.5 43.0 42.3 40.5 40.2 40.2 39.7 38.8 evaluations. In the rest of this sub-section, we provide brief details of the submitted systems, for those in cases where the authors provided such details. 2.5.1 AFRL - SYSCOMB 19 (Gwinnup et al., 2019) is a system combination of a Marian ensemble system, two distinct OpenNMT systems, a Sockeyebased Elastic Weight Consolidation system, and one Moses phrase-based system. Table 3: French→German Meteor scores. Systems MSRA.MADL LinguaCustodia MLLP_UPV Kyoto_University_T2T LIUM onlineY onlineB TartuNLP onlineA onlineX onlineG FULL 52.0 51.3 49.5 48.8 48.3 47.5 46.4 46.3 45.3 42.7 41.7 source FR 51.9 52.5 49.9 49.7 46.5 43.7 43.7 45.0 43.7 41.6 40.9 source DE 52.0 51.0 49.4 48.6 48.7 48.4 47.0 46.7 45.8 42.9 41.9 AFRL- EWC (Gwinnup et al., 2019) is a Sockeye Transformer system trained with the de"
W19-5301,W19-5316,0,0.109691,"boratory (Gwinnup et al., 2019) Apertium (Pirinen, 2019) Apprentice (Li and Specia, 2019) Aylien Ltd. (Hokamp et al., 2019) Baidu (Sun et al., 2019) (no associated paper) (no associated paper) (Liu et al., 2019) Charles University (Popel et al., 2019; Kocmi and Bojar, 2019) and (Kvapilíková et al., 2019) Kumamoto University, Telkom University, Indonesian Institute of Sciences (Budiwati et al., 2019) DFKI (Zhang and van Genabith, 2019) eTranslation (Oravecz et al., 2019) Facebook AI Research (Ng et al., 2019) GTCOM (Bei et al., 2019) University of Helsinki (Talman et al., 2019) IIIT Hyderabad (Goyal and Sharma, 2019) IIT Patna (Sen et al., 2019) Johns Hopkins University (Marchisio et al., 2019) (no associated paper) University of Saarland (Mondal et al., 2019) Kingsoft AI (Guo et al., 2019) University of Kyoto (Cromieres and Kurohashi, 2019) Lingua Custodia (Burlot, 2019) LIUM (Bougares et al., 2019) LMU Munich (Stojanovski and Fraser, 2019; Stojanovski et al., 2019) MLLP, Technical University of Valencia (Iranzo-Sánchez et al., 2019) Microsoft Translator (Junczys-Dowmunt, 2019) Microsoft Research Asia (Xia et al., 2019) Northeastern University / NiuTrans Co., Ltd. (Li et al., 2019a) National Institute of"
W19-5301,E14-1047,1,0.904335,"Missing"
W19-5301,W19-5427,0,0.0467733,"Missing"
W19-5301,W19-5322,1,0.807321,"Missing"
W19-5301,W19-5302,1,0.715203,"20191 hosts a number of shared tasks on various aspects of machine translation. This conference builds on 13 previous editions of WMT as workshops and conferences (Koehn and Monz, 2006; Callison-Burch et al., 2007, 2008, 2009, 2010, 2011, 2012; Bojar et al., 2013, 2014, 2015, 2016, 2017, 2018). This year we conducted several official tasks. We report in this paper on the news and similar translation tasks. Additional shared tasks are described in separate papers in these proceedings: • biomedical translation (Bawden et al., 2019b) • automatic post-editing (Chatterjee et al., 2019) • metrics (Ma et al., 2019) • quality estimation (Fonseca et al., 2019) • parallel corpus filtering (Koehn et al., 2019) • robustness (Li et al., 2019b) In the news translation task (Section 2), participants were asked to translate a shared test set, optionally restricting themselves to the provided training data (“constrained” condition). We 1 Christof Monz University of Amsterdam Marcos Zampieri University of Wolverhampton held 18 translation tasks this year, between English and each of Chinese, Czech (into Czech only), German, Finnish, Lithuanian, and Russian. New this year were Gujarati↔English and Kazakh↔English. B"
W19-5301,W19-5333,0,0.0923169,"Missing"
W19-5301,W19-5353,0,0.0658382,"Missing"
W19-5301,W19-5430,1,0.873847,"Missing"
W19-5301,W19-5431,0,0.0199622,"Universitat Politècnica de València (UPV) participated with a Transformer (implemented with FairSeq (Ott et al., 2019)) and a finetuning strategy for domain adaptaion in the task of Spanish-Portuguese. Fine-tunning on the development data provide improvements of almost 12 BLEU points, which may explain their clear best performance in the task for this language pair. As a contrastive system authors provided only for the Portuguese-to-Spanish a novel 2D alternating RNN model which did not respond so well when fine-tunning. UBC-NLP: Team UBC-NLP from the University of British Columbia in Canada (Przystupa and Abdul-Mageed, 2019) compared the performance of the LSTM plus attention (Bahdanau et al., 2015) and Transformer (Vaswani et al., 2017) (implemented in OpenNMT toolkit22 ) perform for the three tasks at hand. Authors use backtranslation to introduce monolingual data in their systems. LSTM plus attention outperformed Transformer for Hindi-Nepali, and viceversa for the other two tasks. As reported by the authors, Hindi-Nepali task provides much more shorter sentences than KYOTOUNIVERSITY: Kyoto University’s submission, listed simply as KYOTO in Table 25 for PT → ES task is based on transformer NMT system. They used"
W19-5301,P02-1040,0,0.11337,"ation of the source (CS), and a second encoder to encode sub-word (byte-pair-encoding) information of the source (CS). The results obtained by their system in translating from Czech→Polish and comment on the impact of out-of-domain test data in the performance of their system. UDSDFKI ranked second among ten teams in Czech– Polish translation. 5.3 Results We present results for the three language pairs, each of them in the two possible directions. For this first edition of the Similar Translation Task and differently from News task, evaluation was only performed on automatic basis using BLEU (Papineni et al., 2002) and TER (Snover et al., 2006) measures. Each language direction is reported in one different table which contain information of the team; type of system, either contrastive (C) or primary (P), and the BLEU and TER results. In general, primary systems tend to be better than contrastive systems, as expected, but there are some exceptions. Even if we are presenting 3 pairs of languages each pair belonging to the same family, translation quality in terms of BLEU varies signficantly. While the best systems for Spanish-Portuguese are above 64 BLEU and below 21 TER (see Tables 26 and 27), best syste"
W19-5301,W19-5354,0,0.0611791,"Missing"
W19-5301,W18-6486,0,0.0189853,"the agglutinative nature of Kazakh, (ii) data from an additional language (Russian), given the scarcity of English–Kazakh data and (iii) synthetic data for the source language filtered using language-independent sentence similarity. RUG _ KKEN _ MORFESSOR Tilde developed both constrained and unconstrained NMT systems for English-Lithuanian and Lithuanian-English using the Marian toolkit. All systems feature ensembles of four to five transformer models that were trained using the quasi-hyperbolic Adam optimiser (Ma and Yarats, 2018). Data for the systems were prepared using TildeMT filtering (Pinnis, 2018) and preprocessing (Pinnis et al., 2018) methods. For unconstrained systems, data were additionally filtered using dual conditional cross-entropy filtering (Junczys-Dowmunt, 2018a). All systems were trained using iterative back-translation (Rikters, 2018) and feature synthetic data that allows training NMT systems to support handling of unknown phenomena (Pinnis et al., 2017). During translation, automatic named entity and nontranslatable phrase post-editing were performed. For constrained systems, named entities and nontranslatable phrase lists were extracted from the parallel training data."
W19-5301,W19-5335,0,0.0408704,"Missing"
W19-5301,W19-5344,1,0.904781,"n Institute of Sciences (Budiwati et al., 2019) DFKI (Zhang and van Genabith, 2019) eTranslation (Oravecz et al., 2019) Facebook AI Research (Ng et al., 2019) GTCOM (Bei et al., 2019) University of Helsinki (Talman et al., 2019) IIIT Hyderabad (Goyal and Sharma, 2019) IIT Patna (Sen et al., 2019) Johns Hopkins University (Marchisio et al., 2019) (no associated paper) University of Saarland (Mondal et al., 2019) Kingsoft AI (Guo et al., 2019) University of Kyoto (Cromieres and Kurohashi, 2019) Lingua Custodia (Burlot, 2019) LIUM (Bougares et al., 2019) LMU Munich (Stojanovski and Fraser, 2019; Stojanovski et al., 2019) MLLP, Technical University of Valencia (Iranzo-Sánchez et al., 2019) Microsoft Translator (Junczys-Dowmunt, 2019) Microsoft Research Asia (Xia et al., 2019) Northeastern University / NiuTrans Co., Ltd. (Li et al., 2019a) National Institute of Information and Communications Technology (Dabre et al., 2019; Marie et al., 2019b) National Research Council of Canada (Littell et al., 2019) Bo˘gaziçi University (Biçici, 2019) PROMT LLC (Molchanov, 2019) University of Groningen (Toral et al., 2019) RWTH Aachen (Rosendahl et al., 2019) TALP Research Center, Universitat Politècnica de Catalunya (Casas e"
W19-5301,W19-5346,0,0.197908,"rtium (Pirinen, 2019) Apprentice (Li and Specia, 2019) Aylien Ltd. (Hokamp et al., 2019) Baidu (Sun et al., 2019) (no associated paper) (no associated paper) (Liu et al., 2019) Charles University (Popel et al., 2019; Kocmi and Bojar, 2019) and (Kvapilíková et al., 2019) Kumamoto University, Telkom University, Indonesian Institute of Sciences (Budiwati et al., 2019) DFKI (Zhang and van Genabith, 2019) eTranslation (Oravecz et al., 2019) Facebook AI Research (Ng et al., 2019) GTCOM (Bei et al., 2019) University of Helsinki (Talman et al., 2019) IIIT Hyderabad (Goyal and Sharma, 2019) IIT Patna (Sen et al., 2019) Johns Hopkins University (Marchisio et al., 2019) (no associated paper) University of Saarland (Mondal et al., 2019) Kingsoft AI (Guo et al., 2019) University of Kyoto (Cromieres and Kurohashi, 2019) Lingua Custodia (Burlot, 2019) LIUM (Bougares et al., 2019) LMU Munich (Stojanovski and Fraser, 2019; Stojanovski et al., 2019) MLLP, Technical University of Valencia (Iranzo-Sánchez et al., 2019) Microsoft Translator (Junczys-Dowmunt, 2019) Microsoft Research Asia (Xia et al., 2019) Northeastern University / NiuTrans Co., Ltd. (Li et al., 2019a) National Institute of Information and Communicatio"
W19-5301,W19-5341,0,0.0172601,"A,B,G,X,Y. For presentation of the results, systems are treated as either constrained or unconstrained, depending on whether their models were trained only on the provided data. Since we do not know how they were built, the online systems are treated as unconstrained during the automatic and human AYLIEN _ MULTILINGUAL (Hokamp et al., 2019) The Aylien research team built a Multilingual NMT system which is trained on all WMT2019 language pairs in all directions, then fine-tuned for a small number of iterations on Gujarati-English data only, including some self-backtranslated data. 2.5.5 BAIDU (Sun et al., 2019) Baidu systems are based on the Transformer architecture with several improvements. Data selection, back translation, data augmentation, knowledge distillation, domain adaptation, model ensemble and re-ranking are employed and proven effective in our experiments. 7 Team AFRL A PERTIUM - FIN - ENG A PPRENTICE - C AYLIEN _ MULTILINGUAL BAIDU BTRANS BASELINE - RE - RERANK CA I RE CUNI DBMS-KU DFKI - NMT E T RANSLATION FACEBOOK FAIR GTCOM H ELSINKI NLP IIITH-MT IITP JHU JUMT JU_S AARLAND KSAI K YOTO U NIVERSITY L INGUA C USTODIA LIUM LMU-NMT MLLP-UPV MS T RANSLATOR MSRA N IU T RANS NICT NRC PARFDA"
W19-5301,P16-1162,1,0.310296,"ssible, 2.5.13 E T RANSLATION (Oravecz et al., 2019) E T RANSLATION En-De E T RANSLATION ’s EnDe system is an ensemble of 3 base Transformers and a Transformer-type language model, trained from all available parallel data (cleaned up and filtered with dual conditional cross-entropy filtering) and with additional back-translated data generated 9 2.5.17 from monolingual news. Each Transformer model is fine tuned on previous years’ test sets. H ELSINKI NLP is a Transformer (Vaswani et al., 2017) style model implemented in OpenNMTpy using a variety of corpus filtering techniques, truecasing, BPE (Sennrich et al., 2016), backtranslation, ensembling and fine-tuning for domain adaptation. E T RANSLATION Fr-De The Fr-De system is an ensemble of 2 big Transformers (with size 8192 FFN layers). Back-translation data was selected using topic modelling techniques to tune the model towards the domain defined in the task. 2.5.18 En-Lt The En-Lt system is an ensemble of 2 big Transformers (as for Fr-De) and a Transformer type language model. The training data contains the Rapid corpus and the news domain back-translated data sets 2 times oversampled. E T RANSLATION 2.5.19 FACEBOOK FAIR (Ng et al., 2019) 2.5.20 JHU (Mar"
W19-5301,W19-5339,0,0.0767002,"Missing"
W19-5301,W19-5347,0,0.0328257,"Missing"
W19-5301,W19-5342,1,0.887858,"encia (Iranzo-Sánchez et al., 2019) Microsoft Translator (Junczys-Dowmunt, 2019) Microsoft Research Asia (Xia et al., 2019) Northeastern University / NiuTrans Co., Ltd. (Li et al., 2019a) National Institute of Information and Communications Technology (Dabre et al., 2019; Marie et al., 2019b) National Research Council of Canada (Littell et al., 2019) Bo˘gaziçi University (Biçici, 2019) PROMT LLC (Molchanov, 2019) University of Groningen (Toral et al., 2019) RWTH Aachen (Rosendahl et al., 2019) TALP Research Center, Universitat Politècnica de Catalunya (Casas et al., 2019) University of Tartu (Tättar et al., 2019) Tilde (Pinnis et al., 2019) Universitat d’Alacant (Sánchez-Cartagena et al., 2019) University of Cambridge (Stahlberg et al., 2019) Saarland University, DFKI (España-Bonet and Ruiter, 2019) University of Edinburgh (Bawden et al., 2019a) University of Maryland (Briakou and Carpuat, 2019) (no associated paper) University of Sydney (Ding and Tao, 2019) (no associated paper) 8 participated in all language pairs. The translations from the Table 5: Participants in the shared translation task. Not all teams online systems were not submitted by their respective companies but were obtained by us, and"
W19-5301,W19-5355,1,0.869964,"Missing"
W19-5301,W19-5350,0,0.0441915,"Missing"
W19-5301,P98-2238,0,0.38957,"n trained to translate texts from and to English or they use English as a pivot language to translate between resource-poorer languages. The interest in English is reflected, for example, in the WMT translation tasks (e.g. News, Biomedical) which have always included language pairs in which texts are translated to and/or from English. With the widespread use of MT technology, there is more and more interest in training systems to translate between languages other than English. One evidence of this is the need of directly translating between pairs of similar languages, varieties, and dialects (Zhang, 1998; Marujo et al., 2011; Hassani, 2017; Costa-jussà et al., 2018). The main challenge is to take advantage of the similarity between languages to overcome the limitation given the low amount of available parallel data to produce an accurate output. Given the interest of the community in this topic we organize, for the first time at WMT, a shared task on ""Similar Language Translation"" to evaluate the performance of state-of-the-art translation systems on translating between pairs of languages from the same language family. We provide participants with training and testing data from three language"
W19-5344,J82-2005,0,0.772854,"Missing"
W19-5344,Q17-1010,0,0.0501673,"Crawl articles from 2007 to 2018. In the case of both languages the corpora contained a small set of sentences coming from foreign languages which we filtered out using a language detection tool2 . The datasets were tokenized and truecased with the standard scripts from the Moses toolkit (Koehn et al., 2007). For the bilingual word embeddings used by our PBT system we compound split the German corpus using compound-splitter.perl from the Moses toolkit with the following parameters: minimum word size 4; minimum count 5; maximum count 1000. To train monolingual word embeddings we used fasttext (Bojanowski et al., 2017), instead of word2vec (Mikolov et al., 2013), 2 de 270M 75M 270M 37M cs 67M 67M 67M 41M Table 1: Training data sizes in number of sentences. 5.2 PBT Experiments As mentioned earlier we initialize our PBT system with BWEs trained on compound split data. In Table 2 we show baseline word-by-word (wbw) results, i.e., we greedily translate each source word independently of the others using the most similar target word, according to the BWE-based dictionary, without any reordering. We compare BWEs trained with and without compound split data. The results of both approaches are low, which is due to t"
W19-5344,D18-1062,0,0.0378496,"Missing"
W19-5344,P07-2045,0,0.0114114,"ry of the 100 nearest target words for each source language word with their similarities which we convert to a phrase table. For more details on phrase-table creation see Section 3. One problem with the approach arises when translating German compound words which are combinations of two or more words that function as a single unit of meaning. In most of the cases, these words should be translated into multiple Czech words, but our generated dictionary 3 Unsupervised Phrase-based Translation We build on the BWEs to create an unsupervised phrase-based translation system using the Moses decoder (Koehn et al., 2007). In an initial step (iteration 0), a bilingual wordbased translation lexicon is obtained from the embeddings space and stored in a format compatible with Moses’ phrase table. The BWE cosine similarities serve as translation feature scores. We include multiple single-word target-side translation candidates per source-side token, given as the nearest neighbors in the bilingual embeddings space. An n-gram language model trained on target-side monolingual data is provided to Moses as another feature function. Moses then decodes with a variant of a beam search algorithm. We tune scaling factors to"
W19-5344,P18-1073,0,0.285165,"Processing LMU Munich {stojanovski,hangyav,mhuck,fraser}@cis.lmu.de Abstract Knowles (2017) also show that in low-resource setups neural models fail to match traditional phrasebased systems in terms of quality. This is the motivation for the unsupervised track at WMT19. The system we use to participate in the shared task is multipart and borrows on existing techniques for unsupervised learning. We make use of bilingual word embeddings (BWE), phrase-based translation (PBT), cross-lingual masked language models (MLM) and NMT models, all trained in an unsupervised way. Lample et al. (2018a) and Artetxe et al. (2018c) showed that, given proper bootstrapping, it is possible to train unsupervised NMT models by making use of two general techniques, denoising autoencoding and online backtranslation. Lample et al. (2018b) and Artetxe et al. (2018b) further showed that this is also possible for phrase-based statistical machine translation. A key technique that enables this is obtaining word-by-word translations by utilizing unsupervised bilingual word embeddings. Lample et al. (2018b) further simplified the bootstrapping step by showing that jointly trained BPE-level (Sennrich et al., 2016) embeddings are a be"
W19-5344,W18-6319,0,0.0233906,"sCrawl 2017-2018, and Czech NewsCrawl 2007-2018 monolingual data. For the unsupervised NMT model, we use NewsCrawl 2018 for German and NewsCrawl 2013-2018 for Czech. In this way, both models are trained with roughly equal amounts of German and Czech data. Details on the training data is in Table 1. For the NMT experiments, we use the code from (Lample and Conneau, 2019)3 . In the following we perform evaluation for both our unsupervised phrase-based and neural machine translation systems. We report BLEU scores on the detokenized translations of newstest2013 and newstest2019 using sacreBLEU 4 (Post, 2018). Incorporating PBT Synthetic Data The training curriculum to enable this model to work is to first pretrain a cross-lingual MLM. Subsequently, one can further bootstrap this model with back-translations from an unsupervised phrase-based system and finally, fine-tune this model with the unsupervised neural criteria. However, due to time constraints we first fine-tune the pretrained MLM with the NMT system. After several iterations of training, we include additional back-translations from the phrase-based system. We only used pseudo-parallel German→Czech translations. We continue using online b"
W19-5344,P16-1162,0,0.0710583,"le et al. (2018a) and Artetxe et al. (2018c) showed that, given proper bootstrapping, it is possible to train unsupervised NMT models by making use of two general techniques, denoising autoencoding and online backtranslation. Lample et al. (2018b) and Artetxe et al. (2018b) further showed that this is also possible for phrase-based statistical machine translation. A key technique that enables this is obtaining word-by-word translations by utilizing unsupervised bilingual word embeddings. Lample et al. (2018b) further simplified the bootstrapping step by showing that jointly trained BPE-level (Sennrich et al., 2016) embeddings are a better alternative, assuming closely related languages that potentially share surface forms. Lample et al. (2018b) also showed that a single shared encoder and decoder are sufficient for learning both translation directions. A general trend in NLP recently has been unsupervised masked language model pretraining. Devlin et al. (2018) showed that a wide range of NLP tasks are significantly improved by fine-tuning large MLM. They propose a way to train a Transformer language model which has access to left and right context as opposed to traditional LM which only have left contex"
W19-5344,W18-6428,1,0.787961,"vised translation such as denoising autoencoding and online back-translation. We bootstrap the model with masked language model pretraining and enhance it with back-translations from an unsupervised phrase-based system which is itself bootstrapped using unsupervised bilingual word embeddings. 1 Introduction In this paper we describe the system we developed at the LMU Munich Center for Information and Language Processing, which we used to participate in the unsupervised track of the news translation task at WMT19. The system builds on our last year’s submission to the unsupervised shared task (Stojanovski et al., 2018) and previous work on unsupervised machine translation (Lample et al., 2018a; Artetxe et al., 2018c; Lample et al., 2018b; Lample and Conneau, 2019). We submitted system runs for the German→Czech translation direction. The goal of the unsupervised track is to train machine translation models without access to any bilingual or comparable monolingual data. Supervised neural machine translation (NMT) has achieved state-of-the-art results (Bahdanau et al., 2015). With the introduction of the Transformer (Vaswani et al., 2017) the quality of automatic translations has been significantly improved. H"
