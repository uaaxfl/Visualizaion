2021.mtsummit-research.22,Introducing Mouse Actions into Interactive-Predictive Neural Machine Translation,2021,-1,-1,2,0,5065,angel navarro,Proceedings of Machine Translation Summit XVIII: Research Track,0,The quality of the translations generated by Machine Translation (MT) systems has highly improved through the years and but we are still far away to obtain fully automatic high-quality translations. To generate them and translators make use of Computer-Assisted Translation (CAT) tools and among which we find the Interactive-Predictive Machine Translation (IPMT) systems. In this paper and we use bandit feedback as the main and only information needed to generate new predictions that correct the previous translations. The application of bandit feedback reduces significantly the number of words that the translator need to type in an IPMT session. In conclusion and the use of this technique saves useful time and effort to translators and its performance improves with the future advances in MT and so we recommend its application in the actuals IPMT systems.
2020.eamt-1.34,A User Study of the Incremental Learning in {NMT},2020,-1,-1,7,1,20855,miguel domingo,Proceedings of the 22nd Annual Conference of the European Association for Machine Translation,0,"In the translation industry, human experts usually supervise and post-edit machine translation hypotheses. Adaptive neural machine translation systems, able to incrementally update the underlying models under an online learning regime, have been proven to be useful to improve the efficiency of this workflow. However, this incremental adaptation is somewhat unstable, and it may lead to undesirable side effects. One of them is the sporadic appearance of made-up words, as a byproduct of an erroneous application of subword segmentation techniques. In this work, we extend previous studies on on-the-fly adaptation of neural machine translation systems. We perform a user study involving professional, experienced post-editors, delving deeper on the aforementioned problems. Results show that adaptive systems were able to learn how to generate the correct translation for task-specific terms, resulting in an improvement of the user{'}s productivity. We also observed a close similitude, in terms of morphology, between made-up words and the words that were expected."
2020.eamt-1.35,{NICE}: Neural Integrated Custom Engines,2020,-1,-1,4,0,20858,daniel buj,Proceedings of the 22nd Annual Conference of the European Association for Machine Translation,0,"In this paper, we present a machine translation system implemented by the Translation Centre for the Bodies of the European Union (CdT). The main goal of this project is to create domain-specific machine translation engines in order to support machine translation services and applications to the Translation Centre{'}s clients. In this article, we explain the entire implementation process of NICE: Neural Integrated Custom Engines. We describe the problems identified and the solutions provided, and present the final results for different language pairs. Finally, we describe the work that will be done on this project in the future."
W19-6737,Incremental Adaptation of {NMT} for Professional Post-editors: A User Study,2019,41,1,7,1,20855,miguel domingo,"Proceedings of Machine Translation Summit XVII: Translator, Project and User Tracks",0,"A common use of machine translation in the industry is providing initial translation hypotheses, which are later supervised and post-edited by a human expert. During this revision process, new bilingual data are continuously generated. Machine translation systems can benefit from these new data, incrementally updating the underlying models under an online learning paradigm. We conducted a user study on this scenario, for a neural machine translation system. The experimentation was carried out by professional translators, with a vast experience in machine translation post-editing. The results showed a reduction in the required amount of human effort needed when post-editing the outputs of the system, improvements in the translation quality and a positive perception of the adaptive system by the users."
W19-5439,Filtering of Noisy Parallel Corpora Based on Hypothesis Generation,2019,0,0,3,0,20860,zuzanna parcheta,"Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",0,"The filtering task of noisy parallel corpora in WMT2019 aims to challenge participants to create filtering methods to be useful for training machine translation systems. In this work, we introduce a noisy parallel corpora filtering system based on generating hypotheses by means of a translation model. We train translation models in both language pairs: Nepali{--}English and Sinhala{--}English using provided parallel corpora. We select the training subset for three language pairs (Nepali, Sinhala and Hindi to English) jointly using bilingual cross-entropy selection to create the best possible translation model for both language pairs. Once the translation models are trained, we translate the noisy corpora and generate a hypothesis for each sentence pair. We compute the smoothed BLEU score between the target sentence and generated hypothesis. In addition, we apply several rules to discard very noisy or inadequate sentences which can lower the translation score. These heuristics are based on sentence length, source and target similarity and source language detection. We compare our results with the baseline published on the shared task website, which uses the Zipporah model, over which we achieve significant improvements in one of the conditions in the shared task. The designed filtering system is domain independent and all experiments are conducted using neural machine translation."
P19-3012,Demonstration of a Neural Machine Translation System with Online Learning for Translators,2019,16,0,7,1,20855,miguel domingo,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations,0,"We present a demonstration of our system, which implements online learning for neural machine translation in a production environment. These techniques allow the system to continuously learn from the corrections provided by the translators. We implemented an end-to-end platform integrating our machine translation servers to one of the most common user interfaces for professional translators: SDL Trados Studio. We pretend to save post-editing effort as the machine is continuously learning from its mistakes and adapting the models to a specific domain or user style."
P19-3014,"A Neural, Interactive-predictive System for Multimodal Sequence to Sequence Tasks",2019,0,0,2,1,20856,alvaro peris,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations,0,"We present a demonstration of a neural interactive-predictive system for tackling multimodal sequence to sequence tasks. The system generates text predictions to different sequence to sequence tasks: machine translation, image and video captioning. These predictions are revised by a human agent, who introduces corrections in the form of characters. The system reacts to each correction, providing alternative hypotheses, compelling with the feedback provided by the user. The final objective is to reduce the human effort required during this correction process. This system is implemented following a client-server architecture. For accessing the system, we developed a website, which communicates with the neural model, hosted in a local server. From this website, the different tasks can be tackled following the interactive{--}predictive framework. We open-source all the code developed for building this system. The demonstration in hosted in http://casmacat.prhlt.upv.es/interactive-seq2seq."
K18-1015,Active Learning for Interactive Neural Machine Translation of Data Streams,2018,0,7,2,1,20856,alvaro peris,Proceedings of the 22nd Conference on Computational Natural Language Learning,0,"We study the application of active learning techniques to the translation of unbounded data streams via interactive neural machine translation. The main idea is to select, from an unbounded stream of source sentences, those worth to be supervised by a human agent. The user will interactively translate those samples. Once validated, these data is useful for adapting the neural machine translation model. We propose two novel methods for selecting the samples to be validated. We exploit the information from the attention mechanism of a neural machine translation system. Our experiments show that the inclusion of active learning techniques into this pipeline allows to reduce the effort required during the process, while increasing the quality of the translation system. Moreover, it enables to balance the human effort required for achieving a certain translation quality. Moreover, our neural system outperforms classical approaches by a large margin."
W17-4714,Adapting Neural Machine Translation with Parallel Synthetic Data,2017,25,10,3,0,17880,mara chinearios,Proceedings of the Second Conference on Machine Translation,0,None
W16-3415,Interactive-Predictive Translation Based on Multiple Word-Segments,2016,18,4,3,1,20855,miguel domingo,Proceedings of the 19th Annual Conference of the {E}uropean Association for Machine Translation,0,None
K16-1020,Beyond Prefix-Based Interactive Translation Prediction,2016,16,6,3,1,23854,jesus gonzalezrubio,Proceedings of The 20th {SIGNLL} Conference on Computational Natural Language Learning,0,None
underwood-etal-2014-evaluating,Evaluating the effects of interactivity in a post-editing workbench,2014,11,4,10,0,39532,nancy underwood,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"This paper describes the field trial and subsequent evaluation of a post-editing workbench which is currently under development in the EU-funded CasMaCat project. Based on user evaluations of the initial prototype of the workbench, this second prototype of the workbench includes a number of interactive features designed to improve productivity and user satisfaction. Using CasMaCat{'}s own facilities for logging keystrokes and eye tracking, data were collected from nine post-editors in a professional setting. These data were then used to investigate the effects of the interactive features on productivity, quality, user satisfaction and cognitive load as reflected in the post-editorsÂ gaze activity. These quantitative results are combined with the qualitative results derived from user questionnaires and interviews conducted with all the participants."
chinea-rios-etal-2014-online,Online optimisation of log-linear weights in interactive machine translation,2014,7,2,4,0,24999,mara rios,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"Whenever the quality provided by a machine translation system is not enough, a human expert is required to correct the sentences provided by the machine translation system. In such a setup, it is crucial that the system is able to learn from the errors that have already been corrected. In this paper, we analyse the applicability of discriminative ridge regression for learning the log-linear weights of a state-of-the-art machine translation system underlying an interactive machine translation framework, with encouraging results."
E14-4018,Inference of Phrase-Based Translation Models via Minimum Description Length,2014,17,2,2,1,23854,jesus gonzalezrubio,"Proceedings of the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics, volume 2: Short Papers",0,"We present an unsupervised inference procedure for phrase-based translation models based on the minimum description length principle. In comparison to current inference techniques that rely on long pipelines of training heuristics, this procedure represents a theoretically wellfounded approach to directly infer phrase lexicons. Empirical results show that the proposed inference procedure has the potential to overcome many of the problems inherent to the current inference approaches for phrase-based models."
E14-2007,{CASMACAT}: A Computer-assisted Translation Workbench,2014,6,10,4,1,38851,vicent alabau,Proceedings of the Demonstrations at the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"CASMACAT is a modular, web-based translation workbench that offers advanced functionalities for computer-aided translation and the scientific study of human translation: automatic interaction with machine translation (MT) engines and translation memories (TM) to obtain raw translations or close TM matches for conventional post-editing; interactive translation prediction based on an MT enginexe2x80x99s search graph, detailed recording and replay of edit actions and translatorxe2x80x99s gaze (the latter via eye-tracking), and the support of e-pen as an alternative input device. The system is open source sofware and interfaces with multiple MT systems."
E14-2012,The New Thot Toolkit for Fully-Automatic and Interactive Statistical Machine Translation,2014,10,14,2,1,35489,daniel ortizmartinez,Proceedings of the Demonstrations at the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"We present the new THOT toolkit for fullyautomatic and interactive statistical machine translation (SMT). Initial public versions of THOT date back to 2005 and did only include estimation of phrase-based models. By contrast, the new version offers several new features that had not been previously incorporated. The key innovations provided by the toolkit are computeraided translation, including post-editing and interactive SMT, incremental learning and robust generation of alignments at phrase level. In addition to this, the toolkit also provides standard SMT features such as fully-automatic translation, scalable and parallel algorithms for model training, client-server implementation of the translation functionality, etc. The toolkit can be compiled in Unix-like and Windows platforms and it is released under the GNU Lesser General Public License (LGPL)."
2014.eamt-1.5,Efficient wordgraph for interactive translation prediction,2014,-1,-1,3,1,23855,german sanchistrilles,Proceedings of the 17th Annual conference of the European Association for Machine Translation,0,None
2014.eamt-1.12,{CASMACAT}: cognitive analysis and statistical methods for advanced computer aided translation,2014,-1,-1,3,0,4417,philipp koehn,Proceedings of the 17th Annual conference of the European Association for Machine Translation,0,None
2014.amta-workshop.1,Integrating online and active learning in a computer-assisted translation workbench,2014,-1,-1,5,1,38851,vicent alabau,Workshop on interactive and adaptive machine translation,0,"This paper describes a pilot study with a computed-assisted translation workbench aiming at testing the integration of online and active learning features. We investigate the effect of these features on translation productivity, using interactive translation prediction (ITP) as a baseline. User activity data were collected from five beta testers using key-logging and eye-tracking. User feedback was also collected at the end of the experiments in the form of retrospective think-aloud protocols. We found that OL performs better than ITP, especially in terms of translation speed. In addition, AL provides better translation quality than ITP for the same levels of user effort. We plan to incorporate these features in the final version of the workbench."
D13-1025,Interactive Machine Translation using Hierarchical Translation Models,2013,26,8,4,1,23854,jesus gonzalezrubio,Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,0,"Current automatic machine translation systems are not able to generate error-free translations and human intervention is often required to correct their output. Alternatively, an interactive framework that integrates the human knowledge into the translation process has been presented in previous works. Here, we describe a new interactive machine translation approach that is able to work with phrase-based and hierarchical translation models, and integrates error-correction all in a unified statistical framework. In our experiments, our approach outperforms previous interactive translation systems, and achieves estimated effort reductions of as much as 48% relative over a traditional post-edition system."
2013.mtsummit-wptp.7,Advanced computer aided translation with a web-based workbench,2013,11,5,5,1,38851,vicent alabau,Proceedings of the 2nd Workshop on Post-editing Technology and Practice,0,"We describe a web-based workbench that offers advanced computer aided translation (CAT) functionality: post-editing machine translation (MT), interactive translation prediction (ITP), visualization of word alignment, extensive logging with replay mode, integration with eye trackers and epen. It is available open source and integrates with multiple MT systems. The goal of the CASMACAT project1 is to develop an advanced computer aided translation workbench. At the mid-point of the 3-year project, we release this tool as open source software. It already includes a wide range of novel advanced types of assistance and other functionalities that do not exist together in any other computer aided translation tool. The CASMACAT is working in close collaboration with the MATECAT project2, which also has the goal of developing a new open source webbased computer aided translation tool, and focuses mainly on post-editing machine translation, adaptation methods, and ease of use that make such a tool suitable for professional users. Through this combined effort, we hope to kickstart broader research into computer aided translation methods, facilitating diverse translation process studies, and reach volunteer and professional translators without advanced technical skills. The tool is developed as a web-based platform using HTML5 and Javascript in the Browser and PHP in the backend, supported by a CAT and MT server that run as independent process (both implemented in Python but integrating tools written in various other programming languages). http://www.casmacat.eu/ http://www.matecat.com/ 1 Related Work There is increasing evidence for productivity gains of professional translators when they post-edit machine translation output. For instance, Plitt and Masselot (2010) compare post-editing machine translation against unassisted translation in a web-based tool for a number of language pairs, showing productivity gains of up to 80%. Skadixc5x86s et al. (2011) show a 30 percent increase for English-Latvian translation with a slight but acceptable degradation in quality. Federico et al. (2012) assess the benefit of offering machine translation output in addition to translation memory matches (marked as such) in a realistic work environment for translators working on legal and information technology documents. They observe productivity gains of 20-50%, roughly independent from the original translator speed and segment length, but with different results for different language pairs and domains. Moreover, Pouliquen et al. (2011) show that, aided by machine translation, non-professional post-editors may be able to create high-quality translations, comparable to a professional translation agency. So far, usage of machine translation technology has concentrated on human-computer interaction involving the human translator as a post-editor, but rarely involves the human translator influencing the decisions of the machine translation system. Recent efforts on building interactive machine translation systems include work by Langlais et al. (2000) and Barrachina et al. (2009). Both studies develop research systems looking into a tighter integration of human translators in MT processes by developing a prediction model that interactively suggests translations to the human translator as he or she types. Related work displays several word and phrase translation choices to human translators (Koehn, 2010). Figure 1: View for uploading new documents"
2013.mtsummit-user.9,User Evaluation of Advanced Interaction Features for a Computer-Assisted Translation Workbench,2013,13,1,6,1,41890,vicente alabau,Proceedings of Machine Translation Summit XIV: User track,0,"This paper reports on the results of a user satisfaction survey carried out among 16 translators using a new computer-assisted translation workbench. Participants were asked to provide feedback after performing different post-editing tasks on different configurations of the workbench, using different features and tools. Resulting from the feedback provided, we report on the utility of each of the features, identifying new ways of implementing them according to the usersxe2x80x99 suggestions."
2013.mtsummit-european.3,{CASMACAT}: Cognitive Analysis and Statistical Methods for Advanced Computer Aided Translation,2013,0,5,3,0,4417,philipp koehn,Proceedings of Machine Translation Summit XIV: European projects,0,None
2013.iwslt-papers.4,Improving the minimum {B}ayes{'} risk combination of machine translation systems,2013,19,0,2,1,23854,jesus gonzalezrubio,Proceedings of the 10th International Workshop on Spoken Language Translation: Papers,0,"We investigate the problem of combining the outputs of different translation systems into a minimum Bayes{'} risk consensus translation. We explore different risk formulations based on the BLEU score, and provide a dynamic programming decoding algorithm for each of them. In our experiments, these algorithms generated consensus translations with better risk, and more efficiently, than previous proposals."
2013.iwslt-papers.5,Emprical study of a two-step approach to estimate translation quality,2013,-1,-1,3,1,23854,jesus gonzalezrubio,Proceedings of the 10th International Workshop on Spoken Language Translation: Papers,0,"We present a method to estimate the quality of automatic translations when reference translations are not available. Quality estimation is addressed as a two-step regression problem where multiple features are combined to predict a quality score. Given a set of features, we aim at automatically extracting the variables that better explain translation quality, and use them to predict the quality score. The soundness of our approach is assessed by the encouraging results obtained in an exhaustive experimentation with several feature sets. Moreover, the studied approach is highly-scalable allowing us to employ hundreds of features to predict translation quality."
W12-6217,Finite-State Acoustic and Translation Model Composition in Statistical Speech Translation: Empirical Assessment,2012,15,1,3,1,33527,alicia perez,Proceedings of the 10th International Workshop on Finite State Methods and Natural Language Processing,0,"Speech translation can be tackled by means of the so-called decoupled approach: a speech recognition system followed by a text translation system. The major drawback of this two-pass decoding approach lies in the fact that the translation system has to cope with the errors derived from the speech recognition system. There is hardly any cooperation between the acoustic and the translation knowledge sources. There is a line of research focusing on alternatives to implement speech translation efficiently: ranging from semi-decoupled to tightly integrated approaches. The goal of integration is to make acoustic and translation models cooperate in the underlying decision problem. That is, the translation is built by virtue of the joint action of both models. As a side-advantage of the integrated approaches, the translation is obtained in a single-pass decoding strategy. The aim of this paper is to assess the quality of the hypotheses explored within different speech translation approaches. Evidence of the performance is given through experimental results on a limited-domain task."
W12-3111,{PRHLT} Submission to the {WMT}12 Quality Estimation Task,2012,4,17,3,0,42243,jesus rubio,Proceedings of the Seventh Workshop on Statistical Machine Translation,0,"This is a description of the submissions made by the pattern recognition and human language technology group (PRHLT) of the Universitat Politecnica de Valencia to the quality estimation task of the seventh workshop on statistical machine translation (WMT12). We focus on two different issues: how to effectively combine subsequence-level features into sentence-level features, and how to select the most adequate subset of features. Results showed that an adequate selection of a subset of highly discriminative features can improve efficiency and performance of the quality estimation system."
E12-1016,Does more data always yield better translations?,2012,25,25,5,1,43584,guillem gasco,Proceedings of the 13th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"Nowadays, there are large amounts of data available to train statistical machine translation systems. However, it is not clear whether all the training data actually help or not. A system trained on a subset of such huge bilingual corpora might outperform the use of all the bilingual data. This paper studies such issues by analysing two training data selection techniques: one based on approximating the probability of an indomain corpus; and another based on infrequent n-gram occurrence. Experimental results not only report significant improvements over random sentence selection but also an improvement over a system trained with the whole available data. Surprisingly, the improvements are obtained with just a small fraction of the data that accounts for less than 0.5% of the sentences. Afterwards, we show that a much larger room for improvement exists, although this is done under non-realistic conditions."
E12-1025,Active learning for interactive machine translation,2012,0,0,3,1,23854,jesus gonzalezrubio,Proceedings of the 13th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,The research leading to these results has re- ceived funding from the European Union Seventh Framework Programme (FP7/2007-2013) under grant agreement no 287576. Work also supported by the EC (FEDER/FSE) and the Spanish MEC under the MIPRCV Consolider Ingenio 2010 pro- gram (CSD2007-00018) and iTrans2 (TIN2009- 14511) project and by the Generalitat Valenciana under grant ALMPR (Prometeo/2009/01)
2012.eamt-1.5,User Evaluation of Interactive Machine Translation Systems,2012,5,9,4,0,43853,vincent alabau,Proceedings of the 16th Annual conference of the European Association for Machine Translation,0,"Recent developments in search algorithms and software architecture have enabled multi-user web-based prototypes for Interactive Machine Translation (IMT), a technology that aims to assist, rather than replace, the human translator. Surprisingly, formal human evaluations of IMT systems are highly scarce in the literature. To this regard, we discuss experiences gained while testing IMT systems. We report the lessons learned from two user evaluations. Our results can provide researchers and practitioners with several guidelines towards the design of on-line IMT tools."
W11-4414,Stochastic {K}-{TSS} Bi-Languages for Machine Translation,2011,27,4,2,1,41029,ines torres,Proceedings of the 9th International Workshop on Finite State Methods and Natural Language Processing,0,One of the approaches to statistical machine translation is based on joint probability distributions over some source and target languages. In this work we propose to model the joint probability distribution by stochastic regular bi-languages. Specifically we introduce the stochastic k-testable in the strict sense bi-languages to represent the joint probability distribution of source and target languages. With this basis we present a reformulation of the GIATI methodology to infer stochastic regular bi-languages for machine translation purposes.
W11-2116,The {UPV}-{PRHLT} combination system for {WMT} 2011,2011,12,1,2,1,23854,jesus gonzalezrubio,Proceedings of the Sixth Workshop on Statistical Machine Translation,0,This paper presents the submissions of the pattern recognition and human language technology (PRHLT) group to the system combination task of the sixth workshop on statistical machine translation (WMT 2011). Each submissions is generated by a multi-system minimum Bayes risk (MBR) technique. Our technique uses the MBR decision rule and a linear combination of the component systems' probability distributions to search for the minimum risk translation among all the sentences in the target language.
P11-4012,An Interactive Machine Translation System with Online Learning,2011,10,23,5,1,35489,daniel ortizmartinez,Proceedings of the {ACL}-{HLT} 2011 System Demonstrations,0,"State-of-the-art Machine Translation (MT) systems are still far from being perfect. An alternative is the so-called Interactive Machine Translation (IMT) framework, where the knowledge of a human translator is combined with the MT system. We present a statistical IMT system able to learn from user feedback by means of the application of online learning techniques. These techniques allow the MT system to update the parameters of the underlying models in real time. According to empirical results, our system outperforms the results of conventional IMT systems. To the best of our knowledge, this online learning capability has never been provided by previous IMT systems. Our IMT system is implemented in C, JavaScript, and ActionScript; and is publicly available on the Web."
P11-2068,Improving On-line Handwritten Recognition using Translation Models in Multimodal Interactive Machine Translation,2011,14,6,3,1,38851,vicent alabau,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,0,"In interactive machine translation (IMT), a human expert is integrated into the core of a machine translation (MT) system. The human expert interacts with the IMT system by partially correcting the errors of the system's output. Then, the system proposes a new solution. This process is repeated until the output meets the desired quality. In this scenario, the interaction is typically performed using the keyboard and the mouse. In this work, we present an alternative modality to interact within IMT systems by writing on a tactile display or using an electronic pen. An on-line handwritten text recognition (HTR) system has been specifically designed to operate with IMT systems. Our HTR system improves previous approaches in two main aspects. First, HTR decoding is tightly coupled with the IMT system. Second, the language models proposed are context aware, in the sense that they take into account the partial corrections and the source sentence by using a combination of n-grams and word-based IBM models. The proposed system achieves an important boost in performance with respect to previous work."
P11-1127,Minimum {B}ayes-risk System Combination,2011,26,9,3,1,23854,jesus gonzalezrubio,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,1,"We present minimum Bayes-risk system combination, a method that integrates consensus decoding and system combination into a unified multi-system minimum Bayes-risk (MBR) technique. Unlike other MBR methods that re-rank translations of a single SMT system, MBR system combination uses the MBR decision rule and a linear combination of the component systems' probability distributions to search for the minimum risk translation among all the finite-length strings over the output vocabulary. We introduce expected BLEU, an approximation to the BLEU score that allows to efficiently apply MBR in these conditions. MBR system combination is a general method that is independent of specific SMT models, enabling us to combine systems with heterogeneous structure. Experiments show that our approach bring significant improvements to single-system-based MBR decoding and achieves comparable results to different state-of-the-art system combination methods."
W10-1725,{UPV}-{PRHLT} {E}nglish{--}{S}panish System for {WMT}10,2010,8,4,8,1,23855,german sanchistrilles,Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and {M}etrics{MATR},0,"In this paper, the system submitted by the PRHLT group for the Fifth Workshop on Statistical Machine Translation of ACL2010 is presented. On this evaluation campaign, we have worked on the English--Spanish language pair, putting special emphasis on two problems derived from the large amount of data available. The first one, how to optimize the use of the monolingual data within the language model, and the second one, how to make good use of all the bilingual data provided without making use of unnecessary computational resources."
W10-1743,The {UPV}-{PRHLT} Combination System for {WMT} 2010,2010,13,2,8,1,23854,jesus gonzalezrubio,Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and {M}etrics{MATR},0,"UPV-PRHLT participated in the System Combination task of the Fifth Workshop on Statistical Machine Translation (WMT 2010). On each translation direction, all the submitted systems were combined into a consensus translation. These consensus translations always improve translation quality of the best individual system."
P10-2032,Balancing User Effort and Translation Error in Interactive Machine Translation via Confidence Measures,2010,14,18,3,1,23854,jesus gonzalezrubio,Proceedings of the {ACL} 2010 Conference Short Papers,0,"This work deals with the application of confidence measures within an interactive-predictive machine translation system in order to reduce human effort. If a small loss in translation quality can be tolerated for the sake of efficiency, user effort can be saved by interactively translating only those initial translations which the confidence measure classifies as incorrect. We apply confidence estimation as a way to achieve a balance between user effort savings and final translation error. Empirical results show that our proposal allows to obtain almost perfect translations while significantly reducing user effort."
N10-1079,Online Learning for Interactive Statistical Machine Translation,2010,35,56,3,1,35489,daniel ortizmartinez,Human Language Technologies: The 2010 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics,0,"State-of-the-art Machine Translation (MT) systems are still far from being perfect. An alternative is the so-called Interactive Machine Translation (IMT) framework. In this framework, the knowledge of a human translator is combined with a MT system. The vast majority of the existing work on IMT makes use of the well-known batch learning paradigm. In the batch learning paradigm, the training of the IMT system and the interactive translation process are carried out in separate stages. This paradigm is not able to take advantage of the new knowledge produced by the user of the IMT system. In this paper, we present an application of the online learning paradigm to the IMT framework. In the online learning paradigm, the training and prediction stages are no longer separated. This feature is particularly useful in IMT since it allows the user feedback to be taken into account. The online learning techniques proposed here incrementally update the statistical models involved in the translation process. Empirical results show the great potential of online learning in the IMT framework."
gonzalez-rubio-etal-2010-saturnalia,{S}aturnalia: A {L}atin-{C}atalan Parallel Corpus for Statistical {MT},2010,11,0,4,1,23854,jesus gonzalezrubio,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"Currently, a great effort is being carried out in the digitalisation of large historical document collections for preservation purposes. The documents in these collections are usually written in ancient languages, such as Latin or Greek, which limits the access of the general public to their content due to the language barrier. Therefore, digital libraries aim not only at storing raw images of digitalised documents, but also to annotate them with their corresponding text transcriptions and translations into modern languages. Unfortunately, ancient languages have at their disposal scarce electronic resources to be exploited by natural language processing techniques. This paper describes the compilation process of a novel Latin-Catalan parallel corpus as a new task for statistical machine translation (SMT). Preliminary experimental results are also reported using a state-of-the-art phrase-based SMT system. The results presented in this work reveal the complexity of the task and its challenging, but interesting nature for future development."
C10-2124,Log-linear weight optimisation via {B}ayesian Adaptation in Statistical Machine Translation,2010,24,17,2,1,23855,german sanchistrilles,Coling 2010: Posters,0,"We present an adaptation technique for statistical machine translation, which applies the well-known Bayesian learning paradigm for adapting the model parameters. Since state-of-the-art statistical machine translation systems model the translation process as a log-linear combination of simpler models, we present the formal derivation of how to apply such paradigm to the weights of the log-linear combination. We show empirical results in which a small amount of adaptation data is able to improve both the non-adapted system and a system which optimises the above-mentioned weights on the adaptation set only, while gaining both in reliability and speed."
2010.iwslt-evaluation.10,{ITI}-{UPV} machine translation system for {IWSLT} 2010,2010,0,4,7,1,43584,guillem gasco,Proceedings of the 7th International Workshop on Spoken Language Translation: Evaluation Campaign,0,This paper presents the submissions of the PRHLT group for the evaluation campaign of the International Workshop on Spoken Language Translation. We focus on the development of reliable translation systems between syntactically different languages (DIALOG task) and on the efficient training of SMT models in resource-rich scenarios (TALK task).
2010.eamt-1.16,Potential scope of a fully-integrated architecture for speech translation,2010,18,3,3,1,33527,alicia perez,Proceedings of the 14th Annual conference of the European Association for Machine Translation,0,"The classical approach to tackle speech translation assembles a text-to-text translation system placed after a speech recogniser, yielding the so-called decoupled architecture. In this regard, there are two issues to bear in mind: first, what is translated in the decoupled architecture is the most likely transcription of the spoken utterance; second, translation systems are sensitive to errors in the source string, and speech recognition systems are still far from being flawless. In this paper we promote the use of an architecture to carry out speech translation that allows to build up the most likely translation relying upon both acoustic and translation models in a cooperative manner, that is the so-called integrated architecture. The integrated architecture is implemented in the finite-state framework by virtue of the composition of finite-state acoustic models of the source language within a stochastic finite-state transducer that would encompass source and target languages. The potential performance of the integrated architecture is assessed quantitatively in relation to the decoupled one. We conclude that while the single-best approach for both decoupled and integrated architectures show similar performance, an oracle evaluation reveals that the potential scope of the integrated architecture would offer statistically significant differences."
2010.eamt-1.18,On the Use of Confidence Measures within an Interactive-predictive Machine Translation System,2010,-1,-1,3,1,23854,jesus gonzalezrubio,Proceedings of the 14th Annual conference of the European Association for Machine Translation,0,None
W09-1005,{GREAT}: A Finite-State Machine Translation Toolkit Implementing a Grammatical Inference Approach for Transducer Inference ({GIATI}),2009,10,3,2,1,42032,jorge gonzalez,Proceedings of the {EACL} 2009 Workshop on Computational Linguistic Aspects of Grammatical Inference,0,"GREAT is a finite-state toolkit which is devoted to Machine Translation and that learns structured models from bilingual data. The training procedure is based on grammatical inference techniques to obtain stochastic transducers that model both the structure of the languages and the relationship between them. The inference of grammars from natural language causes the models to become larger when a less restrictive task is involved; even more if a bilingual modelling is being considered. GREAT has been successful to implement the GIATI learning methodology, using different scalability issues to be able to deal with corpora of high volume of data. This is reported with experiments on the EuroParl corpus, which is a state-of-the-art task in Statistical Machine Translation."
R09-1060,Interactive Machine Translation Based on Partial Statistical Phrase-based Alignments,2009,16,9,3,1,35489,daniel ortizmartinez,Proceedings of the International Conference {RANLP}-2009,0,"State-of-the-art Machine Translation (MT) systems are still far from being perfect. An alternative is the so-called Interactive Machine Translation (IMT) framework. In this framework, the knowledge of a human translator is combined with a MT system. We present a new technique for IMT which is based on the generation of partial alignments at phrase-level. The proposed technique partially aligns the source sentence with the user prefix and then translates the unaligned portion of the source sentence. The generation of such partial alignments is driven by statistical phrase-based models. Our technique relies on the application of smoothing techniques over the phrase models to appropriately assign probabilities to unseen events. We report experiments investigating the impact of the different smoothing techniques in the accuracy of our system. In addition, we compare the results obtained by our system with those obtained by other well-known IMT systems."
N09-2055,Statistical Post-Editing of a Rule-Based Machine Translation System,2009,11,53,3,0,47320,antoniol lagarda,"Proceedings of Human Language Technologies: The 2009 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics, Companion Volume: Short Papers",0,"Automatic post-editing (APE) systems aim at correcting the output of machine translation systems to produce better quality translations, i.e. produce translations can be manually post-edited with an increase in productivity. In this work, we present an APE system that uses statistical models to enhance a commercial rule-based machine translation (RBMT) system. In addition, a procedure for effortless human evaluation has been established. We have tested the APE system with two corpora of different complexity. For the Parliament corpus, we show that the APE system significantly complements and improves the RBMT system. Results for the Protocols corpus, although less conclusive, are promising as well. Finally, several possible sources of errors have been identified which will help develop future system enhancements."
J09-1002,Statistical Approaches to Computer-Assisted Translation,2009,57,140,3,0,47362,sergio barrachina,Computational Linguistics,0,"Current machine translation (MT) systems are still not perfect. In practice, the output from these systems needs to be edited to correct errors. A way of increasing the productivity of the whole translation process (MT plus human work) is to incorporate the human correction activities within the translation process itself, thereby shifting the MT paradigm to that of computer-assisted translation. This model entails an iterative process in which the human translator activity is included in the loop: In each iteration, a prefix of the translation is validated (accepted or amended) by the human and the system computes its best (or n-best) translation suffix hypothesis to complete this prefix. A successful framework for MT is the so-called statistical (or pattern recognition) framework. Interestingly, within this framework, the adaptation of MT systems to the interactive scenario affects mainly the search process, allowing a great reuse of successful techniques and models. In this article, alignment templates, phrase-based models, and stochastic finite-state transducers are used to develop computer-assisted translation systems. These systems were assessed in a European project (TransType2) in two real tasks: The translation of printer manuals; manuals and the translation of the Bulletin of the European Union. In each task, the following three pairs of languages were involved (in both translation directions): English-Spanish, English-German, and English-French."
D08-1051,Improving Interactive Machine Translation via Mouse Actions,2008,25,24,4,1,23855,german sanchistrilles,Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,0,"Although Machine Translation (MT) is a very active research field which is receiving an increasing amount of attention from the research community, the results that current MT systems are capable of producing are still quite far away from perfection. Because of this, and in order to build systems that yield correct translations, human knowledge must be integrated into the translation process, which will be carried out in our case in an Interactive-Predictive (IP) framework. In this paper, we show that considering Mouse Actions as a significant information source for the underlying system improves the productivity of the human translator involved. In addition, we also show that the initial translations that the MT system provides can be quickly improved by an expert by only performing additional Mouse Actions. In this work, we will be using word graphs as an efficient interface between a phrase-based MT system and the IP engine."
2008.eamt-1.8,A finite-state framework for log-linear models in machine translation,2008,-1,-1,2,1,42032,jorge gonzalez,Proceedings of the 12th Annual conference of the European Association for Machine Translation,0,None
2008.eamt-1.9,A novel alignment model inspired on {IBM} Model 1,2008,28,3,4,1,23854,jesus gonzalezrubio,Proceedings of the 12th Annual conference of the European Association for Machine Translation,0,We present an extension to IBM Model 1 for training word-to-word lexicon probabilities. This model takes into account a given fixed segmentation of the source and target sentences in the estimation of the statistical dictionary. Our experimentation on the Europarl corpus shows that a statistical consistent improvement in the translation quality can be achieved by including our proposed model as a new information source in a log-linear combination of models.
2008.eamt-1.14,Applying boosting to statistical machine translation,2008,-1,-1,2,1,47364,antonio lagarda,Proceedings of the 12th Annual conference of the European Association for Machine Translation,0,None
2008.eamt-1.22,Phrase-level alignment generation using a smoothed loglinear phrase-based statistical alignment model,2008,-1,-1,3,1,35489,daniel ortizmartinez,Proceedings of the 12th Annual conference of the European Association for Machine Translation,0,None
W07-0708,Speech-Input Multi-Target Machine Translation,2007,16,2,4,1,33527,alicia perez,Proceedings of the Second Workshop on Statistical Machine Translation,0,"In order to simultaneously translate speech into multiple languages an extension of stochastic finite-state transducers is proposed. In this approach the speech translation model consists of a single network where acoustic models (in the input) and the multilingual model (in the output) are embedded.n n The multi-target model has been evaluated in a practical situation, and the results have been compared with those obtained using several mono-target models. Experimental results show that the multi-target one requires less amount of memory. In addition, a single decoding is enough to get the speech translated into multiple languages."
N07-2034,An Integrated Architecture for Speech-Input Multi-Target Machine Translation,2007,7,0,4,1,33527,alicia perez,"Human Language Technologies 2007: The Conference of the North {A}merican Chapter of the Association for Computational Linguistics; Companion Volume, Short Papers",0,"The aim of this work is to show the ability of finite-state transducers to simultaneously translate speech into multiple languages. Our proposal deals with an extension of stochastic finite-state transducers that can produce more than one output at the same time. These kind of devices offer great versatility for the integration with other finite-state devices such as acoustic models in order to produce a speech translation system. This proposal has been evaluated in a practical situation, and its results have been compared with those obtained using a standard mono-target speech transducer."
2007.tmi-papers.2,Combining translation models in statistical machine translation,2007,-1,-1,3,1,43585,jesus andresferrer,Proceedings of the 11th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages: Papers,0,None
2007.tmi-papers.23,Reordering via n-best lists for {S}panish-{B}asque translation,2007,-1,-1,2,0,41869,german sanchis,Proceedings of the 11th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages: Papers,0,None
2007.mtsummit-papers.2,Improving speech-to-speech translation using word posterior probabilities,2007,-1,-1,3,1,41890,vicente alabau,Proceedings of Machine Translation Summit XI: Papers,0,None
2007.iwslt-1.2,A comparison of linguistically and statistically enhanced models for speech-to-speech machine translation,2007,11,1,5,1,33527,alicia perez,Proceedings of the Fourth International Workshop on Spoken Language Translation,0,"The goal of this work is to improve current translation models by taking into account additional knowledge sources such as semantically motivated segmentation or statistical categorization. Specifically, two different approaches are discussed. On the one hand, phrase-based approach, and on the other hand, categorization. For both approaches, both statistical and linguistic alternatives are explored. As for translation framework, finite-state transducers are considered. These are versatile models that can be easily integrated on-the-fly with acoustic models for speech translation purposes. In what the experimental framework concerns, all the models presented were evaluated and compared taking confidence intervals into account."
2007.iwslt-1.19,Using word posterior probabilities in lattice translation,2007,21,1,3,1,41890,vicente alabau,Proceedings of the Fourth International Workshop on Spoken Language Translation,0,"In this paper we describe the statistical machine translation system developed at ITI/UPV, which aims especially at speech recognition and statistical machine translation integration, for the evaluation campaign of the International Workshop on Spoken Language Translation (2007). The system we have developed takes advantage of an improved word lattice representation that uses word posterior probabilities. These word posterior probabilities are then added as a feature to a log-linear model. This model includes a stochastic finite-state transducer which allows an easy lattice integration. Furthermore, it provides a statistical phrase-based reordering model that is able to perform local reorderings of the output. We have tested this model on the Italian-English corpus, for clean text, 1-best ASR and lattice ASR inputs. The results and conclusions of such experiments are reported at the end of this paper."
W06-3109,Generalized Stack Decoding Algorithms for Statistical Machine Translation,2006,16,1,3,0,49654,daniel martinez,Proceedings on the Workshop on Statistical Machine Translation,0,"In this paper we propose a generalization of the Stack-based decoding paradigm for Statistical Machine Translation. The well known single and multi-stack decoding algorithms defined in the literature have been integrated within a new formalism which also defines a new family of stack-based decoders. These decoders allows a tradeoff to be made between the advantages of using only one or multiple stacks. The key point of the new formalism consists in parameterizeing the number of stacks to be used during the decoding process, and providing an efficient method to decide in which stack each partial hypothesis generated is to be inserted-during the search process. Experimental results are also reported for a search algorithm for phrase-based statistical translation models."
P06-2107,Statistical Phrase-Based Models for Interactive Computer-Assisted Translation,2006,18,20,2,1,46052,jesus tomas,Proceedings of the {COLING}/{ACL} 2006 Main Conference Poster Sessions,0,"Obtaining high-quality machine translations is still a long way off. A post-editing phase is required to improve the output of a machine translation system. An alternative is the so called computer-assisted translation. In this framework, a human translator interacts with the system in order to obtain high-quality translations. A statistical phrase-based approach to computer-assisted translation is described in this article. A new decoder algorithm for interactive search is also presented, that combines monotone and non-monotone search. The system has been assessed in the Trans Type-2 project for the translation of several printer manuals, from (to) English to (from) Spanish, German and French."
2006.eamt-1.5,A Computer-Assisted Translation Tool based on Finite-State Technology,2006,-1,-1,4,0.833333,23848,jorge civera,Proceedings of the 11th Annual conference of the European Association for Machine Translation,0,None
2005.mtsummit-papers.19,Thot: a Toolkit To Train Phrase-based Statistical Translation Models,2005,-1,-1,3,1,35489,daniel ortizmartinez,Proceedings of Machine Translation Summit X: Papers,0,"In this paper, we present the Thot toolkit, a set of tools to train phrase-based models for statistical machine translation, which is publicly available as open source software. The toolkit obtains phrase-based models from word-based alignment models; to our knowledge, this functionality has not been offered by any publicly available toolkit. The Thot toolkit also implements a new way for estimating phrase models, this allows to obtain more complete phrase models than the methods described in the literature, including a segmentation length submodel. The toolkit output can be given in different formats in order to be used by other statistical machine translation tools like Pharaoh, which is a beam search decoder for phrase-based alignment models which was used in order to perform translation experiments with the generated models. Additionally, the Thot toolkit can be used to obtain the best alignment between a sentence pair at phrase level."
W04-3245,From Machine Translation to Computer Assisted Translation using Finite-State Models,2004,12,18,7,0.833333,23848,jorge civera,Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing,0,"State-of-the-art machine translation techniques are still far from producing high quality translations. This drawback leads us to introduce an alternative approach to the translation problem that brings human expertise into the machine translation scenario. In this framework, namely Computer Assisted Translation (CAT), human translators interact with a translation system, as an assistance tool, that dinamically offers, a list of translations that best completes the part of the sentence already translated. In this paper, finite state transducers are presented as a candidate technology in the CAT paradigm. The appropriateness of this technique is evaluated on a printer manual corpus and results from preliminary experiments confirm that human translators would reduce to less than 25% the amount of work to be done for the same task."
nevado-etal-2004-translation,Translation Memories Enrichment by Statistical Bilingual Segmentation,2004,12,8,2,0,52156,francisco nevado,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"A majority of Machine Aided Translation systems are based on comparisons between a source sentence and reference sentences stored in Translation Memories (TMs). The translation search is done by looking for sentences in a database which are similar to the source sentence. TMs have two basic limitations: the dependency on the repetition of complete sentences and the high cost of building a TM. As human translators do not only remember sentences from their preceding translations, but they also decompose the sentence to be translated and work with smaller units, it would be desirable to enrich the TM database with smaller translation units. This enrichment should also be automatic in order not to increase the cost of building a TM. We propose the application of two automatic bilingual segmentation techniques based on statistical translation methods in order to create new, shorter bilingual segments to be included in a TM database. An evaluation of the two techniques is carried out for a bilingual Basque-Spanish task."
J04-2004,Machine Translation with Inferred Stochastic Finite-State Transducers,2004,38,132,1,1,5066,francisco casacuberta,Computational Linguistics,0,"Finite-state transducers are models that are being used in different areas of pattern recognition and computational linguistics. One of these areas is machine translation, in which the approaches that are based on building models automatically from training examples are becoming more and more attractive. Finite-state transducers are very adequate for use in constrained tasks in which training samples of pairs of sentences are available. A technique for inferring finite-state transducers is proposed in this article. This technique is based on formal relations between finite-state transducers and rational grammars. Given a training corpus of source-target pairs of sentences, the proposed approach uses statistical alignment methods to produce a set of conventional strings from which a stochastic rational grammar (e.g., an n -gram) is inferred. This grammar is finally converted into a finite-state transducer. The proposed methods are assessed through a series of machine translation experiments within the framework of the EuTrans project."
W03-2804,A Quantitative Method for Machine Translation Evaluation,2003,6,12,3,1,46052,jesus tomas,"Proceedings of the {EACL} 2003 Workshop on Evaluation Initiatives in Natural Language Processing: are evaluation methods, metrics and resources reusable?",0,"Accurate evaluation of machine translation (MT) is an open problem. A brief survey of the current approach to tackle this problem is presented and a new proposal is introduced. This proposal attempts to measure the percentage of words, which should be modified at the output of an automatic translator in order to obtain a correct translation. To show the feasibility of the method we have assessed the most important Spanish-Catalan translators in comparing the results obtained by the various methods."
W03-2205,Parallel Corpora Segmentation Using Anchor Words,2003,5,11,2,0,52156,francisco nevado,"Proceedings of the 7th International {EAMT} workshop on {MT} and other language technology tools, Improving {MT} through other language technology tools, Resource and tools for building {MT} at {EACL} 2003",0,"A new technique for monotone segmentation of parallel corpora is introduced. This segmentation is based on a set of anchor words which are defined manually. The parallel segments are computed using a dynamic programming algorithm. To assess this technique, finite-state transducers are inferred from both non-segmented and segmented corpora. Experiments have been carried out with Spanish-English and Italian-English translation tasks. This technique has proven useful in improving the results with respect to those obtained with unsegmented corpora."
2003.mtsummit-papers.40,On the use of statistical machine-translation techniques within a memory-based translation system ({AMETRA}),2003,-1,-1,3,0,26967,daniel ortiz,Proceedings of Machine Translation Summit IX: Papers,0,"The goal of the AMETRA project is to make a computer-assisted translation tool from the Spanish language to the Basque language under the memory-based translation framework. The system is based on a large collection of bilingual word-segments. These segments are obtained using linguistic or statistical techniques from a Spanish-Basque bilingual corpus consisting of sentences extracted from the Basque Country{'}s of{\pounds}cial government record. One of the tasks within the global information document of the AMETRA project is to study the combination of well-known statistical techniques for the translation of short sequences and techniques for memory-based translation. In this paper, we address the problem of constructing a statistical module to deal with the task of translating segments. The task undertaken in the AMETRA project is compared with other existing translation tasks, This study includes the results of some preliminary experiments we have carried out using well-known statistical machine translation tools and techniques."
2003.eamt-1.6,Adapting finite-state translation to the {T}rans{T}ype2 project,2003,9,10,4,0,47363,elsa cubel,EAMT Workshop: Improving MT through other language technology tools: resources and tools for building MT,0,"Machine translation can play an important role nowadays, helping communication between people. One of the projects in this field is TransType2 1. Its purpose is to develop an innovative, interactive machine translation system. TransType2 aims at facilitating the task of producing high-quality translations, and make the translation task more cost-effective for human translators. To achieve this goal, stochastic finite-state transducers are being used. Stochastic finite-state transducers are generated by means of hybrid finite-state and statistical alignment techniques. Viterbi parsing procedure with stochastic finite-state transducers have been adapted to take into account the source sentence to be translated and the target prefix given by the human translator. Experiments have been carried out with a corpus of printer manuals. The first results showed that with this preliminary prototype, users can only type a 15% of the words instead the whole complete translated text. TransType2 Computer Assisted Translation, RTD project by the European Commission under the IST Programme (IST2001-32091)."
W02-0706,Architectures for Speech-to-Speech Translation Using Finite-state Models,2002,9,27,1,1,5066,francisco casacuberta,Proceedings of the {ACL}-02 Workshop on Speech-to-Speech Translation: Algorithms and Systems,0,"Speech-to-speech translation can be approached using finite state models and several ideas borrowed from automatic speech recognition. The models can be Hidden Markov Models for the accoustic part, language models for the source language and finite state transducers for the transfer between the source and target language. A serial architecture would use the Hidden Markov and the language models for recognizing input utterance and the transducer for finding the translation. An integrated architecture, on the other hand, would integrate all the models in a single network where the search process takes place. The output of this search process is the target word sequence associated to the optimal path. In both architectures, HMMs can be trained from a source-language speech corpus, and the translation model can be learned automatically from a parallel text training corpus. The experiments presented here correspond to speech-input translations from Spanish to English and from Italian to English, in applications involving the interaction (by telephone) of a customer with the front-desk of a hotel."
C02-1032,Improving Alignment Quality in Statistical Machine Translation Using Context-dependent Maximum Entropy Models,2002,9,16,4,0,49655,ismael varea,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"Typically, statistical alignment models are based on single-word dependencies. These models do not include contextual information, which can lead to inadequate alignments. In this paper, we present an approach to include contextual dependencies in the statistical alignment model by using a refined lexicon model. Unlike previous work, we directly integrate this in the EM algorithm of statistical alignment models. Experimental results are given for the French-English Canadian Parliament Hansards task and the Verbmobil task. The evaluation is performed by comparing the obtained alignments with a manually annotated reference alignment."
garcia-varea-etal-2002-efficient,Efficient integration of maximum entropy lexicon models within the training of statistical alignment models,2002,10,5,4,1,43571,ismael garciavarea,Proceedings of the 5th Conference of the Association for Machine Translation in the Americas: Technical Papers,0,"Maximum entropy (ME) models have been successfully applied to many natural language problems. In this paper, we show how to integrate ME models efficiently within a maximum likelihood training scheme of statistical machine translation models. Specifically, we define a set of context-dependent ME lexicon models and we present how to perform an efficient training of these ME models within the conventional expectation-maximization (EM) training of statistical translation models. Experimental results are also given in order to demonstrate how these ME models improve the results obtained with the traditional translation models. The results are presented by means of alignment quality comparing the resulting alignments with manually annotated reference alignments."
P01-1027,Refined Lexicon Models for Statistical Machine Translation using a Maximum Entropy Approach,2001,17,29,4,1,43571,ismael garciavarea,Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics,1,"Typically, the lexicon models used in statistical machine translation systems do not include any kind of linguistic or contextual information, which often leads to problems in performing a correct word sense disambiguation. One way to deal with this problem within the statistical framework is to use maximum entropy methods. In this paper, we present how to use this type of information within a statistical machine translation system. We show that it is possible to significantly decrease training and test corpus perplexity of the translation models. In addition, we perform a rescoring of N-Best lists using our maximum entropy model and thereby yield an improvement in translation quality. Experimental results are presented on the so-called Verbmobil Task."
2001.mtsummit-papers.22,Search algorithms for statistical machine translation based on dynamic programming and pruning techniques,2001,8,11,2,1,43571,ismael garciavarea,Proceedings of Machine Translation Summit VIII,0,"The increasing interest in the statistical approach to Machine Translation is due to the development of effective algorithms for training the probabilistic models proposed so far. However, one of the open problems with statistical machine translation is the design of efficient algorithms for translating a given input string. For some interesting models, only (good) approximate solutions can be found. Recently, a dynamic programming-like algorithm for the IBM-Model 2 has been proposed which is based on an iterative process of refinement solutions. A new dynamic programming-like algorithm is proposed here to deal with more complex IBM models (models 3 to 5). The computational cost of the algorithm is reduced by using an alignment-based pruning technique. Experimental results with the so-called {``}Tourist Task{''} are also presented."
2001.mtsummit-papers.55,A morphological analyser for machine translation based on finite-state transducers,2001,12,3,7,1,42244,alberto sanchis,Proceedings of Machine Translation Summit VIII,0,"A finite-state, rule-based morphological analyser is presented here, within the framework of machine translation system TAVAL. This morphological analyser introduces specific features which are particularly useful for translation, such as the detection and morphological tagging of word groups that act as a single lexical unit for translation purposes. The case where words in one such group are not strictly contiguous is also covered. A brief description of the Spanish-to-Catalan and Catalan-to-Spanish translation system TAVAL is given in the paper."
2001.mtsummit-papers.64,Monotone statistical translation using word groups,2001,14,44,2,1,46052,jesus tomas,Proceedings of Machine Translation Summit VIII,0,"A new system for statistical natural language translation for languages with similar grammar is introduced. Specifically, it can be used with Romanic Languages, such as French, Spanish or Catalan. The statistical translation uses two sources of information: a language model and a translation model. The language model used is a standard trigram model. A new approach is defined in the translation model. The two main properties of the translation model are: the translation probabilities are computed between groups of words and the alignment between those groups is monotone. That is, the order between the word groups in the source sentence is conserved in the target sentence. Once, the translation model has been defined, we present an algorithm to infer its parameters from training samples. The translation process is carried out with an efficient algorithm based on stack-decoding. Finally, we present some translation results from Catalan to Spanish and compare our model with other conventional models."
1997.tmi-1.16,Error correcting parsing for text-to-text machine translation using finite state models,1997,-1,-1,3,0,55748,juan amengual,Proceedings of the 7th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,None
1997.tmi-1.19,Machine translation using neural networks and finite-state models,1997,-1,-1,2,0,55749,asuncion castano,Proceedings of the 7th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,None
