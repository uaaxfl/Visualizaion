2021.teachingnlp-1.20,Naive {B}ayes versus {BERT}: {J}upyter notebook assignments for an introductory {NLP} course,2021,-1,-1,1,1,819,jennifer foster,Proceedings of the Fifth Workshop on Teaching NLP,0,"We describe two Jupyter notebooks that form the basis of two assignments in an introductory Natural Language Processing (NLP) module taught to final year undergraduate students at Dublin City University. The notebooks show the students how to train a bag-of-words polarity classifier using multinomial Naive Bayes, and how to fine-tune a polarity classifier using BERT. The students take the code as a starting point for their own experiments."
2021.iwpt-1.22,The {DCU}-{EPFL} Enhanced Dependency Parser at the {IWPT} 2021 Shared Task,2021,-1,-1,4,1,5840,james barry,Proceedings of the 17th International Conference on Parsing Technologies and the IWPT 2021 Shared Task on Parsing into Enhanced Universal Dependencies (IWPT 2021),0,"We describe the DCU-EPFL submission to the IWPT 2021 Parsing Shared Task: From Raw Text to Enhanced Universal Dependencies. The task involves parsing Enhanced UD graphs, which are an extension of the basic dependency trees designed to be more facilitative towards representing semantic structure. Evaluation is carried out on 29 treebanks in 17 languages and participants are required to parse the data from each language starting from raw strings. Our approach uses the Stanza pipeline to preprocess the text files, XLM-RoBERTa to obtain contextualized token representations, and an edge-scoring and labeling model to predict the enhanced graph. Finally, we run a postprocessing script to ensure all of our outputs are valid Enhanced UD graphs. Our system places 6th out of 9 participants with a coarse Enhanced Labeled Attachment Score (ELAS) of 83.57. We carry out additional post-deadline experiments which include using Trankit for pre-processing, XLM-RoBERTa LARGE, treebank concatenation, and multitask learning between a basic and an enhanced dependency parser. All of these modifications improve our initial score and our final system has a coarse ELAS of 88.04."
2021.emnlp-main.340,Improving Unsupervised Question Answering via Summarization-Informed Question Generation,2021,-1,-1,4,0,9402,chenyang lyu,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"Question Generation (QG) is the task of generating a plausible question for a given {\textless}passage, answer{\textgreater} pair. Template-based QG uses linguistically-informed heuristics to transform declarative sentences into interrogatives, whereas supervised QG uses existing Question Answering (QA) datasets to train a system to generate a question given a passage and an answer. A disadvantage of the heuristic approach is that the generated questions are heavily tied to their declarative counterparts. A disadvantage of the supervised approach is that they are heavily tied to the domain/language of the QA dataset used as training data. In order to overcome these shortcomings, we propose a distantly-supervised QG method which uses questions generated heuristically from summaries as a source of training data for a QG system. We make use of freely available news summary data, transforming declarative summary sentences into appropriate questions using heuristics informed by dependency parsing, named entity recognition and semantic role labeling. The resulting questions are then combined with the original news articles to train an end-to-end neural QG model. We extrinsically evaluate our approach using unsupervised QA: our QG model is used to generate synthetic QA pairs for training a QA model. Experimental results show that, trained with only 20k English Wikipedia-based synthetic QA pairs, the QA model substantially outperforms previous unsupervised models on three in-domain datasets (SQuAD1.1, Natural Questions, TriviaQA) and three out-of-domain datasets (NewsQA, BioASQ, DuoRC), demonstrating the transferability of the approach."
2021.emnlp-main.693,{E}nglish Machine Reading Comprehension Datasets: A Survey,2021,-1,-1,2,1,10031,daria dzendzik,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"This paper surveys 60 English Machine Reading Comprehension datasets, with a view to providing a convenient resource for other researchers interested in this problem. We categorize the datasets according to their question and answer form and compare them across various dimensions including size, vocabulary, data source, method of creation, human performance level, and first question word. Our analysis reveals that Wikipedia is by far the most common data source and that there is a relative lack of why, when, and where questions across datasets."
2021.emnlp-main.745,Revisiting Tri-training of Dependency Parsers,2021,-1,-1,2,0,820,joachim wagner,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"We compare two orthogonal semi-supervised learning techniques, namely tri-training and pretrained word embeddings, in the task of dependency parsing. We explore language-specific FastText and ELMo embeddings and multilingual BERT embeddings. We focus on a low resource scenario as semi-supervised learning can be expected to have the most impact here. Based on treebank size and available ELMo models, we select Hungarian, Uyghur (a zero-shot language for mBERT) and Vietnamese. Furthermore, we include English in a simulated low-resource setting. We find that pretrained word embeddings make more effective use of unlabelled data than tri-training but that the two approaches can be successfully combined."
2020.mwe-1.7,Annotating Verbal {MWE}s in {I}rish for the {PARSEME} Shared Task 1.2,2020,-1,-1,3,1,14283,abigail walsh,Proceedings of the Joint Workshop on Multiword Expressions and Electronic Lexicons,0,"This paper describes the creation of two Irish corpora (labelled and unlabelled) for verbal MWEs for inclusion in the PARSEME Shared Task 1.2 on automatic identification of verbal MWEs, and the process of developing verbal MWE categories for Irish. A qualitative analysis on the two corpora is presented, along with discussion of Irish verbal MWEs."
2020.iwpt-1.24,The {ADAPT} Enhanced Dependency Parser at the {IWPT} 2020 Shared Task,2020,-1,-1,3,1,5840,james barry,Proceedings of the 16th International Conference on Parsing Technologies and the IWPT 2020 Shared Task on Parsing into Enhanced Universal Dependencies,0,"We describe the ADAPT system for the 2020 IWPT Shared Task on parsing enhanced Universal Dependencies in 17 languages. We implement a pipeline approach using UDPipe and UDPipe-future to provide initial levels of annotation. The enhanced dependency graph is either produced by a graph-based semantic dependency parser or is built from the basic tree using a small set of heuristics. Our results show that, for the majority of languages, a semantic dependency parser can be successfully applied to the task of parsing enhanced dependencies. Unfortunately, we did not ensure a connected graph as part of our pipeline approach and our competition submission relied on a last-minute fix to pass the validation script which harmed our official evaluation scores significantly. Our submission ranked eighth in the official evaluation with a macro-averaged coarse ELAS F1 of 67.23 and a treebank average of 67.49. We later implemented our own graph-connecting fix which resulted in a score of 79.53 (language average) or 79.76 (treebank average), which would have placed fourth in the competition evaluation."
2020.insights-1.2,{Q}. Can Knowledge Graphs be used to Answer {B}oolean Questions? {A}. It{'}s complicated!,2020,-1,-1,3,1,10031,daria dzendzik,Proceedings of the First Workshop on Insights from Negative Results in NLP,0,"In this paper we explore the problem of machine reading comprehension, focusing on the BoolQ dataset of Yes/No questions. We carry out an error analysis of a BERT-based machine reading comprehension model on this dataset, revealing issues such as unstable model behaviour and some noise within the dataset itself. We then experiment with two approaches for integrating information from knowledge graphs: (i) concatenating knowledge graph triples to text passages and (ii) encoding knowledge with a Graph Neural Network. Neither of these approaches show a clear improvement and we hypothesize that this may be due to a combination of inaccuracies in the knowledge graph, imprecision in entity linking, and the models{'} inability to capture additional information from knowledge graphs."
2020.emnlp-main.230,How to Make Neural Natural Language Generation as Reliable as Templates in Task-Oriented Dialogue,2020,-1,-1,3,1,16529,henry elder,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,"Neural Natural Language Generation (NLG) systems are well known for their unreliability. To overcome this issue, we propose a data augmentation approach which allows us to restrict the output of a network and guarantee reliability. While this restriction means generation will be less diverse than if randomly sampled, we include experiments that demonstrate the tendency of existing neural generation approaches to produce dull and repetitive text, and we argue that reliability is more important than diversity for this task. The system trained using this approach scored 100{\%} in semantic accuracy on the E2E NLG Challenge dataset, the same as a template system."
2020.coling-main.590,Improving Document-Level Sentiment Analysis with User and Product Context,2020,-1,-1,2,0,9402,chenyang lyu,Proceedings of the 28th International Conference on Computational Linguistics,0,"Past work that improves document-level sentiment analysis by encoding user and product in- formation has been limited to considering only the text of the current review. We investigate incorporating additional review text available at the time of sentiment prediction that may prove meaningful for guiding prediction. Firstly, we incorporate all available historical review text belonging to the author of the review in question. Secondly, we investigate the inclusion of his- torical reviews associated with the current product (written by other users). We achieve this by explicitly storing representations of reviews written by the same user and about the same product and force the model to memorize all reviews for one particular user and product. Additionally, we drop the hierarchical architecture used in previous work to enable words in the text to directly attend to each other. Experiment results on IMDB, Yelp 2013 and Yelp 2014 datasets show improvement to state-of-the-art of more than 2 percentage points in the best case."
2020.acl-main.665,{S}hape of Synth to Come: {W}hy We Should Use Synthetic Data for {E}nglish Surface Realization,2020,24,0,4,1,16529,henry elder,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,1,"The Surface Realization Shared Tasks of 2018 and 2019 were Natural Language Generation shared tasks with the goal of exploring approaches to surface realization from Universal-Dependency-like trees to surface strings for several languages. In the 2018 shared task there was very little difference in the absolute performance of systems trained with and without additional, synthetically created data, and a new rule prohibiting the use of synthetic data was introduced for the 2019 shared task. Contrary to the findings of the 2018 shared task, we show, in experiments on the English 2018 dataset, that the use of synthetic data can have a substantial positive effect {--} an improvement of almost 8 BLEU points for a previously state-of-the-art system. We analyse the effects of synthetic data, and we argue that its use should be encouraged rather than prohibited so that future research efforts continue to explore systems that can take advantage of such data."
2020.acl-main.778,Treebank Embedding Vectors for Out-of-Domain Dependency Parsing,2020,9,0,3,0.876493,820,joachim wagner,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,1,"A recent advance in monolingual dependency parsing is the idea of a treebank embedding vector, which allows all treebanks for a particular language to be used as training data while at the same time allowing the model to prefer training data from one treebank over others and to select the preferred treebank at test time. We build on this idea by 1) introducing a method to predict a treebank vector for sentences that do not come from a treebank used in training, and 2) exploring what happens when we move away from predefined treebank embedding vectors during test time and instead devise tailored interpolations. We show that 1) there are interpolated vectors that are superior to the predefined ones, and 2) treebank vectors can be predicted with sufficient accuracy, for nine out of ten test languages, to match the performance of an oracle approach that knows the most suitable predefined treebank embedding for the test set."
W19-5120,{I}lfhocail: A Lexicon of {I}rish {MWE}s,2019,0,0,3,1,14283,abigail walsh,Proceedings of the Joint Workshop on Multiword Expressions and WordNet (MWE-WN 2019),0,"This paper describes the categorisation of Irish MWEs, and the construction of the first version of a lexicon of Irish MWEs for NLP purposes (Ilfhocail, meaning {`}Multiwords{'}), collected from a number of resources. For the purposes of quality assurance, 530 entries of this lexicon were examined and manually annotated for POS information and MWE category."
W19-2308,Designing a Symbolic Intermediate Representation for Neural Surface Realization,2019,35,0,2,1,16529,henry elder,Proceedings of the Workshop on Methods for Optimizing and Evaluating Neural Language Generation,0,"Generated output from neural NLG systems often contain errors such as hallucination, repetition or contradiction. This work focuses on designing a symbolic intermediate representation to be used in multi-stage neural generation with the intention of reducing the frequency of failed outputs. We show that surface realization from this intermediate representation is of high quality and when the full system is applied to the E2E dataset it outperforms the winner of the E2E challenge. Furthermore, by breaking out the surface realization step from typically end-to-end neural systems, we also provide a framework for non-neural based content selection and planning systems to potentially take advantage of semi-supervised pretraining of neural surface realization models."
P19-2048,Fact or Factitious? Contextualized Opinion Spam Detection,2019,0,1,5,0,25528,stefan kennedy,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop,0,"In this paper we perform an analytic comparison of a number of techniques used to detect fake and deceptive online reviews. We apply a number machine learning approaches found to be effective, and introduce our own approach by fine-tuning state of the art contextualised embeddings. The results we obtain show the potential of contextualised embeddings for fake review detection, and lay the groundwork for future research in this area."
N19-3001,Is It Dish Washer Safe? Automatically Answering {``}Yes/No{''} Questions Using Customer Reviews,2019,0,0,3,1,10031,daria dzendzik,Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Student Research Workshop,0,"It has become commonplace for people to share their opinions about all kinds of products by posting reviews online. It has also become commonplace for potential customers to do research about the quality and limitations of these products by posting questions online. We test the extent to which reviews are useful in question-answering by combining two Amazon datasets and focusing our attention on yes/no questions. A manual analysis of 400 cases reveals that the reviews directly contain the answer to the question just over a third of the time. Preliminary reading comprehension experiments with this dataset prove inconclusive, with accuracy in the range 50-66{\%}."
D19-6118,Cross-lingual Parsing with Polyglot Training and Multi-treebank Learning: A {F}aroese Case Study,2019,29,0,3,1,5840,james barry,Proceedings of the 2nd Workshop on Deep Learning Approaches for Low-Resource NLP (DeepLo 2019),0,"Cross-lingual dependency parsing involves transferring syntactic knowledge from one language to another. It is a crucial component for inducing dependency parsers in low-resource scenarios where no training data for a language exists. Using Faroese as the target language, we compare two approaches using annotation projection: first, projecting from multiple monolingual source models; second, projecting from a single polyglot model which is trained on the combination of all source languages. Furthermore, we reproduce multi-source projection (Tyers et al., 2018), in which dependency trees of multiple sources are combined. Finally, we apply multi-treebank modelling to the projected treebanks, in addition to or alternatively to polyglot modelling on the source side. We find that polyglot training on the source languages produces an overall trend of better results on the target language but the single best result for the target language is obtained by projecting from monolingual source parsing models and then training multi-treebank POS tagging and parsing models on the target side."
W18-6222,Sentiment Expression Boundaries in Sentiment Polarity Classification,2018,0,0,2,1,27769,rasoul kaljahi,"Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",0,We investigate the effect of using sentiment expression boundaries in predicting sentiment polarity in aspect-level sentiment analysis. We manually annotate a freely available English sentiment polarity dataset with these boundaries and carry out a series of experiments which demonstrate that high quality sentiment expressions can boost the performance of polarity classification. Our experiments with neural architectures also show that CNN networks outperform LSTMs on this task and dataset.
E17-1012,If You Can{'}t Beat Them Join Them: Handcrafted Features Complement Neural Nets for Non-Factoid Answer Reranking,2017,18,6,2,1,33018,dasha bogdanova,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 1, Long Papers",0,"We show that a neural approach to the task of non-factoid answer reranking can benefit from the inclusion of tried-and-tested handcrafted features. We present a neural network architecture based on a combination of recurrent neural networks that are used to encode questions and answers, and a multilayer perceptron. We show how this approach can be combined with additional features, in particular, the discourse features used by previous research. Our neural approach achieves state-of-the-art performance on a public dataset from Yahoo! Answers and its performance is further improved by incorporating the discourse features. Additionally, we present a new dataset of Ask Ubuntu questions where the hybrid approach also achieves good results."
W16-5804,"Part-of-speech Tagging of Code-mixed Social Media Content: Pipeline, Stacking and Joint Modelling",2016,7,6,3,1,28976,utsab barman,Proceedings of the Second Workshop on Computational Approaches to Code Switching,0,"Multilingual users of social media sometimes use multiple languages during conversation. Mixing multiple languages in contentn is known as code-mixing. We annotate a subset of a trilingual code-mixed corpus (Barmann et al., 2014) with part-of-speech (POS) tags.n We investigate two state-of-the-art POS tagging techniques for code-mixed content andn combine the features of the two systems ton build a better POS tagger. Furthermore, wen investigate the use of a joint model which performs language identification (LID) and partof-speech (POS) tagging simultaneously."
W16-4307,Detecting Opinion Polarities using Kernel Methods,2016,28,2,2,1,27769,rasoul kaljahi,"Proceedings of the Workshop on Computational Modeling of People{'}s Opinions, Personality, and Emotions in Social Media ({PEOPLES})",0,"We investigate the application of kernel methods to representing both structural and lexical knowledge for predicting polarity of opinions in consumer product review. We introduce any-gram kernels which model lexical information in a significantly faster way than the traditional n-gram features, while capturing all possible orders of n-grams n in a sequence without the need to explicitly present a pre-specified set of such orders. We also present an effective format to represent constituency and dependency structure together with aspect terms and sentiment polarity scores. Furthermore, we modify the traditional tree kernel function to compute the similarity based on word embedding vectors instead of exact string match and present experiments using the new models."
N16-1154,This is how we do it: Answer Reranking for Open-domain How Questions with Paragraph Vectors and Minimal Feature Engineering,2016,6,10,2,1,33018,dasha bogdanova,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"We present a simple yet powerful approach to non-factoid answer reranking whereby question-answer pairs are represented by concatenated distributed representation vectors and a multilayer perceptron is used to compute the score for an answer. Despite its simplicity, our approach achieves state-of-the-art performance on a public dataset of How questions, outperforming systems which employ sophisticated feature sets. We attribute this good performance to the use of paragraph instead of word vector representations and to the use of suitable data for training these representations."
W15-4314,{DCU}-{ADAPT}: Learning Edit Operations for Microblog Normalisation with the Generalised Perceptron,2015,19,1,2,1,820,joachim wagner,Proceedings of the Workshop on Noisy User-generated Text,0,"We describe the work carried out by the DCU-ADAPT team on the Lexical Normalisation shared task at W-NUT 2015. We train a generalised perceptron to annotate noisy text with edit operations that normalise the text when executed. Features are charactern-grams, recurrent neural network language model hidden layer activations, character class and eligibility for editing according to the task rules. We combine predictions from 25 models trained on subsets of the training data by selecting the most-likely normalisation according to a character language model. We compare the use of a generalised perceptron to the use of conditional random fields restricted to smaller amounts of training data due to memory constraints. Furthermore, we make a first attempt to ver"
S15-2026,{DCU}: Using Distributional Semantics and Domain Adaptation for the Semantic Textual Similarity {S}em{E}val-2015 Task 2,2015,16,2,3,0.833333,19340,piyush arora,Proceedings of the 9th International Workshop on Semantic Evaluation ({S}em{E}val 2015),0,"We describe the work carried out by the DCU team on the Semantic Textual Similarity task at SemEval-2015. We learn a regression model to predict a semantic similarity score between a sentence pair. Our system exploits distributional semantics in combination with tried-and-tested features from previous tasks in order to compute sentence similarity. Our team submitted 3 runs for each of the five English test sets. For two of the test sets, belief and headlines, our best system ranked second and fourth out of the 73 submitted systems. Our best submission averaged over all test sets ranked 26 out of the 73 systems."
D15-1157,{F}oreebank: Syntactic Analysis of Customer Support Forums,2015,25,8,2,1,27769,rasoul kaljahi,Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,0,"We present a new treebank of English and French technical forum content which has been annotated for grammatical errors and phrase structure. This double annotation allows us to empirically measure the effect of errors on parsing performance. While it is slightly easier to parse the corrected versions of the forum sentences, the errors are not the main factor in making this kind of text hard to parse."
W14-4606,Cross-lingual Transfer Parsing for Low-Resourced Languages: An {I}rish Case Study,2014,18,9,2,1,14284,teresa lynn,Proceedings of the First Celtic Language Technology Workshop,0,"We present a study of cross-lingual direct transfer parsing for the Irish language. Firstly we discuss mapping of the annotation scheme of the Irish Dependency Treebank to a universal dependency scheme. We explain our dependency label mapping choices and the structural changes required in the Irish Dependency Treebank. We then experiment with the universally annotated treebanks of ten languages from four language family groups to assess which languages are the most useful for cross-lingual parsing of Irish by using these treebanks to train delexicalised parsing models which are then applied to sentences from the Irish Dependency Treebank. The best results are achieved when using Indonesian, a language from the Austronesian language family."
W14-4008,Syntax and Semantics in Quality Estimation of Machine Translation,2014,33,3,2,1,27769,rasoul kaljahi,"Proceedings of {SSST}-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation",0,"We employ syntactic and semantic information in estimating the quality of machine translation from a new data set which contains source text from English customer support forums and target text consisting of its machine translation into French. These translations have been both post-edited and evaluated by professional translators. We find that quality estimation using syntactic and semantic information on this data set can hardly improve over a baseline which uses only surface features. However, the performance can be improved when they are combined with such surface features. We also introduce a novel metric to measure translation adequacy based on predicate-argument structure match using word alignments. While word alignments can be reliably used, the two main factors affecting the performance of all semantic-based methods seems to be the low quality of semantic role labelling (especially on ill-formed text) and the lack of nominal predicate annotation."
W14-3902,Code Mixing: A Challenge for Language Identification in the Language of Social Media,2014,38,96,4,1,28976,utsab barman,Proceedings of the First Workshop on Computational Approaches to Code Switching,0,"In social media communication, multilingual speakers often switch between languages, and, in such an environment, automatic language identification becomes both a necessary and challenging task. In this paper, we describe our work in progress on the problem of automatic language identification for the language of social media. We describe a new dataset that we are in the process of creating, which contains Facebook posts and comments that exhibit code mixing between Bengali, English and Hindi. We also present some preliminary word-level language identification experiments using this dataset. Different techniques are employed, including a simple unsupervised dictionary-based approach, supervised word-level classification with and without contextual clues, and sequence labelling using Conditional Random Fields. We find that the dictionary-based approach is surpassed by supervised classification and sequence labelling, and that it is important to take contextual clues into consideration."
W14-3915,{DCU}-{UVT}: Word-Level Language Classification with Code-Mixed Data,2014,21,10,4,1,28976,utsab barman,Proceedings of the First Workshop on Computational Approaches to Code Switching,0,"This paper describes the DCU-UVT teamxe2x80x99s participation in the Language Identification in Code-Switched Data shared task in the Workshop on Computational Approaches to Code Switching. Word-level classification experiments were carried out using a simple dictionary-based method, linear kernel support vector machines (SVMs) with and without contextual clues, and a k-nearest neighbour approach. Based on these experiments, we select our SVM-based system with contextual clues as our final system and present results for the Nepali-English and Spanish-English datasets."
S14-2036,{DCU}: Aspect-based Polarity Classification for {S}em{E}val Task 4,2014,23,70,6,1,820,joachim wagner,Proceedings of the 8th International Workshop on Semantic Evaluation ({S}em{E}val 2014),0,"We describe the work carried out by DCU on the Aspect Based Sentiment Analysis task at SemEval 2014. Our team submitted one constrained run for the restaurant domain and one for the laptop domain for sub-task B (aspect term polarity prediction), ranking highest out of 36 systems on the restaurant test set and joint highest out of 32 systems on the laptop test set."
S14-1012,Semantic Role Labelling with minimal resources: Experiments with {F}rench,2014,21,5,2,1,27769,rasoul kaljahi,Proceedings of the Third Joint Conference on Lexical and Computational Semantics (*{SEM} 2014),0,"This paper describes a series of French semantic role labelling experiments which show that a small set of manually annotated training data is superior to a much larger set containing semantic role labels which have been projected from a source language via word alignment. Using universal part-of-speech tags and dependencies makes little difference over the original fine-grained tagset and dependency scheme. Moreover, there seems to be no improvement gained from projecting semantic roles between direct translations than between indirect translations."
C14-1194,Quality Estimation of {E}nglish-{F}rench Machine Translation: A Detailed Study of the Role of Syntax,2014,32,5,2,1,27769,rasoul kaljahi,"Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: Technical Papers",0,"We investigate the usefulness of syntactic knowledge in estimating the quality of English-French translations. We find that dependency and constituency tree kernels perform well but the error rate can be further reduced when these are combined with hand-crafted syntactic features. Both types of syntactic features provide information which is complementary to tried-and-tested nonsyntactic features. We then compare source and target syntax and find that the use of parse trees of machine translated sentences does not affect the performance of quality estimation nor does the intrinsic accuracy of the parser itself. However, the relatively flat structure of the French Treebank does appear to have an adverse effect, and this is significantly improved by simple transformations of the French trees. Finally, we provide further evidence of the usefulness of these transformations by applying them in a separate task xe2x80x90 parser accuracy prediction."
W13-4901,Working with a small dataset - semi-supervised dependency parsing for {I}rish,2013,24,5,2,1,14284,teresa lynn,Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically-Rich Languages,0,"We present a number of semi-supervised parsing experiments on the Irish language carried out using a small seed set of manually parsed trees and a larger, yet still relatively small, set of unlabelled sentences. We take two popular dependency parsers xe2x80x90 one graph-based and one transition-based xe2x80x90 and compare results for both. Results show that using semisupervised learning in the form of self-training and co-training yields only very modest improvements in parsing accuracy. We also try to use morphological information in a targeted way and fail to see any improvements."
W13-4917,Overview of the {SPMRL} 2013 Shared Task: A Cross-Framework Evaluation of Parsing Morphologically Rich Languages,2013,110,38,7,0.110519,167,djame seddah,Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically-Rich Languages,0,"This paper reports on the first shared task on statistical parsing of morphologically rich languages (MRLs). The task features data sets from nine languages, each available both in constituency and dependency annotation. We report on the preparation of the data sets, on the proposed parsing scenarios, and on the evaluation metrics for parsing MRLs given different representation types. We present and analyze parsing results obtained by the task participants, and then provide an analysis and comparison of the parsers across languages and frameworks, reported for gold input as well as more realistic parsing scenarios."
W13-2249,{DCU}-{S}ymantec at the {WMT} 2013 Quality Estimation Shared Task,2013,9,7,3,0.846154,8609,raphael rubino,Proceedings of the Eighth Workshop on Statistical Machine Translation,0,"We describe the two systems submitted by the DCU-Symantec team to Task 1.1. of the WMT 2013 Shared Task on Quality Estimation for Machine Translation. Task 1.1 involve estimating postediting effort for English-Spanish translation pairs in the news domain. The two systems use a wide variety of features, of which the most effective are the word-alignment, n-gram frequency, language model, POS-tag-based and pseudoreferences ones. Both systems perform at a similarly high level in the two tasks of scoring and ranking translations, although there is some evidence that the systems are over-fitting to the training data."
W13-1106,Sentiment Analysis of Political Tweets: Towards an Accurate Classifier,2013,25,56,2,0,41103,akshat bakliwal,Proceedings of the Workshop on Language Analysis in Social Media,0,"We perform a series of 3-class sentiment classification experiments on a set of 2,624 tweets produced during the run-up to the Irish General Elections in February 2011. Even though tweets that have been labelled as sarcastic have been omitted from this set, it still represents a difficult test set and the highest accuracy we achieve is 61.6% using supervised learning and a feature set consisting of subjectivity-lexicon-based scores, Twitter- specific features and the top 1,000 most dis- criminative words. This is superior to various naive unsupervised approaches which use subjectivity lexicons to compute an overall sentiment score for a pair."
I13-1153,Parser Accuracy in Quality Estimation of Machine Translation: A Tree Kernel Approach,2013,26,5,2,1,27769,rasoul kaljahi,Proceedings of the Sixth International Joint Conference on Natural Language Processing,0,"We report on experiments designed to investigate the role of syntactic features in the task of quality estimation for machine translation, focusing on the effect of parser accuracy. Tree kernels are used to predict the segment-level BLEU score of EnglishFrench translations. In order to examine the effect of the accuracy of the parse tree on the accuracy of the quality estimation system, we experiment with various parsing systems which differ substantially with respect to their Parseval f-scores. We find that it makes very little difference which system we choose to use in the quality estimation task xe2x80x90 this effect is particularly apparent for source-side English parse trees."
I13-1166,Estimating the Quality of Translated User-Generated Content,2013,24,2,2,0.846154,8609,raphael rubino,Proceedings of the Sixth International Joint Conference on Natural Language Processing,0,Previous research on quality estimation for machine translation has demonstrated the possibility of predicting the translation quality of well-formed data. We present a first study on estimating the translation quality of user-generated content. Our dataset contains English technical forum comments which were translated into French by three automatic systems. These translations were rated in terms of both comprehensibility and fidelity by human annotators. Our experiments show that tried-and-tested quality estimation features work well on this type of data but that extending this set can be beneficial. We also show that the performance of particular types of features depends on the type of system used to produce the translation.
D13-1116,Combining {PCFG}-{LA} Models with Dual Decomposition: A Case Study with Function Labels and Binarization,2013,35,4,3,0,5824,joseph roux,Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,0,"It has recently been shown that different NLP models can be effectively combined using dual decomposition. In this paper we demon-strate that PCFG-LA parsing models are suit-able for combination in this way. We exper-iment with the different models which result from alternative methods of extracting a gram-mar from a treebank (retaining or discarding function labels, left binarization versus right binarization) and achieve a labeled Parseval F-score of 92.4 on Wall Street Journal Sec-tion 23 xe2x80x93 this represents an absolute improve-ment of 0.7 and an error reduction rate of 7% over a strong PCFG-LA product-model base-line. Although we experiment only with bina-rization and function labels in this study, there is much scope for applying this approach to other grammar extraction strategies."
2013.mtsummit-posters.12,Key Problems in Conversion from Simplified to Traditional {C}hinese Characters Topic Models for Translation Quality Estimation for Gisting Purposes,2013,-1,-1,3,0.846154,8609,raphael rubino,Proceedings of Machine Translation Summit XIV: Posters,0,None
2013.mtsummit-posters.13,Topic Models for Translation Quality Estimation for Gisting Purposes,2013,22,19,3,0.846154,8609,raphael rubino,Proceedings of Machine Translation Summit XIV: Posters,0,"This paper addresses the problem of predicting how adequate a machine translation is for gisting purposes. It focuses on the contribution of lexicalised features based on different types of topic models, as we believe these features are more robust than those used in previous work, which depend on linguistic processors that are often unreliable on automatic translations. Experiments with a number of datasets show promising results: the use of topic models outperforms the state-of-the-art approaches by a large margin in all datasets annotated for adequacy."
W12-3117,{DCU}-Symantec Submission for the {WMT} 2012 Quality Estimation Task,2012,30,30,2,0.846154,8609,raphael rubino,Proceedings of the Seventh Workshop on Statistical Machine Translation,0,"This paper describes the features and the machine learning methods used by Dublin City University (DCU) and SYMANTEC for the WMT 2012 quality estimation task. Two sets of features are proposed: one constrained, i.e. respecting the data limitation suggested by the workshop organisers, and one unconstrained, i.e. using data or tools trained on data that was not provided by the workshop organisers. In total, more than 300 features were extracted and used to train classifiers in order to predict the translation quality of unseen data. In this paper, we focus on a subset of our feature set that we consider to be relatively novel: features based on a topic model built using the Latent Dirichlet Allocation approach, and features based on source and target language syntax extracted using part-of-speech (POS) taggers and parsers. We evaluate nine feature combinations using four classification-based and four regression-based machine learning techniques."
U12-1005,Active Learning and the {I}rish Treebank,2012,28,7,2,1,14284,teresa lynn,Proceedings of the Australasian Language Technology Association Workshop 2012,0,"We report on our ongoing work in developing the Irish Dependency Treebank, describe the results of two Inter annotator Agreement (IAA) studies, demonstrate improvements in annotation consistency which have a knock-on effect on parsing accuracy, and present the final set of dependency labels. We then go on to investigate the extent to which active learning can play a role in treebank and parser development by comparing an active learning bootstrapping approach to a passive approach in which sentences are chosen at random for manual revision. We show that active learning outperforms passive learning, but when annotation effort is taken into account, it is not clear how much of an advantage the active learning approach has. Finally, we present results which suggest that adding automatic parses to the training data along with manually revised parses in an active learning setup does not greatly affect parsing accuracy."
P12-2066,Identifying High-Impact Sub-Structures for Convolution Kernels in Document-level Sentiment Classification,2012,24,15,3,0,4187,zhaopeng tu,Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"Convolution kernels support the modeling of complex syntactic information in machine-learning tasks. However, such models are highly sensitive to the type and size of syntactic structure used. It is therefore an important challenge to automatically identify high impact sub-structures relevant to a given task. In this paper we present a systematic study investigating (combinations of) sequence and convolution kernels using different types of substructures in document-level sentiment classification. We show that minimal sub-structures extracted from constituency and dependency trees guided by a polarity lexicon show 1.45 point absolute improvement in accuracy over a bag-of-words classifier on a widely used sentiment corpus."
lynn-etal-2012-irish,{I}rish Treebanking and Parsing: A Preliminary Evaluation,2012,40,9,3,1,14284,teresa lynn,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"Language resources are essential for linguistic research and the development of NLP applications. Low-density languages, such as Irish, therefore lack significant research in this area. This paper describes the early stages in the development of new language resources for Irish â namely the first Irish dependency treebank and the first Irish statistical dependency parser. We present the methodology behind building our new treebank and the steps we take to leverage upon the few existing resources. We discuss language-specific choices made when defining our dependency labelling scheme, and describe interesting Irish language characteristics such as prepositional attachment, copula, and clefting. We manually develop a small treebank of 300 sentences based on an existing POS-tagged corpus and report an inter-annotator agreement of 0.7902. We train MaltParser to achieve preliminary parsing results for Irish and describe a bootstrapping approach for further stages of development."
2012.amta-papers.27,A Detailed Analysis of Phrase-based and Syntax-based {MT}: The Search for Systematic Differences,2012,29,5,4,1,27769,rasoul kaljahi,Proceedings of the 10th Conference of the Association for Machine Translation in the Americas: Research Papers,0,"This paper describes a range of automatic and manual comparisons of phrase-based and syntax-based statistical machine translation methods applied to English-German and English-French translation of user-generated content. The syntax-based methods underperform the phrase-based models and the relaxation of syntactic constraints to broaden translation rule coverage means that these models do not necessarily generate output which is more grammatical than the output produced by the phrase-based models. Although the systems generate different output and can potentially be fruitfully combined, the lack of systematic difference between these models makes the combination task more challenging."
W11-2925,Comparing the Use of Edited and Unedited Text in Parser Self-Training,2011,15,5,1,1,819,jennifer foster,Proceedings of the 12th International Conference on Parsing Technologies,0,"We compare the use of edited text in the form of newswire and unedited text in the form of discussion forum posts as sources for training material in a self-training experiment involving the Brown reranking parser and a test set of sentences from an online sports discussion forum. We find that grammars induced from the two automatically parsed corpora achieve similar Parseval f-scores, with the grammars induced from the discussion forum material being slightly superior. An error analysis reveals that the two types of grammars do behave differently."
W11-0804,Decreasing Lexical Data Sparsity in Statistical Syntactic Parsing - Experiments with Named Entities,2011,17,8,2,1,44159,deirdre hogan,Proceedings of the Workshop on Multiword Expressions: from Parsing and Generation to the Real World,0,"In this paper we present preliminary experiments that aim to reduce lexical data sparsity in statistical parsing by exploiting information about named entities. Words in the WSJ corpus are mapped to named entity clusters and a latent variable constituency parser is trained and tested on the transformed corpus. We explore two different methods for mapping words to entities, and look at the effect of mapping various subsets of named entity types. Thus far, results show no improvement in parsing accuracy over the best baseline score; we identify possible problems and outline suggestions for future directions."
I11-1100,From News to Comment: Resources and Benchmarks for Parsing the Language of Web 2.0,2011,28,58,1,1,819,jennifer foster,Proceedings of 5th International Joint Conference on Natural Language Processing,0,"We investigate the problem of parsing the noisy language of social media. We evaluate four Wall-Street-Journal-trained statistical parsers (Berkeley, Brown, Malt and MST) on a new dataset containing 1,000 phrase structure trees for sentences from microblogs (tweets) and discussion forum posts. We compare the four parsers on their ability to produce Stanford dependencies for these Web 2.0 sentences. We find that the parsers have a particular problem with tweets and that a substantial part of this problem is related to POS tagging accuracy. We attempt three retraining experiments involving Malt, Brown and an in-house Berkeley-style parser and obtain a statistically significant improvement for all three parsers."
W10-1401,"Statistical Parsing of Morphologically Rich Languages ({SPMRL}) What, How and Whither",2010,60,61,7,0.273954,5249,reut tsarfaty,Proceedings of the {NAACL} {HLT} 2010 First Workshop on Statistical Parsing of Morphologically-Rich Languages,0,"The term Morphologically Rich Languages (MRLs) refers to languages in which significant information concerning syntactic units and relations is expressed at word-level. There is ample evidence that the application of readily available statistical parsing models to such languages is susceptible to serious performance degradation. The first workshop on statistical parsing of MRLs hosts a variety of contributions which show that despite language-specific idiosyncrasies, the problems associated with parsing MRLs cut across languages and parsing frameworks. In this paper we review the current state-of-affairs with respect to parsing MRLs and point out central challenges. We synthesize the contributions of researchers working on parsing Arabic, Basque, French, German, Hebrew, Hindi and Korean to point out shared solutions across languages. The overarching analysis suggests itself as a source of directions for future investigations."
W10-1408,"Handling Unknown Words in Statistical Latent-Variable Parsing Models for {A}rabic, {E}nglish and {F}rench",2010,21,43,2,0,24071,mohammed attia,Proceedings of the {NAACL} {HLT} 2010 First Workshop on Statistical Parsing of Morphologically-Rich Languages,0,"This paper presents a study of the impact of using simple and complex morphological clues to improve the classification of rare and unknown words for parsing. We compare this approach to a language-independent technique often used in parsers which is based solely on word frequencies. This study is applied to three languages that exhibit different levels of morphological expressiveness: Arabic, French and English. We integrate information about Arabic affixes and morphotactics into a PCFG-LA parser and obtain state-of-the-art accuracy. We also show that these morphological clues can be learnt automatically from an annotated corpus."
P10-2065,Using Parse Features for Preposition Selection and Error Detection,2010,18,69,2,0,191,joel tetreault,Proceedings of the {ACL} 2010 Conference Short Papers,0,We evaluate the effect of adding parse features to a leading model of preposition usage. Results show a significant improvement in the preposition selection task on native speaker text and a modest increment in precision and recall in an ESL error detection task. Analysis of the parser output indicates that it is robust enough in the face of noisy non-native writing to extract useful information.
N10-1060,{``}cba to check the spelling{''}: Investigating Parser Performance on Discussion Forum Posts,2010,10,42,1,1,819,jennifer foster,Human Language Technologies: The 2010 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics,0,"We evaluate the Berkeley parser on text from an online discussion forum. We evaluate the parser output with and without gold tokens and spellings (using Sparseval and Parseval), and we compile a list of problematic phenomena for this domain. The Parseval f-score for a small development set is 77.56. This increases to 80.27 when we apply a set of simple transformations to the input sentences and to the Wall Street Journal (WSJ) training sections."
W09-3827,The effect of correcting grammatical errors on parse probabilities,2009,9,13,2,1,820,joachim wagner,Proceedings of the 11th International Conference on Parsing Technologies ({IWPT}{'}09),0,"We parse the sentences in three parallel error corpora using a generative, probabilistic parser and compare the parse probabilities of the most likely analyses for each grammatical sentence and its closely related ungrammatical counterpart."
W09-2112,{G}en{ERR}ate: Generating Errors for Use in Grammatical Error Detection,2009,22,53,1,1,819,jennifer foster,Proceedings of the Fourth Workshop on Innovative Use of {NLP} for Building Educational Applications,0,"This paper explores the issue of automatically generated ungrammatical data and its use in error detection, with a focus on the task of classifying a sentence as grammatical or ungrammatical. We present an error generation tool called GenERRate and show how GenERRate can be used to improve the performance of a classifier on learner data. We describe initial attempts to replicate Cambridge Learner Corpus errors using GenERRate."
W08-1122,Parser-Based Retraining for Domain Adaptation of Probabilistic Generators,2008,13,5,2,1,44159,deirdre hogan,Proceedings of the Fifth International Natural Language Generation Conference,0,"While the effect of domain variation on Penn-treebank-trained probabilistic parsers has been investigated in previous work, we study its effect on a Penn-Treebank-trained probabilistic generator. We show that applying the generator to data from the British National Corpus results in a performance drop (from a BLEU score of 0.66 on the standard WSJ test set to a BLEU score of 0.54 on our BNC test set). We develop a generator retraining method where the domain-specific training data is automatically produced using state-of-the-art parser output. The retraining method recovers a substantial portion of the performance drop, resulting in a generator which achieves a BLEU score of 0.61 on our BNC test data."
P08-2056,Adapting a {WSJ}-Trained Parser to Grammatically Noisy Text,2008,9,25,1,1,819,jennifer foster,"Proceedings of ACL-08: HLT, Short Papers",0,"We present a robust parser which is trained on a treebank of ungrammatical sentences. The treebank is created automatically by modifying Penn treebank sentences so that they contain one or more syntactic errors. We evaluate an existing Penn-treebank-trained parser on the ungrammatical treebank to see how it reacts to noise in the form of grammatical errors. We re-train this parser on the training section of the ungrammatical treebank, leading to an significantly improved performance on the ungrammatical test sets. We show how a classifier can be used to prevent performance degradation on the original grammatical data."
foster-van-genabith-2008-parser,Parser Evaluation and the {BNC}: Evaluating 4 constituency parsers with 3 metrics,2008,18,11,1,1,819,jennifer foster,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"We evaluate discriminative parse reranking and parser self-training on a new English test set using four versions of the Charniak parser and a variety of parser evaluation metrics. The new test set consists of 1,000 hand-corrected British National Corpus parse trees. We directly evaluate parser output using both the Parseval and the Leaf Ancestor metrics. We also convert the hand-corrected and parser output phrase structure trees to dependency trees using a state-of-the-art functional tag labeller and constituent-to-dependency conversion tool, and then calculate label accuracy, unlabelled attachment and labelled attachment scores over the dependency structures. We find that reranking leads to a performance improvement on the new test set (albeit a modest one). We find that self-training using BNC data leads to significantly better results. However, it is not clear how effective self-training is when the training material comes from the North American News Corpus."
W07-2204,Adapting {WSJ}-Trained Parsers to the {B}ritish {N}ational {C}orpus using In-Domain Self-Training,2007,10,18,1,1,819,jennifer foster,Proceedings of the Tenth International Conference on Parsing Technologies,0,"We introduce a set of 1,000 gold standard parse trees for the British National Corpus (BNC) and perform a series of self-training experiments with Charniak and Johnson's reranking parser and BNC sentences. We show that retraining this parser with a combination of one million BNC parse trees (produced by the same parser) and the original WSJ training data yields improvements of 0.4% on WSJ Section 23 and 1.7% on the new BNC gold standard set."
D07-1012,A Comparative Evaluation of Deep and Shallow Approaches to the Automatic Detection of Common Grammatical Errors,2007,25,36,2,1,820,joachim wagner,Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning ({EMNLP}-{C}o{NLL}),0,"This paper compares a deep and a shallow processing approach to the problem of classifying a sentence as grammatically wellformed or ill-formed. The deep processing approach uses the XLE LFG parser and English grammar: two versions are presented, one which uses the XLE directly to perform the classification, and another one which uses a decision tree trained on features consisting of the XLExe2x80x99s output statistics. The shallow processing approach predicts grammaticality based on n-gram frequency statistics: we present two versions, one which uses frequency thresholds and one which uses a decision tree trained on the frequencies of the rarest n-grams in the input sentence. We find that the use of a decision tree improves on the basic approach only for the deep parser-based approach. We also show that combining both the shallow and deep decision tree features is effective. Our evaluation is carried out using a large test set of grammatical and ungrammatical sentences. The ungrammatical test set is generated automatically by inserting grammatical errors into well-formed BNC sentences."
foster-2004-parsing,Parsing Ungrammatical Input: an Evaluation Procedure,2004,6,14,1,1,819,jennifer foster,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"This paper presents a procedure for evaluating a parserxe2x80x99s ability to produce an accurate parse for an ungrammatical sentence. It is based on the existence of a corpus of ungrammatical sentences, and a parallel corpus containing corrected, and hence grammatical, versions of the sentences in the first corpus. This procedure is applied to a wide-coverage probabilistic parser (Charniak, 2000), and the performance of this parser with respect to ungrammatical input is analysed."
