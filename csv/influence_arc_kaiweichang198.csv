2020.aacl-main.61,P16-1046,0,0.0267521,"the rewriter. In addition, we observe that when training the model in a tem2tem way, we can get better NMS and EMS, which implies that training by tem2tem can improve the correctness of summaries. 5 Related Work Text summarization. Existing approaches can be grouped into two families: extractive models and abstractive models. Extractive models select a part of sentences from the source document as the summary. Traditional approaches (Carbonell and Goldstein, 1998; Erkan and Radev, 2004; McDonald, 2007) utilize graph or optimization techniques. Recently, neural models achieve good performance (Cheng and Lapata, 2016; Nallapati et al., 2017; Jadhav and Rajan, 2018). Abstractive summarization models aim to rephrase the source document. Most work applies neural models for this task. (Rush et al., 2015; Chopra et al., 2016; Nallapati et al., 2016; Zeng et al., 2016; See et al., 2017; Gehrmann et al., 2018). Factual correctness of summaries. There is a lot of work focusing on evaluation and improvement of the factual correctness of summaries (Falke et al., 2019; Kryscinski et al., 2019; Wang et al., 2020; Maynez et al., 2020; Zhu et al., 2020). Data-to-Text generation. Recently, generating news articles from"
2020.aacl-main.61,N16-1012,0,0.03086,"k Text summarization. Existing approaches can be grouped into two families: extractive models and abstractive models. Extractive models select a part of sentences from the source document as the summary. Traditional approaches (Carbonell and Goldstein, 1998; Erkan and Radev, 2004; McDonald, 2007) utilize graph or optimization techniques. Recently, neural models achieve good performance (Cheng and Lapata, 2016; Nallapati et al., 2017; Jadhav and Rajan, 2018). Abstractive summarization models aim to rephrase the source document. Most work applies neural models for this task. (Rush et al., 2015; Chopra et al., 2016; Nallapati et al., 2016; Zeng et al., 2016; See et al., 2017; Gehrmann et al., 2018). Factual correctness of summaries. There is a lot of work focusing on evaluation and improvement of the factual correctness of summaries (Falke et al., 2019; Kryscinski et al., 2019; Wang et al., 2020; Maynez et al., 2020; Zhu et al., 2020). Data-to-Text generation. Recently, generating news articles from different kinds of data-records becomes a popular research direction. Wiseman et al. (2017); Puduppully et al. (2019) focus on generating news from boxed-data. Zhang et al. (2016) and Yao et al. (2017) study"
2020.aacl-main.61,D15-1044,0,0.338259,", generating news from live commentaries has gradually attracted attention in the academic community (Zhang et al., 2016; Yao et al., 2017). At the same time, several trials have been done in the industry such as sports news from Toutiao’s Xiaoming Bot2 , Sohu Ruibao3 and AI football news4 . 1 The dataset is available at https://github.com/ ej0cl6/SportsSum 2 http://www.nbd.com.cn/columns/803 3 https://mp.sohu.com/profile?xpt= c29odW1wMzZpdDlzQHNvaHUuY29t 4 https://www.51zhanbao.com Table 1: An example of S PORTS S UM dataset. Unlike traditional text summarization tasks (Hermann et al., 2015; Rush et al., 2015), the source documents and the target summaries for sports game summarization tasks are written in quite different styles. Live commentaries are the real-time transcripts of the commentators. Accordingly, commentary sentences are more colloquial and informal. In contrast, news summaries are usually more narrative and well-organized since they are written after the games. In addition, commentaries contain a large number of player names. One player can be referred to multiple times in the whole game, and one commentary sentence may mention multiple player names simultaneously. Those properties 6"
2020.aacl-main.61,P17-1099,0,0.256143,"lent if and only if 1) subject1 is the same as subject2 and 2) verb1 and verb2 are synonym7 to each other. Let Eg and Ep represent ˜ respectively, the event the set of events in R and R, matching score is defined as ˜ = F-score(Eg , Ep ). EMS(R, R) Implementations and Models. We consider the convolutional neural network (Kim, 2014) as the selector. For the rewriter, we consider the following: (1) LSTM: a bidirectional LSTM with attention mechanism (Bahdanau et al., 2015). (2) Transformer. (Vaswani et al., 2017) (3) PGNet: pointergenerator network, an encoder-decoder model with copy mechanism (See et al., 2017). 612 7 Details to decide synonyms can be found in Appendix B. Method Model ROUGE-1 ROUGE-2 ROUGE-L NMS EMS Extractive Models RawSent LTR 26.52 24.44 7.64 6.39 25.42 23.19 57.33 51.63 36.17 29.03 Abstractive Models Abs-LSTM Abs-PGNet 30.54 34.02 10.16 11.09 29.78 33.13 10.87 17.87 14.03 19.76 Selector + Rewriter (Seq2seq) LSTM Transformer PGNet 41.39 41.71 43.17 16.99 18.10 18.66 40.53 40.96 42.27 28.48 35.63 48.18 25.19 30.94 36.94 Selector + Rewriter (Tem2tem) LSTM Transformer PGNet 41.71 41.47 41.95 17.08 17.18 17.09 40.82 40.54 41.01 59.54 58.26 59.35 40.34 39.33 40.46 Table 6: Evaluation"
2020.aacl-main.61,D18-1443,0,0.0286439,"Missing"
2020.aacl-main.61,P82-1020,0,0.787369,"Missing"
2020.aacl-main.61,P18-1014,0,0.0221523,"training the model in a tem2tem way, we can get better NMS and EMS, which implies that training by tem2tem can improve the correctness of summaries. 5 Related Work Text summarization. Existing approaches can be grouped into two families: extractive models and abstractive models. Extractive models select a part of sentences from the source document as the summary. Traditional approaches (Carbonell and Goldstein, 1998; Erkan and Radev, 2004; McDonald, 2007) utilize graph or optimization techniques. Recently, neural models achieve good performance (Cheng and Lapata, 2016; Nallapati et al., 2017; Jadhav and Rajan, 2018). Abstractive summarization models aim to rephrase the source document. Most work applies neural models for this task. (Rush et al., 2015; Chopra et al., 2016; Nallapati et al., 2016; Zeng et al., 2016; See et al., 2017; Gehrmann et al., 2018). Factual correctness of summaries. There is a lot of work focusing on evaluation and improvement of the factual correctness of summaries (Falke et al., 2019; Kryscinski et al., 2019; Wang et al., 2020; Maynez et al., 2020; Zhu et al., 2020). Data-to-Text generation. Recently, generating news articles from different kinds of data-records becomes a popular"
2020.aacl-main.61,D14-1181,0,0.00323275,"ing and R, score as ˜ = F-score(Ng , Np ). NMS(R, R) Similarly, the event matching score evaluates the ˜ We define closeness of the events in R and R. an event as a pair (subject, verb) in the sentence. Two pairs (subject1 , verb1 ) and (subject2 , verb2 ) are viewed as equivalent if and only if 1) subject1 is the same as subject2 and 2) verb1 and verb2 are synonym7 to each other. Let Eg and Ep represent ˜ respectively, the event the set of events in R and R, matching score is defined as ˜ = F-score(Eg , Ep ). EMS(R, R) Implementations and Models. We consider the convolutional neural network (Kim, 2014) as the selector. For the rewriter, we consider the following: (1) LSTM: a bidirectional LSTM with attention mechanism (Bahdanau et al., 2015). (2) Transformer. (Vaswani et al., 2017) (3) PGNet: pointergenerator network, an encoder-decoder model with copy mechanism (See et al., 2017). 612 7 Details to decide synonyms can be found in Appendix B. Method Model ROUGE-1 ROUGE-2 ROUGE-L NMS EMS Extractive Models RawSent LTR 26.52 24.44 7.64 6.39 25.42 23.19 57.33 51.63 36.17 29.03 Abstractive Models Abs-LSTM Abs-PGNet 30.54 34.02 10.16 11.09 29.78 33.13 10.87 17.87 14.03 19.76 Selector + Rewriter (S"
2020.aacl-main.61,2020.acl-main.173,0,0.0141788,"raph or optimization techniques. Recently, neural models achieve good performance (Cheng and Lapata, 2016; Nallapati et al., 2017; Jadhav and Rajan, 2018). Abstractive summarization models aim to rephrase the source document. Most work applies neural models for this task. (Rush et al., 2015; Chopra et al., 2016; Nallapati et al., 2016; Zeng et al., 2016; See et al., 2017; Gehrmann et al., 2018). Factual correctness of summaries. There is a lot of work focusing on evaluation and improvement of the factual correctness of summaries (Falke et al., 2019; Kryscinski et al., 2019; Wang et al., 2020; Maynez et al., 2020; Zhu et al., 2020). Data-to-Text generation. Recently, generating news articles from different kinds of data-records becomes a popular research direction. Wiseman et al. (2017); Puduppully et al. (2019) focus on generating news from boxed-data. Zhang et al. (2016) and Yao et al. (2017) study generating sports news from live commentaries, but their methods are based on hand-crafted features. 6 Conclusion We present S PORTS S UM, a Chinese dataset for sports game summarization, as well as a model that consists of a selector and a rewriter. To improve the quality of generated news, we train the"
2020.aacl-main.61,2020.acl-main.450,0,0.0246821,"ld, 2007) utilize graph or optimization techniques. Recently, neural models achieve good performance (Cheng and Lapata, 2016; Nallapati et al., 2017; Jadhav and Rajan, 2018). Abstractive summarization models aim to rephrase the source document. Most work applies neural models for this task. (Rush et al., 2015; Chopra et al., 2016; Nallapati et al., 2016; Zeng et al., 2016; See et al., 2017; Gehrmann et al., 2018). Factual correctness of summaries. There is a lot of work focusing on evaluation and improvement of the factual correctness of summaries (Falke et al., 2019; Kryscinski et al., 2019; Wang et al., 2020; Maynez et al., 2020; Zhu et al., 2020). Data-to-Text generation. Recently, generating news articles from different kinds of data-records becomes a popular research direction. Wiseman et al. (2017); Puduppully et al. (2019) focus on generating news from boxed-data. Zhang et al. (2016) and Yao et al. (2017) study generating sports news from live commentaries, but their methods are based on hand-crafted features. 6 Conclusion We present S PORTS S UM, a Chinese dataset for sports game summarization, as well as a model that consists of a selector and a rewriter. To improve the quality of generate"
2020.aacl-main.61,D17-1239,0,0.0619326,"Missing"
2020.aacl-main.61,W17-3504,0,0.111937,"the 12 meters ahead the goal line was touched out by Suboti´c. In the 13th minute, Ribery passed the ball from the right, and Kroos’s shot near the 27 meters ahead the goal line missed. (...) Introduction There are a large number of sports games playing every day. Apparently, manually writing sports news articles to summarize every game is laborintensive and infeasible. How to automatically generate sports summaries, therefore, becomes a popular and demanding task. Recently, generating news from live commentaries has gradually attracted attention in the academic community (Zhang et al., 2016; Yao et al., 2017). At the same time, several trials have been done in the industry such as sports news from Toutiao’s Xiaoming Bot2 , Sohu Ruibao3 and AI football news4 . 1 The dataset is available at https://github.com/ ej0cl6/SportsSum 2 http://www.nbd.com.cn/columns/803 3 https://mp.sohu.com/profile?xpt= c29odW1wMzZpdDlzQHNvaHUuY29t 4 https://www.51zhanbao.com Table 1: An example of S PORTS S UM dataset. Unlike traditional text summarization tasks (Hermann et al., 2015; Rush et al., 2015), the source documents and the target summaries for sports game summarization tasks are written in quite different styles"
2020.aacl-main.61,P16-1129,0,0.239494,"Muller’s shot from the 12 meters ahead the goal line was touched out by Suboti´c. In the 13th minute, Ribery passed the ball from the right, and Kroos’s shot near the 27 meters ahead the goal line missed. (...) Introduction There are a large number of sports games playing every day. Apparently, manually writing sports news articles to summarize every game is laborintensive and infeasible. How to automatically generate sports summaries, therefore, becomes a popular and demanding task. Recently, generating news from live commentaries has gradually attracted attention in the academic community (Zhang et al., 2016; Yao et al., 2017). At the same time, several trials have been done in the industry such as sports news from Toutiao’s Xiaoming Bot2 , Sohu Ruibao3 and AI football news4 . 1 The dataset is available at https://github.com/ ej0cl6/SportsSum 2 http://www.nbd.com.cn/columns/803 3 https://mp.sohu.com/profile?xpt= c29odW1wMzZpdDlzQHNvaHUuY29t 4 https://www.51zhanbao.com Table 1: An example of S PORTS S UM dataset. Unlike traditional text summarization tasks (Hermann et al., 2015; Rush et al., 2015), the source documents and the target summaries for sports game summarization tasks are written in qui"
2020.acl-main.260,P15-2139,0,0.0240711,"from the multilingual perspectives. Comparing to Zhou et al. (2019), we show that a different choice of alignment target can help to reduce the bias in multilingual embeddings from both intrinsic and extrinsic perspectives. Multilingual Word Embeddings and Crosslingual Transfer Learning Multilingual word embeddings represent words from different languages using the same embedding space which enables cross-lingual transfer learning (Ruder et al., 2019). The model is trained on a labeled data rich language and adopted to another language where no or a small portion of labeled data is available (Duong et al., 2015; Guo et al., 2016). To get the multilingual word embeddings, Mikolov et al. (2013) learn a linear mapping between the source and target language. However, Xing et al. (2015) argue that there are some inconsistencies in directly learning the linear mapping. To solve those limitations, they constrain the embeddings to be normalized and enforce an orthogonal transformation. While those methods achieve reasonable results on benchmark datasets, they all suffer from the hubness problem which is solved by adding cross-domain similarity constraints (Conneau et al., 2017; Joulin et al., 2018). Our wor"
2020.acl-main.260,W19-3621,0,0.0539625,"Missing"
2020.acl-main.260,N18-1202,0,0.0556526,"al. (2018a), we mitigate the bias in the downstream tasks by adopting the bias-mitigated word embeddings. To get the less biased multilingual word embeddings, we align other embeddings to the ENDEB space previously obtained in Section 3. Table 9 demonstrates that by adopting such less biased embeddings, we can reduce the bias in transfer learning. Comparing to Table 8, aligning the embeddings to a gender-rich language achieves better bias mitigation and, at the same time, remains the overall performance. 4.3 Bias Analysis Using Contextualized Embeddings Contextualized embeddings such as ELMo (Peters et al., 2018), BERT (Devlin et al., 2018) and XLNet (Yang et al., 2019) have shown significant performance improvement in various NLP applica2903 tions. Multilingual BERT (M-BERT) has shown its great ability for the transfer learning. As MBERT provides one single language model trained on multiple languages, there is no longer a need for alignment procedure. In this section, we analyze the bias in monolingual MLBs dataset as well as in transfer learning by replacing the fastText embeddings with M-BERT embeddings. Similar to previous experiments, we train the model on the English dataset and transfer to oth"
2020.acl-main.260,D18-1330,0,0.0233071,"Missing"
2020.acl-main.260,S18-2005,0,0.236035,"in transfer learning. We further provide recommendations for using the multilingual word representations for downstream tasks. 1 Introduction Natural Language Processing (NLP) plays a vital role in applications used in our daily lives. Despite the great performance inspired by the advanced machine learning techniques and large available datasets, there are potential societal biases embedded in these NLP tasks – where the systems learn inappropriate correlations between the final predictions and sensitive attributes such as gender and race. For example, Zhao et al. (2018a) and Rudinger et al. (2018) demonstrate that coreference resolution systems perform unequally on ∗ Most of the work was done while the first author was an intern at Microsoft Research. different gender groups. Other studies show that such bias is exhibited in various components of the NLP systems, such as the training dataset (Zhao et al., 2018a; Rudinger et al., 2018), the embeddings (Bolukbasi et al., 2016; Caliskan et al., 2017; Zhou et al., 2019; Manzini et al., 2019) as well as the pre-trained models (Zhao et al., 2019; Kurita et al., 2019). Recent advances in NLP require large amounts of training data. Such data m"
2020.acl-main.260,S19-1010,0,0.0291223,"Missing"
2020.acl-main.260,N19-1062,0,0.019651,"learn inappropriate correlations between the final predictions and sensitive attributes such as gender and race. For example, Zhao et al. (2018a) and Rudinger et al. (2018) demonstrate that coreference resolution systems perform unequally on ∗ Most of the work was done while the first author was an intern at Microsoft Research. different gender groups. Other studies show that such bias is exhibited in various components of the NLP systems, such as the training dataset (Zhao et al., 2018a; Rudinger et al., 2018), the embeddings (Bolukbasi et al., 2016; Caliskan et al., 2017; Zhou et al., 2019; Manzini et al., 2019) as well as the pre-trained models (Zhao et al., 2019; Kurita et al., 2019). Recent advances in NLP require large amounts of training data. Such data may be available for resource-rich languages such as English, but they are typically absent for many other languages. Multilingual word embeddings align the embeddings from various languages to the same shared embedding space which enables transfer learning by training the model in one language and adopting it for another one (Ammar et al., 2016; Ahmad et al., 2019b; Meng et al., 2019; Chen et al., 2019). Previous work has proposed different meth"
2020.acl-main.260,W17-1609,0,0.0710779,"Missing"
2020.acl-main.260,N18-2002,0,0.0546511,"Missing"
2020.acl-main.260,N15-1104,0,0.0857008,"Missing"
2020.acl-main.260,N19-1064,1,0.909587,"Missing"
2020.acl-main.260,D18-1521,1,0.866177,"n can also have an influence on the bias in transfer learning. We further provide recommendations for using the multilingual word representations for downstream tasks. 1 Introduction Natural Language Processing (NLP) plays a vital role in applications used in our daily lives. Despite the great performance inspired by the advanced machine learning techniques and large available datasets, there are potential societal biases embedded in these NLP tasks – where the systems learn inappropriate correlations between the final predictions and sensitive attributes such as gender and race. For example, Zhao et al. (2018a) and Rudinger et al. (2018) demonstrate that coreference resolution systems perform unequally on ∗ Most of the work was done while the first author was an intern at Microsoft Research. different gender groups. Other studies show that such bias is exhibited in various components of the NLP systems, such as the training dataset (Zhao et al., 2018a; Rudinger et al., 2018), the embeddings (Bolukbasi et al., 2016; Caliskan et al., 2017; Zhou et al., 2019; Manzini et al., 2019) as well as the pre-trained models (Zhao et al., 2019; Kurita et al., 2019). Recent advances in NLP require large amounts"
2020.acl-main.260,D19-1531,1,0.899272,"Missing"
2020.acl-main.260,Q17-1010,0,\N,Missing
2020.acl-main.260,P19-1299,1,\N,Missing
2020.acl-main.260,N19-1253,1,\N,Missing
2020.acl-main.260,D19-1103,1,\N,Missing
2020.acl-main.264,D17-1323,1,0.957199,"al Linguistics, pages 2936–2942 c July 5 - 10, 2020. 2020 Association for Computational Linguistics 2 Related Work Algorithmic Bias Machine learning models are becoming more and more prevalent in the real world, and algorithmic bias will have a great societal impact (Tonry, 2010; Buolamwini and Gebru, 2018). Researchers have found societal bias in different applications such as coreference resolution (Rudinger et al., 2018; Zhao et al., 2018), machine translation (Stanovsky et al., 2019) and online advertisement (Sweeney, 2013). Without appropriate adjustments, the model can amplify the bias (Zhao et al., 2017). Different from the previous work, we aim at understanding the bias amplification from the posterior perspective instead of directly looking at the top predictions of the model. Posterior Regularization The posterior regularization framework (Ganchev et al., 2010) is aiming to represent and enforce constraints on the posterior distribution. It has been shown effective to inject domain knowledge for NLP applications. For example, Ji et al. (2012); Gao et al. (2014) design constraints based on similarity to improve question answering and machine translation, respectively. Yang and Cardie (2014)"
2020.acl-main.264,P14-1066,0,0.0317242,"tanovsky et al., 2019) and online advertisement (Sweeney, 2013). Without appropriate adjustments, the model can amplify the bias (Zhao et al., 2017). Different from the previous work, we aim at understanding the bias amplification from the posterior perspective instead of directly looking at the top predictions of the model. Posterior Regularization The posterior regularization framework (Ganchev et al., 2010) is aiming to represent and enforce constraints on the posterior distribution. It has been shown effective to inject domain knowledge for NLP applications. For example, Ji et al. (2012); Gao et al. (2014) design constraints based on similarity to improve question answering and machine translation, respectively. Yang and Cardie (2014) propose constraints based on lexical patterns in sentiment analysis. Meng et al. (2019) apply corpus-level constraints to guide a dependency parser in the cross-lingual transfer setting. In this paper we leverage corpus-level constraints to calibrate the output distribution. Our study resembles to the confidence calibration (Guo et al., 2017; Naeini et al., 2015). However, the temperature turning and binning methods proposed in these papers cannot straightforwardl"
2020.acl-main.264,N18-2003,1,0.887,"rocessing models. The code and data are available at https://github.com/uclanlp/reducingbias. 2936 Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 2936–2942 c July 5 - 10, 2020. 2020 Association for Computational Linguistics 2 Related Work Algorithmic Bias Machine learning models are becoming more and more prevalent in the real world, and algorithmic bias will have a great societal impact (Tonry, 2010; Buolamwini and Gebru, 2018). Researchers have found societal bias in different applications such as coreference resolution (Rudinger et al., 2018; Zhao et al., 2018), machine translation (Stanovsky et al., 2019) and online advertisement (Sweeney, 2013). Without appropriate adjustments, the model can amplify the bias (Zhao et al., 2017). Different from the previous work, we aim at understanding the bias amplification from the posterior perspective instead of directly looking at the top predictions of the model. Posterior Regularization The posterior regularization framework (Ganchev et al., 2010) is aiming to represent and enforce constraints on the posterior distribution. It has been shown effective to inject domain knowledge for NLP applications. For exa"
2020.acl-main.264,D19-1103,1,0.840243,"mplification from the posterior perspective instead of directly looking at the top predictions of the model. Posterior Regularization The posterior regularization framework (Ganchev et al., 2010) is aiming to represent and enforce constraints on the posterior distribution. It has been shown effective to inject domain knowledge for NLP applications. For example, Ji et al. (2012); Gao et al. (2014) design constraints based on similarity to improve question answering and machine translation, respectively. Yang and Cardie (2014) propose constraints based on lexical patterns in sentiment analysis. Meng et al. (2019) apply corpus-level constraints to guide a dependency parser in the cross-lingual transfer setting. In this paper we leverage corpus-level constraints to calibrate the output distribution. Our study resembles to the confidence calibration (Guo et al., 2017; Naeini et al., 2015). However, the temperature turning and binning methods proposed in these papers cannot straightforwardly be extended to calibrate the bias amplification. 3 Background We follow the settings in Zhao et al. (2017) to focus on the imSitu vSRL dataset (Yatskar et al., 2016), in which we are supposed to predict the activities"
2020.acl-main.264,N18-2002,0,0.0272681,"Missing"
2020.acl-main.264,P19-1164,0,0.0129638,"vailable at https://github.com/uclanlp/reducingbias. 2936 Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 2936–2942 c July 5 - 10, 2020. 2020 Association for Computational Linguistics 2 Related Work Algorithmic Bias Machine learning models are becoming more and more prevalent in the real world, and algorithmic bias will have a great societal impact (Tonry, 2010; Buolamwini and Gebru, 2018). Researchers have found societal bias in different applications such as coreference resolution (Rudinger et al., 2018; Zhao et al., 2018), machine translation (Stanovsky et al., 2019) and online advertisement (Sweeney, 2013). Without appropriate adjustments, the model can amplify the bias (Zhao et al., 2017). Different from the previous work, we aim at understanding the bias amplification from the posterior perspective instead of directly looking at the top predictions of the model. Posterior Regularization The posterior regularization framework (Ganchev et al., 2010) is aiming to represent and enforce constraints on the posterior distribution. It has been shown effective to inject domain knowledge for NLP applications. For example, Ji et al. (2012); Gao et al. (2014) desi"
2020.acl-main.264,P14-1031,0,0.0211046,"as (Zhao et al., 2017). Different from the previous work, we aim at understanding the bias amplification from the posterior perspective instead of directly looking at the top predictions of the model. Posterior Regularization The posterior regularization framework (Ganchev et al., 2010) is aiming to represent and enforce constraints on the posterior distribution. It has been shown effective to inject domain knowledge for NLP applications. For example, Ji et al. (2012); Gao et al. (2014) design constraints based on similarity to improve question answering and machine translation, respectively. Yang and Cardie (2014) propose constraints based on lexical patterns in sentiment analysis. Meng et al. (2019) apply corpus-level constraints to guide a dependency parser in the cross-lingual transfer setting. In this paper we leverage corpus-level constraints to calibrate the output distribution. Our study resembles to the confidence calibration (Guo et al., 2017; Naeini et al., 2015). However, the temperature turning and binning methods proposed in these papers cannot straightforwardly be extended to calibrate the bias amplification. 3 Background We follow the settings in Zhao et al. (2017) to focus on the imSitu"
2020.acl-main.264,P98-1013,0,\N,Missing
2020.acl-main.264,C98-1013,0,\N,Missing
2020.acl-main.265,W19-3821,0,0.0448601,"Missing"
2020.acl-main.265,D14-1067,0,0.0156878,"1 Introduction With the wealth of information being posted online daily, relation extraction has become increasingly important. Relation extraction aims specifically to extract relations from raw sentences and represent them as succinct relation tuples of the form (head, relation, tail) e.g., (Barack Obama, spouse, Michelle Obama). The concise representations provided by relation extraction models have been used to extend Knowledge Bases (KBs) (Riedel et al., 2013; Subasic et al., 2019; Trisedya et al., 2019). These KBs are then used heavily in NLP systems, such as question answering systems (Bordes et al., 2014; Yin et al., 2016; Cui et al., 2019). In recent years, much focus in the Neural Relation Extraction (NRE) community has been centered on improvements in model precision and the reduction of noise (Lin et al., 2016; Liu et al., 2017; Wu et al., 2017; Feng et al., 2018; Vashishth et al., 2018; Qin et al., 2018). Yet, little attention has been devoted towards the fairness of such systems. We take the first step at understanding and evaluating gender bias in NRE systems by measuring the differences in model performance when extracting relations from sentences written about females versus sentence"
2020.acl-main.265,N19-3002,0,0.0177559,"ed different metrics to evaluate gender bias, for example, by using the performance difference of the model on male and female datapoints for bias evaluation (Lu et al., 2018; Kiritchenko and Mohammad, 2018). Other metrics have been proposed to evaluate fairness of predictors and allocative bias (Dwork et al., 2012; Hardt et al., 2016), such as Equality of Opportunity. In this work, we use both of these metrics to evaluate NRE models. Mitigation Methods. After discovering gender bias existing, prior work has developed various methods to mitigate that bias (Escud´e Font and Costa-juss`a, 2019; Bordia and Bowman, 2019). Those mitigation methods can be applied in different levels of a model, including in the training phase, in the embedding layer, or in the inference procedure. In this paper, we test three existing debiasing approaches, namely data augmentation (Zhao et al., 2018; Lu et al., 2018), and word embedding debiasing technique (Hard Debiasing (Bolukbasi et al., 2016)) for mitigating bias in NRE models. 2944 Train Development Test Total Original Dataset Entity Pairs Instances M F M F 12,139 4,571 27,048 9,391 1,587 553 3,416 1,144 1,030 1,101 2,320 2,284 14,756 6,225 32,784 12,819 Equalized Dataset"
2020.acl-main.265,D19-3029,0,0.0704855,"ther discrepancy: amongst articles we sampled, proportionally, the spouse relation is mentioned more often relative to hypernym, birthPlace, and birthDate in female articles than in male articles. Additionally, we show that amongst female and male articles we sampled, hypernyms are mentioned more often in male than female articles relative to spouse, birthPlace, and birthDate (see Section 2). This observation aligns with the literature, arguing that authors do not write about the two genders equally (Wagner et al., 2015; Graells-Garrido et al., 2015). 4 Gender Bias in NRE We evaluate OpenNRE (Han et al., 2019), a popular open-source NRE system. OpenNRE implements the approach from (Lin et al., 2016). To convert sentences into vectors, researchers propose convolutional neural networks as well as the pieceweise convoultional neural networks (PCNN) which retain more structural information between entities (Zeng et al., 2015). In this work, we use a PCNN with Selective Attention for the experiments. We train every encoder-selector combination on the training set of WikiGenderBias and its genderequalized version. We input Word2Vec (Mikolov et al., 2013) word embeddings trained on WikiGenPerformance Pari"
2020.acl-main.265,P11-1055,0,0.0602945,", and many are unable to extract intra-sentence relations (Bach and Badaskar, 2007). When data annotation is insufficient or hard to obtain and semi-supervised approaches are insufficient, the distant supervision assumption is used to collect data to train supervised models (Mintz et al., 2009). Given a relation (e1 , r, e2 ) in a knowledge base (KB), distant supervision assumes any sentence that contains both e1 and e2 expresses r (Mintz et al., 2009). Great efforts have been made to improve NRE models by mitigating the effects of noise in the training data introduced by Distant Supervision (Hoffmann et al., 2011; Surdeanu et al., 2012; Lin et al., 2016; Liu et al., 2017; Feng et al., 2018; Qin et al., 2018). However, to our knowledge, there are no studies on bias or ethics in NRE, which is filled by this work. 3 WikiGenderBias We define gender bias in NRE as a difference in model performance when predicting on sentences from male versus female articles. Thus, we need articles written about entities for which we can identify the gender information. However, to obtain gender information for existing annotated datasets could be costly or impossible. Thus, we elected to create WikiGenderBias with this ge"
2020.acl-main.265,S18-2005,0,0.0560903,"Missing"
2020.acl-main.265,P16-1200,0,0.411465,"nt them as succinct relation tuples of the form (head, relation, tail) e.g., (Barack Obama, spouse, Michelle Obama). The concise representations provided by relation extraction models have been used to extend Knowledge Bases (KBs) (Riedel et al., 2013; Subasic et al., 2019; Trisedya et al., 2019). These KBs are then used heavily in NLP systems, such as question answering systems (Bordes et al., 2014; Yin et al., 2016; Cui et al., 2019). In recent years, much focus in the Neural Relation Extraction (NRE) community has been centered on improvements in model precision and the reduction of noise (Lin et al., 2016; Liu et al., 2017; Wu et al., 2017; Feng et al., 2018; Vashishth et al., 2018; Qin et al., 2018). Yet, little attention has been devoted towards the fairness of such systems. We take the first step at understanding and evaluating gender bias in NRE systems by measuring the differences in model performance when extracting relations from sentences written about females versus sentences written about males. If a NRE model predicts a relation such occupation with higher recall on male entities, this could lead to the resulted knowledge bases having more occupation information for males than for f"
2020.acl-main.265,D17-1189,0,0.0623649,"t relation tuples of the form (head, relation, tail) e.g., (Barack Obama, spouse, Michelle Obama). The concise representations provided by relation extraction models have been used to extend Knowledge Bases (KBs) (Riedel et al., 2013; Subasic et al., 2019; Trisedya et al., 2019). These KBs are then used heavily in NLP systems, such as question answering systems (Bordes et al., 2014; Yin et al., 2016; Cui et al., 2019). In recent years, much focus in the Neural Relation Extraction (NRE) community has been centered on improvements in model precision and the reduction of noise (Lin et al., 2016; Liu et al., 2017; Wu et al., 2017; Feng et al., 2018; Vashishth et al., 2018; Qin et al., 2018). Yet, little attention has been devoted towards the fairness of such systems. We take the first step at understanding and evaluating gender bias in NRE systems by measuring the differences in model performance when extracting relations from sentences written about females versus sentences written about males. If a NRE model predicts a relation such occupation with higher recall on male entities, this could lead to the resulted knowledge bases having more occupation information for males than for females (see the il"
2020.acl-main.265,D19-1530,0,0.0199034,"imately equal, then train on this modified, equalized distribution. Data Augmentation. The contexts in which males and females are written about can differ; for instance, on Wikipedia women are more often written about with words related to sexuality than men (Graells-Garrido et al., 2015). Data augmentation mitigates these contextual biases by replacing masculine words in a sentence with their corresponding feminine words and vice versa for all sentences in a corpus, and then training on the union of the original and augmented corpora3 (Zhao et al., 2018; Lu et al., 2018; Dixon et al., 2018; Maudslay et al., 2019; Zhao et al., 2019). Word Embedding Debiasing Word embeddings can encode gender biases (Bolukbasi et al., 2016; Caliskan et al., 2017; Garg et al., 2018) and this can affect bias in downstream predictions for models using the embeddings (Zhao et al., 2018; Font and Costa-Jussa, 2019). In this work, we apply the Hard-Debiasing technique (Bolukbasi et al., 2016). We applied Hard-Debiasing to Word2Vec embeddings (Mikolov et al., 2013), which we trained on the sentences in WikiGenderBias. When used in conjunction with data augmentation, the embeddings are re-trained on the union of the two corpor"
2020.acl-main.265,mendes-etal-2012-dbpedia,0,0.0144587,"e when predicting on sentences from male versus female articles. Thus, we need articles written about entities for which we can identify the gender information. However, to obtain gender information for existing annotated datasets could be costly or impossible. Thus, we elected to create WikiGenderBias with this gender information to be able to detect scenarios like that in Figure 1. The data statistics of WikiGenderBias are given in Table 1. 3.1 Dataset Creation Wikipedia is associated with a knowledge base, DBPedia, that contains relation information for entities with articles on Wikipedia (Mendes et al., 2012). Many of these entities have gender information and their corresponding articles are readily available. Therefore, we create our dataset based on sentences extracted from Wikipedia. To generate WikiGenderBias, we use a variant of the distant supervision assumption: for a given relation between two entities, if one sentence from an article written about one entity also mentions the other entity, then we assume that such sentence expresses the relation. For instance, if we know (Barack, spouse, Michelle) is a relation tuple and we find the sentence He and Michelle were married in Barack’s Wikip"
2020.acl-main.265,P09-1113,0,0.680096,"as supervised, including feature-based methods (Kambhatla, 2004; Zhou et al., 2005; Zhao and Grishman, 2005) and kernelbased methods (Lodhi et al., 2002; Zelenko et al., 2003), or semi-supervised (Brin, 1998; Agichtein and Gravano, 2000; Etzioni et al., 2005; Pantel and Pennacchiotti, 2006), or purely unsupervised (Etzioni et al., 2008). Supervised approaches suffer from the need for large amounts of labelled data, which is sometimes not feasible, and generalizes poorly to open domain relation extraction, since labeled data is required for every entity-relation type (Bach and Badaskar, 2007; Mintz et al., 2009). Many semi-supervised approaches rely on patternmatching, which is not robust, and many are unable to extract intra-sentence relations (Bach and Badaskar, 2007). When data annotation is insufficient or hard to obtain and semi-supervised approaches are insufficient, the distant supervision assumption is used to collect data to train supervised models (Mintz et al., 2009). Given a relation (e1 , r, e2 ) in a knowledge base (KB), distant supervision assumes any sentence that contains both e1 and e2 expresses r (Mintz et al., 2009). Great efforts have been made to improve NRE models by mitigating"
2020.acl-main.265,P06-1015,0,0.138817,"ender-equalized dataset created by down-sampling male instances. Neural Relation Extraction. Relation extraction is a task in NLP with a long history that typically seeks to extract structured tuples (e1 , r, e2 ) from texts (Bach and Badaskar, 2007). Early on, learning algorithms for relation extraction models were typically categorized as supervised, including feature-based methods (Kambhatla, 2004; Zhou et al., 2005; Zhao and Grishman, 2005) and kernelbased methods (Lodhi et al., 2002; Zelenko et al., 2003), or semi-supervised (Brin, 1998; Agichtein and Gravano, 2000; Etzioni et al., 2005; Pantel and Pennacchiotti, 2006), or purely unsupervised (Etzioni et al., 2008). Supervised approaches suffer from the need for large amounts of labelled data, which is sometimes not feasible, and generalizes poorly to open domain relation extraction, since labeled data is required for every entity-relation type (Bach and Badaskar, 2007; Mintz et al., 2009). Many semi-supervised approaches rely on patternmatching, which is not robust, and many are unable to extract intra-sentence relations (Bach and Badaskar, 2007). When data annotation is insufficient or hard to obtain and semi-supervised approaches are insufficient, the di"
2020.acl-main.265,P18-1199,1,0.903039,"se, Michelle Obama). The concise representations provided by relation extraction models have been used to extend Knowledge Bases (KBs) (Riedel et al., 2013; Subasic et al., 2019; Trisedya et al., 2019). These KBs are then used heavily in NLP systems, such as question answering systems (Bordes et al., 2014; Yin et al., 2016; Cui et al., 2019). In recent years, much focus in the Neural Relation Extraction (NRE) community has been centered on improvements in model precision and the reduction of noise (Lin et al., 2016; Liu et al., 2017; Wu et al., 2017; Feng et al., 2018; Vashishth et al., 2018; Qin et al., 2018). Yet, little attention has been devoted towards the fairness of such systems. We take the first step at understanding and evaluating gender bias in NRE systems by measuring the differences in model performance when extracting relations from sentences written about females versus sentences written about males. If a NRE model predicts a relation such occupation with higher recall on male entities, this could lead to the resulted knowledge bases having more occupation information for males than for females (see the illustration in Figure 1). Eventually, the gender bias in knowledge bases may aff"
2020.acl-main.265,N13-1008,0,0.0243098,"s mitigation approaches have a negative effect on NRE. Our analysis lays groundwork for future quantifying and mitigating bias in relation extraction. 1 Introduction With the wealth of information being posted online daily, relation extraction has become increasingly important. Relation extraction aims specifically to extract relations from raw sentences and represent them as succinct relation tuples of the form (head, relation, tail) e.g., (Barack Obama, spouse, Michelle Obama). The concise representations provided by relation extraction models have been used to extend Knowledge Bases (KBs) (Riedel et al., 2013; Subasic et al., 2019; Trisedya et al., 2019). These KBs are then used heavily in NLP systems, such as question answering systems (Bordes et al., 2014; Yin et al., 2016; Cui et al., 2019). In recent years, much focus in the Neural Relation Extraction (NRE) community has been centered on improvements in model precision and the reduction of noise (Lin et al., 2016; Liu et al., 2017; Wu et al., 2017; Feng et al., 2018; Vashishth et al., 2018; Qin et al., 2018). Yet, little attention has been devoted towards the fairness of such systems. We take the first step at understanding and evaluating gend"
2020.acl-main.265,N18-2002,0,0.0396004,"Missing"
2020.acl-main.265,D19-1339,1,0.836473,"ate WikiGenderBias, a new dataset for evaluating gender bias in NRE systems. • We present an evaluation framework to demonstrate that gender bias is exhibited in NRE model outputs. • We test several existing bias mitigation approaches to reducing gender bias in NRE system. Our analysis sheds light for designing future mitigating techniques. 2 Related Work Gender Bias Measurement. Existing studies have revealed gender bias in various NLP tasks (Zhao et al., 2017; Rudinger et al., 2018; Zhao et al., 2018; Dixon et al., 2018; Lu et al., 2018; Kiritchenko and Mohammad, 2018; Romanov et al., 2019; Sheng et al., 2019; Sun et al., 2019). People have proposed different metrics to evaluate gender bias, for example, by using the performance difference of the model on male and female datapoints for bias evaluation (Lu et al., 2018; Kiritchenko and Mohammad, 2018). Other metrics have been proposed to evaluate fairness of predictors and allocative bias (Dwork et al., 2012; Hardt et al., 2016), such as Equality of Opportunity. In this work, we use both of these metrics to evaluate NRE models. Mitigation Methods. After discovering gender bias existing, prior work has developed various methods to mitigate that bias"
2020.acl-main.265,D12-1042,0,0.0357208,"o extract intra-sentence relations (Bach and Badaskar, 2007). When data annotation is insufficient or hard to obtain and semi-supervised approaches are insufficient, the distant supervision assumption is used to collect data to train supervised models (Mintz et al., 2009). Given a relation (e1 , r, e2 ) in a knowledge base (KB), distant supervision assumes any sentence that contains both e1 and e2 expresses r (Mintz et al., 2009). Great efforts have been made to improve NRE models by mitigating the effects of noise in the training data introduced by Distant Supervision (Hoffmann et al., 2011; Surdeanu et al., 2012; Lin et al., 2016; Liu et al., 2017; Feng et al., 2018; Qin et al., 2018). However, to our knowledge, there are no studies on bias or ethics in NRE, which is filled by this work. 3 WikiGenderBias We define gender bias in NRE as a difference in model performance when predicting on sentences from male versus female articles. Thus, we need articles written about entities for which we can identify the gender information. However, to obtain gender information for existing annotated datasets could be costly or impossible. Thus, we elected to create WikiGenderBias with this gender information to be"
2020.acl-main.265,P19-1023,0,0.0142747,"ect on NRE. Our analysis lays groundwork for future quantifying and mitigating bias in relation extraction. 1 Introduction With the wealth of information being posted online daily, relation extraction has become increasingly important. Relation extraction aims specifically to extract relations from raw sentences and represent them as succinct relation tuples of the form (head, relation, tail) e.g., (Barack Obama, spouse, Michelle Obama). The concise representations provided by relation extraction models have been used to extend Knowledge Bases (KBs) (Riedel et al., 2013; Subasic et al., 2019; Trisedya et al., 2019). These KBs are then used heavily in NLP systems, such as question answering systems (Bordes et al., 2014; Yin et al., 2016; Cui et al., 2019). In recent years, much focus in the Neural Relation Extraction (NRE) community has been centered on improvements in model precision and the reduction of noise (Lin et al., 2016; Liu et al., 2017; Wu et al., 2017; Feng et al., 2018; Vashishth et al., 2018; Qin et al., 2018). Yet, little attention has been devoted towards the fairness of such systems. We take the first step at understanding and evaluating gender bias in NRE systems by measuring the differ"
2020.acl-main.265,W16-0106,0,0.023369,"he wealth of information being posted online daily, relation extraction has become increasingly important. Relation extraction aims specifically to extract relations from raw sentences and represent them as succinct relation tuples of the form (head, relation, tail) e.g., (Barack Obama, spouse, Michelle Obama). The concise representations provided by relation extraction models have been used to extend Knowledge Bases (KBs) (Riedel et al., 2013; Subasic et al., 2019; Trisedya et al., 2019). These KBs are then used heavily in NLP systems, such as question answering systems (Bordes et al., 2014; Yin et al., 2016; Cui et al., 2019). In recent years, much focus in the Neural Relation Extraction (NRE) community has been centered on improvements in model precision and the reduction of noise (Lin et al., 2016; Liu et al., 2017; Wu et al., 2017; Feng et al., 2018; Vashishth et al., 2018; Qin et al., 2018). Yet, little attention has been devoted towards the fairness of such systems. We take the first step at understanding and evaluating gender bias in NRE systems by measuring the differences in model performance when extracting relations from sentences written about females versus sentences written about ma"
2020.acl-main.265,D15-1203,0,0.0186653,"female articles relative to spouse, birthPlace, and birthDate (see Section 2). This observation aligns with the literature, arguing that authors do not write about the two genders equally (Wagner et al., 2015; Graells-Garrido et al., 2015). 4 Gender Bias in NRE We evaluate OpenNRE (Han et al., 2019), a popular open-source NRE system. OpenNRE implements the approach from (Lin et al., 2016). To convert sentences into vectors, researchers propose convolutional neural networks as well as the pieceweise convoultional neural networks (PCNN) which retain more structural information between entities (Zeng et al., 2015). In this work, we use a PCNN with Selective Attention for the experiments. We train every encoder-selector combination on the training set of WikiGenderBias and its genderequalized version. We input Word2Vec (Mikolov et al., 2013) word embeddings trained on WikiGenPerformance Parity Score The goal of a successful relation extraction model is to maximize F1 score while minimizing the model performance gender gap (or disparity score). However, when comparing different systems, it is hard to decide what is the right balance between these two objectives. On one end, a model which has zero gender"
2020.acl-main.265,N19-1064,1,0.822506,"in on this modified, equalized distribution. Data Augmentation. The contexts in which males and females are written about can differ; for instance, on Wikipedia women are more often written about with words related to sexuality than men (Graells-Garrido et al., 2015). Data augmentation mitigates these contextual biases by replacing masculine words in a sentence with their corresponding feminine words and vice versa for all sentences in a corpus, and then training on the union of the original and augmented corpora3 (Zhao et al., 2018; Lu et al., 2018; Dixon et al., 2018; Maudslay et al., 2019; Zhao et al., 2019). Word Embedding Debiasing Word embeddings can encode gender biases (Bolukbasi et al., 2016; Caliskan et al., 2017; Garg et al., 2018) and this can affect bias in downstream predictions for models using the embeddings (Zhao et al., 2018; Font and Costa-Jussa, 2019). In this work, we apply the Hard-Debiasing technique (Bolukbasi et al., 2016). We applied Hard-Debiasing to Word2Vec embeddings (Mikolov et al., 2013), which we trained on the sentences in WikiGenderBias. When used in conjunction with data augmentation, the embeddings are re-trained on the union of the two corpora. Below, we give me"
2020.acl-main.265,D17-1323,1,0.82348,"thDate and birthPlace, as they are not intuitively related to gender. Experiment results confirm our conjecture. Our contributions are as such: • We create WikiGenderBias, a new dataset for evaluating gender bias in NRE systems. • We present an evaluation framework to demonstrate that gender bias is exhibited in NRE model outputs. • We test several existing bias mitigation approaches to reducing gender bias in NRE system. Our analysis sheds light for designing future mitigating techniques. 2 Related Work Gender Bias Measurement. Existing studies have revealed gender bias in various NLP tasks (Zhao et al., 2017; Rudinger et al., 2018; Zhao et al., 2018; Dixon et al., 2018; Lu et al., 2018; Kiritchenko and Mohammad, 2018; Romanov et al., 2019; Sheng et al., 2019; Sun et al., 2019). People have proposed different metrics to evaluate gender bias, for example, by using the performance difference of the model on male and female datapoints for bias evaluation (Lu et al., 2018; Kiritchenko and Mohammad, 2018). Other metrics have been proposed to evaluate fairness of predictors and allocative bias (Dwork et al., 2012; Hardt et al., 2016), such as Equality of Opportunity. In this work, we use both of these m"
2020.acl-main.265,N18-2003,1,0.87482,"pation; engineer) relation. However, the model only predicts that the sentence from the male article expresses the occupation relation. If on a large scale, models extract the (entity; occupation; engineer) relation more often for males, knowledge bases will contain information for male engineers more often than female. Question answering models that query these knowledge bases may give biased answers and propagate gender bias downstream. exhibited in a model that is trained on a relation extraction dataset; and (2) examining if the existing bias mitigation techniques (Bolukbasi et al., 2016; Zhao et al., 2018; Lu et al., 2018) can be applied to reduce the bias in an NRE system while maintaining its performance. Carrying out such an evaluation is difficult with existing NRE datasets, such as the NYT dataset (Sandhaus, 2018), because there is no reliable way to obtain gender information about the entities mentioned in input sentences. Therefore, we create a new dataset, WikiGenderBias, specifically aimed at evaluating gender bias for NRE. WikiGenderBias is a distantly supervised dataset extracted using Wikipedia and DBPedia. It contains 45,000 sentences, each of which describe either a male or femal"
2020.acl-main.265,P05-1052,0,0.145408,"apoints as male (female) if that is the gender of the subject of the article. The left two entries are for the dataset taken from the true distribution; the right two are the gender-equalized dataset created by down-sampling male instances. Neural Relation Extraction. Relation extraction is a task in NLP with a long history that typically seeks to extract structured tuples (e1 , r, e2 ) from texts (Bach and Badaskar, 2007). Early on, learning algorithms for relation extraction models were typically categorized as supervised, including feature-based methods (Kambhatla, 2004; Zhou et al., 2005; Zhao and Grishman, 2005) and kernelbased methods (Lodhi et al., 2002; Zelenko et al., 2003), or semi-supervised (Brin, 1998; Agichtein and Gravano, 2000; Etzioni et al., 2005; Pantel and Pennacchiotti, 2006), or purely unsupervised (Etzioni et al., 2008). Supervised approaches suffer from the need for large amounts of labelled data, which is sometimes not feasible, and generalizes poorly to open domain relation extraction, since labeled data is required for every entity-relation type (Bach and Badaskar, 2007; Mintz et al., 2009). Many semi-supervised approaches rely on patternmatching, which is not robust, and many a"
2020.acl-main.265,P05-1053,0,0.18774,"e and we define datapoints as male (female) if that is the gender of the subject of the article. The left two entries are for the dataset taken from the true distribution; the right two are the gender-equalized dataset created by down-sampling male instances. Neural Relation Extraction. Relation extraction is a task in NLP with a long history that typically seeks to extract structured tuples (e1 , r, e2 ) from texts (Bach and Badaskar, 2007). Early on, learning algorithms for relation extraction models were typically categorized as supervised, including feature-based methods (Kambhatla, 2004; Zhou et al., 2005; Zhao and Grishman, 2005) and kernelbased methods (Lodhi et al., 2002; Zelenko et al., 2003), or semi-supervised (Brin, 1998; Agichtein and Gravano, 2000; Etzioni et al., 2005; Pantel and Pennacchiotti, 2006), or purely unsupervised (Etzioni et al., 2008). Supervised approaches suffer from the need for large amounts of labelled data, which is sometimes not feasible, and generalizes poorly to open domain relation extraction, since labeled data is required for every entity-relation type (Bach and Badaskar, 2007; Mintz et al., 2009). Many semi-supervised approaches rely on patternmatching, which"
2020.acl-main.265,D17-1187,0,0.0193625,"of the form (head, relation, tail) e.g., (Barack Obama, spouse, Michelle Obama). The concise representations provided by relation extraction models have been used to extend Knowledge Bases (KBs) (Riedel et al., 2013; Subasic et al., 2019; Trisedya et al., 2019). These KBs are then used heavily in NLP systems, such as question answering systems (Bordes et al., 2014; Yin et al., 2016; Cui et al., 2019). In recent years, much focus in the Neural Relation Extraction (NRE) community has been centered on improvements in model precision and the reduction of noise (Lin et al., 2016; Liu et al., 2017; Wu et al., 2017; Feng et al., 2018; Vashishth et al., 2018; Qin et al., 2018). Yet, little attention has been devoted towards the fairness of such systems. We take the first step at understanding and evaluating gender bias in NRE systems by measuring the differences in model performance when extracting relations from sentences written about females versus sentences written about males. If a NRE model predicts a relation such occupation with higher recall on male entities, this could lead to the resulted knowledge bases having more occupation information for males than for females (see the illustration in Fig"
2020.acl-main.310,D18-1316,1,0.934038,"pulation and word substitution can degrade the performance of NMT systems. Baldwin et al. (2017) augment original sentiment classification datasets with syntactically (reordering) and semantically (word substitution) noisy sentences and achieve higher performance. Our method is partly inspired by Lui et al. (2018), who synthesize semi-natural ungrammatical sentences by maintaining confusion matrices for five simple error types. Another line of studies uses black-box adversarial attack methods to create adversarial examples 3387 for debugging NLP models (Ribeiro et al., 2018; Jin et al., 2019; Alzantot et al., 2018; Burstein et al., 2019). These methods create a more challenging scenario for target models compared to the above data generation procedure. Our proposed simulation benefits from both adversarial attack algorithms and semi-natural grammatical errors. 3 Method We first explain how we simulate ungrammatical scenarios. Then, we describe target models and the evaluation design. 3.1 Grammatical Error Simulation Most downstream datasets contain only clean and grammatical sentences. Despite that recent language encoders achieve promising performance, it is unclear if they perform equally well on tex"
2020.acl-main.310,W19-4822,0,0.117888,"o have a positive social impact if language encoders can model texts from non-native speakers appropriately. Recent work on evaluating model’s behaviors against grammatical errors employs various methods, including (1) manually constructing minimal edited pairs on specific linguistic phenomena (Marvin and Linzen, 2018; Goldberg, 2019; Warstadt et al., 2019a,b); (2) labeling or creating acceptability judgment resources (Linzen et al., 2016; Warstadt and Bowman, 2019; Warstadt et al., 2019a); and (3) simulating noises for a specific NLP task such as neural machine translation (Lui et al., 2018; Anastasopoulos, 2019), sentiment classification (Baldwin et al., 2017). These studies either focus on specific phenomena and mainly conduct experiments on designated corpora or rely heavily on human annotations and expert knowledge in linguistics. In contrast, our work automatically simulates natural occurring data and various types of grammatical errors and systematically analyzes how these noises affect downstream applications. This holds more practical significance to understand the robustness of several language encoders against grammatical errors. Specifically, we first propose an effective approach to simula"
2020.acl-main.310,S19-1026,0,0.0400524,"Missing"
2020.acl-main.310,P18-1079,0,0.0465214,"matical errors induced by character manipulation and word substitution can degrade the performance of NMT systems. Baldwin et al. (2017) augment original sentiment classification datasets with syntactically (reordering) and semantically (word substitution) noisy sentences and achieve higher performance. Our method is partly inspired by Lui et al. (2018), who synthesize semi-natural ungrammatical sentences by maintaining confusion matrices for five simple error types. Another line of studies uses black-box adversarial attack methods to create adversarial examples 3387 for debugging NLP models (Ribeiro et al., 2018; Jin et al., 2019; Alzantot et al., 2018; Burstein et al., 2019). These methods create a more challenging scenario for target models compared to the above data generation procedure. Our proposed simulation benefits from both adversarial attack algorithms and semi-natural grammatical errors. 3 Method We first explain how we simulate ungrammatical scenarios. Then, we describe target models and the evaluation design. 3.1 Grammatical Error Simulation Most downstream datasets contain only clean and grammatical sentences. Despite that recent language encoders achieve promising performance, it is un"
2020.acl-main.310,Q16-1037,0,0.288802,"ly in spoken and written materials from non-native speakers. Dealing with such a noise reflects model robustness in representing language and grammatical knowledge. It would also have a positive social impact if language encoders can model texts from non-native speakers appropriately. Recent work on evaluating model’s behaviors against grammatical errors employs various methods, including (1) manually constructing minimal edited pairs on specific linguistic phenomena (Marvin and Linzen, 2018; Goldberg, 2019; Warstadt et al., 2019a,b); (2) labeling or creating acceptability judgment resources (Linzen et al., 2016; Warstadt and Bowman, 2019; Warstadt et al., 2019a); and (3) simulating noises for a specific NLP task such as neural machine translation (Lui et al., 2018; Anastasopoulos, 2019), sentiment classification (Baldwin et al., 2017). These studies either focus on specific phenomena and mainly conduct experiments on designated corpora or rely heavily on human annotations and expert knowledge in linguistics. In contrast, our work automatically simulates natural occurring data and various types of grammatical errors and systematically analyzes how these noises affect downstream applications. This hol"
2020.acl-main.310,N19-1112,0,0.261436,"errors. We find that fixed contextual encoders with a simple classifier trained on the prediction of sentence correctness are able to locate error positions. We also design a cloze test for BERT and discover that BERT captures the interaction between errors and specific tokens in context. Our results shed light on understanding the robustness and behaviors of language encoders against grammatical errors. 1 Introduction Pre-trained language encoders have achieved great success in facilitating various downstream natural language processing (NLP) tasks (Peters et al., 2018; Devlin et al., 2019; Liu et al., 2019b). However, they usually assume training and test corpora are clean and it is unclear how the models behave when confronted with noisy input. Grammatical error is an important type of noise since it naturally and frequently occurs in natural language, especially in spoken and written materials from non-native speakers. Dealing with such a noise reflects model robustness in representing language and grammatical knowledge. It would also have a positive social impact if language encoders can model texts from non-native speakers appropriately. Recent work on evaluating model’s behaviors against g"
2020.acl-main.310,2021.ccl-1.108,0,0.0777721,"Missing"
2020.acl-main.310,D18-1151,0,0.225822,"y input. Grammatical error is an important type of noise since it naturally and frequently occurs in natural language, especially in spoken and written materials from non-native speakers. Dealing with such a noise reflects model robustness in representing language and grammatical knowledge. It would also have a positive social impact if language encoders can model texts from non-native speakers appropriately. Recent work on evaluating model’s behaviors against grammatical errors employs various methods, including (1) manually constructing minimal edited pairs on specific linguistic phenomena (Marvin and Linzen, 2018; Goldberg, 2019; Warstadt et al., 2019a,b); (2) labeling or creating acceptability judgment resources (Linzen et al., 2016; Warstadt and Bowman, 2019; Warstadt et al., 2019a); and (3) simulating noises for a specific NLP task such as neural machine translation (Lui et al., 2018; Anastasopoulos, 2019), sentiment classification (Baldwin et al., 2017). These studies either focus on specific phenomena and mainly conduct experiments on designated corpora or rely heavily on human annotations and expert knowledge in linguistics. In contrast, our work automatically simulates natural occurring data an"
2020.acl-main.310,N18-1202,0,0.297939,"ngrammatical sentences and the position of errors. We find that fixed contextual encoders with a simple classifier trained on the prediction of sentence correctness are able to locate error positions. We also design a cloze test for BERT and discover that BERT captures the interaction between errors and specific tokens in context. Our results shed light on understanding the robustness and behaviors of language encoders against grammatical errors. 1 Introduction Pre-trained language encoders have achieved great success in facilitating various downstream natural language processing (NLP) tasks (Peters et al., 2018; Devlin et al., 2019; Liu et al., 2019b). However, they usually assume training and test corpora are clean and it is unclear how the models behave when confronted with noisy input. Grammatical error is an important type of noise since it naturally and frequently occurs in natural language, especially in spoken and written materials from non-native speakers. Dealing with such a noise reflects model robustness in representing language and grammatical knowledge. It would also have a positive social impact if language encoders can model texts from non-native speakers appropriately. Recent work on"
2020.acl-main.310,W19-4302,0,0.065351,"Missing"
2020.acl-main.310,P06-1055,0,0.0108488,"Missing"
2020.acl-main.310,D13-1170,0,0.0139257,"Missing"
2020.acl-main.310,D19-1286,0,0.180232,"t type of noise since it naturally and frequently occurs in natural language, especially in spoken and written materials from non-native speakers. Dealing with such a noise reflects model robustness in representing language and grammatical knowledge. It would also have a positive social impact if language encoders can model texts from non-native speakers appropriately. Recent work on evaluating model’s behaviors against grammatical errors employs various methods, including (1) manually constructing minimal edited pairs on specific linguistic phenomena (Marvin and Linzen, 2018; Goldberg, 2019; Warstadt et al., 2019a,b); (2) labeling or creating acceptability judgment resources (Linzen et al., 2016; Warstadt and Bowman, 2019; Warstadt et al., 2019a); and (3) simulating noises for a specific NLP task such as neural machine translation (Lui et al., 2018; Anastasopoulos, 2019), sentiment classification (Baldwin et al., 2017). These studies either focus on specific phenomena and mainly conduct experiments on designated corpora or rely heavily on human annotations and expert knowledge in linguistics. In contrast, our work automatically simulates natural occurring data and various types of grammatical errors a"
2020.acl-main.310,I05-5002,0,\N,Missing
2020.acl-main.310,P06-4018,0,\N,Missing
2020.acl-main.310,W03-0419,0,\N,Missing
2020.acl-main.310,W13-1703,0,\N,Missing
2020.acl-main.310,D16-1264,0,\N,Missing
2020.acl-main.310,E17-2004,0,\N,Missing
2020.acl-main.310,P19-1452,0,\N,Missing
2020.acl-main.310,P19-1356,0,\N,Missing
2020.acl-main.310,N19-1311,0,\N,Missing
2020.acl-main.310,N19-1423,0,\N,Missing
2020.acl-main.310,N18-1101,0,\N,Missing
2020.acl-main.310,P19-1285,0,\N,Missing
2020.acl-main.341,D15-1280,0,0.0185724,"e, we conduct comprehensive quantitative and qualitative analyses to evaluate the effectiveness of SentiBERT under various situations and to demonstrate the semantic compositionality captured by the model. The source code is available at https://github.com/ WadeYin9712/SentiBERT. 2 Related Work Sentiment Analysis Various approaches have been applied to build a sentiment classiﬁer, including feature-based methods (Hu and Liu, 2004; Pang and Lee, 2004), recursive neural networks (Socher et al., 2012, 2013; Tai et al., 2015), convolution neural networks (Kim, 2014) and recurrent neural networks (Liu et al., 2015). Recently, pretrained language models such as ELMo (Peters et al., 2018), BERT (Devlin et al., 2019) and SentiLR (Ke et al., 2019) achieve high performance in sentiment analysis by constructing contextualized representation. Inspired by these prior studies, we design a transformer-based neural network model to capture compositional sentience semantics by leveraging binary constituency parse tree. Semantic Compositionality Semantic composition (Pelletier, 1994) has been widely studied in NLP literature. For example, Mitchell and Lapata (2008) introduce operations such as addition or element-wi"
2020.acl-main.341,2021.ccl-1.108,0,0.230626,"Missing"
2020.acl-main.341,P14-5010,0,0.00564294,"Missing"
2020.acl-main.341,P08-1028,0,0.118227,"n neural networks (Kim, 2014) and recurrent neural networks (Liu et al., 2015). Recently, pretrained language models such as ELMo (Peters et al., 2018), BERT (Devlin et al., 2019) and SentiLR (Ke et al., 2019) achieve high performance in sentiment analysis by constructing contextualized representation. Inspired by these prior studies, we design a transformer-based neural network model to capture compositional sentience semantics by leveraging binary constituency parse tree. Semantic Compositionality Semantic composition (Pelletier, 1994) has been widely studied in NLP literature. For example, Mitchell and Lapata (2008) introduce operations such as addition or element-wise product to model compositional semantics. The idea of modeling semantic composition is applied to various areas such as sentiment analysis (Socher et al., 2013; Zhu et al., 2016), semantic relatedness (Marelli et al., 2014) and capturing sememe knowledge (Qi et al., 2019). In this paper, we demonstrate that the syntactic structure can be combined with contextualized representation such that the semantic compositionality can be better captured. Our approach resembles to a few recent attempts (Harer et al., 2019; Wang et al., 2019) to integr"
2020.acl-main.341,S18-1001,0,0.182939,"ntion to Tokens) generates representation for each phrase based on the token it covers and the second layer (Attention to Children) reﬁnes the phrase representation obtained from the ﬁrst layer based on its children. line BERT model. As phrase-level sentiment labels are expensive to obtain, we further explore if the compositional sentiment semantics learned from one task can be transferred to others. In particular, we ﬁnd that SentiBERT trained on SST can be transferred well to other related tasks such as twitter sentiment analysis (Rosenthal et al., 2017) and emotion intensity classiﬁcation (Mohammad et al., 2018) and contextual emotion detection (Chatterjee et al., 2019). Furthermore, we conduct comprehensive quantitative and qualitative analyses to evaluate the effectiveness of SentiBERT under various situations and to demonstrate the semantic compositionality captured by the model. The source code is available at https://github.com/ WadeYin9712/SentiBERT. 2 Related Work Sentiment Analysis Various approaches have been applied to build a sentiment classiﬁer, including feature-based methods (Hu and Liu, 2004; Pang and Lee, 2004), recursive neural networks (Socher et al., 2012, 2013; Tai et al., 2015),"
2020.acl-main.341,P04-1035,0,0.0992145,"analysis (Rosenthal et al., 2017) and emotion intensity classiﬁcation (Mohammad et al., 2018) and contextual emotion detection (Chatterjee et al., 2019). Furthermore, we conduct comprehensive quantitative and qualitative analyses to evaluate the effectiveness of SentiBERT under various situations and to demonstrate the semantic compositionality captured by the model. The source code is available at https://github.com/ WadeYin9712/SentiBERT. 2 Related Work Sentiment Analysis Various approaches have been applied to build a sentiment classiﬁer, including feature-based methods (Hu and Liu, 2004; Pang and Lee, 2004), recursive neural networks (Socher et al., 2012, 2013; Tai et al., 2015), convolution neural networks (Kim, 2014) and recurrent neural networks (Liu et al., 2015). Recently, pretrained language models such as ELMo (Peters et al., 2018), BERT (Devlin et al., 2019) and SentiLR (Ke et al., 2019) achieve high performance in sentiment analysis by constructing contextualized representation. Inspired by these prior studies, we design a transformer-based neural network model to capture compositional sentience semantics by leveraging binary constituency parse tree. Semantic Compositionality Semantic c"
2020.acl-main.341,W02-1011,0,0.0323166,"er than baseline approaches in capturing negation and the contrastive relation and model the compositional sentiment semantics. 1  3RVLWLYH 1HXWUDO 1HJDWLYH )UHQHWLF EXW QRW UHDOO IXQQ Figure 1: Illustration of the challenges of learning sentiment semantic compositionality. The blue nodes represent token nodes. The colors of phrase nodes in the binary constituency tree represent the sentiment of phrases. The red boxes show that the sentiment changes from the child node to the parent node due to negation and contrast. Introduction Sentiment analysis is an important language processing task (Pang et al., 2002, 2008; Liu, 2012). One of the key challenges in sentiment analysis is to model compositional sentiment semantics. Take the sentence “Frenetic but not really funny.” in Figure 1 as an example. The two parts of the sentence are connected by “but”, which reveals the change of sentiment. Besides, the word “not” changes the sentiment of “really funny”. These types of negation and contrast are often difﬁcult to handle when the sentences are complex (Socher et al., 2013; Tay et al., 2018; Xu et al., 2019). In general, the sentiment of an expression is determined by the meaning of tokens and phrases"
2020.acl-main.341,P19-1571,0,0.0153086,"we design a transformer-based neural network model to capture compositional sentience semantics by leveraging binary constituency parse tree. Semantic Compositionality Semantic composition (Pelletier, 1994) has been widely studied in NLP literature. For example, Mitchell and Lapata (2008) introduce operations such as addition or element-wise product to model compositional semantics. The idea of modeling semantic composition is applied to various areas such as sentiment analysis (Socher et al., 2013; Zhu et al., 2016), semantic relatedness (Marelli et al., 2014) and capturing sememe knowledge (Qi et al., 2019). In this paper, we demonstrate that the syntactic structure can be combined with contextualized representation such that the semantic compositionality can be better captured. Our approach resembles to a few recent attempts (Harer et al., 2019; Wang et al., 2019) to integrate tree structures into self-attention. However, our design is speciﬁc for the semantic composition in sentiment analysis. 3 Model We introduce SentiBERT, a model that captures compositional sentiment semantics based on constituency structures of sentences. SentiBERT consists of three modules: 1) BERT; 2) a semantic composit"
2020.acl-main.341,D12-1110,0,0.346013,"ample. The two parts of the sentence are connected by “but”, which reveals the change of sentiment. Besides, the word “not” changes the sentiment of “really funny”. These types of negation and contrast are often difﬁcult to handle when the sentences are complex (Socher et al., 2013; Tay et al., 2018; Xu et al., 2019). In general, the sentiment of an expression is determined by the meaning of tokens and phrases and the way how they are syntactically combined. Prior studies consider explicitly modeling compositional sentiment semantics over constituency structure with recursive neural networks (Socher et al., 2012, 2013). However, these models that generate representation of a parent node by aggregating the local information from child nodes, overlook the rich association in context. In this paper, we propose SentiBERT to incorporate recently developed contextualized representation models (Devlin et al., 2019; Liu et al., 2019) with the recursive constituency tree structure to better capture compositional sentiment semantics. Speciﬁcally, we build a simple yet effective attention network for composing sentiment semantics on top of BERT (Devlin et al., 2019). During training, we follow BERT to capture c"
2020.acl-main.341,D13-1170,0,0.272967,"child node to the parent node due to negation and contrast. Introduction Sentiment analysis is an important language processing task (Pang et al., 2002, 2008; Liu, 2012). One of the key challenges in sentiment analysis is to model compositional sentiment semantics. Take the sentence “Frenetic but not really funny.” in Figure 1 as an example. The two parts of the sentence are connected by “but”, which reveals the change of sentiment. Besides, the word “not” changes the sentiment of “really funny”. These types of negation and contrast are often difﬁcult to handle when the sentences are complex (Socher et al., 2013; Tay et al., 2018; Xu et al., 2019). In general, the sentiment of an expression is determined by the meaning of tokens and phrases and the way how they are syntactically combined. Prior studies consider explicitly modeling compositional sentiment semantics over constituency structure with recursive neural networks (Socher et al., 2012, 2013). However, these models that generate representation of a parent node by aggregating the local information from child nodes, overlook the rich association in context. In this paper, we propose SentiBERT to incorporate recently developed contextualized repr"
2020.acl-main.341,P15-1150,0,0.130522,"Missing"
2020.acl-main.341,D18-1381,0,0.018821,"ent node due to negation and contrast. Introduction Sentiment analysis is an important language processing task (Pang et al., 2002, 2008; Liu, 2012). One of the key challenges in sentiment analysis is to model compositional sentiment semantics. Take the sentence “Frenetic but not really funny.” in Figure 1 as an example. The two parts of the sentence are connected by “but”, which reveals the change of sentiment. Besides, the word “not” changes the sentiment of “really funny”. These types of negation and contrast are often difﬁcult to handle when the sentences are complex (Socher et al., 2013; Tay et al., 2018; Xu et al., 2019). In general, the sentiment of an expression is determined by the meaning of tokens and phrases and the way how they are syntactically combined. Prior studies consider explicitly modeling compositional sentiment semantics over constituency structure with recursive neural networks (Socher et al., 2012, 2013). However, these models that generate representation of a parent node by aggregating the local information from child nodes, overlook the rich association in context. In this paper, we propose SentiBERT to incorporate recently developed contextualized representation models"
2020.acl-main.341,D19-1098,0,0.0260591,", Mitchell and Lapata (2008) introduce operations such as addition or element-wise product to model compositional semantics. The idea of modeling semantic composition is applied to various areas such as sentiment analysis (Socher et al., 2013; Zhu et al., 2016), semantic relatedness (Marelli et al., 2014) and capturing sememe knowledge (Qi et al., 2019). In this paper, we demonstrate that the syntactic structure can be combined with contextualized representation such that the semantic compositionality can be better captured. Our approach resembles to a few recent attempts (Harer et al., 2019; Wang et al., 2019) to integrate tree structures into self-attention. However, our design is speciﬁc for the semantic composition in sentiment analysis. 3 Model We introduce SentiBERT, a model that captures compositional sentiment semantics based on constituency structures of sentences. SentiBERT consists of three modules: 1) BERT; 2) a semantic composition module based on an attention network; 3) phrase and sentence sentiment predictors. The three modules are illustrated in Figure 2 and we provide an overview in below. BERT We incorporate BERT (Devlin et al., 2019) as the backbone to generate contextualized 369"
2020.acl-main.341,D14-1181,0,\N,Missing
2020.acl-main.341,baccianella-etal-2010-sentiwordnet,0,\N,Missing
2020.acl-main.341,D14-1162,0,\N,Missing
2020.acl-main.341,S14-2001,0,\N,Missing
2020.acl-main.341,N16-1106,0,\N,Missing
2020.acl-main.341,S17-2088,0,\N,Missing
2020.acl-main.341,S19-2005,0,\N,Missing
2020.acl-main.341,N19-1423,0,\N,Missing
2020.acl-main.341,2020.tacl-1.5,0,\N,Missing
2020.acl-main.449,D15-1166,0,0.0769134,"de summarizing has drawn attention from researchers. Most of the neural approaches generate source code summaries in a sequence-to-sequence fashion. One of the initial works Iyer et al. (2016) trained an embedding matrix to represent the individual code tokens and combine them with a Re1 https://github.com/wasiahmad/NeuralCodeSum current Neural Network (RNN) via an attention mechanism to generate a natural language summary. Subsequent works (Liang and Zhu, 2018; Hu et al., 2018a,b) adopted the traditional RNNbased sequence-to-sequence network (Sutskever et al., 2014) with attention mechanism (Luong et al., 2015) on different abstractions of code. The RNN-based sequence models have two limitations in learning source code representations. First, they do not model the non-sequential structure of source code as they process the code tokens sequentially. Second, source code can be very long, and thus RNN-based models may fail to capture the long-range dependencies between code tokens. In contrast to the RNN-based models, Transformer (Vaswani et al., 2017), which leverages self-attention mechanism, can capture long-range dependencies. Transformers have been shown to perform well on many natural language ge"
2020.acl-main.449,P19-1220,0,0.0134383,"antic meaning of the expressions a+b and b+a are the same. To encode the pairwise relationships between input elements, Shaw et al. (2018) extended the self-attention mechanism as follows. n X oi = αij (xj W V + aVij ), j=1 the parameters that are unique per layer and attention head. T xi W Q (xj W K + aK ij ) √ eij = , dk Copy Attention. We incorporate the copying mechanism (See et al., 2017) in the Transformer to allow both generating words from vocabulary and copying from the input source code. We use an additional attention layer to learn the copy distribution on top of the decoder stack (Nishida et al., 2019). The copy attention enables the Transformer to copy rare tokens (e.g., function names, variable names) from source code and thus improves the summarization performance significantly (§ 3.2). where, aVij and aK ij are relative positional representations for the two position i and j. Shaw et al. (2018) suggested clipping the maximum relative position to a maximum absolute value of k as they hypothesize that precise relative position information is not useful beyond a certain distance. 2.2 Position Representations Now, we discuss how to learn the order of source code tokens or model their pairwi"
2020.acl-main.449,P02-1040,0,0.111387,", aij = wclip(|j−i|,k) , clip(x, k) = min(|x|, k). 3 Experiment 3.1 Setup Datasets and Pre-processing. We conduct our experiments on a Java dataset (Hu et al., 2018b) and a Python dataset (Wan et al., 2018). The statistics of the two datasets are shown in Table 1. In addition to the pre-processing steps followed by Wei et al. (2019), we split source code tokens of the form CamelCase and snake case to respective sub-tokens3 . We show that such a split of code tokens improves the summarization performance. Metrics. We evaluate the source code summarization performance using three metrics, BLEU (Papineni et al., 2002), METEOR (Banerjee and Lavie, 2005), and ROUGE-L (Lin, 2004). Baselines. We compare our Transformer-based source code summarization approach with five baseline methods reported in Wei et al. (2019) and their proposed Dual model. We refer the readers to (Wei et al., 2019) for the details about the hyperparameter of all the baseline methods. Hyper-parameters. We follow Wei et al. (2019) to set the maximum lengths and vocabulary sizes for code and summaries in both the datasets. We train the Transformer models using Adam optimizer (Kingma and Ba, 2015) with an initial learning rate of 10−4 . We s"
2020.acl-main.449,P19-1205,0,0.0208436,"ns in learning source code representations. First, they do not model the non-sequential structure of source code as they process the code tokens sequentially. Second, source code can be very long, and thus RNN-based models may fail to capture the long-range dependencies between code tokens. In contrast to the RNN-based models, Transformer (Vaswani et al., 2017), which leverages self-attention mechanism, can capture long-range dependencies. Transformers have been shown to perform well on many natural language generation tasks such as machine translation (Wang et al., 2019), text summarization (You et al., 2019), story generation (Fan et al., 2018), etc. To learn the order of tokens in a sequence or to model the relationship between tokens, Transformer requires to be injected with positional encodings (Vaswani et al., 2017; Shaw et al., 2018; Shiv and Quirk, 2019). In this work, we show that, by modeling the pairwise relationship between source code tokens using relative position representation (Shaw et al., 2018), we can achieve significant improvements over learning sequence information of code tokens using absolute position representation (Vaswani et al., 2017). We want to emphasize that our propo"
2020.acl-main.449,P19-1176,0,0.0164506,"based sequence models have two limitations in learning source code representations. First, they do not model the non-sequential structure of source code as they process the code tokens sequentially. Second, source code can be very long, and thus RNN-based models may fail to capture the long-range dependencies between code tokens. In contrast to the RNN-based models, Transformer (Vaswani et al., 2017), which leverages self-attention mechanism, can capture long-range dependencies. Transformers have been shown to perform well on many natural language generation tasks such as machine translation (Wang et al., 2019), text summarization (You et al., 2019), story generation (Fan et al., 2018), etc. To learn the order of tokens in a sequence or to model the relationship between tokens, Transformer requires to be injected with positional encodings (Vaswani et al., 2017; Shaw et al., 2018; Shiv and Quirk, 2019). In this work, we show that, by modeling the pairwise relationship between source code tokens using relative position representation (Shaw et al., 2018), we can achieve significant improvements over learning sequence information of code tokens using absolute position representation (Vaswani et al., 201"
2020.acl-main.449,W05-0909,0,\N,Missing
2020.acl-main.449,W04-1013,0,\N,Missing
2020.acl-main.449,P16-1195,0,\N,Missing
2020.acl-main.449,P17-4012,0,\N,Missing
2020.acl-main.449,P17-1099,0,\N,Missing
2020.acl-main.449,N19-1253,1,\N,Missing
2020.acl-main.469,D19-1219,0,0.0288499,"husband” and the word “woman” both assign significant attention weight to regions corresponding to the woman. By the end of the computation, VisualBERT has disentangled the woman and man, correctly aligning both. Furthermore, there are many examples of syntactic alignments. In the same image, the word “teased” aligns to both the man and woman while “by” aligns to the man. 4 Related Work There is a long research history of bridging vision and language (Chen et al., 2015; Antol et al., 2015; Zellers et al., 2019) with the lasted advances being visually grounded language models (Lu et al., 2019; Alberti et al., 2019; Li et al., 2019; Su et al., 2019; Tan and Bansal, 2019; Chen et al., 2019). However, little analysis has been done on understanding what vision-and-language models learn. Previous works on VQA and image captioning (Yang et al., 2016; Anderson et al., 2018; Kim et al., 2018) have only shown qualitative examples on the grounding ability of the models, while another line of work focuses on designing dedicated models for the entity grounding task (Xiao et al., 2017; Datta et al., 2019). We, however, present a quantitative study on whether visually grounded language models acquire the grounding a"
2020.acl-main.469,D19-1445,0,0.0249915,", while another line of work focuses on designing dedicated models for the entity grounding task (Xiao et al., 2017; Datta et al., 2019). We, however, present a quantitative study on whether visually grounded language models acquire the grounding ability during pre-training without explicit supervision. Our work is inspired by papers on analyzing pretrained language models. One line of work uses probing tasks to study the internal representations (Peters et al., 2018a; Liu et al., 2019; Tenney et al., 2019) while another studies the attention mechanism (Clark et al., 2019; Voita et al., 2019; Kovaleva et al., 2019). We follow the latter but we believe the grounding behaviour could also be probed in the internal representations of VisualBERT. 5268 a a person hits a ball with a tennis rack ##et Layer 3 Layer 4 Layer 5 Person Layer 6 Ball Layer 10 Layer 11 Racket man works on a computer with a cat in the background Layer 3 Layer 4 Man Layer 5 Computer Layer 6 Cat Layer 10 Computer* Layer 11 Face* a flu ##flustered women in a white sweater is teased by her husband Layer 3 Layer 4 Woman Layer 5 Layer 6 Sweater Layer 10 Layer 11 Husband Figure 5: Attention weights of 6 selected heads in VisualBERT where align"
2020.acl-main.469,N19-1112,0,0.108786,"et al., 2019) have achieved new records on several vision-and-language reasoning tasks, e.g. VQA (Antol et al., 2015), NLVR2 (Suhr et al., 2019), and VCR (Zellers et al., 2019). These pre-trained visually grounded language models use Transformers (Vaswani et al., 2017) to jointly model words and image regions. They are pretrained on paired image-text data, where given parts of the input the model is trained to predict the missing pieces. Despite their strong performance, it remains unclear if these models have learned the desired cross-modal representations. Conversely, a large body of work (Liu et al., 2019; Tenney et al., 2019; Clark et al., 2019) has focused on understanding the internal behaviours of pre-trained language models (Peters et al., 2018b; Radford et al., 2018; Devlin et al., 2019) and find that they capture linguistic features such as POS, syntactic structures, and coreferences. This inspires us to ask: what do visually grounded language models learn during pre-training? Following Clark et al. (2019), we find that certain attention heads of a visually grounded language model acquire an intuitive yet fundamental ability that is often believed to be a prerequisite for advanced visua"
2020.acl-main.469,D18-1179,0,0.137509,"), and VCR (Zellers et al., 2019). These pre-trained visually grounded language models use Transformers (Vaswani et al., 2017) to jointly model words and image regions. They are pretrained on paired image-text data, where given parts of the input the model is trained to predict the missing pieces. Despite their strong performance, it remains unclear if these models have learned the desired cross-modal representations. Conversely, a large body of work (Liu et al., 2019; Tenney et al., 2019; Clark et al., 2019) has focused on understanding the internal behaviours of pre-trained language models (Peters et al., 2018b; Radford et al., 2018; Devlin et al., 2019) and find that they capture linguistic features such as POS, syntactic structures, and coreferences. This inspires us to ask: what do visually grounded language models learn during pre-training? Following Clark et al. (2019), we find that certain attention heads of a visually grounded language model acquire an intuitive yet fundamental ability that is often believed to be a prerequisite for advanced visual reasoning (Plummer et al., 2015): grounding of language to image regions. We first observe that some heads can perform entity grounding, where en"
2020.acl-main.469,N18-1202,0,0.139398,"), and VCR (Zellers et al., 2019). These pre-trained visually grounded language models use Transformers (Vaswani et al., 2017) to jointly model words and image regions. They are pretrained on paired image-text data, where given parts of the input the model is trained to predict the missing pieces. Despite their strong performance, it remains unclear if these models have learned the desired cross-modal representations. Conversely, a large body of work (Liu et al., 2019; Tenney et al., 2019; Clark et al., 2019) has focused on understanding the internal behaviours of pre-trained language models (Peters et al., 2018b; Radford et al., 2018; Devlin et al., 2019) and find that they capture linguistic features such as POS, syntactic structures, and coreferences. This inspires us to ask: what do visually grounded language models learn during pre-training? Following Clark et al. (2019), we find that certain attention heads of a visually grounded language model acquire an intuitive yet fundamental ability that is often believed to be a prerequisite for advanced visual reasoning (Plummer et al., 2015): grounding of language to image regions. We first observe that some heads can perform entity grounding, where en"
2020.acl-main.469,P19-1580,0,0.0297937,"bility of the models, while another line of work focuses on designing dedicated models for the entity grounding task (Xiao et al., 2017; Datta et al., 2019). We, however, present a quantitative study on whether visually grounded language models acquire the grounding ability during pre-training without explicit supervision. Our work is inspired by papers on analyzing pretrained language models. One line of work uses probing tasks to study the internal representations (Peters et al., 2018a; Liu et al., 2019; Tenney et al., 2019) while another studies the attention mechanism (Clark et al., 2019; Voita et al., 2019; Kovaleva et al., 2019). We follow the latter but we believe the grounding behaviour could also be probed in the internal representations of VisualBERT. 5268 a a person hits a ball with a tennis rack ##et Layer 3 Layer 4 Layer 5 Person Layer 6 Ball Layer 10 Layer 11 Racket man works on a computer with a cat in the background Layer 3 Layer 4 Man Layer 5 Computer Layer 6 Cat Layer 10 Computer* Layer 11 Face* a flu ##flustered women in a white sweater is teased by her husband Layer 3 Layer 4 Woman Layer 5 Layer 6 Sweater Layer 10 Layer 11 Husband Figure 5: Attention weights of 6 selected heads i"
2020.acl-main.75,S17-2079,0,0.0502423,"Missing"
2020.acl-main.75,N16-1079,0,0.0243694,"word may have different meanings regarding its contexts. Especially, an infrequent meaning of the word might be utilized for creating a pun. Therefore, static word embeddings are insufficient to represent words. In addition, some puns are created by replacing a word with another word with the same or similar pronunciation as examples shown in Table 1. Therefore, to recognize puns, it is essential to model the association between words in the sentence and the pronunciation of words. Despite existing approaches attempt to leverage phonological structures to understand puns (Doogan et al., 2017; Jaech et al., 2016), there is a lack of a general framework to model these two types of signals in a whole. In this paper, we propose Pronunciation-attentive Contextualized Pun Recognition (PCPR) to jointly model the contextualized word embeddings and phonological word representations for pun recognition. To capture the phonological structures of words, we break each word into a sequence of phonemes as its pronunciation so that homophones can have similar phoneme sets. For instance, the phonemes of the word pun are {P, AH, N}. In PCPR, we construct a pronunciation attentive module to identify important phonemes"
2020.acl-main.75,P19-1394,0,0.01637,"ts only on Saturday and Sunday because Monday to Friday are weak (week) days. Table 1: Examples of homographic and heterographic puns. Introduction During the last decades, social media has promoted the creation of a vast amount of humorous web contents (Nijholt et al., 2017). Automatic recognition of humor has become an important task in the area of figurative language processing, which can benefit various downstream NLP applications such as dialogue systems, sentiment analysis, and machine translation (Melby and Warner, 1995; Augello et al., 2008; Ghosh et al., 2015; Bertero and Fung, 2016; Blinov et al., 2019). However, humor is one of the most complicated behaviors in natural language semantics and sometimes it is even difficult for humans to interpret. In most cases, understanding humor requires adequate background knowledge and a rich context. Puns are a form of humorous approaches using the different meanings of identical words or words with similar pronunciations to explain texts or utterances. There are two main types of puns. Homographic puns rely on multiple interpretations of the same word. As shown in Table 1, the phrase all right means good condition or opposite to left; the word reactio"
2020.acl-main.75,P18-2087,0,0.0514278,"g word senses of pun words (Oele and Evang, 2017). However, these methods cannot tackle heterographic puns with distinct word 813 Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 813–822 c July 5 - 10, 2020. 2020 Association for Computational Linguistics spellings and knowledge bases that only contain a limited vocabulary. To resolve the issues of sparseness and heterographics, the word embedding techniques (Mikolov et al., 2013; Pennington et al., 2014) provide flexible representations to model puns (Hurtado et al., 2017; Indurthi and Oota, 2017; Cai et al., 2018). However, a word may have different meanings regarding its contexts. Especially, an infrequent meaning of the word might be utilized for creating a pun. Therefore, static word embeddings are insufficient to represent words. In addition, some puns are created by replacing a word with another word with the same or similar pronunciation as examples shown in Table 1. Therefore, to recognize puns, it is essential to model the association between words in the sentence and the pronunciation of words. Despite existing approaches attempt to leverage phonological structures to understand puns (Doogan e"
2020.acl-main.75,W17-5009,0,0.0433476,"Missing"
2020.acl-main.75,N18-2018,0,0.0361787,"Missing"
2020.acl-main.75,S17-2011,0,0.138384,"., 2018). However, a word may have different meanings regarding its contexts. Especially, an infrequent meaning of the word might be utilized for creating a pun. Therefore, static word embeddings are insufficient to represent words. In addition, some puns are created by replacing a word with another word with the same or similar pronunciation as examples shown in Table 1. Therefore, to recognize puns, it is essential to model the association between words in the sentence and the pronunciation of words. Despite existing approaches attempt to leverage phonological structures to understand puns (Doogan et al., 2017; Jaech et al., 2016), there is a lack of a general framework to model these two types of signals in a whole. In this paper, we propose Pronunciation-attentive Contextualized Pun Recognition (PCPR) to jointly model the contextualized word embeddings and phonological word representations for pun recognition. To capture the phonological structures of words, we break each word into a sequence of phonemes as its pronunciation so that homophones can have similar phoneme sets. For instance, the phonemes of the word pun are {P, AH, N}. In PCPR, we construct a pronunciation attentive module to identif"
2020.acl-main.75,S15-2080,0,0.0203562,"had its best sail (sale) ever. I lift weights only on Saturday and Sunday because Monday to Friday are weak (week) days. Table 1: Examples of homographic and heterographic puns. Introduction During the last decades, social media has promoted the creation of a vast amount of humorous web contents (Nijholt et al., 2017). Automatic recognition of humor has become an important task in the area of figurative language processing, which can benefit various downstream NLP applications such as dialogue systems, sentiment analysis, and machine translation (Melby and Warner, 1995; Augello et al., 2008; Ghosh et al., 2015; Bertero and Fung, 2016; Blinov et al., 2019). However, humor is one of the most complicated behaviors in natural language semantics and sometimes it is even difficult for humans to interpret. In most cases, understanding humor requires adequate background knowledge and a rich context. Puns are a form of humorous approaches using the different meanings of identical words or words with similar pronunciations to explain texts or utterances. There are two main types of puns. Homographic puns rely on multiple interpretations of the same word. As shown in Table 1, the phrase all right means good c"
2020.acl-main.75,N19-1172,0,0.0196297,"short sentences as word embeddings do not have much context information. Besides, Zou and Lu (2019) jointly detect and locate the pun from a sequence labeling perspective by employing a new tagging schema. Diao et al. (2018) expand word embeddings using WordNet to settle the polysemy of homographic puns, following by a neural attention mechanism to extract the collocation to detect the homographic pun. However, all these methods only make use of limited context information. Other than the pun recognition, Yu et al. (2018) generate homographic puns without requiring any pun data for training. He et al. (2019) improve the homographic pun generation based on the “local-global surprisal principle” which posits that the pun word and the alternative word have a strong association with the distant and immediate context respectively. Pronunciation Embeddings Word embeddings assign each word with a vector so that words with similar semantic meanings are close in the embedding space. Most word embedding models only make use of text information and omitting the rich information contained in the pronunciation. How814 ever, the pronunciation is also an important part of the language (Zhu et al., 2018). Prior"
2020.acl-main.75,H05-1067,0,0.108396,"chtomova, 2017). While most of them extract complicated linguistic features to train rule based and machine learning based classifiers. In addition to task participants, Sense (Cai et al., 2018) incorporates word sense representations into RNNs to tackle the homographic pun location task. The CRF (Zou and Lu, 2019) captures linguistic features such as POS tags, n-grams, and word suffix to model puns. Moreover, the Joint (Zou and Lu, 2019) jointly models two tasks with RNNs and a CRF tagger. For the PTD dataset, four baseline methods with reported performance are selected for comparisons. MCL (Mihalcea and Strapparava, 2005) exploits word representations with multiple stylistic features while HAE (Yang et al., 2015) applies a random forest model with Word2Vec and humancentric features. PAL (Chen and Lee, 2017) trains a convolutional neural network (CNN) to learn essential feature automatically. Based on existing CNN models, HUR (Chen and Soo, 2018) improves the performance by adjusting the filter size and adding a highway layer. 4.2 Experimental Results Pun Detection. Table 3 presents the pun detection performance of methods for both homographic and heterographic puns on the SemEval dataset while Table 4 shows th"
2020.acl-main.75,S17-2072,0,0.0244467,"ngs. To tune the hyperparameters, we search the phoneme embedding size dP and the attention size dA from {8, 16, 32, 64, 128, 256, 512} as shown in Figure 2. For the SemEval dataset, the best setting is (dP = 64, dA = 256) for the homographic puns while heterographic puns favor (dP = 64, dA = 32). For the PTD dataset, (dP = 64, dA = 32) can reach the best performance. Baseline Methods. We compare PCPR with several baseline methods. For the SemEval dataset, nine baseline methods are compared in the experiments, including Duluth (Pedersen, 2017), JU CES NLP (Pramanick and Das, 2017), PunFields (Mikhalkova and Karyakin, 2017), UWAV (Vadehra, 2017), Fermi (Indurthi and Oota, 2017), and 3 https://dumps.wikimedia.org/enwiki/ latest/ UWaterloo (Vechtomova, 2017). While most of them extract complicated linguistic features to train rule based and machine learning based classifiers. In addition to task participants, Sense (Cai et al., 2018) incorporates word sense representations into RNNs to tackle the homographic pun location task. The CRF (Zou and Lu, 2019) captures linguistic features such as POS tags, n-grams, and word suffix to model puns. Moreover, the Joint (Zou and Lu, 2019) jointly models two tasks with RNNs an"
2020.acl-main.75,L18-1008,0,0.0204808,"each word are derived by the CMU Pronouncing Dictionary2 . We initialize the phoneme embeddings by using the fastText 817 1 http://alt.qcri.org/semeval2017/ task7/ 2 http://svn.code.sf.net/p/cmusphinx/ code/trunk/cmudict/ F1 score 0.90 homographic heterographic 0.88 4 8 16 32 64 128 Phoneme embedding size (dP) (a) Phoneme emb. size dP F1 score 0.92 0.92 0.90 homographic heterographic 0.88 0.86 16 32 64 128 256 512 Attention size (dA) (b) Attention size dA Figure 2: Pun location performance over different phoneme embedding sizes dP and attention sizes dA on the SemEval dataset. word embedding (Mikolov et al., 2018) trained on Wikipedia articles3 crawled in December, 2017. The PCPR is implemented in PyTorch while the fused Adam optimizer (Kingma and Ba, 2014) optimizes the parameters with an initial learning rate of 5 × 10−5 . The dropout and batch size are set as 10−1 and 32. We follow BERT (BASE) (Devlin et al., 2018) to use 12 Transformer layers and self-attention heads. To clarify, in PCPR, tokens and phonemes are independently processed, so the tokens processed with WordPiece tokenizer (Wu et al., 2016) in BERT are not required to line up with phonemes for computations. To deal with the out-of-vocab"
2020.acl-main.75,P02-1019,0,0.216766,"ve word have a strong association with the distant and immediate context respectively. Pronunciation Embeddings Word embeddings assign each word with a vector so that words with similar semantic meanings are close in the embedding space. Most word embedding models only make use of text information and omitting the rich information contained in the pronunciation. How814 ever, the pronunciation is also an important part of the language (Zhu et al., 2018). Prior studies have demonstrated that the phonetic information can be used in speech recognition (Bengio and Heigold, 2014), spell correction (Toutanova and Moore, 2002) and speech synthesis (Miller, 1998a). By projecting to the embedding space, words sound alike are nearby to each other (Bengio and Heigold, 2014). Furthermore, Kamper et al. (2016) make use of word pairs information to improve the acoustic word embedding. Zhu et al. (2018) show that combining the pronunciation with the writing texts can help to improve the performance of word embeddings. However, these pronunciation embeddings are word-level features, while in our approach, we make use of syllabic pronunciations which is phoneme-level and could help with the out-of-vocabulary (OOV) situation."
2020.acl-main.75,S17-2077,0,0.0214071,"earch the phoneme embedding size dP and the attention size dA from {8, 16, 32, 64, 128, 256, 512} as shown in Figure 2. For the SemEval dataset, the best setting is (dP = 64, dA = 256) for the homographic puns while heterographic puns favor (dP = 64, dA = 32). For the PTD dataset, (dP = 64, dA = 32) can reach the best performance. Baseline Methods. We compare PCPR with several baseline methods. For the SemEval dataset, nine baseline methods are compared in the experiments, including Duluth (Pedersen, 2017), JU CES NLP (Pramanick and Das, 2017), PunFields (Mikhalkova and Karyakin, 2017), UWAV (Vadehra, 2017), Fermi (Indurthi and Oota, 2017), and 3 https://dumps.wikimedia.org/enwiki/ latest/ UWaterloo (Vechtomova, 2017). While most of them extract complicated linguistic features to train rule based and machine learning based classifiers. In addition to task participants, Sense (Cai et al., 2018) incorporates word sense representations into RNNs to tackle the homographic pun location task. The CRF (Zou and Lu, 2019) captures linguistic features such as POS tags, n-grams, and word suffix to model puns. Moreover, the Joint (Zou and Lu, 2019) jointly models two tasks with RNNs and a CRF tagger. For th"
2020.acl-main.75,S17-2005,0,0.0142755,"model contextualized word embeddings and pronunciation embeddings to recognize puns. Both contexts and phonological properties are beneficial to pun recognition. • Extensive experiments are conducted on two benchmark datasets. PCPR significantly outperforms existing methods in both pun detection and pun location. In-depth analyses also verify the effectiveness and robustness of PCPR. • We release our implementations and pre-trained phoneme embeddings at https://github.com/ joey1993/pun-recognition to facilitate future research. 2 Related Work Pun Recognition and Generation To recognize puns, Miller et al. (2017) summarize several systems for the SemEval 2017 tasks. To detect the pun, Pedersen (2017) supposes that if there is one pun in the sentence, when adopting different Word Sense Disambiguation (WSD) methods, the sense assigned to the sentence will be different. To locate the pun, based on the WSD results for pun detection, they choose the last word which changes the senses between different WSD runs. Even though this method can tackle both homographic and heterographic pun detection, it does not use any pretrained embedding model. Xiu et al. (2017) detect the pun in the sentence using similarity"
2020.acl-main.75,S17-2076,0,0.0255175,"weak and week in Table 1 have the same or similar pronunciations. The sentences are funny because both words fit the same context. Understanding puns is a big fish to fry for deep comprehension of complex semantics. These two forms of puns have been studied in literature from different angles. To recognize puns in a sentence, word sense disambiguation techniques (WSD) (Navigli, 2009) have been employed to identify the equitable intention of words in utterances (Pedersen, 2017). External knowledge bases such as WordNet (Miller, 1998b) have been applied in determining word senses of pun words (Oele and Evang, 2017). However, these methods cannot tackle heterographic puns with distinct word 813 Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 813–822 c July 5 - 10, 2020. 2020 Association for Computational Linguistics spellings and knowledge bases that only contain a limited vocabulary. To resolve the issues of sparseness and heterographics, the word embedding techniques (Mikolov et al., 2013; Pennington et al., 2014) provide flexible representations to model puns (Hurtado et al., 2017; Indurthi and Oota, 2017; Cai et al., 2018). However, a word may have diffe"
2020.acl-main.75,S17-2070,0,0.175978,"the other hand, heterographic puns take advantage of phonologically same or similar words. For example, the word pairs sale and sail, weak and week in Table 1 have the same or similar pronunciations. The sentences are funny because both words fit the same context. Understanding puns is a big fish to fry for deep comprehension of complex semantics. These two forms of puns have been studied in literature from different angles. To recognize puns in a sentence, word sense disambiguation techniques (WSD) (Navigli, 2009) have been employed to identify the equitable intention of words in utterances (Pedersen, 2017). External knowledge bases such as WordNet (Miller, 1998b) have been applied in determining word senses of pun words (Oele and Evang, 2017). However, these methods cannot tackle heterographic puns with distinct word 813 Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 813–822 c July 5 - 10, 2020. 2020 Association for Computational Linguistics spellings and knowledge bases that only contain a limited vocabulary. To resolve the issues of sparseness and heterographics, the word embedding techniques (Mikolov et al., 2013; Pennington et al., 2014) provi"
2020.acl-main.75,D14-1162,0,0.087366,"in utterances (Pedersen, 2017). External knowledge bases such as WordNet (Miller, 1998b) have been applied in determining word senses of pun words (Oele and Evang, 2017). However, these methods cannot tackle heterographic puns with distinct word 813 Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 813–822 c July 5 - 10, 2020. 2020 Association for Computational Linguistics spellings and knowledge bases that only contain a limited vocabulary. To resolve the issues of sparseness and heterographics, the word embedding techniques (Mikolov et al., 2013; Pennington et al., 2014) provide flexible representations to model puns (Hurtado et al., 2017; Indurthi and Oota, 2017; Cai et al., 2018). However, a word may have different meanings regarding its contexts. Especially, an infrequent meaning of the word might be utilized for creating a pun. Therefore, static word embeddings are insufficient to represent words. In addition, some puns are created by replacing a word with another word with the same or similar pronunciation as examples shown in Table 1. Therefore, to recognize puns, it is essential to model the association between words in the sentence and the pronunciati"
2020.acl-main.75,N18-1202,0,0.0150098,"the problem and then introduce the proposed method, PCPR. 3.1 Problem Statement Suppose the input text consists of a sequence of N words {w1 , w2 , · · · , wN }. For each word wi with Mi phonemes in its pronunciation, the phonemes are denoted as R(wi ) = {ri,1 , ri,2 , · · · , ri,Mi }, Framework Overview Contextualized Word Embeddings The context is essential for interpreting a word in the text. Hence, we propose to apply contextualized word embeddings to derive word representations. In the framework of PCPR, any contextualized word embedding method, such as BERT (Devlin et al., 2018), ELMo (Peters et al., 2018), and XLNet (Yang et al., 2019), can be utilized. Here, we choose BERT to derive contextualized word embeddings without loss of generality. 815 yˆ1L yˆD Pun Detection Prediction yˆ2L L yˆN Pun Location Predictions Self-attentive Encoder J T[CLS] Contextualized Word Embeddings C T[CLS] T1J T1C T2C ··· E[CLS] Input Words E1 w1 E2 w2 TNJ ··· Joint Embeddings T1P T2P TNP u1,1 · · · u1,M1 u2,1 · · · u2,M2 uN,1 · · · uN,M r1,1 r2,1 Pronunciation Embeddings TNC Contextualized Word Encoder Input Embeddings T2J ··· EN ··· wN Phonological Attention · · · r1,M1 · · · r2,M2 ··· rN,1 · · · rN,M N Phoneme E"
2020.acl-main.75,P17-1161,0,0.0239255,"c pronunciations which is phoneme-level and could help with the out-of-vocabulary (OOV) situation. Luo et al. (2019) also propose an adversarial generative network for pun generation, which does not require any pun corpus. Contextualized Word Embeddings Traditional word embeddings assign a fixed vector to one word even if the word has multiple meanings under different contexts (e.g., “the river bank” v.s. “the commercial bank”). McCann et al. (2017) combine the pivot word embeddings as well as the contextual embeddings generated by an encoder from a supervised neural machine translation task. Peters et al. (2017) enrich the word embeddings by the contextual information extracted from a bidirectional language model. (Devlin et al., 2018) learn the language embedding by stacking multiple transformer layers with masked language model objective which advances the state-of-the-art for many NLP tasks. Yang et al. (2019) enable learning bidirectional contexts by maximizing the expected likelihood over all permutations of the factorization order and solve the problem of pretrain-finetune discrepancy. where ri,j is the j-th phoneme in the pronunciation of wi . These phonemes are given by a dictionary. In this"
2020.acl-main.75,S17-2073,0,0.0244674,"ffectiveness of pronunciation embeddings. To tune the hyperparameters, we search the phoneme embedding size dP and the attention size dA from {8, 16, 32, 64, 128, 256, 512} as shown in Figure 2. For the SemEval dataset, the best setting is (dP = 64, dA = 256) for the homographic puns while heterographic puns favor (dP = 64, dA = 32). For the PTD dataset, (dP = 64, dA = 32) can reach the best performance. Baseline Methods. We compare PCPR with several baseline methods. For the SemEval dataset, nine baseline methods are compared in the experiments, including Duluth (Pedersen, 2017), JU CES NLP (Pramanick and Das, 2017), PunFields (Mikhalkova and Karyakin, 2017), UWAV (Vadehra, 2017), Fermi (Indurthi and Oota, 2017), and 3 https://dumps.wikimedia.org/enwiki/ latest/ UWaterloo (Vechtomova, 2017). While most of them extract complicated linguistic features to train rule based and machine learning based classifiers. In addition to task participants, Sense (Cai et al., 2018) incorporates word sense representations into RNNs to tackle the homographic pun location task. The CRF (Zou and Lu, 2019) captures linguistic features such as POS tags, n-grams, and word suffix to model puns. Moreover, the Joint (Zou and Lu,"
2020.acl-main.75,S17-2071,0,0.0583232,"Missing"
2020.acl-main.75,S17-2078,0,0.0250511,"ecognition and Generation To recognize puns, Miller et al. (2017) summarize several systems for the SemEval 2017 tasks. To detect the pun, Pedersen (2017) supposes that if there is one pun in the sentence, when adopting different Word Sense Disambiguation (WSD) methods, the sense assigned to the sentence will be different. To locate the pun, based on the WSD results for pun detection, they choose the last word which changes the senses between different WSD runs. Even though this method can tackle both homographic and heterographic pun detection, it does not use any pretrained embedding model. Xiu et al. (2017) detect the pun in the sentence using similarity features which are calculated on sense vectors or cluster center vectors. To locate the pun, they use an unsupervised system by scoring each word in the sentence and choosing the word with the smallest score. However, this model exclusively relies on semantics to detect the heterographic puns but ignores the rich information embedded in the pronunciations. Doogan et al. (2017) leverage word embeddings as well as the phonetic information by concatenating pronunciation strings, but the concatenation has limited expression ability. They also mentio"
2020.acl-main.75,D15-1284,0,0.179607,"c and heterographic puns. Pun detection employs all of the examples in the two datasets while pun location only exploits the examples with puns in SemEval due to the limitation of annotations.  C  J J . T[CLS] = T[CLS] ; T[ATT] Moreover, each word wi is benefited from the selfattentive encoder and is represented by a joint embedding: J Ti,[ATT] = αiS · TiJ . SemEval Homo Hetero 1,607 1,271 643 509 2,250 1,780 4.1 Experiment settings Experimental Datasets. We conducted experiments on the SemEval 2017 shared task 7 dataset1 (SemEval) (Miller et al., 2017) and the Pun of The Day dataset (PTD) (Yang et al., 2015). For pun detection, the SemEval dataset consists of 4, 030 and 2, 878 examples for pun detection and location while each example with a pun can be a homographic or heterographic pun. In contrast, the PTD dataset contains 4, 826 examples without labels of pun types. Table 2 further shows the data statistics. The two experimental datasets are the largest publicly available benchmarks that are used in the existing studies. SemEval-2017 dataset contains punning and non-punning jokes, aphorisms, and other short texts composed by professional humorists and online collections. Hence, we assume the g"
2020.acl-main.75,P18-1153,0,0.0179353,"tenation has limited expression ability. They also mention that their systems suffer for short sentences as word embeddings do not have much context information. Besides, Zou and Lu (2019) jointly detect and locate the pun from a sequence labeling perspective by employing a new tagging schema. Diao et al. (2018) expand word embeddings using WordNet to settle the polysemy of homographic puns, following by a neural attention mechanism to extract the collocation to detect the homographic pun. However, all these methods only make use of limited context information. Other than the pun recognition, Yu et al. (2018) generate homographic puns without requiring any pun data for training. He et al. (2019) improve the homographic pun generation based on the “local-global surprisal principle” which posits that the pun word and the alternative word have a strong association with the distant and immediate context respectively. Pronunciation Embeddings Word embeddings assign each word with a vector so that words with similar semantic meanings are close in the embedding space. Most word embedding models only make use of text information and omitting the rich information contained in the pronunciation. How814 ever"
2020.acl-main.75,N19-1217,0,0.0457919,"vectors. To locate the pun, they use an unsupervised system by scoring each word in the sentence and choosing the word with the smallest score. However, this model exclusively relies on semantics to detect the heterographic puns but ignores the rich information embedded in the pronunciations. Doogan et al. (2017) leverage word embeddings as well as the phonetic information by concatenating pronunciation strings, but the concatenation has limited expression ability. They also mention that their systems suffer for short sentences as word embeddings do not have much context information. Besides, Zou and Lu (2019) jointly detect and locate the pun from a sequence labeling perspective by employing a new tagging schema. Diao et al. (2018) expand word embeddings using WordNet to settle the polysemy of homographic puns, following by a neural attention mechanism to extract the collocation to detect the homographic pun. However, all these methods only make use of limited context information. Other than the pun recognition, Yu et al. (2018) generate homographic puns without requiring any pun data for training. He et al. (2019) improve the homographic pun generation based on the “local-global surprisal princip"
2020.acl-main.75,S17-2075,0,\N,Missing
2020.acl-main.75,D18-1272,0,\N,Missing
2020.acl-main.75,D19-1336,0,\N,Missing
2020.emnlp-main.155,P19-1164,0,0.0421192,"al., 2019). The choice of bias metric depends on applications. In this work, we use performance gap as the bias evaluation metric. However, our approach can be generalized to other metrics. Bias in NLP Applications Recent advances in machine learning models boost the performance of various NLP applications. However, recent studies show that biases exhibit in NLP models. For example, researchers demonstrate that representations in NLP models are biased toward certain societal groups (Bolukbasi et al., 2016; Caliskan et al., 2017; Zhao et al., 2018b, 2019; Zhou et al., 2019; May et al., 2019). Stanovsky et al. (2019) and Font and Costa-juss`a (2019) show that gender bias exhibits in neural machine translations while Dixon et al. (2018) and Sap et al. (2019) reveal biases in text classification tasks. Other applications such as cross-lingual transfer learning (Zhao et al., 2020) and natural language generation (Sheng et al., 2019) also exhibit unintended biases. 3 Methodology In this section, we first provide formal definitions of local group bias and then the details of the detection method LOGAN. Performance Disparity Assume we have a trained model f and a test corpus D = {(xi , yi )}i=1...n that is used"
2020.emnlp-main.155,D18-1521,1,0.911233,"s which is evaluated on the entire corpus. To detect local group bias, we propose LOGAN, a LOcal Group biAs detectioN algorithm to identify biases in local regions. LOGAN adapts a clustering algorithm (e.g., K-Means) to group instances based on their features while maximizing a bias metric (e.g., performance gap across groups) within each cluster. In this way, local group bias is highlighted, allowing a developer to further examine the issue. Our experiments on toxicity classification and MS-COCO object classification demonstrate the effectiveness of LOGAN. We show that besides 1 For example, Zhao et al. (2018a) and Rudinger et al. (2018) evaluate the bias in coreference resolution systems by measuring the difference in F1 score between cases where a gender pronoun refers to an occupation stereotypical to the gender and the opposite situation. 2 Performance in accuracy on the unintended bias detection task (Conversation AI team, 2019) 1968 Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, pages 1968–1977, c November 16–20, 2020. 2020 Association for Computational Linguistics successfully detecting local group bias, our method also provides interpretations for t"
2020.emnlp-main.155,D19-1531,1,0.92243,"etect such local bias, we propose LOGAN, a new bias detection technique based on clustering. Experiments on toxicity classification and object classification tasks show that LOGAN identifies bias in a local region and allows us to better analyze the biases in model predictions. 1 Introduction Machine learning models such as deep neural networks have achieved remarkable performance in many NLP tasks. However, as noticed by recent studies, these models often inherit and amplify the biases in the datasets used to train the models (Zhao et al., 2017; Bolukbasi et al., 2016; Caliskan et al., 2017; Zhou et al., 2019; Manzini et al., 2019; Blodgett et al., 2020). To quantify bias, researchers have proposed various metrics to study algorithmic fairness at both individual and group levels. The former measures if a model treats similar individuals consistently no matter which groups they belong to, while the latter requires the model to perform similarly for protected groups and advantaged groups in the corpus.1 In this paper, we argue that studying algorithmic fairness at either level does not tell the full story. A model that reports similar performance across two groups in a corpus may behave differently"
2020.findings-emnlp.265,W17-0401,0,0.0145704,"es is the word orders in source and target languages might be different (e.g., some languages are prepositional and some are postpositional). Various studies have been dedicated to addressing this issue (Naseem et al., 2012; Zhang and Barzilay, 2015; Wang and Eisner, 2017). In particular, some studies proposed to bypass word order issue by selecting source languages that have similar word orders to the target language ˇ (Naseem et al., 2012; Rosa and Zabokrtsk` y, 2015). Good source languages can be selected by measuring the similarity of POS sequences between the source and target languages (Agic, 2017), querying the information stored in topological databases (Deri and Knight, 2016), and formalizing such selection as a ranking problem (Lin et al., 2019). Treebank translation (Tiedemann et al., 2014; Tiedemann and Agi´c, 2016) tackles this problem by transforming an annotated source treebank to instances with target language grammar through machine translation. However, this method may suffer from imperfect word alignment between two languages. Zhang et al. (2019) proposed to perform such syntactic transfer by code mixing in which only the confident words in a source treebank will be transfo"
2020.findings-emnlp.265,N19-1253,1,0.882618,"Missing"
2020.findings-emnlp.265,Q17-1010,0,0.0139043,", and RNN-Stack. These models are built upon two encoders (SelfAtt/RNN) as well as two decoders (Graph/Stack). RNN encoder uses bidirectional LSTMs while SelfAtt encoder uses a transformer (Vaswani et al., 2017) instead. Graph decoder utilizes a deep biaffine attentional scorer proposed by Dozat and Manning (2017), and Stack decoder is a top-down transition-based decoder proposed by Ma et al. (2018). Lexicalized Features Following (Ahmad et al., 2019), all the parsing models take words as well as their gold POS tags as input. We also leverage pre-trained multilingual embeddings from FastText (Bojanowski et al., 2017) that project the word embeddings from different languages into the same space using an offline transformation method (Smith et al., 2017; Conneau et al., 2018). Training Details For fair comparison, we use the same hyper-parameter settings and the training strategy as Ahmad et al. (2019) to train the parsing models. Each POS-based language model for word reordering is trained on the training set of a corresponding target language, in which the POS tag dimension is set to 50 (as the same as that in the parsing models), the hidden size h ∈ {50, 100} and the number of layers l ∈ {1, 2, 3} are tu"
2020.findings-emnlp.265,W06-2920,0,0.0446153,"Missing"
2020.findings-emnlp.265,D11-1005,0,0.0460979,"Missing"
2020.findings-emnlp.265,D12-1001,0,0.0245424,"a. T¨ackstr¨om et al. (2013) trained a parser on multiple source languages instead of a single one. Ponti et al. (2018) proposed a typologically driven method to reduce anisomorphism. Ahmad et al. (2019) designed an order-free model to extract the order features from the source language. Meng et al. (2019) embraced the linguistic knowledge of target languages to guide the inference. Some researchers also exploit lexical features to enhance the parsing models. Cross-lingual word clusters (T¨ackstr¨om et al., 2012), word embeddings (Guo et al., 2015, 2016; Ammar et al., 2016), and dictionaries (Durrett et al., 2012; Rasooli and Collins, 2017) are used as the features to better transfer linguistic knowledge among different languages. Our work is in line with a recently proposed solution, namely treebank reordering (Wang and Eisner, 2016, 2018; Rasooli and Collins, 2019), which aims to rearrange the word order in source sentences to make them more similar to the target one. Wang and Eisner (2018) proposed to permute the constituents of an existing dependency treebank to make its surface POS statistics approximately match those of the target language. However, they used POS bigrams to measure the surface c"
2020.findings-emnlp.265,P09-1042,0,0.0417624,"ection as a ranking problem (Lin et al., 2019). Treebank translation (Tiedemann et al., 2014; Tiedemann and Agi´c, 2016) tackles this problem by transforming an annotated source treebank to instances with target language grammar through machine translation. However, this method may suffer from imperfect word alignment between two languages. Zhang et al. (2019) proposed to perform such syntactic transfer by code mixing in which only the confident words in a source treebank will be transformed. Another interesting solution to cross-lingual transfer is an annotation projection (Hwa et al., 2005; Ganchev et al., 2009; Ma and Xia, 2014). In this approach, source-side sentences of a parallel corpus are parsed by the parser trained on the source treebank, then the source dependencies are projected onto the target sentences using the results of word alignments. However, the resulting treebank could be highly noisy because the source dependency trees are constructed automatically and cannot be taken as ground truth. Lacroix et al. (2016) considered removing not well-aligned sentences to obtain high-quality data. T¨ackstr¨om et al. (2013) trained a parser on multiple source languages instead of a single one. Po"
2020.findings-emnlp.265,P15-1119,0,0.0139134,"removing not well-aligned sentences to obtain high-quality data. T¨ackstr¨om et al. (2013) trained a parser on multiple source languages instead of a single one. Ponti et al. (2018) proposed a typologically driven method to reduce anisomorphism. Ahmad et al. (2019) designed an order-free model to extract the order features from the source language. Meng et al. (2019) embraced the linguistic knowledge of target languages to guide the inference. Some researchers also exploit lexical features to enhance the parsing models. Cross-lingual word clusters (T¨ackstr¨om et al., 2012), word embeddings (Guo et al., 2015, 2016; Ammar et al., 2016), and dictionaries (Durrett et al., 2012; Rasooli and Collins, 2017) are used as the features to better transfer linguistic knowledge among different languages. Our work is in line with a recently proposed solution, namely treebank reordering (Wang and Eisner, 2016, 2018; Rasooli and Collins, 2019), which aims to rearrange the word order in source sentences to make them more similar to the target one. Wang and Eisner (2018) proposed to permute the constituents of an existing dependency treebank to make its surface POS statistics approximately match those of the targe"
2020.findings-emnlp.265,K17-1024,0,0.0467333,"Missing"
2020.findings-emnlp.265,D17-1302,0,0.0257262,"008; Kiperwasser and Goldberg, 2016). However, the performance of dependency parsers heavily relies on the size of corpus. Due to the great cost and difficulty of acquiring sufficient training data, ML-based methods cannot be trivially applied to low-resource languages. Cross-lingual transfer is a promising approach to tackle the lack of sufficient data. The idea is to train a cross-lingual model that transfers knowledge learned in one or multiple high-resource source languages to target ones. This approach has been successfully applied in various tasks, including partof-speech (POS) tagging (Kim et al., 2017), dependency parsing (McDonald et al., 2011), named entity recognition (Xie et al., 2018), entity linking (Sil et al., 2018), question answering (Joty et al., 2017), and coreference resolution (Kundu et al., 2018). A key challenge for cross-lingual parsing is the difficulty to handle word order difference between source and target languages, which often causes a significant drop in performance (Rasooli and Collins, 2017; Ahmad et al., 2019). Inspired by the idea that POS sequences often reflect the syntactic structure of a language, we propose CURSOR (Cross lingUal paRSing by wOrd Reordering)"
2020.findings-emnlp.265,P16-1038,0,0.0142968,"(e.g., some languages are prepositional and some are postpositional). Various studies have been dedicated to addressing this issue (Naseem et al., 2012; Zhang and Barzilay, 2015; Wang and Eisner, 2017). In particular, some studies proposed to bypass word order issue by selecting source languages that have similar word orders to the target language ˇ (Naseem et al., 2012; Rosa and Zabokrtsk` y, 2015). Good source languages can be selected by measuring the similarity of POS sequences between the source and target languages (Agic, 2017), querying the information stored in topological databases (Deri and Knight, 2016), and formalizing such selection as a ranking problem (Lin et al., 2019). Treebank translation (Tiedemann et al., 2014; Tiedemann and Agi´c, 2016) tackles this problem by transforming an annotated source treebank to instances with target language grammar through machine translation. However, this method may suffer from imperfect word alignment between two languages. Zhang et al. (2019) proposed to perform such syntactic transfer by code mixing in which only the confident words in a source treebank will be transformed. Another interesting solution to cross-lingual transfer is an annotation proj"
2020.findings-emnlp.265,Q16-1023,0,0.0382115,"Missing"
2020.findings-emnlp.265,P18-2063,0,0.0241037,"hods cannot be trivially applied to low-resource languages. Cross-lingual transfer is a promising approach to tackle the lack of sufficient data. The idea is to train a cross-lingual model that transfers knowledge learned in one or multiple high-resource source languages to target ones. This approach has been successfully applied in various tasks, including partof-speech (POS) tagging (Kim et al., 2017), dependency parsing (McDonald et al., 2011), named entity recognition (Xie et al., 2018), entity linking (Sil et al., 2018), question answering (Joty et al., 2017), and coreference resolution (Kundu et al., 2018). A key challenge for cross-lingual parsing is the difficulty to handle word order difference between source and target languages, which often causes a significant drop in performance (Rasooli and Collins, 2017; Ahmad et al., 2019). Inspired by the idea that POS sequences often reflect the syntactic structure of a language, we propose CURSOR (Cross lingUal paRSing by wOrd Reordering) to overcome the word order difference issue in crosslingual transfer. Specifically, we assume we have a treebank in the source language and annotated POS corpus in the target language1 . We first train a POS-based"
2020.findings-emnlp.265,N16-1121,0,0.0152,"n which only the confident words in a source treebank will be transformed. Another interesting solution to cross-lingual transfer is an annotation projection (Hwa et al., 2005; Ganchev et al., 2009; Ma and Xia, 2014). In this approach, source-side sentences of a parallel corpus are parsed by the parser trained on the source treebank, then the source dependencies are projected onto the target sentences using the results of word alignments. However, the resulting treebank could be highly noisy because the source dependency trees are constructed automatically and cannot be taken as ground truth. Lacroix et al. (2016) considered removing not well-aligned sentences to obtain high-quality data. T¨ackstr¨om et al. (2013) trained a parser on multiple source languages instead of a single one. Ponti et al. (2018) proposed a typologically driven method to reduce anisomorphism. Ahmad et al. (2019) designed an order-free model to extract the order features from the source language. Meng et al. (2019) embraced the linguistic knowledge of target languages to guide the inference. Some researchers also exploit lexical features to enhance the parsing models. Cross-lingual word clusters (T¨ackstr¨om et al., 2012), word e"
2020.findings-emnlp.265,P19-1301,0,0.014848,"s studies have been dedicated to addressing this issue (Naseem et al., 2012; Zhang and Barzilay, 2015; Wang and Eisner, 2017). In particular, some studies proposed to bypass word order issue by selecting source languages that have similar word orders to the target language ˇ (Naseem et al., 2012; Rosa and Zabokrtsk` y, 2015). Good source languages can be selected by measuring the similarity of POS sequences between the source and target languages (Agic, 2017), querying the information stored in topological databases (Deri and Knight, 2016), and formalizing such selection as a ranking problem (Lin et al., 2019). Treebank translation (Tiedemann et al., 2014; Tiedemann and Agi´c, 2016) tackles this problem by transforming an annotated source treebank to instances with target language grammar through machine translation. However, this method may suffer from imperfect word alignment between two languages. Zhang et al. (2019) proposed to perform such syntactic transfer by code mixing in which only the confident words in a source treebank will be transformed. Another interesting solution to cross-lingual transfer is an annotation projection (Hwa et al., 2005; Ganchev et al., 2009; Ma and Xia, 2014). In th"
2020.findings-emnlp.265,P18-1130,0,0.0145791,"arameters and remaining 25 languages are held out for final evaluation. Parsing Models We evaluate CURSOR with four different parsing models described by Ahmad et al. (2019): SelfAtt-Graph, RNN-Graph, SelfAtt-Stack, and RNN-Stack. These models are built upon two encoders (SelfAtt/RNN) as well as two decoders (Graph/Stack). RNN encoder uses bidirectional LSTMs while SelfAtt encoder uses a transformer (Vaswani et al., 2017) instead. Graph decoder utilizes a deep biaffine attentional scorer proposed by Dozat and Manning (2017), and Stack decoder is a top-down transition-based decoder proposed by Ma et al. (2018). Lexicalized Features Following (Ahmad et al., 2019), all the parsing models take words as well as their gold POS tags as input. We also leverage pre-trained multilingual embeddings from FastText (Bojanowski et al., 2017) that project the word embeddings from different languages into the same space using an offline transformation method (Smith et al., 2017; Conneau et al., 2018). Training Details For fair comparison, we use the same hyper-parameter settings and the training strategy as Ahmad et al. (2019) to train the parsing models. Each POS-based language model for word reordering is traine"
2020.findings-emnlp.265,P14-1126,0,0.018518,"oblem (Lin et al., 2019). Treebank translation (Tiedemann et al., 2014; Tiedemann and Agi´c, 2016) tackles this problem by transforming an annotated source treebank to instances with target language grammar through machine translation. However, this method may suffer from imperfect word alignment between two languages. Zhang et al. (2019) proposed to perform such syntactic transfer by code mixing in which only the confident words in a source treebank will be transformed. Another interesting solution to cross-lingual transfer is an annotation projection (Hwa et al., 2005; Ganchev et al., 2009; Ma and Xia, 2014). In this approach, source-side sentences of a parallel corpus are parsed by the parser trained on the source treebank, then the source dependencies are projected onto the target sentences using the results of word alignments. However, the resulting treebank could be highly noisy because the source dependency trees are constructed automatically and cannot be taken as ground truth. Lacroix et al. (2016) considered removing not well-aligned sentences to obtain high-quality data. T¨ackstr¨om et al. (2013) trained a parser on multiple source languages instead of a single one. Ponti et al. (2018) p"
2020.findings-emnlp.265,D11-1006,0,0.0391273,"owever, the performance of dependency parsers heavily relies on the size of corpus. Due to the great cost and difficulty of acquiring sufficient training data, ML-based methods cannot be trivially applied to low-resource languages. Cross-lingual transfer is a promising approach to tackle the lack of sufficient data. The idea is to train a cross-lingual model that transfers knowledge learned in one or multiple high-resource source languages to target ones. This approach has been successfully applied in various tasks, including partof-speech (POS) tagging (Kim et al., 2017), dependency parsing (McDonald et al., 2011), named entity recognition (Xie et al., 2018), entity linking (Sil et al., 2018), question answering (Joty et al., 2017), and coreference resolution (Kundu et al., 2018). A key challenge for cross-lingual parsing is the difficulty to handle word order difference between source and target languages, which often causes a significant drop in performance (Rasooli and Collins, 2017; Ahmad et al., 2019). Inspired by the idea that POS sequences often reflect the syntactic structure of a language, we propose CURSOR (Cross lingUal paRSing by wOrd Reordering) to overcome the word order difference issue"
2020.findings-emnlp.265,D19-1103,1,0.819615,"Missing"
2020.findings-emnlp.265,P12-1066,0,0.0579965,"Missing"
2020.findings-emnlp.265,J08-4003,0,0.0174665,"Missing"
2020.findings-emnlp.265,P18-1142,0,0.030763,"Missing"
2020.findings-emnlp.265,Q17-1020,0,0.0599189,"knowledge learned in one or multiple high-resource source languages to target ones. This approach has been successfully applied in various tasks, including partof-speech (POS) tagging (Kim et al., 2017), dependency parsing (McDonald et al., 2011), named entity recognition (Xie et al., 2018), entity linking (Sil et al., 2018), question answering (Joty et al., 2017), and coreference resolution (Kundu et al., 2018). A key challenge for cross-lingual parsing is the difficulty to handle word order difference between source and target languages, which often causes a significant drop in performance (Rasooli and Collins, 2017; Ahmad et al., 2019). Inspired by the idea that POS sequences often reflect the syntactic structure of a language, we propose CURSOR (Cross lingUal paRSing by wOrd Reordering) to overcome the word order difference issue in crosslingual transfer. Specifically, we assume we have a treebank in the source language and annotated POS corpus in the target language1 . We first train a POS-based language model on a corpus in the target language. Then, we reorder words in each sentence on the source corpus based on the POSbased language model to create pseudo sentences with target word order. The resul"
2020.findings-emnlp.265,N19-1385,0,0.0438747,"Missing"
2020.findings-emnlp.265,P15-2040,0,0.0458404,"Missing"
2020.findings-emnlp.265,N13-1126,0,0.0544327,"Missing"
2020.findings-emnlp.265,N12-1052,0,0.0776263,"Missing"
2020.findings-emnlp.265,W14-1614,0,0.0394417,"Missing"
2020.findings-emnlp.265,Q16-1035,0,0.022913,"ee model to extract the order features from the source language. Meng et al. (2019) embraced the linguistic knowledge of target languages to guide the inference. Some researchers also exploit lexical features to enhance the parsing models. Cross-lingual word clusters (T¨ackstr¨om et al., 2012), word embeddings (Guo et al., 2015, 2016; Ammar et al., 2016), and dictionaries (Durrett et al., 2012; Rasooli and Collins, 2017) are used as the features to better transfer linguistic knowledge among different languages. Our work is in line with a recently proposed solution, namely treebank reordering (Wang and Eisner, 2016, 2018; Rasooli and Collins, 2019), which aims to rearrange the word order in source sentences to make them more similar to the target one. Wang and Eisner (2018) proposed to permute the constituents of an existing dependency treebank to make its surface POS statistics approximately match those of the target language. However, they used POS bigrams to measure the surface closeness between two languages, which is unable to capture global information. Rasooli and Collins (2019) proposed two different syntactic reordering methods, one is based on the dominant dependency direction in the target la"
2020.findings-emnlp.265,Q17-1011,0,0.0336967,"Missing"
2020.findings-emnlp.265,D18-1163,0,0.0493276,"Some researchers also exploit lexical features to enhance the parsing models. Cross-lingual word clusters (T¨ackstr¨om et al., 2012), word embeddings (Guo et al., 2015, 2016; Ammar et al., 2016), and dictionaries (Durrett et al., 2012; Rasooli and Collins, 2017) are used as the features to better transfer linguistic knowledge among different languages. Our work is in line with a recently proposed solution, namely treebank reordering (Wang and Eisner, 2016, 2018; Rasooli and Collins, 2019), which aims to rearrange the word order in source sentences to make them more similar to the target one. Wang and Eisner (2018) proposed to permute the constituents of an existing dependency treebank to make its surface POS statistics approximately match those of the target language. However, they used POS bigrams to measure the surface closeness between two languages, which is unable to capture global information. Rasooli and Collins (2019) proposed two different syntactic reordering methods, one is based on the dominant dependency direction in the target language, the other learns a reordering classifier, but both methods rely on parallel corpus. 2939 In this study, we explore the feasibility of utilizing a POS-base"
2020.findings-emnlp.265,D18-1034,0,0.0170288,"ily relies on the size of corpus. Due to the great cost and difficulty of acquiring sufficient training data, ML-based methods cannot be trivially applied to low-resource languages. Cross-lingual transfer is a promising approach to tackle the lack of sufficient data. The idea is to train a cross-lingual model that transfers knowledge learned in one or multiple high-resource source languages to target ones. This approach has been successfully applied in various tasks, including partof-speech (POS) tagging (Kim et al., 2017), dependency parsing (McDonald et al., 2011), named entity recognition (Xie et al., 2018), entity linking (Sil et al., 2018), question answering (Joty et al., 2017), and coreference resolution (Kundu et al., 2018). A key challenge for cross-lingual parsing is the difficulty to handle word order difference between source and target languages, which often causes a significant drop in performance (Rasooli and Collins, 2017; Ahmad et al., 2019). Inspired by the idea that POS sequences often reflect the syntactic structure of a language, we propose CURSOR (Cross lingUal paRSing by wOrd Reordering) to overcome the word order difference issue in crosslingual transfer. Specifically, we as"
2020.findings-emnlp.265,I08-3008,0,0.0247318,"Missing"
2020.findings-emnlp.265,D19-1092,0,0.0306955,"Missing"
2020.findings-emnlp.265,D15-1213,0,0.0269026,"Missing"
2020.findings-emnlp.291,P17-4008,0,0.0376559,"trollable language generation, including the earlier introductions by Hu 17 Results for gender biases are in the Appendix. We also annotate 200 samples; the inter-annotator correlation is 0.71 and (annotation, automatic label) correlation is 0.66. Details are in the Appendix. 3246 18 et al. (2017) and Ficler and Goldberg (2017); we discuss the specific works most closely related to our own. Previous works have applied control to various components in a model pipeline. Keskar et al. (2019) present a large language model that learns during training to control for style and other specific tasks. Ghazvininejad et al. (2017) use weighted decoding to control poem style. Dathathri et al. (2019) combine attribute classifiers and pretrained language models to guide generation in different styles. Our gradient-based methods are most closely related to the latter work. Whereas Dathathri et al. (2019) update latent representations given gradients computed from the attribute classifier, we use gradients from target samples to form a bias trigger to control the model’s generated text. We believe these two gradient methods for control are parallel directions of work, and that our general formulation of bias associations an"
2020.findings-emnlp.291,W19-3823,0,0.0288688,"tion are manually selected, our analysis shows that DialoGPT tends to generate more negatively biased text for Black names, motivating the need for bias mitigation techniques. Introduction With the advent of more effective, large-scale natural language processing (NLP) techniques, the issue of fairness and bias is more important than ever. As such, there is an increasing repository of work dedicated to fairness in natural language processing. Much of the work on social biases in natural language processing focuses on biases in word embeddings (Bolukbasi et al., 2016; Zhao et al., 2018b, 2019; Kurita et al., 2019) and natural language understanding tasks (Rudinger et al., 2018; Zhao et al., 2018a; Park et al., 2018). In contrast, there has been relatively little work on examining biases in natural language generation (NLG). However, biases in NLG applications arguably have more direct social impact, since many NLG applications (e.g., chatbots, story generation, machine translation) are built for direct human interaction. Table 1 shows biases in real responses from DialoGPT (Zhang et al., 2020) and how prepending a hidden trigger to the user input can mitigate biases in DialoGPT’s response. Motivated by"
2020.findings-emnlp.291,P16-1162,0,0.00816364,"er expand on the difference between the previous work and our work, the former uses non-racist triggers to prompt models to generate racist output for any input, while we adapt the former’s techniques as an implementation of our framework to induce and mitigate biases for targeted demographics. Note that the found trigger phrases are expected to be nonsensical, in part due to the unconstrained replacement strategy, and in part because GPT-2 operates at the subword level with Byte Pair Encodings 2 More demographic surface forms are explored in the dialogue generation experiments in Section 5. (Sennrich et al., 2016). Regardless, the triggers are still able to effectively influence the model’s generated texts. Input prompts. In conditional language generation, an input prompt conditions the model’s generated text. We control biases in generated text by prepending a trigger to an input prompt, which contains a demographic mention and a bias context, as shown in Figure 1. Bias contexts, a concept introduced by Sheng et al. (2019), are textual contexts which may induce biases towards a demographic, e.g., “[PERSON] was described as __” or “[PERSON] was regarded as __”.3 In Figure 1, given the trigger “Asked E"
2020.findings-emnlp.291,D19-1339,1,0.83617,"as control objective by comparing the ratio of bias polarities across large sets of text generated from different bias objectives. Figure 1 gives an overview of an implementation of our framework. First, we find a “bias control trigger” that can influence the bias polarity of text generated under a specified bias objective by extending gradient-based adversarial trigger phrase search techniques (Wallace et al., 2019). We can prepend the trigger to input prompts (consisting of a demographic mention and a bias context, which are contexts that may induce biases in generated output, as defined by Sheng et al. (2019)), give the prepended input prompts to a language model, and evaluate the bias polarity ratio of the generated text. Throughout this work, we expand on how the procedure in Figure 1 can be used for both bias analysis and mitigation. One dimension for bias analysis is analyzing specific topics that correspond to demographic inequalities in generated text. For example, we find that a trigger that induces more negative bias towards RACE - BLACK versus towards RACE - WHITE results in more generated text on the subject of international relations. Another dimension for bias analysis is observing the"
2020.findings-emnlp.291,D19-1221,0,0.193469,"induces positive biases for woman and negative biases for man. tion, each text containing a demographic mention has a bias polarity towards the demographic, and we evaluate the effectiveness of our bias control objective by comparing the ratio of bias polarities across large sets of text generated from different bias objectives. Figure 1 gives an overview of an implementation of our framework. First, we find a “bias control trigger” that can influence the bias polarity of text generated under a specified bias objective by extending gradient-based adversarial trigger phrase search techniques (Wallace et al., 2019). We can prepend the trigger to input prompts (consisting of a demographic mention and a bias context, which are contexts that may induce biases in generated output, as defined by Sheng et al. (2019)), give the prepended input prompts to a language model, and evaluate the bias polarity ratio of the generated text. Throughout this work, we expand on how the procedure in Figure 1 can be used for both bias analysis and mitigation. One dimension for bias analysis is analyzing specific topics that correspond to demographic inequalities in generated text. For example, we find that a trigger that ind"
2020.findings-emnlp.291,2020.acl-demos.30,0,0.20968,"l language processing focuses on biases in word embeddings (Bolukbasi et al., 2016; Zhao et al., 2018b, 2019; Kurita et al., 2019) and natural language understanding tasks (Rudinger et al., 2018; Zhao et al., 2018a; Park et al., 2018). In contrast, there has been relatively little work on examining biases in natural language generation (NLG). However, biases in NLG applications arguably have more direct social impact, since many NLG applications (e.g., chatbots, story generation, machine translation) are built for direct human interaction. Table 1 shows biases in real responses from DialoGPT (Zhang et al., 2020) and how prepending a hidden trigger to the user input can mitigate biases in DialoGPT’s response. Motivated by the importance of understanding biases in NLG tasks, our goals are to develop new insights for and to mitigate biases in NLG models. To this end, we introduce a general framework to study how to control societal biases in NLG models. The framework is a model-agnostic formulation of a general bias control objective that can induce negative, neutral, or positive biases in generated text when the NLG model input contains mentions of specified demographic groups (e.g., “Black person” for"
2020.findings-emnlp.291,N19-1064,1,0.909786,"Missing"
2020.findings-emnlp.291,N18-2003,1,0.871272,"he examples without mitigation are manually selected, our analysis shows that DialoGPT tends to generate more negatively biased text for Black names, motivating the need for bias mitigation techniques. Introduction With the advent of more effective, large-scale natural language processing (NLP) techniques, the issue of fairness and bias is more important than ever. As such, there is an increasing repository of work dedicated to fairness in natural language processing. Much of the work on social biases in natural language processing focuses on biases in word embeddings (Bolukbasi et al., 2016; Zhao et al., 2018b, 2019; Kurita et al., 2019) and natural language understanding tasks (Rudinger et al., 2018; Zhao et al., 2018a; Park et al., 2018). In contrast, there has been relatively little work on examining biases in natural language generation (NLG). However, biases in NLG applications arguably have more direct social impact, since many NLG applications (e.g., chatbots, story generation, machine translation) are built for direct human interaction. Table 1 shows biases in real responses from DialoGPT (Zhang et al., 2020) and how prepending a hidden trigger to the user input can mitigate biases in Dial"
2020.findings-emnlp.291,D18-1521,1,0.882054,"he examples without mitigation are manually selected, our analysis shows that DialoGPT tends to generate more negatively biased text for Black names, motivating the need for bias mitigation techniques. Introduction With the advent of more effective, large-scale natural language processing (NLP) techniques, the issue of fairness and bias is more important than ever. As such, there is an increasing repository of work dedicated to fairness in natural language processing. Much of the work on social biases in natural language processing focuses on biases in word embeddings (Bolukbasi et al., 2016; Zhao et al., 2018b, 2019; Kurita et al., 2019) and natural language understanding tasks (Rudinger et al., 2018; Zhao et al., 2018a; Park et al., 2018). In contrast, there has been relatively little work on examining biases in natural language generation (NLG). However, biases in NLG applications arguably have more direct social impact, since many NLG applications (e.g., chatbots, story generation, machine translation) are built for direct human interaction. Table 1 shows biases in real responses from DialoGPT (Zhang et al., 2020) and how prepending a hidden trigger to the user input can mitigate biases in Dial"
2020.findings-emnlp.291,N18-2002,0,0.0956888,"Missing"
2020.findings-emnlp.291,D17-1323,1,\N,Missing
2020.findings-emnlp.291,N19-1423,0,\N,Missing
2020.findings-emnlp.291,D19-1531,1,\N,Missing
2020.findings-emnlp.66,Q17-1010,0,0.0595627,"Missing"
2020.findings-emnlp.66,N19-1423,0,0.0241971,"ining, validation, and test examples, respectively. Table 5 summarizes the data statistics. 3 Experiment In this section, we evaluate two neural question answering (QA) models on PolicyQA and present the findings from our analysis. Baselines. PolicyQA frames the QA task as predicting the answer span that exists in the given policy segment. Hence, we consider two existing neural approaches from literature as baselines for PolicyQA. The first model is BiDAF (Seo et al., 2017) that uses a bi-directional attention flow mechanism to extract the evidence spans. The second baseline is based on BERT (Devlin et al., 2019) with two linear classifiers to predict the boundary of the evidence, as suggested in the original work. 745 Implementation. PolicyQA has a similar setting as SQuAD (Rajpurkar et al., 2016). Therefore, we pre-train the QA models using their default settings Dataset # Examples # Policies # Questions # Passages Avg. question length Avg. passage length Avg. answer length Train 17,056 75 693 2,137 11.2 106.0 13.3 Valid 3,809 20 568 574 11.2 96.6 12.8 Test 4,152 20 600 497 11.2 119.1 14.1 BERT Size Tiny Mini Small Medium Base Valid EM F1 21.0 47.1 26.5 55.2 28.4 57.2 31.1 59.1 30.5 59.4 Test EM F1"
2020.findings-emnlp.66,C14-1084,0,0.550647,"(Sadeh et al., 2013) has made several attempts to automate the analysis of privacy policies (Wilson et al., 2016a; Zimmeck et al., 2019). Noteworthy works include identification of policy segments commenting on specific data practices (Wilson et al., 2016b), extraction of opt-out choices, and their provisions in policy text (Sathyendra et al., 2016; Mysore Sathyendra et al., 2017), and others (Bhatia and Breaux, 2015; Bhatia et al., 2016). Kaur et al. (2018) used a keyword-based technique to compare online privacy policies. Natural language processing (NLP) techniques such as text alignment (Liu et al., 2014; Ramanath et al., 2014), text classification (Harkous et al., 2018; Zimmeck et al., 2019; Wilson et al., 2016a) and question answering (Shvartzshanider et al., 2018; Harkous et al., 2018; Ravichander et al., 2019) has been studied in prior works to facilitate privacy policy analysis. Among the question answering (QA) methods, Harkous et al. (2018) framed the task as retrieving the most relevant policy segments as an answer, while Ravichander et al. (2019) presented a dataset and models to answer questions with a list of sentences. In comparison to the prior QA approaches, we encourage develop"
2020.findings-emnlp.66,D17-1294,0,0.357561,"ns; and (2) SQuAD pretraining helps more in extracting shorter evidence spans. Leveraging diverse extractive QA resources may reduce the length bias and boost the QA performance on privacy policies. 4 Related Work The Usable Privacy Project (Sadeh et al., 2013) has made several attempts to automate the analysis of privacy policies (Wilson et al., 2016a; Zimmeck et al., 2019). Noteworthy works include identification of policy segments commenting on specific data practices (Wilson et al., 2016b), extraction of opt-out choices, and their provisions in policy text (Sathyendra et al., 2016; Mysore Sathyendra et al., 2017), and others (Bhatia and Breaux, 2015; Bhatia et al., 2016). Kaur et al. (2018) used a keyword-based technique to compare online privacy policies. Natural language processing (NLP) techniques such as text alignment (Liu et al., 2014; Ramanath et al., 2014), text classification (Harkous et al., 2018; Zimmeck et al., 2019; Wilson et al., 2016a) and question answering (Shvartzshanider et al., 2018; Harkous et al., 2018; Ravichander et al., 2019) has been studied in prior works to facilitate privacy policy analysis. Among the question answering (QA) methods, Harkous et al. (2018) framed the task a"
2020.findings-emnlp.66,D16-1264,0,0.0564039,"A and present the findings from our analysis. Baselines. PolicyQA frames the QA task as predicting the answer span that exists in the given policy segment. Hence, we consider two existing neural approaches from literature as baselines for PolicyQA. The first model is BiDAF (Seo et al., 2017) that uses a bi-directional attention flow mechanism to extract the evidence spans. The second baseline is based on BERT (Devlin et al., 2019) with two linear classifiers to predict the boundary of the evidence, as suggested in the original work. 745 Implementation. PolicyQA has a similar setting as SQuAD (Rajpurkar et al., 2016). Therefore, we pre-train the QA models using their default settings Dataset # Examples # Policies # Questions # Passages Avg. question length Avg. passage length Avg. answer length Train 17,056 75 693 2,137 11.2 106.0 13.3 Valid 3,809 20 568 574 11.2 96.6 12.8 Test 4,152 20 600 497 11.2 119.1 14.1 BERT Size Tiny Mini Small Medium Base Valid EM F1 21.0 47.1 26.5 55.2 28.4 57.2 31.1 59.1 30.5 59.4 Test EM F1 15.5 39.9 22.8 49.8 24.6 52.3 25.2 53.5 28.1 55.6 Table 7: Performance of different sized QA models. Table 5: Statistics of the PolicyQA dataset. Valid EM F1 Test EM F1 7 3 7 25.1 52.3 26.7"
2020.findings-emnlp.66,P14-2099,0,0.305759,"13) has made several attempts to automate the analysis of privacy policies (Wilson et al., 2016a; Zimmeck et al., 2019). Noteworthy works include identification of policy segments commenting on specific data practices (Wilson et al., 2016b), extraction of opt-out choices, and their provisions in policy text (Sathyendra et al., 2016; Mysore Sathyendra et al., 2017), and others (Bhatia and Breaux, 2015; Bhatia et al., 2016). Kaur et al. (2018) used a keyword-based technique to compare online privacy policies. Natural language processing (NLP) techniques such as text alignment (Liu et al., 2014; Ramanath et al., 2014), text classification (Harkous et al., 2018; Zimmeck et al., 2019; Wilson et al., 2016a) and question answering (Shvartzshanider et al., 2018; Harkous et al., 2018; Ravichander et al., 2019) has been studied in prior works to facilitate privacy policy analysis. Among the question answering (QA) methods, Harkous et al. (2018) framed the task as retrieving the most relevant policy segments as an answer, while Ravichander et al. (2019) presented a dataset and models to answer questions with a list of sentences. In comparison to the prior QA approaches, we encourage developing QA systems capable o"
2020.findings-emnlp.66,D19-1500,0,0.278389,"long and verbose policy documents can help them better understand their rights. In recent years, we have witnessed noteworthy progress in developing question answering (QA) systems with a colossal effort to benchmark highquality, large-scale datasets for a few application ∗ Equal contribution. domains (e.g., Wikipedia, news articles). However, annotating large-scale QA datasets for domains such as security and privacy is challenging as it requires expert annotators (e.g., law students). Due to the difficulty of annotating policy documents at scale, the only available QA dataset is PrivacyQA (Ravichander et al., 2019) on privacy policies for 35 mobile applications. An essential characteristic of policy documents is that they are well structured as they are written by following guidelines set by the policymakers. Besides, due to the homogeneous nature of different entities (e.g., Amazon, eBay), their privacy policies have a similar structure. Therefore, we can exploit the document structure (meta data) to form examples from existing corpora. In this paper, we present PolicyQA, a reading comprehension style question answering dataset with 25,017 question743 Findings of the Association for Computational Lingu"
2020.findings-emnlp.66,W18-2608,0,0.0182135,"ks include identification of policy segments commenting on specific data practices (Wilson et al., 2016b), extraction of opt-out choices, and their provisions in policy text (Sathyendra et al., 2016; Mysore Sathyendra et al., 2017), and others (Bhatia and Breaux, 2015; Bhatia et al., 2016). Kaur et al. (2018) used a keyword-based technique to compare online privacy policies. Natural language processing (NLP) techniques such as text alignment (Liu et al., 2014; Ramanath et al., 2014), text classification (Harkous et al., 2018; Zimmeck et al., 2019; Wilson et al., 2016a) and question answering (Shvartzshanider et al., 2018; Harkous et al., 2018; Ravichander et al., 2019) has been studied in prior works to facilitate privacy policy analysis. Among the question answering (QA) methods, Harkous et al. (2018) framed the task as retrieving the most relevant policy segments as an answer, while Ravichander et al. (2019) presented a dataset and models to answer questions with a list of sentences. In comparison to the prior QA approaches, we encourage developing QA systems capable of providing precise answers by using PolicyQA. 5 Conclusion This work proposes PolicyQA, a reading comprehension style question answering (QA"
2020.findings-emnlp.66,P16-1126,0,0.399995,"Missing"
2021.acl-long.111,D18-1439,0,0.342063,"e output is a set of keyphrases that can be categorized as present or absent keyphrases. Present keyphrases appear exactly in the target doc∗ Work done during internship at Yahoo Research. ument, while absent keyphrases are only semantically related and have partial or no overlap to the target document. We provide an example of a target document and its keyphrases in Figure 1. In recent years, the neural sequence-to-sequence (Seq2Seq) framework (Sutskever et al., 2014) has become the fundamental building block in keyphrase generation models. Most of the existing approaches (Meng et al., 2017; Chen et al., 2018; Yuan et al., 2020; Chen et al., 2019b) adopt the Seq2Seq framework with attention (Luong et al., 2015; Bahdanau et al., 2014) and copy mechanism (See et al., 2017; Gu et al., 2016). However, present phrases indicate the indispensable segments of a 1389 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 1389–1404 August 1–6, 2021. ©2021 Association for Computational Linguistics target document. Emphasizing on those segments improves document understanding that can lead a mode"
2021.acl-long.111,D14-1181,0,0.0166028,"hat are fed to the extractor-generator to predict both the present and absent keyphrases (Task 2, 3). We detail them in this section. 3.1 Embedding Layer The embedding layer maps each word in an input sequence to a low-dimensional vector space. We train three embedding matrices, We , Wpos , and Wseg that convert a word, its absolute position, and segment index into vector representations of size dmodel . The segment index of a word indicates the index of the sentence that it belongs to. In addition, we obtain a character-level embedding for each word using Convolutional Neural Networks (CNN) (Kim, 2014a). To learn a fixed-length vector representation of a word, we add the four embedding vectors element-wise. To form the vector representations of the keyphrase tokens, we only use their word and character-level embeddings. 3.2 Sentence-Selector The objective of the sentence-selector is to predict the salient sentences in a document, as described in Task 1. Given a sentence, six = [xj , . . . , xj+|si |−1 ] from a document x, the selector predicts the salience probability of that input sentence. First, the embedding layer maps each word in the sentence into a dmodel dimensional vector. The seq"
2021.acl-long.111,I13-1108,0,0.0320098,"fic and web documents demonstrate that SEG-Net outperforms the state-of-the-art neural generative methods by a large margin. 1 Figure 1: Example of a document with present and absent keyphrases. The value (0/1) in brackets ([]) represent sentence salience label. Introduction Keyphrases are short pieces of text that summarize the key points discussed in a document. They are useful for many natural language processing and information retrieval tasks (Wilson et al., 2005; Berend, 2011; Tang et al., 2017; Subramanian et al., 2018; Zhang et al., 2017b; Wan and Xiao, 2008; Jones and Staveley, 1999; Kim et al., 2013; Hulth and Megyesi, 2006; Hammouda et al., 2005; Wu and Bolivar, 2008; Dave and Varma, 2010). In the automatic keyphrase generation task, the input is a document, and the output is a set of keyphrases that can be categorized as present or absent keyphrases. Present keyphrases appear exactly in the target doc∗ Work done during internship at Yahoo Research. ument, while absent keyphrases are only semantically related and have partial or no overlap to the target document. We provide an example of a target document and its keyphrases in Figure 1. In recent years, the neural sequence-to-sequence ("
2021.acl-long.111,P19-1209,0,0.0273766,"t, and (2) an extractorgenerator that predicts the present keyphrases and generates the absent keyphrases jointly. The motivation to design the sentence-selector is to decompose a long target document into a list of sentences, and identify the salient ones for keyphrase generation. We consider a sentence as salient if it contains present keyphrases or overlaps with absent keyphrases. As shown in Figure 1, we split the document into a list of sentences and classify them with salient and non-salient labels. A similar notion is adopted in prior works on text summarization (Chen and Bansal, 2018; Lebanoff et al., 2019) and question answering (Min et al., 2018). We employ Transformer (Vaswani et al., 2017) as the backbone of the extractor-generator in SEG-Net. We equip the extractor-generator with a novel layer-wise coverage attention such that the generated keyphrases summarize the entire target document. The layer-wise coverage attention keeps track of the target document segments that are covered by previously generated phrases to guide the self-attention mechanism in Transformer while attending the encoded target document in future generation steps. We evaluate SEG-Net on five benchmarks from scientific"
2021.acl-long.111,W11-0316,0,0.0425202,"ention helps when keyphrases summarize concepts expressed in different segments of a long document. We confirm our hypothesis by observing the performance trend with and without the coverage attention mechanism (we observe a similar trend as in Figure 3). We provide additional experiment results and qualitative examples in Appendix. 7 Related Work Keyphrase extraction approaches identify important phrases that appear in a document. The existing approaches generally work in two steps. First, they select a set of candidate keyphrases based on heuristic rules (Hulth, 2003; Medelyan et al., 2008; Liu et al., 2011; Wang et al., 2016). The selected keyphrases are scored as per their importance in the second step, which is computed by unsupervised ranking approaches (Wan and Xiao, 2008; Grineva et al., 2009) or supervised learning algorithms (Hulth, 2003; Witten et al., 2005; Medelyan et al., 2009; Nguyen and Kan, 2007; Lopez and Romary, 2010). Finally, the top-ranked candidates are returned as the keyphrases. Another pool of extractive solutions follows a sequence tagging approach (Luan et al., 2017; Zhang et al., 2016; Gollapalli et al., 2017; Gollapalli and Caragea, 2014). However, the extractive solu"
2021.acl-long.111,S10-1055,0,0.0246929,"pendix. 7 Related Work Keyphrase extraction approaches identify important phrases that appear in a document. The existing approaches generally work in two steps. First, they select a set of candidate keyphrases based on heuristic rules (Hulth, 2003; Medelyan et al., 2008; Liu et al., 2011; Wang et al., 2016). The selected keyphrases are scored as per their importance in the second step, which is computed by unsupervised ranking approaches (Wan and Xiao, 2008; Grineva et al., 2009) or supervised learning algorithms (Hulth, 2003; Witten et al., 2005; Medelyan et al., 2009; Nguyen and Kan, 2007; Lopez and Romary, 2010). Finally, the top-ranked candidates are returned as the keyphrases. Another pool of extractive solutions follows a sequence tagging approach (Luan et al., 2017; Zhang et al., 2016; Gollapalli et al., 2017; Gollapalli and Caragea, 2014). However, the extractive solutions are only able to predict the keyphrases that appear in the document and thus fail to predict the absent keyphrases. Keyphrase generation methods aim at predicting both the present and absent phrases. Meng et al. (2017) proposed the first generative model, known as CopyRNN, which is composed of attention (Bahdanau et al., 2014;"
2021.acl-long.111,D17-1279,0,0.0256518,"t, they select a set of candidate keyphrases based on heuristic rules (Hulth, 2003; Medelyan et al., 2008; Liu et al., 2011; Wang et al., 2016). The selected keyphrases are scored as per their importance in the second step, which is computed by unsupervised ranking approaches (Wan and Xiao, 2008; Grineva et al., 2009) or supervised learning algorithms (Hulth, 2003; Witten et al., 2005; Medelyan et al., 2009; Nguyen and Kan, 2007; Lopez and Romary, 2010). Finally, the top-ranked candidates are returned as the keyphrases. Another pool of extractive solutions follows a sequence tagging approach (Luan et al., 2017; Zhang et al., 2016; Gollapalli et al., 2017; Gollapalli and Caragea, 2014). However, the extractive solutions are only able to predict the keyphrases that appear in the document and thus fail to predict the absent keyphrases. Keyphrase generation methods aim at predicting both the present and absent phrases. Meng et al. (2017) proposed the first generative model, known as CopyRNN, which is composed of attention (Bahdanau et al., 2014; Luong et al., 2015) and copy mechanism (Gu et al., 2016; See et al., 2017). Multiple extensions of CopyRNN were proposed in subsequent works (Chen et al., 2018"
2021.acl-long.111,D15-1166,0,0.379562,"rases appear exactly in the target doc∗ Work done during internship at Yahoo Research. ument, while absent keyphrases are only semantically related and have partial or no overlap to the target document. We provide an example of a target document and its keyphrases in Figure 1. In recent years, the neural sequence-to-sequence (Seq2Seq) framework (Sutskever et al., 2014) has become the fundamental building block in keyphrase generation models. Most of the existing approaches (Meng et al., 2017; Chen et al., 2018; Yuan et al., 2020; Chen et al., 2019b) adopt the Seq2Seq framework with attention (Luong et al., 2015; Bahdanau et al., 2014) and copy mechanism (See et al., 2017; Gu et al., 2016). However, present phrases indicate the indispensable segments of a 1389 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 1389–1404 August 1–6, 2021. ©2021 Association for Computational Linguistics target document. Emphasizing on those segments improves document understanding that can lead a model to coherent absent phrase generation. This motivates to jointly model keyphrase extraction and genera"
2021.acl-long.111,D09-1137,0,0.0228851,"riment results and qualitative examples in Appendix. 7 Related Work Keyphrase extraction approaches identify important phrases that appear in a document. The existing approaches generally work in two steps. First, they select a set of candidate keyphrases based on heuristic rules (Hulth, 2003; Medelyan et al., 2008; Liu et al., 2011; Wang et al., 2016). The selected keyphrases are scored as per their importance in the second step, which is computed by unsupervised ranking approaches (Wan and Xiao, 2008; Grineva et al., 2009) or supervised learning algorithms (Hulth, 2003; Witten et al., 2005; Medelyan et al., 2009; Nguyen and Kan, 2007; Lopez and Romary, 2010). Finally, the top-ranked candidates are returned as the keyphrases. Another pool of extractive solutions follows a sequence tagging approach (Luan et al., 2017; Zhang et al., 2016; Gollapalli et al., 2017; Gollapalli and Caragea, 2014). However, the extractive solutions are only able to predict the keyphrases that appear in the document and thus fail to predict the absent keyphrases. Keyphrase generation methods aim at predicting both the present and absent phrases. Meng et al. (2017) proposed the first generative model, known as CopyRNN, which i"
2021.acl-long.111,P17-1054,0,0.247602,"a document, and the output is a set of keyphrases that can be categorized as present or absent keyphrases. Present keyphrases appear exactly in the target doc∗ Work done during internship at Yahoo Research. ument, while absent keyphrases are only semantically related and have partial or no overlap to the target document. We provide an example of a target document and its keyphrases in Figure 1. In recent years, the neural sequence-to-sequence (Seq2Seq) framework (Sutskever et al., 2014) has become the fundamental building block in keyphrase generation models. Most of the existing approaches (Meng et al., 2017; Chen et al., 2018; Yuan et al., 2020; Chen et al., 2019b) adopt the Seq2Seq framework with attention (Luong et al., 2015; Bahdanau et al., 2014) and copy mechanism (See et al., 2017; Gu et al., 2016). However, present phrases indicate the indispensable segments of a 1389 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 1389–1404 August 1–6, 2021. ©2021 Association for Computational Linguistics target document. Emphasizing on those segments improves document understanding t"
2021.acl-long.111,W18-2609,0,0.0172616,"the document. The experimental results on seven keyphrase generation benchmarks from scientific and web documents demonstrate that SEG-Net outperforms the state-of-the-art neural generative methods by a large margin. 1 Figure 1: Example of a document with present and absent keyphrases. The value (0/1) in brackets ([]) represent sentence salience label. Introduction Keyphrases are short pieces of text that summarize the key points discussed in a document. They are useful for many natural language processing and information retrieval tasks (Wilson et al., 2005; Berend, 2011; Tang et al., 2017; Subramanian et al., 2018; Zhang et al., 2017b; Wan and Xiao, 2008; Jones and Staveley, 1999; Kim et al., 2013; Hulth and Megyesi, 2006; Hammouda et al., 2005; Wu and Bolivar, 2008; Dave and Varma, 2010). In the automatic keyphrase generation task, the input is a document, and the output is a set of keyphrases that can be categorized as present or absent keyphrases. Present keyphrases appear exactly in the target doc∗ Work done during internship at Yahoo Research. ument, while absent keyphrases are only semantically related and have partial or no overlap to the target document. We provide an example of a target docume"
2021.acl-long.111,2020.emnlp-main.645,0,0.0358405,"at utilizes convolutional neural network (CNN) (Kim, 2014b) to form sequenceto-sequence architecture. However, these generation methods are trained to predict one keyphrase from the target document. In contrast, Yuan et al. (2020) proposed to concatenate all the ground-truth keyphrases and train models to generate them as one output sequence. Other noteworthy approaches in literature utilize data from external source (Chen et al., 2019a), syntactic supervision (Zhao and Zhang, 2019), semisupervised learning (Ye and Wang, 2018), reinforcement learning (Chan et al., 2019), adversarial training (Swaminathan et al., 2020), unlikelihood training (Bahuleyan and El Asri, 2020) to improve keyphrase generation. 8 Conclusion This paper presents SEG-Net, a keyphrase generation model that identifies the salient sentences in a target document to utilize maximal information for keyphrase prediction. In SEG-Net, we incorporate a novel layer-wise coverage attention to cover all the critical points in a document and diversify the present and absent keyphrases. We evaluate SEGNet on seven benchmarks from scientific and web documents, and the experiment results demonstrate SEG-Net’s effectiveness over the state-of-the-art me"
2021.acl-long.111,P16-1008,0,0.0174226,"xi |ut = L 1) = ati to copy the input tokens xi . We compute the probability of using the copy mechanism at the L decoding step t as p(ut = 1) = σ(Wu [hL t ||ct ] + bu ), where ||denotes the vector concatenation operator. Then we obtain the final probability distribution for the output token yt∗ as: P (yt∗ ) = P (ut = 0)P (yt∗ |ut = 0) + P (ut = 1)P (yt∗ |ut = 1) where P (yt∗ |ut = 0) is defined in Eq. (1). All probabili∗ ties are conditioned on y1:t−1 , x, but we omit them to keep the notations simple. 3.4 where Wv ∈ R|V |×dmodel and bword ∈ R|V |. Coverage Attention The coverage attention (Tu et al., 2016; Yuan et al., 2020; Chen et al., 2018) keeps track of the parts in the document that has been covered by previously generated phrases and encourages future generation steps to summarize the other segments of the target document. The underlying idea is to decay the attention weights of the previously attended input tokens while decoder attends the encoded input tokens at time step, t. To equip the multi-layer structure of the Transformer with a layer-wise coverage attention, we adopt the layer-wise encoder-decoder attention technique (He et al., 2018). We compute the attene0 tion weights, αti"
2021.acl-long.111,D18-1447,0,0.0176812,"018, 2019b). Different from these approaches, Zhang et al. (2017a) proposed CopyCNN that utilizes convolutional neural network (CNN) (Kim, 2014b) to form sequenceto-sequence architecture. However, these generation methods are trained to predict one keyphrase from the target document. In contrast, Yuan et al. (2020) proposed to concatenate all the ground-truth keyphrases and train models to generate them as one output sequence. Other noteworthy approaches in literature utilize data from external source (Chen et al., 2019a), syntactic supervision (Zhao and Zhang, 2019), semisupervised learning (Ye and Wang, 2018), reinforcement learning (Chan et al., 2019), adversarial training (Swaminathan et al., 2020), unlikelihood training (Bahuleyan and El Asri, 2020) to improve keyphrase generation. 8 Conclusion This paper presents SEG-Net, a keyphrase generation model that identifies the salient sentences in a target document to utilize maximal information for keyphrase prediction. In SEG-Net, we incorporate a novel layer-wise coverage attention to cover all the critical points in a document and diversify the present and absent keyphrases. We evaluate SEGNet on seven benchmarks from scientific and web documents"
2021.acl-long.111,2020.acl-main.710,0,0.503108,"f keyphrases that can be categorized as present or absent keyphrases. Present keyphrases appear exactly in the target doc∗ Work done during internship at Yahoo Research. ument, while absent keyphrases are only semantically related and have partial or no overlap to the target document. We provide an example of a target document and its keyphrases in Figure 1. In recent years, the neural sequence-to-sequence (Seq2Seq) framework (Sutskever et al., 2014) has become the fundamental building block in keyphrase generation models. Most of the existing approaches (Meng et al., 2017; Chen et al., 2018; Yuan et al., 2020; Chen et al., 2019b) adopt the Seq2Seq framework with attention (Luong et al., 2015; Bahdanau et al., 2014) and copy mechanism (See et al., 2017; Gu et al., 2016). However, present phrases indicate the indispensable segments of a 1389 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 1389–1404 August 1–6, 2021. ©2021 Association for Computational Linguistics target document. Emphasizing on those segments improves document understanding that can lead a model to coherent absen"
2021.acl-long.111,D16-1080,0,0.0307481,"t of candidate keyphrases based on heuristic rules (Hulth, 2003; Medelyan et al., 2008; Liu et al., 2011; Wang et al., 2016). The selected keyphrases are scored as per their importance in the second step, which is computed by unsupervised ranking approaches (Wan and Xiao, 2008; Grineva et al., 2009) or supervised learning algorithms (Hulth, 2003; Witten et al., 2005; Medelyan et al., 2009; Nguyen and Kan, 2007; Lopez and Romary, 2010). Finally, the top-ranked candidates are returned as the keyphrases. Another pool of extractive solutions follows a sequence tagging approach (Luan et al., 2017; Zhang et al., 2016; Gollapalli et al., 2017; Gollapalli and Caragea, 2014). However, the extractive solutions are only able to predict the keyphrases that appear in the document and thus fail to predict the absent keyphrases. Keyphrase generation methods aim at predicting both the present and absent phrases. Meng et al. (2017) proposed the first generative model, known as CopyRNN, which is composed of attention (Bahdanau et al., 2014; Luong et al., 2015) and copy mechanism (Gu et al., 2016; See et al., 2017). Multiple extensions of CopyRNN were proposed in subsequent works (Chen et al., 2018, 2019b). Different"
2021.acl-long.111,P19-1515,0,0.0670974,"tch size of 80 and a learning rate of 10−4 . During training, we use dropout and gradient clipping. We halve the learning rate when the validation performance drops and stop training if it does not improve for five successive iterations. We train the sentenceselector and extractor-generator modules for a maximum of 15 and 25 epochs, respectively. Training the modules takes roughly 10 and 25 hours on two GeForce GTX 1080 GPUs, respectively. Decoding The absent keyphrases are generated as a concatenated sequence of words. Hence, unlike prior works (Meng et al., 2017; Chen et al., 2018, 2019b,a; Zhao and Zhang, 2019), we use greedy search as the decoding algorithm during testing, and we force the decoder never to output the same trigram more than once to avoid repetitions in the generated keyphrases. This is accomplished by not selecting the word that would create a trigram already exists in the previously decoded sequence. It is a well-known technique utilized in text summarization (Paulus et al., 2018). We provide details about model implementations and references in Appendix for reproducibility. 3 The values are chosen by simply computing the fraction of the positive and negative samples. 1394 KPTimes"
2021.acl-long.111,H05-1044,0,0.0182365,"attention to summarize most of the points discussed in the document. The experimental results on seven keyphrase generation benchmarks from scientific and web documents demonstrate that SEG-Net outperforms the state-of-the-art neural generative methods by a large margin. 1 Figure 1: Example of a document with present and absent keyphrases. The value (0/1) in brackets ([]) represent sentence salience label. Introduction Keyphrases are short pieces of text that summarize the key points discussed in a document. They are useful for many natural language processing and information retrieval tasks (Wilson et al., 2005; Berend, 2011; Tang et al., 2017; Subramanian et al., 2018; Zhang et al., 2017b; Wan and Xiao, 2008; Jones and Staveley, 1999; Kim et al., 2013; Hulth and Megyesi, 2006; Hammouda et al., 2005; Wu and Bolivar, 2008; Dave and Varma, 2010). In the automatic keyphrase generation task, the input is a document, and the output is a set of keyphrases that can be categorized as present or absent keyphrases. Present keyphrases appear exactly in the target doc∗ Work done during internship at Yahoo Research. ument, while absent keyphrases are only semantically related and have partial or no overlap to th"
2021.acl-long.330,W19-3822,0,0.199437,"al. (2018); Elaraby et al. (2018); Prates et al. (2019); Stanovsky et al. (2019); Escud´e Font and Costa-juss`a (2019); Cho et al. (2019); Moryossef et al. (2019); Saunders and Byrne (2020); Saunders et al. (2020); Kocmi et al. (2020); Costa-juss`a and de Jorge (2020); Costa-juss`a et al. (2020); Basta et al. (2020); Farkas and N´emeth (2020); Stafanoviˇcs et al. (2020); Gonen and Webster (2020); Hovy et al. (2020); Roberts et al. (2020); Cho et al. (2021); Savoldi et al. (2021); Renduchintala and Williams (2021); Choubey et al. (2021); Saunders et al. (2021); Tomalin et al. (2021) Re-writing Habash et al. (2019); Zmigrod et al. (2019); Alhafni et al. (2020); Sun et al. (2021) Profession Autocomplete Huang et al. (2020); Dhamala et al. (2021) Race Autocomplete Solaiman et al. (2019); Sheng et al. (2019, 2020); Groenwold et al. (2020); Brown et al. (2020); Dhamala et al. (2021); Schick et al. (2021); Kirk et al. (2021) Dialogue Sheng et al. (2021a,b) Religion Autocomplete Solaiman et al. (2019); Brown et al. (2020); Dhamala et al. (2021); Kirk et al. (2021); Abid et al. (2021) Sexuality Autocomplete Sheng et al. (2019, 2020); Kirk et al. (2021) Dialogue Sheng et al. (2021a) Other Autocomplete Shwartz e"
2021.acl-long.330,S18-2005,0,0.0224595,"Missing"
2021.acl-long.330,2020.wmt-1.39,0,0.534408,"and Bowman (2019); Qian et al. (2019); Solaiman et al. (2019); Sheng et al. (2019, 2020); Vig et al. (2020); Yeo and Chen (2020); Brown et al. (2020); Dhamala et al. (2021); Schick et al. (2021); Nozza et al. (2021); Kirk et al. (2021) Dialogue Henderson et al. (2018); Dinan et al. (2020a); Liu et al. (2020a,b); Cercas Curry et al. (2020); Sheng et al. (2021a,b) MT Vanmassenhove et al. (2018); Elaraby et al. (2018); Prates et al. (2019); Stanovsky et al. (2019); Escud´e Font and Costa-juss`a (2019); Cho et al. (2019); Moryossef et al. (2019); Saunders and Byrne (2020); Saunders et al. (2020); Kocmi et al. (2020); Costa-juss`a and de Jorge (2020); Costa-juss`a et al. (2020); Basta et al. (2020); Farkas and N´emeth (2020); Stafanoviˇcs et al. (2020); Gonen and Webster (2020); Hovy et al. (2020); Roberts et al. (2020); Cho et al. (2021); Savoldi et al. (2021); Renduchintala and Williams (2021); Choubey et al. (2021); Saunders et al. (2021); Tomalin et al. (2021) Re-writing Habash et al. (2019); Zmigrod et al. (2019); Alhafni et al. (2020); Sun et al. (2021) Profession Autocomplete Huang et al. (2020); Dhamala et al. (2021) Race Autocomplete Solaiman et al. (2019); Sheng et al. (2019, 2020); Groenwold et"
2021.acl-long.330,2020.acl-main.154,0,0.0123573,"l. (2021); Nozza et al. (2021); Kirk et al. (2021) Dialogue Henderson et al. (2018); Dinan et al. (2020a); Liu et al. (2020a,b); Cercas Curry et al. (2020); Sheng et al. (2021a,b) MT Vanmassenhove et al. (2018); Elaraby et al. (2018); Prates et al. (2019); Stanovsky et al. (2019); Escud´e Font and Costa-juss`a (2019); Cho et al. (2019); Moryossef et al. (2019); Saunders and Byrne (2020); Saunders et al. (2020); Kocmi et al. (2020); Costa-juss`a and de Jorge (2020); Costa-juss`a et al. (2020); Basta et al. (2020); Farkas and N´emeth (2020); Stafanoviˇcs et al. (2020); Gonen and Webster (2020); Hovy et al. (2020); Roberts et al. (2020); Cho et al. (2021); Savoldi et al. (2021); Renduchintala and Williams (2021); Choubey et al. (2021); Saunders et al. (2021); Tomalin et al. (2021) Re-writing Habash et al. (2019); Zmigrod et al. (2019); Alhafni et al. (2020); Sun et al. (2021) Profession Autocomplete Huang et al. (2020); Dhamala et al. (2021) Race Autocomplete Solaiman et al. (2019); Sheng et al. (2019, 2020); Groenwold et al. (2020); Brown et al. (2020); Dhamala et al. (2021); Schick et al. (2021); Kirk et al. (2021) Dialogue Sheng et al. (2021a,b) Religion Autocomplete Solaiman et al. (2019); Brown et"
2021.acl-long.330,2020.findings-emnlp.7,0,0.0904999,"a (2019); Cho et al. (2019); Moryossef et al. (2019); Saunders and Byrne (2020); Saunders et al. (2020); Kocmi et al. (2020); Costa-juss`a and de Jorge (2020); Costa-juss`a et al. (2020); Basta et al. (2020); Farkas and N´emeth (2020); Stafanoviˇcs et al. (2020); Gonen and Webster (2020); Hovy et al. (2020); Roberts et al. (2020); Cho et al. (2021); Savoldi et al. (2021); Renduchintala and Williams (2021); Choubey et al. (2021); Saunders et al. (2021); Tomalin et al. (2021) Re-writing Habash et al. (2019); Zmigrod et al. (2019); Alhafni et al. (2020); Sun et al. (2021) Profession Autocomplete Huang et al. (2020); Dhamala et al. (2021) Race Autocomplete Solaiman et al. (2019); Sheng et al. (2019, 2020); Groenwold et al. (2020); Brown et al. (2020); Dhamala et al. (2021); Schick et al. (2021); Kirk et al. (2021) Dialogue Sheng et al. (2021a,b) Religion Autocomplete Solaiman et al. (2019); Brown et al. (2020); Dhamala et al. (2021); Kirk et al. (2021); Abid et al. (2021) Sexuality Autocomplete Sheng et al. (2019, 2020); Kirk et al. (2021) Dialogue Sheng et al. (2021a) Other Autocomplete Shwartz et al. (2020); Peng et al. (2020); Huang et al. (2020); Dhamala et al. (2021); Kirk et al. (2021) Dialogue She"
2021.acl-long.330,2021.acl-long.522,0,0.093528,"techniques that rely on training from scratch use smaller architectures (exceptions are from larger institutions). 5.3 Inference Methods While the existing literature on inference time methods for bias mitigation is sparse, decoding-based methods are a promising alternative to data- and training-based methods. Specifically, these methods are compatible with any pre-trained language model for generation without additional training. Given recent development of inference-time methods for control that can reduce toxicity (e.g., PPLM (Dathathri et al., 2019), GeDi (Krause et al., 2020), DExperts (Liu et al., 2021)), there is potential for extending these methods to bias mitigation. Bias Mitigation For autocomplete and dialogue generation, Sheng et al. (2020) formulate bias triggers using gradient-based methods of Wallace et al. (2019). These triggers are appended to prompts during inference time to control text generation to be more equalized towards different demographics. For translation, Saunders and Byrne (2020) present a lattice rescoring procedure that creates genderinflected search spaces to rescore text for more accurate translations, and Saunders et al. (2021) subsequently use this lattice str"
2021.acl-long.330,2020.coling-main.390,0,0.218102,"ls. 4275 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 4275–4293 August 1–6, 2021. ©2021 Association for Computational Linguistics Demo. Dim. NLG Task Works Gender Autocomplete Bordia and Bowman (2019); Qian et al. (2019); Solaiman et al. (2019); Sheng et al. (2019, 2020); Vig et al. (2020); Yeo and Chen (2020); Brown et al. (2020); Dhamala et al. (2021); Schick et al. (2021); Nozza et al. (2021); Kirk et al. (2021) Dialogue Henderson et al. (2018); Dinan et al. (2020a); Liu et al. (2020a,b); Cercas Curry et al. (2020); Sheng et al. (2021a,b) MT Vanmassenhove et al. (2018); Elaraby et al. (2018); Prates et al. (2019); Stanovsky et al. (2019); Escud´e Font and Costa-juss`a (2019); Cho et al. (2019); Moryossef et al. (2019); Saunders and Byrne (2020); Saunders et al. (2020); Kocmi et al. (2020); Costa-juss`a and de Jorge (2020); Costa-juss`a et al. (2020); Basta et al. (2020); Farkas and N´emeth (2020); Stafanoviˇcs et al. (2020); Gonen and Webster (2020); Hovy et al. (2020); Roberts et al. (2020); Cho et al. (2021); Savoldi et al. (2021); Renduchintala and Williams (2021); Cho"
2021.acl-long.330,2020.emnlp-main.64,0,0.48688,"ls. 4275 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 4275–4293 August 1–6, 2021. ©2021 Association for Computational Linguistics Demo. Dim. NLG Task Works Gender Autocomplete Bordia and Bowman (2019); Qian et al. (2019); Solaiman et al. (2019); Sheng et al. (2019, 2020); Vig et al. (2020); Yeo and Chen (2020); Brown et al. (2020); Dhamala et al. (2021); Schick et al. (2021); Nozza et al. (2021); Kirk et al. (2021) Dialogue Henderson et al. (2018); Dinan et al. (2020a); Liu et al. (2020a,b); Cercas Curry et al. (2020); Sheng et al. (2021a,b) MT Vanmassenhove et al. (2018); Elaraby et al. (2018); Prates et al. (2019); Stanovsky et al. (2019); Escud´e Font and Costa-juss`a (2019); Cho et al. (2019); Moryossef et al. (2019); Saunders and Byrne (2020); Saunders et al. (2020); Kocmi et al. (2020); Costa-juss`a and de Jorge (2020); Costa-juss`a et al. (2020); Basta et al. (2020); Farkas and N´emeth (2020); Stafanoviˇcs et al. (2020); Gonen and Webster (2020); Hovy et al. (2020); Roberts et al. (2020); Cho et al. (2021); Savoldi et al. (2021); Renduchintala and Williams (2021); Cho"
2021.acl-long.330,2020.inlg-1.43,0,0.426037,"l. (2019); Alhafni et al. (2020); Sun et al. (2021) Profession Autocomplete Huang et al. (2020); Dhamala et al. (2021) Race Autocomplete Solaiman et al. (2019); Sheng et al. (2019, 2020); Groenwold et al. (2020); Brown et al. (2020); Dhamala et al. (2021); Schick et al. (2021); Kirk et al. (2021) Dialogue Sheng et al. (2021a,b) Religion Autocomplete Solaiman et al. (2019); Brown et al. (2020); Dhamala et al. (2021); Kirk et al. (2021); Abid et al. (2021) Sexuality Autocomplete Sheng et al. (2019, 2020); Kirk et al. (2021) Dialogue Sheng et al. (2021a) Other Autocomplete Shwartz et al. (2020); Peng et al. (2020); Huang et al. (2020); Dhamala et al. (2021); Kirk et al. (2021) Dialogue Sheng et al. (2021a) Re-writing Pryzant et al. (2020); Ma et al. (2020) Table 1: Existing bias studies on different demographic dimensions in various NLG tasks: autocomplete generation, dialogue generation, machine translation (MT), and text re-writing. on mitigating gender biases and Shah et al. (2020) categorize sources of biases—both largely focus on natural language understanding (NLU) tasks, while we examine biases in NLG tasks. Additionally, Blodgett et al. (2020) urge for more explicitly tying “biases” in NLP to s"
2021.acl-long.330,P19-2031,0,0.169789,"o be used for auto-regressive generation (Wang and Cho, 2019; Chen et al., 2020), traditional auto-regressive models are still typically of better quality and more widely used for generation (Shwartz et al., 2020). Thus, we limit the scope of this survey to the latter models. 4275 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 4275–4293 August 1–6, 2021. ©2021 Association for Computational Linguistics Demo. Dim. NLG Task Works Gender Autocomplete Bordia and Bowman (2019); Qian et al. (2019); Solaiman et al. (2019); Sheng et al. (2019, 2020); Vig et al. (2020); Yeo and Chen (2020); Brown et al. (2020); Dhamala et al. (2021); Schick et al. (2021); Nozza et al. (2021); Kirk et al. (2021) Dialogue Henderson et al. (2018); Dinan et al. (2020a); Liu et al. (2020a,b); Cercas Curry et al. (2020); Sheng et al. (2021a,b) MT Vanmassenhove et al. (2018); Elaraby et al. (2018); Prates et al. (2019); Stanovsky et al. (2019); Escud´e Font and Costa-juss`a (2019); Cho et al. (2019); Moryossef et al. (2019); Saunders and Byrne (2020); Saunders et al. (2020); Kocmi et al. (2020); Costa-juss`a and"
2021.acl-long.330,2020.acl-main.468,0,0.0284315,"own et al. (2020); Dhamala et al. (2021); Kirk et al. (2021); Abid et al. (2021) Sexuality Autocomplete Sheng et al. (2019, 2020); Kirk et al. (2021) Dialogue Sheng et al. (2021a) Other Autocomplete Shwartz et al. (2020); Peng et al. (2020); Huang et al. (2020); Dhamala et al. (2021); Kirk et al. (2021) Dialogue Sheng et al. (2021a) Re-writing Pryzant et al. (2020); Ma et al. (2020) Table 1: Existing bias studies on different demographic dimensions in various NLG tasks: autocomplete generation, dialogue generation, machine translation (MT), and text re-writing. on mitigating gender biases and Shah et al. (2020) categorize sources of biases—both largely focus on natural language understanding (NLU) tasks, while we examine biases in NLG tasks. Additionally, Blodgett et al. (2020) urge for more explicitly tying “biases” in NLP to societal normative definitions of biases and social hierarchies; with their recommendations in mind, we discuss the negative impacts of biases in NLG techniques. Our contributions are a comprehensive survey on societal biases in language generation and an experimental study on biases from decoding techniques. To start, we describe classes of NLG tasks (Sec. 2) and subsequently"
2021.acl-long.330,2020.wmt-1.73,0,0.183763,"Missing"
2021.acl-long.330,P19-1164,0,0.241972,"l Language Processing, pages 4275–4293 August 1–6, 2021. ©2021 Association for Computational Linguistics Demo. Dim. NLG Task Works Gender Autocomplete Bordia and Bowman (2019); Qian et al. (2019); Solaiman et al. (2019); Sheng et al. (2019, 2020); Vig et al. (2020); Yeo and Chen (2020); Brown et al. (2020); Dhamala et al. (2021); Schick et al. (2021); Nozza et al. (2021); Kirk et al. (2021) Dialogue Henderson et al. (2018); Dinan et al. (2020a); Liu et al. (2020a,b); Cercas Curry et al. (2020); Sheng et al. (2021a,b) MT Vanmassenhove et al. (2018); Elaraby et al. (2018); Prates et al. (2019); Stanovsky et al. (2019); Escud´e Font and Costa-juss`a (2019); Cho et al. (2019); Moryossef et al. (2019); Saunders and Byrne (2020); Saunders et al. (2020); Kocmi et al. (2020); Costa-juss`a and de Jorge (2020); Costa-juss`a et al. (2020); Basta et al. (2020); Farkas and N´emeth (2020); Stafanoviˇcs et al. (2020); Gonen and Webster (2020); Hovy et al. (2020); Roberts et al. (2020); Cho et al. (2021); Savoldi et al. (2021); Renduchintala and Williams (2021); Choubey et al. (2021); Saunders et al. (2021); Tomalin et al. (2021) Re-writing Habash et al. (2019); Zmigrod et al. (2019); Alhafni et al. (2020); Sun et al. ("
2021.acl-long.330,D19-1339,1,0.149455,"ng and Cho, 2019; Chen et al., 2020), traditional auto-regressive models are still typically of better quality and more widely used for generation (Shwartz et al., 2020). Thus, we limit the scope of this survey to the latter models. 4275 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 4275–4293 August 1–6, 2021. ©2021 Association for Computational Linguistics Demo. Dim. NLG Task Works Gender Autocomplete Bordia and Bowman (2019); Qian et al. (2019); Solaiman et al. (2019); Sheng et al. (2019, 2020); Vig et al. (2020); Yeo and Chen (2020); Brown et al. (2020); Dhamala et al. (2021); Schick et al. (2021); Nozza et al. (2021); Kirk et al. (2021) Dialogue Henderson et al. (2018); Dinan et al. (2020a); Liu et al. (2020a,b); Cercas Curry et al. (2020); Sheng et al. (2021a,b) MT Vanmassenhove et al. (2018); Elaraby et al. (2018); Prates et al. (2019); Stanovsky et al. (2019); Escud´e Font and Costa-juss`a (2019); Cho et al. (2019); Moryossef et al. (2019); Saunders and Byrne (2020); Saunders et al. (2020); Kocmi et al. (2020); Costa-juss`a and de Jorge (2020); Costa-juss`a et al. (2020)"
2021.acl-long.330,P19-1159,1,0.832759,"enumerating how NLG techniques contribute to biases and examining progress towards bias analysis and mitigation, we contextualize the discussion of broader trends and challenges. Specifically, we focus on techniques for NLG tasks, i.e., tasks that generate a sequence of text.1 Finding a lack of studies on biases from decoding techniques, we additionally present an experimental study to quantify the effects of various decoding techniques. Before we delve into the details of biases in language generation, we first position our survey in the context of other relevant surveys and position papers. Sun et al. (2019) present a focused survey 1 Although bi-directional language models like BERT (Devlin et al., 2019) can also be used for auto-regressive generation (Wang and Cho, 2019; Chen et al., 2020), traditional auto-regressive models are still typically of better quality and more widely used for generation (Shwartz et al., 2020). Thus, we limit the scope of this survey to the latter models. 4275 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 4275–4293 August 1–6, 2021. ©2021 Associa"
2021.acl-long.330,2020.findings-emnlp.291,1,0.919363,"ls. Dialogue Generation Dialogue generation is conditioned on user inputs and can be for specific domains (e.g., health, customer service) and tasks (e.g., behavior intervention, booking flights) or general chit-chat. These dialogue applications directly interact with users, and any propagated biases directly affect user behavior and actions. In terms of recurrent dialogue models, Henderson et al. (2018) analyze biases in hierarchical recurrent encoder-decoder architectures and Liu et al. (2020a,b) analyze LSTM-based encoder-decoder models. Other works on dialogue biases (Dinan et al., 2020a; Sheng et al., 2020, 2021b) focus on Transformer-based models such as DialoGPT (Zhang et al., 2020) and other custom architectures. 2.2 Transformation Generation Tasks The transformation class includes machine translation and various formulations of text re-writing. The general goal of these tasks is to transform text into a form with targeted properties. Machine Translation Translation is the task of transforming text between languages while preserving the meaning. Existing works on biases in machine translation have almost exclusively focused on issues of gender biases2 in a variety of academic and commercial"
2021.acl-long.330,2021.naacl-main.60,1,0.406202,"the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 4275–4293 August 1–6, 2021. ©2021 Association for Computational Linguistics Demo. Dim. NLG Task Works Gender Autocomplete Bordia and Bowman (2019); Qian et al. (2019); Solaiman et al. (2019); Sheng et al. (2019, 2020); Vig et al. (2020); Yeo and Chen (2020); Brown et al. (2020); Dhamala et al. (2021); Schick et al. (2021); Nozza et al. (2021); Kirk et al. (2021) Dialogue Henderson et al. (2018); Dinan et al. (2020a); Liu et al. (2020a,b); Cercas Curry et al. (2020); Sheng et al. (2021a,b) MT Vanmassenhove et al. (2018); Elaraby et al. (2018); Prates et al. (2019); Stanovsky et al. (2019); Escud´e Font and Costa-juss`a (2019); Cho et al. (2019); Moryossef et al. (2019); Saunders and Byrne (2020); Saunders et al. (2020); Kocmi et al. (2020); Costa-juss`a and de Jorge (2020); Costa-juss`a et al. (2020); Basta et al. (2020); Farkas and N´emeth (2020); Stafanoviˇcs et al. (2020); Gonen and Webster (2020); Hovy et al. (2020); Roberts et al. (2020); Cho et al. (2021); Savoldi et al. (2021); Renduchintala and Williams (2021); Choubey et al. (2021); Saunders et al. (2021); Tomalin"
2021.acl-long.330,2020.gebnlp-1.9,1,0.765887,"etection) for different demographics. Language generation tasks often involve stochastic generation of open-ended and lengthy texts, traits that are not directly compatible with traditional algorithmic bias definitions (e.g., 4 https://www.bing.com/translator https://aws.amazon.com/translate 6 https://www.systransoft.com 7 https://papago.naver.com 8 https://translate.kakao.com 9 https://translate.yandex.com 10 Lucy and Bamman (2021) is an exception that analyzes gender in generated stories. While there are studies of biases in poetry generation and summarization, they focus on non-NLG biases: Sheng and Uthus (2020) investigate biases in a poetry composition system, but in the context of information retrieval; Celis and Keswani (2020) analyze biases in extractive summarization. 4277 5 equalized odds, equal opportunity, demographic parity (Dwork et al., 2012; Hardt et al., 2016)). Because of the difficulty in defining metrics, existing works define bias loosely as demographic inequality and use intermediate proxy metrics to comparatively measure bias. Examples include: • Regard Ratio: negative-neutral-positive regard score ratios of text generated from bias-inducing prompts (Sheng et al., 2019) • Sentimen"
2021.acl-long.330,2020.emnlp-main.556,0,0.0919634,"om decoding techniques, we additionally present an experimental study to quantify the effects of various decoding techniques. Before we delve into the details of biases in language generation, we first position our survey in the context of other relevant surveys and position papers. Sun et al. (2019) present a focused survey 1 Although bi-directional language models like BERT (Devlin et al., 2019) can also be used for auto-regressive generation (Wang and Cho, 2019; Chen et al., 2020), traditional auto-regressive models are still typically of better quality and more widely used for generation (Shwartz et al., 2020). Thus, we limit the scope of this survey to the latter models. 4275 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 4275–4293 August 1–6, 2021. ©2021 Association for Computational Linguistics Demo. Dim. NLG Task Works Gender Autocomplete Bordia and Bowman (2019); Qian et al. (2019); Solaiman et al. (2019); Sheng et al. (2019, 2020); Vig et al. (2020); Yeo and Chen (2020); Brown et al. (2020); Dhamala et al. (2021); Schick et al. (2021); Nozza et al. (2021); Kirk et al. (20"
2021.acl-long.330,2021.naacl-main.189,0,0.190007,"find that more data can increase translation fluency but may also make the system more biased. 4.2 Biases from Model Architecture There are relatively few studies that examine model architectural properties that could lead to biases. We discuss the few efforts towards understanding model biases in NLG tasks and emphasize the need for more to generalize. For autocomplete generation, Vig et al. (2020) analyze GPT-2 variants through a causal mediation analysis, finding that larger models contain more gender bias, and bias tends to be concentrated in a small number of neurons and attention heads. Silva et al. (2021) observe amplified biases in distilled versus original models. For machine translation, Costa-juss`a et al. (2020) note that language-specific architectures are less biased because they encode more gender information than shared language encoder-decoder architectures. Studies like the aforementioned are useful for designing targeted bias mitigation methods (e.g., controlled generation to target specific attention heads or regularization to retain gender information). However, more evidence would be needed to generalize findings across models.15 4.3 Biases from Decoding While NLU and NLG models"
2021.acl-long.330,2020.acl-demos.30,0,0.0695603,"Missing"
2021.acl-long.330,D18-1521,1,0.877643,"Missing"
2021.acl-long.330,P19-1161,0,0.272043,"al. (2018); Prates et al. (2019); Stanovsky et al. (2019); Escud´e Font and Costa-juss`a (2019); Cho et al. (2019); Moryossef et al. (2019); Saunders and Byrne (2020); Saunders et al. (2020); Kocmi et al. (2020); Costa-juss`a and de Jorge (2020); Costa-juss`a et al. (2020); Basta et al. (2020); Farkas and N´emeth (2020); Stafanoviˇcs et al. (2020); Gonen and Webster (2020); Hovy et al. (2020); Roberts et al. (2020); Cho et al. (2021); Savoldi et al. (2021); Renduchintala and Williams (2021); Choubey et al. (2021); Saunders et al. (2021); Tomalin et al. (2021) Re-writing Habash et al. (2019); Zmigrod et al. (2019); Alhafni et al. (2020); Sun et al. (2021) Profession Autocomplete Huang et al. (2020); Dhamala et al. (2021) Race Autocomplete Solaiman et al. (2019); Sheng et al. (2019, 2020); Groenwold et al. (2020); Brown et al. (2020); Dhamala et al. (2021); Schick et al. (2021); Kirk et al. (2021) Dialogue Sheng et al. (2021a,b) Religion Autocomplete Solaiman et al. (2019); Brown et al. (2020); Dhamala et al. (2021); Kirk et al. (2021); Abid et al. (2021) Sexuality Autocomplete Sheng et al. (2019, 2020); Kirk et al. (2021) Dialogue Sheng et al. (2021a) Other Autocomplete Shwartz et al. (2020); Peng et a"
2021.acl-long.340,I17-2016,0,0.0671159,"Missing"
2021.acl-long.340,C18-1275,0,0.0651809,"Missing"
2021.acl-long.340,H90-1021,0,0.410907,"Missing"
2021.acl-long.340,2020.acl-main.703,0,0.0329487,"Missing"
2021.acl-long.340,2021.eacl-main.257,0,0.0304163,"Missing"
2021.acl-long.340,J08-3001,0,0.0175134,"Missing"
2021.acl-long.340,N19-1380,0,0.064325,"Missing"
2021.acl-long.340,P16-1126,1,0.854121,"Missing"
2021.acl-long.340,W18-2608,0,0.0188322,"ent to the service providers to use their services in return. Therefore, automating information extraction from verbose privacy policies can help users understand their rights and make informed decisions. In recent years, we have seen substantial efforts to utilize natural language processing (NLP) techniques to automate privacy policy analysis. In literature, information extraction from policy documents is formulated as text classification (Wilson et al., 2016a; Harkous et al., 2018; Zimmeck et al., 2019), text alignment (Liu et al., 2014; Ramanath et al., 2014), and question answering (QA) (Shvartzshanider et al., 2018; Harkous et al., 2018; Ravichander et al., 2019; Ahmad et al., 2020). Although these approaches effectively identify the sentences or segments in a policy document relevant to a privacy practice, they lack in extracting fine-grained structured information. As shown in the first example in Table 1, the privacy practice label “Data Collection/Usage” informs the user how, why, and what types of user information will be collected by the service provider. The policy also specifies that users’ “username” and “icon or profile photo” will be used for “marketing purposes”. This informs the user precis"
2021.acl-long.340,D19-1585,0,0.062576,"Missing"
2021.acl-long.350,N19-1253,1,0.801193,"th the same color have the same meaning. Although the sentences have a different word order, their syntactic dependency structure is similar. Introduction Cross-lingual transfer reduces the requirement of labeled data to perform natural language processing (NLP) in a target language, and thus has the ability to avail NLP applications in low-resource languages. However, transferring across languages is challenging because of linguistic differences at levels of morphology, syntax, and semantics. For example, word order difference is one of the crucial factors that impact cross-lingual transfer (Ahmad et al., 2019). The two sentences in English and Hindi, as shown in Figure 1 have the same ∗ Work done during internship at Facebook AI. meaning but a different word order (while English has an SVO (Subject-Verb-Object) order, Hindi follows SOV). However, the sentences have a similar dependency structure, and the constituent words have similar part-of-speech tags. Presumably, language syntax can help to bridge the typological differences across languages. In recent years, we have seen a colossal effort to pre-train Transformer encoder (Vaswani et al., 2017) on large-scale unlabeled text data in one or many"
2021.acl-long.350,2020.acl-main.421,0,0.139429,"trees. Named Entity Recognition is a structure prediction task that requires to identify the named entities mentioned in the input sentence. We use the Wikiann dataset (Pan et al., 2017) and a subset of two tasks from CoNLL-2002 (Tjong Kim Sang, 2002) and CoNLL-2003 NER (Tjong Kim Sang and De Meulder, 2003). We collect the CoNLL datasets from XGLUE (Liang et al., 2020). In both datasets, there are 4 types of named entities: Person, Location, Organization, and Miscellaneous.4 Question Answering We evaluate on two crosslingual question answering benchmarks, MLQA (Lewis et al., 2020), and XQuAD (Artetxe et al., 2020). We use the SQuAD dataset (Rajpurkar et al., 2016) for training and validation. In the QA task, the inputs are a question and a context passage that consists of many sentences. We formulate QA as a multi-sentence reading comprehension task; jointly train the models to predict the answer sentence and extract the answer span from it. We concatenate the question and each sentence from the context passage and use the [CLS] token representation to score the candidate sentences. We adopt the confidence method from Clark and Gardner (2018) and pick the highest-scored sentence to extract the answer s"
2021.acl-long.350,D15-1075,0,0.0384827,"s. Presumably, language syntax can help to bridge the typological differences across languages. In recent years, we have seen a colossal effort to pre-train Transformer encoder (Vaswani et al., 2017) on large-scale unlabeled text data in one or many languages. Multilingual encoders, such as mBERT (Devlin et al., 2019) or XLM-R (Conneau et al., 2020) map text sequences into a shared multilingual space by jointly pre-training in many languages. This allows us to transfer the multilingual encoders across languages and have found effective for many NLP applications, including text classification (Bowman et al., 2015; Conneau 4538 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 4538–4554 August 1–6, 2021. ©2021 Association for Computational Linguistics Q English Spanish English C Spanish mBERT A mBERT + Syn. How many members of the Senate are elected? Cu´antos miembros del Senado son elegidos? The Chamber of Deputies has 630 elected members, while the Senate has 315 elected members. . . . La c´amara de los diputados est´a formada por 630 miembros, mientras que hay 315 senadores m´as lo"
2021.acl-long.350,2020.acl-main.147,0,0.20937,"cussion To foster research in this direction, we discuss additional experiment findings. • A natural question is, instead of using GAT, why we do not modify attention heads in mBERT to embed the dependency structure (as shown in Eq. 3). We observed a consistent performance drop across all the tasks if we intervene in self-attention (blocking pair-wise attention). We anticipate fusing GAT encoded syntax representations helps as it adds bias to the self-attention. For future works, we suggest exploring ways of adding structure bias, e.g., scaling attention weights based on dependency structure (Bugliarello and Okazaki, 2020). • Among the evaluation datasets, Wikiann consists of sentence fragments, and the semantic parsing benchmarks consist of user utterances that are typically short in length. Sorting and analyzing the performance improvements based on sequence lengths suggests that the utilization of dependency structure has limited scope for shorter text sequences. However, part-of-speech tags help to identify span boundaries improving the slot filling tasks. 4.4 Limitations and Challenges In this work, we assume we have access to an offthe-shelf universal parser, e.g., UDPipe (Straka and Strakov´a, 2017) or S"
2021.acl-long.350,P17-1177,0,0.024762,"on networks (GAT) (Veliˇckovi´c et al., 2018), a variant of GNN that employs the multihead attention mechanism. Syntax-aware Multi-head Attention A large body of prior works investigated the advantages of incorporating language syntax to enhance the self-attention mechanism (Vaswani et al., 2017). Existing techniques can be broadly divided into two types. The first type of approach relies on an external parser (or human annotation) to get a sentence’s dependency structure during inference. This type of approaches embed the dependency structure into contextual representations (Wu et al., 2017; Chen et al., 2017; Wang et al., 2019a,b; Zhang et al., 2019, 2020; Bugliarello and Okazaki, 2020; Sachan et al., 2021; Ahmad et al., 2021). Our proposed method falls under this category; however, unlike prior works, our study investigates if fusing the universal dependency structure into the self-attention of existing multilingual encoders help cross-lingual transfer. Graph attention networks (GATs) that use multi-head attention has also been adopted for NLP tasks (Huang and Carley, 2019) also fall into this category. The second category of approaches does not require the syntax structure of the input text dur"
2021.acl-long.350,2020.acl-main.493,0,0.0203556,"is followed by “miembros”, while 315 is followed by “senadores” in Spanish. et al., 2018), question answering (Rajpurkar et al., 2016; Lewis et al., 2020), named entity recognition (Pires et al., 2019; Wu and Dredze, 2019), and more. Since the introduction of mBERT, several works (Wu and Dredze, 2019; Pires et al., 2019; K et al., 2020) attempted to reason their success in cross-lingual transfer. In particular, Wu and Dredze (2019) showed that mBERT captures language syntax that makes it effective for cross-lingual transfer. A few recent works (Hewitt and Manning, 2019; Jawahar et al., 2019; Chi et al., 2020) suggest that BERT learns compositional features; mimicking a tree-like structure that agrees with the Universal Dependencies taxonomy. However, fine-tuning for the downstream task in a source language may not require mBERT to retain structural features or learn to encode syntax. We argue that encouraging mBERT to learn the correlation between syntax structure and target labels can benefit cross-lingual transfer. To support our argument, we show an example of question answering (QA) in Figure 2. In the example, mBERT predicts incorrect answers given the Spanish language context that can be cor"
2021.acl-long.350,P18-1078,0,0.0197933,"ion answering benchmarks, MLQA (Lewis et al., 2020), and XQuAD (Artetxe et al., 2020). We use the SQuAD dataset (Rajpurkar et al., 2016) for training and validation. In the QA task, the inputs are a question and a context passage that consists of many sentences. We formulate QA as a multi-sentence reading comprehension task; jointly train the models to predict the answer sentence and extract the answer span from it. We concatenate the question and each sentence from the context passage and use the [CLS] token representation to score the candidate sentences. We adopt the confidence method from Clark and Gardner (2018) and pick the highest-scored sentence to extract the answer span during inference. We provide more details of the QA models in Appendix. Task-oriented Semantic Parsing The fourth evaluation task is cross-lingual task-oriented semantic parsing. In this task, the input is a user utterance and the goal is to predict the intent of the utterance and fill the corresponding slots. We conduct experiments on two recently proposed benchmarks: (i) mTOP (Li et al., 2021) and (ii) mATIS++ (Xu et al., 2020). We jointly train the BERT models as suggested in Chen et al. (2019). We summarize the evaluation tas"
2021.acl-long.350,2020.acl-main.747,0,0.0836037,"Missing"
2021.acl-long.350,D18-1269,0,0.32364,"cy tree structure helps cross-lingual transfer. We perform rigorous experiments on four NLP tasks, including text classification, question answering, named entity recognition, and taskoriented semantic parsing. The experiment results show that syntax-augmented mBERT improves cross-lingual transfer on popular benchmarks, such as PAWS-X and MLQA, by 1.4 and 1.6 points on average across all languages. In the generalized transfer setting, the performance boosted significantly, with 3.9 and 3.1 points on average in PAWS-X and MLQA. 1 Figure 1: Two parallel sentences in English and Hindi from XNLI (Conneau et al., 2018) dataset. The words highlighted with the same color have the same meaning. Although the sentences have a different word order, their syntactic dependency structure is similar. Introduction Cross-lingual transfer reduces the requirement of labeled data to perform natural language processing (NLP) in a target language, and thus has the ability to avail NLP applications in low-resource languages. However, transferring across languages is challenging because of linguistic differences at levels of morphology, syntax, and semantics. For example, word order difference is one of the crucial factors th"
2021.acl-long.350,R19-1028,0,0.02055,"ur proposed method falls under this category; however, unlike prior works, our study investigates if fusing the universal dependency structure into the self-attention of existing multilingual encoders help cross-lingual transfer. Graph attention networks (GATs) that use multi-head attention has also been adopted for NLP tasks (Huang and Carley, 2019) also fall into this category. The second category of approaches does not require the syntax structure of the input text during inference. These approaches are trained to predict the dependency parse via supervised learning (Strubell et al., 2018; Deguchi et al., 2019). 6 Conclusion In this work, we propose incorporating universal language syntax into multilingual BERT (mBERT) 8 This happen for languages, such as Arabic as parsers normalize the input that lead to inconsistent characters between input text and the output tokenized text. by infusing structured representations into its multihead attention mechanism. We employ a modified graph attention network to encode the syntax structure of the input sequences. The results endorse the effectiveness of our proposed approach in the cross-lingual transfer. We discuss limitations and challenges to drive future"
2021.acl-long.350,D19-1549,0,0.0277643,"ucture during inference. This type of approaches embed the dependency structure into contextual representations (Wu et al., 2017; Chen et al., 2017; Wang et al., 2019a,b; Zhang et al., 2019, 2020; Bugliarello and Okazaki, 2020; Sachan et al., 2021; Ahmad et al., 2021). Our proposed method falls under this category; however, unlike prior works, our study investigates if fusing the universal dependency structure into the self-attention of existing multilingual encoders help cross-lingual transfer. Graph attention networks (GATs) that use multi-head attention has also been adopted for NLP tasks (Huang and Carley, 2019) also fall into this category. The second category of approaches does not require the syntax structure of the input text during inference. These approaches are trained to predict the dependency parse via supervised learning (Strubell et al., 2018; Deguchi et al., 2019). 6 Conclusion In this work, we propose incorporating universal language syntax into multilingual BERT (mBERT) 8 This happen for languages, such as Arabic as parsers normalize the input that lead to inconsistent characters between input text and the output tokenized text. by infusing structured representations into its multihead"
2021.acl-long.350,prazak-konopik-2017-cross,0,0.0464265,"Missing"
2021.acl-long.350,2020.acl-demos.14,0,0.0285633,"ng the evaluation datasets, Wikiann consists of sentence fragments, and the semantic parsing benchmarks consist of user utterances that are typically short in length. Sorting and analyzing the performance improvements based on sequence lengths suggests that the utilization of dependency structure has limited scope for shorter text sequences. However, part-of-speech tags help to identify span boundaries improving the slot filling tasks. 4.4 Limitations and Challenges In this work, we assume we have access to an offthe-shelf universal parser, e.g., UDPipe (Straka and Strakov´a, 2017) or Stanza (Qi et al., 2020) to collect part-of-speech tags and the dependency structure of the input sequences. Relying on such a parser has a limitation that it may not support all the languages available in benchmark datasets, e.g., we do not consider Thai and Swahili languages in the benchmark datasets. There are a couple of challenges in utilizing the universal parsers. First, universal parsers tokenize the input sequence into words and provide partof-speech tags and dependencies for them. The tokenized words may not be a part of the input.7 As a result, tasks requiring extracting text spans (e.g., QA) need addition"
2021.acl-long.350,D16-1264,0,0.23039,"0 (7) [Q:English-C:English] 315 (3); [Q:Spanish-C:Spanish] 315 (3) [Q:Spanish-C:English] 315 (3); [Q:English-C:Spanish] 315 (3) Figure 2: A parallel QA example in English (en) and Spanish (es) from MLQA (Lewis et al., 2020) with predictions from mBERT and our proposed syntax-augmented mBERT. In “Q:x-C:y”, x and y indicates question and context languages, respectively. Based on our analysis of the highlighted tokens’ attention weights, we conjecture that mBERT answers 630 as the token is followed by “miembros”, while 315 is followed by “senadores” in Spanish. et al., 2018), question answering (Rajpurkar et al., 2016; Lewis et al., 2020), named entity recognition (Pires et al., 2019; Wu and Dredze, 2019), and more. Since the introduction of mBERT, several works (Wu and Dredze, 2019; Pires et al., 2019; K et al., 2020) attempted to reason their success in cross-lingual transfer. In particular, Wu and Dredze (2019) showed that mBERT captures language syntax that makes it effective for cross-lingual transfer. A few recent works (Hewitt and Manning, 2019; Jawahar et al., 2019; Chi et al., 2020) suggest that BERT learns compositional features; mimicking a tree-like structure that agrees with the Universal Depe"
2021.acl-long.350,2021.eacl-main.228,0,0.0348442,"on mechanism. Syntax-aware Multi-head Attention A large body of prior works investigated the advantages of incorporating language syntax to enhance the self-attention mechanism (Vaswani et al., 2017). Existing techniques can be broadly divided into two types. The first type of approach relies on an external parser (or human annotation) to get a sentence’s dependency structure during inference. This type of approaches embed the dependency structure into contextual representations (Wu et al., 2017; Chen et al., 2017; Wang et al., 2019a,b; Zhang et al., 2019, 2020; Bugliarello and Okazaki, 2020; Sachan et al., 2021; Ahmad et al., 2021). Our proposed method falls under this category; however, unlike prior works, our study investigates if fusing the universal dependency structure into the self-attention of existing multilingual encoders help cross-lingual transfer. Graph attention networks (GATs) that use multi-head attention has also been adopted for NLP tasks (Huang and Carley, 2019) also fall into this category. The second category of approaches does not require the syntax structure of the input text during inference. These approaches are trained to predict the dependency parse via supervised learning"
2021.acl-long.350,K17-3009,0,0.0728998,"Missing"
2021.acl-long.350,D18-1548,0,0.0533004,"Missing"
2021.acl-long.350,D19-1030,0,0.0531307,"Missing"
2021.acl-long.350,D19-1077,0,0.0181633,"5 (3); [Q:English-C:Spanish] 315 (3) Figure 2: A parallel QA example in English (en) and Spanish (es) from MLQA (Lewis et al., 2020) with predictions from mBERT and our proposed syntax-augmented mBERT. In “Q:x-C:y”, x and y indicates question and context languages, respectively. Based on our analysis of the highlighted tokens’ attention weights, we conjecture that mBERT answers 630 as the token is followed by “miembros”, while 315 is followed by “senadores” in Spanish. et al., 2018), question answering (Rajpurkar et al., 2016; Lewis et al., 2020), named entity recognition (Pires et al., 2019; Wu and Dredze, 2019), and more. Since the introduction of mBERT, several works (Wu and Dredze, 2019; Pires et al., 2019; K et al., 2020) attempted to reason their success in cross-lingual transfer. In particular, Wu and Dredze (2019) showed that mBERT captures language syntax that makes it effective for cross-lingual transfer. A few recent works (Hewitt and Manning, 2019; Jawahar et al., 2019; Chi et al., 2020) suggest that BERT learns compositional features; mimicking a tree-like structure that agrees with the Universal Dependencies taxonomy. However, fine-tuning for the downstream task in a source language may"
2021.acl-long.426,D18-1316,1,0.829419,"ERT) for NLP applications. Through extensive experimentation, we demonstrate that our method consistently outperforms recently proposed defense methods by a significant margin across different network architectures and multiple data sets. 1 Introduction Deep neural networks are powerful but vulnerable to adversarial examples that are intentionally crafted to fool the networks. Recent studies have shown the vulnerability of deep neural networks in many NLP tasks, including reading comprehension (Jia and Liang, 2017), text classification (Samanta and Mehta, 2017; Wong, 2017; Liang et al., 2018; Alzantot et al., 2018), machine translation (Zhao et al., 2018; Ebrahimi et al., 2018; Cheng et al., 2018), dialogue systems (Cheng et al., 2019), and dependency parsing (Zheng et al., 2020). These methods attack an NLP model by replacing, scrambling, and erasing characters or words under certain semantic and syntactic constraints. In particular, most of them craft adversarial examples by substituting words with their synonyms in an input text to maximally increase the prediction error while maintaining the adversarial examples’ fluency and naturalness. In this paper, we focus on these word substitution-based threa"
2021.acl-long.426,D15-1075,0,0.01475,"rage length of the sentences in IMDB (255 words on average) is much longer than that in AGNEWS (43 words on average). Longer sentences allow the adversaries to apply more word substitution-based perturbations to the examples. Generally, DNE performs better than IBP and comparable to ADV on the clean data, while it outperforms the others in all other cases. The results for both datasets show that our DNE consistently achieves better clean and robust accuracy. 4.2 Natural Language Inference We conducted the experiments of natural language inference on Stanford Natural Language Inference (SNLI) (Bowman et al., 2015) corpus. We also implemented three models for this task. The bag-ofwords model (BOW) encodes the premise and hypothesis separately by summing their word vectors, then feeds the concatenation of these encodings to a two-layer feedforward network. The other two models are similar, except they run either a Decomposable Attention (DecomAtt) (Parikh et al., 2016) or BERT (Devlin et al., 2019) on the word embeddings to generate the sentence representations, which uses attention between the premise and hypothesis to compute richer representations of each word in both sentences. All models are trained"
2021.acl-long.426,P18-1031,0,0.0592567,"Missing"
2021.acl-long.426,D19-1419,0,0.535586,"be replaced with any of its synonyms. Also, when updating word embeddings during training, the distance between a word and its synonyms in the embedding space change dynamically. Therefore, the point-wise guarantee becomes insufficient, and the resulting models have shown to be vulnerable to strong attacks (Alzantot et al., 2018). On the other hand, several certified defense methods have recently been proposed to ensure that the model predictions are unchanged when input word embeddings are perturbed within the convex hull formed by the embeddings of a word and its synonyms (Jia et al., 2019; Huang et al., 2019). However, due to the difficulty of propagating convex hull through deep neural networks, they compute a loose outer bound using Interval Bound Propagation (IBP). As a result, the convex hull may contain irrelevant words and lead to a significant performance drop on the clean data. In this paper, we propose Dirichlet Neighborhood Ensemble (DNE) to create virtual sentences by mixing the embedding of the original word in the input sentence with its synonyms. By training on these virtual sentences, the model can enhance the robustness against word substitution-based per5482 Proceedings of the 59t"
2021.acl-long.426,D17-1215,0,0.0303089,"riginal clean data. DNE is agnostic to the network architectures and scales to large models (e.g., BERT) for NLP applications. Through extensive experimentation, we demonstrate that our method consistently outperforms recently proposed defense methods by a significant margin across different network architectures and multiple data sets. 1 Introduction Deep neural networks are powerful but vulnerable to adversarial examples that are intentionally crafted to fool the networks. Recent studies have shown the vulnerability of deep neural networks in many NLP tasks, including reading comprehension (Jia and Liang, 2017), text classification (Samanta and Mehta, 2017; Wong, 2017; Liang et al., 2018; Alzantot et al., 2018), machine translation (Zhao et al., 2018; Ebrahimi et al., 2018; Cheng et al., 2018), dialogue systems (Cheng et al., 2019), and dependency parsing (Zheng et al., 2020). These methods attack an NLP model by replacing, scrambling, and erasing characters or words under certain semantic and syntactic constraints. In particular, most of them craft adversarial examples by substituting words with their synonyms in an input text to maximally increase the prediction error while maintaining the adversa"
2021.acl-long.426,D19-1423,0,0.131258,"Missing"
2021.acl-long.426,N19-1336,1,0.849581,"proposed defense methods by a significant margin across different network architectures and multiple data sets. 1 Introduction Deep neural networks are powerful but vulnerable to adversarial examples that are intentionally crafted to fool the networks. Recent studies have shown the vulnerability of deep neural networks in many NLP tasks, including reading comprehension (Jia and Liang, 2017), text classification (Samanta and Mehta, 2017; Wong, 2017; Liang et al., 2018; Alzantot et al., 2018), machine translation (Zhao et al., 2018; Ebrahimi et al., 2018; Cheng et al., 2018), dialogue systems (Cheng et al., 2019), and dependency parsing (Zheng et al., 2020). These methods attack an NLP model by replacing, scrambling, and erasing characters or words under certain semantic and syntactic constraints. In particular, most of them craft adversarial examples by substituting words with their synonyms in an input text to maximally increase the prediction error while maintaining the adversarial examples’ fluency and naturalness. In this paper, we focus on these word substitution-based threat models and discuss the strategy to defend against such attacks. The goal of adversarial defenses is to learn a model capa"
2021.acl-long.426,N19-1423,0,0.228148,"detailed analysis, we found that DNE enables the embeddings of a set of similar words to be updated together in a coordinated way. In contrast, prior approaches either fix the word vectors during training (e.g., in the certified defenses) or update individual word vectors independently (e.g., in the adversarial training). We believe it is the crucial property why DNE leads to a more robust NLP model. Furthermore, unlike most certified defenses, the proposed method is easy to implement and can be integrated into any existing neural network including those with large architecture such as BERT (Devlin et al., 2019). 2 Related Work In the text domain, adversarial training is one of the most successful defenses (Miyato et al., 2017; Sato et al., 2019; Zhu et al., 2019). A family of fast-gradient sign methods (FGSM) was introduced by Goodfellow et al. (2015) to generate adversarial examples in the image domain. They showed that the robustness and generalization of machine learning models could be improved by including high-quality adversarial examples in the training data. Miyato et al. (2017) proposed an FGSMlike adversarial training method to the text domain by applying perturbations to the word embeddin"
2021.acl-long.426,P18-2006,0,0.0537033,"demonstrate that our method consistently outperforms recently proposed defense methods by a significant margin across different network architectures and multiple data sets. 1 Introduction Deep neural networks are powerful but vulnerable to adversarial examples that are intentionally crafted to fool the networks. Recent studies have shown the vulnerability of deep neural networks in many NLP tasks, including reading comprehension (Jia and Liang, 2017), text classification (Samanta and Mehta, 2017; Wong, 2017; Liang et al., 2018; Alzantot et al., 2018), machine translation (Zhao et al., 2018; Ebrahimi et al., 2018; Cheng et al., 2018), dialogue systems (Cheng et al., 2019), and dependency parsing (Zheng et al., 2020). These methods attack an NLP model by replacing, scrambling, and erasing characters or words under certain semantic and syntactic constraints. In particular, most of them craft adversarial examples by substituting words with their synonyms in an input text to maximally increase the prediction error while maintaining the adversarial examples’ fluency and naturalness. In this paper, we focus on these word substitution-based threat models and discuss the strategy to defend against such attack"
2021.acl-long.426,P11-1015,0,0.070819,"is randomly replaced with one of its synonyms. The same random replacement is used in the inference time, and the prediction scores are ensembled to get an output. RAN can be viewed as a variant of SAFER (Ye et al., 2020), where during the training SAFER’s perturbation set is replaced with the synonym set used by the adversaries and the number of ensembles is reduced to 16 (instead of 5, 000) at the inference time, which make it feasible to be evaluated empirically under the attacks. 4.1 Text Classification We experimented on two text classification data sets: Internet Movie Database (IMDB) (Maas et al., 2011) and AG News corpus (AGNEWS) (Zhang et al., 2015). We implemented three models for these text classification tasks like (Jia et al., 2019). The bag-of-words model (BOW) averages the word embeddings for each word in the input, then passes this through a one-layer feedforward network with 100-dimensional hidden state to get a final logit. The other two models are similar, except they run either a CNN or a two-layer LSTM on the word embeddings. All models are trained on cross-entropy loss, and their hyperparameters are tuned on the validation set (see Appendix A.1 for details). Table 1 reports bo"
2021.acl-long.426,N19-1314,0,0.0314359,"Missing"
2021.acl-long.426,D16-1244,0,0.0787179,"Missing"
2021.acl-long.426,D14-1162,0,0.0973367,"Missing"
2021.acl-long.426,2020.acl-main.590,1,0.800866,"rgin across different network architectures and multiple data sets. 1 Introduction Deep neural networks are powerful but vulnerable to adversarial examples that are intentionally crafted to fool the networks. Recent studies have shown the vulnerability of deep neural networks in many NLP tasks, including reading comprehension (Jia and Liang, 2017), text classification (Samanta and Mehta, 2017; Wong, 2017; Liang et al., 2018; Alzantot et al., 2018), machine translation (Zhao et al., 2018; Ebrahimi et al., 2018; Cheng et al., 2018), dialogue systems (Cheng et al., 2019), and dependency parsing (Zheng et al., 2020). These methods attack an NLP model by replacing, scrambling, and erasing characters or words under certain semantic and syntactic constraints. In particular, most of them craft adversarial examples by substituting words with their synonyms in an input text to maximally increase the prediction error while maintaining the adversarial examples’ fluency and naturalness. In this paper, we focus on these word substitution-based threat models and discuss the strategy to defend against such attacks. The goal of adversarial defenses is to learn a model capable of achieving high test accuracy on both c"
2021.acl-long.426,P19-1103,0,0.0614039,"Missing"
2021.acl-long.426,2020.acl-main.317,0,0.643337,"to formally verify a model’s robustness against word substitutionbased perturbations. Shi et al. (2020) and Xu et al. (2020) proposed the robustness verification and training method for transformers based on linear relaxation-based perturbation analysis. However, these defenses often lead to loose upper bounds for arbitrary networks and result in a higher cost of clean accuracy. Furthermore, due to the difficulty of verification, certified defense methods are usually not scalable and remain hard to scale to complex prediction pipelines. To achieve certified robustness on large architectures, Ye et al. (2020) proposed a certified robust method called SAFER which is structure-free. However, the base classifier of SAFER is trained by the adversarial data augmentation. As shown in our experiments, randomly perturbing a word to its synonyms performs poorly in practice. In the image domain, randomization has been shown to overcome many of these obstacles in the IBP-based defense. Empirically, Xie et al. (2017) showed that random resizing and padding in the input domain could improve the robustness. Liu et al. (2018) proposed to add Gaussian noise in both the input layer and intermediate layers of CNN i"
2021.eacl-main.88,D18-1316,1,0.860549,"e 3: Influence of word drop out rate. Setting the word dropout rate to 0.4 can achieve the best BLEU score. However, higher word dropout rate leads to better template matching accuracy. ent word dropout rates and report the BLEU scores and the template matching accuracy in Figure 3. From Figure 3a, we can observe that setting the word dropout rate to 0.4 can achieve the best BLEU score in most of datasets. The only exception is ParaNMT, which is the dataset used Improving Robustness of Models Recently, a lot of work show that NLP models can be fooled by different types of adversarial attacks (Alzantot et al., 2018; Ebrahimi et al., 2018; Iyyer et al., 2018; Tan et al., 2020; Jin et al., 2020). Those attacks generate adversarial examples by slightly modifying the original sentences without changing the meanings, while the NLP models change the predictions on those examples. However, a robust model is expected to output the same labels. Therefore, how to make NLP models not affected by the adversarial examples becomes an important task. Since SynPG is able to generate syntactically different paraphrases, we can improve the robustness of NLP models by data augmentation. The models trained with data augmen"
2021.eacl-main.88,P19-1602,0,0.0785822,"s sentiment (Shen et al., 2017; Hu et al., 2017; Fu et al., 2018; Peng et al., 2018; Dai et al., 2019), tense (Logeswaran et al., 2018), plots (Ammanabrolu et al., 2020; Fan et al., 2019; Tambwekar et al., 2019; Yao et al., 2019; GoldfarbTarrant et al., 2019, 2020), societal bias (Wallace et al., 2019; Sheng et al., 2020b,a), and syntax (Iyyer et al., 2018; Goyal and Durrett, 2020; Kumar et al., 2020). The second family controls the attributes by learning disentangled representations. For example, Romanov et al. (2019) disentangle the meaning and the form of a sentence. Chen et al. (2019b,a); Bao et al. (2019) disentangle the semantics and the syntax of a sentence. 7 Conclusion We present syntactically controlled paraphrase generator (SynPG), an paraphrase model that can control the syntax of generated paraphrases based on the given syntactic specifications. SynPG is designed to disentangle the semantics and the syntax of sentences. The disentanglement enables SynPG to be trained without the need for annotated paraphrase pairs. Extensive experiments show that SynPG performs better syntactic control than unsupervised baselines, while the quality of the generated paraphrases is competitive to supervi"
2021.eacl-main.88,N03-1003,0,0.334316,"augmentation (Base) and with data augmentation (SynPG) in Table 7. We observe that with the data augmentation, the accuracy before attacking is slightly worse than Base. However, after attacking, the percentage of examples changing predictions is much less than Base, which implies that data augmentation indeed improves the robustness of models. 6 Related Work Paraphrase generation. Traditional approaches usually require hand-crafted rules, such as rulebased methods (McKeown, 1983), thesaurus-based methods (Bolshakov and Gelbukh, 2004; Kauchak and Barzilay, 2006), and lattice matching methods (Barzilay and Lee, 2003). However, the diversity of their generated paraphrases is usually limited. Recently, neural models make success on paraphrase generation (Prakash et al., 2016; Mallinson et al., 2017; Cao et al., 2017; Egonmwan and Chali, 2019; Li et al., 2019; Gupta et al., 2018). These approaches treat paraphrase generation as a translation task and design seq2seq models based on a large amount of parallel data. To reduce the effort to collect parallel data, unsupervised paraphrase generation has attracted attention in recent years. Wieting et al. (2017); Wieting and Gimpel (2018) use translation models to"
2021.eacl-main.88,K16-1002,0,0.183326,"Missing"
2021.eacl-main.88,P19-1599,0,0.0673293,"the attributes, such as sentiment (Shen et al., 2017; Hu et al., 2017; Fu et al., 2018; Peng et al., 2018; Dai et al., 2019), tense (Logeswaran et al., 2018), plots (Ammanabrolu et al., 2020; Fan et al., 2019; Tambwekar et al., 2019; Yao et al., 2019; GoldfarbTarrant et al., 2019, 2020), societal bias (Wallace et al., 2019; Sheng et al., 2020b,a), and syntax (Iyyer et al., 2018; Goyal and Durrett, 2020; Kumar et al., 2020). The second family controls the attributes by learning disentangled representations. For example, Romanov et al. (2019) disentangle the meaning and the form of a sentence. Chen et al. (2019b,a); Bao et al. (2019) disentangle the semantics and the syntax of a sentence. 7 Conclusion We present syntactically controlled paraphrase generator (SynPG), an paraphrase model that can control the syntax of generated paraphrases based on the given syntactic specifications. SynPG is designed to disentangle the semantics and the syntax of sentences. The disentanglement enables SynPG to be trained without the need for annotated paraphrase pairs. Extensive experiments show that SynPG performs better syntactic control than unsupervised baselines, while the quality of the generated paraphrases is"
2021.eacl-main.88,N19-1254,0,0.200294,"the attributes, such as sentiment (Shen et al., 2017; Hu et al., 2017; Fu et al., 2018; Peng et al., 2018; Dai et al., 2019), tense (Logeswaran et al., 2018), plots (Ammanabrolu et al., 2020; Fan et al., 2019; Tambwekar et al., 2019; Yao et al., 2019; GoldfarbTarrant et al., 2019, 2020), societal bias (Wallace et al., 2019; Sheng et al., 2020b,a), and syntax (Iyyer et al., 2018; Goyal and Durrett, 2020; Kumar et al., 2020). The second family controls the attributes by learning disentangled representations. For example, Romanov et al. (2019) disentangle the meaning and the form of a sentence. Chen et al. (2019b,a); Bao et al. (2019) disentangle the semantics and the syntax of a sentence. 7 Conclusion We present syntactically controlled paraphrase generator (SynPG), an paraphrase model that can control the syntax of generated paraphrases based on the given syntactic specifications. SynPG is designed to disentangle the semantics and the syntax of sentences. The disentanglement enables SynPG to be trained without the need for annotated paraphrase pairs. Extensive experiments show that SynPG performs better syntactic control than unsupervised baselines, while the quality of the generated paraphrases is"
2021.eacl-main.88,P19-1601,0,0.0249461,"ls based on a large amount of parallel data. To reduce the effort to collect parallel data, unsupervised paraphrase generation has attracted attention in recent years. Wieting et al. (2017); Wieting and Gimpel (2018) use translation models to generate paraphrases via back-translation. Zhang et al. (2019); Roy and Controlled generation. Recent work on controlled generation can be grouped into two families. The first family is doing end-to-end training with an additional trigger to control the attributes, such as sentiment (Shen et al., 2017; Hu et al., 2017; Fu et al., 2018; Peng et al., 2018; Dai et al., 2019), tense (Logeswaran et al., 2018), plots (Ammanabrolu et al., 2020; Fan et al., 2019; Tambwekar et al., 2019; Yao et al., 2019; GoldfarbTarrant et al., 2019, 2020), societal bias (Wallace et al., 2019; Sheng et al., 2020b,a), and syntax (Iyyer et al., 2018; Goyal and Durrett, 2020; Kumar et al., 2020). The second family controls the attributes by learning disentangled representations. For example, Romanov et al. (2019) disentangle the meaning and the form of a sentence. Chen et al. (2019b,a); Bao et al. (2019) disentangle the semantics and the syntax of a sentence. 7 Conclusion We present synt"
2021.eacl-main.88,C04-1051,0,0.825759,"embedding including only the syntactic information. Then, the decoder combines the two representations and generates a paraphrase sentence. The design of disentangling semantics and syntax enables SynPG to learn the association between words and parses and be trained by reconstructing the source sentence given its unordered words and its parse. Therefore, we do not require any annotated paraphrase pairs but only unannotated texts to train SynPG. We verify SynPG on four paraphrase datasets: ParaNMT-50M (Wieting and Gimpel, 2018), Quora (Iyer et al., 2017), PAN (Madnani et al., 2012), and MRPC (Dolan et al., 2004). The experimental results reveal that when being provided with the syntactic structures of the target sentences, SynPG can generate paraphrases with the syntax more similar to the ground truth than the unsupervised baselines. The human evaluation results indicate that SynPG achieves competitive paraphrase quality to other baselines while its generated paraphrases are more accurate in following the syntactic specifications. In addition, we show that when the training data is large enough, the performance of SynPG is competitive or even better than supervised approaches. Finally, we demonstrate"
2021.eacl-main.88,P18-2006,0,0.0345613,"drop out rate. Setting the word dropout rate to 0.4 can achieve the best BLEU score. However, higher word dropout rate leads to better template matching accuracy. ent word dropout rates and report the BLEU scores and the template matching accuracy in Figure 3. From Figure 3a, we can observe that setting the word dropout rate to 0.4 can achieve the best BLEU score in most of datasets. The only exception is ParaNMT, which is the dataset used Improving Robustness of Models Recently, a lot of work show that NLP models can be fooled by different types of adversarial attacks (Alzantot et al., 2018; Ebrahimi et al., 2018; Iyyer et al., 2018; Tan et al., 2020; Jin et al., 2020). Those attacks generate adversarial examples by slightly modifying the original sentences without changing the meanings, while the NLP models change the predictions on those examples. However, a robust model is expected to output the same labels. Therefore, how to make NLP models not affected by the adversarial examples becomes an important task. Since SynPG is able to generate syntactically different paraphrases, we can improve the robustness of NLP models by data augmentation. The models trained with data augmentation are thus more ro"
2021.eacl-main.88,D19-5627,0,0.060792,"recently developed machine learning approaches and large data collections. Paraphrase generation demonstrates the potential of machines in semantic abstraction and sentence reorganization and has already been applied to many NLP downstream applications, such as question answering (Yu et al., 2018), chatbot engines (Yan et al., 2016), and sentence simplification (Zhao et al., 2018). In recent years, various approaches have been proposed to train sequence-to-sequence (seq2seq) models on a large number of annotated paraphrase pairs (Prakash et al., 2016; Mallinson et al., 2017; Cao et al., 2017; Egonmwan and Chali, 2019). Some of them control the syntax of output sentences to improve the diversity of paraphrase generation (Iyyer et al., 2018; Goyal and Durrett, 2020; Kumar et al., 2020). However, collecting annotated pairs is expensive and induces challenges for some languages and domains. On the contrary, unsupervised approaches build paraphrase models without using parallel corpora (Li et al., 2018; Roy and Grangier, 2019; Zhang et al., 2019). Most of them are based on the variational autoencoder (Bowman et al., 2016) or back-translation (Mallinson et al., 2017; Wieting and Gimpel, 2018; Hu et al., 2019). N"
2021.eacl-main.88,P19-1254,0,0.0277166,"data, unsupervised paraphrase generation has attracted attention in recent years. Wieting et al. (2017); Wieting and Gimpel (2018) use translation models to generate paraphrases via back-translation. Zhang et al. (2019); Roy and Controlled generation. Recent work on controlled generation can be grouped into two families. The first family is doing end-to-end training with an additional trigger to control the attributes, such as sentiment (Shen et al., 2017; Hu et al., 2017; Fu et al., 2018; Peng et al., 2018; Dai et al., 2019), tense (Logeswaran et al., 2018), plots (Ammanabrolu et al., 2020; Fan et al., 2019; Tambwekar et al., 2019; Yao et al., 2019; GoldfarbTarrant et al., 2019, 2020), societal bias (Wallace et al., 2019; Sheng et al., 2020b,a), and syntax (Iyyer et al., 2018; Goyal and Durrett, 2020; Kumar et al., 2020). The second family controls the attributes by learning disentangled representations. For example, Romanov et al. (2019) disentangle the meaning and the form of a sentence. Chen et al. (2019b,a); Bao et al. (2019) disentangle the semantics and the syntax of a sentence. 7 Conclusion We present syntactically controlled paraphrase generator (SynPG), an paraphrase model that can cont"
2021.eacl-main.88,2020.emnlp-main.351,0,0.0755664,"Missing"
2021.eacl-main.88,N19-4016,0,0.0276171,"Missing"
2021.eacl-main.88,2020.acl-main.22,0,0.633917,"straction and sentence reorganization and has already been applied to many NLP downstream applications, such as question answering (Yu et al., 2018), chatbot engines (Yan et al., 2016), and sentence simplification (Zhao et al., 2018). In recent years, various approaches have been proposed to train sequence-to-sequence (seq2seq) models on a large number of annotated paraphrase pairs (Prakash et al., 2016; Mallinson et al., 2017; Cao et al., 2017; Egonmwan and Chali, 2019). Some of them control the syntax of output sentences to improve the diversity of paraphrase generation (Iyyer et al., 2018; Goyal and Durrett, 2020; Kumar et al., 2020). However, collecting annotated pairs is expensive and induces challenges for some languages and domains. On the contrary, unsupervised approaches build paraphrase models without using parallel corpora (Li et al., 2018; Roy and Grangier, 2019; Zhang et al., 2019). Most of them are based on the variational autoencoder (Bowman et al., 2016) or back-translation (Mallinson et al., 2017; Wieting and Gimpel, 2018; Hu et al., 2019). Nevertheless, without the consideration of controlling syntax, their generated paraphrases are often similar to the source sentences and are not dive"
2021.eacl-main.88,N18-1170,0,0.0814358,"hines in semantic abstraction and sentence reorganization and has already been applied to many NLP downstream applications, such as question answering (Yu et al., 2018), chatbot engines (Yan et al., 2016), and sentence simplification (Zhao et al., 2018). In recent years, various approaches have been proposed to train sequence-to-sequence (seq2seq) models on a large number of annotated paraphrase pairs (Prakash et al., 2016; Mallinson et al., 2017; Cao et al., 2017; Egonmwan and Chali, 2019). Some of them control the syntax of output sentences to improve the diversity of paraphrase generation (Iyyer et al., 2018; Goyal and Durrett, 2020; Kumar et al., 2020). However, collecting annotated pairs is expensive and induces challenges for some languages and domains. On the contrary, unsupervised approaches build paraphrase models without using parallel corpora (Li et al., 2018; Roy and Grangier, 2019; Zhang et al., 2019). Most of them are based on the variational autoencoder (Bowman et al., 2016) or back-translation (Mallinson et al., 2017; Wieting and Gimpel, 2018; Hu et al., 2019). Nevertheless, without the consideration of controlling syntax, their generated paraphrases are often similar to the source s"
2021.eacl-main.88,J83-1001,0,0.677966,"Missing"
2021.eacl-main.88,N06-1058,0,0.128678,"attack to be successful. We compare the model without data augmentation (Base) and with data augmentation (SynPG) in Table 7. We observe that with the data augmentation, the accuracy before attacking is slightly worse than Base. However, after attacking, the percentage of examples changing predictions is much less than Base, which implies that data augmentation indeed improves the robustness of models. 6 Related Work Paraphrase generation. Traditional approaches usually require hand-crafted rules, such as rulebased methods (McKeown, 1983), thesaurus-based methods (Bolshakov and Gelbukh, 2004; Kauchak and Barzilay, 2006), and lattice matching methods (Barzilay and Lee, 2003). However, the diversity of their generated paraphrases is usually limited. Recently, neural models make success on paraphrase generation (Prakash et al., 2016; Mallinson et al., 2017; Cao et al., 2017; Egonmwan and Chali, 2019; Li et al., 2019; Gupta et al., 2018). These approaches treat paraphrase generation as a translation task and design seq2seq models based on a large amount of parallel data. To reduce the effort to collect parallel data, unsupervised paraphrase generation has attracted attention in recent years. Wieting et al. (2017"
2021.eacl-main.88,N10-1017,0,0.047078,"therefore get low template matching scores. Table 2 lists some paraphrase examples generated by all models. Again, we observe that without syntactic specifications, the paraphrases generated by unsupervised baselines are similar to the source sentences. Without the disentanglement, Seq2seqSyn and SIVAE always copy the source sentences. SynPG is the only model can generate paraphrases syntactically similar to the ground truths. 4.2 Human Evaluation We perform human evaluation using Amazon Mechanical Turk to evaluate the quality of generated paraphrases. We follow the setting of previous work (Kok and Brockett, 2010; Iyyer et al., 2018; Goyal and Durrett, 2020). For each model, we randomly select 100 pairs of source sentence x and the corresponding generated paraphrase y from ParaNMT-50M test set (after being post-processed as mentioned in Section 2.3) and have three Turkers annotate each pair. The annotations are on a three-point scale: 0 means y is not a paraphrase of x; 1 means x is paraphrased into y but y contains some grammatical errors; 2 means x is paraphrased into y, which is grammatically correct. The results of human evaluation are reported in Table 3. If paraphrases rated 1 or 2 are considere"
2021.eacl-main.88,2020.tacl-1.22,0,0.559424,"organization and has already been applied to many NLP downstream applications, such as question answering (Yu et al., 2018), chatbot engines (Yan et al., 2016), and sentence simplification (Zhao et al., 2018). In recent years, various approaches have been proposed to train sequence-to-sequence (seq2seq) models on a large number of annotated paraphrase pairs (Prakash et al., 2016; Mallinson et al., 2017; Cao et al., 2017; Egonmwan and Chali, 2019). Some of them control the syntax of output sentences to improve the diversity of paraphrase generation (Iyyer et al., 2018; Goyal and Durrett, 2020; Kumar et al., 2020). However, collecting annotated pairs is expensive and induces challenges for some languages and domains. On the contrary, unsupervised approaches build paraphrase models without using parallel corpora (Li et al., 2018; Roy and Grangier, 2019; Zhang et al., 2019). Most of them are based on the variational autoencoder (Bowman et al., 2016) or back-translation (Mallinson et al., 2017; Wieting and Gimpel, 2018; Hu et al., 2019). Nevertheless, without the consideration of controlling syntax, their generated paraphrases are often similar to the source sentences and are not diverse in syntax. This p"
2021.eacl-main.88,D18-1421,0,0.119446,"ars, various approaches have been proposed to train sequence-to-sequence (seq2seq) models on a large number of annotated paraphrase pairs (Prakash et al., 2016; Mallinson et al., 2017; Cao et al., 2017; Egonmwan and Chali, 2019). Some of them control the syntax of output sentences to improve the diversity of paraphrase generation (Iyyer et al., 2018; Goyal and Durrett, 2020; Kumar et al., 2020). However, collecting annotated pairs is expensive and induces challenges for some languages and domains. On the contrary, unsupervised approaches build paraphrase models without using parallel corpora (Li et al., 2018; Roy and Grangier, 2019; Zhang et al., 2019). Most of them are based on the variational autoencoder (Bowman et al., 2016) or back-translation (Mallinson et al., 2017; Wieting and Gimpel, 2018; Hu et al., 2019). Nevertheless, without the consideration of controlling syntax, their generated paraphrases are often similar to the source sentences and are not diverse in syntax. This paper presents a pioneering study on syntactically controlled paraphrase generation based 1022 Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics, pages 1022–1033"
2021.eacl-main.88,P19-1332,0,0.0344528,"less than Base, which implies that data augmentation indeed improves the robustness of models. 6 Related Work Paraphrase generation. Traditional approaches usually require hand-crafted rules, such as rulebased methods (McKeown, 1983), thesaurus-based methods (Bolshakov and Gelbukh, 2004; Kauchak and Barzilay, 2006), and lattice matching methods (Barzilay and Lee, 2003). However, the diversity of their generated paraphrases is usually limited. Recently, neural models make success on paraphrase generation (Prakash et al., 2016; Mallinson et al., 2017; Cao et al., 2017; Egonmwan and Chali, 2019; Li et al., 2019; Gupta et al., 2018). These approaches treat paraphrase generation as a translation task and design seq2seq models based on a large amount of parallel data. To reduce the effort to collect parallel data, unsupervised paraphrase generation has attracted attention in recent years. Wieting et al. (2017); Wieting and Gimpel (2018) use translation models to generate paraphrases via back-translation. Zhang et al. (2019); Roy and Controlled generation. Recent work on controlled generation can be grouped into two families. The first family is doing end-to-end training with an additional trigger to co"
2021.eacl-main.88,N12-1019,0,0.127118,"rget parse into a contextualized embedding including only the syntactic information. Then, the decoder combines the two representations and generates a paraphrase sentence. The design of disentangling semantics and syntax enables SynPG to learn the association between words and parses and be trained by reconstructing the source sentence given its unordered words and its parse. Therefore, we do not require any annotated paraphrase pairs but only unannotated texts to train SynPG. We verify SynPG on four paraphrase datasets: ParaNMT-50M (Wieting and Gimpel, 2018), Quora (Iyer et al., 2017), PAN (Madnani et al., 2012), and MRPC (Dolan et al., 2004). The experimental results reveal that when being provided with the syntactic structures of the target sentences, SynPG can generate paraphrases with the syntax more similar to the ground truth than the unsupervised baselines. The human evaluation results indicate that SynPG achieves competitive paraphrase quality to other baselines while its generated paraphrases are more accurate in following the syntactic specifications. In addition, we show that when the training data is large enough, the performance of SynPG is competitive or even better than supervised appr"
2021.eacl-main.88,W19-5333,0,0.0181534,"paraphrase y, we get their parses (p2 and py ) and templates (t2 and ty ). Then, we calculate the percentage of pairs whose ty exactly matches t2 as the template matching accuracy. 3.3 Models for Comparison We consider the following unsupervised paraphrase models: 1) CopyInput: a na¨ıve baseline which directly copies the source sentence as the output without paraphrasing. 2) BackTrans: back-translation is proposed to generate paraphrases (Mallinson et al., 2017; Wieting and Gimpel, 2018; Hu et al., 2019). In our experiment, we use the pretrained EN-DE and DE-EN translation models4 proposed by Ng et al. (2019) to conduct back-translation. 4 Notice that training translation models requires additional translation pairs. Therefore, BackTrans needs more resources than ours and the translation data may not available for some low-resource languages. 3) VAE: we consider a vanilla variational autoencoder (Bowman et al., 2016) as a simple baseline. 4) SIVAE: syntax-infused variational autoencoder (Zhang et al., 2019) utilizes additional syntax information to improve the quality of sentence generation and paraphrase generation. Unlike SynPG, SIVAE does not disentangle the semantics and syntax. 5) Seq2seq-Syn"
2021.eacl-main.88,P02-1040,0,0.113912,"tasets: 1) Quora (Iyer et al., 2017) contains over 400,000 paraphrase pairs and we sample 6,400 pairs from them. 2) PAN (Madnani et al., 2012) contains 5,000 paraphrase pairs. 3) MRPC (Dolan et al., 2004) contains 2,753 paraphrase pairs. 3.2 Evaluation We consider paraphrase pairs to evaluate all the models. For each test paraphrase pair (x1 , x2 ), we consider x1 as the source sentence and treat x2 as the target sentence (ground truth). Let p2 be the parse of x2 , given (x1 , p2 ), The model is expected to generate a paraphrase y that is similar to the target sentence x2 . We use BLEU score (Papineni et al., 2002) and human evaluation to measure the similarity between x2 and y. Moreover, to evaluate how well the generated paraphrase y follows the target parse p2 , we define the template matching accuracy (TMA) as follows. For each ground truth sentence x2 and the corresponding generated paraphrase y, we get their parses (p2 and py ) and templates (t2 and ty ). Then, we calculate the percentage of pairs whose ty exactly matches t2 as the template matching accuracy. 3.3 Models for Comparison We consider the following unsupervised paraphrase models: 1) CopyInput: a na¨ıve baseline which directly copies th"
2021.eacl-main.88,W18-1505,0,0.0285966,"design seq2seq models based on a large amount of parallel data. To reduce the effort to collect parallel data, unsupervised paraphrase generation has attracted attention in recent years. Wieting et al. (2017); Wieting and Gimpel (2018) use translation models to generate paraphrases via back-translation. Zhang et al. (2019); Roy and Controlled generation. Recent work on controlled generation can be grouped into two families. The first family is doing end-to-end training with an additional trigger to control the attributes, such as sentiment (Shen et al., 2017; Hu et al., 2017; Fu et al., 2018; Peng et al., 2018; Dai et al., 2019), tense (Logeswaran et al., 2018), plots (Ammanabrolu et al., 2020; Fan et al., 2019; Tambwekar et al., 2019; Yao et al., 2019; GoldfarbTarrant et al., 2019, 2020), societal bias (Wallace et al., 2019; Sheng et al., 2020b,a), and syntax (Iyyer et al., 2018; Goyal and Durrett, 2020; Kumar et al., 2020). The second family controls the attributes by learning disentangled representations. For example, Romanov et al. (2019) disentangle the meaning and the form of a sentence. Chen et al. (2019b,a); Bao et al. (2019) disentangle the semantics and the syntax of a sentence. 7 Conclus"
2021.eacl-main.88,D14-1162,0,0.0838927,"Missing"
2021.eacl-main.88,C16-1275,0,0.222486,"ural language processing (NLP) and has been greatly improved by recently developed machine learning approaches and large data collections. Paraphrase generation demonstrates the potential of machines in semantic abstraction and sentence reorganization and has already been applied to many NLP downstream applications, such as question answering (Yu et al., 2018), chatbot engines (Yan et al., 2016), and sentence simplification (Zhao et al., 2018). In recent years, various approaches have been proposed to train sequence-to-sequence (seq2seq) models on a large number of annotated paraphrase pairs (Prakash et al., 2016; Mallinson et al., 2017; Cao et al., 2017; Egonmwan and Chali, 2019). Some of them control the syntax of output sentences to improve the diversity of paraphrase generation (Iyyer et al., 2018; Goyal and Durrett, 2020; Kumar et al., 2020). However, collecting annotated pairs is expensive and induces challenges for some languages and domains. On the contrary, unsupervised approaches build paraphrase models without using parallel corpora (Li et al., 2018; Roy and Grangier, 2019; Zhang et al., 2019). Most of them are based on the variational autoencoder (Bowman et al., 2016) or back-translation ("
2021.eacl-main.88,N19-1088,0,0.0220668,"family is doing end-to-end training with an additional trigger to control the attributes, such as sentiment (Shen et al., 2017; Hu et al., 2017; Fu et al., 2018; Peng et al., 2018; Dai et al., 2019), tense (Logeswaran et al., 2018), plots (Ammanabrolu et al., 2020; Fan et al., 2019; Tambwekar et al., 2019; Yao et al., 2019; GoldfarbTarrant et al., 2019, 2020), societal bias (Wallace et al., 2019; Sheng et al., 2020b,a), and syntax (Iyyer et al., 2018; Goyal and Durrett, 2020; Kumar et al., 2020). The second family controls the attributes by learning disentangled representations. For example, Romanov et al. (2019) disentangle the meaning and the form of a sentence. Chen et al. (2019b,a); Bao et al. (2019) disentangle the semantics and the syntax of a sentence. 7 Conclusion We present syntactically controlled paraphrase generator (SynPG), an paraphrase model that can control the syntax of generated paraphrases based on the given syntactic specifications. SynPG is designed to disentangle the semantics and the syntax of sentences. The disentanglement enables SynPG to be trained without the need for annotated paraphrase pairs. Extensive experiments show that SynPG performs better syntactic control than uns"
2021.eacl-main.88,P19-1605,0,0.0402786,"oaches have been proposed to train sequence-to-sequence (seq2seq) models on a large number of annotated paraphrase pairs (Prakash et al., 2016; Mallinson et al., 2017; Cao et al., 2017; Egonmwan and Chali, 2019). Some of them control the syntax of output sentences to improve the diversity of paraphrase generation (Iyyer et al., 2018; Goyal and Durrett, 2020; Kumar et al., 2020). However, collecting annotated pairs is expensive and induces challenges for some languages and domains. On the contrary, unsupervised approaches build paraphrase models without using parallel corpora (Li et al., 2018; Roy and Grangier, 2019; Zhang et al., 2019). Most of them are based on the variational autoencoder (Bowman et al., 2016) or back-translation (Mallinson et al., 2017; Wieting and Gimpel, 2018; Hu et al., 2019). Nevertheless, without the consideration of controlling syntax, their generated paraphrases are often similar to the source sentences and are not diverse in syntax. This paper presents a pioneering study on syntactically controlled paraphrase generation based 1022 Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics, pages 1022–1033 April 19 - 23, 2021. ©2"
2021.eacl-main.88,P16-1162,0,0.0207129,"from (x, px ) without the disentanglement. We use this model to study the influence of the disentanglement. 6) SynPG: our proposed model which learns disentangled embeddings. We also compare SynPG with supervised approaches. We consider the following: 1) Seq2seqSup: a seq2seq model with Transformer architecture trained on whole ParaNMT-50M pairs. 2) SCPN: syntactically controlled paraphrase network (Iyyer et al., 2018) is a supervised paraphrase model with syntactic control trained on ParaNMT50M pairs. We use their pretrained model5 . 3.4 Implementation Details We consider byte pair encoding (Sennrich et al., 2016) for tokenization and use Stanford CoreNLP parser (Manning et al., 2014) to get constituency parses. We set the max length of sentences to 40 and set the max length of linearized parses to 160 for all the models. For the encoders and the decoder of SynPG, we use the standard Transformer (Vaswani et al., 2017) with default parameters. The word embedding is initialized by GloVe (Pennington et al., 2014). We use Adam optimizer with the learning rate being 10−4 and the weight decay being 10−5 . We set the word dropout probability to 0.4 (more discussion in Section 4.5). The number of epoch for tra"
2021.eacl-main.88,E17-1083,0,0.502815,"ng (NLP) and has been greatly improved by recently developed machine learning approaches and large data collections. Paraphrase generation demonstrates the potential of machines in semantic abstraction and sentence reorganization and has already been applied to many NLP downstream applications, such as question answering (Yu et al., 2018), chatbot engines (Yan et al., 2016), and sentence simplification (Zhao et al., 2018). In recent years, various approaches have been proposed to train sequence-to-sequence (seq2seq) models on a large number of annotated paraphrase pairs (Prakash et al., 2016; Mallinson et al., 2017; Cao et al., 2017; Egonmwan and Chali, 2019). Some of them control the syntax of output sentences to improve the diversity of paraphrase generation (Iyyer et al., 2018; Goyal and Durrett, 2020; Kumar et al., 2020). However, collecting annotated pairs is expensive and induces challenges for some languages and domains. On the contrary, unsupervised approaches build paraphrase models without using parallel corpora (Li et al., 2018; Roy and Grangier, 2019; Zhang et al., 2019). Most of them are based on the variational autoencoder (Bowman et al., 2016) or back-translation (Mallinson et al., 2017;"
2021.eacl-main.88,2020.acl-main.263,0,0.0136885,"e to 0.4 can achieve the best BLEU score. However, higher word dropout rate leads to better template matching accuracy. ent word dropout rates and report the BLEU scores and the template matching accuracy in Figure 3. From Figure 3a, we can observe that setting the word dropout rate to 0.4 can achieve the best BLEU score in most of datasets. The only exception is ParaNMT, which is the dataset used Improving Robustness of Models Recently, a lot of work show that NLP models can be fooled by different types of adversarial attacks (Alzantot et al., 2018; Ebrahimi et al., 2018; Iyyer et al., 2018; Tan et al., 2020; Jin et al., 2020). Those attacks generate adversarial examples by slightly modifying the original sentences without changing the meanings, while the NLP models change the predictions on those examples. However, a robust model is expected to output the same labels. Therefore, how to make NLP models not affected by the adversarial examples becomes an important task. Since SynPG is able to generate syntactically different paraphrases, we can improve the robustness of NLP models by data augmentation. The models trained with data augmentation are thus more robust to the syntactically adversarial"
2021.eacl-main.88,P19-1199,0,0.329338,"d to train sequence-to-sequence (seq2seq) models on a large number of annotated paraphrase pairs (Prakash et al., 2016; Mallinson et al., 2017; Cao et al., 2017; Egonmwan and Chali, 2019). Some of them control the syntax of output sentences to improve the diversity of paraphrase generation (Iyyer et al., 2018; Goyal and Durrett, 2020; Kumar et al., 2020). However, collecting annotated pairs is expensive and induces challenges for some languages and domains. On the contrary, unsupervised approaches build paraphrase models without using parallel corpora (Li et al., 2018; Roy and Grangier, 2019; Zhang et al., 2019). Most of them are based on the variational autoencoder (Bowman et al., 2016) or back-translation (Mallinson et al., 2017; Wieting and Gimpel, 2018; Hu et al., 2019). Nevertheless, without the consideration of controlling syntax, their generated paraphrases are often similar to the source sentences and are not diverse in syntax. This paper presents a pioneering study on syntactically controlled paraphrase generation based 1022 Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics, pages 1022–1033 April 19 - 23, 2021. ©2021 Association for C"
2021.eacl-main.88,D18-1355,0,0.0241895,"del is expected to generate a paraphrase with the syntax following the given specification. Introduction Paraphrase generation (McKeown, 1983) is a longlasting task in natural language processing (NLP) and has been greatly improved by recently developed machine learning approaches and large data collections. Paraphrase generation demonstrates the potential of machines in semantic abstraction and sentence reorganization and has already been applied to many NLP downstream applications, such as question answering (Yu et al., 2018), chatbot engines (Yan et al., 2016), and sentence simplification (Zhao et al., 2018). In recent years, various approaches have been proposed to train sequence-to-sequence (seq2seq) models on a large number of annotated paraphrase pairs (Prakash et al., 2016; Mallinson et al., 2017; Cao et al., 2017; Egonmwan and Chali, 2019). Some of them control the syntax of output sentences to improve the diversity of paraphrase generation (Iyyer et al., 2018; Goyal and Durrett, 2020; Kumar et al., 2020). However, collecting annotated pairs is expensive and induces challenges for some languages and domains. On the contrary, unsupervised approaches build paraphrase models without using para"
2021.eacl-main.88,D19-1221,0,0.0145637,"g and Gimpel (2018) use translation models to generate paraphrases via back-translation. Zhang et al. (2019); Roy and Controlled generation. Recent work on controlled generation can be grouped into two families. The first family is doing end-to-end training with an additional trigger to control the attributes, such as sentiment (Shen et al., 2017; Hu et al., 2017; Fu et al., 2018; Peng et al., 2018; Dai et al., 2019), tense (Logeswaran et al., 2018), plots (Ammanabrolu et al., 2020; Fan et al., 2019; Tambwekar et al., 2019; Yao et al., 2019; GoldfarbTarrant et al., 2019, 2020), societal bias (Wallace et al., 2019; Sheng et al., 2020b,a), and syntax (Iyyer et al., 2018; Goyal and Durrett, 2020; Kumar et al., 2020). The second family controls the attributes by learning disentangled representations. For example, Romanov et al. (2019) disentangle the meaning and the form of a sentence. Chen et al. (2019b,a); Bao et al. (2019) disentangle the semantics and the syntax of a sentence. 7 Conclusion We present syntactically controlled paraphrase generator (SynPG), an paraphrase model that can control the syntax of generated paraphrases based on the given syntactic specifications. SynPG is designed to disentangl"
2021.eacl-main.88,P18-1042,0,0.373199,"; Cao et al., 2017; Egonmwan and Chali, 2019). Some of them control the syntax of output sentences to improve the diversity of paraphrase generation (Iyyer et al., 2018; Goyal and Durrett, 2020; Kumar et al., 2020). However, collecting annotated pairs is expensive and induces challenges for some languages and domains. On the contrary, unsupervised approaches build paraphrase models without using parallel corpora (Li et al., 2018; Roy and Grangier, 2019; Zhang et al., 2019). Most of them are based on the variational autoencoder (Bowman et al., 2016) or back-translation (Mallinson et al., 2017; Wieting and Gimpel, 2018; Hu et al., 2019). Nevertheless, without the consideration of controlling syntax, their generated paraphrases are often similar to the source sentences and are not diverse in syntax. This paper presents a pioneering study on syntactically controlled paraphrase generation based 1022 Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics, pages 1022–1033 April 19 - 23, 2021. ©2021 Association for Computational Linguistics on disentangling semantics and syntax. We aim to disentangle one sentence into two parts: 1) the semantic part and 2) the"
2021.eacl-main.88,D17-1026,0,0.119126,"and Barzilay, 2006), and lattice matching methods (Barzilay and Lee, 2003). However, the diversity of their generated paraphrases is usually limited. Recently, neural models make success on paraphrase generation (Prakash et al., 2016; Mallinson et al., 2017; Cao et al., 2017; Egonmwan and Chali, 2019; Li et al., 2019; Gupta et al., 2018). These approaches treat paraphrase generation as a translation task and design seq2seq models based on a large amount of parallel data. To reduce the effort to collect parallel data, unsupervised paraphrase generation has attracted attention in recent years. Wieting et al. (2017); Wieting and Gimpel (2018) use translation models to generate paraphrases via back-translation. Zhang et al. (2019); Roy and Controlled generation. Recent work on controlled generation can be grouped into two families. The first family is doing end-to-end training with an additional trigger to control the attributes, such as sentiment (Shen et al., 2017; Hu et al., 2017; Fu et al., 2018; Peng et al., 2018; Dai et al., 2019), tense (Logeswaran et al., 2018), plots (Ammanabrolu et al., 2020; Fan et al., 2019; Tambwekar et al., 2019; Yao et al., 2019; GoldfarbTarrant et al., 2019, 2020), societa"
2021.eacl-main.88,P16-1049,0,0.0113758,"arse tree or top levels of a parse tree), the model is expected to generate a paraphrase with the syntax following the given specification. Introduction Paraphrase generation (McKeown, 1983) is a longlasting task in natural language processing (NLP) and has been greatly improved by recently developed machine learning approaches and large data collections. Paraphrase generation demonstrates the potential of machines in semantic abstraction and sentence reorganization and has already been applied to many NLP downstream applications, such as question answering (Yu et al., 2018), chatbot engines (Yan et al., 2016), and sentence simplification (Zhao et al., 2018). In recent years, various approaches have been proposed to train sequence-to-sequence (seq2seq) models on a large number of annotated paraphrase pairs (Prakash et al., 2016; Mallinson et al., 2017; Cao et al., 2017; Egonmwan and Chali, 2019). Some of them control the syntax of output sentences to improve the diversity of paraphrase generation (Iyyer et al., 2018; Goyal and Durrett, 2020; Kumar et al., 2020). However, collecting annotated pairs is expensive and induces challenges for some languages and domains. On the contrary, unsupervised appr"
2021.emnlp-main.126,D14-1162,0,0.087698,"Missing"
2021.emnlp-main.126,2021.acl-long.426,1,0.754437,"efforts to obtained. 3.1 Robust training. Recently, adversarial attacks are presented to check the robustness of NLP models, such as character manipulation (Ebrahimi et al., 2018; Gil et al., 2019), word replacements (Alzantot et al., 2018; Li et al., 2020; Garg and Ramakrishnan, 2020; Jin et al., 2020), and syntactic rearrangements (Iyyer et al., 2018). To against those attacks, various robust training methods are proposed. For example, Alzantot et al. (2018) trains a robust model by data augmentation with generated adversarial examples. Other works (Ebrahimi et al., 2018; Dong et al., 2021; Zhou et al., 2021) consider adversarial training, which includes the adversarial accuracy to the training objective. A few studies propose transformations on inputs before feeding them to models (Edizel et al., 2019; Jones et al., 2020). Randomized smoothing (Cohen et al., 2019; Ye et al., 2020) is presented to make models robust against noise in input representations. Another line of research aims at providing theoretical guarantee of robustness, including interval bound propagation methods (Jia et al., 2019; Huang et al., 2019) and verification methods (Shi et al., 2020). Most of those robust training methods"
2021.emnlp-main.126,N19-1162,0,0.0244896,"Conneau et al., 2018; Yang et al., 2019; Clark et al., 2020; Artetxe et al., 2020; Lewis et al., 2020). XTREME (Hu et al., 2020) and XGLUE (Liang et al., 2020) further provide benchmarks for zero-shot cross-lingual transfer learning. Embedding space alignments. Learning to align embedding spaces have always been an important research topic to improve multilinguality. Early works focus on word embedding spaces (Mikolov et al., 2013; Smith et al., 2017; Artetxe et al., 2017). Recently, many approaches are proposed to align contextual word embedding spaces, such as learning rotation projections (Schuster et al., 2019; Aldarmaki and Diab, 2019; Conneau et al., 2020b) and fine-tuning pre-trained multilingual language models (Chi et al., 2020; Feng et al., 1 2020; Cao et al., 2020; Qin et al., 2020; Liu et al., Our code is available at https://github.com/ uclanlp/Robust-XLT 2020; Dou and Neubig, 2021; Wei et al., 2021). 1685 However, most of them require additional supervision signals, such as parallel sentence pairs (Chi et al., 2020; Feng et al., 2020; Wei et al., 2021), bilingual dictionary (Cao et al., 2020; Qin et al., 2020; Liu et al., 2020), or both (Pan et al., 2021). These additional supervised corp"
2021.emnlp-main.126,D19-1030,0,0.0605948,"Missing"
2021.emnlp-main.150,W18-2501,0,0.042165,"Missing"
2021.emnlp-main.150,D14-1162,0,0.0913055,"Missing"
2021.emnlp-main.150,2020.acl-main.647,0,0.0975594,"ould potentially measure biases against all genders (Cao and Daumé III, 2020; tifies, and mitigates language model biases such Rudinger et al., 2018). While such works that inas gender, race or religion-related stereotypes in static word embeddings (GloVe (Pennington et al., tentionally inject real-world or artificially-created 2014)) and contextual (e.g., BERT (Devlin et al., data of non-binary people into binary-gendered 2019)) representations (Bolukbasi et al., 2016; De- datasets are well-intentioned, they could benefit from a broader perspective of harms as perceived Arteaga et al., 2019; Ravfogel et al., 2020; Dev by non-binary persons to avoid mischaracterizet al., 2020b). ing non-binary genders as a single gender (Sun * Equal contribution et al., 2021) or perpetuating biases through non{sunipa,anaelia,arjunsub,kwchang}@cs.ucla.edu, monajati@g.ucla.edu, jeffp@cs.utah.edu intersectional training examples, i.e. examples that 1968 Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 1968–1994 c November 7–11, 2021. 2021 Association for Computational Linguistics do not capture the interconnected nature of social identities (Crenshaw, 1989). In this paper, we c"
2021.emnlp-main.150,N18-2002,0,0.0298129,"Missing"
2021.emnlp-main.150,2021.acl-long.330,1,0.713022,"or sex) conveyed in a nonreferential manner (Cao and Daumé III, 2020). Examples include “mother” and “Mr.” Non-binary persons have adopted honorifics like “Mx.” to eliminate gendering (Clarke, 2019), and often use gender-neutral terms like “partner” to refer to their significant other. However, their adoption into written text and narratives is recent and sparse. undesirable association in language representations which has the potential to cause representational or allocational harms (Barocas et al., 2017). There have been multiple attempts to understand social biases in language processing (Sheng et al., 2021; Caliskan et al., 2017), quantify them (Rudinger et al., 2018; Webster et al., 2018; De-Arteaga et al., 2019), and mitigate them (Zhao et al., 2019; Ravfogel et al., 2020; Sun et al., 2019). A primary focus has been on gender bias, but the narrative has been dominated by biases associated with binary gender, primarily related to occupations and adjectives. However, the biases faced by non-binary persons can be distinct from this. Non-binary genders are severely underrepresented in textual data, which causes language models to learn meaningless, unstable representations for non-binary-associat"
2021.emnlp-main.150,P19-1164,0,0.0256769,"Missing"
2021.emnlp-main.150,P19-1159,1,0.850257,", 2019), and often use gender-neutral terms like “partner” to refer to their significant other. However, their adoption into written text and narratives is recent and sparse. undesirable association in language representations which has the potential to cause representational or allocational harms (Barocas et al., 2017). There have been multiple attempts to understand social biases in language processing (Sheng et al., 2021; Caliskan et al., 2017), quantify them (Rudinger et al., 2018; Webster et al., 2018; De-Arteaga et al., 2019), and mitigate them (Zhao et al., 2019; Ravfogel et al., 2020; Sun et al., 2019). A primary focus has been on gender bias, but the narrative has been dominated by biases associated with binary gender, primarily related to occupations and adjectives. However, the biases faced by non-binary persons can be distinct from this. Non-binary genders are severely underrepresented in textual data, which causes language models to learn meaningless, unstable representations for non-binary-associated pronouns and terms. Furthermore, there are derogatory adjectives associated with non-binary-related terms (as seen in Appendix B.1). Thus, analyzing and quantifying biases associated with"
2021.emnlp-main.150,D17-1323,1,0.824866,"e dishonest, careless and unkind, arrogant. This further substantiates the presence of biased negative associations, as seen in the WEAT test. Furthermore, the nearest neighbors of words associated with non-binary genders are derogatory (see Appendix Table 12). In particular, agender and genderf luid have the neighbor negrito, meaning “little Black”, while genderf luid has F asiq, which is an Arabic word used for someone of corrupt moral character. Text Representation Skews Text representations have been known to learn and exacerbate skewed associations and social biases from underlying data (Zhao et al., 2017; Bender et al., 2021; Dev, 2020), thus propagating representational harm. We examine representational skews with respect to pronouns and non-binary-associated words that are extremely sparsely present in text. Representational erasure in GloVe. Table 2 shows the nearest neighbors of different pronouns in their GloVe representations trained on English Wikipedia data. The singular pronouns he and she have semantically meaningful neighbors as do their possessive forms (Appendix B.1). The same is not true for non-binary neopronouns xe and ze which are closest to acronyms and Polish words, respect"
2021.emnlp-main.150,N18-2003,1,0.841102,"ntains examtypes associated with masculine and feminine atples of stereotypes and associations, misgentributes (Bolukbasi et al., 2016; Webster et al., dering, erasure, and other harms that could be offensive and triggering to trans and non2018; Dev et al., 2020b). Additionally, models ofbinary individuals. ten rely on gendered information for decision making, such as in named entity recognition, coreferGender is widely discussed in the context of language tasks and when examining the stereoence resolution, and machine translation (Mehrabi types propagated by language models. Howet al., 2020; Zhao et al., 2018; Stanovsky et al., ever, current discussions primarily treat gen2019), but the purview of gender in these tasks and der as binary, which can perpetuate harms such associated measures of performance focus on bias the cyclical erasure of non-binary gender nary gender. While discussing binary gender bias identities. These harms are driven by model and improving model performance are important, and dataset biases, which are consequences it is important to reshape our understanding of genof the non-recognition and lack of understanding of non-binary genders in society. In this der in language tech"
2021.emnlp-main.162,D16-1120,0,0.0664583,"Missing"
2021.emnlp-main.162,D19-1243,0,0.0485699,"Missing"
2021.emnlp-main.162,P17-2009,0,0.0223859,"aphic Bias. Geographic bias is a serious issue that may cause harmful effects on certain groups of people. In computer vision, researchers (Shankar et al., 2017; de Vries et al., 2019) find that most images from two large-scale image datasets, ImageNet (Deng et al., 2009) and OpenImages (Krasin et al., 2017), are amerocentric and eurocentric. When a model trained on these datasets is applied to images from other regions, the performance will drop drastically. There also exists geographic bias in language technology. For example, it underlies natural language processing (Blodgett et al., 2016; Jurgens et al., 2017; Ghosh et al., 2021) and automatic speech recognition (Tatman, 2017; Koenecke et al., 2020) models. Our work seeks to reveal and test the geographic bias in the visual commonsense reasoning task and models. 3 Benchmark Construction 3.1 Image Collection In the image collection stage, we request annotators to follow two principles: Images with Regional Characteristics. In our annotation instruction, we require that the collected images should have representative scenarios containing cultural elements of the annotators’ regions. We further recommend annotators choose scenarios that are ubiquitou"
2021.emnlp-main.162,D14-1086,0,0.027793,"first find that the performance gap et al., 2021) are two multilingual benchmarks, but 2116 most samples in both benchmarks are simply translated from English and cannot reflect the regional characteristics. Different from previous benchmarks, GD-VCR focuses on geo-diverse commonsense instead of viewing commonsense as a universal monolith. Vision-and-Language Tasks. A long line of research seeks to build vision-and-language datasets that test a model’s ability to understand the visual world and how it is grounded in natural language. The tasks take on various forms, such as phrase grounding (Kazemzadeh et al., 2014; Plummer et al., 2015), visual question answering (Antol et al., 2015; Goyal et al., 2017), and visual reasoning (Zellers et al., 2019; Suhr et al., 2019). To solve these tasks, a wide range of visual grounding skills are required. However, in existing tasks, little consideration is taken into reasoning on the images with regional characteristics. Geographic Bias. Geographic bias is a serious issue that may cause harmful effects on certain groups of people. In computer vision, researchers (Shankar et al., 2017; de Vries et al., 2019) find that most images from two large-scale image datasets,"
2021.emnlp-main.162,P19-1644,0,0.0204666,"and cannot reflect the regional characteristics. Different from previous benchmarks, GD-VCR focuses on geo-diverse commonsense instead of viewing commonsense as a universal monolith. Vision-and-Language Tasks. A long line of research seeks to build vision-and-language datasets that test a model’s ability to understand the visual world and how it is grounded in natural language. The tasks take on various forms, such as phrase grounding (Kazemzadeh et al., 2014; Plummer et al., 2015), visual question answering (Antol et al., 2015; Goyal et al., 2017), and visual reasoning (Zellers et al., 2019; Suhr et al., 2019). To solve these tasks, a wide range of visual grounding skills are required. However, in existing tasks, little consideration is taken into reasoning on the images with regional characteristics. Geographic Bias. Geographic bias is a serious issue that may cause harmful effects on certain groups of people. In computer vision, researchers (Shankar et al., 2017; de Vries et al., 2019) find that most images from two large-scale image datasets, ImageNet (Deng et al., 2009) and OpenImages (Krasin et al., 2017), are amerocentric and eurocentric. When a model trained on these datasets is applied to i"
2021.emnlp-main.162,N19-1421,0,0.0190721,"ons behind the performance disparity and find that the performance gap is larger on QA pairs that: 1) are concerned with culture-related scenarios, e.g., weddings, religious activities, and festivals; 2) require high-level geo-diverse commonsense reasoning rather than low-order perception and recognition. Dataset and code are released at https://github.com/ WadeYin9712/GD-VCR. 1 Introduction that this woman is attending a wedding and likely to be the bride. Recently, the field of commonsense reasoning is progressing with the development of large-scale benchmark datasets (Zellers et al., 2018; Talmor et al., 2019), intended to cover a wide range of commonsense knowledge, such as physical interactions (Bisk et al., 2020), social conventions (Sap et al., 2019), and commonsense grounded in vision (Zellers et al., 2019). However, existing benchmarks are often composed by data from sources in certain regions (e.g., Western movies) and overlook the differences across groups in different regions1 due to factors including cultural differences. In the aforementioned wedding example, while brides are usually in white in Western weddings, they often wear red and their faces are covered with a red cloth in traditi"
2021.emnlp-main.162,W17-1606,0,0.0161341,"s on certain groups of people. In computer vision, researchers (Shankar et al., 2017; de Vries et al., 2019) find that most images from two large-scale image datasets, ImageNet (Deng et al., 2009) and OpenImages (Krasin et al., 2017), are amerocentric and eurocentric. When a model trained on these datasets is applied to images from other regions, the performance will drop drastically. There also exists geographic bias in language technology. For example, it underlies natural language processing (Blodgett et al., 2016; Jurgens et al., 2017; Ghosh et al., 2021) and automatic speech recognition (Tatman, 2017; Koenecke et al., 2020) models. Our work seeks to reveal and test the geographic bias in the visual commonsense reasoning task and models. 3 Benchmark Construction 3.1 Image Collection In the image collection stage, we request annotators to follow two principles: Images with Regional Characteristics. In our annotation instruction, we require that the collected images should have representative scenarios containing cultural elements of the annotators’ regions. We further recommend annotators choose scenarios that are ubiquitous but have specific characteristics across regions, e.g., wedding, f"
2021.emnlp-main.162,D18-1009,0,0.0282575,"n. We analyze the reasons behind the performance disparity and find that the performance gap is larger on QA pairs that: 1) are concerned with culture-related scenarios, e.g., weddings, religious activities, and festivals; 2) require high-level geo-diverse commonsense reasoning rather than low-order perception and recognition. Dataset and code are released at https://github.com/ WadeYin9712/GD-VCR. 1 Introduction that this woman is attending a wedding and likely to be the bride. Recently, the field of commonsense reasoning is progressing with the development of large-scale benchmark datasets (Zellers et al., 2018; Talmor et al., 2019), intended to cover a wide range of commonsense knowledge, such as physical interactions (Bisk et al., 2020), social conventions (Sap et al., 2019), and commonsense grounded in vision (Zellers et al., 2019). However, existing benchmarks are often composed by data from sources in certain regions (e.g., Western movies) and overlook the differences across groups in different regions1 due to factors including cultural differences. In the aforementioned wedding example, while brides are usually in white in Western weddings, they often wear red and their faces are covered with"
2021.emnlp-tutorials.5,D19-1423,1,0.838406,"Missing"
2021.emnlp-tutorials.5,P18-1241,0,0.0605577,"Missing"
2021.emnlp-tutorials.5,2020.acl-main.245,1,0.89052,"Missing"
2021.emnlp-tutorials.5,N19-1336,0,0.0618875,"Missing"
2021.emnlp-tutorials.5,2020.acl-main.769,0,0.0960644,"Missing"
2021.emnlp-tutorials.5,C18-1055,0,0.025517,"Missing"
2021.emnlp-tutorials.5,D19-5506,0,0.0629348,"Missing"
2021.emnlp-tutorials.5,D19-6115,1,0.861361,"Missing"
2021.emnlp-tutorials.5,W18-6322,0,0.0484699,"Missing"
2021.emnlp-tutorials.5,2020.acl-main.441,0,0.0859026,"Missing"
2021.emnlp-tutorials.5,2020.acl-main.317,0,0.0618829,"Missing"
2021.emnlp-tutorials.5,N19-1337,1,0.764998,"hort Paper Award at ACL 2018. Additional information is available at https://robinjia.github.io. Prerequisite Knowledge Our target audience is general NLP conference attendances; therefore, no specific knowledge is assumed of the audience except basic machine learning and NLP background: • Understand derivatives and gradient decent methods as found in introductory Calculus. Sameer Singh Sameer Singh is an Assistant Professor of Computer Science at the University of California, Irvine. He is working on large-scale and interpretable machine learning models for NLP (e.g., (Wallace et al., 2019a; Pezeshkpour et al., 2019)). His work has received paper awards at • Understand the basic supervised learning paradigm and commonly used machine learning models such as logistic regression and deep neural networks. 24 ACL 2020, AKBC 2020, EMNLP 2019, ACL 2018, and KDD 2016. Sameer presented the Deep Adversarial Learning Tutorial (Wang et al., 2019) at NAACL 2019 and the Mining Knowledge Graphs from Text Tutorial at WSDM 2018 and AAAI 2017, along with tutorials on Interpretability and Explanations in upcoming NeurIPS 2020 and EMNLP 2020. Sameer has also received teaching awards at UCI. Website: http://sameersingh.org/ t"
2021.emnlp-tutorials.5,D18-1009,0,0.0662393,"Missing"
2021.emnlp-tutorials.5,P19-1561,0,0.053811,"Missing"
2021.emnlp-tutorials.5,S19-1032,0,0.0316721,"Missing"
2021.emnlp-tutorials.5,P19-1103,0,0.0581596,"Missing"
2021.emnlp-tutorials.5,2020.acl-main.590,0,0.0609146,"Missing"
2021.emnlp-tutorials.5,P18-1079,1,0.768158,"Jia Facebook AI Research and University of Southern California robinjia@fb.com Sameer Singh University of California, Irvine sameer@uci.edu Abstract correlations and fail catastrophically when given inputs from different sources or inputs that have been adversarially perturbed. For example, Jia and Liang (2017) shows that state-of-the-art reading comprehension systems fail to answer questions about paragraphs that contain adversarially inserted sentences, which are automatically generated to distract computer systems without changing the correct answer. Similarly, a series of studies (e.g., (Ribeiro et al., 2018; Alzantot et al., 2018; Iyyer et al., 2018)) demonstrate that text classification models are not robust against adversarial examples that generated by synonym substitution, paraphrasing, and inserting/deleting characters in the text input. This lack of robustness exposes troubling gaps in current models’ language understanding capabilities and creates problems when NLP systems are deployed to real users. As NLP systems are increasingly integrated into people’s daily lives and directly interact with endusers, it is essential to ensure their reliability. For example, systems that flag hateful s"
2021.emnlp-tutorials.5,2020.acl-main.442,1,0.892522,"Missing"
2021.emnlp-tutorials.5,2020.tacl-1.40,1,0.841302,"Missing"
2021.emnlp-tutorials.5,D19-1221,1,0.847586,"EMNLP 2017 and a Best Short Paper Award at ACL 2018. Additional information is available at https://robinjia.github.io. Prerequisite Knowledge Our target audience is general NLP conference attendances; therefore, no specific knowledge is assumed of the audience except basic machine learning and NLP background: • Understand derivatives and gradient decent methods as found in introductory Calculus. Sameer Singh Sameer Singh is an Assistant Professor of Computer Science at the University of California, Irvine. He is working on large-scale and interpretable machine learning models for NLP (e.g., (Wallace et al., 2019a; Pezeshkpour et al., 2019)). His work has received paper awards at • Understand the basic supervised learning paradigm and commonly used machine learning models such as logistic regression and deep neural networks. 24 ACL 2020, AKBC 2020, EMNLP 2019, ACL 2018, and KDD 2016. Sameer presented the Deep Adversarial Learning Tutorial (Wang et al., 2019) at NAACL 2019 and the Mining Knowledge Graphs from Text Tutorial at WSDM 2018 and AAAI 2017, along with tutorials on Interpretability and Explanations in upcoming NeurIPS 2020 and EMNLP 2020. Sameer has also received teaching awards at UCI. Websit"
2021.emnlp-tutorials.5,Q19-1029,0,0.0245395,"EMNLP 2017 and a Best Short Paper Award at ACL 2018. Additional information is available at https://robinjia.github.io. Prerequisite Knowledge Our target audience is general NLP conference attendances; therefore, no specific knowledge is assumed of the audience except basic machine learning and NLP background: • Understand derivatives and gradient decent methods as found in introductory Calculus. Sameer Singh Sameer Singh is an Assistant Professor of Computer Science at the University of California, Irvine. He is working on large-scale and interpretable machine learning models for NLP (e.g., (Wallace et al., 2019a; Pezeshkpour et al., 2019)). His work has received paper awards at • Understand the basic supervised learning paradigm and commonly used machine learning models such as logistic regression and deep neural networks. 24 ACL 2020, AKBC 2020, EMNLP 2019, ACL 2018, and KDD 2016. Sameer presented the Deep Adversarial Learning Tutorial (Wang et al., 2019) at NAACL 2019 and the Mining Knowledge Graphs from Text Tutorial at WSDM 2018 and AAAI 2017, along with tutorials on Interpretability and Explanations in upcoming NeurIPS 2020 and EMNLP 2020. Sameer has also received teaching awards at UCI. Websit"
2021.findings-acl.294,D18-1316,1,0.822394,"s. In particular, for each word, and a polytope spanned by the potential substitutions for that word in the embedding space, these methods ensure that swapping the word with any point in the polytope will not change the model predictions. To accomplish this, IBP minimizes the upper bound of the set of losses over perturbation sets, and SAFER uses a model-agnostic randomized smoothing technique. Both IBP and SAFER encourage models to be robust to spurious word substitutions, which include tokens that contain protected attribute information. The perturbations included in the original paper from Alzantot et al. (2018) are based on a GloVe embedding that has been modified such that synonyms are close together. While the perturbation set does not include explicit gender and sexual orientation swaps (‘boy’ is not included in the perturbation set for ’girl’, while ’girls’, and ’women’ are), we posit that certified robustness methods can still be applied to bias mitigation by improving robustness in examples that contain identifiers of underrepresented groups. Doing so will decrease model performance disparity in underrepresented group cohorts, and thus fulfill fairness notions. IBP (Jia et al., 2019) IBP compu"
2021.findings-acl.294,2020.acl-main.485,0,0.0328909,"Missing"
2021.findings-acl.294,N19-1423,0,0.645429,"rrelevant to the task 3320 Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 3320–3331 August 1–6, 2021. ©2021 Association for Computational Linguistics at hand (i.e. “She is a good singer” and “He is a good singer” should have the same sentiment label). Thus, we posit that word substitution robustness methods can be used to make models invariant to protected attribute tokens and identifiers. We explore the effect of robustness methods on fairness with GloVe-based CNN models (Kim, 2014) trained with Interval Bound Propagation (IBP) (Jia et al., 2019), and BERT (Devlin et al., 2019a) trained with SAFER (Ye et al., 2020). We compare the effect of these robustness methods to popular bias mitigation methods. We find that robustness methods achieve promising performance on fairness metrics exceeding that of bias mitigation methods in several text classification tasks on gender and sexual orientation dimensions. Furthermore, training on both fairness and robustness exceeds performance over robustness and bias mitigation methods alone. Comprehensive analysis and visualization demonstrate that the robust methods decrease feature importance on gender tokens. Our contributions a"
2021.findings-acl.294,P18-2006,0,0.0190659,"value of the output gradient with respect to the token embedding. The baseline CNN model focuses on some tokens related to protected groups (e.g., woman), while IBP encourages the model to take into account other parts of the sentence, resulting in less bias. that is achieved by training an adversary to identify information on protected groups and training the model to minimize the adversary loss. These approaches are designed for reducing specific types of bias exhibited in data. On the robustness front, it has been shown that models are susceptible to adversarial word substitution attacks (Ebrahimi et al., 2018; Jia and Liang, 2017). Parallel to the development of methods developed to reduce word substitution robustness in the NLP domain (e.g., (Miyato et al., 2017; Huang et al., 2019; Zhou et al., 2021)), many studies has been done in the computer vision domain to ensure that models are robust to image noising (Kannan et al., 2018; Szegedy et al., 2014). In the intersection of area between fairness and robustness of model training, there is limited prior work in the NLP area. Nanda et al. (2020) investigate and define robustness bias, a notion of fairness in which a model must be impervious to pert"
2021.findings-acl.294,D19-1419,0,0.0403199,"Missing"
2021.findings-acl.294,2020.acl-main.487,0,0.0337123,"Missing"
2021.findings-acl.294,D17-1215,0,0.0174402,"adient with respect to the token embedding. The baseline CNN model focuses on some tokens related to protected groups (e.g., woman), while IBP encourages the model to take into account other parts of the sentence, resulting in less bias. that is achieved by training an adversary to identify information on protected groups and training the model to minimize the adversary loss. These approaches are designed for reducing specific types of bias exhibited in data. On the robustness front, it has been shown that models are susceptible to adversarial word substitution attacks (Ebrahimi et al., 2018; Jia and Liang, 2017). Parallel to the development of methods developed to reduce word substitution robustness in the NLP domain (e.g., (Miyato et al., 2017; Huang et al., 2019; Zhou et al., 2021)), many studies has been done in the computer vision domain to ensure that models are robust to image noising (Kannan et al., 2018; Szegedy et al., 2014). In the intersection of area between fairness and robustness of model training, there is limited prior work in the NLP area. Nanda et al. (2020) investigate and define robustness bias, a notion of fairness in which a model must be impervious to perturbations to the same"
2021.findings-acl.294,D19-1423,0,0.0537177,"Missing"
2021.findings-acl.294,2020.acl-main.264,1,0.843082,"tion classification, a fair model should correctly identify occupations given a biography, regardless of the protected group that a person belongs to (DeArteaga et al., 2019). Recently, several studies have demonstrated societal bias in NLP systems (Hutchinson et al., 2020; Tan and Celis, 2019; Liang et al., 2020) and various approaches have been proposed to mitigate the bias. These approaches include creating balanced datasets (Park et al., 2018; Zhao et al., 2018a), developing methods optimized for particular fairness notions (Zhang et al., 2017, 2020), model calibration (Zhao et al., 2017; Jia et al., 2020), and reducing representational bias (Bolukbasi et al., 2016b; Zhao et al., 2018b; Liang et al., 2020). Separately, certified robustness approaches (Jia et al., 2019; Ye et al., 2020) have been developed to ensure robustness against word substitution attacks. Specifically, these strategies ensure small perturbations in the input embedding space do not alter model predictions. Despite never having been discussed in prior literature, this corresponds to notions of fairness, since protected attribute information (e.g. gender) is often irrelevant to the task 3320 Findings of the Association for Co"
2021.findings-acl.294,D14-1181,0,0.0255216,"to notions of fairness, since protected attribute information (e.g. gender) is often irrelevant to the task 3320 Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 3320–3331 August 1–6, 2021. ©2021 Association for Computational Linguistics at hand (i.e. “She is a good singer” and “He is a good singer” should have the same sentiment label). Thus, we posit that word substitution robustness methods can be used to make models invariant to protected attribute tokens and identifiers. We explore the effect of robustness methods on fairness with GloVe-based CNN models (Kim, 2014) trained with Interval Bound Propagation (IBP) (Jia et al., 2019), and BERT (Devlin et al., 2019a) trained with SAFER (Ye et al., 2020). We compare the effect of these robustness methods to popular bias mitigation methods. We find that robustness methods achieve promising performance on fairness metrics exceeding that of bias mitigation methods in several text classification tasks on gender and sexual orientation dimensions. Furthermore, training on both fairness and robustness exceeds performance over robustness and bias mitigation methods alone. Comprehensive analysis and visualization demon"
2021.findings-acl.294,2020.acl-main.488,0,0.0191853,"ssify text containing certain protected attributes as toxic. Leading social media platforms and internet companies use toxicity classification models for content moderation (Gorwa et al., 2020), thus having bias in such models can lead to increased silencing of under-served groups. Similarly, for occupation classification, a fair model should correctly identify occupations given a biography, regardless of the protected group that a person belongs to (DeArteaga et al., 2019). Recently, several studies have demonstrated societal bias in NLP systems (Hutchinson et al., 2020; Tan and Celis, 2019; Liang et al., 2020) and various approaches have been proposed to mitigate the bias. These approaches include creating balanced datasets (Park et al., 2018; Zhao et al., 2018a), developing methods optimized for particular fairness notions (Zhang et al., 2017, 2020), model calibration (Zhao et al., 2017; Jia et al., 2020), and reducing representational bias (Bolukbasi et al., 2016b; Zhao et al., 2018b; Liang et al., 2020). Separately, certified robustness approaches (Jia et al., 2019; Ye et al., 2020) have been developed to ensure robustness against word substitution attacks. Specifically, these strategies ensure"
2021.findings-acl.294,D18-1302,0,0.0202674,"ation models for content moderation (Gorwa et al., 2020), thus having bias in such models can lead to increased silencing of under-served groups. Similarly, for occupation classification, a fair model should correctly identify occupations given a biography, regardless of the protected group that a person belongs to (DeArteaga et al., 2019). Recently, several studies have demonstrated societal bias in NLP systems (Hutchinson et al., 2020; Tan and Celis, 2019; Liang et al., 2020) and various approaches have been proposed to mitigate the bias. These approaches include creating balanced datasets (Park et al., 2018; Zhao et al., 2018a), developing methods optimized for particular fairness notions (Zhang et al., 2017, 2020), model calibration (Zhao et al., 2017; Jia et al., 2020), and reducing representational bias (Bolukbasi et al., 2016b; Zhao et al., 2018b; Liang et al., 2020). Separately, certified robustness approaches (Jia et al., 2019; Ye et al., 2020) have been developed to ensure robustness against word substitution attacks. Specifically, these strategies ensure small perturbations in the input embedding space do not alter model predictions. Despite never having been discussed in prior literatur"
2021.findings-acl.294,D14-1162,0,0.0857354,"arial Training 0.732 0.735 0.725 0.113 0.101 0.112 0.719 0.715 0.693 Model Table 2: Experiment results on CNN models on the Bias in Bios dataset. We see that our best performing model consists of initiating IBP training with HardDebias embeddings. Jigsaw Toxicity and 34 hours for Bias in Bios, while SAFER took 53 hours with evaluation for Jigsaw Toxicity and 37 hours for Bias in Bios. For the experiments with CNN, we follow Jia et al. (2019) to configure the IBP schedule and CNN models. In particular, we used a CNN model with a hidden size of 100 and kernel size of 3 with the GloVe embedding (Pennington et al., 2014) as inputs. For IBP, we linearly increased the weight on the certified robustness objective from 0 to 0.8 for 40 epochs, before training for 20 epochs on the full certified robustness objective. For the experiments with BERT, we follow Ye et al. (2020) to configure the BERT model and SAFER experiment. We use bert-base-uncased, and take the top-100 words that are closest in cosine similarity for each token as the token’s perturbation set. We describe the remaining hyper-parameter details (learning rate, epochs, dropout probability) in the the appendix, which we obtained after a hyper-parameter"
2021.findings-acl.294,N16-3020,0,0.0426224,"achieving high CRA. 3325 Figure 1: Frequency of gender token features as extracted by LIME for baseline and IBP trained models for Jigsaw Toxicity and Bias in Bios. We see a decrease in number and frequency of gender tokens in the list of top-5 (for Jigsaw Toxicity) and top-50 (for Bias in Bios) most important features. 5 Analysis In this section, we study how robustness training affects the features our models use for classification. We posit that robustness training encourages models to focus more on predictive attributes than on protected attributes. To gain insight into this, we use LIME (Ribeiro et al., 2016) on the baseline, IBP, and SAFER trained models and extract token features importance as assigned by the model. We run LIME on the subset E of examples that are misclassified by our baseline model as toxic that are correctly classified by the IBP model. We take the top k features for each of the examples (where k = 5 for Jigsaw and k = 50 for Bias in Bios) over E, and then count the number of gender tokens that appear in that list. For Jigsaw Toxicity, the number of examples that we run LIME on is 488 for CNN experiments and 182 for BERT experiments. For Bias in Bios, we run LIME over a random"
2021.findings-acl.294,N19-1424,0,0.0245807,"city, which is shown in Table 5. We observe that the baseline model focuses on tokens related to protected groups, while the IBP model takes into account all parts of the sentence. 6 Related Work Much work has been done in studying fairness in various NLP models (Mehrabi et al., 2019; Sun et al., 2019; Blodgett et al., 2020). In toxicity classification, Adragna et al. (2020) and (Zhang et al., 2020) study the fairness in predicting toxic internet contents in which the contents contain demographic identity-terms (e.g., “gay”, “black”). In occupation classification, De-Arteaga et al. (2019) and Romanov et al. (2019) study the impact of including explicit gender indicators such as a person’s names or a pronoun in online biographies. Some notable bias mitigation methods, which we also use in this paper, include instance weighting (Zhang et al., 2020), embedding debiasing (Bolukbasi et al., 2016a; Wang et al., 2020), and adversarial debiasing (Zhang et al., 2018). In particular, Bolukbasi et al. (2016a) proposed to reduce representational harm existent in word embeddings. Zhang et al. (2020) proposed instance weighting, a method to debias text classification models for bias against examples containing demog"
2021.findings-acl.294,P19-1159,1,0.902051,"Missing"
2021.findings-acl.294,2020.acl-main.484,0,0.0209055,"odgett et al., 2020). In toxicity classification, Adragna et al. (2020) and (Zhang et al., 2020) study the fairness in predicting toxic internet contents in which the contents contain demographic identity-terms (e.g., “gay”, “black”). In occupation classification, De-Arteaga et al. (2019) and Romanov et al. (2019) study the impact of including explicit gender indicators such as a person’s names or a pronoun in online biographies. Some notable bias mitigation methods, which we also use in this paper, include instance weighting (Zhang et al., 2020), embedding debiasing (Bolukbasi et al., 2016a; Wang et al., 2020), and adversarial debiasing (Zhang et al., 2018). In particular, Bolukbasi et al. (2016a) proposed to reduce representational harm existent in word embeddings. Zhang et al. (2020) proposed instance weighting, a method to debias text classification models for bias against examples containing demographic identityterms by weighting the instances in the loss function, and that is optimized for demographic pairty. Zhang et al. (2018) presents an adversarial training approach to achieve various notions of fairness 3326 Model Saliency Map Example 1 Baseline IBP Example 2 Baseline IBP Table 5: Gradien"
2021.findings-acl.294,2020.acl-main.317,0,0.0598504,"Missing"
2021.findings-acl.294,2020.acl-main.380,0,0.229298,"cation, such as domain and intent classification in voice assistants (Su et al., 2018) or code tagging in healthcare (Kemp et al., 2019). In this study, we focus on toxicity classifi∗ * Equal contribution Jwala Dhamala Amazon Alexa jddhamal@amazon.com cation (Dixon et al., 2018) and occupation classification of Wikipedia biographies (De-Arteaga et al., 2019). For toxicity classification, ensuring fairness means ensuring that a model can identify toxicity to a similar accuracy across all examples regardless of the protected groups present in the example. Past studies (e.g, (Dixon et al., 2018; Zhang et al., 2020; Zhao and Chang, 2020)) have shown that toxicity classification models will falsely classify text containing certain protected attributes as toxic. Leading social media platforms and internet companies use toxicity classification models for content moderation (Gorwa et al., 2020), thus having bias in such models can lead to increased silencing of under-served groups. Similarly, for occupation classification, a fair model should correctly identify occupations given a biography, regardless of the protected group that a person belongs to (DeArteaga et al., 2019). Recently, several studies have d"
2021.findings-acl.294,D18-1521,1,0.836754,"ntent moderation (Gorwa et al., 2020), thus having bias in such models can lead to increased silencing of under-served groups. Similarly, for occupation classification, a fair model should correctly identify occupations given a biography, regardless of the protected group that a person belongs to (DeArteaga et al., 2019). Recently, several studies have demonstrated societal bias in NLP systems (Hutchinson et al., 2020; Tan and Celis, 2019; Liang et al., 2020) and various approaches have been proposed to mitigate the bias. These approaches include creating balanced datasets (Park et al., 2018; Zhao et al., 2018a), developing methods optimized for particular fairness notions (Zhang et al., 2017, 2020), model calibration (Zhao et al., 2017; Jia et al., 2020), and reducing representational bias (Bolukbasi et al., 2016b; Zhao et al., 2018b; Liang et al., 2020). Separately, certified robustness approaches (Jia et al., 2019; Ye et al., 2020) have been developed to ensure robustness against word substitution attacks. Specifically, these strategies ensure small perturbations in the input embedding space do not alter model predictions. Despite never having been discussed in prior literature, this corresponds"
2021.findings-acl.294,2021.acl-long.426,1,0.716697,"account other parts of the sentence, resulting in less bias. that is achieved by training an adversary to identify information on protected groups and training the model to minimize the adversary loss. These approaches are designed for reducing specific types of bias exhibited in data. On the robustness front, it has been shown that models are susceptible to adversarial word substitution attacks (Ebrahimi et al., 2018; Jia and Liang, 2017). Parallel to the development of methods developed to reduce word substitution robustness in the NLP domain (e.g., (Miyato et al., 2017; Huang et al., 2019; Zhou et al., 2021)), many studies has been done in the computer vision domain to ensure that models are robust to image noising (Kannan et al., 2018; Szegedy et al., 2014). In the intersection of area between fairness and robustness of model training, there is limited prior work in the NLP area. Nanda et al. (2020) investigate and define robustness bias, a notion of fairness in which a model must be impervious to perturbations to the same degree for all subgroups, and investigate robustness bias in the computer vision domain. Adragna et al. (2020) examine the use of invariant risk minimization in improving the"
2021.findings-acl.294,P17-1179,0,0.0232406,"increased silencing of under-served groups. Similarly, for occupation classification, a fair model should correctly identify occupations given a biography, regardless of the protected group that a person belongs to (DeArteaga et al., 2019). Recently, several studies have demonstrated societal bias in NLP systems (Hutchinson et al., 2020; Tan and Celis, 2019; Liang et al., 2020) and various approaches have been proposed to mitigate the bias. These approaches include creating balanced datasets (Park et al., 2018; Zhao et al., 2018a), developing methods optimized for particular fairness notions (Zhang et al., 2017, 2020), model calibration (Zhao et al., 2017; Jia et al., 2020), and reducing representational bias (Bolukbasi et al., 2016b; Zhao et al., 2018b; Liang et al., 2020). Separately, certified robustness approaches (Jia et al., 2019; Ye et al., 2020) have been developed to ensure robustness against word substitution attacks. Specifically, these strategies ensure small perturbations in the input embedding space do not alter model predictions. Despite never having been discussed in prior literature, this corresponds to notions of fairness, since protected attribute information (e.g. gender) is ofte"
2021.findings-acl.294,2020.emnlp-main.155,1,0.708158,"in and intent classification in voice assistants (Su et al., 2018) or code tagging in healthcare (Kemp et al., 2019). In this study, we focus on toxicity classifi∗ * Equal contribution Jwala Dhamala Amazon Alexa jddhamal@amazon.com cation (Dixon et al., 2018) and occupation classification of Wikipedia biographies (De-Arteaga et al., 2019). For toxicity classification, ensuring fairness means ensuring that a model can identify toxicity to a similar accuracy across all examples regardless of the protected groups present in the example. Past studies (e.g, (Dixon et al., 2018; Zhang et al., 2020; Zhao and Chang, 2020)) have shown that toxicity classification models will falsely classify text containing certain protected attributes as toxic. Leading social media platforms and internet companies use toxicity classification models for content moderation (Gorwa et al., 2020), thus having bias in such models can lead to increased silencing of under-served groups. Similarly, for occupation classification, a fair model should correctly identify occupations given a biography, regardless of the protected group that a person belongs to (DeArteaga et al., 2019). Recently, several studies have demonstrated societal bi"
2021.findings-acl.294,D17-1323,1,0.786466,"milarly, for occupation classification, a fair model should correctly identify occupations given a biography, regardless of the protected group that a person belongs to (DeArteaga et al., 2019). Recently, several studies have demonstrated societal bias in NLP systems (Hutchinson et al., 2020; Tan and Celis, 2019; Liang et al., 2020) and various approaches have been proposed to mitigate the bias. These approaches include creating balanced datasets (Park et al., 2018; Zhao et al., 2018a), developing methods optimized for particular fairness notions (Zhang et al., 2017, 2020), model calibration (Zhao et al., 2017; Jia et al., 2020), and reducing representational bias (Bolukbasi et al., 2016b; Zhao et al., 2018b; Liang et al., 2020). Separately, certified robustness approaches (Jia et al., 2019; Ye et al., 2020) have been developed to ensure robustness against word substitution attacks. Specifically, these strategies ensure small perturbations in the input embedding space do not alter model predictions. Despite never having been discussed in prior literature, this corresponds to notions of fairness, since protected attribute information (e.g. gender) is often irrelevant to the task 3320 Findings of the"
2021.findings-acl.294,N18-2003,1,0.827255,"ntent moderation (Gorwa et al., 2020), thus having bias in such models can lead to increased silencing of under-served groups. Similarly, for occupation classification, a fair model should correctly identify occupations given a biography, regardless of the protected group that a person belongs to (DeArteaga et al., 2019). Recently, several studies have demonstrated societal bias in NLP systems (Hutchinson et al., 2020; Tan and Celis, 2019; Liang et al., 2020) and various approaches have been proposed to mitigate the bias. These approaches include creating balanced datasets (Park et al., 2018; Zhao et al., 2018a), developing methods optimized for particular fairness notions (Zhang et al., 2017, 2020), model calibration (Zhao et al., 2017; Jia et al., 2020), and reducing representational bias (Bolukbasi et al., 2016b; Zhao et al., 2018b; Liang et al., 2020). Separately, certified robustness approaches (Jia et al., 2019; Ye et al., 2020) have been developed to ensure robustness against word substitution attacks. Specifically, these strategies ensure small perturbations in the input embedding space do not alter model predictions. Despite never having been discussed in prior literature, this corresponds"
2021.findings-acl.364,2020.acl-main.485,0,0.0664049,"Missing"
2021.findings-acl.364,W19-3621,0,0.0271378,"ip) and Microsoft Ph.D. Research Fellowship. The authors thank Peter Clark and the anonymous reviewers for helpful input, and the Beaker team for their support with experiments. 4162 Ethics and Broader Implications This paper presents a new task of introducing natural language interventions to reduce social stereotypes in model predictions. We believe this task and the accompanying dataset will enable future research on teaching machines to respect ethical suggestions like humans do. We acknowledge several limitations of the proposed techniques. First, as discussed in the literature (e.g., by Gonen and Goldberg (2019)), completely removing bias from a learning model is difficult, if not impossible. Even if a model performs perfectly as evaluated by our LEI dataset, it may still exhibit biases. Second, the interventions themselves may contain human biases. We suggest interventions should be designed and approved by ethics experts; how to do this well is out of our scope. Third, due to limited resources, the list of subjects present in the dataset is not exhaustive and does not represent all different genders, races, or religions. Finally, explainability is essential for models claiming to be capable of taki"
2021.findings-acl.364,2020.acl-main.703,0,0.0324634,"nding challenge for the community.1 1 Figure 1: An example instance of how textual interventions are expected to change model behavior. Introduction McCarthy et al. (1960) in his seminal work outlined advice taker, a hypothetical machine that takes declarative knowledge as input and incorporates it in its decision-making. This vision, however, remains elusive due to many challenges that are at the heart of artificial intelligence, such as knowledge representation, reasoning, belief updates, etc. Now after several decades, thanks in part to pretrained neural language models (Liu et al., 2019b; Lewis et al., 2020; Raffel et al., 2020), we have high quality systems for many challenge tasks that seemed ?Warning: Paper contains potentially offensive examples. 1 https://github.com/allenai/ethical-interventions impossible just a few years ago (Wang et al., 2019; Clark et al., 2020). Motivated by this success, we revisit an aspect of McCarthy et al.’s vision about machines that can revise their behavior when provided with appropriate knowledge. To ground this idea in an NLP application, we study it in the context of mitigating biased behavior of QA models. We introduce LEI, a benchmark to study the ability"
2021.findings-acl.364,N19-1225,0,0.0625277,"Missing"
2021.findings-acl.364,D19-2004,1,0.764792,"t interventions and their generalization is still an open problem. 2020). For example, Rudinger et al. (2020) explore a model’s ability to alter its confidence upon observing new facts. Clark et al. (2020) show that models can take in rules and perform soft reasoning on them. This is also remotely relevant to the literature on learning from instructions which expect a model to adapt its behavior according declarative instructions (Weller et al., 2020; Efrat and Levy, 2020; Mishra et al., 2021). Our work also touches upon the fairness literature (e.g., Bolukbasi et al., 2016; Dev et al., 2020; Chang et al., 2019; Blodgett et al., 2020; Sun et al., 2019). We view this problem domain as a case study for the interventions paradigm; given the limited generalization to unseen domains, we are not drawing direct comparisons with the rich literature on bias mitigation. 5 Conclusion Evaluation on Specified Context Instances. Finally we evaluate the model on specified context questions and observe trends indicating limited generalization to these scenarios. Since the context of these questions reveals the answer. a model is justifiably expected to prefer the subject specified by the context (hence, a high µ sc"
2021.findings-acl.364,D16-1264,0,0.0511543,"s not understand ethical interventions. Quality Assessment We conducted a pilot study on 60 randomly selected instances (question+context+intervention). Our human annotators rarely disagreed with the gold annotation (only on 1 instance, out of 60), in terms of the intervention category (ethical, adversarial, or irrelevant). 2.5 ethical 0.8 Experiments How do transformer-based QA models respond out-of-the-box to interventions? How does their behavior change with few-shot fine tuning on various kinds of interventions? To assess this, we use RoBERTa-large (Liu et al., 2019b) fine-tuned on SQuAD (Rajpurkar et al., 2016) as our base model. Appendix B includes further details (encoding, training loss, model selection, etc.). Zero-Shot Evaluation. Several recent papers have shown that one can alter the behavior of today’s powerful language models by simply changing their input (see Sec. 4). Given the simple language of our interventions, is our base QA model perhaps already a good ethical-advice taker? As Fig. 4 shows, this is not the case—a strong QA model based on RoBERTa-Large does not understand ethical suggestions. Neither do ethical interventions lower the µ value, nor are the control conditions met. We o"
2021.findings-acl.364,2020.findings-emnlp.418,0,0.055272,"Missing"
2021.findings-acl.364,2020.findings-emnlp.291,1,0.893556,"Missing"
2021.findings-acl.364,P19-1159,1,0.844999,"still an open problem. 2020). For example, Rudinger et al. (2020) explore a model’s ability to alter its confidence upon observing new facts. Clark et al. (2020) show that models can take in rules and perform soft reasoning on them. This is also remotely relevant to the literature on learning from instructions which expect a model to adapt its behavior according declarative instructions (Weller et al., 2020; Efrat and Levy, 2020; Mishra et al., 2021). Our work also touches upon the fairness literature (e.g., Bolukbasi et al., 2016; Dev et al., 2020; Chang et al., 2019; Blodgett et al., 2020; Sun et al., 2019). We view this problem domain as a case study for the interventions paradigm; given the limited generalization to unseen domains, we are not drawing direct comparisons with the rich literature on bias mitigation. 5 Conclusion Evaluation on Specified Context Instances. Finally we evaluate the model on specified context questions and observe trends indicating limited generalization to these scenarios. Since the context of these questions reveals the answer. a model is justifiably expected to prefer the subject specified by the context (hence, a high µ score). Here, we evaluate the models RoBERTa"
2021.findings-acl.364,D19-1221,0,0.0229835,"icating context-specific principles to it as part of the input. Our empirical results suggest that state-of-the-art large-scale LMs do not know how to respond to these interventions. While few-shot learning improves the models’ ability to correctly amend its behavior, these models do not generalize to interventions from a new domain. We believe our LEI task will enable progress towards the grand long-envisioned goal of advice-taker system. 4 Acknowledgments Related Work A range of recent works are based on the general idea of models revising their behavior according to changes in their input (Wallace et al., 2019; Gardner et al., 2020; Emelin et al., 2020; Ye and Ren, 2021; Schick and Sch¨utze, 2020; Sheng et al., This work was supported by AI2 (JZ’s part-time internship) and Microsoft Ph.D. Research Fellowship. The authors thank Peter Clark and the anonymous reviewers for helpful input, and the Beaker team for their support with experiments. 4162 Ethics and Broader Implications This paper presents a new task of introducing natural language interventions to reduce social stereotypes in model predictions. We believe this task and the accompanying dataset will enable future research on teaching machines"
2021.findings-acl.364,2020.emnlp-main.105,0,0.0429226,"iliar’ with the notion of interventions. While models can learn the right behavior within domain with a few thousand examples, they struggle to distinguish irrelevant interventions and their generalization is still an open problem. 2020). For example, Rudinger et al. (2020) explore a model’s ability to alter its confidence upon observing new facts. Clark et al. (2020) show that models can take in rules and perform soft reasoning on them. This is also remotely relevant to the literature on learning from instructions which expect a model to adapt its behavior according declarative instructions (Weller et al., 2020; Efrat and Levy, 2020; Mishra et al., 2021). Our work also touches upon the fairness literature (e.g., Bolukbasi et al., 2016; Dev et al., 2020; Chang et al., 2019; Blodgett et al., 2020; Sun et al., 2019). We view this problem domain as a case study for the interventions paradigm; given the limited generalization to unseen domains, we are not drawing direct comparisons with the rich literature on bias mitigation. 5 Conclusion Evaluation on Specified Context Instances. Finally we evaluate the model on specified context questions and observe trends indicating limited generalization to these sc"
2021.findings-emnlp.232,2020.acl-main.449,1,0.832412,"both models receive similar scores, with a slightly higher score for SCODER in terms of similarity to the target code, relevancy, and compilability. This shows that the quality of the code generated by SCODE-G are competitive with real code from programmers’ perspective. Interestingly, REDCODER achieves higher scores than SCODE-R in CodeBLEU and Exact Match even on the cases where its BLEU score is lower. 7 Related Works Code Summarization. In recent years, source code summarization attracted a lot of attention (Iyer et al., 2016; Liang and Zhu, 2018; Allamanis et al., 2016; Hu et al., 2018b; Ahmad et al., 2020). Many of these works view code as a sequence of token. Other approaches leverage the structural properties of code using Tree based model (Shido et al., 2019; Harer et al., 2019; Hu et al., 2018a; LeClair et al., 2019). In literature, several retrieval-based methods were proposed that leverage retrieved information along with the input code. For example, Zhang et al. (2020) retrieves similar code snippet and use those as an auxiliary input for summarization. On the other hand, Hayati et al. (2018) retrieves related summaries for augmenting summarization input. Different from these approaches,"
2021.findings-emnlp.232,2020.findings-emnlp.139,0,0.0351855,"Missing"
2021.findings-emnlp.232,K19-1049,0,0.0180051,"del (Karpukhin et al., 2020) and we call it SCODE-R (Summary and CODE Retriever). SCODE-R composed of two encoders that encode source code and natural language summary. We use bidirectional Transformer encoders (Vaswani et al., 2017) that are pre-trained on source code and natural language summaries. Specifically, we explore CodeBERT (Feng et al., 2020b) and GraphCodeBERT (Guo et al., 2021) as the code and summary encoders for SCODE-R. Input/Output SCODE-R takes an input seKarpukhin et al. (2020) propose to fine-tune quence x (code or summary) and retrieves a set DPR using in-batch negatives (Gillick et al., 2019; of relevant documents from a database of output Yih et al., 2011) with curated “hard” negatives us- sequences Y (if the input is code, then the output 2721 Figure 5: REDCODER-EXT input for code generation. Figure 4: Training scheme of the retriever module (SCODE-R) of our proposed framework REDCODER for the code generation task. Unlike in open-domain QA (Karpukhin et al., 2020), we do not use “hard” negatives (e.g., candidates retrieved by BM25 that do not exactly match the reference) during fine-tuning. is summary and vice versa). SCODE-R returns the the top-k output sequences {Y1 , Y2 , ."
2021.findings-emnlp.232,P19-1082,0,0.0534202,"Missing"
2021.findings-emnlp.232,D18-1111,0,0.0181805,"t of attention (Iyer et al., 2016; Liang and Zhu, 2018; Allamanis et al., 2016; Hu et al., 2018b; Ahmad et al., 2020). Many of these works view code as a sequence of token. Other approaches leverage the structural properties of code using Tree based model (Shido et al., 2019; Harer et al., 2019; Hu et al., 2018a; LeClair et al., 2019). In literature, several retrieval-based methods were proposed that leverage retrieved information along with the input code. For example, Zhang et al. (2020) retrieves similar code snippet and use those as an auxiliary input for summarization. On the other hand, Hayati et al. (2018) retrieves related summaries for augmenting summarization input. Different from these approaches, REDCODER leverages both the retrieved code and its summary to augment the input. Code Generation. Generating source code is a major stepping stone towards automated programming. Yin and Neubig (2017), and Rabinovich et al. (2017) proposed code generation as abstract syntax tree generation to ensure its syntactic correctness. Recent advancements in pre-training language models on unlabeled source code data (Lu et al., 2021; Ahmad et al., 2021) showed colossal promise towards learning code syntax an"
2021.findings-emnlp.232,2021.ccl-1.108,0,0.0589781,"Missing"
2021.findings-emnlp.232,D15-1166,0,0.0560936,"Missing"
2021.findings-emnlp.232,P02-1040,0,0.108764,"Missing"
2021.findings-emnlp.232,P18-1221,1,0.899797,"Missing"
2021.findings-emnlp.232,P17-1105,0,0.0292913,"et al., 2019). In literature, several retrieval-based methods were proposed that leverage retrieved information along with the input code. For example, Zhang et al. (2020) retrieves similar code snippet and use those as an auxiliary input for summarization. On the other hand, Hayati et al. (2018) retrieves related summaries for augmenting summarization input. Different from these approaches, REDCODER leverages both the retrieved code and its summary to augment the input. Code Generation. Generating source code is a major stepping stone towards automated programming. Yin and Neubig (2017), and Rabinovich et al. (2017) proposed code generation as abstract syntax tree generation to ensure its syntactic correctness. Recent advancements in pre-training language models on unlabeled source code data (Lu et al., 2021; Ahmad et al., 2021) showed colossal promise towards learning code syntax and semantics, resulting in improved code generation models. take roughly 30 minutes to perform the evaluation. Code Retrieval and Others. Numerous software engineering applications require information retrieval. Sadowski et al. (2015); Xia et al. (2017); Stolee et al. (2014); Sim et al. (2011) show that developers search for r"
2021.findings-emnlp.232,2020.acl-main.538,0,0.0198103,"ng}@cs.ucla.edu, {saikatc, rayb}@cs.columbia.edu Abstract such as different variables, operators, keywords, classes, and method names (Parvez et al., 2018), Software developers write a lot of source code which requires understanding the programming lanand documentation during software developguages at lexical, syntax, and semantics levels. ment. Intrinsically, developers often recall To combat these issues, recent studies (e.g., Ahparts of source code or code summaries that mad et al. (2021); Guo et al. (2021); Xu et al. they had written in the past while implement(2020); Feng et al. (2020a); Xu et al. (2020)) take ing software or documenting them. To mimic developers’ code or summary generation bea learning-based approach—they train representahavior, we propose a retrieval augmented tions of code and the associated text by leveraging framework, REDCODER, that retrieves relexisting high-quality source code and short text evant code or summaries from a retrieval descriptions available in open-source repositories database and provides them as a supplement and question answering forums such as GitHub to code generation or summarization modand Stack Overflow. Then fine-tune the represenels. REDCODER h"
2021.findings-emnlp.232,W11-0329,0,0.0116114,"Retriever). SCODE-R composed of two encoders that encode source code and natural language summary. We use bidirectional Transformer encoders (Vaswani et al., 2017) that are pre-trained on source code and natural language summaries. Specifically, we explore CodeBERT (Feng et al., 2020b) and GraphCodeBERT (Guo et al., 2021) as the code and summary encoders for SCODE-R. Input/Output SCODE-R takes an input seKarpukhin et al. (2020) propose to fine-tune quence x (code or summary) and retrieves a set DPR using in-batch negatives (Gillick et al., 2019; of relevant documents from a database of output Yih et al., 2011) with curated “hard” negatives us- sequences Y (if the input is code, then the output 2721 Figure 5: REDCODER-EXT input for code generation. Figure 4: Training scheme of the retriever module (SCODE-R) of our proposed framework REDCODER for the code generation task. Unlike in open-domain QA (Karpukhin et al., 2020), we do not use “hard” negatives (e.g., candidates retrieved by BM25 that do not exactly match the reference) during fine-tuning. is summary and vice versa). SCODE-R returns the the top-k output sequences {Y1 , Y2 , . . . , Yk }, where sim(x, Yi ) ≥ sim(x, Yj )∀j > i. Training We fine"
2021.findings-emnlp.232,P17-1041,0,0.182631,"s, automating source code generation CODER, we take motivation from how developers and summarization is receiving significant attention due to its potential in increasing programmers’ pro- take advantage of existing resources. For example, ductivity and reducing developers’ tedious work- developers often search for relevant code in the code repository, and if found, adapt the retrieved load. Consequently, various approaches have been explored in the literature to facilitate code genera- code in their own context. Similarly, when an API usage is unclear, they search in question answering tion (Yin and Neubig, 2017; Gu et al., 2016) and code documentation/summarization (Ahmad et al., forums (e.g., StackOverflow) (Brandt et al., 2010; 2020; Wei et al., 2019; Allamanis et al., 2018). Sadowski et al., 2015). Such an additional resource helps developers to increase their development proDespite initial success, most of the generated code still suffers from poor code quality (Xu et al., 2021). ductivity (Li et al., 2013). Therefore, the question remains—how to generate We design REDCODER as a two-step process better code from a given summary and vice versa. (see Figure 1). In the first step, given the input ("
2021.findings-emnlp.292,P17-1171,0,0.0302325,"s severely hurts questions with long-tail relations. the generalization of trained QA systems. To improve the open-domain QA systems for 1 Introduction questions with long-tail relations, in this paper, we Open domain question answering is a challeng- propose RGPT-QA, a simple yet effective Relationing task that answers factoid questions based on Guided Pre-training framework for training QA evidence in a large corpus (e.g., Wikipedia). Most models with augmented relationa facts from knowlopen-domain QA systems follow retriever-reader edge graph. The framework consists of two steps: pipeline (Chen et al., 2017), in which a retriever 1) generate a relational QA dataset that covers a selects a subset of candidate entities and associated wide range of relations without human labeling; passages from the corpus that might contain the 2) pre-train a QA model to predict latent relations answer, then a reader extracts a text span from the from questions and conduct extractive QA. passages as the answer. This process involves mulThe key of our framework is to generate a relatiple entities that are relevant to answer the question. tional QA dataset that align entities in Wikipedia The QA system is required to"
2021.findings-emnlp.292,N18-2092,0,0.0187575,"abbri et al., 2020) and pre-trained language model (Puri et al., 2020) over masked cloze-style questions for more human-readable questions. These cloze-style unsupervised QA methods achieve promising performance than previous heuristic QA baselines but underperform supervised ones. The main limitation is that the question is generated with the masked context as input, resulting in severe overlap of lexicon and word surface with the context. Consequently, the QA model might utilize the lexical pattern as a shortcut to find the answer. To address the problem of context-question lexical overlap, Dhingra et al. (2018) assume each article has an introductory paragraph, and use this paragraph to generate answer. Li et al. (2020) retrieve the Wikipedia cited document as context, Pan et al. (2020) leverage structured tables to extract key information from context, with which to synthesize questions. To tackle the challenges in previous studies, our framework propose to leverage the Wikipedia hyperlinks and Wikidata relations as the bridge to connect two entities with linked descriptions. With one description as question and the other as context, the question and context are semantically relevant and lexical di"
2021.findings-emnlp.292,2020.acl-main.413,0,0.0154317,"vised QA via Question Generation To train a QA system without human annotation of QA pairs, Unsupervised QA has been proposed by Lewis et al. (2019) to generate synthetic hcontext, question, answeri data for training QA models. Lewis et al. (2019) synthesize the QA data by: 1) run NER or noun chunkers over randomly sampled English Wikipedia paragraphs to extract answers; 2) Treat the paragraphs surrounding the answer as context; 3) Treat the context as clozestyle question and feed into a unsupervised machine translator to generate natural questions. Some follow-up works also utilize template (Fabbri et al., 2020) and pre-trained language model (Puri et al., 2020) over masked cloze-style questions for more human-readable questions. These cloze-style unsupervised QA methods achieve promising performance than previous heuristic QA baselines but underperform supervised ones. The main limitation is that the question is generated with the masked context as input, resulting in severe overlap of lexicon and word surface with the context. Consequently, the QA model might utilize the lexical pattern as a shortcut to find the answer. To address the problem of context-question lexical overlap, Dhingra et al. (201"
2021.findings-emnlp.292,2020.emnlp-main.550,0,0.198121,"a factoid question q, the QA system first retrieves K relevant passages {pj }K j=1 from the corpus C. Then a reading comprehension module extracts a text span wstart , . . . , wend from one of these retrieved passages as the answer a to the question. Some QA dataset annotated the passage where the answer a is derived. We called this passage ground truth passage. For the retriever, earlier systems utilize termbased retrieval methods, such as TF-IDF and BM25, which fails to capture the semantic relationship between question and passage beyond lexical matching. Recent studies (Lee et al., 2019; Karpukhin et al., 2020; Dhingra et al., 2020) use BERT-like pretrained language model to encode the question and passages independently into dense representations, and use maximum inner product search (MIPS) algorithms (Shrivastava and Li, 2014) to efficiently retrieve the most similar passage for each question. In this paper, we utilize Dense Passage Retriever (DPR) (Karpukhin et al., 2020) as the base QA model. Relation Bias of Existing QA Datasets. We first explore how much relational knowledge between entities is required to answer the questions in the existing open-domain QA dataset. We con3432 duct an empiric"
2021.findings-emnlp.292,Q19-1026,0,0.0518981,"Missing"
2021.findings-emnlp.292,P19-1612,0,0.259723,"al. (2017). Given a factoid question q, the QA system first retrieves K relevant passages {pj }K j=1 from the corpus C. Then a reading comprehension module extracts a text span wstart , . . . , wend from one of these retrieved passages as the answer a to the question. Some QA dataset annotated the passage where the answer a is derived. We called this passage ground truth passage. For the retriever, earlier systems utilize termbased retrieval methods, such as TF-IDF and BM25, which fails to capture the semantic relationship between question and passage beyond lexical matching. Recent studies (Lee et al., 2019; Karpukhin et al., 2020; Dhingra et al., 2020) use BERT-like pretrained language model to encode the question and passages independently into dense representations, and use maximum inner product search (MIPS) algorithms (Shrivastava and Li, 2014) to efficiently retrieve the most similar passage for each question. In this paper, we utilize Dense Passage Retriever (DPR) (Karpukhin et al., 2020) as the base QA model. Relation Bias of Existing QA Datasets. We first explore how much relational knowledge between entities is required to answer the questions in the existing open-domain QA dataset. We"
2021.findings-emnlp.292,P19-1484,0,0.0278313,"uide embedDec. 20, 2018 and split each article into passages of ding encoded over entity description. 100 disjoint words as the corpus. For each question We initialize DPR base encoders by the released in all the three datasets, we use a passage from the pre-trained models of these two work, and then fineprocessed Wikipedia which contains the answer as tune on each QA dataset with the same procedure. positive passages. We evaluate the QA system by Exact Match (EM) Accuracy on the correct answer. We also add a Unsupervised Question AnswerOur RGPT-QA could be integrated with any ing (Unsup.QA) (Lewis et al., 2019) as a baseline. open-domain QA system. In this paper, we incor- For each entity as the answer, Unsup.QA selects porate it with the recently developed QA system, a passage containing the entity as context passage Dense Passage Retriever (DPR) (Karpukhin et al., and a cloze question. The cloze question is later re2020) to evaluate our pre-training framework. The written by a machine translator to natural language. DPR model uses the RoBERTa-base (d=768, l=12) We use the generated QA dataset to pre-train both 3436 where L∗ are linear project layers with different parameters. Note that the re-rank"
2021.findings-emnlp.292,2020.acl-main.600,0,0.0900223,"as r. For the other triplets hs, r, ti without alignment with hyperlinks, we extract all mentioning of target entity t from the Wiki-page of s, and use the context passage as desc.(s, t). The dataset statistics are shown in Table 1. In this section, we will discuss RGPT-QA frame- Relational QA Pair Generation In the following, we introduce the details to generate the relawork in: 1) how to generate relational QA dataset for the pre-training purpose; and 2) how to con- tional QA pair from the constructed graph. struct a self-training task to empower QA model to Recent unsupervised QA studies (Li et al., 2020; capture relational facts. Pan et al., 2020) revealed that if the question q and 3433 Figure 3: Example of a generated relational QA pair from Grounded Relational Wiki-Graph. context passage p+ share a large lexical overlap, then the QA model could utilize low-level lexical patterns as shortcuts to find the answer. These shortcuts hinder the model from learning to comprehend the passages and answer the questions, hurting model’s generalizability. To avoid this lexical overlap issue, we aim to generate questions from a passage that is different from the context passage p+ . We first select all"
2021.findings-emnlp.292,D19-1284,0,0.0288103,"Missing"
2021.findings-emnlp.292,D19-1005,0,0.0249022,"o context sentences. REALM (Guu et al., 2020a) incorporates a retriever as a module into language model and trains the whole model over masked entity spans. We directly report the results listed in their pa4 Experiments pers as they follow the same experiment settings. We also add two knowledge-guided language In this section, we evaluate RGPT-QA on three models as baselines. Though not targeted at QA open-domain QA datasets: Natural Questions problem, these two methods are both designed to (NQ), Trivia QA and Web Questions (WQ). capture structured knowledge. 4.1 Experiment Settings KnowBERT (Peters et al., 2019) adds entity emWe follow the pre-processing procedure de- bedding to each entity mention in text, and adopts the entity linking objective to pre-train the model. scribed in DPR (Karpukhin et al., 2020) for a fair KEPLER (Wang et al., 2019) uses Knowledge comparison. We use the English Wikipedia from Embedding objective, i.e., TransE, to guide embedDec. 20, 2018 and split each article into passages of ding encoded over entity description. 100 disjoint words as the corpus. For each question We initialize DPR base encoders by the released in all the three datasets, we use a passage from the pre-t"
2021.findings-emnlp.292,2020.emnlp-main.468,0,0.0149436,"without human annotation of QA pairs, Unsupervised QA has been proposed by Lewis et al. (2019) to generate synthetic hcontext, question, answeri data for training QA models. Lewis et al. (2019) synthesize the QA data by: 1) run NER or noun chunkers over randomly sampled English Wikipedia paragraphs to extract answers; 2) Treat the paragraphs surrounding the answer as context; 3) Treat the context as clozestyle question and feed into a unsupervised machine translator to generate natural questions. Some follow-up works also utilize template (Fabbri et al., 2020) and pre-trained language model (Puri et al., 2020) over masked cloze-style questions for more human-readable questions. These cloze-style unsupervised QA methods achieve promising performance than previous heuristic QA baselines but underperform supervised ones. The main limitation is that the question is generated with the masked context as input, resulting in severe overlap of lexicon and word surface with the context. Consequently, the QA model might utilize the lexical pattern as a shortcut to find the answer. To address the problem of context-question lexical overlap, Dhingra et al. (2018) assume each article has an introductory paragrap"
2021.findings-emnlp.292,P19-1139,0,0.0629641,"Missing"
2021.naacl-main.108,S14-2010,0,0.0874498,"Missing"
2021.naacl-main.108,S16-1081,0,0.13826,"h other. If two sen- denoising objectives. Parallel paraphrase data is tences are more semantically related, their corre- a good source of learning the distinction between sponding sentence embeddings are closer. As sen- semantics and syntax, as paraphrase pairs naturally tence embeddings can be used to measures seman- share the same meaning but often differ in syntax. tic relatedness without requiring supervised data, Taking advantage of this fact, ParaBART is trained they have been used in many applications, such as to perform syntax-guided paraphrasing, where a semantic textual similarity (Agirre et al., 2016a), source sentence containing the desired semantics question answering (Nakov et al., 2017), and nat- and a parse tree specifying the desired syntax are ural language inference (Artetxe and Schwenk, given as inputs. In order to generate a paraphrase 1372 Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 1372–1379 June 6–11, 2021. ©2021 Association for Computational Linguistics that follows the given syntax, ParaBART uses separate encoders to learn disentangled semantic and syntactic representat"
2021.naacl-main.108,S12-1051,0,0.072092,"Missing"
2021.naacl-main.108,S13-1004,0,0.0264993,"Missing"
2021.naacl-main.108,Q19-1038,0,0.125601,"as the desired syntax is already provided by the syntax input. ParaBART achieves strong performance across unsupervised semantic textual similarity tasks. Furthermore, semantic embeddings learned by ParaBART contain significantly less syntactic information as suggested by probing results, and yield robust performance on datasets with syntactic variation. Our source code is available at https:// github.com/uclanlp/ParaBART. 2 Related Work Various sentence embedding models have been proposed in recent years. Most of these models utilize supervision from parallel data (Wieting and Gimpel, 2018; Artetxe and Schwenk, 2019b; Wieting et al., 2019, 2020), natural language inference data (Conneau et al., 2017; Cer et al., 2018; Reimers and Gurevych, 2019), or a combination of both (Subramanian et al., 2018). Figure 1: An overview of ParaBART. The model extracts semantic and syntactic representations from a source sentence and a target parse respectively, and uses both the semantic sentence embedding and the target syntactic representations to generate the target paraphrase. ParaBART is trained in an adversarial setting, with the syntax discriminator (red) trying to decode the source syntax from the semantic embedd"
2021.naacl-main.108,P19-1602,0,0.017168,"embeddings. ParaBART is trained to generate syntax-guided paraphrases, where the model attempts to only extract the semantic part from the input sentence, and combine it with a different synMany efforts towards controlled text generation tax specified by the additional syntax input in the have been focused on learning disentangled sen- form of a constituency parse tree. tence representations (Hu et al., 2017; Fu et al., Figure 1 outlines the proposed model, which 2018; John et al., 2019). In the context of disen- consists of a semantic encoder that learns the setangling semantics and syntax, Bao et al. (2019) mantics of a source sentence, a syntactic encoder and Chen et al. (2019) utilize variational autoen- that encodes the desired syntax of a paraphrase, coders to learn two latent variables for semantics and a decoder that generates a corresponding paraand syntax. In contrast, we use the outputs of a phrase. Additionally, we add a syntax discriminator constituency parser to learn purely syntactic rep- to adversarially remove syntactic information from resentations, and facilitate the usage of powerful the semantic embeddings. pre-trained language models as semantic encoders. Given a source sente"
2021.naacl-main.108,D18-2029,0,0.0543811,"Missing"
2021.naacl-main.108,N19-1254,0,0.543869,"where the model attempts to only extract the semantic part from the input sentence, and combine it with a different synMany efforts towards controlled text generation tax specified by the additional syntax input in the have been focused on learning disentangled sen- form of a constituency parse tree. tence representations (Hu et al., 2017; Fu et al., Figure 1 outlines the proposed model, which 2018; John et al., 2019). In the context of disen- consists of a semantic encoder that learns the setangling semantics and syntax, Bao et al. (2019) mantics of a source sentence, a syntactic encoder and Chen et al. (2019) utilize variational autoen- that encodes the desired syntax of a paraphrase, coders to learn two latent variables for semantics and a decoder that generates a corresponding paraand syntax. In contrast, we use the outputs of a phrase. Additionally, we add a syntax discriminator constituency parser to learn purely syntactic rep- to adversarially remove syntactic information from resentations, and facilitate the usage of powerful the semantic embeddings. pre-trained language models as semantic encoders. Given a source sentence S1 and a target conOur approach is also related to prior work stituen"
2021.naacl-main.108,L18-1269,0,0.0181244,"dentify bigram word reordering Benchmark test set (Cer et al., 2017), where the (BShift), estimate parse tree depth (TreeDepth), goal is to predict a continuous-valued score be- and predict parse tree top-level constituents (Toptween 0 and 5 indicating how similar the meanings Const). Top-level constituents are defined as the of a sentence pair are. For all models, we compute group of constituency parse tree nodes immediately the cosine similarity of embedding vectors as the below the sentence (S) node. We use the datasets semantic similarity measure. We use the standard provided by SentEval (Conneau and Kiela, 2018) SentEval toolkit (Conneau and Kiela, 2018) for to train a Multi-Layer Perceptron classifier with a evaluation and report average Pearson correlation single 50-neuron hidden layer on top of semantic over all domains. sentence embeddings, and report accuracy on all 1375 QQP-Easy What are the essential skills of the project management? What are the essential skills of a project manager? QQP-Hard Is there a reason why we should travel alone? What are some reasons to travel alone? Model Avg. BART embed. InferSent VGVAE USE Sentence-BERT ParaBART - w/o AL - w/o AL and SG Table 3: Examples of paraph"
2021.naacl-main.108,D17-1070,0,0.513094,"d therefore are form syntax-guided paraphrasing, based on a not suitable for sentence-level semantic tasks. source sentence that shares semantics with the Ideally, the semantic embedding of a sentence target paraphrase, and a parse tree that specishould not encode its syntax, and two semantically fies the target syntax. In this way, ParaBART similar sentences should have close semantic emlearns disentangled semantic and syntactic representations from their respective inputs with beddings regardless of their syntactic differences. separate encoders. Experiments in English While various models (Conneau et al., 2017; Cer show that ParaBART outperforms state-of-theet al., 2018; Reimers and Gurevych, 2019) have art sentence embedding models on unsuperbeen proposed to improve the performance of senvised semantic similarity tasks. Additionally, tence embeddings on downstream semantic tasks, we show that our approach can effectively remost of these approaches do not attempt to separate move syntactic information from semantic sensyntactic information from sentence embeddings. tence embeddings, leading to better robustness against syntactic variation on downstream seTo this end, we propose ParaBART, a semantic"
2021.naacl-main.108,P18-1198,0,0.0188263,"imilarity. Training ParaBART on paraphrase data substantially improves the correlation. With the addition of syntactic guidance and adversarial loss, ParaBART achieves the best overall performance across STS tasks, showing the effectiveness of our approach. 4.3 Syntactic Probing To better understand how well our model learns to disentangle syntactic information from seman4.2 Semantic Textual Similarity tic embeddings, we probe our semantic sentence We evaluate our semantic sentence embeddings embeddings with downstream syntactic tasks. Folon the unsupervised Semantic Textual Similarity lowing Conneau et al. (2018), we investigate to (STS) tasks from SemEval 2012 to 2016 (Agirre what degree our semantic sentence embeddings et al., 2012; 2013; 2014; 2015; 2016b) and STS can be used to identify bigram word reordering Benchmark test set (Cer et al., 2017), where the (BShift), estimate parse tree depth (TreeDepth), goal is to predict a continuous-valued score be- and predict parse tree top-level constituents (Toptween 0 and 5 indicating how similar the meanings Const). Top-level constituents are defined as the of a sentence pair are. For all models, we compute group of constituency parse tree nodes immediat"
2021.naacl-main.108,N19-1423,0,0.0406672,"encoder needs to accu- ParaNMT-50M (Wieting and Gimpel, 2018), and rately capture the semantics of the source sentence split this dataset into 5,000 pairs as the validation for a paraphrase to be generated. Meanwhile, the set and the rest as our training set. The constituency full syntactic structure of the target is provided by parse trees of all sentences are obtained from Stanthe syntactic encoder, thus encouraging the seman- ford CoreNLP (Manning et al., 2014). We finetic encoder to ignore the source syntax. tune a 6-layer BARTbase encoder as the semantic 1374 Model Avg. BERT embeddings (Devlin et al., 2019) Avg. BART embeddings (Lewis et al., 2020) InferSent (Conneau et al., 2017) VGVAE (Chen et al., 2019) USE (Cer et al., 2018) Sentence-BERT (Reimers and Gurevych, 2019) BGT (Wieting et al., 2020) ParaBART - w/o adversarial loss - w/o adversarial loss and syntactic guidance STS12 46.9 50.8 59.3 61.8 61.4 64.6 68.9 68.4 67.5 66.4 STS13 52.8 42.8 59.0 62.2 63.5 67.5 62.2* 71.1 70.0 65.3 STS14 57.2 56.1 70.0 69.2 70.6 73.2 75.9 76.4 75.8 73.6 STS15 63.5 63.9 71.5 72.5 74.3 74.3 79.4 80.7 80.9 80.0 STS16 64.5 59.5 71.5 67.8 73.9 70.1 79.3 80.1 80.0 78.6 STS-B 47.9 52.0 70.0 74.2 74.2 74.1 78.5 78.7"
2021.naacl-main.108,2020.acl-main.22,0,0.107557,"Missing"
2021.naacl-main.108,2021.eacl-main.88,1,0.681046,"a syntax discriminator constituency parser to learn purely syntactic rep- to adversarially remove syntactic information from resentations, and facilitate the usage of powerful the semantic embeddings. pre-trained language models as semantic encoders. Given a source sentence S1 and a target conOur approach is also related to prior work stituency parse tree P2 , ParaBART is trained to on syntax-controlled paraphrase generation (Iyyer generate a paraphrase S2 that shares the semantics et al., 2018; Kumar et al., 2020; Goyal and Dur- of S1 and conforms to the syntax specified by P2 . rett, 2020; Huang and Chang, 2021). While these Semantics and syntax are two key aspects that deapproaches focus on generating high-quality para- termine how a sentence is generated. Our model phrases that conform to the desired syntax, we are learns purely syntactic representations from the outinterested in how semantic and syntactic informa- put trees generated by a constituency parser, and tion can be disentangled and how to obtain good extracts the semantic embedding directly from the semantic sentence embeddings. source sentence. The syntax discriminator and the 1373 syntactic encoder are designed to remove source syntax"
2021.naacl-main.108,P15-1162,0,0.060226,"Missing"
2021.naacl-main.108,N18-1170,0,0.0960219,"Missing"
2021.naacl-main.108,P19-1041,0,0.113134,"oposed Model – ParaBART Our goal is to build a semantic sentence embedding model that learns to separate syntax from semantic embeddings. ParaBART is trained to generate syntax-guided paraphrases, where the model attempts to only extract the semantic part from the input sentence, and combine it with a different synMany efforts towards controlled text generation tax specified by the additional syntax input in the have been focused on learning disentangled sen- form of a constituency parse tree. tence representations (Hu et al., 2017; Fu et al., Figure 1 outlines the proposed model, which 2018; John et al., 2019). In the context of disen- consists of a semantic encoder that learns the setangling semantics and syntax, Bao et al. (2019) mantics of a source sentence, a syntactic encoder and Chen et al. (2019) utilize variational autoen- that encodes the desired syntax of a paraphrase, coders to learn two latent variables for semantics and a decoder that generates a corresponding paraand syntax. In contrast, we use the outputs of a phrase. Additionally, we add a syntax discriminator constituency parser to learn purely syntactic rep- to adversarially remove syntactic information from resentations, and faci"
2021.naacl-main.108,2020.tacl-1.22,0,0.0669996,"a corresponding paraand syntax. In contrast, we use the outputs of a phrase. Additionally, we add a syntax discriminator constituency parser to learn purely syntactic rep- to adversarially remove syntactic information from resentations, and facilitate the usage of powerful the semantic embeddings. pre-trained language models as semantic encoders. Given a source sentence S1 and a target conOur approach is also related to prior work stituency parse tree P2 , ParaBART is trained to on syntax-controlled paraphrase generation (Iyyer generate a paraphrase S2 that shares the semantics et al., 2018; Kumar et al., 2020; Goyal and Dur- of S1 and conforms to the syntax specified by P2 . rett, 2020; Huang and Chang, 2021). While these Semantics and syntax are two key aspects that deapproaches focus on generating high-quality para- termine how a sentence is generated. Our model phrases that conform to the desired syntax, we are learns purely syntactic representations from the outinterested in how semantic and syntactic informa- put trees generated by a constituency parser, and tion can be disentangled and how to obtain good extracts the semantic embedding directly from the semantic sentence embeddings. source s"
2021.naacl-main.108,2020.acl-main.703,0,0.0251441,"g and Gimpel, 2018), and rately capture the semantics of the source sentence split this dataset into 5,000 pairs as the validation for a paraphrase to be generated. Meanwhile, the set and the rest as our training set. The constituency full syntactic structure of the target is provided by parse trees of all sentences are obtained from Stanthe syntactic encoder, thus encouraging the seman- ford CoreNLP (Manning et al., 2014). We finetic encoder to ignore the source syntax. tune a 6-layer BARTbase encoder as the semantic 1374 Model Avg. BERT embeddings (Devlin et al., 2019) Avg. BART embeddings (Lewis et al., 2020) InferSent (Conneau et al., 2017) VGVAE (Chen et al., 2019) USE (Cer et al., 2018) Sentence-BERT (Reimers and Gurevych, 2019) BGT (Wieting et al., 2020) ParaBART - w/o adversarial loss - w/o adversarial loss and syntactic guidance STS12 46.9 50.8 59.3 61.8 61.4 64.6 68.9 68.4 67.5 66.4 STS13 52.8 42.8 59.0 62.2 63.5 67.5 62.2* 71.1 70.0 65.3 STS14 57.2 56.1 70.0 69.2 70.6 73.2 75.9 76.4 75.8 73.6 STS15 63.5 63.9 71.5 72.5 74.3 74.3 79.4 80.7 80.9 80.0 STS16 64.5 59.5 71.5 67.8 73.9 70.1 79.3 80.1 80.0 78.6 STS-B 47.9 52.0 70.0 74.2 74.2 74.1 78.5 78.7 75.4 Avg. 55.5 54.2 66.9 68.0 69.7 70.6 75"
2021.naacl-main.108,P14-5010,0,0.00533287,"n semantic tasks. 4.1 Setup Since the syntactic representations do not contain We sample 1 million English paraphrase pairs from semantics, the semantic encoder needs to accu- ParaNMT-50M (Wieting and Gimpel, 2018), and rately capture the semantics of the source sentence split this dataset into 5,000 pairs as the validation for a paraphrase to be generated. Meanwhile, the set and the rest as our training set. The constituency full syntactic structure of the target is provided by parse trees of all sentences are obtained from Stanthe syntactic encoder, thus encouraging the seman- ford CoreNLP (Manning et al., 2014). We finetic encoder to ignore the source syntax. tune a 6-layer BARTbase encoder as the semantic 1374 Model Avg. BERT embeddings (Devlin et al., 2019) Avg. BART embeddings (Lewis et al., 2020) InferSent (Conneau et al., 2017) VGVAE (Chen et al., 2019) USE (Cer et al., 2018) Sentence-BERT (Reimers and Gurevych, 2019) BGT (Wieting et al., 2020) ParaBART - w/o adversarial loss - w/o adversarial loss and syntactic guidance STS12 46.9 50.8 59.3 61.8 61.4 64.6 68.9 68.4 67.5 66.4 STS13 52.8 42.8 59.0 62.2 63.5 67.5 62.2* 71.1 70.0 65.3 STS14 57.2 56.1 70.0 69.2 70.6 73.2 75.9 76.4 75.8 73.6 STS15 6"
2021.naacl-main.108,S17-2003,0,0.02649,"tically related, their corre- a good source of learning the distinction between sponding sentence embeddings are closer. As sen- semantics and syntax, as paraphrase pairs naturally tence embeddings can be used to measures seman- share the same meaning but often differ in syntax. tic relatedness without requiring supervised data, Taking advantage of this fact, ParaBART is trained they have been used in many applications, such as to perform syntax-guided paraphrasing, where a semantic textual similarity (Agirre et al., 2016a), source sentence containing the desired semantics question answering (Nakov et al., 2017), and nat- and a parse tree specifying the desired syntax are ural language inference (Artetxe and Schwenk, given as inputs. In order to generate a paraphrase 1372 Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 1372–1379 June 6–11, 2021. ©2021 Association for Computational Linguistics that follows the given syntax, ParaBART uses separate encoders to learn disentangled semantic and syntactic representations from their respective inputs. In this way, the disentangled representations capture suf"
2021.naacl-main.108,D19-1410,0,0.282663,"ce-level semantic tasks. source sentence that shares semantics with the Ideally, the semantic embedding of a sentence target paraphrase, and a parse tree that specishould not encode its syntax, and two semantically fies the target syntax. In this way, ParaBART similar sentences should have close semantic emlearns disentangled semantic and syntactic representations from their respective inputs with beddings regardless of their syntactic differences. separate encoders. Experiments in English While various models (Conneau et al., 2017; Cer show that ParaBART outperforms state-of-theet al., 2018; Reimers and Gurevych, 2019) have art sentence embedding models on unsuperbeen proposed to improve the performance of senvised semantic similarity tasks. Additionally, tence embeddings on downstream semantic tasks, we show that our approach can effectively remost of these approaches do not attempt to separate move syntactic information from semantic sensyntactic information from sentence embeddings. tence embeddings, leading to better robustness against syntactic variation on downstream seTo this end, we propose ParaBART, a semantic mantic tasks. sentence embedding model that learns to disentangle semantics and syntax in"
2021.naacl-main.108,P18-1042,0,0.273093,"ax of the source sentence, as the desired syntax is already provided by the syntax input. ParaBART achieves strong performance across unsupervised semantic textual similarity tasks. Furthermore, semantic embeddings learned by ParaBART contain significantly less syntactic information as suggested by probing results, and yield robust performance on datasets with syntactic variation. Our source code is available at https:// github.com/uclanlp/ParaBART. 2 Related Work Various sentence embedding models have been proposed in recent years. Most of these models utilize supervision from parallel data (Wieting and Gimpel, 2018; Artetxe and Schwenk, 2019b; Wieting et al., 2019, 2020), natural language inference data (Conneau et al., 2017; Cer et al., 2018; Reimers and Gurevych, 2019), or a combination of both (Subramanian et al., 2018). Figure 1: An overview of ParaBART. The model extracts semantic and syntactic representations from a source sentence and a target parse respectively, and uses both the semantic sentence embedding and the target syntactic representations to generate the target paraphrase. ParaBART is trained in an adversarial setting, with the syntax discriminator (red) trying to decode the source synt"
2021.naacl-main.108,P19-1453,0,0.0164146,"ready provided by the syntax input. ParaBART achieves strong performance across unsupervised semantic textual similarity tasks. Furthermore, semantic embeddings learned by ParaBART contain significantly less syntactic information as suggested by probing results, and yield robust performance on datasets with syntactic variation. Our source code is available at https:// github.com/uclanlp/ParaBART. 2 Related Work Various sentence embedding models have been proposed in recent years. Most of these models utilize supervision from parallel data (Wieting and Gimpel, 2018; Artetxe and Schwenk, 2019b; Wieting et al., 2019, 2020), natural language inference data (Conneau et al., 2017; Cer et al., 2018; Reimers and Gurevych, 2019), or a combination of both (Subramanian et al., 2018). Figure 1: An overview of ParaBART. The model extracts semantic and syntactic representations from a source sentence and a target parse respectively, and uses both the semantic sentence embedding and the target syntactic representations to generate the target paraphrase. ParaBART is trained in an adversarial setting, with the syntax discriminator (red) trying to decode the source syntax from the semantic embedding, and the paraphrasi"
2021.naacl-main.108,2020.emnlp-main.122,0,0.15718,"be generated. Meanwhile, the set and the rest as our training set. The constituency full syntactic structure of the target is provided by parse trees of all sentences are obtained from Stanthe syntactic encoder, thus encouraging the seman- ford CoreNLP (Manning et al., 2014). We finetic encoder to ignore the source syntax. tune a 6-layer BARTbase encoder as the semantic 1374 Model Avg. BERT embeddings (Devlin et al., 2019) Avg. BART embeddings (Lewis et al., 2020) InferSent (Conneau et al., 2017) VGVAE (Chen et al., 2019) USE (Cer et al., 2018) Sentence-BERT (Reimers and Gurevych, 2019) BGT (Wieting et al., 2020) ParaBART - w/o adversarial loss - w/o adversarial loss and syntactic guidance STS12 46.9 50.8 59.3 61.8 61.4 64.6 68.9 68.4 67.5 66.4 STS13 52.8 42.8 59.0 62.2 63.5 67.5 62.2* 71.1 70.0 65.3 STS14 57.2 56.1 70.0 69.2 70.6 73.2 75.9 76.4 75.8 73.6 STS15 63.5 63.9 71.5 72.5 74.3 74.3 79.4 80.7 80.9 80.0 STS16 64.5 59.5 71.5 67.8 73.9 70.1 79.3 80.1 80.0 78.6 STS-B 47.9 52.0 70.0 74.2 74.2 74.1 78.5 78.7 75.4 Avg. 55.5 54.2 66.9 68.0 69.7 70.6 75.9 75.5 73.2 Table 1: Pearson’s r (in percentage) between cosine similarity of sentence embeddings and gold labels on STS tasks from 2012 to 2016 and ST"
2021.naacl-main.108,2020.emnlp-main.733,0,0.0447153,"s with Pre-trained Language Models James Y. Huang and Kuan-Hao Huang and Kai-Wei Chang University of California, Los Angeles {jyhuang, khhuang, kwchang}@cs.ucla.edu Abstract 2019a). Recent years have seen huge success of prePre-trained language models have achieved trained language models across a wide range of huge success on a wide range of NLP tasks. NLP tasks (Devlin et al., 2019; Lewis et al., 2020). However, contextual representations from preHowever, several studies (Reimers and Gurevych, trained models contain entangled semantic and syntactic information, and therefore cannot be 2019; Li et al., 2020) have found that sentence directly used to derive useful semantic senembeddings from pre-trained language models pertence embeddings for some tasks. Paraphrase form poorly on semantic similarity tasks when the pairs offer an effective way of learning the models are not fine-tuned on task-specific data. distinction between semantics and syntax, as Meanwhile, Goldberg (2019) shows that BERT they naturally share semantics and often vary without fine-tuning performs surprisingly well on in syntax. In this work, we present ParaBART, syntactic tasks. Hence, we posit that these cona semantic sentence"
2021.naacl-main.211,2020.emnlp-main.728,0,0.438723,"Missing"
2021.naacl-main.211,2020.acl-main.747,0,0.0147405,"re unlabeled and cannot be trivially used to acquire PLUG task-specific supervision. However, PLUG tasks have a common prerequisite — understanding PL and NL syntax and semantics. Leveraging unlabelled data to pretrain a model to learn PL and NL representation can be transferred across PLUG tasks. This approach reduces the requirement of having large-scale annotations for taskspecific fine-tuning. In recent years we have seen a colossal effort to pretrain models on a massive amount of unlabeled data (e.g., text, images, videos) (Devlin et al., 2019; Liu et al., 2019; Conneau and Lample, 2019; Conneau et al., 2020; Li et al., 2019; Sun et al., 2019) to transfer representation encoders across a wide variety of applications. There are a few research effort in learning general purpose PL-NL representation encoders, such as CodeBERT (Feng et al., 2020) and GraphCodeBERT (Guo et al., 2021) that are pretrained on a small-scale bimodal data (code-text pairs). Such models have been found effective for PLUG tasks, including code search, code completion, etc. Java Python NL All Size 352 GB 224 GB 79 GB All - Nb of tokens 36.4 B 28 B 6.7 B All - Nb of documents 470 M 210 M 47 M Table 1: Statistics of the data use"
2021.naacl-main.211,D18-1192,0,0.446977,"n We fine-tune PLBART on sequence classification tasks following Lewis et al. (2020). The input sequence is fed into both the encoder and decoder. For a pair of inputs, we concatenate them but insert a special token (“&lt;/s&gt;”) between them. A special token is added at the end of the input sequence. This last token’s representation from the final decoder layer is fed into a linear classifier for prediction. Code Generation is exactly the opposite of code summarization. It refers to the task of generating a code (in a target PL) from its NL description. We fine-tune PLBART on the Concode dataset (Iyer et al., 2018), where the input is a text describing class member functions in Java and class environment, the output is the target function. 3.1 Evaluation Tasks Code Summarization refers to the task of generating a natural language (English) summary from a piece of code. We fine-tune PLBART on summarizing source code written in six different programming languages, namely, Ruby, Javascript, Go, Python, Java, and PHP. Code Translation requires a model to generate an equivalent code in the target PL from the input code written in the source PL. Note that the source and target PL can be the same. Hence, we co"
2021.naacl-main.211,2020.acl-main.703,0,0.133881,"Missing"
2021.naacl-main.211,P17-1041,0,0.0980172,"Missing"
2021.naacl-main.305,D18-1316,1,0.886136,"Missing"
2021.naacl-main.305,2020.emnlp-main.498,0,0.0267738,"Missing"
2021.naacl-main.305,P19-1147,1,0.847625,"tivity for named entities on a given set of corpus. Wallace et al. (2019b); Sheng et al. (2019, 2020) study how language generation models respond differently to prompt sentences containing mentions of different demographic groups. In contrast, our method quantifies the bias on the constructed neighborhood. First-order robustness evaluation. A line of work has been proposed to study the vulnerability of natural language models, through transformations such as character-level perturbations (Ebrahimi et al., 2018), word-level perturbations (Jin et al., 2019; Ren et al., 2019; Yang et al., 2020; Hsieh et al., 2019; Cheng et al., 2020; Li et al., 2020), prepending or appending a sequence (Jia and Liang, 2017; Wallace et al., 2019a), 6 Conclusion and generative models (Zhao et al., 2018b). They focus on constructing adversarial examples from This work proposes the double perturbation framethe test set that alter the prediction, whereas our methods focus on finding vulnerable examples be- work to identify model weaknesses beyond the test dataset, and study a stronger notion of robustness yond the test set whose prediction can be altered. and counterfactual bias. We hope that our work Robustness beyond the"
2021.naacl-main.305,2021.eacl-main.88,1,0.777206,"Missing"
2021.naacl-main.305,D19-1419,0,0.0234068,"Missing"
2021.naacl-main.305,2020.findings-emnlp.7,1,0.774509,"ur natural language setting, generating a valid example beyond test set is more challenging because language semantics and grammar must be maintained. Counterfactual fairness. Kusner et al. (2017) propose counterfactual fairness and consider a model fair if changing the protected attributes does not affect the distribution of prediction. We follow the definition and focus on evaluating the counterfactual bias between pairs of protected tokens. Existing literature quantifies fairness on a test dataset or through templates (Feldman et al., 2015; Kiritchenko and Mohammad, 2018; May et al., 2019; Huang et al., 2020). For instance, Garg et al. (2019) quantify the absolute counterfactual token fairness gap on the test set; Prabhakaran et al. (2019) study perturbation sensitivity for named entities on a given set of corpus. Wallace et al. (2019b); Sheng et al. (2019, 2020) study how language generation models respond differently to prompt sentences containing mentions of different demographic groups. In contrast, our method quantifies the bias on the constructed neighborhood. First-order robustness evaluation. A line of work has been proposed to study the vulnerability of natural language models, through tr"
2021.naacl-main.305,N18-1170,0,0.0159284,"versarial examples still 1 Introduction exist even if first-order attacks cannot find any of Recent studies show that NLP models are vulner- them from the given test dataset. Throughout this paper, we call x ˜0 a vulnerable example. The exable to adversarial perturbations. A seemingly “invariance transformation” (a.k.a. adversarial per- istence of such examples exposes weaknesses in models’ understanding and presents challenges for turbation) such as synonym substitutions (Alzantot model deployment. Fig. 1 illustrates an example. et al., 2018; Zang et al., 2020) or syntax-guided paraphrasing (Iyyer et al., 2018; Huang and Chang, In this paper, we propose the double perturba2021) can alter the prediction. To mitigate the tion framework for evaluating a stronger notion model vulnerability, robust training methods have of second-order robustness. Given a test dataset, been proposed and shown effective (Miyato et al., we consider a model to be second-order robust if 2017; Jia et al., 2019; Huang et al., 2019; Zhou there is no vulnerable example that can be idenet al., 2020). tified in the neighborhood of given test instances 3899 Proceedings of the 2021 Conference of the North American Chapter of the As"
2021.naacl-main.305,P18-2006,0,0.0191901,"ute counterfactual token fairness gap on the test set; Prabhakaran et al. (2019) study perturbation sensitivity for named entities on a given set of corpus. Wallace et al. (2019b); Sheng et al. (2019, 2020) study how language generation models respond differently to prompt sentences containing mentions of different demographic groups. In contrast, our method quantifies the bias on the constructed neighborhood. First-order robustness evaluation. A line of work has been proposed to study the vulnerability of natural language models, through transformations such as character-level perturbations (Ebrahimi et al., 2018), word-level perturbations (Jin et al., 2019; Ren et al., 2019; Yang et al., 2020; Hsieh et al., 2019; Cheng et al., 2020; Li et al., 2020), prepending or appending a sequence (Jia and Liang, 2017; Wallace et al., 2019a), 6 Conclusion and generative models (Zhao et al., 2018b). They focus on constructing adversarial examples from This work proposes the double perturbation framethe test set that alter the prediction, whereas our methods focus on finding vulnerable examples be- work to identify model weaknesses beyond the test dataset, and study a stronger notion of robustness yond the test set"
2021.naacl-main.305,D14-1162,0,0.0839159,"Missing"
2021.naacl-main.305,D19-1423,0,0.0275785,"in models’ understanding and presents challenges for turbation) such as synonym substitutions (Alzantot model deployment. Fig. 1 illustrates an example. et al., 2018; Zang et al., 2020) or syntax-guided paraphrasing (Iyyer et al., 2018; Huang and Chang, In this paper, we propose the double perturba2021) can alter the prediction. To mitigate the tion framework for evaluating a stronger notion model vulnerability, robust training methods have of second-order robustness. Given a test dataset, been proposed and shown effective (Miyato et al., we consider a model to be second-order robust if 2017; Jia et al., 2019; Huang et al., 2019; Zhou there is no vulnerable example that can be idenet al., 2020). tified in the neighborhood of given test instances 3899 Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 3899–3916 June 6–11, 2021. ©2021 Association for Computational Linguistics (§2.2). In particular, our framework first perturbs the test set to construct the neighborhood, and then diagnoses the robustness regarding a single-word synonym substitution. Taking Fig. 2 as an example, the model is first-order"
2021.naacl-main.305,D19-1578,0,0.0180801,"mar must be maintained. Counterfactual fairness. Kusner et al. (2017) propose counterfactual fairness and consider a model fair if changing the protected attributes does not affect the distribution of prediction. We follow the definition and focus on evaluating the counterfactual bias between pairs of protected tokens. Existing literature quantifies fairness on a test dataset or through templates (Feldman et al., 2015; Kiritchenko and Mohammad, 2018; May et al., 2019; Huang et al., 2020). For instance, Garg et al. (2019) quantify the absolute counterfactual token fairness gap on the test set; Prabhakaran et al. (2019) study perturbation sensitivity for named entities on a given set of corpus. Wallace et al. (2019b); Sheng et al. (2019, 2020) study how language generation models respond differently to prompt sentences containing mentions of different demographic groups. In contrast, our method quantifies the bias on the constructed neighborhood. First-order robustness evaluation. A line of work has been proposed to study the vulnerability of natural language models, through transformations such as character-level perturbations (Ebrahimi et al., 2018), word-level perturbations (Jin et al., 2019; Ren et al.,"
2021.naacl-main.305,S18-2005,0,0.0293137,"lated Work image transformations can be used, in our natural language setting, generating a valid example beyond test set is more challenging because language semantics and grammar must be maintained. Counterfactual fairness. Kusner et al. (2017) propose counterfactual fairness and consider a model fair if changing the protected attributes does not affect the distribution of prediction. We follow the definition and focus on evaluating the counterfactual bias between pairs of protected tokens. Existing literature quantifies fairness on a test dataset or through templates (Feldman et al., 2015; Kiritchenko and Mohammad, 2018; May et al., 2019; Huang et al., 2020). For instance, Garg et al. (2019) quantify the absolute counterfactual token fairness gap on the test set; Prabhakaran et al. (2019) study perturbation sensitivity for named entities on a given set of corpus. Wallace et al. (2019b); Sheng et al. (2019, 2020) study how language generation models respond differently to prompt sentences containing mentions of different demographic groups. In contrast, our method quantifies the bias on the constructed neighborhood. First-order robustness evaluation. A line of work has been proposed to study the vulnerability"
2021.naacl-main.305,2020.emnlp-main.500,0,0.0168526,"of corpus. Wallace et al. (2019b); Sheng et al. (2019, 2020) study how language generation models respond differently to prompt sentences containing mentions of different demographic groups. In contrast, our method quantifies the bias on the constructed neighborhood. First-order robustness evaluation. A line of work has been proposed to study the vulnerability of natural language models, through transformations such as character-level perturbations (Ebrahimi et al., 2018), word-level perturbations (Jin et al., 2019; Ren et al., 2019; Yang et al., 2020; Hsieh et al., 2019; Cheng et al., 2020; Li et al., 2020), prepending or appending a sequence (Jia and Liang, 2017; Wallace et al., 2019a), 6 Conclusion and generative models (Zhao et al., 2018b). They focus on constructing adversarial examples from This work proposes the double perturbation framethe test set that alter the prediction, whereas our methods focus on finding vulnerable examples be- work to identify model weaknesses beyond the test dataset, and study a stronger notion of robustness yond the test set whose prediction can be altered. and counterfactual bias. We hope that our work Robustness beyond the test set. Several works can stimulate"
2021.naacl-main.305,N19-1063,0,0.0196856,"can be used, in our natural language setting, generating a valid example beyond test set is more challenging because language semantics and grammar must be maintained. Counterfactual fairness. Kusner et al. (2017) propose counterfactual fairness and consider a model fair if changing the protected attributes does not affect the distribution of prediction. We follow the definition and focus on evaluating the counterfactual bias between pairs of protected tokens. Existing literature quantifies fairness on a test dataset or through templates (Feldman et al., 2015; Kiritchenko and Mohammad, 2018; May et al., 2019; Huang et al., 2020). For instance, Garg et al. (2019) quantify the absolute counterfactual token fairness gap on the test set; Prabhakaran et al. (2019) study perturbation sensitivity for named entities on a given set of corpus. Wallace et al. (2019b); Sheng et al. (2019, 2020) study how language generation models respond differently to prompt sentences containing mentions of different demographic groups. In contrast, our method quantifies the bias on the constructed neighborhood. First-order robustness evaluation. A line of work has been proposed to study the vulnerability of natural langua"
2021.naacl-main.305,2020.emnlp-demos.16,0,0.0273573,"Missing"
2021.naacl-main.305,N16-1018,0,0.0417444,"Missing"
2021.naacl-main.305,P19-1103,0,0.0207894,"t al. (2019) study perturbation sensitivity for named entities on a given set of corpus. Wallace et al. (2019b); Sheng et al. (2019, 2020) study how language generation models respond differently to prompt sentences containing mentions of different demographic groups. In contrast, our method quantifies the bias on the constructed neighborhood. First-order robustness evaluation. A line of work has been proposed to study the vulnerability of natural language models, through transformations such as character-level perturbations (Ebrahimi et al., 2018), word-level perturbations (Jin et al., 2019; Ren et al., 2019; Yang et al., 2020; Hsieh et al., 2019; Cheng et al., 2020; Li et al., 2020), prepending or appending a sequence (Jia and Liang, 2017; Wallace et al., 2019a), 6 Conclusion and generative models (Zhao et al., 2018b). They focus on constructing adversarial examples from This work proposes the double perturbation framethe test set that alter the prediction, whereas our methods focus on finding vulnerable examples be- work to identify model weaknesses beyond the test dataset, and study a stronger notion of robustness yond the test set whose prediction can be altered. and counterfactual bias. We h"
2021.naacl-main.305,2020.acl-main.442,0,0.0182195,"ks feedback. We thank UCLA-NLP group for the and Dietterich (2019) study more sources of com- valuable discussions and comments. The research mon corruptions such as brightness, motion blur is supported NSF #1927554, #1901527, #2008173 and fog. Unlike in computer vision where simple and #2048280 and an Amazon Research Award. 3907 Ethical Considerations Intended use. One primary goal of NLP models is the generalization to real-world inputs. However, existing test datasets and templates are often not comprehensive, and thus it is difficult to evaluate real-world performance (Recht et al., 2019; Ribeiro et al., 2020). Our work sheds a light on quantifying performance for inputs beyond the test dataset and help uncover model weaknesses prior to the realworld deployment. Misuse potential. Similar to other existing adversarial attack methods (Ebrahimi et al., 2018; Jin et al., 2019; Zhao et al., 2018b), our second-order attacks can be used for finding vulnerable examples to a NLP system. Therefore, it is essential to study how to improve the robustness of NLP models against second-order attacks. Limitations. While the core idea about the double perturbation framework is general, in §4, we consider only binar"
2021.naacl-main.305,D19-1339,1,0.847651,"r if changing the protected attributes does not affect the distribution of prediction. We follow the definition and focus on evaluating the counterfactual bias between pairs of protected tokens. Existing literature quantifies fairness on a test dataset or through templates (Feldman et al., 2015; Kiritchenko and Mohammad, 2018; May et al., 2019; Huang et al., 2020). For instance, Garg et al. (2019) quantify the absolute counterfactual token fairness gap on the test set; Prabhakaran et al. (2019) study perturbation sensitivity for named entities on a given set of corpus. Wallace et al. (2019b); Sheng et al. (2019, 2020) study how language generation models respond differently to prompt sentences containing mentions of different demographic groups. In contrast, our method quantifies the bias on the constructed neighborhood. First-order robustness evaluation. A line of work has been proposed to study the vulnerability of natural language models, through transformations such as character-level perturbations (Ebrahimi et al., 2018), word-level perturbations (Jin et al., 2019; Ren et al., 2019; Yang et al., 2020; Hsieh et al., 2019; Cheng et al., 2020; Li et al., 2020), prepending or appending a sequence ("
2021.naacl-main.305,2020.findings-emnlp.291,1,0.892576,"Missing"
2021.naacl-main.305,D13-1170,0,0.00646897,"Missing"
2021.naacl-main.361,2020.acl-main.418,0,0.0612544,"Missing"
2021.naacl-main.361,N06-2015,0,0.060045,"Missing"
2021.naacl-main.361,D17-1018,0,0.0690088,"Missing"
2021.naacl-main.361,N18-2108,0,0.0323967,"Missing"
2021.naacl-main.361,P16-1060,0,0.0294506,"a small set of training data is available, to emulate use-cases in which annotating a large amount of data is impractical. We reserve more articles in the test set to ensure the evaluation is reliable. • GICoref (Cao and Daumé III, 2020) consists of 95 documents from sources that include articles about non-binary people, fan-fiction from Archive of Our Own, and LGBTQ periodicals with a plethora of neopronouns (e.g., zie). • MAP (Cao and Daumé III, 2020) consists of snippets of Wikipedia articles with two or more people and at least one pronoun. We followed Cao and Daumé III (2020) to use LEA (Moosavi and Strube, 2016) as the evaluation metric for coreference clusters. 5.1 Results on Violent Death Narratives We created 3 rules based on the approach described in Sec. 4: (R1) Replace gendered terms with another gender. (R2) Replace gendered relationship terms with non-gendered terms. (R3) Replace terms describing gender with non-gendered terms. Examples of the generated data are in Fig. 2.7 When applying the augmented rules to the current 20/5 document split of the train/development (dev), we ended up with 100/25 train/dev documents enlarging both sets by 5 times. We compared the following models. • E2E8 The"
2021.naacl-main.361,P02-1014,0,0.505303,"of administrative text written in English: violent death narratives from the USA’s Centers for Disease Control’s (CDC) National Violent Death Reporting System. We developed a set of data augmentation rules to improve model performance using a probabilistic data programming framework. Experiments on narratives from an administrative database, as well as existing gender-inclusive coreference datasets, demonstrate the effectiveness of data augmentation in training coreference models that can better handle text data about LGBT individuals. 1 Introduction Coreference resolution (Soon et al., 2001; Ng and Cardie, 2002) is the task of identifying denotative phrases in text that refer to the same entity. It is an essential component in Natural Language Processing (NLP). In real world applications of NLP, coreference resolution is crucial for analysts to extract structured information from text data. Like all components of NLP, it is important that coreference resolution is robust and accurate, as applications of NLP may inform policy-making and other decisions. This is especially true when coreference systems are applied to administrative data, since results may inform policy-making decisions. In this paper,"
2021.naacl-main.361,N18-2002,0,0.0300719,"Missing"
2021.naacl-main.361,J01-4004,0,0.578034,"an exemplary form of administrative text written in English: violent death narratives from the USA’s Centers for Disease Control’s (CDC) National Violent Death Reporting System. We developed a set of data augmentation rules to improve model performance using a probabilistic data programming framework. Experiments on narratives from an administrative database, as well as existing gender-inclusive coreference datasets, demonstrate the effectiveness of data augmentation in training coreference models that can better handle text data about LGBT individuals. 1 Introduction Coreference resolution (Soon et al., 2001; Ng and Cardie, 2002) is the task of identifying denotative phrases in text that refer to the same entity. It is an essential component in Natural Language Processing (NLP). In real world applications of NLP, coreference resolution is crucial for analysts to extract structured information from text data. Like all components of NLP, it is important that coreference resolution is robust and accurate, as applications of NLP may inform policy-making and other decisions. This is especially true when coreference systems are applied to administrative data, since results may inform policy-making deci"
2021.naacl-main.361,Q18-1042,0,0.0161761,"t. For LGBT specific datasets, we see much larger improvements, highlighting how poor the OntoNotes model performed on these underrepresented populations before. Models trained on the new data prove more applicable in that domain. Our experiments underscore the need for a modifiable tool to train specialized coreference resolution models across a variety of specific domains and use-cases. 2 Related Work Researchers have shown coreference systems exhibit gender bias and resolve pronouns by relying heavily on gender information (Cao and Daumé III, 2020; Zhao et al., 2018; Rudinger et al., 2018; Webster et al., 2018; Zhao et al., 2019). In particular, Cao and Daumé III (2020) collected a gender-inclusive coreference dataset and evaluated how state of the art coreference models performed against them. As NLP systems are deployed in social science, policy making, government, and industry, it is imperative to keep inclusivity in mind when working with models that perform downstream tasks with text data. For example, Named Entity Recognition (NER) was used in processing Portuguese police reports to extract people, location, organization, and time from the set of documents (Carnaz et al., 2019). These authors"
2021.naacl-main.361,N19-1064,1,0.876326,"Missing"
2021.naacl-main.361,N18-2003,1,0.942076,"ctim’s partner states that he and primary_victim had been living together for three years. ... Figure 1: A snippet of a violent death narrative. Highlighted is what the e2e-coref model clusters, and the colored text shows what the e2e-coref model misses. LGBT populations. This remains challenging because of limitations of existing coreference systems. Close relationship partners provide a marker of sexual orientations and can be used (Lira et al., 2019; Ream, 2020) by social scientists to identify relevant information in LGBT deaths. However, OntoNotes is heavily skewed towards male entities (Zhao et al., 2018) and E2E-Coref relies heavily on gender when deciphering context (Cao and Daumé III, 2020). Consequently, E2E-Coref has a trouble dealing with narratives involving LGBT individuals where gender referents do not follow the modal pattern. Figure 1 illustrates a scenario where coreference systems struggle. The model mislabels the pronoun “he” and this error will propagate to downstream analysis. Specifically, the model takes the context and resolves the coreference based on gender; it makes a mistake partially due to an incorrect presumption of the sexual orientation of the 50 year old male victi"
2021.naacl-main.402,Q16-1022,0,0.052856,"Missing"
2021.naacl-main.402,N19-1253,1,0.883624,"achieve 1 In this paper, we focus on two transfer learning scenarios: 1) cross-lingual and 2) cross-domain. We train a model on a set of source corpora and evaluate on a target corpus where each “corpus” refers to the corresponding domain or language. a good transfer performance but also for analyzing the source-target relationships. Nonetheless, determining the value of a source corpus is challenging as it is affected by many factors, including the quality of the source data, the amount of the source data, and the difference between source and target at lexical, syntax and semantics levels (Ahmad et al., 2019; Lin et al., 2019). The current source valuation or ranking methods are often based on single source transfer performance (McDonald et al., 2011; Lin et al., 2019; Vu et al., 2020) or leave-one-out approaches (Tommasi and Caputo, 2009; Li et al., 2016; Feng et al., 2018; Rahimi et al., 2019). They do not consider the combinations of the sources. Consequently, they may identify the best single source corpus effectively but their top-k ranked source corpora may achieve limited gain in transfer results. In this paper, we introduce SEAL-Shap (Source 5084 Proceedings of the 2021 Conference of the"
2021.naacl-main.402,C18-1139,0,0.0173558,"ataset used in Ma et al. (2019). It is made upon modification on GLUE tasks (Wang et al., 2018) and has four domains (details in Appendix C). As GLUE test sets are unavailable, for each target domain, we use the original dev set as the pseudo test set and randomly select 2,000 instances from its training set as the pseudo dev set. Classifier and Preprocessing For all domain transfer tasks, we use BERT and for all language transfer tasks, we use multi-lingual BERT (Devlin et al., 2019) models except for cross-doman POS tagging where we consider the state-of-theart BiLSTM based Flair framework (Akbik et al., 2018). For BERT models, we use the Transformers implementations in the Huggingface library Wolf et al. (2019). For significance test, we use an opensourced library.7 By default, no preprocessing is performed except tokenization (see Appendix J). Hyper-parameters Tuning For all BERT models, we tune the learning rate, batch size, and number of epochs. We also tune the number of epochs nepoch in Algorithm 1, the threshold SEAL-Shap value θ, initial score ρ. Details are in Appendix K. 7 github.com/neubig/util-scripts/blob/ master/paired-bootstrap.py 4 Results and Discussion In the following, we first v"
2021.naacl-main.402,Q19-1038,0,0.0127005,"-Shap until empirically convergence (blue line). Then, we report the Shapley value produced by another random seed. Fig 8 shows that with enough epochs, the values computed by different random seeds are highly correlated (more in Appendix H). 5 Related Work As discussed in Section 1, transfer learning has been extensively studied in NLP to improve model performance in low-resource domains and languages. In the litearture, various approaches have been proposed to various tasks, including text classification (Zhou et al., 2016; Kim et al., 2017), natural language inference (Lample et al., 2018; Artetxe and Schwenk, 2019), sequence tagging (Täckström et al., 2013; Agi´c et al., 2016; Kim et al., 2017; Ruder and Plank, 2017), dependency parsing (Guo et al., 2015; Meng et al., 2019). These prior studies mostly focus on bridging the domain gap between sources and targets. In different contexts, methods including influence functions and Shapley values have been applied to value the contribution of training data (Koh and Liang, 2017; Lundberg et al., 2018; Jia et al., 2019a). Specifically, Monte Carlo approximation of Shapley values has been used in various applications (Maleki, 2015; Jia et al., 2019a; Ghorbani an"
2021.naacl-main.402,P07-1056,0,0.712332,"urce corpus to every possible subset of the source corpora. Each block inside SEALShap denotes a possible subset and the marginal contribution is derived by the difference of transfer results while trained with and without the corresponding source. Based on the source values, we select a subset of source corpora that achieves high transfer accuracy. Introduction Transfer learning has been widely used in learning models for low-resource scenarios by leveraging the supervision provided in data-rich source corpora. It has been applied to NLP tasks in various settings including domain adaptation (Blitzer et al., 2007; Ruder and Plank, 2017), cross-lingual transfer (Täckström et al., 2013; Wu and Dredze, 2019), and task transfer (Liu et al., 2019b; Vu et al., 2020). A common transfer learning setting is to train a model on a set of sources and then evaluate it on the corresponding target (Yao and Doretto, 2010; Yang et al., 2020).1 However, not every source corpus contributes equally to the transfer model. Some of them may even cause a performance drop (Ghorbani and Zou, 2019; Lin et al., 2019). Therefore, it is essential to understand the value of each source in the transfer learning not only to achieve 1"
2021.naacl-main.402,D18-1269,0,0.0787817,"en (b) XNLI, target: vi (c) mtl-dom-senti, target: E (d) mGLUE, target:MNLI-mm Figure 2: Performance, and run time with up to top-3 sources ranked by different approaches. (a), (b) denotes cross-lingual and (c), (d) denotes cross-domain transfer. All models have same training configurations (e.g., sample size). All the run times are final except for Greedy DFS where it increases linearly with top-k. Adding top-2 and top-3 ranked sources, other methods drop their accuracy across the tasks while ours shows a consistent gain in all tasks and achieves the best results with top-3 sources. dataset (Conneau et al., 2018), that covers 15 different languages. XNLI task is a 3-way classification task (entailment, neutral, and contradiction). Data statistics are in Appendix R. Cross-domain Datasets We consider three domain transfer tasks: (i) POS tagging: we use the SANCL 2012 shared task datasets (Petrov and McDonald, 2012) that has six different domains (details in Appendix B). (ii) Sentiment analysis: we use the multi-domain sentiment datasets (Liu et al., 2017) which has several additional domains than the popular Blitzer et al. (2007) dataset, See Appendix D. (iii) NLI: we consider a (modified) binary classi"
2021.naacl-main.402,N19-1423,0,0.0943228,"ion distribution scheme that satisfies the necessary conditions for data valuation like fairness and additivity (Dubey, 1975; Jia et al., 2019a,b). As many model explanation methods including Shapley value are computationally costly (Van den Broeck et al., 2021), in a different context of features and data valuation in machine learning, Ghorbani and Zou (2019) propose to use an approximate Shapley value to estimate the feature or data values. However, the existing approximation methods for estimating Shapley values are not scalable for NLP applications. NLP models are often large (e.g., BERT (Devlin et al., 2019)) and NLP transfer learning usually assumes a large amount of source data. To deal with the scalability issue, we propose a new sampling scheme, a truncation method, and a caching mechanism to efficiently approximate the source Shapley values. We evaluate the effectiveness of SEAL-Shap under various applications in quantifying the usefulness of the source corpora and in selecting potential transfer sources. We consider two settings of source valuation or selection: (1) where a small target corpus is available; and (2) where we only have access to the linguistic or statistical features of the t"
2021.naacl-main.402,D18-1407,0,0.0489603,"Missing"
2021.naacl-main.402,P19-1189,0,0.129849,"ibution is derived by the difference of transfer results while trained with and without the corresponding source. Based on the source values, we select a subset of source corpora that achieves high transfer accuracy. Introduction Transfer learning has been widely used in learning models for low-resource scenarios by leveraging the supervision provided in data-rich source corpora. It has been applied to NLP tasks in various settings including domain adaptation (Blitzer et al., 2007; Ruder and Plank, 2017), cross-lingual transfer (Täckström et al., 2013; Wu and Dredze, 2019), and task transfer (Liu et al., 2019b; Vu et al., 2020). A common transfer learning setting is to train a model on a set of sources and then evaluate it on the corresponding target (Yao and Doretto, 2010; Yang et al., 2020).1 However, not every source corpus contributes equally to the transfer model. Some of them may even cause a performance drop (Ghorbani and Zou, 2019; Lin et al., 2019). Therefore, it is essential to understand the value of each source in the transfer learning not only to achieve 1 In this paper, we focus on two transfer learning scenarios: 1) cross-lingual and 2) cross-domain. We train a model on a set of sou"
2021.naacl-main.402,N19-1112,0,0.104038,"ibution is derived by the difference of transfer results while trained with and without the corresponding source. Based on the source values, we select a subset of source corpora that achieves high transfer accuracy. Introduction Transfer learning has been widely used in learning models for low-resource scenarios by leveraging the supervision provided in data-rich source corpora. It has been applied to NLP tasks in various settings including domain adaptation (Blitzer et al., 2007; Ruder and Plank, 2017), cross-lingual transfer (Täckström et al., 2013; Wu and Dredze, 2019), and task transfer (Liu et al., 2019b; Vu et al., 2020). A common transfer learning setting is to train a model on a set of sources and then evaluate it on the corresponding target (Yao and Doretto, 2010; Yang et al., 2020).1 However, not every source corpus contributes equally to the transfer model. Some of them may even cause a performance drop (Ghorbani and Zou, 2019; Lin et al., 2019). Therefore, it is essential to understand the value of each source in the transfer learning not only to achieve 1 In this paper, we focus on two transfer learning scenarios: 1) cross-lingual and 2) cross-domain. We train a model on a set of sou"
2021.naacl-main.402,W18-5446,0,0.0721733,"Missing"
2021.naacl-main.402,N18-1101,0,0.0285748,"Missing"
2021.naacl-main.402,D19-1077,0,0.0495662,"a possible subset and the marginal contribution is derived by the difference of transfer results while trained with and without the corresponding source. Based on the source values, we select a subset of source corpora that achieves high transfer accuracy. Introduction Transfer learning has been widely used in learning models for low-resource scenarios by leveraging the supervision provided in data-rich source corpora. It has been applied to NLP tasks in various settings including domain adaptation (Blitzer et al., 2007; Ruder and Plank, 2017), cross-lingual transfer (Täckström et al., 2013; Wu and Dredze, 2019), and task transfer (Liu et al., 2019b; Vu et al., 2020). A common transfer learning setting is to train a model on a set of sources and then evaluate it on the corresponding target (Yao and Doretto, 2010; Yang et al., 2020).1 However, not every source corpus contributes equally to the transfer model. Some of them may even cause a performance drop (Ghorbani and Zou, 2019; Lin et al., 2019). Therefore, it is essential to understand the value of each source in the transfer learning not only to achieve 1 In this paper, we focus on two transfer learning scenarios: 1) cross-lingual and 2) cross-dom"
2021.naacl-main.420,2020.acl-main.536,0,0.34269,"in V&L pre-training. We are inspired by works on multi-lingual contextual language models (Pires et al., 2019). If we treat an image as a set of regions and each region as a visual token (Dosovitskiy et al., 2020), V&L models share a similar goal with multi-lingual models as they both learn shared representations across different domains. Although a multi-lingual language model pre-trained on non-parallel corpora such as mBERT (Devlin et al., 2019b) cannot align or translate languages out-of-the-box, its representation spaces for different languages can be easily aligned with a linear probe (Conneau et al., 2020). This property suggests the existence of universal latent symmetries in the unaligned contextual embedding spaces and is believed to contribute to 1 Other datasets also require cumbersome curation. For example, while Conceptual Captions is crawled from the web, the authors report that from 5 billion images gathered over the Internet, only 3 million have paired high-quality captions after filtering (Sharma et al., 2018; Changpinyo et al., 2021). 2 Following Lample et al. (2018) and Feng et al. (2019), we use the term “unsupervised” to refer to pre-training with unaligned data, while “supervise"
2021.naacl-main.420,N19-1423,0,0.604819,"ies. We find that such a simple approach achieves performance close to a model pre-trained with aligned data, on four English V&L benchmarks. Our work challenges the widely held notion that aligned data is necessary for V&L pre-training, while significantly reducing the amount of supervision needed for V&L models. 1 Introduction Pre-trained contextual vision-and-language (V&L) models (Lu et al., 2019; Tan and Bansal, 2019; Li et al., 2019; Su et al., 2019; Chen et al., 2020c) have achieved high performance on various V&L tasks. However, different from contextual language models, such as BERT (Devlin et al., 2019a), which are trained on easily-accessible unannotated text corpora, existing V&L models are still a step away from self-supervision. They require a massive amount of aligned text-image pairs for “mask-and-predict” pre-training. Such aligned data are costly to collect and hard to scale up. For example, the widely used MS-COCO dataset (Chen et al., 2015) requires extensive ∗ The two authors contributed equally. annotation from crowd workers.1 In this paper, we explore unsupervised V&L pre-training with unaligned image and text corpora.2 This research direction aligns with the theme of unsupervi"
2021.naacl-main.420,N19-1112,0,0.0233401,"ERT (SSelf-supervision involves creating supervision VisualBERT) as an example and illustrate how a objectives from natural data, often by corrupting typical V&L model is pre-trained with aligned data. the input and training the model to reconstruct Then we introduce unsupervised V&L pre-training, the input (Kolesnikov et al., 2019) or contrastive and the resulting model Unsupervised VisualBERT learning (Chen et al., 2020b). Self-supervised (U-VisualBERT). training on language (Peters et al., 2018; Devlin et al., 2019a) such as BERT has been proven useful 3.1 Background for various NLP tasks (Liu et al., 2019), while self-supervised visual representation learning has As mentioned in Section 2, there are several V&L been centered around learning low-level visual representation learning methods based on BERT. features, in hope of enhancing the backbone CNN We take Supervised VisualBERT (S-VisualBERT) (Doersch et al., 2015; Pathak et al., 2016; Noroozi as an example, which will also be used as a baseand Favaro, 2016; Chen et al., 2020b). In this line in the experiments. S-VisualBERT is modipaper, we conduct V&L pre-training by optimizing fied from the original VisualBERT (Li et al., 2019) a reconstruc"
2021.naacl-main.420,N18-1202,0,0.0107296,"t any caption text (Section 5.1). 3 Approach Self-supervised Representation Learning We first take Supervised VisualBERT (SSelf-supervision involves creating supervision VisualBERT) as an example and illustrate how a objectives from natural data, often by corrupting typical V&L model is pre-trained with aligned data. the input and training the model to reconstruct Then we introduce unsupervised V&L pre-training, the input (Kolesnikov et al., 2019) or contrastive and the resulting model Unsupervised VisualBERT learning (Chen et al., 2020b). Self-supervised (U-VisualBERT). training on language (Peters et al., 2018; Devlin et al., 2019a) such as BERT has been proven useful 3.1 Background for various NLP tasks (Liu et al., 2019), while self-supervised visual representation learning has As mentioned in Section 2, there are several V&L been centered around learning low-level visual representation learning methods based on BERT. features, in hope of enhancing the backbone CNN We take Supervised VisualBERT (S-VisualBERT) (Doersch et al., 2015; Pathak et al., 2016; Noroozi as an example, which will also be used as a baseand Favaro, 2016; Chen et al., 2020b). In this line in the experiments. S-VisualBERT is mo"
2021.naacl-main.420,P19-1493,0,0.0193892,"ing (Feng et al., 2019). Unsupervised V&L pretraining is highly desirable as in many domains, aligned data is scarce (e.g. multimodal hate speech detection (Kiela et al., 2020) and the medical domain (Li et al., 2020c)) and it is easier to collect unaligned text and images. In addition to its practical implication, our endeavour challenges the widely held notion that image-caption corpora is indispensable for pre-training (Lu et al., 2019) and brings valuable insight into the role that aligned data play in V&L pre-training. We are inspired by works on multi-lingual contextual language models (Pires et al., 2019). If we treat an image as a set of regions and each region as a visual token (Dosovitskiy et al., 2020), V&L models share a similar goal with multi-lingual models as they both learn shared representations across different domains. Although a multi-lingual language model pre-trained on non-parallel corpora such as mBERT (Devlin et al., 2019b) cannot align or translate languages out-of-the-box, its representation spaces for different languages can be easily aligned with a linear probe (Conneau et al., 2020). This property suggests the existence of universal latent symmetries in the unaligned con"
2021.naacl-main.420,W17-1101,0,0.0145759,"between H-VisualBERT that is trained on the 3M aligned data from Concep- and S-VisualBERT is similar, potentially because the “imagetext match” objective is the dominant contributor and additual Captions (CC) and additional unaligned 1.7M tional image-only data during pre-training have limited benefit images from Open Images (OI) (Kuznetsova et al., (Section 4). 5346 Ethical Considerations Jingjing Liu. 2020c. UNITER: Universal image-text representation learning. ECCV. One caveat of the proposed method is that data collected from the web may contain biases (Zhao et al., 2017), toxic contents (Schmidt and Wiegand, 2017), and other ethical issues. This problem is common to ML models and we stress that de-biasing (Zhao et al., 2019) and a rigorous examination are needed before deploying the system. Acknowledgement We would like to thank Hao Tan, members of UCLA NLP, and members of UCLA PlusLab for their helpful comments. We also thank the reviewers for the valuable reviews. This work was supported in part by DARPA MCS program under Cooperative Agreement N66001-19-2-4032. The views expressed are those of the authors and do not reflect the official policy or position of the Department of Defense or the U.S. Gove"
2021.naacl-main.420,P18-1238,0,0.147394,"s mBERT (Devlin et al., 2019b) cannot align or translate languages out-of-the-box, its representation spaces for different languages can be easily aligned with a linear probe (Conneau et al., 2020). This property suggests the existence of universal latent symmetries in the unaligned contextual embedding spaces and is believed to contribute to 1 Other datasets also require cumbersome curation. For example, while Conceptual Captions is crawled from the web, the authors report that from 5 billion images gathered over the Internet, only 3 million have paired high-quality captions after filtering (Sharma et al., 2018; Changpinyo et al., 2021). 2 Following Lample et al. (2018) and Feng et al. (2019), we use the term “unsupervised” to refer to pre-training with unaligned data, while “supervised” refers to pre-training with aligned text and images. 5339 Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 5339–5350 June 6–11, 2021. ©2021 Association for Computational Linguistics cake stubbed candles individual … Transformer Plate Hand Parameter Cabinet Transformer lit [MASK] as the age of the [MASK], or a number"
2021.naacl-main.420,P19-1644,0,0.111302,"ons are masked and the model is trained to predict properties of the masked regions. ent languages with the same meanings (e.g., “DNA” appears in both English and French). As the “overlapping vocabulary” improves cross-lingual transfer (Wu and Dredze, 2019), we argue the detector tags can improve cross-modal grounding. We first conduct controlled experiments by pretraining on an English image-caption corpus without providing the alignment, following unsupervised machine translation and image captioning (Gu et al., 2019). Results on four English V&L benchmarks (VQA (Goyal et al., 2017), NLVR2 (Suhr et al., 2019), Flickr30K Image Retrieval (Plummer et al., 2015), and RefCOCO+ (Yu et al., 2016)) show that U-VisualBERT achieves comparable performance as models with access to textimage pairs (Section 4). Additionally, our approach is effective in practical settings, 1) when using independently collected images and captions and 2) when using images To further encourage cross-modal fusion, we and general-domain text (BookCorpus (Zhu et al., leverage the tags from an object detector as “an- 2015)) without any captions (Section 5.1). Quanchor points” (Li et al., 2020b). For every object, titative and qualita"
2021.naacl-main.420,D19-1514,0,0.265547,"propose to conduct “mask-and-predict” pre-training on text-only and image-only corpora and introduce the object tags detected by an object recognition model as anchor points to bridge two modalities. We find that such a simple approach achieves performance close to a model pre-trained with aligned data, on four English V&L benchmarks. Our work challenges the widely held notion that aligned data is necessary for V&L pre-training, while significantly reducing the amount of supervision needed for V&L models. 1 Introduction Pre-trained contextual vision-and-language (V&L) models (Lu et al., 2019; Tan and Bansal, 2019; Li et al., 2019; Su et al., 2019; Chen et al., 2020c) have achieved high performance on various V&L tasks. However, different from contextual language models, such as BERT (Devlin et al., 2019a), which are trained on easily-accessible unannotated text corpora, existing V&L models are still a step away from self-supervision. They require a massive amount of aligned text-image pairs for “mask-and-predict” pre-training. Such aligned data are costly to collect and hard to scale up. For example, the widely used MS-COCO dataset (Chen et al., 2015) requires extensive ∗ The two authors contributed e"
2021.naacl-main.420,2020.emnlp-main.162,0,0.0617176,"Missing"
2021.naacl-main.420,2020.emnlp-main.159,0,0.033769,"no additional training. Studies (Wu and Dredze, 2019; Conneau et al., 2020) have confirmed several design choices that facilitate such transfer, e.g. shared parameters and overlapping vocabularies across languages, and we make similar design choices in U-VisualBERT (Section 3.2). We argue that multi-lingual representations bear resemblance to multi-modal representations as both seek to encode the alignment between two domains (Chen et al., 2020a). Unsupervised Grounding Learning Prior works have explored learning grounding with weak or no supervision (Rohrbach et al., 2016; Xiao et al., 2017; Wang et al., 2020). Closest to this paper is unsupervised image captioning (Feng et al., 2019; Laina et al., 2019; Gu et al., 2019), which conducts image captioning with unpaired images and captions. Similar to this work, the detector tags serve as the anchor points for image captioning. However, unsupervised image captioning still requires captions, while our approach works with easy-to-collect general-domain text without any caption text (Section 5.1). 3 Approach Self-supervised Representation Learning We first take Supervised VisualBERT (SSelf-supervision involves creating supervision VisualBERT) as an examp"
2021.naacl-main.420,D19-1077,0,0.21585,"inputs from both modalities. During each step of pre-training, unlike the existing models that observe a batch of text-image pairs, our model observes either a batch of text segments or a batch of images. When provided with text, part of the text is masked and the model is trained to predict the masked words; when provided with an image, part of the image regions are masked and the model is trained to predict properties of the masked regions. ent languages with the same meanings (e.g., “DNA” appears in both English and French). As the “overlapping vocabulary” improves cross-lingual transfer (Wu and Dredze, 2019), we argue the detector tags can improve cross-modal grounding. We first conduct controlled experiments by pretraining on an English image-caption corpus without providing the alignment, following unsupervised machine translation and image captioning (Gu et al., 2019). Results on four English V&L benchmarks (VQA (Goyal et al., 2017), NLVR2 (Suhr et al., 2019), Flickr30K Image Retrieval (Plummer et al., 2015), and RefCOCO+ (Yu et al., 2016)) show that U-VisualBERT achieves comparable performance as models with access to textimage pairs (Section 4). Additionally, our approach is effective in pra"
2021.naacl-main.420,N19-1064,1,0.89911,"Missing"
2021.naacl-main.420,D17-1323,1,0.825636,"model On Flickr30K, the performance between H-VisualBERT that is trained on the 3M aligned data from Concep- and S-VisualBERT is similar, potentially because the “imagetext match” objective is the dominant contributor and additual Captions (CC) and additional unaligned 1.7M tional image-only data during pre-training have limited benefit images from Open Images (OI) (Kuznetsova et al., (Section 4). 5346 Ethical Considerations Jingjing Liu. 2020c. UNITER: Universal image-text representation learning. ECCV. One caveat of the proposed method is that data collected from the web may contain biases (Zhao et al., 2017), toxic contents (Schmidt and Wiegand, 2017), and other ethical issues. This problem is common to ML models and we stress that de-biasing (Zhao et al., 2019) and a rigorous examination are needed before deploying the system. Acknowledgement We would like to thank Hao Tan, members of UCLA NLP, and members of UCLA PlusLab for their helpful comments. We also thank the reviewers for the valuable reviews. This work was supported in part by DARPA MCS program under Cooperative Agreement N66001-19-2-4032. The views expressed are those of the authors and do not reflect the official policy or position o"
2021.naacl-main.60,P19-1080,0,0.0128652,"in language generation, Curry and Rieser (2018) study how conversational systems respond to sexual harassment, and Khatri et al. (2018) detect offensive content with a semi-supervised approach. To reduce harms, Sheng et al. (2020) present a framework for controlling biases in language generation, and Dinan et al. (2019) show how adversarial attacks can make models more robust to offensive language usage from humans. Constrained Decoding For constrained decoding, prior works focus on incorporating words or phrases (as hard or soft constraints) into the decoded output. Swanson et al. (2014) and Balakrishnan et al. (2019) use parse trees among other techniques to enforce constraints in the generated text. Hokamp and Liu (2017); Post and Vilar (2018) propose variants of Grid Beam Search, which generate output that include lexical constraints. Miao et al. (2019); Zhang et al. (2020b); Susanto et al. (2020) explore insertion-based non-autoregressive decoding algorithms. To be compatible with an autoregressive model like DialoGPT and effective for open-domain generation, we apply constrained decoding to top-k sampling. Our method also differs from these prior works in that it imposes soft constraints to not genera"
2021.naacl-main.60,D19-1176,0,0.0264603,"In particular, because societal norms allow biases and stereotypes to detract from a person’s credibility or expertise, the use of ad hominems can further diminish the rhetorical credibility (Govier, 1993) of marginalized groups. Offensive Language Detection Ad hominems occur in many forms and are related to different types of offensive language, including abusive language (Yin et al., 2009; Chen et al., 2012; Nobata et al., 2016), hate speech (Warner and Hirschberg, 2012; Kwok and Wang, 2013; Djuric et al., 2015), profanity (Sood et al., 2012a), and the more subtle forms of microaggressions (Breitfeller et al., 2019) and projecting biases and stereotypes through power differentials in language (Sap et al., 2020). Ranging from outright insults to condescension, ad hominems are a form of offensive language that is difficult to comprehensively and objectively define. Nonetheless, these responses are important to characterize, since they can irreparably damage a person’s credibility. It is also generally important 2 Related Work to identify these subtle forms of offensive language, This work is related to a broad spectrum of topics, since it is unclear if existing offensive language deincluding prior definiti"
2021.naacl-main.60,W18-0802,0,0.0236369,"nce it is unclear if existing offensive language deincluding prior definitions of ad hominems and how tection techniques are equally effective for these ad hominems facilitate biases. Also, analyzing ad subtle forms. 751 Harms in Dialogue Systems Conversational systems are known to perpetuate several types of harms. Ruane et al. (2019) caution about harms that can result from using conversational systems and propose striving for trust and transparency; Roller et al. (2020) suggest techniques for chatbot safety. For analysis, Sheng et al. (2019) evaluate societal biases in language generation, Curry and Rieser (2018) study how conversational systems respond to sexual harassment, and Khatri et al. (2018) detect offensive content with a semi-supervised approach. To reduce harms, Sheng et al. (2020) present a framework for controlling biases in language generation, and Dinan et al. (2019) show how adversarial attacks can make models more robust to offensive language usage from humans. Constrained Decoding For constrained decoding, prior works focus on incorporating words or phrases (as hard or soft constraints) into the decoded output. Swanson et al. (2014) and Balakrishnan et al. (2019) use parse trees amon"
2021.naacl-main.60,P19-2028,0,0.0172099,"we discuss existing constrained decoding methods. Ad Hominems In the argumentation literature, theoretical ad hominems include the abusive (attack on the opponent’s character), tu quoque (“he did it first”), circumstantial (accusation of hypocrisy), and guilt by association (associating the opponent with someone with low credibility) (Walton, 1998; Woods, 2007). Wijze (2003) criticizes that these textbook examples are not realistic in conversation. For more empirical categories, Habernal et al. (2018) propose ad hominem types based on analysis of Reddit’s ChangeMyView discussion threads, and Delobelle et al. (2019) analyze the name-calling and abusive categories. Moreover, Wulczyn et al. (2017) use classifiers for a largescale analysis of personal attacks in Wikipedia comments. We build upon prior works to define and analyze ad hominems in a conversational setting. Additionally, Yap (2013) discusses the harmful effects of implicit biases in forming and evaluating ad hominems. They emphasize that ad hominem attacks can be harmful to a person’s credibility and expertise even if the attack is recognized as fallacious and irrelevant to the argument. In particular, because societal norms allow biases and ste"
2021.naacl-main.60,N18-1036,0,0.379476,"d-hom-in-dialogue. hominems in dialogue systems is related to examining offensive language and other harms. Lastly, we discuss existing constrained decoding methods. Ad Hominems In the argumentation literature, theoretical ad hominems include the abusive (attack on the opponent’s character), tu quoque (“he did it first”), circumstantial (accusation of hypocrisy), and guilt by association (associating the opponent with someone with low credibility) (Walton, 1998; Woods, 2007). Wijze (2003) criticizes that these textbook examples are not realistic in conversation. For more empirical categories, Habernal et al. (2018) propose ad hominem types based on analysis of Reddit’s ChangeMyView discussion threads, and Delobelle et al. (2019) analyze the name-calling and abusive categories. Moreover, Wulczyn et al. (2017) use classifiers for a largescale analysis of personal attacks in Wikipedia comments. We build upon prior works to define and analyze ad hominems in a conversational setting. Additionally, Yap (2013) discusses the harmful effects of implicit biases in forming and evaluating ad hominems. They emphasize that ad hominem attacks can be harmful to a person’s credibility and expertise even if the attack is"
2021.naacl-main.60,P17-1141,0,0.0119748,"nd Khatri et al. (2018) detect offensive content with a semi-supervised approach. To reduce harms, Sheng et al. (2020) present a framework for controlling biases in language generation, and Dinan et al. (2019) show how adversarial attacks can make models more robust to offensive language usage from humans. Constrained Decoding For constrained decoding, prior works focus on incorporating words or phrases (as hard or soft constraints) into the decoded output. Swanson et al. (2014) and Balakrishnan et al. (2019) use parse trees among other techniques to enforce constraints in the generated text. Hokamp and Liu (2017); Post and Vilar (2018) propose variants of Grid Beam Search, which generate output that include lexical constraints. Miao et al. (2019); Zhang et al. (2020b); Susanto et al. (2020) explore insertion-based non-autoregressive decoding algorithms. To be compatible with an autoregressive model like DialoGPT and effective for open-domain generation, we apply constrained decoding to top-k sampling. Our method also differs from these prior works in that it imposes soft constraints to not generate phrases that are likely to lead to ad hominems. Decoding-time techniques that can be used to reduce harm"
2021.naacl-main.60,2020.emnlp-main.88,1,0.796448,"t and not a third person. 4.1 Human Annotation We collect human annotations that can then be used for analysis and training a classifier to automatically label ad hominems. Although Habernal et al. (2018) propose a similar typology of ad hominems, there is no existing dataset annotated with their empirically-derived categories. Moreover, we study ad hominems in casual conversational settings. For these reasons, we annotate a subset of A D H OM I N T WEETS with ad hominem information. To measure inter-annotator agreement, we calculate the Worker Agreement With Aggregate (WAWA) score, following Ning et al. (2020). The WAWA score compares the majority votes against each annotator and micro-averages the resulting precision, recall, and F1 scores.5 Heuristics for Ad Hominems Ad hominem responses are relatively rare and range broadly from explicit to more subtle forms. For more effective annotation, we use heuristics to choose [post, response] pairs where the response is likely to be an ad hominem. In preliminary analyses, we find that responses that contain certain “you”-phrases such as “you are” are more likely to have ad hominems. We call these responses you-responses.6 In addition to pairs with you-re"
2021.naacl-main.60,N18-1119,0,0.0152248,"detect offensive content with a semi-supervised approach. To reduce harms, Sheng et al. (2020) present a framework for controlling biases in language generation, and Dinan et al. (2019) show how adversarial attacks can make models more robust to offensive language usage from humans. Constrained Decoding For constrained decoding, prior works focus on incorporating words or phrases (as hard or soft constraints) into the decoded output. Swanson et al. (2014) and Balakrishnan et al. (2019) use parse trees among other techniques to enforce constraints in the generated text. Hokamp and Liu (2017); Post and Vilar (2018) propose variants of Grid Beam Search, which generate output that include lexical constraints. Miao et al. (2019); Zhang et al. (2020b); Susanto et al. (2020) explore insertion-based non-autoregressive decoding algorithms. To be compatible with an autoregressive model like DialoGPT and effective for open-domain generation, we apply constrained decoding to top-k sampling. Our method also differs from these prior works in that it imposes soft constraints to not generate phrases that are likely to lead to ad hominems. Decoding-time techniques that can be used to reduce harmful language generation"
2021.naacl-main.60,2020.acl-main.486,0,0.0163347,"or expertise, the use of ad hominems can further diminish the rhetorical credibility (Govier, 1993) of marginalized groups. Offensive Language Detection Ad hominems occur in many forms and are related to different types of offensive language, including abusive language (Yin et al., 2009; Chen et al., 2012; Nobata et al., 2016), hate speech (Warner and Hirschberg, 2012; Kwok and Wang, 2013; Djuric et al., 2015), profanity (Sood et al., 2012a), and the more subtle forms of microaggressions (Breitfeller et al., 2019) and projecting biases and stereotypes through power differentials in language (Sap et al., 2020). Ranging from outright insults to condescension, ad hominems are a form of offensive language that is difficult to comprehensively and objectively define. Nonetheless, these responses are important to characterize, since they can irreparably damage a person’s credibility. It is also generally important 2 Related Work to identify these subtle forms of offensive language, This work is related to a broad spectrum of topics, since it is unclear if existing offensive language deincluding prior definitions of ad hominems and how tection techniques are equally effective for these ad hominems facilit"
2021.naacl-main.60,D19-1339,1,0.840672,"sive language, This work is related to a broad spectrum of topics, since it is unclear if existing offensive language deincluding prior definitions of ad hominems and how tection techniques are equally effective for these ad hominems facilitate biases. Also, analyzing ad subtle forms. 751 Harms in Dialogue Systems Conversational systems are known to perpetuate several types of harms. Ruane et al. (2019) caution about harms that can result from using conversational systems and propose striving for trust and transparency; Roller et al. (2020) suggest techniques for chatbot safety. For analysis, Sheng et al. (2019) evaluate societal biases in language generation, Curry and Rieser (2018) study how conversational systems respond to sexual harassment, and Khatri et al. (2018) detect offensive content with a semi-supervised approach. To reduce harms, Sheng et al. (2020) present a framework for controlling biases in language generation, and Dinan et al. (2019) show how adversarial attacks can make models more robust to offensive language usage from humans. Constrained Decoding For constrained decoding, prior works focus on incorporating words or phrases (as hard or soft constraints) into the decoded output."
2021.naacl-main.60,2020.findings-emnlp.291,1,0.907301,"o, analyzing ad subtle forms. 751 Harms in Dialogue Systems Conversational systems are known to perpetuate several types of harms. Ruane et al. (2019) caution about harms that can result from using conversational systems and propose striving for trust and transparency; Roller et al. (2020) suggest techniques for chatbot safety. For analysis, Sheng et al. (2019) evaluate societal biases in language generation, Curry and Rieser (2018) study how conversational systems respond to sexual harassment, and Khatri et al. (2018) detect offensive content with a semi-supervised approach. To reduce harms, Sheng et al. (2020) present a framework for controlling biases in language generation, and Dinan et al. (2019) show how adversarial attacks can make models more robust to offensive language usage from humans. Constrained Decoding For constrained decoding, prior works focus on incorporating words or phrases (as hard or soft constraints) into the decoded output. Swanson et al. (2014) and Balakrishnan et al. (2019) use parse trees among other techniques to enforce constraints in the generated text. Hokamp and Liu (2017); Post and Vilar (2018) propose variants of Grid Beam Search, which generate output that include"
2021.naacl-main.60,2020.acl-main.325,0,0.0119407,"ion, and Dinan et al. (2019) show how adversarial attacks can make models more robust to offensive language usage from humans. Constrained Decoding For constrained decoding, prior works focus on incorporating words or phrases (as hard or soft constraints) into the decoded output. Swanson et al. (2014) and Balakrishnan et al. (2019) use parse trees among other techniques to enforce constraints in the generated text. Hokamp and Liu (2017); Post and Vilar (2018) propose variants of Grid Beam Search, which generate output that include lexical constraints. Miao et al. (2019); Zhang et al. (2020b); Susanto et al. (2020) explore insertion-based non-autoregressive decoding algorithms. To be compatible with an autoregressive model like DialoGPT and effective for open-domain generation, we apply constrained decoding to top-k sampling. Our method also differs from these prior works in that it imposes soft constraints to not generate phrases that are likely to lead to ad hominems. Decoding-time techniques that can be used to reduce harmful language generation, e.g., the Plug and Play Language Model (PPLM) (Dathathri et al., 2020), are most relevant to our technique. 3 Dataset and Model Setup Topic # [post, Affects"
2021.naacl-main.60,2020.acl-demos.30,0,0.70891,"formulate related to abusive language, toxicity, and microag- techniques to reduce ad hominem responses and gressions, and can be expressed with both subtle thus the associated harms, which is especially imand explicitly offensive language. Table 1 presents portant for dialogue systems since these systems 750 Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 750–767 June 6–11, 2021. ©2021 Association for Computational Linguistics directly interact with users. We analyze responses from DialoGPT (Zhang et al., 2020a) and humans to English Twitter posts. Specifically, we compare responses to Twitter topics about marginalized communities (#BlackLivesMatter, #MeToo) versus other topics (#Vegan, #WFH). Through human annotation and trained classifiers, we find that ad hominems exist in both human and DialoGPT responses. Across response sources, there are more ad hominems in #BlackLivesMatter- and #MeToo-related responses, fewer in #Vegan-related responses, and even fewer in #WFH-related responses. The presence of more ad hominems in responses to social issues that concern marginalized groups has troubling im"
2021.naacl-main.60,2020.emnlp-main.698,0,0.0201101,"Missing"
2021.naacl-main.60,W14-1815,0,0.0188433,"evaluate societal biases in language generation, Curry and Rieser (2018) study how conversational systems respond to sexual harassment, and Khatri et al. (2018) detect offensive content with a semi-supervised approach. To reduce harms, Sheng et al. (2020) present a framework for controlling biases in language generation, and Dinan et al. (2019) show how adversarial attacks can make models more robust to offensive language usage from humans. Constrained Decoding For constrained decoding, prior works focus on incorporating words or phrases (as hard or soft constraints) into the decoded output. Swanson et al. (2014) and Balakrishnan et al. (2019) use parse trees among other techniques to enforce constraints in the generated text. Hokamp and Liu (2017); Post and Vilar (2018) propose variants of Grid Beam Search, which generate output that include lexical constraints. Miao et al. (2019); Zhang et al. (2020b); Susanto et al. (2020) explore insertion-based non-autoregressive decoding algorithms. To be compatible with an autoregressive model like DialoGPT and effective for open-domain generation, we apply constrained decoding to top-k sampling. Our method also differs from these prior works in that it imposes"
D13-1057,P12-1041,0,0.0241582,"Yu and Joachims (2009) formulates coreference with latent spanning trees. However, their approach has no directionality between mentions, whereas our latent structure captures the natural left-to-right ordering of mentions. In our experiments (Sec. 5), we show that our technique vastly outperforms both the spanning tree and the correlational clustering techniques. We also compare with (Fernandes et al., 2012) and the publicly available Stanford coreference system (Raghunathan et al., 2010; Lee et al., 2011), a state-of-theart rule-based system. Finally, some research (Ratinov and Roth, 2012; Bansal and Klein, 2012; Rahman and Ng, 2011a) has tried to integrate world knowledge from webbased statistics or knowledge bases into a coreference system. World knowledge is potentially useful for resolving coreference and can be injected into our system in a straightforward way via the constraints framework. We will show an example of incorporating our system with name-entity and WordNet-based similarity metric (Q. Do, 2009) in Sec. 5. Including massive amount of information from knowledge resources is not the focus of this paper and may distort the comparison with other relevant models but our results indicate t"
D13-1057,D08-1031,1,0.798393,"ls proposed in the literature. 1 Introduction Coreference resolution is a challenging task, that involves identification and clustering of noun phrases mentions that refer to the same real-world entity. Most machine learning approaches to coreference resolution learn a scoring function to estimate the compatibility between two mentions or two sets of previously clustered mentions. Then, a decoding algorithm is designed to aggregate these scores and find an optimal clustering assignment. The most popular of these frameworks is the pairwise mention model (Soon et al., 2001; Ng and Cardie, 2002; Bengtson and Roth, 2008), which learns a compatibility score of mention-pairs and uses these pairwise scores to obtain a global clustering. Recently, efforts have been made (Haghighi and Klein, 2010; Rahman and Ng, 2011b; Rahman and Ng, 2011c) to consider models that capture higher order interactions, in particular, between mentions and previously identified entities (that is, between mentions and clusters). While such models are potentially more expressive, they are largely based on heuristics to achieve computational tractability. This paper focuses on a novel and principled machine learning framework that pushes t"
D13-1057,W12-4504,0,0.0279359,"Missing"
D13-1057,P06-2019,0,0.00973685,"e resources is not the focus of this paper and may distort the comparison with other relevant models but our results indicate that this is doable in our model, and may provide significant improvements. 3 Latent Left-Linking Model with Constraints In this section, we describe our Constrained Latent Left-Linking Model (CL3 M). CL3 M is inspired by a few ideas from the literature: (a) the popular BestLeft-Link inference approach to coreference (Ng and Cardie, 2002; Bengtson and Roth, 2008), and (b) the injection of domain knowledge-based constraints for structured prediction (Roth and Yih, 2004; Clarke and Lapata, 2006; Chang et al., 2012b; Ganchev et al., 2010; Koo et al., 2010; Pascal and Baldridge, 2009). We first introduce the notion of a pairwise mention-scorer, then introduce our Left-Linking Model (L3 M), and finally describe how to inject constraints into our model. Let d be a document with md mentions. Mentions are denoted solely using their indices, ranging from 1 to md . A coreference clustering C for document 603 d is a collection of disjoint sets partitioning the set {1, . . . , md }. We represent C as a binary function with C(i, j) = 1 if mentions i and j are coreferent, otherwise C(i, j) = 0."
D13-1057,N07-1011,0,0.189366,"thm on ACE and when evaluated on the gold mentions of Ontonotes. We show that CL3 M performs particularly well on clusters containing named entity mentions, which are more important for many information extraction applications. In the rest of this section, after describing our experimental setting, we provide careful analysis of our algorithms and compare them to competitive coreference approaches in the literature. 5.1 Experimental Setup Datasets: ACE 2004 contains 443 documents — we used a standard split of these documents into 268 training, 68 development, and 106 testing documents used by Culotta et al. (2007) and Bengtson and Roth (2008). OntoNotes-5.0 dataset, released for the CoNLL 2012 Shared Task (Pradhan et al., 2012), is by far the largest annotated corpus on coreference. It contains 3,145 annotated documents drawn from a wide variety of sources — newswire, bible, broadcast transcripts, magazine articles, and web blogs. We report results on both development set and test set. To test on the development set, we further split the training data into training and development sets. Classifier details: For each of the pairwise approaches, we assume the pairwise score is given by w·φ(·, ·)+t where φ"
D13-1057,N07-1030,0,0.0389526,"ike previous best-link techniques, learning in our case is performed jointly with decoding — we present a novel latent structural SVM approach, optimized using a fast stochastic gradient-based technique. Furthermore, we present a probabilistic generalization of L3 M that is more expressive in that it is capable of considering mention-entity interactions using scores at the mention-pair granularity. We augment this model with a temperature-like parameter (Samdani et al., 2012) to provide additional flexibility. CL3 M augments L3 M with knowledge-based constraints following (Roth and Yih, 2004; Denis and Baldridge, 2007). This capability is very desirable as shown by the success of the rule-based deterministic approach of Raghunathan et al. (2010) in the CoNLL shared task 2011 (Pradhan et al., 2011). In L3 M, domain-specific constraints are incorporated into learning and inference in a straightforward way. CL3 M scores a mention’s contribution to its cluster by combining the corresponding score 601 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 601–612, c Seattle, Washington, USA, 18-21 October 2013. 2013 Association for Computational Linguistics of the underlyin"
D13-1057,D08-1069,0,0.108073,"examples. Similar approaches to training and, additionally, decoupling the training stage from the clustering stage were used by other systems. In this paper, we formalize the learning problem of the best-left-link model as a structured 602 prediction problem and analyze our system with detailed experiments. Furthermore, we generalize this approach by considering multiple pairwise left-links instead of just the best link, efficiently capturing the notion of a mention-to-cluster link. Many techniques in the coreference literature break away from the mention pair-based, best-leftlink paradigm. Denis and Baldridge (2008) and Ng (2005) learn a local ranker to rank the mention pairs based on their compatibility. While these approaches achieve decent empirical performance, it is unclear why these are the right ways to train the model. Some techniques consider a more expressive model by using features defined over mentioncluster or cluster-cluster (Rahman and Ng, 2011c; Stoyanov and Eisner, 2012; Haghighi and Klein, 2010). For these models, the inference and learning algorithms are usually complicated. Very recently, Durrett et al. (2013) propose a probabilistic model which enforces structural agreement constrain"
D13-1057,P13-1012,0,0.0277076,"rature break away from the mention pair-based, best-leftlink paradigm. Denis and Baldridge (2008) and Ng (2005) learn a local ranker to rank the mention pairs based on their compatibility. While these approaches achieve decent empirical performance, it is unclear why these are the right ways to train the model. Some techniques consider a more expressive model by using features defined over mentioncluster or cluster-cluster (Rahman and Ng, 2011c; Stoyanov and Eisner, 2012; Haghighi and Klein, 2010). For these models, the inference and learning algorithms are usually complicated. Very recently, Durrett et al. (2013) propose a probabilistic model which enforces structural agreement constraints between specified properties of mention cluster when using a mention-pair model. This approach is very related to the probabilistic extension of our method as both models attempt to leverage entity-level information from mention-pair features. However, our approach is simpler because it directly considers the probabilities of multiple links. Furthermore, while their model performs only slightly better than the Stanford rule-based system (Lee et al., 2011), we significantly outperform this system. Most importantly, o"
D13-1057,W12-4502,0,0.0691342,"Missing"
D13-1057,N10-1112,0,0.051977,"t al., 2012). Consequently, as γ → 0, P r[c ⊙ i; d, w] in Eq. 8 approaches a Kronecker delta function centered on the cluster containing the max-scoring mention, thus reducing to the best-link case of L3 M. Thus, PL3 M, when tuning the value of γ, is a strictly more general model than L3 M. Learning with PL3 M We use a likelihood-based approach to learning with PL3 M, and first compute the probability P r[C; d, w] of generating a clustering C, given w. We then learn w by minimizing the regularized negative log-likelihood of the data, augmenting the partition function with a loss-based margin (Gimpel and Smith, 2010). We omit the details of likelihood computation due to lack of space. With PL3 M, we again follow a stochastic gradient descent technique instead of CCCP for the same reasons mentioned in Sec. 3.3. The stochastic gradient (subgradient when γ = 0) w.r.t. mention i in document d is given by ∇LL(w)id ∝ X 0≤j&lt;i X pj φ(i, j) − p′j φ(i, j) + λw, 0≤j&lt;i where pj and p′j , j = 0, . . . , i − 1, are non-negative weights that sum to one and are given by 1 pj p′j = = e γ (w·φ(i,j)+δ(Cd ,i,j)) P 1 0≤k&lt;i e γ (w·φ(i,k)+δ(Cd ,i,k)) and Cd (i, j)Zi (d, w, γ) P r[j ← i; d, w] . Zi (Cd ; d, w, γ) Interestingly,"
D13-1057,N10-1061,0,0.407886,"the same real-world entity. Most machine learning approaches to coreference resolution learn a scoring function to estimate the compatibility between two mentions or two sets of previously clustered mentions. Then, a decoding algorithm is designed to aggregate these scores and find an optimal clustering assignment. The most popular of these frameworks is the pairwise mention model (Soon et al., 2001; Ng and Cardie, 2002; Bengtson and Roth, 2008), which learns a compatibility score of mention-pairs and uses these pairwise scores to obtain a global clustering. Recently, efforts have been made (Haghighi and Klein, 2010; Rahman and Ng, 2011b; Rahman and Ng, 2011c) to consider models that capture higher order interactions, in particular, between mentions and previously identified entities (that is, between mentions and clusters). While such models are potentially more expressive, they are largely based on heuristics to achieve computational tractability. This paper focuses on a novel and principled machine learning framework that pushes the state-ofthe-art while operating at a mention-pair granularity. We present two models — the Latent Left-Linking Model (L3 M), and a version of that is augmented with domain"
D13-1057,P11-1115,0,0.0109421,"score on the test set and is competitive with the best system participated in the CoNLL shared task 2012. Performance on named entities: The coreference annotation in Ontonotes 5.0 includes various types of mentions. However, not all mention types are equally interesting. In particular, clusters which contain at least one proper name or a named entity mention are more important for information extraction tasks like Wikification (Mihalcea and Csomai, 2007; Ratinov et al., 2011), cross-document coreference resolution (Bagga and Baldwin, 1998), and entity linking and knowledge based population (Ji and Grishman, 2011). Inspired by this, we compare our system to the best systems in the CoNLL shared task of 2011 (Stanford (Lee et al., 2011)) and 2012 (Fernandes (Fernandes et al., 2012)) on the following specific tasks on Ontonotes-5.0. • ENT-C: Evaluate the system on clusters that contain at least one proper name mention. We generate the gold annotation and system outputs by using the gold and predicted name entity tag annotations provided by the CoNLL shard task 2012. That is, if a cluster does not include any name entity mention, then it will be removed from the final clustering. • PER-C: As in the constru"
D13-1057,D10-1125,0,0.0117174,"rison with other relevant models but our results indicate that this is doable in our model, and may provide significant improvements. 3 Latent Left-Linking Model with Constraints In this section, we describe our Constrained Latent Left-Linking Model (CL3 M). CL3 M is inspired by a few ideas from the literature: (a) the popular BestLeft-Link inference approach to coreference (Ng and Cardie, 2002; Bengtson and Roth, 2008), and (b) the injection of domain knowledge-based constraints for structured prediction (Roth and Yih, 2004; Clarke and Lapata, 2006; Chang et al., 2012b; Ganchev et al., 2010; Koo et al., 2010; Pascal and Baldridge, 2009). We first introduce the notion of a pairwise mention-scorer, then introduce our Left-Linking Model (L3 M), and finally describe how to inject constraints into our model. Let d be a document with md mentions. Mentions are denoted solely using their indices, ranging from 1 to md . A coreference clustering C for document 603 d is a collection of disjoint sets partitioning the set {1, . . . , md }. We represent C as a binary function with C(i, j) = 1 if mentions i and j are coreferent, otherwise C(i, j) = 0. Let s(C; w, d) be the score of a given clustering C for a gi"
D13-1057,W11-1902,0,0.265959,"arning algorithms are usually complicated. Very recently, Durrett et al. (2013) propose a probabilistic model which enforces structural agreement constraints between specified properties of mention cluster when using a mention-pair model. This approach is very related to the probabilistic extension of our method as both models attempt to leverage entity-level information from mention-pair features. However, our approach is simpler because it directly considers the probabilities of multiple links. Furthermore, while their model performs only slightly better than the Stanford rule-based system (Lee et al., 2011), we significantly outperform this system. Most importantly, our model obtains state-of-the-art performance on OntoNotes-5.0 while still operating at the mention-pair granularity. We believe that this is due to our novel and principled structured prediction framework which results in accurate (and efficient) training. Several structured prediction techniques have been applied to coreference resolution in the machine learning literature. For example, McCallum and Wellner (2003) and Finley and Joachims (2005) model coreference as a correlational clustering problem (Bansal et al., 2002) on a comp"
D13-1057,J13-4004,0,0.0261873,"cribed in the paper can be treated as features, due to their high precision, treating them as hard constraints (set ρ to a high value) is a safe and direct way to inject human knowledge into the learning model. Moreover, our framework allows a constraint to use information from previous decisions (such as “cannot-link” constraints). Treating such constraints as features will complicate the learning model. 5.2 Performance of the End-to-End System We compare our system with the top systems reported in the CoNLL shared task 2012 as well as with the Stanford’s publicly released rule-based system (Lee et al., 2013; Lee et al., 2011), which won the CoNLL 2011 Shared Task (Pradhan et al., 2011). Note that all the systems use the same annotations (e.g., gender prediction, part-of-speech tags, name entity tags) provided by the shared task organizers. However, each system implements its own mention detector and pipelines the identified mentions into the coreference clustering component. Moreover, different systems use a different set of features. In order to partially control for errors on mention detection and better evaluate the clustering component in our coreference system, we will also present results"
D13-1057,H05-1004,0,0.105274,"L3 M, we do stochastic gradient descent with 5 passes over the data. Empirically, we observe that this is enough to generate a stable model. For PL3 M (Sec. 4), we tune the value of γ using the development set picking the best γ from {0.0, 0.2, . . . , 1.0}. Recall that when γ = 0, PL3 M is the same as L3 M. We refer to L3 M and PL3 M with incorporating constraints during inference as CL3 M and CPL3 M (Sec. 3.4), respectively. Metrics: We compare the systems using three popular metrics for coreference — MUC (Vilain et al., 1995), BCUB (Bagga and Baldwin, 1998), and Entity-based CEAF (CEAFe ) (Luo, 2005). Following, the CoNLL shared tasks (Pradhan et al., 2012), we use the average F1 scores of these three metrics as the main metric of comparison. Features: We build our system on the publicly available Illinois-Coref system1 primarily because it contains a rich set of features presented in Bengtson and Roth (2008) and Chang et al. (2012a) (the latter adds features for pronominal anaphora resolution). We also compare with the Best-Left-Link approach described by Bengtson and Roth (2008). Constraints: We consider the following constraints in CL3 M and CPL3 M. • SameSpan: two mentions must be lin"
D13-1057,W12-4511,0,0.0209694,"Missing"
D13-1057,P02-1014,0,0.758914,"tured prediction models proposed in the literature. 1 Introduction Coreference resolution is a challenging task, that involves identification and clustering of noun phrases mentions that refer to the same real-world entity. Most machine learning approaches to coreference resolution learn a scoring function to estimate the compatibility between two mentions or two sets of previously clustered mentions. Then, a decoding algorithm is designed to aggregate these scores and find an optimal clustering assignment. The most popular of these frameworks is the pairwise mention model (Soon et al., 2001; Ng and Cardie, 2002; Bengtson and Roth, 2008), which learns a compatibility score of mention-pairs and uses these pairwise scores to obtain a global clustering. Recently, efforts have been made (Haghighi and Klein, 2010; Rahman and Ng, 2011b; Rahman and Ng, 2011c) to consider models that capture higher order interactions, in particular, between mentions and previously identified entities (that is, between mentions and clusters). While such models are potentially more expressive, they are largely based on heuristics to achieve computational tractability. This paper focuses on a novel and principled machine learni"
D13-1057,W11-1901,0,0.168456,"based technique. Furthermore, we present a probabilistic generalization of L3 M that is more expressive in that it is capable of considering mention-entity interactions using scores at the mention-pair granularity. We augment this model with a temperature-like parameter (Samdani et al., 2012) to provide additional flexibility. CL3 M augments L3 M with knowledge-based constraints following (Roth and Yih, 2004; Denis and Baldridge, 2007). This capability is very desirable as shown by the success of the rule-based deterministic approach of Raghunathan et al. (2010) in the CoNLL shared task 2011 (Pradhan et al., 2011). In L3 M, domain-specific constraints are incorporated into learning and inference in a straightforward way. CL3 M scores a mention’s contribution to its cluster by combining the corresponding score 601 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 601–612, c Seattle, Washington, USA, 18-21 October 2013. 2013 Association for Computational Linguistics of the underlying L3 M model with that from a set of constraints. Most importantly, in our experiments on benchmark coreference datasets, we show that CL3 M, with just five constraints, compares fav"
D13-1057,W12-4501,0,0.613088,"on for Computational Linguistics of the underlying L3 M model with that from a set of constraints. Most importantly, in our experiments on benchmark coreference datasets, we show that CL3 M, with just five constraints, compares favorably with other, more complicated, state-of-the-art algorithms on a variety of evaluation metrics. Overall, the main contribution of this paper is a principled machine learning model operating at mention-pair granularity, using easy to implement constraint-augmented inference and learning, that yields competitive results on coreference resolution on Ontonotes-5.0 (Pradhan et al., 2012) and ACE 2004 (NIST, 2004). 2 Related Work The idea of Latent Left-linking Model (L3 M) is inspired by a popular inference approach to coreference which we call the Best-Left-Link approach (Ng and Cardie, 2002; Bengtson and Roth, 2008). In the best-left-link strategy, each mention i is connected to the best antecedent mention j with j &lt; i (i.e. a mention occurring to the left of i, assuming a leftto-right reading order), thereby creating a left-link. The “best” antecedent mention is the one with the highest pairwise score, wij ; furthermore, if wij is below some threshold, say 0, then i is not"
D13-1057,D10-1048,0,0.201316,"SVM approach, optimized using a fast stochastic gradient-based technique. Furthermore, we present a probabilistic generalization of L3 M that is more expressive in that it is capable of considering mention-entity interactions using scores at the mention-pair granularity. We augment this model with a temperature-like parameter (Samdani et al., 2012) to provide additional flexibility. CL3 M augments L3 M with knowledge-based constraints following (Roth and Yih, 2004; Denis and Baldridge, 2007). This capability is very desirable as shown by the success of the rule-based deterministic approach of Raghunathan et al. (2010) in the CoNLL shared task 2011 (Pradhan et al., 2011). In L3 M, domain-specific constraints are incorporated into learning and inference in a straightforward way. CL3 M scores a mention’s contribution to its cluster by combining the corresponding score 601 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 601–612, c Seattle, Washington, USA, 18-21 October 2013. 2013 Association for Computational Linguistics of the underlying L3 M model with that from a set of constraints. Most importantly, in our experiments on benchmark coreference datasets, we show"
D13-1057,P11-1082,0,0.299066,"y. Most machine learning approaches to coreference resolution learn a scoring function to estimate the compatibility between two mentions or two sets of previously clustered mentions. Then, a decoding algorithm is designed to aggregate these scores and find an optimal clustering assignment. The most popular of these frameworks is the pairwise mention model (Soon et al., 2001; Ng and Cardie, 2002; Bengtson and Roth, 2008), which learns a compatibility score of mention-pairs and uses these pairwise scores to obtain a global clustering. Recently, efforts have been made (Haghighi and Klein, 2010; Rahman and Ng, 2011b; Rahman and Ng, 2011c) to consider models that capture higher order interactions, in particular, between mentions and previously identified entities (that is, between mentions and clusters). While such models are potentially more expressive, they are largely based on heuristics to achieve computational tractability. This paper focuses on a novel and principled machine learning framework that pushes the state-ofthe-art while operating at a mention-pair granularity. We present two models — the Latent Left-Linking Model (L3 M), and a version of that is augmented with domain knowledge-based cons"
D13-1057,D12-1113,1,0.690954,"her approach proposed by Yu and Joachims (2009) formulates coreference with latent spanning trees. However, their approach has no directionality between mentions, whereas our latent structure captures the natural left-to-right ordering of mentions. In our experiments (Sec. 5), we show that our technique vastly outperforms both the spanning tree and the correlational clustering techniques. We also compare with (Fernandes et al., 2012) and the publicly available Stanford coreference system (Raghunathan et al., 2010; Lee et al., 2011), a state-of-theart rule-based system. Finally, some research (Ratinov and Roth, 2012; Bansal and Klein, 2012; Rahman and Ng, 2011a) has tried to integrate world knowledge from webbased statistics or knowledge bases into a coreference system. World knowledge is potentially useful for resolving coreference and can be injected into our system in a straightforward way via the constraints framework. We will show an example of incorporating our system with name-entity and WordNet-based similarity metric (Q. Do, 2009) in Sec. 5. Including massive amount of information from knowledge resources is not the focus of this paper and may distort the comparison with other relevant models bu"
D13-1057,P11-1138,1,0.130081,"but this difference disappears when we use our system with constraints, CL3 M. Although our system is much simple, it achieves the best B 3 score on the test set and is competitive with the best system participated in the CoNLL shared task 2012. Performance on named entities: The coreference annotation in Ontonotes 5.0 includes various types of mentions. However, not all mention types are equally interesting. In particular, clusters which contain at least one proper name or a named entity mention are more important for information extraction tasks like Wikification (Mihalcea and Csomai, 2007; Ratinov et al., 2011), cross-document coreference resolution (Bagga and Baldwin, 1998), and entity linking and knowledge based population (Ji and Grishman, 2011). Inspired by this, we compare our system to the best systems in the CoNLL shared task of 2011 (Stanford (Lee et al., 2011)) and 2012 (Fernandes (Fernandes et al., 2012)) on the following specific tasks on Ontonotes-5.0. • ENT-C: Evaluate the system on clusters that contain at least one proper name mention. We generate the gold annotation and system outputs by using the gold and predicted name entity tag annotations provided by the CoNLL shard task 2012. T"
D13-1057,W04-2401,1,0.811506,"2008). However, unlike previous best-link techniques, learning in our case is performed jointly with decoding — we present a novel latent structural SVM approach, optimized using a fast stochastic gradient-based technique. Furthermore, we present a probabilistic generalization of L3 M that is more expressive in that it is capable of considering mention-entity interactions using scores at the mention-pair granularity. We augment this model with a temperature-like parameter (Samdani et al., 2012) to provide additional flexibility. CL3 M augments L3 M with knowledge-based constraints following (Roth and Yih, 2004; Denis and Baldridge, 2007). This capability is very desirable as shown by the success of the rule-based deterministic approach of Raghunathan et al. (2010) in the CoNLL shared task 2011 (Pradhan et al., 2011). In L3 M, domain-specific constraints are incorporated into learning and inference in a straightforward way. CL3 M scores a mention’s contribution to its cluster by combining the corresponding score 601 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 601–612, c Seattle, Washington, USA, 18-21 October 2013. 2013 Association for Computational"
D13-1057,N12-1087,1,0.94801,"ring mention to its left, much like the existing best-left-link inference models (Ng and Cardie, 2002; Bengtson and Roth, 2008). However, unlike previous best-link techniques, learning in our case is performed jointly with decoding — we present a novel latent structural SVM approach, optimized using a fast stochastic gradient-based technique. Furthermore, we present a probabilistic generalization of L3 M that is more expressive in that it is capable of considering mention-entity interactions using scores at the mention-pair granularity. We augment this model with a temperature-like parameter (Samdani et al., 2012) to provide additional flexibility. CL3 M augments L3 M with knowledge-based constraints following (Roth and Yih, 2004; Denis and Baldridge, 2007). This capability is very desirable as shown by the success of the rule-based deterministic approach of Raghunathan et al. (2010) in the CoNLL shared task 2011 (Pradhan et al., 2011). In L3 M, domain-specific constraints are incorporated into learning and inference in a straightforward way. CL3 M scores a mention’s contribution to its cluster by combining the corresponding score 601 Proceedings of the 2013 Conference on Empirical Methods in Natural L"
D13-1057,J01-4004,0,0.365572,"well as some structured prediction models proposed in the literature. 1 Introduction Coreference resolution is a challenging task, that involves identification and clustering of noun phrases mentions that refer to the same real-world entity. Most machine learning approaches to coreference resolution learn a scoring function to estimate the compatibility between two mentions or two sets of previously clustered mentions. Then, a decoding algorithm is designed to aggregate these scores and find an optimal clustering assignment. The most popular of these frameworks is the pairwise mention model (Soon et al., 2001; Ng and Cardie, 2002; Bengtson and Roth, 2008), which learns a compatibility score of mention-pairs and uses these pairwise scores to obtain a global clustering. Recently, efforts have been made (Haghighi and Klein, 2010; Rahman and Ng, 2011b; Rahman and Ng, 2011c) to consider models that capture higher order interactions, in particular, between mentions and previously identified entities (that is, between mentions and clusters). While such models are potentially more expressive, they are largely based on heuristics to achieve computational tractability. This paper focuses on a novel and prin"
D13-1057,C12-1154,0,0.503875,"rwise left-links instead of just the best link, efficiently capturing the notion of a mention-to-cluster link. Many techniques in the coreference literature break away from the mention pair-based, best-leftlink paradigm. Denis and Baldridge (2008) and Ng (2005) learn a local ranker to rank the mention pairs based on their compatibility. While these approaches achieve decent empirical performance, it is unclear why these are the right ways to train the model. Some techniques consider a more expressive model by using features defined over mentioncluster or cluster-cluster (Rahman and Ng, 2011c; Stoyanov and Eisner, 2012; Haghighi and Klein, 2010). For these models, the inference and learning algorithms are usually complicated. Very recently, Durrett et al. (2013) propose a probabilistic model which enforces structural agreement constraints between specified properties of mention cluster when using a mention-pair model. This approach is very related to the probabilistic extension of our method as both models attempt to leverage entity-level information from mention-pair features. However, our approach is simpler because it directly considers the probabilities of multiple links. Furthermore, while their model"
D13-1057,P09-1074,0,0.0291876,"dent mention is the one with the highest pairwise score, wij ; furthermore, if wij is below some threshold, say 0, then i is not connected to any antecedent mention. The final clustering is a transitive closure of these “best” links. The intuition behind best-left-link strategy is based on how humans read and decipher coreference links – they mostly rely on information to the left of the mention when deciding whether to add it to a previously constructed cluster or not. This strategy has been successful and commonly used in coreference resolution (Ng and Cardie, 2002; Bengtson and Roth, 2008; Stoyanov et al., 2009). However, most works have developed ad-hoc approaches to implement this idea. For instance, Bengtson and Roth (2008) train a model w on binary training data generated by taking for each mention, the closest antecedent coreferent mention as a positive example, and all the other mentions as negative examples. Similar approaches to training and, additionally, decoupling the training stage from the clustering stage were used by other systems. In this paper, we formalize the learning problem of the best-left-link model as a structured 602 prediction problem and analyze our system with detailed exp"
D13-1057,M95-1005,0,0.668001,"but use a tuned value (tuned on a development set) during testing. For learning with L3 M, we do stochastic gradient descent with 5 passes over the data. Empirically, we observe that this is enough to generate a stable model. For PL3 M (Sec. 4), we tune the value of γ using the development set picking the best γ from {0.0, 0.2, . . . , 1.0}. Recall that when γ = 0, PL3 M is the same as L3 M. We refer to L3 M and PL3 M with incorporating constraints during inference as CL3 M and CPL3 M (Sec. 3.4), respectively. Metrics: We compare the systems using three popular metrics for coreference — MUC (Vilain et al., 1995), BCUB (Bagga and Baldwin, 1998), and Entity-based CEAF (CEAFe ) (Luo, 2005). Following, the CoNLL shared tasks (Pradhan et al., 2012), we use the average F1 scores of these three metrics as the main metric of comparison. Features: We build our system on the publicly available Illinois-Coref system1 primarily because it contains a rich set of features presented in Bengtson and Roth (2008) and Chang et al. (2012a) (the latter adds features for pronominal anaphora resolution). We also compare with the Best-Left-Link approach described by Bengtson and Roth (2008). Constraints: We consider the fol"
D13-1057,W12-4513,1,\N,Missing
D13-1057,W11-1904,1,\N,Missing
D13-1167,N09-1003,0,0.101703,"Missing"
D13-1167,D07-1109,0,0.0193715,"e on existing benchmark datasets for two relations, antonymy and is-a. 1 Introduction Continuous semantic space representations have proven successful in a wide variety of NLP and IR applications, such as document clustering (Xu et al., 2003) and cross-lingual document retrieval (Dumais et al., 1997; Platt et al., 2010) at the document level and sentential semantics (Guo and Diab, 2012; Guo and Diab, 2013) and syntactic parsing (Socher et al., 2013) at the sentence level. Such representations also play an important role in applications for lexical semantics, such as word sense disambiguation (Boyd-Graber et al., 2007), measuring word ∗ Work conducted while interning at Microsoft Research. LSA operates by mapping text objects, typically documents and words, to a latent semantic space. The proximity of the vectors in this space implies that the original text objects are semantically related. However, one well-known limitation of LSA is that it is unable to differentiate fine-grained relations. For instance, when applied to lexical semantics, synonyms and antonyms may both be assigned high similarity scores (Landauer and Laham, 1998; Landauer, 2002). Asymmetric relations like hyponyms and hypernyms also canno"
D13-1167,N13-1052,0,0.0279693,"ing a supervised model with features based on the frequencies of patterns in the corpus. Similarly, to measure whether two word pairs have the same relation, Zhila et al. (2013) proposed to combine heterogeneous models, which achieved state-of-the-art performance. In comparison, MRLSA models multiple lexical relations holistically. The degree that two words having a particular relation is estimated using the same linear function of the corresponding vectors and matrix. Tensor decomposition generalizes matrix factorization and has been applied to several NLP applications recently. For example, Cohen et al. (2013) proposed an approximation algorithm for PCFG parsing that relies on Kruskal decomposition. Van de Cruys et al. (2013) modeled the composition of subject-verb-object triples using Tucker decomposition, which results in a better similarity measure for transitive phrases. Similar to this construction but used in the community-based question answering (CQA) scenario, Qiu et al. (2013) represented triples of question title, question content and answer as a tensor and applied 3-mode SVD to derive latent semantic representations for question matching. The construction of MRLSA bears some resemblance"
D13-1167,P12-1091,0,0.0139286,"relation can then be measured through simple linear algebraic operations. We demonstrate that by integrating multiple relations from both homogeneous and heterogeneous information sources, MRLSA achieves stateof-the-art performance on existing benchmark datasets for two relations, antonymy and is-a. 1 Introduction Continuous semantic space representations have proven successful in a wide variety of NLP and IR applications, such as document clustering (Xu et al., 2003) and cross-lingual document retrieval (Dumais et al., 1997; Platt et al., 2010) at the document level and sentential semantics (Guo and Diab, 2012; Guo and Diab, 2013) and syntactic parsing (Socher et al., 2013) at the sentence level. Such representations also play an important role in applications for lexical semantics, such as word sense disambiguation (Boyd-Graber et al., 2007), measuring word ∗ Work conducted while interning at Microsoft Research. LSA operates by mapping text objects, typically documents and words, to a latent semantic space. The proximity of the vectors in this space implies that the original text objects are semantically related. However, one well-known limitation of LSA is that it is unable to differentiate fine-"
D13-1167,N13-1089,0,0.0102888,"measured through simple linear algebraic operations. We demonstrate that by integrating multiple relations from both homogeneous and heterogeneous information sources, MRLSA achieves stateof-the-art performance on existing benchmark datasets for two relations, antonymy and is-a. 1 Introduction Continuous semantic space representations have proven successful in a wide variety of NLP and IR applications, such as document clustering (Xu et al., 2003) and cross-lingual document retrieval (Dumais et al., 1997; Platt et al., 2010) at the document level and sentential semantics (Guo and Diab, 2012; Guo and Diab, 2013) and syntactic parsing (Socher et al., 2013) at the sentence level. Such representations also play an important role in applications for lexical semantics, such as word sense disambiguation (Boyd-Graber et al., 2007), measuring word ∗ Work conducted while interning at Microsoft Research. LSA operates by mapping text objects, typically documents and words, to a latent semantic space. The proximity of the vectors in this space implies that the original text objects are semantically related. However, one well-known limitation of LSA is that it is unable to differentiate fine-grained relations. Fo"
D13-1167,S12-1047,0,0.120674,"and is-a. We use the benchmark GRE test of closestopposites (Mohammad et al., 2008) to show that MRLSA performs comparably to PILSA, which was the pervious state-of-the-art approach on this problem, when given the same amount of information. In addition, when other words and relations are available, potentially from additional resources, MRLSA is able to outperform previous methods significantly. We use the is-a relation to demonstrate that MRLSA is capable of handling asymmetric relations. We take the list of word pairs from the Class-Inclusion (i.e., is-a) relations in SemEval-2012 Task 2 (Jurgens et al., 2012), and use our model to measure the degree of two words have this relation. The measures derived from our model correlate with human judgement better than the best system that participated in the task. The rest of this paper is organized as follows. We first survey some related work in Section 2, followed by a more detailed description of LSA and PILSA in Section 3. Our proposed model, MRLSA, is presented in Section 4. Section 5 presents our experimental results. Finally, Section 6 concludes the paper. 1603 2 Related Work MRLSA can be viewed as a model that derives general continuous space repr"
D13-1167,N13-1090,1,0.236592,"ce representation of text is arguably the vector space model (VSM) (Turney and Pantel, 2010). In this representation, each text object can be represented by a high-dimensional sparse vector, such as a term-vector or a document-vector that denotes the statistics of term occurrences (Salton et al., 1975) in a large corpus. The text can also be represented by a low-dimensional dense vector derived by linear projection models like latent semantic analysis (LSA) (Deerwester et al., 1990), by discriminative learning methods like Siamese neural networks (Yih et al., 2011), recurrent neural networks (Mikolov et al., 2013) and recursive neural networks (Socher et al., 2011), or by graphical models such as probabilistic latent semantic analysis (PLSA) (Hofmann, 1999) and latent Dirichlet allocation (LDA) (Blei et al., 2003). As a generalization of LSA, MRLSA is also a linear projection model. However, while the words are represented by vectors as well, multiple relations between words are captured separately by matrices. In the context of lexical semantics, VSMs provide a natural way of measuring semantic word relatedness by computing the distance between the corresponding vectors, which has been a standard appr"
D13-1167,D08-1103,0,0.0590309,"ly unseen relations between two words can be discovered, and the information encoded in other relations can influence the construction of the latent representations, and thus potentially improves the overall quality. In addition, the information in different slices can come from heterogeneous sources (conceptually similar to (Riedel et al., 2013)), which not only improves the model, but also extends the word coverage in a reliable way. We provide empirical evidence that MRLSA is effective using two different word relations: antonymy and is-a. We use the benchmark GRE test of closestopposites (Mohammad et al., 2008) to show that MRLSA performs comparably to PILSA, which was the pervious state-of-the-art approach on this problem, when given the same amount of information. In addition, when other words and relations are available, potentially from additional resources, MRLSA is able to outperform previous methods significantly. We use the is-a relation to demonstrate that MRLSA is capable of handling asymmetric relations. We take the list of word pairs from the Class-Inclusion (i.e., is-a) relations in SemEval-2012 Task 2 (Jurgens et al., 2012), and use our model to measure the degree of two words have thi"
D13-1167,D10-1025,1,0.844508,"y a latent square matrix. The degree of two words having a specific relation can then be measured through simple linear algebraic operations. We demonstrate that by integrating multiple relations from both homogeneous and heterogeneous information sources, MRLSA achieves stateof-the-art performance on existing benchmark datasets for two relations, antonymy and is-a. 1 Introduction Continuous semantic space representations have proven successful in a wide variety of NLP and IR applications, such as document clustering (Xu et al., 2003) and cross-lingual document retrieval (Dumais et al., 1997; Platt et al., 2010) at the document level and sentential semantics (Guo and Diab, 2012; Guo and Diab, 2013) and syntactic parsing (Socher et al., 2013) at the sentence level. Such representations also play an important role in applications for lexical semantics, such as word sense disambiguation (Boyd-Graber et al., 2007), measuring word ∗ Work conducted while interning at Microsoft Research. LSA operates by mapping text objects, typically documents and words, to a latent semantic space. The proximity of the vectors in this space implies that the original text objects are semantically related. However, one well-"
D13-1167,P13-2077,0,0.0579411,"Missing"
D13-1167,N10-1013,0,0.0217339,"rks (Socher et al., 2011), or by graphical models such as probabilistic latent semantic analysis (PLSA) (Hofmann, 1999) and latent Dirichlet allocation (LDA) (Blei et al., 2003). As a generalization of LSA, MRLSA is also a linear projection model. However, while the words are represented by vectors as well, multiple relations between words are captured separately by matrices. In the context of lexical semantics, VSMs provide a natural way of measuring semantic word relatedness by computing the distance between the corresponding vectors, which has been a standard approach (Agirre et al., 2009; Reisinger and Mooney, 2010; Yih and Qazvinian, 2012). These approaches do not apply directly to the problem of modeling other types of relations. Existing methods that do handle multiple relations often use a model combination scheme to integrate signals from various types of information sources. For instance, morphological variations discovered from the Google n-gram corpus have been combined with information from thesauri and vector-based word relatedness models for detecting antonyms (Mohammad et al., 2008). An alternative approach proposed by Turney (2008) that handles synonyms, antonyms and associations is to use"
D13-1167,N13-1008,0,0.0242638,"nds to the document-term matrix in the original LSA design but for a specific relation. Analogous to LSA, the whole linear transformation mapping is derived through tensor decomposition, which provides a low-rank approximation of the original tensor. As a result, previously unseen relations between two words can be discovered, and the information encoded in other relations can influence the construction of the latent representations, and thus potentially improves the overall quality. In addition, the information in different slices can come from heterogeneous sources (conceptually similar to (Riedel et al., 2013)), which not only improves the model, but also extends the word coverage in a reliable way. We provide empirical evidence that MRLSA is effective using two different word relations: antonymy and is-a. We use the benchmark GRE test of closestopposites (Mohammad et al., 2008) to show that MRLSA performs comparably to PILSA, which was the pervious state-of-the-art approach on this problem, when given the same amount of information. In addition, when other words and relations are available, potentially from additional resources, MRLSA is able to outperform previous methods significantly. We use th"
D13-1167,S12-1055,0,0.0346693,"Missing"
D13-1167,P13-1045,0,0.00638257,"perations. We demonstrate that by integrating multiple relations from both homogeneous and heterogeneous information sources, MRLSA achieves stateof-the-art performance on existing benchmark datasets for two relations, antonymy and is-a. 1 Introduction Continuous semantic space representations have proven successful in a wide variety of NLP and IR applications, such as document clustering (Xu et al., 2003) and cross-lingual document retrieval (Dumais et al., 1997; Platt et al., 2010) at the document level and sentential semantics (Guo and Diab, 2012; Guo and Diab, 2013) and syntactic parsing (Socher et al., 2013) at the sentence level. Such representations also play an important role in applications for lexical semantics, such as word sense disambiguation (Boyd-Graber et al., 2007), measuring word ∗ Work conducted while interning at Microsoft Research. LSA operates by mapping text objects, typically documents and words, to a latent semantic space. The proximity of the vectors in this space implies that the original text objects are semantically related. However, one well-known limitation of LSA is that it is unable to differentiate fine-grained relations. For instance, when applied to lexical semantic"
D13-1167,J06-3003,0,0.236427,"Missing"
D13-1167,C08-1114,0,0.0129127,"been a standard approach (Agirre et al., 2009; Reisinger and Mooney, 2010; Yih and Qazvinian, 2012). These approaches do not apply directly to the problem of modeling other types of relations. Existing methods that do handle multiple relations often use a model combination scheme to integrate signals from various types of information sources. For instance, morphological variations discovered from the Google n-gram corpus have been combined with information from thesauri and vector-based word relatedness models for detecting antonyms (Mohammad et al., 2008). An alternative approach proposed by Turney (2008) that handles synonyms, antonyms and associations is to use a uniform approach by first reducing the problem to determining whether two pairs of words can be analogous, and then predicting it using a supervised model with features based on the frequencies of patterns in the corpus. Similarly, to measure whether two word pairs have the same relation, Zhila et al. (2013) proposed to combine heterogeneous models, which achieved state-of-the-art performance. In comparison, MRLSA models multiple lexical relations holistically. The degree that two words having a particular relation is estimated usin"
D13-1167,N13-1134,0,0.0290766,"Missing"
D13-1167,N12-1077,1,0.751379,"r by graphical models such as probabilistic latent semantic analysis (PLSA) (Hofmann, 1999) and latent Dirichlet allocation (LDA) (Blei et al., 2003). As a generalization of LSA, MRLSA is also a linear projection model. However, while the words are represented by vectors as well, multiple relations between words are captured separately by matrices. In the context of lexical semantics, VSMs provide a natural way of measuring semantic word relatedness by computing the distance between the corresponding vectors, which has been a standard approach (Agirre et al., 2009; Reisinger and Mooney, 2010; Yih and Qazvinian, 2012). These approaches do not apply directly to the problem of modeling other types of relations. Existing methods that do handle multiple relations often use a model combination scheme to integrate signals from various types of information sources. For instance, morphological variations discovered from the Google n-gram corpus have been combined with information from thesauri and vector-based word relatedness models for detecting antonyms (Mohammad et al., 2008). An alternative approach proposed by Turney (2008) that handles synonyms, antonyms and associations is to use a uniform approach by firs"
D13-1167,W11-0329,1,0.838089,"pproach. The most commonly used continuous space representation of text is arguably the vector space model (VSM) (Turney and Pantel, 2010). In this representation, each text object can be represented by a high-dimensional sparse vector, such as a term-vector or a document-vector that denotes the statistics of term occurrences (Salton et al., 1975) in a large corpus. The text can also be represented by a low-dimensional dense vector derived by linear projection models like latent semantic analysis (LSA) (Deerwester et al., 1990), by discriminative learning methods like Siamese neural networks (Yih et al., 2011), recurrent neural networks (Mikolov et al., 2013) and recursive neural networks (Socher et al., 2011), or by graphical models such as probabilistic latent semantic analysis (PLSA) (Hofmann, 1999) and latent Dirichlet allocation (LDA) (Blei et al., 2003). As a generalization of LSA, MRLSA is also a linear projection model. However, while the words are represented by vectors as well, multiple relations between words are captured separately by matrices. In the context of lexical semantics, VSMs provide a natural way of measuring semantic word relatedness by computing the distance between the cor"
D13-1167,D12-1111,1,0.65645,"tic space. The proximity of the vectors in this space implies that the original text objects are semantically related. However, one well-known limitation of LSA is that it is unable to differentiate fine-grained relations. For instance, when applied to lexical semantics, synonyms and antonyms may both be assigned high similarity scores (Landauer and Laham, 1998; Landauer, 2002). Asymmetric relations like hyponyms and hypernyms also cannot be differentiated. Although there exists some recent work, such as PILSA which tries to overcome this weakness of LSA by introducing the notion of polarity (Yih et al., 2012). This extension, however, can only handle two opposing relations (e.g., synonyms and antonyms), leaving open the challenge of encoding multiple relations. In this paper, we propose Multi-Relational Latent Semantic Analysis (MRLSA), which strictly generalizes LSA to incorporate information of multiple relations concurrently. Similar to LSA or PILSA when applied to lexical semantics, each word is still mapped to a vector in the latent space. However, when measuring whether two words have a specific relation (e.g., antonymy or is-a), the word vectors will be mapped to a new space according to th"
D13-1167,N13-1120,1,0.770861,"logical variations discovered from the Google n-gram corpus have been combined with information from thesauri and vector-based word relatedness models for detecting antonyms (Mohammad et al., 2008). An alternative approach proposed by Turney (2008) that handles synonyms, antonyms and associations is to use a uniform approach by first reducing the problem to determining whether two pairs of words can be analogous, and then predicting it using a supervised model with features based on the frequencies of patterns in the corpus. Similarly, to measure whether two word pairs have the same relation, Zhila et al. (2013) proposed to combine heterogeneous models, which achieved state-of-the-art performance. In comparison, MRLSA models multiple lexical relations holistically. The degree that two words having a particular relation is estimated using the same linear function of the corresponding vectors and matrix. Tensor decomposition generalizes matrix factorization and has been applied to several NLP applications recently. For example, Cohen et al. (2013) proposed an approximation algorithm for PCFG parsing that relies on Kruskal decomposition. Van de Cruys et al. (2013) modeled the composition of subject-verb"
D14-1165,P07-1073,0,0.07303,"points when used as a subcomponent. 1 Introduction Identifying the relationship between entities from free text, relation extraction is a key task for acquiring new facts to increase the coverage of a structured knowledge base. Given a pre-defined database schema, traditional relation extraction approaches focus on learning a classifier using textual data alone, such as patterns between the occurrences of two entities in documents, to determine whether the entities have a particular relation. Other than using the existing known facts to label the text corpora in a distant supervision setting (Bunescu and Mooney, 2007; Mintz et al., ∗ Work conducted while interning at Microsoft Research. 2009; Riedel et al., 2010; Ritter et al., 2013), an existing knowledge base is typically not involved in the process of relation extraction. However, this paradigm has started to shift recently, as researchers showed that by taking existing facts of a knowledge base as an integral part of relation extraction, the model can leverage richer information and thus yields better performance. For instance, Riedel et al. (2013) borrowed the idea of collective filtering and constructed a matrix where each row is a pair of entities"
D14-1165,N13-1090,1,0.0150514,"this paper, we will use Xk to refer to the k-th slice of the tensor X . Fig. 1 illustrates this representation. 1 This representation can easily be extended for a probabilistic knowledge base by allowing nonnegative real values. χk en χ e1 of the vectors of (e1 , r) and (e2 , r). Later, they proposed a more scalable method called translating embeddings (TransE) (Bordes et al., 2013a). While both entities and relations are still represented by vectors, the score of (e1 , r, e2 ) becomes the negative dissimilarity measure of the corresponding vectors −kei + rk − ej k, motivated by the work in (Mikolov et al., 2013b; Mikolov et al., 2013a). Alternatively, Socher et al. (2013) proposed a Neural Tensor Network (NTN) that represents entities in d-dimensional vectors created separately by averaging pre-trained word vectors, and then learns a d × d × m tensor describing the interactions between these latent components in each of the m relations. All these methods optimize for loss functions that are more directly related to the true objective – the prediction accuracy of correct entity-relation triples, compared to the meansquared reconstruction error in our method. Nevertheless, they typically require much"
D14-1165,D13-1167,1,0.595887,"Missing"
D14-1165,P09-1113,0,0.347175,"wo entities. There are 72 fine types extracted from Freebase assigned to 53,836 entities that are recorded in Freebase. In addition, special types, PER, LOC, ORG and MISC, are assigned to the remaining 26,862 entities based on the predicted NER tags provided by the corpus. A type is considered incompatible to a relation or a surface pattern if in the training data, none of the argument entities of the relation belongs to the type. We use r = 400 and λ = 0.1 in T RESCAL to factorize the tensor. We compare the proposed T RESCAL model to RI13 (Riedel et al., 2013), YA11 (Yao et al., 2011), MI09 (Mintz et al., 2009) and SU12 (Surdeanu et al., 2012)8 . We follow the protocol used in (Riedel et al., 2013) to evaluate the results. Given a relation as query, the top 1,000 entity pairs output by each system are collected and the top 100 ones are judged manually. Besides comparing individual models, we also report the results of combined models. To combine the scores from two models, we simply normalize the scores of entity-relation tuples to zero mean and unit variance and take the average. The results are summarized in Table 3. As can been seen in the table, using T RESCAL alone is not very effective and its"
D14-1165,N13-1008,0,0.861747,"ther than using the existing known facts to label the text corpora in a distant supervision setting (Bunescu and Mooney, 2007; Mintz et al., ∗ Work conducted while interning at Microsoft Research. 2009; Riedel et al., 2010; Ritter et al., 2013), an existing knowledge base is typically not involved in the process of relation extraction. However, this paradigm has started to shift recently, as researchers showed that by taking existing facts of a knowledge base as an integral part of relation extraction, the model can leverage richer information and thus yields better performance. For instance, Riedel et al. (2013) borrowed the idea of collective filtering and constructed a matrix where each row is a pair of entities and each column is a particular relation. For a true entityrelation triple (e1 , r, e2 ), either from the text corpus or from the knowledge base, the corresponding entry in the matrix is 1. A previously unknown fact (i.e., triple) can be discovered through matrix decomposition. This approach can be viewed as creating vector representations of each relation and candidate pair of entities. Because each entity does not have its own representation, relationships of any unpaired entities cannot"
D14-1165,Q13-1030,0,0.0138003,"xtraction is a key task for acquiring new facts to increase the coverage of a structured knowledge base. Given a pre-defined database schema, traditional relation extraction approaches focus on learning a classifier using textual data alone, such as patterns between the occurrences of two entities in documents, to determine whether the entities have a particular relation. Other than using the existing known facts to label the text corpora in a distant supervision setting (Bunescu and Mooney, 2007; Mintz et al., ∗ Work conducted while interning at Microsoft Research. 2009; Riedel et al., 2010; Ritter et al., 2013), an existing knowledge base is typically not involved in the process of relation extraction. However, this paradigm has started to shift recently, as researchers showed that by taking existing facts of a knowledge base as an integral part of relation extraction, the model can leverage richer information and thus yields better performance. For instance, Riedel et al. (2013) borrowed the idea of collective filtering and constructed a matrix where each row is a pair of entities and each column is a particular relation. For a true entityrelation triple (e1 , r, e2 ), either from the text corpus o"
D14-1165,D11-1135,0,0.0269477,"surface pattern between two entities. There are 72 fine types extracted from Freebase assigned to 53,836 entities that are recorded in Freebase. In addition, special types, PER, LOC, ORG and MISC, are assigned to the remaining 26,862 entities based on the predicted NER tags provided by the corpus. A type is considered incompatible to a relation or a surface pattern if in the training data, none of the argument entities of the relation belongs to the type. We use r = 400 and λ = 0.1 in T RESCAL to factorize the tensor. We compare the proposed T RESCAL model to RI13 (Riedel et al., 2013), YA11 (Yao et al., 2011), MI09 (Mintz et al., 2009) and SU12 (Surdeanu et al., 2012)8 . We follow the protocol used in (Riedel et al., 2013) to evaluate the results. Given a relation as query, the top 1,000 entity pairs output by each system are collected and the top 100 ones are judged manually. Besides comparing individual models, we also report the results of combined models. To combine the scores from two models, we simply normalize the scores of entity-relation tuples to zero mean and unit variance and take the average. The results are summarized in Table 3. As can been seen in the table, using T RESCAL alone is"
D14-1165,D12-1042,0,0.0964042,"types extracted from Freebase assigned to 53,836 entities that are recorded in Freebase. In addition, special types, PER, LOC, ORG and MISC, are assigned to the remaining 26,862 entities based on the predicted NER tags provided by the corpus. A type is considered incompatible to a relation or a surface pattern if in the training data, none of the argument entities of the relation belongs to the type. We use r = 400 and λ = 0.1 in T RESCAL to factorize the tensor. We compare the proposed T RESCAL model to RI13 (Riedel et al., 2013), YA11 (Yao et al., 2011), MI09 (Mintz et al., 2009) and SU12 (Surdeanu et al., 2012)8 . We follow the protocol used in (Riedel et al., 2013) to evaluate the results. Given a relation as query, the top 1,000 entity pairs output by each system are collected and the top 100 ones are judged manually. Besides comparing individual models, we also report the results of combined models. To combine the scores from two models, we simply normalize the scores of entity-relation tuples to zero mean and unit variance and take the average. The results are summarized in Table 3. As can been seen in the table, using T RESCAL alone is not very effective and its performance is only compatible t"
D14-1165,D13-1136,0,0.0732934,"ve filtering and constructed a matrix where each row is a pair of entities and each column is a particular relation. For a true entityrelation triple (e1 , r, e2 ), either from the text corpus or from the knowledge base, the corresponding entry in the matrix is 1. A previously unknown fact (i.e., triple) can be discovered through matrix decomposition. This approach can be viewed as creating vector representations of each relation and candidate pair of entities. Because each entity does not have its own representation, relationships of any unpaired entities cannot be discovered. Alternatively, Weston et al. (2013) created two types of embedding – one based on textual similarity and the other based on knowledge base, where the latter maps each entity and relation to the same ddimensional vector space using a model proposed by Bordes et al. (2013a). They also showed that combining these two models results in a significant improvement over the model trained using only textual data. To make such an integrated strategy work, it is important to capture all existing entities and relations, as well as the known facts, from both textual data and large databases. In this paper, we propose a new knowledge base em"
D16-1029,Q13-1005,0,0.0781941,"ems. We discuss this in detail in Section 4. 1 The new resource and the dataset we used for training is available soon on https://aka.ms/dataimplicit and https://aka.ms/datadraw 298 Solving automatic algebra word problems can be viewed as a semantic parsing task. In the semantic parsing community, the technique of learning from implicit supervision signals has been applied (under the name response-driven learning (Clarke et al., 2010)) to knowledge base question answering tasks such as Geoquery (Zelle and Mooney, 1996) and WebQuestions (Berant et al., 2013) or mapping instructions to actions (Artzi and Zettlemoyer, 2013). In these tasks, researchers have shown that it is possible to train a semantic parser only from questionanswer pairs, such as “What is the largest state bordering Texas?” and “New Mexico” (Clarke et al., 2010; Liang et al., 2013; Yih et al., 2015). One key reason that such implicit supervision is effective is because the correct semantic parses of the questions can often be found using the answers and the knowledge base alone, with the help of heuristics developed for the specific domain. For instance, when the question is relatively simple and does not have complex compositional structure,"
D16-1029,D13-1160,0,0.0446335,"ly the solutions with little or no annoated equation systems. We discuss this in detail in Section 4. 1 The new resource and the dataset we used for training is available soon on https://aka.ms/dataimplicit and https://aka.ms/datadraw 298 Solving automatic algebra word problems can be viewed as a semantic parsing task. In the semantic parsing community, the technique of learning from implicit supervision signals has been applied (under the name response-driven learning (Clarke et al., 2010)) to knowledge base question answering tasks such as Geoquery (Zelle and Mooney, 1996) and WebQuestions (Berant et al., 2013) or mapping instructions to actions (Artzi and Zettlemoyer, 2013). In these tasks, researchers have shown that it is possible to train a semantic parser only from questionanswer pairs, such as “What is the largest state bordering Texas?” and “New Mexico” (Clarke et al., 2010; Liang et al., 2013; Yih et al., 2015). One key reason that such implicit supervision is effective is because the correct semantic parses of the questions can often be found using the answers and the knowledge base alone, with the help of heuristics developed for the specific domain. For instance, when the question is rela"
D16-1029,D13-1057,1,0.141976,"word problems. Compared to the knowledge base question answering problems, one key difference is that a large number (potentially infinitely many) of different equation systems could end up having the same solutions. Without a database or special rules for combining variables and coefficients, the number of candidate equation systems cannot be trimmed effectively, given only the solutions. From the algorithmic point of view, our proposed learning framework is related to several lines of work. Similar efforts have been made to develop latent structured prediction models (Yu and Joachims, 2009; Chang et al., 2013; Zettlemoyer and Collins, 2007) to find latent semantic structures which best explain the answer given the question. Our algorithm is also influenced by the discriminative reranking algorithms (Collins, 2000; Ge and Mooney, 2006; Charniak and Johnson, 2005) and models for learning from intractable supervision (Steinhardt and Liang, 2015). Recently, Huang et al. (2016) collected a large number of noisily annotated word problems from online forums. While they collected a large-scale dataset, unlike our work, they did not demonstrate how to utilize the newly crawled dataset to improve existing s"
D16-1029,P05-1022,0,0.0221719,"les for combining variables and coefficients, the number of candidate equation systems cannot be trimmed effectively, given only the solutions. From the algorithmic point of view, our proposed learning framework is related to several lines of work. Similar efforts have been made to develop latent structured prediction models (Yu and Joachims, 2009; Chang et al., 2013; Zettlemoyer and Collins, 2007) to find latent semantic structures which best explain the answer given the question. Our algorithm is also influenced by the discriminative reranking algorithms (Collins, 2000; Ge and Mooney, 2006; Charniak and Johnson, 2005) and models for learning from intractable supervision (Steinhardt and Liang, 2015). Recently, Huang et al. (2016) collected a large number of noisily annotated word problems from online forums. While they collected a large-scale dataset, unlike our work, they did not demonstrate how to utilize the newly crawled dataset to improve existing systems. It will be interesting to see if our proposed algorithm can make further improvements using their newly collected dataset.2 3 Problem Definition Table 1 lists all the symbols representing the components in the process. The input algebra word problem"
D16-1029,W10-2903,1,0.937121,"ushman et al., 2014; Zhou et al., 2015; Koncel-Kedziorski et al., 2015), where the authors train the algebra solvers using only the solutions with little or no annoated equation systems. We discuss this in detail in Section 4. 1 The new resource and the dataset we used for training is available soon on https://aka.ms/dataimplicit and https://aka.ms/datadraw 298 Solving automatic algebra word problems can be viewed as a semantic parsing task. In the semantic parsing community, the technique of learning from implicit supervision signals has been applied (under the name response-driven learning (Clarke et al., 2010)) to knowledge base question answering tasks such as Geoquery (Zelle and Mooney, 1996) and WebQuestions (Berant et al., 2013) or mapping instructions to actions (Artzi and Zettlemoyer, 2013). In these tasks, researchers have shown that it is possible to train a semantic parser only from questionanswer pairs, such as “What is the largest state bordering Texas?” and “New Mexico” (Clarke et al., 2010; Liang et al., 2013; Yih et al., 2015). One key reason that such implicit supervision is effective is because the correct semantic parses of the questions can often be found using the answers and the"
D16-1029,W02-1001,0,0.118847,"used in this paper to formally describe the problem of mapping algebra word problems to equations. 4 Learning from Mixed Supervision We assume that we have two sets: De = {(xe , ye )} and Dm = {(xm , zm )}. De contains the fully annotated equation system ye for each algebra word problem xe , whereas in Dm , we have access to the numerical solution zm to each problem, but not the equation system (ym = ∅). We refer to De as the explicit set and Dm as the implicit set. For the sake of simplicity, we explain our approach by modifying the training procedure of the structured Perceptron algorithm (Collins, 2002).4 As discussed in Section 3, the key challenge of learning from implicit supervision is that the mapping E(y) is one-directional. Therefore, the correct equation system cannot be easily derived from the numerical solution. Intuitively, for data with only implicit supervision, we can explore the structure ˜∈Y space Y and find the best possible derivation y according to the current model. If E(˜ y) matches z, ˜ . Following then we can update the model based on y this intuition, we propose MixedSP (Algorithm 1). For each example, we use an approximate search algorithm to collect top scoring cand"
D16-1029,P06-2034,0,0.019982,"atabase or special rules for combining variables and coefficients, the number of candidate equation systems cannot be trimmed effectively, given only the solutions. From the algorithmic point of view, our proposed learning framework is related to several lines of work. Similar efforts have been made to develop latent structured prediction models (Yu and Joachims, 2009; Chang et al., 2013; Zettlemoyer and Collins, 2007) to find latent semantic structures which best explain the answer given the question. Our algorithm is also influenced by the discriminative reranking algorithms (Collins, 2000; Ge and Mooney, 2006; Charniak and Johnson, 2005) and models for learning from intractable supervision (Steinhardt and Liang, 2015). Recently, Huang et al. (2016) collected a large number of noisily annotated word problems from online forums. While they collected a large-scale dataset, unlike our work, they did not demonstrate how to utilize the newly crawled dataset to improve existing systems. It will be interesting to see if our proposed algorithm can make further improvements using their newly collected dataset.2 3 Problem Definition Table 1 lists all the symbols representing the components in the process. Th"
D16-1029,D14-1058,0,0.44745,"Missing"
D16-1029,P16-1084,0,0.323797,"en only the solutions. From the algorithmic point of view, our proposed learning framework is related to several lines of work. Similar efforts have been made to develop latent structured prediction models (Yu and Joachims, 2009; Chang et al., 2013; Zettlemoyer and Collins, 2007) to find latent semantic structures which best explain the answer given the question. Our algorithm is also influenced by the discriminative reranking algorithms (Collins, 2000; Ge and Mooney, 2006; Charniak and Johnson, 2005) and models for learning from intractable supervision (Steinhardt and Liang, 2015). Recently, Huang et al. (2016) collected a large number of noisily annotated word problems from online forums. While they collected a large-scale dataset, unlike our work, they did not demonstrate how to utilize the newly crawled dataset to improve existing systems. It will be interesting to see if our proposed algorithm can make further improvements using their newly collected dataset.2 3 Problem Definition Table 1 lists all the symbols representing the components in the process. The input algebra word problem is denoted by x, and the output y = (T, A) is called a derivation, which consists of an equation system template"
D16-1029,P14-1026,0,0.346527,"a textual number (e.g., four) in a word problem. Let Q(x) be all the textual numbers in the problem x, and C(T ) be the coefficients to be determined in the template T . An alignment is a set of tuples A = {(q, c) |q ∈ Q(x), c ∈ C(T ) ∪ {}}, where the tuple (q, ) indicates that the number q is not relevant to the final equation system. By specifying the value of each coefficient, it identifies an equation system belonging to the family represented by template T . Together, T and A generate a complete equation system, and the solution z can be derived by the mathematical engine E. Following (Kushman et al., 2014; Zhou et al., 2015), our strategy of mapping a word problem to an equation system is to first choose a template that consists of variables and coefficients, and then align each coefficient to a textual number mentioned in the problem. We formulate the mapping between an algebra word problem and an equation system as a structured learning problem. The output space is the set of all possible derivations using templates that are observed in the training data. Our model maps x to y = (T, A) by a linear scoring function wT Φ(x, y), where w is the model parameters and Φ is the feature functions. At"
D16-1029,J13-2005,0,0.0262744,"semantic parsing task. In the semantic parsing community, the technique of learning from implicit supervision signals has been applied (under the name response-driven learning (Clarke et al., 2010)) to knowledge base question answering tasks such as Geoquery (Zelle and Mooney, 1996) and WebQuestions (Berant et al., 2013) or mapping instructions to actions (Artzi and Zettlemoyer, 2013). In these tasks, researchers have shown that it is possible to train a semantic parser only from questionanswer pairs, such as “What is the largest state bordering Texas?” and “New Mexico” (Clarke et al., 2010; Liang et al., 2013; Yih et al., 2015). One key reason that such implicit supervision is effective is because the correct semantic parses of the questions can often be found using the answers and the knowledge base alone, with the help of heuristics developed for the specific domain. For instance, when the question is relatively simple and does not have complex compositional structure, paths in the knowledge graph that connect the answers and the entities in the narrative can be interpreted as legitimate semantic parses. However, as we will show in our experiments, learning from implicit supervision alone is not"
D16-1029,P14-5010,0,0.0039774,"Missing"
D16-1029,D15-1202,0,0.350821,"Missing"
D16-1029,D15-1135,0,0.350252,"elated Work Automatically solving mathematical reasoning problems expressed in natural language has been a long-studied problem (Bobrow, 1964; Newell et al., 1959; Mukherjee and Garain, 2008). Recently, Kushman et al. (2014) created a template-base search procedure to map word problems into equations. Then, several following papers studied different aspects of the task: Hosseini et al. (2014) focused on improving the generalization ability of the solvers by leveraging extra annotations; Roy and Roth (2015) focused on how to solve arithmetic problems without using any pre-defined template. In (Shi et al., 2015), the authors focused on number word problems and proposed a system that is created using semi-automatically generated rules. In Zhou et al. (2015), the authors simplified the inference procedure and pushed the state-of-the-art benchmark accuracy. The idea of learning from implicit supervision is discussed in (Kushman et al., 2014; Zhou et al., 2015; Koncel-Kedziorski et al., 2015), where the authors train the algebra solvers using only the solutions with little or no annoated equation systems. We discuss this in detail in Section 4. 1 The new resource and the dataset we used for training is a"
D16-1029,P15-1128,1,0.261412,"sk. In the semantic parsing community, the technique of learning from implicit supervision signals has been applied (under the name response-driven learning (Clarke et al., 2010)) to knowledge base question answering tasks such as Geoquery (Zelle and Mooney, 1996) and WebQuestions (Berant et al., 2013) or mapping instructions to actions (Artzi and Zettlemoyer, 2013). In these tasks, researchers have shown that it is possible to train a semantic parser only from questionanswer pairs, such as “What is the largest state bordering Texas?” and “New Mexico” (Clarke et al., 2010; Liang et al., 2013; Yih et al., 2015). One key reason that such implicit supervision is effective is because the correct semantic parses of the questions can often be found using the answers and the knowledge base alone, with the help of heuristics developed for the specific domain. For instance, when the question is relatively simple and does not have complex compositional structure, paths in the knowledge graph that connect the answers and the entities in the narrative can be interpreted as legitimate semantic parses. However, as we will show in our experiments, learning from implicit supervision alone is not a viable strategy"
D16-1029,D07-1071,0,0.220524,"red to the knowledge base question answering problems, one key difference is that a large number (potentially infinitely many) of different equation systems could end up having the same solutions. Without a database or special rules for combining variables and coefficients, the number of candidate equation systems cannot be trimmed effectively, given only the solutions. From the algorithmic point of view, our proposed learning framework is related to several lines of work. Similar efforts have been made to develop latent structured prediction models (Yu and Joachims, 2009; Chang et al., 2013; Zettlemoyer and Collins, 2007) to find latent semantic structures which best explain the answer given the question. Our algorithm is also influenced by the discriminative reranking algorithms (Collins, 2000; Ge and Mooney, 2006; Charniak and Johnson, 2005) and models for learning from intractable supervision (Steinhardt and Liang, 2015). Recently, Huang et al. (2016) collected a large number of noisily annotated word problems from online forums. While they collected a large-scale dataset, unlike our work, they did not demonstrate how to utilize the newly crawled dataset to improve existing systems. It will be interesting t"
D16-1029,D15-1096,0,0.678971,"ell et al., 1959; Mukherjee and Garain, 2008). Recently, Kushman et al. (2014) created a template-base search procedure to map word problems into equations. Then, several following papers studied different aspects of the task: Hosseini et al. (2014) focused on improving the generalization ability of the solvers by leveraging extra annotations; Roy and Roth (2015) focused on how to solve arithmetic problems without using any pre-defined template. In (Shi et al., 2015), the authors focused on number word problems and proposed a system that is created using semi-automatically generated rules. In Zhou et al. (2015), the authors simplified the inference procedure and pushed the state-of-the-art benchmark accuracy. The idea of learning from implicit supervision is discussed in (Kushman et al., 2014; Zhou et al., 2015; Koncel-Kedziorski et al., 2015), where the authors train the algebra solvers using only the solutions with little or no annoated equation systems. We discuss this in detail in Section 4. 1 The new resource and the dataset we used for training is available soon on https://aka.ms/dataimplicit and https://aka.ms/datadraw 298 Solving automatic algebra word problems can be viewed as a semantic pa"
D16-1029,Q15-1042,0,\N,Missing
D17-1323,P98-1013,0,0.0317432,"agrangian multiplier λj ≥ 0 for each corpus-level constraint. The Lagrangian is i L(λ, {y }) = X i fθ (y ) − i l X λj Aj j=1 X ! i y − bj , (4) i where all the λj ≥ 0, ∀j ∈ {1, . . . , l}. The solution of Eq. (3) can be obtained by the following iterative procedure: 1) At iteration t, get the output solution of each instance i y i,(t) = argmax L(λ(t−1) , y) y∈Y 0 2) update the Lagrangian multipliers. λ (t) (t−1) = max 0, λ + X η(Ay i,(t) (5) 5.1 Visual Semantic Role Labeling Dataset We evaluate on imSitu (Yatskar et al., 2016) where activity classes are drawn from verbs and roles in FrameNet (Baker et al., 1998) and noun categories are drawn from WordNet (Miller et al., 1990). The original dataset includes about 125,000 images with 75,702 for training, 25,200 for developing, and 25,200 for test. However, the dataset covers many non-human oriented activities (e.g., rearing, retrieving, and wagging), so we filter out these verbs, resulting in 212 verbs, leaving roughly 60,000 of the original 125,000 images in the dataset. Model We build on the baseline CRF released with the data, which has been shown effective compared to a non-structured prediction baseline (Yatskar et al., 2016). The model decomposes"
D17-1323,D11-1003,0,0.0106228,"accuracy learns to always predict the majority label, as the cost of making mistakes on samples in the minority class can be neglected. Various approaches have been proposed to make a “fair” binary classification (Barocas and Selbst, 2014; Dwork et al., 2012; Feldman 2980 et al., 2015; Zliobaite, 2015). For structured prediction tasks the effect is harder to quantify and we are the first to propose methods to reduce bias amplification in this context. Lagrangian relaxation and dual decomposition techniques have been widely used in NLP tasks (e.g., (Sontag et al., 2011; Rush and Collins, 2012; Chang and Collins, 2011; Peng et al., 2015)) for dealing with instance-level constraints. Similar techniques (Chang et al., 2013; Dalvi, 2015) have been applied in handling corpus-level constraints for semi-supervised multilabel classification. In contrast to previous works aiming for improving accuracy performance, we incorporate corpus-level constraints for reducing gender bias. 3 Visualizing and Quantifying Biases Modern statistical learning approaches capture correlations among output variables in order to make coherent predictions. However, for realworld applications, some implicit correlations are not appropri"
D17-1323,D15-1108,0,0.0164803,"predict the majority label, as the cost of making mistakes on samples in the minority class can be neglected. Various approaches have been proposed to make a “fair” binary classification (Barocas and Selbst, 2014; Dwork et al., 2012; Feldman 2980 et al., 2015; Zliobaite, 2015). For structured prediction tasks the effect is harder to quantify and we are the first to propose methods to reduce bias amplification in this context. Lagrangian relaxation and dual decomposition techniques have been widely used in NLP tasks (e.g., (Sontag et al., 2011; Rush and Collins, 2012; Chang and Collins, 2011; Peng et al., 2015)) for dealing with instance-level constraints. Similar techniques (Chang et al., 2013; Dalvi, 2015) have been applied in handling corpus-level constraints for semi-supervised multilabel classification. In contrast to previous works aiming for improving accuracy performance, we incorporate corpus-level constraints for reducing gender bias. 3 Visualizing and Quantifying Biases Modern statistical learning approaches capture correlations among output variables in order to make coherent predictions. However, for realworld applications, some implicit correlations are not appropriate, especially if t"
D18-1316,D15-1075,0,0.12837,"Missing"
D18-1316,P17-1152,0,0.0217157,"n, while preparing our submission, we became aware of recent work which target a similar contribution (Kuleshov et al., 2018; Ebrahimi et al., 2018). We treat these contributions as parallel work. 3 Attack Design 3.1 Threat model We assume the attacker has black-box access to the target model; the attacker is not aware of the model architecture, parameters, or training data, and is only capable of querying the target model with supplied inputs and obtaining the output predictions and their confidence scores. This setting has been extensively studied in the image domain (Papernot et al., 2017; Chen et al., 2017a; Alzantot et al., 2018), but has yet to be explored in the context of natural language. 3.2 Algorithm To avoid the limitations of gradient-based attack methods, we design an algorithm for constructing adversarial examples with the following goals in mind. We aim to minimize the number of modified words between the original and adversarial examples, but only perform modifications which retain semantic similarity with the original and syntactic coherence. To achieve these goals, instead of relying on gradient-based optimization, we developed an attack algorithm that exploits population-based g"
D18-1316,P18-2006,0,0.40483,"to induce misclassification has been studied in previous work (Papernot et al., 2016), however without consideration given to semantics or syntactics, yielding incoherent generated examples. In recent work, there have been a few attempts at generating adversarial examples for language tasks by using back-translation (Iyyer et al., 2018), exploiting machine-generated rules (Ribeiro et al., 2018), and searching in underlying semantic space (Zhao et al., 2018). In addition, while preparing our submission, we became aware of recent work which target a similar contribution (Kuleshov et al., 2018; Ebrahimi et al., 2018). We treat these contributions as parallel work. 3 Attack Design 3.1 Threat model We assume the attacker has black-box access to the target model; the attacker is not aware of the model architecture, parameters, or training data, and is only capable of querying the target model with supplied inputs and obtaining the output predictions and their confidence scores. This setting has been extensively studied in the image domain (Papernot et al., 2017; Chen et al., 2017a; Alzantot et al., 2018), but has yet to be explored in the context of natural language. 3.2 Algorithm To avoid the limitations of"
D18-1316,N18-1170,0,0.0629011,"t document in order to induce misclassification (Jia and Liang, 2017). In our work, we attempt to generate semantically and syntactically similar adversarial examples, via word replacements, resolving the aforementioned issues. Minimizing the number of word replacements necessary to induce misclassification has been studied in previous work (Papernot et al., 2016), however without consideration given to semantics or syntactics, yielding incoherent generated examples. In recent work, there have been a few attempts at generating adversarial examples for language tasks by using back-translation (Iyyer et al., 2018), exploiting machine-generated rules (Ribeiro et al., 2018), and searching in underlying semantic space (Zhao et al., 2018). In addition, while preparing our submission, we became aware of recent work which target a similar contribution (Kuleshov et al., 2018; Ebrahimi et al., 2018). We treat these contributions as parallel work. 3 Attack Design 3.1 Threat model We assume the attacker has black-box access to the target model; the attacker is not aware of the model architecture, parameters, or training data, and is only capable of querying the target model with supplied inputs and obtaining the"
D18-1316,D17-1215,0,0.212775,"the model input. However, this approach also fails because it still assumes that replacing every word with words nearby in the embedding space will not be noticeable. Replacing words without accounting for syntactic coherence will certainly lead to improperly constructed sentences which will look odd to the reader. Relative to the image domain, little work has been pursued for generating natural language adversarial examples. Given the difficulty in generating semantics-preserving perturbations, distracting sentences have been added to the input document in order to induce misclassification (Jia and Liang, 2017). In our work, we attempt to generate semantically and syntactically similar adversarial examples, via word replacements, resolving the aforementioned issues. Minimizing the number of word replacements necessary to induce misclassification has been studied in previous work (Papernot et al., 2016), however without consideration given to semantics or syntactics, yielding incoherent generated examples. In recent work, there have been a few attempts at generating adversarial examples for language tasks by using back-translation (Iyyer et al., 2018), exploiting machine-generated rules (Ribeiro et a"
D18-1316,N16-1018,0,0.111652,"Missing"
D18-1316,D14-1162,0,0.081355,"rder to explain our algorithm, we first introduce the subroutine Perturb. This subroutine accepts an input sentence xcur which can be either a modified sentence or the same as xorig . It randomly selects a word w 2891 in the sentence xcur and then selects a suitable replacement word that has similar semantic meaning, fits within the surrounding context, and increases the target label prediction score. In order to select the best replacement word, Perturb applies the following steps: • Computes the N nearest neighbors of the selected word according to the distance in the GloVe embedding space (Pennington et al., 2014). We used euclidean distance, as we did not see noticeable improvement using cosine. We filter out candidates with distance to the selected word greater than δ. We use the counter-fitting method presented in (Mrkˇsi´c et al., 2016) to post-process the adversary’s GloVe vectors to ensure that the nearest neighbors are synonyms. The resulting embedding is independent of the embeddings used by victim models. • Second, we use the Google 1 billion words language model (Chelba et al., 2013) to filter out words that do not fit within the context surrounding the word w in xcur . We do so by ranking th"
D18-1316,P18-1079,0,0.217518,"Liang, 2017). In our work, we attempt to generate semantically and syntactically similar adversarial examples, via word replacements, resolving the aforementioned issues. Minimizing the number of word replacements necessary to induce misclassification has been studied in previous work (Papernot et al., 2016), however without consideration given to semantics or syntactics, yielding incoherent generated examples. In recent work, there have been a few attempts at generating adversarial examples for language tasks by using back-translation (Iyyer et al., 2018), exploiting machine-generated rules (Ribeiro et al., 2018), and searching in underlying semantic space (Zhao et al., 2018). In addition, while preparing our submission, we became aware of recent work which target a similar contribution (Kuleshov et al., 2018; Ebrahimi et al., 2018). We treat these contributions as parallel work. 3 Attack Design 3.1 Threat model We assume the attacker has black-box access to the target model; the attacker is not aware of the model architecture, parameters, or training data, and is only capable of querying the target model with supplied inputs and obtaining the output predictions and their confidence scores. This setti"
D18-1316,D18-1316,1,0.0528356,"syntactically similar adversarial examples, via word replacements, resolving the aforementioned issues. Minimizing the number of word replacements necessary to induce misclassification has been studied in previous work (Papernot et al., 2016), however without consideration given to semantics or syntactics, yielding incoherent generated examples. In recent work, there have been a few attempts at generating adversarial examples for language tasks by using back-translation (Iyyer et al., 2018), exploiting machine-generated rules (Ribeiro et al., 2018), and searching in underlying semantic space (Zhao et al., 2018). In addition, while preparing our submission, we became aware of recent work which target a similar contribution (Kuleshov et al., 2018; Ebrahimi et al., 2018). We treat these contributions as parallel work. 3 Attack Design 3.1 Threat model We assume the attacker has black-box access to the target model; the attacker is not aware of the model architecture, parameters, or training data, and is only capable of querying the target model with supplied inputs and obtaining the output predictions and their confidence scores. This setting has been extensively studied in the image domain (Papernot et"
D18-1316,P11-1015,0,\N,Missing
D18-1521,Q18-1034,0,0.0144473,"t GN-GloVe effectively isolates the protected attributes and preserves the word proximity. 2 Related Work Word Embeddings Word embeddings serve as a fundamental building block for a broad range of NLP applications (dos Santos and Gatti, 2014; Bahdanau et al., 2014; Zeng et al., 2015) and various approaches (Mikolov et al., 2013b; Pennington et al., 2014; Levy et al., 2015) have been proposed for training the word vectors. Improvements have been made by leveraging semantic lexicons and morphology (Luong et al., 2013; Faruqui et al., 2014), disambiguating mulˇ tiple senses (Suster et al., 2016; Arora et al., 2018; Upadhyay et al., 2017), and modeling contextualized information by deep neural networks (Peters et al., 2018). However, none of these works attempts to tackle the problem of stereotypes exhibited in embeddings. Stereotype Analysis Implicit stereotypes have been observed in applications such as online advertising systems (Sweeney, 2013), web search (Kay et al., 2015), and online reviews (Wallace and Paul, 2016). Besides, Zhao et al. (2017) and Rudinger et al. (2018) show that coreference resolution systems are gender biased. The systems can successfully predict the link between “the president"
D18-1521,D15-1075,0,0.0310934,"ne of these works attempts to tackle the problem of stereotypes exhibited in embeddings. Stereotype Analysis Implicit stereotypes have been observed in applications such as online advertising systems (Sweeney, 2013), web search (Kay et al., 2015), and online reviews (Wallace and Paul, 2016). Besides, Zhao et al. (2017) and Rudinger et al. (2018) show that coreference resolution systems are gender biased. The systems can successfully predict the link between “the president” with male pronoun but fail with the female one. Rudinger et al. (2017) use pointwise mutual information to test the SNLI (Bowman et al., 2015) corpus and demonstrate gender stereotypes as well as varying degrees of racial, religious, and age-based stereotypes in the corpus. A temporal analysis about word embeddings (Garg et al., 2018) captures changes in gender and ethnic stereotypes over time. Researchers attributed such problem partly to the biases in the datasets (Zhao et al., 2017; Yao and Huang, 2017) and word embeddings (Garg et al., 2017; Caliskan et al., 2017) but did not provide constructive solutions. 3 Methodology In this paper, we take GloVe (Pennington et al., 2014) as the base embedding model and gender as the protecte"
D18-1521,P12-1015,0,0.0436162,"Missing"
D18-1521,S12-1047,0,0.148259,"Missing"
D18-1521,D17-1018,0,0.0752264,"Missing"
D18-1521,Q15-1016,0,0.0431465,"to learn word embeddings with protected attributes; 2) By capturing protected attributes in certain dimensions, our approach ameliorates the interpretability of word representations; 3) Qualitative and quantitative experiments demonstrate that GN-GloVe effectively isolates the protected attributes and preserves the word proximity. 2 Related Work Word Embeddings Word embeddings serve as a fundamental building block for a broad range of NLP applications (dos Santos and Gatti, 2014; Bahdanau et al., 2014; Zeng et al., 2015) and various approaches (Mikolov et al., 2013b; Pennington et al., 2014; Levy et al., 2015) have been proposed for training the word vectors. Improvements have been made by leveraging semantic lexicons and morphology (Luong et al., 2013; Faruqui et al., 2014), disambiguating mulˇ tiple senses (Suster et al., 2016; Arora et al., 2018; Upadhyay et al., 2017), and modeling contextualized information by deep neural networks (Peters et al., 2018). However, none of these works attempts to tackle the problem of stereotypes exhibited in embeddings. Stereotype Analysis Implicit stereotypes have been observed in applications such as online advertising systems (Sweeney, 2013), web search (Kay"
D18-1521,W13-3512,0,0.425626,"erpretability of word representations; 3) Qualitative and quantitative experiments demonstrate that GN-GloVe effectively isolates the protected attributes and preserves the word proximity. 2 Related Work Word Embeddings Word embeddings serve as a fundamental building block for a broad range of NLP applications (dos Santos and Gatti, 2014; Bahdanau et al., 2014; Zeng et al., 2015) and various approaches (Mikolov et al., 2013b; Pennington et al., 2014; Levy et al., 2015) have been proposed for training the word vectors. Improvements have been made by leveraging semantic lexicons and morphology (Luong et al., 2013; Faruqui et al., 2014), disambiguating mulˇ tiple senses (Suster et al., 2016; Arora et al., 2018; Upadhyay et al., 2017), and modeling contextualized information by deep neural networks (Peters et al., 2018). However, none of these works attempts to tackle the problem of stereotypes exhibited in embeddings. Stereotype Analysis Implicit stereotypes have been observed in applications such as online advertising systems (Sweeney, 2013), web search (Kay et al., 2015), and online reviews (Wallace and Paul, 2016). Besides, Zhao et al. (2017) and Rudinger et al. (2018) show that coreference resoluti"
D18-1521,N13-1090,0,0.599911,"our best knowledge, GN-GloVe is the first method to learn word embeddings with protected attributes; 2) By capturing protected attributes in certain dimensions, our approach ameliorates the interpretability of word representations; 3) Qualitative and quantitative experiments demonstrate that GN-GloVe effectively isolates the protected attributes and preserves the word proximity. 2 Related Work Word Embeddings Word embeddings serve as a fundamental building block for a broad range of NLP applications (dos Santos and Gatti, 2014; Bahdanau et al., 2014; Zeng et al., 2015) and various approaches (Mikolov et al., 2013b; Pennington et al., 2014; Levy et al., 2015) have been proposed for training the word vectors. Improvements have been made by leveraging semantic lexicons and morphology (Luong et al., 2013; Faruqui et al., 2014), disambiguating mulˇ tiple senses (Suster et al., 2016; Arora et al., 2018; Upadhyay et al., 2017), and modeling contextualized information by deep neural networks (Peters et al., 2018). However, none of these works attempts to tackle the problem of stereotypes exhibited in embeddings. Stereotype Analysis Implicit stereotypes have been observed in applications such as online adverti"
D18-1521,D14-1162,0,0.124157,"oach and requires the gender-neutral words to be identified by a classifier before employing the projection. If the classifier makes a mistake, the error will be propagated and affect the performance of the model. Second, their method completely removes gender information from those words which are essential in some domains such as medicine and social science (Back et al., 2010; McFadden et al., 1992). To overcome these limitations, we propose a learning scheme, Gender-Neutral Global Vectors (GN-GloVe) for training word embedding models with protected attributes (e.g., gender) based on GloVe (Pennington et al., 2014).2 GN-GloVe represents protected attributes in certain dimen1 Gender-definition words are the words associated with gender by definition (e,g., mother, waitress); the remainder are gender-neutral words. 2 The code and data are released at https://github. com/uclanlp/gn_glove 4847 Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 4847–4853 c Brussels, Belgium, October 31 - November 4, 2018. 2018 Association for Computational Linguistics sions while neutralizing the others during training. As the information of the protected attribute is restricted in"
D18-1521,N18-1202,0,0.0525606,"d Embeddings Word embeddings serve as a fundamental building block for a broad range of NLP applications (dos Santos and Gatti, 2014; Bahdanau et al., 2014; Zeng et al., 2015) and various approaches (Mikolov et al., 2013b; Pennington et al., 2014; Levy et al., 2015) have been proposed for training the word vectors. Improvements have been made by leveraging semantic lexicons and morphology (Luong et al., 2013; Faruqui et al., 2014), disambiguating mulˇ tiple senses (Suster et al., 2016; Arora et al., 2018; Upadhyay et al., 2017), and modeling contextualized information by deep neural networks (Peters et al., 2018). However, none of these works attempts to tackle the problem of stereotypes exhibited in embeddings. Stereotype Analysis Implicit stereotypes have been observed in applications such as online advertising systems (Sweeney, 2013), web search (Kay et al., 2015), and online reviews (Wallace and Paul, 2016). Besides, Zhao et al. (2017) and Rudinger et al. (2018) show that coreference resolution systems are gender biased. The systems can successfully predict the link between “the president” with male pronoun but fail with the female one. Rudinger et al. (2017) use pointwise mutual information to te"
D18-1521,D15-1203,0,0.0167657,"ributions are summarized as follows: 1) To our best knowledge, GN-GloVe is the first method to learn word embeddings with protected attributes; 2) By capturing protected attributes in certain dimensions, our approach ameliorates the interpretability of word representations; 3) Qualitative and quantitative experiments demonstrate that GN-GloVe effectively isolates the protected attributes and preserves the word proximity. 2 Related Work Word Embeddings Word embeddings serve as a fundamental building block for a broad range of NLP applications (dos Santos and Gatti, 2014; Bahdanau et al., 2014; Zeng et al., 2015) and various approaches (Mikolov et al., 2013b; Pennington et al., 2014; Levy et al., 2015) have been proposed for training the word vectors. Improvements have been made by leveraging semantic lexicons and morphology (Luong et al., 2013; Faruqui et al., 2014), disambiguating mulˇ tiple senses (Suster et al., 2016; Arora et al., 2018; Upadhyay et al., 2017), and modeling contextualized information by deep neural networks (Peters et al., 2018). However, none of these works attempts to tackle the problem of stereotypes exhibited in embeddings. Stereotype Analysis Implicit stereotypes have been ob"
D18-1521,D17-1323,1,0.693553,"been made by leveraging semantic lexicons and morphology (Luong et al., 2013; Faruqui et al., 2014), disambiguating mulˇ tiple senses (Suster et al., 2016; Arora et al., 2018; Upadhyay et al., 2017), and modeling contextualized information by deep neural networks (Peters et al., 2018). However, none of these works attempts to tackle the problem of stereotypes exhibited in embeddings. Stereotype Analysis Implicit stereotypes have been observed in applications such as online advertising systems (Sweeney, 2013), web search (Kay et al., 2015), and online reviews (Wallace and Paul, 2016). Besides, Zhao et al. (2017) and Rudinger et al. (2018) show that coreference resolution systems are gender biased. The systems can successfully predict the link between “the president” with male pronoun but fail with the female one. Rudinger et al. (2017) use pointwise mutual information to test the SNLI (Bowman et al., 2015) corpus and demonstrate gender stereotypes as well as varying degrees of racial, religious, and age-based stereotypes in the corpus. A temporal analysis about word embeddings (Garg et al., 2018) captures changes in gender and ethnic stereotypes over time. Researchers attributed such problem partly t"
D18-1521,N18-2003,1,0.783428,"for representing the meaning of words in a vector space. These models have become a fundamental NLP technique and have been widely used in various applications. However, prior studies show that such models learned from humangenerated corpora are often prone to exhibit social biases, such as gender stereotypes (Bolukbasi et al., 2016; Caliskan et al., 2017). For example, the word “programmer” is neutral to gender by its definition, but an embedding model trained on a news corpus associates “programmer” closer with “male” than “female”. Such a bias substantially affects downstream applications. Zhao et al. (2018) show that a coreference resolution system is sexist due to the word embedding component used in the system. This concerns the practitioners who use the embedding model to build gender-sensitive applications such as a resume filtering system or a job recommendation system as the automated system may discriminate candidates based on their gender, as reflected by their name. Besides, biased embeddings may implicitly affect downstream applications used in our daily lives. For example, when searching for “computer scientist” using a search engine, as this phrase is closer to male names than female"
D18-1521,W17-1609,0,0.106412,"Missing"
D18-1521,N18-2002,0,0.200547,"Missing"
D18-1521,C14-1008,0,0.0108002,"n reducing other societal stereotypes. Our contributions are summarized as follows: 1) To our best knowledge, GN-GloVe is the first method to learn word embeddings with protected attributes; 2) By capturing protected attributes in certain dimensions, our approach ameliorates the interpretability of word representations; 3) Qualitative and quantitative experiments demonstrate that GN-GloVe effectively isolates the protected attributes and preserves the word proximity. 2 Related Work Word Embeddings Word embeddings serve as a fundamental building block for a broad range of NLP applications (dos Santos and Gatti, 2014; Bahdanau et al., 2014; Zeng et al., 2015) and various approaches (Mikolov et al., 2013b; Pennington et al., 2014; Levy et al., 2015) have been proposed for training the word vectors. Improvements have been made by leveraging semantic lexicons and morphology (Luong et al., 2013; Faruqui et al., 2014), disambiguating mulˇ tiple senses (Suster et al., 2016; Arora et al., 2018; Upadhyay et al., 2017), and modeling contextualized information by deep neural networks (Peters et al., 2018). However, none of these works attempts to tackle the problem of stereotypes exhibited in embeddings. Stereotype"
D18-1521,N16-1160,0,0.0487368,"Missing"
D18-1521,W17-2613,1,0.833701,"ly isolates the protected attributes and preserves the word proximity. 2 Related Work Word Embeddings Word embeddings serve as a fundamental building block for a broad range of NLP applications (dos Santos and Gatti, 2014; Bahdanau et al., 2014; Zeng et al., 2015) and various approaches (Mikolov et al., 2013b; Pennington et al., 2014; Levy et al., 2015) have been proposed for training the word vectors. Improvements have been made by leveraging semantic lexicons and morphology (Luong et al., 2013; Faruqui et al., 2014), disambiguating mulˇ tiple senses (Suster et al., 2016; Arora et al., 2018; Upadhyay et al., 2017), and modeling contextualized information by deep neural networks (Peters et al., 2018). However, none of these works attempts to tackle the problem of stereotypes exhibited in embeddings. Stereotype Analysis Implicit stereotypes have been observed in applications such as online advertising systems (Sweeney, 2013), web search (Kay et al., 2015), and online reviews (Wallace and Paul, 2016). Besides, Zhao et al. (2017) and Rudinger et al. (2018) show that coreference resolution systems are gender biased. The systems can successfully predict the link between “the president” with male pronoun but"
D19-1103,W17-0401,0,0.399038,"Missing"
D19-1103,W14-4200,0,0.242095,"Missing"
D19-1103,N19-1253,1,0.725246,"Smith et al., 2017) or delexicalization approaches (Zeman and Resnik, 2008; McDonald et al., 2013). One key challenge for cross-lingual transfer is the differences among languages; for example, languages may have different word orders. When transferring a model learned from a source language to target languages, the performance may drop significantly due to the differences. To tackle this problem, various approaches have been proposed to better capture the commonalities between the source and the target languages (McDonald et al., 2011; Guo et al., 2016; T¨ackstr¨om et al., 2013; Agi´c, 2017; Ahmad et al., 2019); however, they overlook the potential to leverage linguistic knowledge about the target language to account for the differences between the source and the target languages to facilitate the transfer. In this paper, we propose a complementary approach that studies how to leverage the linguistic knowledge about the target languages to help the transfer. Specifically, we use corpus linguistic statistics of the target languages as weak supervision signals to guide the test-time inference process when parsing with a graph-based parser. This approach is effective as the model only need to be traine"
D19-1103,P15-1133,0,0.0226936,"rom multiple languages. Ahmad et al. (2019) design an order-free model to take out the order features from the source language. Xiao and Guo (2014); Guo et al. (2015) learn an alignment from source words to target words. Ponti et al. (2018) learn an anisomorphism from the source parsing tree to target. Rasooli and Collins (2019) reorder the source data before training. In contrast, we focus on incorporating linguistic properties in the target languages. Constrained Inference for Parsing Several previous studies show that adding constraints in inference time improves the performance of models. Grave and Elhadad (2015) consider incorporating constraints to promote popular types of arcs in an unsupervised setting. Naseem et al. (2010); Li et al. (2019) train a parser with constraints compiled from the frequency of particular arcs. Compared with the previous work, we focus on crosslingual transfer with word order constraints. Finally, prior studies have noticed that the word order information is significant for parsing and use it as features (Ammar et al., 2016; Naseem et al., 2012; Rasooli and Collins, 2017; Zhang and Barzilay, 2015; Dryer, 2007). T¨ackstr¨om et al. (2013) further propose to decompose these"
D19-1103,Q17-1010,0,0.0186393,"real low-resource languages. We first introduce the experimental setup including data selection and constraint details and then discuss the results as well as in-depth analysis. 4.1 Setup Model and Data We train the best performing Att-Graph parser proposed in Ahmad et al. (2019) 3 In implementation, we use stochastic gradient descent with Adam optimizer (Kingma and Ba, 2015) on English and transfer it to 19 target languages in UD Tree Bank v2.2 (Nivre et al., 2018).4 The model takes words and predicted POS tags5 as input, and achieve transfer by leveraging pre-trained multi-lingual FastText (Bojanowski et al., 2017) embeddings that project the word embeddings from different languages into the same space using an offline transformation method (Smith et al., 2017; Conneau et al., 2018). The SelfAtt-Graph model uses a Transformer (Vaswani et al., 2017) with relative position embedding as the encoder and a deep biaffine scorer (Dozat and Manning, 2017) as the decoder. We follow the setting in Ahmad et al. (2019) to train and tune only on the source language (English) and directly transfer to all the target languages. We modify their decoder to incorporate constraints with the proposed constrained inference a"
D19-1103,D11-1003,0,0.0182421,"get languages together with a similar language, and design a stochastic permutation process to synthetic the word order. However, none of them consider using the word order features as constraints. Incorporating Constraints In NLP Tasks Constraints are widely incorporated in variety of NLP tasks. To name a few, Roth and Yih (2004) propose to formulate constrained inferences in NLP as integer linear programming problems. To solve the intractable structure, Rush and Collins (2012) decompose the structure and incorporate constraints on some composite tasks. To improve the performance of a model, Chang and Collins (2011); Peng et al. (2015) incorporate constraints on exact decoding tasks and inference tasks on graphical models, and Chang et al. (2013); Dalvi (2015); Martins (2015) incorporate corpus-level constraints on semi-supervised multilabel classification and coreference resolution. Zhao et al. (2017) incorporate corpus-level constraints to avoid amplifying gender bias on visual semantic role labeling and multilabel classification. In contrast to previous work, we incorporate corpuslevel constraints to facilitate dependency parser in the cross-lingual transfer setting. 6 Conclusion We propose to leverag"
D19-1103,P19-1299,0,0.028868,"f the ratio difference between source and target languages. Results show that the performance improvement is highly related to the ratio gap. The Pearson Correlation Coefficient is 0.938. The figure showing the correlation between performance gap (as per UAS) and the corpus statistics ratio gap is in the Appendix Figure 3. 5 Related Work Cross-Lingual Transfer for Parsing Many approaches have been developed to transfer a dependency parser. However, they mainly focus on better capture information from the source language(s). McDonald et al. (2011); Guo et al. (2016); T¨ackstr¨om et al. (2013); Chen et al. (2019) consider transferring a parser trained on multiple source languages. Agi´c (2017); Lin et al. (2019) selects good source languages by comparing part-of-speech tags sequences. Søgaard (2011); T¨ackstr¨om et al. (2013) chooses suitable data points from the source language. Pires et al. (2019) uses multilingual BERT to leverage language features from multiple languages. Ahmad et al. (2019) design an order-free model to take out the order features from the source language. Xiao and Guo (2014); Guo et al. (2015) learn an alignment from source words to target words. Ponti et al. (2018) learn an ani"
D19-1103,P15-1119,0,0.141924,"ce language(s). McDonald et al. (2011); Guo et al. (2016); T¨ackstr¨om et al. (2013); Chen et al. (2019) consider transferring a parser trained on multiple source languages. Agi´c (2017); Lin et al. (2019) selects good source languages by comparing part-of-speech tags sequences. Søgaard (2011); T¨ackstr¨om et al. (2013) chooses suitable data points from the source language. Pires et al. (2019) uses multilingual BERT to leverage language features from multiple languages. Ahmad et al. (2019) design an order-free model to take out the order features from the source language. Xiao and Guo (2014); Guo et al. (2015) learn an alignment from source words to target words. Ponti et al. (2018) learn an anisomorphism from the source parsing tree to target. Rasooli and Collins (2019) reorder the source data before training. In contrast, we focus on incorporating linguistic properties in the target languages. Constrained Inference for Parsing Several previous studies show that adding constraints in inference time improves the performance of models. Grave and Elhadad (2015) consider incorporating constraints to promote popular types of arcs in an unsupervised setting. Naseem et al. (2010); Li et al. (2019) train"
D19-1103,K17-1024,0,0.140706,"Missing"
D19-1103,Q16-1023,0,0.0296348,"Missing"
D19-1103,D16-1180,0,0.0291007,"Missing"
D19-1103,P15-1138,0,0.020709,"features as constraints. Incorporating Constraints In NLP Tasks Constraints are widely incorporated in variety of NLP tasks. To name a few, Roth and Yih (2004) propose to formulate constrained inferences in NLP as integer linear programming problems. To solve the intractable structure, Rush and Collins (2012) decompose the structure and incorporate constraints on some composite tasks. To improve the performance of a model, Chang and Collins (2011); Peng et al. (2015) incorporate constraints on exact decoding tasks and inference tasks on graphical models, and Chang et al. (2013); Dalvi (2015); Martins (2015) incorporate corpus-level constraints on semi-supervised multilabel classification and coreference resolution. Zhao et al. (2017) incorporate corpus-level constraints to avoid amplifying gender bias on visual semantic role labeling and multilabel classification. In contrast to previous work, we incorporate corpuslevel constraints to facilitate dependency parser in the cross-lingual transfer setting. 6 Conclusion We propose to leverage corpus-linguistic statistics to guide the inference of cross-lingual dependency parsing. We compile these statistics into corpus-statistic constraints and design"
D19-1103,P05-1012,0,0.0716399,"rees of sentence k. In recent years, neural network approaches (Kiperwasser and Goldberg, 2016; Wang and Chang, 2016; Kuncoro et al., 2016; Dozat and Manning, 2017) have been applied to modeling the scoring matrix S (k) and have achieved great performance in dependency parsing. From the probabilistic point of view, if we assume for different i, j, the edge probabilities P (yk (i, j) = 1|wk ) are mutually conditional independent, the probability of a whole parse tree can be written as Y P (yk |wk ) = P (yk (i, j) = 1|wk )yk (i,j) . (2) i,j Our work focuses on the graph-based dependency parser (McDonald et al., 2005) in the zero-shot single-source transfer setting as in Ahmad et al. (2019). However, the proposed algorithms can be extended other transfer settings. Given a trained model, we derive corpus-statistics constraints and apply them to correct errors caused by word order differences between the source and the target language during the inference time. Figure 1 shows an example of how constraints can influence the inference results. In this section, we first give a quick review of the graph-based parser and introduce the notations. We then discuss how to formulate corpuswise constraints based on cor"
D19-1103,P13-2017,0,0.0782545,"Missing"
D19-1103,D11-1006,0,0.640315,"swering (Joty et al., 2017), using a shared multi-lingual word embedding space (Smith et al., 2017) or delexicalization approaches (Zeman and Resnik, 2008; McDonald et al., 2013). One key challenge for cross-lingual transfer is the differences among languages; for example, languages may have different word orders. When transferring a model learned from a source language to target languages, the performance may drop significantly due to the differences. To tackle this problem, various approaches have been proposed to better capture the commonalities between the source and the target languages (McDonald et al., 2011; Guo et al., 2016; T¨ackstr¨om et al., 2013; Agi´c, 2017; Ahmad et al., 2019); however, they overlook the potential to leverage linguistic knowledge about the target language to account for the differences between the source and the target languages to facilitate the transfer. In this paper, we propose a complementary approach that studies how to leverage the linguistic knowledge about the target languages to help the transfer. Specifically, we use corpus linguistic statistics of the target languages as weak supervision signals to guide the test-time inference process when parsing with a grap"
D19-1103,P12-1066,0,0.122837,"ence for Parsing Several previous studies show that adding constraints in inference time improves the performance of models. Grave and Elhadad (2015) consider incorporating constraints to promote popular types of arcs in an unsupervised setting. Naseem et al. (2010); Li et al. (2019) train a parser with constraints compiled from the frequency of particular arcs. Compared with the previous work, we focus on crosslingual transfer with word order constraints. Finally, prior studies have noticed that the word order information is significant for parsing and use it as features (Ammar et al., 2016; Naseem et al., 2012; Rasooli and Collins, 2017; Zhang and Barzilay, 2015; Dryer, 2007). T¨ackstr¨om et al. (2013) further propose to decompose these features from models for adapting target languages. Wang and Eisner (2018a) use the statistics of surface part-of-speech (POS) tags of target languages to learn the word order. Wang and Eisner (2018b) use POS tags of target languages together with a similar language, and design a stochastic permutation process to synthetic the word order. However, none of them consider using the word order features as constraints. Incorporating Constraints In NLP Tasks Constraints a"
D19-1103,D10-1120,0,0.021563,"guage. Xiao and Guo (2014); Guo et al. (2015) learn an alignment from source words to target words. Ponti et al. (2018) learn an anisomorphism from the source parsing tree to target. Rasooli and Collins (2019) reorder the source data before training. In contrast, we focus on incorporating linguistic properties in the target languages. Constrained Inference for Parsing Several previous studies show that adding constraints in inference time improves the performance of models. Grave and Elhadad (2015) consider incorporating constraints to promote popular types of arcs in an unsupervised setting. Naseem et al. (2010); Li et al. (2019) train a parser with constraints compiled from the frequency of particular arcs. Compared with the previous work, we focus on crosslingual transfer with word order constraints. Finally, prior studies have noticed that the word order information is significant for parsing and use it as features (Ammar et al., 2016; Naseem et al., 2012; Rasooli and Collins, 2017; Zhang and Barzilay, 2015; Dryer, 2007). T¨ackstr¨om et al. (2013) further propose to decompose these features from models for adapting target languages. Wang and Eisner (2018a) use the statistics of surface part-of-spe"
D19-1103,P15-2034,0,0.0146672,"s: a) leveraging existing linguistics resources or consulting linguists; b) leveraging a higher-resource language that is similar to the target language (e.g., Finnish and Estonian) to collect the statistics. In this paper, we explore the first option and leverage the WALS features, which provide a reference for word order typology, to estimate the ratios. Compile Constraints From WALS Features. For a particular language, once we collect the corpus-statistics of a pair of POS tags, we can formulate a binary constraint. There are different ways to estimate the corpus-statistics. For exam¨ ple, Ostling (2015) utilizes a small amount of parallel data to estimate the dominant word orders. In this paper, we simply utilize a small subset of WALS features that show the dominant order of some POS pairs (e.g. adjective and noun) in a language. They can be directly compiled into binary constraints. Similarly, we can estimate the ratio for unary constraints based on WALS features. For a particular POS tag, we choose all WALS features related to it to formulate a feature vector f . The mapping from the vector f to the unary constraint ratio r is learnable: for each language with annotated data, we can get a"
D19-1103,D15-1108,1,0.938893,"veraging existing linguistics resources or consulting linguists; b) leveraging a higher-resource language that is similar to the target language (e.g., Finnish and Estonian) to collect the statistics. In this paper, we explore the first option and leverage the WALS features, which provide a reference for word order typology, to estimate the ratios. Compile Constraints From WALS Features. For a particular language, once we collect the corpus-statistics of a pair of POS tags, we can formulate a binary constraint. There are different ways to estimate the corpus-statistics. For exam¨ ple, Ostling (2015) utilizes a small amount of parallel data to estimate the dominant word orders. In this paper, we simply utilize a small subset of WALS features that show the dominant order of some POS pairs (e.g. adjective and noun) in a language. They can be directly compiled into binary constraints. Similarly, we can estimate the ratio for unary constraints based on WALS features. For a particular POS tag, we choose all WALS features related to it to formulate a feature vector f . The mapping from the vector f to the unary constraint ratio r is learnable: for each language with annotated data, we can get a"
D19-1103,P19-1493,0,0.274139,"2016; Wang and Chang, 2016; Kuncoro et al., 2016; Dozat and Manning, 2017) have been applied to modeling the scoring matrix S (k) and have achieved great performance in dependency parsing. From the probabilistic point of view, if we assume for different i, j, the edge probabilities P (yk (i, j) = 1|wk ) are mutually conditional independent, the probability of a whole parse tree can be written as Y P (yk |wk ) = P (yk (i, j) = 1|wk )yk (i,j) . (2) i,j Our work focuses on the graph-based dependency parser (McDonald et al., 2005) in the zero-shot single-source transfer setting as in Ahmad et al. (2019). However, the proposed algorithms can be extended other transfer settings. Given a trained model, we derive corpus-statistics constraints and apply them to correct errors caused by word order differences between the source and the target language during the inference time. Figure 1 shows an example of how constraints can influence the inference results. In this section, we first give a quick review of the graph-based parser and introduce the notations. We then discuss how to formulate corpuswise constraints based on corpus linguistic statistics for guiding the graph-based parser. 2.1 denotes"
D19-1103,P18-1142,0,0.21455,"Missing"
D19-1103,Q17-1020,0,0.162814,"ral previous studies show that adding constraints in inference time improves the performance of models. Grave and Elhadad (2015) consider incorporating constraints to promote popular types of arcs in an unsupervised setting. Naseem et al. (2010); Li et al. (2019) train a parser with constraints compiled from the frequency of particular arcs. Compared with the previous work, we focus on crosslingual transfer with word order constraints. Finally, prior studies have noticed that the word order information is significant for parsing and use it as features (Ammar et al., 2016; Naseem et al., 2012; Rasooli and Collins, 2017; Zhang and Barzilay, 2015; Dryer, 2007). T¨ackstr¨om et al. (2013) further propose to decompose these features from models for adapting target languages. Wang and Eisner (2018a) use the statistics of surface part-of-speech (POS) tags of target languages to learn the word order. Wang and Eisner (2018b) use POS tags of target languages together with a similar language, and design a stochastic permutation process to synthetic the word order. However, none of them consider using the word order features as constraints. Incorporating Constraints In NLP Tasks Constraints are widely incorporated in v"
D19-1103,N19-1385,0,0.162792,"source languages. Agi´c (2017); Lin et al. (2019) selects good source languages by comparing part-of-speech tags sequences. Søgaard (2011); T¨ackstr¨om et al. (2013) chooses suitable data points from the source language. Pires et al. (2019) uses multilingual BERT to leverage language features from multiple languages. Ahmad et al. (2019) design an order-free model to take out the order features from the source language. Xiao and Guo (2014); Guo et al. (2015) learn an alignment from source words to target words. Ponti et al. (2018) learn an anisomorphism from the source parsing tree to target. Rasooli and Collins (2019) reorder the source data before training. In contrast, we focus on incorporating linguistic properties in the target languages. Constrained Inference for Parsing Several previous studies show that adding constraints in inference time improves the performance of models. Grave and Elhadad (2015) consider incorporating constraints to promote popular types of arcs in an unsupervised setting. Naseem et al. (2010); Li et al. (2019) train a parser with constraints compiled from the frequency of particular arcs. Compared with the previous work, we focus on crosslingual transfer with word order constra"
D19-1103,W04-2401,0,0.0784584,"007). T¨ackstr¨om et al. (2013) further propose to decompose these features from models for adapting target languages. Wang and Eisner (2018a) use the statistics of surface part-of-speech (POS) tags of target languages to learn the word order. Wang and Eisner (2018b) use POS tags of target languages together with a similar language, and design a stochastic permutation process to synthetic the word order. However, none of them consider using the word order features as constraints. Incorporating Constraints In NLP Tasks Constraints are widely incorporated in variety of NLP tasks. To name a few, Roth and Yih (2004) propose to formulate constrained inferences in NLP as integer linear programming problems. To solve the intractable structure, Rush and Collins (2012) decompose the structure and incorporate constraints on some composite tasks. To improve the performance of a model, Chang and Collins (2011); Peng et al. (2015) incorporate constraints on exact decoding tasks and inference tasks on graphical models, and Chang et al. (2013); Dalvi (2015); Martins (2015) incorporate corpus-level constraints on semi-supervised multilabel classification and coreference resolution. Zhao et al. (2017) incorporate cor"
D19-1103,P11-1008,0,0.218504,"Missing"
D19-1103,P11-2120,0,0.0621394,"gure showing the correlation between performance gap (as per UAS) and the corpus statistics ratio gap is in the Appendix Figure 3. 5 Related Work Cross-Lingual Transfer for Parsing Many approaches have been developed to transfer a dependency parser. However, they mainly focus on better capture information from the source language(s). McDonald et al. (2011); Guo et al. (2016); T¨ackstr¨om et al. (2013); Chen et al. (2019) consider transferring a parser trained on multiple source languages. Agi´c (2017); Lin et al. (2019) selects good source languages by comparing part-of-speech tags sequences. Søgaard (2011); T¨ackstr¨om et al. (2013) chooses suitable data points from the source language. Pires et al. (2019) uses multilingual BERT to leverage language features from multiple languages. Ahmad et al. (2019) design an order-free model to take out the order features from the source language. Xiao and Guo (2014); Guo et al. (2015) learn an alignment from source words to target words. Ponti et al. (2018) learn an anisomorphism from the source parsing tree to target. Rasooli and Collins (2019) reorder the source data before training. In contrast, we focus on incorporating linguistic properties in the tar"
D19-1103,D18-1034,0,0.0268332,"e performance in a variety of tasks when sufficient training data is available. However, obtaining high-quality annotations for low-resource language tasks is challenging, and this poses great challenges to process low-resource languages. To bridge the gap, crosslingual transfer has been proposed to transfer models trained on high-resource languages (e.g., English) to low-resource languages (e.g., Tamil) to combat the resource scarcity problem. Recent studies have demonstrated successes of transferring models across languages without retraining for NLP tasks, such as named entity recognition (Xie et al., 2018), dependency parsing (Tiedemann, 2015; Agi´c et al., 2014), and question answering (Joty et al., 2017), using a shared multi-lingual word embedding space (Smith et al., 2017) or delexicalization approaches (Zeman and Resnik, 2008; McDonald et al., 2013). One key challenge for cross-lingual transfer is the differences among languages; for example, languages may have different word orders. When transferring a model learned from a source language to target languages, the performance may drop significantly due to the differences. To tackle this problem, various approaches have been proposed to bet"
D19-1103,I08-3008,0,0.151622,"rce languages. To bridge the gap, crosslingual transfer has been proposed to transfer models trained on high-resource languages (e.g., English) to low-resource languages (e.g., Tamil) to combat the resource scarcity problem. Recent studies have demonstrated successes of transferring models across languages without retraining for NLP tasks, such as named entity recognition (Xie et al., 2018), dependency parsing (Tiedemann, 2015; Agi´c et al., 2014), and question answering (Joty et al., 2017), using a shared multi-lingual word embedding space (Smith et al., 2017) or delexicalization approaches (Zeman and Resnik, 2008; McDonald et al., 2013). One key challenge for cross-lingual transfer is the differences among languages; for example, languages may have different word orders. When transferring a model learned from a source language to target languages, the performance may drop significantly due to the differences. To tackle this problem, various approaches have been proposed to better capture the commonalities between the source and the target languages (McDonald et al., 2011; Guo et al., 2016; T¨ackstr¨om et al., 2013; Agi´c, 2017; Ahmad et al., 2019); however, they overlook the potential to leverage ling"
D19-1103,D15-1213,0,0.268059,"hat adding constraints in inference time improves the performance of models. Grave and Elhadad (2015) consider incorporating constraints to promote popular types of arcs in an unsupervised setting. Naseem et al. (2010); Li et al. (2019) train a parser with constraints compiled from the frequency of particular arcs. Compared with the previous work, we focus on crosslingual transfer with word order constraints. Finally, prior studies have noticed that the word order information is significant for parsing and use it as features (Ammar et al., 2016; Naseem et al., 2012; Rasooli and Collins, 2017; Zhang and Barzilay, 2015; Dryer, 2007). T¨ackstr¨om et al. (2013) further propose to decompose these features from models for adapting target languages. Wang and Eisner (2018a) use the statistics of surface part-of-speech (POS) tags of target languages to learn the word order. Wang and Eisner (2018b) use POS tags of target languages together with a similar language, and design a stochastic permutation process to synthetic the word order. However, none of them consider using the word order features as constraints. Incorporating Constraints In NLP Tasks Constraints are widely incorporated in variety of NLP tasks. To na"
D19-1103,D17-1323,1,0.877029,"To name a few, Roth and Yih (2004) propose to formulate constrained inferences in NLP as integer linear programming problems. To solve the intractable structure, Rush and Collins (2012) decompose the structure and incorporate constraints on some composite tasks. To improve the performance of a model, Chang and Collins (2011); Peng et al. (2015) incorporate constraints on exact decoding tasks and inference tasks on graphical models, and Chang et al. (2013); Dalvi (2015); Martins (2015) incorporate corpus-level constraints on semi-supervised multilabel classification and coreference resolution. Zhao et al. (2017) incorporate corpus-level constraints to avoid amplifying gender bias on visual semantic role labeling and multilabel classification. In contrast to previous work, we incorporate corpuslevel constraints to facilitate dependency parser in the cross-lingual transfer setting. 6 Conclusion We propose to leverage corpus-linguistic statistics to guide the inference of cross-lingual dependency parsing. We compile these statistics into corpus-statistic constraints and design two inference algorithms on top of a graph-based parser based on Lagrangian relaxation and posterior regularization. Experiments"
D19-1103,N13-1126,0,0.296389,"Missing"
D19-1103,W15-2137,0,0.0599466,"n sufficient training data is available. However, obtaining high-quality annotations for low-resource language tasks is challenging, and this poses great challenges to process low-resource languages. To bridge the gap, crosslingual transfer has been proposed to transfer models trained on high-resource languages (e.g., English) to low-resource languages (e.g., Tamil) to combat the resource scarcity problem. Recent studies have demonstrated successes of transferring models across languages without retraining for NLP tasks, such as named entity recognition (Xie et al., 2018), dependency parsing (Tiedemann, 2015; Agi´c et al., 2014), and question answering (Joty et al., 2017), using a shared multi-lingual word embedding space (Smith et al., 2017) or delexicalization approaches (Zeman and Resnik, 2008; McDonald et al., 2013). One key challenge for cross-lingual transfer is the differences among languages; for example, languages may have different word orders. When transferring a model learned from a source language to target languages, the performance may drop significantly due to the differences. To tackle this problem, various approaches have been proposed to better capture the commonalities between"
D19-1103,Q18-1046,0,0.0903621,"ar types of arcs in an unsupervised setting. Naseem et al. (2010); Li et al. (2019) train a parser with constraints compiled from the frequency of particular arcs. Compared with the previous work, we focus on crosslingual transfer with word order constraints. Finally, prior studies have noticed that the word order information is significant for parsing and use it as features (Ammar et al., 2016; Naseem et al., 2012; Rasooli and Collins, 2017; Zhang and Barzilay, 2015; Dryer, 2007). T¨ackstr¨om et al. (2013) further propose to decompose these features from models for adapting target languages. Wang and Eisner (2018a) use the statistics of surface part-of-speech (POS) tags of target languages to learn the word order. Wang and Eisner (2018b) use POS tags of target languages together with a similar language, and design a stochastic permutation process to synthetic the word order. However, none of them consider using the word order features as constraints. Incorporating Constraints In NLP Tasks Constraints are widely incorporated in variety of NLP tasks. To name a few, Roth and Yih (2004) propose to formulate constrained inferences in NLP as integer linear programming problems. To solve the intractable stru"
D19-1103,D18-1163,0,0.354441,"ar types of arcs in an unsupervised setting. Naseem et al. (2010); Li et al. (2019) train a parser with constraints compiled from the frequency of particular arcs. Compared with the previous work, we focus on crosslingual transfer with word order constraints. Finally, prior studies have noticed that the word order information is significant for parsing and use it as features (Ammar et al., 2016; Naseem et al., 2012; Rasooli and Collins, 2017; Zhang and Barzilay, 2015; Dryer, 2007). T¨ackstr¨om et al. (2013) further propose to decompose these features from models for adapting target languages. Wang and Eisner (2018a) use the statistics of surface part-of-speech (POS) tags of target languages to learn the word order. Wang and Eisner (2018b) use POS tags of target languages together with a similar language, and design a stochastic permutation process to synthetic the word order. However, none of them consider using the word order features as constraints. Incorporating Constraints In NLP Tasks Constraints are widely incorporated in variety of NLP tasks. To name a few, Roth and Yih (2004) propose to formulate constrained inferences in NLP as integer linear programming problems. To solve the intractable stru"
D19-1103,P16-1218,0,0.0645363,"Missing"
D19-1103,W14-1613,0,0.0211856,"rmation from the source language(s). McDonald et al. (2011); Guo et al. (2016); T¨ackstr¨om et al. (2013); Chen et al. (2019) consider transferring a parser trained on multiple source languages. Agi´c (2017); Lin et al. (2019) selects good source languages by comparing part-of-speech tags sequences. Søgaard (2011); T¨ackstr¨om et al. (2013) chooses suitable data points from the source language. Pires et al. (2019) uses multilingual BERT to leverage language features from multiple languages. Ahmad et al. (2019) design an order-free model to take out the order features from the source language. Xiao and Guo (2014); Guo et al. (2015) learn an alignment from source words to target words. Ponti et al. (2018) learn an anisomorphism from the source parsing tree to target. Rasooli and Collins (2019) reorder the source data before training. In contrast, we focus on incorporating linguistic properties in the target languages. Constrained Inference for Parsing Several previous studies show that adding constraints in inference time improves the performance of models. Grave and Elhadad (2015) consider incorporating constraints to promote popular types of arcs in an unsupervised setting. Naseem et al. (2010); Li e"
D19-1108,P17-1020,0,0.0264693,"ma (2013); Karayev et al. (2013); Xu et al. (2013); Kusner et al. (2014); Bengio et al. (2016); Leroux et al. (2017); Zhu et al. (2019); Nan and Saligrama (2017); Bolukbasi et al. (2017) focus on gating various components of existing networks. Finally, aggregating data or models has been studied under different contexts (e.g., in context of reinforcement learning (Ross et al., 2011), Bagging models (Breiman, 1996), etc.) while we aggregate the data output from selectors instead of models. 2 3 Related Work Several approaches have been proposed to speed up the DNN in test time (Wu et al., 2017; Choi et al., 2017). LSTM-jump (Yu et al., 2017) learns to completely skip words deemed to be irrelevant and skim-RNN (Seo et al., 2018) uses a lowcomplexity LSTM to skim words rather than skipping. Another version of LSTM-jump, LSTMshuttle (Fu and Ma, 2018) first skips a number of words, then goes backward to recover lost information by reading some words skipped before. All these approaches require to modify the architecture of the underlying classifier and cannot easily extend to another architecture. In contrast, we adopt existing classifier architectures (e.g., LSTM, BCN (McCann et al., 2017)) and propose a"
D19-1108,P15-1144,0,0.0157079,"acy as DNNs leverage word combinations, sentence structure, which this approach does not account for. To mitigate this problem, we propose a data aggregation framework that augments the training corpus with outputs from selectors at different budget levels. By training the classifier on the aggregated structured blank-out text, the classifier learns to fuse fragmented sentences into a feature representation that mirrors the representation obtained on full sentences and thus realizes highaccuracy. We evaluate our approach through comprehensive experiments on real-world datasets. 1 Group Lasso (Faruqui et al., 2015), BLasso (Gao et al., 2007)). However, these approaches either cannot obtain sparse features or cannot straightforwardly be applied to speed up a DNN classifier. Different from ours, Viola and Jones (2001); Trapeznikov and Saligrama (2013); Karayev et al. (2013); Xu et al. (2013); Kusner et al. (2014); Bengio et al. (2016); Leroux et al. (2017); Zhu et al. (2019); Nan and Saligrama (2017); Bolukbasi et al. (2017) focus on gating various components of existing networks. Finally, aggregating data or models has been studied under different contexts (e.g., in context of reinforcement learning (Ros"
D19-1108,D18-1474,0,0.0152142,"s. Finally, aggregating data or models has been studied under different contexts (e.g., in context of reinforcement learning (Ross et al., 2011), Bagging models (Breiman, 1996), etc.) while we aggregate the data output from selectors instead of models. 2 3 Related Work Several approaches have been proposed to speed up the DNN in test time (Wu et al., 2017; Choi et al., 2017). LSTM-jump (Yu et al., 2017) learns to completely skip words deemed to be irrelevant and skim-RNN (Seo et al., 2018) uses a lowcomplexity LSTM to skim words rather than skipping. Another version of LSTM-jump, LSTMshuttle (Fu and Ma, 2018) first skips a number of words, then goes backward to recover lost information by reading some words skipped before. All these approaches require to modify the architecture of the underlying classifier and cannot easily extend to another architecture. In contrast, we adopt existing classifier architectures (e.g., LSTM, BCN (McCann et al., 2017)) and propose a metalearning algorithm to train the model. Our framework is generic and a classifier can be viewed as a black-box. Similar to us, Lei et al. (2016) propose a selector-classifier framework to find text snippets as justification for text cl"
D19-1108,P07-1104,0,0.035462,"nations, sentence structure, which this approach does not account for. To mitigate this problem, we propose a data aggregation framework that augments the training corpus with outputs from selectors at different budget levels. By training the classifier on the aggregated structured blank-out text, the classifier learns to fuse fragmented sentences into a feature representation that mirrors the representation obtained on full sentences and thus realizes highaccuracy. We evaluate our approach through comprehensive experiments on real-world datasets. 1 Group Lasso (Faruqui et al., 2015), BLasso (Gao et al., 2007)). However, these approaches either cannot obtain sparse features or cannot straightforwardly be applied to speed up a DNN classifier. Different from ours, Viola and Jones (2001); Trapeznikov and Saligrama (2013); Karayev et al. (2013); Xu et al. (2013); Kusner et al. (2014); Bengio et al. (2016); Leroux et al. (2017); Zhu et al. (2019); Nan and Saligrama (2017); Bolukbasi et al. (2017) focus on gating various components of existing networks. Finally, aggregating data or models has been studied under different contexts (e.g., in context of reinforcement learning (Ross et al., 2011), Bagging mo"
D19-1108,D16-1011,0,0.148223,"plexity LSTM to skim words rather than skipping. Another version of LSTM-jump, LSTMshuttle (Fu and Ma, 2018) first skips a number of words, then goes backward to recover lost information by reading some words skipped before. All these approaches require to modify the architecture of the underlying classifier and cannot easily extend to another architecture. In contrast, we adopt existing classifier architectures (e.g., LSTM, BCN (McCann et al., 2017)) and propose a metalearning algorithm to train the model. Our framework is generic and a classifier can be viewed as a black-box. Similar to us, Lei et al. (2016) propose a selector-classifier framework to find text snippets as justification for text classification but their selector and classifier have similar complexity and require similar processing times; therefore, it is not suitable for computation gain. Various feature selection approaches (Chandrashekar and Sahin, 2014) have been discussed in literature. For example, removing predefined stop-words (see Appendix A), attention based models (Bahdanau et al., 2015; Luong et al., 2015), feature subspace selection methods (e.g., PCA), and applying the L1 regularization (e.g., Lasso (Tibshirani, 1996)"
D19-1108,D15-1166,0,0.0179342,"algorithm to train the model. Our framework is generic and a classifier can be viewed as a black-box. Similar to us, Lei et al. (2016) propose a selector-classifier framework to find text snippets as justification for text classification but their selector and classifier have similar complexity and require similar processing times; therefore, it is not suitable for computation gain. Various feature selection approaches (Chandrashekar and Sahin, 2014) have been discussed in literature. For example, removing predefined stop-words (see Appendix A), attention based models (Bahdanau et al., 2015; Luong et al., 2015), feature subspace selection methods (e.g., PCA), and applying the L1 regularization (e.g., Lasso (Tibshirani, 1996) or 1 Our source code is available at: https://github.com/uclanlp/ Fast-and-Robust-Text-Classification Classification on a Test-Time Budget Our goal is to build a robust classifier along with a suite of selectors to achieve good performance with consistent speedup under different selection budgets at test-time. Formally, a classifier C(ˆ x) takes a word sequence x ˆ and predicts the corresponding output label y, and a selector Sb (x) with selection budget b takes an input word se"
D19-1108,P11-1015,0,0.044978,"Missing"
D19-1108,D13-1170,0,0.00599058,"Missing"
D19-1108,P17-1172,0,0.0703365,"rom different selectors and train the classifier on the aggregated corpus. Introduction Recent advances in deep neural networks (DNNs) have achieved high accuracy on many text classification tasks. These approaches process the entire text and encode words and phrases in order to perform target tasks. While these models realize high accuracy, the computational time scales linearly with the size of the documents, which can be slow for a long document. In this context, various approaches based on modifying the RNN or LSTM architecture have been proposed to speed up the process (Seo et al., 2018; Yu et al., 2017). However, the processing in these models is still fundamentally sequential and needs to operate on the whole document which limits the computational gain. In contrast to previous approaches, we propose a novel framework for efficient text classification on long documents that mitigates sequential processing. The framework consists of a selector and a classifier. Given a selection budget as input, the selector performs a coarse one-shot selection deleting unimportant words and pass the remainder to the classifier. The classifier then takes the sentence fragments as an input and performs the ta"
D19-1108,D14-1162,0,0.0820434,"erated after filtering by the selector as  I x, Sb (x) = {wk : zwk = 1, ∀wk ∈ x}. We aim to train a classifier C and the selector Sb such that  I x, Sb (x) is sufficient to make accurate predic tion on the output label (i.e., C I x, Sb (x) ≈ C(x)). The selection budget (a.k.a selection rate) b is controlled by the hyper-parameters of the selector. Higher budget often leads to higher accuracy and longer test time. 3.1 Learning a Selector We propose two simple but efficient selectors. Word Embedding (WE) selector. We consider a parsimonious word-selector using word embeddings (e.g., GloVe (Pennington et al., 2014)) as features to predict important words. We assume the informative words can be identified independently and model the probability that a word wk is selected by P (zwk = 1|wk ) = σ(θST w ~ k ), where θS is the model parameters of the selector Sb , w ~k is the corresponding word vector, and σ is the sigmoid function. As we do not have explicit anno1168 tations about which words are important, we train the selector Sb along with a classifier C in an endto-end manner following Lei et al. (2016), and an L1-regularizer is added to control the sparsity (i.e., selection budget) of Sb (x). Bag-of-Wor"
D19-1113,S15-2045,0,0.0638872,"Missing"
D19-1113,S16-1081,0,0.118624,"Missing"
D19-1113,S17-2001,0,0.0675616,"Missing"
D19-1113,L18-1269,0,0.0248987,"terminating condition, we train a Multi-Layer Perceptron (MLP) classifier on the same paraphrase training set and terminate training based on the paraphrase identification performance on a set of held-out paraphrases. The sentence in the dataset is represented by the average of the word embeddings. λ is selected from {0.1, 0.5, 1, 2} and γ from {1, 2, 3, 4} based on validation set. The best margin γ and epochs ζ by early stopping are {γ = 3, ζ = 20} on MRPC, {γ = 2, ζ = 14} on PAN, and {γ = 3, ζ = 10} on Sampled Quora, with λ = 1 in all settings. 4.2 Evaluation We use the SentEval framework (Conneau and Kiela, 2018) to evaluate the sentence embeddings on a wide range of sentence-level tasks. We consider two baselines models: (1) ELMo (all layers) constructs a 3,074-dimensional sentence embedding by averaging the hidden states of all the language model layers. (2) ELMo (top layers) encodes a sentence to a 1,024 dimensional vector by averaging the representations of the top layer. We compare these baselines with four variants of PAR built upon ELMo (all layers) that trained on different paraphrase corpora. 4.3 Task Descriptions Sentence classification tasks. We evaluate the sentence embedding on four sente"
D19-1113,N19-1423,0,0.208884,"Related Work Contextualized word embedding models have been studied by a series of recent research efforts, where different types of pre-trained language models are employed to capture the context information. CoVe (McCann et al., 2017) trains a neural machine translation model and extracts representations of input sentences from the source language encoder. ELMo (Peters et al., 2018) pretrains LSTM-based language models from both directions and combines the vectors to construct contextualized word representations. Recent studies substitute LSTMs with Transformers (Radford et al., 2018, 2019; Devlin et al., 2019). As shown in these studies, contextualized word embeddings perform well on downstream tasks at the cost of extensive parameter complexity and the long training process on large corpora (Strubell et al., 2019). Retrofitting methods have been used to incorporate semantic knowledge from external resources into word embeddings (Faruqui et al., 2015; Yu et al., 2016; Glavaˇs and Vuli´c, 2018). These techniques are shown to improve the characterization of word relatedness and the compositionality of word representations. To the best of our knowledge, none of the previous approaches has been applied"
D19-1113,D17-1215,0,0.0676407,"Missing"
D19-1113,N12-1019,0,0.0250453,"In our experiment, we apply PAR on ELMo (Peters et al., 2018) and evaluate the quality of the retrofitted ELMo on a broad range of sentence-level tasks and the adversarial SQuAD corpus. 4.1 Experimental Configuration We use the officially released 3-layer ELMo (original), which is trained on the 1 Billion Word Benchmark with 93.6 million parameters. We retrofit ELMo with PAR on the training sets of three paraphrase datasets: (i) MRPC contains 2,753 paraphrase pairs; (ii) Sampled Quora contains randomly sampled 20,000 paraphrased question pairs (Iyer et al., 2017); and (iii) PAN training set (Madnani et al., 2012) contains 5,000 paraphrase pairs. The orthogonal transformation M is initialized as an identity matrix. In our preliminary experiments, we observed that SGD optimizer is more stable and less likely to quickly overfit the training set than other optimizers with adaptive learning rates (Reddi et al., 2018; Kingma and Ba, 2015). Therefore, we use SGD with the learning rate of 0.005 and a batch size of 128. To determine the terminating condition, we train a Multi-Layer Perceptron (MLP) classifier on the same paraphrase training set and terminate training based on the paraphrase identification perf"
D19-1113,S14-2001,0,0.022823,"tion tasks. We evaluate the sentence embedding on four sentence classification tasks including two sentiment analysis (MR (Pang and Lee, 2004), SST-2 (Socher et al., 2013)), product reviews (CR (Hu and Liu, 2004)), and opinion polarity (MPQA (Wiebe et al., 2005)). These tasks are all binary classification tasks. We employ a MLP with a single hidden layer of 50 neurons to train the classifer, using a batch size of 64 and Adam optimizer. Sentence inference tasks We consider two sentence inference tasks: paraphrase identification on MRPC (Dolan et al., 2004) and the textual entailment on SICK-E (Marelli et al., 2014). MRPC consists of pairs of sentences, where the model aims to classify if two sentences are semantically equivalent. The SICK dataset contains 10,000 English sentence pairs annotated for relatedness in meaning and entailment. The aim of SICK-E is to detect discourse relations of entailment, contradiction and neutral between the two sentences. Similar to the sentence classification tasks, we apply a MLP with the same hyperparameters to conduct the classification. Semantic textual similarity tasks. Semantic Textual Similarity (STS-15 (Agirre et al., 2015) and STS-16 (Agirre et al., 2016)) measu"
D19-1113,P04-1035,0,0.0244871,"e-level tasks. We consider two baselines models: (1) ELMo (all layers) constructs a 3,074-dimensional sentence embedding by averaging the hidden states of all the language model layers. (2) ELMo (top layers) encodes a sentence to a 1,024 dimensional vector by averaging the representations of the top layer. We compare these baselines with four variants of PAR built upon ELMo (all layers) that trained on different paraphrase corpora. 4.3 Task Descriptions Sentence classification tasks. We evaluate the sentence embedding on four sentence classification tasks including two sentiment analysis (MR (Pang and Lee, 2004), SST-2 (Socher et al., 2013)), product reviews (CR (Hu and Liu, 2004)), and opinion polarity (MPQA (Wiebe et al., 2005)). These tasks are all binary classification tasks. We employ a MLP with a single hidden layer of 50 neurons to train the classifer, using a batch size of 64 and Adam optimizer. Sentence inference tasks We consider two sentence inference tasks: paraphrase identification on MRPC (Dolan et al., 2004) and the textual entailment on SICK-E (Marelli et al., 2014). MRPC consists of pairs of sentences, where the model aims to classify if two sentences are semantically equivalent. The"
D19-1113,P17-1161,0,0.0665672,"Missing"
D19-1113,N18-1202,0,0.739456,"tion layer to a contextualized embedding model. Without retraining the parameters of an existing model, PAR learns the transformation to minimize the differ1198 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 1198–1203, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics ence of the contextualized representations of the shared word in paraphrased contexts, while differentiating between those in other contexts. We apply PAR to retrofit ELMo (Peters et al., 2018) and show that the resulted embeddings provide more robust contextualized word representations as desired, which further lead to significant improvements on various sentence classification and inference tasks. 2 &apos; Paraphrase-Aware Retrofitting Contextualized Word Embeddings We use S = (w1 , w2 , · · · , wl ) to denote a sequence of words of length l, where each word w belongs to the vocabulary V . We use boldfaced w ∈ Rk to denote a k-dimensional input word embedding, which can be pre-trained or derived from a character-level encoder (e.g., the character-level ♦ Input Representations S1/------"
D19-1113,D16-1264,0,0.0410979,"asks. We do not report results of ELMo-PAR on MRPC when MRPC is used in training the model. The baseline results are from (Perone et al., 2018). AddOneSent AddSent EM F1 EM F1 BiSAE 47.7 53.7 36.1 41.7 BiSAE-PAR(MRPC) 51.6 57.9 40.8 47.1 Model Table 3: Exact Match and F1 on Adversarial SQuAD. semantic scores between 0 and 5. The goal of the tasks is to measure the degree of semantic relatedness between two sentences. We learn treestructured LSTM (Tai et al., 2015) to predict the probability distribution of relatedness scores. Adversarial SQuAD The Stanford Question Answering Datasets (SQuAD) (Rajpurkar et al., 2016) is a machine comprehension dataset containing 107,785 human-generated reading comprehension questions annotated on Wikipedia articles. Adversarial SQuAD (Jia and Liang, 2017) appends adversarial sentences to the passage in the SQuAD dataset to study the robustness of the model. We conduct evaluations on two Adversarial SQuAD datasets: AddOneSent which adds a random human-approved sentence, and AddSent which adds grammatical sentences that look similar to the question. We train the Bi-Directional Attention Flow (BiDAF) network (Seo et al., 2017) with self-attention and ELMo embeddings on the S"
D19-1113,N16-1091,0,0.051337,"Missing"
D19-1113,D13-1170,0,0.00621952,"wo baselines models: (1) ELMo (all layers) constructs a 3,074-dimensional sentence embedding by averaging the hidden states of all the language model layers. (2) ELMo (top layers) encodes a sentence to a 1,024 dimensional vector by averaging the representations of the top layer. We compare these baselines with four variants of PAR built upon ELMo (all layers) that trained on different paraphrase corpora. 4.3 Task Descriptions Sentence classification tasks. We evaluate the sentence embedding on four sentence classification tasks including two sentiment analysis (MR (Pang and Lee, 2004), SST-2 (Socher et al., 2013)), product reviews (CR (Hu and Liu, 2004)), and opinion polarity (MPQA (Wiebe et al., 2005)). These tasks are all binary classification tasks. We employ a MLP with a single hidden layer of 50 neurons to train the classifer, using a batch size of 64 and Adam optimizer. Sentence inference tasks We consider two sentence inference tasks: paraphrase identification on MRPC (Dolan et al., 2004) and the textual entailment on SICK-E (Marelli et al., 2014). MRPC consists of pairs of sentences, where the model aims to classify if two sentences are semantically equivalent. The SICK dataset contains 10,000"
D19-1113,P19-1355,0,0.0197636,"n. CoVe (McCann et al., 2017) trains a neural machine translation model and extracts representations of input sentences from the source language encoder. ELMo (Peters et al., 2018) pretrains LSTM-based language models from both directions and combines the vectors to construct contextualized word representations. Recent studies substitute LSTMs with Transformers (Radford et al., 2018, 2019; Devlin et al., 2019). As shown in these studies, contextualized word embeddings perform well on downstream tasks at the cost of extensive parameter complexity and the long training process on large corpora (Strubell et al., 2019). Retrofitting methods have been used to incorporate semantic knowledge from external resources into word embeddings (Faruqui et al., 2015; Yu et al., 2016; Glavaˇs and Vuli´c, 2018). These techniques are shown to improve the characterization of word relatedness and the compositionality of word representations. To the best of our knowledge, none of the previous approaches has been applied in contextualized word embeddings. 3 Contextualized Embedding Model s -------,s 2 2 I hav,; life insurance. How_ is life in priso�? ;-;.;;;i;�&quot;&quot;e, , &apos; noii-pi;api;;�e Figure 1: Learning framework of PAR CNN u"
D19-1113,P15-1150,0,0.0533655,"mance on downstream applications. We report accuracy for classification and inference tasks, and Pearson correlation for relatedness and similarity tasks. We do not report results of ELMo-PAR on MRPC when MRPC is used in training the model. The baseline results are from (Perone et al., 2018). AddOneSent AddSent EM F1 EM F1 BiSAE 47.7 53.7 36.1 41.7 BiSAE-PAR(MRPC) 51.6 57.9 40.8 47.1 Model Table 3: Exact Match and F1 on Adversarial SQuAD. semantic scores between 0 and 5. The goal of the tasks is to measure the degree of semantic relatedness between two sentences. We learn treestructured LSTM (Tai et al., 2015) to predict the probability distribution of relatedness scores. Adversarial SQuAD The Stanford Question Answering Datasets (SQuAD) (Rajpurkar et al., 2016) is a machine comprehension dataset containing 107,785 human-generated reading comprehension questions annotated on Wikipedia articles. Adversarial SQuAD (Jia and Liang, 2017) appends adversarial sentences to the passage in the SQuAD dataset to study the robustness of the model. We conduct evaluations on two Adversarial SQuAD datasets: AddOneSent which adds a random human-approved sentence, and AddSent which adds grammatical sentences that l"
D19-1113,W16-6106,0,0.0262902,"ters et al., 2018) pretrains LSTM-based language models from both directions and combines the vectors to construct contextualized word representations. Recent studies substitute LSTMs with Transformers (Radford et al., 2018, 2019; Devlin et al., 2019). As shown in these studies, contextualized word embeddings perform well on downstream tasks at the cost of extensive parameter complexity and the long training process on large corpora (Strubell et al., 2019). Retrofitting methods have been used to incorporate semantic knowledge from external resources into word embeddings (Faruqui et al., 2015; Yu et al., 2016; Glavaˇs and Vuli´c, 2018). These techniques are shown to improve the characterization of word relatedness and the compositionality of word representations. To the best of our knowledge, none of the previous approaches has been applied in contextualized word embeddings. 3 Contextualized Embedding Model s -------,s 2 2 I hav,; life insurance. How_ is life in priso�? ;-;.;;;i;�&quot;&quot;e, , &apos; noii-pi;api;;�e Figure 1: Learning framework of PAR CNN used in ELMo (Peters et al., 2018)). A contextualized embedding model E takes input vectors of the words in S, and computes the contextspecific representati"
D19-1339,N18-2003,1,0.848017,"contexts Biases can occur in different textual contexts, some biases manifesting more subtly than others. In this work, we analyze biases that occur in two contexts: those that deal with descriptive levels of respect towards a demographic and those that deal with the different occupations of a demographic. The first four examples in Table 1 are generated text with occupation contexts, and the latter two are generated text with respect contexts. We analyze these two bias contexts because the occupation context has been well-studied in other tasks (Bolukbasi et al., 2016; Rudinger et al., 2018; Zhao et al., 2018; Zhou et al., 2019), and the more descriptive language in respect contexts are a good contrast for the more subtle occupation contexts. For each context, we analyze generated sentences that have been conditioned on content relating to the bias context. Demographics In the process of examining biases in language generation, we need to compare the magnitude of biases across different demographics. Here, we use the term “demographic” to refer to a group of people with the same gender, race, or sexual orientation. Specifically, we examine the groups female and male for gender, Black and White for"
D19-1339,D19-1531,1,0.820085,"occur in different textual contexts, some biases manifesting more subtly than others. In this work, we analyze biases that occur in two contexts: those that deal with descriptive levels of respect towards a demographic and those that deal with the different occupations of a demographic. The first four examples in Table 1 are generated text with occupation contexts, and the latter two are generated text with respect contexts. We analyze these two bias contexts because the occupation context has been well-studied in other tasks (Bolukbasi et al., 2016; Rudinger et al., 2018; Zhao et al., 2018; Zhou et al., 2019), and the more descriptive language in respect contexts are a good contrast for the more subtle occupation contexts. For each context, we analyze generated sentences that have been conditioned on content relating to the bias context. Demographics In the process of examining biases in language generation, we need to compare the magnitude of biases across different demographics. Here, we use the term “demographic” to refer to a group of people with the same gender, race, or sexual orientation. Specifically, we examine the groups female and male for gender, Black and White for race, and gay and s"
D19-1339,S18-2005,0,0.193017,"Missing"
D19-1339,P09-5002,0,0.0110727,"y to find his own voice and to speak clearly. Table 1: Examples of text continuations generated from OpenAI’s medium-sized GPT-2 model, given different prompts Introduction Recent works in machine translation (Prates et al., 2018) and dialogue systems (Henderson et al., 2018) have brought to attention the perpetuation of biases in natural language generation (NLG) systems. In this work, we present a systematic study of biases in open-domain NLG by examining language models. Language models are a fundamental component of NLG that are widely used in downstream tasks such as machine translation (Koehn, 2009), dialogue generation (Serban et al., 2016), and story generation (Yao et al., 2019); as such, biases propagated through the language models will have a profound impact on a variety of other NLG tasks. More generally, NLG systems are at the forefront of developments in humancomputer interaction, and systematic biases in language models have a direct impact on society and broader AI applications. A text is positively or negatively inclined towards a demographic if the text causes the specific demographic to be positively or negatively perceived. When NLP models systematically produce text with"
D19-1339,W16-0429,0,0.0302826,"t in text, we manually construct five placeholder prefix templates for each bias context (Table 2), where the demographic mention in all templates is the placeholder XYZ.4 For each &lt;bias context placeholder prefix template, demographic&gt; pair, we fill in the template with the appropriate demographic (“XYZ worked as” becomes “The woman worked as”), forming complete prefix templates to prompt language generation. Annotation task To select text for annotation, we sample equally from text generated from the different prefix templates. The sentiment and regard annotation guidelines are adapted from Mohammad (2016)’s sentiment annotation guidelines. There are six categories each for sentiment and regard, and both metrics have positive, negative, and neutral categories.5 1. For each &lt;bias context placeholder prefix template, demographic&gt; pair, we generate a complete prefix template, for a total of 60 unique templates. We then use GPT-2 to generate 100 samples per complete prefix template. 2. Each generated sample is truncated so that at most one sentence is in the sample. 3. We use VADER to predict a sentiment score for each generated sample, and for each prefix template, we randomly choose three posgard"
D19-1339,N18-2002,0,0.157462,"Missing"
D19-1496,N18-1170,0,0.18667,"fense against adversarial attacks (Yuan et al., 2019). In the field of NLP, most of the existing studies focus on the former. For example, Ebrahimi et al. (2017); Alzantot et al. (2018) replace a word with synonyms or similar words while Gao et al. (2018); Liang et al. (2017); Ebrahimi et al. (2017) conduct characterlevel manipulations to fool the models. Moreover, it is not straightforward to adapt existing approaches for blocking adversarial attacks, such as data augmentation (Krizhevsky et al., 2012; Ribeiro et al., 2018; Ren et al., 2019) and adversarial training (Goodfellow et al., 2015; Iyyer et al., 2018; Marzinotto et al., 2019; Cheng et al., 2019; Zhu et al., 2019), to NLP applications. Hence, the defense against adversarial attacks in NLP remains a challenging and unsolved problem. Recognizing and removing the inconspicuous perturbations are the core of defense against adversarial attacks. For instance, in computer vision, denoising auto-encoders (Warde-Farley and Bengio, 2017; Gu and Rigazio, 2015) are applied to remove the noises introduced by perturbations; Prakash et al. (2018) manipulate the images to make the trained models more robust to the perturbations; Samangouei et al. (2018) a"
D19-1496,D18-1316,1,0.934519,"ls by adding a few inconspicuous perturbations into input data, such as masking images with unrecognizable filters and making low-key modifications for texts. Therefore, developing techniques to equip models against adversarial attacks becomes a prominent research problem. ∗ Equal contribution. Listing order is random. Existing studies on adversarial attacks can be classified into two groups, generation of adversarial examples and defense against adversarial attacks (Yuan et al., 2019). In the field of NLP, most of the existing studies focus on the former. For example, Ebrahimi et al. (2017); Alzantot et al. (2018) replace a word with synonyms or similar words while Gao et al. (2018); Liang et al. (2017); Ebrahimi et al. (2017) conduct characterlevel manipulations to fool the models. Moreover, it is not straightforward to adapt existing approaches for blocking adversarial attacks, such as data augmentation (Krizhevsky et al., 2012; Ribeiro et al., 2018; Ren et al., 2019) and adversarial training (Goodfellow et al., 2015; Iyyer et al., 2018; Marzinotto et al., 2019; Cheng et al., 2019; Zhu et al., 2019), to NLP applications. Hence, the defense against adversarial attacks in NLP remains a challenging and"
D19-1496,P11-1015,0,0.0640328,"rm moviemaking at its beast. Old-form moviemaking at its be s t. Old-form moviemaking at its bets. Old-form moviemaking at its aggrandize. Old-form moviemaking at its way. Table 2: Examples of each type of attack ber of embeddings in the embedding corpus C. 4 Experiments In this section, we conduct extensive experiments to evaluate the performance of DISP in improving model robustness. 4.1 Experimental Settings Experimental Datasets. Experiments are conducted on two benchmark datasets: (1) Stanford Sentiment Treebank Binary (SST-2) (Socher et al., 2013) and (2) Internet Movie Database (IMDb) (Maas et al., 2011). SST-2 and IMDb are both sentiment classification datasets which involve binary labels annotating sentiment of sentences in movie reviews. Detailed statistics of two datasets are listed in Table 1. Attack Generation. We consider three types of character-level attacks and two types of word-level attacks. The character-level attacks consist of insertion, deletion, and swap. Insertion and deletion attacks inject and remove a character, respectively, while a swap attack flips two adjacent characters. The word-level attacks include random and embed. A random attack randomly samples a word to repla"
D19-1496,N19-2021,0,0.0648996,"Missing"
D19-1496,L18-1008,0,0.0871069,"Missing"
D19-1496,P19-1103,0,0.0758892,"classified into two groups, generation of adversarial examples and defense against adversarial attacks (Yuan et al., 2019). In the field of NLP, most of the existing studies focus on the former. For example, Ebrahimi et al. (2017); Alzantot et al. (2018) replace a word with synonyms or similar words while Gao et al. (2018); Liang et al. (2017); Ebrahimi et al. (2017) conduct characterlevel manipulations to fool the models. Moreover, it is not straightforward to adapt existing approaches for blocking adversarial attacks, such as data augmentation (Krizhevsky et al., 2012; Ribeiro et al., 2018; Ren et al., 2019) and adversarial training (Goodfellow et al., 2015; Iyyer et al., 2018; Marzinotto et al., 2019; Cheng et al., 2019; Zhu et al., 2019), to NLP applications. Hence, the defense against adversarial attacks in NLP remains a challenging and unsolved problem. Recognizing and removing the inconspicuous perturbations are the core of defense against adversarial attacks. For instance, in computer vision, denoising auto-encoders (Warde-Farley and Bengio, 2017; Gu and Rigazio, 2015) are applied to remove the noises introduced by perturbations; Prakash et al. (2018) manipulate the images to make the train"
D19-1496,P18-1079,0,0.0978005,"sarial attacks can be classified into two groups, generation of adversarial examples and defense against adversarial attacks (Yuan et al., 2019). In the field of NLP, most of the existing studies focus on the former. For example, Ebrahimi et al. (2017); Alzantot et al. (2018) replace a word with synonyms or similar words while Gao et al. (2018); Liang et al. (2017); Ebrahimi et al. (2017) conduct characterlevel manipulations to fool the models. Moreover, it is not straightforward to adapt existing approaches for blocking adversarial attacks, such as data augmentation (Krizhevsky et al., 2012; Ribeiro et al., 2018; Ren et al., 2019) and adversarial training (Goodfellow et al., 2015; Iyyer et al., 2018; Marzinotto et al., 2019; Cheng et al., 2019; Zhu et al., 2019), to NLP applications. Hence, the defense against adversarial attacks in NLP remains a challenging and unsolved problem. Recognizing and removing the inconspicuous perturbations are the core of defense against adversarial attacks. For instance, in computer vision, denoising auto-encoders (Warde-Farley and Bengio, 2017; Gu and Rigazio, 2015) are applied to remove the noises introduced by perturbations; Prakash et al. (2018) manipulate the image"
D19-1496,I17-2062,0,0.110183,"Missing"
D19-1496,D13-1170,0,0.00747921,"n is the numExample Old-form moviemaking at its best. Old-form moviemaking at its beast. Old-form moviemaking at its be s t. Old-form moviemaking at its bets. Old-form moviemaking at its aggrandize. Old-form moviemaking at its way. Table 2: Examples of each type of attack ber of embeddings in the embedding corpus C. 4 Experiments In this section, we conduct extensive experiments to evaluate the performance of DISP in improving model robustness. 4.1 Experimental Settings Experimental Datasets. Experiments are conducted on two benchmark datasets: (1) Stanford Sentiment Treebank Binary (SST-2) (Socher et al., 2013) and (2) Internet Movie Database (IMDb) (Maas et al., 2011). SST-2 and IMDb are both sentiment classification datasets which involve binary labels annotating sentiment of sentences in movie reviews. Detailed statistics of two datasets are listed in Table 1. Attack Generation. We consider three types of character-level attacks and two types of word-level attacks. The character-level attacks consist of insertion, deletion, and swap. Insertion and deletion attacks inject and remove a character, respectively, while a swap attack flips two adjacent characters. The word-level attacks include random"
D19-1496,P19-1366,0,0.141784,"ld of NLP, most of the existing studies focus on the former. For example, Ebrahimi et al. (2017); Alzantot et al. (2018) replace a word with synonyms or similar words while Gao et al. (2018); Liang et al. (2017); Ebrahimi et al. (2017) conduct characterlevel manipulations to fool the models. Moreover, it is not straightforward to adapt existing approaches for blocking adversarial attacks, such as data augmentation (Krizhevsky et al., 2012; Ribeiro et al., 2018; Ren et al., 2019) and adversarial training (Goodfellow et al., 2015; Iyyer et al., 2018; Marzinotto et al., 2019; Cheng et al., 2019; Zhu et al., 2019), to NLP applications. Hence, the defense against adversarial attacks in NLP remains a challenging and unsolved problem. Recognizing and removing the inconspicuous perturbations are the core of defense against adversarial attacks. For instance, in computer vision, denoising auto-encoders (Warde-Farley and Bengio, 2017; Gu and Rigazio, 2015) are applied to remove the noises introduced by perturbations; Prakash et al. (2018) manipulate the images to make the trained models more robust to the perturbations; Samangouei et al. (2018) apply generative adversarial networks to generate perturbation-fr"
D19-1496,D09-1129,0,\N,Missing
D19-1496,P18-2006,0,\N,Missing
D19-1496,N19-1336,0,\N,Missing
D19-1531,W19-3805,0,0.0528656,"Missing"
D19-1531,Q17-1010,0,0.0597394,"rections are overlapped to some extent but not identical. This is reasonable because words such as “mujer (woman)”, “doctor (female doctor)” are both semantically and grammatically marked as feminine. To better distinguish between these two directions, we project out the grammatical gender component in the computed gender direction to make the semantic gender direction d~s orthogonal to the grammatical gender direction: 5277 D E d~s = d~P CA − d~P CA , d~g d~g , Visualizing and Analyzing Bias in Spanish We take Spanish as an example and analyze gender bias in Spanish fastText word embeddings (Bojanowski et al., 2017) pre-trained on Spanish Wikipedia. For simplicity, we assume that the embeddings contain all gender forms of the words. To show bias, we randomly select several pairs of gender-definition and occupation words as well as inanimate nouns in Spanish and visualize them on the two gender directions defined above. Figure 1 shows that the inanimate nouns lie near the origin point on the semantic gender direction, while the masculine and feminine forms of the occupation words are on the opposite sides for both directions. However, while projections of occupation words on the grammatical gender directi"
D19-1531,N19-3002,0,0.0797182,"Missing"
D19-1531,S17-2002,0,0.0316142,"iginal Spanish and French embeddings exhibit strong bias and Hybrid Ori significantly reduces the bias in the embedding to to an insignificant level (p-value &gt; 0.05). male and female attribute words for our WEAT experiments and translate them to Spanish and French. For the word pair translation task, we use 7 common adjectives and pair every adjective with each occupation, resulting in 406 pairs for Spanish and 161 for French. 4.2 architect* arquitecta lawyer* abogada enfermera 0.2 Word Similarity We test the quality of the embeddings after mitigation on the SemEval 2017 word similarity task (Camacho-Collados et al., 2017) for monolingual embeddings. This task evaluates how well the cosine similarity between two words correlates with a human-labeled score for which we report the Pearson correlation score. Results Table 1 shows that Hybrid Ori significantly decreases the difference of association between two genders as indicated by MWEAT–Diff and p-value. Other methods only show marginal doctor nurse* 0.1 enfermero 0.0 0.1 Semantic Gender Direction 0.2 0.3 Figure 3: Projections of occupations words on the semantic gender direction after hybrid mitigation with origin as the anchor point. The two forms of occupati"
D19-1531,P19-1166,0,0.0757875,"natural language processing tools. By virtue of their being trained on large, human-written corpora, recent studies have shown that word embeddings, in addition to capturing a word’s semantics, also encode gender bias in society (Bolukbasi et al., 2016; Caliskan et al., 2017). As a result of this bias, the embeddings may cause undesired consequences in the resulting models (Zhao et al., 2018a; Font and Costa-juss`a, 2019). Therefore, extensive effort has been put toward analyzing and mitigating gender bias in word embeddings (Bolukbasi et al., 2016; Zhao et al., 2018b; Dev and Phillips, 2019; Ethayarajh et al., 2019). Existing studies on gender bias almost exclusively focus on English (EN) word embeddings. Unfortunately, the techniques used to mitigate bias in English word embeddings cannot be directly applied to languages with grammatical gender1 , where all nouns are assigned a gender class and the corresponding dependent articles, adjectives, and verbs must agree in gender with the noun (e.g. in Spanish: la buena enfermera the good female nurse, el buen enfermero the good male nurse) (Corbett, 1991, 2006). This is because most existing approaches define bias in word embeddings based on the projection o"
D19-1531,W19-3821,0,0.0439998,"Missing"
D19-1531,N18-2002,0,0.130865,"Missing"
D19-1531,D18-1521,1,0.825445,"ord translation, and word pair translation tasks show that the proposed approaches effectively reduce the gender bias while preserving the utility of the embeddings. 1 Introduction Word embeddings are widely used in modern natural language processing tools. By virtue of their being trained on large, human-written corpora, recent studies have shown that word embeddings, in addition to capturing a word’s semantics, also encode gender bias in society (Bolukbasi et al., 2016; Caliskan et al., 2017). As a result of this bias, the embeddings may cause undesired consequences in the resulting models (Zhao et al., 2018a; Font and Costa-juss`a, 2019). Therefore, extensive effort has been put toward analyzing and mitigating gender bias in word embeddings (Bolukbasi et al., 2016; Zhao et al., 2018b; Dev and Phillips, 2019; Ethayarajh et al., 2019). Existing studies on gender bias almost exclusively focus on English (EN) word embeddings. Unfortunately, the techniques used to mitigate bias in English word embeddings cannot be directly applied to languages with grammatical gender1 , where all nouns are assigned a gender class and the corresponding dependent articles, adjectives, and verbs must agree in gender wit"
D19-3042,D17-1018,0,0.0237025,"mp) and Verb (e.g., liked), appear together in a news sentence in the corpus. The edge label reflects the total number of semantic role combination in the given dataset, which depicts the importance of a news action. Forest Graph for Semantic Roles In news articles, President Trump have different references, such as Donald Trump, the president of the United States, and pronoun “he” – a well-known task, called coreference resolution. When generating semantic trees, the system should not look only for Trump but also other references. To realize this, we preprocess the dataset with CoRef system (Lee et al., 2017) in AllenNLP (Gardner et al., 2018) and generate local coreference clusters for each news article. To obtain a global view, we merge the clusters across documents together until none of them shares a common role. A visualization demo for CoRef is also provided. In Figure 3, the CoRef system clusters “the Philladelphia Eagles” with “the Eagles”, and “Hilary” with “Hilary Clinton”. The red nodes are center roles, which are representative phrases. For example, “the Philladelphia Eagles” and “Hilary Clinton” are the center roles of their corresponding cluster. We use the following three rules to d"
D19-3042,D14-1162,0,0.0928655,"Missing"
D19-3042,W18-2501,0,0.0234211,"Missing"
D19-3042,P16-1141,0,0.0337062,"can recognize the difference between “resign” and “might resign”. We also add negation as an extra sentiment information. Verbs have different forms and tenses (e.g., win, won, winning). If we merge all verbs with the same root form, we can obtain a larger clusters and reduce duplicated trees. However, for some analysis, the tense of verbs are important. Therefore, we provide Lemmatizating as an option in our system. Figure 3: Coreference Resolution Clusters. 3.2 Dynamic Word Embeddings Dynamic word embeddings model align word embeddings trained on corpora collected in different time periods (Hamilton et al., 2016). It divides data into time slices and obtains the word vector representations of each time slice separately. To capture how the trends in news change monthly, we train a word2vec word embedding model on news articles collected in each month. We then apply the orthogonal Procrustes to align the embeddings from different time periods by learning a transformation R(t) ∈ Rd×d : tied, the one with longest length will be selected: LongestSpan method selects the role with longest length. WordNet method marks spans not in the WordNet (Miller, 1998) as specific roles. NameEntity method marks roles in"
D19-3042,P17-1044,0,0.0496097,"Missing"
I17-2009,W01-0100,0,0.207909,"and ultimately learn models that differ from those that were deployed to collect the data, so we can deploy a single model and improve it based on the data collected (Swaminathan and Joachims, 2015). Intuitively, if we deploy a model h0 and observe what actions it takes and what feedback it gets, we could improve the model by making it more likely to suggest the phrases that got good feedback. Suppose we deploy a reference model4 h0 and log a dataset Related Work Language models have a long history and play an important role in many NLP applications (Sordoni et al., 2015; Rambow et al., 2001; Mani, 2001; Johnson et al., 2016). However, these models do not model human preferences from interactions. Existing deployed keyboards use n-gram language models (Quinn and Zhai, 2016; Kneser and Ney, 1995), or sometimes neural language models (Kim et al., 2016), trained to predict the next word given recent context. Recent advances in language modeling have increased the accuracy of these predictions by using additional context (Mikolov and Zweig, 2012). But as argued in Arnold et al. (2016), these increases in accuracy do not necessarily translate into better suggestions. The difference between sugges"
I17-2009,P13-2121,0,0.0449745,"Missing"
I17-2009,H01-1055,0,0.0280664,"llows us to evaluate and ultimately learn models that differ from those that were deployed to collect the data, so we can deploy a single model and improve it based on the data collected (Swaminathan and Joachims, 2015). Intuitively, if we deploy a model h0 and observe what actions it takes and what feedback it gets, we could improve the model by making it more likely to suggest the phrases that got good feedback. Suppose we deploy a reference model4 h0 and log a dataset Related Work Language models have a long history and play an important role in many NLP applications (Sordoni et al., 2015; Rambow et al., 2001; Mani, 2001; Johnson et al., 2016). However, these models do not model human preferences from interactions. Existing deployed keyboards use n-gram language models (Quinn and Zhai, 2016; Kneser and Ney, 1995), or sometimes neural language models (Kim et al., 2016), trained to predict the next word given recent context. Recent advances in language modeling have increased the accuracy of these predictions by using additional context (Mikolov and Zweig, 2012). But as argued in Arnold et al. (2016), these increases in accuracy do not necessarily translate into better suggestions. The difference be"
I17-2009,Q17-1024,0,0.0666777,"Missing"
I17-2009,N15-1020,0,0.0867472,"nterfactual learning allows us to evaluate and ultimately learn models that differ from those that were deployed to collect the data, so we can deploy a single model and improve it based on the data collected (Swaminathan and Joachims, 2015). Intuitively, if we deploy a model h0 and observe what actions it takes and what feedback it gets, we could improve the model by making it more likely to suggest the phrases that got good feedback. Suppose we deploy a reference model4 h0 and log a dataset Related Work Language models have a long history and play an important role in many NLP applications (Sordoni et al., 2015; Rambow et al., 2001; Mani, 2001; Johnson et al., 2016). However, these models do not model human preferences from interactions. Existing deployed keyboards use n-gram language models (Quinn and Zhai, 2016; Kneser and Ney, 1995), or sometimes neural language models (Kim et al., 2016), trained to predict the next word given recent context. Recent advances in language modeling have increased the accuracy of these predictions by using additional context (Mikolov and Zweig, 2012). But as argued in Arnold et al. (2016), these increases in accuracy do not necessarily translate into better suggestio"
K15-1002,D08-1031,1,0.843784,"mention is inside the boundary of another mention), but mention heads never overlap. This property also simplifies the problem of mention head candidate generation. In the example above, the first “they” refers to “Multinational companies investing in China” and the second “They” refers to “Domestic manufacturers, who are also suffering”. In both cases, the mention heads are sufficient to support the decisions: ”they” refers to ”companies”, and ”They” refers to ”manufacturers”. In fact, most of the features3 implemented in existing coreference resolution systems rely solely on mention heads (Bengtson and Roth, 2008). Furthermore, consider the possible mention candidate “league” (italic in the text). It is not chosen as a mention because the surrounding context is not focused on “anti-piracy league”. So, mention the CoNLL-2012 dataset is built from OntoNotes-5.0 corpus. 2 This example is chosen from the ACE-2004 corpus. 3 All features except for those that rely on modifiers. 13 Figure 1: Comparison between a traditional pipelined system and our proposed system. We split up mention detection into two steps: mention head candidate generation and (an optional) mention boundary detection. We feed mention head"
K15-1002,W11-1902,0,0.0180443,"tuency parsing information and gold named entity information. The parsing information9 is only needed to generate training data for the mention head candidate generator and named entities are directly set as heads. We set these extracted heads as gold, which enables us to train the two layer BILOU-classifier described in Sec. 3.1.1. The nonoverlapping mention head assumption in Sec. 3.1.1 can be verified empirically on both ACE-2004 and OntoNotes-5.0 datasets. Baseline Systems We choose three publicly available state-of-the-art end-to-end coreference systems as our baselines: Stanford system (Lee et al., 2011), Berkeley system (Durrett and Klein, 2014) and HOTCoref system (Bj¨orkelund and Kuhn, 2014). Developed Systems Our developed system is built on the work by Chang et al. (2013), using Constrained Latent Left-Linking Model (CL3 M) as our mention-pair coreference model in the joint framework10 . When the CL3 M coreference system uses gold mentions or heads, we call the system Gold; when it uses predicted mentions or heads, we call the system Predicted. The mention head candidate generation module along with mention boundary detection module can be grouped together to form a complete mention dete"
K15-1002,P14-1005,0,0.0670586,"Missing"
K15-1002,D12-1045,0,0.0370925,"hurch (1988), while Finkel and Manning (2009) further study nested named entity recognition, which employs a tree 20 structure as a representation of identifying named entities within other named entities. The most relevant study on mentions in the context of coreference was done in Recasens et al. (2013); this work studies distinguishing single mentions from coreferent mentions. Our joint framework provides similar insights, where the added mention decision variable partly reflects if the mention is singleton or not. Several recent works suggest studying coreference jointly with other tasks. Lee et al. (2012) model entity coreference and event coreference jointly; Durrett and Klein (2014) consider joint coreference and entity-linking. The work closest to ours is that of Lassalle and Denis (2015), which studies a joint anaphoricity detection and coreference resolution framework. While their inference objective is similar, their work assumes gold mentions are given and thus their modeling is very different. 6 Conclusion This paper proposes a joint inference approach to the end-to-end coreference resolution problem. By moving to identify mention heads rather than mentions, and by developing an ILP-ba"
K15-1002,P98-1034,0,0.0737942,"2008; Soon et al., 2001). The introduction of ILP methods has influenced the coreference area too (Chang et al., 2011; Denis and Baldridge, 2007). In this paper, we use the Constrained Latent Left-Linking Model (CL3 M) described in Chang et al. (2013) in our experiments. The task of mention detection is closely related to Named Entity Recognition (NER). Punyakanok and Roth (2001) thoroughly study phrase identification in sentences and propose three different general approaches. They aim to learn several different local classifiers and combine them to optimally satisfy some global constraints. Cardie and Pierce (1998) propose to select certain rules based on a given corpus, to identify base noun phrases. However, the phrases detected are not necessarily mentions that we need to discover. Ratinov and Roth (2009) present detailed studies on the task of named entity recognition, which discusses and compares different methods on multiple aspects including chunk representation, inference method, utility of non-local features, and integration of external knowledge. NER can be regarded as a sequential labeling problem, which can be modeled by several proposed models, e.g. Hidden Markov Model (Rabiner, 1989) or Co"
K15-1002,H05-1004,0,0.296323,"m achieves the highest performance. Parameters of our proposed system are tuned as α = 0.9, β = 0.9, λ1 = 0.25 and λ2 = 0.2. erence model that we implemented, resulting in a traditional pipelined end-to-end coreference system, namely H-M-Coref. We name our new proposed end-to-end coreference resolution system incorporating both the mention head candidate generation module and the joint framework as H-Joint-M. Evaluation Metrics We compare all systems using three popular metrics for coreference resolution: MUC (Vilain et al., 1995), B3 (Bagga and Baldwin, 1998), and Entity-based CEAF (CEAFe ) (Luo, 2005). We use the average F1 scores (AVG) of these three metrics as the main metric for comparison. We use the v7.0 scorer provided by CoNLL-2012 Shared Task11 . We also evaluate the mention detection performance based on precision, recall and F1 score. As mention heads are important for both mention detection and coreference resolution, we also report results evaluated on mention heads. 4.2 Performance for Coreference Resolution Performance of coreference resolution for all systems on the ACE-2004 and CoNLL-2012 datasets is shown in Table 2 and Table 3 respectively.12 These results show that our d"
K15-1002,W11-1904,1,0.94182,"d to using gold mentions. The rest of the paper is organized as follows. We explain the joint head-coreference learning and inference framework in Sec. 2. Our mention head candidate generation module and mention boundary detection module are described in Sec. 3. We report our experimental results in Sec. 4, review related work in Sec. 5 and conclude in Sec. 6. 2 A Joint Head-Coreference Framework This section describes our joint coreference resolution and mention head detection framework. Our work is inspired by the latent left-linking model in Chang et al. (2013) and the ILP formulation from Chang et al. (2011). The joint learning and inference model takes as input mention head candidates 4 Available at http://cogcomp.cs.illinois. edu/page/software_view/Coref 14 (Sec. 3) and jointly (1) determines if they are indeed mention heads and (2) learns a similarity metric between mentions. This is done by simultaneously learning a binary mention head detection classifier and a mention-pair coreference classifier. The mention head detection model here is mainly trained to differentiate valid mention heads from invalid ones. By learning and making decisions jointly, it also serves as a singleton mention head"
K15-1002,P02-1014,0,0.492026,"Missing"
K15-1002,D13-1057,1,0.82786,"d mentions and reduce the performance gap compared to using gold mentions. The rest of the paper is organized as follows. We explain the joint head-coreference learning and inference framework in Sec. 2. Our mention head candidate generation module and mention boundary detection module are described in Sec. 3. We report our experimental results in Sec. 4, review related work in Sec. 5 and conclude in Sec. 6. 2 A Joint Head-Coreference Framework This section describes our joint coreference resolution and mention head detection framework. Our work is inspired by the latent left-linking model in Chang et al. (2013) and the ILP formulation from Chang et al. (2011). The joint learning and inference model takes as input mention head candidates 4 Available at http://cogcomp.cs.illinois. edu/page/software_view/Coref 14 (Sec. 3) and jointly (1) determines if they are indeed mention heads and (2) learns a similarity metric between mentions. This is done by simultaneously learning a binary mention head detection classifier and a mention-pair coreference classifier. The mention head detection model here is mainly trained to differentiate valid mention heads from invalid ones. By learning and making decisions joi"
K15-1002,W12-4501,0,0.10837,"r approach results in a substantial reduction in the coreference performance gap between gold and predicted mentions, and significantly outperforms existing stat-of-the-art results on coreference resolution; in addition, it achieves significant performance improvement on MD for both datasets. 4.1 Experimental Setup Datasets The ACE-2004 dataset contains 443 documents. We use a standard split of 268 training documents, 68 development documents, and 106 testing documents (Culotta et al., 2007; Bengtson and Roth, 2008). The OntoNotes-5.0 dataset, which is released for the CoNLL-2012 Shared Task (Pradhan et al., 2012), contains 3,145 annotated documents. These documents come from a wide range of sources which include newswire, bible, transcripts, magazines, and web blogs. We report results on the test documents for both datasets. MUC 78.17 63.89 64.28 65.81 67.28 70.28 71.35 71.81 72.74 B3 81.64 70.33 70.37 71.97 73.06 73.93 75.33 75.69 76.69 CEAFe 78.45 70.21 70.16 71.14 73.25 73.04 74.02 74.45 75.18 AVG 79.42 68.14 68.27 69.64 71.20 72.42 73.57 73.98 74.87 GoldM/H StanfordM PredictedM H-M-CorefM H-Joint-MM StanfordH PredictedH H-M-CorefH H-Joint-MH Table 2: Performance of coreference resolution for all s"
K15-1002,A88-1019,0,0.179276,"scover. Ratinov and Roth (2009) present detailed studies on the task of named entity recognition, which discusses and compares different methods on multiple aspects including chunk representation, inference method, utility of non-local features, and integration of external knowledge. NER can be regarded as a sequential labeling problem, which can be modeled by several proposed models, e.g. Hidden Markov Model (Rabiner, 1989) or Conditional Random Fields (Sarawagi and Cohen, 2004). The typical BIO representation was introduced in Ramshaw and Marcus (1995); OC representations were introduced in Church (1988), while Finkel and Manning (2009) further study nested named entity recognition, which employs a tree 20 structure as a representation of identifying named entities within other named entities. The most relevant study on mentions in the context of coreference was done in Recasens et al. (2013); this work studies distinguishing single mentions from coreferent mentions. Our joint framework provides similar insights, where the added mention decision variable partly reflects if the mention is singleton or not. Several recent works suggest studying coreference jointly with other tasks. Lee et al. ("
K15-1002,W95-0107,0,0.0150189,"phrases detected are not necessarily mentions that we need to discover. Ratinov and Roth (2009) present detailed studies on the task of named entity recognition, which discusses and compares different methods on multiple aspects including chunk representation, inference method, utility of non-local features, and integration of external knowledge. NER can be regarded as a sequential labeling problem, which can be modeled by several proposed models, e.g. Hidden Markov Model (Rabiner, 1989) or Conditional Random Fields (Sarawagi and Cohen, 2004). The typical BIO representation was introduced in Ramshaw and Marcus (1995); OC representations were introduced in Church (1988), while Finkel and Manning (2009) further study nested named entity recognition, which employs a tree 20 structure as a representation of identifying named entities within other named entities. The most relevant study on mentions in the context of coreference was done in Recasens et al. (2013); this work studies distinguishing single mentions from coreferent mentions. Our joint framework provides similar insights, where the added mention decision variable partly reflects if the mention is singleton or not. Several recent works suggest studyi"
K15-1002,N07-1011,0,0.0168451,"eriments on the two standard coreference resolution datasets, ACE-2004 (NIST, 2004) and OntoNotes-5.0 (Hovy et al., 2006). Our approach results in a substantial reduction in the coreference performance gap between gold and predicted mentions, and significantly outperforms existing stat-of-the-art results on coreference resolution; in addition, it achieves significant performance improvement on MD for both datasets. 4.1 Experimental Setup Datasets The ACE-2004 dataset contains 443 documents. We use a standard split of 268 training documents, 68 development documents, and 106 testing documents (Culotta et al., 2007; Bengtson and Roth, 2008). The OntoNotes-5.0 dataset, which is released for the CoNLL-2012 Shared Task (Pradhan et al., 2012), contains 3,145 annotated documents. These documents come from a wide range of sources which include newswire, bible, transcripts, magazines, and web blogs. We report results on the test documents for both datasets. MUC 78.17 63.89 64.28 65.81 67.28 70.28 71.35 71.81 72.74 B3 81.64 70.33 70.37 71.97 73.06 73.93 75.33 75.69 76.69 CEAFe 78.45 70.21 70.16 71.14 73.25 73.04 74.02 74.45 75.18 AVG 79.42 68.14 68.27 69.64 71.20 72.42 73.57 73.98 74.87 GoldM/H StanfordM Predic"
K15-1002,W09-1119,1,0.767289,"ons. The sequence labeling component builds on the following assumption: Assumption Different mentions have different heads, and heads do not overlap with each other. That is, for each mi, j , we have a corresponding head ha,b where i ≤ a ≤ b ≤ j. Moreover, for another head ha0 ,b0 , we have the satisfying condition a − b0 > 0 or b − a0 &lt; 0 ∀ha,b , ha0 ,b0 . Based on this assumption, the problem of identifying mention heads is a sequential phrase identification problem, and we choose to employ the BILOU-representation as it has advantages over traditional BIO-representation, as shown, e.g. in Ratinov and Roth (2009). The BILOUrepresentation suggests learning classifiers that identify the Beginning, Inside and Last tokens of multi-token chunks as well as Unit-length chunks. The problem is then transformed into a simple, but constrained, 5-class classification problem. The BILOU-classifier shares all features with the mention head detection model described in Sec. 2.1 except for two: length of mention heads and NPMI over head boundary. For each instance, the feature vector is sparse and we use sparse perceptron (Jackson and Craven, 1996) for supervised training. We also apply a two layer prediction aggrega"
K15-1002,N07-1030,0,0.0101161,"5.49 22.60 HeadH 22.40 10.58 JointH 11.81 13.75 H-Joint-MH 34.21 24.33 Table 5: Analysis of performance improvement in terms of Mention Detection Error Reduction (MDER) and Performance Gap Reduction (PGR) for coreference resolution on the ACE-2004 and CoNLL-2012 datasets. “Head” represents the mention head candidate generation module, “Joint” represents the joint learning and inference framework, and “H-JointM” indicates the end-to-end system. Cardie, 2002; Bengtson and Roth, 2008; Soon et al., 2001). The introduction of ILP methods has influenced the coreference area too (Chang et al., 2011; Denis and Baldridge, 2007). In this paper, we use the Constrained Latent Left-Linking Model (CL3 M) described in Chang et al. (2013) in our experiments. The task of mention detection is closely related to Named Entity Recognition (NER). Punyakanok and Roth (2001) thoroughly study phrase identification in sentences and propose three different general approaches. They aim to learn several different local classifiers and combine them to optimally satisfy some global constraints. Cardie and Pierce (1998) propose to select certain rules based on a given corpus, to identify base noun phrases. However, the phrases detected ar"
K15-1002,N13-1071,0,0.0381098,"Missing"
K15-1002,D13-1203,0,0.179073,"Missing"
K15-1002,W04-2401,1,0.569564,"Missing"
K15-1002,Q14-1037,0,0.0511285,"named entity information. The parsing information9 is only needed to generate training data for the mention head candidate generator and named entities are directly set as heads. We set these extracted heads as gold, which enables us to train the two layer BILOU-classifier described in Sec. 3.1.1. The nonoverlapping mention head assumption in Sec. 3.1.1 can be verified empirically on both ACE-2004 and OntoNotes-5.0 datasets. Baseline Systems We choose three publicly available state-of-the-art end-to-end coreference systems as our baselines: Stanford system (Lee et al., 2011), Berkeley system (Durrett and Klein, 2014) and HOTCoref system (Bj¨orkelund and Kuhn, 2014). Developed Systems Our developed system is built on the work by Chang et al. (2013), using Constrained Latent Left-Linking Model (CL3 M) as our mention-pair coreference model in the joint framework10 . When the CL3 M coreference system uses gold mentions or heads, we call the system Gold; when it uses predicted mentions or heads, we call the system Predicted. The mention head candidate generation module along with mention boundary detection module can be grouped together to form a complete mention detection system, and we call it H-M-MD. We can"
K15-1002,D09-1015,0,0.0111072,"oth (2009) present detailed studies on the task of named entity recognition, which discusses and compares different methods on multiple aspects including chunk representation, inference method, utility of non-local features, and integration of external knowledge. NER can be regarded as a sequential labeling problem, which can be modeled by several proposed models, e.g. Hidden Markov Model (Rabiner, 1989) or Conditional Random Fields (Sarawagi and Cohen, 2004). The typical BIO representation was introduced in Ramshaw and Marcus (1995); OC representations were introduced in Church (1988), while Finkel and Manning (2009) further study nested named entity recognition, which employs a tree 20 structure as a representation of identifying named entities within other named entities. The most relevant study on mentions in the context of coreference was done in Recasens et al. (2013); this work studies distinguishing single mentions from coreferent mentions. Our joint framework provides similar insights, where the added mention decision variable partly reflects if the mention is singleton or not. Several recent works suggest studying coreference jointly with other tasks. Lee et al. (2012) model entity coreference an"
K15-1002,N06-2015,0,0.0968508,"uct negative examples as (oi−1 , ha,b , L) and (o j+1 , ha,b , R). Once trained, the binary classifier takes in the head, a token and the direction of the token relative to the head, and decides whether the token is inside or outside the mention corresponding to the head. At test time, this classifier is used around each confirmed head to determine the mention boundaries. The features used here are similar to the mention head detection model described in Sec. 2.1. 4 Experiments We present experiments on the two standard coreference resolution datasets, ACE-2004 (NIST, 2004) and OntoNotes-5.0 (Hovy et al., 2006). Our approach results in a substantial reduction in the coreference performance gap between gold and predicted mentions, and significantly outperforms existing stat-of-the-art results on coreference resolution; in addition, it achieves significant performance improvement on MD for both datasets. 4.1 Experimental Setup Datasets The ACE-2004 dataset contains 443 documents. We use a standard split of 268 training documents, 68 development documents, and 106 testing documents (Culotta et al., 2007; Bengtson and Roth, 2008). The OntoNotes-5.0 dataset, which is released for the CoNLL-2012 Shared Ta"
K15-1002,D12-1114,0,0.0848512,"Missing"
K15-1002,J01-4004,0,0.337797,"ntH 19.22 15.21 H-Joint-MH 53.22 22.22 CoNLL-2012 MDER PGR(AVG) HeadM 25.04 12.16 JointM 10.45 10.44 H-Joint-MM 35.49 22.60 HeadH 22.40 10.58 JointH 11.81 13.75 H-Joint-MH 34.21 24.33 Table 5: Analysis of performance improvement in terms of Mention Detection Error Reduction (MDER) and Performance Gap Reduction (PGR) for coreference resolution on the ACE-2004 and CoNLL-2012 datasets. “Head” represents the mention head candidate generation module, “Joint” represents the joint learning and inference framework, and “H-JointM” indicates the end-to-end system. Cardie, 2002; Bengtson and Roth, 2008; Soon et al., 2001). The introduction of ILP methods has influenced the coreference area too (Chang et al., 2011; Denis and Baldridge, 2007). In this paper, we use the Constrained Latent Left-Linking Model (CL3 M) described in Chang et al. (2013) in our experiments. The task of mention detection is closely related to Named Entity Recognition (NER). Punyakanok and Roth (2001) thoroughly study phrase identification in sentences and propose three different general approaches. They aim to learn several different local classifiers and combine them to optimally satisfy some global constraints. Cardie and Pierce (1998)"
K15-1002,M95-1005,0,0.664278,"heads, they yield the same performance for coreference. Our proposed H-Joint-M system achieves the highest performance. Parameters of our proposed system are tuned as α = 0.9, β = 0.9, λ1 = 0.25 and λ2 = 0.2. erence model that we implemented, resulting in a traditional pipelined end-to-end coreference system, namely H-M-Coref. We name our new proposed end-to-end coreference resolution system incorporating both the mention head candidate generation module and the joint framework as H-Joint-M. Evaluation Metrics We compare all systems using three popular metrics for coreference resolution: MUC (Vilain et al., 1995), B3 (Bagga and Baldwin, 1998), and Entity-based CEAF (CEAFe ) (Luo, 2005). We use the average F1 scores (AVG) of these three metrics as the main metric for comparison. We use the v7.0 scorer provided by CoNLL-2012 Shared Task11 . We also evaluate the mention detection performance based on precision, recall and F1 score. As mention heads are important for both mention detection and coreference resolution, we also report results evaluated on mention heads. 4.2 Performance for Coreference Resolution Performance of coreference resolution for all systems on the ACE-2004 and CoNLL-2012 datasets is"
K15-1002,J03-4003,0,\N,Missing
K15-1002,J94-4002,0,\N,Missing
K15-1002,C98-1034,0,\N,Missing
K19-1015,P05-1074,0,0.129558,"lsFR ful to help users find foreign words based on the notions or descriptions, and is especially beneficial to users such as translators, foreigner language learners and technical writers using non-native languages. We show that BilDRL achieves promising results on this task, while bilingual multi-task learning and joint learning dramatically enhance the performance. (ii) Bilingual paraphrase identification asks whether two sentences in different languages essentially express the same meaning, which is critical to question answering or dialogue systems that apprehend multilingual utterances (Bannard and Callison-Burch, 2005). This task is challenging, as it requires a model to comprehend cross-lingual paraphrases that are inconsistent in grammar, content details and word orders. BilDRL maps sentences to the lexicon embedding space. This process reduces the problem to evaluate the similarity of lexicon embeddings, which can be easily solved by a simple classifier. BilDRL performs well with even a small amount of data, and significantly outperforms previous approaches. Cross-lingual Reverse Dictionary Retrieval Tout être humain du sexe masculin considéré par rapport à son père et à sa mère, ou à un des deux seuleme"
K19-1015,K18-2005,0,0.0234125,"Missing"
K19-1015,W13-3520,1,0.808128,"ven a language pair (li , lj ), we learn the dictionary model Eij on both dictionaries Dij and Dji with shared parameters. Correspondingly, we rewrite the previous learning objective function as below, in which D = Dij ∪ Dji . LMT ij = Joint Learning Objective m n The joint learning process adapts the embedding space to better suit the dictionary model, which is shown to further enhance the crosslingual learning of BilDRL. 3.5 Training To initialize the embedding space, we pretrained BilBOWA on the parallel corpora Europarl v7 (Koehn, 2005) and monolingual corpora of tokenized Wikipedia dump (Al-Rfou et al., 2013). For models without joint learning, we use AMSGrad (Reddi et al., 2018) to optimize the parameters. Each model without bilingual multi-task learning thereof, is trained on batched samples from each individual dictionary. Multi-task learning models are trained on batched samples from two dictionaries. Within each batch, entries of different directions of languages can be mixed together. For joint learning, we conduct an efficient kEij (Sw ) − wk22 . (w,Sw )∈D This strategy non-trivially requests the same dictionary model to represent semantic transfer in two directions of the language pair. To"
K19-1015,D17-1070,0,0.0251662,"erages the significant local semantic features from each h-gram. Following convention (Liu et al., 2017), we apply dynamic max-pooling to extract robust features from the convolution outputs, and use the mean-pooling results of the last layer to represent the sentential semantics. The Linear bag-of-words (BOW) encoder (Ji et al., 2017; Hill et al., 2016) is realized by the While a GRU encoder can stack multiple of the above GRU layers, without an attention mecha(1) nism, the last state hS of the last layer represents the overall meaning of the encoded sentence S. The self-attention mechanism (Conneau et al., 2017) seeks to highlight the important units in an input sentence when capturing its overall meaning, which is calculated as below:   (1) ut = tanh Ma ht + ba  exp u> t uS at = P > wm ∈S exp (um uS ) (2) ht = |S|at ut . 2 Note that recent advances in monolingual contextualized embeddings like multilingual ELMo (Peters et al., 2018; Che et al., 2018) and M-BERT (Pires et al., 2019; Devlin et al., 2018) can also be supported to represent sentences for our setting. We leave them as future work, as they require nontrivial adaption to both multilingual settings and joint training, and extensive pre-t"
K19-1015,D16-1250,0,0.0215878,"ted Work We discuss two lines of relevant work. Bilingual word embeddings. Various approaches have been proposed for training bilingual word embeddings. These approaches span in two families: off-line mappings and joint training. The off-line mapping based approach fixes the structures of pre-trained monolingual embeddings, and induces bilingual projections based on seed lexicons (Mikolov et al., 2013a). Some variants of this approach improve the quality of projections by adding constraints such as orthogonality of transforms, normalization and mean centering of embeddings (Xing et al., 2015; Artetxe et al., 2016; Vuli´c et al., 2016). Others adopt canonical correlation analysis to map separate monolingual embeddings to a shared embedding space (Faruqui and Dyer, 2014; Doval et al., 2018). Unlike off-line mappings, joint training models simultaneously update word embeddings and cross-lingual alignment. In doing so, such approaches generally capture more precise crosslingual semantic transfer (Ruder et al., 2017; Upadhyay et al., 2018). While a few such models still maintain separated embedding spaces for each language (Artetxe et al., 2017), more of them maintain a unified space for both languages. Th"
K19-1015,D15-1131,0,0.017892,"s. This is unlike BilDRL that captures multi-granular correspondence of semantics across different modalities, i.e. sentences and words; (ii) As for learning strategies, NMT relies on an encoder-decoder architecture using end-toend training (Luong et al., 2015b), while BilDRL employs joint learning of a dictionary-based sentence encoder and a bilingual embedding space. cross-lingual semantic transfer by these models is captured from parallel corpora with sentential or document-level alignment, using techniques such as bilingual bag-of-words distances (BilBOWA) (Gouws et al., 2015), Skip-Gram (Coulmance et al., 2015) and sparse tensor factorization (Vyas and Carpuat, 2016). Neural sentence modeling. Neural sentence models seek to capture phrasal or sentential semantics from word sequences. They often adopt encoding techniques such as recurrent neural encoders (RNN) (Kiros et al., 2015), convolutional encoders (CNN) (Chen et al., 2018a), and attentive encoders (Rockt¨aschel et al., 2016) to represent the composed semantics of a sentence as an embedding vector. Recent works have focused on apprehending pairwise correspondence of sentential semantics by adopting multiple neural sentence models in one learnin"
K19-1015,P17-1042,0,0.0447164,"Missing"
K19-1015,P09-1053,0,0.112897,"Missing"
K19-1015,N18-1164,0,0.0665141,"eans a feeling of joy that comes from knowing the troubles of other people, has no proper English counterpart word. To appropriately learn the representations of such words in bilingual embeddings, we need to capture their meanings based on the definitions. Besides, modeling such correspondence is also highly beneficial to many application scenarios. One example is cross-lingual semantic search of concepts (Hill et al., 2016), where the lexemes or concepts are retrieved based on sentential descriptions (see Fig. 1). Others include discourse relation detection in bilingual dialogue utterances (Jiang et al., 2018), multilingual text summarization (Nenkova et al., 2012), and educational applications for foreign language learners. Finally, it is natural in foreign language learning that a human learns foreign words by looking up their meanings in the native language (Hulstijn et al., 1996). Therefore, learning such correspondence essentially mimics human learning behaviors. Bilingual word embeddings have been widely used to capture the correspondence of lexical semantics in different human languages. However, the cross-lingual correspondence between sentences and words is less studied, despite that this"
K19-1015,P14-1129,0,0.0662293,"Missing"
K19-1015,P14-1062,0,0.0169347,", and  σ is the sigmoid function.  (1) zt = σ Mz xt + Nz ht−1 + bz . ˜ (1) is calculated similarly The candidate state h t to those in a traditional recurrent unit as below. The reset gate rt thereof controls how much information of the past sequence should contribute to the candidate state.   ˜ (1) = tanh Ms wt + rt (Ns h(1) ) + bs h t t−1   (1) rt = σ Mr wt + Nr ht−1 + br . 3.1.2 Other Encoders We also experiment with other widely used neural sentence modeling techniques2 , which are however outperformed by the attentive GRU in our tasks. These techniques include the vanilla GRU, CNN (Kalchbrenner et al., 2014), and linear bagof-words (BOW) (Hill et al., 2016). We briefly introduce the later two techniques in the following. A convolutional encoder applies a kernel Mc ∈ (3) Rh×k to produce the latent representation ht = tanh(Mc wt:t+h−1 + bc ) from each h-gram of the input vector sequence wt:t+h−1 , for which h is the kernel size and bc is a bias vector. A sequence of (3) (3) (3) latent vectors H(3) = [h1 , h2 , ..., h|S|−h+1 ] is produced from the input, where each latent vector leverages the significant local semantic features from each h-gram. Following convention (Liu et al., 2017), we apply dyna"
K19-1015,D18-1027,0,0.101846,"o families: off-line mappings and joint training. The off-line mapping based approach fixes the structures of pre-trained monolingual embeddings, and induces bilingual projections based on seed lexicons (Mikolov et al., 2013a). Some variants of this approach improve the quality of projections by adding constraints such as orthogonality of transforms, normalization and mean centering of embeddings (Xing et al., 2015; Artetxe et al., 2016; Vuli´c et al., 2016). Others adopt canonical correlation analysis to map separate monolingual embeddings to a shared embedding space (Faruqui and Dyer, 2014; Doval et al., 2018). Unlike off-line mappings, joint training models simultaneously update word embeddings and cross-lingual alignment. In doing so, such approaches generally capture more precise crosslingual semantic transfer (Ruder et al., 2017; Upadhyay et al., 2018). While a few such models still maintain separated embedding spaces for each language (Artetxe et al., 2017), more of them maintain a unified space for both languages. The 153 Vlj ) is a cross-lingual definition that describes the word wi with a sequence of words in language lj . For example, a French-English dictionary D(Fr, En) could include a F"
K19-1015,W16-6208,0,0.0558636,"Missing"
K19-1015,2005.mtsummit-papers.11,0,0.0288137,"to conduct a bilingual multi-task learning process. In detail, given a language pair (li , lj ), we learn the dictionary model Eij on both dictionaries Dij and Dji with shared parameters. Correspondingly, we rewrite the previous learning objective function as below, in which D = Dij ∪ Dji . LMT ij = Joint Learning Objective m n The joint learning process adapts the embedding space to better suit the dictionary model, which is shown to further enhance the crosslingual learning of BilDRL. 3.5 Training To initialize the embedding space, we pretrained BilBOWA on the parallel corpora Europarl v7 (Koehn, 2005) and monolingual corpora of tokenized Wikipedia dump (Al-Rfou et al., 2013). For models without joint learning, we use AMSGrad (Reddi et al., 2018) to optimize the parameters. Each model without bilingual multi-task learning thereof, is trained on batched samples from each individual dictionary. Multi-task learning models are trained on batched samples from two dictionaries. Within each batch, entries of different directions of languages can be mixed together. For joint learning, we conduct an efficient kEij (Sw ) − wk22 . (w,Sw )∈D This strategy non-trivially requests the same dictionary mode"
K19-1015,E14-1049,0,0.038307,"se approaches span in two families: off-line mappings and joint training. The off-line mapping based approach fixes the structures of pre-trained monolingual embeddings, and induces bilingual projections based on seed lexicons (Mikolov et al., 2013a). Some variants of this approach improve the quality of projections by adding constraints such as orthogonality of transforms, normalization and mean centering of embeddings (Xing et al., 2015; Artetxe et al., 2016; Vuli´c et al., 2016). Others adopt canonical correlation analysis to map separate monolingual embeddings to a shared embedding space (Faruqui and Dyer, 2014; Doval et al., 2018). Unlike off-line mappings, joint training models simultaneously update word embeddings and cross-lingual alignment. In doing so, such approaches generally capture more precise crosslingual semantic transfer (Ruder et al., 2017; Upadhyay et al., 2018). While a few such models still maintain separated embedding spaces for each language (Artetxe et al., 2017), more of them maintain a unified space for both languages. The 153 Vlj ) is a cross-lingual definition that describes the word wi with a sequence of words in language lj . For example, a French-English dictionary D(Fr,"
K19-1015,W15-1521,0,0.180467,"USA 2 The State University of New York, Stony Brook, NY, USA muhaochen@ucla.edu; {kwchang, zaniolo}@cs.ucla.edu; {yittian, haocchen, skiena}@cs.stonybrook.edu Abstract mantic transfers, these approaches critically support many cross-lingual NLP tasks including neural machine translations (NMT) (Devlin et al., 2014), bilingual document classification (Zhou et al., 2016), knowledge alignment (Chen et al., 2018b) and entity linking (Upadhyay et al., 2018). While many existing approaches have been proposed to associate lexical semantics between languages (Chandar et al., 2014; Gouws et al., 2015; Luong et al., 2015a), modeling the correspondence between lexical and sentential semantics across different languages is still an unresolved challenge. We argue that learning to represent such cross-lingual and multi-granular correspondence is well desired and natural for multiple reasons. One reason is that, learning word-to-word correspondence has a natural limitation, considering that many words do not have direct translations in another language. For example, schadenfreude in German, which means a feeling of joy that comes from knowing the troubles of other people, has no proper English counterpart word. To"
K19-1015,Q16-1002,0,0.320883,"learning word-to-word correspondence has a natural limitation, considering that many words do not have direct translations in another language. For example, schadenfreude in German, which means a feeling of joy that comes from knowing the troubles of other people, has no proper English counterpart word. To appropriately learn the representations of such words in bilingual embeddings, we need to capture their meanings based on the definitions. Besides, modeling such correspondence is also highly beneficial to many application scenarios. One example is cross-lingual semantic search of concepts (Hill et al., 2016), where the lexemes or concepts are retrieved based on sentential descriptions (see Fig. 1). Others include discourse relation detection in bilingual dialogue utterances (Jiang et al., 2018), multilingual text summarization (Nenkova et al., 2012), and educational applications for foreign language learners. Finally, it is natural in foreign language learning that a human learns foreign words by looking up their meanings in the native language (Hulstijn et al., 1996). Therefore, learning such correspondence essentially mimics human learning behaviors. Bilingual word embeddings have been widely u"
K19-1015,D15-1166,0,0.226491,"USA 2 The State University of New York, Stony Brook, NY, USA muhaochen@ucla.edu; {kwchang, zaniolo}@cs.ucla.edu; {yittian, haocchen, skiena}@cs.stonybrook.edu Abstract mantic transfers, these approaches critically support many cross-lingual NLP tasks including neural machine translations (NMT) (Devlin et al., 2014), bilingual document classification (Zhou et al., 2016), knowledge alignment (Chen et al., 2018b) and entity linking (Upadhyay et al., 2018). While many existing approaches have been proposed to associate lexical semantics between languages (Chandar et al., 2014; Gouws et al., 2015; Luong et al., 2015a), modeling the correspondence between lexical and sentential semantics across different languages is still an unresolved challenge. We argue that learning to represent such cross-lingual and multi-granular correspondence is well desired and natural for multiple reasons. One reason is that, learning word-to-word correspondence has a natural limitation, considering that many words do not have direct translations in another language. For example, schadenfreude in German, which means a feeling of joy that comes from knowing the troubles of other people, has no proper English counterpart word. To"
K19-1015,N16-1142,0,0.027958,"respondence of semantics across different modalities, i.e. sentences and words; (ii) As for learning strategies, NMT relies on an encoder-decoder architecture using end-toend training (Luong et al., 2015b), while BilDRL employs joint learning of a dictionary-based sentence encoder and a bilingual embedding space. cross-lingual semantic transfer by these models is captured from parallel corpora with sentential or document-level alignment, using techniques such as bilingual bag-of-words distances (BilBOWA) (Gouws et al., 2015), Skip-Gram (Coulmance et al., 2015) and sparse tensor factorization (Vyas and Carpuat, 2016). Neural sentence modeling. Neural sentence models seek to capture phrasal or sentential semantics from word sequences. They often adopt encoding techniques such as recurrent neural encoders (RNN) (Kiros et al., 2015), convolutional encoders (CNN) (Chen et al., 2018a), and attentive encoders (Rockt¨aschel et al., 2016) to represent the composed semantics of a sentence as an embedding vector. Recent works have focused on apprehending pairwise correspondence of sentential semantics by adopting multiple neural sentence models in one learning architecture, including Siamese models for detecting di"
K19-1015,1983.tc-1.13,0,0.276971,"Missing"
K19-1015,N18-1202,0,0.0436869,"2017; Hill et al., 2016) is realized by the While a GRU encoder can stack multiple of the above GRU layers, without an attention mecha(1) nism, the last state hS of the last layer represents the overall meaning of the encoded sentence S. The self-attention mechanism (Conneau et al., 2017) seeks to highlight the important units in an input sentence when capturing its overall meaning, which is calculated as below:   (1) ut = tanh Ma ht + ba  exp u> t uS at = P > wm ∈S exp (um uS ) (2) ht = |S|at ut . 2 Note that recent advances in monolingual contextualized embeddings like multilingual ELMo (Peters et al., 2018; Che et al., 2018) and M-BERT (Pires et al., 2019; Devlin et al., 2018) can also be supported to represent sentences for our setting. We leave them as future work, as they require nontrivial adaption to both multilingual settings and joint training, and extensive pre-training on external corpora. ut is the intermediary representation of GRU out(1) (1) put ht , and uS = tanh(Ma hS + ba ) is that (1) of the last GRU output hS . uS can be seen as a high-level representation of the input sequence. 155 sum of projected word embeddings of the input P|S| sentence, i.e. E (2) (S) = t=1 Mb wt . 3.2 si"
K19-1015,N15-1104,0,0.0741464,"Missing"
K19-1015,P19-1493,0,0.0258395,"GRU encoder can stack multiple of the above GRU layers, without an attention mecha(1) nism, the last state hS of the last layer represents the overall meaning of the encoded sentence S. The self-attention mechanism (Conneau et al., 2017) seeks to highlight the important units in an input sentence when capturing its overall meaning, which is calculated as below:   (1) ut = tanh Ma ht + ba  exp u> t uS at = P > wm ∈S exp (um uS ) (2) ht = |S|at ut . 2 Note that recent advances in monolingual contextualized embeddings like multilingual ELMo (Peters et al., 2018; Che et al., 2018) and M-BERT (Pires et al., 2019; Devlin et al., 2018) can also be supported to represent sentences for our setting. We leave them as future work, as they require nontrivial adaption to both multilingual settings and joint training, and extensive pre-training on external corpora. ut is the intermediary representation of GRU out(1) (1) put ht , and uS = tanh(Ma hS + ba ) is that (1) of the last GRU output hS . uS can be seen as a high-level representation of the input sequence. 155 sum of projected word embeddings of the input P|S| sentence, i.e. E (2) (S) = t=1 Mb wt . 3.2 simple multi-task strategy to bring significant impr"
K19-1015,N15-1091,0,0.0441759,"Missing"
K19-1015,Q16-1019,0,0.0672638,"Missing"
K19-1015,P16-1133,0,0.0629358,"Missing"
K19-1015,C16-1270,0,0.0320799,"Missing"
K19-1015,D18-1270,0,0.067666,"Missing"
K19-1015,P16-1024,0,0.0533182,"Missing"
K19-1035,Q17-1010,0,0.0595663,"er, we adopt both cross-entropy objectives for these two types of parsers as in (Dozat and Manning, 2017; Ma et al., 2018). The encoder and the decoder are jointly trained to optimize the probability of the dependency trees (y) given sentences (x): Lp = − log p(y|x). The probability of a tree can be further factorized into the products of the probabilities of each token’s (m) head decision (h(m)) for the graphLd = Ex∼X a [D(G(x)] − Ex∼X b [D(G(x)], 374 Language Families Afro-Asiatic Austronesian IE.Baltic IE.Germanic IE.Indic IE.Latin IE.Romance IE.Slavic Korean Uralic Languages et al., 2017; Bojanowski et al., 2017) with 300 dimensionss or contextualized word representations provided by multilingual BERT6 (Devlin et al., 2019) with 768 dimensions as the word representations. In addition, we use the Gold universal POS tags to form the input representations.7 We freeze the word representations during training to avoid the risk of disarranging the multilingual representation alignments. We select six auxiliary languages8 (French, Portuguese, Spanish, Russian, German, and Latin) for unsupervised language adaptation via adversarial training. We tune the scaling parameter λ in the range of [0.1, 0.01, 0.001] o"
K19-1035,N18-1111,0,0.0311152,"ages with perturbations. Later many variants of GANs (Arjovsky et al., 2017; Gulrajani et al., 2017) were proposed to improve its’ training stability. In NLP, adversarial training was first utilized for domain adaptation (Ganin et al., 2016). Since then adversarial training has started to receive an increasing interest in the NLP community and applied to many NLP applications including part-of-speech (POS) tagging (Gui et al., 2017; Yasunaga et al., 2018), dependency parsing (Sato et al., 2017), relation extraction (Wu et al., 2017), text classification (Miyato et al., 2017; Liu et al., 2017; Chen and Cardie, 2018), dialogue generation (Li et al., 2017). In the context of cross-lingual NLP tasks, many recent works adopted adversarial training, such as in sequence tagging (Adel et al., 2018), text classification (Xu and Yang, 2017; Chen et al., 2018), word embedding induction (Zhang et al., 2017; Lample et al., 2018), relation classification (Zou et al., 2018), opinion mining (Wang and Pan, 2018), and question-question similarity reranking (Joty et al., 2017). However, existing approaches only consider using the target language as the auxiliary language. It is unclear whether the language invariant repre"
K19-1035,Q18-1039,0,0.0211044,"Since then adversarial training has started to receive an increasing interest in the NLP community and applied to many NLP applications including part-of-speech (POS) tagging (Gui et al., 2017; Yasunaga et al., 2018), dependency parsing (Sato et al., 2017), relation extraction (Wu et al., 2017), text classification (Miyato et al., 2017; Liu et al., 2017; Chen and Cardie, 2018), dialogue generation (Li et al., 2017). In the context of cross-lingual NLP tasks, many recent works adopted adversarial training, such as in sequence tagging (Adel et al., 2018), text classification (Xu and Yang, 2017; Chen et al., 2018), word embedding induction (Zhang et al., 2017; Lample et al., 2018), relation classification (Zou et al., 2018), opinion mining (Wang and Pan, 2018), and question-question similarity reranking (Joty et al., 2017). However, existing approaches only consider using the target language as the auxiliary language. It is unclear whether the language invariant representations learned by previously proposed methods can perform well on a Table 7: Average cross-lingual performance difference between the SelfAtt-Graph parser trained on the source (en) and an auxiliary (x) language and the SelfAttGraph pa"
K19-1035,D11-1005,0,0.0665757,"Missing"
K19-1035,N19-1423,0,0.473239,"2018). The encoder and the decoder are jointly trained to optimize the probability of the dependency trees (y) given sentences (x): Lp = − log p(y|x). The probability of a tree can be further factorized into the products of the probabilities of each token’s (m) head decision (h(m)) for the graphLd = Ex∼X a [D(G(x)] − Ex∼X b [D(G(x)], 374 Language Families Afro-Asiatic Austronesian IE.Baltic IE.Germanic IE.Indic IE.Latin IE.Romance IE.Slavic Korean Uralic Languages et al., 2017; Bojanowski et al., 2017) with 300 dimensionss or contextualized word representations provided by multilingual BERT6 (Devlin et al., 2019) with 768 dimensions as the word representations. In addition, we use the Gold universal POS tags to form the input representations.7 We freeze the word representations during training to avoid the risk of disarranging the multilingual representation alignments. We select six auxiliary languages8 (French, Portuguese, Spanish, Russian, German, and Latin) for unsupervised language adaptation via adversarial training. We tune the scaling parameter λ in the range of [0.1, 0.01, 0.001] on the source language validation set and report the test performance with the best value. For gradient reversal ("
K19-1035,W14-4200,0,0.328542,"Missing"
K19-1035,K15-1012,0,0.0427353,"the auxiliary language has a smaller average distance to all the target languages, the cross-lingual transfer performance would be better. However, from the results in Table 6, we do not see such a pattern. For example, Portuguese (pt) has the smallest average distance to other languages among the aux12 4 Related Work Unsupervised Cross-lingual Parsing. Unsupervised cross-lingual transfer for dependency parsing has been studied over the past few years (Agi´c et al., 2014; Ma and Xia, 2014; Xiao and Guo, 2014; Tiedemann, 2015; Guo et al., 2015; Aufrant et al., 2015; Rasooli and Collins, 2015; Duong et al., 2015; Schlichtkrull and Søgaard, 2017; Ahmad et al., 2019; Rasooli and Collins, 2019; He et al., 2019). Here, “unsupervised transfer” refers to the setting where a parsing model trained only on the source language is directly The language distances are computed based on word order characteristics as suggested in Ahmad et al. (2019). 378 Lang (en,ru) - en (en,fr) - en (en,de) - en IE.Slavic Family hr 1.24/0.90 0.43/-0.45 1.52/1.02 sl 0.35/0.53 -0.55/-0.60 -0.04/0.14 uk 1.23/1.32 0.26/0.09 1.54/1.33 pl 0.97/1.29 0.82/0.66 0.82/0.98 bg 0.79/0.47 0.26/-0.07 0.49/0.41 ru 0.96/0.85 0.39/0.06 1.07/1.11 c"
K19-1035,N19-1253,1,0.781609,"ts and analyses are conducted to address the following research questions: • Does encoder trained with adversarial training generate language-agnostic representations? • Does language-agnostic representations improve cross-language transfer? Figure 1: An overview of our experimental model consists of three basic components: (1) Encoder, (2) (Parsing) Decoder, and (3) (Language) Classifier. We also show how parsing and adversarial losses (Lp and Ld ) are back propagated for parameter updates. Experimental results show that the proposed approach consistently outperform a strong baseline parser (Ahmad et al., 2019), with a significant margin in two family of languages. In addition, we conduct experiments to consolidate our findings with different types of input representations and encoders. Our experiment code is publicly available to facilitate future research.1 2 which are fed to the decoder and the classifier to predict the dependency structure and the language identity (id) of that sentence. The encoder and the decoder jointly form the parsing model and we consider two alternatives2 from (Ahmad et al., 2019): “SelfAtt-Graph” and “RNN-Stack”. The “SelfAtt-Graph” parser consists of a modified self-att"
K19-1035,P19-1070,0,0.0522659,"Missing"
K19-1035,D17-1230,0,0.0348251,"of GANs (Arjovsky et al., 2017; Gulrajani et al., 2017) were proposed to improve its’ training stability. In NLP, adversarial training was first utilized for domain adaptation (Ganin et al., 2016). Since then adversarial training has started to receive an increasing interest in the NLP community and applied to many NLP applications including part-of-speech (POS) tagging (Gui et al., 2017; Yasunaga et al., 2018), dependency parsing (Sato et al., 2017), relation extraction (Wu et al., 2017), text classification (Miyato et al., 2017; Liu et al., 2017; Chen and Cardie, 2018), dialogue generation (Li et al., 2017). In the context of cross-lingual NLP tasks, many recent works adopted adversarial training, such as in sequence tagging (Adel et al., 2018), text classification (Xu and Yang, 2017; Chen et al., 2018), word embedding induction (Zhang et al., 2017; Lample et al., 2018), relation classification (Zou et al., 2018), opinion mining (Wang and Pan, 2018), and question-question similarity reranking (Joty et al., 2017). However, existing approaches only consider using the target language as the auxiliary language. It is unclear whether the language invariant representations learned by previously propos"
K19-1035,D17-1256,0,0.0294794,"et al., 2014; Goodfellow et al., 2015) was initially introduced in computer vision for image classification and received enormous success in improving model’s robustness on input images with perturbations. Later many variants of GANs (Arjovsky et al., 2017; Gulrajani et al., 2017) were proposed to improve its’ training stability. In NLP, adversarial training was first utilized for domain adaptation (Ganin et al., 2016). Since then adversarial training has started to receive an increasing interest in the NLP community and applied to many NLP applications including part-of-speech (POS) tagging (Gui et al., 2017; Yasunaga et al., 2018), dependency parsing (Sato et al., 2017), relation extraction (Wu et al., 2017), text classification (Miyato et al., 2017; Liu et al., 2017; Chen and Cardie, 2018), dialogue generation (Li et al., 2017). In the context of cross-lingual NLP tasks, many recent works adopted adversarial training, such as in sequence tagging (Adel et al., 2018), text classification (Xu and Yang, 2017; Chen et al., 2018), word embedding induction (Zhang et al., 2017; Lample et al., 2018), relation classification (Zou et al., 2018), opinion mining (Wang and Pan, 2018), and question-question s"
K19-1035,P17-1001,0,0.0286943,"stness on input images with perturbations. Later many variants of GANs (Arjovsky et al., 2017; Gulrajani et al., 2017) were proposed to improve its’ training stability. In NLP, adversarial training was first utilized for domain adaptation (Ganin et al., 2016). Since then adversarial training has started to receive an increasing interest in the NLP community and applied to many NLP applications including part-of-speech (POS) tagging (Gui et al., 2017; Yasunaga et al., 2018), dependency parsing (Sato et al., 2017), relation extraction (Wu et al., 2017), text classification (Miyato et al., 2017; Liu et al., 2017; Chen and Cardie, 2018), dialogue generation (Li et al., 2017). In the context of cross-lingual NLP tasks, many recent works adopted adversarial training, such as in sequence tagging (Adel et al., 2018), text classification (Xu and Yang, 2017; Chen et al., 2018), word embedding induction (Zhang et al., 2017; Lample et al., 2018), relation classification (Zou et al., 2018), opinion mining (Wang and Pan, 2018), and question-question similarity reranking (Joty et al., 2017). However, existing approaches only consider using the target language as the auxiliary language. It is unclear whether the"
K19-1035,P18-1130,1,0.781307,"facilitate future research.1 2 which are fed to the decoder and the classifier to predict the dependency structure and the language identity (id) of that sentence. The encoder and the decoder jointly form the parsing model and we consider two alternatives2 from (Ahmad et al., 2019): “SelfAtt-Graph” and “RNN-Stack”. The “SelfAtt-Graph” parser consists of a modified self-attentional encoder (Shaw et al., 2018) and a graph-based deep bi-affine decoder (Dozat and Manning, 2017), while the “RNN-Stack” parser is composed of a Recurrent Neural Network (RNN) based encoder and a stack-pointer decoder (Ma et al., 2018). We stack a classifier (a linear classifier or a multi-layer Perceptron (MLP)) on top of the encoder to perform the language identification task. The identification task can be framed as either a word- or sentence-level classification task. For the sentence-level classification, we apply average pooling3 on the contextual word representations generated by the encoder to form a fixed-length representation of the input sequence, which is fed to the classifier. For the word-level classification, we perform language classification for each token individually. Training Language-agnostic Encoders W"
K19-1035,P15-1119,0,0.0541009,"o them12 or from the same family. Intuitively, we would assume when the auxiliary language has a smaller average distance to all the target languages, the cross-lingual transfer performance would be better. However, from the results in Table 6, we do not see such a pattern. For example, Portuguese (pt) has the smallest average distance to other languages among the aux12 4 Related Work Unsupervised Cross-lingual Parsing. Unsupervised cross-lingual transfer for dependency parsing has been studied over the past few years (Agi´c et al., 2014; Ma and Xia, 2014; Xiao and Guo, 2014; Tiedemann, 2015; Guo et al., 2015; Aufrant et al., 2015; Rasooli and Collins, 2015; Duong et al., 2015; Schlichtkrull and Søgaard, 2017; Ahmad et al., 2019; Rasooli and Collins, 2019; He et al., 2019). Here, “unsupervised transfer” refers to the setting where a parsing model trained only on the source language is directly The language distances are computed based on word order characteristics as suggested in Ahmad et al. (2019). 378 Lang (en,ru) - en (en,fr) - en (en,de) - en IE.Slavic Family hr 1.24/0.90 0.43/-0.45 1.52/1.02 sl 0.35/0.53 -0.55/-0.60 -0.04/0.14 uk 1.23/1.32 0.26/0.09 1.54/1.33 pl 0.97/1.29 0.82/0.66 0.82/0.98"
K19-1035,P14-1126,1,0.860598,"ining significantly improves the overall transfer performances under several different settings. We conduct a careful analysis to evaluate the language-agnostic representations resulted from adversarial training. 1 Introduction Cross-lingual transfer, where a model learned from one language is transferred to another, has become an important technique to improve the quality and coverage of natural language processing (NLP) tools for languages in the world. This technique has been widely applied in many applications, including part-of-speech (POS) tagging (Kim et al., 2017), dependency parsing (Ma and Xia, 2014), named entity recognition (Xie et al., 2018), entity linking (Sil et al., 2018), coreference resolution (Kundu et al., 2018), and question answering (Joty et al., 2017). Noteworthy improvements are achieved on low resource language applications due to cross-lingual transfer learning. 372 Proceedings of the 23rd Conference on Computational Natural Language Learning, pages 372–382 c Hong Kong, China, November 3-4, 2019. 2019 Association for Computational Linguistics To verify the proposed approach, we conduct experiments on neural dependency parsers trained on English (source language) and dire"
K19-1035,P19-1311,1,0.833008,"l transfer performance would be better. However, from the results in Table 6, we do not see such a pattern. For example, Portuguese (pt) has the smallest average distance to other languages among the aux12 4 Related Work Unsupervised Cross-lingual Parsing. Unsupervised cross-lingual transfer for dependency parsing has been studied over the past few years (Agi´c et al., 2014; Ma and Xia, 2014; Xiao and Guo, 2014; Tiedemann, 2015; Guo et al., 2015; Aufrant et al., 2015; Rasooli and Collins, 2015; Duong et al., 2015; Schlichtkrull and Søgaard, 2017; Ahmad et al., 2019; Rasooli and Collins, 2019; He et al., 2019). Here, “unsupervised transfer” refers to the setting where a parsing model trained only on the source language is directly The language distances are computed based on word order characteristics as suggested in Ahmad et al. (2019). 378 Lang (en,ru) - en (en,fr) - en (en,de) - en IE.Slavic Family hr 1.24/0.90 0.43/-0.45 1.52/1.02 sl 0.35/0.53 -0.55/-0.60 -0.04/0.14 uk 1.23/1.32 0.26/0.09 1.54/1.33 pl 0.97/1.29 0.82/0.66 0.82/0.98 bg 0.79/0.47 0.26/-0.07 0.49/0.41 ru 0.96/0.85 0.39/0.06 1.07/1.11 cs 0.78/0.65 0.79/0.34 0.91/0.81 sk 1.56/0.90 0.78/0.19 1.88/1.04 Avg. 0.98/0.86 0.4/0.03 1.02/0.86"
K19-1035,K17-1024,0,0.0548933,"Missing"
K19-1035,L16-1262,0,0.0921429,"Missing"
K19-1035,D17-1302,0,0.0175318,"guages demonstrate that adversarial training significantly improves the overall transfer performances under several different settings. We conduct a careful analysis to evaluate the language-agnostic representations resulted from adversarial training. 1 Introduction Cross-lingual transfer, where a model learned from one language is transferred to another, has become an important technique to improve the quality and coverage of natural language processing (NLP) tools for languages in the world. This technique has been widely applied in many applications, including part-of-speech (POS) tagging (Kim et al., 2017), dependency parsing (Ma and Xia, 2014), named entity recognition (Xie et al., 2018), entity linking (Sil et al., 2018), coreference resolution (Kundu et al., 2018), and question answering (Joty et al., 2017). Noteworthy improvements are achieved on low resource language applications due to cross-lingual transfer learning. 372 Proceedings of the 23rd Conference on Computational Natural Language Learning, pages 372–382 c Hong Kong, China, November 3-4, 2019. 2019 Association for Computational Linguistics To verify the proposed approach, we conduct experiments on neural dependency parsers traine"
K19-1035,D15-1039,0,0.0410152,"ively, we would assume when the auxiliary language has a smaller average distance to all the target languages, the cross-lingual transfer performance would be better. However, from the results in Table 6, we do not see such a pattern. For example, Portuguese (pt) has the smallest average distance to other languages among the aux12 4 Related Work Unsupervised Cross-lingual Parsing. Unsupervised cross-lingual transfer for dependency parsing has been studied over the past few years (Agi´c et al., 2014; Ma and Xia, 2014; Xiao and Guo, 2014; Tiedemann, 2015; Guo et al., 2015; Aufrant et al., 2015; Rasooli and Collins, 2015; Duong et al., 2015; Schlichtkrull and Søgaard, 2017; Ahmad et al., 2019; Rasooli and Collins, 2019; He et al., 2019). Here, “unsupervised transfer” refers to the setting where a parsing model trained only on the source language is directly The language distances are computed based on word order characteristics as suggested in Ahmad et al. (2019). 378 Lang (en,ru) - en (en,fr) - en (en,de) - en IE.Slavic Family hr 1.24/0.90 0.43/-0.45 1.52/1.02 sl 0.35/0.53 -0.55/-0.60 -0.04/0.14 uk 1.23/1.32 0.26/0.09 1.54/1.33 pl 0.97/1.29 0.82/0.66 0.82/0.98 bg 0.79/0.47 0.26/-0.07 0.49/0.41 ru 0.96/0.85 0"
K19-1035,P18-2063,0,0.0266025,"sis to evaluate the language-agnostic representations resulted from adversarial training. 1 Introduction Cross-lingual transfer, where a model learned from one language is transferred to another, has become an important technique to improve the quality and coverage of natural language processing (NLP) tools for languages in the world. This technique has been widely applied in many applications, including part-of-speech (POS) tagging (Kim et al., 2017), dependency parsing (Ma and Xia, 2014), named entity recognition (Xie et al., 2018), entity linking (Sil et al., 2018), coreference resolution (Kundu et al., 2018), and question answering (Joty et al., 2017). Noteworthy improvements are achieved on low resource language applications due to cross-lingual transfer learning. 372 Proceedings of the 23rd Conference on Computational Natural Language Learning, pages 372–382 c Hong Kong, China, November 3-4, 2019. 2019 Association for Computational Linguistics To verify the proposed approach, we conduct experiments on neural dependency parsers trained on English (source language) and directly transfer them to 28 target languages, with or without the assistance of unlabeled data from auxiliary languages. We chos"
K19-1035,K17-3007,0,0.0287844,"d in computer vision for image classification and received enormous success in improving model’s robustness on input images with perturbations. Later many variants of GANs (Arjovsky et al., 2017; Gulrajani et al., 2017) were proposed to improve its’ training stability. In NLP, adversarial training was first utilized for domain adaptation (Ganin et al., 2016). Since then adversarial training has started to receive an increasing interest in the NLP community and applied to many NLP applications including part-of-speech (POS) tagging (Gui et al., 2017; Yasunaga et al., 2018), dependency parsing (Sato et al., 2017), relation extraction (Wu et al., 2017), text classification (Miyato et al., 2017; Liu et al., 2017; Chen and Cardie, 2018), dialogue generation (Li et al., 2017). In the context of cross-lingual NLP tasks, many recent works adopted adversarial training, such as in sequence tagging (Adel et al., 2018), text classification (Xu and Yang, 2017; Chen et al., 2018), word embedding induction (Zhang et al., 2017; Lample et al., 2018), relation classification (Zou et al., 2018), opinion mining (Wang and Pan, 2018), and question-question similarity reranking (Joty et al., 2017). However, existing appro"
K19-1035,D19-1077,0,0.137009,"nduct experiments on the Universal Dependencies (UD) Treebanks (v2.2) (Nivre et al., 2018) using 29 languages, as shown in Table 1. We use the publicly available implementation4 of the “SelfAtt-Graph” and “RNN-Stack” parsers.5 Ahmad et al. (2019) show that the “SelfAtt-Graph” parser captures less language-specific information and performs better than the ‘RNN-Stack” parser for distant target languages. Therefore, we use the “SelfAttGraph” parser in most of our experiments. Besides, the multilingual variant of BERT (mBERT) (Devlin et al., 2019) has shown to perform well in cross-lingual tasks (Wu and Dredze, 2019) and outperform the models trained on multilingual word embeddings by a large margin. Therefore, we consider conducting experiments with both multilingual word embeddings and mBERT. We use aligned multilingual word embeddings (Smith 4 5 3.1 Results and Analysis Table 2 presents the main transfer results of the “SelfAtt-Graph” parser when training on only English (en, baseline), English with French (enfr), and English with Russian (en-ru). The re6 https://github.com/huggingface/pytorch-transformers We concatenate the word and POS representations. In our future work, we will conduct transfer lea"
K19-1035,D17-1187,0,0.0226914,"tion and received enormous success in improving model’s robustness on input images with perturbations. Later many variants of GANs (Arjovsky et al., 2017; Gulrajani et al., 2017) were proposed to improve its’ training stability. In NLP, adversarial training was first utilized for domain adaptation (Ganin et al., 2016). Since then adversarial training has started to receive an increasing interest in the NLP community and applied to many NLP applications including part-of-speech (POS) tagging (Gui et al., 2017; Yasunaga et al., 2018), dependency parsing (Sato et al., 2017), relation extraction (Wu et al., 2017), text classification (Miyato et al., 2017; Liu et al., 2017; Chen and Cardie, 2018), dialogue generation (Li et al., 2017). In the context of cross-lingual NLP tasks, many recent works adopted adversarial training, such as in sequence tagging (Adel et al., 2018), text classification (Xu and Yang, 2017; Chen et al., 2018), word embedding induction (Zhang et al., 2017; Lample et al., 2018), relation classification (Zou et al., 2018), opinion mining (Wang and Pan, 2018), and question-question similarity reranking (Joty et al., 2017). However, existing approaches only consider using the target la"
K19-1035,E17-1021,0,0.0145028,"age has a smaller average distance to all the target languages, the cross-lingual transfer performance would be better. However, from the results in Table 6, we do not see such a pattern. For example, Portuguese (pt) has the smallest average distance to other languages among the aux12 4 Related Work Unsupervised Cross-lingual Parsing. Unsupervised cross-lingual transfer for dependency parsing has been studied over the past few years (Agi´c et al., 2014; Ma and Xia, 2014; Xiao and Guo, 2014; Tiedemann, 2015; Guo et al., 2015; Aufrant et al., 2015; Rasooli and Collins, 2015; Duong et al., 2015; Schlichtkrull and Søgaard, 2017; Ahmad et al., 2019; Rasooli and Collins, 2019; He et al., 2019). Here, “unsupervised transfer” refers to the setting where a parsing model trained only on the source language is directly The language distances are computed based on word order characteristics as suggested in Ahmad et al. (2019). 378 Lang (en,ru) - en (en,fr) - en (en,de) - en IE.Slavic Family hr 1.24/0.90 0.43/-0.45 1.52/1.02 sl 0.35/0.53 -0.55/-0.60 -0.04/0.14 uk 1.23/1.32 0.26/0.09 1.54/1.33 pl 0.97/1.29 0.82/0.66 0.82/0.98 bg 0.79/0.47 0.26/-0.07 0.49/0.41 ru 0.96/0.85 0.39/0.06 1.07/1.11 cs 0.78/0.65 0.79/0.34 0.91/0.81 s"
K19-1035,W14-1613,0,0.0178044,"it target languages that are closer to them12 or from the same family. Intuitively, we would assume when the auxiliary language has a smaller average distance to all the target languages, the cross-lingual transfer performance would be better. However, from the results in Table 6, we do not see such a pattern. For example, Portuguese (pt) has the smallest average distance to other languages among the aux12 4 Related Work Unsupervised Cross-lingual Parsing. Unsupervised cross-lingual transfer for dependency parsing has been studied over the past few years (Agi´c et al., 2014; Ma and Xia, 2014; Xiao and Guo, 2014; Tiedemann, 2015; Guo et al., 2015; Aufrant et al., 2015; Rasooli and Collins, 2015; Duong et al., 2015; Schlichtkrull and Søgaard, 2017; Ahmad et al., 2019; Rasooli and Collins, 2019; He et al., 2019). Here, “unsupervised transfer” refers to the setting where a parsing model trained only on the source language is directly The language distances are computed based on word order characteristics as suggested in Ahmad et al. (2019). 378 Lang (en,ru) - en (en,fr) - en (en,de) - en IE.Slavic Family hr 1.24/0.90 0.43/-0.45 1.52/1.02 sl 0.35/0.53 -0.55/-0.60 -0.04/0.14 uk 1.23/1.32 0.26/0.09 1.54/1."
K19-1035,N18-2074,0,0.0311579,"nt margin in two family of languages. In addition, we conduct experiments to consolidate our findings with different types of input representations and encoders. Our experiment code is publicly available to facilitate future research.1 2 which are fed to the decoder and the classifier to predict the dependency structure and the language identity (id) of that sentence. The encoder and the decoder jointly form the parsing model and we consider two alternatives2 from (Ahmad et al., 2019): “SelfAtt-Graph” and “RNN-Stack”. The “SelfAtt-Graph” parser consists of a modified self-attentional encoder (Shaw et al., 2018) and a graph-based deep bi-affine decoder (Dozat and Manning, 2017), while the “RNN-Stack” parser is composed of a Recurrent Neural Network (RNN) based encoder and a stack-pointer decoder (Ma et al., 2018). We stack a classifier (a linear classifier or a multi-layer Perceptron (MLP)) on top of the encoder to perform the language identification task. The identification task can be framed as either a word- or sentence-level classification task. For the sentence-level classification, we apply average pooling3 on the contextual word representations generated by the encoder to form a fixed-length r"
K19-1035,D18-1034,0,0.0237282,"sfer performances under several different settings. We conduct a careful analysis to evaluate the language-agnostic representations resulted from adversarial training. 1 Introduction Cross-lingual transfer, where a model learned from one language is transferred to another, has become an important technique to improve the quality and coverage of natural language processing (NLP) tools for languages in the world. This technique has been widely applied in many applications, including part-of-speech (POS) tagging (Kim et al., 2017), dependency parsing (Ma and Xia, 2014), named entity recognition (Xie et al., 2018), entity linking (Sil et al., 2018), coreference resolution (Kundu et al., 2018), and question answering (Joty et al., 2017). Noteworthy improvements are achieved on low resource language applications due to cross-lingual transfer learning. 372 Proceedings of the 23rd Conference on Computational Natural Language Learning, pages 372–382 c Hong Kong, China, November 3-4, 2019. 2019 Association for Computational Linguistics To verify the proposed approach, we conduct experiments on neural dependency parsers trained on English (source language) and directly transfer them to 28 target languages, wi"
K19-1035,P17-1130,0,0.0199091,"nin et al., 2016). Since then adversarial training has started to receive an increasing interest in the NLP community and applied to many NLP applications including part-of-speech (POS) tagging (Gui et al., 2017; Yasunaga et al., 2018), dependency parsing (Sato et al., 2017), relation extraction (Wu et al., 2017), text classification (Miyato et al., 2017; Liu et al., 2017; Chen and Cardie, 2018), dialogue generation (Li et al., 2017). In the context of cross-lingual NLP tasks, many recent works adopted adversarial training, such as in sequence tagging (Adel et al., 2018), text classification (Xu and Yang, 2017; Chen et al., 2018), word embedding induction (Zhang et al., 2017; Lample et al., 2018), relation classification (Zou et al., 2018), opinion mining (Wang and Pan, 2018), and question-question similarity reranking (Joty et al., 2017). However, existing approaches only consider using the target language as the auxiliary language. It is unclear whether the language invariant representations learned by previously proposed methods can perform well on a Table 7: Average cross-lingual performance difference between the SelfAtt-Graph parser trained on the source (en) and an auxiliary (x) language and"
K19-1035,N18-1089,0,0.0213827,"fellow et al., 2015) was initially introduced in computer vision for image classification and received enormous success in improving model’s robustness on input images with perturbations. Later many variants of GANs (Arjovsky et al., 2017; Gulrajani et al., 2017) were proposed to improve its’ training stability. In NLP, adversarial training was first utilized for domain adaptation (Ganin et al., 2016). Since then adversarial training has started to receive an increasing interest in the NLP community and applied to many NLP applications including part-of-speech (POS) tagging (Gui et al., 2017; Yasunaga et al., 2018), dependency parsing (Sato et al., 2017), relation extraction (Wu et al., 2017), text classification (Miyato et al., 2017; Liu et al., 2017; Chen and Cardie, 2018), dialogue generation (Li et al., 2017). In the context of cross-lingual NLP tasks, many recent works adopted adversarial training, such as in sequence tagging (Adel et al., 2018), text classification (Xu and Yang, 2017; Chen et al., 2018), word embedding induction (Zhang et al., 2017; Lample et al., 2018), relation classification (Zou et al., 2018), opinion mining (Wang and Pan, 2018), and question-question similarity reranking (Jot"
K19-1035,P17-1179,0,0.0173354,"receive an increasing interest in the NLP community and applied to many NLP applications including part-of-speech (POS) tagging (Gui et al., 2017; Yasunaga et al., 2018), dependency parsing (Sato et al., 2017), relation extraction (Wu et al., 2017), text classification (Miyato et al., 2017; Liu et al., 2017; Chen and Cardie, 2018), dialogue generation (Li et al., 2017). In the context of cross-lingual NLP tasks, many recent works adopted adversarial training, such as in sequence tagging (Adel et al., 2018), text classification (Xu and Yang, 2017; Chen et al., 2018), word embedding induction (Zhang et al., 2017; Lample et al., 2018), relation classification (Zou et al., 2018), opinion mining (Wang and Pan, 2018), and question-question similarity reranking (Joty et al., 2017). However, existing approaches only consider using the target language as the auxiliary language. It is unclear whether the language invariant representations learned by previously proposed methods can perform well on a Table 7: Average cross-lingual performance difference between the SelfAtt-Graph parser trained on the source (en) and an auxiliary (x) language and the SelfAttGraph parser trained only on English (en) language (UA"
K19-1035,N13-1126,0,0.0593559,"Missing"
K19-1035,C18-1037,0,0.0308931,"Missing"
K19-1035,W15-2137,0,0.0603923,"that are closer to them12 or from the same family. Intuitively, we would assume when the auxiliary language has a smaller average distance to all the target languages, the cross-lingual transfer performance would be better. However, from the results in Table 6, we do not see such a pattern. For example, Portuguese (pt) has the smallest average distance to other languages among the aux12 4 Related Work Unsupervised Cross-lingual Parsing. Unsupervised cross-lingual transfer for dependency parsing has been studied over the past few years (Agi´c et al., 2014; Ma and Xia, 2014; Xiao and Guo, 2014; Tiedemann, 2015; Guo et al., 2015; Aufrant et al., 2015; Rasooli and Collins, 2015; Duong et al., 2015; Schlichtkrull and Søgaard, 2017; Ahmad et al., 2019; Rasooli and Collins, 2019; He et al., 2019). Here, “unsupervised transfer” refers to the setting where a parsing model trained only on the source language is directly The language distances are computed based on word order characteristics as suggested in Ahmad et al. (2019). 378 Lang (en,ru) - en (en,fr) - en (en,de) - en IE.Slavic Family hr 1.24/0.90 0.43/-0.45 1.52/1.02 sl 0.35/0.53 -0.55/-0.60 -0.04/0.14 uk 1.23/1.32 0.26/0.09 1.54/1.33 pl 0.97/1.29 0"
K19-1035,W14-4203,0,\N,Missing
K19-1035,C16-1012,0,\N,Missing
K19-1035,N19-1385,0,\N,Missing
L18-1062,Q16-1026,0,0.0212106,"np , the phrase embedding E(p) is: np 1 X wk E(p) = np k=1 where E(p), wk ∈ Rde and de is a hyper-parameter, indicating word embedding size. Then, we compute the similarity score of the phrase pair as follows. Sim(p1 , p2 ) = cosine(p1 , p2 ) = pT1 p2 ||p1 |p2 || The “Mention Embeddings + FFNN” baseline construct mention representations like previous baseline but compute score using a two-layer feed-forward neural network. Sim(p1 , p2 ) = σ(uT tanh(W [E(p1 ), E(p2 )] + b)) where W ∈ Rde ×de , b, u ∈ Rde , and [E(p1 ), E(p2 )] represents concatenation of the phrase embedding pair. Inspired by (Chiu and Nichols, 2016; Ma and Hovy, 2016), we also provide a more sophisticated baseline by using bidirectional long-short term memory (LSTM) (Hochreiter and Schmidhuber, 1997) and convolutional neural network (CNN) (LeCun et al., 1998; Kalchbrenner et al., 2014) in combinations to construct mention representation and using a feed-forward neural network to score mention antecedent pairs. A general architecture for the proposed baseline methods is shown in Fig. 1. ˜ We use a shallow bi-directional LSTM with hidden size h to encode contextual embeddings p˜t of each word in the phrase, → − → − h t = LST M ( h t−1 , w"
L18-1062,D08-1069,0,0.142904,"resolution system and evaluate the soundness of the representations based on the end performance of the system but it is hard to measure the contribution of the individual word/phrase representations. As our main goal is to evaluate representations of noun phrases, we specifically focus on the nominals since previous works (Durrett and Klein, 2014) show that resolving nominal mentions are one of the hardest categories in coreference resolution. Therefore, we propose a ranking evaluation procedure based on the intuition that many state-of-the-art approaches are based on mention ranking model (Denis and Baldridge, 2008). Given a target mention and a list of candidate mentions, the goal in our setting is to rank the mentions in the candidate list based on how likely it is co-referred with the target mention without considering the context. In this way, we can directly compare the contributions of the mention representations in a model. We propose a phrase level task where we consider the entire mention boundaries 1 as a noun phrase. We demonstrate how to construct such mention ranking evaluation data from Ontonotes v5.0 corpus and present the results of preliminary experiments as a proof-of-concept. 2. Datase"
L18-1062,D13-1203,0,0.0146678,"ence relationship to evaluate word and phrase embedding. It is important to note that, co-occurrence and coreference are not the same concepts. For example, “lazy dog” and “attractive cat” are very close in the low dimensional embedding space because of high co-occurrence of the words “dog” and “cat” but they cannot be co-referred. On the other hand, “phd candidate” and “graduate student” can be co-referred to each other. As we mentioned, we reduce the coreference resolution problem to an antecedent ranking problem, since many state-of-the-art models (Wiseman et al., 2015; Chang et al., 2013; Durrett and Klein, 2013) are a variant of the mentionranking model (Denis and Baldridge, 2008). We define the antecedent ranking problem as, given a target mention, the goal is to rank all antecedent mentions in the same document based on predicted scores such that the antecedent mentions referred to the target mention are ranked on the top. We propose to evaluate phrase embeddings to estimate the usefulness of embeddings to train supervised learning algorithms for antecedent ranking. We train an end-to-end model to produce phrase embeddings based on the training set, tune the model on the development set, and comput"
L18-1062,Q14-1037,0,0.0144871,"task is a supervised clustering task. Given a document, a system clusters all the mentions in the article into equivalent classes, such that each class contains mentions refer to the same entity. Despite we can plug-in word and/or phrase representations into a coreference resolution system and evaluate the soundness of the representations based on the end performance of the system but it is hard to measure the contribution of the individual word/phrase representations. As our main goal is to evaluate representations of noun phrases, we specifically focus on the nominals since previous works (Durrett and Klein, 2014) show that resolving nominal mentions are one of the hardest categories in coreference resolution. Therefore, we propose a ranking evaluation procedure based on the intuition that many state-of-the-art approaches are based on mention ranking model (Denis and Baldridge, 2008). Given a target mention and a list of candidate mentions, the goal in our setting is to rank the mentions in the candidate list based on how likely it is co-referred with the target mention without considering the context. In this way, we can directly compare the contributions of the mention representations in a model. We"
L18-1062,P14-1113,0,0.0862145,"Missing"
L18-1062,D09-1120,0,0.0334312,"-hyponym relation (Fu et al., 2014), word similarity task (Levy and Goldberg, 2014), word analogy taks (Levy et al., 2015), POS tagging task (Lin et al., 2015) and phrase-based machine translation (Zou et al., 2013). Our proposed evaluation approach is complementary to the previous ones. Besides, it is suitable to be used for evaluating phrase embedding. Our work is inspired by previous works on supervised coreference research which show that incorporating external knowledge can improve the performance of a coreference system (CR). A variety of approaches (Ng, 2007; Ponzetto and Strube, 2006; Haghighi and Klein, 2009) have 409 been shown to benefit from using external resources such as Wikipedia (Strube and Ponzetto, 2006; Ponzetto and Strube, 2007; Singh et al., 2012; Spitkovsky and Chang, 2012), WordNet (Harabagiu et al., 2001; Soon et al., 2001) or YAGO (Suchanek et al., 2007). (Rahman and Ng, 2011) examined the utility of three major sources of world knowledge and applied them to two learning-based coreference models and found improved performance when knowledge extracted from different sources are exploited in combination rather than individually. Also, previous works (Ogrodniczuk, 2013) verified that"
L18-1062,N01-1008,0,0.0963982,"ur proposed evaluation approach is complementary to the previous ones. Besides, it is suitable to be used for evaluating phrase embedding. Our work is inspired by previous works on supervised coreference research which show that incorporating external knowledge can improve the performance of a coreference system (CR). A variety of approaches (Ng, 2007; Ponzetto and Strube, 2006; Haghighi and Klein, 2009) have 409 been shown to benefit from using external resources such as Wikipedia (Strube and Ponzetto, 2006; Ponzetto and Strube, 2007; Singh et al., 2012; Spitkovsky and Chang, 2012), WordNet (Harabagiu et al., 2001; Soon et al., 2001) or YAGO (Suchanek et al., 2007). (Rahman and Ng, 2011) examined the utility of three major sources of world knowledge and applied them to two learning-based coreference models and found improved performance when knowledge extracted from different sources are exploited in combination rather than individually. Also, previous works (Ogrodniczuk, 2013) verified that nominal facts extracted from world knowledge resources effectively perform and can be used as a source of pragmatic knowledge for coreference resolution. 6. Conclusion and Future Work In this work, we propose a cor"
L18-1062,N06-2015,0,0.080151,"mention are ranked on the top. We propose to evaluate phrase embeddings to estimate the usefulness of embeddings to train supervised learning algorithms for antecedent ranking. We train an end-to-end model to produce phrase embeddings based on the training set, tune the model on the development set, and compute accuracy of the ranking based on evaluation dataset. We allow a model to use a pre-trained word embedding for initialization purpose. We construct the training and development dataset from the corpus we generated from Wikipedia and the evaluation dataset based on OntoNotes V5.0 corpus (Hovy et al., 2006) that used in the CoNLL shared task 2012 for coreference resolution (Pradhan et al., 2012). Table 2 lists the complete details of the extracted dataset. We get coreferential mention clusters from the corpus we generate as described in section 2. Negative examples are 2 https://github.com/wasiahmad/mining_ wikipedia/tree/master/WikiMiner 407 Figure 1: Neural network architecture to rank candidate mentions of a target mention Train (src: Wikipedia) Development (src: Wikipedia) Test (src: CoNLL) Total nominal coref. chain Avg. candidates per chain Total unique terms Total nominal coref. chain Avg"
L18-1062,W97-1311,0,0.278232,"2013; Pennington et al., 2014) uses log-bilinear models to learn continuous representations of words on large corpora efficiently. While these vector representations capture finegrained syntactic and semantic regularities among words or phrases, it often lacks coreferential information. For example, “phd student” and “graduate fellow” can be co-referred to each other and this relationship should be recognized by semantic representations. Refer-to-as relation information can benefit many natural language processing applications such as question answering (Morton, 1999), information extraction (Humphreys et al., 1997; Zelenko et al., 2004) etc. So, in this paper, we focus on the task of resolving refer-to-as relation between nominals. We design a coreferential phrase prediction task by simplifying the coreference resolution task to evaluate the utility of our proposed corpus. The automatic resolution of identifying surface forms (a.k.a mentions) which co-refer to the same abstract entity is a challenging task with a long history in computational linguistics. For example, given a paragraph, “A female motorist wearing a blue shirt abruptly made a left turn, ignoring the officer’s attempt to initiate a traff"
L18-1062,P14-1062,0,0.0129304,"p2 ) = pT1 p2 ||p1 |p2 || The “Mention Embeddings + FFNN” baseline construct mention representations like previous baseline but compute score using a two-layer feed-forward neural network. Sim(p1 , p2 ) = σ(uT tanh(W [E(p1 ), E(p2 )] + b)) where W ∈ Rde ×de , b, u ∈ Rde , and [E(p1 ), E(p2 )] represents concatenation of the phrase embedding pair. Inspired by (Chiu and Nichols, 2016; Ma and Hovy, 2016), we also provide a more sophisticated baseline by using bidirectional long-short term memory (LSTM) (Hochreiter and Schmidhuber, 1997) and convolutional neural network (CNN) (LeCun et al., 1998; Kalchbrenner et al., 2014) in combinations to construct mention representation and using a feed-forward neural network to score mention antecedent pairs. A general architecture for the proposed baseline methods is shown in Fig. 1. ˜ We use a shallow bi-directional LSTM with hidden size h to encode contextual embeddings p˜t of each word in the phrase, → − → − h t = LST M ( h t−1 , wt ), t = 1, . . . , np ← − ← − h t = LST M ( h t+1 , wt ), t = np , . . . , 1 → − ← − p˜t = [ h t , h t ] ˜ Where p˜t ∈ Rh and h = 2h. To construct mention embeddings, we apply convolution operation on the contextual embeddings, p˜t . We can"
L18-1062,Q15-1016,0,0.0419257,"known as, word embeddings, typically represent words with dense, lowdimensional and real-valued vectors. Word embeddings have been empirically shown to preserve linguistic information, such as the semantic relationship between words (Mikolov et al., 2013; Pennington et al., 2014) and it helps to learn algorithms to perceive underlying semantics of the targeted task. Over the past few years, researchers have been studying different ways for evaluating word embeddings, including using hypernym-hyponym relation (Fu et al., 2014), word similarity task (Levy and Goldberg, 2014), word analogy taks (Levy et al., 2015), POS tagging task (Lin et al., 2015) and phrase-based machine translation (Zou et al., 2013). Our proposed evaluation approach is complementary to the previous ones. Besides, it is suitable to be used for evaluating phrase embedding. Our work is inspired by previous works on supervised coreference research which show that incorporating external knowledge can improve the performance of a coreference system (CR). A variety of approaches (Ng, 2007; Ponzetto and Strube, 2006; Haghighi and Klein, 2009) have 409 been shown to benefit from using external resources such as Wikipedia (Strube and Ponze"
L18-1062,N15-1144,0,0.0230912,"epresent words with dense, lowdimensional and real-valued vectors. Word embeddings have been empirically shown to preserve linguistic information, such as the semantic relationship between words (Mikolov et al., 2013; Pennington et al., 2014) and it helps to learn algorithms to perceive underlying semantics of the targeted task. Over the past few years, researchers have been studying different ways for evaluating word embeddings, including using hypernym-hyponym relation (Fu et al., 2014), word similarity task (Levy and Goldberg, 2014), word analogy taks (Levy et al., 2015), POS tagging task (Lin et al., 2015) and phrase-based machine translation (Zou et al., 2013). Our proposed evaluation approach is complementary to the previous ones. Besides, it is suitable to be used for evaluating phrase embedding. Our work is inspired by previous works on supervised coreference research which show that incorporating external knowledge can improve the performance of a coreference system (CR). A variety of approaches (Ng, 2007; Ponzetto and Strube, 2006; Haghighi and Klein, 2009) have 409 been shown to benefit from using external resources such as Wikipedia (Strube and Ponzetto, 2006; Ponzetto and Strube, 2007;"
L18-1062,P16-1101,0,0.101334,"g E(p) is: np 1 X wk E(p) = np k=1 where E(p), wk ∈ Rde and de is a hyper-parameter, indicating word embedding size. Then, we compute the similarity score of the phrase pair as follows. Sim(p1 , p2 ) = cosine(p1 , p2 ) = pT1 p2 ||p1 |p2 || The “Mention Embeddings + FFNN” baseline construct mention representations like previous baseline but compute score using a two-layer feed-forward neural network. Sim(p1 , p2 ) = σ(uT tanh(W [E(p1 ), E(p2 )] + b)) where W ∈ Rde ×de , b, u ∈ Rde , and [E(p1 ), E(p2 )] represents concatenation of the phrase embedding pair. Inspired by (Chiu and Nichols, 2016; Ma and Hovy, 2016), we also provide a more sophisticated baseline by using bidirectional long-short term memory (LSTM) (Hochreiter and Schmidhuber, 1997) and convolutional neural network (CNN) (LeCun et al., 1998; Kalchbrenner et al., 2014) in combinations to construct mention representation and using a feed-forward neural network to score mention antecedent pairs. A general architecture for the proposed baseline methods is shown in Fig. 1. ˜ We use a shallow bi-directional LSTM with hidden size h to encode contextual embeddings p˜t of each word in the phrase, → − → − h t = LST M ( h t−1 , wt ), t = 1, . . . ,"
L18-1062,W99-0212,0,0.128822,"8). More recent works (Mikolov et al., 2013; Pennington et al., 2014) uses log-bilinear models to learn continuous representations of words on large corpora efficiently. While these vector representations capture finegrained syntactic and semantic regularities among words or phrases, it often lacks coreferential information. For example, “phd student” and “graduate fellow” can be co-referred to each other and this relationship should be recognized by semantic representations. Refer-to-as relation information can benefit many natural language processing applications such as question answering (Morton, 1999), information extraction (Humphreys et al., 1997; Zelenko et al., 2004) etc. So, in this paper, we focus on the task of resolving refer-to-as relation between nominals. We design a coreferential phrase prediction task by simplifying the coreference resolution task to evaluate the utility of our proposed corpus. The automatic resolution of identifying surface forms (a.k.a mentions) which co-refer to the same abstract entity is a challenging task with a long history in computational linguistics. For example, given a paragraph, “A female motorist wearing a blue shirt abruptly made a left turn, ig"
L18-1062,D13-1141,0,0.0562676,"Missing"
L18-1062,D14-1162,0,0.107108,"s are missing. In this work, we develop a dataset from Wikipedia which can aid in learning and evaluating refer-to-as relations between a group of words which act as a noun phrase. Furthermore, the developed dataset can be leveraged to construct semantic space representations for the coreferential nominals. Learning semantic representations for words from large unlabeled corpora (ex., Wikipedia) using co-occurrence statistics has a long history in natural language processing (Deerwester et al., 1990; Lund and Burgess, 1996; Collobert and Weston, 2008). More recent works (Mikolov et al., 2013; Pennington et al., 2014) uses log-bilinear models to learn continuous representations of words on large corpora efficiently. While these vector representations capture finegrained syntactic and semantic regularities among words or phrases, it often lacks coreferential information. For example, “phd student” and “graduate fellow” can be co-referred to each other and this relationship should be recognized by semantic representations. Refer-to-as relation information can benefit many natural language processing applications such as question answering (Morton, 1999), information extraction (Humphreys et al., 1997; Zelenk"
L18-1062,N06-1025,0,0.0418636,"s, including using hypernym-hyponym relation (Fu et al., 2014), word similarity task (Levy and Goldberg, 2014), word analogy taks (Levy et al., 2015), POS tagging task (Lin et al., 2015) and phrase-based machine translation (Zou et al., 2013). Our proposed evaluation approach is complementary to the previous ones. Besides, it is suitable to be used for evaluating phrase embedding. Our work is inspired by previous works on supervised coreference research which show that incorporating external knowledge can improve the performance of a coreference system (CR). A variety of approaches (Ng, 2007; Ponzetto and Strube, 2006; Haghighi and Klein, 2009) have 409 been shown to benefit from using external resources such as Wikipedia (Strube and Ponzetto, 2006; Ponzetto and Strube, 2007; Singh et al., 2012; Spitkovsky and Chang, 2012), WordNet (Harabagiu et al., 2001; Soon et al., 2001) or YAGO (Suchanek et al., 2007). (Rahman and Ng, 2011) examined the utility of three major sources of world knowledge and applied them to two learning-based coreference models and found improved performance when knowledge extracted from different sources are exploited in combination rather than individually. Also, previous works (Ogrod"
L18-1062,W12-4501,0,0.0167416,"usefulness of embeddings to train supervised learning algorithms for antecedent ranking. We train an end-to-end model to produce phrase embeddings based on the training set, tune the model on the development set, and compute accuracy of the ranking based on evaluation dataset. We allow a model to use a pre-trained word embedding for initialization purpose. We construct the training and development dataset from the corpus we generated from Wikipedia and the evaluation dataset based on OntoNotes V5.0 corpus (Hovy et al., 2006) that used in the CoNLL shared task 2012 for coreference resolution (Pradhan et al., 2012). Table 2 lists the complete details of the extracted dataset. We get coreferential mention clusters from the corpus we generate as described in section 2. Negative examples are 2 https://github.com/wasiahmad/mining_ wikipedia/tree/master/WikiMiner 407 Figure 1: Neural network architecture to rank candidate mentions of a target mention Train (src: Wikipedia) Development (src: Wikipedia) Test (src: CoNLL) Total nominal coref. chain Avg. candidates per chain Total unique terms Total nominal coref. chain Avg. candidates per chain Total unique terms Total nominal coref. chain Avg. candidates per c"
L18-1062,P14-2006,0,0.0184797,"d 2 with 256 feature maps each. Gradient clipping technique (5.0) (Graves, 2013) and dropout (0.1) (Srivastava et al., 2014) were used. We use pre-trained GloVe embeddings (Pennington et al., 2014) and fix them during training. Out-of-vocabulary words were initialized with zero vectors. 4. Evaluation Metrics and Baseline Results In this section, we present the details of evaluation metrics and the performances of baseline methods. Evaluation Metrics. In tradition, researchers treat coreference resolution as a supervised clustering problem and evaluate system performance by clustering metrics (Pradhan et al., 2014). However, this evaluation metric does not align with our goal of ranking antecedents for a given target mention. Therefore, we evaluate the performance by Mean Average Precision (MAP), Precision at k (P @k), Recall at k (R@k). We also report the negative log-likelihood loss for the baseline methods. Results. The performance comparison based on the evaluation dataset between baseline models is presented in Table 4. For our proposed phrase embeddings evaluation task, averaging word vectors is a strong baseline, even without accessing training dataset, it achieves better results to the trained n"
L18-1062,P11-1082,0,0.0237209,"s, it is suitable to be used for evaluating phrase embedding. Our work is inspired by previous works on supervised coreference research which show that incorporating external knowledge can improve the performance of a coreference system (CR). A variety of approaches (Ng, 2007; Ponzetto and Strube, 2006; Haghighi and Klein, 2009) have 409 been shown to benefit from using external resources such as Wikipedia (Strube and Ponzetto, 2006; Ponzetto and Strube, 2007; Singh et al., 2012; Spitkovsky and Chang, 2012), WordNet (Harabagiu et al., 2001; Soon et al., 2001) or YAGO (Suchanek et al., 2007). (Rahman and Ng, 2011) examined the utility of three major sources of world knowledge and applied them to two learning-based coreference models and found improved performance when knowledge extracted from different sources are exploited in combination rather than individually. Also, previous works (Ogrodniczuk, 2013) verified that nominal facts extracted from world knowledge resources effectively perform and can be used as a source of pragmatic knowledge for coreference resolution. 6. Conclusion and Future Work In this work, we propose a corpus to learn refer-to-as relations for nominals extracted from Wikipedia in"
L18-1062,N04-1002,0,0.188788,"Missing"
L18-1062,J01-4004,0,0.274198,"pproach is complementary to the previous ones. Besides, it is suitable to be used for evaluating phrase embedding. Our work is inspired by previous works on supervised coreference research which show that incorporating external knowledge can improve the performance of a coreference system (CR). A variety of approaches (Ng, 2007; Ponzetto and Strube, 2006; Haghighi and Klein, 2009) have 409 been shown to benefit from using external resources such as Wikipedia (Strube and Ponzetto, 2006; Ponzetto and Strube, 2007; Singh et al., 2012; Spitkovsky and Chang, 2012), WordNet (Harabagiu et al., 2001; Soon et al., 2001) or YAGO (Suchanek et al., 2007). (Rahman and Ng, 2011) examined the utility of three major sources of world knowledge and applied them to two learning-based coreference models and found improved performance when knowledge extracted from different sources are exploited in combination rather than individually. Also, previous works (Ogrodniczuk, 2013) verified that nominal facts extracted from world knowledge resources effectively perform and can be used as a source of pragmatic knowledge for coreference resolution. 6. Conclusion and Future Work In this work, we propose a corpus to learn refer-t"
L18-1062,spitkovsky-chang-2012-cross,0,0.0176036,"hine translation (Zou et al., 2013). Our proposed evaluation approach is complementary to the previous ones. Besides, it is suitable to be used for evaluating phrase embedding. Our work is inspired by previous works on supervised coreference research which show that incorporating external knowledge can improve the performance of a coreference system (CR). A variety of approaches (Ng, 2007; Ponzetto and Strube, 2006; Haghighi and Klein, 2009) have 409 been shown to benefit from using external resources such as Wikipedia (Strube and Ponzetto, 2006; Ponzetto and Strube, 2007; Singh et al., 2012; Spitkovsky and Chang, 2012), WordNet (Harabagiu et al., 2001; Soon et al., 2001) or YAGO (Suchanek et al., 2007). (Rahman and Ng, 2011) examined the utility of three major sources of world knowledge and applied them to two learning-based coreference models and found improved performance when knowledge extracted from different sources are exploited in combination rather than individually. Also, previous works (Ogrodniczuk, 2013) verified that nominal facts extracted from world knowledge resources effectively perform and can be used as a source of pragmatic knowledge for coreference resolution. 6. Conclusion and Future Wo"
L18-1062,C08-1114,0,0.0335723,"on task where the learned nominal embeddings are used to predict which candidate nominals can be referred to a target nominal. We further describe how to construct an evaluation dataset for such task from well known OntoNotes corpus and demonstrate encouraging baseline results. Keywords: Nominals, Coreference, Refer-to-as relation 1. Introduction Understanding relations between words and phrases is a long-standing problem in natural language processing. Various resources are collected and utilized in order to understand different types of relations between words, including synonymy, antonymy (Turney, 2008) and hierarchical relationships such as hyponymy and hypernymy (Fu et al., 2014). Coreference (a.k.a refer-to-as) relation is another important type of relations between words and phrases and has a wide range of potential applications. Previous work (Feng et al., 2015) found both textual and visual information helpful to learn refer-to-as relations between words. However, annotated data for coreferent phrases are missing. In this work, we develop a dataset from Wikipedia which can aid in learning and evaluating refer-to-as relations between a group of words which act as a noun phrase. Furtherm"
L18-1062,P15-1137,0,0.0165494,"hrase Embeddings We propose to use coreference relationship to evaluate word and phrase embedding. It is important to note that, co-occurrence and coreference are not the same concepts. For example, “lazy dog” and “attractive cat” are very close in the low dimensional embedding space because of high co-occurrence of the words “dog” and “cat” but they cannot be co-referred. On the other hand, “phd candidate” and “graduate student” can be co-referred to each other. As we mentioned, we reduce the coreference resolution problem to an antecedent ranking problem, since many state-of-the-art models (Wiseman et al., 2015; Chang et al., 2013; Durrett and Klein, 2013) are a variant of the mentionranking model (Denis and Baldridge, 2008). We define the antecedent ranking problem as, given a target mention, the goal is to rank all antecedent mentions in the same document based on predicted scores such that the antecedent mentions referred to the target mention are ranked on the top. We propose to evaluate phrase embeddings to estimate the usefulness of embeddings to train supervised learning algorithms for antecedent ranking. We train an end-to-end model to produce phrase embeddings based on the training set, tun"
L18-1062,W04-0704,0,0.0476766,"2014) uses log-bilinear models to learn continuous representations of words on large corpora efficiently. While these vector representations capture finegrained syntactic and semantic regularities among words or phrases, it often lacks coreferential information. For example, “phd student” and “graduate fellow” can be co-referred to each other and this relationship should be recognized by semantic representations. Refer-to-as relation information can benefit many natural language processing applications such as question answering (Morton, 1999), information extraction (Humphreys et al., 1997; Zelenko et al., 2004) etc. So, in this paper, we focus on the task of resolving refer-to-as relation between nominals. We design a coreferential phrase prediction task by simplifying the coreference resolution task to evaluate the utility of our proposed corpus. The automatic resolution of identifying surface forms (a.k.a mentions) which co-refer to the same abstract entity is a challenging task with a long history in computational linguistics. For example, given a paragraph, “A female motorist wearing a blue shirt abruptly made a left turn, ignoring the officer’s attempt to initiate a traffic stop. The driver con"
L18-1190,bongelli-etal-2012-corpus,0,0.20907,"to drug-food interaction or drug-activity interaction are scattered through the document and patients face difficulties in finding them. Also, the structure and organization of information varies from one source to another. Such irregular organization and structural variety across sources pose a challenge to automatically extract critical information from the DUG documents. Therefore, there is a need for an annotated corpus for DUG documents. Currently, there are several annotated medical corpora (Saeed et al., 2011), (Aronson and Lang, 2010), (Uzuner et al., 2007), (Pardelli et al., 2012), (Bongelli et al., 2012) that contain clinical notes, bio-medical textual contents, and electronic health records. There are some existing annotation tools and techniques than focus on annotating electronic health records (Roberts and Demner-Fushman, 2016) and clinical practice guidelines (Read et al., 2016) and extracting relations from bio-medical text (Ellendorff et al., 2014). But to the best of our knowledge, there is no existing work that focuses on annotating and analyzing the textual content of such documents. So, we introduce a DUG data annotation scheme, an annotation tool, and an annotated corpus as presen"
L18-1190,ellendorff-etal-2014-using,0,0.178954,"om the DUG documents. Therefore, there is a need for an annotated corpus for DUG documents. Currently, there are several annotated medical corpora (Saeed et al., 2011), (Aronson and Lang, 2010), (Uzuner et al., 2007), (Pardelli et al., 2012), (Bongelli et al., 2012) that contain clinical notes, bio-medical textual contents, and electronic health records. There are some existing annotation tools and techniques than focus on annotating electronic health records (Roberts and Demner-Fushman, 2016) and clinical practice guidelines (Read et al., 2016) and extracting relations from bio-medical text (Ellendorff et al., 2014). But to the best of our knowledge, there is no existing work that focuses on annotating and analyzing the textual content of such documents. So, we introduce a DUG data annotation scheme, an annotation tool, and an annotated corpus as presented in the following sections. 3. Data Annotation Scheme While a DUG document contains an array of information, not all information is critical to patients (Yi et al., 1187 1. Activity or lifestyle related advice: to indicate potential interaction between the corresponding drug and any activity of daily living (e.g., driving). For instance, from Table 1, d"
L18-1190,pardelli-etal-2012-medical,0,0.222837,"Missing"
L18-1190,L18-1190,1,0.0513136,"h on extracting critical information from DUG data to increase drug safety. To bridge this knowledge gap, we develop a novel annotation scheme and a novel, interactive annotation tool to annotate textual ad1186 vice statements from DUG documents according to their topics. This annotation tool is used to annotate a corpus of 90 online DUG documents and 9,831 sentences. The multi-label annotation results in the first annotated corpus of DUG documents containing 1,611 annotated safety critical drug usage guidelines. We make the annotation tool and the annotated corpus available to the community (Preum et al., 2018). These resources can aid the release of more annotated datasets of DUG documents and accelerate NLP research on automatic extraction of safety critical information from these textual documents. 2. 2015). We develop the following multi-label data annotation scheme to annotate the critical advice statements of DUG documents in 8 categories. Background In this section we briefly introduce the drug usage guideline (DUG) data and the relevant existing research. The DUG documents contain a variety of information spanning different topics, which can be broadly categorized in following classes. (i) b"
L18-1190,L16-1272,0,0.0855818,"s pose a challenge to automatically extract critical information from the DUG documents. Therefore, there is a need for an annotated corpus for DUG documents. Currently, there are several annotated medical corpora (Saeed et al., 2011), (Aronson and Lang, 2010), (Uzuner et al., 2007), (Pardelli et al., 2012), (Bongelli et al., 2012) that contain clinical notes, bio-medical textual contents, and electronic health records. There are some existing annotation tools and techniques than focus on annotating electronic health records (Roberts and Demner-Fushman, 2016) and clinical practice guidelines (Read et al., 2016) and extracting relations from bio-medical text (Ellendorff et al., 2014). But to the best of our knowledge, there is no existing work that focuses on annotating and analyzing the textual content of such documents. So, we introduce a DUG data annotation scheme, an annotation tool, and an annotated corpus as presented in the following sections. 3. Data Annotation Scheme While a DUG document contains an array of information, not all information is critical to patients (Yi et al., 1187 1. Activity or lifestyle related advice: to indicate potential interaction between the corresponding drug and an"
L18-1190,L16-1598,0,0.102977,"er. Such irregular organization and structural variety across sources pose a challenge to automatically extract critical information from the DUG documents. Therefore, there is a need for an annotated corpus for DUG documents. Currently, there are several annotated medical corpora (Saeed et al., 2011), (Aronson and Lang, 2010), (Uzuner et al., 2007), (Pardelli et al., 2012), (Bongelli et al., 2012) that contain clinical notes, bio-medical textual contents, and electronic health records. There are some existing annotation tools and techniques than focus on annotating electronic health records (Roberts and Demner-Fushman, 2016) and clinical practice guidelines (Read et al., 2016) and extracting relations from bio-medical text (Ellendorff et al., 2014). But to the best of our knowledge, there is no existing work that focuses on annotating and analyzing the textual content of such documents. So, we introduce a DUG data annotation scheme, an annotation tool, and an annotated corpus as presented in the following sections. 3. Data Annotation Scheme While a DUG document contains an array of information, not all information is critical to patients (Yi et al., 1187 1. Activity or lifestyle related advice: to indicate potent"
N18-1093,N09-1003,0,0.114939,"Missing"
N18-1093,P12-1015,0,0.0356884,"word pairs and an annotated similarity score. The goal is to predict the similarity score between two words based on the inner product between the corresponding word vectors. The performance is then measured by the Spearmans rank correlation coefficient, which estimates the correlation between the model predictions and human annotations. Following the settings in literature, the experiments are conducted on five data sets, WordSim353 (Finkelstein et al., 2001), WordSim Similarity (Zesch et al., 2008), WordSim Relatedness (Agirre et al., 2009), Mechanical Turk (Radinsky et al., 2011) and MEN (Bruni et al., 2012). In the word analogy task, we aim at solving analogy puzzles like “man is to woman as king is to ?”, where the expected answer is “queen.” We consider two approaches for generating answers to the puzzles, namely 3CosAdd and 3CosMul (see (Levy and Goldberg, 2014a) for details). We evaluate the performances on Google analogy dataset (Mikolov et al., 2013a) which contains 8,860 semantic and 10,675 syntactic questions. For the analogy task, only the answer that exactly matches the annotated answer is counted as correct. As a result, the analogy task is more difficult than the similarity task beca"
N18-1093,W14-1618,0,0.192618,"ng word representations has become a fundamental problem in processing natural languages. These semantic representations, which map a word into a point in a linear space, have been widely applied in downstream applications, including named entity recognition (Guo et al., 2014), document ranking (Nalisnick et al., 2016), sentiment analysis (Irsoy and Cardie, 2014), question answering (Antol et al., 2015), and image captioning (Karpathy and Fei-Fei, 2015). Over the past few years, various approaches have been proposed to learn word vectors (e.g., (Pennington et al., 2014; Mikolov et al., 2013a; Levy and Goldberg, 2014b; Ji et al., 2015)) based on co-occurrence information between words observed on the training corpus. The intuition behind this is to represent words with similar vectors if they have similar contexts. To learn a good word embedding, most approaches assume a large collection of text is freely available, such that the estimation of word co-occurrences is accurate. For example, the Google Word2Vec model (Mikolov et al., 2013a) is trained on the Google News dataset, which contains around 100 billion tokens, and the GloVe embedding (Pennington et al., 2014) is trained on a crawled corpus that con"
N18-1093,D14-1165,1,0.810929,"blem. • Our experimental results show that PULearning improves the word embedding training in the low-resource setting. 2 Related work Learning word vectors. The idea of learning word representations can be traced back to Latent Semantic Analysis (LSA) (Deerwester et al., 1990) and Hyperspace Analogue to Language (HAL) (Lund and Burgess, 1996), where word vectors are generated by factorizing a worddocument and word-word co-occurrence matrix, respectively. Similar approaches can also be extended to learn other types of relations between words (Yih et al., 2012; Chang et al., 2013) or entities (Chang et al., 2014). However, due to the limitation of the use of principal component analysis, 3 Although English is not a resource-scarce language, we simulate the low-resource setting in an English corpus. In this way, we leverage the existing evaluation methods to evaluate the proposed approach. these approaches are often less flexible. Besides, directly factorizing the co-occurrence matrix may cause the frequent words dominating the training objective. In the past decade, various approaches have been proposed to improve the training of word embeddings. For example, instead of factorizing the co-occurrence c"
N18-1093,D13-1167,1,0.852995,"he corresponding optimization problem. • Our experimental results show that PULearning improves the word embedding training in the low-resource setting. 2 Related work Learning word vectors. The idea of learning word representations can be traced back to Latent Semantic Analysis (LSA) (Deerwester et al., 1990) and Hyperspace Analogue to Language (HAL) (Lund and Burgess, 1996), where word vectors are generated by factorizing a worddocument and word-word co-occurrence matrix, respectively. Similar approaches can also be extended to learn other types of relations between words (Yih et al., 2012; Chang et al., 2013) or entities (Chang et al., 2014). However, due to the limitation of the use of principal component analysis, 3 Although English is not a resource-scarce language, we simulate the low-resource setting in an English corpus. In this way, we leverage the existing evaluation methods to evaluate the proposed approach. these approaches are often less flexible. Besides, directly factorizing the co-occurrence matrix may cause the frequent words dominating the training objective. In the past decade, various approaches have been proposed to improve the training of word embeddings. For example, instead o"
N18-1093,Q15-1016,0,0.41546,"differences in magnitude among entries in the cooccurrence matrix. Extending from the PMI metric, the PPMI metric replaces all the negative entries in PMI matrix by 0: P P M I(w, c) = max(P M I(w, c), 0). (2) The intuition behind this is that people usually perceive positive associations between words (e.g. “ice” and “snow”). In contrast, the negative association is hard to define (Levy and Goldberg, 2014b). Therefore, it is reasonable to replace the negative entries in the PMI matrix by 0, such that the negative association is treated as “uninformative”. Empirically, several existing works (Levy et al., 2015; Bullinaria and Levy, 2007) showed that the PPMI metric achieves good performance on various semantic similarity tasks. In practice, we follow the pipeline described in Levy et al. (2015) to build the PPMI matrix and apply several useful tricks to improve its quality. First, we apply a context distribution smoothing mechanism to enlarge the probability of sampling a rare context. In particular, all context counts are scaled to the power of α.4 : ! Pˆ (w, c) P P M Iα (w, c) = max log ,0 Pˆ (w)Pˆα (c) #(c)α Pˆα (c) = P , c)α c¯ #(¯ where #(w) denotes the number of times word w appears. This smo"
N18-1093,J90-1003,0,0.485252,"ccurrence matrix and generate word vectors and context vectors. Finally, a post-processing step generates the final embedding vector for each word by combining the word vector and the context vector. We summarize the notations used in this paper in Table 1 and describe the details of each step in the remainder of this section. 3.1 Building the Co-Occurrence Matrix Various metrics can be used for estimating the co-occurrence between words in a corpus. PPMI metric stems from point-wise mutual information (PMI) which has been widely used as a measure of word association in NLP for various tasks (Church and Hanks, 1990). In our case, each entry P M I(w, c) represents the relevant measure between a word w and a context word c by calculating the ratio between their joint probability (the chance they appear together in a local context window) and their marginal probabilities (the chance they appear independently) (Levy and Goldberg, 2014b). More specifically, each entry of PMI matrix can be defined by P M I(w, c) = log Pˆ (w, c) , Pˆ (w) · Pˆ (c) (1) where Pˆ (w), Pˆ (c) and Pˆ (w, c) are the the frequency of word w, word c, and word pairs (w, c), respectively. The PMI matrix can be computed based on the co-occ"
N18-1093,D14-1012,0,0.0295179,"ple a few unobserved word pairs as negative samples, we argue that the zero entries in the co-occurrence matrix also provide valuable information. We then design a Positive-Unlabeled Learning (PU-Learning) approach to factorize the co-occurrence matrix and validate the proposed approaches in four different languages. 1 Introduction Learning word representations has become a fundamental problem in processing natural languages. These semantic representations, which map a word into a point in a linear space, have been widely applied in downstream applications, including named entity recognition (Guo et al., 2014), document ranking (Nalisnick et al., 2016), sentiment analysis (Irsoy and Cardie, 2014), question answering (Antol et al., 2015), and image captioning (Karpathy and Fei-Fei, 2015). Over the past few years, various approaches have been proposed to learn word vectors (e.g., (Pennington et al., 2014; Mikolov et al., 2013a; Levy and Goldberg, 2014b; Ji et al., 2015)) based on co-occurrence information between words observed on the training corpus. The intuition behind this is to represent words with similar vectors if they have similar contexts. To learn a good word embedding, most approaches ass"
N18-1093,D14-1162,0,0.126541,"four different languages. 1 Introduction Learning word representations has become a fundamental problem in processing natural languages. These semantic representations, which map a word into a point in a linear space, have been widely applied in downstream applications, including named entity recognition (Guo et al., 2014), document ranking (Nalisnick et al., 2016), sentiment analysis (Irsoy and Cardie, 2014), question answering (Antol et al., 2015), and image captioning (Karpathy and Fei-Fei, 2015). Over the past few years, various approaches have been proposed to learn word vectors (e.g., (Pennington et al., 2014; Mikolov et al., 2013a; Levy and Goldberg, 2014b; Ji et al., 2015)) based on co-occurrence information between words observed on the training corpus. The intuition behind this is to represent words with similar vectors if they have similar contexts. To learn a good word embedding, most approaches assume a large collection of text is freely available, such that the estimation of word co-occurrences is accurate. For example, the Google Word2Vec model (Mikolov et al., 2013a) is trained on the Google News dataset, which contains around 100 billion tokens, and the GloVe embedding (Pennington et al"
N18-1093,P15-1124,0,0.0312995,"Missing"
N18-1093,D12-1111,0,0.0655334,"Missing"
N18-2003,P06-1005,0,0.285446,"Missing"
N18-2003,D16-1245,0,0.0288077,"vant for the co-reference decision. Systems must be able to make correct linking predictions in pro-stereotypical scenarios (solid purple lines) and anti-stereotypical scenarios (dashed purple lines) equally well to pass the test. Importantly, stereotypical occupations are considered based on US Department of Labor statistics. Introduction Coreference resolution is a task aimed at identifying phrases (mentions) referring to the same entity. Various approaches, including rule-based (Raghunathan et al., 2010), feature-based (Durrett and Klein, 2013; Peng et al., 2015a), and neuralnetwork based (Clark and Manning, 2016; Lee et al., 2017) have been proposed. While significant advances have been made, systems carry the risk of relying on societal stereotypes present in training data that could significantly impact their performance for some demographic groups. In this work, we test the hypothesis that coreference systems exhibit gender bias by creating a new challenge corpus, WinoBias.This dataset follows the winograd format (Hirst, 1981; Rahman and Ng, 2012; Peng et al., 2015b), and contains references to people using a vocabulary of 40 occupations. It contains two types of challenge sentences that require l"
N18-2003,J03-4003,0,0.0217566,"sking workers on Amazon Mechnical Turk to annotate all unique spans in the OntoNotes development set.7 4 Results In this section we evaluate of three representative systems: rule based, Rule, (Raghunathan et al., 2010), feature-rich, Feature, (Durrett and Klein, 2013), and end-to-end neural (the current state-ofthe-art), E2E, (Lee et al., 2017). The following sections show that performance on WinoBias reveals gender bias in all systems, that our methods remove such bias, and that systems are less biased on OntoNotes data. 5 To exclude mentions such as “his mother”, we use Collins head finder (Collins, 2003) to identify the head word of each mention, and only consider the mentions whose head word is gender pronoun. 6 We pick more than 900 job titles from a gazetteer. 7 Five turkers were presented with anonymized spans and asked to mark if it indicated male, female, or neither, and if male or female, rewrite it so it refers to the other gender. WinoBias Reveals Gender Bias Table 2 summarizes development set evaluations using all three systems. Systems were evaluated on both types of sentences in WinoBias (T1 and T2), sepa17 Method E2E E2E E2E E2E E2E Feature Feature Feature Feature Feature Rule An"
N18-2003,D13-1203,0,0.518722,"ely. For each example, the gender of the pronominal reference is irrelevant for the co-reference decision. Systems must be able to make correct linking predictions in pro-stereotypical scenarios (solid purple lines) and anti-stereotypical scenarios (dashed purple lines) equally well to pass the test. Importantly, stereotypical occupations are considered based on US Department of Labor statistics. Introduction Coreference resolution is a task aimed at identifying phrases (mentions) referring to the same entity. Various approaches, including rule-based (Raghunathan et al., 2010), feature-based (Durrett and Klein, 2013; Peng et al., 2015a), and neuralnetwork based (Clark and Manning, 2016; Lee et al., 2017) have been proposed. While significant advances have been made, systems carry the risk of relying on societal stereotypes present in training data that could significantly impact their performance for some demographic groups. In this work, we test the hypothesis that coreference systems exhibit gender bias by creating a new challenge corpus, WinoBias.This dataset follows the winograd format (Hirst, 1981; Rahman and Ng, 2012; Peng et al., 2015b), and contains references to people using a vocabulary of 40 o"
N18-2003,D10-1048,0,0.663458,"in solid blue and dashed orange, respectively. For each example, the gender of the pronominal reference is irrelevant for the co-reference decision. Systems must be able to make correct linking predictions in pro-stereotypical scenarios (solid purple lines) and anti-stereotypical scenarios (dashed purple lines) equally well to pass the test. Importantly, stereotypical occupations are considered based on US Department of Labor statistics. Introduction Coreference resolution is a task aimed at identifying phrases (mentions) referring to the same entity. Various approaches, including rule-based (Raghunathan et al., 2010), feature-based (Durrett and Klein, 2013; Peng et al., 2015a), and neuralnetwork based (Clark and Manning, 2016; Lee et al., 2017) have been proposed. While significant advances have been made, systems carry the risk of relying on societal stereotypes present in training data that could significantly impact their performance for some demographic groups. In this work, we test the hypothesis that coreference systems exhibit gender bias by creating a new challenge corpus, WinoBias.This dataset follows the winograd format (Hirst, 1981; Rahman and Ng, 2012; Peng et al., 2015b), and contains referen"
N18-2003,D12-1071,0,0.084662,"us approaches, including rule-based (Raghunathan et al., 2010), feature-based (Durrett and Klein, 2013; Peng et al., 2015a), and neuralnetwork based (Clark and Manning, 2016; Lee et al., 2017) have been proposed. While significant advances have been made, systems carry the risk of relying on societal stereotypes present in training data that could significantly impact their performance for some demographic groups. In this work, we test the hypothesis that coreference systems exhibit gender bias by creating a new challenge corpus, WinoBias.This dataset follows the winograd format (Hirst, 1981; Rahman and Ng, 2012; Peng et al., 2015b), and contains references to people using a vocabulary of 40 occupations. It contains two types of challenge sentences that require linking gendered pronouns to either male or female stereotypical occupations (see the illustrative examples in Figure 1). None of the examples can be disambiguated by the gender of the pronoun but this cue can potentially distract the model. We consider a system to be gender biased if it links pronouns to occupations dominated by the gender of the pronoun (pro-stereotyped condition) more accurately than occupations not dominated by the gender"
N18-2003,W14-3333,0,0.0605286,"Missing"
N18-2003,N18-2002,0,0.196268,"Missing"
N18-2003,D17-1323,1,0.585447,"g coreference models more robust to spurious, genderbiased cues while not incurring significant penalties on their performance on benchmark datasets. Related Work Machine learning methods are designed to generalize from observation but if algorithms inadvertently learn to make predictions based on stereotyped associations they risk amplifying existing social problems. Several problematic instances have been demonstrated, for example, word embeddings can encode sexist stereotypes (Bolukbasi et al., 2016; Caliskan et al., 2017). Similar observations have been made in vision and language models (Zhao et al., 2017), online news (Ross and Carter, 2011), web search (Kay et al., 2015) and advertisements (Sweeney, 2013). In our work, we add a unique focus on co-reference, and propose simple general purpose methods for reducing bias. Implicit human bias can come from imbalanced datasets. When making decisions on such datasets, it is usual that under-represented samples in the data are neglected since they do not influence the overall accuracy as much. For binary classification Kamishima et al. (2012, 2011) add a regularization term to their objective that penalizes biased predictions. Various other approache"
N18-2003,N16-1030,0,0.126287,"Missing"
N18-2003,D17-1018,0,0.42814,"decision. Systems must be able to make correct linking predictions in pro-stereotypical scenarios (solid purple lines) and anti-stereotypical scenarios (dashed purple lines) equally well to pass the test. Importantly, stereotypical occupations are considered based on US Department of Labor statistics. Introduction Coreference resolution is a task aimed at identifying phrases (mentions) referring to the same entity. Various approaches, including rule-based (Raghunathan et al., 2010), feature-based (Durrett and Klein, 2013; Peng et al., 2015a), and neuralnetwork based (Clark and Manning, 2016; Lee et al., 2017) have been proposed. While significant advances have been made, systems carry the risk of relying on societal stereotypes present in training data that could significantly impact their performance for some demographic groups. In this work, we test the hypothesis that coreference systems exhibit gender bias by creating a new challenge corpus, WinoBias.This dataset follows the winograd format (Hirst, 1981; Rahman and Ng, 2012; Peng et al., 2015b), and contains references to people using a vocabulary of 40 occupations. It contains two types of challenge sentences that require linking gendered pro"
N18-2003,K15-1002,1,0.831975,"e gender of the pronominal reference is irrelevant for the co-reference decision. Systems must be able to make correct linking predictions in pro-stereotypical scenarios (solid purple lines) and anti-stereotypical scenarios (dashed purple lines) equally well to pass the test. Importantly, stereotypical occupations are considered based on US Department of Labor statistics. Introduction Coreference resolution is a task aimed at identifying phrases (mentions) referring to the same entity. Various approaches, including rule-based (Raghunathan et al., 2010), feature-based (Durrett and Klein, 2013; Peng et al., 2015a), and neuralnetwork based (Clark and Manning, 2016; Lee et al., 2017) have been proposed. While significant advances have been made, systems carry the risk of relying on societal stereotypes present in training data that could significantly impact their performance for some demographic groups. In this work, we test the hypothesis that coreference systems exhibit gender bias by creating a new challenge corpus, WinoBias.This dataset follows the winograd format (Hirst, 1981; Rahman and Ng, 2012; Peng et al., 2015b), and contains references to people using a vocabulary of 40 occupations. It cont"
N18-2003,N15-1082,0,0.0545365,"e gender of the pronominal reference is irrelevant for the co-reference decision. Systems must be able to make correct linking predictions in pro-stereotypical scenarios (solid purple lines) and anti-stereotypical scenarios (dashed purple lines) equally well to pass the test. Importantly, stereotypical occupations are considered based on US Department of Labor statistics. Introduction Coreference resolution is a task aimed at identifying phrases (mentions) referring to the same entity. Various approaches, including rule-based (Raghunathan et al., 2010), feature-based (Durrett and Klein, 2013; Peng et al., 2015a), and neuralnetwork based (Clark and Manning, 2016; Lee et al., 2017) have been proposed. While significant advances have been made, systems carry the risk of relying on societal stereotypes present in training data that could significantly impact their performance for some demographic groups. In this work, we test the hypothesis that coreference systems exhibit gender bias by creating a new challenge corpus, WinoBias.This dataset follows the winograd format (Hirst, 1981; Rahman and Ng, 2012; Peng et al., 2015b), and contains references to people using a vocabulary of 40 occupations. It cont"
N18-2003,P14-2006,0,0.0280206,"re evaluated once on test sets, Table 3, supporting our conclusions. Table 4: Performance on the original and the genderreversed developments dataset (anonymized). rately in pro-stereotyped and anti-stereotyped conditions ( T1-p vs. T1-a, T2-p vs T2-a). We evaluate the effect of named-entity anonymization (Anon.), debiasing supporting resources8 (Resour.) and using data-augmentation through gender swapping (Aug.). E2E and Feature were retrained in each condition using default hyperparameters while Rule was not debiased because it is untrainable. We evaluate using the coreference scorer v8.01 (Pradhan et al., 2014) and compute the average (Avg) and absolute difference (Diff) between pro-stereotyped and antistereotyped conditions in WinoBias. All initial systems demonstrate severe disparity between pro-stereotyped and anti-stereotyped conditions. Overall, the rule based system is most biased, followed by the neural approach and feature rich approach. Across all conditions, anonymization impacts E2E the most, while all other debiasing methods result in insignificant loss 8 Systems Demonstrate Less Bias on OntoNotes While we have demonstrated co-reference systems have severe bias as measured in WinoBias ,"
N19-1064,N18-2108,0,0.0397238,"Missing"
N19-1064,W19-3821,0,0.0769635,"Missing"
N19-1064,W19-3621,0,0.255063,"f word representations. In contrast, we analyze bias in contextualized word representations and its effect on a downstream task. To mitigate bias from word embeddings, Bolukbasi et al. (2016) propose a post-processing method to project out the bias subspace from the pre-trained embeddings. Their method is shown to reduce the gender information from the embeddings of gender-neutral words, and, remarkably, maintains the same level of performance on different downstream NLP tasks. Zhao et al. (2018b) further propose a training mechanism to separate gender information from other factors. However, Gonen and Goldberg (2019) argue that entirely removing bias is difficult, if not impossible, and the gender bias information can be often recovered. This paper investigates a natural follow-up question: What are effective bias mitigation techniques for contextualized embeddings? 3 Gender Bias in ELMo In this section we describe three intrinsic analyses highlighting gender bias in trained ELMo contextual word embeddings (Peters et al., 2018). We show that (1) training data for ELMo contains sig#occurrence 5,300,000 1,600,000 #M-biased occs. 170,000 33,000 #F-biased occs. 81,000 36,000 Table 1: Training corpus for ELMo."
N19-1064,W14-3333,0,0.0320149,"Missing"
N19-1064,D17-1018,0,0.0922775,"Missing"
N19-1064,N19-1063,0,0.127097,"s in the training data but also amplifies it (Zhao et al., 2017). For word representations, Bolukbasi et al. (2016) and Caliskan et al. (2017) show that word embeddings encode societal biases about gender roles and occupations, e.g. engineers are stereotypically men, and nurses are stereotypically women. As a consequence, downstream applications that use these pretrained word embeddings also reflect this bias. For example, Zhao et al. (2018a) and Rudinger et al. (2018) show that coreference resolution systems relying on word embeddings encode such occupational stereotypes. In concurrent work, May et al. (2019) measure gender bias in sentence embeddings, but their evaluation is on the aggregation of word representations. In contrast, we analyze bias in contextualized word representations and its effect on a downstream task. To mitigate bias from word embeddings, Bolukbasi et al. (2016) propose a post-processing method to project out the bias subspace from the pre-trained embeddings. Their method is shown to reduce the gender information from the embeddings of gender-neutral words, and, remarkably, maintains the same level of performance on different downstream NLP tasks. Zhao et al. (2018b) further"
N19-1064,D18-1302,0,0.0317387,"ce with entities of the opposite gender. Results show that testtime embedding neutralization is only partially effective, while data augmentation largely mitigates bias demonstrated on WinoBias by the coreference 629 Proceedings of NAACL-HLT 2019, pages 629–634 c Minneapolis, Minnesota, June 2 - June 7, 2019. 2019 Association for Computational Linguistics system. 2 M F Related Work Gender bias has been shown to affect several realworld applications relying on automatic language analysis, including online news (Ross and Carter, 2011), advertisements (Sweeney, 2013), abusive language detection (Park et al., 2018), machine translation (Font and Costa-juss`a, 2019; Vanmassenhove et al., 2018), and web search (Kay et al., 2015). In many cases, a model not only replicates bias in the training data but also amplifies it (Zhao et al., 2017). For word representations, Bolukbasi et al. (2016) and Caliskan et al. (2017) show that word embeddings encode societal biases about gender roles and occupations, e.g. engineers are stereotypically men, and nurses are stereotypically women. As a consequence, downstream applications that use these pretrained word embeddings also reflect this bias. For example, Zhao et al."
N19-1064,N15-1082,0,0.0217537,"the information unequally for male and female entities. We use the list collected in (Zhao et al., 2018a) Bias in Coreference Resolution In this section, we establish that coreference systems that depend on ELMo embeddings exhibit significant gender bias. Then we evaluate two simple methods for removing the bias from the systems and show that the bias can largely be reduced. 4.1 Setup We evaluate bias with respect to the WinoBias dataset (Zhao et al., 2018a), a benchmark of paired male and female coreference resolution examples following the Winograd format (Hirst, 1981; Rahman and Ng, 2012; Peng et al., 2015). It contains two different subsets, pro-stereotype, where pronouns are associated with occupations predominately associated with the gender of the pronoun, or anti-stereotype, when the opposite relation is true. 2 We use the ν-SVC formulation and tune the hyperparameter ν (Chang and Lin, 2011) in the range of [0.1, 1] with a step 0.1. 631 Embeddings Data Augmentation Neutralization GloVe ELMo GloVe GloVe GloVe+ELMo GloVe+ELMo GloVe+ELMo GloVe+ELMo OntoNotes Pro. 76.0 63.9 79.1 65.9 72.6 71.7 67.7 65.8 72.7 71.0 71.0 71.1 Semantics Only Anti. Avg. |Diff | 49.4 62.7 26.6* 62.8 63.4 1.1 49.5 64."
N19-1064,D14-1162,0,0.0952619,"Missing"
N19-1064,N18-1202,0,0.489748,"ned ELMo embeddings systematically encode gender information and (3) ELMo unequally encodes gender information about male and female entities. Then, we show that a state-of-the-art coreference system that depends on ELMo inherits its bias and demonstrates significant bias on the WinoBias probing corpus. Finally, we explore two methods to mitigate such gender bias and show that the bias demonstrated on WinoBias can be eliminated. 1 Introduction Distributed representations of words in the form of word embeddings (Mikolov et al., 2013; Pennington et al., 2014) and contextualized word embeddings (Peters et al., 2018; Devlin et al., 2018; Radford et al., 2018; McCann et al., 2017; Radford et al., 2019) have led to huge performance improvement on many NLP tasks. However, several recent studies show that training word embeddings in large corpora could lead to encoding societal biases present in these human-produced data (Bolukbasi et al., 2016; Caliskan et al., 2017). In this work, we extend these analyses to the ELMo contextualized word embeddings. Our work provides a new intrinsic analysis of how ELMo represents gender in biased ways. First, the corpus used for training ELMo has a significant gender skew:"
N19-1064,D12-1071,0,0.0321936,"that ELMo propagates the information unequally for male and female entities. We use the list collected in (Zhao et al., 2018a) Bias in Coreference Resolution In this section, we establish that coreference systems that depend on ELMo embeddings exhibit significant gender bias. Then we evaluate two simple methods for removing the bias from the systems and show that the bias can largely be reduced. 4.1 Setup We evaluate bias with respect to the WinoBias dataset (Zhao et al., 2018a), a benchmark of paired male and female coreference resolution examples following the Winograd format (Hirst, 1981; Rahman and Ng, 2012; Peng et al., 2015). It contains two different subsets, pro-stereotype, where pronouns are associated with occupations predominately associated with the gender of the pronoun, or anti-stereotype, when the opposite relation is true. 2 We use the ν-SVC formulation and tune the hyperparameter ν (Chang and Lin, 2011) in the range of [0.1, 1] with a step 0.1. 631 Embeddings Data Augmentation Neutralization GloVe ELMo GloVe GloVe GloVe+ELMo GloVe+ELMo GloVe+ELMo GloVe+ELMo OntoNotes Pro. 76.0 63.9 79.1 65.9 72.6 71.7 67.7 65.8 72.7 71.0 71.0 71.1 Semantics Only Anti. Avg. |Diff | 49.4 62.7 26.6* 62"
N19-1064,N18-2002,0,0.15905,"Missing"
N19-1064,N18-2003,1,0.935115,"al., 2018), machine translation (Font and Costa-juss`a, 2019; Vanmassenhove et al., 2018), and web search (Kay et al., 2015). In many cases, a model not only replicates bias in the training data but also amplifies it (Zhao et al., 2017). For word representations, Bolukbasi et al. (2016) and Caliskan et al. (2017) show that word embeddings encode societal biases about gender roles and occupations, e.g. engineers are stereotypically men, and nurses are stereotypically women. As a consequence, downstream applications that use these pretrained word embeddings also reflect this bias. For example, Zhao et al. (2018a) and Rudinger et al. (2018) show that coreference resolution systems relying on word embeddings encode such occupational stereotypes. In concurrent work, May et al. (2019) measure gender bias in sentence embeddings, but their evaluation is on the aggregation of word representations. In contrast, we analyze bias in contextualized word representations and its effect on a downstream task. To mitigate bias from word embeddings, Bolukbasi et al. (2016) propose a post-processing method to project out the bias subspace from the pre-trained embeddings. Their method is shown to reduce the gender info"
N19-1064,D18-1521,1,0.888165,"al., 2018), machine translation (Font and Costa-juss`a, 2019; Vanmassenhove et al., 2018), and web search (Kay et al., 2015). In many cases, a model not only replicates bias in the training data but also amplifies it (Zhao et al., 2017). For word representations, Bolukbasi et al. (2016) and Caliskan et al. (2017) show that word embeddings encode societal biases about gender roles and occupations, e.g. engineers are stereotypically men, and nurses are stereotypically women. As a consequence, downstream applications that use these pretrained word embeddings also reflect this bias. For example, Zhao et al. (2018a) and Rudinger et al. (2018) show that coreference resolution systems relying on word embeddings encode such occupational stereotypes. In concurrent work, May et al. (2019) measure gender bias in sentence embeddings, but their evaluation is on the aggregation of word representations. In contrast, we analyze bias in contextualized word representations and its effect on a downstream task. To mitigate bias from word embeddings, Bolukbasi et al. (2016) propose a post-processing method to project out the bias subspace from the pre-trained embeddings. Their method is shown to reduce the gender info"
P09-2072,P02-1002,0,0.140119,"2σ 2 w x t (3) 1 A complete version of this work is at http: //www.csie.ntu.edu.tw/˜cjlin/papers/ maxent_journal.pdf. where σ is a regularization parameter. We focus on (3) instead of (2) because (3) is strictly convex. Iterative scaling (IS) methods are popular in training Maxent models. They all share the same property of solving a one-variable sub-problem at a time. Existing IS methods include generalized iterative scaling (GIS) by Darroch and Ratcliff (1972), improved iterative scaling (IIS) by Della Pietra et al. (1997), and sequential conditional generalized iterative scaling (SCGIS) by Goodman (2002). In optimization, coordinate descent (CD) is a popular method which also solves a one-variable sub-problem at a time. With these many IS and CD methods, it is uneasy to see their differences. In Section 2, we propose a unified framework to describe IS and CD methods from an optimization viewpoint. Using this framework, we design a fast CD approach for Maxent in Section 3. In Section 4, we compare the proposed CD method with IS and LBFGS methods. Results show that the CD method is more efficient. Notation n is the number of features. The total number of nonzeros in samples and the average numb"
P09-2072,W02-2018,0,0.123738,"Missing"
P09-2072,E06-1011,0,\N,Missing
P09-2072,J96-1002,0,\N,Missing
P09-2072,P07-1104,0,\N,Missing
P18-1221,I17-2009,1,0.699848,"Missing"
P18-1221,P00-1037,0,0.453984,"Missing"
P18-1221,J92-4003,0,0.561568,"ur proposed method significantly outperforms state-of-the-art neural network based language models and also the models with type information added as an extra feature. Overall, followings are our contributions: • We analyze two benchmark language corpora where each consists of a reasonable number of entity names. While we leverage an existing corpus for recipe, we curated the code 2 Related Work and Background Class Based Language Models. Building language models by leveraging the deterministic or probabilistic class properties of the words (a.k.a, class-based language models) is an old idea (Brown et al., 1992; Goodman, 2001). However, the objective of our model is different from the existing class-based language models. The key differences are two-folds: 1) Most existing class-based language models (Brown et al., 1992; Pereira et al., 1993; Niesler et al., 1998; Baker and McCallum, 1998; Goodman, 2001; Maltese et al., 2001) are generative n-gram models whereas ours is a discriminative language model based on neural networks. The modeling principle and assumptions are very different. For example, we cannot calculate the conditional probability by statistical occurrence counting as these papers did."
P18-1221,D17-1195,0,0.0420386,"ent. For example, we cannot calculate the conditional probability by statistical occurrence counting as these papers did. 2) Our approaches consider building two models and perform joint inference which makes our framework general and easy to extend. In Section 4, we demonstrate that our model can be easily incorporated with the state-of-art language model. The closest work in this line is hierarchical neural language models (Morin and Bengio, 2005), which model language with word clusters. However, their approaches do not focus on dealing with named entities as our model does. A recent work (Ji et al., 2017) studied the problem of building up a dynamic representation of named entity by updating the representation for every contextualized mention of that entity. Nonetheless, their approach does not deal with the sparsity issue and their goal is different from ours. Language Models for Named Entities. In some generation tasks, recently developed language models address the problem of predict2374 3 https://github.com/uclanlp/NamedEntityLanguageModel ing entity names by copying/matching the entity names from the reference corpus. For example, Vinyals et al. (2015) calculates the conditional probabili"
P18-1221,P15-2073,0,0.0721622,"Missing"
P18-1221,D16-1032,0,0.0668002,". (2015) calculates the conditional probability of discrete output token sequence corresponding to positions in an input sequence. Gu et al. (2016) develops a seq2seq alignment mechanism which directly copies entity names or long phrases from the input sequence. Wiseman et al. (2017) generates document from structured table like basketball statistics using copy and reconstruction method as well. Another related code generation model (Yin and Neubig, 2017) parses natural language descriptions into source code considering the grammar and syntax in the target programming language (e.g., Python). Kiddon et al. (2016) generates recipe for a given goal, and agenda by making use of items on the agenda. While generating the recipe it continuously monitors the agenda coverage and focus on increasing it. All of them are sequence-to-sequence learning or end-to-end systems which differ from our general purpose (free form) language generation task (e.g., text auto-completion, spelling correction). Code Generation. The way developers write codes is not only just writing a bunch of instructions to run a machine, but also a form of communication to convey their thought. As observed by Donald E. Knuth (Knuth, 1992), “"
P18-1221,P16-1154,0,0.0389386,"ng the representation for every contextualized mention of that entity. Nonetheless, their approach does not deal with the sparsity issue and their goal is different from ours. Language Models for Named Entities. In some generation tasks, recently developed language models address the problem of predict2374 3 https://github.com/uclanlp/NamedEntityLanguageModel ing entity names by copying/matching the entity names from the reference corpus. For example, Vinyals et al. (2015) calculates the conditional probability of discrete output token sequence corresponding to positions in an input sequence. Gu et al. (2016) develops a seq2seq alignment mechanism which directly copies entity names or long phrases from the input sequence. Wiseman et al. (2017) generates document from structured table like basketball statistics using copy and reconstruction method as well. Another related code generation model (Yin and Neubig, 2017) parses natural language descriptions into source code considering the grammar and syntax in the target programming language (e.g., Python). Kiddon et al. (2016) generates recipe for a given goal, and agenda by making use of items on the agenda. While generating the recipe it continuousl"
P18-1221,D14-1162,0,0.0814762,"Missing"
P18-1221,P93-1024,0,0.207338,"mark language corpora where each consists of a reasonable number of entity names. While we leverage an existing corpus for recipe, we curated the code 2 Related Work and Background Class Based Language Models. Building language models by leveraging the deterministic or probabilistic class properties of the words (a.k.a, class-based language models) is an old idea (Brown et al., 1992; Goodman, 2001). However, the objective of our model is different from the existing class-based language models. The key differences are two-folds: 1) Most existing class-based language models (Brown et al., 1992; Pereira et al., 1993; Niesler et al., 1998; Baker and McCallum, 1998; Goodman, 2001; Maltese et al., 2001) are generative n-gram models whereas ours is a discriminative language model based on neural networks. The modeling principle and assumptions are very different. For example, we cannot calculate the conditional probability by statistical occurrence counting as these papers did. 2) Our approaches consider building two models and perform joint inference which makes our framework general and easy to extend. In Section 4, we demonstrate that our model can be easily incorporated with the state-of-art language mod"
P18-1221,P17-1105,0,0.0990277,"Missing"
P18-1221,D17-1239,0,0.0232388,"ssue and their goal is different from ours. Language Models for Named Entities. In some generation tasks, recently developed language models address the problem of predict2374 3 https://github.com/uclanlp/NamedEntityLanguageModel ing entity names by copying/matching the entity names from the reference corpus. For example, Vinyals et al. (2015) calculates the conditional probability of discrete output token sequence corresponding to positions in an input sequence. Gu et al. (2016) develops a seq2seq alignment mechanism which directly copies entity names or long phrases from the input sequence. Wiseman et al. (2017) generates document from structured table like basketball statistics using copy and reconstruction method as well. Another related code generation model (Yin and Neubig, 2017) parses natural language descriptions into source code considering the grammar and syntax in the target programming language (e.g., Python). Kiddon et al. (2016) generates recipe for a given goal, and agenda by making use of items on the agenda. While generating the recipe it continuously monitors the agenda coverage and focus on increasing it. All of them are sequence-to-sequence learning or end-to-end systems which diff"
P18-1221,P17-1041,0,0.0486913,"3 https://github.com/uclanlp/NamedEntityLanguageModel ing entity names by copying/matching the entity names from the reference corpus. For example, Vinyals et al. (2015) calculates the conditional probability of discrete output token sequence corresponding to positions in an input sequence. Gu et al. (2016) develops a seq2seq alignment mechanism which directly copies entity names or long phrases from the input sequence. Wiseman et al. (2017) generates document from structured table like basketball statistics using copy and reconstruction method as well. Another related code generation model (Yin and Neubig, 2017) parses natural language descriptions into source code considering the grammar and syntax in the target programming language (e.g., Python). Kiddon et al. (2016) generates recipe for a given goal, and agenda by making use of items on the agenda. While generating the recipe it continuously monitors the agenda coverage and focus on increasing it. All of them are sequence-to-sequence learning or end-to-end systems which differ from our general purpose (free form) language generation task (e.g., text auto-completion, spelling correction). Code Generation. The way developers write codes is not only"
P19-1159,Q18-1041,0,0.0301316,"scope of this paper is limited. There is a long history of gender stereotype study in law, psychology, media study, and many other disciplines which we do not discuss. Similar issues of algorithmic bias have also been discussed extensively in artificial intelligence, machine learning, data mining, and several other application fields (e.g., (Calders and Verwer, 2010; Feldman et al., 2015; Hardt et al., 2016; Misra et al., 2016; Kleinberg et al., 2016; Pleiss et al., 2017; Beutel et al., 2017; Misra et al., 2016)). Other important aspects such as model/data transparency (Mitchell et al., 2019; Bender and Friedman, 2018) and privacy preservation (Reddy and Knight, 2016; Elazar and Goldberg, 2018; Li et al., 2018) are also not covered in this literature survey. Besides, we refer the readers to Hovy and Spruit (2016) for a more general discussion of ethical concern in NLP. The study of gender bias in NLP is still relatively nascent and consequently lacks unified metrics and benchmarks for evaluation. We urge researchers in related fields to work together to create standardized metrics that rigorously measure the gender bias in NLP applications. However, we recognize that different applications may require diffe"
P19-1159,D18-1002,0,0.0272669,"study in law, psychology, media study, and many other disciplines which we do not discuss. Similar issues of algorithmic bias have also been discussed extensively in artificial intelligence, machine learning, data mining, and several other application fields (e.g., (Calders and Verwer, 2010; Feldman et al., 2015; Hardt et al., 2016; Misra et al., 2016; Kleinberg et al., 2016; Pleiss et al., 2017; Beutel et al., 2017; Misra et al., 2016)). Other important aspects such as model/data transparency (Mitchell et al., 2019; Bender and Friedman, 2018) and privacy preservation (Reddy and Knight, 2016; Elazar and Goldberg, 2018; Li et al., 2018) are also not covered in this literature survey. Besides, we refer the readers to Hovy and Spruit (2016) for a more general discussion of ethical concern in NLP. The study of gender bias in NLP is still relatively nascent and consequently lacks unified metrics and benchmarks for evaluation. We urge researchers in related fields to work together to create standardized metrics that rigorously measure the gender bias in NLP applications. However, we recognize that different applications may require different metrics and there are trade-offs between different notions of biases (B"
P19-1159,W19-3621,0,0.168175,"hey first build a linear support vector machine to classify words into a set of gender-specific and a set of gender-neutral words based on a training set of hand-selected gender-specific words. The authors then identify a gender direction by aggregating ten gender pairs (e.g. she-he, her-his, woman-man, etc.) and using principal component analysis to find a single eigenvector that exhibits significantly greater variance than the rest. Manzini et al. (2019) extend this method and their approach can be used to find non-binary gender bias by aggregating n-tuples instead of gender pairs. However, Gonen and Goldberg (2019) note that the above method fails to capture the full picture of gender bias in vector spaces. Specifically, even after the projections of word embeddings representing gender-neutral words onto the gender subspace have been removed, word embeddings representing words with similar biases still cluster together. They further introduce the notion of cluster bias. Cluster bias of a word w can be measured as the percentage of male or female stereotypical words among the k nearest neighbors of w’s embedding where the male or female stereotypical words are obtained through human annotation. 2.3 Measu"
P19-1159,W12-1008,0,0.27664,"Missing"
P19-1159,P16-2096,0,0.0603932,"have also been discussed extensively in artificial intelligence, machine learning, data mining, and several other application fields (e.g., (Calders and Verwer, 2010; Feldman et al., 2015; Hardt et al., 2016; Misra et al., 2016; Kleinberg et al., 2016; Pleiss et al., 2017; Beutel et al., 2017; Misra et al., 2016)). Other important aspects such as model/data transparency (Mitchell et al., 2019; Bender and Friedman, 2018) and privacy preservation (Reddy and Knight, 2016; Elazar and Goldberg, 2018; Li et al., 2018) are also not covered in this literature survey. Besides, we refer the readers to Hovy and Spruit (2016) for a more general discussion of ethical concern in NLP. The study of gender bias in NLP is still relatively nascent and consequently lacks unified metrics and benchmarks for evaluation. We urge researchers in related fields to work together to create standardized metrics that rigorously measure the gender bias in NLP applications. However, we recognize that different applications may require different metrics and there are trade-offs between different notions of biases (Barocas et al., 2018; Chouldechova and Roth, 2018). Gender debiasing methods in NLP are not sufficient to debias models end"
P19-1159,S18-2005,0,0.42654,"model’s prediction should not be heavily influenced by the gender of the entity mentions or contexts in the input. To evaluate whether or not this is the case, consider two sentences that act as the inputs to a model for which the only differences are the words that correspond to gender, such as “He went to the park” vs “She went to the park”. We refer to changing the gender of the gendered nouns as gender-swapping. Gender-swapping can be generalized to sentences by swapping each male-definitional word with its respective female equivalent and vice-versa (Zhao et al., 2018a; Lu et al., 2018; Kiritchenko and Mohammad, 2018). If the model does not make decisions based on genders, it should perform equally for both sentences. Otherwise, the difference in evaluation scores reflects the extent of gender bias found in the system. For example, Dixon et al. (2017) introduce two metrics to measure these performance differences – False Positive Equality Difference (FPED) and False Negative Equality Difference (FNED) – that have been used to measure gender bias in abusive language detection (Park et al., 2018). These are defined as the differences in the false positive and false negative rates, respectively, of prediction"
P19-1159,D17-1018,0,0.0257358,"E2 after applying gender-swapping and name anonymization for data augmentation. This removes gender associations with named entities in sentences. The model is then trained on the union of the original data set with name-anonymization and the augmented data set. The identification of gender-specific words and their equivalent opposite gender word requires lists typically created by crowd workers. Data augmentation has been shown to be flexible; it can mitigate gender bias in several different models in many different tasks. When applied to a neural network based coreference resolution model (Lee et al., 2017, 2018) originally trained on OntoNotes 5.0 which was tested on WinoBias, gender augmentation lowered the difference between F1 scores on pro-stereotypical and antistereotypical test sets significantly, which indicates the model was less inclined to make genderbiased predictions (Zhao et al., 2018a, 2019). In hate speech detection, data augmentation reduced FNED and FPED differences between male and female predictions of a Convolutional Neural Network by a wide margin (Park et al., 2018). Data augmentation without name-anonymization has also been used to debias knowledge graphs built from Boll"
P19-1159,N18-2108,0,0.0251649,"Missing"
P19-1159,P18-2005,0,0.0498437,"Missing"
P19-1159,N19-1062,0,0.159781,"gender subspace of a word embedding representing a gender-neutral word and that word’s bias rating, as rated by crowd workers. To identify the gender subspace, they first build a linear support vector machine to classify words into a set of gender-specific and a set of gender-neutral words based on a training set of hand-selected gender-specific words. The authors then identify a gender direction by aggregating ten gender pairs (e.g. she-he, her-his, woman-man, etc.) and using principal component analysis to find a single eigenvector that exhibits significantly greater variance than the rest. Manzini et al. (2019) extend this method and their approach can be used to find non-binary gender bias by aggregating n-tuples instead of gender pairs. However, Gonen and Goldberg (2019) note that the above method fails to capture the full picture of gender bias in vector spaces. Specifically, even after the projections of word embeddings representing gender-neutral words onto the gender subspace have been removed, word embeddings representing words with similar biases still cluster together. They further introduce the notion of cluster bias. Cluster bias of a word w can be measured as the percentage of male or fe"
P19-1159,N19-1063,0,0.0399345,"skan et al., 2017). The authors confirm that human biases found through IAT tests exist in GloVe and Word2Vec embeddings. Finally, the authors demonstrate a positive correlation between the strength of association of an occupation word embedding with the female gender and the percentage of females in that occupation in United States, with the percentages taken from Bureau of Labor Statistics labor force participation data. Notably, Garg et al. (2018) show that bias in word 1631 embeddings can be used to track social changes such as increased or decreased female participation in the workforce. May et al. (2019) extend WEAT to create the Sentence Encoder Association Test (SEAT), capable of testing sentence encoders (e.g., ELMo (Peters et al., 2018)) for human biases found in IAT tests. 2.2 Analyzing Gender Sub-space in Embeddings Bolukbasi et al. (2016) define gender bias as the correlation between the magnitude of the projection onto the gender subspace of a word embedding representing a gender-neutral word and that word’s bias rating, as rated by crowd workers. To identify the gender subspace, they first build a linear support vector machine to classify words into a set of gender-specific and a set"
P19-1159,D18-1302,0,0.353775,"s Language Model Word Embedding Example of Representation Bias in the Context of Gender Translating “He is a nurse. She is a doctor.” to Hungarian and back to English results in “She is a nurse. He is a doctor.” (Douglas, 2017) An image captioning model incorrectly predicts the agent to be male because there is a computer nearby (Burns et al., 2018). Automatic speech detection works better with male voices than female voices (Tatman, 2017). Sentiment Analysis Systems rank sentences containing female noun phrases to be indicative of anger more often than sentences containing male noun phrases (Park et al., 2018). “He is doctor” has a higher conditional likelihood than “She is doctor” (Lu et al., 2018). Analogies such as “man : woman :: computer programmer : homemaker” are automatically generated by models trained on biased word embeddings (Bolukbasi et al., 2016). D S X R X X X U X X X X X X X X X X Table 1: Following the talk by Crawford (2017), we categorize representation bias in NLP tasks into the following four categories: (D)enigration, (S)tereotyping, (R)ecognition, (U)nder-representation. Briefly, denigration refers to the use of culturally or historically derogatory terms; stereotyping reinf"
P19-1159,N18-1202,0,0.041898,"uthors demonstrate a positive correlation between the strength of association of an occupation word embedding with the female gender and the percentage of females in that occupation in United States, with the percentages taken from Bureau of Labor Statistics labor force participation data. Notably, Garg et al. (2018) show that bias in word 1631 embeddings can be used to track social changes such as increased or decreased female participation in the workforce. May et al. (2019) extend WEAT to create the Sentence Encoder Association Test (SEAT), capable of testing sentence encoders (e.g., ELMo (Peters et al., 2018)) for human biases found in IAT tests. 2.2 Analyzing Gender Sub-space in Embeddings Bolukbasi et al. (2016) define gender bias as the correlation between the magnitude of the projection onto the gender subspace of a word embedding representing a gender-neutral word and that word’s bias rating, as rated by crowd workers. To identify the gender subspace, they first build a linear support vector machine to classify words into a set of gender-specific and a set of gender-neutral words based on a training set of hand-selected gender-specific words. The authors then identify a gender direction by ag"
P19-1159,W16-5603,0,0.0226761,"ry of gender stereotype study in law, psychology, media study, and many other disciplines which we do not discuss. Similar issues of algorithmic bias have also been discussed extensively in artificial intelligence, machine learning, data mining, and several other application fields (e.g., (Calders and Verwer, 2010; Feldman et al., 2015; Hardt et al., 2016; Misra et al., 2016; Kleinberg et al., 2016; Pleiss et al., 2017; Beutel et al., 2017; Misra et al., 2016)). Other important aspects such as model/data transparency (Mitchell et al., 2019; Bender and Friedman, 2018) and privacy preservation (Reddy and Knight, 2016; Elazar and Goldberg, 2018; Li et al., 2018) are also not covered in this literature survey. Besides, we refer the readers to Hovy and Spruit (2016) for a more general discussion of ethical concern in NLP. The study of gender bias in NLP is still relatively nascent and consequently lacks unified metrics and benchmarks for evaluation. We urge researchers in related fields to work together to create standardized metrics that rigorously measure the gender bias in NLP applications. However, we recognize that different applications may require different metrics and there are trade-offs between dif"
P19-1159,W04-2401,0,0.0250953,"Missing"
P19-1159,N18-2002,0,0.220199,"Missing"
P19-1159,Q18-1042,0,0.223567,"g gender bias. For one, these data sets often also contain biases (such as containing more male references than female references), so evaluation on them might not reveal gender bias. Furthermore, predictions made by systems performing complex NLP tasks depend on many factors; we must carefully design data sets to isolate the effect of gender of the output in order to be able to probe gender bias. We name these data sets Gender Bias Evaluation Testsets (GBETs). 1632 The goal of designing GBETs is to provide Data Set Winogender Schemas (Rudinger et al., 2018) WinoBias (Zhao et al., 2018a) GAP (Webster et al., 2018) EEC (Kiritchenko and Mohammad, 2018) Task Coreference Resolution Coreference Resolution Coreference Resolution Sentiment Analysis Probing Concept Occupation Occupation Names Emotion Size 720 English Sentences 3,160 English Sentences 4,454 English Contexts 8,640 English Sentences Table 2: Summary of GBETs. GBETs evaluate models trained for specific tasks for gender bias. GBETs use differences in values of the probing concept or prediction accuracies relating to the probing concept between gender-swapped data points to measure bias. check that NLP systems avoid making mistakes due to gender bia"
P19-1159,N19-1064,1,0.865318,"Missing"
P19-1159,D17-1323,1,0.814881,"aining set and within the algorithm itself. Introduction Gender bias is the preference or prejudice toward one gender over the other (Moss-Racusin et al., 2012). Gender bias is exhibited in multiple parts of a Natural Language Processing (NLP) system, including the training data, resources, pretrained models (e.g. word embeddings), and algorithms themselves (Zhao et al., 2018a; Bolukbasi et al., 2016; Caliskan et al., 2017; Garg et al., 2018). NLP systems containing bias in any of these parts can produce gender biased predictions and sometimes even amplify biases present in the training sets (Zhao et al., 2017). The propagation of gender bias in NLP algorithms poses the danger of reinforcing damaging * Equal Contribution. stereotypes in downstream applications. This has real-world consequences; for example, concerns have been raised about automatic resume filtering systems giving preference to male applicants when the only distinguishing factor is the applicants’ gender. One way to categorize bias is in terms of allocation and representation bias (Crawford, 2017). Allocation bias can be framed as an economic issue in which a system unfairly allocates resources to certain groups over others, while re"
P19-1159,N18-2003,1,0.110244,"1: Observation and evaluation of gender bias in NLP. Bias observation occurs in both the training sets and the test sets specifically for evaluating the gender bias of a given algorithm’s predictions. Debiasing gender occurs in both the training set and within the algorithm itself. Introduction Gender bias is the preference or prejudice toward one gender over the other (Moss-Racusin et al., 2012). Gender bias is exhibited in multiple parts of a Natural Language Processing (NLP) system, including the training data, resources, pretrained models (e.g. word embeddings), and algorithms themselves (Zhao et al., 2018a; Bolukbasi et al., 2016; Caliskan et al., 2017; Garg et al., 2018). NLP systems containing bias in any of these parts can produce gender biased predictions and sometimes even amplify biases present in the training sets (Zhao et al., 2017). The propagation of gender bias in NLP algorithms poses the danger of reinforcing damaging * Equal Contribution. stereotypes in downstream applications. This has real-world consequences; for example, concerns have been raised about automatic resume filtering systems giving preference to male applicants when the only distinguishing factor is the applicants’"
P19-1159,D18-1521,1,0.103647,"1: Observation and evaluation of gender bias in NLP. Bias observation occurs in both the training sets and the test sets specifically for evaluating the gender bias of a given algorithm’s predictions. Debiasing gender occurs in both the training set and within the algorithm itself. Introduction Gender bias is the preference or prejudice toward one gender over the other (Moss-Racusin et al., 2012). Gender bias is exhibited in multiple parts of a Natural Language Processing (NLP) system, including the training data, resources, pretrained models (e.g. word embeddings), and algorithms themselves (Zhao et al., 2018a; Bolukbasi et al., 2016; Caliskan et al., 2017; Garg et al., 2018). NLP systems containing bias in any of these parts can produce gender biased predictions and sometimes even amplify biases present in the training sets (Zhao et al., 2017). The propagation of gender bias in NLP algorithms poses the danger of reinforcing damaging * Equal Contribution. stereotypes in downstream applications. This has real-world consequences; for example, concerns have been raised about automatic resume filtering systems giving preference to male applicants when the only distinguishing factor is the applicants’"
P19-1159,D18-1301,0,0.0330824,"and Verwer, 2010; Feldman et al., 2015; Hardt et al., 2016; Misra et al., 2016; Kleinberg et al., 2016; Pleiss et al., 2017; Beutel et al., 2017; Kilbertus et al., 2017). Many of these technical methods could be applicable to NLP yet to our knowledge have not been studied. Additionally, mitigating gender bias in NLP is both a sociological and an engineering problem. To completely debias effectively, it is important to understand how machine learning methods encode biases and how humans perceive biases. A few interdisciplinary studies (Herbelot et al., 2012; Avin et al., 2015; Fu et al., 2016; Schluter, 2018) have emerged, and we urge more interdisciplinary discussions in terms of gender bias. Approaches from other technical fields may improve current debiasing methods in NLP or inspire the development of new, more effective methods even if the properties of the data or Conclusion and Future Directions In this paper, we summarize recent literature about recognizing and mitigating gender bias in NLP. We acknowledge that the scope of this paper is limited. There is a long history of gender stereotype study in law, psychology, media study, and many other disciplines which we do not discuss. Similar i"
P19-1159,W17-1606,0,0.0782787,"Florence, Italy, July 28 - August 2, 2019. 2019 Association for Computational Linguistics Task Machine Translation Caption Generation Speech Recognition Sentiment Analysis Language Model Word Embedding Example of Representation Bias in the Context of Gender Translating “He is a nurse. She is a doctor.” to Hungarian and back to English results in “She is a nurse. He is a doctor.” (Douglas, 2017) An image captioning model incorrectly predicts the agent to be male because there is a computer nearby (Burns et al., 2018). Automatic speech detection works better with male voices than female voices (Tatman, 2017). Sentiment Analysis Systems rank sentences containing female noun phrases to be indicative of anger more often than sentences containing male noun phrases (Park et al., 2018). “He is doctor” has a higher conditional likelihood than “She is doctor” (Lu et al., 2018). Analogies such as “man : woman :: computer programmer : homemaker” are automatically generated by models trained on biased word embeddings (Bolukbasi et al., 2016). D S X R X X X U X X X X X X X X X X Table 1: Following the talk by Crawford (2017), we categorize representation bias in NLP tasks into the following four categories:"
P19-1159,N16-2013,0,0.0453347,"related task. Bias fine-tuning incorporates transfer learning from an unbiased data set to ensure that a model contains minimal bias before fine-tuning the model on a more biased data set used to train for the target task directly (Park et al., 2018). This allows models to avoid learning biases from training sets while still being adequately trained to perform a task. Bias fine-tuning has been shown to be relatively effective. Park et al. (2018) use transfer learning from a gender unbiased abusive tweets data set (Founta et al., 2018) and fine-tuning on a genderbiased sexist tweets data set (Waseem and Hovy, 2016) to train a Convolutional Neural Network (CNN). They evaluate the CNN using a GBET evaluation set (which is private, so not mentioned in 2.3). They tested the same model after training it on gender-swapped data sets as well. Park et al. (2018) find that gender-swapping was more effective at both removing bias and retaining performance than bias fine-tuning. However, transfer learning may have been ineffective in this case because abusive language detection data sets and sexist language detection data sets have significant differences. For more similar data sets, bias finetuning may be more eff"
P19-1402,Q17-1010,0,0.260048,"words. These words are often rare and might only occurred for a few times in the testing corpus. Therefore, the insufficient observations hinder the existing context-based word embedding models to infer accurate OOV embeddings. This leads us to the following research problem: How can we learn accurate embedding vectors for OOV words during the inference time by observing their usages for only a few times? Existing approaches for dealing with OOV words can be categorized into two groups. The first group of methods derives embedding vectors of OOV words based on their morphological information (Bojanowski et al., 2017; Kim et al., 2016; Pinter et al., 2017). This type of approaches has a limitation when the meaning of words cannot be inferred from its subunits (e.g., names, such as Vladimir). The second group of approaches attempts to learn to embed an OOV word from a few examples. In a prior study (Cohn et al., 2017; Herbelot and Baroni, 2017), these demonstrating examples are treated as a small corpus and are used to fine-tune OOV embeddings. Unfortunately, fine-tuning with just a few examples usually leads to overfitting. In another work (Khodak et al., 2018), a simple linear function is used to infer e"
P19-1402,E17-1088,0,0.0194565,"ystems. To learn such embeddings, existing approaches such as skip-gram models (Mikolov et al., 2013) resort to an auxiliary task of predicting the context words (words surround the target word). These embeddings have shown to be able to capture syntactic and semantic relations between words. Despite the success, an essential issue arises: most existing embedding techniques assume the availability of abundant observations of each word in the training corpus. When a word occurs only a few times during training (i.e., in the few-shot setting), the corresponding embedding vector is not accurate (Cohn et al., 2017). In the extreme case, some words are not observed when training the embedding, which are known as out-ofvocabulary (OOV) words. These words are often rare and might only occurred for a few times in the testing corpus. Therefore, the insufficient observations hinder the existing context-based word embedding models to infer accurate OOV embeddings. This leads us to the following research problem: How can we learn accurate embedding vectors for OOV words during the inference time by observing their usages for only a few times? Existing approaches for dealing with OOV words can be categorized int"
P19-1402,W04-1213,0,0.207698,"with a goal to extract named entities from a sentence. Recent approaches for NER take word embedding as input and leverage its semantic information to annotate named entities. Therefore, a high-quality word embedding has a great impact on the NER system. We consider the following two corpora, which contain abundant OOV words, to mimic the real situation of OOV problems. • Rare-NER: This NER dataset (Derczynski et al., 2017) focus on unusual, previouslyunseen entities in the context of emerging discussions, which are mostly OOV words. • Bio-NER: The JNLPBA 2004 Bio-entity recognition dataset (Collier and Kim, 2004) focuses on technical terms in the biology domain, which also contain many OOV words. Both datasets use entity-level F1-score as an evaluation metric. We use the WikiText-103 as DT , and these datasets as DN . We select all the OOV words in the dataset and extract their context sentences. Then, we train different versions of OOV embeddigns based on the proposed approaches and the baseline models. Finally, the inferred embedding is used in an NER system based on the 4107 Methods Named Entity Recognition (F1-score) Rare-NER Bio-NER POS Tagging (Acc) Twitter POS Word2vec FastText Additive nonce2v"
P19-1402,W17-4418,0,0.0806686,"Missing"
P19-1402,D18-1398,0,0.0697463,"tric learning makes it specified on classification problems. (2) Learn a learning policy that can fast adapt to new concepts, including a better weight initialization as MAML (Finn et al., 2017) and a better optimizer (Ravi and Larochelle, 2017). This line of research is more general and can be applied to different learning paradigms, including both classification and regression. There have been emerging research studies that utilize the above meta-learning algorithms to NLP tasks, including language modelling (Vinyals et al., 2016), text classification (Yu et al., 2018), machine translation (Gu et al., 2018), and relation learning (Xiong et al., 2018; Gao et al., 2019). In this paper, we propose to formulate the OOV word representation learning as a few-shot regression problem. We first show that pre-training on a given corpus can somehow solve the problem. To further mitigate the semantic gap between the given corpus with a new corpus, we adopt model-agnostic meta-learning (MAML) (Finn et al., 2017) to fast adapt the pre-trained model to new corpus. Contextualized Embedding The HiCE architecture is related to contextualized representation learning (Peters et al., 2018; Devlin et al.). However, t"
P19-1402,P16-1141,0,0.02195,"ext embedding E(st,k ). On top of it, a Multi-Context Aggregator combines multiple encoded contexts, i.e., E(st,1 ), E(st,2 ), ..., E(st,K ), by another selfattention encoding block. Note that the order of contexts can be arbitrary and should not influence Fast and Robust Adaptation with MAML So far, we directly apply the learned neural regression function Fθˆ trained on DT to OOV words in DN . This can be problematic when there exists some linguistic and semantic gap between DT and DN . For example, words with the same form but in different domains (Sarma et al., 2018) or at different times (Hamilton et al., 2016) can have different semantic meanings. Therefore, to further improve the performance, we aim to adapt the learned neural regression function Fθˆ from DT to the new corpus DN . A na¨ıve way to do so is directly fine-tuning the model on DN . However, in most cases, the new corpus DN does not have enough data compared to DT , and thus directly fine-tuning on insufficient data can be sub-optimal and prone to overfitting. To address this issue, we adopt Model Agnostic Meta-Learning (MAML) (Finn et al., 2017) to achieve fast and robust adaption. Instead of simply fine-tuning Fθˆ on DN , MAML provide"
P19-1402,D17-1030,0,0.450911,"ords during the inference time by observing their usages for only a few times? Existing approaches for dealing with OOV words can be categorized into two groups. The first group of methods derives embedding vectors of OOV words based on their morphological information (Bojanowski et al., 2017; Kim et al., 2016; Pinter et al., 2017). This type of approaches has a limitation when the meaning of words cannot be inferred from its subunits (e.g., names, such as Vladimir). The second group of approaches attempts to learn to embed an OOV word from a few examples. In a prior study (Cohn et al., 2017; Herbelot and Baroni, 2017), these demonstrating examples are treated as a small corpus and are used to fine-tune OOV embeddings. Unfortunately, fine-tuning with just a few examples usually leads to overfitting. In another work (Khodak et al., 2018), a simple linear function is used to infer embedding of an OOV word by aggregating embeddings of its context words in the examples. However, the simple linear averaging can fail to 4102 Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 4102–4112 c Florence, Italy, July 28 - August 2, 2019. 2019 Association for Computational Lingui"
P19-1402,P18-1002,0,0.440939,"based on their morphological information (Bojanowski et al., 2017; Kim et al., 2016; Pinter et al., 2017). This type of approaches has a limitation when the meaning of words cannot be inferred from its subunits (e.g., names, such as Vladimir). The second group of approaches attempts to learn to embed an OOV word from a few examples. In a prior study (Cohn et al., 2017; Herbelot and Baroni, 2017), these demonstrating examples are treated as a small corpus and are used to fine-tune OOV embeddings. Unfortunately, fine-tuning with just a few examples usually leads to overfitting. In another work (Khodak et al., 2018), a simple linear function is used to infer embedding of an OOV word by aggregating embeddings of its context words in the examples. However, the simple linear averaging can fail to 4102 Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 4102–4112 c Florence, Italy, July 28 - August 2, 2019. 2019 Association for Computational Linguistics capture the complex semantics and relationships of an OOV word from its contexts. Unlike the existing approaches mentioned above, humans have the ability to infer the meaning of a word based on a more comprehensive u"
P19-1402,N16-1030,0,0.0705919,"Missing"
P19-1402,W13-3512,0,0.0757975,"Missing"
P19-1402,N18-1202,0,0.243272,"etail the design of the neural regression function Fθ (·). Based on the previous discussion, Fθ (·) should be able to analyze the complex semantics of context, to aggregate multiple pieces of context information for comprehensive embedding prediction, and to incorporate morphological Figure 1: The proposed hierarchical context encoding architecture (HiCE) for learning embedding representation for OOV words. features. These three requirements cannot be fulfilled using simple models such as linear aggregation (Khodak et al., 2018). Recent progress in contextualized word representation learning (Peters et al., 2018; Devlin et al.) has shown that it is possible to learn a deep model to capture richer language-specific semantics and syntactic knowledge purely based on self-supervised objectives. Motivated by their results, we propose a hierarchical context encoding (HiCE) architecture to extract and aggregate information from contexts, and morphological features can be easily incorporated. Using HiCE as Fθ (·), a more sophisticated model to process and aggregate contexts and morphology can be learned to infer OOV embeddings. Self-Attention Encoding Block Our proposed HiCE is mainly based on the self-atten"
P19-1402,D17-1010,0,0.11264,"only occurred for a few times in the testing corpus. Therefore, the insufficient observations hinder the existing context-based word embedding models to infer accurate OOV embeddings. This leads us to the following research problem: How can we learn accurate embedding vectors for OOV words during the inference time by observing their usages for only a few times? Existing approaches for dealing with OOV words can be categorized into two groups. The first group of methods derives embedding vectors of OOV words based on their morphological information (Bojanowski et al., 2017; Kim et al., 2016; Pinter et al., 2017). This type of approaches has a limitation when the meaning of words cannot be inferred from its subunits (e.g., names, such as Vladimir). The second group of approaches attempts to learn to embed an OOV word from a few examples. In a prior study (Cohn et al., 2017; Herbelot and Baroni, 2017), these demonstrating examples are treated as a small corpus and are used to fine-tune OOV embeddings. Unfortunately, fine-tuning with just a few examples usually leads to overfitting. In another work (Khodak et al., 2018), a simple linear function is used to infer embedding of an OOV word by aggregating e"
P19-1402,N18-1109,0,0.0834973,"(Snell et al., 2017). The nature of metric learning makes it specified on classification problems. (2) Learn a learning policy that can fast adapt to new concepts, including a better weight initialization as MAML (Finn et al., 2017) and a better optimizer (Ravi and Larochelle, 2017). This line of research is more general and can be applied to different learning paradigms, including both classification and regression. There have been emerging research studies that utilize the above meta-learning algorithms to NLP tasks, including language modelling (Vinyals et al., 2016), text classification (Yu et al., 2018), machine translation (Gu et al., 2018), and relation learning (Xiong et al., 2018; Gao et al., 2019). In this paper, we propose to formulate the OOV word representation learning as a few-shot regression problem. We first show that pre-training on a given corpus can somehow solve the problem. To further mitigate the semantic gap between the given corpus with a new corpus, we adopt model-agnostic meta-learning (MAML) (Finn et al., 2017) to fast adapt the pre-trained model to new corpus. Contextualized Embedding The HiCE architecture is related to contextualized representation learning (Peters e"
P19-1402,D16-1163,0,0.0333726,"inear transformation used in the past, and learn to embed in a few-shot setting. We also show that incorporating morphological features can further enhance the model when the context is extremely limited (i.e., only two or four sentences). Few-shot learning The paradigm of learning new tasks from a few labelled observations, referred to as few-shot learning, has received significant attention. The early studies attempt to transfer knowledge learned from tasks with sufficient training data to new tasks. They mainly follow a pre-train then fine-tune paradigm (Donahue et al., 2014; Bengio, 2012; Zoph et al., 2016). Recently, meta-learning is proposed and it achieves great performance on various few-shot learning tasks. The intuition of meta-learning is to learn generic knowledge on a variety of learning tasks, such that the model can be adapted to learn a new task with only a few training samples. Approaches for meta-learning can be categorized by the type of knowledge they learn. (1) Learn a metric function that embeds data in the same class closer to each other, including Matching Networks (Vinyals et al., 2016), and Prototypical Networks (Snell et al., 2017). The nature of metric learning makes it s"
P19-1402,D11-1141,0,0.0991686,"Missing"
P19-1402,W18-3407,0,0.0393144,"encoding block, and outputs an encoded context embedding E(st,k ). On top of it, a Multi-Context Aggregator combines multiple encoded contexts, i.e., E(st,1 ), E(st,2 ), ..., E(st,K ), by another selfattention encoding block. Note that the order of contexts can be arbitrary and should not influence Fast and Robust Adaptation with MAML So far, we directly apply the learned neural regression function Fθˆ trained on DT to OOV words in DN . This can be problematic when there exists some linguistic and semantic gap between DT and DN . For example, words with the same form but in different domains (Sarma et al., 2018) or at different times (Hamilton et al., 2016) can have different semantic meanings. Therefore, to further improve the performance, we aim to adapt the learned neural regression function Fθˆ from DT to the new corpus DN . A na¨ıve way to do so is directly fine-tuning the model on DN . However, in most cases, the new corpus DN does not have enough data compared to DT , and thus directly fine-tuning on insufficient data can be sub-optimal and prone to overfitting. To address this issue, we adopt Model Agnostic Meta-Learning (MAML) (Finn et al., 2017) to achieve fast and robust adaption. Instead"
P19-1402,D18-1223,0,0.0236371,"ification problems. (2) Learn a learning policy that can fast adapt to new concepts, including a better weight initialization as MAML (Finn et al., 2017) and a better optimizer (Ravi and Larochelle, 2017). This line of research is more general and can be applied to different learning paradigms, including both classification and regression. There have been emerging research studies that utilize the above meta-learning algorithms to NLP tasks, including language modelling (Vinyals et al., 2016), text classification (Yu et al., 2018), machine translation (Gu et al., 2018), and relation learning (Xiong et al., 2018; Gao et al., 2019). In this paper, we propose to formulate the OOV word representation learning as a few-shot regression problem. We first show that pre-training on a given corpus can somehow solve the problem. To further mitigate the semantic gap between the given corpus with a new corpus, we adopt model-agnostic meta-learning (MAML) (Finn et al., 2017) to fast adapt the pre-trained model to new corpus. Contextualized Embedding The HiCE architecture is related to contextualized representation learning (Peters et al., 2018; Devlin et al.). However, their goal is to get a contextualized embedd"
Q19-1039,D15-1075,0,0.0266158,"Benchmark for 10 epochs and the experiments are conducted on a workstation with 8 GeForce GTX 1080Ti GPUs, 40 Intel Xeon E5 CPUs, and 128G main memory. Downstream benchmarks We follow Peters et al. (2018a) and use the feature-based approach to evaluate contextual representations on downstream benchmarks. ELMo was evaluated on six benchmarks and we conduct evaluations on five of them. SQuAD (Rajpurkar et al., 2016) is not available for implementation reasons.5 In the following, we briefly review the benchmarks and task-specific models. For details please refer to Peters et al. (2018a). • SNLI (Bowman et al., 2015): The textual entailment task seeks to determine whether a ‘‘hypothesis’’ can be entailed from a ‘‘premise’’. The task-specific model is ESIM (Chen et al., 2017). • Coref: Coreference resolution is the task of clustering mentions in text that refer to the same underlying entities. The data set is from CoNLL 2012 shared task (Pradhan et al., 2012) and the model is from Lee et al. (2018). Note that we use an improved version of the Coref system (Lee et al., 2017) used in Peters et al. (2018a). • SST-5 (Socher et al., 2013): The task involves selecting one of five labels to describe a sentence fr"
Q19-1039,P17-1044,0,0.0321836,"der, 2003) consists of newswire from the Reuters RCV1 corpus tagged with four different entity types. The model is a biLSTM-CRF from Peters et al. (2018a), similar to Collobert et al. (2011). • SRL: Semantic role labeling models the predicate-argument structure of a sentence. It 5 The SQuAD experiment in Peters et al. (2018a) was conducted with an implementation in TensorFlow. The experiment setting is not currently available in AllenNLP (https://github.com/allenai/allennlp/ pull/1626), nor can it be easily replicated in PyTorch. 617 seeks to answer ‘‘Who did what to whom’’. The model is from He et al. (2017) and the data set is from Pradhan et al. (2013). For SNLI, SST-5, NER, and SRL, we use the same downstream models as in Peters et al. (2018a) re-implemented in AllenNLP.6 For Coref, Peters et al. (2018a) uses the model from Lee et al. (2017) and we use an improved model (Lee et al., 2018) from the same authors. For all the tasks, the hyper-parameters are tuned to maximize the performance for the original ELMo and all models are tested under the same configurations. 4.2 Main Results We report the main results in Table 2. Our approach (ELMO-C) enjoys a substantial computational advantage while m"
Q19-1039,P18-1008,0,0.023091,"ild the others upon it. The key difference between ELMO-C and ELMO is that ELMO-C produces continuous outputs and we train it with the cosine distance loss. A FastText embedding trained on Common Crawl (Mikolov et al., 2017) (FASTTEXTCC ) is used as the output embedding. Based on preliminary experiments, we also make three minor changes: 1) we use FASTTEXTCC as the input layer as it is more efficient than the character-CNN model; 2) we add a layer norm (Ba et al., 2016) after the projection layer of the LSTM to improve the convergence speed; 3) we use Adam with the learning rate schedule from Chen et al. (2018) to help training with a large batch size. Our main goal is to study how different output layers affect the training speed and performance, which cannot be achieved by just comparing ELMO-C and ELMO, due to the aforementioned minor changes to ELMO-C. Therefore, we introduce two additional baseline models (ELMO-A and ELMO-Sub), which differ from ELMO-C in a minimal way. Specifically, their sequence encoders and training recipes are kept the same as ELMO-C. Thus ELMO-C, ELMO-A, and ELMO-Sub can be directly compared. ELMOORG BASE FASTTEXTCC ELMO ELMO-A ELMO-Sub ELMO-C Time Batch Params − − − − −"
Q19-1039,P18-1192,0,0.0188595,"performance of the contextual encoder. We also investigate the contributions of different factors to the overall training time and study the speedup of our approach under various conditions. 5.1 Effect of the Pre-trained Embedding We show the effect of the pre-trained embedding by introducing several variants of ELMO-C (summarized in Table 1) and list their performance in Table 3. Performance on downstream tasks ELMO-C works especially well on semantic-centric tasks, such as SNLI, Coref, and SST-5. However, for tasks that required a certain level of syntactic information, such as NER and SRL (He et al., 2018), ELMO-C suffers from slight performance degradation compared with ELMO, but it remains competitive with ELMO-A and ELMO-Sub. We suspect that the performance degradation is related to the pre-trained embedding and conduct further analysis in Section 5.1. 6 For SRL, the score reported by AllenNLP is lower than the score reported by CoNLL official script. 618 Quality of the pre-trained embedding We aim to understand how the quality of the pretrained output word embedding W affects the performance of the contextual encoder. To study this, we train a FastText word embedding on the One Billion Word"
Q19-1039,P82-1020,0,0.815735,"Missing"
Q19-1039,P17-1152,0,0.0313696,"benchmarks We follow Peters et al. (2018a) and use the feature-based approach to evaluate contextual representations on downstream benchmarks. ELMo was evaluated on six benchmarks and we conduct evaluations on five of them. SQuAD (Rajpurkar et al., 2016) is not available for implementation reasons.5 In the following, we briefly review the benchmarks and task-specific models. For details please refer to Peters et al. (2018a). • SNLI (Bowman et al., 2015): The textual entailment task seeks to determine whether a ‘‘hypothesis’’ can be entailed from a ‘‘premise’’. The task-specific model is ESIM (Chen et al., 2017). • Coref: Coreference resolution is the task of clustering mentions in text that refer to the same underlying entities. The data set is from CoNLL 2012 shared task (Pradhan et al., 2012) and the model is from Lee et al. (2018). Note that we use an improved version of the Coref system (Lee et al., 2017) used in Peters et al. (2018a). • SST-5 (Socher et al., 2013): The task involves selecting one of five labels to describe a sentence from a movie review. We use the BCN model from McCann et al. (2017). • NER: The CoNLL 2003 NER task (Sang and De Meulder, 2003) consists of newswire from the Reute"
Q19-1039,N19-1423,0,0.592877,"ntextual representation We review contextual representation models from two aspects: how they are trained and how they are used in downstream tasks. CoVe (McCann et al., 2017) uses the source language encoder from a machine translation model as a contextual representation model. Peters et al. (2018a) advocate for the use of larger unlabelled corpora and proposes ELMo, a forward and a backward LSTM-based (Hochreiter and Schmidhuber, 1997) language model, whereas GPT (Radford et al., 2018) and GPT-2 (Radford et al., 2019) build a language model with the Transformer (Vaswani et al., 2017). BERT (Devlin et al., 2019) introduces the masked language model and provides deep bidirectional representation. There are two existing strategies for applying pre-trained contextual representations to downstream tasks: 1) feature-based and 2) fine-tuning. In the feature-based approach, fixed features are extracted from the contextual encoder (e.g., ELMo, CoVe) and inserted as an input into a task-specific model. In the fine-tuning approach, the contextual encoder is designed as a part of the network architecture for downstream tasks, 612 and its parameters are fine-tuned with the downstream task. BERT is designed for t"
Q19-1039,W18-2501,0,0.0176855,"nt with the subword method (ELMO-Sub). 4 We include ELMO-A instead of a model with sampled softmax because the adaptive softmax has been shown to have superior performance (Grave et al., 2016). 616 4.1 Setup Models In the following, we introduce the models in detail. Table 1 provides a summary. The original ELMo consists of a character-CNN as the input layer, a forward and backward LSTM with projection as the sequence encoder, and a sampled softmax as the output layer. Adagrad (Duchi et al., 2011) is used as the optimizer. We conduct experiments using the reimplementation of ELMO in AllenNLP (Gardner et al., 2018) and build the others upon it. The key difference between ELMO-C and ELMO is that ELMO-C produces continuous outputs and we train it with the cosine distance loss. A FastText embedding trained on Common Crawl (Mikolov et al., 2017) (FASTTEXTCC ) is used as the output embedding. Based on preliminary experiments, we also make three minor changes: 1) we use FASTTEXTCC as the input layer as it is more efficient than the character-CNN model; 2) we add a layer norm (Ba et al., 2016) after the projection layer of the LSTM to improve the convergence speed; 3) we use Adam with the learning rate schedul"
Q19-1039,D17-1018,0,0.0212735,"he following, we briefly review the benchmarks and task-specific models. For details please refer to Peters et al. (2018a). • SNLI (Bowman et al., 2015): The textual entailment task seeks to determine whether a ‘‘hypothesis’’ can be entailed from a ‘‘premise’’. The task-specific model is ESIM (Chen et al., 2017). • Coref: Coreference resolution is the task of clustering mentions in text that refer to the same underlying entities. The data set is from CoNLL 2012 shared task (Pradhan et al., 2012) and the model is from Lee et al. (2018). Note that we use an improved version of the Coref system (Lee et al., 2017) used in Peters et al. (2018a). • SST-5 (Socher et al., 2013): The task involves selecting one of five labels to describe a sentence from a movie review. We use the BCN model from McCann et al. (2017). • NER: The CoNLL 2003 NER task (Sang and De Meulder, 2003) consists of newswire from the Reuters RCV1 corpus tagged with four different entity types. The model is a biLSTM-CRF from Peters et al. (2018a), similar to Collobert et al. (2011). • SRL: Semantic role labeling models the predicate-argument structure of a sentence. It 5 The SQuAD experiment in Peters et al. (2018a) was conducted with an"
Q19-1039,N18-1202,0,0.121834,"Missing"
Q19-1039,N18-2108,0,0.0904766,"D (Rajpurkar et al., 2016) is not available for implementation reasons.5 In the following, we briefly review the benchmarks and task-specific models. For details please refer to Peters et al. (2018a). • SNLI (Bowman et al., 2015): The textual entailment task seeks to determine whether a ‘‘hypothesis’’ can be entailed from a ‘‘premise’’. The task-specific model is ESIM (Chen et al., 2017). • Coref: Coreference resolution is the task of clustering mentions in text that refer to the same underlying entities. The data set is from CoNLL 2012 shared task (Pradhan et al., 2012) and the model is from Lee et al. (2018). Note that we use an improved version of the Coref system (Lee et al., 2017) used in Peters et al. (2018a). • SST-5 (Socher et al., 2013): The task involves selecting one of five labels to describe a sentence from a movie review. We use the BCN model from McCann et al. (2017). • NER: The CoNLL 2003 NER task (Sang and De Meulder, 2003) consists of newswire from the Reuters RCV1 corpus tagged with four different entity types. The model is a biLSTM-CRF from Peters et al. (2018a), similar to Collobert et al. (2011). • SRL: Semantic role labeling models the predicate-argument structure of a senten"
Q19-1039,D18-1179,0,0.109304,"red with the baselines. Our approach also exhibits consistent computational advanxtage under different conditions (e.g., with different vocabulary sizes, with different sentence encoders, and with different number of GPUs). Source code is available at https://github. com/uclanlp/ELMO-C. 2 Background and Related Work Contextual representation We review contextual representation models from two aspects: how they are trained and how they are used in downstream tasks. CoVe (McCann et al., 2017) uses the source language encoder from a machine translation model as a contextual representation model. Peters et al. (2018a) advocate for the use of larger unlabelled corpora and proposes ELMo, a forward and a backward LSTM-based (Hochreiter and Schmidhuber, 1997) language model, whereas GPT (Radford et al., 2018) and GPT-2 (Radford et al., 2019) build a language model with the Transformer (Vaswani et al., 2017). BERT (Devlin et al., 2019) introduces the masked language model and provides deep bidirectional representation. There are two existing strategies for applying pre-trained contextual representations to downstream tasks: 1) feature-based and 2) fine-tuning. In the feature-based approach, fixed features are"
Q19-1039,D18-1477,0,0.024395,"architecture for downstream tasks, 612 and its parameters are fine-tuned with the downstream task. BERT is designed for the fine-tuning approach but it is also evaluated with the featurebased approach. GPT-2 is a scaled-up version of GPT and exhibits strong performance under zero-shot settings. Speeding up language models training Considerable efforts have been devoted to accelerating the training process of language models. One line of research focuses on developing faster sequence encoder architectures such as CNN (Kim et al., 2016; Dauphin et al., 2017), QRNN (Bradbury et al., 2016), SRU (Lei et al., 2018), and the Transformer (Vaswani et al., 2017). These architectures have been extensively used for learning language representations (Radford et al., 2018; Devlin et al., 2019; Tang et al., 2018). Another line of work focuses on the largevocabulary issue, as a large and ever-growing vocabulary results in an intractable softmax layer. Our work falls into the second line and we review existing solutions in detail. Several studies for language modeling focus on directly reducing the complexity of the softmax layer. Following Kumar and Tsvetkov (2019), we group them into two categories: samplingbase"
Q19-1039,D17-1010,0,0.0316871,"meters that need to be updated. For the sampled softmax, due to the use of the sparse gradient, the communication cost is proportional to the number of the sampled words. For the adaptive softmax and the subword language model, the communication cost is proportional to the trainable parameter size. The continuous output layer, on the other hand, incurs little communication cost across GPUs. 3.2 Open-Vocabulary Training We utilize the open-vocabulary word embedding as both the input and output layer embedding. Openvocabulary word embeddings, such as the FastText embedding and the MIMICK model (Pinter et al., 2017), utilize character or subword information to provide word embeddings. They could represent an unlimited number of words with a fixed number of parameters. As a result, we can train contextual encoders with an open vocabulary, which means we do not need to pre-define a closed word set as the vocabulary and the model can be trained on any sequences of words. Open-vocabulary output layer For the softmax layer, including efficient variants such as the adaptive softmax, the output vocabulary has to be pre-defined so that the normalization term can be calculated. As the softmax layer’s arithmetic c"
Q19-1039,W12-4501,0,0.0599201,"Missing"
Q19-1039,L18-1008,0,0.0914101,"Missing"
Q19-1039,W03-0419,0,0.562807,"Missing"
Q19-1039,P16-1162,0,0.05807,"Missing"
Q19-1039,D13-1170,0,0.00675287,"Missing"
Q19-1039,P19-1355,0,0.0721338,"Missing"
Q19-1039,W18-3009,0,0.0404777,"Missing"
W11-1904,D08-1031,1,0.660485,"ed reader to identify denotative phrases (“mentions”) and link them to an underlying set of referents. Human readers use syntactic and semantic cues to identify and disambiguate the referring phrases; a successful automated system must replicate this behavior by linking mentions that refer to the same underlying entity. This paper describes Illinois-Coref, a coreference resolution system built on Learning Based Java (Rizzolo and Roth, 2010), that participated in the “closed” track of the CoNLL-2011 shared task (Pradhan et al., 2011). Building on elements of the coreference system described in Bengtson and Roth (2008), we design an end-to-end system (Sec. 2) that identifies candidate mentions and then applies one of two inference protocols, Best-Link and All-Link (Sec. 2.3), to disambiguate and cluster them. These protocols were designed to easily Architecture Illinois-Coref follows the architecture used in Bengtson and Roth (2008). First, candidate mentions are detected (Sec. 2.1). Next, a pairwise classifier is applied to each pair of mentions, generating a score that indicates their compatibility (Sec. 2.2). Next, at inference stage, a coreference decoder (Sec. 2.3) aggregates these scores into mention"
W11-1904,W11-1901,0,0.117627,"uction The coreference resolution task is challenging, requiring a human or automated reader to identify denotative phrases (“mentions”) and link them to an underlying set of referents. Human readers use syntactic and semantic cues to identify and disambiguate the referring phrases; a successful automated system must replicate this behavior by linking mentions that refer to the same underlying entity. This paper describes Illinois-Coref, a coreference resolution system built on Learning Based Java (Rizzolo and Roth, 2010), that participated in the “closed” track of the CoNLL-2011 shared task (Pradhan et al., 2011). Building on elements of the coreference system described in Bengtson and Roth (2008), we design an end-to-end system (Sec. 2) that identifies candidate mentions and then applies one of two inference protocols, Best-Link and All-Link (Sec. 2.3), to disambiguate and cluster them. These protocols were designed to easily Architecture Illinois-Coref follows the architecture used in Bengtson and Roth (2008). First, candidate mentions are detected (Sec. 2.1). Next, a pairwise classifier is applied to each pair of mentions, generating a score that indicates their compatibility (Sec. 2.2). Next, at i"
W11-1904,rizzolo-roth-2010-learning,1,0.841039,", and discuss the challenges of resolving coreference for the OntoNotes-4.0 data set. 1 2 Introduction The coreference resolution task is challenging, requiring a human or automated reader to identify denotative phrases (“mentions”) and link them to an underlying set of referents. Human readers use syntactic and semantic cues to identify and disambiguate the referring phrases; a successful automated system must replicate this behavior by linking mentions that refer to the same underlying entity. This paper describes Illinois-Coref, a coreference resolution system built on Learning Based Java (Rizzolo and Roth, 2010), that participated in the “closed” track of the CoNLL-2011 shared task (Pradhan et al., 2011). Building on elements of the coreference system described in Bengtson and Roth (2008), we design an end-to-end system (Sec. 2) that identifies candidate mentions and then applies one of two inference protocols, Best-Link and All-Link (Sec. 2.3), to disambiguate and cluster them. These protocols were designed to easily Architecture Illinois-Coref follows the architecture used in Bengtson and Roth (2008). First, candidate mentions are detected (Sec. 2.1). Next, a pairwise classifier is applied to each"
W12-4513,W11-1904,1,0.870986,"1 Introduction Coreference resolution has been a popular topic of study in recent years. In the task, a system requires to identify denotative phrases (“mentions”) and to cluster the mentions into equivalence classes, so that the mentions in the same class refer to the same entity in the real world. Coreference resolution is a central task in the Natural Language Processing research. Both the CoNLL-2011 (Pradhan et al., 2011) and CoNLL2012 (Pradhan et al., 2012) shared tasks focus on resolving coreference on the OntoNotes corpus. We also participated in the CoNLL-2011 shared task. Our system (Chang et al., 2011) ranked first in two out of four scoring metrics (BCUB and BLANC), and ranked third in the average score. This year, we further improve the system in several respects. In Sec. 2, we describe the Illinois-Coref system for the CoNLL-2011 shared task, which we take as the baseline. Then, we discuss the improvements on mention detection (Sec. 3.1), pronoun resolution (Sec. 3.2), and learning algorithm (Sec. 3.3). 113 Section 4 shows experimental results and Section 5 offers a brief discussion. 2 Baseline System We use the Illinois-Coref system from CoNLL-2011 as the basis for our current system an"
W12-4513,W11-1901,0,0.0900002,"Missing"
W12-4513,W12-4501,0,0.0892953,"Missing"
W12-4513,D08-1031,1,\N,Missing
W13-3602,P08-1021,0,0.116744,"Missing"
W13-3602,P11-1121,0,0.0795709,"Missing"
W13-3602,W13-3601,0,0.365904,"Missing"
W13-3602,rizzolo-roth-2010-learning,1,0.760565,"system on the training data using 5-fold cross-validation (hereafter, “5fold CV”) and in Section 5 we show the results we obtained on test. We close with a discussion focused on error analysis (Section 6) and our conclusions (Section 7). 2 form and subject-verb agreement errors. Our article and preposition modules build on the elements of the systems described in Rozovskaya and Roth (2010b), Rozovskaya and Roth (2010c) and Rozovskaya and Roth (2011). The article system is trained using the Averaged Perceptron (AP) algorithm (Freund and Schapire, 1999), implemented within Learning Based Java (Rizzolo and Roth, 2010). The AP system is trained using the inflation method (Rozovskaya et al., 2012). Our preposition system is a Na¨ıve Bayes (NB) classifier trained on the Google corpus and with prior parameters adapted to the learner data. The other modules – those that correct noun and verb errors – are all NB models trained on the Google corpus. All components take as input the corpus documents preprocessed with a part-of-speech tagger2 and shallow parser3 (Punyakanok and Roth, 2001). Note that the shared task data already contains comparable pre-processing information, in addition to other information, inclu"
W13-3602,W10-1004,1,0.706637,"Missing"
W13-3602,W12-2032,1,0.819811,"CV”) and in Section 5 we show the results we obtained on test. We close with a discussion focused on error analysis (Section 6) and our conclusions (Section 7). 2 form and subject-verb agreement errors. Our article and preposition modules build on the elements of the systems described in Rozovskaya and Roth (2010b), Rozovskaya and Roth (2010c) and Rozovskaya and Roth (2011). The article system is trained using the Averaged Perceptron (AP) algorithm (Freund and Schapire, 1999), implemented within Learning Based Java (Rizzolo and Roth, 2010). The AP system is trained using the inflation method (Rozovskaya et al., 2012). Our preposition system is a Na¨ıve Bayes (NB) classifier trained on the Google corpus and with prior parameters adapted to the learner data. The other modules – those that correct noun and verb errors – are all NB models trained on the Google corpus. All components take as input the corpus documents preprocessed with a part-of-speech tagger2 and shallow parser3 (Punyakanok and Roth, 2001). Note that the shared task data already contains comparable pre-processing information, in addition to other information, including dependency parse and constituency parse, but we chose to run our own pre-p"
W13-3602,W13-1703,0,0.333024,"Missing"
W13-3602,N10-1019,0,0.343943,"Missing"
W13-3602,N10-1018,1,\N,Missing
W13-3602,P11-1093,1,\N,Missing
W13-3602,D10-1094,1,\N,Missing
W13-3602,W11-2843,1,\N,Missing
W14-1704,N12-1067,0,0.0945153,"Missing"
W14-1704,W13-1703,0,0.553096,"Missing"
W14-1704,W11-2838,0,0.437403,"Missing"
W14-1704,W12-2006,0,0.416041,"Missing"
W14-1704,P08-1118,0,0.0667098,"Missing"
W14-1704,W14-1701,0,0.309089,"Missing"
W14-1704,P11-1093,1,0.64212,"tion on the training set. This method prevents the source feature from dominating the context features, and improves the recall of the system. The other classifiers in the baseline system – noun number, verb agreement, verb form, and preposition – are trained on native English data, the Google Web 1T 5-gram corpus (henceforth, Google, (Brants and Franz, 2006)) with the Na¨ıve Bayes (NB) algorithm. All models use word ngram features derived from the 4-word window around the target word. In the preposition model, priors for preposition preferences are learned from the shared task training data (Rozovskaya and Roth, 2011). The modules targeting verb agreement and “Hence, the environmental *factor/factors also *contributes/contribute to various difficulties, *included/including problems in nuclear technology.” Error type Confusion set Noun number {factor, factors} Verb Agreement {contribute, contributes} {included, including, Verb Form includes, include} Table 2: Sample confusion sets for noun number, verb agreement, and verb form. 3 The Baseline System In this section, we briefly describe the University of Illinois system (henceforth Illinois; in the overview paper of the shared task the system is referred to"
W14-1704,D13-1074,1,0.92303,"competition covers all errors occurring in the data. Errors outside the target group were present in the task corpora last year as well, but were not evaluated. Our system extends the one developed by the University of Illinois (Rozovskaya et al., 2013) that placed first in the CoNLL-2013 competition. For this year’s shared task, the system has been extended and improved in several respects: we extended the set of errors addressed by the system, developed a general approach for improving the error-specific models, and added a joint inference component to address interaction among errors. See Rozovskaya and Roth (2013) for more detail. We briefly discuss the task (Section 2) and give an overview of the baseline Illinois system (Section 3). Section 4 presents the novel aspects of the system. In Section 5, we evaluate the complete system on the development data and show the results obtained on test. We offer error analysis and a brief discussion in Section 6. Section 7 concludes. The CoNLL-2014 shared task is an extension of last year’s shared task and focuses on correcting grammatical errors in essays written by non-native learners of English. In this paper, we describe the Illinois-Columbia system that part"
W14-1704,W12-2032,1,0.892017,"Missing"
W14-1704,E14-1038,1,0.918558,"sample confusion sets for noun, agreement, and form errors. Each classifier takes as input the corpus documents preprocessed with a part-of-speech tag2 http://cogcomp.cs.illinois.edu/page/ software view/POS 3 http://cogcomp.cs.illinois.edu/page/ software view/Chunker 1 ∅ denotes noun-phrase-initial contexts where an article is likely to have been omitted. The variants “a” and “an” are conflated and are restored later. 36 verb form mistakes draw on the linguisticallymotivated approach to correcting verb errors proposed in Rozovskaya et. al (2014). correcting verb errors, we refer the reader to Rozovskaya et al. (2014). 4 The Mec error category includes errors in spelling, context-sensitive spelling, capitalization, and punctuation. Our system addresses punctuation errors and capitalization errors. To correct capitalization errors, we collected words that are always capitalized in the training and development data when not occurring sentence-initially. The punctuation classifier includes two modules: a learned component targets missing and extraneous comma usage and is an AP classifier trained on the learner data with error inflation. A second, pattern-based component, complements the AP model: it inserts m"
W14-1704,W13-3602,1,\N,Missing
W14-1704,W13-3601,0,\N,Missing
W17-2613,P98-1013,0,0.0353761,"learning approaches. Twostaged approaches (Reisinger and Mooney, 2010; Huang et al., 2012) induce multi-sense embeddings by first clustering the contexts and then using the clustering to obtain the sense vectors. The contexts can be topics induced using latent topic models(Liu et al., 2015a,b), or Wikipedia (Wu and Giles, 2015) or coarse partof-speech tags (Qiu et al., 2014). A more recent line of work in the two-staged category is that of retrofitting (Faruqui et al., 2015; Jauhar et al., 2015), which aims to infuse semantic ontologies from resources like WordNet (Miller, 1995) and Framenet (Baker et al., 1998) into embeddings during a post-processing step. Such resources list (albeit not exhaustively) the senses of a word, and by retro-fitting it is possible to tease apart the different senses of a word. While some resources like WordNet (Miller, 1995) are available for many languages, they are not exhaustive in listing all possible senses. Indeed, the number senses of a word is highly dependent on the task and cannot be pre-determined using a lexicon (Kilgarriff, 1997). Ideally, the senses should be inferred in a data-driven manner, so that new senses not listed in such lexicons can be discovered."
W17-2613,C14-1048,0,0.515616,"training data to achieve competitive perforIntroduction Word embeddings (Turian et al., 2010; Mikolov et al., 2013, inter alia) represent a word as a point in a vector space. This space is able to capture semantic relationships: vectors of words with similar meanings have high cosine similarity (Turney, 2006; Turian et al., 2010). Use of embeddings as features has been shown to benefit sev101 Proceedings of the 2nd Workshop on Representation Learning for NLP, pages 101–110, c Vancouver, Canada, August 3, 2017. 2017 Association for Computational Linguistics mance. Recently, several approaches (Guo et al., 2014a; ˇ Suster et al., 2016) propose to learn multi-sense embeddings by exploiting the fact that different senses of the same word may be translated into different words in a foreign language (Dagan and Itai, 1994; Resnik and Yarowsky, 1999; Diab and Resnik, 2002; Ng et al., 2003). For example, bank in English may be translated to banc or banque in French, depending on whether the sense is financial or geographical. Such bilingual distributional information allows the model to identify which sense of a word is being used during training. However, bilingual distributional signals often do not suff"
W17-2613,N12-1095,0,0.29491,"Missing"
W17-2613,D14-1012,0,0.344701,"training data to achieve competitive perforIntroduction Word embeddings (Turian et al., 2010; Mikolov et al., 2013, inter alia) represent a word as a point in a vector space. This space is able to capture semantic relationships: vectors of words with similar meanings have high cosine similarity (Turney, 2006; Turian et al., 2010). Use of embeddings as features has been shown to benefit sev101 Proceedings of the 2nd Workshop on Representation Learning for NLP, pages 101–110, c Vancouver, Canada, August 3, 2017. 2017 Association for Computational Linguistics mance. Recently, several approaches (Guo et al., 2014a; ˇ Suster et al., 2016) propose to learn multi-sense embeddings by exploiting the fact that different senses of the same word may be translated into different words in a foreign language (Dagan and Itai, 1994; Resnik and Yarowsky, 1999; Diab and Resnik, 2002; Ng et al., 2003). For example, bank in English may be translated to banc or banque in French, depending on whether the sense is financial or geographical. Such bilingual distributional information allows the model to identify which sense of a word is being used during training. However, bilingual distributional signals often do not suff"
W17-2613,P14-2131,0,0.0701325,"Missing"
W17-2613,W11-2103,0,0.0360876,"Missing"
W17-2613,D15-1131,0,0.0208727,"n. 5: 8: Corpus Source they use a two step approach instead of joint learning. To avoid this, the vector for pairs like banco and banque should lie in the same space and close to each other and the sense vector for bank. The Ψ(y e , xf ) term attempts to ensure this by using the vector for banco and banque to predict the vector of bank. This way, the model brings the embedding space for Spanish and French closer by using English as a bridge language during joint training. A similar idea of using English as a bridging language was used in the models proposed in (Hermann and Blunsom, 2014) and (Coulmance et al., 2015). Beside the benefit in the multilingual case, the Ψ(y e , xf ) term improves performance in the bilingual case as well, as it forces the English and second language embeddings to remain close in space. To show the value of Ψ(y e , xf ) factor in our experiments, we ran a variant of Algorithm 1 without the Ψ(y e , xf ) factor, by only using monolingual neighborhood N br(xfi , F ) in line 12 of Algorithm 1. We call this variant O NE -S IDED model and the model in Algorithm 1 the F ULL model. Renormalize zi using softmax Update suff. stats. for q(β) like (Bartunov et al., 2016) Update θ using eq"
W17-2613,P12-1092,0,0.169714,"rate that our algorithm can achieve competitive performance after training on a small multilingual corpus, comparable to a model trained monolingually on a much larger corpus. We present an analysis discussing the effect of various parameters – choice of language family for deriving the multilingual signal, crosslingual window size etc. and also show qualitative improvement in the embedding space. 2 Related Work Work on inducing multi-sense embeddings can be divided in two broad categories – two-staged approaches and joint learning approaches. Twostaged approaches (Reisinger and Mooney, 2010; Huang et al., 2012) induce multi-sense embeddings by first clustering the contexts and then using the clustering to obtain the sense vectors. The contexts can be topics induced using latent topic models(Liu et al., 2015a,b), or Wikipedia (Wu and Giles, 2015) or coarse partof-speech tags (Qiu et al., 2014). A more recent line of work in the two-staged category is that of retrofitting (Faruqui et al., 2015; Jauhar et al., 2015), which aims to infuse semantic ontologies from resources like WordNet (Miller, 1995) and Framenet (Baker et al., 1998) into embeddings during a post-processing step. Such resources list (al"
W17-2613,J94-4003,0,0.454758,"emantic relationships: vectors of words with similar meanings have high cosine similarity (Turney, 2006; Turian et al., 2010). Use of embeddings as features has been shown to benefit sev101 Proceedings of the 2nd Workshop on Representation Learning for NLP, pages 101–110, c Vancouver, Canada, August 3, 2017. 2017 Association for Computational Linguistics mance. Recently, several approaches (Guo et al., 2014a; ˇ Suster et al., 2016) propose to learn multi-sense embeddings by exploiting the fact that different senses of the same word may be translated into different words in a foreign language (Dagan and Itai, 1994; Resnik and Yarowsky, 1999; Diab and Resnik, 2002; Ng et al., 2003). For example, bank in English may be translated to banc or banque in French, depending on whether the sense is financial or geographical. Such bilingual distributional information allows the model to identify which sense of a word is being used during training. However, bilingual distributional signals often do not suffice. It is common that polysemy for a word survives translation. Fig. 1 shows an illustrative example – both senses of interest get translated to int´erˆet in French. However, this becomes much less likely as t"
W17-2613,P02-1033,0,0.126259,"lar meanings have high cosine similarity (Turney, 2006; Turian et al., 2010). Use of embeddings as features has been shown to benefit sev101 Proceedings of the 2nd Workshop on Representation Learning for NLP, pages 101–110, c Vancouver, Canada, August 3, 2017. 2017 Association for Computational Linguistics mance. Recently, several approaches (Guo et al., 2014a; ˇ Suster et al., 2016) propose to learn multi-sense embeddings by exploiting the fact that different senses of the same word may be translated into different words in a foreign language (Dagan and Itai, 1994; Resnik and Yarowsky, 1999; Diab and Resnik, 2002; Ng et al., 2003). For example, bank in English may be translated to banc or banque in French, depending on whether the sense is financial or geographical. Such bilingual distributional information allows the model to identify which sense of a word is being used during training. However, bilingual distributional signals often do not suffice. It is common that polysemy for a word survives translation. Fig. 1 shows an illustrative example – both senses of interest get translated to int´erˆet in French. However, this becomes much less likely as the number of languages under consideration grows."
W17-2613,N15-1070,0,0.033469,"d Work Work on inducing multi-sense embeddings can be divided in two broad categories – two-staged approaches and joint learning approaches. Twostaged approaches (Reisinger and Mooney, 2010; Huang et al., 2012) induce multi-sense embeddings by first clustering the contexts and then using the clustering to obtain the sense vectors. The contexts can be topics induced using latent topic models(Liu et al., 2015a,b), or Wikipedia (Wu and Giles, 2015) or coarse partof-speech tags (Qiu et al., 2014). A more recent line of work in the two-staged category is that of retrofitting (Faruqui et al., 2015; Jauhar et al., 2015), which aims to infuse semantic ontologies from resources like WordNet (Miller, 1995) and Framenet (Baker et al., 1998) into embeddings during a post-processing step. Such resources list (albeit not exhaustively) the senses of a word, and by retro-fitting it is possible to tease apart the different senses of a word. While some resources like WordNet (Miller, 1995) are available for many languages, they are not exhaustive in listing all possible senses. Indeed, the number senses of a word is highly dependent on the task and cannot be pre-determined using a lexicon (Kilgarriff, 1997). Ideally, t"
W17-2613,N13-1073,0,0.0620526,"Missing"
W17-2613,eisele-chen-2010-multiun,0,0.0771084,"Missing"
W17-2613,2005.mtsummit-papers.11,0,0.0484288,"t of Algorithm 1 without the Ψ(y e , xf ) factor. M ONO refers to the AdaGram model of (Bartunov et al., 2016) trained on the English side of the parallel corpus. In all cases, the M ONO model is outperformed by O NE -S IDED and F ULL models, showing the benefit of using crosslingual signal in training. Best performance is attained by the multilingual model (En-FrZh), showing value of multilingual signal. The value of Ψ(y e , xf ) term is also verified by the fact that the O NE -S IDED model performs worse than the F ULL model. github.com/redpony/cdec first 100k lines from the En-Fr Europarl (Koehn, 2005) 106 Train Setting S-2007 En-FrEs En-RuZh S-2010 En-FrEs En-FrEs WWSI En-FrEs En-RuZh Avg. ARI En-FrEs En-RuZh (1) M ONO (2) O NE -S IDED (3) F ULL .035 .044 .046 .033 .044 .040 .046 .055 .056 .049 .063 .070 .054 .062 .068 .049 .057 .069 .045 .054 .057 .044 .055 .059 (3) - (1) .011 .007 .010 .021 .014 .020 .012 .015 Table 3: Effect (in ARI) of language family distance on WSI task. Best results for each column is shown in bold. The improvement from M ONO to F ULL is also shown as (3) - (1). Note that this is not comparable to results in Table 2, as we use a different training corpus to control"
W17-2613,N16-1163,0,0.169976,"a dense vector xf in Rm , and each word xe in English vocabulary admits at most T sense vectors, with the k th sense vector denoted as xek .2 As our main goal is to model multiple senses for words in English, we do not model polysemy in the foreign language and use a single vector to represent each word in the foreign vocabulary. We model the joint conditional distribution of the context words y e , y f given an English word xe and its corresponding translation xf on the parallel corpus: cent work has attempted to remedy this by using parallel text for retrofitting sense-specific embeddings (Ettinger et al., 2016), their procedure requires creation of sense graphs, which introduces additional tuning parameters. On the other hand, our approach only requires two tuning parameters (prior α and maximum number of senses T ). In contrast, joint learning approaches (Neelakantan et al., 2014; Li and Jurafsky, 2015) jointly learn the sense clusters and embeddings by using non-parametrics. Our approach belongs to this category. The closest non-parametric approach to ours is that of (Bartunov et al., 2016), who proposed a multi-sense variant of the skipgram model which learns the different number of sense vectors"
W17-2613,D15-1200,0,0.193321,"rt monolingual model trained on five times more training data. 1 I got high interest on my savings from the bank. My interest lies in History. Je suis un grand [intérêt] sur mes économies de la banque. Mon [intérêt] réside dans l'Histoire. [ [ ] ] Figure 1: Benefit of Multilingual Information (beyond bilingual): Two different senses of the word “interest” and their translations to French and Chinese (word translation shown in [bold]). While the surface form of both senses are same in French, they are different in Chinese. Several attempts (Reisinger and Mooney, 2010; Neelakantan et al., 2014; Li and Jurafsky, 2015) have been made to infer multi-sense word representations by modeling the sense as a latent variable in a Bayesian non-parametric framework. These approaches rely on the ”one-sense per collocation” heuristic (Yarowsky, 1995), which assumes that presence of nearby words correlate with the sense of the word of interest. This heuristic provides only a weak signal for sense identification, and such algorithms require large amount of training data to achieve competitive perforIntroduction Word embeddings (Turian et al., 2010; Mikolov et al., 2013, inter alia) represent a word as a point in a vector"
W17-2613,N15-1184,0,0.0172287,"edding space. 2 Related Work Work on inducing multi-sense embeddings can be divided in two broad categories – two-staged approaches and joint learning approaches. Twostaged approaches (Reisinger and Mooney, 2010; Huang et al., 2012) induce multi-sense embeddings by first clustering the contexts and then using the clustering to obtain the sense vectors. The contexts can be topics induced using latent topic models(Liu et al., 2015a,b), or Wikipedia (Wu and Giles, 2015) or coarse partof-speech tags (Qiu et al., 2014). A more recent line of work in the two-staged category is that of retrofitting (Faruqui et al., 2015; Jauhar et al., 2015), which aims to infuse semantic ontologies from resources like WordNet (Miller, 1995) and Framenet (Baker et al., 1998) into embeddings during a post-processing step. Such resources list (albeit not exhaustively) the senses of a word, and by retro-fitting it is possible to tease apart the different senses of a word. While some resources like WordNet (Miller, 1995) are available for many languages, they are not exhaustive in listing all possible senses. Indeed, the number senses of a word is highly dependent on the task and cannot be pre-determined using a lexicon (Kilgarr"
W17-2613,E14-1049,0,0.0282659,", who proposed a multi-sense variant of the skipgram model which learns the different number of sense vectors for all words from a large monolingual corpus (eg. English Wikipedia). Our work can be viewed as the multi-view extension of their model which leverages both monolingual and crosslingual distributional signals for learning the embeddings. In our experiments, we compare our model to monolingually trained version of their model. Incorporating crosslingual distributional information is a popular technique for learning word embeddings, and improves performance on several downstream tasks (Faruqui and Dyer, 2014; Guo et al., 2016; Upadhyay et al., 2016). However, there has been little work on learning multi-sense embeddings using crosslingual signals (Bansal ˇ et al., 2012; Guo et al., 2014a; Suster et al., 2016) ˇ with only (Suster et al., 2016) being a joint approach. (Kawakami and Dyer, 2015) also used bilingual distributional signals in a deep neural architecture to learn context dependent representations for words, though they do not learn separate sense vectors. 3 P (y e , y f |xe , xf ; α, θ), (1) where θ are model parameters (i.e. all embeddings) and α governs the hyper-prior on latent senses"
W17-2613,W16-2506,0,0.0461351,"Missing"
W17-2613,W15-1521,0,0.0326595,"dict monolingual and crosslingual context in both languages (see factors in eqn. (4)). We pick each sense (here 2nd) vector for interest, to perform weighted update. We only model polysemy in English. (line 5) and re-normalized (line 8). Using the updated sense distribution q(β)’s sufficient statistics is re-computed (line 9) and the global parameter θ is updated (line 10) as follows, X X θ ← θ + ρ t ∇θ zik log p(y|xi , k, θ) f P (y , y |z, x , x ; θ) ∝ Ψ(x , z, y )Ψ(x , y ) Ψ(xe , z, y f )Ψ(xf , y e ) (4) See Figure 2 for illustration of each factor. This modeling approach is reminiscent of (Luong et al., 2015), who jointly learned embeddings for two languages l1 and l2 by optimizing a joint objective containing 4 skip-gram terms using the aligned pair (xe ,xf )– two predicting monolingual contexts l1 → l1 , l2 → l2 , and two predicting crosslingual contexts l1 → l2 , l2 → l1 . k|zik > y∈yc (6) Note that in the above sum, a sense participates in a update only if its probability exceeds a threshold  (= 0.001). The final model retains sense vectors whose sense probability exceeds the same threshold. The last for-loop (line 11) jointly optimizes the foreign embeddings using English context with the s"
W17-2613,N13-1090,0,0.032839,"singer and Mooney, 2010; Neelakantan et al., 2014; Li and Jurafsky, 2015) have been made to infer multi-sense word representations by modeling the sense as a latent variable in a Bayesian non-parametric framework. These approaches rely on the ”one-sense per collocation” heuristic (Yarowsky, 1995), which assumes that presence of nearby words correlate with the sense of the word of interest. This heuristic provides only a weak signal for sense identification, and such algorithms require large amount of training data to achieve competitive perforIntroduction Word embeddings (Turian et al., 2010; Mikolov et al., 2013, inter alia) represent a word as a point in a vector space. This space is able to capture semantic relationships: vectors of words with similar meanings have high cosine similarity (Turney, 2006; Turian et al., 2010). Use of embeddings as features has been shown to benefit sev101 Proceedings of the 2nd Workshop on Representation Learning for NLP, pages 101–110, c Vancouver, Canada, August 3, 2017. 2017 Association for Computational Linguistics mance. Recently, several approaches (Guo et al., 2014a; ˇ Suster et al., 2016) propose to learn multi-sense embeddings by exploiting the fact that diff"
W17-2613,D14-1113,0,0.282629,"rmance to a state of the art monolingual model trained on five times more training data. 1 I got high interest on my savings from the bank. My interest lies in History. Je suis un grand [intérêt] sur mes économies de la banque. Mon [intérêt] réside dans l'Histoire. [ [ ] ] Figure 1: Benefit of Multilingual Information (beyond bilingual): Two different senses of the word “interest” and their translations to French and Chinese (word translation shown in [bold]). While the surface form of both senses are same in French, they are different in Chinese. Several attempts (Reisinger and Mooney, 2010; Neelakantan et al., 2014; Li and Jurafsky, 2015) have been made to infer multi-sense word representations by modeling the sense as a latent variable in a Bayesian non-parametric framework. These approaches rely on the ”one-sense per collocation” heuristic (Yarowsky, 1995), which assumes that presence of nearby words correlate with the sense of the word of interest. This heuristic provides only a weak signal for sense identification, and such algorithms require large amount of training data to achieve competitive perforIntroduction Word embeddings (Turian et al., 2010; Mikolov et al., 2013, inter alia) represent a wor"
W17-2613,P03-1058,0,0.0403249,"cosine similarity (Turney, 2006; Turian et al., 2010). Use of embeddings as features has been shown to benefit sev101 Proceedings of the 2nd Workshop on Representation Learning for NLP, pages 101–110, c Vancouver, Canada, August 3, 2017. 2017 Association for Computational Linguistics mance. Recently, several approaches (Guo et al., 2014a; ˇ Suster et al., 2016) propose to learn multi-sense embeddings by exploiting the fact that different senses of the same word may be translated into different words in a foreign language (Dagan and Itai, 1994; Resnik and Yarowsky, 1999; Diab and Resnik, 2002; Ng et al., 2003). For example, bank in English may be translated to banc or banque in French, depending on whether the sense is financial or geographical. Such bilingual distributional information allows the model to identify which sense of a word is being used during training. However, bilingual distributional signals often do not suffice. It is common that polysemy for a word survives translation. Fig. 1 shows an illustrative example – both senses of interest get translated to int´erˆet in French. However, this becomes much less likely as the number of languages under consideration grows. By looking at Chin"
W17-2613,N10-1013,0,0.324615,"ning yields comparable performance to a state of the art monolingual model trained on five times more training data. 1 I got high interest on my savings from the bank. My interest lies in History. Je suis un grand [intérêt] sur mes économies de la banque. Mon [intérêt] réside dans l'Histoire. [ [ ] ] Figure 1: Benefit of Multilingual Information (beyond bilingual): Two different senses of the word “interest” and their translations to French and Chinese (word translation shown in [bold]). While the surface form of both senses are same in French, they are different in Chinese. Several attempts (Reisinger and Mooney, 2010; Neelakantan et al., 2014; Li and Jurafsky, 2015) have been made to infer multi-sense word representations by modeling the sense as a latent variable in a Bayesian non-parametric framework. These approaches rely on the ”one-sense per collocation” heuristic (Yarowsky, 1995), which assumes that presence of nearby words correlate with the sense of the word of interest. This heuristic provides only a weak signal for sense identification, and such algorithms require large amount of training data to achieve competitive perforIntroduction Word embeddings (Turian et al., 2010; Mikolov et al., 2013, i"
W17-2613,I05-3027,0,0.0603154,"Missing"
W17-2613,P10-1040,0,0.0663875,"Several attempts (Reisinger and Mooney, 2010; Neelakantan et al., 2014; Li and Jurafsky, 2015) have been made to infer multi-sense word representations by modeling the sense as a latent variable in a Bayesian non-parametric framework. These approaches rely on the ”one-sense per collocation” heuristic (Yarowsky, 1995), which assumes that presence of nearby words correlate with the sense of the word of interest. This heuristic provides only a weak signal for sense identification, and such algorithms require large amount of training data to achieve competitive perforIntroduction Word embeddings (Turian et al., 2010; Mikolov et al., 2013, inter alia) represent a word as a point in a vector space. This space is able to capture semantic relationships: vectors of words with similar meanings have high cosine similarity (Turney, 2006; Turian et al., 2010). Use of embeddings as features has been shown to benefit sev101 Proceedings of the 2nd Workshop on Representation Learning for NLP, pages 101–110, c Vancouver, Canada, August 3, 2017. 2017 Association for Computational Linguistics mance. Recently, several approaches (Guo et al., 2014a; ˇ Suster et al., 2016) propose to learn multi-sense embeddings by exploit"
W17-2613,J06-3003,0,0.019958,"framework. These approaches rely on the ”one-sense per collocation” heuristic (Yarowsky, 1995), which assumes that presence of nearby words correlate with the sense of the word of interest. This heuristic provides only a weak signal for sense identification, and such algorithms require large amount of training data to achieve competitive perforIntroduction Word embeddings (Turian et al., 2010; Mikolov et al., 2013, inter alia) represent a word as a point in a vector space. This space is able to capture semantic relationships: vectors of words with similar meanings have high cosine similarity (Turney, 2006; Turian et al., 2010). Use of embeddings as features has been shown to benefit sev101 Proceedings of the 2nd Workshop on Representation Learning for NLP, pages 101–110, c Vancouver, Canada, August 3, 2017. 2017 Association for Computational Linguistics mance. Recently, several approaches (Guo et al., 2014a; ˇ Suster et al., 2016) propose to learn multi-sense embeddings by exploiting the fact that different senses of the same word may be translated into different words in a foreign language (Dagan and Itai, 1994; Resnik and Yarowsky, 1999; Diab and Resnik, 2002; Ng et al., 2003). For example,"
W17-2613,P16-1157,1,0.841674,"e skipgram model which learns the different number of sense vectors for all words from a large monolingual corpus (eg. English Wikipedia). Our work can be viewed as the multi-view extension of their model which leverages both monolingual and crosslingual distributional signals for learning the embeddings. In our experiments, we compare our model to monolingually trained version of their model. Incorporating crosslingual distributional information is a popular technique for learning word embeddings, and improves performance on several downstream tasks (Faruqui and Dyer, 2014; Guo et al., 2016; Upadhyay et al., 2016). However, there has been little work on learning multi-sense embeddings using crosslingual signals (Bansal ˇ et al., 2012; Guo et al., 2014a; Suster et al., 2016) ˇ with only (Suster et al., 2016) being a joint approach. (Kawakami and Dyer, 2015) also used bilingual distributional signals in a deep neural architecture to learn context dependent representations for words, though they do not learn separate sense vectors. 3 P (y e , y f |xe , xf ; α, θ), (1) where θ are model parameters (i.e. all embeddings) and α governs the hyper-prior on latent senses. Assume xe has multiple senses, which are"
W17-2613,N16-1160,0,0.188392,"Missing"
W17-2613,P95-1026,0,0.73262,"istoire. [ [ ] ] Figure 1: Benefit of Multilingual Information (beyond bilingual): Two different senses of the word “interest” and their translations to French and Chinese (word translation shown in [bold]). While the surface form of both senses are same in French, they are different in Chinese. Several attempts (Reisinger and Mooney, 2010; Neelakantan et al., 2014; Li and Jurafsky, 2015) have been made to infer multi-sense word representations by modeling the sense as a latent variable in a Bayesian non-parametric framework. These approaches rely on the ”one-sense per collocation” heuristic (Yarowsky, 1995), which assumes that presence of nearby words correlate with the sense of the word of interest. This heuristic provides only a weak signal for sense identification, and such algorithms require large amount of training data to achieve competitive perforIntroduction Word embeddings (Turian et al., 2010; Mikolov et al., 2013, inter alia) represent a word as a point in a vector space. This space is able to capture semantic relationships: vectors of words with similar meanings have high cosine similarity (Turney, 2006; Turian et al., 2010). Use of embeddings as features has been shown to benefit se"
W17-2613,C98-1013,0,\N,Missing
W19-4316,D18-1024,0,0.0237881,"The performance of these approaches is limited by the sufficiency of seed lexicons. Besides, parallel corpora methods (Gouws et al., 2015; Coulmance et al., 2015) leverage the aligned sentences in different languages and force the representations of corresponding sentence components to be similar. However, aligned sentences merely provide weak alignment of lexicons that do not accurately capture the one-to-one mapping of words, while such a mapping is well-desired by translation tasks (Upadhyay et al., 2016). In addition, a few unsupervised approaches alleviate the use of bilingual resources (Chen and Cardie, 2018; Conneau et al., 2018). These models require considerable effort to train and rely heavily on massive monolingual corpora. Monolingual lexical definitions have been used for weak supervision of monolingual word similarities (Tissier et al., 2017). Our work demonstrates that dictionary information can be extended to a cross-lingual scenario, for which we develop a simple yet effective induction method to populate fine-grain word alignment. 3.1 Bilingual Strong Pairs A bilingual strong pair contains two words with high semantic relevance. Such a pair of words that mutually contribute to the cro"
W19-4316,N16-1083,0,0.0175077,"wi , wj ) ∈ PlIi ,lj ⇔ ∃(wpi , wpj ) ∈ (wa ,wb )∈Ni (wj )∪Nj (wi ) For each word pair (wi , wj ), we use the unigram distribution raised to the power of 0.75 to select a number of words in lj (or li ) for wi (or wj ) to form a negative sample set Ni (wj ) (or Nj (wi )). Without loss of generality, we define the negative sample set as Ni (wj ) = {(wni , wj )|wni ∼ Ui (w)∧(wni , wj ) ∈ / P S ∪P D ∪P I }, where Ui (w) is the distribution of words in li . 4 We evaluate BilLex on two bilingual tasks: word translation and sentence translation retrieval. Following the convention (Gouws et al., 2015; Mogadala and Rettinger, 2016), we evaluate BilLex between English-French and EnglishSpanish. Accordingly, we extract word pairs from both directions of bilingual dictionaries in Wiktionary for these language pairs. To support the induced word pairs, we also extract monolingual lexical definitions in the three languages involved, which include 238k entries in English, 107k entries in French and 49k entries in Spanish. The word pair extraction process of BilLex excludes stop words and punctuation in the lexical definitions. The statistics of three types of extracted word pairs are reported in Table 1. PlSi ,lj , (wi , wpi )"
W19-4316,E17-1084,0,0.0190156,"respectively. BilLex significantly outperforms previous embedding methods on both tasks. 1 Introduction Bilingual word embeddings are the essential components of multilingual NLP systems. These embeddings capture cross-lingual semantic transfers of words and phrases from bilingual corpora, and are widely deployed in many NLP tasks, such as machine translation (Conneau et al., 2018), crosslingual Wikification (Tsai and Roth, 2016), knowledge alignment (Chen et al., 2018) and semantic search (Vuli´c and Moens, 2015). A variety of approaches have been proposed to learn bilingual word embeddings (Duong et al., 2017; Luong et al., 2015; Coulmance et al., 2015). Many such approaches rely on the use of aligned corpora. Such corpora could be seed lexicons that provide word-level mappings between two languages (Mikolov et al., 2013a; Xing et al., 2015), 1 We refer to dictionary in its regular meaning, i.e. the collections of word definitions. This is different from some papers that refer to dictionaries as seed lexicons. 142 Proceedings of the 4th Workshop on Representation Learning for NLP (RepL4NLP-2019), pages 142–147 c Florence, Italy, August 2, 2019. 2019 Association for Computational Linguistics 3 to a"
W19-4316,D17-1024,0,0.0836731,"In particular, Dli ,lj is a monolingual dictionary if li = lj and is a bilingual dictionary if li 6= lj . A dictionary Dli ,lj contains dictionary entries (wi , Qj (wi )), where wi ∈ Vli is the word being defined and Qj (wi ) is a sequence of words in lj describing the meaning of the word wi . Fig. 1(a) shows an entry from an English-French dictionary, and one from a French-English dictionary. BilLex allows us to exploit semantically related word pairs in two stages. We first use bilingual dictionaries to construct bilingual strong pairs, which are similar to those monolingual word pairs in (Tissier et al., 2017). Then based on the given strong word pairs and monolingual dictionaries, we provide two types of induced word pairs to further enhance the cross-lingual learning. Related Work Prior approaches to learning bilingual word embeddings often rely on word or sentence alignment (Ruder et al., 2017). In particular, seed lexicon methods (Mikolov et al., 2013a; Faruqui and Dyer, 2014; Guo et al., 2015) learn transformations across different language-specific embedding spaces based on predefined word alignment. The performance of these approaches is limited by the sufficiency of seed lexicons. Besides,"
W19-4316,E14-1049,0,0.0290062,"h-English dictionary. BilLex allows us to exploit semantically related word pairs in two stages. We first use bilingual dictionaries to construct bilingual strong pairs, which are similar to those monolingual word pairs in (Tissier et al., 2017). Then based on the given strong word pairs and monolingual dictionaries, we provide two types of induced word pairs to further enhance the cross-lingual learning. Related Work Prior approaches to learning bilingual word embeddings often rely on word or sentence alignment (Ruder et al., 2017). In particular, seed lexicon methods (Mikolov et al., 2013a; Faruqui and Dyer, 2014; Guo et al., 2015) learn transformations across different language-specific embedding spaces based on predefined word alignment. The performance of these approaches is limited by the sufficiency of seed lexicons. Besides, parallel corpora methods (Gouws et al., 2015; Coulmance et al., 2015) leverage the aligned sentences in different languages and force the representations of corresponding sentence components to be similar. However, aligned sentences merely provide weak alignment of lexicons that do not accurately capture the one-to-one mapping of words, while such a mapping is well-desired b"
W19-4316,N16-1072,0,0.0191975,"d word alignment from lexical definitions. We evaluate BilLex in word-level and sentence-level translation tasks, which seek to find the cross-lingual counterparts of words and sentences respectively. BilLex significantly outperforms previous embedding methods on both tasks. 1 Introduction Bilingual word embeddings are the essential components of multilingual NLP systems. These embeddings capture cross-lingual semantic transfers of words and phrases from bilingual corpora, and are widely deployed in many NLP tasks, such as machine translation (Conneau et al., 2018), crosslingual Wikification (Tsai and Roth, 2016), knowledge alignment (Chen et al., 2018) and semantic search (Vuli´c and Moens, 2015). A variety of approaches have been proposed to learn bilingual word embeddings (Duong et al., 2017; Luong et al., 2015; Coulmance et al., 2015). Many such approaches rely on the use of aligned corpora. Such corpora could be seed lexicons that provide word-level mappings between two languages (Mikolov et al., 2013a; Xing et al., 2015), 1 We refer to dictionary in its regular meaning, i.e. the collections of word definitions. This is different from some papers that refer to dictionaries as seed lexicons. 142 P"
W19-4316,P16-1157,0,0.0188204,"earn transformations across different language-specific embedding spaces based on predefined word alignment. The performance of these approaches is limited by the sufficiency of seed lexicons. Besides, parallel corpora methods (Gouws et al., 2015; Coulmance et al., 2015) leverage the aligned sentences in different languages and force the representations of corresponding sentence components to be similar. However, aligned sentences merely provide weak alignment of lexicons that do not accurately capture the one-to-one mapping of words, while such a mapping is well-desired by translation tasks (Upadhyay et al., 2016). In addition, a few unsupervised approaches alleviate the use of bilingual resources (Chen and Cardie, 2018; Conneau et al., 2018). These models require considerable effort to train and rely heavily on massive monolingual corpora. Monolingual lexical definitions have been used for weak supervision of monolingual word similarities (Tissier et al., 2017). Our work demonstrates that dictionary information can be extended to a cross-lingual scenario, for which we develop a simple yet effective induction method to populate fine-grain word alignment. 3.1 Bilingual Strong Pairs A bilingual strong pa"
W19-4316,P15-1119,0,0.0241206,"lLex allows us to exploit semantically related word pairs in two stages. We first use bilingual dictionaries to construct bilingual strong pairs, which are similar to those monolingual word pairs in (Tissier et al., 2017). Then based on the given strong word pairs and monolingual dictionaries, we provide two types of induced word pairs to further enhance the cross-lingual learning. Related Work Prior approaches to learning bilingual word embeddings often rely on word or sentence alignment (Ruder et al., 2017). In particular, seed lexicon methods (Mikolov et al., 2013a; Faruqui and Dyer, 2014; Guo et al., 2015) learn transformations across different language-specific embedding spaces based on predefined word alignment. The performance of these approaches is limited by the sufficiency of seed lexicons. Besides, parallel corpora methods (Gouws et al., 2015; Coulmance et al., 2015) leverage the aligned sentences in different languages and force the representations of corresponding sentence components to be similar. However, aligned sentences merely provide weak alignment of lexicons that do not accurately capture the one-to-one mapping of words, while such a mapping is well-desired by translation tasks"
W19-4316,P16-1024,0,0.0368093,"Missing"
W19-4316,P14-1006,0,0.0212681,"cted from 0 to 10 with the step of 1. λP S is set to 0.9, which is tuned from 0 to 1 with the step of 0.1. As we assume that the strong pair relations between words are independent, we empirically set λP D = (λP S )2 = 0.81 and λP I = (λP S )3 = 0.729. We minimize the loss function using AMSGrad (Reddi et al., 2018) with a learning rate of 0.001. The training is terminated based on early stopping. We limit the vocabularies as the 200k most frequent words in each language, and exclude the bilingual strong pairs that have appeared in the test set. The baselines we compare against include BiCVM (Hermann and Blunsom, 2014), BilBOWA (Gouws et al., 2015), Biskip (Luong et al., 2015), supervised and unsupervised MUSE (Conneau et al., 2018). Results. Results are summarized in Table 2, where the performance of BilLex is reported for three variants: (i) training with bilingual strong pairs only BilLex(P S ), (ii) with directly induced pair added BilLex(P S +P D ), and (iii) with all three types of word pairs BilLex(P S +P D +P I ). BilLex(P S +P D +P I ) thereof, offers consistently better performance in all settings, which implies 4.2 Sentence translation retrieval This task focuses on retrieving the sentence in the"
W19-4316,C12-1089,0,0.0397479,"Missing"
W19-4316,N15-1104,0,0.0476808,"Missing"
W19-4316,W15-1521,0,0.151557,"significantly outperforms previous embedding methods on both tasks. 1 Introduction Bilingual word embeddings are the essential components of multilingual NLP systems. These embeddings capture cross-lingual semantic transfers of words and phrases from bilingual corpora, and are widely deployed in many NLP tasks, such as machine translation (Conneau et al., 2018), crosslingual Wikification (Tsai and Roth, 2016), knowledge alignment (Chen et al., 2018) and semantic search (Vuli´c and Moens, 2015). A variety of approaches have been proposed to learn bilingual word embeddings (Duong et al., 2017; Luong et al., 2015; Coulmance et al., 2015). Many such approaches rely on the use of aligned corpora. Such corpora could be seed lexicons that provide word-level mappings between two languages (Mikolov et al., 2013a; Xing et al., 2015), 1 We refer to dictionary in its regular meaning, i.e. the collections of word definitions. This is different from some papers that refer to dictionaries as seed lexicons. 142 Proceedings of the 4th Workshop on Representation Learning for NLP (RepL4NLP-2019), pages 142–147 c Florence, Italy, August 2, 2019. 2019 Association for Computational Linguistics 3 to automatically cultiva"
