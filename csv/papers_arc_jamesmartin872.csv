2020.louhi-1.12,Defining and Learning Refined Temporal Relations in the Clinical Narrative,2020,-1,-1,7,0,17864,kristin wrightbettner,Proceedings of the 11th International Workshop on Health Text Mining and Information Analysis,0,"We present refinements over existing temporal relation annotations in the Electronic Medical Record clinical narrative. We refined the THYME corpus annotations to more faithfully represent nuanced temporality and nuanced temporal-coreferential relations. The main contributions are in re-defining CONTAINS and OVERLAP relations into CONTAINS, CONTAINS-SUBEVENT, OVERLAP and NOTED-ON. We demonstrate that these refinements lead to substantial gains in learnability for state-of-the-art transformer models as compared to previously reported results on the original THYME corpus. We thus establish a baseline for the automatic extraction of these refined temporal relations. Although our study is done on clinical narrative, we believe it addresses far-reaching challenges that are corpus- and domain- agnostic."
P17-1043,{A}bstract {M}eaning {R}epresentation Parsing using {LSTM} Recurrent Neural Networks,2017,21,13,2,1,32606,william foland,Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"We present a system which parses sentences into Abstract Meaning Representations, improving state-of-the-art results for this task by more than 5{\%}. AMR graphs represent semantic content using linguistic properties such as semantic roles, coreference, negation, and more. The AMR parser does not rely on a syntactic pre-parse, or heavily engineered features, and uses five recurrent neural networks as the key architectural components for inferring AMR graphs."
S16-1185,{CU}-{NLP} at {S}em{E}val-2016 Task 8: {AMR} Parsing using {LSTM}-based Recurrent Neural Networks,2016,9,1,2,1,32606,william foland,Proceedings of the 10th International Workshop on Semantic Evaluation ({S}em{E}val-2016),0,None
L16-1558,A Tangled Web: The Faint Signals of Deception in Text - Boulder Lies and Truth Corpus ({BLT}-{C}),2016,0,0,3,0,35295,franco salvetti,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"We present an approach to creating corpora for use in detecting deception in text, including a discussion of the challenges peculiar to this task. Our approach is based on soliciting several types of reviews from writers and was implemented using Amazon Mechanical Turk. We describe the multi-dimensional corpus of reviews built using this approach, available free of charge from LDC as the Boulder Lies and Truth Corpus (BLT-C). Challenges for both corpus creation and the deception detection include the fact that human performance on the task is typically at chance, that the signal is faint, that paid writers such as turkers are sometimes deceptive, and that deception is a complex human behavior; manifestations of deception depend on details of domain, intrinsic properties of the deceiver (such as education, linguistic competence, and the nature of the intention), and specifics of the deceptive act (e.g., lying vs. fabricating.) To overcome the inherent lack of ground truth, we have developed a set of semi-automatic techniques to ensure corpus validity. We present some preliminary results on the task of deception detection which suggest that the BLT-C is an improvement in the quality of resources available for this task."
S15-1013,{SGR}ank: Combining Statistical and Graphical Methods to Improve the State of the Art in Unsupervised Keyphrase Extraction,2015,20,28,3,0,37313,soheil danesh,Proceedings of the Fourth Joint Conference on Lexical and Computational Semantics,0,"Keyphrase extraction is a fundamental technique in natural language processing. It enables documents to be mapped to a concise set of phrases that can be used for indexing, clustering, ontology building, auto-tagging and other information organization schemes. Two major families of unsupervised keyphrase extraction algorithms may be characterized as statistical and graph-based. We present a hybrid statistical-graphical algorithm that capitalizes on the heuristics of both families of algorithms and is able to outperform the state of the art in unsupervised keyphrase extraction on several datasets."
S15-1033,Dependency-Based Semantic Role Labeling using Convolutional Neural Networks,2015,17,7,2,1,32606,william foland,Proceedings of the Fourth Joint Conference on Lexical and Computational Semantics,0,"We describe a semantic role labeler with stateof-the-art performance and low computational requirements, which uses convolutional and time-domain neural networks. The system is designed to work with features derived from a dependency parser output. Various system options and architectural details are discussed. Incremental experiments were run to explore the benefits of adding increasingly more complex dependency-based features to the system; results are presented for both in-domain and out-of-domain datasets."
W12-2002,Identifying science concepts and student misconceptions in an interactive essay writing tutor,2012,12,7,5,0.965617,224,steven bethard,Proceedings of the Seventh Workshop on Building Educational Applications Using {NLP},0,"We present initial steps towards an interactive essay writing tutor that improves science knowledge by analyzing student essays for misconceptions and recommending science webpages that help correct those misconceptions. We describe the five components in this system: identifying core science concepts, determining appropriate pedagogical sequences for the science concepts, identifying student misconceptions in essays, aligning student misconceptions to science concepts, and recommending webpages to address misconceptions. We provide initial models and evaluations of the models for each component."
corvey-etal-2012-foundations,Foundations of a Multilayer Annotation Framework for {T}witter Communications During Crisis Events,2012,12,18,5,1,43313,william corvey,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"In times of mass emergency, vast amounts of data are generated via computer-mediated communication (CMC) that are difficult to manually collect and organize into a coherent picture. Yet valuable information is broadcast, and can provide useful insight into time- and safety-critical situations if captured and analyzed efficiently and effectively. We describe a natural language processing component of the EPIC (Empowering the Public with Information in Crisis) Project infrastructure, designed to extract linguistic and behavioral information from tweet text to aid in the task of information integration. The system incorporates linguistic annotation, in the form of Named Entity Tagging, as well as behavioral annotations to capture tweets contributing to situational awareness and analyze the information type of the tweet content. We show classification results and describe future integration of these classifiers in the larger EPIC infrastructure."
W09-2002,Topic Model Analysis of Metaphor Frequency for Psycholinguistic Stimuli,2009,16,11,3,1,224,steven bethard,Proceedings of the Workshop on Computational Approaches to Linguistic Creativity,0,"Psycholinguistic studies of metaphor processing must control their stimuli not just for word frequency but also for the frequency with which a term is used metaphorically. Thus, we consider the task of metaphor frequency estimation, which predicts how often target words will be used metaphorically. We develop metaphor classifiers which represent metaphorical domains through Latent Dirichlet Allocation, and apply these classifiers to the target words, aggregating their decisions to estimate the metaphorical frequencies. Training on only 400 sentences, our models are able to achieve 61.3% accuracy on metaphor classification and 77.8% accuracy on High vs. Low metaphorical frequency estimation."
W08-0902,Classification Errors in a Domain-Independent Assessment System,2008,22,8,3,0,24264,rodney nielsen,Proceedings of the Third Workshop on Innovative Use of {NLP} for Building Educational Applications,0,"We present a domain-independent technique for assessing learners' constructed responses. The system exceeds the accuracy of the majority class baseline by 15.4% and a lexical baseline by 5.9%. The emphasis of this paper is to provide an error analysis of performance, describing the types of errors committed, their frequency, and some issues in their resolution."
P08-2005,Extractive Summaries for Educational Science Content,2008,13,0,3,0,47872,sebastian chica,"Proceedings of ACL-08: HLT, Short Papers",0,This paper describes an extractive summarizer for educational science content called COGENT. COGENT extends MEAD based on strategies elicited from an empirical study with domain and instructional experts. COGENT implements a hybrid approach integrating both domain independent sentence scoring features and domain-aware features. Initial evaluation results indicate that COGENT outperforms existing summarizers and generates summaries that closely resemble those generated by human experts.
P08-2045,Learning Semantic Links from a Corpus of Parallel Temporal and Causal Relations,2008,10,49,2,1,224,steven bethard,"Proceedings of ACL-08: HLT, Short Papers",0,"Finding temporal and causal relations is crucial to understanding the semantic structure of a text. Since existing corpora provide no parallel temporal and causal annotations, we annotated 1000 conjoined event pairs, achieving inter-annotator agreement of 81.2% on temporal relations and 77.8% on causal relations. We trained machine learning models using features derived from WordNet and the Google N-gram corpus, and they outperformed a variety of baselines, achieving an F-measure of 49.0 for temporals and 52.4 for causals. Analysis of these models suggests that additional data will improve performance, and that temporal information is crucial to causal relation identification."
P08-2061,Extracting a Representation from Text for Semantic Analysis,2008,11,7,3,0,24264,rodney nielsen,"Proceedings of ACL-08: HLT, Short Papers",0,"We present a novel fine-grained semantic representation of text and an approach to constructing it. This representation is largely extractable by today's technologies and facilitates more detailed semantic analysis. We discuss the requirements driving the representation, suggest how it might be of value in the automated tutoring domain, and provide evidence of its validity."
bethard-etal-2008-building,Building a Corpus of Temporal-Causal Structure,2008,18,33,4,1,224,steven bethard,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"While recent corpus annotation efforts cover a wide variety of semantic structures, work on temporal and causal relations is still in its early stages. Annotation efforts have typically considered either temporal relations or causal relations, but not both, and no corpora currently exist that allow the relation between temporals and causals to be examined empirically. We have annotated a corpus of 1000 event pairs for both temporal and causal relations, focusing on a relatively frequent construction in which the events are conjoined by the word ÂandÂ. Temporal relations were annotated using an extension of the BEFORE and AFTER scheme used in the TempEval competition, and causal relations were annotated using a scheme based on connective phrases like Âand as a resultÂ. The annotators achieved 81.2{\%} agreement on temporal relations and 77.8{\%} agreement on causal relations. Analysis of the resulting corpus revealed some interesting findings, for example, that over 30{\%} of CAUSAL relations do not have an underlying BEFORE relation. The corpus was also explored using machine learning methods, and while model performance exceeded all baselines, the results suggested that simple grammatical cues may be insufficient for identifying the more difficult temporal and causal relations."
nielsen-etal-2008-annotating,Annotating Students{'} Understanding of Science Concepts,2008,18,28,3,0,24264,rodney nielsen,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"This paper summarizes the annotation of fine-grained entailment relationships in the context of student answers to science assessment questions. We annotated a corpus of 15,357 answer pairs with 145,911 fine-grained entailment relationships. We provide the rationale for such fine-grained analysis and discuss its perceived benefits to an Intelligent Tutoring System. The corpus also has potential applications in other areas, such as question answering and multi-document summarization. Annotators achieved 86.2{\%} inter-annotator agreement (Kappa=0.728, corresponding to substantial agreement) annotating the fine-grained facets of reference answers with regard to understanding expressed in student answers and labeling from one of five possible detailed relationship categories. The corpus described in this paper, which is the only one providing such detailed entailment annotations, is available as a public resource for the research community. The corpus is expected to enable application development, not only for intelligent tutoring systems, but also for general textual entailment applications, that is currently not practical."
J08-2006,Towards Robust Semantic Role Labeling,2008,-1,-1,3,1,11322,sameer pradhan,Computational Linguistics,0,None
C08-1023,Pedagogically Useful Extractive Summaries for Science Education,2008,19,7,3,0,47872,sebastian chica,Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008),0,This paper describes the design and evaluation of an extractive summarizer for educational science content called COGENT. COGENT extends MEAD based on strategies elicited from an empirical study with science domain and instructional design experts. COGENT identifies sentences containing pedagogically relevant concepts for a specific science domain. The algorithms pursue a hybrid approach integrating both domain independent bottom-up sentence scoring features and domain-aware top-down features. Evaluation results indicate that COGENT outperforms existing summarizers and generates summaries that closely resemble those generated by human experts. COGENT concept inventories appear to also support the computational identification of student misconceptions about earthquakes and plate tectonics.
S07-1024,{CU}-{COMSEM}: Exploring Rich Features for Unsupervised Web Personal Name Disambiguation,2007,12,33,2,0,12273,ying chen,Proceedings of the Fourth International Workshop on Semantic Evaluations ({S}em{E}val-2007),0,"The increasing number of web sources is exacerbating the named-entity ambiguity problem. This paper explores the use of various token-based and phrase-based features in unsupervised clustering of web pages containing personal names. From these experiments, we find that the use of rich features can significantly improve the disambiguation performance for web personal names."
S07-1025,{CU}-{TMP}: Temporal Relation Classification Using Syntactic and Semantic Features,2007,5,60,2,1,224,steven bethard,Proceedings of the Fourth International Workshop on Semantic Evaluations ({S}em{E}val-2007),0,"We approached the temporal relation identification tasks of TempEval 2007 as pair-wise classification tasks. We introduced a variety of syntactically and semantically motivated features, including temporal-logic-based features derived from running our Task B system on the Task A and C data. We trained support vector machine models and achieved the second highest accuracies on the tasks: 61% on Task A, 75% on Task B and 54% on Task C."
N07-1070,Towards Robust Semantic Role Labeling,2007,51,107,3,1,11322,sameer pradhan,Human Language Technologies 2007: The Conference of the North {A}merican Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference,0,"Most semantic role labeling (SRL) research has been focused on training and evaluating on the same corpus. This strategy, although appropriate for initiating research, can lead to overtraining to the particular corpus. This article describes the operation of assert, a state-of-the art SRL system, and analyzes the robustness of the system when trained on one genre of data and used to label a different genre. As a starting point, results are first presented for training and testing the system on the PropBank corpus, which is annotated Wall Street Journal (WSJ) data. Experiments are then presented to evaluate the portability of the system to another source of data. These experiments are based on comparisons of performance using PropBanked WSJ data and PropBanked Brown Corpus data. The results indicate that whereas syntactic parses and argument identification transfer relatively well to a new corpus, argument classification does not. An analysis of the reasons for this is presented and these generally point to the nature of the more lexical/semantic features dominating the classification task where more general structural features are dominant in the argument identification task."
D07-1020,Towards Robust Unsupervised Personal Name Disambiguation,2007,15,51,2,0,12273,ying chen,Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning ({EMNLP}-{C}o{NLL}),0,"The increasing use of large open-domain document sources is exacerbating the problem of ambiguity in named entities. This paper explores the use of a range of syntactic and semantic features in unsupervised clustering of documents that result from ad hoc queries containing names. From these experiments, we find that the use of robust syntactic and semantic features can significantly improve the state of the art for disambiguation performance for personal names for both Chinese and English."
W06-1618,Identification of Event Mentions and their Semantic Class,2006,11,55,2,1,224,steven bethard,Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,0,"Complex tasks like question answering need to be able to identify events in text and the relations among those events. We show that this event identification task and a related task, identifying the semantic class of these events, can both be formulated as classification problems in a word-chunking paradigm. We introduce a variety of linguistically motivated features for this task and then train a system that is able to identify events with a precision of 82% and a recall of 71%. We then show a variety of analyses of this model, and their implications for the event identification task."
W05-0634,Semantic Role Chunking Combining Complementary Syntactic Views,2005,14,60,4,1,11322,sameer pradhan,Proceedings of the Ninth Conference on Computational Natural Language Learning ({C}o{NLL}-2005),0,"This paper describes a semantic role labeling system that uses features derived from different syntactic views, and combines them within a phrase-based chunking paradigm. For an input sentence, syntactic constituent structure parses are generated by a Charniak parser and a Collins parser. Semantic role labels are assigned to the constituents of each parse using Support Vector Machine classifiers. The resulting semantic role labels are converted to an IOB representation. These IOB representations are used as additional features, along with flat syntactic chunks, by a chunking SVM classifier that produces the final SRL output. This strategy for combining features from three different syntactic views gives a significant improvement in performance over roles produced by using any one of the syntactic views individually."
P05-1072,Semantic Role Labeling Using Different Syntactic Views,2005,24,94,4,1,11322,sameer pradhan,Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics ({ACL}{'}05),1,"Semantic role labeling is the process of annotating the predicate-argument structure in text with semantic labels. In this paper we present a state-of-the-art baseline semantic role labeling system based on Support Vector Machine classifiers. We show improvements on this system by: i) adding new features including features extracted from dependency parses, ii) performing feature selection and calibration and iii) combining parses obtained from semantic parsers trained using different syntactic views. Error analysis of the baseline system showed that approximately half of the argument identification errors resulted from parse errors in which there was no syntactic constituent that aligned with the correct argument. In order to address this problem, we combined semantic parses from a Minipar syntactic parse and from a chunked syntactic representation with our original baseline system which was based on Charniak parses. All of the reported techniques resulted in performance improvements."
W04-2416,Semantic Role Labeling by Tagging Syntactic Chunks,2004,6,88,4,0.637255,47311,kadri hacioglu,Proceedings of the Eighth Conference on Computational Natural Language Learning ({C}o{NLL}-2004) at {HLT}-{NAACL} 2004,0,None
N04-4036,Parsing Arguments of Nominalizations in {E}nglish and {C}hinese,2004,17,28,4,1,11322,sameer pradhan,Proceedings of {HLT}-{NAACL} 2004: Short Papers,0,"In this paper, we use a machine learning framework for semantic argument parsing, and apply it to the task of parsing arguments of eventive nominalizations in the FrameNet database. We create a baseline system using a subset of features introduced by Gildea and Jurafsky (2002), which are directly applicable to nominal predicates. We then investigate new features which are designed to capture the novelties in nominal argument structure and show a significant performance improvement using these new features. We also investigate the parsing performance of nominalizations in Chinese and compare the salience of the features for the two languages."
N04-1030,Shallow Semantic Parsing using Support Vector Machines,2004,19,328,4,1,11322,sameer pradhan,Proceedings of the Human Language Technology Conference of the North {A}merican Chapter of the Association for Computational Linguistics: {HLT}-{NAACL} 2004,0,None
A97-1025,Contextual Spelling Correction Using Latent Semantic Analysis,1997,16,61,2,0,29423,michael jones,Fifth Conference on Applied Natural Language Processing,0,"Contextual spelling errors are defined as the use of an incorrect, though valid, word in a particular sentence or context. Traditional spelling checkers flag misspelled words, but they do not typically attempt to identify words that are used incorrectly in a sentence. We explore the use of Latent Semantic Analysis for correcting these incorrectly used words and the results are compared to earlier work based on a Bayesian classifier."
J95-1002,Expressing Rhetorical Relations in Instructional Text: a case study of the purpose relation,1995,48,39,2,0,47769,keith linden,Computational Linguistics,0,"Natural language provides an extensive set of lexical and grammatical forms for expressing concepts, a set from which writers choose the particular form that they feel will produce the most effective expression given the communicative context. An important task of the text generation researcher is to specify both the range of these forms and the contexts in which they are used. This paper addresses this issue in the context of the expression of procedural relations between actions in instructional text. It employs the following four-step approach to achieve this goal: (1) collect a corpus of the relevant text type; (2) perform a detailed linguistic study of a portion of this corpus, called the training set, and reserve the remainder as a testing set; (3) implement the results of this study in a text generation system; and (4) compare the output of the system with the text found in the entire corpus. This has resulted in the construction of IMAGENE, an instructional text generation system that embodies a model of the forms of expression consistently used by instructional text writers over a broad range of instruction types. The details of IMAGENE's treatment of purpose expressions are given as representative of the coverage and form of the full system."
J92-1011,Knowledge Representation and Metaphor,1992,7,11,1,1,18430,james martin,Computational Linguistics,0,None
W91-0206,Conventional Metaphor and the Lexicon,1991,15,2,1,1,18430,james martin,Lexical Semantics and Knowledge Representation,0,"Metaphor and other forms of non-literal language are essential parts of language which have direct bearing on theories of lexical semantics. Neither narrow theories of lexical semantics, nor theories relying solely on world knowledge are sufficient to account for our ability to generate and interpret non-literal language. This paper presents an emerging approach that may provide such an account. This approach is based on systematic representations that capture non-literal language conventions, and mechanisms that can dynamically understand and learn new uses as they are encountered."
J88-4003,The {B}erkeley {U}nix {C}onsultant Project,1988,0,0,4,0,57376,robert wilensky,Computational Linguistics,0,"UC (UNIX Consultant) is an intelligent, natural language interface that allows naive users to learn about the UNIX2 operating system. UC was undertaken because the task was thought to be both a fer..."
C88-1081,Representing Regularities in the Metaphoric Lexicon,1988,10,14,1,1,18430,james martin,{C}oling {B}udapest 1988 Volume 1: {I}nternational {C}onference on {C}omputational {L}inguistics,0,"This paper describes a system for representing knowledge about conventional metaphors for use by natural language analysis, generation and acquisition systems. A system of hierarchically related structured associations is used. These associations are implemented as a part of the KODIAK representation language. Particular attention is paid in this paper to representational mechanisms that can capture generalizations over the system of conventional metaphors as a whole."
