2021.bsnlp-1.15,"Slav-{NER}: the 3rd Cross-lingual Challenge on Recognition, Normalization, Classification, and Linking of Named Entities across {S}lavic Languages",2021,-1,-1,2,0,6080,jakub piskorski,Proceedings of the 8th Workshop on Balto-Slavic Natural Language Processing,0,"This paper describes Slav-NER: the 3rd Multilingual Named Entity Challenge in Slavic languages. The tasks involve recognizing mentions of named entities in Web documents, normalization of the names, and cross-lingual linking. The Challenge covers six languages and five entity types, and is organized as part of the 8th Balto-Slavic Natural Language Processing Workshop, co-located with the EACL 2021 Conference. Ten teams participated in the competition. Performance for the named entity recognition task reached 90{\%} F-measure, much higher than reported in the first edition of the Challenge. Seven teams covered all six languages, and five teams participated in the cross-lingual entity linking task. Detailed valuation information is available on the shared task web page."
W19-3701,Unsupervised Induction of {U}krainian Morphological Paradigms for the New Lexicon: Extending Coverage for Named Entities and Neologisms using Inflection Tables and Unannotated Corpora,2019,0,0,1,1,12054,bogdan babych,Proceedings of the 7th Workshop on Balto-Slavic Natural Language Processing,0,"The paper presents an unsupervised method for quickly extending a Ukrainian lexicon by generating paradigms and morphological feature structures for new Named Entities and neologisms, which are not covered by existing static morphological resources. This approach addresses a practical problem of modelling paradigms for entities created by the dynamic processes in the lexicon: this problem is especially serious for highly-inflected languages in domains with specialised or quickly changing lexicon. The method uses an unannotated Ukrainian corpus and a small fixed set of inflection tables, which can be found in traditional grammar textbooks. The advantage of the proposed approach is that updating the morphological lexicon does not require training or linguistic annotation, allowing fast knowledge-light extension of an existing static lexicon to improve morphological coverage on a specific corpus. The method is implemented in an open-source package on a GitHub repository. It can be applied to other low-resourced inflectional languages which have internet corpora and linguistic descriptions of their inflection system, following the example of inflection tables for Ukrainian. Evaluation results shows consistent improvements in coverage for Ukrainian corpora of different corpus types."
W16-3402,Graphonological {L}evenshtein Edit Distance: Application for Automated Cognate Identification,2016,20,0,1,1,12054,bogdan babych,Proceedings of the 19th Annual Conference of the {E}uropean Association for Machine Translation,0,"This paper presents a methodology for calculating a modified Levenshtein edit distance between character strings, and applies it to the task of automated cognate identification from non-parallel (comparable) corpora. This task is an important stage in developing MT systems and bilingual dictionaries beyond the coverage of traditionally used aligned parallel corpora, which can be used for finding translation equivalents for the xe2x80x98long tailxe2x80x99 in Zipfian distribution: low-frequency and usually unambiguous lexical items in closely-related languages (many of those often under-resourced). Graphonological Levenshtein edit distance relies on editing hierarchical representations of phonological features for graphemes (graphonological representations) and improves on phonological edit distance proposed for measuring dialectological variation. Graphonological edit distance works directly with character strings and does not require an intermediate stage of phonological transcription, exploiting the advantages of historical and morphological principles of orthography, which are obscured if only phonetic principle is applied. Difficulties associated with plain feature representations (unstructured feature sets or vectors) are addressed by using linguistically-motivated feature hierarchy that restricts matching of lower-level graphonological features when higher-level features are not matched. The paper presents an evaluation of the graphonological edit distance in comparison with the traditional Levenshtein edit distance from the perspective of its usefulness for the task of automated cognate identification. It discusses the advantages of the proposed method, which can be used for morphology induction, for robust transliteration across different alphabets (Latin, Cyrillic, Arabic, etc.) and robust identification of words with non-standard or distorted spelling, e.g., in user-generated content on the web such as posts on social media, blogs and comments. Software for calculating the modified feature-based Levenshtein distance, and the corresponding graphonological feature representations (vectors and the hierarchies of graphemesxe2x80x99 features) are released on the authorxe2x80x99s webpage: http://corpus.leeds.ac.uk/bogdan/phonologylevenshtein/. Features are currently available for Latin and Cyrillic alphabets and will be extended to other alphabets and languages."
L16-1581,{M}o{B}i{L}: A Hybrid Feature Set for Automatic Human Translation Quality Assessment,2016,18,1,3,0,17072,yu yuan,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"In this paper we introduce MoBiL, a hybrid Monolingual, Bilingual and Language modelling feature set and feature selection and evaluation framework. The set includes translation quality indicators that can be utilized to automatically predict the quality of human translations in terms of content adequacy and language fluency. We compare MoBiL with the QuEst baseline set by using them in classifiers trained with support vector machine and relevance vector machine learning algorithms on the same data set. We also report an experiment on feature selection to opt for fewer but more informative features from MoBiL. Our experiments show that classifiers trained on our feature set perform consistently better in predicting both adequacy and fluency than the classifiers trained on the baseline feature set. MoBiL also performs well when used with both support vector machine and relevance vector machine algorithms."
W14-1014,Deriving de/het gender classification for {D}utch nouns for rule-based {MT} generation tasks,2014,4,0,1,1,12054,bogdan babych,Proceedings of the 3rd Workshop on Hybrid Approaches to Machine Translation ({H}y{T}ra),0,"Linguistic resources available in the public domain, such as lemmatisers, part-ofspeech taggers and parsers can be used for the development of MT systems: as separate processing modules or as annotation tools for the training corpus. For SMT this annotation is used for training factored models, and for the rule-based systems linguistically annotated corpus is the basis for creating analysis, generation and transfer dictionaries from corpora. However, the annotation in many cases is insufficient for rule-based MT, especially for the generation tasks. In this paper we analyze a specific case when the part-ofspeech tagger does not provide information about de/het gender of Dutch nouns that is needed for our rule-based MT systems translating into Dutch. We show that this information can be derived from large annotated monolingual corpora using a set of context-checking rules on the basis of co-occurrence of nouns and determiners in certain morphosyntactic configurations. As not all contexts are sufficient for disambiguation, we evaluate the coverage and the accuracy of our method for different frequency thresholds xc2xa9 2014 European Association for Computational Linguistics. in the news corpora. Further we discuss possible generalization of our method, and using it to automatically derive other types of linguistic information needed for rule-based MT: syntactic subcategorization frames, feature agreement rules and contextually appropriate collocates."
W13-2801,Workshop on Hybrid Approaches to Translation: Overview and Developments,2013,17,6,6,0,5326,marta costajussa,Proceedings of the Second Workshop on Hybrid Approaches to Translation,0,"A current increasing trend in machine translation is to combine data-driven and rule-based techniques. Such combinations typically involve the hybridization of different paradigms such as, for instance, the introduction of linguistic knowledge into statistical paradigms, the incorporation of data-driven components into rulebased paradigms, or the pre- and postprocessing of either sort of translation system outputs. Aiming at bringing together researchers and practitioners from the different multidisciplinary areas working in these directions, as well as at creating a brainstorming and discussion venue for Hybrid Translation approaches, the HyTra initiative was born. This paper gives an overview of the Second Workshop on Hybrid Approaches to Translation (HyTra 2013) concerning its motivation, contents and outcomes."
W12-0102,Measuring Comparability of Documents in Non-Parallel Corpora for Efficient Extraction of (Semi-)Parallel Translation Equivalents,2012,26,14,2,0,42571,fangzhong su,Proceedings of the Joint Workshop on Exploiting Synergies between Information Retrieval and Machine Translation ({ESIRMT}) and Hybrid Approaches to Machine Translation ({H}y{T}ra),0,"In this paper we present and evaluate three approaches to measure comparability of documents in non-parallel corpora. We develop a task-oriented definition of comparability, based on the performance of automatic extraction of translation equivalents from the documents aligned by the proposed metrics, which formalises intuitive definitions of comparability for machine translation research. We demonstrate application of our metrics for the task of automatic extraction of parallel and semiparallel translation equivalents and discuss how these resources can be used in the frameworks of statistical and rule-based machine translation."
W12-0114,Design of a hybrid high quality machine translation system,2012,37,5,1,1,12054,bogdan babych,Proceedings of the Joint Workshop on Exploiting Synergies between Information Retrieval and Machine Translation ({ESIRMT}) and Hybrid Approaches to Machine Translation ({H}y{T}ra),0,"This paper gives an overview of the ongoing FP7 project HyghTra (2010--2014). The HyghTra project is conducted in a partnership between academia and industry involving the University of Leeds and Lingenio GmbH (company). It adopts a hybrid and bootstrapping approach to the enhancement of MT quality by applying rule-based analysis and statistical evaluation techniques to both parallel and comparable corpora in order to extract linguistic information and enrich the lexical and syntactic resources of the underlying (rule-based) MT system that is used for analysing the corpora. The project places special emphasis on the extension of systems to new language pairs and corresponding rapid, automated creation of high quality resources. The techniques are fielded and evaluated within an existing commercial MT environment."
P12-3016,{ACCURAT} Toolkit for Multi-Level Alignment and Information Extraction from Comparable Corpora,2012,23,13,7,0,4943,marcis pinnis,Proceedings of the {ACL} 2012 System Demonstrations,0,"The lack of parallel corpora and linguistic resources for many languages and domains is one of the major obstacles for the further advancement of automated translation. A possible solution is to exploit comparable corpora (non-parallel bi- or multi-lingual text resources) which are much more widely available than parallel translation data. Our presented toolkit deals with parallel content extraction from comparable corpora. It consists of tools bundled in two workflows: (1) alignment of comparable documents and extraction of parallel sentences and (2) extraction and bilingual mapping of terms and named entities. The toolkit pairs similar bilingual comparable documents and extracts parallel sentences and bilingual terminological and named entity dictionaries from comparable corpora. This demonstration focuses on the English, Latvian, Lithuanian, and Romanian languages."
su-babych-2012-development,Development and Application of a Cross-language Document Comparability Metric,2012,22,7,2,0,42571,fangzhong su,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"In this paper we present a metric that measures comparability of documents across different languages. The metric is developed within the FP7 ICT ACCURAT project, as a tool for aligning comparable corpora on the document level; further these aligned comparable documents are used for phrase alignment and extraction of translation equivalents, with the aim to extend phrase tables of statistical MT systems without the need to use parallel texts. The metric uses several features, such as lexical information, document structure, keywords and named entities, which are combined in an ensemble manner. We present the results by measuring the reliability and effectiveness of the metric, and demonstrate its application and the impact for the task of parallel phrase extraction from comparable corpora."
rapp-etal-2012-identifying,Identifying Word Translations from Comparable Documents Without a Seed Lexicon,2012,8,11,3,0,20907,reinhard rapp,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"The extraction of dictionaries from parallel text corpora is an established technique. However, as parallel corpora are a scarce resource, in recent years the extraction of dictionaries using comparable corpora has obtained increasing attention. In order to find a mapping between languages, almost all approaches suggested in the literature rely on a seed lexicon. The work described here achieves competitive results without requiring such a seed lexicon. Instead it presupposes mappings between comparable documents in different languages. For some common types of textual resources (e.g. encyclopedias or newspaper texts) such mappings are either readily available or can be established relatively easily. The current work is based on Wikipedias where the mappings between languages are determined by the authors of the articles. We describe a neural-network inspired algorithm which first characterizes each Wikipedia article by a number of keywords, and then considers the identification of word translations as a variant of word alignment in a noisy environment. We present results and evaluations for eight language pairs involving Germanic, Romanic, and Slavic languages as well as Chinese."
skadina-etal-2012-collecting,Collecting and Using Comparable Corpora for Statistical Machine Translation,2012,32,25,8,0,17522,inguna skadicna,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"Lack of sufficient parallel data for many languages and domains is currently one of the major obstacles to further advancement of automated translation. The ACCURAT project is addressing this issue by researching methods how to improve machine translation systems by using comparable corpora. In this paper we present tools and techniques developed in the ACCURAT project that allow additional data needed for statistical machine translation to be extracted from comparable corpora. We present methods and tools for acquisition of comparable corpora from the Web and other sources, for evaluation of the comparability of collected corpora, for multi-level alignment of comparable corpora and for extraction of lexical and terminological data for machine translation. Finally, we present initial evaluation results on the utility of collected corpora in domain-adapted machine translation and real-life applications."
2012.tc-1.1,{MNH}-{TT}: a collaborative platform for translator training,2012,-1,-1,1,1,12054,bogdan babych,Proceedings of Translating and the Computer 34,0,None
2010.jec-1.2,"Shared Resources, Shared Values? Ethical Implications of Sharing Translation Resources",2010,-1,-1,2,0,46608,jo drugan,Proceedings of the Second Joint EM+/CNGL Workshop: Bringing MT to the User: Research on Integrating MT in the Translation Industry,0,"The exploitation of large corpora to create and populate shared translation resources has been hampered in two areas: first, practical problems ({``}locked-in{''} data, ineffective exchange formats, client reservations); and second, ethical and legal problems. Recent developments, notably online collaborative translation environments (Desillets, 2007) and greater industry openness, might have been expected to highlight such issues. Yet the growing use of shared data is being addressed only gingerly. Good reasons lie behind the failure to broach the ethics of shared resources. The issues are challenging: confidentiality, ownership, copyright, authorial rights, attribution, the law, protectionism, costs, fairness, motivation, trust, quality, reliability. However, we argue that, though complex, these issues should not be swept under the carpet. The huge demand for translation cannot be met without intelligent sharing of resources (Kelly, 2009). Relevant ethical considerations have already been identified in translation and related domains, in such texts as Codes of Ethics, international conventions and declarations, and Codes of Professional Conduct; these can be useful here. We outline two case studies from current industry initiatives, highlighting their ethical implications. We identify questions which users and developers should be asking and relate these to existing debates and codes as a practical framework for their consideration."
2009.eamt-1.6,Evaluation-Guided Pre-Editing of Source Text: Improving {MT}-Tractability of Light Verb Constructions,2009,6,2,1,1,12054,bogdan babych,Proceedings of the 13th Annual conference of the European Association for Machine Translation,0,"This paper reports an experiment on evaluating and improving MT quality of light-verb construction (LVCs) xe2x80x93 combinations of a xe2x80x98semantically depletedxe2x80x99 verb and its complement. Our method uses construction-level human evaluation for systematic discovery of mistranslated contexts and creating automatic pre-editing rules, which make the constructions more tractable for Rule-Based Machine Translation (RBMT) systems. For rewritten phrases we achieve about 40% reduction in the number of incomprehensible translations into English from both French and Russian. The proposed method can be used for enhancing automatic pre-editing functionality of state-of-theart MT systems. It will allow MT users to create their own rewriting rules for frequently mistranslated constructions and contexts, going beyond existing systemsxe2x80x99 capabilities offered by user dictionaries and do-not translate lists."
babych-etal-2008-generalising,Generalising Lexical Translation Strategies for {MT} Using Comparable Corpora,2008,15,3,1,1,12054,bogdan babych,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"We report on an on-going research project aimed at increasing the range of translation equivalents which can be automatically discovered by MT systems. The methodology is based on semi-supervised learning of indirect translation strategies from large comparable corpora and applying them in run-time to generate novel, previously unseen translation equivalents. This approach is different from methods based on parallel resources, which currently can reuse only individual translation equivalents. Instead it models translation strategies which generalise individual equivalents and can successfully generate an open class of new translation solutions. The task of the project is integration of the developed technology into open-source MT systems."
babych-hartley-2008-sensitivity,Sensitivity of Automated {MT} Evaluation Metrics on Higher Quality {MT} Output: {BLEU} vs Task-Based Evaluation Methods,2008,8,6,1,1,12054,bogdan babych,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"We report the results of our experiment on assessing the ability of automated MT evaluation metrics to remain sensitive to variations in MT quality as the average quality of the compared systems goes up. We compare two groups of metrics: those, which measure the proximity of MT output to some reference translation, and those which evaluate the performance of some automated process on degraded MT output. The experiment shows that proximity-based metrics (such as BLEU) loose sensitivity as the scores go up, but performance-based metrics (e.g., Named Entity recognition from MT output) remain sensitive across the scale. We suggest a model for explaining this result, which attributes stable sensitivity of performance-based metrics to measuring cumulative functional effect of different language levels, while proximity-based metrics measure structural matches on a lexical level and therefore miss higher-level errors that are more typical for better MT systems. Development of new automated metrics should take into account possible decline in sensitivity on higher-quality MT, which should be tested as part of meta-evaluation of the metrics."
P07-1018,Assisting Translators in Indirect Lexical Transfer,2007,9,11,1,1,12054,bogdan babych,Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,1,"We present the design and evaluation of a translatorxe2x80x99s amenuensis that uses comparable corpora to propose and rank nonliteral solutions to the translation of expressions from the general lexicon. Using distributional similarity and bilingual dictionaries, the method outperforms established techniques for extracting translation equivalents from parallel corpora. The interface to the system is available at: http://corpus.leeds.ac.uk/assist/v05/"
2007.tc-1.3,A dynamic dictionary for discovering indirect translation equivalents,2007,-1,-1,1,1,12054,bogdan babych,Proceedings of Translating and the Computer 29,0,None
2007.mtsummit-papers.5,Translating from under-resourced languages: comparing direct transfer against pivot translation,2007,-1,-1,1,1,12054,bogdan babych,Proceedings of Machine Translation Summit XI: Papers,0,None
2007.mtsummit-aptme.7,Sensitivity of automated models for {MT} evaluation: proximity-based vs. performance-based methods,2007,-1,-1,1,1,12054,bogdan babych,Proceedings of the Workshop on Automatic procedures in MT evaluation,0,None
P06-2095,Using Comparable Corpora to Solve Problems Difficult for Human Translators,2006,12,15,2,0.470357,519,serge sharoff,Proceedings of the {COLING}/{ACL} 2006 Main Conference Poster Sessions,0,"In this paper we present a tool that uses comparable corpora to find appropriate translation equivalents for expressions that are considered by translators as difficult. For a phrase in the source language the tool identifies a range of possible expressions used in similar contexts in target language corpora and presents them to the translator as a list of suggestions. In the paper we discuss the method and present results of human evaluation of the performance of the tool, which highlight its usefulness when dictionary solutions are lacking."
sharoff-etal-2006-using,Using collocations from comparable corpora to find translation equivalents,2006,14,4,2,0.470357,519,serge sharoff,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,In this paper we present a tool for finding appropriate translation equivalents for words from the general lexicon using comparable corpora. For a phrase in the source language the tool suggests arange of possible expressions used in similar contexts in target language corpora. In the paper we discuss the method and present results of human evaluation of the performance of the tool.
E06-2014,{ASSIST}: Automated Semantic Assistance for Translators,2006,10,4,2,0.470357,519,serge sharoff,Demonstrations,0,"The problem we address in this paper is that of providing contextual examples of translation equivalents for words from the general lexicon using comparable corpora and semantic annotation that is uniform for the source and target languages. For a sentence, phrase or a query expression in the source language the tool detects the semantic type of the situation in question and gives examples of similar contexts from the target language corpus."
2005.mtsummit-posters.13,Estimating the predictive Power of N-gram {MT} Evaluation Metrics across Language and Text Types,2005,-1,-1,1,1,12054,bogdan babych,Proceedings of Machine Translation Summit X: Posters,0,"The use of n-gram metrics to evaluate the output of MT systems is widespread. Typically, they are used in system development, where an increase in the score is taken to represent an improvement in the output of the system. However, purchasers of MT systems or services are more concerned to know how well a score predicts the acceptability of the output to a reader-user. Moreover, they usually want to know if these predictions will hold across a range of target languages and text types. We describe an experiment involving human and automated evaluations of four MT systems across two text types and 23 language directions. It establishes that the correlation between human and automated scores is high, but that the predictive power of these scores depends crucially on target language and text type."
P04-1079,Extending the {BLEU} {MT} Evaluation Method with Frequency Weightings,2004,6,54,1,1,12054,bogdan babych,Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics ({ACL}-04),1,"We present the results of an experiment on extending the automatic method of Machine Translation evaluation BLUE with statistical weights for lexical items, such as tf.idf scores. We show that this extension gives additional information about evaluated texts; in particular it allows us to measure translation Adequacy, which, for statistical MT systems, is often overestimated by the baseline BLEU method. The proposed model uses a single human reference translation, which increases the usability of the proposed method for practical purposes. The model suggests a linguistic interpretation which relates frequency weights and human intuition about translation Adequacy and Fluency."
babych-etal-2004-calibrating,Calibrating Resource-light Automatic {MT} Evaluation: a Cheap Approach to Ranking {MT} Systems by the Usability of Their Output,2004,3,1,1,1,12054,bogdan babych,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"MT systems are traditionally evaluated with different criteria, such as adequacy and fluency. Automatic evaluation scores are designed to match these quality parameters. In this paper we introduce a novel parameter xe2x80x93 usability (or utility) of output, which was found to integrate both fluency and adequacy. We confronted two automated metrics, BLEU and LTV, with new data for which human evaluation scores were also produced; we then measured the agreement between the automated and human evaluation scores. The resources produced in the experiment are available on the authorsxe2x80x99 website."
babych-hartley-2004-modelling,Modelling Legitimate Translation Variation for Automatic Evaluation of {MT} Quality,2004,3,9,1,1,12054,bogdan babych,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"Automatic methods for MT evaluation are often based on the assumption that MT quality is related to some kind of distance between the evaluated text and a professional human translation (e.g., an edit distance or the precision of matched N-grams). However, independently produced human translations are necessarily different, conveying the same content by dissimilar means. Such legitimate translation variation is a serious problem for distance-based evaluation methods, because mismatches do not necessarily mean degradation in MT quality. In this paper we explore the link between legitimate translation variation and statistical measures of a words salience within a given document, such as tf.idf scores. We show that the use of such scores extends the N-gram distance measures in a way that allows us to accurately predict multiple quality parameters of the text, such as translation adequacy and fluency. However legitimate translation variation also reveals fundamental limits on the applicability of distance-based MT evaluation methods and on data-driven architectures for MT."
C04-1016,Extending {MT} evaluation tools with translation complexity metrics,2004,6,6,1,1,12054,bogdan babych,{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics,0,"In this paper we report on the results of an experiment in designing resource-light metrics that predict the potential translation complexity of a text or a corpus of homogenous texts for state-of-the-art MT systems. We show that the best prediction of translation complexity is given by the average number of syllables per word (ASW). The translation complexity metrics based on this parameter are used to normalise automated MT evaluation scores such as BLEU, which otherwise are variable across texts of different types. The suggested approach makes a fairer comparison between the MT systems evaluated on different corpora. The translation complexity metric was integrated into two automated MT evaluation packages - BLEU and the Weighted N-gram model. The extended MT evaluation tools are available from the first author's web site: http://www.comp.leeds.ac.uk/bogdan/evalMT.html"
2004.eamt-1.3,Disambiguating translation strategies in {MT} using automatic named entity recognition,2004,-1,-1,1,1,12054,bogdan babych,Proceedings of the 9th EAMT Workshop: Broadening horizons of machine translation and its applications,0,None
W03-2201,Improving Machine Translation Quality with Automatic Named Entity Recognition,2003,14,126,1,1,12054,bogdan babych,"Proceedings of the 7th International {EAMT} workshop on {MT} and other language technology tools, Improving {MT} through other language technology tools, Resource and tools for building {MT} at {EACL} 2003",0,"Named entities create serious problems for state-of-the-art commercial machine translation (MT) systems and often cause translation failures beyond the local context, affecting both the overall morphosyntactic well-formedness of sentences and word sense disambiguation in the source text. We report on the results of an experiment in which MT input was processed using output from the named entity recognition module of Sheffield's GATE information extraction (IE) system. The gain in MT quality indicates that specific components of IE technology could boost the performance of current MT systems."
