2021.nodalida-main.4,Large-Scale Contextualised Language Modelling for {N}orwegian,2021,-1,-1,4,0.397408,2619,andrey kutuzov,Proceedings of the 23rd Nordic Conference on Computational Linguistics (NoDaLiDa),0,"We present the ongoing NorLM initiative to support the creation and use of very large contextualised language models for Norwegian (and in principle other Nordic languages), including a ready-to-use software environment, as well as an experience report for data preparation and training. This paper introduces the first large-scale monolingual language models for Norwegian, based on both the ELMo and BERT frameworks. In addition to detailing the training process, we present contrastive benchmark results on a suite of NLP tasks for Norwegian. For additional background and access to the data, models, and software, please see: http://norlm.nlpl.eu"
2021.nodalida-main.30,Negation in {N}orwegian: an annotated dataset,2021,-1,-1,4,1,2682,petter maehlum,Proceedings of the 23rd Nordic Conference on Computational Linguistics (NoDaLiDa),0,"This paper introduces NorecNeg {--} the first annotated dataset of negation for Norwegian. Negation cues and their in-sentence scopes have been annotated across more than 11K sentences spanning more than 400 documents for a subset of the Norwegian Review Corpus (NoReC). In addition to providing in-depth discussion of the annotation guidelines, we also present a first set of benchmark results based on a graph-parsing approach."
2021.nodalida-main.41,Multilingual {ELM}o and the Effects of Corpus Sampling,2021,-1,-1,3,0.769231,2707,vinit ravishankar,Proceedings of the 23rd Nordic Conference on Computational Linguistics (NoDaLiDa),0,"Multilingual pretrained language models are rapidly gaining popularity in NLP systems for non-English languages. Most of these models feature an important corpus sampling step in the process of accumulating training data in different languages, to ensure that the signal from better resourced languages does not drown out poorly resourced ones. In this study, we train multiple multilingual recurrent language models, based on the ELMo architecture, and analyse both the effect of varying corpus size ratios on downstream performance, as well as the performance difference between monolingual models for each language, and broader multilingual language models. As part of this effort, we also make these trained models available for public use."
2021.gebnlp-1.8,Using Gender- and Polarity-Informed Models to Investigate Bias,2021,-1,-1,2,0.78125,2743,samia touileb,Proceedings of the 3rd Workshop on Gender Bias in Natural Language Processing,0,"In this work we explore the effect of incorporating demographic metadata in a text classifier trained on top of a pre-trained transformer language model. More specifically, we add information about the gender of critics and book authors when classifying the polarity of book reviews, and the polarity of the reviews when classifying the genders of authors and critics. We use an existing data set of Norwegian book reviews with ratings by professional critics, which has also been augmented with gender information, and train a document-level sentiment classifier on top of a recently released Norwegian BERT-model. We show that gender-informed models obtain substantially higher accuracy, and that polarity-informed models obtain higher accuracy when classifying the genders of book authors. For this particular data set, we take this result as a confirmation of the gender bias in the underlying label distribution, but in other settings we believe a similar approach can be used for mitigating bias in the model."
2021.eacl-main.5,"If you{'}ve got it, flaunt it: Making the most of fine-grained sentiment annotations",2021,-1,-1,2,0.916667,2620,jeremy barnes,Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume,0,"Fine-grained sentiment analysis attempts to extract sentiment holders, targets and polar expressions and resolve the relationship between them, but progress has been hampered by the difficulty of annotation. Targeted sentiment analysis, on the other hand, is a more narrow task, focusing on extracting sentiment targets and classifying their polarity. In this paper, we explore whether incorporating holder and expression information can improve target extraction and classification and perform experiments on eight English datasets. We conclude that jointly predicting target and polarity BIO labels improves target extraction, and that augmenting the input text with gold expressions generally improves targeted polarity classification. This highlights the potential importance of annotating expressions for fine-grained sentiment datasets. At the same time, our results show that performance of current models for predicting polar expressions is poor, hampering the benefit of this information in practice."
2021.acl-long.263,Structured Sentiment Analysis as Dependency Graph Parsing,2021,-1,-1,4,0.916667,2620,jeremy barnes,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),1,"Structured sentiment analysis attempts to extract full opinion tuples from a text, but over time this task has been subdivided into smaller and smaller sub-tasks, e.g., target extraction or targeted polarity classification. We argue that this division has become counterproductive and propose a new unified framework to remedy the situation. We cast the structured sentiment problem as dependency graph parsing, where the nodes are spans of sentiment holders, targets and expressions, and the arcs are the relations between them. We perform experiments on five datasets in four languages (English, Norwegian, Basque, and Catalan) and show that this approach leads to strong improvements over state-of-the-art baselines. Our analysis shows that refining the sentiment graphs with syntactic dependency information further improves results."
2021.acl-long.323,"Anonymisation Models for Text Data: State of the art, Challenges and Future Directions",2021,-1,-1,5,0,2642,pierre lison,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),1,"This position paper investigates the problem of automated text anonymisation, which is a prerequisite for secure sharing of documents containing sensitive information about individuals. We summarise the key concepts behind text anonymisation and provide a review of current approaches. Anonymisation methods have so far been developed in two fields with little mutual interaction, namely natural language processing and privacy-preserving data publishing. Based on a case study, we outline the benefits and limitations of these approaches and discuss a number of open challenges, such as (1) how to account for multiple types of semantic inferences, (2) how to strike a balance between disclosure risk and data utility and (3) how to evaluate the quality of the resulting anonymisation. We lay out a case for moving beyond sequence labelling models and incorporate explicit measures of disclosure risk into the text anonymisation process."
2020.multilingualbio-1.2,Building a {N}orwegian Lexical Resource for Medical Entity Recognition,2020,18,0,3,0.965846,13178,ildiko pilan,Proceedings of the LREC 2020 Workshop on Multilingual Biomedical Text Processing (MultilingualBIO 2020),0,"We present a large Norwegian lexical resource of categorized medical terms. The resource, which merges information from large medical databases, contains over 56,000 entries, including automatically mapped terms from a Norwegian medical dictionary. We describe the methodology behind this automatic dictionary entry mapping based on keywords and suffixes and further present the results of a manual evaluation performed on a subset by a domain expert. The evaluation indicated that ca. 80{\%} of the mappings were correct."
2020.lrec-1.234,A Tale of Three Parsers: Towards Diagnostic Evaluation for Meaning Representation Parsing,2020,-1,-1,4,0,17079,maja buljan,Proceedings of the 12th Language Resources and Evaluation Conference,0,"We discuss methodological choices in contrastive and diagnostic evaluation in meaning representation parsing, i.e. mapping from natural language utterances to graph-based encodings of its semantic structure. Drawing inspiration from earlier work in syntactic dependency parsing, we transfer and refine several quantitative diagnosis techniques for use in the context of the 2019 shared task on Meaning Representation Parsing (MRP). As in parsing proper, moving evaluation from simple rooted trees to general graphs brings along its own range of challenges. Specifically, we seek to begin to shed light on relative strenghts and weaknesses in different broad families of parsing techniques. In addition to these theoretical reflections, we conduct a pilot experiment on a selection of top-performing MRP systems and one of the five meaning representation frameworks in the shared task. Empirical results suggest that the proposed methodology can be meaningfully applied to parsing into graph-structured target representations, uncovering hitherto unknown properties of the different systems that can inform future development and cross-fertilization across approaches."
2020.lrec-1.559,{N}or{NE}: Annotating Named Entities for {N}orwegian,2020,-1,-1,4,0,17782,fredrik jorgensen,Proceedings of the 12th Language Resources and Evaluation Conference,0,"This paper presents NorNE, a manually annotated corpus of named entities which extends the annotation of the existing Norwegian Dependency Treebank. Comprising both of the official standards of written Norwegian (Bokm{\aa}l and Nynorsk), the corpus contains around 600,000 tokens and annotates a rich set of entity types including persons, organizations, locations, geo-political entities, products, and events, in addition to a class corresponding to nominals derived from names. We here present details on the annotation effort, guidelines, inter-annotator agreement and an experimental analysis of the corpus using a neural sequence labeling architecture."
2020.lrec-1.618,A Fine-grained Sentiment Dataset for {N}orwegian,2020,-1,-1,1,1,2622,lilja ovrelid,Proceedings of the 12th Language Resources and Evaluation Conference,0,"We here introduce NoReC{\_}fine, a dataset for fine-grained sentiment analysis in Norwegian, annotated with respect to polar expressions, targets and holders of opinion. The underlying texts are taken from a corpus of professionally authored reviews from multiple news-sources and across a wide variety of domains, including literature, games, music, products, movies and more. We here present a detailed description of this annotation effort. We provide an overview of the developed annotation guidelines, illustrated with examples and present an analysis of inter-annotator agreement. We also report the first experimental results on the dataset, intended as a preliminary benchmark for further experiments."
2020.gebnlp-1.11,"Gender and sentiment, critics and authors: a dataset of {N}orwegian book reviews",2020,-1,-1,2,0.833333,2743,samia touileb,Proceedings of the Second Workshop on Gender Bias in Natural Language Processing,0,"Gender bias in models and datasets is widely studied in NLP. The focus has usually been on analysing how females and males express themselves, or how females and males are described. However, a less studied aspect is the combination of these two perspectives, how female and male describe the same or opposite gender. In this paper, we present a new gender annotated sentiment dataset of critics reviewing the works of female and male authors. We investigate if this newly annotated dataset contains differences in how the works of male and female authors are critiqued, in particular in terms of positive and negative sentiment. We also explore the differences in how this is done by male and female critics. We show that there are differences in how critics assess the works of authors of the same or opposite gender. For example, male critics rate crime novels written by females, and romantic and sentimental works written by males, more negatively."
2020.clinicalnlp-1.9,Classification of Syncope Cases in {N}orwegian Medical Records,2020,-1,-1,7,0.965846,13178,ildiko pilan,Proceedings of the 3rd Clinical Natural Language Processing Workshop,0,"Loss of consciousness, so-called syncope, is a commonly occurring symptom associated with worse prognosis for a number of heart-related diseases. We present a comparison of methods for a diagnosis classification task in Norwegian clinical notes, targeting syncope, i.e. fainting cases. We find that an often neglected baseline with keyword matching constitutes a rather strong basis, but more advanced methods do offer some improvement in classification performance, especially a convolutional neural network model. The developed pipeline is planned to be used for quantifying unregistered syncope cases in Norway."
W19-6205,Multilingual Probing of Deep Pre-Trained Contextual Encoders,2019,-1,-1,3,0.769231,2707,vinit ravishankar,Proceedings of the First NLPL Workshop on Deep Learning for Natural Language Processing,0,"Encoders that generate representations based on context have, in recent years, benefited from adaptations that allow for pre-training on large text corpora. Earlier work on evaluating fixed-length sentence representations has included the use of {`}probing{'} tasks, that use diagnostic classifiers to attempt to quantify the extent to which these encoders capture specific linguistic phenomena. The principle of probing has also resulted in extended evaluations that include relatively newer word-level pre-trained encoders. We build on probing tasks established in the literature and comprehensively evaluate and analyse {--} from a typological perspective amongst others {--} multilingual variants of existing encoders on probing datasets constructed for 6 non-English languages. Specifically, we probe each layer of a multiple monolingual RNN-based ELMo models, the transformer-based BERT{'}s cased and uncased multilingual variants, and a variant of BERT that uses a cross-lingual modelling scheme (XLM)."
W19-6113,Annotating evaluative sentences for sentiment analysis: a dataset for {N}orwegian,2019,0,2,3,1,2682,petter maehlum,Proceedings of the 22nd Nordic Conference on Computational Linguistics,0,This paper documents the creation of a large-scale dataset of evaluative sentences {--} i.e. both subjective and objective sentences that are found to be sentiment-bearing {--} based on mixed-domain professional reviews from various news-sources. We present both the annotation scheme and first results for classification experiments. The effort represents a step toward creating a Norwegian dataset for fine-grained sentiment analysis.
W19-6119,Lexicon information in neural sentiment analysis: a multi-task learning approach,2019,0,4,3,0.916667,2620,jeremy barnes,Proceedings of the 22nd Nordic Conference on Computational Linguistics,0,"This paper explores the use of multi-task learning (MTL) for incorporating external knowledge in neural models. Specifically, we show how MTL can enable a BiLSTM sentiment classifier to incorporate information from sentiment lexicons. Our MTL set-up is shown to improve model performance (compared to a single-task set-up) on both English and Norwegian sentence-level sentiment datasets. The paper also introduces a new sentiment lexicon for Norwegian."
W19-4802,Sentiment Analysis Is Not Solved! Assessing and Probing Sentiment Classification,2019,48,0,2,0.916667,2620,jeremy barnes,Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP,0,"Neural methods for sentiment analysis have led to quantitative improvements over previous approaches, but these advances are not always accompanied with a thorough analysis of the qualitative differences. Therefore, it is not clear what outstanding conceptual challenges for sentiment analysis remain. In this work, we attempt to discover what challenges still prove a problem for sentiment classifiers for English and to provide a challenging dataset. We collect the subset of sentences that an (oracle) ensemble of state-of-the-art sentiment classifiers misclassify and then annotate them for 18 linguistic and paralinguistic phenomena, such as negation, sarcasm, modality, etc. Finally, we provide a case study that demonstrates the usefulness of the dataset to probe the performance of a given sentiment classifier with respect to linguistic phenomena."
W19-4724,One-to-{X} Analogical Reasoning on Word Embeddings: a Case for Diachronic Armed Conflict Prediction from News Texts,2019,14,0,3,0.513676,2619,andrey kutuzov,Proceedings of the 1st International Workshop on Computational Approaches to Historical Language Change,0,"We extend the well-known word analogy task to a one-to-X formulation, including one-to-none cases, when no correct answer exists. The task is cast as a relation discovery problem and applied to historical armed conflicts datasets, attempting to predict new relations of type {`}location:armed-group{'} based on data about past events. As the source of semantic information, we use diachronic word embedding models trained on English news texts. A simple technique to improve diachronic performance in such task is demonstrated, using a threshold based on a function of cosine distance to decrease the number of false positives; this approach is shown to be beneficial on two different corpora. Finally, we publish a ready-to-use test set for one-to-X analogy evaluation on historical armed conflicts data."
W19-4409,Regression or classification? Automated Essay Scoring for {N}orwegian,2019,0,0,3,0,24159,stig berggren,Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications,0,"In this paper we present first results for the task of Automated Essay Scoring for Norwegian learner language. We analyze a number of properties of this task experimentally and assess (i) the formulation of the task as either regression or classification, (ii) the use of various non-neural and neural machine learning architectures with various types of input representations, and (iii) applying multi-task learning for joint prediction of essay scoring and native language identification. We find that a GRU-based attention model trained in a single-task setting performs best at the AES task."
W19-4318,Probing Multilingual Sentence Representations With {X}-Probe,2019,36,0,2,0.769231,2707,vinit ravishankar,Proceedings of the 4th Workshop on Representation Learning for NLP (RepL4NLP-2019),0,"This paper extends the task of probing sentence representations for linguistic insight in a multilingual domain. In doing so, we make two contributions: first, we provide datasets for multilingual probing, derived from Wikipedia, in five languages, viz. English, French, German, Spanish and Russian. Second, we evaluate six sentence encoders for each language, each trained by mapping sentence representations to English sentence representations, using sentences in a parallel corpus. We discover that cross-lingually mapped representations are often better at retaining certain linguistic information than representations derived from English encoders trained on natural language inference (NLI) as a downstream task."
D19-6125,Reinforcement-based denoising of distantly supervised {NER} with partial annotation,2019,0,1,3,1,7007,farhad nooralahzadeh,Proceedings of the 2nd Workshop on Deep Learning Approaches for Low-Resource NLP (DeepLo 2019),0,"Existing named entity recognition (NER) systems rely on large amounts of human-labeled data for supervision. However, obtaining large-scale annotated data is challenging particularly in specific domains like health-care, e-commerce and so on. Given the availability of domain specific knowledge resources, (e.g., ontologies, dictionaries), distant supervision is a solution to generate automatically labeled training data to reduce human effort. The outcome of distant supervision for NER, however, is often noisy. False positive and false negative instances are the main issues that reduce performance on this kind of auto-generated data. In this paper, we explore distant supervision in a supervised setup. We adopt a technique of partial annotation to address false negative cases and implement a reinforcement learning strategy with a neural network policy to identify false positive instances. Our results establish a new state-of-the-art on four benchmark datasets taken from different domains and different languages. We then go on to show that our model reduces the amount of manually annotated data required to perform NER in a new domain."
W18-6003,Expletives in {U}niversal {D}ependency Treebanks,2018,0,0,6,0,5827,gosse bouma,Proceedings of the Second Workshop on Universal Dependencies ({UDW} 2018),0,"Although treebanks annotated according to the guidelines of Universal Dependencies (UD) now exist for many languages, the goal of annotating the same phenomena in a cross-linguistically consistent fashion is not always met. In this paper, we investigate one phenomenon where we believe such consistency is lacking, namely expletive elements. Such elements occupy a position that is structurally associated with a core argument (or sometimes an oblique dependent), yet are non-referential and semantically void. Many UD treebanks identify at least some elements as expletive, but the range of phenomena differs between treebanks, even for closely related languages, and sometimes even for different treebanks for the same language. In this paper, we present criteria for identifying expletives that are applicable across languages and compatible with the goals of UD, give an overview of expletives as found in current UD treebanks, and present recommendations for the annotation of expletives so that more consistent annotation can be achieved in future releases."
W18-5613,Iterative development of family history annotation guidelines using a synthetic corpus of clinical text,2018,0,1,4,0.148031,21002,taraka rama,Proceedings of the Ninth International Workshop on Health Text Mining and Information Analysis,0,"In this article, we describe the development of annotation guidelines for family history information in Norwegian clinical text. We make use of incrementally developed synthetic clinical text describing patients{'} family history relating to cases of cardiac disease and present a general methodology which integrates the synthetically produced clinical statements and guideline development. We analyze inter-annotator agreement based on the developed guidelines and present results from experiments aimed at evaluating the validity and applicability of the annotated corpus using machine learning techniques. The resulting annotated corpus contains 477 sentences and 6030 tokens. Both the annotation guidelines and the annotated corpus are made freely available and as such constitutes the first publicly available resource of Norwegian clinical text."
W18-5519,{SIRIUS}-{LTG}: An Entity Linking Approach to Fact Extraction and Verification,2018,0,0,2,1,7007,farhad nooralahzadeh,Proceedings of the First Workshop on Fact Extraction and {VER}ification ({FEVER}),0,"This article presents the SIRIUS-LTG system for the Fact Extraction and VERification (FEVER) Shared Task. It consists of three components: 1) \textit{Wikipedia Page Retrieval}: First we extract the entities in the claim, then we find potential Wikipedia URI candidates for each of the entities using a SPARQL query over DBpedia 2) \textit{Sentence selection}: We investigate various techniques i.e. Smooth Inverse Frequency (SIF), Word Mover{'}s Distance (WMD), Soft-Cosine Similarity, Cosine similarity with unigram Term Frequency Inverse Document Frequency (TF-IDF) to rank sentences by their similarity to the claim. 3) \textit{Textual Entailment}: We compare three models for the task of claim classification. We apply a Decomposable Attention (DA) model (Parikh et al., 2016), a Decomposed Graph Entailment (DGE) model (Khot et al., 2018) and a Gradient-Boosted Decision Trees (TalosTree) model (Sean et al., 2017) for this task. The experiments show that the pipeline with simple Cosine Similarity using TFIDF in sentence selection along with DA model as labelling model achieves the best results on the development set (F1 evidence: 32.17, label accuracy: 59.61 and FEVER score: 0.3778). Furthermore, it obtains 30.19, 48.87 and 36.55 in terms of F1 evidence, label accuracy and FEVER score, respectively, on the test set. Our system ranks 15th among 23 participants in the shared task prior to any human-evaluation of the evidence."
W18-2907,Syntactic Dependency Representations in Neural Relation Classification,2018,16,0,2,1,7007,farhad nooralahzadeh,Proceedings of the Workshop on the Relevance of Linguistic Structure in Neural Architectures for {NLP},0,"We investigate the use of different syntactic dependency representations in a neural relation classification task and compare the CoNLL, Stanford Basic and Universal Dependencies schemes. We further compare with a syntax-agnostic approach and perform an error analysis in order to gain a better understanding of the results."
S18-1128,{SIRIUS}-{LTG}-{U}i{O} at {S}em{E}val-2018 Task 7: Convolutional Neural Networks with Shortest Dependency Paths for Semantic Relation Extraction and Classification in Scientific Papers,2018,15,0,2,1,7007,farhad nooralahzadeh,Proceedings of The 12th International Workshop on Semantic Evaluation,0,"This article presents the SIRIUS-LTG-UiO system for the SemEval 2018 Task 7 on Semantic Relation Extraction and Classification in Scientific Papers. First we extract the shortest dependency path (sdp) between two entities, then we introduce a convolutional neural network (CNN) which takes the shortest dependency path embeddings as input and performs relation classification with differing objectives for each subtask of the shared task. This approach achieved overall F1 scores of 76.7 and 83.2 for relation classification on clean and noisy data, respectively. Furthermore, for combined relation extraction and classification on clean data, it obtained F1 scores of 37.4 and 33.6 for each phase. Our system ranks 3rd in all three sub-tasks of the shared task."
L18-1228,Evaluation of Domain-specific Word Embeddings using Knowledge Resources,2018,0,6,2,1,7007,farhad nooralahzadeh,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
L18-1661,{N}o{R}e{C}: The {N}orwegian Review Corpus,2018,-1,-1,2,0,2621,erik velldal,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
L18-1710,The {LIA} Treebank of Spoken {N}orwegian Dialects,2018,0,0,1,1,2622,lilja ovrelid,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
K18-2002,The 2018 Shared Task on Extrinsic Parser Evaluation: On the Downstream Utility of {E}nglish {U}niversal {D}ependency Parsers,2018,0,6,3,0,30331,murhaf fares,Proceedings of the {C}o{NLL} 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies,0,"We summarize empirical results and tentative conclusions from the Second Extrinsic Parser Evaluation Initiative (EPE 2018). We review the basic task setup, downstream applications involved, and end-to-end results for seventeen participating teams. Based on in-depth quantitative and qualitative analysis, we correlate intrinsic evaluation results at different layers of morph-syntactic analysis with observed downstream behavior."
C18-1117,Diachronic word embeddings and semantic shifts: a survey,2018,0,20,2,0.672648,2619,andrey kutuzov,Proceedings of the 27th International Conference on Computational Linguistics,0,"Recent years have witnessed a surge of publications aimed at tracing temporal changes in lexical semantics using distributional methods, particularly prediction-based word embedding models. However, this vein of research lacks the cohesion, common terminology and shared practices of more established areas of natural language processing. In this paper, we survey the current state of academic research related to diachronic word embeddings and semantic shifts detection. We start with discussing the notion of semantic shifts, and then continue with an overview of the existing methods for tracing such time-related shifts with word embedding models. We propose several axes along which these methods can be compared, and outline the main challenges before this emerging subfield of NLP, as well as prospects and possible applications."
W17-7602,Downstream use of syntactic analysis: does representation matter?,2017,-1,-1,1,1,2622,lilja ovrelid,Proceedings of the 16th International Workshop on Treebanks and Linguistic Theories,0,None
W17-2705,Tracing armed conflicts with diachronic word embedding models,2017,0,6,3,0.672648,2619,andrey kutuzov,Proceedings of the Events and Stories in the News Workshop,0,"Recent studies have shown that word embedding models can be used to trace time-related (diachronic) semantic shifts in particular words. In this paper, we evaluate some of these approaches on the new task of predicting the dynamics of global armed conflicts on a year-to-year basis, using a dataset from the conflict research field as the gold standard and the Gigaword news corpus as the training data. The results show that much work still remains in extracting {`}cultural{'} semantic shifts from diachronic word embedding models. At the same time, we present a new task complete with an evaluation set and introduce the {`}anchor words{'} method which outperforms previous approaches on this set."
W17-1810,An open-source tool for negation detection: a maximum-margin approach,2017,12,7,3,0,32024,martine enger,Proceedings of the Workshop Computational Semantics Beyond Events and Roles,0,"This paper presents an open-source toolkit for negation detection. It identifies negation cues and their corresponding scope in either raw or parsed text using maximum-margin classification. The system design draws on best practice from the existing literature on negation detection, aiming for a simple and portable system that still achieves competitive performance. Pre-trained models and experimental results are provided for English."
W17-0201,Joint {UD} Parsing of {N}orwegian {B}okm{\\aa}l and Nynorsk,2017,25,1,2,0,2621,erik velldal,Proceedings of the 21st Nordic Conference on Computational Linguistics,0,None
W17-0217,Optimizing a {P}o{S} Tagset for {N}orwegian Dependency Parsing,2017,15,2,2,0,32161,petter hohle,Proceedings of the 21st Nordic Conference on Computational Linguistics,0,None
W17-0242,{W}ordnet extension via word embeddings: Experiments on the {N}orwegian {W}ordnet,2017,10,0,3,0,32190,heidi sand,Proceedings of the 21st Nordic Conference on Computational Linguistics,0,None
D17-1194,Temporal dynamics of semantic relations in word embeddings: an application to predicting armed conflict participants,2017,10,1,3,0.672648,2619,andrey kutuzov,Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing,0,"This paper deals with using word embedding models to trace the temporal dynamics of semantic relations between pairs of words. The set-up is similar to the well-known analogies task, but expanded with a time dimension. To this end, we apply incremental updating of the models with new training texts, including incremental vocabulary expansion, coupled with learned transformation matrices that let us map between members of the relation. The proposed approach is evaluated on the task of predicting insurgent armed groups based on geographical locations. The gold standard data for the time span 1994{--}2010 is extracted from the UCDP Armed Conflicts dataset. The results show that the method is feasible and outperforms the baselines, but also that important work still remains to be done."
W16-0413,Threat detection in online discussions,2016,12,8,2,0,34098,aksel wester,"Proceedings of the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",0,"This paper investigates the effect of various types of linguistic features (lexical, syntactic and semantic) for training classifiers to detect threats of violence in a corpus of YouTube comments. Our results show that combinations of lexical features outperform the use of more complex syntactic and semantic features for this task."
L16-1250,{U}niversal {D}ependencies for {N}orwegian,2016,18,8,1,1,2622,lilja ovrelid,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"This article describes the conversion of the Norwegian Dependency Treebank to the Universal Dependencies scheme. This paper details the mapping of PoS tags, morphological features and dependency relations and provides a description of the structural changes made to NDT analyses in order to make it compliant with the UD guidelines. We further present PoS tagging and dependency parsing experiments which report first results for the processing of the converted treebank. The full converted treebank was made available with the 1.2 release of the UD treebanks."
K16-2002,"{OPT}: {O}slo{--}{P}otsdam{--}{T}eesside. Pipelining Rules, Rankers, and Classifier Ensembles for Shallow Discourse Parsing",2016,15,2,7,0,2623,stephan oepen,Proceedings of the {C}o{NLL}-16 shared task,0,"The OPT submission to the Shared Task of the 2016 Conference on Natural Language Learning (CoNLL) implements a xe2x80x98classicxe2x80x99 pipeline architecture, combining binary classification of (candidate) explicit connectives, heuristic rules for non-explicit discourse relations, ranking and xe2x80x98editingxe2x80x99 of syntactic constituents for argument identification, and an ensemble of classifiers to assign discourse senses. With an end-toend performance of 27.77 F1 on the English xe2x80x98blindxe2x80x99 test data, our system advances the previous state of the art (Wang & Lan, 2015) by close to four F1 points, with particularly good results for the argument identification sub-tasks. OPT system results appear more competitive on the new, xe2x80x98blindxe2x80x99 test data than on the xe2x80x98testxe2x80x99 and xe2x80x98developmentxe2x80x99 sections of the Penn Discourse Treebank (PDTB; Prasad et al., 2008), which may indicate reduced over-fitting to specific properties of the venerable Wall Street Journal (WSJ) text underlying the PDTB."
K16-1012,Redefining part-of-speech classes with distributional semantic models,2016,22,0,3,0.636925,2619,andrey kutuzov,Proceedings of The 20th {SIGNLL} Conference on Computational Natural Language Learning,0,"This paper studies how word embeddings trained on the British National Corpus interact with part of speech boundaries. Our work targets the Universal PoS tag set, which is currently actively being used for annotation of a range of languages. We experiment with training classifiers for predicting PoS tags for words based on their embeddings. The results show that the information about PoS affiliation contained in the distributional vectors allows us to discover groups of words with distributional patterns that differ from other words of the same part of speech. n This data often reveals hidden inconsistencies of the annotation process or guidelines. At the same time, it supports the notion of `soft' or `graded' part of speech affiliations. Finally, we show that information about PoS is distributed among dozens of vector components, not limited to only one or two features."
W15-1816,Improving cross-domain dependency parsing with dependency-derived clusters,2015,24,0,3,0,36978,jostein lien,Proceedings of the 20th Nordic Conference of Computational Linguistics ({NODALIDA} 2015),0,"This paper describes a semi-supervised approach to improving statistical dependency parsing using dependency-based word clusters. After applying a baseline parser to unlabeled text, clusters are induced using K-means with word features based on the dependency structures. The parser is then re-trained using information about the clusters, yielding improved parsing accuracy on a range of different data sets, including WSJ and the English Web Treebank. We report improved results using both in-domain and out-of-domain data, and also include a comparison with usingn-gramxe2x80x90based Brown clustering."
W14-2616,Sentiment classification of online political discussions: a comparison of a word-based and dependency-based method,2014,19,11,3,0,34099,hugo hammer,"Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",0,Online political discussions have received a lot of attention over the past years. In this paper we compare two sentiment lexicon approaches to classify the sentiment of sentences from political discussions. The first approach is based on applying the number of words between the target and the sentiment words to weight the sentence sentiment score. The second approach is based on using the shortest paths between target and sentiment words in a dependency graph and linguistically motivated syntactic patterns expressed as dependency paths. The methods are tested on a corpus of sentences from online Norwegian political discussions. The results show that the method based on dependency graphs performs significantly better than the word-based approach.
solberg-etal-2014-norwegian,The {N}orwegian Dependency Treebank,2014,23,13,3,0,27834,per solberg,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"The Norwegian Dependency Treebank is a new syntactic treebank for Norwegian Bokm{\""a}l and Nynorsk with manual syntactic and morphological annotation, developed at the National Library of Norway in collaboration with the University of Oslo. It is the first publically available treebank for Norwegian. This paper presents the core principles behind the syntactic annotation and how these principles were employed in certain specific cases. We then present the selection of texts and distribution between genres, as well as the annotation process and an evaluation of the inter-annotator agreement. Finally, we present the first results of data-driven dependency parsing of Norwegian, contrasting four state-of-the-art dependency parsers trained on the treebank. The consistency and the parsability of this treebank is shown to be comparable to other large treebank initiatives."
W13-5707,"On Different Approaches to Syntactic Analysis Into Bi-Lexical Dependencies. An Empirical Comparison of Direct, {PCFG}-Based, and {HPSG}-Based Parsers",2013,0,3,5,1,35341,angelina ivanova,Proceedings of the 13th International Conference on Parsing Technologies ({IWPT} 2013),0,None
P13-3005,Survey on parsing three dependency representations for {E}nglish,2013,20,8,3,1,35341,angelina ivanova,51st Annual Meeting of the Association for Computational Linguistics Proceedings of the Student Research Workshop,0,"In this paper we focus on practical issues of data representation for dependency parsing. We carry out an experimental comparison of (a) three syntactic dependency schemes; (b) three data-driven dependency parsers; and (c) the influence of two different approaches to lexical category disambiguation (aka tagging) prior to parsing. Comparing parsing accuracies in various setups, we study the interactions of these three aspects and analyze which configurations are easier to learn for a dependency parser."
W12-3602,Who Did What to Whom? A Contrastive Study of Syntacto-Semantic Dependencies,2012,32,39,3,1,35341,angelina ivanova,Proceedings of the Sixth Linguistic Annotation Workshop,0,"We investigate aspects of interoperability between a broad range of common annotation schemes for syntacto-semantic dependencies. With the practical goal of making the LinGO Redwoods Treebank accessible to broader usage, we contrast seven distinct annotation schemes of functor--argument structure, both in terms of syntactic and semantic relations. Drawing examples from a multi-annotated gold standard, we show how abstractly similar information can take quite different forms across frameworks. We further seek to shed light on the representational 'distance' between pure bilexical dependencies, on the one hand, and full-blown logical-form propositional semantics, on the other hand. Furthermore, we propose a fully automated conversion procedure from (logical-form) meaning representation to bilexical semantic dependencies."
S12-1041,{U}i{O}1: Constituent-Based Discriminative Ranking for Negation Resolution,2012,8,14,3,0.532633,35001,jonathon read,"*{SEM} 2012: The First Joint Conference on Lexical and Computational Semantics {--} Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation ({S}em{E}val 2012)",0,"This paper describes the first of two systems submitted from the University of Oslo (UiO) to the 2012 *SEM Shared Task on resolving negation. Our submission is an adaption of the negation system of Velldal et al. (2012), which combines SVM cue classification with SVM-based ranking of syntactic constituents for scope resolution. The approach further extends our prior work in that we also identify factual negated events. While submitted for the closed track, the system was the top performer in the shared task overall."
S12-1042,{U}i{O} 2: Sequence-labeling Negation Using Dependency Features,2012,11,16,3,0,32118,emanuele lapponi,"*{SEM} 2012: The First Joint Conference on Lexical and Computational Semantics {--} Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation ({S}em{E}val 2012)",0,"This paper describes the second of two systems submitted from the University of Oslo (UiO) to the 2012 *SEM Shared Task on resolving negation. The system combines SVM cue classification with CRF sequence labeling of events and scopes. Models for scopes and events are created using lexical and syntactic features, together with a fine-grained set of labels that capture the scopal behavior of certain tokens. Following labeling, negated tokens are assigned to their respective cues using simple post-processing heuristics. The system was ranked first in the open track and third in the closed track, and was one of the top performers in the scope resolution sub-task overall."
read-etal-2012-wesearch,"The {W}e{S}earch Corpus, Treebank, and Treecache {--} A Comprehensive Sample of User-Generated Content",2012,16,8,5,0.532633,35001,jonathon read,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"We present the WeSearch Data Collection (WDC)âa freely redistributable, partly annotated, comprehensive sample of User-Generated Content. The WDC contains data extracted from a range of genres of varying formality (user forums, product review sites, blogs and Wikipedia) and covers two different domains (NLP and Linux). In this article, we describe the data selection and extraction process, with a focus on the extraction of linguistic content from different sources. We present the format of syntacto-semantic annotations found in this resource and present initial parsing results for these data, as well as some reflections following a first round of treebanking."
J12-2005,"Speculation and Negation: Rules, Rankers, and the Role of Syntax",2012,47,52,2,0.784061,2621,erik velldal,Computational Linguistics,0,"This article explores a combination of deep and shallow approaches to the problem of resolving the scope of speculation and negation within a sentence, specifically in the domain of biomedical research literature. The first part of the article focuses on speculation. After first showing how speculation cues can be accurately identified using a very simple classifier informed only by local lexical context, we go on to explore two different syntactic approaches to resolving the in-sentence scopes of these cues. Whereas one uses manually crafted rules operating over dependency structures, the other automatically learns a discriminative ranking function over nodes in constituent trees. We provide an in-depth error analysis and discussion of various linguistic properties characterizing the problem, and show that although both approaches perform well in isolation, even better results can be obtained by combining them, yielding the best published results to date on the CoNLL-2010 Shared Task data. The last part of the article describes how our speculation system is ported to also resolve the scope of negation. With only modest modifications to the initial design, the system obtains state-of-the-art results on this task also."
C12-2088,Lexical Categories for Improved Parsing of Web Data,2012,19,8,1,1,2622,lilja ovrelid,Proceedings of {COLING} 2012: Posters,0,"We investigate the use of features expressing lexical generalizations over word forms when parsing web data and experiment with a range of web text samples, taken from the Ontonotes corpus, as well as the web 2.0 data sets described in Foster et al. (2011b). We obtain significant improvements for a standard data-driven dependency parser when incorporating features expressing these lexical categories, and in fact find that we may dispense with word form features altogether and still observe the same levels of improvement."
W10-3007,Resolving Speculation: {M}ax{E}nt Cue Classification and Dependency-Based Scope Rules,2010,20,29,2,0.784061,2621,erik velldal,Proceedings of the Fourteenth Conference on Computational Natural Language Learning {--} Shared Task,0,"This paper describes a hybrid, two-level approach for resolving hedge cues, the problem of the CoNLL-2010 shared task. First, a maximum entropy classifier is applied to identify cue words, using both syntactic- and surface-oriented features. Second, a set of manually crafted rules, operating on dependency representations and the output of the classifier, is applied to resolve the scope of the hedge cues within the sentence."
bouma-etal-2010-towards,Towards a Large Parallel Corpus of Cleft Constructions,2010,16,3,2,0,2746,gerlof bouma,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"We present our efforts to create a large-scale, semi-automatically annotated parallel corpus of cleft constructions. The corpus is intended to reduce or make more effective the manual task of finding examples of clefts in a corpus. The corpus is being developed in the context of the Collaborative Research Centre SFB 632, which is a large, interdisciplinary research initiative to study information structure, at the University of Potsdam and the Humboldt University in Berlin. The corpus is based on the Europarl corpus (version 3). We show how state-of-the-art NLP tools, like POS taggers and statistical dependency parsers, may facilitate powerful and precise searches. We argue that identifying clefts using automatically added syntactic structure annotation is ultimately to be preferred over using lower level, though more robust, extraction methods like regular expression matching. An evaluation of the extraction method for one of the languages also offers some support for this method. We end the paper by discussing the resulting corpus itself. We present some examples of interesting clefts and translational counterparts from the corpus and suggest ways of exploiting our newly created resource in the cross-linguistic study of clefts."
spreyer-etal-2010-training,Training Parsers on Partial Trees: A Cross-language Comparison,2010,15,12,2,0,46263,kathrin spreyer,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"We present a study that compares data-driven dependency parsers obtained by means of annotation projection between language pairs of varying structural similarity. We show how the partial dependency trees projected from English to Dutch, Italian and German can be exploited to train parsers for the target languages. We evaluate the parsers against manual gold standard annotations and find that the projected parsers substantially outperform our heuristic baselines by 9â25{\%} UAS, which corresponds to a 21â43{\%} reduction in error rate. A comparative error analysis focuses on how the projected target language parsers handle subjects, which is especially interesting for Italian as an instance of a pro-drop language. For Dutch, we further present experiments with German as an alternative source language. In both source languages, we contrast standard baseline parsers with parsers that are enhanced with the predictions from large-scale LFG grammars through a technique of parser stacking, and show that improvements of the source language parser can directly lead to similar improvements of the projected target language parser."
C10-2129,Informed ways of improving data-driven dependency parsing for {G}erman,2010,28,8,3,0,17921,wolfgang seeker,Coling 2010: Posters,0,"We investigate a series of targeted modifications to a data-driven dependency parser of German and show that these can be highly effective even for a relatively well studied language like German if they are made on a (linguistically and methodologically) informed basis and with a parser implementation that allows for fast and robust training and application. Making relatively small changes to a range of very different system components, we were able to increase labeled accuracy on a standard test set (from the CoNLL 2009 shared task), ignoring gold standard part-of-speech tags, from 87.64% to 89.40%. The study was conducted in less than five weeks and as a secondary project of all four authors. Effective modifications include the quality and combination of auto-assigned morphosyntactic features entering machine learning, the internal feature handling as well as the inclusion of global constraints and a combination of different parsing strategies."
C10-1155,Syntactic Scope Resolution in Uncertainty Analysis,2010,21,32,1,1,2622,lilja ovrelid,Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010),0,"We show how the use of syntactic structure enables the resolution of hedge scope in a hybrid, two-stage approach to uncertainty analysis. In the first stage, a Maximum Entropy classifier, combining surface-oriented and syntactic features, identifies cue words. With a small set of hand-crafted rules operating over dependency representations in stage two, we attain the best overall result (in terms of both combined ranks and average F1) in the 2010 CoNLL Shared Task."
W09-4638,Cross-lingual porting of distributional semantic classification,2009,0,0,1,1,2622,lilja ovrelid,Proceedings of the 17th Nordic Conference of Computational Linguistics ({NODALIDA} 2009),0,None
P09-2010,Improving data-driven dependency parsing using large-scale {LFG} grammars,2009,11,17,1,1,2622,lilja ovrelid,Proceedings of the {ACL}-{IJCNLP} 2009 Conference Short Papers,0,"This paper presents experiments which combine a grammar-driven and a data-driven parser. We show how the conversion of LFG output to dependency representation allows for a technique of parser stacking, whereby the output of the grammar-driven parser supplies features for a data-driven dependency parser. We evaluate on English and German and show significant improvements stemming from the proposed dependency structure as well as various other, deep linguistic features derived from the respective grammars."
E09-1072,Empirical Evaluations of {A}nimacy Annotation,2009,24,9,1,1,2622,lilja ovrelid,Proceedings of the 12th Conference of the {E}uropean Chapter of the {ACL} ({EACL} 2009),0,"This article presents empirical evaluations of aspects of annotation for the linguistic property of animacy in Swedish, ranging from manual human annotation, automatic classification and, finally, an external evaluation in the task of syntactic parsing. We show that a treatment of animacy as a lexical semantic property of noun types enables generalization over distributional properties of these nouns which proves beneficial in automatic classification and furthermore gives significant improvements in terms of parsing accuracy for Swedish, compared to a state-of-the-art baseline parser with gold standard animacy information."
W08-2104,Linguistic features in data-driven dependency parsing,2008,14,9,1,1,2622,lilja ovrelid,{C}o{NLL} 2008: Proceedings of the Twelfth Conference on Computational Natural Language Learning,0,"This article investigates the effect of a set of linguistically motivated features on argument disambiguation in data-driven dependency parsing of Swedish. We present results from experiments with gold standard features, such as animacy, definiteness and finiteness, as well as corresponding experiments where these features have been acquired automatically and show significant improvements both in overall parse results and in the analysis of specific argument relations, such as subjects, objects and predicatives."
E06-3008,Towards Robust {A}nimacy Classification Using Morphosyntactic Distributional Features,2006,13,6,1,1,2622,lilja ovrelid,Student Research Workshop,0,"This paper presents results from experiments in automatic classification of animacy for Norwegian nouns using decision-tree classifiers. The method makes use of relative frequency measures for linguistically motivated morphosyntactic features extracted from an automatically annotated corpus of Norwegian. The classifiers are evaluated using leave-one-out training and testing and the initial results are promising (approaching 90% accuracy) for high frequency nouns, however deteriorate gradually as lower frequency nouns are classified. Experiments attempting to empirically locate a frequency threshold for the classification method indicate that a subset of the chosen morphosyntactic features exhibit a notable resilience to data sparseness. Results will be presented which show that the classification accuracy obtained for high frequency nouns (with absolute frequencies >1000) can be maintained for nouns with considerably lower frequencies (~50) by backing off to a smaller set of features at classification."
