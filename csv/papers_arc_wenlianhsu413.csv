P19-1147,On the Robustness of Self-Attentive Models,2019,0,11,5,1,25636,yulun hsieh,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"This work examines the robustness of self-attentive neural networks against adversarial input perturbations. Specifically, we investigate the attention and feature extraction mechanisms of state-of-the-art recurrent neural networks and self-attentive architectures for sentiment analysis, entailment and machine translation under adversarial attacks. We also propose a novel attack algorithm for generating more natural adversarial examples that could mislead neural models but not humans. Experimental results show that, compared to recurrent neural models, self-attentive models are more robust against adversarial perturbation. In addition, we provide theoretical explanations for their superior robustness to support our claims."
2019.rocling-1.23,"{MONPA}:ä¸­æå½åå¯¦é«åæ·è©èè©æ§åæ­¥æ¨è¨»ç³»çµ±({MONPA}: A Multitask {C}hinese Segmentation, Named-entity and Part-of-speech Annotator)",2019,-1,-1,4,0,2373,wenchao yeh,Proceedings of the 31st Conference on Computational Linguistics and Speech Processing (ROCLING 2019),0,None
W17-5804,Incorporating Dependency Trees Improve Identification of Pregnant Women on Social Media Platforms,2017,17,1,10,0,31451,yijie huang,Proceedings of the International Workshop on Digital Disease Detection using Social Media 2017 ({DDDSM}-2017),0,"The increasing popularity of social media lead users to share enormous information on the internet. This information has various application like, it can be used to develop models to understand or predict user behavior on social media platforms. For example, few online retailers have studied the shopping patterns to predict shopper{'}s pregnancy stage. Another interesting application is to use the social media platforms to analyze users{'} health-related information. In this study, we developed a tree kernel-based model to classify tweets conveying pregnancy related information using this corpus. The developed pregnancy classification model achieved an accuracy of 0.847 and an F-score of 0.565. A new corpus from popular social media platform Twitter was developed for the purpose of this study. In future, we would like to improve this corpus by reducing noise such as retweets."
W17-5809,Chemical-Induced Disease Detection Using Invariance-based Pattern Learning Model,2017,4,1,3,0,31470,neha warikoo,Proceedings of the International Workshop on Digital Disease Detection using Social Media 2017 ({DDDSM}-2017),0,"In this work, we introduce a novel feature engineering approach named {``}algebraic invariance{''} to identify discriminative patterns for learning relation pair features for the chemical-disease relation (CDR) task of BioCreative V. Our method exploits the existing structural similarity of the key concepts of relation descriptions from the CDR corpus to generate robust linguistic patterns for SVM tree kernel-based learning. Preprocessing of the training data classifies the entity pairs as either related or unrelated to build instance types for both inter-sentential and intra-sentential scenarios. An invariant function is proposed to process and optimally cluster similar patterns for both positive and negative instances. The learning model for CDR pairs is based on the SVM tree kernel approach, which generates feature trees and vectors and is modeled on suitable invariance based patterns, bringing brevity, precision and context to the identifier features. Results demonstrate that our method outperformed other compared approaches, achieved a high recall rate of 85.08{\%}, and averaged an F1-score of 54.34{\%} without the use of any additional knowledge bases."
O17-2001,ç¶ä»£éç£ç£å¼æ¹æ³ä¹æ¯è¼æ¼ç¯éå¼èªé³æè¦ (An Empirical Comparison of Contemporary Unsupervised Approaches for Extractive Speech Summarization) [In {C}hinese],2017,0,0,6,0.893344,19036,shihhung liu,"International Journal of Computational Linguistics {\\&} {C}hinese Language Processing, Volume 22, Number 1, June 2017",0,None
I17-4015,{CIAL} at {IJCNLP}-2017 Task 2: An Ensemble Valence-Arousal Analysis System for {C}hinese Words and Phrases,2017,0,0,5,0,32809,zhengwen lin,"Proceedings of the {IJCNLP} 2017, Shared Tasks",0,"Sentiment lexicon is very helpful in dimensional sentiment applications. Because of countless Chinese words, developing a method to predict unseen Chinese words is required. The proposed method can handle both words and phrases by using an ADVWeight List for word prediction, which in turn improves our performance at phrase level. The evaluation results demonstrate that our system is effective in dimensional sentiment analysis for Chinese phrases. The Mean Absolute Error (MAE) and Pearson{'}s Correlation Coefficient (PCC) for Valence are 0.723 and 0.835, respectively, and those for Arousal are 0.914 and 0.756, respectively."
I17-2014,{MONPA}: Multi-objective Named-entity and Part-of-speech Annotator for {C}hinese using Recurrent Neural Network,2017,18,2,6,1,25636,yulun hsieh,Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 2: Short Papers),0,"Part-of-speech (POS) tagging and named entity recognition (NER) are crucial steps in natural language processing. In addition, the difficulty of word segmentation places additional burden on those who intend to deal with languages such as Chinese, and pipelined systems often suffer from error propagation. This work proposes an end-to-end model using character-based recurrent neural network (RNN) to jointly accomplish segmentation, POS tagging and NER of a Chinese sentence. Experiments on previous word segmentation and NER datasets show that a single model with the proposed architecture is comparable to those trained specifically for each task, and outperforms freely-available softwares. Moreover, we provide a web-based interface for the public to easily access this resource."
I17-2041,Identifying Protein-protein Interactions in Biomedical Literature using Recurrent Neural Networks with Long Short-Term Memory,2017,15,11,4,1,25636,yulun hsieh,Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 2: Short Papers),0,"In this paper, we propose a recurrent neural network model for identifying protein-protein interactions in biomedical literature. Experiments on two largest public benchmark datasets, AIMed and BioInfer, demonstrate that our approach significantly surpasses state-of-the-art methods with relative improvements of 10{\%} and 18{\%}, respectively. Cross-corpus evaluation also demonstrate that the proposed model remains robust despite using different training data. These results suggest that RNN can effectively capture semantic relationships among proteins as well as generalizes over different corpora, without any feature engineering."
W16-6211,How Do {I} Look? Publicity Mining From Distributed Keyword Representation of Socially Infused News Articles,2016,23,2,4,1,25636,yulun hsieh,Proceedings of The Fourth International Workshop on Natural Language Processing for Social Media,0,None
O16-2002,Linguistic Template Extraction for Recognizing Reader-Emotion,2016,27,3,4,1,2375,yungchun chang,"International Journal of Computational Linguistics {\\&} {C}hinese Language Processing, Volume 21, Number 1, June 2016",0,"Previous studies on emotion classification mainly focus on the emotional state of the writer. By contrast, our research emphasizes emotion detection from the readers' perspective. The classification of documents into reader-emotion categories can be applied in several ways, and one of the applications is to retain only the documents that trigger desired emotions to enable users to retrieve documents that contain relevant contents and at the same time instill proper emotions. However, current information retrieval (IR) systems lack the ability to discern emotions within texts, and the detection of reader's emotion has yet to achieve a comparable performance. Moreover, previous machine learning-based approaches generally use statistical models that are not in a human-readable form. Thereby, it is difficult to pinpoint the reason for recognition failures and understand the types of emotions that the articles inspired on their readers. In this paper, we propose a flexible emotion template-based approach (TBA) for reader-emotion detection that simulates such process in a human perceptive manner. TBA is a highly automated process that incorporates various knowledge sources to learn an emotion template from raw text that characterize an emotion and are comprehensible for humans. Generated templates are adopted to predict reader's emotion through an alignment-based matching algorithm that allows an emotion template to be partially matched through a statistical scoring scheme. Experimental results demonstrate that our approach can effectively detect reader's emotions by exploiting the syntactic structures and semantic associations in the context, while outperforming currently well-known statistical text classification methods and the stat-of-the-art reader-emotion detection method."
O16-1012,éç¨åºåå°åºåçææ¶æ§æ¼éå¯«å¼èªåæè¦(Exploiting Sequence-to-Sequence Generation Framework for Automatic Abstractive Summarization)[In {C}hinese],2016,0,0,5,1,25636,yulun hsieh,Proceedings of the 28th Conference on Computational Linguistics and Speech Processing ({ROCLING} 2016),0,None
P15-2127,Linguistic Template Extraction for Recognizing Reader-Emotion and Emotional Resonance Writing Assistance,2015,18,11,5,1,2375,yungchun chang,Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers),0,"In this paper, we propose a flexible principle-based approach (PBA) for reader-emotion classification and writing assistance. PBA is a highly automated process that learns emotion templates from raw texts to characterize an emotion and is comprehensible for humans. These templates are adopted to predict reader-emotion, and may further assist in emotional resonance writing. Results demonstrate that PBA can effectively detect reader-emotions by exploiting the syntactic structures and semantic associations in the context, thus outperforming wellknown statistical text classification methods and the state-of-the-art reader-emotion classification method. Moreover, writers are able to create more emotional resonance in articles under the assistance of the generated emotion templates. These templates have been proven to be highly interpretable, which is an attribute that is difficult to accomplish in traditional statistical methods."
Y14-1011,Semantic Frame-based Statistical Approach for Topic Detection,2014,29,1,6,1,2375,yungchun chang,"Proceedings of the 28th Pacific Asia Conference on Language, Information and Computing",0,"We propose a statistical frame-based approach (FBA) for natural language processing, and demonstrate its advantage over traditional machine learning methods by using topic detection as a case study. FBA perceives and identifies semantic knowledge in a more general manner by collecting important linguistic patterns within documents through a unique flexible matching scheme that allows word insertion, deletion and substitution (IDS) to capture linguistic structures within the text. In addition, FBA can also overcome major issues of the rule-based approach by reducing human effort through its highly automated pattern generation and summarization. Using Yahoo! Chinese news corpus containing about 140,000 news articles, we provide a comprehensive performance evaluation that demonstrates the effectiveness of FBA in detecting the topic of a document by exploiting the semantic association and the context within the text. Moreover, it outperforms common topic models like Naive Bayes, Vector Space Model, and LDA-SVM."
O14-2002,Joint Learning of Entity Linking Constraints Using a {M}arkov-{L}ogic Network,2014,31,2,3,1,14599,hongjie dai,"International Journal of Computational Linguistics {\\&} {C}hinese Language Processing, Volume 19, Number 1, March 2014",0,"Entity linking (EL) is the task of linking a textual named entity mention to a knowledge base entry. Traditional approaches have addressed the problem by dividing the task into separate stages: entity recognition/classification, entity filtering, and entity mapping, in which different constraints are used to improve the system's performance. Nevertheless, these constraints are executed separately and cannot be used interactively. In this paper, we propose an integrated solution to the task based on a Markov logic network (MLN). We show how the stage decision can be formulated and combined in an MLN. We conducted experiments on the biomedical EL task, gene mention linking (GML), and compared our model's performance with those of two other GML approaches. Our experimental results provide the first comprehensive GML evaluations from three different perspectives: article-wide precision/recall/F-measure (PRF), instance-based PRF, and question answering accuracy. This paper also provides formal definitions of all of the above EL tasks. Experimental results show that our method outperforms the baseline and state-of-the-art systems under all three evaluation schemes."
O14-1002,æ¢ç©¶æ°ç©èªå¥æ¨¡ååæè¡æ¼ç¯éå¼èªé³æè¦ (Investigating Novel Sentence Modeling Techniques for Extractive Speech Summarization) [In {C}hinese],2014,0,0,6,1,19036,shihhung liu,Proceedings of the 26th Conference on Computational Linguistics and Speech Processing ({ROCLING} 2014),0,None
D14-1156,Leveraging Effective Query Modeling Techniques for Speech Recognition and Summarization,2014,47,7,6,1,2312,kuanyu chen,Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP}),0,"Statistical language modeling (LM) that purports to quantify the acceptability of a given piece of text has long been an interesting yet challenging research area. In particular, language modeling for information retrieval (IR) has enjoyed remarkable empirical success; one emerging stream of the LM approach for IR is to employ the pseudo-relevance feedback process to enhance the representation of an input query so as to improve retrieval effectiveness. This paper presents a continuation of such a general line of research and the main contribution is threefold. First, we propose a principled framework which can unify the relationships among several widely-used query modeling formulations. Second, on top of the successfully developed framework, we propose an extended query modeling formulation by incorporating critical query-specific information cues to guide the model estimation. Third, we further adopt and formalize such a framework to the speech recognition and summarization tasks. A series of empirical experiments reveal the feasibility of such an LM framework and the performance merits of the deduced models on these two tasks."
W13-4417,Sinica-{IASL} {C}hinese spelling check system at Sighan-7,2013,6,4,6,1,40683,tinghao yang,Proceedings of the Seventh {SIGHAN} Workshop on {C}hinese Language Processing,0,"We developed a Chinese spelling check system for error detection and error correction subtasks in the 2013 SIGHAN-7 Chinese Spelling Check Bake-off. By using the resources of Chinese phonology and orthographic components, our system contains four parts: high confidence pattern matcher, the detection module, the correction module, and the merger. We submitted 2 official runs for both subtasks. The evaluation result show that our system achieved 0.6016 in error detection F-score of subtask 1, and 0.448 in correction accuracy of subtask 2. 1"
O13-1001,æ¹è¯èªå¥æ¨¡åæè¡æ¼ç¯éå¼èªé³æè¦ä¹ç ç©¶ (Improved Sentence Modeling Techniques for Extractive Speech Summarization) [In {C}hinese],2013,0,0,4,1,19036,shihhung liu,Proceedings of the 25th Conference on Computational Linguistics and Speech Processing ({ROCLING} 2013),0,None
W12-4412,Cost-benefit Analysis of Two-Stage Conditional Random Fields based {E}nglish-to-{C}hinese Machine Transliteration,2012,19,3,5,0,42164,chanhung kuo,Proceedings of the 4th Named Entity Workshop ({NEWS}) 2012,0,This work presents an English-to-Chinese (E2C) machine transliteration system based on two-stage conditional random fields (CRF) models with accessor variety (AV) as an additional feature to approximate local context of the source language. Experiment results show that two-stage CRF method outperforms the one-stage opponent since the former costs less to encode more features and finer grained labels than the latter.
O12-4003,Enhancement of Feature Engineering for Conditional Random Field Learning in {C}hinese Word Segmentation Using Unlabeled Data,2012,34,2,6,1,42165,mike jiang,"International Journal of Computational Linguistics {\\&} {C}hinese Language Processing, Volume 17, Number 3, September 2012",0,"This work proposes a unified view of several features based on frequent strings extracted from unlabeled data that improve the conditional random fields (CRF) model for Chinese word segmentation (CWS). These features include character-based n-gram (CNG), accessor variety based string (AVS) and its variation of left-right co-existed feature (LRAVS), term-contributed frequency (TCF), and term-contributed boundary (TCB) with a specific manner of boundary overlapping. For the experiments, the baseline is the 6-tag, a state-of-the-art labeling scheme of CRF-based CWS, and the data set is acquired from the 2005 CWS Bakeoff of Special Interest Group on Chinese Language Processing (SIGHAN) of the Association for Computational Linguistics (ACL) and SIGHAN CWS Bakeoff 2010. The experimental results show that all of these features improve the performance of the baseline system in terms of recall, precision, and their harmonic average as F1 measure score, on both accuracy (F) and out-of-vocabulary recognition (FOOV). In particular, this work presents compound features involving LRAVS/AVS and TCF/TCB that are competitive with other types of features for CRF-based CWS in terms of F and FOOV, respectively."
Y11-1011,Evaluation via Negativa of {C}hinese Word Segmentation for Information Retrieval,2011,36,1,4,1,42165,mike jiang,"Proceedings of the 25th Pacific Asia Conference on Language, Information and Computation",0,"Numerous studies have analyzed the influences of word segmentation (WS) performance on information retrieval (IR) for Mandarin Chinese and have demonstrated a non-monotonic relationship between WS accuracy and IR effectiveness. The usefulness of the compound words that have been a focus of the IR literature is not reflected by common WS evaluation metrics of word-based precision (P) and recall (R). This investigation proposes alternative measurements of WS accuracy, which are based on negative segments that are annotated against four standards of referenced corpora, called true negative rate (TNR) and negative predictive value (NPV), and compares with P and R through search engine simulation,. Accuracy-controlled WS systems segment queries for the simulation including NTCIR collections and Sogou logs. Mean average precision (MAP) estimates the similarity of search results between the original and segmented queries. The statistics demonstrate that TNR and NPV are generally more closely correlated with MAP than are P and R."
Y11-1040,Iteratively Estimating Pattern Reliability and Seed Quality With Extraction Consistency,2011,12,0,3,1,43952,yihsun lee,"Proceedings of the 25th Pacific Asia Conference on Language, Information and Computation",0,"In this paper, we focus on the task of distilling relation instances from the Web. Most of the approaches for this task were based on provided seed instances or patterns to initiate the process. Thus, the result of the extraction depends largely on the quality of the instances and patterns. For this matter, we propose an iterative mechanism that estimates the reliability of a pattern by the consistency of its ex- tractions, and reevaluate the usefulness of seed instance based on estimated pattern reliability. The resulting system is a semi-supervised method that can take a large quantity of seed instances with diverse quality. To evaluate the effectiveness of our approach, we experimented on 8 types of relationships. The empirical results show that our system performs quite consistency in different relationships while maintain- ing high precision and recall value."
W11-3509,Robustness Analysis of Adaptive {C}hinese Input Methods,2011,21,1,5,1,42165,mike jiang,Proceedings of the Workshop on Advances in Text Input Methods ({WTIM} 2011),0,"This work proposes a novel metric, Maximally Amortized Cost (MAC), for cost evaluations of error correction of predictive Chinese input methods (IMs). With a series of real-time simulation, user correction behaviors are analyzed by estimating generalized backward compatibility of adaptive Chinese IMs. Comparisons between three IMs by using MAC with different context lengths report empirical factors of context length for improving predictive IMs. The error-tolerance levelxe2x80x94Futile Effort, Beneficial Effort and Utilityxe2x80x94of adaptive IMs is also proposed and analyzed."
W11-3213,{E}nglish-to-{C}hinese Machine Transliteration using Accessor Variety Features of Source Graphemes,2011,39,0,3,1,42165,mike jiang,Proceedings of the 3rd Named Entities Workshop ({NEWS} 2011),0,"This work describes a grapheme-based approach of English-to-Chinese (E2C) transliteration, which includes many-to-many alignment models and conditional random fields using accessor variety (AV) as an additional feature based on source graphemes. Experimental results indicate that the AV of a given English segment can generally improve effectiveness of E2C transliteration."
O11-1007,Unsupervised Overlapping Feature Selection for Conditional Random Fields Learning in {C}hinese Word Segmentation,2011,23,4,5,1,40683,tinghao yang,Proceedings of the 23rd Conference on Computational Linguistics and Speech Processing ({ROCLING} 2011),0,"This work represents several unsupervised feature selections based on frequent strings that help improve conditional random fields (CRF) model for Chinese word segmentation (CWS). These features include character-based N-gram (CNG), Accessor Variety based string (AVS), and Term Contributed Frequency (TCF) with a specific manner of boundary overlapping. For the experiment, the baseline is the 6-tag, a state-of-the-art labeling scheme of CRF-based CWS; and the data set is acquired from SIGHAN CWS bakeoff 2005. The experiment results show that all of those features improve our system's F1 measure (F) and Recall of Out-of-Vocabulary (ROOV). In particular, the feature collections which contain AVS feature outperform other types of features in terms of F, whereas the feature collections containing TCB/TCF information has better ROOV."
I11-1095,Entity Disambiguation Using a {M}arkov-{L}ogic Network,2011,28,16,3,1,14599,hongjie dai,Proceedings of 5th International Joint Conference on Natural Language Processing,0,"*Entity linking (EL) is the task of linking a textual named entity mention to a knowledge base entry. It is a difficult task involving many challenges, but the most crucial problem is entity ambiguity. Traditional EL approaches usually employ different constraints and filtering techniques to improve performance. However, these constraints are executed in several different stages and cannot be used interactively. In this paper, we propose several disambiguation formulae/features and employ a Markov logic network to model interweaved constraints found in one type of EL, gene mention linking. To assess our systems effectiveness in different applications, we adopt two evaluation schemes: article-wide and instance-based precision/recall/F-measure. Experimental results show that our system outperforms the baseline systems and state-of-the-art systems under both evaluation schemes."
I11-1157,Text Patterns and Compression Models for Semantic Class Learning,2011,21,0,3,0,43953,chungyao chuang,Proceedings of 5th International Joint Conference on Natural Language Processing,0,"This paper proposes a weakly-supervised approach for extracting instances of semantic classes. This method constructs simple wrappers automatically based on specified seed instances and uses a compression model to assess the contextual evidence of its extraction. By adopting this compression model, our approach can better avoid erroneous extractions in a noisy corpus such as the Web. The empirical results show that our system performs quite consistently even when operating on a noisy text with a lot of possibly irrelevant documents."
W10-4138,Term Contributed Boundary Tagging by Conditional Random Fields for {SIGHAN} 2010 {C}hinese Word Segmentation Bakeoff,2010,6,5,4,1,44732,tianjian jiang,{CIPS}-{SIGHAN} Joint Conference on {C}hinese Language Processing,0,None
O10-1010,Term Contributed Boundary Feature using Conditional Random Fields for {C}hinese Word Segmentation Task,2010,12,1,4,1,44732,tianjian jiang,Proceedings of the 22nd Conference on Computational Linguistics and Speech Processing ({ROCLING} 2010),0,"This paper proposes a novel feature for conditional random field (CRF) model in Chinese word segmentation system. The system uses a conditional random field as machine learning model with one simple feature called term contributed boundaries (TCB) in addition to the xe2x80x9cBIEOxe2x80x9d character-based label scheme. TCB can be extracted from unlabeled corpora automatically, and segmentation variations of different domains are expected to be reflected implicitly. The dataset used in this paper is the closed training task in CIPS-SIGHAN-2010 bakeoff, including simplified and traditional Chinese texts. The experiment result shows that TCB does improve xe2x80x9cBIEOxe2x80x9d tagging domain-independently about 1% of the F1 measure score."
C10-2026,Global Ranking via Data Fusion,2010,20,1,4,1,14599,hongjie dai,Coling 2010: Posters,0,"Global ranking, a new information retrieval (IR) technology, uses a ranking model for cases in which there exist relationships between the objects to be ranked. In the ranking task, the ranking model is defined as a function of the properties of the objects as well as the relations between the objects. Existing global ranking approaches address the problem by learning to rank. In this paper, we propose a global ranking framework that solves the problem via data fusion. The idea is to take each retrieved document as a pseudo-IR system. Each document generates a pseudo-ranked list by a global function. The data fusion algorithm is then adapted to generate the final ranked list. Taking a biomedical information extraction task, namely, interactor normalization task (INT), as an example, we explain how the problem can be formulated as a global ranking problem, and demonstrate how the proposed fusion-based framework outperforms baseline methods. By using the proposed framework, we improve the performance of the top 1 INT system by 3.2% using the official evaluation metric of the BioCreAtIvE challenge. In addition, by employing the standard ranking quality measure, NDCG, we demonstrate that the proposed framework can be cascaded with different local ranking models and improve their ranking results."
O08-3001,Exploring Shallow Answer Ranking Features in Cross-Lingual and Monolingual Factoid Question Answering,2008,-1,-1,3,0,42166,chengwei lee,"International Journal of Computational Linguistics {\\&} {C}hinese Language Processing, Volume 13, Number 1, March 2008: Special Issue on Cross-Lingual Information Retrieval and Question Answering",0,None
I08-1037,Learning Patterns from the Web to Translate Named Entities for Cross Language Information Retrieval,2008,6,5,3,1,32677,yuchun wang,Proceedings of the Third International Joint Conference on Natural Language Processing: Volume-{I},0,"Named entity (NE) translation plays an important role in many applications. In this paper, we focus on translating NEs from Korean to Chinese to improve Korean-Chinese cross-language information retrieval (KCIR). The ideographic nature of Chinese makes NE translation difficult because one syllable may map to several Chinese characters. We propose a hybrid NE translation system. First, we integrate two online databases to extend the coverage of our bilingual dictionaries. We use Wikipedia as a translation tool based on the inter-language links between the Korean edition and the Chinese or English editions. We also use Naver.comxe2x80x99s people search engine to find a query namexe2x80x99s Chinese or English translation. The second component is able to learn Korean-Chinese (KC), Korean-English (K-E), and EnglishChinese (E-C) translation patterns from the web. These patterns can be used to extract K-C, K-E and E-C pairs from Google snippets. We found KCIR performance using this hybrid configuration over five times better than that a dictionary-based configuration using only Naver people search. Mean average precision was as high as 0.3385 and recall reached 0.7578. Our method can handle Chinese, Japanese, Korean, and nonCJK NE translation and improve performance of KCIR substantially."
Y07-1051,{K}orean-{C}hinese Person Name Translation for Cross Language Information Retrieval,2007,8,0,5,1,32677,yuchun wang,"Proceedings of the 21st Pacific Asia Conference on Language, Information and Computation",0,"Named entity translation plays an important role in many applications, such as information retrieval and machine translation. In this paper, we focus on translating person names, the most common type of name entity in Korean-Chinese cross language information retrieval (KCIR). Unlike other languages, Chinese uses characters (ideographs), which makes person name translation difficult because one syllable may map to several Chinese characters. We propose an effective hybrid person name translation method to improve the performance of KCIR. First, we use Wikipedia as a translation tool based on the inter-language links between the Korean edition and the Chinese or English editions. Second, we adopt the Naver people search engine to find the query name's Chinese or English translation. Third, we extract Korean-English transliteration pairs from Google snippets, and then search for the English-Chinese transliteration in the database of Taiwan's Central News Agency or in Google. The performance of KCIR using our method is over five times better than that of a dictionary-based system. The mean average precision is 0.3490 and the average recall is 0.7534. The method can deal with Chinese, Japanese, Korean, as well as non-CJK person name translation from Korean to Chinese. Hence, it substantially improves the performance of KCIR."
O07-1003,{K}orean-{C}hinese Cross-Language Information Retrieval Based on Extension of Dictionaries and Transliteration,2007,8,0,4,1,32677,yuchun wang,Proceedings of the 19th Conference on Computational Linguistics and Speech Processing,0,"This paper describes our Korean-Chinese cross-language information retrieval system. Our system uses a bi-lingual dictionary to perform query translation. We expand our bilingual dictionary by extracting words and their translations from the Wikipedia site, an online encyclopedia. To resolve the problem of translating Western peoplexe2x80x99s names into Chinese, we propose a transliteration mapping method. We translate queries form Korean query to Chinese by using a co-occurrence method. When evaluating on the NTCIR-6 test set, the performance of our system achieves a mean average precision (MAP) of 0.1392 (relax score) for title query type and 0.1274 (relax score) for description query type."
W06-3308,{BIOSMILE}: Adapting Semantic Role Labeling for Biomedical Verbs:,2006,0,0,8,1,8569,richard tsai,Proceedings of the {HLT}-{NAACL} {B}io{NLP} Workshop on Linking Natural Language and Biology,0,None
W06-0602,A Semi-Automatic Method for Annotating a Biomedical {P}roposition {B}ank,2006,19,37,6,0,49625,wenchi chou,Proceedings of the Workshop on Frontiers in Linguistically Annotated Corpora 2006,0,"In this paper, we present a semiautomatic approach for annotating semantic information in biomedical texts. The information is used to construct a biomedical proposition bank called BioProp. Like PropBank in the newswire domain, BioProp contains annotations of predicate argument structures and semantic roles in a treebank schema. To construct BioProp, a semantic role labeling (SRL) system trained on PropBank is used to annotate BioProp. Incorrect tagging results are then corrected by human annotators. To suit the needs in the biomedical domain, we modify the PropBank annotation guidelines and characterize semantic roles as components of biological events. The method can substantially reduce annotation efforts, and we introduce a measure of an upper bound for the saving of annotation efforts. Thus far, the method has been applied experimentally to a 4,389-sentence tree-bank corpus for the construction of BioProp. Inter-annotator agreement measured by kappa statistic reaches .95 for combined decision of role identification and classification when all argument labels are considered. In addition, we show that, when trained on BioProp, our biomedical SRL system called BIOSMILE achieves an F-score of 87%."
W06-0120,On Closed Task of {C}hinese Word Segmentation: An Improved {CRF} Model Coupled with Character Clustering and Automatically Generated Template Matching,2006,1,13,5,1,8569,richard tsai,Proceedings of the Fifth {SIGHAN} Workshop on {C}hinese Language Processing,0,"This paper addresses two major problems in closed task of Chinese word segmentation (CWS): tagging sentences interspersed with non-Chinese words, and long named entity (NE) identification. To resolve the former, we apply Kmeans clustering to identify non-Chinese characters, and then adopt a two-tagger architecture: one for Chinese text and the other for non-Chinese text. For the latter problem, we apply postprocessing to our CWS output using automatically generated templates. The experiment results show that, when non-Chinese characters are sparse in the training corpus, our two-tagger method significantly improves the segmentation of sentences containing non-Chinese words. Identification of long NEs and long words is also enhanced by template-based postprocessing. In the closed task of SIGHAN 2006 CWS, our system achieved F-scores of 0.957, 0.972, and 0.955 on the CKIP, CTU, and MSR corpora respectively."
W06-0122,On Using Ensemble Methods for {C}hinese Named Entity Recognition,2006,9,17,4,1,49862,chiawei wu,Proceedings of the Fifth {SIGHAN} Workshop on {C}hinese Language Processing,0,"In sequence labeling tasks, applying different machine learning models and feature sets usually leads to different results. In this paper, we exploit two ensemble methods in order to integrate multiple results generated under different conditions. One method is based on majority vote, while the other is a memory-based approach that integrates maximum entropy and conditional random field classifiers. Our results indicate that the memory-based method can outperform the individual classifiers, but the majority vote method cannot."
W05-0638,Exploiting Full Parsing Information to Label Semantic Roles Using an Ensemble of {ME} and {SVM} via Integer Linear Programming,2005,7,24,4,1,37579,tzonghan tsai,Proceedings of the Ninth Conference on Computational Natural Language Learning ({C}o{NLL}-2005),0,"In this paper, we propose a method that exploits full parsing information by representing it as features of argument classification models and as constraints in integer linear learning programs. In addition, to take advantage of SVM-based and Maximum Entropy-based argument classification models, we incorporate their scoring matrices, and use the combined matrix in the above-mentioned integer linear programs. The experimental results show that full parsing information not only increases the F-score of argument classification models by 0.7%, but also effectively removes all labeling inconsistencies, which increases the F-score by 0.64%. The ensemble of SVM and ME also boosts the F-score by 0.77%. Our system achieves an F-score of 76.53% in the development set and 76.38% in Test WSJ."
O05-1017,Applying Maximum Entropy to Robust {C}hinese Shallow Parsing,2005,19,6,5,1,2436,shihhung wu,Proceedings of the 17th Conference on Computational Linguistics and Speech Processing,0,"Recently, shallow parsing has been applied to various information processing systems, such as information retrieval, information extraction, question answering, and automatic document summarization. A shallow parser is suitable for online applications, because it is much more efficient and less demanding than a full parser. In this research, we formulate shallow parsing as a sequential tagging problem and use a supervised machine learning technique, Maximum Entropy (ME), to build a Chinese shallow parser. The major features of the ME-based shallow parser are POSs and the context words in a sentence. We adopt the shallow parsing results of Sinica Treebank as our standard, and select 30,000 and 10,000 sentences from Sinica Treebank as the training set and test set respectively. We then test the robustness of the shallow parser with noisy data. The experiment results show that the proposed shallow parser is quite robust for sentences with unknown proper nouns."
I05-2046,Using Maximum Entropy to Extract Biomedical Named Entities without Dictionaries,2005,13,8,3,1,37579,tzonghan tsai,Companion Volume to the Proceedings of Conference including Posters/Demos and tutorial abstracts,0,None
O04-2003,Auto-Generation of {NVEF} Knowledge in {C}hinese,2004,26,2,3,1,48590,jialin tsai,"International Journal of Computational Linguistics {\\&} {C}hinese Language Processing, Volume 9, Number 1, {F}ebruary 2004: Special Issue on Selected Papers from {ROCLING} {XV}",0,"Noun-verb event frame (NVEF) knowledge in conjunction with an NVEF word-pair identifier [Tsai et al. 2002] comprises a system that can be used to support natural language processing (NLP) and natural language understanding (NLU). In [Tsai et al. 2002a], we demonstrated that NVEF knowledge can be used effectively to solve the Chinese word-sense disambiguation (WSD) problem with 93.7% accuracy for nouns and verbs. In [Tsai et al. 2002b], we showed that NVEF knowledge can be applied to the Chinese syllable-to-word (STW) conversion problem to achieve 99.66% accuracy for the NVEF related portions of Chinese sentences. In [Tsai et al. 2002a], we defined a collection of NVEF knowledge as an NVEF word-pair (a meaningful NV word-pair) and its corresponding NVEF sense-pairs. No methods exist that can fully and automatically find collections of NVEF knowledge from Chinese sentences. We propose a method here for automatically acquiring large-scale NVEF knowledge without human intervention in order to identify a large, varied range of NVEF-sentences (sentences containing at least one NVEF word-pair). The auto-generation of NVEF knowledge (AUTO-NVEF) includes four major processes: (1) segmentation checking; (2) Initial Part-of-Speech (IPOS) sequence generation; (3) NV knowledge generation; and (4) NVEF knowledge auto-confirmation.n Our experimental results show that AUTO-NVEF achieved 98.52% accuracy for news and 96.41% for specific text types, which included research reports, classical literature and modern literature. AUTO-NVEF automatically discovered over 400,000 NVEF word-pairs from the 2001 United Daily News (2001 UDN) corpus. According to our estimation, the acquired NVEF knowledge from 2001 UDN helped to identify 54% of the NVEF-sentences in the Academia Sinica Balanced Corpus (ASBC), and 60% in the 2001 UDN corpus. n We plan to expand NVEF knowledge so that it is able to identify more than 75% of NVEF-sentences in ASBC. We will also apply the acquired NVEF knowledge to support other NLP and NLU researches, such as machine translation, shallow parsing, syllable and speech understanding and text indexing. The auto-generation of bilingual, especially Chinese-English, NVEF knowledge will be also addressed in our future work."
O04-2004,{M}encius: A {C}hinese Named Entity Recognizer Using the Maximum Entropy-based Hybrid Model,2004,16,28,5,1,37579,tzonghan tsai,"International Journal of Computational Linguistics {\\&} {C}hinese Language Processing, Volume 9, Number 1, {F}ebruary 2004: Special Issue on Selected Papers from {ROCLING} {XV}",0,"This paper presents a Chinese named entity recognizer (NER): Mencius. It aims to address Chinese NER problems by combining the advantages of rule-based and machine learning (ML) based NER systems. Rule-based NER systems can explicitly encode human comprehension and can be tuned conveniently, while ML-based systems are robust, portable and inexpensive to develop. Our hybrid system incorporates a rule-based knowledge representation and template-matching tool, called InfoMap [Wu et al. 2002], into a maximum entropy (ME) framework. Named entities are represented in InfoMap as templates, which serve as ME features in Mencius. These features are edited manually, and their weights are estimated by the ME framework according to the training data. To understand how word segmentation might influence Chinese NER and the differences between a pure template-based method and our hybrid method, we configure Mencius using four distinct settings. The F-Measures of person names (PER), location names (LOC) and organization names (ORO) of the best configuration in our experiment were respectively 94.3%, 77.8% and 75.3%. From comparing the experiment results obtained using these configurations reveals that hybrid NER Systems always perform better performance in identifying person names. On the other hand, they have a little difficulty identifying location and organization names. Furthermore, using a word segmentation module improves the performance of pure Template-based NER Systems, but, it has little effect on hybrid NER systems."
O04-1009,Applying Meaningful Word-Pair Identifier to the {C}hinese Syllable-to-Word Conversion Problem,2004,-1,-1,3,1,48590,jialin tsai,Proceedings of the 16th Conference on Computational Linguistics and Speech Processing,0,None
O04-1032,The Construction of a {C}hinese Named Entity Tagged Corpus: {CNEC}1.0,2004,8,4,5,1,40686,chengwei shih,Proceedings of the 16th Conference on Computational Linguistics and Speech Processing,0,"In order to build an automatic named entity recognition (NER) system for machine learning, a large tagged corpus is necessary. This paper describes the manual construction of a Chinese named entity tagged corpus (CNEC 1.0) that can be used to improve NER performance. In this project, we define five named entity tags: PER (person name), LOC (location name), ORG (organization name), LAO (location as organization), and OAL (organization as location) for named entity categories. In addition, we propose a special tag, DIFF (Difficulty), to annotate ambiguous cases during corpus construction. A, corpus-annotating procedure, a tagging tool, and an original corpus are also introduced. Finally, we demonstrate a part of our manual-tagged corpus."
W03-1118,Text Categorization Using Automatically Acquired Domain Ontology,2003,11,23,3,1,2436,shihhung wu,Proceedings of the Sixth International Workshop on Information Retrieval with {A}sian Languages,0,"In this paper, we describe ontology-based text categorization in which the domain ontologies are automatically acquired through morphological rules and statistical methods. The ontology-based approach is a promising way for general information retrieval applications such as knowledge management or knowledge discovery. As a way to evaluate the quality of domain ontologies, we test our method through several experiments. Automatically acquired domain ontologies, with or without manual editing, have been used for text categorization. The results are quite satisfactory. Furthermore, we have developed an automatic method to evaluate the quality of our domain ontology."
O03-1009,Auto-Discovery of {NVEF} Word-Pairs in {C}hinese,2003,11,1,3,1,48590,jialin tsai,Proceedings of Research on Computational Linguistics Conference {XV},0,"A meaningful noun-verb word-pair in a sentence is called a noun-verb event-frame (NVFE). Previously, we have developed an NVEF word-pair identifier to demonstrate that NVEF knowledge can be used effectively to resolve the Chinese word-sense disambiguation (WSD) problem (with 93.7% accuracy) and the Chinese syllable-to-word (STW) conversion problem (with 99.66% accuracy) on the NVEF related portion. In this paper, we propose a method for automatically acquiring a large scale NVEF knowledge without human intervention. The automatic discovery of NVEF knowledge includes four major processes: (1) segmentation check; (2) Initial Part-of-speech (POS) sequence generation; (3) NV knowledge generation and (4) automatic NVEF knowledge confirmation. Our experimental results show that the precision of the automatically acquired NVEF knowledge reaches 98.52% for the test sentences. In fact, it has automatically discovered more than three hundred thousand NVEF word-pairs from the 2001 United Daily News (2001 UDN) corpus. The acquired NVEF knowledge covers 48% NV-sentences in Academia Sinica Balanced Corpus (ASBC), where an NV-sentence is one including at least a noun and a verb. In the future, we will expand the size of NVEF knowledge to cover more than 75% of NV-sentences in ASBC. We will also apply the acquired NVEF knowledge to support other NLP researches, in particular, shallow parsing, syllable/speech understanding and text indexing."
O03-1011,{C}hinese Word Auto-Confirmation Agent,2003,16,8,3,1,48590,jialin tsai,Proceedings of Research on Computational Linguistics Conference {XV},0,"In various Asian languages, including Chinese, there is no space between words in texts. Thus, most Chinese NLP systems must perform word-segmentation (sentence tokenization). However, successful word-segmentation depends on having a sufficiently large lexicon. On the average, about 3% of the words in text are not contained in a lexicon. Therefore, unknown word identification becomes a bottleneck for Chinese NLP systems. In this paper, we present a Chinese word auto-confirmation (CWAC) agent. CWAC agent uses a hybrid approach that takes advantage of statistical and linguistic approaches. The task of a CWAC agent is to auto-confirm whether an n-gram input (n xe2x89xa5 2) is a Chinese word. We design our CWAC agent to satisfy two criteria: (1) a greater than 98% precision rate and a greater than 75% recall rate and (2) domain-independent performance (F-measure). These criteria assure our CWAC agents can work automatically without human intervention. Furthermore, by combining several CWAC agents designed based on different principles, we can construct a multi-CWAC agent through a building-block approach. Three experiments are conducted in this study. The results demonstrate that, for n-gram frequency xe2x89xa5 4 in large corpus, our CWAC agent can satisfy the two criteria and achieve 97.82% precision, 77.11% recall, and 86.24% domain-independent F-measure. No existing systems can achieve such a high precision and domain-independent F-measure. The proposed method is our first attempt for constructing a CWAC agent. We will continue develop other CWAC agents and integrating them into a multi-CWAC agent system."
O03-1012,{M}encius: A {C}hinese Named Entity Recognizer Using Hybrid Model,2003,16,0,3,1,37579,tzonghan tsai,Proceedings of Research on Computational Linguistics Conference {XV},0,"This paper presents a maximum entropy based Chinese named entity recognizer (NER): Mencius. It aims to address Chinese NER problems by combining the advantages of rule-based and machine learning (ML) based NER systems. Rule-based NER systems can explicitly encode human comprehension and can be tuned conveniently, while ML-based systems are robust, portable and inexpensive to develop. Our hybrid system incorporates a rule-based knowledge representation and template-matching tool, InfoMap [1], into a maximum entropy (ME) framework. Named entities are represented in InfoMap as templates, which serve as ME features in Mencius. These features are edited manually and their weights are estimated by the ME framework according to the training data. To avoid the errors caused by word segmentation, we model the NER problem as a character-based tagging problem. In our experiments, Mencius outperforms both pure rule-based and pure ME-based NER systems. The F-Measures of person names (PER), location names (LOC) and organization names (ORG) in the experiment are respectively 92.4%, 73.7% and 75.3%."
O02-1002,Word Sense Disambiguation and Sense-Based {NV} Event Frame Identifier,2002,6,5,2,1,48590,jialin tsai,"International Journal of Computational Linguistics {\\&} {C}hinese Language Processing, Volume 7, Number 1, {F}ebruary 2002: Special Issue on {H}ow{N}et and Its Applications",0,"Word sense is ambiguous in natural language processing (NLP). This phenomenon is particularly keen in cases involving noun-verb (NV) word-pairs. This paper describes a sense-based noun-verb event frame (NVEF) identifier that can be used to disambiguate word sense in Chinese sentences effectively. A knowledge representation system (the NVEF-KR tree) for the NVEF sense-pair identifier is also proposed. We use the word sense of Hownet, which is a Chinese-English bilingual knowledge-base dictionary. Our experiment showed that the NVEF identifier was able to achieve 74.8% accuracy for the test sentences studied based only on NVEF sense-pair knowledge. By applying the techniques of longest syllabic NVEF-word-pair first and exclusion word checking, the sense accuracy for the same test sentences could be further improved to 93.7%. There were four major reasons for the incorrect cases: (1) lack of a bottom-up tagger, (2) lack of non-NVEF knowledge, (3) inadequate word segmentation, and (4) lack of a multi-NVEF analyzer. If these four problems could be resolved, the accuracy would reach 98.9%. The results of this study indicate that NVEF sense-pair knowledge is effective for word sense disambiguation and is likely to be important for general NLP."
C02-2013,{SOAT}: A Semi-Automatic Domain Ontology Acquisition Tool from {C}hinese Corpus,2002,14,32,2,1,2436,shihhung wu,{COLING} 2002: The 17th International Conference on Computational Linguistics: Project Notes,0,"In this paper, we focus on the domain ontology acquisition from Chinese corpus by extracting rules designed for Chinese phrases. These rules are noun sequences with part-of-speech tags. Experiments show that this process can construct domain ontology prototypes efficiently and effectively."
C02-1089,Applying an {NVEF} Word-Pair Identifier to the {C}hinese Syllable-to-Word Conversion Problem,2002,19,13,2,1,48590,jialin tsai,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"Syllable-to-word (STW) conversion is important in Chinese phonetic input methods and speech recognition. There are two major problems in the STW conversion: (1) resolving the ambiguity caused by homonyms; (2) determining the word segmentation. This paper describes a noun-verb event-frame (NVEF) word identifier that can be used to solve these problems effectively. Our approach includes (a) an NVEF word-pair identifier and (b) other word identifiers for the non-NVEF portion.Our experiment showed that the NVEF word-pair identifier is able to achieve a 99.66% STW accuracy for the NVEF related portion, and by combining with other identifiers for the non-NVEF portion, the overall STW accuracy is 96.50%.The result of this study indicates that the NVEF knowledge is very powerful for the STW conversion. In fact, numerous cases requiring disambiguation in natural language processing fall into such chicken-and-egg situation. The NVEF knowledge can be employed as a general tool in such systems for disambiguating the NVEF related portion independently (thus breaking the chicken-and-egg situation) and using that as a good fundamental basis to treat the remaining portion. This shows that the NVEF knowledge is likely to be important for general NLP. To further expand its coverage, we shall extend the study of NVEF to that of other co-occurrence restrictions such as noun-noun pairs, noun-adjective pairs and verb-adverb pairs. We believe the STW accuracy can be further improved with the additional knowledge."
O98-2001,çµåçµ±è¨èè¦åçå¤å±¤æ¬¡ä¸­ææ·è©ç³»çµ± (A hierarchical {C}hinese word segmentation system based on statistical and rule-based methods) [In {C}hinese],1998,0,0,2,0,55370,chungchen chen,{ROCLING} 1998 Short Papers,0,None
