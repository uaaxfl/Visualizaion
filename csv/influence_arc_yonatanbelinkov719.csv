2020.acl-main.422,W19-4814,0,0.0311576,"a similar approach, but explores a range of similarity measures over different contextual word representation models. Questions of localization and distributivity of information have been under investigation for a long time in the connectionist cognitive science literature (Page, 2000; Bowers, 2002; Gayler and Levy, 2011). While neural language representations are thought to be densely distributed, several recent studies have pointed out the importance of individual neurons (Qian et al., 2016; Shi et al., 2016; Radford et al., 2017; Lakretz et al., 2019; Bau et al., 2019; Dalvi et al., 2019; Baan et al., 2019). Our study contributes to this line of work by designing measures of localization and distributivity of information in a collection of models. Such measures may facilitate incorporating neuron interactions in new training objectives (Li et al., 2020). 3 Similarity Measures We present five groups of similarity measures, each capturing a different similarity notion. Consider a collection of M models {f (m) }M m=1 , yielding (m) word representations hl and potentially atten(m) tion weights αl at each layer l. Let k index neu(m) (m) (m) rons hl [k] or attention heads αl [k]. hl [k], (m) αl [k] ar"
2020.acl-main.422,D19-1445,0,0.0290966,"sk finetuning setup. In contrast, in XLNet, fine-tuning on any task leads to top layers being very different from all layers of models fine-tuned on other tasks. This suggests that XLNet representations become very task-specific, and thus multi-task fine-tuning may be less effective with XLNet than with BERT. Observing the attnsim similarity based on Jensen–Shannon divergence for base and fine-tuned models (Figure 6), we again see that top layers have lower similarities, implying that they undergo greater changed during fine-tuning. Other attentionbased measures behaved similarly (not shown). Kovaleva et al. (2019) made a similar observation by comparing the cosine similarity of attention matrices in BERT, although they did not perform crosstask comparisons. In fact, the diagonals within each block indicate that bottom layers remain similar to one another even when fine-tuning on different tasks, while top layers diverge after finetuning. The vertical bands at layers 0 mean that many higher layers have a head that is very similar to a head from the first layer, that is, a form of redundancy, which can explain why many heads can be pruned (Michel et al., 2019; Voita et al., 2019b; Kovaleva et al., 2019)."
2020.acl-main.422,N19-1002,0,0.0433694,"rt-ofspeech tagger (Saphra and Lopez, 2019). Our work adopts a similar approach, but explores a range of similarity measures over different contextual word representation models. Questions of localization and distributivity of information have been under investigation for a long time in the connectionist cognitive science literature (Page, 2000; Bowers, 2002; Gayler and Levy, 2011). While neural language representations are thought to be densely distributed, several recent studies have pointed out the importance of individual neurons (Qian et al., 2016; Shi et al., 2016; Radford et al., 2017; Lakretz et al., 2019; Bau et al., 2019; Dalvi et al., 2019; Baan et al., 2019). Our study contributes to this line of work by designing measures of localization and distributivity of information in a collection of models. Such measures may facilitate incorporating neuron interactions in new training objectives (Li et al., 2020). 3 Similarity Measures We present five groups of similarity measures, each capturing a different similarity notion. Consider a collection of M models {f (m) }M m=1 , yielding (m) word representations hl and potentially atten(m) tion weights αl at each layer l. Let k index neu(m) (m) (m) ro"
2020.acl-main.422,N19-1112,1,0.849968,"s ELMo (Peters et al., 2018a) and BERT (Devlin et al., 2019) have led to impressive improvements in a variety of tasks. With this progress in breaking the state of the art, interest in the community has expanded to analyzing such models in an effort to illuminate their inner workings. A number of studies have analyzed the internal representations in such models and attempted to assess what linguistic properties they capture. A prominent methodology for this is to train supervised classifiers based on the models’ learned representations, and predict various linguistic properties. For instance, Liu et al. (2019a) train such classifiers on 16 linguistic tasks, including part-of-speech tagging, chunking, named ∗ Equal contribution The code is available at https://github.com/ johnmwu/contextual-corr-analysis. 1 entity recognition, and others. Such an approach may reveal how well representations from different models, and model layers, capture different properties. This approach, known as analysis by probing classifiers, has been used in numerous other studies (Belinkov and Glass, 2019). While the above approach yields compelling insights, its applicability is constrained by the availability of linguist"
2020.acl-main.422,2021.ccl-1.108,0,0.092394,"Missing"
2020.acl-main.422,J93-2004,0,0.0700399,"er-equivalent variant (Peters et al., 2018b). GPT variants We use both the original OpenAI Transformer (GPT; Radford et al. 2018) and its successor GPT2 (Radford et al., 2019), in the small and medium model sizes. These are all unidirectional Transformer LMs. BERT We use BERT-base/large (12/24 layers; Devlin et al. 2019): Transformer LMs trained with a masked LM objective function.6 XLNet We use XLNet-base/large (12/24 layers; Yang et al. 2019). Both are Transformer LM with a permutation-based objective function. Data For analyzing the models, we run them on the Penn Treebank development set (Marcus et al., 1993), following the setup taken by Liu et al. (2019a) in their probing classifier experiments.7 We collect representations and attention weights from each layer in each model for computing the similarity measures. We obtain representations for models used in Liu et al. (2019a) from their implementation and use the transformers library (Wolf et al., 2019) to extract other representations. We aggregate sub-word representations by taking the representation of the last sub-word, following Liu et al. (2019a), and sub-word attentions by summing up at6 BERT is also trained with a next sentence prediction"
2020.acl-main.422,D18-1179,0,0.154589,"the deep models, and facilitate the investigation of which design factors affect model similarity, without requiring any external linguistic annotation. The analysis reveals that models within the same family are more similar to one another, as may be expected. Surprisingly, different architectures have rather similar representations, but different individual neurons. We also observed differences in information localization in lower and higher layers and found that higher layers are more affected by fine-tuning on downstream tasks.1 1 Introduction Contextual word representations such as ELMo (Peters et al., 2018a) and BERT (Devlin et al., 2019) have led to impressive improvements in a variety of tasks. With this progress in breaking the state of the art, interest in the community has expanded to analyzing such models in an effort to illuminate their inner workings. A number of studies have analyzed the internal representations in such models and attempted to assess what linguistic properties they capture. A prominent methodology for this is to train supervised classifiers based on the models’ learned representations, and predict various linguistic properties. For instance, Liu et al. (2019a) train su"
2020.acl-main.422,D16-1079,0,0.0415815,"Missing"
2020.acl-main.422,D16-1264,0,0.0565186,"d Smith, 2019; Brunner et al., 2020). However, characterizing the effect of such concerns on our attention-based similarity measures is beyond the current scope. 6 Similarity of Fine-tuned Models How does fine-tuning on downstream tasks affect model similarity? In this section, we compare pretrained models and their fine-tuned versions. We use four of the GLUE tasks (Wang et al., 2019): MNLI A multi-genre natural language inference dataset (Williams et al., 2018), where the task is to predict whether a premise entails a hypothesis. QNLI A conversion of the Stanford question answering dataset (Rajpurkar et al., 2016), where the task is to determine whether a sentence contains the answer to a question. QQP A collection of question pairs from the Quora website, where the task is to determine whether two questions are semantically equivalent. SST-2 A binary sentiment analysis task using the Stanford sentiment treebank (Socher et al., 2013). 6.1 Results Top layers are more affected by fine-tuning Figure 5 shows representation-level ckasim similarity heatmaps of pre-trained (not fine-tuned) and fine-tuned versions of BERT and XLNet. The most striking pattern is that the top layers are more affected by fine-tun"
2020.acl-main.422,N19-1329,0,0.296007,"ies between model representations. Bau et al. (2019) used this approach to analyze the role of individual neurons in neural machine translation. They found that individual neurons are important and interpretable. However, their work was limited to a certain kind of architecture (specifically, a recurrent one). In contrast, we compare models of various architectures and objective functions. Other work used similarity measures to study learning dynamics in language models by comparing checkpoints of recurrent language models (Morcos et al., 2018), or a language model and a part-ofspeech tagger (Saphra and Lopez, 2019). Our work adopts a similar approach, but explores a range of similarity measures over different contextual word representation models. Questions of localization and distributivity of information have been under investigation for a long time in the connectionist cognitive science literature (Page, 2000; Bowers, 2002; Gayler and Levy, 2011). While neural language representations are thought to be densely distributed, several recent studies have pointed out the importance of individual neurons (Qian et al., 2016; Shi et al., 2016; Radford et al., 2017; Lakretz et al., 2019; Bau et al., 2019; Dal"
2020.acl-main.422,P19-1282,0,0.0196114,"RT-base and middle layers of BERT-large. This parallels the findings from comparing representations of XLNet and BERT, which we conjecture is the result of the permutation-based objective in XLNet. In general, we find the attention-based similarities to be mostly in line with the neuron- and representation-level similarities. Nevertheless, they appear to be harder to interpret, as fine-grained patterns are less noticeable. One might mention in this context concerns regarding the reliability of attention weights for interpreting the importance of input words in a model (Jain and Wallace, 2019; Serrano and Smith, 2019; Brunner et al., 2020). However, characterizing the effect of such concerns on our attention-based similarity measures is beyond the current scope. 6 Similarity of Fine-tuned Models How does fine-tuning on downstream tasks affect model similarity? In this section, we compare pretrained models and their fine-tuned versions. We use four of the GLUE tasks (Wang et al., 2019): MNLI A multi-genre natural language inference dataset (Williams et al., 2018), where the task is to predict whether a premise entails a hypothesis. QNLI A conversion of the Stanford question answering dataset (Rajpurkar et"
2020.acl-main.422,D16-1248,0,0.0236354,"al., 2018), or a language model and a part-ofspeech tagger (Saphra and Lopez, 2019). Our work adopts a similar approach, but explores a range of similarity measures over different contextual word representation models. Questions of localization and distributivity of information have been under investigation for a long time in the connectionist cognitive science literature (Page, 2000; Bowers, 2002; Gayler and Levy, 2011). While neural language representations are thought to be densely distributed, several recent studies have pointed out the importance of individual neurons (Qian et al., 2016; Shi et al., 2016; Radford et al., 2017; Lakretz et al., 2019; Bau et al., 2019; Dalvi et al., 2019; Baan et al., 2019). Our study contributes to this line of work by designing measures of localization and distributivity of information in a collection of models. Such measures may facilitate incorporating neuron interactions in new training objectives (Li et al., 2020). 3 Similarity Measures We present five groups of similarity measures, each capturing a different similarity notion. Consider a collection of M models {f (m) }M m=1 , yielding (m) word representations hl and potentially atten(m) tion weights αl at"
2020.acl-main.422,silveira-etal-2014-gold,0,0.0507562,"Missing"
2020.acl-main.422,D13-1170,0,0.0108017,"Missing"
2020.acl-main.422,P19-1452,0,0.0346209,"layers. In effect, we take the column-wise mean of each heatmap. We do this separately for svsim as the distributed measure and neuronsim as the localized measure, and we subtract the svsim means from the neuronsim means. This results in a measure of localization per layer. Figure 3 shows the results. In all models, the localization score mostly increases with layers, indicating that information tends to become more localized at higher layers.12 This pattern is quite consistent, but may be surprising given prior observations on lower layers capturing phenomena that operate at a local context (Tenney et al., 2019), which presumably require fewer neurons. However, this pattern is in line with observations made by Ethayarajh (2019), who reported that upper layers of pre-trained models produce more context-specific representations. There appears to be a correspondence between our localization score and Ethayarajh’s context-specificity score, which is based on the cosine similarity of representations of the same word in different contexts. Thus, more localized representations are also more context-specific. A direct comparison between context-specificity and localization may be fruitful avenue for future w"
2020.acl-main.422,D19-1448,0,0.380748,"also experimented with the RBF variant, which is computationally demanding. We found similar patterns in preliminary experiments, so we focus on the linear variant. has been used to analyze neural network representations (Bouchacourt and Baroni, 2018; Chrupała and Alishahi, 2019; Chrupała, 2019), or other variants of CCA, such as deep CCA (Andrew et al., 2013). We leave the explorations of such measures to future work. 3.4 Attention-level similarity Previous work analyzing network similarity has mostly focused on representation-based similarities (Morcos et al., 2018; Saphra and Lopez, 2019; Voita et al., 2019a). Here we consider similarity based on attention weights in Transformer models. Analogous to a neuron-level similarity measure, an attention-level similarity measure finds the most “correlated” other attention head. We consider three methods to correlate heads, based on the norm of (m) (m0 ) two attention matrices αl [k], αl0 [k 0 ], their Pearson correlation, and their Jensen–Shannon divergence.5 We then average over heads k in layer l, as before. These measures are similar to neuronsim in that they emphasize localization of information—if two layers have pairs of heads that are very simila"
2020.acl-main.422,P19-1580,0,0.383097,"also experimented with the RBF variant, which is computationally demanding. We found similar patterns in preliminary experiments, so we focus on the linear variant. has been used to analyze neural network representations (Bouchacourt and Baroni, 2018; Chrupała and Alishahi, 2019; Chrupała, 2019), or other variants of CCA, such as deep CCA (Andrew et al., 2013). We leave the explorations of such measures to future work. 3.4 Attention-level similarity Previous work analyzing network similarity has mostly focused on representation-based similarities (Morcos et al., 2018; Saphra and Lopez, 2019; Voita et al., 2019a). Here we consider similarity based on attention weights in Transformer models. Analogous to a neuron-level similarity measure, an attention-level similarity measure finds the most “correlated” other attention head. We consider three methods to correlate heads, based on the norm of (m) (m0 ) two attention matrices αl [k], αl0 [k 0 ], their Pearson correlation, and their Jensen–Shannon divergence.5 We then average over heads k in layer l, as before. These measures are similar to neuronsim in that they emphasize localization of information—if two layers have pairs of heads that are very simila"
2020.acl-main.422,W16-2524,0,\N,Missing
2020.acl-main.422,P17-1080,1,\N,Missing
2020.acl-main.422,D17-1169,0,\N,Missing
2020.acl-main.422,D18-1119,0,\N,Missing
2020.acl-main.422,Q19-1004,1,\N,Missing
2020.acl-main.422,N19-1357,0,\N,Missing
2020.acl-main.422,P19-1283,0,\N,Missing
2020.acl-main.422,N19-1423,0,\N,Missing
2020.acl-main.422,P19-1647,0,\N,Missing
2020.acl-main.422,N18-1101,0,\N,Missing
2020.acl-main.422,D19-1424,0,\N,Missing
2020.acl-main.679,J90-1003,0,\N,Missing
2020.acl-main.679,Q15-1016,0,\N,Missing
2020.acl-main.679,D12-1071,0,\N,Missing
2020.acl-main.679,L16-1680,0,\N,Missing
2020.acl-main.679,K17-1004,0,\N,Missing
2020.acl-main.679,S18-2023,0,\N,Missing
2020.acl-main.679,L18-1239,0,\N,Missing
2020.acl-main.679,W18-5446,0,\N,Missing
2020.acl-main.679,Q19-1004,1,\N,Missing
2020.acl-main.679,P19-1334,0,\N,Missing
2020.acl-main.679,P19-1478,0,\N,Missing
2020.acl-main.679,N19-1419,0,\N,Missing
2020.acl-main.679,W19-4825,0,\N,Missing
2020.acl-main.679,W19-4820,0,\N,Missing
2020.acl-main.679,P19-1084,1,\N,Missing
2020.acl-main.679,W19-4828,0,\N,Missing
2020.acl-main.679,N19-1423,0,\N,Missing
2020.acl-main.679,D19-1109,0,\N,Missing
2020.acl-main.679,D19-1593,1,\N,Missing
2020.acl-main.769,Q15-1034,0,0.0880252,"Missing"
2020.acl-main.769,D19-1341,0,0.122801,".com/rabeehk/robust-nli. 1 Introduction Recent neural models (Devlin et al., 2019; Radford et al., 2018; Chen et al., 2017) have achieved high and even near human-performance on several largescale natural language understanding benchmarks. However, it has been demonstrated that neural models tend to rely on existing idiosyncratic biases in the datasets, and leverage superficial correlations between the label and existing shortcuts in the training dataset to perform surprisingly well,1 without learning the underlying task (Kaushik and Lipton, 2018; Gururangan et al., 2018; Poliak et al., 2018; Schuster et al., 2019; 1 We use biases, heuristics or shortcuts interchangeably. McCoy et al., 2019b). For instance, natural language inference (NLI) is supposed to test the ability of a model to determine whether a hypothesis sentence (There is no teacher in the room) can be inferred from a premise sentence (Kids work at computers with a teacher’s help) (Dagan et al., 2006).2 However, recent work has demonstrated that large-scale NLI benchmarks contain annotation artifacts; certain words in the hypothesis that are highly indicative of inference class and allow models that do not consider the premise to perform un"
2020.acl-main.769,P18-2119,0,0.0286132,"ated with the contradiction label. As a result of the existence of such biases, models exploiting statistical shortcuts during training often perform poorly on out-of-domain datasets, especially if the datasets are carefully designed to limit the spurious cues. To allow proper evaluation, recent studies have tried to create new evaluation datasets that do not contain such biases (Gururangan et al., 2018; Schuster et al., 2019; McCoy et al., 2019b). Unfortunately, it is hard to avoid spurious statistical cues in the construction of large-scale benchmarks, and collecting new datasets is costly (Sharma et al., 2018). It is, therefore, crucial to develop techniques to reduce the reliance on biases during the training of the neural models. We propose two end-to-end debiasing techniques that can be used when the existing bias patterns are identified. These methods work by adjusting the crossentropy loss to reduce the biases learned from the training dataset, down-weighting the biased examples so that the model focuses on learning the hard examples. Figure 1 illustrates an example of applying our strategy to prevent an NLI model from predicting the labels using existing biases in the hypotheses, where the bi"
2020.acl-main.769,P16-2022,0,0.0608664,"Missing"
2020.acl-main.769,P16-1204,0,0.0804035,"Missing"
2020.acl-main.769,I17-1100,0,0.0955643,"Missing"
2020.acl-main.769,N18-1101,0,0.0784115,"urces of bias by training multiple bias-only models. Our approaches are simple and highly effective. They require training only a simple model on top of the base model. They are model agnostic and general enough to be applicable for addressing common biases seen in many datasets in different domains. We evaluate our models on challenging benchmarks in textual entailment and fact verification, including HANS (Heuristic Analysis for NLI Systems) (McCoy et al., 2019b), hard NLI sets (Gururangan et al., 2018) of Stanford Natural Language Inference (SNLI) (Bowman et al., 2015) and MultiNLI (MNLI) (Williams et al., 2018), and FEVER Symmetric test set (Schuster et al., 2019). The selected datasets are highly challenging and have been carefully designed to be unbiased to allow proper evaluation of the out-of-domain performance of the models. We additionally construct hard MNLI datasets from MNLI development sets to facilitate the out-of-domain evaluation on this dataset.3 We show that including our strategies on training baseline models, including BERT (Devlin et al., 2019), provides a substantial gain on out-of-domain performance in all the experiments. In summary, we make the following contributions: 1) Propo"
2020.acl-tutorials.1,S19-1026,1,0.878132,"Missing"
2020.acl-tutorials.1,P18-2006,0,0.0238567,"u et al., 2014; Strobelt et al., 2018), and saliency measures (Li et al., 2016; Murdoch et al., 2018; Arras et al., 2017), including a walkthrough on how to build a simple attention visualization. Next, we will discuss the construction and use of challenge sets for fine-grained evaluation in the context of different tasks (Conneau and Kiela, 2018; Wang et al., 2018; Isabelle and Kuhn, 2018; Sennrich, 2017, inter alia). Finally, we will review work on generating adversarial examples in NLP, focusing on the challenges brought upon by the discrete nature of textual input (Papernot et al., 2016b; Ebrahimi et al., 2018; Jia and Liang, 2017; Belinkov and Bisk, 2018, inter alia). A detailed outline is provided in Section 3. Throughout the tutorial, we will highlight not only the most commonly applied analysis methods, but also the specific limitations and shortcomings of current approaches. By the end of the tutorial, participants will be better informed where to focus future research efforts. 2 5. Other Methods (a) Generating Explanations (b) Psycholinguistic Methods (c) Testing on Formal Languages 6. Conclusion 4 We would assume acquaintance with core linguistic concepts and basic knowledge of machine learn"
2020.acl-tutorials.1,Q16-1037,0,0.327684,"ndardized. This tutorial aims to fill this gap and introduce the nascent field of interpretability and analysis of neural networks in NLP. The tutorial will cover the main lines of analysis work, mostly drawing on the recent TACL survey by Belinkov and Glass (2019).1 In particular, we will devote a large portion to work aiming to find linguistic information that is captured by neural networks, such as probing classifiers (Hupkes et al., 2018; Adi et al., 2017; Conneau et al., 2018a,b; Tenney et al., 2019b, inter alia), controlled behavior studies on language modelling (Gulordava et al., 2018; Linzen et al., 2016a; Marvin and Linzen, 2018) or inference tasks (Poliak et al., 2018a,b; White et al., 2017; Kim et al., 2019; McCoy et al., 2019; Ross and Pavlick, 2019), psycholinguistic methods (Ettinger et al., 2018; Chrupała and Alishahi, 2019), layerwise analyses (Peters et al., 2018; Tenney et al., 2019a), among other methods (Hewitt and Manning, 2019; Zhang While deep learning has transformed the natural language processing (NLP) field and impacted the larger computational linguistics community, the rise of neural networks is stained by their opaque nature: It is challenging to interpret the inner work"
2020.acl-tutorials.1,C18-1152,0,0.0822829,"ly drawing on the recent TACL survey by Belinkov and Glass (2019).1 In particular, we will devote a large portion to work aiming to find linguistic information that is captured by neural networks, such as probing classifiers (Hupkes et al., 2018; Adi et al., 2017; Conneau et al., 2018a,b; Tenney et al., 2019b, inter alia), controlled behavior studies on language modelling (Gulordava et al., 2018; Linzen et al., 2016a; Marvin and Linzen, 2018) or inference tasks (Poliak et al., 2018a,b; White et al., 2017; Kim et al., 2019; McCoy et al., 2019; Ross and Pavlick, 2019), psycholinguistic methods (Ettinger et al., 2018; Chrupała and Alishahi, 2019), layerwise analyses (Peters et al., 2018; Tenney et al., 2019a), among other methods (Hewitt and Manning, 2019; Zhang While deep learning has transformed the natural language processing (NLP) field and impacted the larger computational linguistics community, the rise of neural networks is stained by their opaque nature: It is challenging to interpret the inner workings of neural network models, and explicate their behavior. Therefore, in the last few years, an increasingly large body of work has been devoted to the analysis and interpretation of neural network mo"
2020.acl-tutorials.1,N18-1108,0,0.0235295,"ds which are not yet standardized. This tutorial aims to fill this gap and introduce the nascent field of interpretability and analysis of neural networks in NLP. The tutorial will cover the main lines of analysis work, mostly drawing on the recent TACL survey by Belinkov and Glass (2019).1 In particular, we will devote a large portion to work aiming to find linguistic information that is captured by neural networks, such as probing classifiers (Hupkes et al., 2018; Adi et al., 2017; Conneau et al., 2018a,b; Tenney et al., 2019b, inter alia), controlled behavior studies on language modelling (Gulordava et al., 2018; Linzen et al., 2016a; Marvin and Linzen, 2018) or inference tasks (Poliak et al., 2018a,b; White et al., 2017; Kim et al., 2019; McCoy et al., 2019; Ross and Pavlick, 2019), psycholinguistic methods (Ettinger et al., 2018; Chrupała and Alishahi, 2019), layerwise analyses (Peters et al., 2018; Tenney et al., 2019a), among other methods (Hewitt and Manning, 2019; Zhang While deep learning has transformed the natural language processing (NLP) field and impacted the larger computational linguistics community, the rise of neural networks is stained by their opaque nature: It is challenging to int"
2020.acl-tutorials.1,D18-1151,0,0.0213835,"al aims to fill this gap and introduce the nascent field of interpretability and analysis of neural networks in NLP. The tutorial will cover the main lines of analysis work, mostly drawing on the recent TACL survey by Belinkov and Glass (2019).1 In particular, we will devote a large portion to work aiming to find linguistic information that is captured by neural networks, such as probing classifiers (Hupkes et al., 2018; Adi et al., 2017; Conneau et al., 2018a,b; Tenney et al., 2019b, inter alia), controlled behavior studies on language modelling (Gulordava et al., 2018; Linzen et al., 2016a; Marvin and Linzen, 2018) or inference tasks (Poliak et al., 2018a,b; White et al., 2017; Kim et al., 2019; McCoy et al., 2019; Ross and Pavlick, 2019), psycholinguistic methods (Ettinger et al., 2018; Chrupała and Alishahi, 2019), layerwise analyses (Peters et al., 2018; Tenney et al., 2019a), among other methods (Hewitt and Manning, 2019; Zhang While deep learning has transformed the natural language processing (NLP) field and impacted the larger computational linguistics community, the rise of neural networks is stained by their opaque nature: It is challenging to interpret the inner workings of neural network mode"
2020.acl-tutorials.1,P19-1334,1,0.821801,"s in NLP. The tutorial will cover the main lines of analysis work, mostly drawing on the recent TACL survey by Belinkov and Glass (2019).1 In particular, we will devote a large portion to work aiming to find linguistic information that is captured by neural networks, such as probing classifiers (Hupkes et al., 2018; Adi et al., 2017; Conneau et al., 2018a,b; Tenney et al., 2019b, inter alia), controlled behavior studies on language modelling (Gulordava et al., 2018; Linzen et al., 2016a; Marvin and Linzen, 2018) or inference tasks (Poliak et al., 2018a,b; White et al., 2017; Kim et al., 2019; McCoy et al., 2019; Ross and Pavlick, 2019), psycholinguistic methods (Ettinger et al., 2018; Chrupała and Alishahi, 2019), layerwise analyses (Peters et al., 2018; Tenney et al., 2019a), among other methods (Hewitt and Manning, 2019; Zhang While deep learning has transformed the natural language processing (NLP) field and impacted the larger computational linguistics community, the rise of neural networks is stained by their opaque nature: It is challenging to interpret the inner workings of neural network models, and explicate their behavior. Therefore, in the last few years, an increasingly large body of wor"
2020.acl-tutorials.1,N19-1419,0,0.0199094,"inguistic information that is captured by neural networks, such as probing classifiers (Hupkes et al., 2018; Adi et al., 2017; Conneau et al., 2018a,b; Tenney et al., 2019b, inter alia), controlled behavior studies on language modelling (Gulordava et al., 2018; Linzen et al., 2016a; Marvin and Linzen, 2018) or inference tasks (Poliak et al., 2018a,b; White et al., 2017; Kim et al., 2019; McCoy et al., 2019; Ross and Pavlick, 2019), psycholinguistic methods (Ettinger et al., 2018; Chrupała and Alishahi, 2019), layerwise analyses (Peters et al., 2018; Tenney et al., 2019a), among other methods (Hewitt and Manning, 2019; Zhang While deep learning has transformed the natural language processing (NLP) field and impacted the larger computational linguistics community, the rise of neural networks is stained by their opaque nature: It is challenging to interpret the inner workings of neural network models, and explicate their behavior. Therefore, in the last few years, an increasingly large body of work has been devoted to the analysis and interpretation of neural network models in NLP. This body of work is so far lacking a common framework and methodology. Moreover, approaching the analysis of modern neural netw"
2020.acl-tutorials.1,D17-1215,0,0.0247434,"t et al., 2018), and saliency measures (Li et al., 2016; Murdoch et al., 2018; Arras et al., 2017), including a walkthrough on how to build a simple attention visualization. Next, we will discuss the construction and use of challenge sets for fine-grained evaluation in the context of different tasks (Conneau and Kiela, 2018; Wang et al., 2018; Isabelle and Kuhn, 2018; Sennrich, 2017, inter alia). Finally, we will review work on generating adversarial examples in NLP, focusing on the challenges brought upon by the discrete nature of textual input (Papernot et al., 2016b; Ebrahimi et al., 2018; Jia and Liang, 2017; Belinkov and Bisk, 2018, inter alia). A detailed outline is provided in Section 3. Throughout the tutorial, we will highlight not only the most commonly applied analysis methods, but also the specific limitations and shortcomings of current approaches. By the end of the tutorial, participants will be better informed where to focus future research efforts. 2 5. Other Methods (a) Generating Explanations (b) Psycholinguistic Methods (c) Testing on Formal Languages 6. Conclusion 4 We would assume acquaintance with core linguistic concepts and basic knowledge of machine learning and neural networ"
2020.acl-tutorials.1,D18-1179,0,0.0175049,"rticular, we will devote a large portion to work aiming to find linguistic information that is captured by neural networks, such as probing classifiers (Hupkes et al., 2018; Adi et al., 2017; Conneau et al., 2018a,b; Tenney et al., 2019b, inter alia), controlled behavior studies on language modelling (Gulordava et al., 2018; Linzen et al., 2016a; Marvin and Linzen, 2018) or inference tasks (Poliak et al., 2018a,b; White et al., 2017; Kim et al., 2019; McCoy et al., 2019; Ross and Pavlick, 2019), psycholinguistic methods (Ettinger et al., 2018; Chrupała and Alishahi, 2019), layerwise analyses (Peters et al., 2018; Tenney et al., 2019a), among other methods (Hewitt and Manning, 2019; Zhang While deep learning has transformed the natural language processing (NLP) field and impacted the larger computational linguistics community, the rise of neural networks is stained by their opaque nature: It is challenging to interpret the inner workings of neural network models, and explicate their behavior. Therefore, in the last few years, an increasingly large body of work has been devoted to the analysis and interpretation of neural network models in NLP. This body of work is so far lacking a common framework and"
2020.acl-tutorials.1,W18-5446,0,0.0656659,"Missing"
2020.acl-tutorials.1,N18-2082,1,0.884697,"Missing"
2020.acl-tutorials.1,I17-1100,0,0.0383709,"Missing"
2020.acl-tutorials.1,W18-5441,1,0.841572,"Missing"
2020.acl-tutorials.1,W18-5448,0,0.0639211,"Missing"
2020.acl-tutorials.1,D19-1228,1,0.833586,"al will cover the main lines of analysis work, mostly drawing on the recent TACL survey by Belinkov and Glass (2019).1 In particular, we will devote a large portion to work aiming to find linguistic information that is captured by neural networks, such as probing classifiers (Hupkes et al., 2018; Adi et al., 2017; Conneau et al., 2018a,b; Tenney et al., 2019b, inter alia), controlled behavior studies on language modelling (Gulordava et al., 2018; Linzen et al., 2016a; Marvin and Linzen, 2018) or inference tasks (Poliak et al., 2018a,b; White et al., 2017; Kim et al., 2019; McCoy et al., 2019; Ross and Pavlick, 2019), psycholinguistic methods (Ettinger et al., 2018; Chrupała and Alishahi, 2019), layerwise analyses (Peters et al., 2018; Tenney et al., 2019a), among other methods (Hewitt and Manning, 2019; Zhang While deep learning has transformed the natural language processing (NLP) field and impacted the larger computational linguistics community, the rise of neural networks is stained by their opaque nature: It is challenging to interpret the inner workings of neural network models, and explicate their behavior. Therefore, in the last few years, an increasingly large body of work has been devoted to the"
2020.acl-tutorials.1,E17-2060,0,0.14015,"ties and Bowman, 2018; Shi et al., 2016). We will also present various interactive visualization methods such as neuron activations (Karpathy et al., 2015; Dalvi et al., 2019), attention mechanisms (Bahdanau et al., 2014; Strobelt et al., 2018), and saliency measures (Li et al., 2016; Murdoch et al., 2018; Arras et al., 2017), including a walkthrough on how to build a simple attention visualization. Next, we will discuss the construction and use of challenge sets for fine-grained evaluation in the context of different tasks (Conneau and Kiela, 2018; Wang et al., 2018; Isabelle and Kuhn, 2018; Sennrich, 2017, inter alia). Finally, we will review work on generating adversarial examples in NLP, focusing on the challenges brought upon by the discrete nature of textual input (Papernot et al., 2016b; Ebrahimi et al., 2018; Jia and Liang, 2017; Belinkov and Bisk, 2018, inter alia). A detailed outline is provided in Section 3. Throughout the tutorial, we will highlight not only the most commonly applied analysis methods, but also the specific limitations and shortcomings of current approaches. By the end of the tutorial, participants will be better informed where to focus future research efforts. 2 5. O"
2020.acl-tutorials.1,D16-1159,0,0.0290059,"rafted features, it is more challenging to interpret the 1 A comprehensive bibliography is found in the accompanying website of the survey: https://boknilev. github.io/nlp-analysis-methods/. 1 Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 1–5 c July 5, 2020. 2020 Association for Computational Linguistics https://doi.org/10.18653/v1/P17 (a) How Interaction can help and its limitations (b) Classification and Review of Related Efforts (c) Demo Walk-through: Simple Attention Visualization (d) Broader Perspectives and Opportunities and Bowman, 2018; Shi et al., 2016). We will also present various interactive visualization methods such as neuron activations (Karpathy et al., 2015; Dalvi et al., 2019), attention mechanisms (Bahdanau et al., 2014; Strobelt et al., 2018), and saliency measures (Li et al., 2016; Murdoch et al., 2018; Arras et al., 2017), including a walkthrough on how to build a simple attention visualization. Next, we will discuss the construction and use of challenge sets for fine-grained evaluation in the context of different tasks (Conneau and Kiela, 2018; Wang et al., 2018; Isabelle and Kuhn, 2018; Sennrich, 2017, inter alia). Finally, we"
2020.acl-tutorials.1,P19-1452,1,0.914012,"it requires both a familiarity with recent work in neural NLP and with analysis methods which are not yet standardized. This tutorial aims to fill this gap and introduce the nascent field of interpretability and analysis of neural networks in NLP. The tutorial will cover the main lines of analysis work, mostly drawing on the recent TACL survey by Belinkov and Glass (2019).1 In particular, we will devote a large portion to work aiming to find linguistic information that is captured by neural networks, such as probing classifiers (Hupkes et al., 2018; Adi et al., 2017; Conneau et al., 2018a,b; Tenney et al., 2019b, inter alia), controlled behavior studies on language modelling (Gulordava et al., 2018; Linzen et al., 2016a; Marvin and Linzen, 2018) or inference tasks (Poliak et al., 2018a,b; White et al., 2017; Kim et al., 2019; McCoy et al., 2019; Ross and Pavlick, 2019), psycholinguistic methods (Ettinger et al., 2018; Chrupała and Alishahi, 2019), layerwise analyses (Peters et al., 2018; Tenney et al., 2019a), among other methods (Hewitt and Manning, 2019; Zhang While deep learning has transformed the natural language processing (NLP) field and impacted the larger computational linguistics community"
2020.cl-1.1,D18-1313,0,0.0552683,"This implies that a higher BLEU score does not necessarily entail better morphological representations. In other words, a better translation model learns more informative representations, but only when it is actually learning to translate rather than merely memorizing the data as in the autoencoder case. We found these results to be consistent in other language pairs, that is, by changing the source from Arabic to German and Czech and also using character models instead of words (see Section A.2 in the Appendix for more details); however, more through study is required along this direction as Bisazza and Tump (2018) performed a similar experiment on a fine-grained tag level and found contrastive results. 7. Syntax Results To evaluate the NMT representations from a syntactic perspective, we consider two tasks. First, we made use of CCG supertagging, which is assumed to capture syntax at the word level. Second, we used dependency relations between any two words in the sentence for which a dependency edge exists, to investigate how words compose. Specifically, we ask the following questions: (i) Do NMT models acquire structural information while they are being trained on flat sequences of bilingual sentence"
2020.cl-1.1,C16-1333,0,0.0606149,"Missing"
2020.cl-1.1,W16-2308,0,0.232083,"hoices and performance. In current practice, their development is often limited to a trial-and-error process, without gaining a real understanding of what the system has learned. We aim to increase model transparency by analyzing the representations learned by NMT models at different levels of granularity in light of various linguistic phenomena—at morphological, syntactic, and semantic levels—that are considered important for the task of machine translation and for learning complex natural language processing (NLP) problems. We thus strive for post-hoc decomposability, in the sense of Lipton (2016). That is, we analyze models after they have been trained, to uncover what linguistic phenomena are captured within the underlying representations. More specifically, we aim to address the following questions in this article: • What linguistic information is captured in deep learning models? – – – Do the NMT representations capture word morphology? Do the NMT models, being trained on flat sequences of words, still acquire structural information? Do the NMT models learn informative semantic representations? • Is the language information well distributed across the network or are designated part"
2020.cl-1.1,W17-4705,0,0.0190207,"line of work visualizes hidden unit activations in recurrent neural networks (RNNs) that are trained for a given task (Elman 1991; Karpathy, Johnson, and Li 2015; K´ad´ar, Chrupała, and Alishahi 2017). Although such visualizations illuminate the inner workings of the network, they are often qualitative in nature and somewhat anecdotal. Other work aims to evaluate systems on specific linguistic phenomena represented in so-called challenge sets. Prominent examples include older work on MT evaluation (King and Falkedal 1990), as well as more recent evaluations via contrastive translation pairs (Burlot and Yvon 2017; Rios Gonzales, Mascarell, and 1 The learned parameters are implicitly shared by all the language pairs being modeled. 4 Belinkov, Durrani et al. Linguistic Representations in NMT Sennrich 2017; Sennrich 2017; Bawden et al. 2018). The latter line of work constructs minimal pairs of translations that differ by a known linguistic property, and evaluates whether the MT system assigns a higher score to the correct translation. The challenge set evaluation may produce informative results on the quality of the overall model for some linguistic property, but it does not directly assess the learned r"
2020.cl-1.1,P18-1008,0,0.025914,"on recurrent LSTM encoderdecoder models with attention. Although this is the first successful NMT architecture, and still a dominant one, it is certainly not the only one. Other sucessful architectures include fully convolutional (Gehring et al. 2017) and fully attentional, transformer encoder-decoder models (Vaswani et al. 2017). There are also non-autoregressive models, which are promising in terms of efficiency (Gu et al. 2018). At present, NMT systems based on transformer components appear to be the most successful. Combinations of transformer and recurrent components may also be helpful (Chen et al. 2018). The generalization of the particular results in this work to other architectures is a question of study. Recent efforts to analyze transformer-based NMT models include attempts to extract syntactic trees from self-attention weights (Mareˇcek and Rosa 2018; Raganato and Tiedemann 2018) and evaluating representations from the transformer encoder (Raganato and Tiedemann 2018). The latter found that lower layers tend to focus on POS and shallow syntax, whereas higher layers are more focused on semantic tagging. These results are in line with our findings. However, more work is needed to understa"
2020.cl-1.1,P05-1033,0,0.303982,"or Professor admit@@ s to shoot@@ ing his girl@@ friend Characters Professor admits to shooting his girlfriend 7 Computational Linguistics Volume 46, Number 1 3.2 Syntax Linguistic theories argue that words are hierarchically organized in syntactic constituents referred to as syntactic trees. It is therefore natural to think that translation models should be based on trees rather than a flat sequence representation of sentences. For more than a decade of research in machine translation, a tremendous amount of effort has been put into syntax-based machine translation (Yamada and Knight (2002); Chiang (2005), Galley et al. (2006), Zhang et al. (2007), Shen, Xu, and Weischedel (2010); Neubig and Duh (2014)), with notable success in languages such as Chinese and German, which are syntactically divergent compared to English. However, the sequence-to-sequence NMT systems were able to surpass the performance of the stateof-the-art syntax-based systems in recent MT competitions (Bojar et al. 2016). The LSTM-based RNN model with the help of the attention mechanism is able to handle long-distance dependencies. There have also been recent attempts to integrate syntax into NMT (Eriguchi, Hashimoto, and Tsu"
2020.cl-1.1,N09-1025,0,0.0771531,"Missing"
2020.cl-1.1,P16-1160,0,0.073408,"Missing"
2020.cl-1.1,C04-1041,0,0.0678557,"l. 2016). Third, as dependencies are bi-lexical relations between words, it is straightforward to obtain representations for them from an NMT model. This makes them amenable to the general methodology followed in this paper. Figure 1a shows an example sentence with syntactic dependencies. 3.3 Semantics The holy grail in MT has long been to achieve an interlingua-based translation model, where the goal is to capture the meaning of the source sentence and generate a target sentence with the same meaning. It has been believed since the inception of MT 3 Refer to Steedman and Baldridge (2011) and Clark and Curran (2004) for more information on CCG supertagging. 8 Belinkov, Durrani et al. Linguistic Representations in NMT Figure 1 Example sentence with syntactic and semantic relations. (a) Syntactic relations according to the Universal Dependencies formalism. Here “Obama” and “ Netanyahu” are the subject and object of “receives”, respectively, obl refers to an oblique relation of the locative modifier, nmod denotes the genitive relation, the prepositions “in” and “of” are treated as case-marking elements, and “the” is a determiner. See https://universaldependencies.org/guidelines.html for detailed definitions"
2020.cl-1.1,P18-1198,0,0.0310848,"oduce informative results on the quality of the overall model for some linguistic property, but it does not directly assess the learned representations. A different approach tries to provide a quantitative analysis by correlating parts of the neural network with linguistic properties, for example, by training a classifier to predict a feature of interest (Adi et al. 2017; Hupkes, Veldhoen, and Zuidema 2017; Conneau ¨ et al. 2018). Such an analysis has been conducted on word embeddings (Kohn 2015; Qian, Qiu, and Huang 2016b), sentence embeddings (Adi et al. 2017; Ganesh, Gupta, and Varma 2017; Conneau et al. 2018), and RNN states (Qian, Qiu, and Huang 2016a; Wu and King 2016; Wang, Chung, and Lee 2017). The language properties mainly analyzed are morphological (Qian, Qiu, and Huang 2016b; Vylomova et al. 2016; Belinkov et al. 2017a; Dalvi et al. 2017), semantic (Qian, Qiu, and Huang 2016b; Belinkov et al. 2017b), ¨ and syntactic (Tran, Bisazza, and Monz 2018; Kohn 2015; Conneau et al. 2018). Recent studies carried a more fine-grained neuron-level analysis for NMT and LM (Bau et al. 2019a; Dalvi et al. 2019a; Lakretz et al. 2019). In contrast to all of this work, we focus on the representations learned"
2020.cl-1.1,P16-2058,0,0.310821,"and Glass (2019) for a recent survey on the topic. 2.2 Subword Units One of the major challenges in training NMT systems is handling less frequent and out-of-vocabulary words. To address this issue, researchers have resorted to using subword units for training the neural network models. Luong and Manning (2016) trained a hybrid system that integrates character-level representation within a wordbased framework. Ling et al. (2015) used a bidirectional long short-term memory network (LSTM; Hochreiter and Schmidhuber 1997) to compose word embeddings from the character embeddings. Costa-juss`a and Fonollosa (2016) and Renduchintala et al. (2018) combined convolutional and highway layers to replace the standard lookupbased word representations in NMT systems with character-aware representations.2 Sennrich, Haddow, and Birch (2016) used byte-pair encoding (BPE), a data-compression algorithm, to segment words into smaller units. A variant of this method known as a wordpiece model is used by Google (Wu et al. 2016a). Shapiro and Duh (2018) used a similar convolutional architecture on top of BPE. Chung, Cho, and Bengio (2016) used a combination of BPE-based encoder and character-based decoder to improve 2 C"
2020.cl-1.1,I17-1015,1,0.836995,"eural network with linguistic properties, for example, by training a classifier to predict a feature of interest (Adi et al. 2017; Hupkes, Veldhoen, and Zuidema 2017; Conneau ¨ et al. 2018). Such an analysis has been conducted on word embeddings (Kohn 2015; Qian, Qiu, and Huang 2016b), sentence embeddings (Adi et al. 2017; Ganesh, Gupta, and Varma 2017; Conneau et al. 2018), and RNN states (Qian, Qiu, and Huang 2016a; Wu and King 2016; Wang, Chung, and Lee 2017). The language properties mainly analyzed are morphological (Qian, Qiu, and Huang 2016b; Vylomova et al. 2016; Belinkov et al. 2017a; Dalvi et al. 2017), semantic (Qian, Qiu, and Huang 2016b; Belinkov et al. 2017b), ¨ and syntactic (Tran, Bisazza, and Monz 2018; Kohn 2015; Conneau et al. 2018). Recent studies carried a more fine-grained neuron-level analysis for NMT and LM (Bau et al. 2019a; Dalvi et al. 2019a; Lakretz et al. 2019). In contrast to all of this work, we focus on the representations learned in neural machine translation in light of various linguistic properties (morphological, syntactic, and semantic) and phenomena such as handling low frequency words. Our work is most similar to Shi, Padhi, and Knight (2016) and Vylomova et al."
2020.cl-1.1,N19-1423,0,0.0237899,"he NMT encoder or decoder. We have already mentioned one work exploiting this idea, known as CoVE (McCann et al. 2017), which used NMT representations as features in other models to perform various NLP tasks. Other prominent contextualizers include ELMo (Peters et al. 2018a), which trains two separate, forward and backward LSTM language models (with a character CNN building block) and concatenates their representations across several layers; GPT (Radford et al. 2018) and GPT-2 (Radford et al. 2019), which use transformer language models based on self-attention (Vaswani et al. 2017); and BERT (Devlin et al. 2019), which uses a bidirectional transformer model trained on masked language modeling (filling the blanks). All these generate representations that feed into task-specific classifiers, potentially with fine-tuning the contextualizer weights.21 21 See Peters, Ruder, and Smith (2019) for an evaluation of when it is worthwhile to fine-tune. 38 Belinkov, Durrani et al. Linguistic Representations in NMT How do NMT representations compare with CWRs trained from raw text? Directly answering this question is beyond the scope of this work, and is also tricky to perform for two reasons. First, CWRs like EL"
2020.cl-1.1,P10-1048,1,0.738996,"representations.2 Sennrich, Haddow, and Birch (2016) used byte-pair encoding (BPE), a data-compression algorithm, to segment words into smaller units. A variant of this method known as a wordpiece model is used by Google (Wu et al. 2016a). Shapiro and Duh (2018) used a similar convolutional architecture on top of BPE. Chung, Cho, and Bengio (2016) used a combination of BPE-based encoder and character-based decoder to improve 2 Character-based systems have been used previously in phrase-based MT for handling morphologically rich (Luong, Nakov, and Kan 2010) and closely related language pairs (Durrani et al. 2010; Nakov and Tiedemann 2012) or for transliterating unknown words (Durrani et al. 2014). 5 Computational Linguistics Volume 46, Number 1 translation quality. Motivated by their findings, Lee, Cho, and Hofmann (2017) explored using fully character representations (with no word boundaries) on both the source and target sides. As BPE segmentation is not linguistically motivated, an alternative to using morpheme-based segmentation has been explored in Bradbury and Socher (2016). It is important to address what using different translation units (word, BPE, morpheme, character) entails. Sennrich (201"
2020.cl-1.1,E14-4029,1,0.825501,"a data-compression algorithm, to segment words into smaller units. A variant of this method known as a wordpiece model is used by Google (Wu et al. 2016a). Shapiro and Duh (2018) used a similar convolutional architecture on top of BPE. Chung, Cho, and Bengio (2016) used a combination of BPE-based encoder and character-based decoder to improve 2 Character-based systems have been used previously in phrase-based MT for handling morphologically rich (Luong, Nakov, and Kan 2010) and closely related language pairs (Durrani et al. 2010; Nakov and Tiedemann 2012) or for transliterating unknown words (Durrani et al. 2014). 5 Computational Linguistics Volume 46, Number 1 translation quality. Motivated by their findings, Lee, Cho, and Hofmann (2017) explored using fully character representations (with no word boundaries) on both the source and target sides. As BPE segmentation is not linguistically motivated, an alternative to using morpheme-based segmentation has been explored in Bradbury and Socher (2016). It is important to address what using different translation units (word, BPE, morpheme, character) entails. Sennrich (2017) performed a comparative evaluation of character- and BPE-based systems on carefully"
2020.cl-1.1,P11-1105,1,0.842798,"Missing"
2020.cl-1.1,P16-1078,0,0.0616503,"Missing"
2020.cl-1.1,P06-1121,0,0.0689132,"mit@@ s to shoot@@ ing his girl@@ friend Characters Professor admits to shooting his girlfriend 7 Computational Linguistics Volume 46, Number 1 3.2 Syntax Linguistic theories argue that words are hierarchically organized in syntactic constituents referred to as syntactic trees. It is therefore natural to think that translation models should be based on trees rather than a flat sequence representation of sentences. For more than a decade of research in machine translation, a tremendous amount of effort has been put into syntax-based machine translation (Yamada and Knight (2002); Chiang (2005), Galley et al. (2006), Zhang et al. (2007), Shen, Xu, and Weischedel (2010); Neubig and Duh (2014)), with notable success in languages such as Chinese and German, which are syntactically divergent compared to English. However, the sequence-to-sequence NMT systems were able to surpass the performance of the stateof-the-art syntax-based systems in recent MT competitions (Bojar et al. 2016). The LSTM-based RNN model with the help of the attention mechanism is able to handle long-distance dependencies. There have also been recent attempts to integrate syntax into NMT (Eriguchi, Hashimoto, and Tsuruoka 2016; Stahlberg"
2020.cl-1.1,D08-1089,0,0.0710678,"rtificial intelligence, including machine translation (MT). Compared with their traditional counterparts, these models are trained in an end-to-end fashion, providing a simple yet elegant mechanism. This simplicity, however, comes at the price of opaqueness. Unlike traditional systems that contain specialized modules carrying specific sub-tasks, neural MT (NMT) systems train one large network, optimized toward the overall task. For example, non-neural statistical MT systems have sub-components to handle fluency (Heafield 2011), lexical generation (Koehn, Och, and Marcu 2003), word reordering (Galley and Manning 2008; Durrani, Schmid, and Fraser 2011), rich morphology (Koehn and Hoang 2007), and a smorgasbord of features (Chiang, Knight, and Wang 2009) for modeling different phenomena. Neural MT systems, on the other hand, contain a single model based on an encoder-decoder mechanism (Sutskever, Vinyals, and Le 2014) with attention (Bahdanau, Cho, and Bengio 2014). Despite its simplicity, neural MT surpassed non-neural statistical MT within a few years of its emergence. Human evaluation and error analysis revealed that the improvements were obtained through more fluent outputs (Toral and S´anchez-Cartagena"
2020.cl-1.1,W11-2123,0,0.0433646,"ep neural networks have quickly become the predominant approach to most tasks in artificial intelligence, including machine translation (MT). Compared with their traditional counterparts, these models are trained in an end-to-end fashion, providing a simple yet elegant mechanism. This simplicity, however, comes at the price of opaqueness. Unlike traditional systems that contain specialized modules carrying specific sub-tasks, neural MT (NMT) systems train one large network, optimized toward the overall task. For example, non-neural statistical MT systems have sub-components to handle fluency (Heafield 2011), lexical generation (Koehn, Och, and Marcu 2003), word reordering (Galley and Manning 2008; Durrani, Schmid, and Fraser 2011), rich morphology (Koehn and Hoang 2007), and a smorgasbord of features (Chiang, Knight, and Wang 2009) for modeling different phenomena. Neural MT systems, on the other hand, contain a single model based on an encoder-decoder mechanism (Sutskever, Vinyals, and Le 2014) with attention (Bahdanau, Cho, and Bengio 2014). Despite its simplicity, neural MT surpassed non-neural statistical MT within a few years of its emergence. Human evaluation and error analysis revealed th"
2020.cl-1.1,P06-1064,0,0.0106613,"ifferent NLP tasks. Table 4 details the number of tags (or labels) in each task across different languages. 6. Morphology Results In this section, we investigate what kind of morphological information is captured within NMT models, using the tasks of POS and morphological tagging. To probe this, we annotated a subset of the training data (see Table 3) using POS or morphological 11 http://www.ims.uni-stuttgart.de/forschung/ressourcen/korpora/tiger.html. 12 There are no available CCG banks for the other languages we experiment with, except for a German CCG bank, which is not publicly available (Hockenmaier 2006). 13 The main differences between PSD and the original tectogrammatical annotation are the omission of elided elements, such that all nodes are surface tokens; the inclusion of functional and punctuation tokens; ignoring most cases of function word attachments to content words; ignoring coreference links; and ignoring grammatemes (tectogrammatical correlates of morphological categories). As a side effect, these simplifications make it straightforward to generate representations for surface tokens participating in dependency relations under the PSD formalism. See http://sdp.delph-in.net for mor"
2020.cl-1.1,J07-3004,0,0.0101183,"3 – – – – – – – – 14,006 5,640 14,006 5,640 – – – – – – – – German, Spanish, and Czech) we used RDRPOST (Nguyen et al. 2014), a state-of-the-art morphological tagger. For experiments using gold tags, we used the Arabic Treebank for Arabic (with the versions and splits described in the MADAMIRA manual) and the Tiger corpus for German.11 For semantic tagging, we used the semantic tags from the Groningen Parallel Meaning Bank (Abzianidze et al. 2017). For syntactic relation labeling we used the Universal Dependencies data set (Nivre et al. 2017). For CCG supertagging we used the English CCGBank (Hockenmaier and Steedman 2007).12 For semantic dependency labeling we used PSD, which is a reduction of the tectogrammatical analysis layer of the Prague Czech–English Dependency Treebank, and is made available as part of the Semantic Dependency Parsing data set (Oepen et al. 2014, 2015). Most of the PSD dependency labels mark semantic roles of arguments, which are called functors in the Prague dependency treebank.13 PSD annotations are available in English and Czech. Table 3 provides the amount of data used to train the MT classifiers for different NLP tasks. Table 4 details the number of tags (or labels) in each task acr"
2020.cl-1.1,E17-2059,0,0.0241302,"bit grammatical relations such as subject/object/predicate or gender agreement by only changing the word form, whereas others achieve the same through word order or addition of particles. Morphology (aka word structure), poses an exigent problem in machine translation and is at the heart of dealing with the challenge of data-sparsity. Although English is limited in morphology, other languages such as Czech, Arabic, and Russian have highly inflected morphology. This entails that for each lemma many possible word variants could exist, thus causing an out-of-vocabulary word problem. For example, Huck et al. (2017) found only one morphological variant of the Czech word “ˇce¨ s˘ ka” (plural of English “kneecap”) in a corpus of 50K parallel sentences. It required 50M sentences, a size of parallel corpus Table 1 Example sentence with different word-level annotations. The CCG supertags are taken from Nadejde et al. (2017). POS and semantic tags are our own annotation, as well as the German translation and its morphological tags. Words Obama receives Netanyahu in the capital of USA POS SEM CCG NP PER NP VBZ ENS ((S[dcl]NP) /PP)/NP NP PER NP IN REL PP/NP DT DEF NP/N NN REL N IN REL (NPNP) /NP NP GEO NP Word"
2020.cl-1.1,Q17-1024,0,0.0766313,"Missing"
2020.cl-1.1,C12-1083,0,0.0202664,"definitions. (b) Semantic relations according to the PSD formalism. Here ACT-arg and PAT-arg refer respectively to the originator and affected arguments of “receives”, LOC in the location, and APP is the thing that “capital” belongs to. For detailed definitions, see Cinkov´a et al. (2004). that without acquiring such meaning representations it will be impossible to generate human-like translations (Weaver 1955). Traditional statistical MT systems are weak at capturing meaning representations (e.g., “who does what to whom—namely, what are the agent, the action, and the patient in the sentence [Jones et al. 2012]). Although neural MT systems are also trained only on parallel data, without providing any direct supervision of word meaning, they are a continuous space model, and are believed to capture word meaning. Johnson et al. (2017), for example, found preliminary evidence that the shared architecture in their multilingual NMT systems learns a universal interlingua. There have also been some recent efforts to incorporate such information in NMT systems, either explicitly (Rios Gonzales, Mascarell, and Sennrich 2017) or implicitly (Liu, Lu, and Neubig 2018). Tagging task. In this article, we study h"
2020.cl-1.1,C90-2037,0,0.773283,"Missing"
2020.cl-1.1,D07-1091,0,0.249735,"Missing"
2020.cl-1.1,N03-1017,0,0.176326,"Missing"
2020.cl-1.1,2006.iwslt-evaluation.11,0,0.156188,"Missing"
2020.cl-1.1,N19-1002,0,0.0298792,"16b), sentence embeddings (Adi et al. 2017; Ganesh, Gupta, and Varma 2017; Conneau et al. 2018), and RNN states (Qian, Qiu, and Huang 2016a; Wu and King 2016; Wang, Chung, and Lee 2017). The language properties mainly analyzed are morphological (Qian, Qiu, and Huang 2016b; Vylomova et al. 2016; Belinkov et al. 2017a; Dalvi et al. 2017), semantic (Qian, Qiu, and Huang 2016b; Belinkov et al. 2017b), ¨ and syntactic (Tran, Bisazza, and Monz 2018; Kohn 2015; Conneau et al. 2018). Recent studies carried a more fine-grained neuron-level analysis for NMT and LM (Bau et al. 2019a; Dalvi et al. 2019a; Lakretz et al. 2019). In contrast to all of this work, we focus on the representations learned in neural machine translation in light of various linguistic properties (morphological, syntactic, and semantic) and phenomena such as handling low frequency words. Our work is most similar to Shi, Padhi, and Knight (2016) and Vylomova et al. (2016). The former used hidden vectors from a neural MT encoder to predict syntactic properties on the English source side, whereas we study multiple language properties in different languages. Vylomova et al. (2016) analyzed different representations for morphologically rich langu"
2020.cl-1.1,Q17-1026,0,0.0448226,"Missing"
2020.cl-1.1,N13-1060,0,0.0603544,"Missing"
2020.cl-1.1,N18-1121,0,0.0457537,"Missing"
2020.cl-1.1,N19-1112,1,0.910624,"Missing"
2020.cl-1.1,P16-1100,0,0.0292588,"for morphologically rich languages in MT, but they did not directly measure the quality of the learned representations. Surveying the work on analyzing neural networks in NLP is beyond the scope of the present paper. We have highlighted here several of the more relevant studies and refer to Belinkov and Glass (2019) for a recent survey on the topic. 2.2 Subword Units One of the major challenges in training NMT systems is handling less frequent and out-of-vocabulary words. To address this issue, researchers have resorted to using subword units for training the neural network models. Luong and Manning (2016) trained a hybrid system that integrates character-level representation within a wordbased framework. Ling et al. (2015) used a bidirectional long short-term memory network (LSTM; Hochreiter and Schmidhuber 1997) to compose word embeddings from the character embeddings. Costa-juss`a and Fonollosa (2016) and Renduchintala et al. (2018) combined convolutional and highway layers to replace the standard lookupbased word representations in NMT systems with character-aware representations.2 Sennrich, Haddow, and Birch (2016) used byte-pair encoding (BPE), a data-compression algorithm, to segment wor"
2020.cl-1.1,D10-1015,0,0.0774087,"Missing"
2020.cl-1.1,W18-5444,0,0.0348371,"Missing"
2020.cl-1.1,W06-2932,0,0.0276513,"Missing"
2020.cl-1.1,J11-1007,0,0.0157602,"), French (fr), German (de), Czech (cs), Arabic (ar), Russian (ru), and Hebrew (he). We trained NMT systems using data made available by the two popular machine translation campaigns, namely, WMT (Bojar et al. 2017) and IWSLT (Cettolo et al. 2016). The MT models were trained using a concatenation of NEWS, TED, and Europarl training data (≈ 2.5M sentence pairs). The multilingual systems were trained by simply concatenating data from different 5 It is also not unrealistic, as dependency parsers often work in two stages, first predicting an unlabeled dependency tree, and then labeling its edges (McDonald and Nivre 2011; McDonald, Lerman, and Pereira 2006). More complicated formulations can be conceived, from predicting the existence of dependencies independently to solving the full parsing task, but dependency labeling is a simple basic task to begin with. 6 Although we studied representations from a charCNN (Kim et al. 2015) in Belinkov et al. (2017a), the extracted features were still based on word representations produced by the charCNN. As a result, in that work we could not analyze and compare subword and character-based models that do not assume a segmentation into words. 7 One could envision more sop"
2020.cl-1.1,P12-2059,0,0.0181017,"ddow, and Birch (2016) used byte-pair encoding (BPE), a data-compression algorithm, to segment words into smaller units. A variant of this method known as a wordpiece model is used by Google (Wu et al. 2016a). Shapiro and Duh (2018) used a similar convolutional architecture on top of BPE. Chung, Cho, and Bengio (2016) used a combination of BPE-based encoder and character-based decoder to improve 2 Character-based systems have been used previously in phrase-based MT for handling morphologically rich (Luong, Nakov, and Kan 2010) and closely related language pairs (Durrani et al. 2010; Nakov and Tiedemann 2012) or for transliterating unknown words (Durrani et al. 2014). 5 Computational Linguistics Volume 46, Number 1 translation quality. Motivated by their findings, Lee, Cho, and Hofmann (2017) explored using fully character representations (with no word boundaries) on both the source and target sides. As BPE segmentation is not linguistically motivated, an alternative to using morpheme-based segmentation has been explored in Bradbury and Socher (2016). It is important to address what using different translation units (word, BPE, morpheme, character) entails. Sennrich (2017) performed a comparative"
2020.cl-1.1,P14-2024,0,0.0151066,"ting his girlfriend 7 Computational Linguistics Volume 46, Number 1 3.2 Syntax Linguistic theories argue that words are hierarchically organized in syntactic constituents referred to as syntactic trees. It is therefore natural to think that translation models should be based on trees rather than a flat sequence representation of sentences. For more than a decade of research in machine translation, a tremendous amount of effort has been put into syntax-based machine translation (Yamada and Knight (2002); Chiang (2005), Galley et al. (2006), Zhang et al. (2007), Shen, Xu, and Weischedel (2010); Neubig and Duh (2014)), with notable success in languages such as Chinese and German, which are syntactically divergent compared to English. However, the sequence-to-sequence NMT systems were able to surpass the performance of the stateof-the-art syntax-based systems in recent MT competitions (Bojar et al. 2016). The LSTM-based RNN model with the help of the attention mechanism is able to handle long-distance dependencies. There have also been recent attempts to integrate syntax into NMT (Eriguchi, Hashimoto, and Tsuruoka 2016; Stahlberg et al. 2016; Aharoni and Goldberg 2017; Chen et al. 2017; Wu et al. 2017), bu"
2020.cl-1.1,E14-2005,0,0.0130295,"and gold annotations for syntactic and semantics tasks. POS tags Morph tags CCG tags Syntactic dependency Semantic tags Semantic dependency Train Test Train Test Train Test Train Test Train Test Train Test de en cs ru fr es 14,498 8,172 14,498 8,172 – – 14,118 1,776 1,490 373 – – 14,498 8,172 14,498 8,172 41,586 2,407 12,467 4,049 14,084 12,168 12,000 9,692 14,498 8,172 14,498 8,172 – – 14,553 1,894 – – 11,999 10,010 11,824 5,999 11,824 5,999 – – 3,848 1,180 – – – – 11,495 3,003 11,495 3,003 – – – – – – – – 14,006 5,640 14,006 5,640 – – – – – – – – German, Spanish, and Czech) we used RDRPOST (Nguyen et al. 2014), a state-of-the-art morphological tagger. For experiments using gold tags, we used the Arabic Treebank for Arabic (with the versions and splits described in the MADAMIRA manual) and the Tiger corpus for German.11 For semantic tagging, we used the semantic tags from the Groningen Parallel Meaning Bank (Abzianidze et al. 2017). For syntactic relation labeling we used the Universal Dependencies data set (Nivre et al. 2017). For CCG supertagging we used the English CCGBank (Hockenmaier and Steedman 2007).12 For semantic dependency labeling we used PSD, which is a reduction of the tectogrammatical"
2020.cl-1.1,S15-2153,0,0.10891,"Missing"
2020.cl-1.1,S14-2008,0,0.146289,"can be noticed by the different graph structure (compare Figure 1b to Figure 1a). Predicate–argument relations have also been used in many (non-neural) MT systems (Komachi, Matsumoto, and Nagata 2006; Wu et al. 2011; Xiong, Zhang, and Li 2012; Li, Resnik, and Daum´e III 2013). Figure 1b shows an example sentence annotated with Prague Semantic Dependencies (PSD), a reduction of the tectogrammatical annotation in the Prague Czech–English Dependency Treebank (Cinkov´a et al. 2004; Cinkov´a et al. 2009), which was made available as part of the Semantic Dependency Parsing shared tasks in SemEval (Oepen et al. 2014, 2015). 4. Methodology We follow a 3-step process for studying linguistic information learned by the trained neural MT systems. The steps include: (i) training a neural MT system; (ii) using the trained model to generate feature representations for words in a language of interest; and (iii) training a classifier using generated features to make predictions for the different linguistic tagging tasks. The quality of the trained classifier on the given task serves as a proxy to the quality of the generated representations. It thus provides a quantitative measure of how well the original MT syste"
2020.cl-1.1,P02-1040,0,0.109365,"s from the forward and backward layers are concatenated. For the average method, all of the hidden states corresponding to subwords or characters of a given word are averaged together for each layer. For the last method, only the hidden state of the final subword or character is considered. language pairs (a total of ≈10M sentence pairs) and training a shared encoder-decoder pipeline. We used German, French, Spanish, and Czech to/from English to train multilingual systems. Language codes were added as prefixes before each sentence. We used official TED test sets to report translation quality (Papineni et al. 2002). We also used the fully aligned United Nations corpus (Ziemski, Junczys-Dowmunt, and Pouliquen 2016) for training the models in some of our experiments. It includes six languages: Arabic, Chinese, English, French, Spanish, and Russian. This data set has the benefit of multiple alignment of the several languages, which allows for comparable cross-linguistic analysis, for example, studying the effect of only changing the target language. We used the first 2 million sentences of the training set, using the official training/development/test split. 5.2 Neural MT Systems 5.2.1 Preprocessing. We us"
2020.cl-1.1,pasha-etal-2014-madamira,0,0.0332275,"Missing"
2020.cl-1.1,W19-4302,0,0.0794676,"Missing"
2020.cl-1.1,N18-1202,0,0.378949,"not all information may be extracted by a simple classifier), as the task-specific encoder-decoder performs better than a classifier trained on its representations. 10.2 Contextualized Word Representations The representations generated by NMT models may be thought of as contextualized word representations (CWRs), as they capture context via the NMT encoder or decoder. We have already mentioned one work exploiting this idea, known as CoVE (McCann et al. 2017), which used NMT representations as features in other models to perform various NLP tasks. Other prominent contextualizers include ELMo (Peters et al. 2018a), which trains two separate, forward and backward LSTM language models (with a character CNN building block) and concatenates their representations across several layers; GPT (Radford et al. 2018) and GPT-2 (Radford et al. 2019), which use transformer language models based on self-attention (Vaswani et al. 2017); and BERT (Devlin et al. 2019), which uses a bidirectional transformer model trained on masked language modeling (filling the blanks). All these generate representations that feed into task-specific classifiers, potentially with fine-tuning the contextualizer weights.21 21 See Peters"
2020.cl-1.1,D18-1179,0,0.0981855,"not all information may be extracted by a simple classifier), as the task-specific encoder-decoder performs better than a classifier trained on its representations. 10.2 Contextualized Word Representations The representations generated by NMT models may be thought of as contextualized word representations (CWRs), as they capture context via the NMT encoder or decoder. We have already mentioned one work exploiting this idea, known as CoVE (McCann et al. 2017), which used NMT representations as features in other models to perform various NLP tasks. Other prominent contextualizers include ELMo (Peters et al. 2018a), which trains two separate, forward and backward LSTM language models (with a character CNN building block) and concatenates their representations across several layers; GPT (Radford et al. 2018) and GPT-2 (Radford et al. 2019), which use transformer language models based on self-attention (Vaswani et al. 2017); and BERT (Devlin et al. 2019), which uses a bidirectional transformer model trained on masked language modeling (filling the blanks). All these generate representations that feed into task-specific classifiers, potentially with fine-tuning the contextualizer weights.21 21 See Peters"
2020.cl-1.1,W17-4737,0,0.1378,"t al. 2016a). Shapiro and Duh (2018) used a similar convolutional architecture on top of BPE. Chung, Cho, and Bengio (2016) used a combination of BPE-based encoder and character-based decoder to improve 2 Character-based systems have been used previously in phrase-based MT for handling morphologically rich (Luong, Nakov, and Kan 2010) and closely related language pairs (Durrani et al. 2010; Nakov and Tiedemann 2012) or for transliterating unknown words (Durrani et al. 2014). 5 Computational Linguistics Volume 46, Number 1 translation quality. Motivated by their findings, Lee, Cho, and Hofmann (2017) explored using fully character representations (with no word boundaries) on both the source and target sides. As BPE segmentation is not linguistically motivated, an alternative to using morpheme-based segmentation has been explored in Bradbury and Socher (2016). It is important to address what using different translation units (word, BPE, morpheme, character) entails. Sennrich (2017) performed a comparative evaluation of character- and BPE-based systems on carefully crafted synthetic tests and found that character-based models are effective in handling unknown words, but perform worse in cap"
2020.cl-1.1,D16-1079,0,0.12019,"Missing"
2020.cl-1.1,P16-1140,0,0.0902583,"Missing"
2020.cl-1.1,W18-5431,0,0.0485817,"Missing"
2020.cl-1.1,J82-2005,0,0.696897,"Missing"
2020.cl-1.1,W17-4702,0,0.0581143,"Missing"
2020.cl-1.1,C94-1027,0,0.359968,"k. 5.4 Supervised Data and Annotations We make use of gold-standard annotations wherever available, but in some cases we have to rely on using automatic taggers to obtain the annotations. In particular, to analyze the representations on the decoder side, we require parallel sentences.10 It is difficult to obtain gold-standard data with parallel sentences, so we rely on automatic annotation tools. An advantage of using automatic annotations, though, is that we can reduce the effect of domain mismatch and high out-of-vocabulary (OOV) rate in analyzing these representations. We used Tree-Tagger (Schmid 1994) for annotating Russian and the MADAMIRA tagger (Pasha et al. 2014) for annotating Arabic. For the remaining languages (French, 9 The sentence length was varied across different configurations, to keep the training data sizes the same for all systems. 10 We need source sentences to generate encoder states, which in turn are required for obtaining the decoder states that we want to analyze. 14 Belinkov, Durrani et al. Linguistic Representations in NMT Table 3 Train and test data (number of sentences) used to train MT classifiers to predict different tasks. We used automated tools to annotate da"
2020.cl-1.1,E17-2060,0,0.270394,". Although such visualizations illuminate the inner workings of the network, they are often qualitative in nature and somewhat anecdotal. Other work aims to evaluate systems on specific linguistic phenomena represented in so-called challenge sets. Prominent examples include older work on MT evaluation (King and Falkedal 1990), as well as more recent evaluations via contrastive translation pairs (Burlot and Yvon 2017; Rios Gonzales, Mascarell, and 1 The learned parameters are implicitly shared by all the language pairs being modeled. 4 Belinkov, Durrani et al. Linguistic Representations in NMT Sennrich 2017; Sennrich 2017; Bawden et al. 2018). The latter line of work constructs minimal pairs of translations that differ by a known linguistic property, and evaluates whether the MT system assigns a higher score to the correct translation. The challenge set evaluation may produce informative results on the quality of the overall model for some linguistic property, but it does not directly assess the learned representations. A different approach tries to provide a quantitative analysis by correlating parts of the neural network with linguistic properties, for example, by training a classifier to pred"
2020.cl-1.1,W17-4739,0,0.137065,"lly rich languages into constituents in a preprocessing step, using word segmentation in Arabic (Pasha et al. 2014; Abdelali et al. 2016) or compound splitting in German (Koehn and Knight 2003). Previous work also explored generative morphological models, known as Factored Translation Models, that explicitly integrate additional linguistic markup at the word level to learn morphology (Koehn and Hoang 2007). In NMT training, using subword units such as byte-pair encoding (Sennrich, Haddow, and Birch 2016) has become a de facto standard in training competition grade systems (Pinnis et al. 2017; Sennrich et al. 2017). A few have tried morpheme-based segmentation (Bradbury and Socher 2016), and several even used character-based systems (Chung, Cho, and Bengio 2016; Lee, Cho, and Hofmann 2017) to achieve similar performance as the BPE-segmented systems. Table 2 shows an example of each representation unit. BPE splits words into symbols (a symbol is a sequence of characters) and then iteratively replaces the most frequent sequences of symbols with a new merged symbol. In essence, frequent character n-gram sequences merge to form one symbol. The number of merge operations is controlled by a hyper-parameter OP"
2020.cl-1.1,P16-1162,0,0.213462,"Missing"
2020.cl-1.1,J10-4005,0,0.059411,"Missing"
2020.cl-1.1,D16-1159,0,0.108794,"Missing"
2020.cl-1.1,E14-2006,0,0.0330156,"Missing"
2020.cl-1.1,P16-2049,0,0.0243138,"al. (2006), Zhang et al. (2007), Shen, Xu, and Weischedel (2010); Neubig and Duh (2014)), with notable success in languages such as Chinese and German, which are syntactically divergent compared to English. However, the sequence-to-sequence NMT systems were able to surpass the performance of the stateof-the-art syntax-based systems in recent MT competitions (Bojar et al. 2016). The LSTM-based RNN model with the help of the attention mechanism is able to handle long-distance dependencies. There have also been recent attempts to integrate syntax into NMT (Eriguchi, Hashimoto, and Tsuruoka 2016; Stahlberg et al. 2016; Aharoni and Goldberg 2017; Chen et al. 2017; Wu et al. 2017), but sequence-to-sequence NMT models without explicit syntax are the state of the art at the moment (Pinnis et al. 2017; Sennrich et al. 2017). Tagging tasks. In this paper, we analyze whether NMT models trained on flat sequences acquire structural syntactic information. To answer this, we use two tagging tasks. First, we use CCG supertagging, which captures global syntactic information locally at the word level by assigning a label to each word annotating its syntactic role in the sentence. The process is almost equivalent to pars"
2020.cl-1.1,E17-1100,0,0.0444399,"Missing"
2020.cl-1.1,D18-1503,0,0.0645852,"Missing"
2020.cl-1.1,P17-1065,0,0.0226344,"ubig and Duh (2014)), with notable success in languages such as Chinese and German, which are syntactically divergent compared to English. However, the sequence-to-sequence NMT systems were able to surpass the performance of the stateof-the-art syntax-based systems in recent MT competitions (Bojar et al. 2016). The LSTM-based RNN model with the help of the attention mechanism is able to handle long-distance dependencies. There have also been recent attempts to integrate syntax into NMT (Eriguchi, Hashimoto, and Tsuruoka 2016; Stahlberg et al. 2016; Aharoni and Goldberg 2017; Chen et al. 2017; Wu et al. 2017), but sequence-to-sequence NMT models without explicit syntax are the state of the art at the moment (Pinnis et al. 2017; Sennrich et al. 2017). Tagging tasks. In this paper, we analyze whether NMT models trained on flat sequences acquire structural syntactic information. To answer this, we use two tagging tasks. First, we use CCG supertagging, which captures global syntactic information locally at the word level by assigning a label to each word annotating its syntactic role in the sentence. The process is almost equivalent to parsing (Bangalore and Joshi 1999). For example, the syntactic tag"
2020.cl-1.1,I11-1004,0,0.0211866,"ted with SEM tags. The semantic tag ENS describes a present-simple event category. The second semantic task is semantic dependency labeling, the task of assigning a type to each arc in a semantic dependency graph. Such dependencies are also known as predicate–argument relations, and may be seen as a first step toward semantic structure. They capture different aspects from syntactic relations, as can be noticed by the different graph structure (compare Figure 1b to Figure 1a). Predicate–argument relations have also been used in many (non-neural) MT systems (Komachi, Matsumoto, and Nagata 2006; Wu et al. 2011; Xiong, Zhang, and Li 2012; Li, Resnik, and Daum´e III 2013). Figure 1b shows an example sentence annotated with Prague Semantic Dependencies (PSD), a reduction of the tectogrammatical annotation in the Prague Czech–English Dependency Treebank (Cinkov´a et al. 2004; Cinkov´a et al. 2009), which was made available as part of the Semantic Dependency Parsing shared tasks in SemEval (Oepen et al. 2014, 2015). 4. Methodology We follow a 3-step process for studying linguistic information learned by the trained neural MT systems. The steps include: (i) training a neural MT system; (ii) using the tra"
2020.cl-1.1,P12-1095,0,0.0631512,"Missing"
2020.cl-1.1,P15-2041,0,0.0418831,"Missing"
2020.cl-1.1,P02-1039,0,0.235127,"s gir@@ l@@ friend Morfessor Professor admit@@ s to shoot@@ ing his girl@@ friend Characters Professor admits to shooting his girlfriend 7 Computational Linguistics Volume 46, Number 1 3.2 Syntax Linguistic theories argue that words are hierarchically organized in syntactic constituents referred to as syntactic trees. It is therefore natural to think that translation models should be based on trees rather than a flat sequence representation of sentences. For more than a decade of research in machine translation, a tremendous amount of effort has been put into syntax-based machine translation (Yamada and Knight (2002); Chiang (2005), Galley et al. (2006), Zhang et al. (2007), Shen, Xu, and Weischedel (2010); Neubig and Duh (2014)), with notable success in languages such as Chinese and German, which are syntactically divergent compared to English. However, the sequence-to-sequence NMT systems were able to surpass the performance of the stateof-the-art syntax-based systems in recent MT competitions (Bojar et al. 2016). The LSTM-based RNN model with the help of the attention mechanism is able to handle long-distance dependencies. There have also been recent attempts to integrate syntax into NMT (Eriguchi, Has"
2020.cl-1.1,W18-5448,0,0.177549,"corpus by training English-to-{French, Arabic, Spanish, Russian, and English} bilingual models. Comparing successive layers (for example, comparing layer 2 versus layer 3), in the majority of the cases, the higher layer performed statistically significantly better than the lower one (ρ &lt; 0.01), according to the approximate randomization test (Pado´ 2006).17 Similar to the results on morphological tagging, a combination of all layers achieved the best results. See the Combination bar in Figure 9a. This implies that although syntax is 16 In their study of NMT and language model representations, Zhang and Bowman (2018) noticed that POS is better represented at layer 1 whereas CCG supertags are sometimes, but not always, better represented at layer 2 (out of 2-layer encoders). 17 See Section 11 in the supplementary information for the detailed results. 24 Belinkov, Durrani et al. Linguistic Representations in NMT mainly learned at higher layers, syntactic information is at least partly distributed across the network. One possible concern with these results is that they may be appearing because of the stacked RNN layers, and not necessarily due to the translation task. In the extreme case, perhaps even a rand"
2020.cl-1.1,2007.mtsummit-papers.71,0,0.109127,"his girl@@ friend Characters Professor admits to shooting his girlfriend 7 Computational Linguistics Volume 46, Number 1 3.2 Syntax Linguistic theories argue that words are hierarchically organized in syntactic constituents referred to as syntactic trees. It is therefore natural to think that translation models should be based on trees rather than a flat sequence representation of sentences. For more than a decade of research in machine translation, a tremendous amount of effort has been put into syntax-based machine translation (Yamada and Knight (2002); Chiang (2005), Galley et al. (2006), Zhang et al. (2007), Shen, Xu, and Weischedel (2010); Neubig and Duh (2014)), with notable success in languages such as Chinese and German, which are syntactically divergent compared to English. However, the sequence-to-sequence NMT systems were able to surpass the performance of the stateof-the-art syntax-based systems in recent MT competitions (Bojar et al. 2016). The LSTM-based RNN model with the help of the attention mechanism is able to handle long-distance dependencies. There have also been recent attempts to integrate syntax into NMT (Eriguchi, Hashimoto, and Tsuruoka 2016; Stahlberg et al. 2016; Aharoni"
2020.cl-1.1,Q16-1027,0,0.0288016,"the BPE-based units. Comparing encoder representations with decoder representations, it is interesting to see that in several cases the decoder-side representations performed better than the encoder-side representations, even though they are trained using a unidirectional LSTM only. Because we did not see any notable trends in differences between encoder and decoder side representations, we only present the encoder-side results in the rest of the paper. 19 Computational Linguistics Volume 46, Number 1 6.3 Effect of Network Depth Modern NMT systems use very deep architectures (Wu et al. 2016b; Zhou et al. 2016). We are interested in understanding what kind of information different layers capture. Given a trained NMT model with multiple layers, we extract feature representations from the different layers in the encoder. We trained 4-layered models (using (NEW+TED+Europarl data). Figure 6 shows morphological tagging results using representations from different encoder and decoder layers across five language pairs. The general trend shows that representations from the first layer are better than those from the higher layers, for the purpose of capturing morphology. We found this observation to be true"
2020.cl-1.1,L16-1561,0,0.0590262,"Missing"
2020.cl-1.1,E03-1076,0,\N,Missing
2020.cl-1.1,P07-2045,0,\N,Missing
2020.cl-1.1,D15-1246,0,\N,Missing
2020.cl-1.1,J17-4003,0,\N,Missing
2020.cl-1.1,N16-3003,1,\N,Missing
2020.cl-1.1,W16-2301,0,\N,Missing
2020.cl-1.1,E17-2039,0,\N,Missing
2020.cl-1.1,P17-1080,1,\N,Missing
2020.cl-1.1,W17-4707,0,\N,Missing
2020.cl-1.1,D17-1304,0,\N,Missing
2020.cl-1.1,W17-4717,0,\N,Missing
2020.cl-1.1,Q19-1004,1,\N,Missing
2020.cl-1.1,N18-1118,0,\N,Missing
2020.emnlp-main.395,E17-2039,0,0.043767,"Missing"
2020.emnlp-main.395,J99-2004,0,0.159195,"The overall pattern remained similar in the task of chunking. Notice however, a shift in pattern – the contribution from lower layers decreased compared to previous tasks, in the case of BERT. For example, in the SEM task, top neurons were dominantly contributed from lower and middle layers, in chunking middle and higher layers contributed most. This could be attributed to the fact that chunking is a more complex syntactic task and is learned at relatively higher layers. CCG Supertagging: Compared to chunking, CCG supertagging is a richer syntactic tagging task, almost equivalent to parsing (Bangalore and Joshi, 1999). The complexity of the task is evident in our results as there is a clear shift in the distribution of top neurons moving from middle to higher layers. The only exception again is the BERT model where this information is well spread across the network, but still dominantly preserved in the final layers. Discussion: Our results are in line with and reinforce the layer-wise analysis presented in Liu et al. (2019). However, unlike their work and all other work on layer-wise probing analysis, which trains a classifier on each layer individually to compare the results, our method trains a single c"
2020.emnlp-main.395,P17-1080,1,0.852479,"tailment, etc. (Rajpurkar et al., 2016; Wang et al., 2018). Central to this revolution is the contextualized embedding, where each word is assigned a vector based on the entire input sequence, allowing it to capture not only a static semantic meaning but also a contextualized meaning. Previous work on analyzing neural networks showed that while learning rich NLP tasks such as machine translation and language modeling, these deep models capture fundamental linguistic phenomena such as word morphology, syntax and various other relevant properties of interest (Shi et al., 2016; Adi et al., 2016; Belinkov et al., 2017a,b; Dalvi et al., 2017; Blevins et al., 2018). More recently Liu et al. (2019) and Tenney et al. (2019) used probing classifiers to analyze pretrained neural language models on a variety of sequence labeling tasks and demonstrated that contextualized representations encode useful, transferable features of language. While most of the previous studies emphasize and analyze representations as a whole, very little work has been carried to analyze individual neurons in deep NLP models. Studying individual neurons can facilitate understanding of the inner workings of neural networks (Karpathy et al"
2020.emnlp-main.395,2020.cl-1.1,1,0.915589,"n, using a categorical cross-entropy loss, optimized by Adam (Kingma and Ba, 2014). Training is run with shuffled mini-batches of size 512 and stopped after 10 epochs. The regularization weights are trained using grid-search algorithm.8 For sub-word based models, we use the last activation value to be the representative of the word as prescribed for the embeddings extracted from Neural MT models (Durrani et al., 2019) and pre-trained Language Models (Liu et al., 2019). Linear classifiers are a popular choice in analyzing deep NLP models due to their better interpretability (Qian et al., 2016; Belinkov et al., 2020). Hewitt and Liang (2019) have also shown linear probes to have higher Selectivity, a property deemed desirable for more interpretable probes. Linear probes are particularly important for our method as we use the learned weights as a proxy to measure the importance of each neuron. 4 Evaluation 4.1 Minimal Neuron Set Now that we have established correctness of the rankings, we apply the algorithm incrementally to select minimal neurons for each linguistic task 8 XLNet All Top Random Bottom 96.04 90.16 28.45 16.86 96.13 92.28 58.17 44.64 All Top Random Bottom 92.09 84.32 64.28 59.02 92.64 90.70"
2020.emnlp-main.395,Q19-1004,1,0.843657,"zation methods to analyze learned representations (Karpathy et al., 2015; K´ad´ar et al., 2017), attention heads (Clark et al., 2019; Vig, 2019) of language compositionality (Li et al., 2016) etc. While such visualizations illuminate the inner workings of the network, they are often qualitative in nature and somewhat anecdotal. A more commonly used approach tries to provide a quantitative analysis by correlating parts of the neural network with linguistic properties, for example by training a classifier to predict a feature of interest (Adi et al., 2016; Conneau et al., 2018). Please refer to Belinkov and Glass (2019) for a comprehensive survey of work done in this direction. Liu et al. (2019) used probing classifiers for investigating the contextualized representations learned from a variety of neural language models on numerous word level linguistic tasks. A similar analysis was carried by Tenney et al. (2019) on a variety of sub-sentence linguistic tasks. We extend this line of work to carry out a more fine-grained neuron level analysis of neural language models. Our work is most similar to Dalvi et al. (2019) who conducted neuron analysis of representations learned from sequence-to-sequence machine tra"
2020.emnlp-main.395,I17-1001,1,0.927499,"Missing"
2020.emnlp-main.395,P18-2003,0,0.0181682,"t al., 2018). Central to this revolution is the contextualized embedding, where each word is assigned a vector based on the entire input sequence, allowing it to capture not only a static semantic meaning but also a contextualized meaning. Previous work on analyzing neural networks showed that while learning rich NLP tasks such as machine translation and language modeling, these deep models capture fundamental linguistic phenomena such as word morphology, syntax and various other relevant properties of interest (Shi et al., 2016; Adi et al., 2016; Belinkov et al., 2017a,b; Dalvi et al., 2017; Blevins et al., 2018). More recently Liu et al. (2019) and Tenney et al. (2019) used probing classifiers to analyze pretrained neural language models on a variety of sequence labeling tasks and demonstrated that contextualized representations encode useful, transferable features of language. While most of the previous studies emphasize and analyze representations as a whole, very little work has been carried to analyze individual neurons in deep NLP models. Studying individual neurons can facilitate understanding of the inner workings of neural networks (Karpathy et al., 2015; Dalvi et al., 2019; Suau et al., 2020"
2020.emnlp-main.395,N19-1112,1,0.712915,"ion is the contextualized embedding, where each word is assigned a vector based on the entire input sequence, allowing it to capture not only a static semantic meaning but also a contextualized meaning. Previous work on analyzing neural networks showed that while learning rich NLP tasks such as machine translation and language modeling, these deep models capture fundamental linguistic phenomena such as word morphology, syntax and various other relevant properties of interest (Shi et al., 2016; Adi et al., 2016; Belinkov et al., 2017a,b; Dalvi et al., 2017; Blevins et al., 2018). More recently Liu et al. (2019) and Tenney et al. (2019) used probing classifiers to analyze pretrained neural language models on a variety of sequence labeling tasks and demonstrated that contextualized representations encode useful, transferable features of language. While most of the previous studies emphasize and analyze representations as a whole, very little work has been carried to analyze individual neurons in deep NLP models. Studying individual neurons can facilitate understanding of the inner workings of neural networks (Karpathy et al., 2015; Dalvi et al., 2019; Suau et al., 2020) and have other potential benefi"
2020.emnlp-main.395,J93-2004,0,0.0764961,"4 dimensions. Its transformer equivalent (T-ELMo) is trained with 7 layers but with the same hidden layer size. The BERT model is trained as an auto-encoder with a dual objective function of predicting masked words and next sentence in auto-encoding fashion. We use base version (13 layers and 768 dimensions). Lastly we included XLNet-base which is trained with the same parameter settings (number and size of hidden layers) as BERT, but with a permutation based auto-regressive objective function. Language Tasks: We evaluated our method on 4 linguistic tasks: POS-tagging using the Penn TreeBank (Marcus et al., 1993), syntax tagging (CCG supertagging)7 using CCGBank (Hockenmaier, 2006), syntactic chunking using CoNLL 2000 shared task dataset (Tjong Kim Sang and Buchholz, 2000), and semantic tagging using the Parallel Meaning Bank data (Abzianidze et al., 2017). We used standard splits for training, de7 CCG captures global syntactic information locally at the word level by assigning a label to each word annotating its syntactic role in the sentence. The annotations can be thought of as a function that takes and return syntactic categories (like an NP: Noun phase). 4867 velopment and test data (See Appendix"
2020.emnlp-main.395,N18-1202,0,0.352548,"rons to play a role in the train4865 Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, pages 4865–4880, c November 16–20, 2020. 2020 Association for Computational Linguistics ing of the classifier. Given a trained classifier, we consider the weights assigned to each neuron as a measure of their importance with respect to the understudied linguistic task. We use probes with high selectivity (Hewitt and Liang, 2019) to ensure that our results reflect the property of representations and not the probe’s capacity to learn. We choose 4 pre-trained models: ELMo (Peters et al., 2018a), its transformer variant T-ELMo (Peters et al., 2018b), BERT (Devlin et al., 2019) and XLNet (Yang et al., 2019) – covering a varied set of modeling choices, including the building blocks (recurrent networks versus Transformers), optimization objective (auto-regressive versus nonautoregressive), and model depth and width. Our cross architectural analysis yields the following insights: • Information across networks is distributed, but it is possible to extract a very small subset of neurons to predict a linguistic task with the same accuracy as using the entire network. • Low level tasks suc"
2020.emnlp-main.395,D18-1179,0,0.0983389,"rons to play a role in the train4865 Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, pages 4865–4880, c November 16–20, 2020. 2020 Association for Computational Linguistics ing of the classifier. Given a trained classifier, we consider the weights assigned to each neuron as a measure of their importance with respect to the understudied linguistic task. We use probes with high selectivity (Hewitt and Liang, 2019) to ensure that our results reflect the property of representations and not the probe’s capacity to learn. We choose 4 pre-trained models: ELMo (Peters et al., 2018a), its transformer variant T-ELMo (Peters et al., 2018b), BERT (Devlin et al., 2019) and XLNet (Yang et al., 2019) – covering a varied set of modeling choices, including the building blocks (recurrent networks versus Transformers), optimization objective (auto-regressive versus nonautoregressive), and model depth and width. Our cross architectural analysis yields the following insights: • Information across networks is distributed, but it is possible to extract a very small subset of neurons to predict a linguistic task with the same accuracy as using the entire network. • Low level tasks suc"
2020.emnlp-main.395,W19-4302,0,0.0441719,"Missing"
2020.emnlp-main.395,2020.acl-main.420,0,0.0155308,"efined control tasks to analyze the role of training data and lexical memorization in probing experiments. Voita and Titov (2020) proposed an alternative that measures Minimal Description Length of labels given representations. It would be interesting to see how a probe’s complexity in their work (code length) compares with the number of selected neurons according to our method. The results are consistent at least in the ELMo POS example, where layer 1 was shown to have the shortest code length in their work. In our case, most top neurons are selected from layer 1 (see Figure 1d for example). Pimentel et al. (2020) discussed the complexity of the probes and argued for using highest performing probes for tighter estimates. However, complex probes are difficult to analyze. Linear models are preferable due to their explainability; especially in our work, as we use the learned weights as a proxy to get a measure of the importance of each neuron. We used linear classifiers with control tasks as described in Hewitt and Liang (2019). Although we mainly used probing accuracy to drive the neuron selection in this work, and Selectivity only to demonstrate that our results reflect the property learned by represent"
2020.emnlp-main.395,D16-1079,0,0.105339,"Missing"
2020.emnlp-main.395,D16-1264,0,0.0345889,"found small subsets of neurons to predict linguistic tasks, with lower level tasks (such as morphology) localized in fewer neurons, compared to higher level task of predicting syntax. Our study reveals interesting cross architectural comparisons. For example, we found neurons in XLNet to be more localized and disjoint when predicting properties compared to BERT and others, where they are more distributed and coupled. 1 Introduction Transformer-based neural language models have constantly pushed the state-of-the-art in downstream NLP tasks such as Question Answering, Textual Entailment, etc. (Rajpurkar et al., 2016; Wang et al., 2018). Central to this revolution is the contextualized embedding, where each word is assigned a vector based on the entire input sequence, allowing it to capture not only a static semantic meaning but also a contextualized meaning. Previous work on analyzing neural networks showed that while learning rich NLP tasks such as machine translation and language modeling, these deep models capture fundamental linguistic phenomena such as word morphology, syntax and various other relevant properties of interest (Shi et al., 2016; Adi et al., 2016; Belinkov et al., 2017a,b; Dalvi et al."
2020.emnlp-main.395,2020.emnlp-main.14,0,0.0116592,"to select the regularization parameters, compared to manual selection of lambdas, which is cumbersome and error-prone. In contemporaneous work, Suau et al. (2020) used max-pooling to identify relevant neurons (aka Expert units) in pre-trained models, with respect to a specific concept (for example word-sense). A pitfall to the approach of probing classifiers is whether the probe is faithfully reflecting the property of the representation or just learned the task? Hewitt and Liang (2019) defined control tasks to analyze the role of training data and lexical memorization in probing experiments. Voita and Titov (2020) proposed an alternative that measures Minimal Description Length of labels given representations. It would be interesting to see how a probe’s complexity in their work (code length) compares with the number of selected neurons according to our method. The results are consistent at least in the ELMo POS example, where layer 1 was shown to have the shortest code length in their work. In our case, most top neurons are selected from layer 1 (see Figure 1d for example). Pimentel et al. (2020) discussed the complexity of the probes and argued for using highest performing probes for tighter estimate"
2020.emnlp-main.395,W18-5446,0,0.0640162,"Missing"
2020.emnlp-main.395,2020.acl-main.422,1,0.786141,"ould be to use selectivity itself to drive the investigation. However, it is not trivial how to optimize for selectivity as it cannot be controlled/tuned directly – for example, removing some neurons may decrease accuracy but may not change selectivity. We leave this exploration for future work. Probing classifiers require supervision for the linguistic tasks of interest with annotations, limiting their applicability. Bau et al. (2019) used unsupervised approach to identify salient neurons in neural machine translation and manipulated translation output by controlling these neurons. Recently, Wu et al. (2020) measured similarity of internal representations and attention across prominent contextualized representations (from BERT, ELMo, etc.). They found that different architectures have similar representations, but different individual neurons. 7 Conclusion We analyzed individual neurons across a variety of neural language models using linguistic correlation analysis on the task of predicting core linguistic properties (morphology, syntax and semantics). Our results reinforce previous findings and also illuminate further insights: i) while the information in neural language models is massively dist"
2020.emnlp-main.398,W17-6901,0,0.0195206,"Missing"
2020.emnlp-main.398,N19-1112,1,0.846794,"Missing"
2020.emnlp-main.398,2020.acl-main.420,0,0.0204587,"asks. 2 Related Work A number of studies have analyzed representations at layer-level (Conneau et al., 2018; Liu et al., 2019; Tenney et al., 2019; Kim et al., 2020; Belinkov et al., 2020) and at neuron-level (Bau et al., 2019; Dalvi et al., 2019; Suau et al., 2020; Durrani et al., 2020). These studies aim at analyzing either the linguistic knowledge learned in representations and in neurons or the general importance of neurons in the model. The former is commonly done using a probing classifier (Shi et al., 2016a; Belinkov et al., 2017; Hupkes et al., 2018). Recently, Voita and Titov (2020); Pimentel et al. (2020) proposed probing methods based on information theoretic measures. The general importance of neurons is mainly captured using similarity and correlationbased methods (Raghu et al., 2017; Chrupała and Alishahi, 2019; Wu et al., 2020). Similar to the work on analyzing deep NLP models, we analyze pretrained models at representation-level and at neuron-level. Different from them, we analyze various forms of redundancy in these models. We draw upon various techniques from the literature and adapt them to perform a redundancy analysis. While the work on pretrained model compression (Cao et al., 2020"
2020.emnlp-main.398,D16-1079,0,0.0261294,"Missing"
2020.emnlp-main.398,D16-1264,0,0.0121626,"h (POS) tagging using the Penn TreeBank, ii) CCG super tagging using CCGBank (Hockenmaier, 2006), iii) semantic tagging (SEM) using Parallel Meaning Bank data (Abzianidze and Bos, 2017) and iv) syntactic chunking using CoNLL 2000 shared task dataset (Sang and Buchholz, 2000). For sequence classification, we study tasks from the GLUE benchmark (Wang et al., 2018), namely i) sentiment analysis (SST-2) (Socher et al., 2013), ii) semantic equivalence classification (MRPC) (Dolan and Brockett, 2005), iii) natural language inference (MNLI) (Williams et al., 2018), iv) question-answering NLI (QNLI) (Rajpurkar et al., 2016), iv) question pair similarity2 (QQP), v) textual entailment (RTE) (Bentivogli et al., 2009), and vi) semantic textual similarity (Cer et al., 2017).3 Complete statistics for all datasets is provided in Appendix A.1. Other Settings The neuron activations for each word in our dataset are extracted from the pretrained model for sequence labeling while the [CLS] token’s representation (from a fine-tuned model) is used for sequence classification. The fine-tuning step is essential to optimize the [CLS] token for sentence representation. In the case of sub-words, we pick the last sub-word’s represe"
2020.emnlp-main.398,W00-0726,0,0.0907869,"Missing"
2020.emnlp-main.398,D16-1248,0,0.360354,"ion in a pretrained model is necessary for specific downstream tasks? and v) can we exploit redundancy to 4908 Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, pages 4908–4926, c November 16–20, 2020. 2020 Association for Computational Linguistics enable efficiency? We introduce several methods to analyze redundancy in the network. Specifically, for general redundancy, we use Center Kernel Alignment (Kornblith et al., 2019) for layer-level analysis, and Correlation Clustering for neuron-level analysis. For task-specific redundancy, we use Linear Probing (Shi et al., 2016a; Belinkov et al., 2017) to identify redundant layers, and Linguistic Correlation Analysis (Dalvi et al., 2019) to examine neuronlevel redundancy. We conduct our study on two pretrained language models, BERT (Devlin et al., 2019) and XLNet (Yang et al., 2019). While these networks are similar in the number of parameters, they are trained using different training objectives, which accounts for interesting comparative analysis between these models. For task-specific analysis, we present our results across a wide suite of downstream tasks: four core NLP sequence labeling tasks and seven sequence"
2020.emnlp-main.398,D16-1159,0,0.250577,"ion in a pretrained model is necessary for specific downstream tasks? and v) can we exploit redundancy to 4908 Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, pages 4908–4926, c November 16–20, 2020. 2020 Association for Computational Linguistics enable efficiency? We introduce several methods to analyze redundancy in the network. Specifically, for general redundancy, we use Center Kernel Alignment (Kornblith et al., 2019) for layer-level analysis, and Correlation Clustering for neuron-level analysis. For task-specific redundancy, we use Linear Probing (Shi et al., 2016a; Belinkov et al., 2017) to identify redundant layers, and Linguistic Correlation Analysis (Dalvi et al., 2019) to examine neuronlevel redundancy. We conduct our study on two pretrained language models, BERT (Devlin et al., 2019) and XLNet (Yang et al., 2019). While these networks are similar in the number of parameters, they are trained using different training objectives, which accounts for interesting comparative analysis between these models. For task-specific analysis, we present our results across a wide suite of downstream tasks: four core NLP sequence labeling tasks and seven sequence"
2020.emnlp-main.398,D13-1170,0,0.00525291,"c analysis, we use two broad categories of downstream tasks – Sequence Labeling and Sequence Classification tasks. For the sequence labeling tasks, we study core linguistic tasks, i) part-of-speech (POS) tagging using the Penn TreeBank, ii) CCG super tagging using CCGBank (Hockenmaier, 2006), iii) semantic tagging (SEM) using Parallel Meaning Bank data (Abzianidze and Bos, 2017) and iv) syntactic chunking using CoNLL 2000 shared task dataset (Sang and Buchholz, 2000). For sequence classification, we study tasks from the GLUE benchmark (Wang et al., 2018), namely i) sentiment analysis (SST-2) (Socher et al., 2013), ii) semantic equivalence classification (MRPC) (Dolan and Brockett, 2005), iii) natural language inference (MNLI) (Williams et al., 2018), iv) question-answering NLI (QNLI) (Rajpurkar et al., 2016), iv) question pair similarity2 (QQP), v) textual entailment (RTE) (Bentivogli et al., 2009), and vi) semantic textual similarity (Cer et al., 2017).3 Complete statistics for all datasets is provided in Appendix A.1. Other Settings The neuron activations for each word in our dataset are extracted from the pretrained model for sequence labeling while the [CLS] token’s representation (from a fine-tun"
2020.emnlp-main.398,P19-1580,0,0.0800221,"e, BERT large (Devlin et al., 2019), NVIDIA’s Megatron model, and Google’s T5 model (Raffel et al., 2019) were trained using 340 million, 8.3 billion and 11 billion parameters respectively. An emerging body of work shows that these models are over-parameterized and do not require all the representational power lent by the rich architectural choices during inference. For example, these models can be distilled (Sanh et al., 2019; 1 The code for the experiments in this paper is available at https://github.com/fdalvi/analyzingredundancy-in-pretrained-transformermodels Sun et al., 2019) or pruned (Voita et al., 2019; Sajjad et al., 2020), with a minor drop in performance. Recent research (Mu et al., 2018; Ethayarajh, 2019) analyzed contextualized embeddings in pretrained models and showed that the representations learned within these models are highly anisotropic. While these approaches successfully exploited over-parameterization and redundancy in pretrained models, the choice of what to prune is empirically motivated and the work does not directly explore the redundancy in the network. Identifying and analyzing redundant parts of the network is useful in: i) developing a better understanding of these m"
2020.nlp4convai-1.15,P18-1198,0,0.110912,"the generated text. In this study, we explore internal representations instead, motivated by the fact that reasonable internal behavior is crucial for interpretability and is often a prerequisite for effective external behavior. Outside of open-domain dialog, probing has been applied for analyzing natural language processing models in machine translation (Belinkov et al., 2017) and visual question answering (Subramanian et al., 2019). Probing is also commonly used for evaluating the quality of “universal” sentence representations which are trained once and used for a variety of applications (Conneau et al., 2018; Adi et al., 2016) (for example, InferSent (Conneau et al., 2017), SkipThought (Kiros et al., 2015), USE (Cer et al., 2018)). Along the same lines, natural language understanding benchmarks such as GLUE (Wang et al., 2018) and SuperGLUE (Wang et al., 2019) propose a set of diverse tasks for evaluating general linguistic knowledge. Our analysis differs from previous work since it is focused on probing for conversational skills that are particularly relevant to dialog generation. With regard to perturbation experiments, Sankar et al. (2019) found that standard dialog models are largely insensit"
2020.nlp4convai-1.15,W19-3646,0,0.0143832,"l., 2017), a popular open-source platform for building dialog systems. We also publicly release all our code at https://github.com/ AbdulSaleh/dialog-probing, hoping that probing will become a standard method for interpreting and analyzing open-domain dialog systems. 2 Related Work Evaluating and interpreting open-domain dialog models is notoriously challenging. Multiple studies have shown that standard evaluation metrics such as perplexity and BLEU scores (Papineni et al., 2002) correlate very weakly with human judgements of conversation quality (Liu et al., 2016; Ghandeharioun et al., 2019; Dziri et al., 2019). This has inspired multiple new approaches for evaluating dialog systems. One popular evaluation metric involves calculating the semantic similarity between the user input and generated response in high-dimensional embedding space (Liu et al., 2016; Ghandeharioun et al., 2019; Dziri et al., 2019; Park et al., 2018; Zhao et al., 2017; Xu et al., 2018). Ghandeharioun et al. (2019) proposed calculating conversation metrics such as sentiment and coherence on self-play conversations generated by trained models. Similarly, Dziri et al. (2019) use neural classifiers to identify whether the modelgene"
2020.nlp4convai-1.15,P17-1080,1,0.843058,"put in a natural language inference setting. To the best of our knowledge, all existing approaches for evaluating the performance of opendomain dialog systems only consider external model behavior in the sense that they analyze properties of the generated text. In this study, we explore internal representations instead, motivated by the fact that reasonable internal behavior is crucial for interpretability and is often a prerequisite for effective external behavior. Outside of open-domain dialog, probing has been applied for analyzing natural language processing models in machine translation (Belinkov et al., 2017) and visual question answering (Subramanian et al., 2019). Probing is also commonly used for evaluating the quality of “universal” sentence representations which are trained once and used for a variety of applications (Conneau et al., 2018; Adi et al., 2016) (for example, InferSent (Conneau et al., 2017), SkipThought (Kiros et al., 2015), USE (Cer et al., 2018)). Along the same lines, natural language understanding benchmarks such as GLUE (Wang et al., 2018) and SuperGLUE (Wang et al., 2019) propose a set of diverse tasks for evaluating general linguistic knowledge. Our analysis differs from p"
2020.nlp4convai-1.15,Q19-1004,1,0.783782,"results on a variety of language generation tasks including machine translation (Bahdanau et al., 2014), abstractive summarization (Rush et al., 2015), and text simplification (Wang et al., 2016). However, current generative models for dialog suffer from several shortcomings that limit their usefulness in the real world. Neural models can be opaque and difficult to interpret, posing barriers to their deployment in safety-critical applications such as mental health or customer service ∗ Second author equal contribution. Our code is available at https://github.com/ AbdulSaleh/dialog-probing 1 (Belinkov and Glass, 2019). End-to-end training provides little insight as to what these models learn about engaging in dialog. Open-domain dialog systems also struggle to maintain basic conversations, frequently ignoring user input (Sankar et al., 2019) while generating irrelevant, repetitive, and contradictory responses (Saleh et al., 2019; Li et al., 2016, 2017a; Welleck et al., 2018). Table 1 shows examples from standard dialog models which fail at basic interactions – struggling to answer questions, detect intent, and understand conversational context. In light of these limitations, we aim to answer the following"
2020.nlp4convai-1.15,D16-1127,0,0.0303883,"opaque and difficult to interpret, posing barriers to their deployment in safety-critical applications such as mental health or customer service ∗ Second author equal contribution. Our code is available at https://github.com/ AbdulSaleh/dialog-probing 1 (Belinkov and Glass, 2019). End-to-end training provides little insight as to what these models learn about engaging in dialog. Open-domain dialog systems also struggle to maintain basic conversations, frequently ignoring user input (Sankar et al., 2019) while generating irrelevant, repetitive, and contradictory responses (Saleh et al., 2019; Li et al., 2016, 2017a; Welleck et al., 2018). Table 1 shows examples from standard dialog models which fail at basic interactions – struggling to answer questions, detect intent, and understand conversational context. In light of these limitations, we aim to answer the following questions: (i) Do neural dialog models effectively encode information about the conversation history? (ii) Do neural dialog models learn basic conversational skills through end-to-end training? (iii) And to what extent do neural dialog models leverage the dyadic, turn-taking structure of dialog to learn these skills? To answer these"
2020.nlp4convai-1.15,D18-2029,0,0.0165447,"behavior is crucial for interpretability and is often a prerequisite for effective external behavior. Outside of open-domain dialog, probing has been applied for analyzing natural language processing models in machine translation (Belinkov et al., 2017) and visual question answering (Subramanian et al., 2019). Probing is also commonly used for evaluating the quality of “universal” sentence representations which are trained once and used for a variety of applications (Conneau et al., 2018; Adi et al., 2016) (for example, InferSent (Conneau et al., 2017), SkipThought (Kiros et al., 2015), USE (Cer et al., 2018)). Along the same lines, natural language understanding benchmarks such as GLUE (Wang et al., 2018) and SuperGLUE (Wang et al., 2019) propose a set of diverse tasks for evaluating general linguistic knowledge. Our analysis differs from previous work since it is focused on probing for conversational skills that are particularly relevant to dialog generation. With regard to perturbation experiments, Sankar et al. (2019) found that standard dialog models are largely insensitive to perturbations of the input text. Here we introduce an alternative set of perturbation experiments to similarly explor"
2020.nlp4convai-1.15,D17-1230,0,0.0293516,"similarly explore the extent to which dialog structure is being leveraged by these models. 3 3.1 Methodology Models and Data In this study, we focus on the three most widespread dialog architectures: recurrent neural networks (RNNs) (Sutskever et al., 2014), RNNs with attention (Bahdanau et al., 2014), and Transformers (Vaswani et al., 2017). We use the ParlAI platform (Miller et al., 2017) for building and training the models. We train models of two different sizes and initialization strategies. Small models (≈ 14M parameters) are initialized randomly and trained from scratch on DailyDialog (Li et al., 2017b). Large models (≈ 70M parameters) are 133 Question Answering Inference & Entailment Intent Detection Emotional Understanding [Usr]: What do you do for a living? [Bot]: I’m from south america, lol [Usr]: what’s your favorite food? [Bot]: I love food [Usr]: you like food? [Bot]: no, I don’t [Usr]: Give me music recommendations. [Bot]: I don’t know what I want to do with my life. [Usr]: I feel so miserable [Bot]: I’m afraid it’s too much for me. Table 1: Examples from open-domain dialog systems struggling with simple conversational skills. Figure 1: Probing setup. Dotted arrows emphasize that p"
2020.nlp4convai-1.15,D17-1070,0,0.0157137,"ations instead, motivated by the fact that reasonable internal behavior is crucial for interpretability and is often a prerequisite for effective external behavior. Outside of open-domain dialog, probing has been applied for analyzing natural language processing models in machine translation (Belinkov et al., 2017) and visual question answering (Subramanian et al., 2019). Probing is also commonly used for evaluating the quality of “universal” sentence representations which are trained once and used for a variety of applications (Conneau et al., 2018; Adi et al., 2016) (for example, InferSent (Conneau et al., 2017), SkipThought (Kiros et al., 2015), USE (Cer et al., 2018)). Along the same lines, natural language understanding benchmarks such as GLUE (Wang et al., 2018) and SuperGLUE (Wang et al., 2019) propose a set of diverse tasks for evaluating general linguistic knowledge. Our analysis differs from previous work since it is focused on probing for conversational skills that are particularly relevant to dialog generation. With regard to perturbation experiments, Sankar et al. (2019) found that standard dialog models are largely insensitive to perturbations of the input text. Here we introduce an alter"
2020.nlp4convai-1.15,I17-1099,0,0.0119748,"similarly explore the extent to which dialog structure is being leveraged by these models. 3 3.1 Methodology Models and Data In this study, we focus on the three most widespread dialog architectures: recurrent neural networks (RNNs) (Sutskever et al., 2014), RNNs with attention (Bahdanau et al., 2014), and Transformers (Vaswani et al., 2017). We use the ParlAI platform (Miller et al., 2017) for building and training the models. We train models of two different sizes and initialization strategies. Small models (≈ 14M parameters) are initialized randomly and trained from scratch on DailyDialog (Li et al., 2017b). Large models (≈ 70M parameters) are 133 Question Answering Inference & Entailment Intent Detection Emotional Understanding [Usr]: What do you do for a living? [Bot]: I’m from south america, lol [Usr]: what’s your favorite food? [Bot]: I love food [Usr]: you like food? [Bot]: no, I don’t [Usr]: Give me music recommendations. [Bot]: I don’t know what I want to do with my life. [Usr]: I feel so miserable [Bot]: I’m afraid it’s too much for me. Table 1: Examples from open-domain dialog systems struggling with simple conversational skills. Figure 1: Probing setup. Dotted arrows emphasize that p"
2020.nlp4convai-1.15,D16-1230,0,0.033189,"ntegrates with and extends ParlAI (Miller et al., 2017), a popular open-source platform for building dialog systems. We also publicly release all our code at https://github.com/ AbdulSaleh/dialog-probing, hoping that probing will become a standard method for interpreting and analyzing open-domain dialog systems. 2 Related Work Evaluating and interpreting open-domain dialog models is notoriously challenging. Multiple studies have shown that standard evaluation metrics such as perplexity and BLEU scores (Papineni et al., 2002) correlate very weakly with human judgements of conversation quality (Liu et al., 2016; Ghandeharioun et al., 2019; Dziri et al., 2019). This has inspired multiple new approaches for evaluating dialog systems. One popular evaluation metric involves calculating the semantic similarity between the user input and generated response in high-dimensional embedding space (Liu et al., 2016; Ghandeharioun et al., 2019; Dziri et al., 2019; Park et al., 2018; Zhao et al., 2017; Xu et al., 2018). Ghandeharioun et al. (2019) proposed calculating conversation metrics such as sentiment and coherence on self-play conversations generated by trained models. Similarly, Dziri et al. (2019) use neu"
2020.nlp4convai-1.15,D15-1166,0,0.166644,"Missing"
2020.nlp4convai-1.15,D17-2014,0,0.0543425,"ode information about the conversation history and the current utterance. In most cases, simply averaging the word embeddings is superior to using the learned encoder representations. This performance gap is smaller for large, pre-trained models. 3. Neural dialog models do not leverage the dyadic, turn-taking nature of conversation. Shuffling conversations in the training data had little impact on perplexity and probing performance. This suggests that breaking the dialog structure did not significantly affect the quality of learned representations. Our code integrates with and extends ParlAI (Miller et al., 2017), a popular open-source platform for building dialog systems. We also publicly release all our code at https://github.com/ AbdulSaleh/dialog-probing, hoping that probing will become a standard method for interpreting and analyzing open-domain dialog systems. 2 Related Work Evaluating and interpreting open-domain dialog models is notoriously challenging. Multiple studies have shown that standard evaluation metrics such as perplexity and BLEU scores (Papineni et al., 2002) correlate very weakly with human judgements of conversation quality (Liu et al., 2016; Ghandeharioun et al., 2019; Dziri et"
2020.nlp4convai-1.15,P02-1040,0,0.109982,"og structure did not significantly affect the quality of learned representations. Our code integrates with and extends ParlAI (Miller et al., 2017), a popular open-source platform for building dialog systems. We also publicly release all our code at https://github.com/ AbdulSaleh/dialog-probing, hoping that probing will become a standard method for interpreting and analyzing open-domain dialog systems. 2 Related Work Evaluating and interpreting open-domain dialog models is notoriously challenging. Multiple studies have shown that standard evaluation metrics such as perplexity and BLEU scores (Papineni et al., 2002) correlate very weakly with human judgements of conversation quality (Liu et al., 2016; Ghandeharioun et al., 2019; Dziri et al., 2019). This has inspired multiple new approaches for evaluating dialog systems. One popular evaluation metric involves calculating the semantic similarity between the user input and generated response in high-dimensional embedding space (Liu et al., 2016; Ghandeharioun et al., 2019; Dziri et al., 2019; Park et al., 2018; Zhao et al., 2017; Xu et al., 2018). Ghandeharioun et al. (2019) proposed calculating conversation metrics such as sentiment and coherence on self-"
2020.nlp4convai-1.15,N18-1162,0,0.0422419,"Missing"
2020.nlp4convai-1.15,D14-1162,0,0.0858223,"g to the previous utterances, [u1 , . . . , ut−1 ], and then we separately averaged the encoder hidden states corresponding to the current utterance, ut , and concatenated the two resulting, equal-length vectors. We also concatenated the last cell state. Similarly, for Transformers, we averaged the encoder outputs corresponding to the previous utterances and separately averaged encoder outputs corresponding to the current utterance and concatenated them. Combined: The combined representations are the concatenation of of the word embeddings and encoder state representations. We also use GloVe (Pennington et al., 2014) word embeddings as a simple baseline. We encode the probing task inputs using the word embeddings approach described above. We ensure that GloVe and all models of a certain size (small vs large) share the same vocabulary for comparability. 3.3 MultiWOZ: Every utterance in a conversation can be considered as an action or a dialog act performed by the speaker. A speaker could be making a request, providing information, or simply greeting the system. MultiWOZ 2.1 (Eric et al., 2019) is a dataset of multi-domain, goal-oriented conversations. Human turns are labeled with dialog acts and the associ"
2020.nlp4convai-1.15,D15-1044,0,0.134145,"Missing"
2020.nlp4convai-1.15,P19-1004,0,0.0540052,"Missing"
2020.nlp4convai-1.15,W18-5446,0,0.0600171,"Missing"
2020.wmt-1.4,abdelali-etal-2014-amara,1,0.827823,"ne translated all comments using an in-house transformer-based model into Japanese and German. The goal of that was to be able to examine potential differences in source and (one example of) translation segments.3 We then pre-processed and automatically annotated all 17K segments with the following soft labels for catastrophic errors: Development Data The task specified the following data to help participants evaluate their system’s performance on unseen and multiple domains. • English-German: participants can use the development data from the News translation task, development data from QED (Abdelali et al., 2014) corpus, development data from WMT19 Medical translation task, and development data from the WMT16 IT translation task. 1. Introduction of toxicity: we checked both source and machine translation for toxic words (using in-house lists) and labelled as positive (i.e. potentially containing errors) cases where the source does not contain such words, but the translation does (at least one). • English-Japanese: participants can use the development data from the News translation task, and development data from the MTNT dataset, which contains noisy social media texts and their clean translations. 3."
2020.wmt-1.4,D17-1158,0,0.0130333,"Another approach trains a system on multiple domains at the same time, while adding domain-specific tags to the input examples (Kobus et al., 2016). Both these approaches were employed by participants of the first shared task on MT robustness (Li et al., 2019). Other methods for domain adaptation of MT systems include instance weighting (Wang et al., 2017b), incorporating a domain classifier (Chen et al., 2017; Britz et al., 2017), and data selection (Wang et al., 2017a). Some make use of monolingual data available either in the target domain—for example by training the decoder on such data (Domhan and Hieber, 2017) or by backtranslating it (Sennrich et al., 2016)—or in the source domain, via similar techniques (Zhang and Zong, 2016). Chu and Wang (2018) provide a broad survey of domain adaptation for neural MT, which demonstrates that the predominant setup assumes knowledge of the target domain and availability of target domain data at training time. In light of this prior work, the shared task proposed a relatively underexplored scenario, where examples in the target domain are either unavailable or relatively few. Other aspects of robustness are robustness to adversarial examples or noisy inputs. The"
2020.wmt-1.4,N19-1311,0,0.0437239,"Missing"
2020.wmt-1.4,P18-1128,0,0.014933,"Naver Labs and LIMSI made specific efforts towards the task of Robustness. Both of them used lightweight domain adaptors proposed by Bapna and Firat (2019). Both teams UEDIN: Team UEDIN also mainly trained their system towards News translation task, but added Gumbel noise to the output layer of the systems submitted to the Robustness task. They followed standard NMT training pipeline and boasted their systems with additional data filtered from the paracrawl corpus. The data was carefully selected using dual cross-entropy (Junczys-Dowmunt, 2018) and length-normalized cross-entropy. 81 script6 (Dror et al., 2018) with p <0.05. The result of significance test in likert score is used for the human judgement ranking. Interestingly, the correlation in the system rankings between human judgments and BLEU is not strong. In other words, the best performing systems in BLEU do not rank high according human judgement, sometimes even rank the lowest. For example, in Ja→En (set2), the online-B system ranks first in BLEU but last in likert score. OPPO outperforms all systems in both directions on set2, and is overall the best system among the constrained, zero-shot submissions. To get insight on the proportion of"
2020.wmt-1.4,2020.lrec-1.520,0,0.0937737,"raped, filtered for noisy comments and translated by professional translators. This year, data was collected for two translation directions: English→Japanese and Japanese→English. For English, comments were collected from the /r/all feed, which encompasses all communities, and filtered for English. Since Japanese is a minority language on Reddit, comments were scraped from a selection of japanese-speaking communities, detailed in Michel and Neubig (2018). Common Voices Test Set (set3): This data was obtained from from the CoVoST corpus (Wang et al., 2020). CoVoST is derived from Common Voice (Ardila et al., 2020), a crowdsourced speech recognition corpus with an open CC0 license. Transcripts were sent to professional translators and the quality of translations was controlled by automatic and manual checks (Guzm´an et al., 2019). For this task, we used the German→English test set with source German sentences deduplicated. 1 Bad: translation errors are so severe that they cause the target text to be incomprehensible. This may be mainly due to major grammatical, typographical, or lexical errors, or omission of critical or important salient information. 2 Poor: the target text contains translation errors,"
2020.wmt-1.4,N19-1154,1,0.82504,"luation and the results discussed in Section 5. We hope that this task leads to more efforts from the community in building robust MT models. Introduction In recent years, Machine Translation (MT) systems have seen great progress, with neural models becoming the de-facto methods and even approaching human quality in news domain (Hassan et al., 2018). However, like other deep learning models, neural machine translation (NMT) models are found to be sensitive to synthetic and natural noise in input, distributional shift, and adversarial examples (Koehn and Knowles, 2017; Belinkov and Bisk, 2018; Durrani et al., 2019; Anastasopoulos et al., 2019; Michel et al., 2019). From an application perspective, MT systems need to deal with non-standard, noisy text of the kind which is ubiquitous on social media and the internet, yet has different distributional signatures from corpora in common benchmark datasets. Following the first shared task on Machine Translation (MT) Robustness, we now propose a second edition, which aims at testing MT systems’ robustness towards domain diversity. Specifically, this year’s task aims to evaluate a general MT system’s performance in the following two scenarios: 2 Related Work Do"
2020.wmt-1.4,D19-1165,0,0.282315,"n a critical way. Critical errors are those that lead to misleading translations which may carry religious, health, safety, legal or financial implications, or introduce toxicity. The set of critical errors used for the guidelines (which also included examples of these errors) includes – but is not limited to – the cases below: Naver Labs (NLE): They participated in Chat and Biomedical tasks along with the Robustness task. They trained a general big-transformer model using FairSeq toolkit (Ott et al., 2019) and adapted it towards different tasks using lightweight adapter layers for each task (Bapna and Firat, 2019). They compared results against the more traditional finetuning method (Luong and Manning, 2015) to show that the former provides a viable alternative, while significantly reducing the amount of parameters per task. They also explored using embedding from pre-trained language models in their NMT system of which they tried two MLM variants: i) using NMT encoder’s setting, using Roberta (Liu et al., 2019). The latter was found more robust to novel domains and noise. The authors found that initializing with first 8 layers instead of the entire model to 80 OPPO: Team OPPO also trained their system"
2020.wmt-1.4,D19-1632,1,0.894086,"Missing"
2020.wmt-1.4,W17-4712,0,0.0183942,"ne-tune on datasets increasingly similar to the target domain (Sajjad et al., 2017), or to dynamically change the balance of data towards the target domain (van der Wees et al., 2017). Another approach trains a system on multiple domains at the same time, while adding domain-specific tags to the input examples (Kobus et al., 2016). Both these approaches were employed by participants of the first shared task on MT robustness (Li et al., 2019). Other methods for domain adaptation of MT systems include instance weighting (Wang et al., 2017b), incorporating a domain classifier (Chen et al., 2017; Britz et al., 2017), and data selection (Wang et al., 2017a). Some make use of monolingual data available either in the target domain—for example by training the decoder on such data (Domhan and Hieber, 2017) or by backtranslating it (Sennrich et al., 2016)—or in the source domain, via similar techniques (Zhang and Zong, 2016). Chu and Wang (2018) provide a broad survey of domain adaptation for neural MT, which demonstrates that the predominant setup assumes knowledge of the target domain and availability of target domain data at training time. In light of this prior work, the shared task proposed a relatively u"
2020.wmt-1.4,W17-3205,0,0.0203483,"to continuously fine-tune on datasets increasingly similar to the target domain (Sajjad et al., 2017), or to dynamically change the balance of data towards the target domain (van der Wees et al., 2017). Another approach trains a system on multiple domains at the same time, while adding domain-specific tags to the input examples (Kobus et al., 2016). Both these approaches were employed by participants of the first shared task on MT robustness (Li et al., 2019). Other methods for domain adaptation of MT systems include instance weighting (Wang et al., 2017b), incorporating a domain classifier (Chen et al., 2017; Britz et al., 2017), and data selection (Wang et al., 2017a). Some make use of monolingual data available either in the target domain—for example by training the decoder on such data (Domhan and Hieber, 2017) or by backtranslating it (Sennrich et al., 2016)—or in the source domain, via similar techniques (Zhang and Zong, 2016). Chu and Wang (2018) provide a broad survey of domain adaptation for neural MT, which demonstrates that the predominant setup assumes knowledge of the target domain and availability of target domain data at training time. In light of this prior work, the shared task pr"
2020.wmt-1.4,P17-2061,0,0.0561223,"Missing"
2020.wmt-1.4,C18-1111,0,0.0137039,"6). Both these approaches were employed by participants of the first shared task on MT robustness (Li et al., 2019). Other methods for domain adaptation of MT systems include instance weighting (Wang et al., 2017b), incorporating a domain classifier (Chen et al., 2017; Britz et al., 2017), and data selection (Wang et al., 2017a). Some make use of monolingual data available either in the target domain—for example by training the decoder on such data (Domhan and Hieber, 2017) or by backtranslating it (Sennrich et al., 2016)—or in the source domain, via similar techniques (Zhang and Zong, 2016). Chu and Wang (2018) provide a broad survey of domain adaptation for neural MT, which demonstrates that the predominant setup assumes knowledge of the target domain and availability of target domain data at training time. In light of this prior work, the shared task proposed a relatively underexplored scenario, where examples in the target domain are either unavailable or relatively few. Other aspects of robustness are robustness to adversarial examples or noisy inputs. The fragility of neural MT models has been previously demonstrated in various settings (Belinkov and Bisk, 2018; Heigold et al., 2017; Anastasopo"
2020.wmt-1.4,W18-6478,0,0.0263186,"different models to obtain further improvements. Only two teams, namely Naver Labs and LIMSI made specific efforts towards the task of Robustness. Both of them used lightweight domain adaptors proposed by Bapna and Firat (2019). Both teams UEDIN: Team UEDIN also mainly trained their system towards News translation task, but added Gumbel noise to the output layer of the systems submitted to the Robustness task. They followed standard NMT training pipeline and boasted their systems with additional data filtered from the paracrawl corpus. The data was carefully selected using dual cross-entropy (Junczys-Dowmunt, 2018) and length-normalized cross-entropy. 81 script6 (Dror et al., 2018) with p <0.05. The result of significance test in likert score is used for the human judgement ranking. Interestingly, the correlation in the system rankings between human judgments and BLEU is not strong. In other words, the best performing systems in BLEU do not rank high according human judgement, sometimes even rank the lowest. For example, in Ja→En (set2), the online-B system ranks first in BLEU but last in likert score. OPPO outperforms all systems in both directions on set2, and is overall the best system among the cons"
2020.wmt-1.4,P17-4012,0,0.0234194,"the decoder. This allows the test sets from known domains to use adapter layers and for novel domains to use the generic system. They created a noisy domain by adding synthetic noise to source data. The idea is that residual adapter layer learned from such data learns how to deal with noisy domain and is also able to preserve performance on the cleaner domains. However this did not work as well. The residual adapter fine-tuned using the ParaCrawl corpus gave better performance. PROMPT: Team PROMPT also participated mainly in the News translation task. Their systems were trained using OpenNMT (Klein et al., 2017) toolkit. They applied several stages of data preprocessing including length-based filtering, removing duplications, and using in-house classifier based on Hunalign aligner to identify and discard non-parallel sentences. They used two types of synthetic data to improve their systems: i) randomly selecting subset of Wikipedia equal to the size of news data and generating parallel corpus through back-translation, ii) creating synthetic data with unknown words using the procedure described in (Pinnis et al., 2017). Systems were trained with tags to differentiate between original data and syntheti"
2020.wmt-1.4,P02-1040,0,0.114721,"l can bias the selection to cases that are challenging for this particular model. In future work following this methodology, we recommend that multiple MT models be used. 4 https://cloud.google. com/natural-language/docs/ analyzing-sentiment 5 https://github.com/carpedm20/emoji/) 2 www.kaggle.com/c/ jigsaw-toxic-comment-classification- challenge 78 3.5 5. Presence of idioms: we checked if the source contains idiomatic expressions, using an inhouse list of idioms built from various sources, and labelled those cases as positive. Evaluation protocol Automatic evaluation: We first computed BLEU (Papineni et al., 2002) for each system using SacreBLEU (Post, 2018). For all language pairs except En→Ja, we used the original reference and SacreBLEU with the default options. In the case of En→Ja, we used the reference tokenized with KyTea and the option --tokenize none. We note that the automatic labelling using our various pre-processing techniques may have introduced errors, but we believe that basing the selection on such heuristics will still lead to higher chances of selecting very challenging source segments than arbitrarily sampling the data. Human evaluation: The system outputs were evaluated by professi"
2020.wmt-1.4,W17-3204,1,0.837046,"e evaluated both automatically and via a human evaluation and the results discussed in Section 5. We hope that this task leads to more efforts from the community in building robust MT models. Introduction In recent years, Machine Translation (MT) systems have seen great progress, with neural models becoming the de-facto methods and even approaching human quality in news domain (Hassan et al., 2018). However, like other deep learning models, neural machine translation (NMT) models are found to be sensitive to synthetic and natural noise in input, distributional shift, and adversarial examples (Koehn and Knowles, 2017; Belinkov and Bisk, 2018; Durrani et al., 2019; Anastasopoulos et al., 2019; Michel et al., 2019). From an application perspective, MT systems need to deal with non-standard, noisy text of the kind which is ubiquitous on social media and the internet, yet has different distributional signatures from corpora in common benchmark datasets. Following the first shared task on Machine Translation (MT) Robustness, we now propose a second edition, which aims at testing MT systems’ robustness towards domain diversity. Specifically, this year’s task aims to evaluate a general MT system’s performance in"
2020.wmt-1.4,W18-6459,0,0.0133196,"rvey of domain adaptation for neural MT, which demonstrates that the predominant setup assumes knowledge of the target domain and availability of target domain data at training time. In light of this prior work, the shared task proposed a relatively underexplored scenario, where examples in the target domain are either unavailable or relatively few. Other aspects of robustness are robustness to adversarial examples or noisy inputs. The fragility of neural MT models has been previously demonstrated in various settings (Belinkov and Bisk, 2018; Heigold et al., 2017; Anastasopoulos et al., 2019; Lee et al., 2018). Michel and Neubig (2018) proposed a new dataset (MTNT) to test MT models for robustness to the types of noise encountered in the Internet. The previous iteration of the shared task focused on robustness of MT systems to such noise (Li et al., 2019). We refer to that report for more details. 3 participants to explore novel training and modeling approaches so that models have more robust performance at test time on multiple domains, including unseen and diversified domains. We offer two language pairs: English-German (En→De) and English-Japanese (En→Ja), with different test sets focusing on on"
2020.wmt-1.4,W19-5303,1,0.901081,"e 5th Conference on Machine Translation (WMT), pages 76–91 c Online, November 19–20, 2020. 2020 Association for Computational Linguistics et al., 2017), to continuously fine-tune on datasets increasingly similar to the target domain (Sajjad et al., 2017), or to dynamically change the balance of data towards the target domain (van der Wees et al., 2017). Another approach trains a system on multiple domains at the same time, while adding domain-specific tags to the input examples (Kobus et al., 2016). Both these approaches were employed by participants of the first shared task on MT robustness (Li et al., 2019). Other methods for domain adaptation of MT systems include instance weighting (Wang et al., 2017b), incorporating a domain classifier (Chen et al., 2017; Britz et al., 2017), and data selection (Wang et al., 2017a). Some make use of monolingual data available either in the target domain—for example by training the decoder on such data (Domhan and Hieber, 2017) or by backtranslating it (Sennrich et al., 2016)—or in the source domain, via similar techniques (Zhang and Zong, 2016). Chu and Wang (2018) provide a broad survey of domain adaptation for neural MT, which demonstrates that the predomin"
2020.wmt-1.4,W18-6319,0,0.0156248,"or this particular model. In future work following this methodology, we recommend that multiple MT models be used. 4 https://cloud.google. com/natural-language/docs/ analyzing-sentiment 5 https://github.com/carpedm20/emoji/) 2 www.kaggle.com/c/ jigsaw-toxic-comment-classification- challenge 78 3.5 5. Presence of idioms: we checked if the source contains idiomatic expressions, using an inhouse list of idioms built from various sources, and labelled those cases as positive. Evaluation protocol Automatic evaluation: We first computed BLEU (Papineni et al., 2002) for each system using SacreBLEU (Post, 2018). For all language pairs except En→Ja, we used the original reference and SacreBLEU with the default options. In the case of En→Ja, we used the reference tokenized with KyTea and the option --tokenize none. We note that the automatic labelling using our various pre-processing techniques may have introduced errors, but we believe that basing the selection on such heuristics will still lead to higher chances of selecting very challenging source segments than arbitrarily sampling the data. Human evaluation: The system outputs were evaluated by professional translators. The translators were presen"
2020.wmt-1.4,E17-2045,0,0.0383395,"o domain shift assume the existence of significant amounts of parallel data in both the source and target domain. In this scenario, a common approach is to first train an MT system on a (generic) source domain and then to fine-tune it on a (specific) target domain (Luong and Manning, 2015; Freitag and Al-Onaizan, 2016; Servan et al., 2016; Chu 76 Proceedings of the 5th Conference on Machine Translation (WMT), pages 76–91 c Online, November 19–20, 2020. 2020 Association for Computational Linguistics et al., 2017), to continuously fine-tune on datasets increasingly similar to the target domain (Sajjad et al., 2017), or to dynamically change the balance of data towards the target domain (van der Wees et al., 2017). Another approach trains a system on multiple domains at the same time, while adding domain-specific tags to the input examples (Kobus et al., 2016). Both these approaches were employed by participants of the first shared task on MT robustness (Li et al., 2019). Other methods for domain adaptation of MT systems include instance weighting (Wang et al., 2017b), incorporating a domain classifier (Chen et al., 2017; Britz et al., 2017), and data selection (Wang et al., 2017a). Some make use of mono"
2020.wmt-1.4,2021.ccl-1.108,0,0.105338,"Missing"
2020.wmt-1.4,P16-1162,0,0.0120732,"ns at the same time, while adding domain-specific tags to the input examples (Kobus et al., 2016). Both these approaches were employed by participants of the first shared task on MT robustness (Li et al., 2019). Other methods for domain adaptation of MT systems include instance weighting (Wang et al., 2017b), incorporating a domain classifier (Chen et al., 2017; Britz et al., 2017), and data selection (Wang et al., 2017a). Some make use of monolingual data available either in the target domain—for example by training the decoder on such data (Domhan and Hieber, 2017) or by backtranslating it (Sennrich et al., 2016)—or in the source domain, via similar techniques (Zhang and Zong, 2016). Chu and Wang (2018) provide a broad survey of domain adaptation for neural MT, which demonstrates that the predominant setup assumes knowledge of the target domain and availability of target domain data at training time. In light of this prior work, the shared task proposed a relatively underexplored scenario, where examples in the target domain are either unavailable or relatively few. Other aspects of robustness are robustness to adversarial examples or noisy inputs. The fragility of neural MT models has been previously"
2020.wmt-1.4,2015.iwslt-evaluation.11,0,0.64331,"ims at testing MT systems’ robustness towards domain diversity. Specifically, this year’s task aims to evaluate a general MT system’s performance in the following two scenarios: 2 Related Work Domain mismatch is a key challenge in machine translation (Koehn and Knowles, 2017). Most approaches for improving robustness of MT systems to domain shift assume the existence of significant amounts of parallel data in both the source and target domain. In this scenario, a common approach is to first train an MT system on a (generic) source domain and then to fine-tune it on a (specific) target domain (Luong and Manning, 2015; Freitag and Al-Onaizan, 2016; Servan et al., 2016; Chu 76 Proceedings of the 5th Conference on Machine Translation (WMT), pages 76–91 c Online, November 19–20, 2020. 2020 Association for Computational Linguistics et al., 2017), to continuously fine-tune on datasets increasingly similar to the target domain (Sajjad et al., 2017), or to dynamically change the balance of data towards the target domain (van der Wees et al., 2017). Another approach trains a system on multiple domains at the same time, while adding domain-specific tags to the input examples (Kobus et al., 2016). Both these approac"
2020.wmt-1.4,N19-1314,1,0.844424,"hope that this task leads to more efforts from the community in building robust MT models. Introduction In recent years, Machine Translation (MT) systems have seen great progress, with neural models becoming the de-facto methods and even approaching human quality in news domain (Hassan et al., 2018). However, like other deep learning models, neural machine translation (NMT) models are found to be sensitive to synthetic and natural noise in input, distributional shift, and adversarial examples (Koehn and Knowles, 2017; Belinkov and Bisk, 2018; Durrani et al., 2019; Anastasopoulos et al., 2019; Michel et al., 2019). From an application perspective, MT systems need to deal with non-standard, noisy text of the kind which is ubiquitous on social media and the internet, yet has different distributional signatures from corpora in common benchmark datasets. Following the first shared task on Machine Translation (MT) Robustness, we now propose a second edition, which aims at testing MT systems’ robustness towards domain diversity. Specifically, this year’s task aims to evaluate a general MT system’s performance in the following two scenarios: 2 Related Work Domain mismatch is a key challenge in machine transla"
2020.wmt-1.4,D18-1050,1,0.940705,"tation for neural MT, which demonstrates that the predominant setup assumes knowledge of the target domain and availability of target domain data at training time. In light of this prior work, the shared task proposed a relatively underexplored scenario, where examples in the target domain are either unavailable or relatively few. Other aspects of robustness are robustness to adversarial examples or noisy inputs. The fragility of neural MT models has been previously demonstrated in various settings (Belinkov and Bisk, 2018; Heigold et al., 2017; Anastasopoulos et al., 2019; Lee et al., 2018). Michel and Neubig (2018) proposed a new dataset (MTNT) to test MT models for robustness to the types of noise encountered in the Internet. The previous iteration of the shared task focused on robustness of MT systems to such noise (Li et al., 2019). We refer to that report for more details. 3 participants to explore novel training and modeling approaches so that models have more robust performance at test time on multiple domains, including unseen and diversified domains. We offer two language pairs: English-German (En→De) and English-Japanese (En→Ja), with different test sets focusing on one or both these language p"
2020.wmt-1.4,2020.lrec-1.517,1,0.814412,"comments from the social media website reddit.com were scraped, filtered for noisy comments and translated by professional translators. This year, data was collected for two translation directions: English→Japanese and Japanese→English. For English, comments were collected from the /r/all feed, which encompasses all communities, and filtered for English. Since Japanese is a minority language on Reddit, comments were scraped from a selection of japanese-speaking communities, detailed in Michel and Neubig (2018). Common Voices Test Set (set3): This data was obtained from from the CoVoST corpus (Wang et al., 2020). CoVoST is derived from Common Voice (Ardila et al., 2020), a crowdsourced speech recognition corpus with an open CC0 license. Transcripts were sent to professional translators and the quality of translations was controlled by automatic and manual checks (Guzm´an et al., 2019). For this task, we used the German→English test set with source German sentences deduplicated. 1 Bad: translation errors are so severe that they cause the target text to be incomprehensible. This may be mainly due to major grammatical, typographical, or lexical errors, or omission of critical or important salient inform"
2020.wmt-1.4,N19-4007,1,0.808507,"as well as an analysis of catastrophic errors (Section 5.2). 5.1 General Quality Overall, the correlation between human judgments and BLEU is not strong. For En→De (set1), the Pearson’s correlation coefficient is 0.97, while for the other four tasks the coefficients are lower, with 0.78, 0.65, 0.52, 0.79 for En→De (set1), Ja→En (set2), En→Ja (set2), and De→En (set3) respectively. Automatic Evaluation The automatic evaluation (BLEU) results of the Shared Task are summarized in Table 2, where we also include the three online translation systems. We performed significance test using compare-mt (Neubig et al., 2019) where systems are considered as significantly different at p <0.05. The result of significance test is used for the automatic evaluation ranking. Overall, the unconstrained online-B system provides strong results and outperforms most systems in the five language pairs, except the De→En (set3) and En→Ja (set1). Among the participating teams, the best zeroshot systems were OPPO, which outperforms other zero-shot systems in En→De (set1), Ja→En (set2), and En→Ja (set2) tasks, and NLE, which outperforms other systems in the other two tasks. Only Naver Labs participated in the few-shot stage (NLE-f"
2020.wmt-1.4,P17-2089,0,0.0494679,"Missing"
2020.wmt-1.4,D17-1155,0,0.0161114,"Association for Computational Linguistics et al., 2017), to continuously fine-tune on datasets increasingly similar to the target domain (Sajjad et al., 2017), or to dynamically change the balance of data towards the target domain (van der Wees et al., 2017). Another approach trains a system on multiple domains at the same time, while adding domain-specific tags to the input examples (Kobus et al., 2016). Both these approaches were employed by participants of the first shared task on MT robustness (Li et al., 2019). Other methods for domain adaptation of MT systems include instance weighting (Wang et al., 2017b), incorporating a domain classifier (Chen et al., 2017; Britz et al., 2017), and data selection (Wang et al., 2017a). Some make use of monolingual data available either in the target domain—for example by training the decoder on such data (Domhan and Hieber, 2017) or by backtranslating it (Sennrich et al., 2016)—or in the source domain, via similar techniques (Zhang and Zong, 2016). Chu and Wang (2018) provide a broad survey of domain adaptation for neural MT, which demonstrates that the predominant setup assumes knowledge of the target domain and availability of target domain data at traini"
2020.wmt-1.4,D17-1147,0,0.0351203,"Missing"
2020.wmt-1.4,D16-1160,0,0.025774,"ples (Kobus et al., 2016). Both these approaches were employed by participants of the first shared task on MT robustness (Li et al., 2019). Other methods for domain adaptation of MT systems include instance weighting (Wang et al., 2017b), incorporating a domain classifier (Chen et al., 2017; Britz et al., 2017), and data selection (Wang et al., 2017a). Some make use of monolingual data available either in the target domain—for example by training the decoder on such data (Domhan and Hieber, 2017) or by backtranslating it (Sennrich et al., 2016)—or in the source domain, via similar techniques (Zhang and Zong, 2016). Chu and Wang (2018) provide a broad survey of domain adaptation for neural MT, which demonstrates that the predominant setup assumes knowledge of the target domain and availability of target domain data at training time. In light of this prior work, the shared task proposed a relatively underexplored scenario, where examples in the target domain are either unavailable or relatively few. Other aspects of robustness are robustness to adversarial examples or noisy inputs. The fragility of neural MT models has been previously demonstrated in various settings (Belinkov and Bisk, 2018; Heigold et"
2021.acl-long.144,2020.acl-main.493,0,0.0145923,"el, but does not inform one of how the model does this or which components are responsible for the observed behavior. 2.2 Probing A separate line of analysis work has investigated representations associated with syntactic dependencies by defining a family of functions (probes) that map from model representations to some phenomenon that those representations are expected to encode. For instance, several studies have mapped LM representations to either independent syntactic dependencies (Belinkov, 2018; Liu et al., 2019; Tenney et al., 2019b) or full dependency parses (Hewitt and Manning, 2019; Chi et al., 2020) as a proxy for discovering latent syntactic knowledge within the model. Most related, Giulianelli et al. (2018) use probes to investigate how LSTMs handle agreement. Probing is more difficult to interpret than behavioral approaches because the addition of a trained classifier introduces confounds (Hewitt and Liang, 2019): most notably, whether the probe maps from model representations to the desired output, or learns the task itself. Probes also only give correlational evidence, rather than causal evidence (Belinkov and Glass, 2019). See Belinkov (2021) for a review of the shortcomings of pro"
2021.acl-long.144,P19-1285,0,0.0713695,"Missing"
2021.acl-long.144,N19-1112,1,0.815376,"inflection given the same context. This approach investigates the output behavior of the model, but does not inform one of how the model does this or which components are responsible for the observed behavior. 2.2 Probing A separate line of analysis work has investigated representations associated with syntactic dependencies by defining a family of functions (probes) that map from model representations to some phenomenon that those representations are expected to encode. For instance, several studies have mapped LM representations to either independent syntactic dependencies (Belinkov, 2018; Liu et al., 2019; Tenney et al., 2019b) or full dependency parses (Hewitt and Manning, 2019; Chi et al., 2020) as a proxy for discovering latent syntactic knowledge within the model. Most related, Giulianelli et al. (2018) use probes to investigate how LSTMs handle agreement. Probing is more difficult to interpret than behavioral approaches because the addition of a trained classifier introduces confounds (Hewitt and Liang, 2019): most notably, whether the probe maps from model representations to the desired output, or learns the task itself. Probes also only give correlational evidence, rather than causal ev"
2021.acl-long.144,N19-1002,0,0.252743,"example, which demonstrates subject-verb agreement across an agreement attractor. Here, a model using a linear ∗ Equal contribution. Work done while visiting Google Research. ‡ Supported by the Viterbi Fellowship in the Center for Computer Engineering at the Technion. † While we have a reasonable understanding of the generally correct behavior of LMs in such contexts, the mechanisms that underlie models’ sensitivity to syntactic agreement are still not well understood. Recent work has performed causal analyses of syntactic agreement units in LSTM (Hochreiter and Schmidhuber, 1997)-based LMs (Lakretz et al., 2019; Lu et al., 2020) or causal analyses of LSTM hidden representations’ impact on syntactic agreement (Giulianelli et al., 2018), but the agreement mechanisms of Transformer-based LMs have not been as extensively investigated. Transformerbased LMs’ syntactic generalization abilities are superior to those of LSTMs (Hu et al., 2020), which makes Transformer-based models enticing candidates for further analysis. We apply the behavioral-structural method of causal mediation analysis (Pearl, 2001) to investigate syntactic agreement in Transformers, following the approach used by Vig et al. (2020a) fo"
2021.acl-long.144,D18-1151,1,0.857953,"d that language models rely on similar sets of neurons when given sentences with similar syntactic structure. 1 (1) The key to the cabinets is/*are next to the coins. Introduction Targeted syntactic evaluations have shown that neural language models (LMs) are able to predict the correct token from a set of grammatically minimally different continuations with high accuracy, even in difficult contexts (Linzen et al., 2016; Gulordava et al., 2018), for constructions such as subject-verb agreement (van Schijndel et al., 2019), filler-gap dependencies (Wilcox et al., 2018), and reflexive anaphora (Marvin and Linzen, 2018). As an illustration of the targeted syntactic evaluation paradigm, consider the following example, which demonstrates subject-verb agreement across an agreement attractor. Here, a model using a linear ∗ Equal contribution. Work done while visiting Google Research. ‡ Supported by the Viterbi Fellowship in the Center for Computer Engineering at the Technion. † While we have a reasonable understanding of the generally correct behavior of LMs in such contexts, the mechanisms that underlie models’ sensitivity to syntactic agreement are still not well understood. Recent work has performed causal an"
2021.acl-long.144,2020.acl-main.490,1,0.768172,"well with human intuitions of syntactic similarity between structures. 2 2.1 Related Work Targeted Syntactic Evaluation Many recent studies have treated neural LMs and contextualized word prediction models—primarily LSTM LMs (Sundermeyer et al., 2012), GPT2 (Radford et al., 2019), and BERT (Devlin et al., 2019)—as psycholinguistic subjects to be studied behaviorally (Linzen et al., 2016; Gulordava et al., 2018; Goldberg, 2019). Some have studied whether models prefer grammatical completions in subjectverb agreement contexts (Marvin and Linzen, 2018; van Schijndel et al., 2019; Goldberg, 2019; Mueller et al., 2020; Lakretz et al., 2021; Futrell et al., 2019), as well as in filler-gap dependencies (Wilcox et al., 2018, 2019). These are based on the approach of Linzen et al. (2016), where a model’s ability to syntactically generalize is measured by its ability to choose the correct inflection in difficult structural contexts instantiated by tokens that the model has not seen together during training. In other words, this approach tests whether the model assigns the correct inflection a higher probability than an incorrect inflection given the same context. This approach investigates the output behavior o"
2021.acl-long.144,2021.naacl-main.290,0,0.031086,"sal mediation analysis to discover and interpret the mechanisms behind syntactic agreement in pre-trained neural language models. Our results reveal the location and importance of various neurons within various models, and provide insights into the inner workings of these LMs. For future work, we suggest intervening on groups of neurons and attention heads to see how these components work together, and extending the analysis to phenomena such as filler-gap dependencies and negative polarity items. Further work should also explore the impact of specific verbs on syntactic agreement mechanisms (Newman et al., 2021). Lastly, we suggest examining examples where the model makes incorrect predictions to determine how models misuse the mechanisms from Section 6.1. Acknowledgements Y.B. was supported in part by the ISRAEL SCIENCE FOUNDATION (grant no. 448/20) and by an Azrieli Foundation Early Career Faculty Fellowship. A.M. was supported by a National Science Foundation Graduate Research Fellowship (grant no. 1746891). 1836 Impact Statement chine Translation and Speech Recognition. Ph.D. thesis, Massachusetts Institute of Technology. In this paper, we apply causal mediation analysis in order to study the sub"
2021.acl-long.144,D19-1592,1,0.931743,"ment in Transformers, following the approach used by Vig et al. (2020a) for interpreting gender bias in pre-trained English LMs. This method allows us to implicate specific model components in the observed behavior of a model. If we view a neural LM as a causal graph proceeding from inputs to outputs, we can view each model component (e.g., a neuron) as a mediator. We measure the contribution of a mediator to the observed output behavior by performing controlled interventions on input sentences and observing how they change the probabilities of continuation pairs. We focus primarily on GPT-2 (Radford et al., 2019), although we also analyze TransformerXL (Dai et al., 1828 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 1828–1843 August 1–6, 2021. ©2021 Association for Computational Linguistics 2019) and XLNet (Yang et al., 2019). We find that both GPT-2 and Transformer-XL use two distinct mechanisms to accomplish subjectverb agreement, one of which is active only when the subject and verb are adjacent. Conversely, XLNet uses one unified mechanism across syntactic structures. Even tho"
2021.acl-long.144,2021.emnlp-main.230,0,0.0821816,"Missing"
2021.acl-long.144,P19-1452,0,0.0617523,"the same context. This approach investigates the output behavior of the model, but does not inform one of how the model does this or which components are responsible for the observed behavior. 2.2 Probing A separate line of analysis work has investigated representations associated with syntactic dependencies by defining a family of functions (probes) that map from model representations to some phenomenon that those representations are expected to encode. For instance, several studies have mapped LM representations to either independent syntactic dependencies (Belinkov, 2018; Liu et al., 2019; Tenney et al., 2019b) or full dependency parses (Hewitt and Manning, 2019; Chi et al., 2020) as a proxy for discovering latent syntactic knowledge within the model. Most related, Giulianelli et al. (2018) use probes to investigate how LSTMs handle agreement. Probing is more difficult to interpret than behavioral approaches because the addition of a trained classifier introduces confounds (Hewitt and Liang, 2019): most notably, whether the probe maps from model representations to the desired output, or learns the task itself. Probes also only give correlational evidence, rather than causal evidence (Belinkov and"
2021.acl-long.144,W18-5423,0,0.0872603,"ructure of the input sentence. Finally, we find that language models rely on similar sets of neurons when given sentences with similar syntactic structure. 1 (1) The key to the cabinets is/*are next to the coins. Introduction Targeted syntactic evaluations have shown that neural language models (LMs) are able to predict the correct token from a set of grammatically minimally different continuations with high accuracy, even in difficult contexts (Linzen et al., 2016; Gulordava et al., 2018), for constructions such as subject-verb agreement (van Schijndel et al., 2019), filler-gap dependencies (Wilcox et al., 2018), and reflexive anaphora (Marvin and Linzen, 2018). As an illustration of the targeted syntactic evaluation paradigm, consider the following example, which demonstrates subject-verb agreement across an agreement attractor. Here, a model using a linear ∗ Equal contribution. Work done while visiting Google Research. ‡ Supported by the Viterbi Fellowship in the Center for Computer Engineering at the Technion. † While we have a reasonable understanding of the generally correct behavior of LMs in such contexts, the mechanisms that underlie models’ sensitivity to syntactic agreement are still not we"
2021.acl-long.144,N19-1334,0,0.039094,"Missing"
2021.eacl-main.295,K19-1033,1,0.843684,"ed to address this limitation: 1) Diagnostic examples, where a small number of samples in a test set are annotated with linguistic phenomena of interest, and task accuracy is reported on these samples (Williams et al., 2018; Joshi et al., 2020). However, it is difficult to determine if models perform well on diagnostic examples because they actually learn the linguistic competency, or if they exploit spurious correlations in the data (McCoy et al., 2019; Gururangan et al., 2018; Poliak et al., 2018). 2) External challenge tests (Naik et al., 2018; Isabelle et al., 2017; Glockner et al., 2018; Ravichander et al., 2019; McCoy et al., 2019), where examples are constructed, either through automatic methods or by experts, exercising a specific phenomenon in isolation. However, it is challenging and expensive to build these evaluations, and non-trivial to isolate phenomena (Liu et al., 2019). Thus, probing or diagnostic classification presents a compelling alternative, wherein learned representations can directly be probed for linguistic properties of interest (Ettinger et al., 2016; Be3364 linkov et al., 2017; Adi et al., 2017; Tenney et al., 2019; Zhang and Bowman, 2018; Warstadt et al., 2019). There has been"
2021.eacl-main.295,2020.nlp4convai-1.15,1,0.842062,"for the auxiliary task— predicting the tense of the verb in the main clause of the sentence. A separate classifier, henceforth called the probing classifier, is trained to predict this property based on the constructed representation. The probing task itself is typically selected to be relevant to the training task, and high probing performance is considered as evidence that the property is encoded in the learned representation. Due to its simplicity, a growing body of work uses this approach to pinpoint the information models rely on to do a task (Alt et al., 2020; Giulianelli et al., 2018; Saleh et al., 2020). In this work, we examine the connection between the information encoded in a representation and the information a model relies on. Through a set of carefully designed experiments on the benchmark SentEval probing framework (Conneau et al., 2018), we shed light on information use in neural models. Our story unfolds in four parts: 1. First, we establish careful control versions of the training task such that task performance is invariant to a chosen linguistic property (Figure 1). We show that even when models cannot use a linguistic property to perform the task, the property can be reliably r"
2021.eacl-main.295,D16-1159,0,0.0320055,"a specific phenomenon in isolation. However, it is challenging and expensive to build these evaluations, and non-trivial to isolate phenomena (Liu et al., 2019). Thus, probing or diagnostic classification presents a compelling alternative, wherein learned representations can directly be probed for linguistic properties of interest (Ettinger et al., 2016; Be3364 linkov et al., 2017; Adi et al., 2017; Tenney et al., 2019; Zhang and Bowman, 2018; Warstadt et al., 2019). There has been a variety of research that employs probing to test hypotheses about the mechanisms models used to perform tasks. Shi et al. (2016) examine learned representations in machine translation for syntactic knowledge. Vanmassenhove et al. (2017) investigate aspect in neural machine translation systems, finding that tense information could be extracted from the encoder, but that part of this information may be lost when decoding. Conneau et al. (2018) use probing to examine the correlation between linguistic properties and downstream tasks (including MT and NLI). Hupkes et al. (2018) train a ’diagnostic classifier’ to extract information from a sequence of hidden representations in a neural network. If the classifier achieves hi"
2021.eacl-main.295,D14-1162,0,0.0861278,"c training. We can observe that probing performance decreases sharply for all models when word embeddings are randomly initialized, suggesting a considerable component of probing performance comes from pretraining word embeddings rather than what a model learns during the task. present in word embeddings, and proposed methods to measure this effect, such as comparing with bag-of-word baselines or random encoders (Wieting and Kiela, 2018). However, these methods fail to isolate the contribution of the training task. To study this, we compare models initialized with pre-trained word embeddings (Pennington et al., 2014) and then trained for the main task, to models initialized with random word embeddings and then updated during the main task. These results are presented in Table 3. We observe that probing accuracies drop across linguistic properties in this setting (compare rows with Word and Rand in the table), indicating that models with randomly initialized embeddings generate representations that contain less linguistic information than the models with pretrained embeddings. This result calls into question how to interpret the contribution of the main task to the encoding of a linguistic property, when t"
2021.eacl-main.295,2020.acl-main.420,0,0.0220406,". (2019) study what different NLP tasks teach models about function word comprehension. Alt et al. (2020) analyze learned representations in relation extraction, through a set of fourteen probing tasks for relevant linguistic properties. Saleh et al. (2020) examine the representations learned by neural dialog models for insights into what the model learns about engaging in dialog. See the survey by Belinkov and Glass (2019) for many more examples. Closely related to our work is that of Hewitt and Liang (2019), which studies the role of lexical memorization in probing, and recently the work of Pimentel et al. (2020) and Voita and Titov (2020) who analyze probing from an information-theoretic perspective. These works join an ongoing debate on the correct way to characterize the expressivity of the probing classifier, with the latter proposing ease of extractability as a criterion for selecting appropriate probes. Our work pursues an orthogonal line of inquiry, demonstrating that relying on diagnostic classifiers to interpret model reasoning for a task suffers from a fundamental limitation: properties may be incidentally encoded even when not required for a task. Thus, our work is also related to a broader"
2021.eacl-main.295,S18-2023,0,0.0576668,"Missing"
2021.eacl-main.295,D16-1264,0,0.0407401,"led synthetic scenario we demonstrate that neural models can encode information incidentally, even if it is distributed as random noise with respect to the training task (§5). We discuss several considerations when interpreting the results of probing experiments and highlight avenues for future research needed in this important area of understanding models, tasks and datasets (§6). 2 Background and Related Work Progress in Natural Language Understanding (NLU) has been driven by a history of defining tasks and corresponding benchmarks for the community (Marcus et al., 1993; Dagan et al., 2006; Rajpurkar et al., 2016). These tasks are often tied to specific practical applications, or to developing models demonstrating competencies that transfer across applications. The corresponding benchmark datasets are utilized as proxies for the tasks themselves. How can we estimate their quality as proxies? While annotation artifacts are one facet that affects proxy-quality (Gururangan et al., 2018; Poliak et al., 2018; Kaushik and Lipton, 2018; Naik et al., 2018; Glockner et al., 2018), a dataset might simply not have coverage across competencies required for a task. Additionally, it might consist of alternate “expla"
2021.eacl-main.295,D19-1448,0,0.0186393,"ctive. These works join an ongoing debate on the correct way to characterize the expressivity of the probing classifier, with the latter proposing ease of extractability as a criterion for selecting appropriate probes. Our work pursues an orthogonal line of inquiry, demonstrating that relying on diagnostic classifiers to interpret model reasoning for a task suffers from a fundamental limitation: properties may be incidentally encoded even when not required for a task. Thus, our work is also related to a broader investigation of how neural models encode information (Tishby and Zaslavsky, 2015; Voita et al., 2019), studying to what extent information encoded in neural representations is indicative of information needed to perform tasks. 3 Methodology In this section we describe our modified probing pipeline (Figure 1), where we construct control datasets, such that a particular linguistic feature is not required in making task judgements.2 Control datasets are based on the intuition that a linguistic feature is not informative for a model to discriminate between classes if the linguistic feature remains constant across classes. For a task label T and linguistic property L, when every example in the con"
2021.eacl-main.295,2020.emnlp-main.14,0,0.0173423,"nt NLP tasks teach models about function word comprehension. Alt et al. (2020) analyze learned representations in relation extraction, through a set of fourteen probing tasks for relevant linguistic properties. Saleh et al. (2020) examine the representations learned by neural dialog models for insights into what the model learns about engaging in dialog. See the survey by Belinkov and Glass (2019) for many more examples. Closely related to our work is that of Hewitt and Liang (2019), which studies the role of lexical memorization in probing, and recently the work of Pimentel et al. (2020) and Voita and Titov (2020) who analyze probing from an information-theoretic perspective. These works join an ongoing debate on the correct way to characterize the expressivity of the probing classifier, with the latter proposing ease of extractability as a criterion for selecting appropriate probes. Our work pursues an orthogonal line of inquiry, demonstrating that relying on diagnostic classifiers to interpret model reasoning for a task suffers from a fundamental limitation: properties may be incidentally encoded even when not required for a task. Thus, our work is also related to a broader investigation of how neura"
2021.eacl-main.295,D19-1286,0,0.0160416,"et al., 2018; Ravichander et al., 2019; McCoy et al., 2019), where examples are constructed, either through automatic methods or by experts, exercising a specific phenomenon in isolation. However, it is challenging and expensive to build these evaluations, and non-trivial to isolate phenomena (Liu et al., 2019). Thus, probing or diagnostic classification presents a compelling alternative, wherein learned representations can directly be probed for linguistic properties of interest (Ettinger et al., 2016; Be3364 linkov et al., 2017; Adi et al., 2017; Tenney et al., 2019; Zhang and Bowman, 2018; Warstadt et al., 2019). There has been a variety of research that employs probing to test hypotheses about the mechanisms models used to perform tasks. Shi et al. (2016) examine learned representations in machine translation for syntactic knowledge. Vanmassenhove et al. (2017) investigate aspect in neural machine translation systems, finding that tense information could be extracted from the encoder, but that part of this information may be lost when decoding. Conneau et al. (2018) use probing to examine the correlation between linguistic properties and downstream tasks (including MT and NLI). Hupkes et al. (2018)"
2021.eacl-main.295,N18-1101,0,0.564763,"bing (Conneau et al., 2018), auxiliary prediction tasks (Adi et al., 2017) and diagnostic classification (Veldhoen et al., 2016; Hupkes et al., 2018). As an example of this approach, let us walk through an application to analyze information about tense stored in a Natural Language Inference (NLI) model. In Conneau et al. (2018), three sentence-encoder models are trained on a 3363 Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics, pages 3363–3377 April 19 - 23, 2021. ©2021 Association for Computational Linguistics NLI dataset (MultiNLI; Williams et al., 2018). The encoder weights are frozen, and the encoders are then used to form sentence representations for the auxiliary task— predicting the tense of the verb in the main clause of the sentence. A separate classifier, henceforth called the probing classifier, is trained to predict this property based on the constructed representation. The probing task itself is typically selected to be relevant to the training task, and high probing performance is considered as evidence that the property is encoded in the learned representation. Due to its simplicity, a growing body of work uses this approach to p"
2021.eacl-main.295,W18-5448,0,0.014751,"et al., 2017; Glockner et al., 2018; Ravichander et al., 2019; McCoy et al., 2019), where examples are constructed, either through automatic methods or by experts, exercising a specific phenomenon in isolation. However, it is challenging and expensive to build these evaluations, and non-trivial to isolate phenomena (Liu et al., 2019). Thus, probing or diagnostic classification presents a compelling alternative, wherein learned representations can directly be probed for linguistic properties of interest (Ettinger et al., 2016; Be3364 linkov et al., 2017; Adi et al., 2017; Tenney et al., 2019; Zhang and Bowman, 2018; Warstadt et al., 2019). There has been a variety of research that employs probing to test hypotheses about the mechanisms models used to perform tasks. Shi et al. (2016) examine learned representations in machine translation for syntactic knowledge. Vanmassenhove et al. (2017) investigate aspect in neural machine translation systems, finding that tense information could be extracted from the encoder, but that part of this information may be lost when decoding. Conneau et al. (2018) use probing to examine the correlation between linguistic properties and downstream tasks (including MT and NLI"
2021.emnlp-main.116,N19-1423,0,0.0302793,"10 20 30 40 50 ∆ Robustness Figure 1: Amount of subsequence bias extracted from different language models vs. the robustness of models to the bias. Robustness is measured as improvement of the model on out-of-distribution examples, while extractability is measured as the improvement of the probe’s ability to extract the bias from a debiased model, compared to the baseline. Introduction 2021, inter alia). Then, the resulting model is evaluated on out-of-distribution (o.o.d) data, in the form State of the art neural language models such as of challenge datasets containing “hard” examples BERT (Devlin et al., 2019) usually work by prethat were deliberately constructed to be anti-biased. training an encoder to learn universal word repreExamples of such datasets include HANS (McCoy sentations, and then fine-tuning it on some classifiet al., 2019) for natural language inference (NLI) cation or regression task. From a robustness point and FEVER-Symmetric (Schuster et al., 2019) for of view, such pretrain-and-fine-tune pipelines are fact verification. An underlying assumption behind known to be prone to biases that are present in data this methodology is that better generalization out (Gururangan et al., 201"
2021.emnlp-main.116,W19-3621,0,0.0159944,"ry subtle and generally within standard deviation bounds. This suggests that while debiasing does not make linguistic information measured in these probing tasks less extractable, it also does not substantially amplify it, as opposed to extractability of bias information. 6 Discussion and Conclusion els, and consider the problem of finding robust, bias-free feature detectors. Another domain where this finding may be alarming is social bias. Previous studies show that word vectors contain social bias (Caliskan et al., 2017), and that debiasing them does not necessarily remove this information (Gonen and Goldberg, 2019). Our work shows that debiasing sometimes increases the information available about bias in the representations, albeit in the context of dataset bias rather than social bias. All of our experiments tested model-based debiasing, where a weak learner is used to capture biased features and discourage their use in model Our work shows that unbiased predictions =⇒ predictions. We discover that for both explicit and biased representations. We speculate that there eximplicit modeling of the bias, this method exposes ists a proxy for the language model that removes the biased features in the represen"
2021.emnlp-main.116,N10-1000,0,0.0400411,"Missing"
2021.emnlp-main.116,N18-2017,0,0.0493636,"Missing"
2021.emnlp-main.116,D19-6115,0,0.0710474,"model the biases during training, by minimizing a loss Lb . The objective of the combination model is to minimize a combined loss function Lc (θm , θb ), such that the main model leverages knowledge about bias in data, obtained using the weak model. This pipeline is general, and it allows models to be trained either end-to-end, or step-by-step by first training the bias model and then using its predictions to robustly train the main model. Recent papers show that such techniques are effective when evaluated on challenge datasets specifically designed to target known biases and hard examples (He et al., 2019; Clark et al., 2019; Utama et al., 2020b,a; Sanh et al., 2021; Mahabadi et al., 2020). However, this approach does not ensure that the model indeed learns more robust features, nor does it shed light on exactly how the feature detectors react to this change, and how the bias is represented in the model. Deep neural models are prone to shortcut learning (Geirhos et al., 2020), by discovering and using idiosyncratic biases, heuristics, and statistical cues in the data. For example, Poliak et al. (2018) showed that the Stanford natural language inference dataset (SNLI; Bowman et al. 2015) contai"
2021.emnlp-main.116,D19-1275,0,0.0207378,"show that such models capture surface features such as sentence length, word content, and the order of words (Adi et al., 2017), or various syntactic and semantic features (Conneau et al., 2018); see Belinkov and Glass (2019) for a survey. In contrast, we focus our analysis on biased features, and employ advances in probing methodology to analyze two kinds of bias—lexical overlap and negation bias. Designing probes to accurately interpret the desired behavior is not trivial and measuring their accuracy is insufficient, since the probing classifiers are prone to memorization and bias as well (Hewitt and Liang, 2019), among other shortcomings (Belinkov, 2021). Recently, Voita and Titov (2020) presented an information-theoretic approach for evaluating probing classifiers, which accounts for the complexity of the probing classifier by measuring its minimum description length (MDL). MDL measures how efficiently a model can extract information about the labels from the inputs, and we use it as a measure of extractability of certain biases from model representations. 3 Methods We lay down a general framework for interpreting bias in inner model representations. Given a model fθ : X → Y with learnable parameter"
2021.emnlp-main.116,2020.acl-main.769,1,0.906658,"he combination model is to minimize a combined loss function Lc (θm , θb ), such that the main model leverages knowledge about bias in data, obtained using the weak model. This pipeline is general, and it allows models to be trained either end-to-end, or step-by-step by first training the bias model and then using its predictions to robustly train the main model. Recent papers show that such techniques are effective when evaluated on challenge datasets specifically designed to target known biases and hard examples (He et al., 2019; Clark et al., 2019; Utama et al., 2020b,a; Sanh et al., 2021; Mahabadi et al., 2020). However, this approach does not ensure that the model indeed learns more robust features, nor does it shed light on exactly how the feature detectors react to this change, and how the bias is represented in the model. Deep neural models are prone to shortcut learning (Geirhos et al., 2020), by discovering and using idiosyncratic biases, heuristics, and statistical cues in the data. For example, Poliak et al. (2018) showed that the Stanford natural language inference dataset (SNLI; Bowman et al. 2015) contains “give-away” words, i.e., words w which have a high value of p (l |w) w.r.t a given"
2021.emnlp-main.116,2020.blackboxnlp-1.21,0,0.026532,"ompression of the probing classifier and Acc is the accuracy. HANS− identifies the performance of the original model on the relevant subset of nonentailed samples in HANS: (1) the lexical overlap subset for Overlap, (2) the subsequence subset for Subsequence. We report results for models with different bias models: (1) explicit bias-only model with lexical overlap features, (2) implicit bias model with subsampling (Subset), and (3) implicit TinyBERT bias model (Tiny). and standard deviations, to account for known variability of fine-tuned models, espeically when evaluated out of distribution (McCoy et al., 2020). We reimplement all debiasing methods in a unified codebase to facilitate a fair comparison. Training details are available in Appendix A.4. Baselines We use the standard base BERT implementation of Wolf et al. (2020). We take the pretrained model without further fine-tuning on any downstream task (denoted as Pretrained) and we also fine-tune the model on the target dataset (Base). To obtain a lower bound on the performance of these models, we take the same model and randomly initialize its weights (Random). 5 Results indicating that the more successful a method is in debiasing model predicti"
2021.emnlp-main.116,S18-2023,0,0.0599076,"Missing"
2021.emnlp-main.116,D19-1341,0,0.160089,"he baseline. Introduction 2021, inter alia). Then, the resulting model is evaluated on out-of-distribution (o.o.d) data, in the form State of the art neural language models such as of challenge datasets containing “hard” examples BERT (Devlin et al., 2019) usually work by prethat were deliberately constructed to be anti-biased. training an encoder to learn universal word repreExamples of such datasets include HANS (McCoy sentations, and then fine-tuning it on some classifiet al., 2019) for natural language inference (NLI) cation or regression task. From a robustness point and FEVER-Symmetric (Schuster et al., 2019) for of view, such pretrain-and-fine-tune pipelines are fact verification. An underlying assumption behind known to be prone to biases that are present in data this methodology is that better generalization out (Gururangan et al., 2018; Poliak et al., 2018; Mcof distribution also means that the model learned Coy et al., 2019; Schuster et al., 2019). Various more robust features. However, while evaluation methods were proposed to mitigate such biases in using challenge datasets only relays information a form of robust training, where a bias model is about the generalization of the model through"
2021.emnlp-main.116,N18-1101,0,0.0242553,"a given dataset, according to the probing property. Since in all our datasets the positive class (biased samples) is the minority class, we subsample the same amount of samples from the remaining subset (the majority class). We end up with a balanced probing dataset. This ensures that when splitting the data during online code training, and when measuring performance on the entire dataset, the process is unaffected by the bias evidence, that is, the amount of bias in the original dataset. The probing datasets are constructed from three base NLU datasets: SNLI (Bowman et al., 2015), MultiNLI (Williams et al., 2018) and FEVER (Thorne et al., 2018), following the original train/validation/test splits.5 Inspired by previous work on biases in NLU datasets (Section 2), we construct NegWords probing datasets from all three base NLU datasets and Overlap/Subsequence probing datasets from SNLI and MNLI. The dataset statistics are presented in Table 1. Task Dataset Train Valid Test SNLI 25104 484 456 NegWords MNLI 126232 3180 3246 FEVER 19874 2180 – Overlap SNLI MNLI 35388 18542 734 518 732 464 Sub. SNLI MNLI 4438 5432 234 202 226 154 Table 1: Number of samples in all probing datasets created from the different b"
2021.emnlp-main.116,N18-1074,0,0.028807,"Missing"
2021.emnlp-main.116,2020.acl-main.770,0,0.374576,"osed to mitigate such biases in using challenge datasets only relays information a form of robust training, where a bias model is about the generalization of the model through pretrained to capture the bias and then used to relax dictions, it does not reveal what actually caused it the predictions of a main model, so that it can focus and how the internal representations were affected. less on biased examples and more on the “hard”, To assess whether bias has been removed from more challenging examples (Clark et al., 2019; Mathe internal representations, we design probing habadi et al., 2020; Utama et al., 2020b; Sanh et al., tasks targeting several known biases: lexical over∗ Supported by the Viterbi Fellowship in the Center for lap biases and negative word bias. While probing is Computer Engineering at the Technion. 1 Our code and data are available at: https://github. usually concerned with simple linguistic properties com/technion-cs-nlp/bias-probing. such as part-of-speech tags (Belinkov and Glass, 1545 Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 1545–1557 c November 7–11, 2021. 2021 Association for Computational Linguistics 2019), we instead de"
2021.emnlp-main.116,2020.emnlp-main.613,0,0.486964,"osed to mitigate such biases in using challenge datasets only relays information a form of robust training, where a bias model is about the generalization of the model through pretrained to capture the bias and then used to relax dictions, it does not reveal what actually caused it the predictions of a main model, so that it can focus and how the internal representations were affected. less on biased examples and more on the “hard”, To assess whether bias has been removed from more challenging examples (Clark et al., 2019; Mathe internal representations, we design probing habadi et al., 2020; Utama et al., 2020b; Sanh et al., tasks targeting several known biases: lexical over∗ Supported by the Viterbi Fellowship in the Center for lap biases and negative word bias. While probing is Computer Engineering at the Technion. 1 Our code and data are available at: https://github. usually concerned with simple linguistic properties com/technion-cs-nlp/bias-probing. such as part-of-speech tags (Belinkov and Glass, 1545 Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 1545–1557 c November 7–11, 2021. 2021 Association for Computational Linguistics 2019), we instead de"
C16-1163,C16-1237,1,0.746099,"Missing"
C16-1163,P15-2114,0,0.0146485,". Table 1: A re-ranking example: we report the Google rank (G), the gold standard relevance (GS) and our rank (R) for each question. et al., 2016), which exploits tree kernel function itself to auto-filter the non relevant subtrees. The main difference with the approach we present in the current paper is the use of neural networks for learning attention weights and thus modeling sentence or word pruning. Neural Approaches Recent work has shown the effectiveness of neural models for answer selection (Severyn and Moschitti, 2015; Tan et al., 2015; Feng et al., 2015) and question similarity (dos Santos et al., 2015) in community question answering. For instance, dos Santos et al. (2015) used CNN and bag-of-words (BOW) representations of original and related questions in order to compute cosine similarity scores. Recently, Bahdanau et al. (2014) presented a neural attention model for machine translation and showed that the attention mechanism is helpful for addressing long sentences. We use an LSTM model (Hochreiter and Schmidhuber, 1997) with an attention mechanism for capturing long dependencies in questions for the question similarity task. The major difference with previous work is that we exploit the"
C16-1163,P08-1019,0,0.0283351,"s our learning-to-rank approach. Section 4 describes the application of LSTMs in TK-based ranking models. Section 5 describes our text selection strategies. Section 6 discusses our experiments and the obtained results. Finally, Section 7 concludes the paper. 2 Related Work Question ranking in cQA has been central in the research community practically since the begining of cQA system design. Beside “standard” similarity measures, different characterizations and models have been explored. For instance, Cao et al. (2008) proposed a question recommendation system based on the questions’ topic and Duan et al. (2008) added the question’s focus into the formula. A different approach using topic modeling for question retrieval was introduced by Ji et al. (2012) and Zhang et al. (2014). Here, the authors use LDA topic modeling to learn the latent semantic topics that generate question/answer pairs and use the learned topic distribution to retrieve similar historical questions. Various methods rely on machine-translation models. For instance, Jeon et al. (2005) and Zhou et al. (2011) used monolingual phrase-based translation models to compare the questions. Jeon et al. (2005) built their translator from a col"
C16-1163,P15-1097,1,0.787031,"ranslation models to compare the questions. Jeon et al. (2005) built their translator from a collection of previously identified similar questions whereas Zhou et al. (2011) used question–answer pairs. Other approaches are based on syntactic representations. This is the case of Wang et al. (2009), who consider the number of common substructures of parse trees to estimate the similarity between two questions. Both Barr´on-Cede˜no et al. (2016) and Filice et al. (2016) use parse trees as well. The difference is that they use them directly within a tree kernel, with the use of the KeLP platform (Filice et al., 2015a). The latter two models were applied on the SemEval 2016 Task 3 challenge on cQA (Nakov et al., 2016), which proposed a task on question ranking (together with one on answer ranking). The best-performing system in this task was the one from Franco-Salvador et al. (2016), which used SVMrank (Joachims, 2006) on a manifold of features, including distributed representations and semantic resources. To our knowledge, the only work exploring text selection for improving cQA or QA systems is (Barr´on-Cede˜no 1735 Original Question qo : What are the tourist places in Qatar? I’m likely to travel in th"
C16-1163,S16-1172,1,0.882623,"uestions. Various methods rely on machine-translation models. For instance, Jeon et al. (2005) and Zhou et al. (2011) used monolingual phrase-based translation models to compare the questions. Jeon et al. (2005) built their translator from a collection of previously identified similar questions whereas Zhou et al. (2011) used question–answer pairs. Other approaches are based on syntactic representations. This is the case of Wang et al. (2009), who consider the number of common substructures of parse trees to estimate the similarity between two questions. Both Barr´on-Cede˜no et al. (2016) and Filice et al. (2016) use parse trees as well. The difference is that they use them directly within a tree kernel, with the use of the KeLP platform (Filice et al., 2015a). The latter two models were applied on the SemEval 2016 Task 3 challenge on cQA (Nakov et al., 2016), which proposed a task on question ranking (together with one on answer ranking). The best-performing system in this task was the one from Franco-Salvador et al. (2016), which used SVMrank (Joachims, 2006) on a manifold of features, including distributed representations and semantic resources. To our knowledge, the only work exploring text select"
C16-1163,S16-1126,0,0.0424839,"s is the case of Wang et al. (2009), who consider the number of common substructures of parse trees to estimate the similarity between two questions. Both Barr´on-Cede˜no et al. (2016) and Filice et al. (2016) use parse trees as well. The difference is that they use them directly within a tree kernel, with the use of the KeLP platform (Filice et al., 2015a). The latter two models were applied on the SemEval 2016 Task 3 challenge on cQA (Nakov et al., 2016), which proposed a task on question ranking (together with one on answer ranking). The best-performing system in this task was the one from Franco-Salvador et al. (2016), which used SVMrank (Joachims, 2006) on a manifold of features, including distributed representations and semantic resources. To our knowledge, the only work exploring text selection for improving cQA or QA systems is (Barr´on-Cede˜no 1735 Original Question qo : What are the tourist places in Qatar? I’m likely to travel in the month of June. Just wanna know some good places to visit. G GS R Retrieved Questions 1 -1 8 The Qatar banana island will be transfered by the end of 2013 to 5 stars resort called Anantara. Has anyone seen this island? Where is it? Is it near to Corniche? 2 +1 2 Is there"
C16-1163,W01-0515,0,0.030947,"gure 1: Representation of two questions as syntactic trees. Related nodes are enriched with REL links. 3.4 Feature Vectors We combine the kernel above with an RBF kernel applied to feature vectors composed of similarity features. These are computed between the original and the related question and the Google rank. Such text similarity features (sim) are 20 similarities sim(qo , qs ) using word n-grams (n = [1, . . . , 4]), after stopword removal, using greedy string tiling (Wise, 1996), longest common subsequences (Allison and Dix, 1986), Jaccard coefficient (Jaccard, 1901), word containment (Lyon et al., 2001), and cosine similarity. We also add a structural similarity obtained by comparing the syntactic trees of the questions of an example pair using the partial tree kernel, i.e., T K(t(qo , qs ), t(qs , qo )). Note that the operands of the kernel function are members of the same pair. The ranking-based feature (rank) is computed using the ranking generated by the baseline Google search engine system. Each candidate question is located in one position in the range [1, . . . , 10]. We exploit this information as the inverse of the position. 4 Long Short-Term Memory Networks for TK-based Reranking A"
C16-1163,S15-2047,1,0.587169,"vance (GS) and our rank (R) for each question. et al., 2016), which exploits tree kernel function itself to auto-filter the non relevant subtrees. The main difference with the approach we present in the current paper is the use of neural networks for learning attention weights and thus modeling sentence or word pruning. Neural Approaches Recent work has shown the effectiveness of neural models for answer selection (Severyn and Moschitti, 2015; Tan et al., 2015; Feng et al., 2015) and question similarity (dos Santos et al., 2015) in community question answering. For instance, dos Santos et al. (2015) used CNN and bag-of-words (BOW) representations of original and related questions in order to compute cosine similarity scores. Recently, Bahdanau et al. (2014) presented a neural attention model for machine translation and showed that the attention mechanism is helpful for addressing long sentences. We use an LSTM model (Hochreiter and Schmidhuber, 1997) with an attention mechanism for capturing long dependencies in questions for the question similarity task. The major difference with previous work is that we exploit the weights learned by the attention model for selecting important text seg"
C16-1163,N16-1152,1,0.849591,"in Section 2, several neural approaches have been successfully applied to QA tasks. Unfortunately, question retrieval in cQA is heavily affected by a large amount of noise and a rather different domain, which make it difficult to effectively use out-of-domain embeddings to pre-train neural networks. This probably prevented the participants to SemEval tasks from achieving satisfactory results with such models (Nakov et al., 2016). In this work, we also tried to exploit neural models using their top-level representations for the (qo , qs ) pair and fed them into the TK classifier as proposed by Tymoshenko et al. (2016), but this simple combination proved to be ineffective as well. In contrast, neural embeddings and weights can be useful for selecting better representations for TK models. In the reminder of this section, we present LSTM networks for question retrieval and our approach for incorporating them into TK-based rerankers. We approach question ranking as a classification task: given a pair (qo , qs ), we need to classify qs as relevant or irrelevant. In order to evaluate the neural classifiers on our ranking task, we can rank candidates, qs , according to their posterior probability. Among the diffe"
C16-1163,P06-1051,1,0.693051,"ining examples, αi are weights, yi are the example labels, φ(qoi , qsi ) is the representation of pairs of the original and candidate questions. This leads to the following scoring function: r(qo , qs ) = n X αi yi φ(qo , qs ) · φ(qoi , qsi ) = i=1 n X  αi yi K hqo , qs i, hqoi , qsi i , i=1 where the kernel, K(·, ·), intends to capture the similarity between pairs of objects constituted by the original and retrieved questions. The definition of effective Ks for QA and other relational learning tasks, e.g., textual entailment and paraphrasing, has been studied in a large body of work, e.g., (Zanzotto and Moschitti, 2006; Filice et al., 2015b). Given the high similarity between question ranking in cQA and passage ranking in QA, we opted for the state-of-the-art model proposed by Severyn and Moschitti (2012). It should be noted that we apply TK models to pairs of questions rather than questions with their passages. Figure 1 displays an example of the structure we used for representing the original question, qo and the seventh candidate question, qs , in Table 1. The graph is composed by two macro-trees, one for each question, which in turn are constituted by the syntactic trees of the sentences composing the t"
C16-1163,P11-1066,0,0.015238,"have been explored. For instance, Cao et al. (2008) proposed a question recommendation system based on the questions’ topic and Duan et al. (2008) added the question’s focus into the formula. A different approach using topic modeling for question retrieval was introduced by Ji et al. (2012) and Zhang et al. (2014). Here, the authors use LDA topic modeling to learn the latent semantic topics that generate question/answer pairs and use the learned topic distribution to retrieve similar historical questions. Various methods rely on machine-translation models. For instance, Jeon et al. (2005) and Zhou et al. (2011) used monolingual phrase-based translation models to compare the questions. Jeon et al. (2005) built their translator from a collection of previously identified similar questions whereas Zhou et al. (2011) used question–answer pairs. Other approaches are based on syntactic representations. This is the case of Wang et al. (2009), who consider the number of common substructures of parse trees to estimate the similarity between two questions. Both Barr´on-Cede˜no et al. (2016) and Filice et al. (2016) use parse trees as well. The difference is that they use them directly within a tree kernel, wit"
C16-1163,S16-1138,1,\N,Missing
D15-1274,W14-3608,0,0.0691264,"presents a problem for many language processing tasks, including acoustic modeling for speech recognition, language modeling, text-to-speech, and morphological analysis. Automatic methods for diacritization aim to restore diacritics in a non-diacritized text. While earlier work used rule-based methods, more recent studies attempted to learn a diacritization model from diacritized text. A variety of methods have been used, including hidden Markov models, finite-state transducers, and maximum entropy – see the review in (Zitouni and Sarikaya, 2009) – and more recently, deep neural networks (Al Sallab et al., 2014). In addition to learning from diacritized text, these methods typically rely on external resources such as part-of-speech taggers and morphological analyzers like the MADA tool (Habash and Rambow, 2007). However, building such resources is a labor-intensive task and cannot be easily extended to new languages, dialects, and domains. 1 Arabic transliteration follows the Buckwalter scheme: http://www.qamus.org/transliteration.htm. 2281 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2281–2285, c Lisbon, Portugal, 17-21 September 2015. 2015 Associatio"
D15-1274,N07-2014,0,0.0836748,"tization aim to restore diacritics in a non-diacritized text. While earlier work used rule-based methods, more recent studies attempted to learn a diacritization model from diacritized text. A variety of methods have been used, including hidden Markov models, finite-state transducers, and maximum entropy – see the review in (Zitouni and Sarikaya, 2009) – and more recently, deep neural networks (Al Sallab et al., 2014). In addition to learning from diacritized text, these methods typically rely on external resources such as part-of-speech taggers and morphological analyzers like the MADA tool (Habash and Rambow, 2007). However, building such resources is a labor-intensive task and cannot be easily extended to new languages, dialects, and domains. 1 Arabic transliteration follows the Buckwalter scheme: http://www.qamus.org/transliteration.htm. 2281 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2281–2285, c Lisbon, Portugal, 17-21 September 2015. 2015 Association for Computational Linguistics. Diacritic X X X X X X X X Transliteration a Transcription /a/ u /u/ i /i/ F /an/ N /un K /in/ ~ Gemination o No vowel l1,...,lT Output layer Softmax h1,...,hT Hidden"
D15-1274,2006.bcs-1.4,0,0.293541,"art methods that have access to additional resources. 1 Introduction Hebrew, Arabic, and other languages based on the Arabic script usually represent only consonants in writing and do not mark vowels. In such writing systems, diacritics are used for marking short vowels, gemination, and other phonetic units. In practice, diacritics are usually restricted to specific settings such as language teaching or to religious texts. Faced with a non-diacritized word, readers infer missing diacritics based on their prior knowledge and the context of the word in order to resolve ambiguities. For example, Maamouri et al. (2006) mention several types of ambiguity for the Arabic string ÕÎ « Elm, both within and across part-of-speech tags, and at a grammatical Gloss he knew it was known he taught knowledge (def.nom) ... knowledge (indef.gen) flag (def.nom) ... flag (indef.gen) Table 1: Possible diacritized forms for ÕÎ« Elm. level. In practice, a morphological analyzer like MADA (Habash et al., 2009) produces at least 13 different diacritized forms for this word, a subset of which is shown in Table 1.1 The ambiguity in Arabic orthography presents a problem for many language processing tasks, including acoustic modeling"
D15-1274,P06-1073,0,\N,Missing
I17-1001,P17-1080,1,0.491617,"ing Layers of Representation in Neural Machine Translation on Part-of-Speech and Semantic Tagging Tasks Yonatan Belinkov1 Llu´ıs M`arquez2 Hassan Sajjad2 Nadir Durrani2 Fahim Dalvi2 James Glass1 1 MIT Computer Science and Artificial Intelligence Laboratory, Cambridge, MA 02139, USA {belinkov, glass}@mit.edu 2 Qatar Computing Research Institute, HBKU, Doha, Qatar {lmarquez, hsajjad, ndurrani, faimaduddin}@qf.org.qa Abstract One observation that has been made is that lower layers in the neural MT network learn different kinds of information than higher layers. For example, Shi et al. (2016) and Belinkov et al. (2017) found that representations from lower layers of the NMT encoder are more predictive of word-level linguistic properties like part-ofspeech (POS) and morphological tags, whereas higher layer representations are more predictive of more global syntactic information. In this work, we take a first step towards understanding what NMT models learn about semantics. We evaluate NMT representations from different layers on a semantic tagging task and compare to the results on a POS tagging task. We believe that understanding the semantics learned in NMT can facilitate using semantic information for imp"
I17-1001,D17-1151,0,0.0125781,"al., 2017; Belinkov and Glass, 2017; Wang et al., 2017) and language processing models (K¨ohn, 2015; Qian et al., 2016a; Adi et al., 2016; Linzen et al., 2016; Qian et al., 2016b). Methodologically, our work is most similar to Shi et al. (2016) and Belinkov et al. (2017), who also used hidden vectors from neural MT models to predict linguistic properties. However, they focused on relatively low-level tasks (syntax and morphology, respectively), while we apply the approach to a semantic task and compare the results with a POS tagging task. Shallower MT models In comparing network depth in NMT, Britz et al. (2017) found that encoders with 2 to 4 layers performed the best. For completeness, we report here results using features extracted from models trained originally with 2 and 3 layers, in addition to our basic setting of 4 layers. Table 6 shows consistent trends with our previous observations: POS tagging does not benefit from upper layers, while SEM tagging does, although the improvement is rather small in the shallower models. 5 0 Related Work Techniques for analyzing neural network models include visualization of hidden units (Elman, 1991; Karpathy et al., 2015; K´ad´ar et al., 2016; Qian et al.,"
I17-1001,E17-2039,0,0.0170778,"Missing"
I17-1001,P07-1005,0,0.0220979,"coder are more predictive of word-level linguistic properties like part-ofspeech (POS) and morphological tags, whereas higher layer representations are more predictive of more global syntactic information. In this work, we take a first step towards understanding what NMT models learn about semantics. We evaluate NMT representations from different layers on a semantic tagging task and compare to the results on a POS tagging task. We believe that understanding the semantics learned in NMT can facilitate using semantic information for improving NMT systems, as previously shown for non-neural MT (Chan et al., 2007; Liu and Gildea, 2010; Gao and Vogel, 2011; Wu et al., 2011; Jones et al., 2012; Bazrafshan and Gildea, 2013, 2014). For the semantic (SEM) tagging task, we use the dataset recently introduced by Bjerva et al. (2016). This is a lexical semantics task: given a sentence, the goal is to assign to each word a tag representing a semantic class. The classes capture nuanced meanings that are ignored in most POS tag schemes. For instance, proximal and distal demonstratives (e.g., this and that) are typically assigned the same POS tag (DT) but receive different SEM tags (PRX and DST, respectively), an"
I17-1001,I17-1015,1,0.421519,"semantics while lower layers tend to be better for part-of-speech tagging. We also observe little effect of the target language on source-side representations, especially in higher quality models.1 1 Introduction Neural machine translation (NMT) offers an elegant end-to-end architecture, while at the same time improving translation quality. However, little is known about the inner workings of these models and their interpretability is limited. Recent work has started exploring what kind of linguistic information such models learn on morphological (Vylomova et al., 2016; Belinkov et al., 2017; Dalvi et al., 2017) and syntactic levels (Shi et al., 2016; Sennrich, 2017). (1) Sarah bought herself a book 1 Our code is available at http://github.com/ boknilev/nmt-repr-analysis. (2) Sarah herself bought a book 1 Proceedings of the The 8th International Joint Conference on Natural Language Processing, pages 1–10, c Taipei, Taiwan, November 27 – December 1, 2017 2017 AFNLP Figure 1: Illustration of our approach, after (Belinkov et al., 2017): (i) NMT system trained on parallel data; (ii) features extracted from pre-trained model; (iii) classifier trained using the extracted features. We train classifiers on e"
I17-1001,K17-1037,0,0.00554294,"ve similar trends as before: POS tagging does not benefit from features from the upper layers, while SEM tagging improves with layer 4 representations. 0 1 2 3 4 4 POS SEM 87.9 81.8 92.0 87.8 91.7 87.4 91.8 87.6 91.9 88.2 3 POS SEM 87.9 81.9 92.5 88.2 92.3 88.0 92.4 88.4 – – 2 POS SEM 87.9 82.0 92.7 88.5 92.7 88.7 – – – – Table 6: POS and SEM tagging accuracy with features from different layers of 2/3/4-layer encoders, averaged over all non-English target languages. tain quantitative correlations between parts of the neural network and linguistic properties, in both speech (Wu and King, 2016; Alishahi et al., 2017; Belinkov and Glass, 2017; Wang et al., 2017) and language processing models (K¨ohn, 2015; Qian et al., 2016a; Adi et al., 2016; Linzen et al., 2016; Qian et al., 2016b). Methodologically, our work is most similar to Shi et al. (2016) and Belinkov et al. (2017), who also used hidden vectors from neural MT models to predict linguistic properties. However, they focused on relatively low-level tasks (syntax and morphology, respectively), while we apply the approach to a semantic task and compare the results with a POS tagging task. Shallower MT models In comparing network depth in NMT, Britz et"
I17-1001,W11-1012,0,0.0281742,"inguistic properties like part-ofspeech (POS) and morphological tags, whereas higher layer representations are more predictive of more global syntactic information. In this work, we take a first step towards understanding what NMT models learn about semantics. We evaluate NMT representations from different layers on a semantic tagging task and compare to the results on a POS tagging task. We believe that understanding the semantics learned in NMT can facilitate using semantic information for improving NMT systems, as previously shown for non-neural MT (Chan et al., 2007; Liu and Gildea, 2010; Gao and Vogel, 2011; Wu et al., 2011; Jones et al., 2012; Bazrafshan and Gildea, 2013, 2014). For the semantic (SEM) tagging task, we use the dataset recently introduced by Bjerva et al. (2016). This is a lexical semantics task: given a sentence, the goal is to assign to each word a tag representing a semantic class. The classes capture nuanced meanings that are ignored in most POS tag schemes. For instance, proximal and distal demonstratives (e.g., this and that) are typically assigned the same POS tag (DT) but receive different SEM tags (PRX and DST, respectively), and proper nouns are assigned different SEM t"
I17-1001,P82-1020,0,0.755314,"Missing"
I17-1001,P13-2074,0,0.0196012,"gical tags, whereas higher layer representations are more predictive of more global syntactic information. In this work, we take a first step towards understanding what NMT models learn about semantics. We evaluate NMT representations from different layers on a semantic tagging task and compare to the results on a POS tagging task. We believe that understanding the semantics learned in NMT can facilitate using semantic information for improving NMT systems, as previously shown for non-neural MT (Chan et al., 2007; Liu and Gildea, 2010; Gao and Vogel, 2011; Wu et al., 2011; Jones et al., 2012; Bazrafshan and Gildea, 2013, 2014). For the semantic (SEM) tagging task, we use the dataset recently introduced by Bjerva et al. (2016). This is a lexical semantics task: given a sentence, the goal is to assign to each word a tag representing a semantic class. The classes capture nuanced meanings that are ignored in most POS tag schemes. For instance, proximal and distal demonstratives (e.g., this and that) are typically assigned the same POS tag (DT) but receive different SEM tags (PRX and DST, respectively), and proper nouns are assigned different SEM tags depending on their type (e.g., geopolitical entity, organizati"
I17-1001,C12-1083,0,0.0154324,"Missing"
I17-1001,P16-1140,0,0.0367,"Missing"
I17-1001,E17-2060,0,0.0165727,"peech tagging. We also observe little effect of the target language on source-side representations, especially in higher quality models.1 1 Introduction Neural machine translation (NMT) offers an elegant end-to-end architecture, while at the same time improving translation quality. However, little is known about the inner workings of these models and their interpretability is limited. Recent work has started exploring what kind of linguistic information such models learn on morphological (Vylomova et al., 2016; Belinkov et al., 2017; Dalvi et al., 2017) and syntactic levels (Shi et al., 2016; Sennrich, 2017). (1) Sarah bought herself a book 1 Our code is available at http://github.com/ boknilev/nmt-repr-analysis. (2) Sarah herself bought a book 1 Proceedings of the The 8th International Joint Conference on Natural Language Processing, pages 1–10, c Taipei, Taiwan, November 27 – December 1, 2017 2017 AFNLP Figure 1: Illustration of our approach, after (Belinkov et al., 2017): (i) NMT system trained on parallel data; (ii) features extracted from pre-trained model; (iii) classifier trained using the extracted features. We train classifiers on either SEM or POS tagging using features from different l"
I17-1001,D16-1159,0,0.531034,"tter for part-of-speech tagging. We also observe little effect of the target language on source-side representations, especially in higher quality models.1 1 Introduction Neural machine translation (NMT) offers an elegant end-to-end architecture, while at the same time improving translation quality. However, little is known about the inner workings of these models and their interpretability is limited. Recent work has started exploring what kind of linguistic information such models learn on morphological (Vylomova et al., 2016; Belinkov et al., 2017; Dalvi et al., 2017) and syntactic levels (Shi et al., 2016; Sennrich, 2017). (1) Sarah bought herself a book 1 Our code is available at http://github.com/ boknilev/nmt-repr-analysis. (2) Sarah herself bought a book 1 Proceedings of the The 8th International Joint Conference on Natural Language Processing, pages 1–10, c Taipei, Taiwan, November 27 – December 1, 2017 2017 AFNLP Figure 1: Illustration of our approach, after (Belinkov et al., 2017): (i) NMT system trained on parallel data; (ii) features extracted from pre-trained model; (iii) classifier trained using the extracted features. We train classifiers on either SEM or POS tagging using features"
I17-1001,D15-1246,0,0.0767367,"Missing"
I17-1001,W17-4115,0,0.0393383,"Missing"
I17-1001,Q16-1037,0,0.0323719,"0 1 2 3 4 4 POS SEM 87.9 81.8 92.0 87.8 91.7 87.4 91.8 87.6 91.9 88.2 3 POS SEM 87.9 81.9 92.5 88.2 92.3 88.0 92.4 88.4 – – 2 POS SEM 87.9 82.0 92.7 88.5 92.7 88.7 – – – – Table 6: POS and SEM tagging accuracy with features from different layers of 2/3/4-layer encoders, averaged over all non-English target languages. tain quantitative correlations between parts of the neural network and linguistic properties, in both speech (Wu and King, 2016; Alishahi et al., 2017; Belinkov and Glass, 2017; Wang et al., 2017) and language processing models (K¨ohn, 2015; Qian et al., 2016a; Adi et al., 2016; Linzen et al., 2016; Qian et al., 2016b). Methodologically, our work is most similar to Shi et al. (2016) and Belinkov et al. (2017), who also used hidden vectors from neural MT models to predict linguistic properties. However, they focused on relatively low-level tasks (syntax and morphology, respectively), while we apply the approach to a semantic task and compare the results with a POS tagging task. Shallower MT models In comparing network depth in NMT, Britz et al. (2017) found that encoders with 2 to 4 layers performed the best. For completeness, we report here results using features extracted from models t"
I17-1001,C10-1081,0,0.031874,"ictive of word-level linguistic properties like part-ofspeech (POS) and morphological tags, whereas higher layer representations are more predictive of more global syntactic information. In this work, we take a first step towards understanding what NMT models learn about semantics. We evaluate NMT representations from different layers on a semantic tagging task and compare to the results on a POS tagging task. We believe that understanding the semantics learned in NMT can facilitate using semantic information for improving NMT systems, as previously shown for non-neural MT (Chan et al., 2007; Liu and Gildea, 2010; Gao and Vogel, 2011; Wu et al., 2011; Jones et al., 2012; Bazrafshan and Gildea, 2013, 2014). For the semantic (SEM) tagging task, we use the dataset recently introduced by Bjerva et al. (2016). This is a lexical semantics task: given a sentence, the goal is to assign to each word a tag representing a semantic class. The classes capture nuanced meanings that are ignored in most POS tag schemes. For instance, proximal and distal demonstratives (e.g., this and that) are typically assigned the same POS tag (DT) but receive different SEM tags (PRX and DST, respectively), and proper nouns are ass"
I17-1001,L16-1561,0,0.00604061,"OS and SEM tags using the features hkj that are obtained from the English encoder and evaluate their accuracies. Figure 1 illustrates the process. • Consistent with previous work, we find that lower layer representations are usually better for POS tagging. However, we also find that representations from higher layers are better at capturing semantics, even though these are word-level labels. This is especially true with tags that are more semantic in nature such as discourse functions or noun concepts. 2 3 3.1 Data and Experimental Setup Data MT We use the fully-aligned United Nations corpus (Ziemski et al., 2016) for training NMT models, which includes 11 million multi-parallel sentences in six languages: Arabic (Ar), Chinese (Zh), English (En), French (Fr), Spanish (Es), and Russian (Ru). We train En-to-* models on the first 2 million sentences of the train set, using the official train/dev/test split. This dataset has the benefit of multiple alignment of the six languages, which allows for comparable cross-linguistic analysis. Note that the parallel dataset is only used for training the NMT model. The classifier is then trained on the supervised data (described next) and all accuracies are reported"
I17-1001,D16-1079,0,0.0193389,"Missing"
I17-1015,I17-1001,1,0.708774,"ng in the Neural Machine Translation Decoder Fahim Dalvi Nadir Durrani Hassan Sajjad Yonatan Belinkov∗ Stephan Vogel Qatar Computing Research Institute – HBKU, Doha, Qatar {faimaduddin, ndurrani, hsajjad, svogel}@qf.org.qa ∗ MIT Computer Science and Artificial Intelligence Laboratory, Cambridge, MA 02139, USA belinkov@mit.edu Abstract what NMT models learn about morphology (Belinkov et al., 2017a), syntax (Shi et al., 2016) and semantics (Belinkov et al., 2017b). Shi et al. (2016) used activations at various layers from the NMT encoder to predict syntactic properties on the source-side, while Belinkov et al. (2017a) and Belinkov et al. (2017b) used a similar approach to investigate the quality of word representations on the task of morphological and semantic tagging. Belinkov et al. (2017a) found that word representations learned from the encoder are rich in morphological information, while representations learned from the decoder are significantly poorer. However, the paper does not present a convincing explanation for this finding. Our first contribution in this work is to provide a more comprehensive analysis of morphological learning on the decoder side. We hypothesize that other components of the"
I17-1015,D16-1025,0,0.0176372,"d iii) multi-task learning. Our results show that explicit morphological information helps the decoder learn target language morphology and improves the translation quality by 0.2–0.6 BLEU points. 1 Introduction • What is the effect of attention on the performance of the decoder? Neural machine translation (NMT) offers an elegant end-to-end architecture, improving translation quality compared to traditional phrase-based machine translation. These improvements are attributed to more fluent output (Toral and S´anchezCartagena, 2017) and better handling of morphology and long-range dependencies (Bentivogli et al., 2016). However, systematic studies are required to understand what kinds of linguistic phenomena (morphology, syntax, semantics, etc.) are learned by these models and more importantly, which of the components is responsible for each phenomenon. A few attempts have been made to understand • How much does the encoder help the decoder in predicting the correct morphological variant of the word it generates? To answer these questions, we train NMT models for different language pairs, involving morphologically rich languages such as German and Czech. We then use the trained models to extract features fr"
I17-1015,2014.iwslt-evaluation.6,1,0.839752,"o integrate morphology into the decoder. Section 5 presents the results. Section 6 gives an account of related work and Section 7 concludes the paper. 2 Language-pair NMT Systems We used the seq2seq-attn implementation (Kim, 2016) with the following default settings: word embeddings and LSTM states with 500 dimensions, SGD with an initial learning rate of 1.0 and decay rate of 0.5 (after the 9th epoch), and dropout rate of 0.3. We use two uni-directional hidden layers for both the encoder and the decoder. 1 These have been used frequently to annotate data in the previous evaluation campaigns (Birch et al., 2014; Durrani et al., 2014a). 2 The difficulty with using these is that it is not straightforward to derive word representations out of a decoder that processes BPE-ed text, because the original words are split into subwords. We considered aggregating the representations of BPE subword units, but the choice of aggregation strategy may have an undesired impact on the analysis. For this reason we decided to leave exploration of BPE for future work. 3 Character-based models are becoming increasingly popular in Neural MT, for addressing the rare word problem – and they have been used previously also t"
I17-1015,P16-2058,0,0.023772,"Missing"
I17-1015,P17-2021,0,0.0187344,"er was tuned on a separate held out development set (test-11), and the results shown in Figure 3 are on blind test sets (test-12,13). Averages are reported in the figure. 6 Integrating Morphology Some work has also been done in injecting morphological or more general linguistic knowledge into an NMT system. Sennrich and Haddow (2016) proposed a factored model that incorporates linguistic features on the source side as additional factors. An embedding is learned for each factor, just like a source word, and then the word and factor embeddings are combined before being passed on to the encoder. Aharoni and Goldberg (2017) proposed a method to predict the target sentence along with its syntactic tree. They linearize the tree in order to use the existing sequence-to-sequence model. Nadejde et al. (2017) also evaluated several methods of incorporating syntactic knowledge on both the source and target. While they used factors on the source side, their best method for the target side was to linearize the information and interleave it between the target words. Garc´ıa-Mart´ınez et al. (2016) used a neural MT model with multiple outputs, like in our case of Multi-task learning. Their model predicts two properties at"
I17-1015,P15-1166,0,0.0240273,"Missing"
I17-1015,W14-3309,1,0.847572,"gy into the decoder. Section 5 presents the results. Section 6 gives an account of related work and Section 7 concludes the paper. 2 Language-pair NMT Systems We used the seq2seq-attn implementation (Kim, 2016) with the following default settings: word embeddings and LSTM states with 500 dimensions, SGD with an initial learning rate of 1.0 and decay rate of 0.5 (after the 9th epoch), and dropout rate of 0.3. We use two uni-directional hidden layers for both the encoder and the decoder. 1 These have been used frequently to annotate data in the previous evaluation campaigns (Birch et al., 2014; Durrani et al., 2014a). 2 The difficulty with using these is that it is not straightforward to derive word representations out of a decoder that processes BPE-ed text, because the original words are split into subwords. We considered aggregating the representations of BPE subword units, but the choice of aggregation strategy may have an undesired impact on the analysis. For this reason we decided to leave exploration of BPE for future work. 3 Character-based models are becoming increasingly popular in Neural MT, for addressing the rare word problem – and they have been used previously also to benefit MT for morph"
I17-1015,P17-1080,1,0.711845,"ng in the Neural Machine Translation Decoder Fahim Dalvi Nadir Durrani Hassan Sajjad Yonatan Belinkov∗ Stephan Vogel Qatar Computing Research Institute – HBKU, Doha, Qatar {faimaduddin, ndurrani, hsajjad, svogel}@qf.org.qa ∗ MIT Computer Science and Artificial Intelligence Laboratory, Cambridge, MA 02139, USA belinkov@mit.edu Abstract what NMT models learn about morphology (Belinkov et al., 2017a), syntax (Shi et al., 2016) and semantics (Belinkov et al., 2017b). Shi et al. (2016) used activations at various layers from the NMT encoder to predict syntactic properties on the source-side, while Belinkov et al. (2017a) and Belinkov et al. (2017b) used a similar approach to investigate the quality of word representations on the task of morphological and semantic tagging. Belinkov et al. (2017a) found that word representations learned from the encoder are rich in morphological information, while representations learned from the decoder are significantly poorer. However, the paper does not present a convincing explanation for this finding. Our first contribution in this work is to provide a more comprehensive analysis of morphological learning on the decoder side. We hypothesize that other components of the"
I17-1015,P10-1048,1,0.860476,"cesses BPE-ed text, because the original words are split into subwords. We considered aggregating the representations of BPE subword units, but the choice of aggregation strategy may have an undesired impact on the analysis. For this reason we decided to leave exploration of BPE for future work. 3 Character-based models are becoming increasingly popular in Neural MT, for addressing the rare word problem – and they have been used previously also to benefit MT for morphologically rich (Luong et al., 2010; Belinkov and Glass, 2016; Costa-juss`a and Fonollosa, 2016) and closely related languages (Durrani et al., 2010; Sajjad et al., 2013). Experimental Design Parallel Data We used the German-English and Czech-English datasets from the WIT3 TED corpus (Cettolo, 2016) made available for IWSLT 2016. We used the official training sets to analyze and evaluate the proposed methods for integrating morphology . The corpus also provides four test sets, test-11 through test-14. We used test-11 for tuning, and the other test sets for evaluation. The statistics for the sets are provided in Table 1. 143 weighted average of these hidden states from the previous decoder state (di−1 ), known as the context vector ci (Equ"
I17-1015,D10-1015,0,0.0577683,"lty with using these is that it is not straightforward to derive word representations out of a decoder that processes BPE-ed text, because the original words are split into subwords. We considered aggregating the representations of BPE subword units, but the choice of aggregation strategy may have an undesired impact on the analysis. For this reason we decided to leave exploration of BPE for future work. 3 Character-based models are becoming increasingly popular in Neural MT, for addressing the rare word problem – and they have been used previously also to benefit MT for morphologically rich (Luong et al., 2010; Belinkov and Glass, 2016; Costa-juss`a and Fonollosa, 2016) and closely related languages (Durrani et al., 2010; Sajjad et al., 2013). Experimental Design Parallel Data We used the German-English and Czech-English datasets from the WIT3 TED corpus (Cettolo, 2016) made available for IWSLT 2016. We used the official training sets to analyze and evaluate the proposed methods for integrating morphology . The corpus also provides four test sets, test-11 through test-14. We used test-11 for tuning, and the other test sets for evaluation. The statistics for the sets are provided in Table 1. 143 wei"
I17-1015,P17-2012,0,0.0111985,"raining is to learn several tasks simultaneously such that each task can benefit from the mutual information learned (Collobert and Weston, 2008). 5 With this motivation, we modified the NMT decoder to predict not only a word but also its corresponding tag. All of the layers below the output layers are shared. We have two output layers in parallel – the first to predict the target word, and the second to predict the morphological tag of the target word. Both ouput layJoint-data Learning Given the drawbacks of the first approach, we considered another data augmentation technique 5 For example, Eriguchi et al. (2017) jointly learned the tasks of parsing and translation. 146 Figure 3: Improvements from adding morphology. A y-value of zero represents the baseline ers have their own separate loss function. While training, we combine the losses from both output layers to jointly train the system. This is different from the Joint-data learning technique, where we predict entire sequences of words or tags without any dependence on each other. Formally, given a set of N tasks, sequence-tosequence multi-task learning involves an objective function minimizing the overall loss, which is a weighted combination of th"
I17-1015,D16-1079,0,0.0518352,"Missing"
I17-1015,Q17-1024,0,0.0293413,"Missing"
I17-1015,P16-1140,0,0.0270118,"Missing"
I17-1015,P13-2001,1,0.838603,"cause the original words are split into subwords. We considered aggregating the representations of BPE subword units, but the choice of aggregation strategy may have an undesired impact on the analysis. For this reason we decided to leave exploration of BPE for future work. 3 Character-based models are becoming increasingly popular in Neural MT, for addressing the rare word problem – and they have been used previously also to benefit MT for morphologically rich (Luong et al., 2010; Belinkov and Glass, 2016; Costa-juss`a and Fonollosa, 2016) and closely related languages (Durrani et al., 2010; Sajjad et al., 2013). Experimental Design Parallel Data We used the German-English and Czech-English datasets from the WIT3 TED corpus (Cettolo, 2016) made available for IWSLT 2016. We used the official training sets to analyze and evaluate the proposed methods for integrating morphology . The corpus also provides four test sets, test-11 through test-14. We used test-11 for tuning, and the other test sets for evaluation. The statistics for the sets are provided in Table 1. 143 weighted average of these hidden states from the previous decoder state (di−1 ), known as the context vector ci (Equation 2). The context"
I17-1015,D07-1091,0,0.203126,"Missing"
I17-1015,C94-1027,0,0.0784836,"logical information during training which can in turn improve the overall translation quality. In order to test this hypothesis, we experiment with three possible solutions: Sentences tokde/cz token De↔En Cz↔En 210K 122K 4M 2.1M 4.2M 2.5M Table 1: Statistics for the data used for training, tuning and testing Morphological Annotations In order to train and evaluate the external classifier on the extracted features, we required data annotated with morphological tags. We used the following tools recommended on the Moses website1 to annotate the data: LoPar (Schmid, 2000) for German, Tree-tagger (Schmid, 1994) for Czech and MXPOST (Ratnaparkhi, 1998) for English. The number of tags produced by these taggers is 214 for German and 368 for Czech. 1. Joint Generation: An NMT model is trained on the concatenation of words and morphological tags on the target side. 2. Joint-data learning: An NMT model is trained where each source sequence is used twice with an artificial token to either predict target words or morphological tags. Data preprocessing We used the standard MT pre-processing pipeline of tokenizing and truecasing the data using Moses (Koehn et al., 2007) scripts. We did not apply byte-pair enc"
I17-1015,P07-2045,0,0.0125609,"Missing"
I17-1015,W16-2209,0,0.0260724,"e at that point the model is only minimizing the tag objective function. Similarly at λ = 0, the model falls back to the baseline model with a single objective function minimizing translation error. For all language pairs, we consistently achieved the best BLEU score at λ = 0.2. The parameter was tuned on a separate held out development set (test-11), and the results shown in Figure 3 are on blind test sets (test-12,13). Averages are reported in the figure. 6 Integrating Morphology Some work has also been done in injecting morphological or more general linguistic knowledge into an NMT system. Sennrich and Haddow (2016) proposed a factored model that incorporates linguistic features on the source side as additional factors. An embedding is learned for each factor, just like a source word, and then the word and factor embeddings are combined before being passed on to the encoder. Aharoni and Goldberg (2017) proposed a method to predict the target sentence along with its syntactic tree. They linearize the tree in order to use the existing sequence-to-sequence model. Nadejde et al. (2017) also evaluated several methods of incorporating syntactic knowledge on both the source and target. While they used factors o"
I17-1015,D15-1246,0,0.0420013,"Missing"
I17-1015,N16-1005,0,0.0144274,"phological knowledge into the decoder inspired by multilingual NMT systems (Johnson et al., 2016). Instead of having multiple source and target languages, we used one source language and two target language variations. The training data consists of sequences of source→target words and source→target morphological tags. We added an artificial token in the beginning of each source sentence indicating whether we want to generate target words or morphological tags. Using an artificial token in the source sentence has been explored and shown to work well to control the style of the target language (Sennrich et al., 2016a). The objective function is the same as the one in usual sequence-to-sequence models, and is hence shared to minimize both morphological and translation error given the mixed data. encoder (Table 2) and the overall system does not learn as much about target morphology as source morphology, we investigated three ways to directly inject target morphology into the decoder, namely: i) Joint Generation, ii) Joint-data Learning, iii) Multi-task Learning. Figure 2 illustrates the approaches. 4.1 Joint Generation As our first approach, we considered a solution that uses the standard NMT architecture"
I17-1015,P16-1162,0,0.0453069,"phological knowledge into the decoder inspired by multilingual NMT systems (Johnson et al., 2016). Instead of having multiple source and target languages, we used one source language and two target language variations. The training data consists of sequences of source→target words and source→target morphological tags. We added an artificial token in the beginning of each source sentence indicating whether we want to generate target words or morphological tags. Using an artificial token in the source sentence has been explored and shown to work well to control the style of the target language (Sennrich et al., 2016a). The objective function is the same as the one in usual sequence-to-sequence models, and is hence shared to minimize both morphological and translation error given the mixed data. encoder (Table 2) and the overall system does not learn as much about target morphology as source morphology, we investigated three ways to directly inject target morphology into the decoder, namely: i) Joint Generation, ii) Joint-data Learning, iii) Multi-task Learning. Figure 2 illustrates the approaches. 4.1 Joint Generation As our first approach, we considered a solution that uses the standard NMT architecture"
I17-1015,D16-1159,0,0.118608,"sus 214 in German. We tuned the weight parameter on held-out data. 147 Figure 4: Multi-task learning: Translation vs. Morphological Tagging weight for En→De model relevant information about the input. K¨ohn (2015) and Qian et al. (2016b) analyzed linguistic information learned in word embeddings, while Qian et al. (2016a) went further and analyzed linguistic properties in the hidden states of a recurrent neural network. Adi et al. (2016) looked at the overall information learned in a sentence summary vector generated by an RNN using a similar approach. Our approach closely aligns with that of Shi et al. (2016) and Belinkov et al. (2017a), where the activations from various layers in a trained NMT system are used to predict linguistic properties. be handy if the morphological information quality is not very high. On the flip side, this additional explicit weight adjustment can also be viewed as a potential constraint that is not present in the jointdata learning approach. Multi-task Weight Hyper-Parameter As discussed, the multi-task learning approach has an additional weight hyper-parameter λ that adjusts the balance between word and tag prediction. Figure 4 shows the result of varying λ from no mo"
I17-1015,E17-1100,0,0.0361648,"Missing"
N18-2082,W17-3209,0,0.0195564,"as used to train the NMT encoder, in capturing semantic proto-roles and paraphrastic inference. In Table 1, we notice a large improvement using sentence representations from an NMT encoder that was trained on en-es parallel text. The improvements are most profound when a classifier trained on DPR data predicts entailment focused on seAppendix D includes some illustrative examples. This is seen in the last columns of the top row in Table 1. 516 MNLI-1 MNLI-2 ar es zh de MAJ 45.9 46.6 45.7 46.7 46.6 48.2 48.0 48.9 35.6 36.5 Gao and Vogel (2011) add semantic-roles to improve phrase-based MT, and Carpuat et al. (2017) demonstrate how filtering parallel sentences that are not parallel in meaning improves translation. Recent work explores how representations learned by NMT systems can improve semantic tasks. McCann et al. (2017) show improvements in many tasks by using contextualized word vectors extracted from a LSTM encoder trained for MT. Their goal is to use NMT to improve other tasks while we focus on using NLI to determine what NMT models learn about different semantic phenomena. Researchers have explored what NMT models learn about other linguistic phenomena, such as morphology (Dalvi et al., 2017; Be"
N18-2082,D17-1311,0,0.0251135,"Berry Rejoins WPP Group Berry was sentient 7 3 3 Figure 1: Example sentence pairs for the different semantic phenomena. DPR deals with complex anaphora resolution, FN+ is concerned with paraphrastic inference, and SPR covers Reisinger et al. (2015)’s semantic proto-roles. 3 / 7 indicates that the first sentence entails / does not entail the second. What do neural machine translation (NMT) models learn about semantics? Many researchers suggest that state-of-the-art NMT models learn representations that capture the meaning of sentences (Gu et al., 2016; Johnson et al., 2017; Zhou et al., 2017; Andreas and Klein, 2017; Neubig, 2017; Koehn, 2017). However, there is limited understanding of how specific semantic phenomena are captured in NMT representations beyond this broad notion. For instance, how well do these representations capture Dowty (1991)’s thematic proto-roles? Are these representations sufficient for understanding paraphrastic inference? Do the sentence representations encompass complex anaphora resolution? We argue that existing semantic annotations recast as Natural Language Inference (NLI) can be leveraged to investigate whether sentence representations encoded by NMT models capture these se"
N18-2082,P07-1005,0,0.0673881,"Missing"
N18-2082,D16-1053,0,0.0226068,"Missing"
N18-2082,D17-1070,0,0.121882,"Missing"
N18-2082,D15-1075,0,0.48305,"e NLI sentence pairs with their respective labels and semantic phenomena. We evaluate NMT sentence representations of 4 NMT models from 2 domains on 4 different NLI datasets to investigate how well they capture different semantic phenomena. We use White et al. (2017)’s Unified Semantic Evaluation Framework (USEF) that recasts three semantic phenomena NLI: 1) semantic proto-roles, 2) paraphrastic inference, 3) and complex anaphora resolution. Additionally, we evaluate the NMT sentence representations on 4) Multi-NLI, a recent extension of the Stanford Natural Language Inference dataset (SNLI) (Bowman et al., 2015) that includes multiple genres and domains (Williams et al., 1 Code developed and data used are available at https: //github.com/boknilev/nmt-repr-analysis. 2 Sometimes referred to as recognizing textual entailment (Dagan et al., 2006, 2013). 1. Introduction 513 Proceedings of NAACL-HLT 2018, pages 513–523 c New Orleans, Louisiana, June 1 - 6, 2018. 2018 Association for Computational Linguistics so correctly identifying them can be important for translation. For example, English does not usually explicitly mark volition, a proto-role, except by using adverbs like intentionally or accidentally."
N18-2082,I17-1015,1,0.829229,"Carpuat et al. (2017) demonstrate how filtering parallel sentences that are not parallel in meaning improves translation. Recent work explores how representations learned by NMT systems can improve semantic tasks. McCann et al. (2017) show improvements in many tasks by using contextualized word vectors extracted from a LSTM encoder trained for MT. Their goal is to use NMT to improve other tasks while we focus on using NLI to determine what NMT models learn about different semantic phenomena. Researchers have explored what NMT models learn about other linguistic phenomena, such as morphology (Dalvi et al., 2017; Belinkov et al., 2017a), syntax (Shi et al., 2016), and lexical semantics (Belinkov et al., 2017b), including word senses (Marvin and Koehn, 2018; Liu et al., 2018) Table 5: Accuracies for MNLI test sets. MNLI-1 refers to the matched case and MNLI-2 is the mismatched. mantic proto-roles or paraphrastic inference. We also note that using the NMT encoder trained on en-es parallel text results in the highest results in 5 of the 6 proto-roles in the top portion of Table 4. When using other sentence representations (Appendix A), we notice that using representations from English-German encoders co"
N18-2082,P14-2124,0,0.0670495,"Missing"
N18-2082,W11-1012,0,0.0246855,"nguage Our experiments show differences based on which target language was used to train the NMT encoder, in capturing semantic proto-roles and paraphrastic inference. In Table 1, we notice a large improvement using sentence representations from an NMT encoder that was trained on en-es parallel text. The improvements are most profound when a classifier trained on DPR data predicts entailment focused on seAppendix D includes some illustrative examples. This is seen in the last columns of the top row in Table 1. 516 MNLI-1 MNLI-2 ar es zh de MAJ 45.9 46.6 45.7 46.7 46.6 48.2 48.0 48.9 35.6 36.5 Gao and Vogel (2011) add semantic-roles to improve phrase-based MT, and Carpuat et al. (2017) demonstrate how filtering parallel sentences that are not parallel in meaning improves translation. Recent work explores how representations learned by NMT systems can improve semantic tasks. McCann et al. (2017) show improvements in many tasks by using contextualized word vectors extracted from a LSTM encoder trained for MT. Their goal is to use NMT to improve other tasks while we focus on using NLI to determine what NMT models learn about different semantic phenomena. Researchers have explored what NMT models learn abo"
N18-2082,P11-1023,0,0.0503801,"Missing"
N18-2082,P14-5010,0,0.00252649,"hat our classifiers using the representations from the NMT encoder perform poorly. Although the sentences in FN+ are much longer than in the other datasets, sentence length does not seem to be responsible for the poor FN+ results. The classifiers do not noticeably perform better on shorter sentences than longer ones, as noted in Appendix C. Upon manual inspection, we noticed that in many not-entailed examples, swapped paraphrases had different part-of-speech (POS) tags. This begs the question of whether different POS tags for swapped paraphrases affects the accuracies. Using Stanford CoreNLP (Manning et al., 2014), we partition our validation set based on whether the paraphrases share the same POS tag. Table 3 reports dev set accuracies using classifiers trained on FN+. Classifiers using features from NMT encoders trained on the three languages from the UN corpus noticeably perform better on cases where paraphrases have different POS tags compared to paraphrases with the same POS tags. These difNatural Language Inference data We use four distinct datasets to train classifiers: MultiNLI (Williams et al., 2017), a recent expansion of SNLI containing a broad array of domains that was used in the 2017 RepE"
N18-2082,P02-1031,0,0.0462015,"rforms the baseline for a proto-role, all the other classifiers do as well. The classifiers outperform the majority baseline for 6 of the reported 16 proto-roles. We observe these 6 properties are more associated with proto-agents than proto-patients. The larger improvements over the majority baseline for SPR compared to FN+ and DPR is not surprising. Dowty (1991) posited that proto-agent, and -patient should correlate with English syntactic subject, and object, respectively, and empirically the necessity of [syntactic] parsing for predicate argument recognition has been observed in practice (Gildea and Palmer, 2002; Punyakanok et al., 2008). Further, recent work is suggestive that LSTM-based frameworks implicitly may encode syntax based on certain learning objectives (Linzen et al., 2016; Shi et al., 2016; Belinkov et al., 2017b). It is unclear whether NMT encoders capture semantic proto-roles specifically or just underlying syntax that affects the proto-roles. Proto-role entailment (SPR) When predicting SPR entailments using a classifier trained on SPR data, we noticeably outperform the majority baseline but are below USEF. Both ours and USEF’s accuracies are lower than Teichert et al. (2017)’s best re"
N18-2082,W18-1812,0,0.0223432,"how representations learned by NMT systems can improve semantic tasks. McCann et al. (2017) show improvements in many tasks by using contextualized word vectors extracted from a LSTM encoder trained for MT. Their goal is to use NMT to improve other tasks while we focus on using NLI to determine what NMT models learn about different semantic phenomena. Researchers have explored what NMT models learn about other linguistic phenomena, such as morphology (Dalvi et al., 2017; Belinkov et al., 2017a), syntax (Shi et al., 2016), and lexical semantics (Belinkov et al., 2017b), including word senses (Marvin and Koehn, 2018; Liu et al., 2018) Table 5: Accuracies for MNLI test sets. MNLI-1 refers to the matched case and MNLI-2 is the mismatched. mantic proto-roles or paraphrastic inference. We also note that using the NMT encoder trained on en-es parallel text results in the highest results in 5 of the 6 proto-roles in the top portion of Table 4. When using other sentence representations (Appendix A), we notice that using representations from English-German encoders consistently outperforms using the other encoders (Tables 6 and 7). This prevents us from making generalizations regarding specific target side langu"
N18-2082,P16-1154,0,0.016256,"ses five research reactors Iran has five research reactors Berry Rejoins WPP Group Berry was sentient 7 3 3 Figure 1: Example sentence pairs for the different semantic phenomena. DPR deals with complex anaphora resolution, FN+ is concerned with paraphrastic inference, and SPR covers Reisinger et al. (2015)’s semantic proto-roles. 3 / 7 indicates that the first sentence entails / does not entail the second. What do neural machine translation (NMT) models learn about semantics? Many researchers suggest that state-of-the-art NMT models learn representations that capture the meaning of sentences (Gu et al., 2016; Johnson et al., 2017; Zhou et al., 2017; Andreas and Klein, 2017; Neubig, 2017; Koehn, 2017). However, there is limited understanding of how specific semantic phenomena are captured in NMT representations beyond this broad notion. For instance, how well do these representations capture Dowty (1991)’s thematic proto-roles? Are these representations sufficient for understanding paraphrastic inference? Do the sentence representations encompass complex anaphora resolution? We argue that existing semantic annotations recast as Natural Language Inference (NLI) can be leveraged to investigate wheth"
N18-2082,P15-2067,1,0.667806,"Missing"
N18-2082,D17-3004,1,0.884949,"Missing"
N18-2082,Q15-1034,1,\N,Missing
N18-2082,P17-1080,1,\N,Missing
N18-2082,W17-5301,0,\N,Missing
N18-2082,I17-1100,1,\N,Missing
N18-2082,W17-5703,0,\N,Missing
N18-2082,N18-1121,0,\N,Missing
N18-2082,I17-1001,1,\N,Missing
N18-2082,J13-3001,0,\N,Missing
N18-2082,2020.wmt-1.63,0,\N,Missing
N18-2082,2020.coling-tutorials.3,0,\N,Missing
N19-1112,E17-2039,0,0.0259669,"Missing"
N19-1112,J99-2004,0,0.205453,"dependently for each token (Belinkov et al., 2017a,b; Blevins et al., 2018, inter alia). We synthesize these disparate studies and build upon them by proposing additional probing tasks. The part-of-speech tagging (POS) task assesses whether CWRs capture basic syntax. We experiment with two standard datasets: the Penn Treebank (PTB; Marcus et al., 1993) and the Universal Dependencies English Web Treebank (UDEWT; Silveira et al., 2014). The CCG supertagging (CCG) task assesses the vectors’ fine-grained information about the syntactic roles of words in context. It is considered “almost parsing” (Bangalore and Joshi, 1999), since a sequence of supertags maps a sentence to a small set of possible parses. We use CCGbank (Hockenmaier and Steedman, 2007), a conversion of the PTB into CCG derivations. The syntactic constituency ancestor tagging tasks are designed to probe the vectors’ knowledge of hierarchical syntax. For a given word, the probing model is trained to predict the constituent la2 http://nelsonliu.me/papers/ contextual-repr-analysis 1074 where a prediction is made only for tokens corresponding to events (rather than every token in a sequence). Performance is measured using Pearson correlation (r); we r"
N19-1112,P17-1080,1,0.922231,"). CWRs are extraordinarily effective—using them in place of traditional static word vectors within the latest models leads to large gains across a variety of NLP tasks. The broad success of CWRs indicates that they encode useful, transferable features of language. However, their linguistic knowledge and transferability are not yet well understood. Recent work has explored the linguistic knowledge captured by language models and neural machine translation systems, but these studies often focus on a single phenomenon, e.g., knowledge of hierarchical syntax (Blevins et al., 2018) or morphology (Belinkov et al., 2017a). We extend prior work by studying CWRs with a diverse set of sixteen probing tasks designed to assess a wide array of phenomena, such as coreference, knowledge of semantic relations, and entity information, among 1073 Proceedings of NAACL-HLT 2019, pages 1073–1094 c Minneapolis, Minnesota, June 2 - June 7, 2019. 2019 Association for Computational Linguistics others. The result is a broader view of the linguistic knowledge encoded within CWRs. With respect to transferability, pretraining contextualizers on the language modeling task has had the most empirical success, but we can also conside"
N19-1112,I17-1001,1,0.899042,"Missing"
N19-1112,C16-1333,0,0.0322078,"ion task. Prepositions are marked by boldface, immediately followed by their labeled function. If applicable, ; precedes the preposition’s labeled role. Figure reproduced from Schneider et al. (2018). bel of its parent (Parent), grandparent (GParent), or great-grandparent (GGParent) in the phrasestructure tree (from the PTB). In the semantic tagging task (ST), tokens are assigned labels that reflect their semantic role in context. These semantic tags assess lexical semantics, and they abstract over redundant POS distinctions and disambiguate useful cases within POS tags. We use the dataset of Bjerva et al. (2016); the tagset has since been developed as part of the Parallel Meaning Bank (Abzianidze et al., 2017). Preposition supersense disambiguation is the task of classifying a preposition’s lexical semantic contribution (the function; PS-fxn) and the semantic role or relation it mediates (the role; PSrole). This task is a specialized kind of word sense disambiguation, and examines one facet of lexical semantic knowledge. In contrast to the tagging tasks above, the model is trained and evaluated on single-token prepositions (rather than making a decision for every token in a sequence). We use the STRE"
N19-1112,P18-2003,0,0.156618,"nguage modeling (Peters et al., 2018a). CWRs are extraordinarily effective—using them in place of traditional static word vectors within the latest models leads to large gains across a variety of NLP tasks. The broad success of CWRs indicates that they encode useful, transferable features of language. However, their linguistic knowledge and transferability are not yet well understood. Recent work has explored the linguistic knowledge captured by language models and neural machine translation systems, but these studies often focus on a single phenomenon, e.g., knowledge of hierarchical syntax (Blevins et al., 2018) or morphology (Belinkov et al., 2017a). We extend prior work by studying CWRs with a diverse set of sixteen probing tasks designed to assess a wide array of phenomena, such as coreference, knowledge of semantic relations, and entity information, among 1073 Proceedings of NAACL-HLT 2019, pages 1073–1094 c Minneapolis, Minnesota, June 2 - June 7, 2019. 2019 Association for Computational Linguistics others. The result is a broader view of the linguistic knowledge encoded within CWRs. With respect to transferability, pretraining contextualizers on the language modeling task has had the most empir"
N19-1112,P18-1246,0,0.0610796,"Missing"
N19-1112,P18-1008,0,0.0289435,"middle layers show varying performance. Across all models, the representations that are better-suited for language modeling are also those that exhibit worse probing task performance (Figure 3), indicating that contextualizer layers trade off between encoding general and task-specific features. These results also reveal a difference in the layerwise behavior of LSTMs and transformers; moving up the LSTM layers yields more taskspecific representations, but the same does not hold for transformers. Better understanding the differences between transformers and LSTMs is an active area of research (Chen et al., 2018; Tang et al., 2018), and we leave further exploration of these observations to future work. These observations motivate the gradual unfreezing method of Howard and Ruder (2018), where the model layers are progressively unfrozen (starting from the final layer) during the finetuning process. Given our observation that higherlevel LSTM layers are less general (and more pretraining task-specific), they likely have to be finetuned a bit more in order to make them appropriately task specific. Meanwhile, the base layer of the LSTM already learns highly transferable features, and may not benefit from"
N19-1112,W18-2501,1,0.861441,"Missing"
N19-1112,D17-1206,0,0.0593364,"Missing"
N19-1112,N16-1026,0,0.0599268,"Missing"
N19-1112,Q16-1037,0,0.0737692,"a variety of other methods to study the learned representations in neural models, such as directly examining the activations of individual neurons (Karpathy et al., 2015; Li et al., 2015; Shi et al., 2016a, inter alia), ablating components of the model and dataset (Kuncoro et al., 2017; Gaddy et al., 2018; Khandelwal et al., 2018), or interpreting attention mechanisms (Bahdanau et al., 2015); see Belinkov and Glass (2019) for a recent survey. One particularly relevant line of work involves the construction of synthetic tasks that a model can only solve if it captures a particular phenomenon (Linzen et al., 2016; Jumelet and Hupkes, 2018; Wilcox et al., 2018; Futrell and Levy, 2019, inter alia). Zhang and Bowman (2018) compare the syntactic knowledge of language models and neural machine translation systems. We widen the range of pretraining tasks and target probing model tasks to gain a more complete picture. We also focus on a stronger contextualizer architecture, ELMo (original), that has produced state-of-the-art results. Several studies have sought to intrinsically evaluate noncontextual word representations with word similarity tasks, such as analogies (Mikolov et al., 2013). These methods diff"
N19-1112,J93-2004,0,0.0674375,"ork in probing the contents of representations.2 See Appendix A for details about task setup. 2.1 Token Labeling The majority of past work in probing the internal representations of neural models has examined various token labeling tasks, where a decision is made independently for each token (Belinkov et al., 2017a,b; Blevins et al., 2018, inter alia). We synthesize these disparate studies and build upon them by proposing additional probing tasks. The part-of-speech tagging (POS) task assesses whether CWRs capture basic syntax. We experiment with two standard datasets: the Penn Treebank (PTB; Marcus et al., 1993) and the Universal Dependencies English Web Treebank (UDEWT; Silveira et al., 2014). The CCG supertagging (CCG) task assesses the vectors’ fine-grained information about the syntactic roles of words in context. It is considered “almost parsing” (Bangalore and Joshi, 1999), since a sequence of supertags maps a sentence to a small set of possible parses. We use CCGbank (Hockenmaier and Steedman, 2007), a conversion of the PTB into CCG derivations. The syntactic constituency ancestor tagging tasks are designed to probe the vectors’ knowledge of hierarchical syntax. For a given word, the probing m"
N19-1112,S15-2153,0,0.101468,"Missing"
N19-1112,D14-1162,0,0.0883484,"and what makes contextual word representations transferable, we compare language model pretraining with eleven supervised pretraining tasks. For any given task, pretraining on a closely related task yields better performance than language model pretraining (which is better on average) when the pretraining dataset is fixed. However, language model pretraining on more data gives the best results. 1 Figure 1: An illustration of the probing model setup used to study the linguistic knowledge within contextual word representations. Introduction Pretrained word representations (Mikolov et al., 2013; Pennington et al., 2014) are a key component of state-of-the-art neural NLP models. Traditionally, these word vectors are static—a single * Work done while at the Allen Institute for Artificial Intelligence. vector is assigned to each word. Recent work has explored contextual word representations (henceforth: CWRs), which assign each word a vector that is a function of the entire input sequence; this enables them to model the use of words in context. CWR s are typically the outputs of a neural network (which we call a contextualizer) trained on tasks with large datasets, such as machine translation (McCann et al., 20"
N19-1112,W19-4302,1,0.768829,"k, since such information is learnable by a task-specific contextualizer. This analysis also reveals insights about contextualizer fine-tuning, which seeks to specialize the CWRs for an end task (Howard and Ruder, 2018; Radford et al., 2018; Devlin et al., 2018). Our results confirm that task-trained contextualization is important when the end task requires specific information that may not be captured by the pretraining task (§4). However, such end-task– specific contextualization can come from either fine-tuning CWRs or using fixed output features as inputs to a task-trained contextualizer; Peters et al. (2019) begins to explore when each approach should be applied. 5 Analyzing Layerwise Transferability We quantify the transferability of CWRs by how well they can do on the range of probing tasks— representations that are more transferable will perform better than alternatives across tasks. When analyzing the representations produced by each layer of pretrained contextualizers, we observe marked patterns in layerwise transferability (Figure 3). The first layer of contextualization in recurrent models (original and 4-layer ELMo) is consistently the most transferable, even outperforming a scalar mix of"
N19-1112,N18-1202,1,0.897768,"te-of-the-art neural NLP models. Traditionally, these word vectors are static—a single * Work done while at the Allen Institute for Artificial Intelligence. vector is assigned to each word. Recent work has explored contextual word representations (henceforth: CWRs), which assign each word a vector that is a function of the entire input sequence; this enables them to model the use of words in context. CWR s are typically the outputs of a neural network (which we call a contextualizer) trained on tasks with large datasets, such as machine translation (McCann et al., 2017) and language modeling (Peters et al., 2018a). CWRs are extraordinarily effective—using them in place of traditional static word vectors within the latest models leads to large gains across a variety of NLP tasks. The broad success of CWRs indicates that they encode useful, transferable features of language. However, their linguistic knowledge and transferability are not yet well understood. Recent work has explored the linguistic knowledge captured by language models and neural machine translation systems, but these studies often focus on a single phenomenon, e.g., knowledge of hierarchical syntax (Blevins et al., 2018) or morphology"
N19-1112,D18-1179,1,0.89357,"te-of-the-art neural NLP models. Traditionally, these word vectors are static—a single * Work done while at the Allen Institute for Artificial Intelligence. vector is assigned to each word. Recent work has explored contextual word representations (henceforth: CWRs), which assign each word a vector that is a function of the entire input sequence; this enables them to model the use of words in context. CWR s are typically the outputs of a neural network (which we call a contextualizer) trained on tasks with large datasets, such as machine translation (McCann et al., 2017) and language modeling (Peters et al., 2018a). CWRs are extraordinarily effective—using them in place of traditional static word vectors within the latest models leads to large gains across a variety of NLP tasks. The broad success of CWRs indicates that they encode useful, transferable features of language. However, their linguistic knowledge and transferability are not yet well understood. Recent work has explored the linguistic knowledge captured by language models and neural machine translation systems, but these studies often focus on a single phenomenon, e.g., knowledge of hierarchical syntax (Blevins et al., 2018) or morphology"
N19-1112,W12-4501,0,0.0474045,"arsing, which score pairs of CWRs to make head attachment and arc labeling decisions (Dozat and Manning, 2016, 2018). To generate negative examples for the dependency arc prediction tasks, we take each positive example (whead , wmod ) and generate a new negative example (wrand , wmod ). wrand is a random token in the sentence that is not the head of wmod . Thus, the datasets used in these tasks are balanced. We also consider a coreference arc prediction task, where the model is trained to predict whether two entities corefer from their CWRs. We use the dataset from the CoNLL 2012 shared task (Pradhan et al., 2012). To generate negative examples, we follow a similar procedure as the dependency arc prediction tasks: given a positive example (wa , wb ), where wb occurs after wa and the two tokens share a coreference cluster, we create a negative example (wrandom entity , wb ), where wrandom entity is a token that occurs before wb and belongs to a different coreference cluster. 3 Models Probing Model We use a linear model as our probing model; limiting its capacity enables us to focus on what information can be easily extracted from CWRs. See Appendix B for probing model training hyperparameters and other"
N19-1112,N19-1162,0,0.032501,"yzing Layerwise Transferability We quantify the transferability of CWRs by how well they can do on the range of probing tasks— representations that are more transferable will perform better than alternatives across tasks. When analyzing the representations produced by each layer of pretrained contextualizers, we observe marked patterns in layerwise transferability (Figure 3). The first layer of contextualization in recurrent models (original and 4-layer ELMo) is consistently the most transferable, even outperforming a scalar mix of layers on most tasks (see Appendix D for scalar mix results). Schuster et al. (2019) see the same trend in English dependency parsing. By contrast, transformer-based contextualizers have no single most-transferable layer; the best performing layer for each task varies, and is usually near the middle. Accordingly, a scalar mix of transformer layers outperforms the best individual layer on most tasks (see Appendix D). Pretraining encourages the model to encode pretraining-task–specific information; they learn transferable features incidentally. We hypothesize that this is an inherent trade-off—since these models used fixed-sized vector representations, taskspecificity comes at"
N19-1112,D16-1248,0,0.459106,"ter understanding the linguistic knowledge and transferability of CWRs is necessary for their principled enhancement through new encoder architectures and pretraining tasks that build upon their strengths or alleviate their weaknesses (Linzen, 2018). This paper asks and answers: 1. What features of language do these vectors capture, and what do they miss? (§4) 2. How and why does transferability vary across representation layers in contextualizers? (§5) 3. How does the choice of pretraining task affect the vectors’ learned linguistic knowledge and transferability? (§6) We use probing models1 (Shi et al., 2016b; Adi et al., 2017; Hupkes et al., 2018; Belinkov and Glass, 2019) to analyze the linguistic information within CWRs. Concretely, we generate features for words from pretrained contextualizers and train a model to make predictions from those features alone (Figure 1). If a simple model can be trained to predict linguistic information about a word (e.g., its part-of-speech tag) or a pair of words (e.g., their semantic relation) from the CWR (s) alone, we can reasonably conclude that the CWR (s) encode this information. Our analysis reveals interesting insights such as: 1. Linear models trained"
N19-1112,D16-1159,0,0.598727,"ter understanding the linguistic knowledge and transferability of CWRs is necessary for their principled enhancement through new encoder architectures and pretraining tasks that build upon their strengths or alleviate their weaknesses (Linzen, 2018). This paper asks and answers: 1. What features of language do these vectors capture, and what do they miss? (§4) 2. How and why does transferability vary across representation layers in contextualizers? (§5) 3. How does the choice of pretraining task affect the vectors’ learned linguistic knowledge and transferability? (§6) We use probing models1 (Shi et al., 2016b; Adi et al., 2017; Hupkes et al., 2018; Belinkov and Glass, 2019) to analyze the linguistic information within CWRs. Concretely, we generate features for words from pretrained contextualizers and train a model to make predictions from those features alone (Figure 1). If a simple model can be trained to predict linguistic information about a word (e.g., its part-of-speech tag) or a pair of words (e.g., their semantic relation) from the CWR (s) alone, we can reasonably conclude that the CWR (s) encode this information. Our analysis reveals interesting insights such as: 1. Linear models trained"
N19-1112,P11-1019,0,0.0388573,"ang and Buchholz, 2000). Named entity recognition (NER) examines whether CWRs encode information about entity types. We use the CoNLL 2003 shared task dataset (Tjong Kim Sang and De Meulder, 2003). Grammatical error detection (GED) is the task of identifying tokens which need to be edited in order to produce a grammatically correct sentence. Given that CWRs are extracted from models trained on large amounts of grammatical text, this task assesses whether embeddings encode features that indicate anomalies in their input (in this case, ungrammaticality). We use the First Certificate in English (Yannakoudakis et al., 2011) dataset, converted into sequence-labeling format by Rei and Yannakoudakis (2016). The conjunct identification (Conj) task challenges the model to identify the tokens that comprise the conjuncts in a coordination construction. Doing so requires highly specific syntactic knowledge. The data comes from the coordinationannotated PTB of Ficler and Goldberg (2016). 2.3 Pairwise Relations We also design probing tasks that examine whether relationships between words are encoded in CWRs. In these tasks, given a word pair w1 , w2 , we input [w1 , w2 , w1 w2 ] into the probing model; it is trained to pr"
N19-1112,N18-1089,0,0.0423259,"Missing"
N19-1112,W18-5448,0,0.0345799,"ning the activations of individual neurons (Karpathy et al., 2015; Li et al., 2015; Shi et al., 2016a, inter alia), ablating components of the model and dataset (Kuncoro et al., 2017; Gaddy et al., 2018; Khandelwal et al., 2018), or interpreting attention mechanisms (Bahdanau et al., 2015); see Belinkov and Glass (2019) for a recent survey. One particularly relevant line of work involves the construction of synthetic tasks that a model can only solve if it captures a particular phenomenon (Linzen et al., 2016; Jumelet and Hupkes, 2018; Wilcox et al., 2018; Futrell and Levy, 2019, inter alia). Zhang and Bowman (2018) compare the syntactic knowledge of language models and neural machine translation systems. We widen the range of pretraining tasks and target probing model tasks to gain a more complete picture. We also focus on a stronger contextualizer architecture, ELMo (original), that has produced state-of-the-art results. Several studies have sought to intrinsically evaluate noncontextual word representations with word similarity tasks, such as analogies (Mikolov et al., 2013). These methods differ from our approach in that they require no extra parameters and directly assess the vectors, while our prob"
N19-1112,silveira-etal-2014-gold,0,0.135261,"Missing"
N19-1112,D18-1458,0,0.0621572,"Missing"
N19-1112,W00-0726,0,0.0824119,"Decompositional Semantics It Happened v2 dataset (Rudinger et al., 2018), and the model is trained to predict a (non)factuality value in the range [−3, 3]. Unlike the tagging tasks above, this task is treated as a regression problem, 2.2 Segmentation Several of our probing tasks involve segmentation using BIO or IO tags. Here the model is trained to predict labels from only a single word’s CWR. Syntactic chunking (Chunk) tests whether CWR s contain notions of spans and boundaries; the task is to segment text into shallow constituent chunks. We use the CoNLL 2000 shared task dataset (Tjong Kim Sang and Buchholz, 2000). Named entity recognition (NER) examines whether CWRs encode information about entity types. We use the CoNLL 2003 shared task dataset (Tjong Kim Sang and De Meulder, 2003). Grammatical error detection (GED) is the task of identifying tokens which need to be edited in order to produce a grammatically correct sentence. Given that CWRs are extracted from models trained on large amounts of grammatical text, this task assesses whether embeddings encode features that indicate anomalies in their input (in this case, ungrammaticality). We use the First Certificate in English (Yannakoudakis et al., 2"
N19-1112,D15-1243,0,0.0265978,"slation systems. We widen the range of pretraining tasks and target probing model tasks to gain a more complete picture. We also focus on a stronger contextualizer architecture, ELMo (original), that has produced state-of-the-art results. Several studies have sought to intrinsically evaluate noncontextual word representations with word similarity tasks, such as analogies (Mikolov et al., 2013). These methods differ from our approach in that they require no extra parameters and directly assess the vectors, while our probing models must be trained. In this regard, our method is similar to QVEC (Tsvetkov et al., 2015). 8 Conclusion We study the linguistic knowledge and transferability of contextualized word representations with a suite of sixteen diverse probing tasks. The features generated by pretrained contextualizers are sufficient for high performance on a broad set of tasks. For tasks that require specific information not captured by the contextual word representation, we show that learning task-specific contextual features helps to encode the requisite knowledge. In addition, our analysis of patterns in the transferability of contextualizer layers shows that the lowest layer of LSTMs encodes the mos"
N19-1112,W18-5423,0,0.0214566,"d representations in neural models, such as directly examining the activations of individual neurons (Karpathy et al., 2015; Li et al., 2015; Shi et al., 2016a, inter alia), ablating components of the model and dataset (Kuncoro et al., 2017; Gaddy et al., 2018; Khandelwal et al., 2018), or interpreting attention mechanisms (Bahdanau et al., 2015); see Belinkov and Glass (2019) for a recent survey. One particularly relevant line of work involves the construction of synthetic tasks that a model can only solve if it captures a particular phenomenon (Linzen et al., 2016; Jumelet and Hupkes, 2018; Wilcox et al., 2018; Futrell and Levy, 2019, inter alia). Zhang and Bowman (2018) compare the syntactic knowledge of language models and neural machine translation systems. We widen the range of pretraining tasks and target probing model tasks to gain a more complete picture. We also focus on a stronger contextualizer architecture, ELMo (original), that has produced state-of-the-art results. Several studies have sought to intrinsically evaluate noncontextual word representations with word similarity tasks, such as analogies (Mikolov et al., 2013). These methods differ from our approach in that they require no ex"
N19-1112,D17-1197,0,0.019245,"WR do not capture much transfer3 See Appendix C for references to the previous state of the art (without pretraining). 4 For brevity, in this section we omit probing tasks that cannot be compared to prior work. See Appendix D for pretrained contextualizer performance for all layers and all tasks. able information about entities and coreference phenomena in their input (e.g., the NER results in Table 1 and the coreference arc prediction results in Appendix D). To alleviate this weakness, future work could augment pretrained contextualizers with explicit entity representations (Ji et al., 2017; Yang et al., 2017; Bosselut et al., 2017). Probing Failures While probing models are at or near state-of-the-art performance across a number of tasks, they also do not perform as well on several others, including NER, grammatical error detection, and conjunct identification. This may occur because (1) the CWR simply does not encode the pertinent information or any predictive correlates, or (2) the probing model does not have the capacity necessary to extract the information or predictive correlates from the vector. In the former case, learning task-specific contextual features might be necessary for encoding t"
N19-1112,S14-2008,0,\N,Missing
N19-1112,J12-2002,0,\N,Missing
N19-1112,W03-0419,0,\N,Missing
N19-1112,J12-2003,0,\N,Missing
N19-1112,J07-3004,0,\N,Missing
N19-1112,P16-1079,0,\N,Missing
N19-1112,P16-1112,0,\N,Missing
N19-1112,E17-1117,1,\N,Missing
N19-1112,P18-2077,0,\N,Missing
N19-1112,Q19-1004,1,\N,Missing
N19-1112,N19-1423,0,\N,Missing
N19-1112,N16-1082,0,\N,Missing
N19-1154,E17-2039,0,0.0379246,"Missing"
N19-1154,P17-1080,1,0.899859,"r for modeling non-local syntactic and semantic dependencies, character-based ones are superior for morphology and are also more robust to noise. There is also value in combining different representations. 2 Related Work Representation analysis aims at demystifying what is learned inside the neural network blackbox. This includes analyzing word and sentence embeddings (Adi et al., 2017; Qian et al., 2016b; Ganesh et al., 2017; Conneau et al., 2018, among others), RNN states (Qian et al., 2016a; Shi et al., 2016; Wu and King, 2016; Wang et al., 2017), and NMT representations (Shi et al., 2016; Belinkov et al., 2017a), as applied to morphological (Vylomova et al., 2017; Dalvi et al., 2017), semantic (Qian et al., 2016b; Belinkov et al., 2017b) and syntactic (Linzen et al., 2016; Tran et al., 2018; Conneau et al., 2018) tasks. See Belinkov and Glass (2019) for a recent survey. Other studies carried a more fine-grained neuronlevel analysis for NMT and LM (Dalvi et al., 2019; Bau et al., 2019; Lakretz et al., 2019). While previous work focused on words, here we compare units of different granularities. Subword translation units aim at reducing the vocabulary size and the out-of-vocabulary (OOV) rate. Resear"
N19-1154,Q19-1004,1,0.851128,"ysis aims at demystifying what is learned inside the neural network blackbox. This includes analyzing word and sentence embeddings (Adi et al., 2017; Qian et al., 2016b; Ganesh et al., 2017; Conneau et al., 2018, among others), RNN states (Qian et al., 2016a; Shi et al., 2016; Wu and King, 2016; Wang et al., 2017), and NMT representations (Shi et al., 2016; Belinkov et al., 2017a), as applied to morphological (Vylomova et al., 2017; Dalvi et al., 2017), semantic (Qian et al., 2016b; Belinkov et al., 2017b) and syntactic (Linzen et al., 2016; Tran et al., 2018; Conneau et al., 2018) tasks. See Belinkov and Glass (2019) for a recent survey. Other studies carried a more fine-grained neuronlevel analysis for NMT and LM (Dalvi et al., 2019; Bau et al., 2019; Lakretz et al., 2019). While previous work focused on words, here we compare units of different granularities. Subword translation units aim at reducing the vocabulary size and the out-of-vocabulary (OOV) rate. Researchers have used BPE units (Sennrich et al., 2016), morphological segmentation (Bradbury and Socher, 2016), characters (Durrani et al., 2014; Lee et al., 2017), and hybrid units (Ling et al., 2015; Costa-juss`a and Fonollosa, 2016) to address th"
N19-1154,I17-1001,1,0.895397,"Missing"
N19-1154,C16-1333,0,0.0223916,"U (Papineni et al., 2002). We trained the morphological classifiers and we tested them on a concatenation of the NEWS and the TED testsets, which were automatically tagged as described in the next paragraph. We trained and evaluated the semantic and the syntactic classifiers on existing annotated corpora. See Table 3 for details about the datasets. 1507 Taggers We used RDRPOST (Nguyen et al., 2014) to annotate data for the classifier. For semantic tagging, we used the gold-annotated semantic tags from the Groningen Parallel Meaning Bank (Abzianidze et al., 2017), which were made available by (Bjerva et al., 2016). The tags are grouped into coarse categories such as events, names, time, and logical expressions. There is enough data for English (≈42K), and we randomly sampled the same amount of data we used to train our morphological classifiers to train the semantic classifiers. Yet, only 1,863 annotated sentences (12,783 tokens) were available for German. Thus, in the experiments, we performed 5-fold cross-validation. For CCG supertagging, we used the English CCGBank (Hockenmaier and Steedman, 2007), which contains 41,586/2,407 train/test sentences.4 See Table 3 for more detailed statistics about the"
N19-1154,W16-2308,0,0.171762,"embeddings for 3M, 2M, and 2.5M words/phrases. The problem is typically addressed using byte-pair encoding (BPE), where words are segmented into pseudo-word sequences (Sennrich et al., 2016). 1504 Proceedings of NAACL-HLT 2019, pages 1504–1516 c Minneapolis, Minnesota, June 2 - June 7, 2019. 2019 Association for Computational Linguistics A less popular solution is to use characters as the basic unit (Chung et al., 2016; Lee et al., 2017), and in the case of morphologically complex languages, yet another alternative is to reduce the vocabulary size by using unsupervised morpheme segmentation (Bradbury and Socher, 2016). The impact of using different units of representation in NMT models has been studied in previous work (Ling et al., 2015; Costa-juss`a and Fonollosa, 2016; Chung et al., 2016; Lee et al., 2017, among others), but the focus has been exclusively on the quality of the resulting translation output. However, it remains unclear what input and output units should be chosen if we are primarily interested in representation learning. Here, we aim at bridging this gap by evaluating the quality of NMT-derived embeddings originating from units of different granularity when used for modeling morphology, s"
N19-1154,P16-1160,0,0.0282665,"st NLP applications need to handle vocabularies of millions of words, e.g., word2vec (Mikolov et al., 2013b), GloVe (Pennington et al., 2014) and FastText (Mikolov et al., 2018) offer pre-trained embeddings for 3M, 2M, and 2.5M words/phrases. The problem is typically addressed using byte-pair encoding (BPE), where words are segmented into pseudo-word sequences (Sennrich et al., 2016). 1504 Proceedings of NAACL-HLT 2019, pages 1504–1516 c Minneapolis, Minnesota, June 2 - June 7, 2019. 2019 Association for Computational Linguistics A less popular solution is to use characters as the basic unit (Chung et al., 2016; Lee et al., 2017), and in the case of morphologically complex languages, yet another alternative is to reduce the vocabulary size by using unsupervised morpheme segmentation (Bradbury and Socher, 2016). The impact of using different units of representation in NMT models has been studied in previous work (Ling et al., 2015; Costa-juss`a and Fonollosa, 2016; Chung et al., 2016; Lee et al., 2017, among others), but the focus has been exclusively on the quality of the resulting translation output. However, it remains unclear what input and output units should be chosen if we are primarily intere"
N19-1154,P18-1198,0,0.0296093,"Missing"
N19-1154,P16-2058,0,0.042031,"Missing"
N19-1154,I17-1015,1,0.857534,"ones are superior for morphology and are also more robust to noise. There is also value in combining different representations. 2 Related Work Representation analysis aims at demystifying what is learned inside the neural network blackbox. This includes analyzing word and sentence embeddings (Adi et al., 2017; Qian et al., 2016b; Ganesh et al., 2017; Conneau et al., 2018, among others), RNN states (Qian et al., 2016a; Shi et al., 2016; Wu and King, 2016; Wang et al., 2017), and NMT representations (Shi et al., 2016; Belinkov et al., 2017a), as applied to morphological (Vylomova et al., 2017; Dalvi et al., 2017), semantic (Qian et al., 2016b; Belinkov et al., 2017b) and syntactic (Linzen et al., 2016; Tran et al., 2018; Conneau et al., 2018) tasks. See Belinkov and Glass (2019) for a recent survey. Other studies carried a more fine-grained neuronlevel analysis for NMT and LM (Dalvi et al., 2019; Bau et al., 2019; Lakretz et al., 2019). While previous work focused on words, here we compare units of different granularities. Subword translation units aim at reducing the vocabulary size and the out-of-vocabulary (OOV) rate. Researchers have used BPE units (Sennrich et al., 2016), morphological segmentati"
N19-1154,N19-1423,0,0.121144,"modeling (LM) using long short-term memory networks (LSTMs) (Hochreiter and Schmidhuber, 1997). It has been further argued that complex auxiliary tasks such as neural machine translation (NMT) are better tailored for representation learning, as the internal understanding of the input language that needs to be built by the network to be able to translate from one language to another needs to be much more comprehensive compared to what would be needed for a simple word prediction task. This idea is implemented in the seq2seqbased CoVe model (McCann et al., 2017). More recently, the BERT model (Devlin et al., 2019) proposed to use representation from another NMT model, the Transformer, while optimizing for two LM-related auxiliary tasks: (i) masked language model and (ii) next sentence prediction. Another important aspect of representation learning is the basic unit the model operates on. In word2vec-style embeddings, it is the word, but this does not hold for NMT-based models, as computational and memory limitations, as of present, prevent NMT from using a large vocabulary, typically limiting it to 30-50k words (Wu et al., 2016). This is a severe limitation, as most NLP applications need to handle voca"
N19-1154,E14-4029,1,0.793179,"al., 2017b) and syntactic (Linzen et al., 2016; Tran et al., 2018; Conneau et al., 2018) tasks. See Belinkov and Glass (2019) for a recent survey. Other studies carried a more fine-grained neuronlevel analysis for NMT and LM (Dalvi et al., 2019; Bau et al., 2019; Lakretz et al., 2019). While previous work focused on words, here we compare units of different granularities. Subword translation units aim at reducing the vocabulary size and the out-of-vocabulary (OOV) rate. Researchers have used BPE units (Sennrich et al., 2016), morphological segmentation (Bradbury and Socher, 2016), characters (Durrani et al., 2014; Lee et al., 2017), and hybrid units (Ling et al., 2015; Costa-juss`a and Fonollosa, 2016) to address the OOV word problem in MT. The choice of translation unit impacts what the network learns. Sennrich (2017) carried a systematic error analysis by comparing subword versus character units and found the latter to be better at handling OOV and transliterations, whereas BPEbased subword units were better at capturing syntactic dependencies. In contrast, here we focus on representation learning, not translation quality. Robustness to noise is an important aspect in machine learning. It has been s"
N19-1154,P18-2006,0,0.0202511,"rns. Sennrich (2017) carried a systematic error analysis by comparing subword versus character units and found the latter to be better at handling OOV and transliterations, whereas BPEbased subword units were better at capturing syntactic dependencies. In contrast, here we focus on representation learning, not translation quality. Robustness to noise is an important aspect in machine learning. It has been studied for various models (Szegedy et al., 2014; Goodfellow et al., 2015), including NLP in general (Papernot et al., 2016; Samanta and Mehta, 2017; Liang et al., 2018; Jia and Liang, 2017; Ebrahimi et al., 2018; Gao et al., 2018), and character-based NMT in particular (Heigold et al., 2018; Belinkov and Bisk, 2018). Unlike this work, we compare robustness to noise for units of different granularity. Moreover, we focus on representation learning rather than on the quality of the translation output. 3 Methodology Our methodology is inspired by research on interpreting neural network (NN) models. A typical framework involves extracting feature representations from different components (e.g., encoder/decoder) of a trained model and then training a classifier to make predictions for an auxiliary task. Th"
N19-1154,W18-1807,0,0.473957,"sus character units and found the latter to be better at handling OOV and transliterations, whereas BPEbased subword units were better at capturing syntactic dependencies. In contrast, here we focus on representation learning, not translation quality. Robustness to noise is an important aspect in machine learning. It has been studied for various models (Szegedy et al., 2014; Goodfellow et al., 2015), including NLP in general (Papernot et al., 2016; Samanta and Mehta, 2017; Liang et al., 2018; Jia and Liang, 2017; Ebrahimi et al., 2018; Gao et al., 2018), and character-based NMT in particular (Heigold et al., 2018; Belinkov and Bisk, 2018). Unlike this work, we compare robustness to noise for units of different granularity. Moreover, we focus on representation learning rather than on the quality of the translation output. 3 Methodology Our methodology is inspired by research on interpreting neural network (NN) models. A typical framework involves extracting feature representations from different components (e.g., encoder/decoder) of a trained model and then training a classifier to make predictions for an auxiliary task. The performance of the trained classifier is considered to be a proxy for judging"
N19-1154,P06-1064,0,0.0101294,"ed the source side with word/BPE/Morfessor/character units. Similarly, when analyzing the representations from the decoder side, we trained the encoder representation with BPE units, and we varied the decoder side using word/BPE/char units. Our motivation for this setup is that we wanted to analyze the encoder/decoder side representations in isolation, keeping the other half of the network (i.e., the decoder/encoder) static across different settings.6 6 4 There are no available CCG banks for the other languages we experiment with, except for a German CCG bank, which is not publicly available (Hockenmaier, 2006). 5 The decoder has to be unidirectional as, at decoding time, the future is unknown. 6 Heigold et al. (2018) used a similar setup. Results We now present the evaluation results for using representations learned from different input units to predict morphology, semantics, and syntax. For subword and character units, we found the activation of the last subword/character unit of a word to be consistently better than using the average of all activations (See Table 4). Therefore, we report only the results using the Last method, for the remainder of the paper. de Last Avg cs ru sub char sub char s"
N19-1154,J07-3004,0,0.00913541,"ed semantic tags from the Groningen Parallel Meaning Bank (Abzianidze et al., 2017), which were made available by (Bjerva et al., 2016). The tags are grouped into coarse categories such as events, names, time, and logical expressions. There is enough data for English (≈42K), and we randomly sampled the same amount of data we used to train our morphological classifiers to train the semantic classifiers. Yet, only 1,863 annotated sentences (12,783 tokens) were available for German. Thus, in the experiments, we performed 5-fold cross-validation. For CCG supertagging, we used the English CCGBank (Hockenmaier and Steedman, 2007), which contains 41,586/2,407 train/test sentences.4 See Table 3 for more detailed statistics about the train/dev/test datasets we used. In our experiments, we used 50k BPE operations and we limited the vocabulary of all systems to 50k. Moreover, we trained the word, BPE, Morfessor, and character-based systems with maximum sentence lengths of 80, 100, 100, and 400 units, respectively. For the classification tasks, we used a logistic regression classifier whose input is either the hidden states in the case of the word-based models, or the Last or the Average representations in the case of chara"
N19-1154,D17-1215,0,0.019313,"what the network learns. Sennrich (2017) carried a systematic error analysis by comparing subword versus character units and found the latter to be better at handling OOV and transliterations, whereas BPEbased subword units were better at capturing syntactic dependencies. In contrast, here we focus on representation learning, not translation quality. Robustness to noise is an important aspect in machine learning. It has been studied for various models (Szegedy et al., 2014; Goodfellow et al., 2015), including NLP in general (Papernot et al., 2016; Samanta and Mehta, 2017; Liang et al., 2018; Jia and Liang, 2017; Ebrahimi et al., 2018; Gao et al., 2018), and character-based NMT in particular (Heigold et al., 2018; Belinkov and Bisk, 2018). Unlike this work, we compare robustness to noise for units of different granularity. Moreover, we focus on representation learning rather than on the quality of the translation output. 3 Methodology Our methodology is inspired by research on interpreting neural network (NN) models. A typical framework involves extracting feature representations from different components (e.g., encoder/decoder) of a trained model and then training a classifier to make predictions fo"
N19-1154,N19-1002,0,0.0260977,"016b; Ganesh et al., 2017; Conneau et al., 2018, among others), RNN states (Qian et al., 2016a; Shi et al., 2016; Wu and King, 2016; Wang et al., 2017), and NMT representations (Shi et al., 2016; Belinkov et al., 2017a), as applied to morphological (Vylomova et al., 2017; Dalvi et al., 2017), semantic (Qian et al., 2016b; Belinkov et al., 2017b) and syntactic (Linzen et al., 2016; Tran et al., 2018; Conneau et al., 2018) tasks. See Belinkov and Glass (2019) for a recent survey. Other studies carried a more fine-grained neuronlevel analysis for NMT and LM (Dalvi et al., 2019; Bau et al., 2019; Lakretz et al., 2019). While previous work focused on words, here we compare units of different granularities. Subword translation units aim at reducing the vocabulary size and the out-of-vocabulary (OOV) rate. Researchers have used BPE units (Sennrich et al., 2016), morphological segmentation (Bradbury and Socher, 2016), characters (Durrani et al., 2014; Lee et al., 2017), and hybrid units (Ling et al., 2015; Costa-juss`a and Fonollosa, 2016) to address the OOV word problem in MT. The choice of translation unit impacts what the network learns. Sennrich (2017) carried a systematic error analysis by comparing subwo"
N19-1154,Q17-1026,0,0.182884,"need to handle vocabularies of millions of words, e.g., word2vec (Mikolov et al., 2013b), GloVe (Pennington et al., 2014) and FastText (Mikolov et al., 2018) offer pre-trained embeddings for 3M, 2M, and 2.5M words/phrases. The problem is typically addressed using byte-pair encoding (BPE), where words are segmented into pseudo-word sequences (Sennrich et al., 2016). 1504 Proceedings of NAACL-HLT 2019, pages 1504–1516 c Minneapolis, Minnesota, June 2 - June 7, 2019. 2019 Association for Computational Linguistics A less popular solution is to use characters as the basic unit (Chung et al., 2016; Lee et al., 2017), and in the case of morphologically complex languages, yet another alternative is to reduce the vocabulary size by using unsupervised morpheme segmentation (Bradbury and Socher, 2016). The impact of using different units of representation in NMT models has been studied in previous work (Ling et al., 2015; Costa-juss`a and Fonollosa, 2016; Chung et al., 2016; Lee et al., 2017, among others), but the focus has been exclusively on the quality of the resulting translation output. However, it remains unclear what input and output units should be chosen if we are primarily interested in representat"
N19-1154,Q16-1037,0,0.0359514,"n combining different representations. 2 Related Work Representation analysis aims at demystifying what is learned inside the neural network blackbox. This includes analyzing word and sentence embeddings (Adi et al., 2017; Qian et al., 2016b; Ganesh et al., 2017; Conneau et al., 2018, among others), RNN states (Qian et al., 2016a; Shi et al., 2016; Wu and King, 2016; Wang et al., 2017), and NMT representations (Shi et al., 2016; Belinkov et al., 2017a), as applied to morphological (Vylomova et al., 2017; Dalvi et al., 2017), semantic (Qian et al., 2016b; Belinkov et al., 2017b) and syntactic (Linzen et al., 2016; Tran et al., 2018; Conneau et al., 2018) tasks. See Belinkov and Glass (2019) for a recent survey. Other studies carried a more fine-grained neuronlevel analysis for NMT and LM (Dalvi et al., 2019; Bau et al., 2019; Lakretz et al., 2019). While previous work focused on words, here we compare units of different granularities. Subword translation units aim at reducing the vocabulary size and the out-of-vocabulary (OOV) rate. Researchers have used BPE units (Sennrich et al., 2016), morphological segmentation (Bradbury and Socher, 2016), characters (Durrani et al., 2014; Lee et al., 2017), and h"
N19-1154,L18-1008,0,0.0277678,"y tasks: (i) masked language model and (ii) next sentence prediction. Another important aspect of representation learning is the basic unit the model operates on. In word2vec-style embeddings, it is the word, but this does not hold for NMT-based models, as computational and memory limitations, as of present, prevent NMT from using a large vocabulary, typically limiting it to 30-50k words (Wu et al., 2016). This is a severe limitation, as most NLP applications need to handle vocabularies of millions of words, e.g., word2vec (Mikolov et al., 2013b), GloVe (Pennington et al., 2014) and FastText (Mikolov et al., 2018) offer pre-trained embeddings for 3M, 2M, and 2.5M words/phrases. The problem is typically addressed using byte-pair encoding (BPE), where words are segmented into pseudo-word sequences (Sennrich et al., 2016). 1504 Proceedings of NAACL-HLT 2019, pages 1504–1516 c Minneapolis, Minnesota, June 2 - June 7, 2019. 2019 Association for Computational Linguistics A less popular solution is to use characters as the basic unit (Chung et al., 2016; Lee et al., 2017), and in the case of morphologically complex languages, yet another alternative is to reduce the vocabulary size by using unsupervised morph"
N19-1154,E14-2005,0,0.0123355,"7) and IWSLT (Cettolo et al., 2016). We trained the MT models using a concatenation of the NEWS and the TED training datasets, and we tested on official TED test sets (testsets-11-13) to perform the evaluation using BLEU (Papineni et al., 2002). We trained the morphological classifiers and we tested them on a concatenation of the NEWS and the TED testsets, which were automatically tagged as described in the next paragraph. We trained and evaluated the semantic and the syntactic classifiers on existing annotated corpora. See Table 3 for details about the datasets. 1507 Taggers We used RDRPOST (Nguyen et al., 2014) to annotate data for the classifier. For semantic tagging, we used the gold-annotated semantic tags from the Groningen Parallel Meaning Bank (Abzianidze et al., 2017), which were made available by (Bjerva et al., 2016). The tags are grouped into coarse categories such as events, names, time, and logical expressions. There is enough data for English (≈42K), and we randomly sampled the same amount of data we used to train our morphological classifiers to train the semantic classifiers. Yet, only 1,863 annotated sentences (12,783 tokens) were available for German. Thus, in the experiments, we pe"
N19-1154,P02-1040,0,0.105423,"er training data for English (en), German (de), Russian (ru), and Czech (cs). Here, CV stands for cross-validation. 5 Experimental Setup Data and Languages We trained NMT systems for four language pairs: German-English, CzechEnglish, Russian-English, and English-German, using data made available through two popular machine translation campaigns, namely, WMT (Bojar et al., 2017) and IWSLT (Cettolo et al., 2016). We trained the MT models using a concatenation of the NEWS and the TED training datasets, and we tested on official TED test sets (testsets-11-13) to perform the evaluation using BLEU (Papineni et al., 2002). We trained the morphological classifiers and we tested them on a concatenation of the NEWS and the TED testsets, which were automatically tagged as described in the next paragraph. We trained and evaluated the semantic and the syntactic classifiers on existing annotated corpora. See Table 3 for details about the datasets. 1507 Taggers We used RDRPOST (Nguyen et al., 2014) to annotate data for the classifier. For semantic tagging, we used the gold-annotated semantic tags from the Groningen Parallel Meaning Bank (Abzianidze et al., 2017), which were made available by (Bjerva et al., 2016). The"
N19-1154,D14-1162,0,0.0879568,"optimizing for two LM-related auxiliary tasks: (i) masked language model and (ii) next sentence prediction. Another important aspect of representation learning is the basic unit the model operates on. In word2vec-style embeddings, it is the word, but this does not hold for NMT-based models, as computational and memory limitations, as of present, prevent NMT from using a large vocabulary, typically limiting it to 30-50k words (Wu et al., 2016). This is a severe limitation, as most NLP applications need to handle vocabularies of millions of words, e.g., word2vec (Mikolov et al., 2013b), GloVe (Pennington et al., 2014) and FastText (Mikolov et al., 2018) offer pre-trained embeddings for 3M, 2M, and 2.5M words/phrases. The problem is typically addressed using byte-pair encoding (BPE), where words are segmented into pseudo-word sequences (Sennrich et al., 2016). 1504 Proceedings of NAACL-HLT 2019, pages 1504–1516 c Minneapolis, Minnesota, June 2 - June 7, 2019. 2019 Association for Computational Linguistics A less popular solution is to use characters as the basic unit (Chung et al., 2016; Lee et al., 2017), and in the case of morphologically complex languages, yet another alternative is to reduce the vocabul"
N19-1154,N18-1202,0,0.211861,"NLP task could be useful for other tasks as well. For example, word embeddings learned for a simple word prediction task in context, word2vec-style (Mikolov et al., 2013b), have now become almost obligatory in state-of-the-art NLP models. One issue with such word embeddings is that the resulting representation is context-independent. Recently, it has been shown that huge performance gains can be achieved by contextualizing the representations, so that the same word could have a different embedding in different contexts. This is best achieved by changing the auxiliary task. For example, ELMo (Peters et al., 2018) learns contextualized word embeddings from language modeling (LM) using long short-term memory networks (LSTMs) (Hochreiter and Schmidhuber, 1997). It has been further argued that complex auxiliary tasks such as neural machine translation (NMT) are better tailored for representation learning, as the internal understanding of the input language that needs to be built by the network to be able to translate from one language to another needs to be much more comprehensive compared to what would be needed for a simple word prediction task. This idea is implemented in the seq2seqbased CoVe model (M"
N19-1154,P17-2095,1,0.861481,"rent word.2 Word Representation Units We consider four representation units: words, byte-pair encoding (BPE) units, morphological units, and characters. Table 2 shows an example of each representation unit. BPE splits words into symbols (a symbol is a sequence of characters) and then iteratively replaces the most frequent sequences of symbols with a new merged symbol. In essence, frequent character n-grams merge to form one symbol. The number of merge operations is controlled by a hyper-parameter OP; a high value of OP means coarse segmentation and a low value means fine-grained segmentation (Sajjad et al., 2017). For morphologically segmented units, we use an unsupervised morphological segmenter, Morfessor (Smit et al., 2014). Note that although BPE and Morfessor segment words at a similar level of granularity, the segmentation generated by Morfessor is linguistically motivated. For example, it splits the gerund verb shooting into root shoot and the suffix ing. Compare this to the BPE segmentation sho + oting, which has no linguistic connotation. On the extreme, the fully character-level units treat each word as a sequence of characters. Extracting Activations for Subword and Character Units (ii) Las"
N19-1154,E17-2060,0,0.0280466,"MT and LM (Dalvi et al., 2019; Bau et al., 2019; Lakretz et al., 2019). While previous work focused on words, here we compare units of different granularities. Subword translation units aim at reducing the vocabulary size and the out-of-vocabulary (OOV) rate. Researchers have used BPE units (Sennrich et al., 2016), morphological segmentation (Bradbury and Socher, 2016), characters (Durrani et al., 2014; Lee et al., 2017), and hybrid units (Ling et al., 2015; Costa-juss`a and Fonollosa, 2016) to address the OOV word problem in MT. The choice of translation unit impacts what the network learns. Sennrich (2017) carried a systematic error analysis by comparing subword versus character units and found the latter to be better at handling OOV and transliterations, whereas BPEbased subword units were better at capturing syntactic dependencies. In contrast, here we focus on representation learning, not translation quality. Robustness to noise is an important aspect in machine learning. It has been studied for various models (Szegedy et al., 2014; Goodfellow et al., 2015), including NLP in general (Papernot et al., 2016; Samanta and Mehta, 2017; Liang et al., 2018; Jia and Liang, 2017; Ebrahimi et al., 201"
N19-1154,P16-1162,0,0.661548,"but this does not hold for NMT-based models, as computational and memory limitations, as of present, prevent NMT from using a large vocabulary, typically limiting it to 30-50k words (Wu et al., 2016). This is a severe limitation, as most NLP applications need to handle vocabularies of millions of words, e.g., word2vec (Mikolov et al., 2013b), GloVe (Pennington et al., 2014) and FastText (Mikolov et al., 2018) offer pre-trained embeddings for 3M, 2M, and 2.5M words/phrases. The problem is typically addressed using byte-pair encoding (BPE), where words are segmented into pseudo-word sequences (Sennrich et al., 2016). 1504 Proceedings of NAACL-HLT 2019, pages 1504–1516 c Minneapolis, Minnesota, June 2 - June 7, 2019. 2019 Association for Computational Linguistics A less popular solution is to use characters as the basic unit (Chung et al., 2016; Lee et al., 2017), and in the case of morphologically complex languages, yet another alternative is to reduce the vocabulary size by using unsupervised morpheme segmentation (Bradbury and Socher, 2016). The impact of using different units of representation in NMT models has been studied in previous work (Ling et al., 2015; Costa-juss`a and Fonollosa, 2016; Chung e"
N19-1154,D16-1159,0,0.0278884,"respect to noise. We found that while representations derived from morphological segments are better for modeling non-local syntactic and semantic dependencies, character-based ones are superior for morphology and are also more robust to noise. There is also value in combining different representations. 2 Related Work Representation analysis aims at demystifying what is learned inside the neural network blackbox. This includes analyzing word and sentence embeddings (Adi et al., 2017; Qian et al., 2016b; Ganesh et al., 2017; Conneau et al., 2018, among others), RNN states (Qian et al., 2016a; Shi et al., 2016; Wu and King, 2016; Wang et al., 2017), and NMT representations (Shi et al., 2016; Belinkov et al., 2017a), as applied to morphological (Vylomova et al., 2017; Dalvi et al., 2017), semantic (Qian et al., 2016b; Belinkov et al., 2017b) and syntactic (Linzen et al., 2016; Tran et al., 2018; Conneau et al., 2018) tasks. See Belinkov and Glass (2019) for a recent survey. Other studies carried a more fine-grained neuronlevel analysis for NMT and LM (Dalvi et al., 2019; Bau et al., 2019; Lakretz et al., 2019). While previous work focused on words, here we compare units of different granularities. S"
N19-1154,E14-2006,0,0.157575,"Missing"
N19-1154,D16-1079,0,0.0226064,"Missing"
N19-1154,D18-1503,0,0.0447618,"Missing"
N19-1154,W17-4115,0,0.0210815,"encies, character-based ones are superior for morphology and are also more robust to noise. There is also value in combining different representations. 2 Related Work Representation analysis aims at demystifying what is learned inside the neural network blackbox. This includes analyzing word and sentence embeddings (Adi et al., 2017; Qian et al., 2016b; Ganesh et al., 2017; Conneau et al., 2018, among others), RNN states (Qian et al., 2016a; Shi et al., 2016; Wu and King, 2016; Wang et al., 2017), and NMT representations (Shi et al., 2016; Belinkov et al., 2017a), as applied to morphological (Vylomova et al., 2017; Dalvi et al., 2017), semantic (Qian et al., 2016b; Belinkov et al., 2017b) and syntactic (Linzen et al., 2016; Tran et al., 2018; Conneau et al., 2018) tasks. See Belinkov and Glass (2019) for a recent survey. Other studies carried a more fine-grained neuronlevel analysis for NMT and LM (Dalvi et al., 2019; Bau et al., 2019; Lakretz et al., 2019). While previous work focused on words, here we compare units of different granularities. Subword translation units aim at reducing the vocabulary size and the out-of-vocabulary (OOV) rate. Researchers have used BPE units (Sennrich et al., 2016), mor"
N19-1154,D16-1181,0,0.0642653,"Missing"
P13-2001,E06-1047,0,0.149589,"012), or by concatenating the parallel data for both languages (Nakov and Ng, 2009). These translation methods generally require parallel data, for which hardly any exists between dialects and MSA. Instead of translating between a dialect and MSA, we tried to narrow down the lexical, morphological and phonetic gap between them using a character-level conversion model, which we trained on a small set of parallel dialect/MSA word pairs. In the context of Arabic dialects3 , most previous work focused on converting dialects to MSA and vice versa to improve the processing of dialects (Sawaf, 2010; Chiang et al., 2006; Mohamed et al., 2012; Utiyama and Isahara, 2008). Sawaf (2010) proposed a dialect to MSA normalization that used character-level rules and morphological analysis. Salloum and Habash (2011) also used a rule-based method to generate MSA paraphrases of dialectal out-of-vocabulary (OOV) and low frequency words. Instead of rules, we automatically We constructed baselines that were based on the following training data: - An Egyptian/English parallel corpus consisting of ≈38k sentences, which is part of the LDC2012T09 corpus (Zbib et al., 2012). We randomly divided it into 32k sentences for trainin"
P13-2001,P10-1048,1,0.686515,"LM experiments also affirmed the importance of in-domain English LMs. We also showed that a conversion does not imply a straight forward usage of MSA resources and there is a need for adaptation which we fulfilled using phrase-table merging (Nakov and Ng, 2009). 2 2.1 Previous Work Baseline Our work is related to research on MT from a resource poor language (to other languages) by pivoting on a closely related resource rich language. This can be done by either translating between the related languages using word-level translation, character level transformations, and language specific rules (Durrani et al., 2010; Hajiˇc et al., 2000; Nakov and Tiedemann, 2012), or by concatenating the parallel data for both languages (Nakov and Ng, 2009). These translation methods generally require parallel data, for which hardly any exists between dialects and MSA. Instead of translating between a dialect and MSA, we tried to narrow down the lexical, morphological and phonetic gap between them using a character-level conversion model, which we trained on a small set of parallel dialect/MSA word pairs. In the context of Arabic dialects3 , most previous work focused on converting dialects to MSA and vice versa to impr"
P13-2001,N13-1044,0,0.12911,"actic challenge in this sentence, since the Egyptian word order in interrogative sentences is normally different from the MSA word order: the interrogative particle appears at the end of the sentence instead of at the beginning. Addressing this problem might have improved translation. The above analysis suggests that incorporating deeper linguistic information in the conversion procedure could improve translation quality. In particular, using a morphological analyzer seeems like a promising possibility. One approach could be to run a morphological analyzer for dialectal Arabic (e.g. MADA-ARZ (Habash et al., 2013)) on the original EG sentence and another analyzer for MSA (such as MADA) on the converted EG0 sentence, and then to compare the morphological features. Discrepancies should be probabilistically incorporated in the conversion. Exploring this approach is left for future work. 4 Conclusion We presented an Egyptian to English MT system. In contrast to previous work, we used an automatic conversion method to map Egyptian close to MSA. The converted Egyptian EG0 had fewer OOV words and spelling mistakes and improved language handling. The MT system built on the adapted parallel data showed an impro"
P13-2001,A00-1002,0,0.0541606,"Missing"
P13-2001,W11-2123,0,0.0145373,"(Och and Ney, 2003), and symmetrized the alignments using grow-diag-final-and heuristic (Koehn et al., 2003). We trained a phrasal MT system (Koehn et al., 2003). We built five-gram LMs using KenLM 3 Due to space limitations, we restrict discussion to work on dialects only. 4 Arabic News (LDC2004T17), eTIRR (LDC2004E72), and parallel corpora the GALE program 2 B1 B2 B3 B4 Train LM AR EG EG EG GW GW EGen EGen GW BLEU OOV 7.48 12.82 13.94 14.23 6.7 5.2 5.2 5.2 Table 1: Baseline results using the EG and AR training sets with GW and EGen corpora for LM training with modified Kneser-Ney smoothing (Heafield, 2011). In case of more than one LM, we tuned their weights on a development set using Minimum Error Rate Training (Och and Ney, 2003). We built several baseline systems as follows: – B1 used AR for training a translation model and GW for LM. – B2-B4 systems used identical training data, namely EG, with the GW, EGen , or both for B2, B3, and B4 respectively for language modeling. Table 1 reports the baseline results. The system trained on AR (B1) performed poorly compared to the one trained on EG (B2) with a 6.75 BLEU points difference. This highlights the difference between MSA and Egyptian. Using"
P13-2001,N03-1017,0,0.00522573,"g of 200k sentences from LDC4 . We refer to this corpus as the AR corpus. For language modeling, we used either EGen or the English side of the AR corpus plus the English side of NIST12 training data and English GigaWord v5. We refer to this corpus as GW. We tokenized Egyptian and Arabic according to the ATB tokenization scheme using the MADA+TOKAN morphological analyzer and tokenizer v3.1 (Roth et al., 2008). Word elongations were already fixed in the corpus. We wordaligned the parallel data using GIZA++ (Och and Ney, 2003), and symmetrized the alignments using grow-diag-final-and heuristic (Koehn et al., 2003). We trained a phrasal MT system (Koehn et al., 2003). We built five-gram LMs using KenLM 3 Due to space limitations, we restrict discussion to work on dialects only. 4 Arabic News (LDC2004T17), eTIRR (LDC2004E72), and parallel corpora the GALE program 2 B1 B2 B3 B4 Train LM AR EG EG EG GW GW EGen EGen GW BLEU OOV 7.48 12.82 13.94 14.23 6.7 5.2 5.2 5.2 Table 1: Baseline results using the EG and AR training sets with GW and EGen corpora for LM training with modified Kneser-Ney smoothing (Heafield, 2011). In case of more than one LM, we tuned their weights on a development set using Minimum Erro"
P13-2001,P12-2035,0,0.0480451,"ting the parallel data for both languages (Nakov and Ng, 2009). These translation methods generally require parallel data, for which hardly any exists between dialects and MSA. Instead of translating between a dialect and MSA, we tried to narrow down the lexical, morphological and phonetic gap between them using a character-level conversion model, which we trained on a small set of parallel dialect/MSA word pairs. In the context of Arabic dialects3 , most previous work focused on converting dialects to MSA and vice versa to improve the processing of dialects (Sawaf, 2010; Chiang et al., 2006; Mohamed et al., 2012; Utiyama and Isahara, 2008). Sawaf (2010) proposed a dialect to MSA normalization that used character-level rules and morphological analysis. Salloum and Habash (2011) also used a rule-based method to generate MSA paraphrases of dialectal out-of-vocabulary (OOV) and low frequency words. Instead of rules, we automatically We constructed baselines that were based on the following training data: - An Egyptian/English parallel corpus consisting of ≈38k sentences, which is part of the LDC2012T09 corpus (Zbib et al., 2012). We randomly divided it into 32k sentences for training, 2k for development"
P13-2001,N12-1006,0,0.379251,"r, we applied an adaptation method to incorporate MSA/English parallel data. The contributions of this paper are as follows: – We trained an Egyptian/MSA transformation model to make Egyptian look similar to MSA. We publicly released the training data. – We built a phrasal Machine Translation (MT) system on adapted Egyptian/English parallel data, which outperformed a non-adapted baseline by 1.87 BLEU points. – We used phrase-table merging (Nakov and Ng, 2009) to utilize MSA/English parallel data with the available in-domain parallel data. learnt character mappings from dialect/MSA word pairs. Zbib et al. (2012) explored several methods for dialect/English MT. Their best Egyptian/English system was trained on dialect/English parallel data. They used two language models built from the English GigaWord corpus and from a large web crawl. Their best system outperformed manually translating Egyptian to MSA then translating using an MSA/English system. In contrast, we showed that training on in-domain dialectal data irrespective of its small size is better than training on large MSA/English data. Our LM experiments also affirmed the importance of in-domain English LMs. We also showed that a conversion does"
P13-2001,D09-1141,0,0.390382,"using character-level transformations and word n-gram models that handle spelling mistakes, phonological variations, and morphological transformations. Later, we applied an adaptation method to incorporate MSA/English parallel data. The contributions of this paper are as follows: – We trained an Egyptian/MSA transformation model to make Egyptian look similar to MSA. We publicly released the training data. – We built a phrasal Machine Translation (MT) system on adapted Egyptian/English parallel data, which outperformed a non-adapted baseline by 1.87 BLEU points. – We used phrase-table merging (Nakov and Ng, 2009) to utilize MSA/English parallel data with the available in-domain parallel data. learnt character mappings from dialect/MSA word pairs. Zbib et al. (2012) explored several methods for dialect/English MT. Their best Egyptian/English system was trained on dialect/English parallel data. They used two language models built from the English GigaWord corpus and from a large web crawl. Their best system outperformed manually translating Egyptian to MSA then translating using an MSA/English system. In contrast, we showed that training on in-domain dialectal data irrespective of its small size is bett"
P13-2001,P12-2059,0,0.0156256,"e of in-domain English LMs. We also showed that a conversion does not imply a straight forward usage of MSA resources and there is a need for adaptation which we fulfilled using phrase-table merging (Nakov and Ng, 2009). 2 2.1 Previous Work Baseline Our work is related to research on MT from a resource poor language (to other languages) by pivoting on a closely related resource rich language. This can be done by either translating between the related languages using word-level translation, character level transformations, and language specific rules (Durrani et al., 2010; Hajiˇc et al., 2000; Nakov and Tiedemann, 2012), or by concatenating the parallel data for both languages (Nakov and Ng, 2009). These translation methods generally require parallel data, for which hardly any exists between dialects and MSA. Instead of translating between a dialect and MSA, we tried to narrow down the lexical, morphological and phonetic gap between them using a character-level conversion model, which we trained on a small set of parallel dialect/MSA word pairs. In the context of Arabic dialects3 , most previous work focused on converting dialects to MSA and vice versa to improve the processing of dialects (Sawaf, 2010; Chia"
P13-2001,J03-1002,0,0.00581558,"(2012) to directly compare to their results. - An MSA/English parallel corpus consisting of 200k sentences from LDC4 . We refer to this corpus as the AR corpus. For language modeling, we used either EGen or the English side of the AR corpus plus the English side of NIST12 training data and English GigaWord v5. We refer to this corpus as GW. We tokenized Egyptian and Arabic according to the ATB tokenization scheme using the MADA+TOKAN morphological analyzer and tokenizer v3.1 (Roth et al., 2008). Word elongations were already fixed in the corpus. We wordaligned the parallel data using GIZA++ (Och and Ney, 2003), and symmetrized the alignments using grow-diag-final-and heuristic (Koehn et al., 2003). We trained a phrasal MT system (Koehn et al., 2003). We built five-gram LMs using KenLM 3 Due to space limitations, we restrict discussion to work on dialects only. 4 Arabic News (LDC2004T17), eTIRR (LDC2004E72), and parallel corpora the GALE program 2 B1 B2 B3 B4 Train LM AR EG EG EG GW GW EGen EGen GW BLEU OOV 7.48 12.82 13.94 14.23 6.7 5.2 5.2 5.2 Table 1: Baseline results using the EG and AR training sets with GW and EGen corpora for LM training with modified Kneser-Ney smoothing (Heafield, 2011). In"
P13-2001,P08-2030,0,0.0379788,"is corpus as EG and the English part of it as EGen . We did not have access to the training/test splits of Zbib et al. (2012) to directly compare to their results. - An MSA/English parallel corpus consisting of 200k sentences from LDC4 . We refer to this corpus as the AR corpus. For language modeling, we used either EGen or the English side of the AR corpus plus the English side of NIST12 training data and English GigaWord v5. We refer to this corpus as GW. We tokenized Egyptian and Arabic according to the ATB tokenization scheme using the MADA+TOKAN morphological analyzer and tokenizer v3.1 (Roth et al., 2008). Word elongations were already fixed in the corpus. We wordaligned the parallel data using GIZA++ (Och and Ney, 2003), and symmetrized the alignments using grow-diag-final-and heuristic (Koehn et al., 2003). We trained a phrasal MT system (Koehn et al., 2003). We built five-gram LMs using KenLM 3 Due to space limitations, we restrict discussion to work on dialects only. 4 Arabic News (LDC2004T17), eTIRR (LDC2004E72), and parallel corpora the GALE program 2 B1 B2 B3 B4 Train LM AR EG EG EG GW GW EGen EGen GW BLEU OOV 7.48 12.82 13.94 14.23 6.7 5.2 5.2 5.2 Table 1: Baseline results using the EG"
P13-2001,W11-2602,0,0.266595,"ects and MSA. Instead of translating between a dialect and MSA, we tried to narrow down the lexical, morphological and phonetic gap between them using a character-level conversion model, which we trained on a small set of parallel dialect/MSA word pairs. In the context of Arabic dialects3 , most previous work focused on converting dialects to MSA and vice versa to improve the processing of dialects (Sawaf, 2010; Chiang et al., 2006; Mohamed et al., 2012; Utiyama and Isahara, 2008). Sawaf (2010) proposed a dialect to MSA normalization that used character-level rules and morphological analysis. Salloum and Habash (2011) also used a rule-based method to generate MSA paraphrases of dialectal out-of-vocabulary (OOV) and low frequency words. Instead of rules, we automatically We constructed baselines that were based on the following training data: - An Egyptian/English parallel corpus consisting of ≈38k sentences, which is part of the LDC2012T09 corpus (Zbib et al., 2012). We randomly divided it into 32k sentences for training, 2k for development and 4k for testing. We henceforth refer to this corpus as EG and the English part of it as EGen . We did not have access to the training/test splits of Zbib et al. (201"
P13-2001,2010.amta-papers.5,0,0.351178,"Tiedemann, 2012), or by concatenating the parallel data for both languages (Nakov and Ng, 2009). These translation methods generally require parallel data, for which hardly any exists between dialects and MSA. Instead of translating between a dialect and MSA, we tried to narrow down the lexical, morphological and phonetic gap between them using a character-level conversion model, which we trained on a small set of parallel dialect/MSA word pairs. In the context of Arabic dialects3 , most previous work focused on converting dialects to MSA and vice versa to improve the processing of dialects (Sawaf, 2010; Chiang et al., 2006; Mohamed et al., 2012; Utiyama and Isahara, 2008). Sawaf (2010) proposed a dialect to MSA normalization that used character-level rules and morphological analysis. Salloum and Habash (2011) also used a rule-based method to generate MSA paraphrases of dialectal out-of-vocabulary (OOV) and low frequency words. Instead of rules, we automatically We constructed baselines that were based on the following training data: - An Egyptian/English parallel corpus consisting of ≈38k sentences, which is part of the LDC2012T09 corpus (Zbib et al., 2012). We randomly divided it into 32k"
P13-2001,P11-2007,0,0.209222,"Missing"
P13-2001,D11-1128,1,\N,Missing
P17-1080,2015.iwslt-evaluation.11,0,0.0948384,"Missing"
P17-1080,P16-1100,0,0.0161522,"Koehn and Hoang, 2007; Durrani et al., 2014). Characters and other sub-word units have become increasingly popular in neural MT, although they had also been used in phrase-based MT for handling morphologically-rich (Luong et al., 2010) or closely related language pairs (Durrani et al., 2010; Nakov and Tiedemann, 2012). In neural MT, such units are obtained in a pre-processing step—e.g. by byte-pair encoding (Sennrich et al., 2016) or the word-piece model (Wu et al., 2016)— or learned during training using a character-based convolutional/recurrent sub-network (Costa-juss`a and Fonollosa, 2016; Luong and Manning, 2016; Vylomova et al., 2016). The latter approach has the advantage of keeping the original word boundaries without requiring pre- and post-processing. Here we focus on a character CNN which has been used in language modeling and machine translation (Kim et al., 2015; Belinkov and Glass, 2016; Costa-juss`a and Fonollosa, 2016; Jozefowicz et al., 2016; Sajjad et al., 2017). We evaluate the quality of different representations learned by an MT system augmented with a character CNN in terms of POS and morphological tagging, and contrast them with a purely word-based system. 7 Conclusion Neural networ"
P17-1080,D10-1015,0,0.0631953,"echniques for representing morphological knowledge, such as word segmentation (Nieflen and Ney, 2000; Koehn and Word Char POS Accuracy ENC DEC BLEU Ar-En En-Ar 89.62 95.35 24.69 28.42 43.93 44.54 13.37 13.00 Table 4: POS tagging accuracy using word-based and char-based encoder/decoder representations. Knight, 2003; Badr et al., 2008) and factored translation and reordering models (Koehn and Hoang, 2007; Durrani et al., 2014). Characters and other sub-word units have become increasingly popular in neural MT, although they had also been used in phrase-based MT for handling morphologically-rich (Luong et al., 2010) or closely related language pairs (Durrani et al., 2010; Nakov and Tiedemann, 2012). In neural MT, such units are obtained in a pre-processing step—e.g. by byte-pair encoding (Sennrich et al., 2016) or the word-piece model (Wu et al., 2016)— or learned during training using a character-based convolutional/recurrent sub-network (Costa-juss`a and Fonollosa, 2016; Luong and Manning, 2016; Vylomova et al., 2016). The latter approach has the advantage of keeping the original word boundaries without requiring pre- and post-processing. Here we focus on a character CNN which has been used in language"
P17-1080,D13-1032,0,0.0236083,"Missing"
P17-1080,P12-2059,0,0.0233233,"(Nieflen and Ney, 2000; Koehn and Word Char POS Accuracy ENC DEC BLEU Ar-En En-Ar 89.62 95.35 24.69 28.42 43.93 44.54 13.37 13.00 Table 4: POS tagging accuracy using word-based and char-based encoder/decoder representations. Knight, 2003; Badr et al., 2008) and factored translation and reordering models (Koehn and Hoang, 2007; Durrani et al., 2014). Characters and other sub-word units have become increasingly popular in neural MT, although they had also been used in phrase-based MT for handling morphologically-rich (Luong et al., 2010) or closely related language pairs (Durrani et al., 2010; Nakov and Tiedemann, 2012). In neural MT, such units are obtained in a pre-processing step—e.g. by byte-pair encoding (Sennrich et al., 2016) or the word-piece model (Wu et al., 2016)— or learned during training using a character-based convolutional/recurrent sub-network (Costa-juss`a and Fonollosa, 2016; Luong and Manning, 2016; Vylomova et al., 2016). The latter approach has the advantage of keeping the original word boundaries without requiring pre- and post-processing. Here we focus on a character CNN which has been used in language modeling and machine translation (Kim et al., 2015; Belinkov and Glass, 2016; Costa"
P17-1080,C00-2162,0,0.212466,"om a neural MT encoder to predict syntactic properties on the English source side. In contrast, we focus on representations in morphologically-rich languages and evaluate both source and target sides across several criteria. Vylomova et al. (2016) also analyze different representations for morphologically-rich languages in MT, but do not directly measure the quality of the learned representations. Word representations in MT Machine translation systems that deal with morphologically-rich languages resort to various techniques for representing morphological knowledge, such as word segmentation (Nieflen and Ney, 2000; Koehn and Word Char POS Accuracy ENC DEC BLEU Ar-En En-Ar 89.62 95.35 24.69 28.42 43.93 44.54 13.37 13.00 Table 4: POS tagging accuracy using word-based and char-based encoder/decoder representations. Knight, 2003; Badr et al., 2008) and factored translation and reordering models (Koehn and Hoang, 2007; Durrani et al., 2014). Characters and other sub-word units have become increasingly popular in neural MT, although they had also been used in phrase-based MT for handling morphologically-rich (Luong et al., 2010) or closely related language pairs (Durrani et al., 2010; Nakov and Tiedemann, 20"
P17-1080,E03-1076,0,0.199308,"Missing"
P17-1080,pasha-etal-2014-madamira,0,0.026797,"Missing"
P17-1080,D15-1246,0,0.0820648,"Missing"
P17-1080,D16-1079,0,0.0296875,"itself can be modeled in different ways. For example, it may be an LSTM over outputs of the encoder. However, as we are interested in assessing the quality of the representations learned by the MT system, we choose to model the classifier as a simple feed-forward neural network with one hidden layer and a ReLU non-linearity. Arguably, if the learned representations are good, then a non-linear classifier should be able to extract useful information from them.2 We empha2 We also experimented with a linear classifier and observed similar trends to the non-linear case, but overall lower results; Qian et al. (2016b) reported similar findings. 862 Train Tokens Dev Tokens Test Tokens POS Tags Morph Tags Ar De Fr Cz Gold Pred BLEU Gold/Pred Gold/Pred Pred Pred 0.5M/2.7M 63K/114K 62K/16K 0.9M/4M 45K/50K 44K/25K 5.2M 55K 23K 2M 35K 20K Word/Char Word/Char Word/Char 42 1969 54 214 33 – 368 – 80.31/93.66 78.20/92.48 87.68/94.57 – – 89.62/95.35 88.33/94.66 93.54/94.63 94.61/95.55 75.71/79.10 24.7/28.4 9.9/10.7 29.6/30.4 37.8/38.8 23.2/25.4 Table 1: Statistics for annotated corpora in Arabic (Ar), German (De), French (Fr), and Czech (Cz). size that our goal is not to beat the state-of-the-art on a given task, b"
P17-1080,P16-1140,0,0.150611,"itself can be modeled in different ways. For example, it may be an LSTM over outputs of the encoder. However, as we are interested in assessing the quality of the representations learned by the MT system, we choose to model the classifier as a simple feed-forward neural network with one hidden layer and a ReLU non-linearity. Arguably, if the learned representations are good, then a non-linear classifier should be able to extract useful information from them.2 We empha2 We also experimented with a linear classifier and observed similar trends to the non-linear case, but overall lower results; Qian et al. (2016b) reported similar findings. 862 Train Tokens Dev Tokens Test Tokens POS Tags Morph Tags Ar De Fr Cz Gold Pred BLEU Gold/Pred Gold/Pred Pred Pred 0.5M/2.7M 63K/114K 62K/16K 0.9M/4M 45K/50K 44K/25K 5.2M 55K 23K 2M 35K 20K Word/Char Word/Char Word/Char 42 1969 54 214 33 – 368 – 80.31/93.66 78.20/92.48 87.68/94.57 – – 89.62/95.35 88.33/94.66 93.54/94.63 94.61/95.55 75.71/79.10 24.7/28.4 9.9/10.7 29.6/30.4 37.8/38.8 23.2/25.4 Table 1: Statistics for annotated corpora in Arabic (Ar), German (De), French (Fr), and Czech (Cz). size that our goal is not to beat the state-of-the-art on a given task, b"
P17-1080,P17-2095,1,0.861424,"Missing"
P17-1080,Q16-1027,0,0.0145163,"PUNC) whose accuracy improves quite a lot. Then there are plural nouns (NNS, DT+NNS) where the char-based model really shines, which makes sense linguistically as plurality in Arabic is usually expressed by certain suffixes (“-wn/yn” for masc. plural, “-At” for fem. plural). The charbased model is thus especially good with frequent tags and infrequent words, which is understandable given that infrequent words typically belong to frequent open categories like nouns and verbs. 4.2 Effect of encoder depth Modern NMT systems use very deep architectures with up to 8 or 16 layers (Wu et al., 2016; Zhou et al., 2016). We would like to understand what kind of information different layers capture. Given a trained NMT model with multiple layers, we extract feature representations from the different layers in the encoder. Let ENCli (s) denote the encoded representation of word wi after the l-th layer. We can vary l and train different classifiers to predict POS or morphological tags. Here we focus on the case of a 2-layer encoder-decoder model for simplicity (l 2 {1, 2}). Figure 6: POS tagging accuracy using representations from layers 0 (word vectors), 1, and 2, taken from encoders of different language pair"
P17-1080,C94-1027,0,0.0759209,"Missing"
P17-1080,P16-1162,0,0.118047,"Missing"
P17-1080,E17-1100,0,0.0558147,"Missing"
P17-1080,D07-1091,0,\N,Missing
P17-1080,P08-2039,1,\N,Missing
P17-1080,P10-1048,1,\N,Missing
P17-1080,C14-1041,1,\N,Missing
P17-1080,P16-2058,0,\N,Missing
P17-1080,C16-1124,0,\N,Missing
P17-1080,D16-1159,0,\N,Missing
P17-1080,2012.eamt-1.60,0,\N,Missing
P17-2095,P10-1048,1,0.856786,"ub-word segmentation based on BPE, and iii) two variants of character-based segmentation. We first map each source word to its corresponding segments (depending on the segmentation scheme), embed all segments of a word in vector space and feed them one-by-one to an encoder-decoder model. See Figure 1 for illustration. 2.1 Figure 1: Segmentation approaches for the word “b$rhm” “ ÑëQå.”; the blue vectors indicate the embedding(s) used before the encoding layer. 2.3 Morphological Segmentation Character-based models have been found to be effective in translating closely related language pairs (Durrani et al., 2010; Nakov and Tiedemann, 2012) and OOV words (Durrani et al., 2014). Ling et al. (2016) used character embeddings to address the OOV word problem. We explored them as an alternative to morphological segmentation. Their advantage is that character embeddings do not require any complicated pre- and post-processing step other than segmenting words into characters. The fully character-level encoder treats the source sentence as a sequence of letters, encoding each letter (including white-space) in the LSTM encoder (see Figure 1). The decoding may follow identical settings. We restricted the characte"
P17-2095,D11-1033,0,0.0328528,"ng several segmentation strategies. 3 Experiments In the following, we describe the data and system settings and later present the results of machine translation and POS tagging. LSTM in the (bidirectional) encoder and the decoder, with a size of 500. We limit the sentence length to 100 for MORPH, UNSEG, BPE, cCNN, and 500 for CHAR experiments. The source and target vocabularies are limited to 50k each. 3.1 3.2 Settings Data The MT systems were trained on 1.2 Million sentences, a concatenation of TED corpus (Cettolo et al., 2012), LDC NEWS data, QED (Guzm´an et al., 2013) and an MML-filtered (Axelrod et al., 2011) UN corpus.1 We used dev+test10 for tuning and tst11-14 for testing. For EnglishArabic, outputs were detokenized using MADA detokenizer. Before scoring the output, we normalized them and reference translations using the QCRI normalizer (Sajjad et al., 2013). Machine Translation Results Table 1 presents MT results using various segmentation strategies. Compared to the UNSEG system, the MORPH system2 improved translation quality by 4.6 and 1.6 BLEU points in Ar-to-En and Ento-Ar systems, respectively. The results also improved by up to 3 BLEU points for cCNN and CHAR systems in the Ar-to-En dire"
P17-2095,E14-4029,1,0.887411,"acter-based segmentation. We first map each source word to its corresponding segments (depending on the segmentation scheme), embed all segments of a word in vector space and feed them one-by-one to an encoder-decoder model. See Figure 1 for illustration. 2.1 Figure 1: Segmentation approaches for the word “b$rhm” “ ÑëQå.”; the blue vectors indicate the embedding(s) used before the encoding layer. 2.3 Morphological Segmentation Character-based models have been found to be effective in translating closely related language pairs (Durrani et al., 2010; Nakov and Tiedemann, 2012) and OOV words (Durrani et al., 2014). Ling et al. (2016) used character embeddings to address the OOV word problem. We explored them as an alternative to morphological segmentation. Their advantage is that character embeddings do not require any complicated pre- and post-processing step other than segmenting words into characters. The fully character-level encoder treats the source sentence as a sequence of letters, encoding each letter (including white-space) in the LSTM encoder (see Figure 1). The decoding may follow identical settings. We restricted the character-level representation to the Arabic side of the parallel corpus"
P17-2095,C96-1017,0,0.0492124,"ranslation system is sensitive to the ratio of source and target tokens, and a ratio close to 1 or greater, gives optimal performance. 1 Introduction Arabic word segmentation has shown to significantly improve output quality in NLP tasks such as machine translation (Habash and Sadat, 2006; Almahairi et al., 2016), part-of-speech tagging (Diab et al., 2004; Habash and Rambow, 2005), and information retrieval (M. Aljlayl and Grossman, 2002). A considerable amount of research has therefore been spent on Arabic morphological segmentation in the past two decades, ranging from rule-based analyzers (Beesley, 1996) to state-of-the-art statistical segmenters (Pasha et al., 2014; Abdelali et al., 2016; Khalifa et al., 2016). Morphological segmentation splits words into morphemes. For example, ‘‘wktAbnA” “ AJK . AJ»ð” (gloss: and our book) is decomposed into its stem H AJ» + ð”. and affixes as: “w+ ktAb +nA” “ AK+ . 601 Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 601–607 c Vancouver, Canada, July 30 - August 4, 2017. 2017 Association for Computational Linguistics https://doi.org/10.18653/v1/P17-2095 2 Segmentation Approaches We experimente"
P17-2095,P17-1080,1,0.841253,"ing a CNN over characters. The embedding are then provided to the encoder as input. The intuition is that the character-based word embedding should be able to learn the morphological phenomena a word inherits. Compared to fully characterlevel encoding, the encoder gets word-level embeddings as in the case of unsegmented words (see Figure 1). However, the word embedding is intuitively richer than the embedding learned over unsegmented words because of the convolution over characters. The method was previously shown to help neural MT (Belinkov and Glass, 2016; Costa-juss`a and Fonollosa, 2016). Belinkov et al. (2017) also showed character-based representations learned using a CNN to be superior, at learning word morphology, than their word-based counter-parts. However, they did not compare these against BPE-based segmentation. We use character-CNN to aid Arabic word segmentation. 602 # SEG tst11 Arabic-to-English tst12 tst13 tst14 AVG. tst11 English-to-Arabic tst12 tst13 tst14 UNSEG 25.7 28.2 27.3 23.9 26.3 15.8 17.1 18.1 15.5 16.6 MORPH cCNN CHAR BPE 29.2 29.0 28.8 29.7 33.0 32.0 31.8 32.5 32.9 32.5 32.5 33.6 28.3 28.0 27.8 28.4 30.9 30.3 30.2 31.1 16.5 14.3 15.3 17.5 18.8 12.8 17.1 18.0 20.4 13.6 18.0 2"
P17-2095,fishel-kirik-2010-linguistically,0,0.0293358,"ntext). The analyses are provided with the original text to a Feature Modeling component that applies an SVM and a language model to make predictions, which are scored by an Analysis Ranking component. Farasa on the other hand is a light weight segmenter, which ignores context and instead uses a variety of features and lexicons for segmentation. 2.2 Character-level Encoding Data Driven Sub-word Units A number of data-driven approaches have been proposed that learn to segment words into smaller units from data (Demberg, 2007; Sami Virpioja and Kurimo, 2013) and shown to improve phrasebased MT (Fishel and Kirik, 2010; Stallard et al., 2012). Recently, with the advent of neural MT, a few sub-word-based techniques have been proposed that segment words into smaller units to tackle the limited vocabulary and unknown word problems (Sennrich et al., 2016; Wu et al., 2016). In this work, we explore Byte-Pair Encoding (BPE), a data compression algorithm (Gage, 1994) as an alternative to morphological segmentation of Arabic. BPE splits words into symbols (a sequence of characters) and then iteratively replaces the most frequent symbols with their merged variants. In essence, frequent character n-gram sequences wil"
P17-2095,A00-1031,0,0.0614725,"this problem is; at test time, BPE is applied to those words only which were known to the full vocabulary of the training corpus. In this way, the sub-word units created by BPE for the word are already seen in a similar context during training and the model has learned to translate them correctly. The downside of this method is that it limits BPE’s power to segment unknown words to their correct sub-word units and outputs them as UNK in translation. 3.3 We also experimented with the aforementioned segmentation strategies for the task of Arabic POS tagging. Probabilistic taggers like HMMbased (Brants, 2000) and sequence learning models like CRF (Lafferty et al., 2001) consider previous words and/or tags to predict the tag of the current word. We mimic a similar setting but in a sequence-to-sequence learning framework. Figure 3 describes a step by step procedure to train a neural encoder-decoder tagger. Consider an Arabic phrase “klm >SdqA}k b$rhm” Discussion: Though BPE performed well for machine translation, there are a few reservations that we would like to discuss here. Since the main goal of the algorithm is to compress data and segmentation comes as a by-product, it often produces different"
P17-2095,2013.iwslt-papers.2,1,0.905117,"Missing"
P17-2095,2012.eamt-1.60,0,0.0196508,"3.6 18.0 20.0 17.2 12.6 15.3 16.6 18.2 13.3 16.4 18.0 AVG. Table 1: Results of comparing several segmentation strategies. 3 Experiments In the following, we describe the data and system settings and later present the results of machine translation and POS tagging. LSTM in the (bidirectional) encoder and the decoder, with a size of 500. We limit the sentence length to 100 for MORPH, UNSEG, BPE, cCNN, and 500 for CHAR experiments. The source and target vocabularies are limited to 50k each. 3.1 3.2 Settings Data The MT systems were trained on 1.2 Million sentences, a concatenation of TED corpus (Cettolo et al., 2012), LDC NEWS data, QED (Guzm´an et al., 2013) and an MML-filtered (Axelrod et al., 2011) UN corpus.1 We used dev+test10 for tuning and tst11-14 for testing. For EnglishArabic, outputs were detokenized using MADA detokenizer. Before scoring the output, we normalized them and reference translations using the QCRI normalizer (Sajjad et al., 2013). Machine Translation Results Table 1 presents MT results using various segmentation strategies. Compared to the UNSEG system, the MORPH system2 improved translation quality by 4.6 and 1.6 BLEU points in Ar-to-En and Ento-Ar systems, respectively. The resul"
P17-2095,P05-1071,0,0.072442,"racter CNN (Convolution Neural Network). On the tasks of Machine Translation and POS tagging, we found these methods to achieve close to, and occasionally surpass state-of-the-art performance. In our analysis, we show that a neural machine translation system is sensitive to the ratio of source and target tokens, and a ratio close to 1 or greater, gives optimal performance. 1 Introduction Arabic word segmentation has shown to significantly improve output quality in NLP tasks such as machine translation (Habash and Sadat, 2006; Almahairi et al., 2016), part-of-speech tagging (Diab et al., 2004; Habash and Rambow, 2005), and information retrieval (M. Aljlayl and Grossman, 2002). A considerable amount of research has therefore been spent on Arabic morphological segmentation in the past two decades, ranging from rule-based analyzers (Beesley, 1996) to state-of-the-art statistical segmenters (Pasha et al., 2014; Abdelali et al., 2016; Khalifa et al., 2016). Morphological segmentation splits words into morphemes. For example, ‘‘wktAbnA” “ AJK . AJ»ð” (gloss: and our book) is decomposed into its stem H AJ» + ð”. and affixes as: “w+ ktAb +nA” “ AK+ . 601 Proceedings of the 55th Annual Meeting of the Association"
P17-2095,P16-2058,0,0.109475,"Missing"
P17-2095,N13-1044,0,0.0576645,"Missing"
P17-2095,P07-1116,0,0.100776,"al analyzer that generates a list of possible word-level analyses (independent of context). The analyses are provided with the original text to a Feature Modeling component that applies an SVM and a language model to make predictions, which are scored by an Analysis Ranking component. Farasa on the other hand is a light weight segmenter, which ignores context and instead uses a variety of features and lexicons for segmentation. 2.2 Character-level Encoding Data Driven Sub-word Units A number of data-driven approaches have been proposed that learn to segment words into smaller units from data (Demberg, 2007; Sami Virpioja and Kurimo, 2013) and shown to improve phrasebased MT (Fishel and Kirik, 2010; Stallard et al., 2012). Recently, with the advent of neural MT, a few sub-word-based techniques have been proposed that segment words into smaller units to tackle the limited vocabulary and unknown word problems (Sennrich et al., 2016; Wu et al., 2016). In this work, we explore Byte-Pair Encoding (BPE), a data compression algorithm (Gage, 1994) as an alternative to morphological segmentation of Arabic. BPE splits words into symbols (a sequence of characters) and then iteratively replaces the most fre"
P17-2095,N06-2013,0,0.0488146,"rd units, ii) characters as a unit of learning, and iii) word embeddings learned using a character CNN (Convolution Neural Network). On the tasks of Machine Translation and POS tagging, we found these methods to achieve close to, and occasionally surpass state-of-the-art performance. In our analysis, we show that a neural machine translation system is sensitive to the ratio of source and target tokens, and a ratio close to 1 or greater, gives optimal performance. 1 Introduction Arabic word segmentation has shown to significantly improve output quality in NLP tasks such as machine translation (Habash and Sadat, 2006; Almahairi et al., 2016), part-of-speech tagging (Diab et al., 2004; Habash and Rambow, 2005), and information retrieval (M. Aljlayl and Grossman, 2002). A considerable amount of research has therefore been spent on Arabic morphological segmentation in the past two decades, ranging from rule-based analyzers (Beesley, 1996) to state-of-the-art statistical segmenters (Pasha et al., 2014; Abdelali et al., 2016; Khalifa et al., 2016). Morphological segmentation splits words into morphemes. For example, ‘‘wktAbnA” “ AJK . AJ»ð” (gloss: and our book) is decomposed into its stem H AJ» + ð”. and af"
P17-2095,C16-2047,0,0.0156449,"ater, gives optimal performance. 1 Introduction Arabic word segmentation has shown to significantly improve output quality in NLP tasks such as machine translation (Habash and Sadat, 2006; Almahairi et al., 2016), part-of-speech tagging (Diab et al., 2004; Habash and Rambow, 2005), and information retrieval (M. Aljlayl and Grossman, 2002). A considerable amount of research has therefore been spent on Arabic morphological segmentation in the past two decades, ranging from rule-based analyzers (Beesley, 1996) to state-of-the-art statistical segmenters (Pasha et al., 2014; Abdelali et al., 2016; Khalifa et al., 2016). Morphological segmentation splits words into morphemes. For example, ‘‘wktAbnA” “ AJK . AJ»ð” (gloss: and our book) is decomposed into its stem H AJ» + ð”. and affixes as: “w+ ktAb +nA” “ AK+ . 601 Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 601–607 c Vancouver, Canada, July 30 - August 4, 2017. 2017 Association for Computational Linguistics https://doi.org/10.18653/v1/P17-2095 2 Segmentation Approaches We experimented with three data-driven segmentation schemes: i) morphological segmentation, ii) sub-word segmentation based"
P17-2095,P16-1162,0,0.504845,"bic translation (El Kholy and Habash, 2012)). More importantly, these tools are dialect- and domain-specific. A segmenter trained for modern standard Arabic (MSA) performs significantly worse on dialectal Arabic (Habash et al., 2013), or when it is applied to a new domain. In this work, we explore whether we can avoid the language-dependent pre/post-processing components and learn segmentation directly from the training data being used for a given task. We investigate data-driven alternatives to morphological segmentation using i) unsupervised sub-word units obtained using byte-pair encoding (Sennrich et al., 2016), ii) purely character-based segmentation (Ling et al., 2015), and iii) a convolutional neural network over characters (Kim et al., 2016). We evaluate these techniques on the tasks of machine translation (MT) and part-of-speech (POS) tagging and compare them against morphological segmenters MADAMIRA (Pasha et al., 2014) and Farasa (Abdelali et al., 2016). On the MT task, byte-pair encoding (BPE) performs the best among the three methods, achieving very similar performance to morphological segmentation in the Arabic-to-English direction and slightly worse in the other direction. Character-based"
P17-2095,P12-2063,0,0.0265535,"provided with the original text to a Feature Modeling component that applies an SVM and a language model to make predictions, which are scored by an Analysis Ranking component. Farasa on the other hand is a light weight segmenter, which ignores context and instead uses a variety of features and lexicons for segmentation. 2.2 Character-level Encoding Data Driven Sub-word Units A number of data-driven approaches have been proposed that learn to segment words into smaller units from data (Demberg, 2007; Sami Virpioja and Kurimo, 2013) and shown to improve phrasebased MT (Fishel and Kirik, 2010; Stallard et al., 2012). Recently, with the advent of neural MT, a few sub-word-based techniques have been proposed that segment words into smaller units to tackle the limited vocabulary and unknown word problems (Sennrich et al., 2016; Wu et al., 2016). In this work, we explore Byte-Pair Encoding (BPE), a data compression algorithm (Gage, 1994) as an alternative to morphological segmentation of Arabic. BPE splits words into symbols (a sequence of characters) and then iteratively replaces the most frequent symbols with their merged variants. In essence, frequent character n-gram sequences will be merged to form one"
P17-2095,P12-2059,0,0.0607745,"ased on BPE, and iii) two variants of character-based segmentation. We first map each source word to its corresponding segments (depending on the segmentation scheme), embed all segments of a word in vector space and feed them one-by-one to an encoder-decoder model. See Figure 1 for illustration. 2.1 Figure 1: Segmentation approaches for the word “b$rhm” “ ÑëQå.”; the blue vectors indicate the embedding(s) used before the encoding layer. 2.3 Morphological Segmentation Character-based models have been found to be effective in translating closely related language pairs (Durrani et al., 2010; Nakov and Tiedemann, 2012) and OOV words (Durrani et al., 2014). Ling et al. (2016) used character embeddings to address the OOV word problem. We explored them as an alternative to morphological segmentation. Their advantage is that character embeddings do not require any complicated pre- and post-processing step other than segmenting words into characters. The fully character-level encoder treats the source sentence as a sequence of letters, encoding each letter (including white-space) in the LSTM encoder (see Figure 1). The decoding may follow identical settings. We restricted the character-level representation to th"
P17-2095,pasha-etal-2014-madamira,0,0.112051,"Missing"
P17-2095,N04-4038,0,\N,Missing
P17-2095,N16-3003,1,\N,Missing
P17-2095,2013.iwslt-evaluation.8,1,\N,Missing
P19-1084,D17-1070,0,0.0437902,"the baseline model learned to rely on the presence/absence of the bias term c, always predicting T RUE/FALSE respectively. Table 1 shows the results of our two proposed methods. As we increase the hyper-parameters α and β, our methods initially behave like the baseline, learning the training set but failing on the test set. However, with strong enough hyperparameters (moving towards the bottom in the tables), they perform perfectly on both the biased training set and the unbiased test set. For Method 1, stronger hyper-parameters work better. Baseline & Implementation Details We use InferSent (Conneau et al., 2017) as our baseline model because it has been shown to work well on popular NLI datasets and is representative of many NLI models. We use separate BiLSTM encoders to learn vector representations of P and H.11 The vector representations are combined following Mou et al. (2016),12 and passed to an MLP classifier with one hidden layer. Our proposed 9 Detailed descriptions of these datasets can be found in Poliak et al. (2018b). 10 We leave additional NLI datasets, such as the Diverse NLI Collection (Poliak et al., 2018a), for future work. 11 Many NLI models encode P and H separately (Rockt¨aschel et"
P19-1084,S19-1028,1,0.7647,"Missing"
P19-1084,D15-1075,0,0.462661,"taset B), a letter c is appended to the hypothesis side in the T RUE examples, but not in the FALSE examples. In order to transfer well to the test set, a model that is trained on this training set needs to learn the underlying relationship—that P entails H if and only if their first letter is identical—rather than relying on the presence of c in the hypothesis side. max L1 (θ) = (1 − α) log pθ (y |P, H) θ − α log pθ,φ (y |P 0 , H) max L2 (φ) = β log pθ,φ (y |P 0 , H) Common NLI datasets Moving to existing NLI datasets, we train models on the Stanford Natural Language Inference dataset (SNLI; Bowman et al., 2015), since it is known to contain significant annotation artifacts. We evaluate the robustness of our methods on other, target datasets. As target datasets, we use the 10 datasets investigated by Poliak et al. (2018b) in their hypothesisonly study, plus two test sets: GLUE’s diagnostic test set, which was carefully constructed to not contain hypothesis-biases (Wang et al., 2018), and SNLI-hard, a subset of the SNLI test set that is thought to have fewer biases (Gururangan et al., 2018). The target datasets include humanjudged datasets that used automatic methods to pair premises and hypotheses, a"
P19-1084,C18-1055,0,0.0314895,"ur methods with known biases in NLI datasets, the effects of stronger bias removal, and the possibility of fine-tuning on the target datasets. Our methodology can be extended to handle biases in other tasks where one is concerned with finding relationships between two objects, such as visual question answering, story cloze completion, and reading comprehension. We hope to encourage such investigation in the broader community. Improving model robustness Neural networks are sensitive to adversarial examples, primarily in machine vision, but also in NLP (Jia & Liang, 2017; Belinkov & Bisk, 2018; Ebrahimi et al., 2018; Heigold et al., 2018; Mudrakarta et al., 2018; Ribeiro et al., 2018; Belinkov & Glass, 2019). A common approach to improving robustness is to include adversarial examples in training (Szegedy et al., 2014; Goodfellow et al., 2015). However, this may not generalize well to new types of examples (Xiaoyong Yuan, 2017; Tramr et al., 2018). Domain-adversarial neural networks aim to increase robustness to domain change, by learning to be oblivious to the domain using gradient reversals (Ganin et al., 2016). Our methods rely similarly on gradient reversals when encouraging models to ignore dataset-"
P19-1084,P17-2097,0,0.232016,"ctic clues alone (Snow et al., 2006; Vanderwende & Dolan, 2006). Recent work also found artifacts in new NLI datasets (Tsuchiya, 2018; Gururangan et al., 2018; Poliak et al., 2018b). Other NLU datasets also exhibit biases. In ROC Stories (Mostafazadeh et al., 2016), a story cloze dataset, Schwartz et al. (2017b) obtained a high performance by only considering the candidate endings, without even looking at the story context. In this case, stylistic features of the candidate endings alone, such as the length or certain words, were strong indicators of the correct ending (Schwartz et al., 2017a; Cai et al., 2017). A similar phenomenon was observed in reading comprehension, where systems performed non-trivially well by using only the final sentence in the passage or ignoring the passage altogether (Kaushik & Lipton, 2018). Finally, multiple studies found non-trivial performance in visual question answering (VQA) by using only the question, without access to the image, due to question biases (Zhang et al., 2016; Kafle & Kanan, 2016, 2017; Goyal et al., 2017; Agrawal et al., 2017). Our main goal is to determine whether our methods help a model perform well across multiple datasets by ignoring dataset-spe"
P19-1084,P18-1225,0,0.0192681,"niques developed for textual entailment“ datasets, e.g., RTE-3, do not transfer well to other domains, specifically conversational entailment (Zhang & Chai, 2009, 2010). Bowman et al. (2015) and Williams et al. (2018) demonstrated (specifically in their respective Tables 7 and 4) how models trained on SNLI and MNLI may not transfer well across other NLI datasets like SICK. Talman & Chatzikyriakidis (2018) recently reported similar findings using many advanced deep-learning models. versarial examples that do not conform to logical rules and regularize models based on those examples. Similarly, Kang et al. (2018) incorporate external linguistic resources and use a GAN-style framework to adversarially train robust NLI models. In contrast, we do not use external resources and we are interested in mitigating hypothesisonly biases. Finally, a similar approach has recently been used to mitigate biases in VQA (Ramakrishnan et al., 2018; Grand & Belinkov, 2019). 8 Conclusion Biases in annotations are a major source of concern for the quality of NLI datasets and systems. We presented a solution for combating annotation biases by proposing two training methods to predict the probability of a premise given an e"
P19-1084,D18-1546,0,0.0793546,"exhibit biases. In ROC Stories (Mostafazadeh et al., 2016), a story cloze dataset, Schwartz et al. (2017b) obtained a high performance by only considering the candidate endings, without even looking at the story context. In this case, stylistic features of the candidate endings alone, such as the length or certain words, were strong indicators of the correct ending (Schwartz et al., 2017a; Cai et al., 2017). A similar phenomenon was observed in reading comprehension, where systems performed non-trivially well by using only the final sentence in the passage or ignoring the passage altogether (Kaushik & Lipton, 2018). Finally, multiple studies found non-trivial performance in visual question answering (VQA) by using only the question, without access to the image, due to question biases (Zhang et al., 2016; Kafle & Kanan, 2016, 2017; Goyal et al., 2017; Agrawal et al., 2017). Our main goal is to determine whether our methods help a model perform well across multiple datasets by ignoring dataset-specific artifacts. In turn, we did not update the models’ parameters on other datasets. But, what if we are given different amounts of training data for a new NLI dataset? To determine if our approach is still help"
P19-1084,W19-1801,1,0.837619,"ss other NLI datasets like SICK. Talman & Chatzikyriakidis (2018) recently reported similar findings using many advanced deep-learning models. versarial examples that do not conform to logical rules and regularize models based on those examples. Similarly, Kang et al. (2018) incorporate external linguistic resources and use a GAN-style framework to adversarially train robust NLI models. In contrast, we do not use external resources and we are interested in mitigating hypothesisonly biases. Finally, a similar approach has recently been used to mitigate biases in VQA (Ramakrishnan et al., 2018; Grand & Belinkov, 2019). 8 Conclusion Biases in annotations are a major source of concern for the quality of NLI datasets and systems. We presented a solution for combating annotation biases by proposing two training methods to predict the probability of a premise given an entailment label and a hypothesis. We demonstrated that this discourages the hypothesis encoder from learning the biases to instead obtain a less biased representation. When empirically evaluating our approaches, we found that in a synthetic setting, as well as on a wide-range of existing NLI datasets, our methods perform better than the tradition"
P19-1084,N18-2017,0,0.0783303,"Missing"
P19-1084,I17-1011,0,0.118985,"Missing"
P19-1084,P18-2005,0,0.0390164,"vious to the domain using gradient reversals (Ganin et al., 2016). Our methods rely similarly on gradient reversals when encouraging models to ignore dataset-specific artifacts. One distinction is that domain-adversarial networks require knowledge of the domain at training time, while our methods learn to ignore latent artifacts and do not require direct supervision in the form of a domain label. Others have attempted to remove biases from learned representations, e.g., gender biases in word embeddings (Bolukbasi et al., 2016) or sensitive information like sex and age in text representations (Li et al., 2018). However, removing such attributes from text representations may be difficult (Elazar & Goldberg, 2018). In contrast to this line of work, our final goal is not the removal of such attributes per se; instead, we strive for more robust representations that better transfer to other datasets, similar to Li et al. (2018). Recent work has applied adversarial learning to NLI. Minervini & Riedel (2018) generate adAcknowledgements We would like to thank Aviad Rubinstein and Cynthia Dwork for discussing an earlier version of this work and the anonymous reviewers for their useful comments. Y.B. was sup"
P19-1084,P16-1204,0,0.135588,"Missing"
P19-1084,marelli-etal-2014-sick,0,0.149192,"Missing"
P19-1084,P15-2067,1,0.883981,"Missing"
P19-1084,K18-1007,0,0.0984265,"in label. Others have attempted to remove biases from learned representations, e.g., gender biases in word embeddings (Bolukbasi et al., 2016) or sensitive information like sex and age in text representations (Li et al., 2018). However, removing such attributes from text representations may be difficult (Elazar & Goldberg, 2018). In contrast to this line of work, our final goal is not the removal of such attributes per se; instead, we strive for more robust representations that better transfer to other datasets, similar to Li et al. (2018). Recent work has applied adversarial learning to NLI. Minervini & Riedel (2018) generate adAcknowledgements We would like to thank Aviad Rubinstein and Cynthia Dwork for discussing an earlier version of this work and the anonymous reviewers for their useful comments. Y.B. was supported by the Harvard Mind, Brain, and Behavior Initiative. A.P. and B.V.D were supported by JHU-HLTCOE and DARPA LORELEI. A.M.R gratefully acknowledges the support of NSF 1845664. Views and conclusions contained in this publication are those of the authors and should not be interpreted as representing official policies or endorsements of DARPA or the U.S. Government. 885 References URL http://ww"
P19-1084,D14-1162,0,0.0849444,"Missing"
P19-1084,N16-1098,0,0.0286455,"ises will lead to a model’s degradation. 6.3 7 Fine-tuning on target datasets Related Work Biases and artifacts in NLU datasets Many natural language undersrtanding (NLU) datasets contain annotation artifacts. Early work on NLI, also known as recognizing textual entailment (RTE), found biases that allowed models to perform relatively well by focusing on syntactic clues alone (Snow et al., 2006; Vanderwende & Dolan, 2006). Recent work also found artifacts in new NLI datasets (Tsuchiya, 2018; Gururangan et al., 2018; Poliak et al., 2018b). Other NLU datasets also exhibit biases. In ROC Stories (Mostafazadeh et al., 2016), a story cloze dataset, Schwartz et al. (2017b) obtained a high performance by only considering the candidate endings, without even looking at the story context. In this case, stylistic features of the candidate endings alone, such as the length or certain words, were strong indicators of the correct ending (Schwartz et al., 2017a; Cai et al., 2017). A similar phenomenon was observed in reading comprehension, where systems performed non-trivially well by using only the final sentence in the passage or ignoring the passage altogether (Kaushik & Lipton, 2018). Finally, multiple studies found no"
P19-1084,W18-5441,1,0.895818,"Missing"
P19-1084,P16-2022,0,0.0707933,"ng the training set but failing on the test set. However, with strong enough hyperparameters (moving towards the bottom in the tables), they perform perfectly on both the biased training set and the unbiased test set. For Method 1, stronger hyper-parameters work better. Baseline & Implementation Details We use InferSent (Conneau et al., 2017) as our baseline model because it has been shown to work well on popular NLI datasets and is representative of many NLI models. We use separate BiLSTM encoders to learn vector representations of P and H.11 The vector representations are combined following Mou et al. (2016),12 and passed to an MLP classifier with one hidden layer. Our proposed 9 Detailed descriptions of these datasets can be found in Poliak et al. (2018b). 10 We leave additional NLI datasets, such as the Diverse NLI Collection (Poliak et al., 2018a), for future work. 11 Many NLI models encode P and H separately (Rockt¨aschel et al., 2016; Mou et al., 2016; Liu et al., 2016; Cheng et al., 2016; Chen et al., 2017), although some share information between the encoders via attention (Parikh et al., 2016; Duan et al., 2018). 12 Specifically, representations are concatenated, subtracted, and multiplie"
P19-1084,P18-1176,0,0.0561621,"Missing"
P19-1084,D12-1071,0,0.092754,"are provided in Appendix A.2. For both methods, we sweep hyper-parameters α, β over {0.05, 0.1, 0.2, 0.4, 0.8, 1.0}. For each target dataset, we choose the best-performing model on its development set and report results on the test set.13 sense Inference (JOCI; Zhang et al., 2017), Multiple Premise Entailment (MPE; Lai et al., 2017),and Sentences Involving Compositional Knowledge (SICK; Marelli et al., 2014). The target datasets also include datasets recast by White et al. (2017) to evaluate different semantic phenomena: FrameNet+ (FN+; Pavlick et al., 2015), Definite Pronoun Resolution (DPR; Rahman & Ng, 2012), and Semantic Proto-Roles (SPR; Reisinger et al., 2015).9 As many of these datasets have different label spaces than SNLI, we define a mapping (Appendix A.1) from our models’ predictions to each target dataset’s labels. Finally, we also test on the Multi-genre NLI dataset (MNLI; Williams et al., 2018), a successor to SNLI.10 5 Results 5.1 Synthetic Experiments To examine how well our methods work in a controlled setup, we train on the biased dataset (B), but evaluate on the unbiased test set (A). As expected, without a method to remove hypothesisonly biases, the baseline fails to generalize t"
P19-1084,D16-1244,0,0.170648,"Missing"
P19-1084,Q15-1034,1,0.916901,"Missing"
P19-1084,P18-1079,0,0.45999,"sentations of P and H, and a classification layer, gθ , which learns a distribution over y. Typically, this is done by maximizing this discriminative likelihood directly, which will act as our baseline (Figure 1a). However, many NLI datasets contain biases that allow models to perform non-trivially well when accessing just the hypotheses (Tsuchiya, 2018; Gururangan et al., 2018; Poliak et al., 2018b). This allows models to leverage hypothesis-only biases that may be present in a dataset. A model may perform well on a specific dataset, without identifying whether P entails H. Gururangan et al. (2018) argue that “the bulk” of many models’ “success [is] attribute[d] to the easy examples”. Consequently, this may limit how well a model trained on one dataset would perform on other datasets that may have different artifacts. Consider an example where P and H are strings from {a, b, c}, and an environment where P enIn summary, in this paper we make the follow878 tails H if and only if the first letters are the same, as in synthetic dataset A. In such a setting, a model should be able to learn the correct condition for P to entail H.4 3.1 Our first approach is to estimate the term p(y |H) direct"
P19-1084,L18-1239,0,0.442811,"se for Granted: Mitigating Artifacts in Natural Language Inference Yonatan Belinkov13∗ Adam Poliak2∗ Stuart M. Shieber1 Benjamin Van Durme2 Alexander M. Rush1 1 2 3 Harvard University Johns Hopkins University Massachusetts Institute of Technology {belinkov,shieber,srush}@seas.harvard.edu {azpoliak,vandurme}@cs.jhu.edu Abstract many NLI datasets contain biases, or annotation artifacts, i.e., features present in hypotheses that enable models to perform surprisingly well using only the hypothesis, without learning the relationship between two texts (Gururangan et al., 2018; Poliak et al., 2018b; Tsuchiya, 2018).3 For instance, in some datasets, negation words like “not” and “nobody” are often associated with a relationship of contradiction. As a ramification of such biases, models may not generalize well to other datasets that contain different or no such biases. Recent studies have tried to create new NLI datasets that do not contain such artifacts, but many approaches to dealing with this issue remain unsatisfactory: constructing new datasets (Sharma et al., 2018) is costly and may still result in other artifacts; filtering “easy” examples and defining a harder subset is useful for evaluation purp"
P19-1084,W18-5446,0,0.0389124,"= (1 − α) log pθ (y |P, H) θ − α log pθ,φ (y |P 0 , H) max L2 (φ) = β log pθ,φ (y |P 0 , H) Common NLI datasets Moving to existing NLI datasets, we train models on the Stanford Natural Language Inference dataset (SNLI; Bowman et al., 2015), since it is known to contain significant annotation artifacts. We evaluate the robustness of our methods on other, target datasets. As target datasets, we use the 10 datasets investigated by Poliak et al. (2018b) in their hypothesisonly study, plus two test sets: GLUE’s diagnostic test set, which was carefully constructed to not contain hypothesis-biases (Wang et al., 2018), and SNLI-hard, a subset of the SNLI test set that is thought to have fewer biases (Gururangan et al., 2018). The target datasets include humanjudged datasets that used automatic methods to pair premises and hypotheses, and then relied on humans to label the pairs: SCITAIL (Khot et al., 2018), ADD-ONE-RTE (Pavlick & CallisonBurch, 2016), Johns Hopkins Ordinal Commonφ Finally, we share the classifier weights between pθ (y |P, H) and pφ,θ (y |P 0 , H). In a sense this is counter-intuitive, since pθ is being trained to unlearn bias, while pφ,θ is being trained to learn it. However, if the models"
P19-1084,K17-1004,0,0.222659,"-tuning on target datasets Related Work Biases and artifacts in NLU datasets Many natural language undersrtanding (NLU) datasets contain annotation artifacts. Early work on NLI, also known as recognizing textual entailment (RTE), found biases that allowed models to perform relatively well by focusing on syntactic clues alone (Snow et al., 2006; Vanderwende & Dolan, 2006). Recent work also found artifacts in new NLI datasets (Tsuchiya, 2018; Gururangan et al., 2018; Poliak et al., 2018b). Other NLU datasets also exhibit biases. In ROC Stories (Mostafazadeh et al., 2016), a story cloze dataset, Schwartz et al. (2017b) obtained a high performance by only considering the candidate endings, without even looking at the story context. In this case, stylistic features of the candidate endings alone, such as the length or certain words, were strong indicators of the correct ending (Schwartz et al., 2017a; Cai et al., 2017). A similar phenomenon was observed in reading comprehension, where systems performed non-trivially well by using only the final sentence in the passage or ignoring the passage altogether (Kaushik & Lipton, 2018). Finally, multiple studies found non-trivial performance in visual question answe"
P19-1084,I17-1100,1,0.922317,"Missing"
P19-1084,W17-0907,0,0.0297645,"Missing"
P19-1084,N18-1101,0,0.316511,"Entailment (MPE; Lai et al., 2017),and Sentences Involving Compositional Knowledge (SICK; Marelli et al., 2014). The target datasets also include datasets recast by White et al. (2017) to evaluate different semantic phenomena: FrameNet+ (FN+; Pavlick et al., 2015), Definite Pronoun Resolution (DPR; Rahman & Ng, 2012), and Semantic Proto-Roles (SPR; Reisinger et al., 2015).9 As many of these datasets have different label spaces than SNLI, we define a mapping (Appendix A.1) from our models’ predictions to each target dataset’s labels. Finally, we also test on the Multi-genre NLI dataset (MNLI; Williams et al., 2018), a successor to SNLI.10 5 Results 5.1 Synthetic Experiments To examine how well our methods work in a controlled setup, we train on the biased dataset (B), but evaluate on the unbiased test set (A). As expected, without a method to remove hypothesisonly biases, the baseline fails to generalize to the test set. Examining its predictions, we found that the baseline model learned to rely on the presence/absence of the bias term c, always predicting T RUE/FALSE respectively. Table 1 shows the results of our two proposed methods. As we increase the hyper-parameters α and β, our methods initially b"
P19-1084,N06-1005,0,0.725739,"Missing"
P19-1084,D10-1074,0,0.0834512,"Missing"
P19-1084,W09-3930,0,0.0870273,"Missing"
P19-1084,Q17-1027,1,0.9051,"Missing"
P19-1084,D16-1053,0,\N,Missing
P19-1084,P17-1152,0,\N,Missing
P19-1084,D18-1007,1,\N,Missing
P19-1084,Q19-1004,1,\N,Missing
P19-1144,N16-1024,0,0.196716,"Missing"
P19-1144,D14-1162,0,0.0837707,"Missing"
P19-1144,P18-1108,0,0.099894,"Missing"
P19-1144,N16-1036,0,0.0698135,"Missing"
Q14-1043,P08-1037,0,0.501726,"ed on syntactic context are more powerful than those based on linear context. This may explain the improved performance of self-trained parsers over parsers that rely on linear context embeddings. 2 Related Work Problem formulation Typically, PP attachment disambiguation is modeled as a binary classification decision between a preceding noun or verb (Brill and Resnik, 1994; Ratnaparkhi et al., 1994; Collins and Brooks, 1995; Olteanu and Moldovan, 2005; ˇ Suster, 2012). In addition, the problem of PP attachment has also been addressed in the context of full parsing (Atterer and Sch¨utze, 2007; Agirre et al., 2008). For instance, Green (2009) engineered statesplit features for the Stanford parser to improve Arabic PP attachment. In this work, we do isolate PP attachments from other parsing decisions. At the same time, we consider a more realistic scenario where multiple candidate heads are allowed. We also compare against full-scale parsers and show that our model predictions improve a state-of-the-art dependency parser. Information sources Lexical sparsity associated with disambiguating PP attachments (Figure 1) has spurred researchers to exploit a wide range of information sources. On the one hand, re"
Q14-1043,J07-4002,0,0.314307,"Missing"
Q14-1043,P14-2131,0,0.167967,"illustrates the resulting enriched vector. Similar dimensions are appended to vectors representing other words participating in the compositions. Our experiments show that such an extension significantly improves performance. 4.3 Syntactic word vectors In the standard Skip-gram model word vectors are trained from raw text using the linear context of neighboring words. We also consider an alternative method for creating word vectors by using the syntactic context of words. Such syntactic context is expected to be relevant for resolving PP attachments. Given a dependency-parsed text, we follow Bansal et al. (2014) and create a new corpus of tuples (l, g, p, c, l), for every word c, its parent p with dependency label l, and its grandparent g. Then we train an ordinary Skip-gram model on this corpus, but with a small window size of 2. Note that the label l appears on both ends so it contributes to the context of the word as well as its grandparent. We find that syntactic vectors yield significant performance gains compared to standard vectors.5 5 Experimental setup 5.1 Extracting PP attachments Instances of PP attachment decisions are extracted from standard treebanks. We use the CATiB dependency treeban"
Q14-1043,C94-2195,0,0.862621,"Missing"
Q14-1043,W95-0103,0,0.486292,"ation. 6.1 Alternative composition architectures In this section we analyze how different composition architectures (Section 3.2) contribute to the overall performance. To isolate the contribution of the architecture, we focus on standard (linear) word vectors, with no relearning or enriching. As Figure 3 shows, simpler models tend to perform worse than more complex ones. The best variants use different composition matrices based on the distance of the candidate head from the PP (HPCD, HPCDN). While the results shown are for 100-dimensional 14 Here we applied basic preprocessing similarly to (Collins and Brooks, 1995), converting 4-digit numbers to YEAR and other numbers to NUMBER; other tokens were lower-cased. 569 Figure 3: PP attachment accuracy of different architectures. (HC) uses only the candidate head and the child of the preposition; (HPC*) models use head, preposition, and child, with the following variants: (HPCT) ternary composition; (HPCL) local matrices for top and bottom compositions; (HPCN) context words; (HPCD) distance-dependent matrices; (HPCDN) combines HPCD+HPCN. vectors, similar trends are observed with lower dimensions, although the gaps between simple and complex models are then mor"
Q14-1043,P97-1003,0,0.237027,"Missing"
Q14-1043,P05-1071,0,0.056325,"dia for English8 and the arTenTen corpus for Arabic, containing web texts crawled in 2012 (Belinkov et al., 2013; Arts et al., 2014). Table 3 similar performance gains. 6 We used the Pennconverter tool: http://nlp.cs. lth.se/software/treebank-converter. 7 We used the word2vec tool: https://code.google. com/p/word2vec, with default settings. We experimented with word vectors of 25, 50, 100, and 200 dimensions, and found 100 to work best in most cases. 8 http://mattmahoney.net/dc/textdata. shows the comparable sizes of the datasets. The Arabic corpus has been tokenized and lemmatized with MADA (Habash and Rambow, 2005; Habash et al., 2005), a necessary procedure in order to separate some prepositions from their child words. In addition, lemmatization reduces vocabulary size and facilitates sharing information between different morphological variants that have the same meaning. For syntactic word vectors, we use the English vectors in (Bansal et al., 2014), which were trained from a parsed BLLIP corpus (minus PTB). For Arabic, we first convert the morphologically-processed arTenTen corpus to CoNLL format with the SPMRL shared-task scripts (Seddah et al., 2013). Then we parse the corpus with a baseline MST p"
Q14-1043,P09-2056,0,0.021064,"d create a new corpus of tuples (l, g, p, c, l), for every word c, its parent p with dependency label l, and its grandparent g. Then we train an ordinary Skip-gram model on this corpus, but with a small window size of 2. Note that the label l appears on both ends so it contributes to the context of the word as well as its grandparent. We find that syntactic vectors yield significant performance gains compared to standard vectors.5 5 Experimental setup 5.1 Extracting PP attachments Instances of PP attachment decisions are extracted from standard treebanks. We use the CATiB dependency treebank (Habash and Roth, 2009) for Arabic and a conversion of the Penn treebank (PTB) to dependency format for English.6 Standard train/dev/test splits are used: sections 2-21/22/23 of the PTB for English, and the split from the SPRML shared-task for Arabic (Seddah et al., 2013). As Table 2 shows, the datasets of the two languages are fairly similar in size, except for the much larger set of prepositions in the English data. Extracting instances of PP attachments from the treebanks is done in the following way. For each 5 We also experimented with another method for creating syntactic vectors by Levy and Goldberg (2014) an"
Q14-1043,P08-1068,0,0.518307,"train a new RNN model. 11 We use SVMRank: http://www.cs.cornell. edu/people/tj/svm_light/svm_rank.html. of the preposition. This feature was found useful ˇ in previous work on PP attachment (Suster, 2012). While this limits the contribution of the word vectors to the learned model to one dimension, attempts to use more dimensions in the SVM were unsuccessful.12 In contrast, the compositional models better capture the full dimensionality of the word vectors. A second type of features induced from raw data that we consider are Brown clusters, which were found to be useful in dependency parsing (Koo et al., 2008). Compared to distributed vectors, Brown clusters provide a more discrete representation that is easier to incorporate in the SVM. We create clusters from our unsupervised corpora using the Liang (2005) implementation of Brown’s algorithm, and add features in the spirit of (Koo et al., 2008). Specifically, we add full and prefixed bit strings for the head, preposition, and child, as well as bi-lexical versions for head-child pairs.13 Table 4 shows a summary of the SVM features. 6 Results Table 5 summarizes the results of our model and other systems. Our best results are obtained with the Head-"
Q14-1043,D12-1096,0,0.102964,"hows a summary of the SVM features. 6 Results Table 5 summarizes the results of our model and other systems. Our best results are obtained with the Head-Prep-Child-Dist (HPCD) model using syntactic vectors, enriching, and relearning. The full model outperforms both full-scale parsers and a dedicated SVM model. More advanced parsers do demonstrate higher accuracy on the PP attachment task, but our method outperforms them as well. Note that the self-trained reranking parser (Charniak-RS) performs especially well and quite better than the RNN parser. This trend is consistent with the results in (Kummerfeld et al., 2012; Socher et al., 2013). Our compositional architecture is effective in exploiting raw data: using only standard word vectors with no enriching, our HPCD (basic) model performs comparably to an SVM with access to all enriching features. Once we improve the representation, we outperform both the SVM and full parsers. In comparison, the contribution of raw data to the SVM, as either word vectors or Brown clusters, is rather limited. 12 For example, we tried adding all word vector dimensions as features, as well as element-wise products of the vectors representing the head and the child. 13 As in"
Q14-1043,P14-1130,1,0.926222,"ll as the Arabic and English VerbNets (Kipper et al., 2008; Mousser, 2010) and WordNets (Rodr´ıquez et al., 2008; Princeton University, 2010). In total, these resources add to each word vector 46/67 extended dimensions in Arabic/English, representing syntactic and semantic information about the word. 5.3 Baselines We compare against full-scale parsers, an SVM ranker, and a simple but strong baseline of always choosing the closest candidate head. Parsers We mostly compare with dependency parsers, including the state-of-the-art Turbo (Martins et al., 2010; Martins et al., 2013) and RBG parsers (Lei et al., 2014), in addition to a secondorder MST parser (McDonald et al., 2005) and the Malt parser (Nivre et al., 2006). We also compare with two constituency parsers: an RNN parser (Socher et al., 2013), which also uses word vectors and a neural network approach, and the Charniak self-trained reranking parser (McClosky et al., 2006). We train all parsers on the train/dev sets and report their PP attachment accuracy on the test sets.10 For the self-trained parser we followed the 9 We use gold POS tags in all systems and experiments. The only exception is the RNN parser, for which we use the built-in Englis"
Q14-1043,P14-2050,0,0.0442242,"ank (Habash and Roth, 2009) for Arabic and a conversion of the Penn treebank (PTB) to dependency format for English.6 Standard train/dev/test splits are used: sections 2-21/22/23 of the PTB for English, and the split from the SPRML shared-task for Arabic (Seddah et al., 2013). As Table 2 shows, the datasets of the two languages are fairly similar in size, except for the much larger set of prepositions in the English data. Extracting instances of PP attachments from the treebanks is done in the following way. For each 5 We also experimented with another method for creating syntactic vectors by Levy and Goldberg (2014) and observed 566 Total Candidates Vocab sizes All Heads Preps Children Arabic Train Test 42,387 3,917 4.5 4.3 English Train Test 35,359 1,951 3.7 3.6 8,230 8,225 13 4,222 11,429 10,395 72 5,504 2,944 2,936 10 1,424 2,440 2,133 46 983 Table 2: Statistics of extracted PP attachments, showing total sizes, average number of candidate heads, and vocabulary sizes. Corpus Tokens Types Arabic arTenTen 130M 43K English Wikipedia BLLIP 120M 43M 218K 317K Table 3: Statistics of Arabic and English corpora used for creating word vectors. preposition, we look for all possible candidate heads in a fixed pre"
Q14-1043,D10-1004,0,0.0154772,", we use part-of-speech information9 from the treebanks as well as the Arabic and English VerbNets (Kipper et al., 2008; Mousser, 2010) and WordNets (Rodr´ıquez et al., 2008; Princeton University, 2010). In total, these resources add to each word vector 46/67 extended dimensions in Arabic/English, representing syntactic and semantic information about the word. 5.3 Baselines We compare against full-scale parsers, an SVM ranker, and a simple but strong baseline of always choosing the closest candidate head. Parsers We mostly compare with dependency parsers, including the state-of-the-art Turbo (Martins et al., 2010; Martins et al., 2013) and RBG parsers (Lei et al., 2014), in addition to a secondorder MST parser (McDonald et al., 2005) and the Malt parser (Nivre et al., 2006). We also compare with two constituency parsers: an RNN parser (Socher et al., 2013), which also uses word vectors and a neural network approach, and the Charniak self-trained reranking parser (McClosky et al., 2006). We train all parsers on the train/dev sets and report their PP attachment accuracy on the test sets.10 For the self-trained parser we followed the 9 We use gold POS tags in all systems and experiments. The only excepti"
Q14-1043,P13-2109,0,0.026728,"h information9 from the treebanks as well as the Arabic and English VerbNets (Kipper et al., 2008; Mousser, 2010) and WordNets (Rodr´ıquez et al., 2008; Princeton University, 2010). In total, these resources add to each word vector 46/67 extended dimensions in Arabic/English, representing syntactic and semantic information about the word. 5.3 Baselines We compare against full-scale parsers, an SVM ranker, and a simple but strong baseline of always choosing the closest candidate head. Parsers We mostly compare with dependency parsers, including the state-of-the-art Turbo (Martins et al., 2010; Martins et al., 2013) and RBG parsers (Lei et al., 2014), in addition to a secondorder MST parser (McDonald et al., 2005) and the Malt parser (Nivre et al., 2006). We also compare with two constituency parsers: an RNN parser (Socher et al., 2013), which also uses word vectors and a neural network approach, and the Charniak self-trained reranking parser (McClosky et al., 2006). We train all parsers on the train/dev sets and report their PP attachment accuracy on the test sets.10 For the self-trained parser we followed the 9 We use gold POS tags in all systems and experiments. The only exception is the RNN parser, f"
Q14-1043,N06-1020,0,0.162558,"that have restricted access to word semantics. These considerations have motivated recent explorations in using distributed word representations for syntactic parsing (Cirik and S¸ensoy, 2013; Socher et al., 2013; Lei et al., 2014). Lowdimensional word embeddings help unveil semantic similarity between words, thereby alleviating the data sparsity problem associated with PP attachment. In this context, large amounts of raw data used to construct embeddings effectively enrich limited syntactic annotations. While these approaches show initial promise, they still lag behind self-trained parsers (McClosky et al., 2006). These parsers also utilize raw data but in a different way: self-trained parsers use it to get additional (noisy) annotations, without computing new word representations. These results suggest that embedding-based representations have not yet been utilized to their full potential. We show that embedding-based representations can indeed significantly improve PP attachment accuracy. We achieve this by using such representations within a compositional neural network architecture. The representations are initially learned from an unlabeled corpus, but are then further discriminatively trained to"
Q14-1043,P05-1012,0,0.0611958,"Mousser, 2010) and WordNets (Rodr´ıquez et al., 2008; Princeton University, 2010). In total, these resources add to each word vector 46/67 extended dimensions in Arabic/English, representing syntactic and semantic information about the word. 5.3 Baselines We compare against full-scale parsers, an SVM ranker, and a simple but strong baseline of always choosing the closest candidate head. Parsers We mostly compare with dependency parsers, including the state-of-the-art Turbo (Martins et al., 2010; Martins et al., 2013) and RBG parsers (Lei et al., 2014), in addition to a secondorder MST parser (McDonald et al., 2005) and the Malt parser (Nivre et al., 2006). We also compare with two constituency parsers: an RNN parser (Socher et al., 2013), which also uses word vectors and a neural network approach, and the Charniak self-trained reranking parser (McClosky et al., 2006). We train all parsers on the train/dev sets and report their PP attachment accuracy on the test sets.10 For the self-trained parser we followed the 9 We use gold POS tags in all systems and experiments. The only exception is the RNN parser, for which we use the built-in English model in Stanford parser’s (version 3.4); 10 567 Source Treeban"
Q14-1043,mousser-2010-large,0,0.0247724,"sh vectors in (Bansal et al., 2014), which were trained from a parsed BLLIP corpus (minus PTB). For Arabic, we first convert the morphologically-processed arTenTen corpus to CoNLL format with the SPMRL shared-task scripts (Seddah et al., 2013). Then we parse the corpus with a baseline MST parser (Section 5.3) and create syntactic word vectors as described in Section 4.3. The Arabic syntactic vectors will be made available to the research community. For enriching word vectors, we use part-of-speech information9 from the treebanks as well as the Arabic and English VerbNets (Kipper et al., 2008; Mousser, 2010) and WordNets (Rodr´ıquez et al., 2008; Princeton University, 2010). In total, these resources add to each word vector 46/67 extended dimensions in Arabic/English, representing syntactic and semantic information about the word. 5.3 Baselines We compare against full-scale parsers, an SVM ranker, and a simple but strong baseline of always choosing the closest candidate head. Parsers We mostly compare with dependency parsers, including the state-of-the-art Turbo (Martins et al., 2010; Martins et al., 2013) and RBG parsers (Lei et al., 2014), in addition to a secondorder MST parser (McDonald et al"
Q14-1043,nivre-etal-2006-maltparser,0,0.0680035,"l., 2008; Princeton University, 2010). In total, these resources add to each word vector 46/67 extended dimensions in Arabic/English, representing syntactic and semantic information about the word. 5.3 Baselines We compare against full-scale parsers, an SVM ranker, and a simple but strong baseline of always choosing the closest candidate head. Parsers We mostly compare with dependency parsers, including the state-of-the-art Turbo (Martins et al., 2010; Martins et al., 2013) and RBG parsers (Lei et al., 2014), in addition to a secondorder MST parser (McDonald et al., 2005) and the Malt parser (Nivre et al., 2006). We also compare with two constituency parsers: an RNN parser (Socher et al., 2013), which also uses word vectors and a neural network approach, and the Charniak self-trained reranking parser (McClosky et al., 2006). We train all parsers on the train/dev sets and report their PP attachment accuracy on the test sets.10 For the self-trained parser we followed the 9 We use gold POS tags in all systems and experiments. The only exception is the RNN parser, for which we use the built-in English model in Stanford parser’s (version 3.4); 10 567 Source Treebank WordNet VerbNet Word Vectors Brown Clus"
Q14-1043,H05-1035,0,0.48423,"Our results 562 demonstrate that relearning the embeddings contributes to the model performance, across a range of configurations. We also notice that representations based on syntactic context are more powerful than those based on linear context. This may explain the improved performance of self-trained parsers over parsers that rely on linear context embeddings. 2 Related Work Problem formulation Typically, PP attachment disambiguation is modeled as a binary classification decision between a preceding noun or verb (Brill and Resnik, 1994; Ratnaparkhi et al., 1994; Collins and Brooks, 1995; Olteanu and Moldovan, 2005; ˇ Suster, 2012). In addition, the problem of PP attachment has also been addressed in the context of full parsing (Atterer and Sch¨utze, 2007; Agirre et al., 2008). For instance, Green (2009) engineered statesplit features for the Stanford parser to improve Arabic PP attachment. In this work, we do isolate PP attachments from other parsing decisions. At the same time, we consider a more realistic scenario where multiple candidate heads are allowed. We also compare against full-scale parsers and show that our model predictions improve a state-of-the-art dependency parser. Information sources"
Q14-1043,H94-1048,0,0.859503,"Missing"
Q14-1043,rodriguez-etal-2008-arabic,0,0.0351991,"Missing"
Q14-1043,W13-4917,0,0.0479966,"Missing"
Q14-1043,P13-1045,0,0.68023,"ing WordNet semantic classes benefits PP attachment performance. On the other hand, researchers have looked into using co-occurrence statistics from raw text (Volk, 2002; Olteanu and Moldovan, 2005; Gala and Lafourcade, 2007). Such statistics can be translated into word vectors from ˇ which a cosine similarity score is calculated (Suster, 2012). We also rely on word vectors, but our model captures more complex relations among them. Algorithmic approach Our work is most similar to recursive neural network parsers (Costa et al., 2003; Menchetti et al., 2005; Socher et al., 2010). In particular, Socher et al. (2013) obtain good parsing performance by building compositional representations from word vectors. However, to combat the computational complexity of the full parsing scenario, they rely on a probabilistic context-free grammar to prune search space. In contrast, focusing on PP attachment allows us to consider various neural network architectures that are more appropriate for this task, including ternary, binary, and distancedependent compositions. Furthermore, we investigate modifications to the original word vectors in several important directions: enriching word vectors with semantic and syntacti"
Q14-1043,W97-0109,0,0.461899,"s for the Stanford parser to improve Arabic PP attachment. In this work, we do isolate PP attachments from other parsing decisions. At the same time, we consider a more realistic scenario where multiple candidate heads are allowed. We also compare against full-scale parsers and show that our model predictions improve a state-of-the-art dependency parser. Information sources Lexical sparsity associated with disambiguating PP attachments (Figure 1) has spurred researchers to exploit a wide range of information sources. On the one hand, researchers have explored using manually crafted resources (Stetina and Nagao, 1997; Gamallo et al., 2003; Olteanu and Moldovan, 2005; Medimi and Bhattacharyya, 2007). For instance, Agirre et al. (2008) demonstrate that using WordNet semantic classes benefits PP attachment performance. On the other hand, researchers have looked into using co-occurrence statistics from raw text (Volk, 2002; Olteanu and Moldovan, 2005; Gala and Lafourcade, 2007). Such statistics can be translated into word vectors from ˇ which a cosine similarity score is calculated (Suster, 2012). We also rely on word vectors, but our model captures more complex relations among them. Algorithmic approach Our"
Q14-1043,P10-1040,0,0.0873257,"l learning rate η = 1.0 (Dyer, n.d.), and minibatch size of 500. Learned parameters are initialized similarly to previous work (Bengio and Glorot, 2010; Socher et al., 2013): composition matrices are set to W = 0.5[I I] + , where  ∼ U (− n1 , n1 ); bias terms b are set to zero; and the weight vector is set to w ∼ U (− √1n , √1n ). 4 Word vector representations Our approach assumes a vector representation for each word. Such representations have gained popularity in recent years, due to the ability to train them from large unlabeled datasets, and their ease of use in a wide variety of tasks (Turian et al., 2010). There are various approaches to training vector representations (Collobert and Weston, 2008; Bengio et al., 2009). Here we chose to focus on the Skip-gram method recently proposed by Mikolov et al. (2013a). The Skip-gram model maximizes the average log-probability of every word generating its context, which is modeled via a neural net architecture, but without the non-linearity. To improve efficiency, this probability is approximated by a hierarchical softmax (Mikolov et al., 2013b) with vocabulary words represented in a binary Huffman tree.3 In the simplest variant of our method, we train t"
Q14-1043,C02-1004,0,0.164705,"state-of-the-art dependency parser. Information sources Lexical sparsity associated with disambiguating PP attachments (Figure 1) has spurred researchers to exploit a wide range of information sources. On the one hand, researchers have explored using manually crafted resources (Stetina and Nagao, 1997; Gamallo et al., 2003; Olteanu and Moldovan, 2005; Medimi and Bhattacharyya, 2007). For instance, Agirre et al. (2008) demonstrate that using WordNet semantic classes benefits PP attachment performance. On the other hand, researchers have looked into using co-occurrence statistics from raw text (Volk, 2002; Olteanu and Moldovan, 2005; Gala and Lafourcade, 2007). Such statistics can be translated into word vectors from ˇ which a cosine similarity score is calculated (Suster, 2012). We also rely on word vectors, but our model captures more complex relations among them. Algorithmic approach Our work is most similar to recursive neural network parsers (Costa et al., 2003; Menchetti et al., 2005; Socher et al., 2010). In particular, Socher et al. (2013) obtain good parsing performance by building compositional representations from word vectors. However, to combat the computational complexity of the"
Q14-1043,W13-4909,0,\N,Missing
Q19-1004,D16-1216,0,0.0227532,"at the NMT model learned a soft alignment between source and target words. Some aspects of word order may also be Figure 2: A visualization of attention weights, showing soft alignment between source and target sentences in an NMT model. Reproduced from Bahdanau et al. (2014), with permission. noticed, as in the reordering of noun and adjective when translating the phrase ‘‘European Economic Area.’’ Another line of work computes various saliency measures to attribute predictions to input features. The important or salient features can then be visualized in selected examples (Li et al., 2016a; Aubakirova and Bansal, 2016; Sundararajan et al., 2017; Arras et al., 2017a,b; Ding et al., 2017; Murdoch et al., 2018; Mudrakarta et al., 2018; Montavon et al., 2018; Godin et al., 2018). Saliency can also be computed with respect to intermediate values, rather than input features (Ghaeini et al., 2018).7 An instructive visualization technique is to cluster neural network activations and compare them to some linguistic property. Early work clustered RNN activations, showing that they organize in lexical categories (Elman, 1989, 1990). Similar techniques have been followed by others. Recent examples include clustering o"
Q19-1004,K17-1037,0,0.344757,"ent models or model components. Other methods for finding correspondences between parts of the neural network and certain properties include counting how often attention weights agree with a linguistic property like anaphora resolution (Voita et al., 2018) or directly computing correlations between neural network activations and some property; for example, correlating RNN state activations with depth in a syntactic tree (Qian et al., 2016a) or with Melfrequency cepstral coefficient (MFCC) acoustic features (Wu and King, 2016). Such correspondence may also be computed indirectly. For instance, Alishahi et al. (2017) defined an ABX discrimination task to evaluate how a neural model of speech (grounded in vision) encoded phonology. Given phoneme representations from different layers in their model, and three phonemes, A, B, and X, they compared whether the model representation for X is closer to A or B. This discrimination task enabled them to draw conclusions about which layers encoder phonology better, observing that lower layers generally encode more phonological information. Methods The most common approach for associating neural network components with linguistic properties is to predict such properti"
Q19-1004,D17-1042,0,0.0106428,", 2017). However, explaining why a deep, highly non-linear neural network makes a certain prediction is not trivial. One solution is to ask the model to generate explanations along with its primary prediction (Zaidan et al., 2007; Zhang et al., 2016),15 but this approach requires manual annotations of explanations, which may be hard to collect. An alternative approach is to use parts of the input as explanations. For example, Lei et al. (2016) defined a generator that learns a distribution over text fragments as candidate rationales for justifying predictions, evaluated on sentiment analysis. Alvarez-Melis and Jaakkola (2017) discovered input–output associations in a sequence-to-sequence learning scenario, by perturbing the input and finding the most relevant associations. Gupta and Sch¨utze (2018) inspected how information is accumulated in RNNs towards a prediction, and associated peaks in prediction scores with important input segments. As these methods use input segments to explain predictions, they do not shed much light on the internal computations that take place in the network. At present, despite the recognized importance for interpretability, our ability to explain predictions of neural networks in NLP i"
Q19-1004,N18-1205,0,0.0363702,"Missing"
Q19-1004,S17-2001,0,0.0170672,"Missing"
Q19-1004,P17-1057,0,0.048326,"Missing"
Q19-1004,P18-1126,0,0.0383012,"Missing"
Q19-1004,P18-1198,0,0.100808,"tions and recording the representations (say, hidden state activations). Another classifier is then used for predicting the property of interest (say, part-of-speech [POS] tags). The performance of this classifier is used for evaluating the quality of the generated representations, and by proxy that of the original model. This kind of approach has been used in numerous papers in recent years; see Table SM1 for references.5 It is referred to by various names, including ‘‘auxiliary prediction tasks’’ (Adi et al., 2017b), ‘‘diagnostic classifiers’’ (Veldhoen et al., 2016), and ‘‘probing tasks’’ (Conneau et al., 2018). As an example of this approach, let us walk through an application to analyzing syntax in neural machine translation (NMT) by Shi et al. (2016b). In this work, two NMT models were trained on standard parallel data—English→ French and English→German. The trained models (specifically, the encoders) were run on an annotated corpus and their hidden states were used for training a logistic regression classifier that predicts different syntactic properties. The authors concluded that the NMT encoders learn 2.2 Linguistic Phenomena Different kinds of linguistic information have been analyzed, rangi"
Q19-1004,P18-1241,0,0.22318,"ficity Adversarial attacks can be classified to targeted vs. non-targeted attacks (Yuan et al., 2017). A targeted attack specifies a specific false class, l0 , while a nontargeted attack cares only that the predicted class is wrong, l0 6= l. Targeted attacks are more difficult to generate, as they typically require knowledge of model parameters; that is, they are white-box attacks. This might explain why the majority of adversarial examples in NLP are nontargeted (see Table SM3). A few targeted attacks include Liang et al. (2018), which specified a desired class to fool a text classifier, and Chen et al. (2018a), which specified words or captions to generate in an image captioning model. Others targeted specific words to omit, replace, or include when attacking seq2seq models (Cheng et al., 2018; Ebrahimi et al., 2018a). Methods for generating targeted attacks in NLP could possibly take more inspiration from adversarial attacks in other fields. For instance, in attacking malware detection systems, several studies developed targeted attacks in a blackbox scenario (Yuan et al., 2017). A black-box targeted attack for MT was proposed by Zhao et al. (2018c), who used GANs to search for 14 These criteria"
Q19-1004,D15-1092,0,0.0260232,"embeddings. Some analysis has also been devoted to joint language–vision or audio–vision models, or to similarities between word embeddings and con volutional image representations. Table SM1 provides detailed references. 2.4 Limitations The classification approach may find that a certain amount of linguistic information is captured in the neural network. However, this does not necessarily mean that the information is used by the network. For example, Vanmassenhove et al. (2017) 6 Others found that even simple binary trees may work well in MT (Wang et al., 2018b) and sentence classification (Chen et al., 2015). 52 Figure 1: A heatmap visualizing neuron activations. In this case, the activations capture position in the sentence. (e.g., tree depth, coordination inversion) gain the most from using a deeper classifier. However, the approach is usually taken for granted; given its prevalence, it appears that better theoretical or empirical foundations are in place. 3 Visualization Visualization is a valuable tool for analyzing neural networks in the language domain and beyond. Early work visualized hidden unit activations in RNNs trained on an artificial language modeling task, and observed how they cor"
Q19-1004,P18-2006,0,0.168718,"as they typically require computing gradients with respect to the input, which would be discrete in the text case. One option is to compute gradients with respect to the input word embeddings, and perturb the embeddings. Since this may result in a vector that does not correspond to any word, one could search for the closest word embedding in a given dictionary (Papernot et al., 2016b); Cheng et al. (2018) extended this idea to seq2seq models. Others computed gradients with respect to input word embeddings to identify and rank words to be modified (Samanta and Mehta, 2017; Liang et al., 2018). Ebrahimi et al. (2018b) developed an alternative method by representing text edit operations in vector space (e.g., a binary vector specifying which characters in a word would be changed) and approximating the change in loss with the derivative along this vector. Given the difficulty in generating white-box adversarial examples for text, much research has been devoted to black-box examples. Often, the adversarial examples are inspired by text edits that are thought to be natural or commonly generated by humans, such as typos, misspellings, and so 5.2 Attack Specificity Adversarial attacks can be classified to targ"
Q19-1004,N15-1004,0,0.0508987,"Missing"
Q19-1004,W16-2524,0,0.0493146,"Missing"
Q19-1004,W16-2506,0,0.0221101,"rse-grained level, but some provide a more fine-grained evaluation of similarity or relatedness. For example, some datasets are dedicated for specific word classes such as verbs (Gerz et al., 2016) or rare words (Luong et al., 2013), or for evaluating compositional knowledge in sentence embeddings (Marelli et al., 2014). Multilingual and cross-lingual versions have also been collected (Leviant and Reichart, 2015; Cer et al., 2017). Although these datasets are widely used, this kind of evaluation has been criticized for its subjectivity and questionable correlation with downstream performance (Faruqui et al., 2016). 4.2 4.3 Languages As unfortunately usual in much NLP work, especially neural NLP, the vast majority of challenge sets are in English. This situation is slightly better in MT evaluation, where naturally all datasets feature other languages (see Table SM2). A notable exception is the work by Gulordava et al. (2018), who constructed examples for evaluating number agreement in language modeling in English, Russian, Hebrew, and Italian. Clearly, there is room for more challenge sets in nonEnglish languages. However, perhaps more pressing is the need for large-scale non-English datasets (besides M"
Q19-1004,N18-1091,0,0.0285527,"Missing"
Q19-1004,D16-1235,0,0.029272,"Missing"
Q19-1004,I17-1004,0,0.0615521,"Missing"
Q19-1004,D18-1537,0,0.0169249,"ermission. noticed, as in the reordering of noun and adjective when translating the phrase ‘‘European Economic Area.’’ Another line of work computes various saliency measures to attribute predictions to input features. The important or salient features can then be visualized in selected examples (Li et al., 2016a; Aubakirova and Bansal, 2016; Sundararajan et al., 2017; Arras et al., 2017a,b; Ding et al., 2017; Murdoch et al., 2018; Mudrakarta et al., 2018; Montavon et al., 2018; Godin et al., 2018). Saliency can also be computed with respect to intermediate values, rather than input features (Ghaeini et al., 2018).7 An instructive visualization technique is to cluster neural network activations and compare them to some linguistic property. Early work clustered RNN activations, showing that they organize in lexical categories (Elman, 1989, 1990). Similar techniques have been followed by others. Recent examples include clustering of sentence embeddings in an RNN encoder trained in a multitask learning scenario (Brunner et al., 2017), and phoneme clusters in a joint audio-visual RNN model (Alishahi et al., 2017). A few online tools for visualizing neural networks have recently become available. LSTMVis 7"
Q19-1004,P17-1047,1,0.872227,"Missing"
Q19-1004,W18-5408,0,0.0245989,"iers lead to overall better results, but do not alter the respective trends when comparing different models or components (Qian et al., 2016b; Belinkov, 2018). Interestingly, Conneau et al. (2018) found that tasks requiring more nuanced linguistic knowledge Neural Network Components In terms of the object of study, various neural network components were investigated, including word embeddings, RNN hidden states or gate activations, sentence embeddings, and attention weights in sequence-to-sequence (seq2seq) models. Generally less work has analyzed convolutional neural networks in NLP, but see Jacovi et al. (2018) for a recent exception. In speech processing, researchers have analyzed layers in deep neural networks for speech recognition and different speaker embeddings. Some analysis has also been devoted to joint language–vision or audio–vision models, or to similarities between word embeddings and con volutional image representations. Table SM1 provides detailed references. 2.4 Limitations The classification approach may find that a certain amount of linguistic information is captured in the neural network. However, this does not necessarily mean that the information is used by the network. For exam"
Q19-1004,W18-1807,0,0.0283029,"Missing"
Q19-1004,W18-2702,0,0.0252175,"1 shows an example visualization of a neuron that captures position of words in a sentence. The heatmap uses blue and red colors for negative and positive activation values, respectively, enabling the user to quickly grasp the function of this neuron. The attention mechanism that originated in work on NMT (Bahdanau et al., 2014) also lends itself to a natural visualization. The alignments obtained via different attention mechanisms have produced visualizations ranging from tasks like NLI (Rockt¨aschel et al., 2016; Yin et al., 2016), summarization (Rush et al., 2015), MT post-editing (Jauregi Unanue et al., 2018), and morphological inflection (Aharoni and Goldberg, 2017) to matching users on social media (Tay et al., 2018). Figure 2 reproduces a visualization of attention alignments from the original work by Bahdanau et al. Here grayscale values correspond to the weight of the attention between words in an English source sentence (columns) and its French translation (rows). As Bahdanau et al. explain, this visualization demonstrates that the NMT model learned a soft alignment between source and target words. Some aspects of word order may also be Figure 2: A visualization of attention weights, showing"
Q19-1004,J15-4004,0,0.0351455,"de a comprehensive categorization like the one compiled here. 8 RNNVis (Ming et al., 2017) is a similar tool, but its online demo does not seem to be available at the time of writing. 54 and Isabelle and Kuhn (2018) prepared challenge sets for MT evaluation covering fine-grained phenomena at morpho-syntactic, syntactic, and lexical levels. Generally, datasets that are constructed programmatically tend to cover less fine-grained linguistic properties, while manually constructed datasets represent more diverse phenomena. to evaluate word embeddings (Finkelstein et al., 2002; Bruni et al., 2012; Hill et al., 2015, inter alia) or sentence embeddings; see the many shared tasks on semantic textual similarity in SemEval (Cer et al., 2017, and previous editions). Many of these datasets evaluate similarity at a coarse-grained level, but some provide a more fine-grained evaluation of similarity or relatedness. For example, some datasets are dedicated for specific word classes such as verbs (Gerz et al., 2016) or rare words (Luong et al., 2013), or for evaluating compositional knowledge in sentence embeddings (Marelli et al., 2014). Multilingual and cross-lingual versions have also been collected (Leviant and"
Q19-1004,D17-1215,0,0.0437099,"ammaticality or similarity of the adversarial examples to the original ones (Zhao et al., 2018c; Alzantot et al., 2018). Given the inherent difficulty in generating imperceptible changes in text, more such evaluations are needed. attacks on Google’s MT system after mapping sentences into continuous space with adversarially regularized autoencoders (Zhao et al., 2018b). 5.3 Linguistic Unit Most of the work on adversarial text examples involves modifications at the character- and/or word-level; see Table SM3 for specific references. Other transformations include adding sentences or text chunks (Jia and Liang, 2017) or generating paraphrases with desired syntactic structures (Iyyer et al., 2018). In image captioning, Chen et al. (2018a) modified pixels in the input image to generate targeted attacks on the caption text. 5.4 6 Explaining specific predictions is recognized as a desideratum in intereptability work (Lipton, 2016), argued to increase the accountability of machine learning systems (Doshi-Velez et al., 2017). However, explaining why a deep, highly non-linear neural network makes a certain prediction is not trivial. One solution is to ask the model to generate explanations along with its primary"
Q19-1004,D17-1263,0,0.118606,"ogical properties (Burlot and Yvon, 2017). See Table SM2 for references to datasets targeting other phenomena. Other challenge sets cover a more diverse range of linguistic properties, in the spirit of some of the earlier work. For instance, extending the categories in Cooper et al. (1996), the GLUE analysis set for NLI covers more than 30 phenomena in four coarse categories (lexical semantics, predicate–argument structure, logic, and knowledge). In MT evaluation, Burchardt et al. (2017) reported results using a large test suite covering 120 phenomena, partly based on Lehmann et al. (1996).11 Isabelle et al. (2017) 4.4 Scale The size of proposed challenge sets varies greatly (Table SM2). As expected, datasets constructed by hand are smaller, with typical sizes in the hundreds. Automatically built datasets are much larger, ranging from several thousands to close to a hundred thousand (Sennrich, 2017), or even more than one million examples (Linzen et al., 2016). In the latter case, the authors argue that such a large test set is needed for obtaining a sufficient representation of rare cases. A few manually constructed datasets contain a fairly large number of examples, up to 10 thousand (Burchardt et al."
Q19-1004,P18-1027,0,0.0214438,"nonyms and other word lists (Samanta and Mehta, 2017; Yang et al., 2018). Some reported whether a human can classify the adversarial example correctly (Yang et al., 7 Other Methods We briefly mention here several analysis methods that do not fall neatly into the previous sections. A number of studies evaluated the effect of erasing or masking certain neural network components, such as word embedding dimensions, hidden units, or even full words (Li et al., 2016b; 15 Other work considered learning textual-visual explanations from multimodal annotations (Park et al., 2018). 58 Feng et al., 2018; Khandelwal et al., 2018; Bau et al., 2018). For example, Li et al. (2016b) erased specific dimensions in word embeddings or hidden states and computed the change in probability assigned to different labels. Their experiments revealed interesting differences between word embedding models, where in some models information is more focused in individual dimensions. They also found that information is more distributed in hidden layers than in the input layer, and erased entire words to find important words in a sentiment analysis task. Several studies conducted behavioral experiments to interpret word embeddings by defin"
Q19-1004,Q16-1023,0,0.0211532,"nterpret, and evaluate neural networks in novel and more fine-grained ways. In this survey paper, we review analysis methods in neural language processing, categorize them according to prominent research trends, highlight existing limitations, and point to potential directions for future work. 1 Introduction The rise of deep learning has transformed the field of natural language processing (NLP) in recent years. Models based on neural networks have obtained impressive improvements in various tasks, including language modeling (Mikolov et al., 2010; Jozefowicz et al., 2016), syntactic parsing (Kiperwasser and Goldberg, 2016), machine translation (MT) (Bahdanau et al., 2014; Sutskever et al., 2014), and many other tasks; see Goldberg (2017) for example success stories. This progress has been accompanied by a myriad of new neural network architectures. In many cases, traditional feature-rich systems are being replaced by end-to-end neural networks that aim to map input text to some output prediction. As end-to-end systems are gaining prevalence, one may point to two trends. First, some push back against the abandonment of linguistic knowledge and call for incorporating it inside 1 See, for instance, Noah Smith’s in"
Q19-1004,N16-1082,0,0.249773,"on demonstrates that the NMT model learned a soft alignment between source and target words. Some aspects of word order may also be Figure 2: A visualization of attention weights, showing soft alignment between source and target sentences in an NMT model. Reproduced from Bahdanau et al. (2014), with permission. noticed, as in the reordering of noun and adjective when translating the phrase ‘‘European Economic Area.’’ Another line of work computes various saliency measures to attribute predictions to input features. The important or salient features can then be visualized in selected examples (Li et al., 2016a; Aubakirova and Bansal, 2016; Sundararajan et al., 2017; Arras et al., 2017a,b; Ding et al., 2017; Murdoch et al., 2018; Mudrakarta et al., 2018; Montavon et al., 2018; Godin et al., 2018). Saliency can also be computed with respect to intermediate values, rather than input features (Ghaeini et al., 2018).7 An instructive visualization technique is to cluster neural network activations and compare them to some linguistic property. Early work clustered RNN activations, showing that they organize in lexical categories (Elman, 1989, 1990). Similar techniques have been followed by others. Recent"
Q19-1004,2001.mtsummit-papers.35,0,0.0713273,"judgments. Datasets containing such similarity scores are often used Challenge Sets The majority of benchmark datasets in NLP are drawn from text corpora, reflecting a natural frequency distribution of language phenomena. While useful in practice for evaluating system performance in the average case, such datasets may fail to capture a wide range of phenomena. An alternative evaluation framework consists of challenge sets, also known as test suites, which have been used in NLP for a long time (Lehmann et al., 1996), especially for evaluating MT systems (King and Falkedal, 1990; Isahara, 1995; Koh et al., 2001). Lehmann et al. (1996) noted several key properties of test suites: systematicity, control over data, inclusion of negative data, 9 One could speculate that their decrease in popularity can be attributed to the rise of large-scale quantitative evaluation of statistical NLP systems. 10 Another typology of evaluation protocols was put forth by Burlot and Yvon (2017). Their criteria are partially overlapping with ours, although they did not provide a comprehensive categorization like the one compiled here. 8 RNNVis (Ming et al., 2017) is a similar tool, but its online demo does not seem to be av"
Q19-1004,D15-1246,0,0.0879949,"Missing"
Q19-1004,Q16-1037,0,0.250987,"eural network models for speech, or in joint audio-visual models. See Table SM1 for references. While it is difficult to synthesize a holistic picture from this diverse body of work, it appears that neural networks are able to learn a substantial amount of information on various linguistic phenomena. These models are especially successful at capturing frequent properties, while some rare properties are more difficult to learn. 5 A similar method has been used to analyze hierarchical structure in neural networks trained on arithmetic expressions (Veldhoen et al., 2016; Hupkes et al., 2018). 51 Linzen et al. (2016), for instance, found that long short-term memory (LSTM) language models are able to capture subject–verb agreement in many common cases, while direct supervision is required for solving harder cases. Another theme that emerges in several studies is the hierarchical nature of the learned representations. We have already mentioned such findings regarding NMT (Shi et al., 2016b) and a visually grounded speech model (Alishahi et al., 2017). Hierarchical representations of syntax were also reported to emerge in other RNN models (Blevins et al., 2018). Finally, a couple of papers discovered that mo"
Q19-1004,W18-3024,0,0.0104913,"nted; given its prevalence, it appears that better theoretical or empirical foundations are in place. 3 Visualization Visualization is a valuable tool for analyzing neural networks in the language domain and beyond. Early work visualized hidden unit activations in RNNs trained on an artificial language modeling task, and observed how they correspond to certain grammatical relations such as agreement (Elman, 1991). Much recent work has focused on visualizing activations on specific examples in modern neural networks for language (Karpathy et al., 2015; K´ad´ar et al., 2017; Qian et al., 2016a; Liu et al., 2018) and speech (Wu and King, 2016; Nagamine et al., 2015; Wang et al., 2017b). Figure 1 shows an example visualization of a neuron that captures position of words in a sentence. The heatmap uses blue and red colors for negative and positive activation values, respectively, enabling the user to quickly grasp the function of this neuron. The attention mechanism that originated in work on NMT (Bahdanau et al., 2014) also lends itself to a natural visualization. The alignments obtained via different attention mechanisms have produced visualizations ranging from tasks like NLI (Rockt¨aschel et al., 20"
Q19-1004,D16-1011,0,0.0259874,"c predictions is recognized as a desideratum in intereptability work (Lipton, 2016), argued to increase the accountability of machine learning systems (Doshi-Velez et al., 2017). However, explaining why a deep, highly non-linear neural network makes a certain prediction is not trivial. One solution is to ask the model to generate explanations along with its primary prediction (Zaidan et al., 2007; Zhang et al., 2016),15 but this approach requires manual annotations of explanations, which may be hard to collect. An alternative approach is to use parts of the input as explanations. For example, Lei et al. (2016) defined a generator that learns a distribution over text fragments as candidate rationales for justifying predictions, evaluated on sentiment analysis. Alvarez-Melis and Jaakkola (2017) discovered input–output associations in a sequence-to-sequence learning scenario, by perturbing the input and finding the most relevant associations. Gupta and Sch¨utze (2018) inspected how information is accumulated in RNNs towards a prediction, and associated peaks in prediction scores with important input segments. As these methods use input segments to explain predictions, they do not shed much light on th"
Q19-1004,W13-3512,0,0.0607766,"d linguistic properties, while manually constructed datasets represent more diverse phenomena. to evaluate word embeddings (Finkelstein et al., 2002; Bruni et al., 2012; Hill et al., 2015, inter alia) or sentence embeddings; see the many shared tasks on semantic textual similarity in SemEval (Cer et al., 2017, and previous editions). Many of these datasets evaluate similarity at a coarse-grained level, but some provide a more fine-grained evaluation of similarity or relatedness. For example, some datasets are dedicated for specific word classes such as verbs (Gerz et al., 2016) or rare words (Luong et al., 2013), or for evaluating compositional knowledge in sentence embeddings (Marelli et al., 2014). Multilingual and cross-lingual versions have also been collected (Leviant and Reichart, 2015; Cer et al., 2017). Although these datasets are widely used, this kind of evaluation has been criticized for its subjectivity and questionable correlation with downstream performance (Faruqui et al., 2016). 4.2 4.3 Languages As unfortunately usual in much NLP work, especially neural NLP, the vast majority of challenge sets are in English. This situation is slightly better in MT evaluation, where naturally all dat"
Q19-1004,W18-2903,0,0.0438856,"Missing"
Q19-1004,N18-1100,0,0.0283759,"Missing"
Q19-1004,C12-1118,0,0.0203432,"d the change in probability assigned to different labels. Their experiments revealed interesting differences between word embedding models, where in some models information is more focused in individual dimensions. They also found that information is more distributed in hidden layers than in the input layer, and erased entire words to find important words in a sentiment analysis task. Several studies conducted behavioral experiments to interpret word embeddings by defining intrusion tasks, where humans need to identify an intruder word, chosen based on difference in word embedding dimensions (Murphy et al., 2012; Fyshe et al., 2015; Faruqui et al., 2015).16 In this kind of work, a word embedding model may be deemed more interpretable if humans are better able to identify the intruding words. Since the evaluation is costly for high-dimensional representations, alternative automatic metrics were considered (Park et al., 2017; Senel et al., 2018). A long tradition in work on neural networks is to evaluate and analyze their ability to learn different formal languages (Das et al., 1992; Casey, 1996; Gers and Schmidhuber, 2001; Bod´en and Wiles, 2002; Chalup and Blair, 2003). This trend continues today, wi"
Q19-1004,C18-1198,0,0.0205847,"this comes at the expense of how natural the examples are. 4.6 contrastive pairs evaluation of Sennrich (2017). Automatic evaluation metrics are cheap to obtain and can be calculated on a large scale. However, they may miss certain aspects. Thus a few studies report human evaluation on their challenge sets, such as in MT (Isabelle et al., 2017; Burchardt et al., 2017). We note here also that judging the quality of a model by its performance on a challenge set can be tricky. Some authors emphasize their wish to test systems on extreme or difficult cases, ‘‘beyond normal operational capacity’’ (Naik et al., 2018). However, whether one should expect systems to perform well on specially chosen cases (as opposed to the average case) may depend on one’s goals. To put results in perspective, one may compare model performance to human performance on the same task (Gulordava et al., 2018). 5 Adversarial Examples Understanding a model also requires an understanding of its failures. Despite their success in many tasks, machine learning systems can also be very sensitive to malicious attacks or adversarial examples (Szegedy et al., 2014; Goodfellow et al., 2015). In the vision domain, small changes to the input"
Q19-1004,W18-5441,0,0.0314285,"Missing"
Q19-1004,K18-1047,0,0.0428315,"Missing"
Q19-1004,S18-2023,0,0.0379384,"Missing"
Q19-1004,D16-1079,0,0.398683,"ormation tends to be stored in the upper layer.’’ These results demonstrate the kind of insights that the classification analysis may lead to, especially when comparing different models or model components. Other methods for finding correspondences between parts of the neural network and certain properties include counting how often attention weights agree with a linguistic property like anaphora resolution (Voita et al., 2018) or directly computing correlations between neural network activations and some property; for example, correlating RNN state activations with depth in a syntactic tree (Qian et al., 2016a) or with Melfrequency cepstral coefficient (MFCC) acoustic features (Wu and King, 2016). Such correspondence may also be computed indirectly. For instance, Alishahi et al. (2017) defined an ABX discrimination task to evaluate how a neural model of speech (grounded in vision) encoded phonology. Given phoneme representations from different layers in their model, and three phonemes, A, B, and X, they compared whether the model representation for X is closer to A or B. This discrimination task enabled them to draw conclusions about which layers encoder phonology better, observing that lower laye"
Q19-1004,P16-1140,0,0.281048,"ormation tends to be stored in the upper layer.’’ These results demonstrate the kind of insights that the classification analysis may lead to, especially when comparing different models or model components. Other methods for finding correspondences between parts of the neural network and certain properties include counting how often attention weights agree with a linguistic property like anaphora resolution (Voita et al., 2018) or directly computing correlations between neural network activations and some property; for example, correlating RNN state activations with depth in a syntactic tree (Qian et al., 2016a) or with Melfrequency cepstral coefficient (MFCC) acoustic features (Wu and King, 2016). Such correspondence may also be computed indirectly. For instance, Alishahi et al. (2017) defined an ABX discrimination task to evaluate how a neural model of speech (grounded in vision) encoded phonology. Given phoneme representations from different layers in their model, and three phonemes, A, B, and X, they compared whether the model representation for X is closer to A or B. This discrimination task enabled them to draw conclusions about which layers encoder phonology better, observing that lower laye"
Q19-1004,D17-1041,0,0.0221322,"d entire words to find important words in a sentiment analysis task. Several studies conducted behavioral experiments to interpret word embeddings by defining intrusion tasks, where humans need to identify an intruder word, chosen based on difference in word embedding dimensions (Murphy et al., 2012; Fyshe et al., 2015; Faruqui et al., 2015).16 In this kind of work, a word embedding model may be deemed more interpretable if humans are better able to identify the intruding words. Since the evaluation is costly for high-dimensional representations, alternative automatic metrics were considered (Park et al., 2017; Senel et al., 2018). A long tradition in work on neural networks is to evaluate and analyze their ability to learn different formal languages (Das et al., 1992; Casey, 1996; Gers and Schmidhuber, 2001; Bod´en and Wiles, 2002; Chalup and Blair, 2003). This trend continues today, with research into modern architectures and what formal languages they can learn (Weiss et al., 2018; Bernardy, 2018; Suzgun et al., 2019), or the formal properties they possess (Chen et al., 2018b). 8 visualization via saliency measures or evaluation by adversarial examples. But even those sometimes require non-trivi"
Q19-1004,P18-1079,0,0.0634436,"Missing"
Q19-1004,D18-1179,0,0.117576,"Missing"
Q19-1004,W17-4702,0,0.0278654,"ate the probability of two candidate translations that are designed to reflect specific linguistic properties. Sennrich generated such pairs programmatically by applying simple heuristics, such as changing gender and number to induce agreement errors, resulting in a large-scale challenge set of close to 100 thousand examples. This framework was extended to evaluate other properties, but often requiring more sophisticated generation methods like using morphological analyzers/ generators (Burlot and Yvon, 2017) or more manual involvement in generation (Bawden et al., 2018) or verification (Rios Gonzales et al., 2017). Finally, a few studies define templates that capture certain linguistic properties and instantiate them with word lists (Dasgupta et al., 2018; Rudinger et al., 2018; Zhao et al., 2018a). Template-based generation has the advantage of providing more control, for example for obtaining a specific vocabulary distribution, but this comes at the expense of how natural the examples are. 4.6 contrastive pairs evaluation of Sennrich (2017). Automatic evaluation metrics are cheap to obtain and can be calculated on a large scale. However, they may miss certain aspects. Thus a few studies report human"
Q19-1004,N18-1179,0,0.0203177,"n, semi-automatic methods are used to compile an initial list of examples that is manually verified by annotators. The specific method also affects the kind of language use and how natural or artificial/synthetic the examples are. We describe here some trends in dataset construction methods in the hope that they may be useful for researchers contemplating new datasets. 11 Their dataset does not seem to be available yet, but more details are promised to appear in a future publication. 55 Several datasets were constructed by modifying or extracting examples from existing datasets. For instance, Sanchez et al. (2018) and Glockner et al. (2018) extracted examples from SNLI (Bowman et al., 2015) and replaced specific words such as hypernyms, synonyms, and antonyms, followed by manual verification. Linzen et al. (2016), on the other hand, extracted examples of subject–verb agreement from raw texts using heuristics, resulting in a large-scale dataset. Gulordava et al. (2018) extended this to other agreement phenomena, but they relied on syntactic information available in treebanks, resulting in a smaller dataset. Several challenge sets utilize existing test suites, either as a direct source of examples (Burch"
Q19-1004,N18-2002,0,0.0284845,"Missing"
Q19-1004,E17-2060,0,0.130236,"number agreement in language modeling in English, Russian, Hebrew, and Italian. Clearly, there is room for more challenge sets in nonEnglish languages. However, perhaps more pressing is the need for large-scale non-English datasets (besides MT) to develop neural models for popular NLP tasks. Linguistic Phenomena One of the primary goals of challenge sets is to evaluate models on their ability to handle specific linguistic phenomena. While earlier studies emphasized exhaustivity (Cooper et al., 1996; Lehmann et al., 1996), recent ones tend to focus on a few properties of interest. For example, Sennrich (2017) introduced a challenge set for MT evaluation focusing on five properties: subject–verb agreement, noun phrase agreement, verb–particle constructions, polarity, and transliteration. Slightly more elaborated is an MT challenge set for morphology, including 14 morphological properties (Burlot and Yvon, 2017). See Table SM2 for references to datasets targeting other phenomena. Other challenge sets cover a more diverse range of linguistic properties, in the spirit of some of the earlier work. For instance, extending the categories in Cooper et al. (1996), the GLUE analysis set for NLI covers more"
Q19-1004,D15-1044,0,0.0518396,"ne et al., 2015; Wang et al., 2017b). Figure 1 shows an example visualization of a neuron that captures position of words in a sentence. The heatmap uses blue and red colors for negative and positive activation values, respectively, enabling the user to quickly grasp the function of this neuron. The attention mechanism that originated in work on NMT (Bahdanau et al., 2014) also lends itself to a natural visualization. The alignments obtained via different attention mechanisms have produced visualizations ranging from tasks like NLI (Rockt¨aschel et al., 2016; Yin et al., 2016), summarization (Rush et al., 2015), MT post-editing (Jauregi Unanue et al., 2018), and morphological inflection (Aharoni and Goldberg, 2017) to matching users on social media (Tay et al., 2018). Figure 2 reproduces a visualization of attention alignments from the original work by Bahdanau et al. Here grayscale values correspond to the weight of the attention between words in an English source sentence (columns) and its French translation (rows). As Bahdanau et al. explain, this visualization demonstrates that the NMT model learned a soft alignment between source and target words. Some aspects of word order may also be Figure 2"
Q19-1004,C18-1315,0,0.0214353,"Missing"
Q19-1004,D16-1248,0,0.21726,", part-of-speech [POS] tags). The performance of this classifier is used for evaluating the quality of the generated representations, and by proxy that of the original model. This kind of approach has been used in numerous papers in recent years; see Table SM1 for references.5 It is referred to by various names, including ‘‘auxiliary prediction tasks’’ (Adi et al., 2017b), ‘‘diagnostic classifiers’’ (Veldhoen et al., 2016), and ‘‘probing tasks’’ (Conneau et al., 2018). As an example of this approach, let us walk through an application to analyzing syntax in neural machine translation (NMT) by Shi et al. (2016b). In this work, two NMT models were trained on standard parallel data—English→ French and English→German. The trained models (specifically, the encoders) were run on an annotated corpus and their hidden states were used for training a logistic regression classifier that predicts different syntactic properties. The authors concluded that the NMT encoders learn 2.2 Linguistic Phenomena Different kinds of linguistic information have been analyzed, ranging from basic properties like sentence length, word position, word presence, or simple word order, to morphological, syntactic, and semantic inf"
Q19-1004,D18-1503,0,0.0603768,"Missing"
Q19-1004,P18-1117,0,0.0280104,"d sentence level. They also compared representations at different encoding layers and found that ‘‘local features are somehow preserved in the lower layer whereas more global, abstract information tends to be stored in the upper layer.’’ These results demonstrate the kind of insights that the classification analysis may lead to, especially when comparing different models or model components. Other methods for finding correspondences between parts of the neural network and certain properties include counting how often attention weights agree with a linguistic property like anaphora resolution (Voita et al., 2018) or directly computing correlations between neural network activations and some property; for example, correlating RNN state activations with depth in a syntactic tree (Qian et al., 2016a) or with Melfrequency cepstral coefficient (MFCC) acoustic features (Wu and King, 2016). Such correspondence may also be computed indirectly. For instance, Alishahi et al. (2017) defined an ABX discrimination task to evaluate how a neural model of speech (grounded in vision) encoded phonology. Given phoneme representations from different layers in their model, and three phonemes, A, B, and X, they compared wh"
Q19-1004,W19-0128,1,0.858898,"Missing"
Q19-1004,W18-5446,0,0.471801,"orks for speech recognition and different speaker embeddings. Some analysis has also been devoted to joint language–vision or audio–vision models, or to similarities between word embeddings and con volutional image representations. Table SM1 provides detailed references. 2.4 Limitations The classification approach may find that a certain amount of linguistic information is captured in the neural network. However, this does not necessarily mean that the information is used by the network. For example, Vanmassenhove et al. (2017) 6 Others found that even simple binary trees may work well in MT (Wang et al., 2018b) and sentence classification (Chen et al., 2015). 52 Figure 1: A heatmap visualizing neuron activations. In this case, the activations capture position in the sentence. (e.g., tree depth, coordination inversion) gain the most from using a deeper classifier. However, the approach is usually taken for granted; given its prevalence, it appears that better theoretical or empirical foundations are in place. 3 Visualization Visualization is a valuable tool for analyzing neural networks in the language domain and beyond. Early work visualized hidden unit activations in RNNs trained on an artificial"
Q19-1004,W18-6304,0,0.0457514,"Missing"
Q19-1004,N07-1033,0,0.0192489,"g paraphrases with desired syntactic structures (Iyyer et al., 2018). In image captioning, Chen et al. (2018a) modified pixels in the input image to generate targeted attacks on the caption text. 5.4 6 Explaining specific predictions is recognized as a desideratum in intereptability work (Lipton, 2016), argued to increase the accountability of machine learning systems (Doshi-Velez et al., 2017). However, explaining why a deep, highly non-linear neural network makes a certain prediction is not trivial. One solution is to ask the model to generate explanations along with its primary prediction (Zaidan et al., 2007; Zhang et al., 2016),15 but this approach requires manual annotations of explanations, which may be hard to collect. An alternative approach is to use parts of the input as explanations. For example, Lei et al. (2016) defined a generator that learns a distribution over text fragments as candidate rationales for justifying predictions, evaluated on sentiment analysis. Alvarez-Melis and Jaakkola (2017) discovered input–output associations in a sequence-to-sequence learning scenario, by perturbing the input and finding the most relevant associations. Gupta and Sch¨utze (2018) inspected how infor"
Q19-1004,D18-1509,0,0.326737,"orks for speech recognition and different speaker embeddings. Some analysis has also been devoted to joint language–vision or audio–vision models, or to similarities between word embeddings and con volutional image representations. Table SM1 provides detailed references. 2.4 Limitations The classification approach may find that a certain amount of linguistic information is captured in the neural network. However, this does not necessarily mean that the information is used by the network. For example, Vanmassenhove et al. (2017) 6 Others found that even simple binary trees may work well in MT (Wang et al., 2018b) and sentence classification (Chen et al., 2015). 52 Figure 1: A heatmap visualizing neuron activations. In this case, the activations capture position in the sentence. (e.g., tree depth, coordination inversion) gain the most from using a deeper classifier. However, the approach is usually taken for granted; given its prevalence, it appears that better theoretical or empirical foundations are in place. 3 Visualization Visualization is a valuable tool for analyzing neural networks in the language domain and beyond. Early work visualized hidden unit activations in RNNs trained on an artificial"
Q19-1004,P18-2117,0,0.0195342,"dding model may be deemed more interpretable if humans are better able to identify the intruding words. Since the evaluation is costly for high-dimensional representations, alternative automatic metrics were considered (Park et al., 2017; Senel et al., 2018). A long tradition in work on neural networks is to evaluate and analyze their ability to learn different formal languages (Das et al., 1992; Casey, 1996; Gers and Schmidhuber, 2001; Bod´en and Wiles, 2002; Chalup and Blair, 2003). This trend continues today, with research into modern architectures and what formal languages they can learn (Weiss et al., 2018; Bernardy, 2018; Suzgun et al., 2019), or the formal properties they possess (Chen et al., 2018b). 8 visualization via saliency measures or evaluation by adversarial examples. But even those sometimes require non-trivial adaptations to work with text input. Some methods are more specific to the field, but may prove useful in other domains. Challenge sets or test suites are such a case. Throughout this survey, we have identified several limitations or gaps in current analysis work: • The use of auxiliary classification tasks for identifying which linguistic properties neural networks capture h"
Q19-1004,D16-1076,0,0.0229308,"sired syntactic structures (Iyyer et al., 2018). In image captioning, Chen et al. (2018a) modified pixels in the input image to generate targeted attacks on the caption text. 5.4 6 Explaining specific predictions is recognized as a desideratum in intereptability work (Lipton, 2016), argued to increase the accountability of machine learning systems (Doshi-Velez et al., 2017). However, explaining why a deep, highly non-linear neural network makes a certain prediction is not trivial. One solution is to ask the model to generate explanations along with its primary prediction (Zaidan et al., 2007; Zhang et al., 2016),15 but this approach requires manual annotations of explanations, which may be hard to collect. An alternative approach is to use parts of the input as explanations. For example, Lei et al. (2016) defined a generator that learns a distribution over text fragments as candidate rationales for justifying predictions, evaluated on sentiment analysis. Alvarez-Melis and Jaakkola (2017) discovered input–output associations in a sequence-to-sequence learning scenario, by perturbing the input and finding the most relevant associations. Gupta and Sch¨utze (2018) inspected how information is accumulated"
Q19-1004,Q18-1019,0,0.0483906,"Missing"
Q19-1004,N18-2003,0,0.360403,"ch as changing gender and number to induce agreement errors, resulting in a large-scale challenge set of close to 100 thousand examples. This framework was extended to evaluate other properties, but often requiring more sophisticated generation methods like using morphological analyzers/ generators (Burlot and Yvon, 2017) or more manual involvement in generation (Bawden et al., 2018) or verification (Rios Gonzales et al., 2017). Finally, a few studies define templates that capture certain linguistic properties and instantiate them with word lists (Dasgupta et al., 2018; Rudinger et al., 2018; Zhao et al., 2018a). Template-based generation has the advantage of providing more control, for example for obtaining a specific vocabulary distribution, but this comes at the expense of how natural the examples are. 4.6 contrastive pairs evaluation of Sennrich (2017). Automatic evaluation metrics are cheap to obtain and can be calculated on a large scale. However, they may miss certain aspects. Thus a few studies report human evaluation on their challenge sets, such as in MT (Isabelle et al., 2017; Burchardt et al., 2017). We note here also that judging the quality of a model by its performance on a challenge"
Q19-1004,Q16-1019,0,0.0684951,"Missing"
Q19-1004,D18-1316,0,0.25584,"ch as changing gender and number to induce agreement errors, resulting in a large-scale challenge set of close to 100 thousand examples. This framework was extended to evaluate other properties, but often requiring more sophisticated generation methods like using morphological analyzers/ generators (Burlot and Yvon, 2017) or more manual involvement in generation (Bawden et al., 2018) or verification (Rios Gonzales et al., 2017). Finally, a few studies define templates that capture certain linguistic properties and instantiate them with word lists (Dasgupta et al., 2018; Rudinger et al., 2018; Zhao et al., 2018a). Template-based generation has the advantage of providing more control, for example for obtaining a specific vocabulary distribution, but this comes at the expense of how natural the examples are. 4.6 contrastive pairs evaluation of Sennrich (2017). Automatic evaluation metrics are cheap to obtain and can be calculated on a large scale. However, they may miss certain aspects. Thus a few studies report human evaluation on their challenge sets, such as in MT (Isabelle et al., 2017; Burchardt et al., 2017). We note here also that judging the quality of a model by its performance on a challenge"
Q19-1004,D15-1075,0,\N,Missing
Q19-1004,D15-1002,0,\N,Missing
Q19-1004,J17-4003,0,\N,Missing
Q19-1004,P17-1080,1,\N,Missing
Q19-1004,P17-1106,0,\N,Missing
Q19-1004,W17-4705,0,\N,Missing
Q19-1004,P18-2103,0,\N,Missing
Q19-1004,W18-5418,0,\N,Missing
Q19-1004,W18-5402,0,\N,Missing
Q19-1004,D18-1007,0,\N,Missing
Q19-1004,D18-1277,0,\N,Missing
Q19-1004,D18-1313,0,\N,Missing
Q19-1004,P17-1183,0,\N,Missing
S15-2048,W14-5201,0,0.0238006,"Missing"
S15-2048,D14-1070,0,0.00899199,"Missing"
S15-2048,P14-2050,0,0.00385405,"refers to all the staff in your company ... you are all considered employees of your company A2: your qid should specify what is the actual profession you have. I think for me, your chances to have a drivers license is low. A3: his asking if he can obtain. means he have the driver license. Introduction Continuous word and phrase vectors, in which similar words and phrases are associated with similar vectors, have been useful in many NLP tasks (AlRfou et al., 2013; Bansal et al., 2014; Bowman et al., 2014; Boyd-Graber et al., 2012; Chen and Rudnicky, 2014; Guo et al., 2014; Iyyer et al., 2014; Levy and Goldberg, 2014; Mikolov et al., 2013c). To evaluate the effectiveness of continuous vector representations for Community question answering (CQA), we focused on using simple features derived from vector similarity as input to a multi-class linear SVM classifier. Our approach is language independent and was evaluated on both English and Arabic. Most of the vectors we use are domain-independent. CQA services provide forums for users to ask or answer questions on any topic, resulting in high variance answer quality (M`arquez et al., 2015). Searching for good answers among the many responses can Answer selectio"
S15-2048,P14-5010,0,0.00175448,"ector representations use the observation that similar words appear in similar contexts (Firth, 1957). The theses of Sahlgren (Sahlgren, 2006), Mikolov (Mikolov, 2012), and Socher (Socher, 2014) provide extensive information on vector representations. Our system analyzes questions and answers with a DkPro (Eckart de Castilho and Gurevych, 2014) uimaFIT (Ogren and Bethard, 2009) pipeline. The DkPro OpenNLP (Apache Software Foundation, 2014) segmenter and chunker tokenize and find sentences and phrases in the English questions and answers, followed by lemmatization with the Stanford lemmatizer (Manning et al., 2014). In Arabic, we only apply lemmatization, with no chunking, using MADAMIRA (Pasha et al., 2014). Stop words are removed in both languages. As shown in Table 1, we compute text-based, vector-based, metadata-based and rank-based features from the pre-processed data. The features are used for a linear SVM classifier for answer selection and YES/NO answer inference tasks. YES/NO answer inference is only performed on good YES/NO question answers, using the YES/NO majority class, and unsure otherwise. SVM parameters are set by grid-search and cross-validation. Text-based features These features are"
S15-2048,S15-2047,0,0.0869744,"Missing"
S15-2048,N13-1090,0,0.17161,"n your company ... you are all considered employees of your company A2: your qid should specify what is the actual profession you have. I think for me, your chances to have a drivers license is low. A3: his asking if he can obtain. means he have the driver license. Introduction Continuous word and phrase vectors, in which similar words and phrases are associated with similar vectors, have been useful in many NLP tasks (AlRfou et al., 2013; Bansal et al., 2014; Bowman et al., 2014; Boyd-Graber et al., 2012; Chen and Rudnicky, 2014; Guo et al., 2014; Iyyer et al., 2014; Levy and Goldberg, 2014; Mikolov et al., 2013c). To evaluate the effectiveness of continuous vector representations for Community question answering (CQA), we focused on using simple features derived from vector similarity as input to a multi-class linear SVM classifier. Our approach is language independent and was evaluated on both English and Arabic. Most of the vectors we use are domain-independent. CQA services provide forums for users to ask or answer questions on any topic, resulting in high variance answer quality (M`arquez et al., 2015). Searching for good answers among the many responses can Answer selection aims to automaticall"
S15-2048,W09-1501,0,0.0202031,"king scores Table 1: The different types of features. 2 Method Continuous vector representations, described by Sch¨utze (Sch¨utze, 1992a; Sch¨utze, 1992b), associate similar vectors with similar words and phrases. Most approaches to computing vector representations use the observation that similar words appear in similar contexts (Firth, 1957). The theses of Sahlgren (Sahlgren, 2006), Mikolov (Mikolov, 2012), and Socher (Socher, 2014) provide extensive information on vector representations. Our system analyzes questions and answers with a DkPro (Eckart de Castilho and Gurevych, 2014) uimaFIT (Ogren and Bethard, 2009) pipeline. The DkPro OpenNLP (Apache Software Foundation, 2014) segmenter and chunker tokenize and find sentences and phrases in the English questions and answers, followed by lemmatization with the Stanford lemmatizer (Manning et al., 2014). In Arabic, we only apply lemmatization, with no chunking, using MADAMIRA (Pasha et al., 2014). Stop words are removed in both languages. As shown in Table 1, we compute text-based, vector-based, metadata-based and rank-based features from the pre-processed data. The features are used for a linear SVM classifier for answer selection and YES/NO answer infer"
S15-2048,pasha-etal-2014-madamira,0,0.0212372,"Missing"
S15-2048,W13-3520,0,\N,Missing
S15-2048,D12-1118,0,\N,Missing
S15-2048,P14-2131,0,\N,Missing
S16-1128,P15-2113,0,0.0615618,"Missing"
S16-1128,S15-2048,1,0.742405,"d a list of questions Q for QR, we aim to rank the lists A and Q with respect to q. To address these problems, we present a bag-of-vectors (BOV) approach to compute various vector- and text-based features for a classifier. Furthermore, we present NN-based approaches (LSTM with attention, CNN and RCNN) for learning the vector representations of the questions and answers to be used for capturing their semantic similarity. The degree of similarity between the Q&A is used for their ranking. 2.1 Bag-of-Vectors (BOV) Previous work presented a BOV approach to address the classification tasks in cQA (Belinkov et al., 2015). In this paper, we aim to extend the previous approach for the ranking tasks by updating the feature sets and developing new models. The features are categorized into text, vector and meta-data based features that are briefly explained below (in the experiments section below we detail the features chosen for each task). Then, we explain our approach to shorten the length of Q&As in the Arabic data. Text-based features These features are mainly computed using text similarity metrics, word clustering and topic modeling. As the first set of text-based features, we use various text similarity met"
S16-1128,J92-4003,0,0.27822,"Missing"
S16-1128,P14-1062,0,0.00653696,"Missing"
S16-1128,S15-2047,1,0.133544,"Missing"
S16-1128,N13-1090,0,0.0115746,"Missing"
S16-1128,S16-1083,1,0.0398741,"Missing"
S16-1128,P14-2105,0,0.00882414,"Missing"
S16-1128,W04-3252,0,\N,Missing
S16-1128,D15-1068,0,\N,Missing
S19-1028,N18-2017,0,0.0824448,"Missing"
S19-1028,D15-1075,0,0.21254,"Missing"
S19-1028,N18-1111,0,0.0169731,"ils another (hypothesis) - contain hypothesis-only biases that allow models to perform the task surprisingly well by only considering hypotheses while ignoring the corresponding premises. For instance, such a method correctly predicted the examples in Table 1 as contradictions. As datasets may always contain biases, it is important to analyze whether, and to what extent, models are immune to or rely on known biases. Furthermore, it is important to build models that can overcome these biases. Recent work in NLP aims to build more robust systems using adversarial methods (Alzantot et al., 2018; Chen & Cardie, 2018; Belinkov & Bisk, 2018, i.a.). In particular, Elazar & Goldberg (2018) attempted to use adversarial training to remove demographic attributes from text data, with limited success. Inspired by this line of work, we use adversarial learning to add small components to an existing and popular NLI system that has been used to learn general sentence representations (Conneau et al., 2017). The adversarial ∗ techniques include (1) using an external adversarial classifier conditioned on hypotheses alone, and (2) creating noisy, perturbed training examples. In our analyses we ask whether hidden, hypoth"
S19-1028,P18-1225,0,0.0559285,"ude (1) using an external adversarial classifier conditioned on hypotheses alone, and (2) creating noisy, perturbed training examples. In our analyses we ask whether hidden, hypothesisonly biases are no longer present in the resulting sentence representations after adversarial learning. The goal is to build models with less bias, ideally while limiting the inevitable degradation in task performance. Our results suggest that progress on this goal may depend on which adversarial learning techniques are used. Although recent work has applied adversarial learning to NLI (Minervini & Riedel, 2018; Kang et al., 2018), this is the first work to our knowledge that explicitly studies NLI models designed to ignore hypothesis-only biases. 2 Methods We consider two types of adversarial methods. In the first method, we incorporate an external classifier to force the hypothesis-encoder to ignore hypothesis-only biases. In the second method, we randomly swap premises in the training set to create noisy examples. Equal contribution 256 Proceedings of the Eighth Joint Conference on Lexical and Computational Semantics (*SEM), pages 256–262 c Minneapolis, June 6–7, 2019. 2019 Association for Computational Linguistics"
S19-1028,D17-1070,0,0.235347,"e immune to or rely on known biases. Furthermore, it is important to build models that can overcome these biases. Recent work in NLP aims to build more robust systems using adversarial methods (Alzantot et al., 2018; Chen & Cardie, 2018; Belinkov & Bisk, 2018, i.a.). In particular, Elazar & Goldberg (2018) attempted to use adversarial training to remove demographic attributes from text data, with limited success. Inspired by this line of work, we use adversarial learning to add small components to an existing and popular NLI system that has been used to learn general sentence representations (Conneau et al., 2017). The adversarial ∗ techniques include (1) using an external adversarial classifier conditioned on hypotheses alone, and (2) creating noisy, perturbed training examples. In our analyses we ask whether hidden, hypothesisonly biases are no longer present in the resulting sentence representations after adversarial learning. The goal is to build models with less bias, ideally while limiting the inevitable degradation in task performance. Our results suggest that progress on this goal may depend on which adversarial learning techniques are used. Although recent work has applied adversarial learning"
S19-1028,K18-1007,0,0.120137,"ersarial ∗ techniques include (1) using an external adversarial classifier conditioned on hypotheses alone, and (2) creating noisy, perturbed training examples. In our analyses we ask whether hidden, hypothesisonly biases are no longer present in the resulting sentence representations after adversarial learning. The goal is to build models with less bias, ideally while limiting the inevitable degradation in task performance. Our results suggest that progress on this goal may depend on which adversarial learning techniques are used. Although recent work has applied adversarial learning to NLI (Minervini & Riedel, 2018; Kang et al., 2018), this is the first work to our knowledge that explicitly studies NLI models designed to ignore hypothesis-only biases. 2 Methods We consider two types of adversarial methods. In the first method, we incorporate an external classifier to force the hypothesis-encoder to ignore hypothesis-only biases. In the second method, we randomly swap premises in the training set to create noisy examples. Equal contribution 256 Proceedings of the Eighth Joint Conference on Lexical and Computational Semantics (*SEM), pages 256–262 c Minneapolis, June 6–7, 2019. 2019 Association for Comput"
S19-1028,P16-2022,0,0.0833388,"filtered such that it may not contain unwanted artifacts. We apply both adversarial techniques to InferSent (Conneau et al., 2017), which serves as our general NLI architecture.2 Following the standard training details used in InferSent, we encode premises and hypotheses separately using bi-directional long short-term memory (BiLSTM) networks (Hochreiter & Schmidhuber, 1997). Premises and hypotheses are initially mapped (token-by-token) to Glove (Pennington et al., 2014) representations. We use max-pooling over the BiLSTM states to extract premise and hypothesis representations and, following Mou et al. (2016), combine the representations by concatenating their vectors, their difference, and their multiplication (element-wise). We use the default training hyper-parameters in the released InferSent codebase.3 These include setting the initial learning rate to 0.1 and the decay rate to 0.99, using SGD optimization and dividing the learning rate by 5 at every epoch when the accuracy deceases on the validation set. The default settings also include stopping training either when the learning rate drops below 10−5 or after 20 epochs. In both adversarial settings, the hyper-parameters are swept through {0"
S19-1028,D14-1162,0,0.0955863,"LI. We use the standard SNLI split and report validation and test results. We also test on SNLI-hard, a subset of SNLI that Gururangan et al. (2018) filtered such that it may not contain unwanted artifacts. We apply both adversarial techniques to InferSent (Conneau et al., 2017), which serves as our general NLI architecture.2 Following the standard training details used in InferSent, we encode premises and hypotheses separately using bi-directional long short-term memory (BiLSTM) networks (Hochreiter & Schmidhuber, 1997). Premises and hypotheses are initially mapped (token-by-token) to Glove (Pennington et al., 2014) representations. We use max-pooling over the BiLSTM states to extract premise and hypothesis representations and, following Mou et al. (2016), combine the representations by concatenating their vectors, their difference, and their multiplication (element-wise). We use the default training hyper-parameters in the released InferSent codebase.3 These include setting the initial learning rate to 0.1 and the decay rate to 0.99, using SGD optimization and dividing the learning rate by 5 at every epoch when the accuracy deceases on the validation set. The default settings also include stopping train"
S19-1028,W17-0907,0,0.145469,"Missing"
S19-1028,L18-1239,0,0.442817,"othesis-only biases. Adversarial learning may help models ignore sensitive biases and spurious correlations in data. We evaluate whether adversarial learning can be used in NLI to encourage models to learn representations free of hypothesis-only biases. Our analyses indicate that the representations learned via adversarial learning may be less biased, with only small drops in NLI accuracy. 1 A person writing something on a newspaper I A person is driving a fire truck A man is doing tricks on a skateboard I Nobody is doing tricks Table 1: Examples from SNLI’s development set that Poliak et al. (2018)’s hypothesis-only model correctly predicted as contradictions. The first line in each section is a premise and lines with I are corresponding hypotheses. The italicized words are correlated with the “contradiction” label in SNLI Introduction Popular datasets for Natural Language Inference (NLI) - the task of determining whether one sentence (premise) likely entails another (hypothesis) - contain hypothesis-only biases that allow models to perform the task surprisingly well by only considering hypotheses while ignoring the corresponding premises. For instance, such a method correctly predicted"
S19-1028,W18-5448,0,0.0525636,"Missing"
S19-1028,D18-1316,0,\N,Missing
S19-1028,D18-1002,0,\N,Missing
S19-1028,W19-1801,1,\N,Missing
W15-3223,darwish-etal-2014-using,1,0.8246,"atching binary feature fires. We found such ranking scores to be a valuable addition in our experiments. To understand why, we note that they are able to neatly separate the different labels, with the following average scores: DIRECT 14.5, RELATED 12.3, and IRRELEVANT 10.5. 3.4 In addition to the machine learning approaches, we adapted our rule-based model, which ranked 2nd in the competition (Nicosia et al., 2015). The basic idea is to rank the comments according to their similarity and label the top ones as DIRECT . In this case our preprocessing consists of stemming, performed with QATARA (Darwish et al., 2014), and again stopword removal. In our implementation, the score of a comment is computed as 1 X score(c) = α · ω(t) + pos(t) |q |t∈q∩c Similarity This set of features measures the similarity sim(q, c) between a question and a comment, assuming that high similarity signals a DIRECT answer. We compute the similarity between word n-gram representations (n = [1, . . . , 4]) of q and c, using different lexical similarity measures: greedy string tiling (Wise, 1996), longest common subsequences (Allison and Dix, 1986), Jaccard coefficient (Jaccard, 1901), word containment (Lyon et al., 2001), and cosi"
W15-3223,N13-1090,0,0.0265105,"cal setting, first discriminating between IRRELEVANT and NON-IRRELEVANT and then between DIRECT and RELATED ; and (ii) a multiclass classification setting. Their third approach was based on an ensemble of classifiers. 3.1 Vectors Our motivation for using word vectors for this task is that they convey a soft representation of word meanings. In contrast to similarity measures that are based on words, using word vectors has the potential to bridge over lack of lexical overlap between questions and answers. We start by creating word vectors from a large corpus of raw Arabic text. We use Word2Vec (Mikolov et al., 2013b; Mikolov et al., 2013a) with default settings for creating 100-dimensional vectors. We experimented with the Arabic Gigaword (Linguistic Data Consortium, 2011), containing newswire text, and with the King Saud University Corpus of Classical Arabic (KSUCCA), containing classical Arabic text (Alrabiah et al., 2013). Table 2 provides some statistics for these corpora. We were initially expecting KSUCCA to produce better results, beFinally, Mohamed et al., (2015) applied a decision tree whose output is composed of lexical and enriched representations of q and c: the terms in the texts are expand"
W15-3223,S15-2040,0,0.0217317,"exical overlap between questions and answers. We start by creating word vectors from a large corpus of raw Arabic text. We use Word2Vec (Mikolov et al., 2013b; Mikolov et al., 2013a) with default settings for creating 100-dimensional vectors. We experimented with the Arabic Gigaword (Linguistic Data Consortium, 2011), containing newswire text, and with the King Saud University Corpus of Classical Arabic (KSUCCA), containing classical Arabic text (Alrabiah et al., 2013). Table 2 provides some statistics for these corpora. We were initially expecting KSUCCA to produce better results, beFinally, Mohamed et al., (2015) applied a decision tree whose output is composed of lexical and enriched representations of q and c: the terms in the texts are expanded on the basis of a set of Quranic ontologies. The authors do not report the 185 cause its language should be more similar to the religious texts in the Fatwa corpus. However, in practice we found vectors trained on the Arabic Gigaword to perform better, possibly thanks to its larger coverage, so we report only results with the Gigaword corpus below. We noticed in preliminary experiments that many errors are due to lack of overlap in vocabulary between answers"
W15-3223,S15-2035,0,0.027656,"easures, statistical ranking, and rule-based ranking. We describe each kind in turn. Belinkov et al., (2015)’s best submission was very similar to the one of Nicosia et al., (2015): a ranking approach based on confidence values obtained by an SVM ranker (Joachims, 2006). Their second approach consisted of a multi-class linear SVM classifier relying on three feature families: (i) lexical similarities between q and c (similar to those applied by the previous team); (ii) word vector representations of q and c; and (iii) a ranking score for c produced by the SVM ranker. The two best approaches of Hou et al., (2015) used features representing different similarities between q and c, lengths of words and sentences, and the number of named-entities in c, among others. In this case [1,2,3]-grams were also considered as features, but with two differences with respect to the other participants: only the most frequent n-grams were used and a translated version to English was also included. They explored two strategies using SVMs in their top performing submissions: (i) a hierarchical setting, first discriminating between IRRELEVANT and NON-IRRELEVANT and then between DIRECT and RELATED ; and (ii) a multiclass c"
W15-3223,S15-2047,0,0.269072,"ence Laboratory, Doha, Qatar Cambridge, MA 02139, USA {albarron, hmubarak}@qf.org.qa belinkov@csail.mit.edu Abstract ing” (Nakov et al., 2015) and focus on the Arabic language. Our approach is treating each question– comment as an instance in a supervised learning scenario. We build a support vector machine (SVM) classifier that is using different kinds of features, including vector representations, similarity measures, and rankings. Our extensive feature set allows us to achieve better results than those of the winner of the competition: 79.25 F1 compared to 78.55, obtained by Nicosia et al. (2015). The rest of the paper is organized as follows. Section 2 describes the experimental framework —composed of the Fatwa corpus and the evaluation metrics— and overviews the different models proposed at competition time. Section 3 describes our model. Experiments and results are discussed in Section 4. Related work is discussed in Section 5. We summarize our contributions in Section 6, and include an error analysis in Appendix A. The task of answer selection in community question answering consists of identifying pertinent answers from a pool of user-generated comments related to a question. The"
W15-3223,S15-2036,1,0.877926,"Missing"
W15-3223,pasha-etal-2014-madamira,0,0.1324,"Missing"
W15-3223,W01-0515,0,0.0181742,"ATARA (Darwish et al., 2014), and again stopword removal. In our implementation, the score of a comment is computed as 1 X score(c) = α · ω(t) + pos(t) |q |t∈q∩c Similarity This set of features measures the similarity sim(q, c) between a question and a comment, assuming that high similarity signals a DIRECT answer. We compute the similarity between word n-gram representations (n = [1, . . . , 4]) of q and c, using different lexical similarity measures: greedy string tiling (Wise, 1996), longest common subsequences (Allison and Dix, 1986), Jaccard coefficient (Jaccard, 1901), word containment (Lyon et al., 2001), and cosine similarity. The preprocessing in this case consists only of stopword removal. Additionally, we further compute cosine similarity on lemmas and part-of-speech tags, both including and excluding stopwords. 3.3 Rule-based Ranking where ω(t) = 1 if t is a 1-gram, 4 if it is a 2-gram, and pos(t) represents the relative position of t in the question and is estimated as the length of q minus the position of t in q. That is, we give significantly more relevance to 2-grams and to those matching n-grams at the beginning of the question. We compute this score twice: once considering the subj"
W15-3223,S15-2048,1,\N,Missing
W16-2007,N15-1107,0,0.090378,"Missing"
W16-2007,D11-1057,0,0.0977516,"Missing"
W16-2007,N13-1138,0,0.133599,"the MS2S model, which is trained greedily without such search procedure. The second system, named BIU/MIT-2, used the NDST architecture and participated only in the first and second sub-tasks. This system did not use beam search, producing only one guess per input. Again, to use the NDST architecture for the second task we simply concatenated the input and output morpho-syntactic attribute embeddings. 4.2 5 While developing our systems we measured our performance on the development set with respect to two baselines: the shared task baseline system (ST-Base) inspired by (Nicolai et al., 2015; Durrett and DeNero, 2013), and the factored sequence to sequence baseline (Fact.) similar to the one introduced in (Faruqui et al., 2016). On the test set, our systems ranked second or third out of eight groups in the shared task (depending on the language). The best participating system, LMU1/2 (Kann and Sch¨utze, 2016) relied on a single encoder-decoder model with attention (Bahdanau et al., 2014) per language, with several improvements like performing prediction using majority voting over an ensemble of five models. In contrast, our first system did not use an explicit attention mechanism and is composed of 3 model"
W16-2007,N16-1077,0,0.491116,"ection from incomplete inflection tables while using several novel ideas for this task: morpho-syntactic attribute embeddings, modeling the concept of templatic morphology, bidirectional input character representations and neural discriminative string transduction. The reported results for the proposed models over the ten languages in the shared task bring this submission to the second/third place (depending on the language) on all three sub-tasks out of eight participating teams, while training only on the Restricted category data. 1 Yonatan Belinkov CSAIL MIT belinkov@mit.edu More recently, Faruqui et al. (2016) used encoder-decoder neural networks for inflection generation inspired by similar approaches for sequence-to-sequence learning for machine translation (Bahdanau et al., 2014; Sutskever et al., 2014). The general idea is to use an encoderdecoder network over characters, that encodes the input lemma into a vector and decodes it one character at a time into the inflected surface word. They factor the data into sets of inflections with identical morpho-syntactic attributes (we refer to each such set as a factor) and try two training approaches: in one they train an individual encoderdecoder RNN"
W16-2007,P16-1154,0,0.0562918,"Missing"
W16-2007,E14-1060,0,0.350803,"Missing"
W16-2007,P16-2090,0,0.10157,"Missing"
W16-2007,J94-3001,0,0.249606,"flected word given the word, its morpho-syntactic attributes and the target inflection’s attributes, and the third requires re-inflection of an inflected word given only the target inflection attributes. The datasets for the different tasks are available on the Introduction Morphological inflection, or reinflection, involves generating a target (surface form) word from a source word (e.g. a lemma), given the morphosyntactic attributes of the target word. Previous approaches to automatic inflection generation usually make use of manually constructed Finite State Transducers (Koskenniemi, 1983; Kaplan and Kay, 1994), which are theoretically appealing but require expert knowledge, or machine learning methods for string transduction (Yarowsky and Wicentowski, 2000; Dreyer and Eisner, 2011; 41 Proceedings of the 14th Annual SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology, pages 41–48, c Berlin, Germany, August 11, 2016. 2016 Association for Computational Linguistics shared task’s website.1 The fact that the data is incomplete makes it problematic to use factored models like the ones introduced in (Faruqui et al., 2016), as there may be insufficient data for training a h"
W16-2007,N15-1093,0,0.086334,"rform beam search over the MS2S model, which is trained greedily without such search procedure. The second system, named BIU/MIT-2, used the NDST architecture and participated only in the first and second sub-tasks. This system did not use beam search, producing only one guess per input. Again, to use the NDST architecture for the second task we simply concatenated the input and output morpho-syntactic attribute embeddings. 4.2 5 While developing our systems we measured our performance on the development set with respect to two baselines: the shared task baseline system (ST-Base) inspired by (Nicolai et al., 2015; Durrett and DeNero, 2013), and the factored sequence to sequence baseline (Fact.) similar to the one introduced in (Faruqui et al., 2016). On the test set, our systems ranked second or third out of eight groups in the shared task (depending on the language). The best participating system, LMU1/2 (Kann and Sch¨utze, 2016) relied on a single encoder-decoder model with attention (Bahdanau et al., 2014) per language, with several improvements like performing prediction using majority voting over an ensemble of five models. In contrast, our first system did not use an explicit attention mechanism"
W16-2007,N16-1076,0,0.102273,"Missing"
W16-2007,D13-1021,0,0.112739,"Missing"
W16-2007,P00-1027,0,0.0177401,"an inflected word given only the target inflection attributes. The datasets for the different tasks are available on the Introduction Morphological inflection, or reinflection, involves generating a target (surface form) word from a source word (e.g. a lemma), given the morphosyntactic attributes of the target word. Previous approaches to automatic inflection generation usually make use of manually constructed Finite State Transducers (Koskenniemi, 1983; Kaplan and Kay, 1994), which are theoretically appealing but require expert knowledge, or machine learning methods for string transduction (Yarowsky and Wicentowski, 2000; Dreyer and Eisner, 2011; 41 Proceedings of the 14th Annual SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology, pages 41–48, c Berlin, Germany, August 11, 2016. 2016 Association for Computational Linguistics shared task’s website.1 The fact that the data is incomplete makes it problematic to use factored models like the ones introduced in (Faruqui et al., 2016), as there may be insufficient data for training a highquality model per factor of inflections with identical morpho-syntactic attributes. For example, in the shared task dataset the training data usua"
W16-2007,W16-2002,0,\N,Missing
W16-4007,P12-1011,0,0.0380936,"Missing"
W16-4007,W06-0903,0,0.0362651,"Missing"
W16-4007,P05-1071,0,0.0722555,"Missing"
W16-4007,E14-4004,0,0.030736,"Missing"
W16-4007,pasha-etal-2014-madamira,0,0.0617883,"Missing"
W16-4007,S15-2147,0,0.0261139,"Missing"
W16-4007,W15-3205,0,0.0252161,"ng with ideas for future work. 2 Related Work Though there has been increasing interest in compiling Arabic corpora in the past decade, very little work has been done on compiling historical corpora reflecting the long history of the Arabic language. Most of the existing corpora focus on modern written Arabic texts, particularly online print media, though there are a growing number of corpora which feature written and to a lesser degree spoken material from Arabic dialects. We mention here several relevant corpora and refer to other surveys for more details (Al-Sulaiti, 2004; Zaghouani, 2014; Shoufan and Alameri, 2015; Al-Thubaity, 2015). To date, there is only a small number of diachronically oriented corpora of Arabic. The King Saud University Corpus of Classical Arabic (KSUCCA) (Alrabiah et al., 2013)3 consists of approximately 50.6 million words from the first 4 Islamic centuries. It has been morphologically analyzed with the MADA tool (Habash and Rambow, 2005; Habash et al., 2009). Almost all of the texts are derived from the Shamela corpus. Text metadata is by century, so more granular buckets are not possible in the current state of this corpus. Other Classical Arabic corpora that are worth mentioni"
W16-4819,W09-0807,0,0.276691,"Missing"
W16-4819,W15-5403,0,0.682166,"Missing"
W16-4819,L16-1284,0,0.176545,"Missing"
W16-4819,D14-1181,0,0.0100157,"ength that we set empirically. Longer texts are truncated and shorter ones are padded with a special PAD symbol. Each 146 character c in the alphabet is represented as a real-valued vector xc ∈ Rdemb . This character embedding is learned during training. Our neural network has the following structure: • Input layer: mapping the character sequence c to a vector sequence x. The embedding layer is followed by dropout. • Convolutional layers: multiple parallel convolutional layers, mapping the vector sequence x to a hidden sequence h. We use filters that slide over character vectors, similarly to Kim (2014)’s CNN over words. A single filter k ∈ Rwdemb of width w creates a new feature fi ∈ R by: fi = k · xi:i+w−1 + b, where xi:i+w−1 is a concatenation of xi , ...xi+w−1 and b ∈ R is a bias term. Each convolution is followed by a Rectified Linear Unit (ReLU) non-linearity (Glorot et al., 2011). The outputs of all the convolutional layers are concatenated. • Pooling layer: a max-over-time pooling layer, mapping the vector sequence h to a single hidden vector h representing the sequence. The size of h is Σj nj wj , where there are nj filters of width wj . • Fully-connected layer: one hidden layer wit"
W16-4819,P16-1100,0,0.0703305,"Missing"
W16-4819,W16-4801,0,0.0863856,"Missing"
W16-4819,W14-5314,0,0.173149,"Missing"
W16-4819,W14-5307,0,0.143673,"Missing"
W16-4819,W15-5401,0,0.135765,"Missing"
W19-0128,W18-3024,0,0.0771767,"evaluation schemes though: They often define a length threshold in the test set and report the performance of the model on this fixed set. We acknowledge three unsettling issues with these formulations. First, the sequences in the training set are usually assumed to be uniformly or geometrically distributed, with little regard to the nature and complexity of the language. This assumption may undermine any conclusions drawn from empirical investigations, especially given that natural language is not uniformly distributed, an aspect that is known to affect learning in modern RNN architectures (Liu et al., 2018). Second, in a test set where the sequences are enumerated by their lengths, if a network makes an error on a sequence of, say, length 7, but correctly recognizes longer sequences of length up to 1000, would we consider the model’s gener277 Proceedings of the Society for Computation in Linguistics (SCiL) 2019, pages 277-286. New York City, New York, January 3-6, 2019 alization as good or bad? In a setting where we monitor only the shortest sequence that was incorrectly predicted by the network, this scheme clearly misses the potential success of the model after witnessing a failure, thereby mi"
W19-0128,P18-2117,0,0.18481,"order to generate the following distributions: U-shaped (↵ = 0.25, = 0.25): The probabilities of having short and long sequences are equally high, but the probability of having an average-length sequence is low. Right-tailed (↵ = 1, = 5): Short sequences are more probable than long sequences. Left-tailed (↵ = 5, = 1): Long sequences are more probable than short sequences. 4.3 Length Windows Most of the previous studies trained networks on sequences of lengths n 2 [1, N ], where typical N values were between 10 and 50 (Bod´en and Wiles, 2000; Gers and Schmidhuber, 2001), and more recently 100 (Weiss et al., 2018). To determine the impact of the choice of training length-window on the stability and inductive capabilities of the LSTM networks, we experimented with three different length-windows for n: [1, 30], [1, 50], and [50, 100]. In the third window setting [50, 100], we further wanted to see whether LSTM are capable of generalizing to short sequences that are contained in the window range [1, 50], as well as to sequences that are longer than the sequences seen in the training set. Figure 3: Generalization graphs showing the average performance of LSTMs trained under different probability distributi"
W19-1801,D16-1203,0,0.0658286,"nd that regularized models tend to over-rely on visual features, while ignoring important linguistic cues in the question. Our results suggest that AdvReg requires further refinement before it can be considered a viable bias mitigation technique for VQA. 1 Introduction In recent years, the Visual Question Answering (VQA) community has grown increasingly cognizant of the confounding role that bias plays in VQA research. Many popular VQA datasets have been shown to contain systematic language biases that enable models to cheat by answering questions “blindly” without considering visual context (Agrawal et al., 2016; Zhang et al., 2016; Goyal et al., 2017; Agrawal et al., 2018). 1 Proceedings of the Second Workshop on Shortcomings in Vision and Language, pages 1–13 c Minneapolis, USA, June 6, 2019. 2017 Association for Computational Linguistics Biases in other language tasks Language biases have also been reported in natural language inference (NLI) (Gururangan et al., 2018; Tsuchiya, 2018; Poliak et al., 2018), reading comprehension (Kaushik and Lipton, 2018), and story cloze completion (Schwartz et al., 2017). Many of these tasks are concerned with inferring the relationship between two objects. As in"
W19-1801,S19-1028,1,0.894552,"Missing"
W19-1801,N18-1040,0,0.0417961,"Missing"
W19-1801,S18-2023,0,0.0529935,"Missing"
W19-1801,W17-0907,0,0.0602076,"that enable models to cheat by answering questions “blindly” without considering visual context (Agrawal et al., 2016; Zhang et al., 2016; Goyal et al., 2017; Agrawal et al., 2018). 1 Proceedings of the Second Workshop on Shortcomings in Vision and Language, pages 1–13 c Minneapolis, USA, June 6, 2019. 2017 Association for Computational Linguistics Biases in other language tasks Language biases have also been reported in natural language inference (NLI) (Gururangan et al., 2018; Tsuchiya, 2018; Poliak et al., 2018), reading comprehension (Kaushik and Lipton, 2018), and story cloze completion (Schwartz et al., 2017). Many of these tasks are concerned with inferring the relationship between two objects. As in VQA, models can often succeed by learning biases associated with one of these objects, while ignoring the other. ture (Jiang et al., 2018b), achieving a new stateof-the-art on VQA-CP v1 and v2. However, we find that AdvReg yields a number of previously unreported and undesirable side-effects. We first observe that AdvReg introduces significant noise into gradient updates that creates instability during training. This finding motivates the introduction of a new scheduling technique that gradually intr"
W19-1801,N18-2017,0,0.10288,"Missing"
W19-1801,L18-1239,0,0.0486736,"le that bias plays in VQA research. Many popular VQA datasets have been shown to contain systematic language biases that enable models to cheat by answering questions “blindly” without considering visual context (Agrawal et al., 2016; Zhang et al., 2016; Goyal et al., 2017; Agrawal et al., 2018). 1 Proceedings of the Second Workshop on Shortcomings in Vision and Language, pages 1–13 c Minneapolis, USA, June 6, 2019. 2017 Association for Computational Linguistics Biases in other language tasks Language biases have also been reported in natural language inference (NLI) (Gururangan et al., 2018; Tsuchiya, 2018; Poliak et al., 2018), reading comprehension (Kaushik and Lipton, 2018), and story cloze completion (Schwartz et al., 2017). Many of these tasks are concerned with inferring the relationship between two objects. As in VQA, models can often succeed by learning biases associated with one of these objects, while ignoring the other. ture (Jiang et al., 2018b), achieving a new stateof-the-art on VQA-CP v1 and v2. However, we find that AdvReg yields a number of previously unreported and undesirable side-effects. We first observe that AdvReg introduces significant noise into gradient updates that cr"
W19-1801,D17-1323,0,0.0331368,"information in the question. The contributions of this work are two-fold. First, we share practical tips for dealing with the idiosyncrasies of AdvReg. Second, we highlight some core drawbacks of AdvReg that have not previously been reported in the literature. By drawing attention to these shortcomings, we hope to motivate future efforts to refine AdvReg. 2 Biases in other vision tasks Images can also encode certain associative biases. For instance, the Commmon Objects in Context (COCO) image dataset (Lin et al., 2014), which is used in VQA, has been shown to contain prominent gender biases (Zhao et al., 2017; Hendricks et al., 2018). Recently, Hendricks et al. (2018) introduced a technique that encourages the assignment of equal gender probability when gender information is occluded from an image. Their Appearance Confusion Loss can be viewed as a vision captioning analogue to AdvReg for VQA. Mitigating bias Initial efforts to address bias in VQA focused on debiasing existing datasets. VQA v2 introduced complimentary examples with different answers to every question (Goyal et al., 2017). While VQA v2 resulted in a near 50/50 balance for Yes/No questions, the distribution for non-binary questions"
W19-1801,D18-1546,0,0.0241154,"have been shown to contain systematic language biases that enable models to cheat by answering questions “blindly” without considering visual context (Agrawal et al., 2016; Zhang et al., 2016; Goyal et al., 2017; Agrawal et al., 2018). 1 Proceedings of the Second Workshop on Shortcomings in Vision and Language, pages 1–13 c Minneapolis, USA, June 6, 2019. 2017 Association for Computational Linguistics Biases in other language tasks Language biases have also been reported in natural language inference (NLI) (Gururangan et al., 2018; Tsuchiya, 2018; Poliak et al., 2018), reading comprehension (Kaushik and Lipton, 2018), and story cloze completion (Schwartz et al., 2017). Many of these tasks are concerned with inferring the relationship between two objects. As in VQA, models can often succeed by learning biases associated with one of these objects, while ignoring the other. ture (Jiang et al., 2018b), achieving a new stateof-the-art on VQA-CP v1 and v2. However, we find that AdvReg yields a number of previously unreported and undesirable side-effects. We first observe that AdvReg introduces significant noise into gradient updates that creates instability during training. This finding motivates the introducti"
W19-3905,J76-4004,0,0.437687,"Missing"
W19-3905,W18-5414,0,0.338283,"2n . Inspired by the early model design of NNPDAs, Grefenstette et al. (2015) also proposed memory-augmented recurrent networks (Neural Stacks, Queues, and DeQues), which are RNNs equipped with unbounded differentiable memory modules, to perform sequence-to-sequence transduction tasks that require specific data structures. Deleu and Dureau (2016) investigated the ability of Neural Turing Machines (NTMs; Graves et al. (2014)) to capture long-distance dependencies in the Dyck-1 language. Their empirical findings demonstrated that an NTM can recognize this language by emulating a DPA. Similarly, Sennhauser and Berwick (2018), Bernardy (2018), and Hao et al. (2018) conducted experiments on the Dyck languages to explore whether recurrent networks can learn nested structures. These studies assessed the performance of their recurrent models to predict the next possible parenthesis, assuming that it is a closing parenthesis.2 In fact, Bernardy (2018) used a purpose-designed architecture, called RUSS, which contains recurrent units with stack-like states, to perform the closing-parenthesis-completion task. Though the RUSS model had no trouble generalizing to longer and deeper sequences, as the author mentions, the spec"
W19-3905,D16-1248,0,0.0488552,"order to validate our hypothesis, we visualized the hidden and cell states of some of our LSTM models that achieved full accuracy on the test sets. Figure 2 illustrates that our LSTM is able to recognize the samples in D1 ||6 by emulating a DCA6 . In fact, the discrete even transitions in the cell state dynamics of the model reveal that six out of eight hidden units in the model are acting like separate counters. In some cases, we further discovered that certain units learned to count the length of the input sequences. Such length counting behaviours are also observed in machine translation (Shi et al., 2016; Bau et al., 2019; Dalvi et al., 2019) when the LSTMs are trained on a fixed-length training corpus.8 On the other hand, Figure 3 provides visualizations of the hidden and cell state dynamics of one of our single-layer LSTM models with four hidden units when the model was presented two sequences in the Dyck-2 language. Both sequences have some noticeable patterns and were chosen to explore whether the model behaves differently in repeated (or similar) subsequences. It seems that the LSTM model is trying to employ a complex counting strategy to learn the Dyck-2 language but failing to accompli"
W19-3905,W18-5425,0,0.190351,"can learn nested structures. These studies assessed the performance of their recurrent models to predict the next possible parenthesis, assuming that it is a closing parenthesis.2 In fact, Bernardy (2018) used a purpose-designed architecture, called RUSS, which contains recurrent units with stack-like states, to perform the closing-parenthesis-completion task. Though the RUSS model had no trouble generalizing to longer and deeper sequences, as the author mentions, the specificity of the architecture disqualifies it as a practical model choice for natural language modeling tasks. Additionally, Skachkova et al. (2018) trained recurrent networks to predict the last appropriate closing parenthesis, given a Dyck-2 sequence without its last symbol. They showed that their GRU and LSTM models performed with almost full accuracy on this parenthesis-completion task, but their task does not illustrate that these RNN models can recognize the Dyck language. Most recently, Weiss et al. (2018) and Suzgun et al. (2019) showed that the LSTM networks can develop natural counting mechanisms to recWe start by defining several subclasses of deterministic pushdown automata (DPA). Following Valiant and Paterson (1975), we defi"
W19-3905,W18-5433,0,0.0178383,"refenstette et al. (2015) also proposed memory-augmented recurrent networks (Neural Stacks, Queues, and DeQues), which are RNNs equipped with unbounded differentiable memory modules, to perform sequence-to-sequence transduction tasks that require specific data structures. Deleu and Dureau (2016) investigated the ability of Neural Turing Machines (NTMs; Graves et al. (2014)) to capture long-distance dependencies in the Dyck-1 language. Their empirical findings demonstrated that an NTM can recognize this language by emulating a DPA. Similarly, Sennhauser and Berwick (2018), Bernardy (2018), and Hao et al. (2018) conducted experiments on the Dyck languages to explore whether recurrent networks can learn nested structures. These studies assessed the performance of their recurrent models to predict the next possible parenthesis, assuming that it is a closing parenthesis.2 In fact, Bernardy (2018) used a purpose-designed architecture, called RUSS, which contains recurrent units with stack-like states, to perform the closing-parenthesis-completion task. Though the RUSS model had no trouble generalizing to longer and deeper sequences, as the author mentions, the specificity of the architecture disqualifies"
W19-3905,W19-0128,1,0.84361,"e generalizing to longer and deeper sequences, as the author mentions, the specificity of the architecture disqualifies it as a practical model choice for natural language modeling tasks. Additionally, Skachkova et al. (2018) trained recurrent networks to predict the last appropriate closing parenthesis, given a Dyck-2 sequence without its last symbol. They showed that their GRU and LSTM models performed with almost full accuracy on this parenthesis-completion task, but their task does not illustrate that these RNN models can recognize the Dyck language. Most recently, Weiss et al. (2018) and Suzgun et al. (2019) showed that the LSTM networks can develop natural counting mechanisms to recWe start by defining several subclasses of deterministic pushdown automata (DPA). Following Valiant and Paterson (1975), we define a deterministic one-counter automaton (DCA1 ) to be a DPA with a stack alphabet consisting of only one symbol. Traditionally, this construction allows moves (that is, executing actions on the stack without the observance of any inputs), but we restrict our attention to simple DCA1 s without -moves in the rest of this paper. Similarly, we call a DPA that contains k separate stacks, with e"
W19-3905,P18-2117,0,0.196759,"nt networks— Elman-RNNs (or RNNs, in short), LSTMs, and Gated Recurrent Units (GRUs)—to perform dynamic counting by training them to learn the Dyck-1 language. Our results demonstrate that the LSTMs with only a single hidden unit perform with perfect accuracy on the Dyck-1 learning task, and successfully generalize far beyond the training set. Furthermore, we show that the LSTMs can learn the shuffles of multiple Dyck-1 languages, defined over disjoint parenthesis-pairs, which require the emulation of multiple-counter arbitraryturn machines. Our results corroborate the theoretical findings of Weiss et al. (2018), while extending their empirical observations. On the other hand, when trained to learn the Dyck-2 language, which is a strictly context-free language, all our recurrent models failed to learn the language. In this paper, we systematically assess the ability of standard recurrent networks to perform dynamic counting and to encode hierarchical representations. All the neural models in our experiments are designed to be smallsized networks both to prevent them from memorizing the training sets and to visualize and interpret their behaviour at test time. Our results demonstrate that the Long Sho"
W19-4808,D17-2021,0,0.031908,"lyzing the Structure of Attention in a Transformer Language Model Yonatan Belinkov Harvard John A. Paulson School of Engineering and Applied Sciences and MIT Computer Science and Artificial Intelligence Laboratory Cambridge, MA, USA belinkov@seas.harvard.edu Jesse Vig Palo Alto Research Center Machine Learning and Data Science Group Interaction and Analytics Lab Palo Alto, CA, USA jesse.vig@parc.com Abstract attention in NLP models, ranging from attention matrix heatmaps (Bahdanau et al., 2015; Rush et al., 2015; Rockt¨aschel et al., 2016) to bipartite graph representations (Liu et al., 2018; Lee et al., 2017; Strobelt et al., 2018). A visualization tool designed specifically for multi-head self-attention in the Transformer (Jones, 2017; Vaswani et al., 2018) was introduced in Vaswani et al. (2017). We extend the work of Jones (2017), by visualizing attention in the Transformer at three levels of granularity: the attention-head level, the model level, and the neuron level. We also adapt the original encoder-decoder implementation to the decoder-only GPT-2 model, as well as the encoder-only BERT model. In addition to visualizing attention for individual inputs to the model, we also analyze attentio"
W19-4808,N19-1112,1,0.917076,"ayers 6–11 and heads 6–11). 4.2 Methods |x |P i P P Pα (tag) = x∈X i=1 j=1 αi,j (x)·1pos(xj )=tag |x |P i P P (3) αi,j (x) x∈X i=1 j=1 where tag is a part-of-speech tag, e.g., NOUN, x is a sentence from the corpus X, αi,j is the attention from xi to xj for the given head (see Section 3), and pos(xj ) is the part-of-speech tag of xj . We also compute the share of attention directed from each part of speech in a similar fashion. 5.1.2 Dependency Relations Recent work shows that Transformers and recurrent models encode dependency relations (Hewitt and Manning, 2019; Raganato and Tiedemann, 2018; Liu et al., 2019). However, different models capture dependency relations at different layer depths. In a Transformer model, the middle layers were most predictive of dependencies (Liu et al., 2019; Tenney et al., 2019). Recurrent models were found to encode dependencies in lower layers for language models (Liu et al., 2019) and in deeper layers for translation models (Belinkov, 2018). We analyze how attention aligns with dependency relations in GPT-2 by computing the proportion of attention that connects tokens that are also in a dependency relation with one another. We Neuron View The neuron view (Figure 3)"
W19-4808,Q19-1004,1,0.827577,"(or similar) objective on large amounts of text. The underlying architecture may be recurrent, as in ELMo (Peters et al., 2018), or based on multi-head self-attention, as in OpenAI’s GPT (Radford et al., 2018) and BERT (Devlin et al., 2018), which are based on the Transformer (Vaswani et al., 2017). Recently, the GPT-2 model (Radford et al., 2019) outperformed other language models in a zeroshot setting, again based on self-attention. An advantage of using attention is that it can help interpret the model by showing how the model attends to different parts of the input (Bahdanau et al., 2015; Belinkov and Glass, 2019). Various tools have been developed to visualize • Does attention align with syntactic dependency relations? • Which attention heads attend to which partof-speech tags? • How does attention capture long-distance relationships versus short-distance ones? We apply our analysis to the GPT-2 small pretrained model. We find that attention follows dependency relations most strongly in the middle layers of the model, and that attention heads target particular parts of speech depending on layer depth. We also find that attention spans the greatest distance in the deepest layers, but varies significant"
W19-4808,D18-2007,0,0.0821816,"Missing"
W19-4808,P18-2003,0,0.191267,"cs 2 Related Work multi-head setting, the queries, keys, and values are linearly projected h times, and the attention operation is performed in parallel for each representation, with the results concatenated. Recent work suggests that the Transformer implicitly encodes syntactic information such as dependency parse trees (Hewitt and Manning, 2019; Raganato and Tiedemann, 2018), anaphora (Voita et al., 2018), and subject-verb pairings (Goldberg, 2019; Wolf, 2019). Other work has shown that RNNs also capture syntax, and that deeper layers in the model capture increasingly high-level constructs (Blevins et al., 2018). In contrast to past work that measure a model’s syntactic knowledge through linguistic probing tasks, we directly compare the model’s attention patterns to syntactic constructs such as dependency relations and part-of-speech tags. Raganato and Tiedemann (2018) also evaluated dependency trees induced from attention weights in a Transformer, but in the context of encoder-decoder translation models. 3 4 Visualizing Individual Inputs In this section, we present three visualizations of attention in the Transformer model: the attentionhead view, the model view, and the neuron view. Source code and"
W19-4808,A94-1016,0,0.10856,"Missing"
W19-4808,P19-1285,0,0.0289642,"hat follows the noun phrase, as the head noun is a strong predictor of this. rectional architecture and is trained on both tokenlevel and sentence-level tasks. Although the Wikipedia sentences used in our analysis cover a diverse range of topics, they all follow a similar encyclopedic format and style. Further study is needed to determine how attention patterns manifest in other types of content, such as dialog scripts or song lyrics. We would also like to analyze attention patterns in text much longer than a single sentence, especially for new Transformer variants such as the Transformer-XL (Dai et al., 2019) and Sparse Transformer (Child et al., 2019), which can handle very long contexts. We believe that interpreting a model based on attention is complementary to linguistic probing approaches (Section 2). While linguistic probing precisely quantifies the amount of information encoded in various components of the model, it requires training and evaluating a probing classifier. Analyzing attention is a simpler process that also produces human-interpretable descriptions of model behavior, though recent work casts doubt on its role in explaining individual predictions (Jain and Wallace, 2019). The re"
W19-4808,N18-1202,0,0.0511303,"een attention and syntax over a large corpus. We find that attention targets different parts of speech at different layer depths within the model, and that attention aligns with dependency relations most strongly in the middle layers. We also find that the deepest layers of the model capture the most distant relationships. Finally, we extract exemplar sentences that reveal highly specific patterns targeted by particular attention heads. 1 Introduction Contextual word representations have recently been used to achieve state-of-the-art performance across a range of language understanding tasks (Peters et al., 2018; Radford et al., 2018; Devlin et al., 2018). These representations are obtained by optimizing a language modeling (or similar) objective on large amounts of text. The underlying architecture may be recurrent, as in ELMo (Peters et al., 2018), or based on multi-head self-attention, as in OpenAI’s GPT (Radford et al., 2018) and BERT (Devlin et al., 2018), which are based on the Transformer (Vaswani et al., 2017). Recently, the GPT-2 model (Radford et al., 2019) outperformed other language models in a zeroshot setting, again based on self-attention. An advantage of using attention is that it can"
W19-4808,I17-1004,0,0.0293971,"Missing"
W19-4808,N19-1419,0,0.121214,"y, our method for extracting exemplar sentences yields many intuitive patterns. 63 Proceedings of the Second BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP, pages 63–76 c Florence, Italy, August 1, 2019. 2019 Association for Computational Linguistics 2 Related Work multi-head setting, the queries, keys, and values are linearly projected h times, and the attention operation is performed in parallel for each representation, with the results concatenated. Recent work suggests that the Transformer implicitly encodes syntactic information such as dependency parse trees (Hewitt and Manning, 2019; Raganato and Tiedemann, 2018), anaphora (Voita et al., 2018), and subject-verb pairings (Goldberg, 2019; Wolf, 2019). Other work has shown that RNNs also capture syntax, and that deeper layers in the model capture increasingly high-level constructs (Blevins et al., 2018). In contrast to past work that measure a model’s syntactic knowledge through linguistic probing tasks, we directly compare the model’s attention patterns to syntactic constructs such as dependency relations and part-of-speech tags. Raganato and Tiedemann (2018) also evaluated dependency trees induced from attention weights i"
W19-4808,W18-5431,0,0.182756,"ng exemplar sentences yields many intuitive patterns. 63 Proceedings of the Second BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP, pages 63–76 c Florence, Italy, August 1, 2019. 2019 Association for Computational Linguistics 2 Related Work multi-head setting, the queries, keys, and values are linearly projected h times, and the attention operation is performed in parallel for each representation, with the results concatenated. Recent work suggests that the Transformer implicitly encodes syntactic information such as dependency parse trees (Hewitt and Manning, 2019; Raganato and Tiedemann, 2018), anaphora (Voita et al., 2018), and subject-verb pairings (Goldberg, 2019; Wolf, 2019). Other work has shown that RNNs also capture syntax, and that deeper layers in the model capture increasingly high-level constructs (Blevins et al., 2018). In contrast to past work that measure a model’s syntactic knowledge through linguistic probing tasks, we directly compare the model’s attention patterns to syntactic constructs such as dependency relations and part-of-speech tags. Raganato and Tiedemann (2018) also evaluated dependency trees induced from attention weights in a Transformer, but in the con"
W19-4808,N19-1357,0,0.0601532,"Missing"
W19-4808,D15-1044,0,0.130866,"Missing"
W19-4808,W18-5451,0,0.147114,"re of Attention in a Transformer Language Model Yonatan Belinkov Harvard John A. Paulson School of Engineering and Applied Sciences and MIT Computer Science and Artificial Intelligence Laboratory Cambridge, MA, USA belinkov@seas.harvard.edu Jesse Vig Palo Alto Research Center Machine Learning and Data Science Group Interaction and Analytics Lab Palo Alto, CA, USA jesse.vig@parc.com Abstract attention in NLP models, ranging from attention matrix heatmaps (Bahdanau et al., 2015; Rush et al., 2015; Rockt¨aschel et al., 2016) to bipartite graph representations (Liu et al., 2018; Lee et al., 2017; Strobelt et al., 2018). A visualization tool designed specifically for multi-head self-attention in the Transformer (Jones, 2017; Vaswani et al., 2018) was introduced in Vaswani et al. (2017). We extend the work of Jones (2017), by visualizing attention in the Transformer at three levels of granularity: the attention-head level, the model level, and the neuron level. We also adapt the original encoder-decoder implementation to the decoder-only GPT-2 model, as well as the encoder-only BERT model. In addition to visualizing attention for individual inputs to the model, we also analyze attention in aggregate over a la"
W19-4808,P19-1452,0,0.243379,"rom the corpus X, αi,j is the attention from xi to xj for the given head (see Section 3), and pos(xj ) is the part-of-speech tag of xj . We also compute the share of attention directed from each part of speech in a similar fashion. 5.1.2 Dependency Relations Recent work shows that Transformers and recurrent models encode dependency relations (Hewitt and Manning, 2019; Raganato and Tiedemann, 2018; Liu et al., 2019). However, different models capture dependency relations at different layer depths. In a Transformer model, the middle layers were most predictive of dependencies (Liu et al., 2019; Tenney et al., 2019). Recurrent models were found to encode dependencies in lower layers for language models (Liu et al., 2019) and in deeper layers for translation models (Belinkov, 2018). We analyze how attention aligns with dependency relations in GPT-2 by computing the proportion of attention that connects tokens that are also in a dependency relation with one another. We Neuron View The neuron view (Figure 3) visualizes how individual neurons interact to produce attention. This view displays the queries and keys for each token, and demonstrates how attention is computed from the scaled dot product of these v"
W19-4808,W18-1819,0,0.0321429,"s and MIT Computer Science and Artificial Intelligence Laboratory Cambridge, MA, USA belinkov@seas.harvard.edu Jesse Vig Palo Alto Research Center Machine Learning and Data Science Group Interaction and Analytics Lab Palo Alto, CA, USA jesse.vig@parc.com Abstract attention in NLP models, ranging from attention matrix heatmaps (Bahdanau et al., 2015; Rush et al., 2015; Rockt¨aschel et al., 2016) to bipartite graph representations (Liu et al., 2018; Lee et al., 2017; Strobelt et al., 2018). A visualization tool designed specifically for multi-head self-attention in the Transformer (Jones, 2017; Vaswani et al., 2018) was introduced in Vaswani et al. (2017). We extend the work of Jones (2017), by visualizing attention in the Transformer at three levels of granularity: the attention-head level, the model level, and the neuron level. We also adapt the original encoder-decoder implementation to the decoder-only GPT-2 model, as well as the encoder-only BERT model. In addition to visualizing attention for individual inputs to the model, we also analyze attention in aggregate over a large corpus to answer the following research questions: The Transformer is a fully attention-based alternative to recurrent networ"
W19-4808,P19-3007,1,0.83623,"elations and part-of-speech tags. Raganato and Tiedemann (2018) also evaluated dependency trees induced from attention weights in a Transformer, but in the context of encoder-decoder translation models. 3 4 Visualizing Individual Inputs In this section, we present three visualizations of attention in the Transformer model: the attentionhead view, the model view, and the neuron view. Source code and Jupyter notebooks are available at https://github.com/jessevig/ bertviz, and a video demonstration can be found at https://vimeo.com/339574955. A more detailed discussion of the tool is provided in Vig (2019). 4.1 Attention-head View The attention-head view (Figure 1) visualizes attention for one or more heads in a model layer. Self-attention is depicted as lines connecting the attending tokens (left) with the tokens being attended to (right). Colors identify the head(s), and line weight reflects the attention weight. This view closely follows the design of Jones (2017), but has been adapted to the GPT-2 model (shown in the figure) and BERT model (not shown). Transformer Architecture Stacked Decoder: GPT-2 is a stacked decoder Transformer, which inputs a sequence of tokens and applies position and"
W19-4808,P18-1117,0,0.0260288,"ve patterns. 63 Proceedings of the Second BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP, pages 63–76 c Florence, Italy, August 1, 2019. 2019 Association for Computational Linguistics 2 Related Work multi-head setting, the queries, keys, and values are linearly projected h times, and the attention operation is performed in parallel for each representation, with the results concatenated. Recent work suggests that the Transformer implicitly encodes syntactic information such as dependency parse trees (Hewitt and Manning, 2019; Raganato and Tiedemann, 2018), anaphora (Voita et al., 2018), and subject-verb pairings (Goldberg, 2019; Wolf, 2019). Other work has shown that RNNs also capture syntax, and that deeper layers in the model capture increasingly high-level constructs (Blevins et al., 2018). In contrast to past work that measure a model’s syntactic knowledge through linguistic probing tasks, we directly compare the model’s attention patterns to syntactic constructs such as dependency relations and part-of-speech tags. Raganato and Tiedemann (2018) also evaluated dependency trees induced from attention weights in a Transformer, but in the context of encoder-decoder transla"
W19-4808,P19-1580,0,0.0958865,"Missing"
W19-5303,2012.eamt-1.60,0,0.0358,"indicate the data domain. For data augmentation, they back-translate from a target language to its noisy source. The intuition, also observed by Michel and Neubig (2018), is that the source sentences are noisier than their target translations. They include out-ofdomain clean data during this step and differentiate data types with a special symbol on the target side. In addition, they also run a model ensemble. Training Data In the constrained setting, participants were allowed to use the WMT15 training data3 for Eng↔Fra and any of the KFTT (Neubig, 2011), JESC (Pryzant et al.) and TED talks (Cettolo et al., 2012) corpora for Jpn↔Eng. Additionally, the use of the MTNT corpus (Michel and Neubig, 2018) was allowed in order to adapt models on limited in-domain data. 3.3 Evaluation protocol Test Data The test sets were collected following the same protocol as the MTNT dataset, i.e. collected from 3 http://www.statmt.org/wmt15/ translation-task.html 93 Figure 1: Annotation interface for human evaluations. 94 Eng-Fra Fra-Eng Eng-Jpn Jpn-Eng # samples 1,401 1,233 1,392 1,111 # source tokens # target tokens 20.0k 22.8k 19.8k 19.2k 20.0k 33.6k 18.7k 13.4k Table 1: Statistics of the test sets. model which was al"
W19-5303,P19-1425,0,0.113812,"inkov and Glass (2019) for a categorization of such work. In particular, some have focused on specific variations of naturally-occurring noise, such as grammatical errors produced by non-native speakers (Anastasopoulos et al., 2019) or errors extracted from Wikipedia edits (Belinkov and Bisk, 2018). It has also been shown that adding synthetic noise does not trivially increase robustness to natural noise (Belinkov and Bisk, 2018) and may require specific recipes (Karpukhin et al., 2019). Michel et al. (2019) recently emphasized the importance of meaning-preserving perturbations and along with Cheng et al. (2019) demonstrated the utility of adversarial training without significantly impairing performance on clean data and domain. Durrani et al. (2019) showed that character-based representations are more robust towards noise compared to such learned using BPE-based sub-word units in the task of machine translation. Jpn→Eng. We describe the dataset and the task setup in Section 3. The shared-task attracted a total of 23 submissions from 11 teams. The teams employed a variety of methods to improve robustness. A specific challenge was the small size of the in-domain noisy parallel dataset. We summarize th"
W19-5303,P17-4012,0,0.0548466,"data, improve existing semisupervised approach such as backtranslation. We provide both in-domain (MTNT) and outof-domain (News Commentary, News Crawl, etc) monolingual data. 3.2 Participants and System Descriptions We received 23 submissions from 11 teams. Except two submissions on the Eng-Fra language pair, all systems used the constrained setup. Below we briefly describe the systems from the 8 teams which submitted corresponding system description papers: Baidu & Oregon State University’s submission (Zheng et al., 2019): Their system is based on the Transformer implementation in OpenNMTpy (Klein et al., 2017). The main methods applied in their submission are: domain-sensitive data mixing and data augmentation with backtranslation. For data mixing, they used a special symbol on the source side to indicate the data domain. For data augmentation, they back-translate from a target language to its noisy source. The intuition, also observed by Michel and Neubig (2018), is that the source sentences are noisier than their target translations. They include out-ofdomain clean data during this step and differentiate data types with a special symbol on the target side. In addition, they also run a model ensem"
W19-5303,P18-1163,0,0.189473,"Missing"
W19-5303,W17-3204,1,0.848798,"re efforts from the community in building robust MT models. 2 Related Work The fragility of neural networks (Szegedy et al., 2013) has been shown to extend to neural machine translation models (Belinkov and Bisk, 2018; Heigold et al., 2017) and recent work focused on various aspects of the problem. From the identification of the causes of this brittleness, to the induction of (adversarial) inputs that trigger the unwanted behavior (attacks) and making such models robust against various types of noisy inputs (defenses); improving robustness has been receiving increasing attention in NMT. While Koehn and Knowles (2017) mentioned domain mismatch as a challenge for neural machine translation, Khayrallah and Koehn (2018) addressed noisy training data and focus on the types of noise occurring in web-crawled corpora. Michel and Neubig (2018) proposed a new dataset (MTNT) to test MT models for robustness to the types of noise encountered in the Internet and demonstrated that these challenges cannot be overcome by simple domain adaptation techniques alone. Belinkov and Bisk (2018) and Heigold et al. (2017) showed that NMT systems are very sensitive to slightly perturbed input forms, and hinted at the importance of"
W19-5303,W19-5362,0,0.149193,"this campaign. Unlike other participants, the winning team Naver Labs B´erard et al. (2019) and NTT (Murakami et al., 2019) applied data cleaning techniques in order to filter noisy parallel sentences. They filtered i) identical sentences on source and target side, ii) sentences that belonged to a language other than the source and target language, iii) sentences with length mismatch, and iv) also applied attention-based filtering. Data cleaning gave an improvement of more than 5 BLEU points with substantial reduction in the hallucination of the model for the winning team. NICT’s submission (Dabre and Sumita, 2019): The authors used Transformer models to train their systems and employed two strategies namely: i) mixed fine-tuning and ii) multilingual models for making the systems robust. The former helps as the in-domain data is available in a very small quantity. Using a mix of in-domain and outdomain data for fine-tuning helps overcome the problem of adjusting learning rate, applying better regularization and other complicated strategies. It is not clear how these two methods contributed towards making the models more robust. According to the authors, mixed fine-tuning and multilingual training (bidir"
W19-5303,D18-2012,0,0.020004,"mer-Big architecture, whereas improvements were substantially larger when the base models were RNN-Based MTNT baselines, about 8+ BLEU points. Participants emphasized the importance of their strong Transformer-Big base JHU’s submission (Post and Duh, 2019): This submission participated in the Fra→Eng and Jpn↔Eng tasks. The participants used data dual cross-entropy filtering for reducing the monolingual data, then back-translate these, and train their Transformer models (Vaswani et al., 2017). They compared Moses tokenization+Byte Pair Encoding (BPE) (Sennrich et al., 2016), and sentencepiece (Kudo and Richardson, 2018) (without any pre-processing) and found the two comparable, and that using larger sentence-piece models improved over smaller ones. For Jpn↔Eng (both di4 http://www.statmt.org/wmt19/biomedical-translationtask.html 95 sis, they found that their system performs poorly in translating emojis. The segmentation errors generated by KyTea resulted in further errors in the translation. rections) they first used both in-domain (MTNT) and out-of-domain data (other constrained), and then continued training (fine-tune) using MTNT only. They also reported many results from their hyper-parameter search (albe"
W19-5303,N19-1154,1,0.767588,"ise, such as grammatical errors produced by non-native speakers (Anastasopoulos et al., 2019) or errors extracted from Wikipedia edits (Belinkov and Bisk, 2018). It has also been shown that adding synthetic noise does not trivially increase robustness to natural noise (Belinkov and Bisk, 2018) and may require specific recipes (Karpukhin et al., 2019). Michel et al. (2019) recently emphasized the importance of meaning-preserving perturbations and along with Cheng et al. (2019) demonstrated the utility of adversarial training without significantly impairing performance on clean data and domain. Durrani et al. (2019) showed that character-based representations are more robust towards noise compared to such learned using BPE-based sub-word units in the task of machine translation. Jpn→Eng. We describe the dataset and the task setup in Section 3. The shared-task attracted a total of 23 submissions from 11 teams. The teams employed a variety of methods to improve robustness. A specific challenge was the small size of the in-domain noisy parallel dataset. We summarize the participating systems in Section 4 and the notable methods in Section 5. The contributions were evaluated both automatically and via a huma"
W19-5303,W18-6459,0,0.0413765,"ish (Eng) and French (Fra) and English and Japanese (Jpn), in four translation directions: Eng→Fra, Fra→Eng, Eng→Jpn, and www.reddit.com https://github.com/neulab/compare-mt 91 Proceedings of the Fourth Conference on Machine Translation (WMT), Volume 2: Shared Task Papers (Day 1) pages 91–102 c Florence, Italy, August 1-2, 2019. 2019 Association for Computational Linguistics examples are generated with access to the model parameters (Ebrahimi et al., 2018; Cheng et al., 2018a,b, 2019) and ii) black-box attacks, where examples are generated without accessing model internals (Zhao et al., 2018; Lee et al., 2018; ?; Anastasopoulos et al., 2019; Vaibhav et al., 2019); see Belinkov and Glass (2019) for a categorization of such work. In particular, some have focused on specific variations of naturally-occurring noise, such as grammatical errors produced by non-native speakers (Anastasopoulos et al., 2019) or errors extracted from Wikipedia edits (Belinkov and Bisk, 2018). It has also been shown that adding synthetic noise does not trivially increase robustness to natural noise (Belinkov and Bisk, 2018) and may require specific recipes (Karpukhin et al., 2019). Michel et al. (2019) recently emphasized th"
W19-5303,N19-1314,1,0.8427,"ernals (Zhao et al., 2018; Lee et al., 2018; ?; Anastasopoulos et al., 2019; Vaibhav et al., 2019); see Belinkov and Glass (2019) for a categorization of such work. In particular, some have focused on specific variations of naturally-occurring noise, such as grammatical errors produced by non-native speakers (Anastasopoulos et al., 2019) or errors extracted from Wikipedia edits (Belinkov and Bisk, 2018). It has also been shown that adding synthetic noise does not trivially increase robustness to natural noise (Belinkov and Bisk, 2018) and may require specific recipes (Karpukhin et al., 2019). Michel et al. (2019) recently emphasized the importance of meaning-preserving perturbations and along with Cheng et al. (2019) demonstrated the utility of adversarial training without significantly impairing performance on clean data and domain. Durrani et al. (2019) showed that character-based representations are more robust towards noise compared to such learned using BPE-based sub-word units in the task of machine translation. Jpn→Eng. We describe the dataset and the task setup in Section 3. The shared-task attracted a total of 23 submissions from 11 teams. The teams employed a variety of methods to improve ro"
W19-5303,C18-1055,0,0.064971,"n this first iteration, the shared-task used the MTNT dataset (Michel and Neubig, 2018) that contains noisy social media texts and their translations between English (Eng) and French (Fra) and English and Japanese (Jpn), in four translation directions: Eng→Fra, Fra→Eng, Eng→Jpn, and www.reddit.com https://github.com/neulab/compare-mt 91 Proceedings of the Fourth Conference on Machine Translation (WMT), Volume 2: Shared Task Papers (Day 1) pages 91–102 c Florence, Italy, August 1-2, 2019. 2019 Association for Computational Linguistics examples are generated with access to the model parameters (Ebrahimi et al., 2018; Cheng et al., 2018a,b, 2019) and ii) black-box attacks, where examples are generated without accessing model internals (Zhao et al., 2018; Lee et al., 2018; ?; Anastasopoulos et al., 2019; Vaibhav et al., 2019); see Belinkov and Glass (2019) for a categorization of such work. In particular, some have focused on specific variations of naturally-occurring noise, such as grammatical errors produced by non-native speakers (Anastasopoulos et al., 2019) or errors extracted from Wikipedia edits (Belinkov and Bisk, 2018). It has also been shown that adding synthetic noise does not trivially increase"
W19-5303,D18-1050,1,0.625161,"erstand the overall challenges in translating social media text and identify major themes of efforts which needs more research from the community. In recent years, Machine Translation (MT) systems have seen great progress, with neural models becoming the de-facto methods and even approaching human quality in news domain (Hassan et al., 2018). However, like other deep learning models, neural machine translation (NMT) models are found to be sensitive to synthetic and natural noise in input, distributional shift, and adversarial 1 2 In this first iteration, the shared-task used the MTNT dataset (Michel and Neubig, 2018) that contains noisy social media texts and their translations between English (Eng) and French (Fra) and English and Japanese (Jpn), in four translation directions: Eng→Fra, Fra→Eng, Eng→Jpn, and www.reddit.com https://github.com/neulab/compare-mt 91 Proceedings of the Fourth Conference on Machine Translation (WMT), Volume 2: Shared Task Papers (Day 1) pages 91–102 c Florence, Italy, August 1-2, 2019. 2019 Association for Computational Linguistics examples are generated with access to the model parameters (Ebrahimi et al., 2018; Cheng et al., 2018a,b, 2019) and ii) black-box attacks, where ex"
W19-5303,W19-5363,0,0.0447228,"e of tied multitask learning, where the noisy source sentences are first decoded by a same-language denoising decoder, and both information is passed on to the translation decoder. This approach requires data triples of noisy source, clean source, translation, which they created by data augmentation over the provided data, using tag-informed translation systems trained on either noisy (MTNT) or clean (Europarl) data. As the participants point out though, their performance improvements seems to be attributed to data augmentation and not to the intermediate denoising decoder. FOKUS’ submission (Grozea, 2019): This team participated in three directions: Eng→Fra, Fra→Eng and Jpn→Eng. For the Eng→Fra and Fra→Eng language pairs, the submissions are unconstrained systems, where the model was trained on the medical domain corpus provided by the WMT biomedical shared task 4 . Despite the training data being out-of-domain, removing “lowquality” parallel data such as “Subtitles” as the author hypothesized helped to bring 2 to 4 BLEU points improvement over the baseline models. Their Jpn→Eng submission is a constrained system, using the same model architecture as the Eng→Fra language pair. To improve robus"
W19-5303,N19-4007,1,0.827549,"ype tags (real or backtranslated) for further categorization of the training data. Compared to fine-tuning, adding tags provides them additional flexibility, resulting in a generalized system, robust towards a variety of input data. Human Evaluation The results of human evaluation following the evaluation protocol described in Section 3.4 are outlined in Table 2. Automatic Evaluation The automatic evaluation (BLEU) results of the Shared Task are summarized in Table 3. 6.2 Qualitative Analysis In order to discover salient differences between the methods, we performed analysis using compare-mt (Neubig et al., 2019), and present a few of the salient findings below. Fine-tuning Along with the noisy in-domain MTNT data, general domain data typically made available for WMT campaign was also allowed for this task. Most participants (Murakami et al., 2019; Dabre and Sumita, 2019; Helcl et al., 2019) trained on general domain data and fine-tuned the models towards the task. Murakami et al. (2019) did not see a consistent improvement with finetuning. Due to the small size of the in-domain data, Dabre and Sumita (2019) fine-tuned on a mix of in-domain and a subset of the out-of-domain data. Stronger Submissions"
W19-5303,W19-5364,0,0.144816,"Missing"
W19-5303,P02-1040,0,0.110507,"he translators were presented the original source sentence, the reference and the system output side by side. The order between the reference and the system output was randomized by the user interface. The translators rated both the reference and the translation on a scale from 1 to 100. For both the original source sentence and the reference, the original text was presented except for Eng-Jpn where the Japanese reference tokenized with KyTea was presented in order to be consistent with the systems’ outputs. The user interface for annotation is illustrated in Figure 1. We also evaluated BLEU (Papineni et al., 2002) for each system using SacreBLEU (Post, 2018). For all language pairs except Eng-Jpn, we used the original reference and SacreBLEU with the default options. In the case of Eng-Jpn, we used the reference tokenized with KyTea and the option --tokenize none. Task Setup The task includes two tracks, constrained and unconstrained depending on whether the system is trained on a predefined training datasets or not. The two tracks are evaluated by the same automatic and human evaluation protocol, however, they are compared separately. For the constrained system track, the task specifies two types of t"
W19-5303,D19-5506,0,0.114843,"thout accessing model internals (Zhao et al., 2018; Lee et al., 2018; ?; Anastasopoulos et al., 2019; Vaibhav et al., 2019); see Belinkov and Glass (2019) for a categorization of such work. In particular, some have focused on specific variations of naturally-occurring noise, such as grammatical errors produced by non-native speakers (Anastasopoulos et al., 2019) or errors extracted from Wikipedia edits (Belinkov and Bisk, 2018). It has also been shown that adding synthetic noise does not trivially increase robustness to natural noise (Belinkov and Bisk, 2018) and may require specific recipes (Karpukhin et al., 2019). Michel et al. (2019) recently emphasized the importance of meaning-preserving perturbations and along with Cheng et al. (2019) demonstrated the utility of adversarial training without significantly impairing performance on clean data and domain. Durrani et al. (2019) showed that character-based representations are more robust towards noise compared to such learned using BPE-based sub-word units in the task of machine translation. Jpn→Eng. We describe the dataset and the task setup in Section 3. The shared-task attracted a total of 23 submissions from 11 teams. The teams employed a variety of"
W19-5303,W18-2709,1,0.860168,"networks (Szegedy et al., 2013) has been shown to extend to neural machine translation models (Belinkov and Bisk, 2018; Heigold et al., 2017) and recent work focused on various aspects of the problem. From the identification of the causes of this brittleness, to the induction of (adversarial) inputs that trigger the unwanted behavior (attacks) and making such models robust against various types of noisy inputs (defenses); improving robustness has been receiving increasing attention in NMT. While Koehn and Knowles (2017) mentioned domain mismatch as a challenge for neural machine translation, Khayrallah and Koehn (2018) addressed noisy training data and focus on the types of noise occurring in web-crawled corpora. Michel and Neubig (2018) proposed a new dataset (MTNT) to test MT models for robustness to the types of noise encountered in the Internet and demonstrated that these challenges cannot be overcome by simple domain adaptation techniques alone. Belinkov and Bisk (2018) and Heigold et al. (2017) showed that NMT systems are very sensitive to slightly perturbed input forms, and hinted at the importance of injecting noisy examples during training, also known as adversarial examples. Further research propo"
W19-5303,W18-6319,0,0.0373317,"ce, the reference and the system output side by side. The order between the reference and the system output was randomized by the user interface. The translators rated both the reference and the translation on a scale from 1 to 100. For both the original source sentence and the reference, the original text was presented except for Eng-Jpn where the Japanese reference tokenized with KyTea was presented in order to be consistent with the systems’ outputs. The user interface for annotation is illustrated in Figure 1. We also evaluated BLEU (Papineni et al., 2002) for each system using SacreBLEU (Post, 2018). For all language pairs except Eng-Jpn, we used the original reference and SacreBLEU with the default options. In the case of Eng-Jpn, we used the reference tokenized with KyTea and the option --tokenize none. Task Setup The task includes two tracks, constrained and unconstrained depending on whether the system is trained on a predefined training datasets or not. The two tracks are evaluated by the same automatic and human evaluation protocol, however, they are compared separately. For the constrained system track, the task specifies two types of training data in addition to MTNT train set: •"
W19-5303,P16-1162,0,0.0719206,"on top of the base models with the Transformer-Big architecture, whereas improvements were substantially larger when the base models were RNN-Based MTNT baselines, about 8+ BLEU points. Participants emphasized the importance of their strong Transformer-Big base JHU’s submission (Post and Duh, 2019): This submission participated in the Fra→Eng and Jpn↔Eng tasks. The participants used data dual cross-entropy filtering for reducing the monolingual data, then back-translate these, and train their Transformer models (Vaswani et al., 2017). They compared Moses tokenization+Byte Pair Encoding (BPE) (Sennrich et al., 2016), and sentencepiece (Kudo and Richardson, 2018) (without any pre-processing) and found the two comparable, and that using larger sentence-piece models improved over smaller ones. For Jpn↔Eng (both di4 http://www.statmt.org/wmt19/biomedical-translationtask.html 95 sis, they found that their system performs poorly in translating emojis. The segmentation errors generated by KyTea resulted in further errors in the translation. rections) they first used both in-domain (MTNT) and out-of-domain data (other constrained), and then continued training (fine-tune) using MTNT only. They also reported many"
W19-5303,N19-1190,1,0.747855,"e (Jpn), in four translation directions: Eng→Fra, Fra→Eng, Eng→Jpn, and www.reddit.com https://github.com/neulab/compare-mt 91 Proceedings of the Fourth Conference on Machine Translation (WMT), Volume 2: Shared Task Papers (Day 1) pages 91–102 c Florence, Italy, August 1-2, 2019. 2019 Association for Computational Linguistics examples are generated with access to the model parameters (Ebrahimi et al., 2018; Cheng et al., 2018a,b, 2019) and ii) black-box attacks, where examples are generated without accessing model internals (Zhao et al., 2018; Lee et al., 2018; ?; Anastasopoulos et al., 2019; Vaibhav et al., 2019); see Belinkov and Glass (2019) for a categorization of such work. In particular, some have focused on specific variations of naturally-occurring noise, such as grammatical errors produced by non-native speakers (Anastasopoulos et al., 2019) or errors extracted from Wikipedia edits (Belinkov and Bisk, 2018). It has also been shown that adding synthetic noise does not trivially increase robustness to natural noise (Belinkov and Bisk, 2018) and may require specific recipes (Karpukhin et al., 2019). Michel et al. (2019) recently emphasized the importance of meaning-preserving perturbations and al"
W19-5303,D18-1316,0,0.0279519,"ations between English (Eng) and French (Fra) and English and Japanese (Jpn), in four translation directions: Eng→Fra, Fra→Eng, Eng→Jpn, and www.reddit.com https://github.com/neulab/compare-mt 91 Proceedings of the Fourth Conference on Machine Translation (WMT), Volume 2: Shared Task Papers (Day 1) pages 91–102 c Florence, Italy, August 1-2, 2019. 2019 Association for Computational Linguistics examples are generated with access to the model parameters (Ebrahimi et al., 2018; Cheng et al., 2018a,b, 2019) and ii) black-box attacks, where examples are generated without accessing model internals (Zhao et al., 2018; Lee et al., 2018; ?; Anastasopoulos et al., 2019; Vaibhav et al., 2019); see Belinkov and Glass (2019) for a categorization of such work. In particular, some have focused on specific variations of naturally-occurring noise, such as grammatical errors produced by non-native speakers (Anastasopoulos et al., 2019) or errors extracted from Wikipedia edits (Belinkov and Bisk, 2018). It has also been shown that adding synthetic noise does not trivially increase robustness to natural noise (Belinkov and Bisk, 2018) and may require specific recipes (Karpukhin et al., 2019). Michel et al. (2019) rece"
W19-5303,W19-5368,1,0.878409,"not experimented. Finally, participants point out one peculiarity they’ve noticed in the train/validation partitioning of the original MTNT dataset; validation source sentences being started with the letter “Y” followed by alphabetically sorted sentences (test partition not effected). The team experimented with the Fra→Eng and Eng→Fra translation directions, obtaining 43.6 and 36.4 BLEU-cased, respectively (3rd place in both). Their ablations show significant benefit from domain-sensitive training (+3 BLEU), with additional improvements from back-translation and ensembling. CMU’s submission (Zhou et al., 2019): This submission only participated in the Fra→Eng direction. They proposed the use of tied multitask learning, where the noisy source sentences are first decoded by a same-language denoising decoder, and both information is passed on to the translation decoder. This approach requires data triples of noisy source, clean source, translation, which they created by data augmentation over the provided data, using tag-informed translation systems trained on either noisy (MTNT) or clean (Europarl) data. As the participants point out though, their performance improvements seems to be attributed to da"
W19-5303,Q19-1004,1,\N,Missing
W19-5303,N19-1311,1,\N,Missing
W19-5303,W19-5366,0,\N,Missing
