2021.wnut-1.53,Sequence-to-Sequence Lexical Normalization with Multilingual Transformers,2021,-1,-1,3,0,265,anamaria bucur,Proceedings of the Seventh Workshop on Noisy User-generated Text (W-NUT 2021),0,"Current benchmark tasks for natural language processing contain text that is qualitatively different from the text used in informal day to day digital communication. This discrepancy has led to severe performance degradation of state-of-the-art NLP models when fine-tuned on real-world data. One way to resolve this issue is through lexical normalization, which is the process of transforming non-standard text, usually from social media, into a more standardized form. In this work, we propose a sentence-level sequence-to-sequence model based on mBART, which frames the problem as a machine translation problem. As the noisy text is a pervasive problem across languages, not just English, we leverage the multi-lingual pre-training of mBART to fine-tune it to our data. While current approaches mainly operate at the word or subword level, we argue that this approach is straightforward from a technical standpoint and builds upon existing pre-trained transformer networks. Our results show that while word-level, intrinsic, performance evaluation is behind other methods, our model improves performance on extrinsic, downstream tasks through normalization compared to models operating on raw, unprocessed, social media text."
2021.winlp-1.4,Natural language processing as a tool to identify the {R}eddit particularities of cancer survivors around the time of diagnosis and remission: A pilot study,2021,-1,-1,6,0,275,ioana podinua,Proceedings of the Fifth Workshop on Widening Natural Language Processing,0,"In the current study, we analyzed 15297 texts from 39 cancer survivors who posted or commented on Reddit in order to detect the language particularities of cancer survivors from online discourse. We performed a computational linguistic analysis (part-of-speech analysis, emoji detection, sentiment analysis) on submissions around the time of the cancer diagnosis and around the time of remission. We found several significant differences in the texts posted around the time of remission compared to those around the time of diagnosis. Though our results need to be backed up by a higher corpus of data, they do cue to the fact that cancer survivors, around the time of remission, focus more on others, are more active on social media, and do not see the glass as half empty as suggested by the valence of the emojis."
2021.lchange-1.9,Tracking Semantic Change in Cognate Sets for {E}nglish and {R}omance Languages,2021,-1,-1,4,1,3052,ana uban,Proceedings of the 2nd International Workshop on Computational Approaches to Historical Language Change 2021,0,"Semantic divergence in related languages is a key concern of historical linguistics. We cross-linguistically investigate the semantic divergence of cognate pairs in English and Romance languages, by means of word embeddings. To this end, we introduce a new curated dataset of cognates in all pairs of those languages. We describe the types of errors that occurred during the automated cognate identification process and manually correct them. Additionally, we label the English cognates according to their etymology, separating them into two groups: old borrowings and recent borrowings. On this curated dataset, we analyse word properties such as frequency and polysemy, and the distribution of similarity scores between cognate sets in different languages. We automatically identify different clusters of English cognates, setting a new direction of research in cognates, borrowings and possibly false friends analysis in related languages."
2021.findings-emnlp.243,Automatic Discrimination between Inherited and Borrowed {L}atin Words in {R}omance Languages,2021,-1,-1,2,0,5416,alina cristea,Findings of the Association for Computational Linguistics: EMNLP 2021,0,"In this paper, we address the problem of automatically discriminating between inherited and borrowed Latin words. We introduce a new dataset and investigate the case of Romance languages (Romanian, Italian, French, Spanish, Portuguese and Catalan), where words directly inherited from Latin coexist with words borrowed from Latin, and explore whether automatic discrimination between them is possible. Having entered the language at a later stage, borrowed words are no longer subject to historical sound shift rules, hence they are presumably less eroded, which is why we expect them to have a different intrinsic structure distinguishable by computational means. We employ several machine learning models to automatically discriminate between inherited and borrowed words and compare their performance with various feature sets. We analyze the models{'} predictive power on two versions of the datasets, orthographic and phonetic. We also investigate whether prior knowledge of the etymon provides better results, employing n-gram character features extracted from the word-etymon pairs and from their alignment."
2021.findings-emnlp.296,A Computational Exploration of Pejorative Language in Social Media,2021,-1,-1,1,1,267,liviu dinu,Findings of the Association for Computational Linguistics: EMNLP 2021,0,"In this paper we study pejorative language, an under-explored topic in computational linguistics. Unlike existing models of offensive language and hate speech, pejorative language manifests itself primarily at the lexical level, and describes a word that is used with a negative connotation, making it different from offensive language or other more studied categories. Pejorativity is also context-dependent: the same word can be used with or without pejorative connotations, thus pejorativity detection is essentially a problem similar to word sense disambiguation. We leverage online dictionaries to build a multilingual lexicon of pejorative terms for English, Spanish, Italian, and Romanian. We additionally release a dataset of tweets annotated for pejorative use. Based on these resources, we present an analysis of the usage and occurrence of pejorative words in social media, and present an attempt to automatically disambiguate pejorative usage in our dataset."
2021.findings-acl.167,Studying the Evolution of Scientific Topics and their Relationships,2021,-1,-1,3,1,3052,ana uban,Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021,0,None
2021.findings-acl.315,An Exploratory Analysis of the Relation between Offensive Language and Mental Health,2021,-1,-1,3,0,265,anamaria bucur,Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021,0,None
2020.lrec-1.367,Automatically Building a Multilingual Lexicon of False {F}riends With No Supervision,2020,-1,-1,2,1,3052,ana uban,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Cognate words, defined as words in different languages which derive from a common etymon, can be useful for language learners, who can leverage the orthographical similarity of cognates to more easily understand a text in a foreign language. Deceptive cognates, or false friends, do not share the same meaning anymore; these can be instead deceiving and detrimental for language acquisition or text understanding in a foreign language. We use an automatic method of detecting false friends from a set of cognates, in a fully unsupervised fashion, based on cross-lingual word embeddings. We implement our method for English and five Romance languages, including a low-resource language (Romanian), and evaluate it against two different gold standards. The method can be extended easily to any language pair, requiring only large monolingual corpora for the involved languages and a small bilingual dictionary for the pair. We additionally propose a measure of {``}falseness{''} of a false friends pair. We publish freely the database of false friends in the six languages, along with the falseness scores for each cognate pair. The resource is the largest of the kind that we are aware of, both in terms of languages covered and number of word pairs."
2020.lrec-1.394,Automatic Reconstruction of Missing {R}omanian Cognates and Unattested {L}atin Words,2020,-1,-1,2,1,17450,alina ciobanu,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Producing related words is a key concern in historical linguistics. Given an input word, the task is to automatically produce either its proto-word, a cognate pair or a modern word derived from it. In this paper, we apply a method for producing related words based on sequence labeling, aiming to fill in the gaps in incomplete cognate sets in Romance languages with Latin etymology (producing Romanian cognates that are missing) and to reconstruct uncertified Latin words. We further investigate an ensemble-based aggregation for combining and re-ranking the word productions of multiple languages."
W19-4720,Studying Laws of Semantic Divergence across Languages using Cognate Sets,2019,0,0,3,1,3052,ana uban,Proceedings of the 1st International Workshop on Computational Approaches to Historical Language Change,0,"Semantic divergence in related languages is a key concern of historical linguistics. Intra-lingual semantic shift has been previously studied in computational linguistics, but this can only provide a limited picture of the evolution of word meanings, which often develop in a multilingual environment. In this paper we investigate semantic change across languages by measuring the semantic distance of cognate words in multiple languages. By comparing current meanings of cognates in different languages, we hope to uncover information about their previous meanings, and about how they diverged in their respective languages from their common original etymon. We further study the properties of their semantic divergence, by analyzing how the features of words such as frequency and polysemy are related to the divergence in their meaning, and thus make the first steps towards formulating laws of cross-lingual semantic change."
R19-1040,Linguistic classification: dealing jointly with irrelevance and inconsistency,2019,0,0,4,0,25292,laura franzoi,Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019),0,"In this paper, we present new methods for language classification which put to good use both syntax and fuzzy tools, and are capable of dealing with irrelevant linguistic features (i.e. features which should not contribute to the classification) and even inconsistent features (which do not make sense for specific languages). We introduce a metric distance, based on the generalized Steinhaus transform, which allows one to deal jointly with irrelevance and inconsistency. To evaluate our methods, we test them on a syntactic data set, due to the linguist G. Longobardi and his school. We obtain phylogenetic trees which sometimes outperform the ones obtained by Atkinson and Gray."
R19-1100,From Image to Text in Sentiment Analysis via Regression and Deep Learning,2019,0,0,2,0,25342,daniela onita,Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019),0,"Images and text represent types of content which are used together for conveying user emotions in online social networks. These contents are usually associated with a sentiment category. In this paper, we investigate an approach for mapping images to text for three types of sentiment categories: positive, neutral and negative. The mapping from images to text is performed using a Kernel Ridge Regression model. We considered two types of image features: i) RGB pixel-values features, and ii) features extracted with a deep learning approach. The experimental evaluation was performed on a Twitter data set containing both text and images and the sentiment associated with these. The experimental results show a difference in performance for different sentiment categories, in particular the mapping that we propose performs better for the positive sentiment category in comparison with the neutral and negative ones. Furthermore, the experimental results show that the more complex deep learning features perform better than the RGB pixel-value features for all sentiment categories and for larger training sets."
J19-4003,Automatic Identification and Production of Related Words for Historical Linguistics,2019,-1,-1,2,1,17450,alina ciobanu,Computational Linguistics,0,"Language change across space and time is one of the main concerns in historical linguistics. In this article, we develop tools to assist researchers and domain experts in the study of language evolution.First, we introduce a method to automatically determine whether two words are cognates. We propose an algorithm for extracting cognates from electronic dictionaries that contain etymological information. Having built a data set of related words, we further develop machine learning methods based on orthographic alignment for identifying cognates. We use aligned subsequences as features for classification algorithms in order to infer rules for linguistic changes undergone by words when entering new languages and to discriminate between cognates and non-cognates.Second, we extend the method to a finer-grained level, to identify the type of relationship between words. Discriminating between cognates and borrowings provides a deeper insight into the history of a language and allows a better characterization of language relatedness. We show that orthographic features have discriminative power and we analyze the underlying linguistic factors that prove relevant in the classification task. To our knowledge, this is the first attempt of this kind.Third, we develop a machine learning method for automatically producing related words. We focus on reconstructing proto-words, but we also address two related sub-problems, producing modern word forms and producing cognates. The task of reconstructing proto-words consists of recreating the words in an ancient language from its modern daughter languages. Having modern word forms in multiple Romance languages, we infer the form of their common Latin ancestors. Our approach relies on the regularities that occurred when words entered the modern languages. We leverage information from several modern languages, building an ensemble system for reconstructing proto-words. We apply our method to multiple data sets, showing that our approach improves on previous results, also having the advantage of requiring less input data, which is essential in historical linguistics, where resources are generally scarce."
D19-1236,The Myth of Double-Blind Review Revisited: {ACL} vs. {EMNLP},2019,0,0,3,0.9965,3708,cornelia caragea,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),0,"The review and selection process for scientific paper publication is essential for the quality of scholarly publications in a scientific field. The double-blind review system, which enforces author anonymity during the review period, is widely used by prestigious conferences and journals to ensure the integrity of this process. Although the notion of anonymity in the double-blind review has been questioned before, the availability of full text paper collections brings new opportunities for exploring the question: Is the double-blind review process really double-blind? We study this question on the ACL and EMNLP paper collections and present an analysis on how well deep learning techniques can infer the authors of a paper. Specifically, we explore Convolutional Neural Networks trained on various aspects of a paper, e.g., content, style features, and references, to understand the extent to which we can infer the authors of a paper and what aspects contribute the most. Our results show that the authors of a paper can be inferred with accuracy as high as 87{\%} on ACL and 78{\%} on EMNLP for the top 100 most prolific authors."
W18-6118,Content Extraction and Lexical Analysis from Customer-Agent Interactions,2018,0,0,3,1,18363,sergiu nisioi,Proceedings of the 2018 {EMNLP} Workshop W-{NUT}: The 4th Workshop on Noisy User-generated Text,0,"In this paper, we provide a lexical comparative analysis of the vocabulary used by customers and agents in an Enterprise Resource Planning (ERP) environment and a potential solution to clean the data and extract relevant content for NLP. As a result, we demonstrate that the actual vocabulary for the language that prevails in the ERP conversations is highly divergent from the standardized dictionary and further different from general language usage as extracted from the Common Crawl corpus. Moreover, in specific business communication circumstances, where it is expected to observe a high usage of standardized language, code switching and non-standard expression are predominant, emphasizing once more the discrepancy between the day-to-day use of language and the standardized one."
W18-3920,Discriminating between {I}ndo-{A}ryan Languages Using {SVM} Ensembles,2018,0,1,5,1,17450,alina ciobanu,"Proceedings of the Fifth Workshop on {NLP} for Similar Languages, Varieties and Dialects ({V}ar{D}ial 2018)",0,"In this paper we present a system based on SVM ensembles trained on characters and words to discriminate between five similar languages of the Indo-Aryan family: Hindi, Braj Bhasha, Awadhi, Bhojpuri, and Magahi. The system competed in the Indo-Aryan Language Identification (ILI) shared task organized within the VarDial Evaluation Campaign 2018. Our best entry in the competition, named ILIdentification, scored 88.95{\%} F1 score and it was ranked 3rd out of 8 teams."
W18-3933,{G}erman Dialect Identification Using Classifier Ensembles,2018,12,2,3,1,17450,alina ciobanu,"Proceedings of the Fifth Workshop on {NLP} for Similar Languages, Varieties and Dialects ({V}ar{D}ial 2018)",0,"In this paper we present the GDI classification entry to the second German Dialect Identification (GDI) shared task organized within the scope of the VarDial Evaluation Campaign 2018. We present a system based on SVM classifier ensembles trained on characters and words. The system was trained on a collection of speech transcripts of five Swiss-German dialects provided by the organizers. The transcripts included in the dataset contained speakers from Basel, Bern, Lucerne, and Zurich. Our entry in the challenge reached 62.03{\%} F1 score and was ranked third out of eight teams."
S18-1158,{ALB} at {S}em{E}val-2018 Task 10: A System for Capturing Discriminative Attributes,2018,0,1,3,0,28899,bogdan dumitru,Proceedings of The 12th International Workshop on Semantic Evaluation,0,"Semantic difference detection attempts to capture whether a word is a discriminative attribute between two other words. For example, the discriminative feature red characterizes the first word from the (apple, banana) pair, but not the second. Modeling semantic difference is essential for language understanding systems, as it provides useful information for identifying particular aspects of word senses. This paper describes our system implementation (the ALB system of the NLP@Unibuc team) for the 10th task of the SemEval 2018 workshop, {``}Capturing Discriminative Attributes{''}. We propose a method for semantic difference detection that uses an SVM classifier with features based on co-occurrence counts and shallow semantic parsing, achieving 0.63 F1 score in the competition."
D18-1067,Exploring Optimism and Pessimism in {T}witter Using Deep Learning,2018,0,0,2,0.9965,3708,cornelia caragea,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,"Identifying optimistic and pessimistic viewpoints and users from Twitter is useful for providing better social support to those who need such support, and for minimizing the negative influence among users and maximizing the spread of positive attitudes and ideas. In this paper, we explore a range of deep learning models to predict optimism and pessimism in Twitter at both tweet and user level and show that these models substantially outperform traditional machine learning classifiers used in prior work. In addition, we show evidence that a sentiment classifier would not be sufficient for accurately predicting optimism and pessimism in Twitter. Last, we study the verb tense usage as well as the presence of polarity words in optimistic and pessimistic tweets."
C18-2015,Simulating Language Evolution: a Tool for Historical Linguistics,2018,0,0,2,1,17450,alina ciobanu,Proceedings of the 27th International Conference on Computational Linguistics: System Demonstrations,0,"Language change across space and time is one of the main concerns in historical linguistics. In this paper, we develop a language evolution simulator: a web-based tool for word form production to assist in historical linguistics, in studying the evolution of the languages. Given a word in a source language, the system automatically predicts how the word evolves in a target language. The method that we propose is language-agnostic and does not use any external knowledge, except for the training word pairs."
C18-1136,Ab Initio: Automatic {L}atin Proto-word Reconstruction,2018,0,1,2,1,17450,alina ciobanu,Proceedings of the 27th International Conference on Computational Linguistics,0,"Proto-word reconstruction is central to the study of language evolution. It consists of recreating the words in an ancient language from its modern daughter languages. In this paper we investigate automatic word form reconstruction for Latin proto-words. Having modern word forms in multiple Romance languages (French, Italian, Spanish, Portuguese and Romanian), we infer the form of their common Latin ancestors. Our approach relies on the regularities that occurred when the Latin words entered the modern languages. We leverage information from all modern languages, building an ensemble system for proto-word reconstruction. We use conditional random fields for sequence labeling, but we conduct preliminary experiments with recurrent neural networks as well. We apply our method on multiple datasets, showing that our method improves on previous results, having also the advantage of requiring less input data, which is essential in historical linguistics, where resources are generally scarce."
W17-5045,Native Language Identification on Text and Speech,2017,10,0,3,0.171263,622,marcos zampieri,Proceedings of the 12th Workshop on Innovative Use of {NLP} for Building Educational Applications,0,This paper presents an ensemble system combining the output of multiple SVM classifiers to native language identification (NLI). The system was submitted to the NLI Shared Task 2017 fusion track which featured students essays and spoken responses in form of audio transcriptions and iVectors by non-native English speakers of eleven native languages. Our system competed in the challenge under the team name ZCD and was based on an ensemble of SVM classifiers trained on character n-grams achieving 83.58{\%} accuracy and ranking 3rd in the shared task.
W17-2210,Finding a Character{'}s Voice: Stylome Classification on Literary Characters,2017,-1,-1,1,1,267,liviu dinu,"Proceedings of the Joint {SIGHUM} Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature",0,"We investigate in this paper the problem of classifying the stylome of characters in a literary work. Previous research in the field of authorship attribution has shown that the writing style of an author can be characterized and distinguished from that of other authors automatically. In this paper we take a look at the less approached problem of how the styles of different characters can be distinguished, trying to verify if an author managed to create believable characters with individual styles. We present the results of some initial experiments developed on the novel {``}Liaisons Dangereuses{''}, showing that a simple bag of words model can be used to classify the characters."
dinu-etal-2017-stylistic,On the stylistic evolution from communism to democracy: {S}olomon {M}arcus study case,2017,0,0,2,0.859449,5417,anca dinu,"Proceedings of the International Conference Recent Advances in Natural Language Processing, {RANLP} 2017",0,"In this article we propose a stylistic analysis of Solomon Marcus{'} non-scientific published texts, gathered in six volumes, aiming to uncover some of his quantitative and qualitative fingerprints. Moreover, we compare and cluster two distinct periods of time in his writing style: 22 years of communist regime (1967-1989) and 27 years of democracy (1990-2016). The distributional analysis of Marcus{'} text reveals that the passing from the communist regime period to democracy is sharply marked by two complementary changes in Marcus{'} writing: in the pre-democracy period, the communist norms of writing style demanded on the one hand long phrases, long words and clich{\'e}s, and on the other hand, a short list of preferred {``}official{''} topics; in democracy tendency was towards shorten phrases and words while approaching a broader area of topics."
P17-2014,Exploring Neural Text Simplification Models,2017,10,26,4,1,18363,sergiu nisioi,Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"We present the first attempt at using sequence to sequence neural networks to model text simplification (TS). Unlike the previously proposed automated TS systems, our neural text simplification (NTS) systems are able to simultaneously perform lexical simplification and content reduction. An extensive human evaluation of the output has shown that NTS systems achieve almost perfect grammaticality and meaning preservation of output sentences and higher level of simplification than the state-of-the-art automated TS systems"
W16-4830,Vanilla Classifiers for Distinguishing between Similar Languages,2016,0,0,3,1,18363,sergiu nisioi,"Proceedings of the Third Workshop on {NLP} for Similar Languages, Varieties and Dialects ({V}ar{D}ial3)",0,"In this paper we describe the submission of the UniBuc-NLP team for the Discriminating between Similar Languages Shared Task, DSL 2016. We present and analyze the results we obtained in the closed track of sub-task 1 (Similar languages and language varieties) and sub-task 2 (Arabic dialects). For sub-task 1 we used a logistic regression classifier with tf-idf feature weighting and for sub-task 2 a character-based string kernel with an SVM classifier. Our results show that good accuracy scores can be obtained with limited feature and model engineering. While certain limitations are to be acknowledged, our approach worked surprisingly well for out-of-domain, social media data, with 0.898 accuracy (3rd place) for dataset B1 and 0.838 accuracy (4th place) for dataset B2."
L16-1522,A Computational Perspective on the {R}omanian Dialects,2016,12,5,2,1,17450,alina ciobanu,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"In this paper we conduct an initial study on the dialects of Romanian. We analyze the differences between Romanian and its dialects using the Swadesh list. We analyze the predictive power of the orthographic and phonetic features of the words, building a classification problem for dialect identification."
L16-1536,Using Word Embeddings to Translate Named Entities,2016,0,3,3,0,31536,octaviamaria csulea,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"In this paper we investigate the usefulness of neural word embeddings in the process of translating Named Entities (NEs) from a resource-rich language to a language low on resources relevant to the task at hand, introducing a novel, yet simple way of obtaining bilingual word vectors. Inspired by observations in (Mikolov et al., 2013b), which show that training their word vector model on comparable corpora yields comparable vector space representations of those corpora, reducing the problem of translating words to finding a rotation matrix, and results in (Zou et al., 2013), which showed that bilingual word embeddings can improve Chinese Named Entity Recognition (NER) and English to Chinese phrase translation, we use the sentence-aligned English-French EuroParl corpora and show that word embeddings extracted from a merged corpus (corpus resulted from the merger of the two aligned corpora) can be used to NE translation. We extrapolate that word embeddings trained on merged parallel corpora are useful in Named Entity Recognition and Translation tasks for resource-poor languages."
L16-1664,"A Corpus of Native, Non-native and Translated Texts",2016,0,3,3,1,18363,sergiu nisioi,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"We describe a monolingual English corpus of original and (human) translated texts, with an accurate annotation of speaker properties, including the original language of the utterances and the speaker{'}s country of origin. We thus obtain three sub-corpora of texts reflecting native English, non-native English, and English translated from a variety of European languages. This dataset will facilitate the investigation of similarities and differences between these kinds of sub-languages. Moreover, it will facilitate a unified comparative study of translations and language produced by (highly fluent) non-native speakers, two closely-related phenomena that have only been studied in isolation so far."
S15-2144,{AMBRA}: A Ranking Approach to Temporal Text Classification,2015,21,6,4,0.306122,622,marcos zampieri,Proceedings of the 9th International Workshop on Semantic Evaluation ({S}em{E}val 2015),0,"This paper describes the AMBRA system, entered in the SemEval-2015 Task 7: xe2x80x98Diachronic Text Evaluationxe2x80x99 subtasks one and two, which consist of predicting the date when a text was originally written. The task is valuable for applications in digital humanities, information systems, and historical linguistics. The novelty of this shared task consists of incorporating label uncertainty by assigning an interval within which the document was written, rather than assigning a clear time marker to each training document. To deal with non-linear effects and variable degrees of uncertainty, we reduce the problem to pairwise comparisons of the form is Document A older than Document B?, and propose a nonparametric way to transform the ordinal output into time intervals."
R15-1014,Readability Assessment of Translated Texts,2015,25,0,2,1,17450,alina ciobanu,Proceedings of the International Conference Recent Advances in Natural Language Processing,0,"In this paper we investigate how readability varies between texts originally written in English and texts translated into English. For quantification, we analyze several factors that are relevant in assessing readability xe2x80x90 shallow, lexical and morpho-syntactic features xe2x80x90 and we employ the widely used Flesch-Kincaid formula to measure the variation of the readability level between original English texts and texts translated into English. Finally, we analyze whether the readability features have enough discriminative power to distinguish between originals and translations."
R15-1021,Cross-lingual Synonymy Overlap,2015,8,0,2,1,5417,anca dinu,Proceedings of the International Conference Recent Advances in Natural Language Processing,0,"We investigate in this paper the degree of overlap between synonym sets of translated word pairs across three languages: French, English and Romanian. We use for this purpose a French Synonym Dictionary, a Romanian Synonym Dictionary, Princetonxe2x80x99s WordNet and Google Translate API. We build a database containing pairs of (translated) words from the three languages, along with their corresponding synonym sets. We use it in order to gain insight into the synonym overlap for each language pair, and thus, into their degree of common concept lexicalization, by various queries. While the overall percentage of common synonyms is (expectedly) quite small (averaging ~6% across all language pairs), the percentage of hard synonyms pairs (pairs that have at least one common synonym), reaching ~62%, is significant. This is encouraging for further use of this special kind of word translated pairs in tasks such as automatic enhancement of lexical databases (such as WordNet) for less resourced languages such as Romanian, based on corresponding English versions of these lexical databases. Another interesting query topic was obtaining distributions of hard synonym pairs, function of their part of speech: hard synonyms were most frequent among verbs for English, and among adjectives for Romanian and French."
P15-2071,Automatic Discrimination between Cognates and Borrowings,2015,29,6,2,1,17450,alina ciobanu,Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers),0,"Identifying the type of relationship between words provides a deeper insight into the history of a language and allows a better characterization of language relatedness. In this paper, we propose a computational approach for discriminating between cognates and borrowings. We show that orthographic features have discriminative power and we analyze the underlying linguistic factors that prove relevant in the classification task. To our knowledge, this is the first attempt of this kind."
W14-1212,A Quantitative Insight into the Impact of Translation on Readability,2014,43,2,2,1,17450,alina ciobanu,Proceedings of the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations ({PITR}),0,"In this paper we investigate the impact of translation on readability. We propose a quantitative analysis of several shallow, lexical and morpho-syntactic features that have been traditionally used for assessing readability and have proven relevant for this task. We conduct our experiments on a parallel corpus of transcribed parliamentary sessions and we investigate readability metrics for the original segments of text, written in the language of the speaker, and their translations."
P14-2017,Automatic Detection of Cognates Using Orthographic Alignment,2014,31,22,2,1,17450,alina ciobanu,Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"Words undergo various changes when entering new languages. Based on the assumption that these linguistic changes follow certain rules, we propose a method for automatically detecting pairs of cognates employing an orthographic alignment method which proved relevant for sequence alignment in computational biology. We use aligned subsequences as features for machine learning algorithms in order to infer rules for linguistic changes undergone by words when entering new languages and to discriminate between cognates and non-cognates. Given a list of known cognates, our approach does not require any other linguistic information. However, it can be customized to integrate historical information regarding language evolution."
dinu-ciobanu-2014-romance,On the {R}omance Languages Mutual Intelligibility,2014,23,4,1,1,267,liviu dinu,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"We propose a method for computing the similarity of natural languages and for clustering them based on their lexical similarity. Our study provides evidence to be used in the investigation of the written intelligibility, i.e., the ability of people writing in different languages to understand one another without prior knowledge of foreign languages. We account for etymons and cognates, we quantify lexical similarity and we extend our analysis from words to languages. Based on the introduced methodology, we compute a matrix of Romance languages intelligibility."
dinu-etal-2014-aggregation,Aggregation methods for efficient collocation detection,2014,13,1,2,1,5417,anca dinu,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"In this article we propose a rank aggregation method for the task of collocations detection. It consists of applying some well-known methods (e.g. Dice method, chi-square test, z-test and likelihood ratio) and then aggregating the resulting collocations rankings by rank distance and Borda score. These two aggregation methods are especially well suited for the task, since the results of each individual method naturally forms a ranking of collocations. Combination methods are known to usually improve the results, and indeed, the proposed aggregation method performs better then each individual method taken in isolation."
dinu-etal-2014-using,Using a machine learning model to assess the complexity of stress systems,2014,14,2,1,1,267,liviu dinu,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"We address the task of stress prediction as a sequence tagging problem. We present sequential models with averaged perceptron training for learning primary stress in Romanian words. We use character n-grams and syllable n-grams as features and we account for the consonant-vowel structure of the words. We show in this paper that Romanian stress is predictable, though not deterministic, by using data-driven machine learning techniques."
dinu-ciobanu-2014-building,Building a Dataset of Multilingual Cognates for the {R}omanian Lexicon,2014,25,4,1,1,267,liviu dinu,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"Identifying cognates is an interesting task with applications in numerous research areas, such as historical and comparative linguistics, language acquisition, cross-lingual information retrieval, readability and machine translation. We propose a dictionary-based approach to identifying cognates based on etymology and etymons. We account for relationships between languages and we extract etymology-related information from electronic dictionaries. We employ the dataset of cognates that we obtain as a gold standard for evaluating to which extent orthographic methods can be used to detect cognate pairs. The question that arises is whether they are able to discriminate between cognates and non-cognates, given the orthographic changes undergone by foreign words when entering new languages. We investigate some orthographic approaches widely used in this research area and some original metrics as well. We run our experiments on the Romanian lexicon, but the method we propose is adaptable to any language, as far as resources are available."
E14-4004,Temporal Text Ranking and Automatic Dating of Texts,2014,15,20,3,0.666667,20226,vlad niculae,"Proceedings of the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics, volume 2: Short Papers",0,"This paper presents a novel approach to the task of temporal text classification combining text ranking and probability for the automatic dating of historical texts. The method was applied to three historical corpora: an English, a Portuguese and a Romanian corpus. It obtained performance ranging from 83% to 93% accuracy, using a fully automated approach with very basic features."
E14-4013,Predicting {R}omanian Stress Assignment,2014,16,3,3,1,17450,alina ciobanu,"Proceedings of the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics, volume 2: Short Papers",0,"We train and evaluate two models for Romanian stress prediction: a baseline model which employs the consonant-vowel structure of the words and a cascaded model with averaged perceptron training consisting of two sequential models xe2x80x90 one for predicting syllable boundaries and another one for predicting stress placement. We show in this paper that Romanian stress is predictable, though not deterministic, by using data-driven machine learning techniques."
D14-1112,An Etymological Approach to Cross-Language Orthographic Similarity. Application on {R}omanian,2014,31,10,2,1,17450,alina ciobanu,Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP}),0,"In this paper we propose a computational method for determining the orthographic similarity between Romanian and related languages. We account for etymons and cognates and we investigate not only the number of related words, but also their forms, quantifying orthographic similarities. The method we propose is adaptable to any language, as far as resources are available."
W13-2714,Temporal classification for historical {R}omanian texts,2013,11,6,3,1,17450,alina ciobanu,"Proceedings of the 7th Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities",0,"In this paper we look at a task at border of natural language processing, historical linguistics and the study of language development, namely that of identifying the time when a text was written. We use machine learning classification using lexical, word ending and dictionary-based features, with linear support vector machines and random forests. We find that lexical features are the most helpful."
R13-1018,Temporal Text Classification for {R}omanian Novels set in the Past,2013,12,5,2,1,17450,alina ciobanu,Proceedings of the International Conference Recent Advances in Natural Language Processing {RANLP} 2013,0,"In this paper we look at a task in historical linguistics and the study of language development, namely that of identifying the time when a text was written. The novelty is that we evaluate our classifier and our selected features on literary texts having their action placed in the past and written so as to give off the impression of the respective epoch. We investigate several types of features and ultimately go with a very simple set of 10 features which very accurately classifies the texts based on the century they were actually written in. We use random forests to obtain high performance."
R13-1019,A Dictionary-Based Approach for Evaluating Orthographic Methods in Cognates Identification,2013,21,3,2,1,17450,alina ciobanu,Proceedings of the International Conference Recent Advances in Natural Language Processing {RANLP} 2013,0,"In this paper we propose a method for identifying cognates based on etymology and etymons. We employ this approach to evaluate the extent to which lexical similarity can be used for automatic detection of cognate pairs. We investigate some orthographic approaches widely used in this research area and some original metrics as well. We apply this procedure for Romanian and its most closely related languages, French and Italian, but our method is applicable to any languages."
R13-1028,Sequence Tagging for Verb Conjugation in {R}omanian,2013,14,3,1,1,267,liviu dinu,Proceedings of the International Conference Recent Advances in Natural Language Processing {RANLP} 2013,0,"Verbs in Romanian sometimes manifest local irregularities in the form of alternating letters. We present a sequence tagging based method for learning stem alternations and ending sequences. Supervised training is based on a morphological dictionary, with a few regular expression paradigms encoded by hand. Our best model improves upon previous machine learning approaches to Romanian verb conjugation, and can generalize to unseen paradigms that can be constructed as variations of the ones in the training set."
R13-1070,A clustering approach for translationese identification,2013,22,2,2,1,18363,sergiu nisioi,Proceedings of the International Conference Recent Advances in Natural Language Processing {RANLP} 2013,0,"Our paper is concerned with investigating the impact of translationese on the novels of a bilingual writer and asking whether one could determine the authorship of a translated document. The main part of our paper will be centered on selecting a good set of lexical features that can be considered characteristic for an author. We used in our research the novels of Vladimir Nabokov, a bilingual author, who wrote his works in both Russian and English. Each text is represented by a vector of function words. We are interested in determining how the results vary across different feature sets and which feature set could be considered the most representative. In order to inspect our results we used a hierarchical clustering method and draw conclusions based on the most frequent result."
W12-0411,Pastiche Detection Based on Stopword Rankings. Exposing Impersonators of a {R}omanian Writer,2012,9,8,1,1,267,liviu dinu,Proceedings of the Workshop on Computational Approaches to Deception Detection,0,"We applied hierarchical clustering using Rank distance, previously used in computational stylometry, on literary texts written by Mateiu Caragiale and a number of different authors who attempted to impersonate Caragiale after his death, or simply to mimic his style. Their pastiches were consistently clustered opposite to the original work, thereby confirming the performance of the method and proposing an extension of the method from simple authorship attribution to the more complicated problem of pastiche detection.n n The novelty of our work is the use of frequency rankings of stopwords as features, showing that this idea yields good results for pastiche detection."
dinu-etal-2012-romanian,The {R}omanian Neuter Examined Through A Two-Gender N-Gram Classification System,2012,7,2,1,1,267,liviu dinu,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"Romanian has been traditionally seen as bearing three lexical genders: masculine, feminine and neuter, although it has always been known to have only two agreement patterns (for masculine and feminine). A recent analysis of the Romanian gender system described in (Bateman and Polinsky, 2010), based on older observations, argues that there are two lexically unspecified noun classes in the singular and two different ones in the plural and that what is generally called neuter in Romanian shares the class in the singular with masculines, and the class in the plural with feminines based not only on agreement features but also on form. Previous machine learning classifiers that have attempted to discriminate Romanian nouns according to gender have so far taken as input only the singular form, presupposing the traditional tripartite analysis. We propose a classifier based on two parallel support vector machines using n-gram features from the singular and from the plural which outperforms previous classifiers in its high ability to distinguish the neuter. The performance of our system suggests that the two-gender analysis of Romanian, on which it is based, is on the right track."
E12-1053,Learning How to Conjugate the {R}omanian Verb. Rules for Regular and Partially Irregular Verbs,2012,6,5,1,1,267,liviu dinu,Proceedings of the 13th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"In this paper we extend our work described in (Dinu et al., 2011) by adding more conjugational rules to the labelling system introduced there, in an attempt to capture the entire dataset of Romanian verbs extracted from (Barbu, 2007), and we employ machine learning techniques to predict a verb's correct label (which says what conjugational pattern it follows) when only the infinitive form is given."
C12-3011,On the {R}omanian Rhyme Detection,2012,7,1,2,1,17450,alina ciobanu,Proceedings of {COLING} 2012: Demonstration Papers,0,"In this paper we focus on detecting Romanian words without rhymes, using knowledge about stressed vowels and syllabification. We also investigate quantitative aspects and the etymological origins of the Romanian words without rhymes."
C12-3015,"Dealing with the Grey Sheep of the {R}omanian Gender System, the Neuter",2012,8,1,1,1,267,liviu dinu,Proceedings of {COLING} 2012: Demonstration Papers,0,"Romanian has been traditionally seen as bearing three lexical genders: masculine, feminine, and neuter, although it has always been known to have only two agreement patterns (for masculine and feminine). Previous machine learning classifiers which have attempted to discriminate Romanian nouns according to gender have taken as input only the singular form, either presupposing the traditional tripartite analysis, or using additional information from case inflected forms. We present here a tool based on two parallel support vector machines using n-gram features from the singular and from the plural, which distinguish the neuter."
C12-3016,Authorial Studies using Ranked Lexical Features,2012,10,1,1,1,267,liviu dinu,Proceedings of {COLING} 2012: Demonstration Papers,0,"The purpose of this article is to propose a tool for measuring distances between different styles of one or more authors. The main study is focused on measuring and visualizing distances in a space induced by ranked lexical features. We investigate the case of Vladimir Nabokov, a bilingual Russian English language author."
R11-1075,Can Alternations Be Learned? A Machine Learning Approach To {R}omanian Verb Conjugation,2011,1,4,1,1,267,liviu dinu,Proceedings of the International Conference Recent Advances in Natural Language Processing 2011,0,"In this paper we look at the conjugation of the Romanian verb, in particular, at its irregularities, from a machine learning point of view. Our attempt is to predict the presence or absence of any alternation in the stem (apophony), using n-gram representations of the infinitive. We combine formal labelling mechanisms with learning methods in order to build a general conjugational model."
W09-4002,On the behavior of {R}omanian syllables related to minimum effort laws,2009,-1,-1,2,0.869565,5417,anca dinu,"Proceedings of the Workshop Multilingual resources, technologies and evaluation for central and Eastern {E}uropean languages",0,None
R09-1063,Comparing Statistical Similarity Measures for Stylistic Multivariate Analysis,2009,8,10,2,1,3055,marius popescu,Proceedings of the International Conference {RANLP}-2009,0,"The goal of this paper is to compare a set of distance/similarity measures, some motivated statistically, others motivated stylistically, regarding their ability to reflect stylistic similarity between texts. To assess the ability of these distance/similarity functions to capture stylistic similarity between texts, we have tested them in the two most frequently employed multivariate statistical analysis settings: cluster analysis and (kernel) principal components analysis."
dinu-etal-2008-authorship,Authorship Identification of {R}omanian Texts with Controversial Paternity,2008,12,12,1,1,267,liviu dinu,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"In this work we propose a new strategy for the authorship identification problem and we test it on an example from Romanian literature: did Radu Albala found the continuation of Mateiu Caragiales novel Sub pecetea tainei, or did he write himself the respective continuation? The proposed strategy is based on the similarity of rankings of function words; we compare the obtained results with the results obtained by a learning method (namely Support Vector Machines -SVM- with a string kernel)."
C08-2023,Rank Distance as a Stylistic Similarity,2008,9,8,2,1,3055,marius popescu,Coling 2008: Companion volume: Posters,0,"In this paper we propose a new distance function (rank distance) designed to reflect stylistic similarity between texts. To assess the ability of this distance measure to capture stylistic similarity between texts, we tested it in two different machine learning settings: clustering and binary classification."
W06-1114,Total Rank Distance and Scaled Total Rank Distance: Two Alternative Metrics in Computational Linguistics,2006,-1,-1,2,0,5417,anca dinu,Proceedings of the Workshop on Linguistic Distances,0,None
dinu-dinu-2006-data,On the data base of {R}omanian syllables and some of its quantitative and cryptographic aspects,2006,5,8,1,1,267,liviu dinu,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,In this paper we argue for the need to construct a data base of Romanian syllables. We explain the reasons for our choice of the DOOM corpus which we have used. We describe the way syllabification was performed and explain how we have constructed the data base. The main quantitative aspects which we have extracted from our research are presented. We also computed the entropy of the syllables and the entropy of the syllables w.r.t. the consonant-vowel structure. The results are compared with results of similar researches realized for different languages.
