2021.reinact-1.5,The Spoon Is in the Sink: Assisting Visually Impaired People in the Kitchen,2021,-1,-1,6,0,2547,katie baker,Proceedings of the Reasoning and Interaction Conference (ReInAct 2021),0,"Visual Question Answering (VQA) systems are increasingly adept at a variety of tasks, and this technology can be used to assist blind and partially sighted people. To do this, the system{'}s responses must not only be accurate, but usable. It is also vital for assistive technologies to be designed with a focus on: (1) privacy, as the camera may capture a user{'}s mail, medication bottles, or other sensitive information; (2) transparency, so that the system{'}s behaviour can be explained and trusted by users; and (3) controllability, to tailor the system for a particular domain or user group. We have therefore extended a conversational VQA framework, called Aye-saac, with these objectives in mind. Specifically, we gave Aye-saac the ability to answer visual questions in the kitchen, a particularly challenging area for visually impaired people. Our system can now answer questions about quantity, positioning, and system confidence in regards to 299 kitchen objects. Questions about the spatial relations between these objects are particularly helpful to visually impaired people, and our system output more usable answers than other state of the art end-to-end VQA systems."
2021.eacl-main.183,An Empirical Study on the Generalization Power of Neural Representations Learned via Visual Guessing Games,2021,-1,-1,7,1,10795,alessandro suglia,Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume,0,"Guessing games are a prototypical instance of the {``}learning by interacting{''} paradigm. This work investigates how well an artificial agent can benefit from playing guessing games when later asked to perform on novel NLP downstream tasks such as Visual Question Answering (VQA). We propose two ways to exploit playing guessing games: 1) a supervised learning scenario in which the agent learns to mimic successful guessing games and 2) a novel way for an agent to play by itself, called Self-play via Iterated Experience Learning (SPIEL). We evaluate the ability of both procedures to generalise: an in-domain evaluation shows an increased accuracy (+7.79) compared with competitors on the evaluation suite CompGuessWhat?!; a transfer evaluation shows improved performance for VQA on the TDIUC dataset in terms of harmonic average accuracy (+5.31) thanks to more fine-grained object representations learned via SPIEL."
2020.sigdial-1.5,Conversational Agents for Intelligent Buildings,2020,-1,-1,4,0,14916,weronika sieinska,Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"We will demonstrate a deployed conversational AI system that acts as a host of a smart-building on a university campus. The system combines open-domain social conversation with task-based conversation regarding navigation in the building, live resource updates (e.g. available computers) and events in the building. We are able to demonstrate the system on several platforms: Google Home devices, Android phones, and a Furhat robot."
2020.coling-main.95,Imagining Grounded Conceptual Representations from Perceptual Information in Situated Guessing Games,2020,-1,-1,7,1,10795,alessandro suglia,Proceedings of the 28th International Conference on Computational Linguistics,0,"In visual guessing games, a Guesser has to identify a target object in a scene by asking questions to an Oracle. An effective strategy for the players is to learn conceptual representations of objects that are both discriminative and expressive enough to ask questions and guess correctly. However, as shown by Suglia et al. (2020), existing models fail to learn truly multi-modal representations, relying instead on gold category labels for objects in the scene both at training and inference time. This provides an unnatural performance advantage when categories at inference time match those at training time, and it causes models to fail in more realistic {``}zero-shot{''} scenarios where out-of-domain object categories are involved. To overcome this issue, we introduce a novel {``}imagination{''} module based on Regularized Auto-Encoders, that learns context-aware and category-aware latent embeddings without relying on category labels at inference time. Our imagination module outperforms state-of-the-art competitors by 8.26{\%} gameplay accuracy in the CompGuessWhat?! zero-shot scenario (Suglia et al., 2020), and it improves the Oracle and Guesser accuracy by 2.08{\%} and 12.86{\%} in the GuessWhat?! benchmark, when no gold categories are available at inference time. The imagination module also boosts reasoning about object properties and attributes."
2020.acl-main.682,{C}omp{G}uess{W}hat?!: A Multi-task Evaluation Framework for Grounded Language Learning,2020,-1,-1,7,1,10795,alessandro suglia,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,1,"Approaches to Grounded Language Learning are commonly focused on a single task-based final performance measure which may not depend on desirable properties of the learned hidden representations, such as their ability to predict object attributes or generalize to unseen situations. To remedy this, we present GroLLA, an evaluation framework for Grounded Language Learning with Attributes based on three sub-tasks: 1) Goal-oriented evaluation; 2) Object attribute prediction evaluation; and 3) Zero-shot evaluation. We also propose a new dataset CompGuessWhat?! as an instance of this framework for evaluating the quality of learned neural representations, in particular with respect to attribute grounding. To this end, we extend the original GuessWhat?! dataset by including a semantic layer on top of the perceptual one. Specifically, we enrich the VisualGenome scene graphs associated with the GuessWhat?! images with several attributes from resources such as VISA and ImSitu. We then compare several hidden state representations from current state-of-the-art approaches to Grounded Language Learning. By using diagnostic classifiers, we show that current models{'} learned representations are not expressive enough to encode object attributes (average F1 of 44.27). In addition, they do not learn strategies nor representations that are robust enough to perform well when novel scenes or objects are involved in gameplay (zero-shot best accuracy 50.06{\%})."
W19-5904,Few-Shot Dialogue Generation Without Annotated Data: A Transfer Learning Approach,2019,22,1,4,1,23733,igor shalyminov,Proceedings of the 20th Annual SIGdial Meeting on Discourse and Dialogue,0,"Learning with minimal data is one of the key challenges in the development of practical, production-ready goal-oriented dialogue systems. In a real-world enterprise setting where dialogue systems are developed rapidly and are expected to work robustly for an ever-growing variety of domains, products, and scenarios, efficient learning from a limited number of examples becomes indispensable. In this paper, we introduce a technique to achieve state-of-the-art dialogue generation performance in a few-shot setup, without using any annotated data. We do this by leveraging background knowledge from a larger, more highly represented dialogue source {---} namely, the MetaLWOz dataset. We evaluate our model on the Stanford Multi-Domain Dialogue Dataset, consisting of human-human goal-oriented dialogues in in-car navigation, appointment scheduling, and weather information domains. We show that our few-shot approach achieves state-of-the art results on that dataset by consistently outperforming the previous best model in terms of BLEU and Entity F1 scores, while being more data-efficient than it by not requiring any data annotation."
W19-5931,Hierarchical Multi-Task Natural Language Understanding for Cross-domain Conversational {AI}: {HERMIT} {NLU},2019,30,1,3,0.784314,10798,andrea vanzo,Proceedings of the 20th Annual SIGdial Meeting on Discourse and Dialogue,0,"We present a new neural architecture for wide-coverage Natural Language Understanding in Spoken Dialogue Systems. We develop a hierarchical multi-task architecture, which delivers a multi-layer representation of sentence meaning (i.e., Dialogue Acts and Frame-like structures). The architecture is a hierarchy of self-attention mechanisms and BiLSTM encoders followed by CRF tagging layers. We describe a variety of experiments, showing that our approach obtains promising results on a dataset annotated with Dialogue Acts and Frame Semantics. Moreover, we demonstrate its applicability to a different, publicly available NLU dataset annotated with domain-specific intents and corresponding semantic roles, providing overall performance higher than state-of-the-art tools such as RASA, Dialogflow, LUIS, and Watson. For example, we show an average 4.45{\%} improvement in entity tagging F-score over Rasa, Dialogflow and LUIS."
D19-1183,Data-Efficient Goal-Oriented Conversation with Dialogue Knowledge Transfer Networks,2019,0,0,4,1,23733,igor shalyminov,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),0,"Goal-oriented dialogue systems are now being widely adopted in industry where it is of key importance to maintain a rapid prototyping cycle for new products and domains. Data-driven dialogue system development has to be adapted to meet this requirement {---} therefore, reducing the amount of data and annotations necessary for training such systems is a central research problem. In this paper, we present the Dialogue Knowledge Transfer Network (DiKTNet), a state-of-the-art approach to goal-oriented dialogue generation which only uses a few example dialogues (i.e. few-shot learning), none of which has to be annotated. We achieve this by performing a 2-stage training. Firstly, we perform unsupervised dialogue representation pre-training on a large source of goal-oriented dialogues in multiple domains, the MetaLWOz corpus. Secondly, at the transfer stage, we train DiKTNet using this representation together with 2 other textual knowledge sources with different levels of generality: ELMo encoder and the main dataset{'}s source domains. Our main dataset is the Stanford Multi-Domain dialogue corpus. We evaluate our model on it in terms of BLEU and Entity F1 scores, and show that our approach significantly and consistently improves upon a series of baseline models as well as over the previous state-of-the-art dialogue generation model, ZSDG. The improvement upon the latter {---} up to 10{\%} in Entity F1 and the average of 3{\%} in BLEU score {---} is achieved using only 10{\%} equivalent of ZSDG{'}s in-domain training data."
W18-5701,Neural Response Ranking for Social Conversation: A Data-Efficient Approach,2018,24,4,3,1,23733,igor shalyminov,Proceedings of the 2018 {EMNLP} Workshop {SCAI}: The 2nd International Workshop on Search-Oriented Conversational {AI},0,"The overall objective of {`}social{'} dialogue systems is to support engaging, entertaining, and lengthy conversations on a wide variety of topics, including social chit-chat. Apart from raw dialogue data, user-provided ratings are the most common signal used to train such systems to produce engaging responses. In this paper we show that social dialogue systems can be trained effectively from raw unannotated data. Using a dataset of real conversations collected in the 2017 Alexa Prize challenge, we developed a neural ranker for selecting {`}good{'} system responses to user utterances, i.e. responses which are likely to lead to long and engaging conversations. We show that (1) our neural ranker consistently outperforms several strong baselines when trained to optimise for user ratings; (2) when trained on larger amounts of data and only using conversation length as the objective, the ranker performs better than the one trained using ratings {--} ultimately reaching a Precision@1 of 0.87. This advance will make data collection for social conversational agents simpler and less expensive in the future."
W17-5524,{VOILA}: An Optimised Dialogue System for Interactively Learning Visually-Grounded Word Meanings (Demonstration System),2017,8,1,3,1,21409,yanchao yu,Proceedings of the 18th Annual {SIG}dial Meeting on Discourse and Dialogue,0,"We present VOILA: an optimised, multi-modal dialogue agent for interactive learning of visually grounded word meanings from a human user. VOILA is: (1) able to learn new visual categories interactively from users from scratch; (2) trained on real human-human dialogues in the same domain, and so is able to conduct natural spontaneous dialogue; (3) optimised to find the most effective trade-off between the accuracy of the visual categories it learns and the cost it incurs to users. VOILA is deployed on Furhat, a human-like, multi-modal robot head with back-projection of the face, and a graphical virtual character."
W17-2802,Learning how to Learn: An Adaptive Dialogue Agent for Incrementally Learning Visually Grounded Word Meanings,2017,26,4,3,1,21409,yanchao yu,Proceedings of the First Workshop on Language Grounding for Robotics,0,"We present an optimised multi-modal dialogue agent for interactive learning of visually grounded word meanings from a human tutor, trained on real human-human tutoring data. Within a life-long interactive learning period, the agent, trained using Reinforcement Learning (RL), must be able to handle natural conversations with human users, and achieve good learning performance (i.e. accuracy) while minimising human effort in the learning process. We train and evaluate this system in interaction with a simulated human tutor, which is built on the BURCHAK corpus {--} a Human-Human Dialogue dataset for the visual learning task. The results show that: 1) The learned policy can coherently interact with the simulated user to achieve the goal of the task (i.e. learning visual attributes of objects, e.g. colour and shape); and 2) it finds a better trade-off between classifier accuracy and tutoring costs than hand-crafted rule-based policies, including ones with dynamic policies."
W17-2811,"Sympathy Begins with a Smile, Intelligence Begins with a Word: Use of Multimodal Features in Spoken Human-Robot Interaction",2017,0,1,4,0.666667,225,jekaterina novikova,Proceedings of the First Workshop on Language Grounding for Robotics,0,"Recognition of social signals, coming from human facial expressions or prosody of human speech, is a popular research topic in human-robot interaction studies. There is also a long line of research in the spoken dialogue community that investigates user satisfaction in relation to dialogue characteristics. However, very little research relates a combination of multimodal social signals and language features detected during spoken face-to-face human-robot interaction to the resulting user perception of a robot. In this paper we show how different emotional facial expressions of human users, in combination with prosodic characteristics of human speech and features of human-robot dialogue, correlate with users{'} impressions of the robot after a conversation. We find that happiness in the user{'}s recognised facial expression strongly correlates with likeability of a robot, while dialogue-related features (such as number of human turns or number of sentences per robot utterance) correlate with perceiving a robot as intelligent. In addition, we show that the facial expression emotional features and prosody are better predictors of human ratings related to perceived robot likeability and anthropomorphism, while linguistic and non-linguistic features more often predict perceived robot intelligence and interpretability. As such, these characteristics may in future be used as an online reward signal for in-situ Reinforcement Learning-based adaptive human-robot dialogue systems."
W17-2001,The {BURCHAK} corpus: a Challenge Data Set for Interactive Learning of Visually Grounded Word Meanings,2017,30,1,4,1,21409,yanchao yu,Proceedings of the Sixth Workshop on Vision and Language,0,"We motivate and describe a new freely available human-human dialogue data set for interactive learning of visually grounded word meanings through ostensive definition by a tutor to a learner. The data has been collected using a novel, character-by-character variant of the DiET chat tool (Healey et al., 2003; anon.) with a novel task, where a Learner needs to learn invented visual attribute words (such as {``}burchak{''} for square) from a tutor. As such, the text-based interactions closely resemble face-to-face conversation and thus contain many of the linguistic phenomena encountered in natural, spontaneous dialogue. These include self- and other-correction, mid-sentence continuations, interruptions, turn overlaps, fillers, hedges and many kinds of ellipsis. We also present a generic n-gram framework for building user (i.e. tutor) simulations from this type of incremental dialogue data, which is freely available to researchers. We show that the simulations produce outputs that are similar to the original data (e.g. 78{\%} turn match similarity). Finally, we train and evaluate a Reinforcement Learning dialogue control agent for learning visually grounded word meanings, trained from the BURCHAK corpus. The learned policy shows comparable performance to a rule-based system built previously."
E17-2077,Evaluating Persuasion Strategies and Deep Reinforcement Learning methods for Negotiation Dialogue agents,2017,8,1,8,1,16749,simon keizer,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 2, Short Papers",0,"In this paper we present a comparative evaluation of various negotiation strategies within an online version of the game {``}Settlers of Catan{''}. The comparison is based on human subjects playing games against artificial game-playing agents ({`}bots{'}) which implement different negotiation dialogue strategies, using a chat dialogue interface to negotiate trades. Our results suggest that a negotiation strategy that uses persuasion, as well as a strategy that is trained from data using Deep Reinforcement Learning, both lead to an improved win rate against humans, compared to previous rule-based and supervised learning baseline dialogue negotiators."
D17-1236,Bootstrapping incremental dialogue systems from minimal data: the generalisation power of dialogue grammars,2017,19,5,3,1,2543,arash eshghi,Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing,0,"We investigate an end-to-end method for automatically inducing task-based dialogue systems from small amounts of unannotated dialogue data. It combines an incremental semantic grammar - Dynamic Syntax and Type Theory with Records (DS-TTR) - with Reinforcement Learning (RL), where language generation and dialogue management are a joint decision problem. The systems thus produced are incremental: dialogues are processed word-by-word, shown previously to be essential in supporting natural, spontaneous dialogue. We hypothesised that the rich linguistic knowledge within the grammar should enable a combinatorially large number of dialogue variations to be processed, even when trained on very few dialogues. Our experiments show that our model can process 74{\%} of the Facebook AI bAbI dataset even when trained on only 0.13{\%} of the data (5 dialogues). It can in addition process 65{\%} of bAbI+, a corpus we created by systematically adding incremental dialogue phenomena such as restarts and self-corrections to bAbI. We compare our model with a state-of-the-art retrieval model, MEMN2N. We find that, in terms of semantic accuracy, the MEMN2N model shows very poor robustness to the bAbI+ transformations even when trained on the full bAbI dataset."
W16-6619,Incremental Generation of Visually Grounded Language in Situated Dialogue (demonstration system),2016,6,1,3,1,21409,yanchao yu,Proceedings of the 9th International Natural Language Generation conference,0,None
W16-6644,Crowd-sourcing {NLG} Data: Pictures Elicit Better Data.,2016,17,15,2,0.666667,225,jekaterina novikova,Proceedings of the 9th International Natural Language Generation conference,0,"Recent advances in corpus-based Natural Language Generation (NLG) hold the promise of being easily portable across domains, but require costly training data, consisting of meaning representations (MRs) paired with Natural Language (NL) utterances. In this work, we propose a novel framework for crowdsourcing high quality NLG training data, using automatic quality control measures and evaluating different MRs with which to elicit data. We show that pictorial MRs result in better NL data being collected than logic-based MRs: utterances elicited by pictorial MRs are judged as significantly more natural, more informative, and better phrased, with a significant increase in average quality ratings (around 0.5 points on a 6-point scale), compared to using the logical MRs. As the MR becomes more complex, the benefits of pictorial stimuli increase. The collected data will be released as part of this submission."
W16-3643,Training an adaptive dialogue policy for interactive learning of visually grounded word meanings,2016,28,15,3,1,21409,yanchao yu,Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"We present a multi-modal dialogue system for interactive learning of perceptually grounded word meanings from a human tutor. The system integrates an incremental, semantic parsing/generation framework - Dynamic Syntax and Type Theory with Records (DS-TTR) - with a set of visual classifiers that are learned throughout the interaction and which ground the meaning representations that it produces. We use this system in interaction with a simulated human tutor to study the effects of different dialogue policies and capabilities on the accuracy of learned meanings, learning rates, and efforts/costs to the tutor. We show that the overall performance of the learning agent is affected by (1) who takes initiative in the dialogues; (2) the ability to express/use their confidence level about visual attributes; and (3) the ability to process elliptical and incrementally constructed dialogue turns. Ultimately, we train an adaptive dialogue policy which optimises the trade-off between classifier accuracy and tutoring costs."
W16-3206,Interactively Learning Visually Grounded Word Meanings from a Human Tutor,2016,7,2,3,1,21409,yanchao yu,Proceedings of the 5th Workshop on Vision and Language,0,None
P16-2043,Natural Language Generation enhances human decision-making with uncertain information,2016,16,1,2,1,5916,dimitra gkatzia,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"Decision-making is often dependent on uncertain data, e.g. data associated with confidence scores or probabilities. We present a comparison of different information presentations for uncertain data and, for the first time, measure their effects on human decision-making. We show that the use of Natural Language Generation (NLG) improves decision-making under uncertainty, compared to state-of-the-art graphical-based representation methods. In a task-based study with 442 adults, we found that presentations using NLG lead to 24% better decision-making on average than the graphical presentations, and to 44% better decision-making when NLG is combined with graphics. We also show that women achieve significantly better results when presented with NLG output (an 87% increase on average compared to graphical presentations)."
W15-4720,A Game-Based Setup for Data Collection and Task-Based Evaluation of Uncertain Information Presentation,2015,6,3,4,1,5916,dimitra gkatzia,Proceedings of the 15th {E}uropean Workshop on Natural Language Generation ({ENLG}),0,"Decision-making is often dependent on uncertain data, e.g. data associated with confidence scores, such as probabilities. A concrete example of such data is weather data. We will demo a game-based setup for exploring the effectiveness of different approaches (graphics vs NLG) to communicating uncertainty in rainfall and temperature predictions (www.macs.hw.ac.uk/ InteractionLab/weathergame/ ). The game incorporates a natural language extension of the MetOffice Weather game1. The extended version of the game can be used in three ways: (1) to compare the effectiveness of different information presentations of uncertain data; (2) to collect data for the development of effective data-driven approaches; and (3) to serve as a task-based evaluation setup for Natural Language Generation (NLG)."
W15-2811,Comparing Attribute Classifiers for Interactive Language Grounding,2015,33,0,3,1,21409,yanchao yu,Proceedings of the Fourth Workshop on Vision and Language,0,"We address the problem of interactively learning perceptually grounded word meanings in a multimodal dialogue system. We design a semantic and visual processing system to support this and illustrate how they can be integrated. We then focus on comparing the performance (Precision, Recall, F1, AUC) of three state-of-the-art attribute classifiers for the purpose of interactive language grounding (MLKNN, DAP, and SVMs), on the aPascal-aYahoo datasets. In prior work, results were presented for object classification using these methods for attribute labelling, whereas we focus on their performance for attribute labelling itself. We find that while these methods can perform well for some of the attributes (e.g. head, ears, furry) none of these models has good performance over the whole attribute set, and none supports incremental learning. This leads us to suggest directions for future work."
W14-4422,Multi-adaptive Natural Language Generation using Principal Component Regression,2014,22,4,3,1,5916,dimitra gkatzia,Proceedings of the 8th International Natural Language Generation Conference ({INLG}),0,"We present FeedbackGen, a system that uses a multi-adaptive approach to Natural Language Generation. With the term xe2x80x98multi-adaptivexe2x80x99, we refer to a system that is able to adapt its content to different user groups simultaneously, in our case adapting to both lecturers and students. We present a novel approach to student feedback generation, which simultaneously takes into account the preferences of lecturers and students when determining the content to be conveyed in a feedback summary. In this framework, we utilise knowledge derived from ratings on feedback summaries by extracting the most relevant features using Principal Component Regression (PCR) analysis. We then model a reward function that is used for training a Reinforcement Learning agent. Our results with students suggest that, from the studentsxe2x80x99 perspective, such an approach can generate more preferable summaries than a purely lecturer-adapted approach."
W14-4308,Learning non-cooperative dialogue behaviours,2014,17,17,2,0,32998,ioannis efstathiou,Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue ({SIGDIAL}),0,"Non-cooperative dialogue behaviour has been identified as important in a variety of application areas, including education, military operations, video games and healthcare. However, it has not been addressed using statistical approaches to dialogue management, which have always been trained for co-operative dialogue. We develop and evaluate a statistical dialogue agent which learns to perform noncooperative dialogue moves in order to complete its own objectives in a stochastic trading game. We show that, when given the ability to perform both cooperative and non-cooperative dialogue moves, such an agent can learn to bluff and to lie so as to win games more often xe2x80x90 against a variety of adversaries, and under various conditions such as risking penalties for being caught in deception. For example, we show that a non-cooperative dialogue agent can learn to win an additional 15.47% of games against a strong rulebased adversary, when compared to an optimised agent which cannot perform noncooperative moves. This work is the first to show how an agent can learn to use noncooperative dialogue to effectively meet its own goals."
W14-4336,The {PARLANCE} mobile application for interactive search in {E}nglish and {M}andarin,2014,3,2,10,0.995663,1049,helen hastie,Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue ({SIGDIAL}),0,We demonstrate a mobile application in English and Mandarin to test and evaluate components of the Parlance dialogue system for interactive search under real-world conditions.
W14-0208,Multi-threaded Interaction Management for Dynamic Spatial Applications,2014,6,2,2,1,38858,srinivasan janarthanam,Proceedings of the {EACL} 2014 Workshop on Dialogue in Motion,0,"We present a multi-threaded Interaction Manager (IM) that is used to track different dimensions of user-system conversations that are required to interleave with each other in a coherent and timely manner. This is explained in the context of a spoken dialogue system for pedestrian navigation and city question-answering, with information push about nearby or visible points-of-interest (PoI)."
P14-1116,Comparing Multi-label Classification with Reinforcement Learning for Summarisation of Time-series Data,2014,35,10,3,1,5916,dimitra gkatzia,Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"We present a novel approach for automatic report generation from time-series data, in the context of student feedback generation. Our proposed methodology treats content selection as a multi-label (ML) classification problem, which takes as input time-series data and outputs a set of templates, while capturing the dependencies between selected templates. We show that this method generates output closer to the feedback that lecturers actually generated, achieving 3.5% higher accuracy and 15% higher F-score than multiple simple classifiers that keep a history of selected templates. Furthermore, we compare a ML classifier with a Reinforcement Learning (RL) approach in simulation and using ratings from real student users. We show that the different methods have different benefits, with ML being more accurate for predicting what was seen in the training data, whereas RL is more exploratory and slightly preferred by the students."
J14-4006,Adaptive Generation in Dialogue Systems Using Dynamic User Modeling,2014,64,20,2,1,38858,srinivasan janarthanam,Computational Linguistics,0,"We address the problem of dynamically modeling and adapting to unknown users in resource-scarce domains in the context of interactive spoken dialogue systems. As an example, we show how a system can learn to choose referring expressions to refer to domain entities for users with different levels of domain expertise, and whose domain knowledge is initially unknown to the system. We approach this problem using a three step process: collecting data using a Wizard-of-Oz method, building simulated users, and learning to model and adapt to users using Reinforcement Learning techniques.n n We show that by using only a small corpus of non-adaptive dialogues and user knowledge profiles it is possible to learn an adaptive user modeling policy using a sense-predict-adapt approach. Our evaluation results show that the learned user modeling and adaptation strategies performed better in terms of adaptation than some simple hand-coded baseline policies, with both simulated and real users. With real users, the learned policy produced around a 20% increase in adaptation in comparison to an adaptive hand-coded baseline. We also show that adaptation to users' domain knowledge results in improving task success (99.47% for the learned policy vs. 84.7% for a hand-coded baseline) and reducing dialogue time of the conversation (11% relative difference). We also compared the learned policy to a variety of carefully hand-crafted adaptive policies that employ the user knowledge profiles to adapt their choices of referring expressions throughout a conversation. We show that the learned policy generalises better to unseen user profiles than these hand-coded policies, while having comparable performance on known user profiles.n n We discuss the overall advantages of this method and how it can be extended to other levels of adaptation such as content selection and dialogue management, and to other domains where adapting to users' domain knowledge is useful, such as travel and healthcare."
E14-4041,Finding middle ground? Multi-objective Natural Language Generation from time-series data,2014,15,6,3,1,5916,dimitra gkatzia,"Proceedings of the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics, volume 2: Short Papers",0,"A Natural Language Generation (NLG) system is able to generate text from nonlinguistic data, ideally personalising the content to a userxe2x80x99s specific needs. In some cases, however, there are multiple stakeholders with their own individual goals, needs and preferences. In this paper, we explore the feasibility of combining the preferences of two different user groups, lecturers and students, when generating summaries in the context of student feedback generation. The preferences of each user group are modelled as a multivariate optimisation function, therefore the task of generation is seen as a multi-objective (MO) optimisation task, where the two functions are combined into one. This initial study shows that treating the preferences of each user group equally smooths the weights of the MO function, in a way that preferred content of the user groups is not presented in the generated summary."
E14-1074,Cluster-based Prediction of User Ratings for Stylistic Surface Realisation,2014,32,15,5,1,26443,nina dethlefs,Proceedings of the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"Surface realisations typically depend on their target style and audience. A challenge in estimating a stylistic realiser from data is that humans vary significantly in their subjective perceptions of linguistic forms and styles, leading to almost no correlation between ratings of the same utterance. We address this problem in two steps. First, we estimate a mapping function between the linguistic features of a corpus of utterances and their human style ratings. Users are partitioned into clusters based on the similarity of their ratings, so that ratings for new utterances can be estimated, even for new, unknown users. In a second step, the estimated model is used to re-rank the outputs of a number of surface realisers to produce stylistically adaptive output. Results confirm that the generated styles are recognisable to human judges and that predictive models based on clusters of users lead to better rating predictions than models based on an average population of users."
W13-4025,A Multithreaded Conversational Interface for Pedestrian Navigation and Question Answering,2013,8,12,2,1,38858,srinivasan janarthanam,Proceedings of the {SIGDIAL} 2013 Conference,0,"We demonstrate a conversational interface that assists pedestrian users in navigating within urban environments and acquiring tourist information by combining spoken dialogue system, question-answering (QA), and geographic information system (GIS) technologies. In contrast to existing mobile applications which treat these problems independently, our Android agent addresses the problem of navigation and touristic question-answering in an integrated fashion using a shared dialogue context with multiple interleaved dialogue threads. In this paper, we present the architecture and features of our latest system, extended from an earlier version which was built and evaluated with real users (Janarthanam et al., 2013). The new features include navigation based on visible landmarks, navigation adapted to the userxe2x80x99s previous route knowledge, and tourist information pushing based on visible and proximal points-of-interest. The system also uses social media to infer xe2x80x9cpopularityxe2x80x9d of geographical entities."
W13-4026,"Demonstration of the {PARLANCE} system: a data-driven incremental, spoken dialogue system for interactive search",2013,6,21,8,1,1049,helen hastie,Proceedings of the {SIGDIAL} 2013 Conference,0,"The Parlance system for interactive search processes dialogue at a microturn level, displaying dialogue phenomena that play a vital role in human spoken conversation. These dialogue phenomena include more natural turn-taking through rapid system responses, generation of backchannels, and user barge-ins. The Parlance demonstration system dierentiates from other incremental systems in that it is data-driven with an infrastructure that scales well."
W13-4036,Training and evaluation of an {MDP} model for social multi-user human-robot interaction,2013,25,24,3,1,16749,simon keizer,Proceedings of the {SIGDIAL} 2013 Conference,0,"This paper describes a new approach to automatic learning of strategies for social multi-user human-robot interaction. Using the example of a robot bartender that tracks multiple customers, takes their orders, and serves drinks, we propose a model consisting of a Social State Recogniser (SSR) which processes audio-visual input and maintains a model of the social state, together with a Social Skills Executor (SSE) which takes social state updates from the SSR as input and generates robot responses as output. The SSE is modelled as two connected Markov Decision Processes (MDPs) with action selection policies that are jointly optimised in interaction with a Multi-User Simulation Environment (MUSE). The SSR and SSE have been integrated in the robot bartender system and evaluated with human users in hand-coded and trained SSE policy variants. The results indicate that the trained policy outperformed the hand-coded policy in terms of both subjective (18%) and objective (10.5%) task success."
W13-4047,Impact of {ASR} N-Best Information on {B}ayesian Dialogue Act Recognition,2013,20,5,4,1,30450,heriberto cuayahuitl,Proceedings of the {SIGDIAL} 2013 Conference,0,"A challenge in dialogue act recognition is the mapping from noisy user inputs to dialogue acts. In this paper we describe an approach for re-ranking dialogue act hypotheses based on Bayesian classifiers that incorporate dialogue history and Automatic Speech Recognition (ASR) N-best information. We report results based on the Letxe2x80x99s Go dialogue corpora that show (1) that including ASR N-best information results in improved dialogue act recognition performance (7% accuracy), and (2) that competitive results can be obtained from as early as the first system dialogue act, reducing the need to wait for subsequent system dialogue acts."
W13-4067,A Simple and Generic Belief Tracking Mechanism for the Dialog State Tracking Challenge: On the believability of observed information,2013,14,91,2,1,29490,zhuoran wang,Proceedings of the {SIGDIAL} 2013 Conference,0,"This paper presents a generic dialogue state tracker that maintains beliefs over user goals based on a few simple domainindependent rules, using basic probability operations. The rules apply to observed system actions and partially observable user acts, without using any knowledge obtained from external resources (i.e. without requiring training data). The core insight is to maximise the amount of information directly gainable from an errorprone dialogue itself, so as to better lowerbound onexe2x80x99s expectations on the performance of more advanced statistical techniques for the task. The proposed method is evaluated in the Dialog State Tracking Challenge, where it achieves comparable performance in hypothesis accuracy to machine learning based systems. Consequently, with respect to different scenarios for the belief tracking problem, the potential superiority and weakness of machine learning approaches in general are investigated."
W13-2115,Generating Student Feedback from Time-Series Data Using Reinforcement Learning,2013,24,12,4,1,5916,dimitra gkatzia,Proceedings of the 14th {E}uropean Workshop on Natural Language Generation,0,"We describe a statistical Natural Language Generation (NLG) method for summarisation of time-series data in the context of feedback generation for students. In this paper, we initially present a method for collecting time-series data from students (e.g. marks, lectures attended) and use example feedback from lecturers in a datadriven approach to content selection. We show a novel way of constructing a reward function for our Reinforcement Learning agent that is informed by the lecturersxe2x80x99 method of providing feedback. We evaluate our system with undergraduate students by comparing it to three baseline systems: a rule-based system, lecturerconstructed summaries and a Brute Force system. Our evaluation shows that the feedback generated by our learning agent is viewed by students to be as good as the feedback from the lecturers. Our findings suggest that the learning agent needs to take into account both the student and lecturersxe2x80x99 preferences."
P13-1123,Conditional Random Fields for Responsive Surface Realisation using Global Features,2013,25,21,4,1,26443,nina dethlefs,Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"Surface realisers in spoken dialogue systems need to be more responsive than conventional surface realisers. They need to be sensitive to the utterance context as well as robust to partial or changing generator inputs. We formulate surface realisation as a sequence labelling task and combine the use of conditional random fields (CRFs) with semantic trees. Due to their extended notion of context, CRFs are able to take the global utterance context into account and are less constrained by local features than other realisers. This leads to more natural and less repetitive surface realisation. It also allows generation from partial and modified inputs and is therefore applicable to incremental surface realisation. Results from a human rating study confirm that users are sensitive to this extended notion of context and assign ratings that are significantly higher (up to 14%) than those for taking only local context into account."
P13-1163,Evaluating a City Exploration Dialogue System with Integrated Question-Answering and Pedestrian Navigation,2013,14,6,2,1,38858,srinivasan janarthanam,Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,None
W12-1808,Incremental Spoken Dialogue Systems: Tools and Data,2012,8,4,2,1,1049,helen hastie,{NAACL}-{HLT} Workshop on Future directions and needs in the Spoken Dialog Community: Tools and Data ({SDCTD} 2012),0,"Strict-turn taking models of dialogue do not accurately model human incremental processing, where users can process partial input and plan partial utterances in parallel. We discuss the current state of the art in incremental systems and propose tools and data required for further advances in the field of Incremental Spoken Dialogue Systems."
W12-1619,"Integrating Location, Visibility, and Question-Answering in a Spoken Dialogue System for Pedestrian City Exploration",2012,11,19,2,1,38858,srinivasan janarthanam,Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"We demonstrate a spoken dialogue-based information system for pedestrians. The system is novel in combining geographic information system (GIS) modules such as a visibility engine with a question-answering (QA) system, integrated within a dialogue system architecture. Users of the demonstration system can use a web-based version (simulating pedestrian movement using StreetView) to engage in a variety of interleaved conversations such as navigating from A to B, using the QA functionality to learn more about points of interest (PoI) nearby, and searching for amenities and tourist attractions. This system explores a variety of research questions involving the integration of multiple information sources within conversational interaction."
W12-1509,Optimising Incremental Generation for Spoken Dialogue Systems: Reducing the Need for Fillers,2012,23,16,4,1,26443,nina dethlefs,{INLG} 2012 Proceedings of the Seventh International Natural Language Generation Conference,0,"Recent studies have shown that incremental systems are perceived as more reactive, natural, and easier to use than non-incremental systems. However, previous work on incremental NLG has not employed recent advances in statistical optimisation using machine learning. This paper combines the two approaches, showing how the update, revoke and purge operations typically used in incremental approaches can be implemented as state transitions in a Markov Decision Process. We design a model of incremental NLG that generates output based on micro-turn interpretations of the user's utterances and is able to optimise its decisions using statistical machine learning. We present a proof-of-concept study in the domain of Information Presentation (IP), where a learning agent faces the trade-off of whether to present information as soon as it is available (for high reactiveness) or else to wait until input ASR hypotheses are more reliable. Results show that the agent learns to avoid long waiting times, fillers and self-corrections, by re-ordering content based on its confidence."
P12-3009,A Web-based Evaluation Framework for Spatial Instruction-Giving Systems,2012,15,10,2,1,38858,srinivasan janarthanam,Proceedings of the {ACL} 2012 System Demonstrations,0,"We demonstrate a web-based environment for development and testing of different pedestrian route instruction-giving systems. The environment contains a City Model, a TTS interface, a game-world, and a user GUI including a simulated street-view. We describe the environment and components, the metrics that can be used for the evaluation of pedestrian route instruction-giving systems, and the shared challenge which is being organised using this environment."
E12-2010,A Statistical Spoken Dialogue System using Complex User Goals and Value Directed Compression,2012,8,2,4,1,1462,paul crook,Proceedings of the Demonstrations at the 13th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"This paper presents the first demonstration of a statistical spoken dialogue system that uses automatic belief compression to reason over complex user goal sets. Reasoning over the power set of possible user goals allows complex sets of user goals to be represented, which leads to more natural dialogues. The use of the power set results in a massive expansion in the number of belief states maintained by the Partially Observable Markov Decision Process (POMDP) spoken dialogue manager. A modified form of Value Directed Compression (VDC) is applied to the POMDP belief states producing a near-lossless compression which reduces the number of bases required to represent the belief distribution."
D12-1008,Optimising Incremental Dialogue Decisions Using Information Density for Interactive Systems,2012,37,30,4,1,26443,nina dethlefs,Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,0,"Incremental processing allows system designers to address several discourse phenomena that have previously been somewhat neglected in interactive systems, such as backchannels or barge-ins, but that can enhance the responsiveness and naturalness of systems. Unfortunately, prior work has focused largely on deterministic incremental decision making, rendering system behaviour less flexible and adaptive than is desirable. We present a novel approach to incremental decision making that is based on Hierarchical Reinforcement Learning to achieve an interactive optimisation of Information Presentation (IP) strategies, allowing the system to generate and comprehend backchannels and barge-ins, by employing the recent psycholinguistic hypothesis of information density (ID) (Jaeger, 2010). Results in terms of average rewards and a human rating study show that our learnt strategy outperforms several baselines that are not sensitive to ID by more than 23%."
W11-2801,Talkin{'} bout a revolution (statistically speaking) [Invited Talk],2011,7,0,1,1,2551,oliver lemon,Proceedings of the 13th {E}uropean Workshop on Natural Language Generation,0,"This talk will describe new methods for generating Natural Language in interactive systems -- methods which are similar to planning approaches, but which use statistical machine learning to develop adaptive NLG components. Employing statistical models of users, generation contexts, and of Natural Languages themselves, has several potentially beneficial features: the ability to train models on real data, the availability of precise mathematical methods for optimisation, and the capacity to adapt robustly to previously unseen situations. Rather than emulating human behaviour in generation (which can be sub-optimal) these methods can even find strategies for NLG which improve upon human performance."
W11-2813,Adaptive Information Presentation for Spoken Dialogue Systems: Evaluation with real users,2011,26,15,3,1,6289,verena rieser,Proceedings of the 13th {E}uropean Workshop on Natural Language Generation,0,"We present evaluation results with human subjects for a novel data-driven approach to Natural Language Generation in spoken dialogue systems. We evaluate a trained Information Presentation (IP) strategy in a deployed tourist-information spoken dialogue system. The IP problem is formulated as statistical decision making under uncertainty using Reinforcement Learning, where both content planning and attribute selection are jointly optimised based on data collected in a Wizard-of-Oz study. After earlier work testing and training this model in simulation, we now present results from an extensive online user study, involving 131 users and more than 800 test dialogues, which explores its contribution to overall 'global' task success. We find that the trained Information Presentation strategy significantly improves dialogue task completion, with up to a 9.7% increase (30% relative) compared to the deployed dialogue system which uses conventional, hand-coded presentation prompts. We also present subjective evaluation results and discuss the implications of these results for future work in dialogue management and NLG."
W11-2830,The {GRUVE} Challenge: Generating Routes under Uncertainty in Virtual Environments,2011,12,12,2,0,44157,srini janarthanam,Proceedings of the 13th {E}uropean Workshop on Natural Language Generation,0,"We propose a shared task based around generation of instructions for pedestrian users navigating in open-world virtual environments. An important variant of this task involves handling uncertainty about the user's location (as would happen in the real world with a standard GPS system). We motivate and explain the task, propose metrics for evaluation of systems, describe the planned software setup, and propose a timeline for the challenge."
W11-2002,Spoken Dialog Challenge 2010: Comparison of Live and Control Test Results,2011,8,49,6,0,4130,alan black,Proceedings of the {SIGDIAL} 2011 Conference,0,"The Spoken Dialog Challenge 2010 was an exercise to investigate how different spoken dialog systems perform on the same task. The existing Let's Go Pittsburgh Bus Information System was used as a task and four teams provided systems that were first tested in controlled conditions with speech researchers as users. The three most stable systems were then deployed to real callers. This paper presents the results of the live tests, and compares them with the control test results. Results show considerable variation both between systems and between the control and live tests. Interestingly, relatively high task completion for controlled tests did not always predict relatively high task completion for live tests. Moreover, even though the systems were quite different in their designs, we saw very similar correlations between word error rate and task completion for all the systems. The dialog data collected is available to the research community."
W11-2017,{``}The day after the day after tomorrow?{''} A machine learning approach to adaptive temporal expression generation: training and evaluation with real users,2011,15,18,3,1,38858,srinivasan janarthanam,Proceedings of the {SIGDIAL} 2011 Conference,0,"Generating Temporal Expressions (TE) that are easy to understand, unambiguous, and reasonably short is a challenge for humans and Spoken Dialogue Systems. Rather than developing hand-written decision rules, we adopt a data-driven approach by collecting user feedback on a variety of possible TEs in terms of task success, ambiguity, and user preference. The data collected in this work is freely available to the research community. These data were then used to train a simulated user and a reinforcement learning policy that learns an adaptive Temporal Expression generation strategy for a variety of contexts. We evaluate our learned policy both in simulation and with real users and show that this data-driven adaptive policy is a significant improvement over a rule-based adaptive policy, leading to a 24% increase in perceived task completion, while showing a small increase in actual task completion, and a 16% decrease in call duration. This means that dialogues are more efficient and that users are also more confident about the appointment that they have agreed with the system."
J11-1006,Learning and Evaluation of Dialogue Strategies for New Applications: Empirical Methods for Optimization from Small Data Sets,2011,81,32,2,1,6289,verena rieser,Computational Linguistics,0,"We present a new data-driven methodology for simulation-based dialogue strategy learning, which allows us to address several problems in the field of automatic optimization of dialogue strategies: learning effective dialogue strategies when no initial data or system exists, and determining a data-driven reward function. In addition, we evaluate the result with real users, and explore how results transfer between simulated and real interactions. We use Reinforcement Learning (RL) to learn multimodal dialogue strategies by interaction with a simulated environment which is bootstrapped from small amounts of Wizard-of-Oz (WOZ) data. This use of WOZ data allows data-driven development of optimal strategies for domains where no working prototype is available. Using simulation-based RL allows us to find optimal policies which are not (necessarily) present in the original data. Our results show that simulation-based RL significantly outperforms the average (human wizard) strategy as learned from the data by using Supervised Learning. The bootstrapped RL-based policy gains on average 50 times more reward when tested in simulation, and almost 18 times more reward when interacting with real users. Users also subjectively rate the RL-based policy on average 10% higher. We also show that results from simulated interaction do transfer to interaction with real users, and we explicitly evaluate the stability of the data-driven reward function."
W10-4324,Adaptive Referring Expression Generation in Spoken Dialogue Systems: Evaluation with Real Users,2010,26,17,2,1,38858,srinivasan janarthanam,Proceedings of the {SIGDIAL} 2010 Conference,0,"We present new results from a real-user evaluation of a data-driven approach to learning user-adaptive referring expression generation (REG) policies for spoken dialogue systems. Referring expressions can be difficult to understand in technical domains where users may not know the technical 'jargon' names of the domain entities. In such cases, dialogue systems must be able to model the user's (lexical) domain knowledge and use appropriate referring expressions. We present a reinforcement learning (RL) framework in which the system learns REG policies which can adapt to unknown users online. For real users of such a system, we show that in comparison to an adaptive hand-coded baseline policy, the learned policy performs significantly better, with a 20.8% average increase in adaptation accuracy, 12.6% decrease in time taken, and a 15.1% increase in task completion rate. The learned policy also has a significantly better subjective rating from users. This is because the learned policies adapt online to changing evidence about the user's domain expertise. We also discuss the issue of evaluation in simulation versus evaluation with real users."
W10-4336,Representing Uncertainty about Complex User Goals in Statistical Dialogue Systems,2010,12,12,2,1,1462,paul crook,Proceedings of the {SIGDIAL} 2010 Conference,0,"We point out several problems in scaling-up statistical approaches to spoken dialogue systems to enable them to deal with complex but natural user goals, such as disjunctive and negated goals and preferences. In particular, we explore restrictions imposed by current independence assumptions in POMDP dialogue models. This position paper proposes the use of Automatic Belief Compression methods to remedy these problems."
W10-4235,Generation Under Uncertainty,2010,22,6,1,1,2551,oliver lemon,Proceedings of the 6th International Natural Language Generation Conference,0,"We invite the research community to consider challenges for NLG which arise from uncertainty. NLG systems should be able to adapt to their audience and the generation environment in general, but often the important features for adaptation are not known precisely. We explore generation challenges which could employ simulated environments to study NLG which is adaptive under uncertainty, and suggest possible metrics for such tasks. It would be particularly interesting to explore how different planning approaches to NLG perform in challenges involving uncertainty in the generation environment."
P10-1008,Learning to Adapt to Unknown Users: Referring Expression Generation in Spoken Dialogue Systems,2010,28,33,2,1,38858,srinivasan janarthanam,Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,1,"We present a data-driven approach to learn user-adaptive referring expression generation (REG) policies for spoken dialogue systems. Referring expressions can be difficult to understand in technical domains where users may not know the technical 'jargon' names of the domain entities. In such cases, dialogue systems must be able to model the user's (lexical) domain knowledge and use appropriate referring expressions. We present a reinforcement learning (RL) framework in which the system learns REG policies which can adapt to unknown users online. Furthermore, unlike supervised learning methods which require a large corpus of expert adaptive behaviour to train on, we show that effective adaptive policies can be learned from a small dialogue corpus of non-adaptive human-machine interaction, by using a RL framework and a statistical user simulation. We show that in comparison to adaptive hand-coded baseline policies, the learned policy performs significantly better, with an 18.6% average increase in adaptation accuracy. The best learned policy also takes less dialogue time (average 1.07 min less) than the best hand-coded policy. This is because the learned policies can adapt online to changing evidence about the user's domain expertise."
P10-1103,Optimising Information Presentation for Spoken Dialogue Systems,2010,35,34,2,1,6289,verena rieser,Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,1,"We present a novel approach to Information Presentation (IP) in Spoken Dialogue Systems (SDS) using a data-driven statistical optimisation framework for content planning and attribute selection. First we collect data in a Wizard-of-Oz (WoZ) experiment and use it to build a supervised model of human behaviour. This forms a baseline for measuring the performance of optimised policies, developed from this data using Reinforcement Learning (RL) methods. We show that the optimised policies significantly outperform the baselines in a variety of generation scenarios: while the supervised model is able to attain up to 87.6% of the possible reward on this task, the RL policies are significantly better in 5 out of 6 scenarios, gaining up to 91.5% of the total possible reward. The RL policies perform especially well in more complex scenarios. We are also the first to show that adding predictive lower level features (e.g. from the NLG realiser) is important for optimising IP strategies according to user preferences. This provides new insights into the nature of the IP problem for SDS."
W09-3916,A Two-Tier User Simulation Model for Reinforcement Learning of Adaptive Referring Expression Generation Policies,2009,13,18,2,1,38858,srinivasan janarthanam,Proceedings of the {SIGDIAL} 2009 Conference,0,"We present a new two-tier user simulation model for learning adaptive referring expression generation (REG) policies for spoken dialogue systems using reinforcement learning. Current user simulation models that are used for dialogue policy learning do not simulate users with different levels of domain expertise and are not responsive to referring expressions used by the system. The two-tier model displays these features, that are crucial to learning an adaptive REG policy. We also show that the two-tier model simulates real user behaviour more closely than other baseline models, using the dialogue similarity measure based on Kullback-Leibler divergence."
W09-3922,"Automatic Generation of Information State Update Dialogue Systems that Dynamically Create Voice {XML}, as Demonstrated on the i{P}hone",2009,5,4,3,1,1049,helen hastie,Proceedings of the {SIGDIAL} 2009 Conference,0,"We demonstrate DUDE (Dialogue and Understanding Development Environment), a prototype development environment that automatically generates dialogue systems from business-user resources and databases. These generated spoken dialogue systems (SDS) are then deployed on an industry standard Voice XML platform. Specifically, the deployed system works by dynamically generating context-sensitive Voice XML pages. The dialogue move of each page is determined in real time by the dialogue manager, which is an Information State Update engine. Firstly, we will demonstrate the development environment which includes automatic generation of speech recognition grammars for robust interpretation of spontaneous speech, and uses the application database to generate lexical entries and grammar rules. A simple graphical interface allows users (i.e. developers) to easily and quickly create and the modify SDS without the need for expensive service providers. Secondly, we will demonstrate the deployed system which enables participants to call up and speak to the SDS recently created. We will also show a pre-built application running on the iPhone and Google Android phone for searching for places such as restaurants, hotels and museums."
W09-0611,Learning Lexical Alignment Policies for Generating Referring Expressions for Spoken Dialogue Systems,2009,19,23,2,1,38858,srinivasan janarthanam,Proceedings of the 12th {E}uropean Workshop on Natural Language Generation ({ENLG} 2009),0,"We address the problem that different users have different lexical knowledge about problem domains, so that automated dialogue systems need to adapt their generation choices online to the users' domain knowledge as it encounters them. We approach this problem using policy learning in Markov Decision Processes (MDP). In contrast to related work we propose a new statistical user model which incorporates the lexical knowledge of different users. We evaluate this user model by showing that it allows us to learn dialogue policies that automatically adapt their choice of referring expressions online to different users, and that these policies are significantly better than adaptive hand-coded policies for this problem. The learned policies are consistently between 2 and 8 turns shorter than a range of different hand-coded but adaptive baseline lexical alignment policies."
W09-0614,A {W}izard-of-{O}z Environment to Study Referring Expression Generation in a Situated Spoken Dialogue Task,2009,5,17,2,1,38858,srinivasan janarthanam,Proceedings of the 12th {E}uropean Workshop on Natural Language Generation ({ENLG} 2009),0,We present a Wizard-of-Oz environment for data collection on Referring Expression Generation (REG) in a real situated spoken dialogue task. The collected data will be used to build user simulation models for reinforcement learning of referring expression generation strategies.
E09-1058,User Simulations for Context-Sensitive Speech Recognition in Spoken Dialogue Systems,2009,18,23,1,1,2551,oliver lemon,Proceedings of the 12th Conference of the {E}uropean Chapter of the {ACL} ({EACL} 2009),0,"We use a machine learner trained on a combination of acoustic and contextual features to predict the accuracy of incoming n-best automatic speech recognition (ASR) hypotheses to a spoken dialogue system (SDS). Our novel approach is to use a simple statistical User Simulation (US) for this task, which measures the likelihood that the user would say each hypothesis in the current context. Such US models are now common in machine learning approaches to SDS, are trained on real dialogue data, and are related to theories of alignment in psycholinguistics. We use a US to predict the user's next dialogue move and thereby re-rank n-best hypotheses of a speech recognizer for a corpus of 2564 user utterances. The method achieved a significant relative reduction of Word Error Rate (WER) of 5% (this is 44% of the possible WER improvement on this data), and 62% of the possible semantic improvement (Dialogue Move Accuracy), compared to the baseline policy of selecting the topmost ASR hypothesis. The majority of the improvement is attributable to the User Simulation feature, as shown by Information Gain analysis."
E09-1078,Natural Language Generation as Planning Under Uncertainty for Spoken Dialogue Systems,2009,37,66,2,1,6289,verena rieser,Proceedings of the 12th Conference of the {E}uropean Chapter of the {ACL} ({EACL} 2009),0,"We present and evaluate a new model for Natural Language Generation (NLG) in Spoken Dialogue Systems, based on statistical planning, given noisy feedback from the current generation context (e.g. a user and a surface realiser). We study its use in a standard NLG problem: how to present information (in this case a set of search results) to users, given the complex tradeoffs between utterance length, amount of information conveyed, and cognitive load. We set these trade-offs by analysing existing match data. We then train a NLG policy using Reinforcement Learning (RL), which adapts its behaviour to noisy feedback from the current generation context. This policy is compared to several baselines derived from previous work in this area. The learned policy significantly outperforms all the prior approaches."
P08-2019,Mixture Model {POMDP}s for Efficient Handling of Uncertainty in Dialogue Management,2008,10,38,2,0,856,james henderson,"Proceedings of ACL-08: HLT, Short Papers",0,"In spoken dialogue systems, Partially Observable Markov Decision Processes (POMDPs) provide a formal framework for making dialogue management decisions under uncertainty, but efficiency and interpretability considerations mean that most current statistical dialogue managers are only MDPs. These MDP systems encode uncertainty explicitly in a single state representation. We formalise such MDP states in terms of distributions over POMDP states, and propose a new dialogue system architecture (Mixture Model POMDPs) which uses mixtures of these distributions to efficiently represent uncertainty. We also provide initial evaluation results (with real users) for this architecture."
P08-1073,Learning Effective Multimodal Dialogue Strategies from {W}izard-of-{O}z Data: Bootstrapping and Evaluation,2008,32,67,2,1,6289,verena rieser,Proceedings of ACL-08: HLT,1,"We address two problems in the field of automatic optimization of dialogue strategies: learning effective dialogue strategies when no initial data or system exists, and evaluating the result with real users. We use Reinforcement Learning (RL) to learn multimodal dialogue strategies by interaction with a simulated environment which is xe2x80x9cbootstrappedxe2x80x9d from small amounts of Wizard-of-Oz (WOZ) data. This use of WOZ data allows development of optimal strategies for domains where no working prototype is available. We compare the RL-based strategy against a supervised strategy which mimics the wizardsxe2x80x99 policies. This comparison allows us to measure relative improvement over the training data. Our results show that RL significantly outperforms Supervised Learning when interacting in simulation as well as for interactions with real users. The RL-based policy gains on average 50-times more reward when tested in simulation, and almost 18-times more reward when interacting with real users. Users also subjectively rate the RL-based policy on average 10% higher."
rieser-lemon-2008-automatic,Automatic Learning and Evaluation of User-Centered Objective Functions for Dialogue System Optimisation,2008,15,14,2,1,6289,verena rieser,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"The ultimate goal when building dialogue systems is to satisfy the needs of real users, but quality assurance for dialogue strategies is a non-trivial problem. The applied evaluation metrics and resulting design principles are often obscure, emerge by trial-and-error, and are highly context dependent. This paper introduces data-driven methods for obtaining reliable objective functions for system design. In particular, we test whether an objective function obtained from Wizard-of-Oz (WOZ) data is a valid estimate of real usersÂ preferences. We test this in a test-retest comparison between the model obtained from the WOZ study and the models obtained when testing with real users. We can show that, despite a low fit to the initial data, the objective function obtained from WOZ data makes accurate predictions for automatic dialogue evaluation, and, when automatically optimising a policy using these predictions, the improvement over a strategy simply mimicking the data becomes clear from an error analysis."
J08-4002,Hybrid Reinforcement/Supervised Learning of Dialogue Policies from Fixed Data Sets,2008,46,87,2,0,856,james henderson,Computational Linguistics,0,"We propose a method for learning dialogue management policies from a fixed data set. The method addresses the challenges posed by Information State Update (ISU)-based dialogue systems, which represent the state of a dialogue as a large set of features, resulting in a very large state space and a huge policy space. To address the problem that any fixed data set will only provide information about small portions of these state and policy spaces, we propose a hybrid model that combines reinforcement learning with supervised learning. The reinforcement learning is used to optimize a measure of dialogue reward, while the supervised learning is used to restrict the learned policy to the portions of these spaces for which we have data. We also use linear function approximation to address the need to generalize from a fixed amount of data to large state spaces. To demonstrate the effectiveness of this method on this challenging task, we trained this model on the COMMUNICATOR corpus, to which we have added annotations for user actions and Information States. When tested with a user simulation trained on a different part of the same data set, our hybrid model outperforms a pure supervised learning model and a pure reinforcement learning model. It also outperforms the hand-crafted systems on the COMMUNICATOR data, according to automatic evaluation measures, improving over the average COMMUNICATOR system policy by 10%. The proposed method will improve techniques for bootstrapping and automatic optimization of dialogue management policies from limited initial data sets."
C08-3005,{``}Build Your Own{''} Spoken Dialogue Systems: Automatically Generating {ISU} Dialogue Systems from Business User Resources,2008,7,2,1,1,2551,oliver lemon,Coling 2008: Companion volume: Demonstrations,0,"Building effective spoken dialogue systems (SDS) is currently a complex task requiring expert knowledge. Our tools give control of SDS application development to non-experts, who need only use a Graphical User Interface or GUI to develop state-of-the-art Information State Update (ISU) dialogue systems. Behind the GUI is a set of Advanced Dialogue Tools (ADT) that generate complete SDS based on Business User Resources. These resources include a database and a Process Model that captures the structure of an application, for example, banking or restaurant information. Also generated are speech recognition Language Models and grammars for robust interpretation of spontaneous speech. We will demonstrate how our simple GUI allows developers to easily and quickly create and modify SDS without the need for expensive speech application service providers. This demonstration shows the interface, the ADT components, and discusses some of the research issues involved. We also show an example application built with the tools: a tourist information system running on an ultra-mobile PC."
2007.sigdial-1.11,Dialogue Policy Learning for Combinations of Noise and User Simulation: Transfer Results,2007,11,15,1,1,2551,oliver lemon,Proceedings of the 8th SIGdial Workshop on Discourse and Dialogue,0,"Once a dialogue strategy has been learned for a particular set of conditions, we need to know how well it will perform when deployed in different conditions to those it was specifically trained for, i.e. how robust it is in transfer to different conditions. We first present novel learning results for different ASR noise models combined with different user simulations. We then show that policies trained in high-noise conditions perform significantly better than those trained for lownoise conditions, even when deployed in low-noise environments."
P06-2085,Using Machine Learning to Explore Human Multimodal Clarification Strategies,2006,17,28,2,1,6289,verena rieser,Proceedings of the {COLING}/{ACL} 2006 Main Conference Poster Sessions,0,"We investigate the use of machine learning in combination with feature engineering techniques to explore human multimodal clarification strategies and the use of those strategies for dialogue systems. We learn from data collected in a Wizard-of-Oz study where different wizards could decide whether to ask a clarification request in a multimodal manner or else use speech alone. We show that there is a uniform strategy across wizards which is based on multiple features in the context. These are generic runtime features which can be implemented in dialogue systems. Our prediction models achieve a weighted f-score of 85.3% (which is a 25.5% improvement over a one-rule baseline). To assess the effects of models, feature discretisation, and selection, we also conduct a regression analysis. We then interpret and discuss the use of the learnt strategy for dialogue systems. Throughout the investigation we discuss the issues arising from using small initial Wizard-of-Oz data sets, and we show that feature engineering is an essential step when learning from such limited data."
P06-1024,Learning More Effective Dialogue Strategies Using Limited Dialogue Move Features,2006,15,39,2,0,45102,matthew frampton,Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,1,"We explore the use of restricted dialogue contexts in reinforcement learning (RL) of effective dialogue strategies for information seeking spoken dialogue systems (e.g. COMMUNICATOR (Walker et al., 2001)). The contexts we use are richer than previous research in this area, e.g. (Levin and Pieraccini, 1997; Scheffler and Young, 2001; Singh et al., 2002; Pietquin, 2004), which use only slot-based information, but are much less complex than the full dialogue Information States explored in (Henderson et al., 2005), for which tractabe learning is an issue. We explore how incrementally adding richer features allows learning of more effective dialogue strategies. We use 2 user simulations learned from COMMUNICATOR data (Walker et al., 2001; Georgila et al., 2005b) to explore the effects of different features on learned dialogue strategies. Our results show that adding the dialogue moves of the last system and user turns increases the average reward of the automatically learned strategies by 65.9% over the original (hand-coded) COMMUNICATOR systems, and by 7.8% over a baseline RL policy that uses only slot-status features. We show that the learned strategies exhibit an emergent focus switching strategy and effective use of the 'give help' action."
N06-2044,Evolving optimal inspectable strategies for spoken dialogue systems,2006,9,10,3,0,48266,dave toney,"Proceedings of the Human Language Technology Conference of the {NAACL}, Companion Volume: Short Papers",0,We report on a novel approach to generating strategies for spoken dialogue systems. We present a series of experiments that illustrate how an evolutionary reinforcement learning algorithm can produce strategies that are both optimal and easily inspectable by human developers. Our experimental strategies achieve a mean performance of 98.9% with respect to a predefined evaluation metric. Our approach also produces a dramatic reduction in strategy size when compared with conventional reinforcement learning techniques (87% in one experiment). We conclude that this algorithm can be used to evolve optimal inspectable dialogue strategies.
E06-2004,"{DUDE}: A Dialogue and Understanding Development Environment, Mapping Business Process Models to Information State Update Dialogue Systems",2006,11,20,1,1,2551,oliver lemon,Demonstrations,0,"We demonstrate a new development environment Information State Update dialogue systems which allows non-expert developers to produce complete spoken dialogue systems based only on a Business Process Model (BPM) describing their application (e.g. banking, cinema booking, shopping, restaurant information). The environment includes automatic generation of Grammatical Framework (GF) grammars for robust interpretation of spontaneous speech, and uses application databases to generate lexical entries and grammar rules. The GF grammar is compiled to an ATK or Nuance language model for speech recognition. The demonstration system allows users to create and modify spoken dialogue systems, starting with a definition of a Business Process Model and ending with a working system. This paper describes the environment, its main components, and some of the research issues involved in its development."
E06-2009,An {ISU} Dialogue System Exhibiting Reinforcement Learning of Dialogue Policies: Generic Slot-Filling in the {TALK} In-car System,2006,5,78,1,1,2551,oliver lemon,Demonstrations,0,"We demonstrate a multimodal dialogue system using reinforcement learning for in-car scenarios, developed at Edinburgh University and Cambridge University for the TALK project. This prototype is the first Information State Update (ISU) dialogue system to exhibit reinforcement learning of dialogue strategies, and also has a fragmentary clarification feature. This paper describes the main components and functionality of the system, as well as the purposes and future use of the system, and surveys the research issues involved in its construction. Evaluation of this system (i.e. comparing the baseline system with handcoded vs. learnt dialogue policies) is ongoing, and the demonstration will show both."
2005.sigdial-1.11,A Corpus Collection and Annotation Framework for Learning Multimodal Clarification Strategies,2005,13,36,3,1,6289,verena rieser,Proceedings of the 6th SIGdial Workshop on Discourse and Dialogue,0,Current dialogue systems are fairly poor in generating the wide range of clarification strategies as found in human-human dialogue. The overall aim of this work is to learn when and how to best employ different types of clarification strategies in multimodal dialogue systems. This paper describes a framework for learning multimodal clarification strategies for an in-car MP3 music player dialogue system. The framework consists of three major parts. First we collect data on multimodal clarification strategies in a wizard-of-oz study. Second we extract feature in the stateaction space to learn an initial policy from this data. Third we specify a reward function to refine that policy using extensions of existing evaluation schemes.
P04-1044,Combining Acoustic and Pragmatic Features to Predict Recognition Performance in Spoken Dialogue Systems,2004,14,61,2,0,51434,malte gabsdil,Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics ({ACL}-04),1,We use machine learners trained on a combination of acoustic confidence and pragmatic plausibility features computed from dialogue context to predict the accuracy of incoming n-best recognition hypotheses to a spoken dialogue system. Our best results show a 25% weighted f-score improvement over a baseline system that implements a grammar-switching approach to context-sensitive speech recognition.
W03-2709,Multi-Level Architecture for Natural Activity-Oriented Dialogue,2003,0,0,1,1,2551,oliver lemon,"Proceedings of the 2003 {EACL} Workshop on Dialogue Systems: interaction, adaptation and styes of management",0,None
W03-2114,Managing Dialogue Interaction: A Multi-Layered Approach,2003,13,22,1,1,2551,oliver lemon,Proceedings of the Fourth {SIG}dial Workshop of Discourse and Dialogue,0,None
W03-2123,{DIPPER}: Description and Formalisation of an Information-State Update Dialogue System Architecture,2003,17,122,3,0,6245,johan bos,Proceedings of the Fourth {SIG}dial Workshop of Discourse and Dialogue,0,None
E03-1075,Targeted Help for Spoken Dialogue Systems,2003,3,4,2,0,46954,beth hockey,10th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,None
W02-0216,Multi-tasking and Collaborative Activities in Dialogue Systems,2002,14,43,1,1,2551,oliver lemon,Proceedings of the Third {SIG}dial Workshop on Discourse and Dialogue,0,"We explain dialogue management techniques for collaborative activities with humans, involving multiple concurrent tasks. Conversational context for multiple concurrent activities is represented using a Dialogue Move Tree and an Activity Tree which support multiple interleaved threads of dialogue about different activities and their execution status. We also describe the incremental message selection, aggregation, and generation method employed in the system."
W02-0217,Probabilistic Dialogue Modelling,2002,5,5,1,1,2551,oliver lemon,Proceedings of the Third {SIG}dial Workshop on Discourse and Dialogue,0,"We show how Bayesian networks and related probabilistic methods provide an efficient way of capturing the complex balancing of different factors that determine interpretation and generation in dialogue. As a case study, we show how a probabilistic approach can be used to model anaphora resolution in dialogue."
lemon-gruenstein-2002-language,Language Resources for Multi-Modal Dialogue Systems.,2002,34,0,1,1,2551,oliver lemon,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"This paper reviews a resource base of software agents for hub-based architectures, which can be used generally for advanced dialogue systems research and deployment. The problem of domain-specificity of dialogue managers is discussed, and we describe an approach to it developed at CSLI, involving a domain-general dialogue manager with application specific xe2x80x9cActivity Modelsxe2x80x9d. We also describe relevant grammar development tools."
