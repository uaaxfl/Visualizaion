2014.amta-researchers.18,W08-0336,0,0.177985,"ey reported the improvement in word segmentation, and did not report its effect on the patent MT. Their work can be seen an application of a semisupervised learning method (Sun and Xu, 2011) to the domain adaptation. Such an approach is appropriate for the patent domain where a huge number of patent documents are publicly available. We extend their domain adaptation by more effective and easy-to-use features, and also incorporate additional Japanese-oriented features to improve the Japanese word segmentation in the patent domain. With respect to the relation between word segmentation and SMT, Chang et al. (2008) reported consistency and granularity of word segmentation is important in Chinese-to-English MT and modified their Chinese word segmenter to optimize the translation performance. Dyer et al. (2008) and Zhang et al. (2008) used multiple word segmentation results to overcome the problem of different word segmentation standards. Xu et al. (2008) optimized Chinese word segmentation for Chinese-to-English SMT using an extended Bayesian word segmentation method with bilingual correspondence. These studies aim to optimize word segmentation using bilingual correspondence and are different from the do"
2014.amta-researchers.18,P08-1115,0,0.0286095,"omain adaptation. Such an approach is appropriate for the patent domain where a huge number of patent documents are publicly available. We extend their domain adaptation by more effective and easy-to-use features, and also incorporate additional Japanese-oriented features to improve the Japanese word segmentation in the patent domain. With respect to the relation between word segmentation and SMT, Chang et al. (2008) reported consistency and granularity of word segmentation is important in Chinese-to-English MT and modified their Chinese word segmenter to optimize the translation performance. Dyer et al. (2008) and Zhang et al. (2008) used multiple word segmentation results to overcome the problem of different word segmentation standards. Xu et al. (2008) optimized Chinese word segmentation for Chinese-to-English SMT using an extended Bayesian word segmentation method with bilingual correspondence. These studies aim to optimize word segmentation using bilingual correspondence and are different from the domain adaptation. Machine transliteration is an important problem for translating names and other imported words (Knight and Graehl, 1998). Conventional methods need to prepare parallel transliterati"
2014.amta-researchers.18,J04-1004,0,0.0347997,"ses B, M, E (beginning/middle/end of a word), and S (single-character word)2 , as Sun and Xu (2011). Our baseline features follow the work of Japanese word segmentation by Neubig et al. (2011): label bigrams, character n-grams (n=1, 2), and character type n-grams (n=1, 2, 3). We use the n-gram features within [i-2, i+2] for classifying the word at the position i. The character types are kanji, katakana, hiragana, digits, roman characters, and others. 4.2 Conventional Method: Word Segmentation Adaptation using Accessor Variety Sun and Xu (2011) and Guo et al. (2012) used Accessor Variety (AV) (Feng et al., 2004) derived from unlabeled corpora as word segmentation features. AV is a word extraction criterion from un-segmented corpora, focusing on the number of distinct characters appearing around a string. The AV of a string xn is defined as AV (xn ) = min {AVL (xn ), AVR (xn )} , where AVL (xn ) is the left AV (the number of distinct predecessor characters) and AVR (xn ) is the right AV (the number of distinct successor characters). The AV-based word extraction is based on an intuitive assumption; a word appears in many different context so that there is a large variation of its accessor characters. I"
2014.amta-researchers.18,N04-1035,0,0.0159661,"© The Authors 234 Finalization (Isozaki et al., 2010), the reordering in Japanese-to-English is not so straightforward. The second problem results from the Japanese orthography in which there are no explicit word boundaries. General-purpose word segmenters often fail to segment the domain-specific words and those words are translated incorrectly or remain untranslated. Some domain-specific words cannot be translated as unknown words even if they are segmented correctly, due to limited SMT training data. The first problem has been addressed by a syntax-based approach (Yamada and Knight, 2002; Galley et al., 2004; Zollmann and Venugopal, 2006), while most previous studies did not deal with the second problem. Since the lexical translation also affects the reordering based on a lexicalized reordering model and an n-gram language model, considering both problems is important for an overall SMT system. The goal of this work is to improve the Japanese-to-English patent SMT by tackling both problems at the same time. The domain-specific words have important roles in the patents and should be translated carefully for meaningful translations. We propose a novel domain adaptation method for the word segmentat"
2014.amta-researchers.18,P06-1085,0,0.0412818,"s Vancouver, BC © The Authors 237 4 Domain Adaptation of Japanese Word Segmentation for Patents We aim to improve the Japanese-to-English translation performance further by the word segmentation adaptation for patent-specific words and technical terms. We use the large-scale monolingual Japanese patent corpora for the domain adaptation, by the semi-supervised approach as Sun and Xu (2011) and Guo et al. (2012). There are also active learning-based supervised domain adaptation (Tsuboi et al., 2008; Neubig et al., 2011) and unsupervised word segmentation (Kempe, 1999; Kubota Ando and Lee, 2003; Goldwater et al., 2006, and many others) approaches, but the semi-supervised approach is expected to be effective; the active learning method is not easy to utilize for such large-scale corpora and the unsupervised method is not so accurate as existing supervised word segmenters. 4.1 Baseline Word Segmentation based on Conditional Random Fields We use a character-based word segmenter based on CRFs (Peng et al., 2004; Tseng et al., 2005). It solves a character-based sequential labeling problem. In this work we employ four classes B, M, E (beginning/middle/end of a word), and S (single-character word)2 , as Sun and X"
2014.amta-researchers.18,I13-1147,1,0.845609,"translation experiments. 2 Related Work The patent MT between Japanese and English has been studied actively on shared tasks in NTCIR (Fujii et al., 2008, 2010; Goto et al., 2011, 2013). Recent important achievements in these studies are on the reordering problem especially in English-to-Japanese direction. Isozaki et al. (2010) proposed a very simple but effective rule-based syntactic pre-ordering method called Head Finalization. It is very effective for the long distance reordering. On the other hand, the Japanese-to-English direction is more difficult due to the lack of such simple rules. Hoshino et al. (2013) proposed an effective rule-based syntactic pre-ordering based on predicate-argument structures. Sudoh et al. (2013b) proposed a different approach called postordering for the Japanese-to-English patent MT, and achieved high translation performance by an efficient syntax-based translation. Our system uses the latter approach based on English syntax rather than the former one based on Japanese syntax. This is because our word segmentation adaptation can be applied directly to it without the Japanese parser adaptation as described earlier. General-purpose Japanese parsers do not work well in the"
2014.amta-researchers.18,W10-1736,1,0.907546,"erence from general-purpose MT. This work focuses on statistical MT (SMT) for patents, from Japanese to English. It is more difficult than English-to-Japanese in: 1) long distance reordering, and 2) word segmentation and lexical translation of domain-specific terms. The first problem is due to large syntactic differences between Japanese and English. Although the reordering in the English-to-Japanese direction can be solved effectively by very simple heuristics called Head Al-Onaizan & Simard (Eds.) Proceedings of AMTA 2014, vol. 1: MT Researchers Vancouver, BC © The Authors 234 Finalization (Isozaki et al., 2010), the reordering in Japanese-to-English is not so straightforward. The second problem results from the Japanese orthography in which there are no explicit word boundaries. General-purpose word segmenters often fail to segment the domain-specific words and those words are translated incorrectly or remain untranslated. Some domain-specific words cannot be translated as unknown words even if they are segmented correctly, due to limited SMT training data. The first problem has been addressed by a syntax-based approach (Yamada and Knight, 2002; Galley et al., 2004; Zollmann and Venugopal, 2006), wh"
2014.amta-researchers.18,P06-2056,0,0.0397128,"Missing"
2014.amta-researchers.18,W99-0702,0,0.0703583,"ings of AMTA 2014, vol. 1: MT Researchers Vancouver, BC © The Authors 237 4 Domain Adaptation of Japanese Word Segmentation for Patents We aim to improve the Japanese-to-English translation performance further by the word segmentation adaptation for patent-specific words and technical terms. We use the large-scale monolingual Japanese patent corpora for the domain adaptation, by the semi-supervised approach as Sun and Xu (2011) and Guo et al. (2012). There are also active learning-based supervised domain adaptation (Tsuboi et al., 2008; Neubig et al., 2011) and unsupervised word segmentation (Kempe, 1999; Kubota Ando and Lee, 2003; Goldwater et al., 2006, and many others) approaches, but the semi-supervised approach is expected to be effective; the active learning method is not easy to utilize for such large-scale corpora and the unsupervised method is not so accurate as existing supervised word segmenters. 4.1 Baseline Word Segmentation based on Conditional Random Fields We use a character-based word segmenter based on CRFs (Peng et al., 2004; Tseng et al., 2005). It solves a character-based sequential labeling problem. In this work we employ four classes B, M, E (beginning/middle/end of a w"
2014.amta-researchers.18,W04-3250,0,0.0288226,"and the large-scale unlabeled patent corpus with the BE and PD features • KyTea, MeCab, and JUMAN10 : publicly available Japanese morphological analyzers We also compared the results by the post-ordering with those by standard SAMT and PBMT. The search space parameters of the standard SAMT were set to the same value as the HFE-toEnglish SAMT, to compare the performance with similar computation time11 . 5.2.3 Results and Discussion Table 4 shows the translation performance in BLEU and TER (Snover et al., 2006) with the results of statistical significance tests (p=0.05) by bootstrap resampling (Koehn, 2004), in which our overall system resulted in the best. The table also shows the results of intermediate Japanese-to-HFE translation. The advantage of our system can be attributed to three techniques included in the system: domain adaption of word segmentation, katakana unknown word transliteration, and post-ordering. 9 It exceeded the maximum sentence length in the development and test sets. 10 http://nlp.ist.i.kyoto-u.ac.jp/EN/index.php?JUMAN 11 Actually the post-ordering needs the time for the first monotone PBMT but it ran very fast and did not affect so much (Sudoh et al., 2013b). Al-Onaizan"
2014.amta-researchers.18,P11-2093,1,0.789822,"e monolingual corpora. Al-Onaizan & Simard (Eds.) Proceedings of AMTA 2014, vol. 1: MT Researchers Vancouver, BC © The Authors 237 4 Domain Adaptation of Japanese Word Segmentation for Patents We aim to improve the Japanese-to-English translation performance further by the word segmentation adaptation for patent-specific words and technical terms. We use the large-scale monolingual Japanese patent corpora for the domain adaptation, by the semi-supervised approach as Sun and Xu (2011) and Guo et al. (2012). There are also active learning-based supervised domain adaptation (Tsuboi et al., 2008; Neubig et al., 2011) and unsupervised word segmentation (Kempe, 1999; Kubota Ando and Lee, 2003; Goldwater et al., 2006, and many others) approaches, but the semi-supervised approach is expected to be effective; the active learning method is not easy to utilize for such large-scale corpora and the unsupervised method is not so accurate as existing supervised word segmenters. 4.1 Baseline Word Segmentation based on Conditional Random Fields We use a character-based word segmenter based on CRFs (Peng et al., 2004; Tseng et al., 2005). It solves a character-based sequential labeling problem. In this work we employ f"
2014.amta-researchers.18,P03-1021,0,0.0420166,"implemented with Moses-chart and trained using the HFE sentences and the corresponding English parse trees. Its reordering parameter max-chart-span was set to 200 to allow arbitrary distance reordering for accurate Japanse-toEnglish translation9 . The search space parameter cube-pruning-pop-limit was set to 32 for efficiency, according to Sudoh et al. (2013b). Their language models were word 6-gram models trained using a large-scale English patent corpus with more than 300 million sentences. Model weights were optimized in BLEU (Papineni et al., 2002) using Minimum Error Rate Training (MERT) (Och, 2003). We chose the best weights among ten individual runs of MERT. The katakana transliteration was implemented as a Moses-based monotone PBMT in the character level, trained using transliteration pairs mined from the Japanese-English phrase table entries whose Japanese part consisted of katakana only. Its character-level language model was character 9-gram models trained using the large-scale English patent corpus which is used for the word-level language models described above. It was used to replace katakana words remained in the intermediate results in HFE with their transliteration results. 5"
2014.amta-researchers.18,P02-1040,0,0.0899612,"strain adjacent phrase translations. The HFE-to-English SAMT was implemented with Moses-chart and trained using the HFE sentences and the corresponding English parse trees. Its reordering parameter max-chart-span was set to 200 to allow arbitrary distance reordering for accurate Japanse-toEnglish translation9 . The search space parameter cube-pruning-pop-limit was set to 32 for efficiency, according to Sudoh et al. (2013b). Their language models were word 6-gram models trained using a large-scale English patent corpus with more than 300 million sentences. Model weights were optimized in BLEU (Papineni et al., 2002) using Minimum Error Rate Training (MERT) (Och, 2003). We chose the best weights among ten individual runs of MERT. The katakana transliteration was implemented as a Moses-based monotone PBMT in the character level, trained using transliteration pairs mined from the Japanese-English phrase table entries whose Japanese part consisted of katakana only. Its character-level language model was character 9-gram models trained using the large-scale English patent corpus which is used for the word-level language models described above. It was used to replace katakana words remained in the intermediate"
2014.amta-researchers.18,C04-1081,0,0.0601299,"al. (2012). There are also active learning-based supervised domain adaptation (Tsuboi et al., 2008; Neubig et al., 2011) and unsupervised word segmentation (Kempe, 1999; Kubota Ando and Lee, 2003; Goldwater et al., 2006, and many others) approaches, but the semi-supervised approach is expected to be effective; the active learning method is not easy to utilize for such large-scale corpora and the unsupervised method is not so accurate as existing supervised word segmenters. 4.1 Baseline Word Segmentation based on Conditional Random Fields We use a character-based word segmenter based on CRFs (Peng et al., 2004; Tseng et al., 2005). It solves a character-based sequential labeling problem. In this work we employ four classes B, M, E (beginning/middle/end of a word), and S (single-character word)2 , as Sun and Xu (2011). Our baseline features follow the work of Japanese word segmentation by Neubig et al. (2011): label bigrams, character n-grams (n=1, 2), and character type n-grams (n=1, 2, 3). We use the n-gram features within [i-2, i+2] for classifying the word at the position i. The character types are kanji, katakana, hiragana, digits, roman characters, and others. 4.2 Conventional Method: Word Seg"
2014.amta-researchers.18,P12-1049,0,0.166158,"nsidering both problems is important for an overall SMT system. The goal of this work is to improve the Japanese-to-English patent SMT by tackling both problems at the same time. The domain-specific words have important roles in the patents and should be translated carefully for meaningful translations. We propose a novel domain adaptation method for the word segmentation, using effective features derived from a large-scale patent corpus. We also incorporate machine transliteration for the unknown Japanese words written in katakana (Japanese phonograms), bootstrapped from the parallel corpus (Sajjad et al., 2012; Sudoh et al., 2013a). Our SMT system integrates these techniques with a post-ordering framework (Sudoh et al., 2013b), which divides the SMT problem explicitly into two sub-problems of the lexical translation and the reordering. In the post-ordering framework, the lexical translation precedes the reordering, different from pre-ordering in which the reordering precedes the lexical translation (Xia and McCord, 2004; Isozaki et al., 2010). An advantage of the post-ordering is that it is easy to integrate the domain-adapted word segmentation and the unknown word transliteration in its lexical tr"
2014.amta-researchers.18,2006.amta-papers.25,0,0.0160653,"tation experiments above • Proposed: the patent-adapted segmenter using the labeled general-domain corpus and the large-scale unlabeled patent corpus with the BE and PD features • KyTea, MeCab, and JUMAN10 : publicly available Japanese morphological analyzers We also compared the results by the post-ordering with those by standard SAMT and PBMT. The search space parameters of the standard SAMT were set to the same value as the HFE-toEnglish SAMT, to compare the performance with similar computation time11 . 5.2.3 Results and Discussion Table 4 shows the translation performance in BLEU and TER (Snover et al., 2006) with the results of statistical significance tests (p=0.05) by bootstrap resampling (Koehn, 2004), in which our overall system resulted in the best. The table also shows the results of intermediate Japanese-to-HFE translation. The advantage of our system can be attributed to three techniques included in the system: domain adaption of word segmentation, katakana unknown word transliteration, and post-ordering. 9 It exceeded the maximum sentence length in the development and test sets. 10 http://nlp.ist.i.kyoto-u.ac.jp/EN/index.php?JUMAN 11 Actually the post-ordering needs the time for the firs"
2014.amta-researchers.18,D13-1021,1,0.223791,"ms is important for an overall SMT system. The goal of this work is to improve the Japanese-to-English patent SMT by tackling both problems at the same time. The domain-specific words have important roles in the patents and should be translated carefully for meaningful translations. We propose a novel domain adaptation method for the word segmentation, using effective features derived from a large-scale patent corpus. We also incorporate machine transliteration for the unknown Japanese words written in katakana (Japanese phonograms), bootstrapped from the parallel corpus (Sajjad et al., 2012; Sudoh et al., 2013a). Our SMT system integrates these techniques with a post-ordering framework (Sudoh et al., 2013b), which divides the SMT problem explicitly into two sub-problems of the lexical translation and the reordering. In the post-ordering framework, the lexical translation precedes the reordering, different from pre-ordering in which the reordering precedes the lexical translation (Xia and McCord, 2004; Isozaki et al., 2010). An advantage of the post-ordering is that it is easy to integrate the domain-adapted word segmentation and the unknown word transliteration in its lexical translation step and t"
2014.amta-researchers.18,D11-1090,0,0.0334295,"Missing"
2014.amta-researchers.18,I05-3027,0,0.0216655,"are also active learning-based supervised domain adaptation (Tsuboi et al., 2008; Neubig et al., 2011) and unsupervised word segmentation (Kempe, 1999; Kubota Ando and Lee, 2003; Goldwater et al., 2006, and many others) approaches, but the semi-supervised approach is expected to be effective; the active learning method is not easy to utilize for such large-scale corpora and the unsupervised method is not so accurate as existing supervised word segmenters. 4.1 Baseline Word Segmentation based on Conditional Random Fields We use a character-based word segmenter based on CRFs (Peng et al., 2004; Tseng et al., 2005). It solves a character-based sequential labeling problem. In this work we employ four classes B, M, E (beginning/middle/end of a word), and S (single-character word)2 , as Sun and Xu (2011). Our baseline features follow the work of Japanese word segmentation by Neubig et al. (2011): label bigrams, character n-grams (n=1, 2), and character type n-grams (n=1, 2, 3). We use the n-gram features within [i-2, i+2] for classifying the word at the position i. The character types are kanji, katakana, hiragana, digits, roman characters, and others. 4.2 Conventional Method: Word Segmentation Adaptation"
2014.amta-researchers.18,C08-1113,1,0.738883,"are trained using the monolingual corpora. Al-Onaizan & Simard (Eds.) Proceedings of AMTA 2014, vol. 1: MT Researchers Vancouver, BC © The Authors 237 4 Domain Adaptation of Japanese Word Segmentation for Patents We aim to improve the Japanese-to-English translation performance further by the word segmentation adaptation for patent-specific words and technical terms. We use the large-scale monolingual Japanese patent corpora for the domain adaptation, by the semi-supervised approach as Sun and Xu (2011) and Guo et al. (2012). There are also active learning-based supervised domain adaptation (Tsuboi et al., 2008; Neubig et al., 2011) and unsupervised word segmentation (Kempe, 1999; Kubota Ando and Lee, 2003; Goldwater et al., 2006, and many others) approaches, but the semi-supervised approach is expected to be effective; the active learning method is not easy to utilize for such large-scale corpora and the unsupervised method is not so accurate as existing supervised word segmenters. 4.1 Baseline Word Segmentation based on Conditional Random Fields We use a character-based word segmenter based on CRFs (Peng et al., 2004; Tseng et al., 2005). It solves a character-based sequential labeling problem. In"
2014.amta-researchers.18,2007.mtsummit-papers.63,0,0.0507407,"s an extended transliteration mining method for Japanese compound words (Sudoh et al., 2013a). 3 System Overview Our Japanese-to-English patent SMT is based on large-scale language resources in the patent domain. This work uses NTCIR PatentMT dataset (Goto et al., 2011, 2013) including a Japanese-English parallel corpus of 3.2 million sentences and monolingual corpora of more than 300 million sentences of Japanese and English. The parallel corpus was developed by an automatic sentence alignment over patent documents in the Japan Patent Office and the United States Patent and Trademark Office (Utiyama and Isahara, 2007). The workflow of our SMT system is illustrated in Figure 1. The translation is divided into the following four processes. 1. Japanese word segmentation using a patent-adapted word segmentation model 2. Translation into an intermediate language, Head Final English (HFE), by a monotone phrase-based SMT 3. Transliteration of untranslated Japanese katakana words (i.e. unknown words in the previous process) into English words, by a monotone phrase-based SMT in the character level 4. Post-ordering into English by a syntax-based SMT Here, HFE is Japanese-ordered English, which was proposed by Isozak"
2014.amta-researchers.18,C04-1073,0,0.0524449,"arge-scale patent corpus. We also incorporate machine transliteration for the unknown Japanese words written in katakana (Japanese phonograms), bootstrapped from the parallel corpus (Sajjad et al., 2012; Sudoh et al., 2013a). Our SMT system integrates these techniques with a post-ordering framework (Sudoh et al., 2013b), which divides the SMT problem explicitly into two sub-problems of the lexical translation and the reordering. In the post-ordering framework, the lexical translation precedes the reordering, different from pre-ordering in which the reordering precedes the lexical translation (Xia and McCord, 2004; Isozaki et al., 2010). An advantage of the post-ordering is that it is easy to integrate the domain-adapted word segmentation and the unknown word transliteration in its lexical translation step and that the reordering can use the improved lexical translation results. If we are to do the same thing in the pre-ordering, we need domain adaptation of its Japanese syntactic parser in addition to the word segmenter, and have to integrate the transliteration process with the SMT decoder as Durrani et al. (2014). Our system shows better translation accuracy in BLEU and TER than baseline methods in"
2014.amta-researchers.18,C08-1128,0,0.022744,"ir domain adaptation by more effective and easy-to-use features, and also incorporate additional Japanese-oriented features to improve the Japanese word segmentation in the patent domain. With respect to the relation between word segmentation and SMT, Chang et al. (2008) reported consistency and granularity of word segmentation is important in Chinese-to-English MT and modified their Chinese word segmenter to optimize the translation performance. Dyer et al. (2008) and Zhang et al. (2008) used multiple word segmentation results to overcome the problem of different word segmentation standards. Xu et al. (2008) optimized Chinese word segmentation for Chinese-to-English SMT using an extended Bayesian word segmentation method with bilingual correspondence. These studies aim to optimize word segmentation using bilingual correspondence and are different from the domain adaptation. Machine transliteration is an important problem for translating names and other imported words (Knight and Graehl, 1998). Conventional methods need to prepare parallel transliteration pairs for training. Sajjad et al. (2012) proposed an unsupervised transliteration mining from standard parallel corpora for bootstrapping machin"
2014.amta-researchers.18,P02-1039,0,0.0604915,"Researchers Vancouver, BC © The Authors 234 Finalization (Isozaki et al., 2010), the reordering in Japanese-to-English is not so straightforward. The second problem results from the Japanese orthography in which there are no explicit word boundaries. General-purpose word segmenters often fail to segment the domain-specific words and those words are translated incorrectly or remain untranslated. Some domain-specific words cannot be translated as unknown words even if they are segmented correctly, due to limited SMT training data. The first problem has been addressed by a syntax-based approach (Yamada and Knight, 2002; Galley et al., 2004; Zollmann and Venugopal, 2006), while most previous studies did not deal with the second problem. Since the lexical translation also affects the reordering based on a lexicalized reordering model and an n-gram language model, considering both problems is important for an overall SMT system. The goal of this work is to improve the Japanese-to-English patent SMT by tackling both problems at the same time. The domain-specific words have important roles in the patents and should be translated carefully for meaningful translations. We propose a novel domain adaptation method f"
2014.amta-researchers.18,W08-0335,0,0.0231886,"an approach is appropriate for the patent domain where a huge number of patent documents are publicly available. We extend their domain adaptation by more effective and easy-to-use features, and also incorporate additional Japanese-oriented features to improve the Japanese word segmentation in the patent domain. With respect to the relation between word segmentation and SMT, Chang et al. (2008) reported consistency and granularity of word segmentation is important in Chinese-to-English MT and modified their Chinese word segmenter to optimize the translation performance. Dyer et al. (2008) and Zhang et al. (2008) used multiple word segmentation results to overcome the problem of different word segmentation standards. Xu et al. (2008) optimized Chinese word segmentation for Chinese-to-English SMT using an extended Bayesian word segmentation method with bilingual correspondence. These studies aim to optimize word segmentation using bilingual correspondence and are different from the domain adaptation. Machine transliteration is an important problem for translating names and other imported words (Knight and Graehl, 1998). Conventional methods need to prepare parallel transliteration pairs for training. S"
2014.amta-researchers.18,Y06-1012,0,0.0222236,"proportional to the corpus size in general. Previous studies use several frequency classes with corresponding threshold values tuned according to the corpus, but it is not straightforward to determine appropriate classes and threshold values. Sun and Xu (2011) used the following features based on the left and right AVs of character n-grams for classifying xi , which imply word boundaries around xi , as illustrated in Figure 4. • Left AV of n-gram starting from xi : AVL (xi , ..., xi+n−1 ) 2 Guo et al. (2012) used six classes including B2, B3 (second and third character in a word) proposed by Zhao et al. (2006) for Chinese word segmentation. This paper uses the four classes, because the six classes did not improve the word segmentation accuracy in our pilot test. Al-Onaizan & Simard (Eds.) Proceedings of AMTA 2014, vol. 1: MT Researchers Vancouver, BC © The Authors 238 と前記複数の の前後方向で と前記ノード 直前に、その と前後で交差 predecessors: と: 3 の: 1 直: 1 Left AV of 前: 3 Right AV of 前: 3 Left BE of 前: 3 3 log 5 5 successors: 記: 2 後: 2 に: 1 2⇥ 1 1 log = 1.057 5 5 Right BE of 前: 2⇥ 2 3 log 5 5 1 1 log = 1.308 5 5 Figure 3: Example of accessor variety (AV) and branching entropy (BE) for a character “前”. character to be classi"
2014.amta-researchers.18,W06-3119,0,0.01628,"nalization (Isozaki et al., 2010), the reordering in Japanese-to-English is not so straightforward. The second problem results from the Japanese orthography in which there are no explicit word boundaries. General-purpose word segmenters often fail to segment the domain-specific words and those words are translated incorrectly or remain untranslated. Some domain-specific words cannot be translated as unknown words even if they are segmented correctly, due to limited SMT training data. The first problem has been addressed by a syntax-based approach (Yamada and Knight, 2002; Galley et al., 2004; Zollmann and Venugopal, 2006), while most previous studies did not deal with the second problem. Since the lexical translation also affects the reordering based on a lexicalized reordering model and an n-gram language model, considering both problems is important for an overall SMT system. The goal of this work is to improve the Japanese-to-English patent SMT by tackling both problems at the same time. The domain-specific words have important roles in the patents and should be translated carefully for meaningful translations. We propose a novel domain adaptation method for the word segmentation, using effective features d"
2014.amta-researchers.18,E14-4029,0,\N,Missing
2014.amta-researchers.18,J98-4003,0,\N,Missing
2020.acl-main.4,W19-5944,0,0.035438,"whether a sentence is a true continuation given a preceding context, where a positive sample is the ground-truth subsequent sentence and a negative sample is a different piece of text. NSP benefits not only evaluation (Tao et al., 2018), but also language understanding (Devlin et al., 2019) and language generation (Bruni and Fernandez, 2017; Wolf et al., 2019). Dialogue response evaluation can also be improved with better automated metrics and approximation to response quality. Examples of successful attempts to improve automated metrics include exploiting multiple references for comparison (Gupta et al., 2019) and combining human judgement with automated metrics (Hashimoto et al., 2019). Li et al. (2019) demonstrated that single-turn human judgement is not reliable as expected and proposed multi-turn human evaluation. Ghandeharioun et al. (2019) approximated sentiment, semantic similarity, and engagement with new automated metrics and used a hybrid metric in a multi-turn evaluation setting. Dziri et al. (2019) showed that entailment is also an option to approximate dialogue coherence and quality. 3 4 Data Collection (3) For assessing dialogue response evaluators, we sample 100 dialogues from the te"
2020.acl-main.4,2021.ccl-1.108,0,0.204294,"Missing"
2020.acl-main.4,P18-1205,0,0.093017,"final group. Semisupervised training yields improvement in correlations, and abandoning referenced metrics makes predictions less conservative. The RoBERTa evaluator outperforms the baselines by a large margin and has a much human-like score diversity. 6.1 Transferability Study We are interested in applying a trained response evaluator to new data of different domains or styles. Therefore, we carry out experiments to study the transferability of the RoBERTa evaluator. In addition to the DailyDialog (DD) corpus, we further collect annotations on 900 responses from the PersonaChat (PC) corpus (Zhang et al., 2018) following the same procedure in Section 4. The evaluator turns out to generalize to a new corpus much better than the baseline RUBER according to results in Table 4. The evaluator trained on the DD corpus achieves even higher correlation scores when applied to the PC corpus. However, performance degradation is observed when applying the evaluator trained on the PC corpus to the DD corpus. It suggests that we should make a careful choice of training data when planning to evaluate our models on different corpora. (5) RoBERTa-eval(c, rˆ) = 4 · MLP(d; θ) + 1, (6) where RoBERTa’s parameter φ and M"
2020.acl-main.4,I17-1099,0,\N,Missing
2020.acl-main.4,W19-3646,0,\N,Missing
2020.acl-main.4,N19-1381,0,\N,Missing
2020.acl-main.4,N19-1169,0,\N,Missing
2020.acl-main.4,2020.tacl-1.5,0,\N,Missing
2020.coling-main.359,D18-1431,0,0.0182243,"model has increment in both acceptance rate and high quality rate, while the baseline model decrement in both. The results shows that the model integrating both proposed constraints can generate more relevant and content-rich responses. 7 Related Work Our proposed work is related to some past works. To generate more content-rich responses, a seq2seq model with an additional topic and semantic constraint that are based on a topic model (Griffiths et al., 2005) and cosine similarity (Arora et al., 2016) has been proposed, showing promising results in the content richness of generated responses (Baheti et al., 2018). Xing et al. also used topic information as side information and showed good results, where the topics are obtained from a pre-trained LDA 4074 Model HRED HRED-Topic HRED-OT HRED-Topic+OT Grammar Relevance 2.77 2.69 2.65 2.90 2.23 2.11 2.23 2.40 Acceptance Rate 0.88 0.83 0.92 0.97 High Quality Rate 0.31 0.26 0.19 0.37 Table 7: Human evaluation results of content-rich response samples. model (Xing et al., 2017). To improve the model structure, Mou el al. proposed a model that generates responses backward and forward starting from a keyword, which is a noun with the highest pointwise mutual inf"
2020.coling-main.359,N19-1423,0,0.00967295,"Missing"
2020.coling-main.359,N16-1014,0,0.153497,"owever, for open-domain dialog response generation, a response can be weakly relevant to its previous utterances. There usually does not exist an obvious alignment between previous utterances and the response. Thus, neural generative models tend to generate safe and generic response, which contains little meaningful information, such as “really?”, and “I don’t know.”. These generic responses are usually short and vague, and can seldom provide effective information as feedback to the other partner in the dialog. This has been identified as one of major challenges in neural response generation (Li et al., 2016). To ameliorate the problem of generic responses, we design a model that can generate responses that are relevant to previous utterances. Two constraints are introduced, 1) topical constraint and 2) semantic constraint, to modify the objective function P (Y |X). Responses which are highly related to their context usually have the same topic as the context does. Thus, the topical constraint conditions the model’s decoding process on topic words in the context, which are identified by a topic word sequence labeler. Moreover, a relevant response should be semantically related to its context. The"
2020.coling-main.359,C16-1316,0,0.0207629,"topics are obtained from a pre-trained LDA 4074 Model HRED HRED-Topic HRED-OT HRED-Topic+OT Grammar Relevance 2.77 2.69 2.65 2.90 2.23 2.11 2.23 2.40 Acceptance Rate 0.88 0.83 0.92 0.97 High Quality Rate 0.31 0.26 0.19 0.37 Table 7: Human evaluation results of content-rich response samples. model (Xing et al., 2017). To improve the model structure, Mou el al. proposed a model that generates responses backward and forward starting from a keyword, which is a noun with the highest pointwise mutual information (PMI) score as a hard constraint, outperforming traditional Sequence-to-Sequence model (Mou et al., 2016). Zhang et al. built their system for ”relevant, contentful and context-consistent responses”(Zhang et al., 2019); Adiwardana et al. built a multi-turn open-domain chatbot and proposed a metric called Sensibleness and Specificity Average (SSA) for human evaluation (Adiwardana et al., 2020); Smith et al. wanted their chatbot to be engaging, knowledgeable, and empathetic and proposed a new dataset called BlendedSkillTalk for analysis (Smith et al., 2020); Roller et al. evaluated their multi-turn dialogue model for engagingness and humanness (Roller et al., 2020). 8 Conclusion A topic-relevant re"
2020.coling-main.359,P02-1040,0,0.107162,"distance between the context and the response to regularize the objective function, where the semantic distance is calculated by optimal transport. The regularization coefficient of OT is 0.5, and the number of the maximal iteration is 50. HRED-Topic+OT. The HRED model with a sequence labeler and an optimal transport layer. The sequence labeler is trained on DailyDialog topic hard. 6.2.2 Automatic Evaluation The models are assessed by the following metrics. BLEU-2 calculates the unigram and bigram overlap of the predicted response and the ground truth response, then takes the average of them (Papineni et al., 2002). Embedding similarity calculates the cosine similarity between a predicted response and the ground truth response. There are different ways of choosing representation: average, extrema, greedy, denoted by Emb-A, Emb-E, Emb-G (Foltz et al., 1998; Forgues et al., 2014; Rus and Lintean, 2012). Distinct calculates the ratio of unique unigram and bigram entries in a predicted response, denoted by Dist-1 and Dist-2. Distinct scores are calculated regarding both the response itself and all responses in the corpus, denoted by Intra Dist and Inter Dist (Li et al., 2016). Distinct scores discover the d"
2020.coling-main.359,W12-2018,0,0.0212876,"er and an optimal transport layer. The sequence labeler is trained on DailyDialog topic hard. 6.2.2 Automatic Evaluation The models are assessed by the following metrics. BLEU-2 calculates the unigram and bigram overlap of the predicted response and the ground truth response, then takes the average of them (Papineni et al., 2002). Embedding similarity calculates the cosine similarity between a predicted response and the ground truth response. There are different ways of choosing representation: average, extrema, greedy, denoted by Emb-A, Emb-E, Emb-G (Foltz et al., 1998; Forgues et al., 2014; Rus and Lintean, 2012). Distinct calculates the ratio of unique unigram and bigram entries in a predicted response, denoted by Dist-1 and Dist-2. Distinct scores are calculated regarding both the response itself and all responses in the corpus, denoted by Intra Dist and Inter Dist (Li et al., 2016). Distinct scores discover the diversity of the predicted response. Table 4 shows the automatic evaluation results of all models. All proposed models outperform the baseline model HRED in terms of the BLEU-2 score, and HRED-Topic-Hard even surpasses the baseline model by one point in the BLEU-2 score. When compared with e"
2020.coling-main.359,2020.acl-main.183,0,0.0117956,"h is a noun with the highest pointwise mutual information (PMI) score as a hard constraint, outperforming traditional Sequence-to-Sequence model (Mou et al., 2016). Zhang et al. built their system for ”relevant, contentful and context-consistent responses”(Zhang et al., 2019); Adiwardana et al. built a multi-turn open-domain chatbot and proposed a metric called Sensibleness and Specificity Average (SSA) for human evaluation (Adiwardana et al., 2020); Smith et al. wanted their chatbot to be engaging, knowledgeable, and empathetic and proposed a new dataset called BlendedSkillTalk for analysis (Smith et al., 2020); Roller et al. evaluated their multi-turn dialogue model for engagingness and humanness (Roller et al., 2020). 8 Conclusion A topic-relevant response should have a common or similar topic with its context, and it should be semantically related to the context. To generate topic-relevant responses and avoid generic responses like “I don’t know”, two constraints placed onto the decoding process are proposed. The first constraint is a topical constraint. To extract topic information from the context, a sequence labeler is trained on two differently constructed dataset with topic word annotations."
2020.coling-main.359,D19-1374,0,0.0242589,"Missing"
2020.lrec-1.319,D18-2012,0,0.0283199,"(meaning “(for a god) to protect from behind”) is divided as i-ser-ma-kus, but the right syllabification is iser-mak-us. 4.2.3. Word Piece The byte pair encoding (BPE) (Sennrich et al., 2015) and the unigram language modeling (Kudo, 2018) are alternative methods for dividing a word into word pieces. The former repeatedly replaces the most common character pair with a new single symbol until the vocabulary becomes the intended size. The latter decides the segmentation to maximize the likelihood of occurrence of the sequence. We adopt the latter and use the open-source software SentencePiece4 (Kudo and Richardson, 2018). With this tool, 4 https://github.com/google/sentencepiece Japanese or English Ainu Table 3: Examples of four modeling units. Label 2’ Label 1 Loss Label 2 CE CE Decoder Decoder Label 2’ ( phone ) CTC CTC FC Loss ( phone ) Attention FC Encoder Acoustic Features Figure 2: The architecture of the multilingual learning with two corpora. ‘FC’ and ‘CE’ means ‘fully connected’ and ‘cross-entropy’ respectively. ‘⟨wb⟩’ and other units are often merged to constitute a single piece as seen in Table 3. 4.2.4. Word The original text can be segmented into words separated by spaces. To make the vocabulary"
2020.lrec-1.319,P18-1007,0,0.0297319,"es. VCR+ → V-CR+ 4. Put a syllable boundary after CV repeatedly from left to right until only CV or CVC is left. (CV)∗ {CV, CVC} → (CV-)∗ {CV, CVC} In addition, ‘=’ and ‘⟨wb⟩’ are added as explained in Section 4.2.1. through the model training process. This procedure does not always generate a morphologically relevant syllable segmentation. For example, a word isermakus (meaning “(for a god) to protect from behind”) is divided as i-ser-ma-kus, but the right syllabification is iser-mak-us. 4.2.3. Word Piece The byte pair encoding (BPE) (Sennrich et al., 2015) and the unigram language modeling (Kudo, 2018) are alternative methods for dividing a word into word pieces. The former repeatedly replaces the most common character pair with a new single symbol until the vocabulary becomes the intended size. The latter decides the segmentation to maximize the likelihood of occurrence of the sequence. We adopt the latter and use the open-source software SentencePiece4 (Kudo and Richardson, 2018). With this tool, 4 https://github.com/google/sentencepiece Japanese or English Ainu Table 3: Examples of four modeling units. Label 2’ Label 1 Loss Label 2 CE CE Decoder Decoder Label 2’ ( phone ) CTC CTC FC Loss"
2020.lrec-1.319,H92-1073,0,0.708757,"arget languages, the ASR model training can be enhanced by taking advantage of data from other languages (Toshniwal et al., 2018; Cho et al., 2018). There are some similarities between Ainu and Japanese language (Tamura, 2013). For instance, both have almost the same set of vowels and do not have consonant clusters (like ‘str’ of ‘strike’ in English). Hence, the multilingual training with a Japanese corpus is expected to be effective. In addition, an English corpus is used for the purpose of comparison. The corpora used are the JNAS corpus (Itou et al., 1999) (in Japanese) and the WSJ corpus (Paul and Baker, 1992) (in English). JNAS comprises roughly 80 hours from 320 speakers, and WSJ has about 70 hours of speech from 280 speakers. In the multilingual training, the encoder and the attention module are shared among the Ainu ASR model and the models for other languages, and they are trained using data for all languages. Figure 2 shows the architecture for the multilingual learning with two corpora. When the input acoustic features are from the Ainu ASR corpus, they go through the shared encoder and attention module and are delivered into the decoder on the left side in Figure 2 as a context vector. In t"
2020.lrec-1.319,L18-1373,0,0.0688132,"Missing"
2020.sigdial-1.15,W15-4616,0,0.0437856,"Missing"
2020.sigdial-1.15,W16-3625,1,0.647755,"Missing"
2020.sigdial-1.15,W17-5516,1,0.802997,"Missing"
2020.sigdial-1.15,C10-1097,0,0.0416782,"Missing"
2020.sigdial-1.15,N09-1071,0,0.0771239,"Missing"
2021.naacl-main.150,N19-1202,0,0.120393,"Missing"
2021.naacl-main.150,N13-1073,0,0.117252,"Missing"
2021.naacl-main.150,D19-5503,0,0.019447,"n-autoregressive (NAR) models (Gu et al., bitext via back-translation. We further propose 2018; Zhou et al., 2019a; Ren et al., 2020). bidirectional SeqKD in which SeqKD from both forward and backward NMT models is Paraphrasing, which represents text in a differcombined. Experimental evaluations on both ent form but with the same meaning, can also be autoregressive and non-autoregressive models regarded as SeqKD when using neural paraphrasshow that SeqKD in each direction consising via back-translation (Mallinson et al., 2017; tently improves the translation performance, Wieting et al., 2017; Federmann et al., 2019). It and the effectiveness is complementary regardhas been studied to improve the reference diversity less of the model capacity. for MT system evaluations (Thompson and Post, 1 Introduction 2020; Bawden et al., 2020a,b) and the performance of low-resource neural MT (NMT) models (Zhou End-to-end speech translation (E2E-ST) (Bérard et al., 2019b; Khayrallah et al., 2020). et al., 2016), which aims to convert source speech to text in another language directly, is an active In this work, due to its simplicity and effectiveresearch area. Because direct ST is a more diffi- ness, we focus on SeqKD f"
2021.naacl-main.150,D19-1633,0,0.0899853,"ration (1) To exploit semantic information in the source language, we leverage machine-generated paraphrases of source transcriptions. We train a text-based target-to-source backward NMT model Mbwd with bwd = Dmt and then generate a new dataset Dst {(Xi , Yˆis , Yit )}Ii=1 , where Yˆis is a paraphrase of bwd for training the E2E-ST models. Yis . We use Dst As neural paraphrasing can be regarded as SeqKD from Mbwd , we referred to it as backward SeqKD Non-autoregressive E2E-ST model We adopt Orthors (Inaguma et al., 2021), in which a decoder based on a conditional masked language model (CMLM) (Ghazvininejad et al., 2019) is jointly trained with an additional AR decoder 1 We focus on a complete triplet of (X, Y s , Y t ) only. However, the proposed method can easily be extended to a semisupervised setting featuring additional ASR and MT pair data. 2 All NMT models are autoregressive in this paper. 3 We found this was more effective than replacing the startof-sentence symbol with a language ID (Inaguma et al., 2019; Wang et al., 2020b; Le et al., 2020) as done in previous multilingual E2E-ST studies. where both Lst and Lsrc are defined as crossentropy losses. The entire encoder-decoder parameters are shared in"
2021.naacl-main.150,2020.acl-demos.34,1,0.93564,"λ∗ is the corresponding tunable loss weight. During inference, the mask-predict algorithm is used for T iterations with a length beam width of l (Ghazvininejad et al., 2019). The best candidate at the last iteration is selected from the NAR decoder based on scores from the AR decoder (Inaguma et al., 2021). Note that we apply Lsrc to the NAR decoder only. 3 BLEU (∆) (↑) Model Experimental setting Data We used Must-C En-De (408 hours) and En-Fr (492 hours) datasets (Di Gangi et al., 2019). Both language pairs consist of a triplet of (X, Y s , Y t ). We performed the same data preprocessing as (Inaguma et al., 2020) (see details in Appendix A.1). We report case-sensitive detokenized BLEU scores (Papineni et al., 2002) on the tst-COMMON set with the multi-bleu-detok.perl script in Moses (Koehn et al., 2007). Fairseq-S2T‡ + Multilingual 22.91 22.7 24.5 Baseline + MT pre-training + Joint ASR + Bwd SeqKD A1 + Fwd SeqKD + MT pre-training + Joint ASR + Original (2ref) A1 + Bidir SeqKD + Original (2ref) 22.77 23.12 22.97 23.11 24.42 24.68 24.67 24.83 24.83 25.28 En-Fr 32.69 32.9 34.9 (+0.35) (+0.20) (+0.34) (+1.65) (+1.91) (+1.90) (+2.06) (+2.06) (+2.51) 33.51 33.84 33.37 33.78 34.66 34.57 34.68 34.92 34.78 35"
2021.naacl-main.150,2020.iwslt-1.8,0,0.066529,"Missing"
2021.naacl-main.150,E17-1083,0,0.020944,"ses the training of student models, phrases are generated from the translations in e.g., non-autoregressive (NAR) models (Gu et al., bitext via back-translation. We further propose 2018; Zhou et al., 2019a; Ren et al., 2020). bidirectional SeqKD in which SeqKD from both forward and backward NMT models is Paraphrasing, which represents text in a differcombined. Experimental evaluations on both ent form but with the same meaning, can also be autoregressive and non-autoregressive models regarded as SeqKD when using neural paraphrasshow that SeqKD in each direction consising via back-translation (Mallinson et al., 2017; tently improves the translation performance, Wieting et al., 2017; Federmann et al., 2019). It and the effectiveness is complementary regardhas been studied to improve the reference diversity less of the model capacity. for MT system evaluations (Thompson and Post, 1 Introduction 2020; Bawden et al., 2020a,b) and the performance of low-resource neural MT (NMT) models (Zhou End-to-end speech translation (E2E-ST) (Bérard et al., 2019b; Khayrallah et al., 2020). et al., 2016), which aims to convert source speech to text in another language directly, is an active In this work, due to its simplic"
2021.naacl-main.150,P02-1040,0,0.1115,"iterations with a length beam width of l (Ghazvininejad et al., 2019). The best candidate at the last iteration is selected from the NAR decoder based on scores from the AR decoder (Inaguma et al., 2021). Note that we apply Lsrc to the NAR decoder only. 3 BLEU (∆) (↑) Model Experimental setting Data We used Must-C En-De (408 hours) and En-Fr (492 hours) datasets (Di Gangi et al., 2019). Both language pairs consist of a triplet of (X, Y s , Y t ). We performed the same data preprocessing as (Inaguma et al., 2020) (see details in Appendix A.1). We report case-sensitive detokenized BLEU scores (Papineni et al., 2002) on the tst-COMMON set with the multi-bleu-detok.perl script in Moses (Koehn et al., 2007). Fairseq-S2T‡ + Multilingual 22.91 22.7 24.5 Baseline + MT pre-training + Joint ASR + Bwd SeqKD A1 + Fwd SeqKD + MT pre-training + Joint ASR + Original (2ref) A1 + Bidir SeqKD + Original (2ref) 22.77 23.12 22.97 23.11 24.42 24.68 24.67 24.83 24.83 25.28 En-Fr 32.69 32.9 34.9 (+0.35) (+0.20) (+0.34) (+1.65) (+1.91) (+1.90) (+2.06) (+2.06) (+2.51) 33.51 33.84 33.37 33.78 34.66 34.57 34.68 34.92 34.78 35.29 (+0.33) (–0.14) (+0.23) (+1.15) (+1.06) (+1.17) (+1.41) (+1.27) (+1.78) Table 2: BLEU scores of AR m"
2021.naacl-main.150,2020.acl-main.15,0,0.0205104,"SeqKD qKD) (Kim and Rush, 2016) is another approach from a target-to-source backward NMT model. to transferring knowledge from one model to anTo this end, we train a bilingual E2E-ST model other. Recent studies have shown that SeqKD has to predict paraphrased transcriptions as an auxthe effect of reducing the complexity of training iliary task with a single decoder. The paradata and thus eases the training of student models, phrases are generated from the translations in e.g., non-autoregressive (NAR) models (Gu et al., bitext via back-translation. We further propose 2018; Zhou et al., 2019a; Ren et al., 2020). bidirectional SeqKD in which SeqKD from both forward and backward NMT models is Paraphrasing, which represents text in a differcombined. Experimental evaluations on both ent form but with the same meaning, can also be autoregressive and non-autoregressive models regarded as SeqKD when using neural paraphrasshow that SeqKD in each direction consising via back-translation (Mallinson et al., 2017; tently improves the translation performance, Wieting et al., 2017; Federmann et al., 2019). It and the effectiveness is complementary regardhas been studied to improve the reference diversity less of"
2021.naacl-main.150,P16-1162,0,0.226994,"Missing"
2021.naacl-main.150,2006.amta-papers.25,0,0.074418,".84 33.37 33.78 34.66 34.57 34.68 34.92 34.78 35.29 (+0.33) (–0.14) (+0.23) (+1.15) (+1.06) (+1.17) (+1.41) (+1.27) (+1.78) Table 2: BLEU scores of AR models on Must-C tst-COMMON set. † (Inaguma et al., 2020), ‡ (Wang et al., 2020a).  Large model trained with eight language pairs (Wang et al., 2020a). Inference For the AR models, we used a beam width of 4. For the NAR models, we set T = {4, 10} and l = 9 as in (Inaguma et al., 2021). 4 4.1 Results Main results We first report the paraphrasing quality, which is shown in Table 1. As confirmed by the BLEU and translation edit rate (TER) scores (Snover et al., 2006), the paraphrased source text was not just a simple copy of the transcription (see examples in Appendix A.5). Autoregressive models The results are shown in Table 2. Pre-training the ST decoder with the forward MT decoder (A2) improved the baseline performance (A1). Joint ASR showed a marginal improvement on En-De but a degraded performance Model configuration We used the Transon En-Fr (A3). We attribute this to the fact that former (Vaswani et al., 2017) architecture having the ASR task was more trivial than the ST task and 12 encoder layers following two CNN blocks biased the shared decoder"
2021.naacl-main.150,Q19-1020,0,0.0328443,"Missing"
2021.naacl-main.150,2020.emnlp-main.8,0,0.0473974,"Missing"
2021.naacl-main.150,2020.aacl-demo.6,0,0.547205,"other language directly, is an active In this work, due to its simplicity and effectiveresearch area. Because direct ST is a more diffi- ness, we focus on SeqKD from text-based NMT cult task than automatic speech recognition (ASR) models to improve the performance of a bilingual and machine translation (MT), various techniques E2E-ST model. In order to fully leverage source have been proposed to ease the training process by language information, we propose backward Seusing source transcription. Examples include pre- qKD, which targets paraphrased source transcriptraining (Bérard et al., 2018; Wang et al., 2020c; tions generated from a target-to-source backward Bansal et al., 2019; Wang et al., 2020d), multi-task NMT model as an auxiliary task. Then, a single ST learning (Weiss et al., 2017; Bérard et al., 2018; Ba- decoder is trained to predict both source and target har et al., 2019), knowledge distillation (Liu et al., language text as in a multilingual setting (Inaguma 2019), meta-learning (Indurthi et al., 2020), two- et al., 2019). This way, the decoder is biased to pass decoding (Anastasopoulos and Chiang, 2018; capture semantic representations from speech, un1872 Proceedings of the 2021 Conf"
2021.naacl-main.150,2020.acl-main.344,0,0.341623,"other language directly, is an active In this work, due to its simplicity and effectiveresearch area. Because direct ST is a more diffi- ness, we focus on SeqKD from text-based NMT cult task than automatic speech recognition (ASR) models to improve the performance of a bilingual and machine translation (MT), various techniques E2E-ST model. In order to fully leverage source have been proposed to ease the training process by language information, we propose backward Seusing source transcription. Examples include pre- qKD, which targets paraphrased source transcriptraining (Bérard et al., 2018; Wang et al., 2020c; tions generated from a target-to-source backward Bansal et al., 2019; Wang et al., 2020d), multi-task NMT model as an auxiliary task. Then, a single ST learning (Weiss et al., 2017; Bérard et al., 2018; Ba- decoder is trained to predict both source and target har et al., 2019), knowledge distillation (Liu et al., language text as in a multilingual setting (Inaguma 2019), meta-learning (Indurthi et al., 2020), two- et al., 2019). This way, the decoder is biased to pass decoding (Anastasopoulos and Chiang, 2018; capture semantic representations from speech, un1872 Proceedings of the 2021 Conf"
2021.naacl-main.150,D17-1026,0,0.0227938,"anslations in e.g., non-autoregressive (NAR) models (Gu et al., bitext via back-translation. We further propose 2018; Zhou et al., 2019a; Ren et al., 2020). bidirectional SeqKD in which SeqKD from both forward and backward NMT models is Paraphrasing, which represents text in a differcombined. Experimental evaluations on both ent form but with the same meaning, can also be autoregressive and non-autoregressive models regarded as SeqKD when using neural paraphrasshow that SeqKD in each direction consising via back-translation (Mallinson et al., 2017; tently improves the translation performance, Wieting et al., 2017; Federmann et al., 2019). It and the effectiveness is complementary regardhas been studied to improve the reference diversity less of the model capacity. for MT system evaluations (Thompson and Post, 1 Introduction 2020; Bawden et al., 2020a,b) and the performance of low-resource neural MT (NMT) models (Zhou End-to-end speech translation (E2E-ST) (Bérard et al., 2019b; Khayrallah et al., 2020). et al., 2016), which aims to convert source speech to text in another language directly, is an active In this work, due to its simplicity and effectiveresearch area. Because direct ST is a more diffi-"
2021.naacl-main.150,P19-2015,0,0.116616,"ose backward SeqKD, SeqKD qKD) (Kim and Rush, 2016) is another approach from a target-to-source backward NMT model. to transferring knowledge from one model to anTo this end, we train a bilingual E2E-ST model other. Recent studies have shown that SeqKD has to predict paraphrased transcriptions as an auxthe effect of reducing the complexity of training iliary task with a single decoder. The paradata and thus eases the training of student models, phrases are generated from the translations in e.g., non-autoregressive (NAR) models (Gu et al., bitext via back-translation. We further propose 2018; Zhou et al., 2019a; Ren et al., 2020). bidirectional SeqKD in which SeqKD from both forward and backward NMT models is Paraphrasing, which represents text in a differcombined. Experimental evaluations on both ent form but with the same meaning, can also be autoregressive and non-autoregressive models regarded as SeqKD when using neural paraphrasshow that SeqKD in each direction consising via back-translation (Mallinson et al., 2017; tently improves the translation performance, Wieting et al., 2017; Federmann et al., 2019). It and the effectiveness is complementary regardhas been studied to improve the referenc"
2021.naacl-main.150,2020.lrec-1.517,0,0.0419998,"other language directly, is an active In this work, due to its simplicity and effectiveresearch area. Because direct ST is a more diffi- ness, we focus on SeqKD from text-based NMT cult task than automatic speech recognition (ASR) models to improve the performance of a bilingual and machine translation (MT), various techniques E2E-ST model. In order to fully leverage source have been proposed to ease the training process by language information, we propose backward Seusing source transcription. Examples include pre- qKD, which targets paraphrased source transcriptraining (Bérard et al., 2018; Wang et al., 2020c; tions generated from a target-to-source backward Bansal et al., 2019; Wang et al., 2020d), multi-task NMT model as an auxiliary task. Then, a single ST learning (Weiss et al., 2017; Bérard et al., 2018; Ba- decoder is trained to predict both source and target har et al., 2019), knowledge distillation (Liu et al., language text as in a multilingual setting (Inaguma 2019), meta-learning (Indurthi et al., 2020), two- et al., 2019). This way, the decoder is biased to pass decoding (Anastasopoulos and Chiang, 2018; capture semantic representations from speech, un1872 Proceedings of the 2021 Conf"
2021.sigdial-1.20,K16-1002,0,0.0680887,"Missing"
2021.sigdial-1.20,P19-1567,0,0.042315,"Missing"
2021.sigdial-1.20,N19-1423,0,0.00878937,"ge model. 3.2 Data Augmentation and Manipulation The multi-referenced training approach can be seen as a data augmentation method. Prior works on data augmentation in text generation tasks often operate on a word level while our method performs 191 sentence-level augmentation. Niu and Bansal (2019) proposed to apply semantic-preserving perturbations to input words for augmenting data in dialogue tasks. Zheng et al. (2018) investigated generating pseudo references by compressing existing multiple references into a lattice and picking new sequences from it. Hu et al. (2019) used finetuned BERT (Devlin et al., 2019) as the data manipulation model to generate word substitutions via reinforcement learning. Another line of research focuses on filtering high-quality training examples for dialogue response generation. Cs´aky et al. (2019) proposed to remove generic responses using an entropy-based approach. Shang et al. (2018) trained a data calibration network to assign higher instance weight to more appropriate responses. 3.3 Expressive Dialogue Models Besides manipulating the training data, dialogue researchers have attempted to strengthen dialogue models’ capacity for capturing complex relations between t"
2021.sigdial-1.20,N16-1024,0,0.0322809,"ration. This confirms our earlier hypothesis that the one-to-many nature is an important characteristic that distinguishes opendomain dialogue modeling from other tasks such as machine translation. In task-oriented dialogues, Peng et al. (2019) proposed to transfer knowledge from multiple teachers for multi-domain task-oriented dialogue response generation via policy distillation and word-level output distillation. Tan et al. (2019) applied a similar approach to multilingual machine translation. Kuncoro et al. (2019) transferred syntactic knowledge from recurrent neural network grammar (RNNG, Dyer et al., 2016) models to a sequential language model. 3.2 Data Augmentation and Manipulation The multi-referenced training approach can be seen as a data augmentation method. Prior works on data augmentation in text generation tasks often operate on a word level while our method performs 191 sentence-level augmentation. Niu and Bansal (2019) proposed to apply semantic-preserving perturbations to input words for augmenting data in dialogue tasks. Zheng et al. (2018) investigated generating pseudo references by compressing existing multiple references into a lattice and picking new sequences from it. Hu et al"
2021.sigdial-1.20,P07-2045,0,0.0102178,"rence ignores the possibility of responding with other valid outputs and is thus insufficient for building a good dialogue system. The current dialogue modeling paradigm is largely derived from MT research, and it trains dialogue models with one output reference given each input. In this paper, we will investigate why single-referenced training harms our dialogue models and how to apply multi-referenced training. Introduction Open-domain dialogue modeling has been formulated as a seq2seq problem since Ritter et al. (2011) and Vinyals and Le (2015) borrowed machine translation (MT) techniques (Koehn et al., 2007; Sutskever et al., 2014) to build dialogue systems, where a model learns to map from one context to one response. In MT, one-to-one mapping is a reasonable assumption since an MT output is highly constrained by its input. Though we may use a variety of expressions to translate the same input sentence, these different translations still highly overlap with each other lexically and semantically 1 Code and data are available at https://github. com/ZHAOTING/dialog-processing/tree/ master/src/tasks/response_gen_multi_ response. 2 Why Multi-Referenced Training Matters? A dialogue context X can be c"
2021.sigdial-1.20,P19-1337,0,0.0169598,"training with multiple generated references can yield far better results in dialogue response generation. This confirms our earlier hypothesis that the one-to-many nature is an important characteristic that distinguishes opendomain dialogue modeling from other tasks such as machine translation. In task-oriented dialogues, Peng et al. (2019) proposed to transfer knowledge from multiple teachers for multi-domain task-oriented dialogue response generation via policy distillation and word-level output distillation. Tan et al. (2019) applied a similar approach to multilingual machine translation. Kuncoro et al. (2019) transferred syntactic knowledge from recurrent neural network grammar (RNNG, Dyer et al., 2016) models to a sequential language model. 3.2 Data Augmentation and Manipulation The multi-referenced training approach can be seen as a data augmentation method. Prior works on data augmentation in text generation tasks often operate on a word level while our method performs 191 sentence-level augmentation. Niu and Bansal (2019) proposed to apply semantic-preserving perturbations to input words for augmenting data in dialogue tasks. Zheng et al. (2018) investigated generating pseudo references by com"
2021.sigdial-1.20,N16-1014,0,0.02494,"bility. The new training objective is: Data We use the DailyDialog corpus (Li et al., 2017) to investigate the effects of the proposed methods. We make a roughly 0.8:0.1:0.1 session-level split for training, validation, and test, respectively.3 4.3 Proposal: Enhancing Data for Multi-Referenced Training where we assume responses Y2 to YN +1 are generated responses. Training with the new loss function can be achieved by directly replacing the ground-truth responses in the training data with the hypotheses.4 Sequences generated by beam search often highly overlap both lexically and semantically (Li et al., 2016). Therefore, we use nucleus sampling with top probability 0.95 (Holtzman et al., 2019) to generate 100 hypotheses as for each context in the training data. 5.1 Training with Hypotheses In this part, we compare baseline HRED models trained with only ground truth (GT) and with different numbers of hypotheses. Since using N hypotheses makes the training data N times larger, we accordingly adjust the maximum number of training epochs. We found that all the models can converge in the given epochs. 5 As shown in Table 1, replacing 1 GT with 1 hypothesis yields a boost on most metrics. Further increa"
2021.sigdial-1.20,I17-1099,0,0.0192758,"automated metrics. The authors reported Pearson’s ρ = 0.64 and Spearman’s ρ = 0.66 on the DailyDialog corpus. 3 To enhance the training data, we try to close the gap between PD (Y |X) and P (Y |X). Since all probability mass is on a single response in PD (Y |X), the gap can be closed by assigning some mass to other valid responses. We use a finetuned GPT2md to generate N hypotheses as valid responses, and let the probability mass to be assigned to them uniformly. It results in Pφ (Y |X) wherein N elements have N1 probability. The new training objective is: Data We use the DailyDialog corpus (Li et al., 2017) to investigate the effects of the proposed methods. We make a roughly 0.8:0.1:0.1 session-level split for training, validation, and test, respectively.3 4.3 Proposal: Enhancing Data for Multi-Referenced Training where we assume responses Y2 to YN +1 are generated responses. Training with the new loss function can be achieved by directly replacing the ground-truth responses in the training data with the hypotheses.4 Sequences generated by beam search often highly overlap both lexically and semantically (Li et al., 2016). Therefore, we use nucleus sampling with top probability 0.95 (Holtzman et"
2021.sigdial-1.20,D19-1132,0,0.0120132,"ted dialogue response generation via policy distillation and word-level output distillation. Tan et al. (2019) applied a similar approach to multilingual machine translation. Kuncoro et al. (2019) transferred syntactic knowledge from recurrent neural network grammar (RNNG, Dyer et al., 2016) models to a sequential language model. 3.2 Data Augmentation and Manipulation The multi-referenced training approach can be seen as a data augmentation method. Prior works on data augmentation in text generation tasks often operate on a word level while our method performs 191 sentence-level augmentation. Niu and Bansal (2019) proposed to apply semantic-preserving perturbations to input words for augmenting data in dialogue tasks. Zheng et al. (2018) investigated generating pseudo references by compressing existing multiple references into a lattice and picking new sequences from it. Hu et al. (2019) used finetuned BERT (Devlin et al., 2019) as the data manipulation model to generate word substitutions via reinforcement learning. Another line of research focuses on filtering high-quality training examples for dialogue response generation. Cs´aky et al. (2019) proposed to remove generic responses using an entropy-ba"
2021.sigdial-1.20,D16-1139,0,0.163914,"e to equip variational models with an expressive prior, named linear Gaussian model (LGM). Experimental results of automated evaluation and human evaluation show that the methods yield significant improvements over baselines.1 1 Dialogue I like cheese. Output 3 チーズが好き。 私はチーズが好き。 チーズが好きです。 What type of cheese? … … … Output 1 Output 2 Me too. I ﬁnd it disgusting. Figure 1: Examples of multiple valid outputs given the same input in machine translation and dialogue. (see the translation example in Figure 1), and learning from one output reference is often sufficient for training a good MT system (Kim and Rush, 2016). In dialogues, however, the same input can be continued with multiple diverse outputs which are different in both the used lexicons and the expressed semantic meanings (see the dialogue example in Figure 1). Learning from barely one output reference ignores the possibility of responding with other valid outputs and is thus insufficient for building a good dialogue system. The current dialogue modeling paradigm is largely derived from MT research, and it trains dialogue models with one output reference given each input. In this paper, we will investigate why single-referenced training harms ou"
2021.sigdial-1.20,P19-1372,0,0.0183654,"anism embeddings m into a seq2seq model for dialogue response generation. The mechanism-aware model decodes a response by selecting a mechanism embedding mk and combining it with context encoding c. Therefore, the model is capable of generating diverse responses by choosing different mechanisms. Zhang et al. (2018) borrowed the conditional value-at-risk (CVaR) from finance as an alternative to sentence likelihood (which is negated LD ) for optimization. Optimizing the CVaR objective can be seen as rejecting to optimize on easy instances whose model probabilities are larger than a threshold α. Qiu et al. (2019) proposed a two-step VHRED variant for modeling one-to-many relation. In the first step, they forced the dialogue encoding vector c to store common features of all response hypotheses Y2:N +1 by adversarial training. In the second step, they trained the latent variable z to capture response-specific information by training with a multiple bag-of-words (MBoW) loss. These three methods will be compared with the proposed model in this work as they have focused on modeling one-to-many relations in dialogue response generation. Gao et al. (2019) relied on vocabulary prediction to model sentence-lev"
2021.sigdial-1.20,D11-1054,0,0.149495,"Missing"
2021.sigdial-1.20,2020.acl-main.324,0,0.023383,"Missing"
2021.sigdial-1.20,P18-1137,0,0.0216427,"ight to more appropriate responses. 3.3 Expressive Dialogue Models Besides manipulating the training data, dialogue researchers have attempted to strengthen dialogue models’ capacity for capturing complex relations between the input context and the output responses. Zhou et al. (2017) incorporated mechanism embeddings m into a seq2seq model for dialogue response generation. The mechanism-aware model decodes a response by selecting a mechanism embedding mk and combining it with context encoding c. Therefore, the model is capable of generating diverse responses by choosing different mechanisms. Zhang et al. (2018) borrowed the conditional value-at-risk (CVaR) from finance as an alternative to sentence likelihood (which is negated LD ) for optimization. Optimizing the CVaR objective can be seen as rejecting to optimize on easy instances whose model probabilities are larger than a threshold α. Qiu et al. (2019) proposed a two-step VHRED variant for modeling one-to-many relation. In the first step, they forced the dialogue encoding vector c to store common features of all response hypotheses Y2:N +1 by adversarial training. In the second step, they trained the latent variable z to capture response-specifi"
2021.sigdial-1.20,P17-1061,0,0.0250766,"ues is often too complex to capture with a single vector c. Serban et al. (2017) proposed variational HRED (VHRED) and used a stochastic latent variable z that follows a multivariate Gaussian distribution to strengthen the model’s expressiveness. µ, σ = MLPθ (c) z ∼ Gaussian(µ, σ 2 I) Q Pθ (Yi |X) = L l=1 Dθ (Yi,l |Yi,:l−1 , c, z), where µ and σ 2 I are parameters of the Gaussian distribution. In order to mitigate the infamous posterior collapse problem in variational models, it is common to apply tricks such as annealing KLD loss (Bowman et al., 2016) and minimizing a bagof-words (BoW) loss (Zhao et al., 2017). 192 VHRED with GMM prior Gu et al. (2019) showed that the performance of the vanilla VHRED is limited by the single-modal nature of Gaussian distribution, and thus they proposed to use as prior a Gaussian Mixture Model (GMM) with K components to capture multiple modes in z’s probability distribution, such that z is sampled in the following way: µk , σ k , πk = MLPθ,k (c) z ∼ GMM({µk , σ 2k I, πk }K k=1 ), Human Evaluation Following Adiwardana et al. (2020), we ask Amazon MTurk human annotators to evaluate each response on two criteria, sensibleness and specificity. Both metrics take binary v"
2021.sigdial-1.20,2020.acl-main.4,1,0.799252,"Metrics We use perplexity on the test data as the metric for intrinsic evaluation. For extrinsic evaluation, we choose BLEU-2 and three types of word embedding similarities (Embedding Extrema, Embedding Average, Embedding Greedy) to measure the closeness between a hypothesis and the corresponding ground-truth reference. For diversity evaluation, we choose to count the number of generated unigram and bigram types at a corpuslevel. Dialogue Response Evaluator Besides the automated metrics above, we also use RoBERTa-eval, a model-based dialogue response evaluator, to approximate human judgement (Zhao et al., 2020). RoBERTa-eval computes the appropriateness (a real value from 1 to 5) of a response hypothesis by conditioning on its context instead of by comparing with its reference. It has been shown to correlate with human judgement significantly better than automated metrics. The authors reported Pearson’s ρ = 0.64 and Spearman’s ρ = 0.66 on the DailyDialog corpus. 3 To enhance the training data, we try to close the gap between PD (Y |X) and P (Y |X). Since all probability mass is on a single response in PD (Y |X), the gap can be closed by assigning some mass to other valid responses. We use a finetune"
2021.sigdial-1.20,D18-1357,0,0.0499212,"Missing"
2021.sigdial-1.27,2020.sigdial-1.15,1,0.861621,"Missing"
2021.sigdial-1.27,W16-3625,1,0.899776,"sed on the turn: body gestures during the system turn, and nodding during the user turn. Body gestures are intended to show openness to users during ERICA’s utterance, mainly moving her right hand, as shown in Figure 3(d) and (e). We design four versatile movements and play one of them randomly during ERICA’s utterance. During the user turn, ERICA nods to play the role of an active listener until 2.0 s of user silence is detected. To enhance the naturalness of ERICA’s behavior during the conversation, a random gazing model is also introduced. ERICA normally does speaker tracking using Kinect (Inoue et al., 2016, 2020), but since the participant in our case is not on-site, we model gazing behavior as a random uniform sampling of a gaze point nearby the webcam. The gaze point will be randomly changed within a hollow cylinder from the center of the webcam with an outer radius of 0.3 m, inner radius of 0.05 m, and width of 0.2 m. The gaze change decision is taken every 1.5 s. 3 Experiments We conducted a comparative evaluation to see how nonverbal information such as facial expressions and body gestures affect the user experience by asking volunteers to participate in a session with the Nora virtual age"
2021.sigdial-1.28,den-etal-2010-two,0,0.0653344,"Missing"
2021.sigdial-1.28,W08-0125,0,0.0264415,"Missing"
2021.sigdial-1.28,2020.sigdial-1.15,1,0.798892,"Missing"
2021.sigdial-1.28,W11-2042,0,0.0880088,"Missing"
akiba-etal-2008-test,maekawa-etal-2000-spontaneous,0,\N,Missing
akiba-etal-2012-designing,maekawa-etal-2000-spontaneous,0,\N,Missing
C00-1068,P99-1040,0,0.0173415,"ing computer-to-computer simulation (Watanabe et al., 1998). These works assume xed performance (averaged speech recognition accuracy) in whole dialogue with any speakers. For exible dialogue management, however the con rmation strategy must be dynamically changed based on the individual utterances. For instance, we human make con rmation only when we are not con dent. Similarly, con dence measures (CMs) of every speech recognition output should be modeled as a criterion to control dialogue management. CMs have been calculated in previous works using transcripts and various knowledge sources (Litman et al., 1999) (Pao et al., 1998). For more exible interaction, it is desirable that CMs are de ned on each word rather than whole sentence, because the system can handle only unreliable portions of an utterance instead of accepting/rejecting whole sentence. In this paper, we propose two concept-level CMs that are on content-word level and on semantic-attribute level for every content word. Because the CMs are de ned using only speech recognizer output, they can be computed in real time. The system can make ecient con rmation and e ective guidance according to the CMs. Even when successful interpretation i"
C00-1068,W85-0116,0,0.275544,"Missing"
C02-1152,P96-1009,0,0.197696,"ppliance manual where structured task knowledge is available. A hierarchical conrmation strategy is proposed by making use of a tree structure of the manual, and then three cost functions for selecting optimal question nodes are compared. Experimental evaluation demonstrates that the proposed system helps users nd their intended items more eciently. 1 Introduction In the past years, a great number of spoken dialogue systems have been developed. Their typical task domains include airline information (Levin et al., 2000 Potamianos et al., 2000 San-Segundo et al., 2000) and train information (Allen et al., 1996 Bennacef et al., 1996 Sturm et al., 1999 Lamel et al., 1999). Most of them model speech understanding process as converting recognition results into semantic representations equivalent to database query (SQL) commands, and dialogue process as disambiguating their unxed slots. Usually, the semantic slots are dened a priori and manually. The approach is workable only when data structure of the application is well-organized typically as a relational database (RDB). Dierent and more exible approach is needed for spoken dialogue interfaces to access information described in less rigid format,"
C02-1152,P98-1040,0,0.0237862,"unxed slots. Usually, the semantic slots are dened a priori and manually. The approach is workable only when data structure of the application is well-organized typically as a relational database (RDB). Dierent and more exible approach is needed for spoken dialogue interfaces to access information described in less rigid format, in particular normal text database. For the purpose, information retrieval (IR) technique is useful to nd a list of matching documents from the input query. Typically, keywords are extracted from the query and statistical matching is performed. Call routing task (Chu-Carroll and Carpenter, 1998) can be regarded as the special case. In IR systems, many candidates are usually obtained as a query result, thus there is a signicant problem of how to nd the user's intended item among them. Especially, either on the telephone or electrical appliances, there is not a large screen displaying the candidates, and all the query results cannot be presented to a user. So it is desirable for the system to narrow down the query results interactively. Moreover, interactive query is more friendly to novice users rather than requiring them to input a detailed query from the beginning. In this paper,"
C02-1152,C00-1068,1,0.875568,"m a user's utterance, and are matched with the system knowledge. Here, we adopt the following matching     Restaurant A Chinese noodles, meat dumpling, Shinjuku, Kabukicho, Ekoda Restaurant B Chinese noodles, meat dumpling, Shinjuku, Kabukicho, Restaurant C Chinese noodles, meat dumpling, noodles with boiled-pork-ribs, Takadanobaba Restaurant D Chinese noodles, fried garlic, Yebisu ... Figure 1: An example of system knowledge function for each item j .  X N Lj = CMi  log df i i2Kj Here, Kj is a set of keywords for item j . CMi is a condence measure of speech recognition for keyword i (Komatani and Kawahara, 2000), N is the total number of items, and dfi is the number of items including keyword i. Intuitively, keyword that is recognized with high condence and does not appear in many items gets higher likelihood Lj by CMi and dfi , respectively. Then, we dene amount of information that is obtained when the system generates yes/no question and the user answers it. Here, C is a current query condition, A is a condition that is added by the system's question, and count(x) is the number of items that satisfy the condition x. The condition consists of the conjunction of the keywords the user specied. Supp"
C02-1152,C00-1073,0,0.025941,"results eciently, using an example of a restaurant query task. The question is selected based on an information theoretic criterion. In section 3, we present a dialogue management method for a query task on the appliance manual where structured task knowledge is available. We propose a conrmation strategy by making use of a tree structure of the manual, and dene three cost functions for selecting question nodes. The method is evaluated by the number of average dialogue turns. Although there are previous studies on optimizing dialogue strategies (Niimi and Kobayashi, 1996 Levin et al., 1997 Litman et al., 2000), most of them assume the tasks of lling semantic slots that are denitely and manually dened, and few focus on follow-up dialogue of information retrieval. For example, (Denecke, 1997) proposed a method to generate guiding questions by making use of a tree structure constructed by unifying retrieved items based on semantic slots. In this paper, we do not assume any structure of semantic slots. Instead, we make use of distribution of document statistics or a structure of task knowledge. We also investigate cost functions for optimal dialogue control by taking into account of speech recogniti"
C02-1152,C98-1040,0,\N,Missing
C04-1158,P96-1009,0,0.0203743,"SR errors. If keywords to be conﬁrmed are deﬁned, the system can conﬁrm them using conﬁdence measures (Komatani and Kawahara, 2000; Hazen et al., 2000) to manage the errors. In conventional tasks for spoken dialogue systems in which their target of retrieval was well-deﬁned, such as the relational database, keywords that are important to achieve the tasks correspond to items in the relational database. Most spoken dialogue systems that have been developed, such as airline information systems (Levin et al., 2000; Potamianos et al., 2000; San-Segundo et al., 2000) and train information systems (Allen et al., 1996; Sturm et al., 1999; Lamel et al., 1999), are categorized here. However, it is not feasible to deﬁne such keywords in retrieval for operation manuals (Komatani et al., 2002) or WWW pages, where the target of retrieval is not organized and is written as natural language text. Another problem is that a user’s utterances may include redundant expressions or out-ofdomain phrases. A speech interface has been said to have the advantage of ease of input. This means that redundant expressions, such as disﬂuency and irrelevant phrases, are easily input. These do not directly contribute to task achieve"
C04-1158,C02-1169,0,0.0269486,"two statistical measures for identifying portions to be conﬁrmed. A relevance score represents the matching degree with the target knowledge base. A signiﬁcance score detects portions that consequently aﬀect the retrieval results. These measures are deﬁned based on information that is automatically derived from the target knowledge base. An experimental evaluation shows that our method improved the success rate of retrieval by generating conﬁrmation more eﬃciently than using a conventional conﬁdence measure. 1 Introduction Information retrieval systems with spoken language have been studied (Harabagiu et al., 2002; Hori et al., 2003). They require both automatic speech recognition (ASR) and information retrieval (IR) technologies. As a straight manifestation to create these systems, we can think of using ASR results as an input for IR systems that retrieve a text knowledge base (KB). However, two problems occur in the characteristics of speech. 1. Speech recognition errors 2. Redundancy included in spoken language expressions One is an ASR error, which is basically inevitable in speech communications. Therefore, an adequate conﬁrmation is indispensable in spoken dialogue systems to eliminate the misund"
C04-1158,C02-1084,0,0.0135181,"if a critical error provided by the Microsoft Corporation. The occurs in the ASR result, such as those in the knowledge base consists of the following three product name in software support, the followcomponents: glossary, frequently asked quesing retrieval would make no sense. Therefore, tions (FAQ), and a database of support articles. we also introduce a conﬁrmation prior to the Figure 1 is an example of the database. The retrieval for critical words. knowledge base is very large-scale, as shown in The system ﬂow including the conﬁrmation is Table 1. summarized below. The Dialog Navigator (Kiyota et al., 2002) 1. Recognize a user’s utterance. was developed in the University of Tokyo as a Summary: This article describes how to use speech recognition in Windows XP. If you installed speech recognition with Microsoft Oﬃce XP, or if you purchased a new computer that has Oﬃce XP installed, you can use speech recognition in all Oﬃce programs as well as other programs for which it is enabled. System Language model for ASR User Language model trained with KB Target text KB Dialog Navigator (text retrieval) TFIDF Speech input ASR (N-best candidates) Critical words Calculation of relevance score Confirmation"
C04-1158,C00-1068,1,0.931176,"traight manifestation to create these systems, we can think of using ASR results as an input for IR systems that retrieve a text knowledge base (KB). However, two problems occur in the characteristics of speech. 1. Speech recognition errors 2. Redundancy included in spoken language expressions One is an ASR error, which is basically inevitable in speech communications. Therefore, an adequate conﬁrmation is indispensable in spoken dialogue systems to eliminate the misunderstandings caused by ASR errors. If keywords to be conﬁrmed are deﬁned, the system can conﬁrm them using conﬁdence measures (Komatani and Kawahara, 2000; Hazen et al., 2000) to manage the errors. In conventional tasks for spoken dialogue systems in which their target of retrieval was well-deﬁned, such as the relational database, keywords that are important to achieve the tasks correspond to items in the relational database. Most spoken dialogue systems that have been developed, such as airline information systems (Levin et al., 2000; Potamianos et al., 2000; San-Segundo et al., 2000) and train information systems (Allen et al., 1996; Sturm et al., 1999; Lamel et al., 1999), are categorized here. However, it is not feasible to deﬁne such keywo"
C04-1158,C02-1152,1,0.844124,"rs. In conventional tasks for spoken dialogue systems in which their target of retrieval was well-deﬁned, such as the relational database, keywords that are important to achieve the tasks correspond to items in the relational database. Most spoken dialogue systems that have been developed, such as airline information systems (Levin et al., 2000; Potamianos et al., 2000; San-Segundo et al., 2000) and train information systems (Allen et al., 1996; Sturm et al., 1999; Lamel et al., 1999), are categorized here. However, it is not feasible to deﬁne such keywords in retrieval for operation manuals (Komatani et al., 2002) or WWW pages, where the target of retrieval is not organized and is written as natural language text. Another problem is that a user’s utterances may include redundant expressions or out-ofdomain phrases. A speech interface has been said to have the advantage of ease of input. This means that redundant expressions, such as disﬂuency and irrelevant phrases, are easily input. These do not directly contribute to task achievement and might even be harmful. ASR results that may include such redundant portions are not adequate for an input of IR systems. A novel method is described in this paper th"
C04-1158,J94-4001,0,0.0348672,"was trained. If the perplexity is small, it indicates the sequence appears frequently in the knowledge base. On the contrary, the perplexity for a portion including the ASR errors increases because it is contextually less frequent. The perplexity for out-ofdomain phrases similarly increases because they scarcely appear in the knowledge base. It enables us to detect a portion that is not inﬂuential for retrieval or those portions that include ASR errors. Here, a phrase, called bunsetsu1 in Japanese, is adopted as a portion for which the perplexity is calculated. We use a syntactic parser KNP (Kurohashi and Nagao, 1994) to divide the ASR results into the phrases2. 1 Bunsetsu is a commonly used linguistic unit in Japanese, which consists of one or more content words and zero or more functional words that follow. 2 As the parser was designed for written language, the division often fails for portions including ASR errors. The division error, however, does not aﬀect the whole system’s performance because the perplexity for the erroneous portions increases, indicating they are irrelevant.   3.2 Conﬁrmation for Critical Words using Relevance Score Critical words should be conﬁrmed before the retrieval. This is"
C04-1158,P03-2028,0,\N,Missing
C04-1159,P96-1025,0,0.0898547,"ependency is represented by a probability estimated by a dependency probability model. Given sentence S, let us assume that it is uniquely divided into n bunsetsus, b1 , . . . , bn , and that it is represented as an ordered set of bunsetsus, B = {b1 , . . . , bn }. Let D be an ordered set of dependencies in the sentence and let Di be a dependency whose modiﬁer is bunsetsu bi (i = 1, . . . , n − 1). Let us also assume that D = {D1 , . . . , Dn−1 }. Statistical dependency structure analysis ﬁnds dependencies that maximize probability P (D|S) given sentence S. The conventional statistical model (Collins, 1996; Fujio and Matsumoto, 1998; Haruno et al., 1998; Uchimoto et al., 1999) uses only the relationship between two bunsetsus to estimate the probability of dependency, whereas the model in this study (Uchimoto et al., 2000) takes into account not only the relationship between two bunsetsus but also the relationship between the left bunsetsu and all the bunsetsus to its right. This model uses more information than the conventional model. We implemented this model within a maximum entropy modeling framework. The features used in the model were basically attributes of bunsetsus, such as character st"
C04-1159,W98-1511,0,0.65108,"is a big diﬀerence between a written text corpus and a spontaneous speech corpus: In spontaneous speech, especially when it is long, sentence boundaries are often ambiguous. In the CSJ, therefore, sentence boundaries were deﬁned based on clauses whose boundaries were automatically detected by using surface information (Maruyama et al., 2003), and they were detected manually (Takanashi et al., 2003). Our deﬁnition of sentence boundaries follows the deﬁnition used in the CSJ. Almost all previous research on Japanese dependency structure analysis dealt with dependency structures in written text (Fujio and Matsumoto, 1998; Haruno et al., 1998; Uchimoto et al., 1999; Uchimoto et al., 2000; Kudo and Matsumoto, 2000). Although Matsubara and colleagues did investigate dependency structures in spontaneous speech (Matsubara et al., 2002), the target speech was dialogues where the utterances were short and sentence boundaries could be easily deﬁned based on turn-taking data. In contrast, we investigated dependency structures in spontaneous and long speeches in the CSJ. The biggest problem in dependency structure analysis with spontaneous and long speeches is that sentence boundaries are ambiguous. Therefore, sentence"
C04-1159,P98-1083,0,0.545732,"a written text corpus and a spontaneous speech corpus: In spontaneous speech, especially when it is long, sentence boundaries are often ambiguous. In the CSJ, therefore, sentence boundaries were deﬁned based on clauses whose boundaries were automatically detected by using surface information (Maruyama et al., 2003), and they were detected manually (Takanashi et al., 2003). Our deﬁnition of sentence boundaries follows the deﬁnition used in the CSJ. Almost all previous research on Japanese dependency structure analysis dealt with dependency structures in written text (Fujio and Matsumoto, 1998; Haruno et al., 1998; Uchimoto et al., 1999; Uchimoto et al., 2000; Kudo and Matsumoto, 2000). Although Matsubara and colleagues did investigate dependency structures in spontaneous speech (Matsubara et al., 2002), the target speech was dialogues where the utterances were short and sentence boundaries could be easily deﬁned based on turn-taking data. In contrast, we investigated dependency structures in spontaneous and long speeches in the CSJ. The biggest problem in dependency structure analysis with spontaneous and long speeches is that sentence boundaries are ambiguous. Therefore, sentence boundaries should be"
C04-1159,W00-1303,0,0.079418,"us speech, especially when it is long, sentence boundaries are often ambiguous. In the CSJ, therefore, sentence boundaries were deﬁned based on clauses whose boundaries were automatically detected by using surface information (Maruyama et al., 2003), and they were detected manually (Takanashi et al., 2003). Our deﬁnition of sentence boundaries follows the deﬁnition used in the CSJ. Almost all previous research on Japanese dependency structure analysis dealt with dependency structures in written text (Fujio and Matsumoto, 1998; Haruno et al., 1998; Uchimoto et al., 1999; Uchimoto et al., 2000; Kudo and Matsumoto, 2000). Although Matsubara and colleagues did investigate dependency structures in spontaneous speech (Matsubara et al., 2002), the target speech was dialogues where the utterances were short and sentence boundaries could be easily deﬁned based on turn-taking data. In contrast, we investigated dependency structures in spontaneous and long speeches in the CSJ. The biggest problem in dependency structure analysis with spontaneous and long speeches is that sentence boundaries are ambiguous. Therefore, sentence boundaries should be detected before or during dependency structure analysis in order to obta"
C04-1159,N01-1025,0,0.0382378,"e extracted as sentence boundary candidates. So, an output sequence is selected from all possible conversion patterns generated using two words to the left and two words to the right of each sentence boundary candidate. To perform this operation, we used a beam search with a width of 10 because a number of conversion patterns can be generated with such a search. 3.4 Sentence Boundary Detection Based on Machine Learning (Method 2) We use Support Vector Machine (SVM) as a machine learning model and we approached the problem of sentence boundary detection as a text chunking task. We used YamCha (Kudo and Matsumoto, 2001) as a text chunker, which is based on SVM and uses polynomial kernel functions. To determine the appropriate chunk label for a target word, YamCha uses two words to the right and two words to the left of the We used the IOE labeling scheme for proper chunking, and the following parameters for YamCha. • Degree of polynomial kernel: 3rd • Analysis direction: Left to right • Multi-class method: Pairwise 4 Experiments and Discussion In our experiments, we used the transcriptions of 188 talks in the CSJ. We used 10 talks for testing. Dependency structure analysis results were evaluated for closed-"
C04-1159,maekawa-etal-2000-spontaneous,1,0.878846,"Missing"
C04-1159,C02-1136,0,0.184882,"were deﬁned based on clauses whose boundaries were automatically detected by using surface information (Maruyama et al., 2003), and they were detected manually (Takanashi et al., 2003). Our deﬁnition of sentence boundaries follows the deﬁnition used in the CSJ. Almost all previous research on Japanese dependency structure analysis dealt with dependency structures in written text (Fujio and Matsumoto, 1998; Haruno et al., 1998; Uchimoto et al., 1999; Uchimoto et al., 2000; Kudo and Matsumoto, 2000). Although Matsubara and colleagues did investigate dependency structures in spontaneous speech (Matsubara et al., 2002), the target speech was dialogues where the utterances were short and sentence boundaries could be easily deﬁned based on turn-taking data. In contrast, we investigated dependency structures in spontaneous and long speeches in the CSJ. The biggest problem in dependency structure analysis with spontaneous and long speeches is that sentence boundaries are ambiguous. Therefore, sentence boundaries should be detected before or during dependency structure analysis in order to obtain the dependency structure of each sentence. In this paper, we ﬁrst describe the problems with dependency structure ana"
C04-1159,E99-1026,1,0.947104,"and a spontaneous speech corpus: In spontaneous speech, especially when it is long, sentence boundaries are often ambiguous. In the CSJ, therefore, sentence boundaries were deﬁned based on clauses whose boundaries were automatically detected by using surface information (Maruyama et al., 2003), and they were detected manually (Takanashi et al., 2003). Our deﬁnition of sentence boundaries follows the deﬁnition used in the CSJ. Almost all previous research on Japanese dependency structure analysis dealt with dependency structures in written text (Fujio and Matsumoto, 1998; Haruno et al., 1998; Uchimoto et al., 1999; Uchimoto et al., 2000; Kudo and Matsumoto, 2000). Although Matsubara and colleagues did investigate dependency structures in spontaneous speech (Matsubara et al., 2002), the target speech was dialogues where the utterances were short and sentence boundaries could be easily deﬁned based on turn-taking data. In contrast, we investigated dependency structures in spontaneous and long speeches in the CSJ. The biggest problem in dependency structure analysis with spontaneous and long speeches is that sentence boundaries are ambiguous. Therefore, sentence boundaries should be detected before or dur"
C04-1159,2000.iwpt-1.43,1,0.944091,"ch corpus: In spontaneous speech, especially when it is long, sentence boundaries are often ambiguous. In the CSJ, therefore, sentence boundaries were deﬁned based on clauses whose boundaries were automatically detected by using surface information (Maruyama et al., 2003), and they were detected manually (Takanashi et al., 2003). Our deﬁnition of sentence boundaries follows the deﬁnition used in the CSJ. Almost all previous research on Japanese dependency structure analysis dealt with dependency structures in written text (Fujio and Matsumoto, 1998; Haruno et al., 1998; Uchimoto et al., 1999; Uchimoto et al., 2000; Kudo and Matsumoto, 2000). Although Matsubara and colleagues did investigate dependency structures in spontaneous speech (Matsubara et al., 2002), the target speech was dialogues where the utterances were short and sentence boundaries could be easily deﬁned based on turn-taking data. In contrast, we investigated dependency structures in spontaneous and long speeches in the CSJ. The biggest problem in dependency structure analysis with spontaneous and long speeches is that sentence boundaries are ambiguous. Therefore, sentence boundaries should be detected before or during dependency structur"
C04-1159,A97-1004,0,\N,Missing
C04-1159,C98-1080,0,\N,Missing
C12-1183,W11-2008,1,0.643275,"ond to but also vague and complex user requests related to, for example, tourist guides or news briefings. This type of application can be achieved through document retrieval in a corresponding domain. For example, we can turn to tourist guidebooks or relevant Wikipedia entries for information on the tourist domain (Misu and Kawahara, 2010). An intelligent dialogue system can be created by restricting the domain and using the knowledge from that domain (Kawahara, 2009). An interactive news navigator that generates dialogues based on news article archives has been developed along this concept (Yoshino et al., 2011). The automatic speech recognition (ASR) module for spoken dialogue systems (SDSs) needs an appropriate language model (LM) adapted to the task domain and style. Even an ASR system with a very large vocabulary cannot cover all proper nouns or named entities (NEs), which are critical in information retrieval. Ideally, an LM should be trained with a large-scale matched corpus, but in many cases this is not realistic. Therefore, two approaches are commonly adopted. The first involves mixing document texts of the target domain with a dialogue corpus of spoken-style expressions. The other involves"
H05-1126,C02-1084,0,0.0265539,"ter stage of the proposed framework, and present a clarification dialogue strategy to narrow down documents. 2.2 Task and back-end retrieval system Our task involves text retrieval from a large-scale knowledge base. For the target domain, we adopt a software support knowledge base (KB) provided by Microsoft Corporation. The knowledge base consists of the following three kinds: glossary, frequently asked questions (FAQ), and support articles. The specification is listed in Table 1, and there are about 40K documents in total. An example of support article is shown in Figure 2. Dialog Navigator (Kiyota et al., 2002) has been developed at University of Tokyo as a retrieval system for this KB. The system accepts a typed-text input from users and outputs a result of the retrieval. The system interprets an input sentence by taking syntactic dependency and synonymous expression into consideration for matching it with the KB. The target of the matching is the summaries and detail information in the support articles, and the titles of the Glossary and FAQ. The retrieved result is displayed to the user as the list of documents like Web   some questions, or may not belong to any category. For example, some docu"
H05-1126,P03-2028,0,\N,Missing
I13-1126,neubig-mori-2010-word,1,0.931736,"ly Annotated Corpora Koichiro Yoshino, Shinsuke Mori, Tatsuya Kawahara School of Informatics, Kyoto University Yoshida-Honmachi, Sakyo-ku, Kyoto 606-8501, Japan yoshino@ar.media.kyoto-u.ac.jp Abstract in target domain is not available in realistic cases, and it is difficult to apply the current supervised approaches to a new domain. When annotating only the domain-specific area, the use of a partially annotated corpus (Tsuboi et al., 2008; Sassano and Kurohashi, 2010) that allows incomplete annotations improves accuracy efficiently and reduce the number of annotations. The pointwise approach (Neubig and Mori, 2010) enables efficient use of such incomplete language resources in word segmentation tasks and requires only partial annotations for the relevant tasks and lower layer annotations on which they depend. We design a new P-A structure analysis method that enables us to directly estimate semantic role labels by referring to a model that is trained from a corpus that includes only partially annotated tag information without word dependencies. We present a novel scheme of predicate argument structure analysis that can be trained from partially annotated corpora. In order to allow partial annotation, th"
I13-1126,P11-2093,1,0.867501,"ted. Various special approaches can be applied after SRL to solve this problem (Sasano and Kurohashi, 2009; Iida and Poesio, 2011; Hayashibe et al., 2011). Some approaches adopt a Salience Reference List (Nariyama, 2002) based on the 1-best argument decision model. 3 Partial annotation for P-A structures Partial annotation allows annotators to focus on efficient examples in the target domain document, and to maximize the cost-effectiveness of annotation. For automatic word segmentation and POS tagging, the scheme allows partial annotation of corpus (Tsuboi et al., 2008; Neubig and Mori, 2010; Neubig et al., 2011) and achieves high accuracy and domain portability though annotation of domain-specific areas. Neubig et al. (2011) report that a comparable accuracy to a CRF-based sequential labeling method can be achieved without referring to the estimated labels for unlabeled words. They call this method a pointwise approach. Even with the pointwise assumption, we can estimate labels as accurately as sequential labeling just by referring to the appropriate features. We design a P-A structure analyzer that directly estimates the semantic role labels by referring to a model that is trained from a corpus. It"
I13-1126,J05-1004,0,0.0429399,"ain adaptation of training data and improves the adaptability to a variety of domains. 1 Introduction The predicate-argument (P-A) structure is one of the most fundamental and important representations in linguistics (Fillmore, 1968). Many applications use P-A structure as a component, for example, QA systems (Shen and Lapata, 2007), text mining systems (Wang and Zhang, 2009), and a spoken dialogue systems (Yoshino et al., 2011). P-A structure analysis is regarded as a task of semantic role labeling (SRL). A semantic role represents a meaning of the components in P-A structure (i.e. Propbank (Palmer et al., 2005), FrameNet (Baker et al., 1998), and NAIST Text Corpus (NTC) (Iida et al., 2007b)). Traditional P-A structure analyzers estimate the semantic role labels for an input sentence by referring to a model trained on data annotated with not only semantic role labels but also dependency labels (Surdeanu et al., 2008; Hajiˇc et al., 2009). Most of the previous approaches to P-A structure analysis assume full annotation for P-A structures and the lower layer labels: word boundaries, parts of speech (POS), and dependencies. Given a corpus fully annotated with them, the structural prediction approach was"
I13-1126,J08-2006,0,0.0262757,"ls (Surdeanu et al., 2008; Hajiˇc et al., 2009). Most of the previous approaches to P-A structure analysis assume full annotation for P-A structures and the lower layer labels: word boundaries, parts of speech (POS), and dependencies. Given a corpus fully annotated with them, the structural prediction approach was shown to be effective (Watanabe et al., 2010). However, this pre-annotation incurs high annotation costs which prevent us from adapting the analyzer to new domains. Having training data that are representative of a domain is essential for constructing a robust semantic role labeler (Pradhan et al., 2008) because the important information structures are specific to each domain (R.Grishman, 2003). Fully annotated corpus 2 Predicate argument structure analysis In this section, we give a brief explanation of PA structure and its problems. Then, we describe the typical method of structural prediction for this task based on supervised machine learning. 2.1 Predicate-argument (P-A) structure A predicate-argument (P-A) structure is a relationship between a verbal expression and its arguments, such as the subject, the direct object, and the indirect object. Predicate P in a document D has arguments A1"
I13-1126,D09-1151,0,0.0211451,"ostly and difficult for untrained annotators. This difficulty interferes with efficient language resource preparation and reduces domain portability. However, the accuracy of P-A structure analysis increases in accordance with the data size. This indicates that we can realize an improvement just by easily preparing more training data for the target domain document. 2.2 Typical solution The typical solution divides the P-A structure prediction into two problems: semantic role labeling (SRL) (Johansson and Nugues, 2008; Bj¨orkelund et al., 2009) and zero-anaphora resolution (Iida et al., 2007a; Sasano and Kurohashi, 2009). The typical approach requires three preprocessing steps: word segmentation, POS tagging, and dependency parsing. After the preprocessing, the task of SRL improves assigning semantic role labels to the edges in word dependencies. A semantic role labeler performs two tasks: predicate sense estimation, and SRL. Zeroanaphora resolution is treated as an independent problem from the SRL task in the previous research. The zero-anaphora problem is caused by the ellipsis of shared words, and it is a gap in a sentence that has an anaphoric function (Iida et al., 2007a). Some semantic relationships exi"
I13-1126,I11-1085,0,0.314177,"ble 2 and 3. Evaluations that are classified with the existing depend and zero property are given in Table 2. Classifiers used in “w.o. feat. (3)” do not refer to case existence features (the binary feature (3) in Table 1). We can see that case frames play a large role in improving the labeling accuracy. This depend and zero property is based on the dependency, which cannot be referred to in the pointwise approach. As an alternative, we used sentence boundaries for the tag classification and Table 3 shows the result. The bottom “cf.” rows in Tables 2 and 3 are the result of the previous work (Sasano and Kurohashi, 2011) for comparison1 . In the comparison, the accuracies of our work are comparable to the accuracies of the previous work. By comparing the total F mea6 Conclusion We presented a novel scheme of P-A structure analysis based on the pointwise approach that makes it possible to use partially annotated corpora. This paper can be seen as an extension of the pointwise approach to a higher NLP layer that allows us to concentrate annotation work on the focused task. The results indicated that our scheme reduces the cost of constructing language resource and makes it easy to adapt the P-A structure analyz"
I13-1126,C08-1097,0,0.331007,"o the type of the predicate. This predicate and semantic case behavior strongly affects the SRL task. The oracle of the case existence is used for SRL features. For example, the predicate “bet” in Figure 5 contains information indicating that the predicate has two kinds of argument: “subject, zero” and “direct object depend.” We assume that the case existence for each predicate can be estimated with case frames (Kawahara and Kurohashi, 2006). A case frame is a set of a predicate and its potential arguments. It is known that the case frames contribute to the P-A structure analysis performance (Sasano et al., 2008). 5 Evaluations We conducted three experiments to evaluate the proposed method: SRL, corpus size discrimination, and domain adaptation. 4.2 SRL and zero-anaphora resolution The second step is SRL that includes zeroanaphora resolution. We handle the problem with a direct approach for SRL that is redefined as a binary classification problem for the pair of an argument candidate and a predicate. Labeled pairs of argument (arg) and predicate (pred) are used as positive training example and unlabeled pairs are used as negative training example. In the example of Figure 5, the pair of “fate” and “pa"
I13-1126,P10-1037,0,0.0270079,"ach. Even with the pointwise assumption, we can estimate labels as accurately as sequential labeling just by referring to the appropriate features. We design a P-A structure analyzer that directly estimates the semantic role labels by referring to a model that is trained from a corpus. It includes only partially annotated POS tags but not with dependency information for the following reasons. Automatic estimation of POS tags achieves high accuracy in domain adaptation cases, and the annotation cost is small (Neubig et al., 2011), but the accuracy for dependency parsing (Flannery et al., 2011; Sassano and Kurohashi, 2010) is not sufficiently high. However, handcraft annotation cost of dependency is so high, and it disturbs rapid preparation of annotation data. We show an example of a partially annotated corpus in Figure 2. The annotation of “reach” is incomplete, and the information that can be referred to by an analyzer is the fully annotated word boundaries, POS tags, and partially annotated P-A tags. Word boundaries and POS tags are output by 2.3 Open problems in P-A structure analysis Existing approaches require full annotation of word boundaries, POS tags, and word dependencies to use them as features. Mo"
I13-1126,D07-1002,0,0.0609882,"novel scheme of predicate argument structure analysis that can be trained from partially annotated corpora. In order to allow partial annotation, this semantic role labeler does not require word dependency information. The advantage of partial annotation is that it allows for smooth domain adaptation of training data and improves the adaptability to a variety of domains. 1 Introduction The predicate-argument (P-A) structure is one of the most fundamental and important representations in linguistics (Fillmore, 1968). Many applications use P-A structure as a component, for example, QA systems (Shen and Lapata, 2007), text mining systems (Wang and Zhang, 2009), and a spoken dialogue systems (Yoshino et al., 2011). P-A structure analysis is regarded as a task of semantic role labeling (SRL). A semantic role represents a meaning of the components in P-A structure (i.e. Propbank (Palmer et al., 2005), FrameNet (Baker et al., 1998), and NAIST Text Corpus (NTC) (Iida et al., 2007b)). Traditional P-A structure analyzers estimate the semantic role labels for an input sentence by referring to a model trained on data annotated with not only semantic role labels but also dependency labels (Surdeanu et al., 2008; Ha"
I13-1126,W08-2121,0,0.0352448,"Missing"
I13-1126,C12-1161,0,0.0232894,"Missing"
I13-1126,C08-1113,1,0.850905,"fill in the words that are semantically omitted. Various special approaches can be applied after SRL to solve this problem (Sasano and Kurohashi, 2009; Iida and Poesio, 2011; Hayashibe et al., 2011). Some approaches adopt a Salience Reference List (Nariyama, 2002) based on the 1-best argument decision model. 3 Partial annotation for P-A structures Partial annotation allows annotators to focus on efficient examples in the target domain document, and to maximize the cost-effectiveness of annotation. For automatic word segmentation and POS tagging, the scheme allows partial annotation of corpus (Tsuboi et al., 2008; Neubig and Mori, 2010; Neubig et al., 2011) and achieves high accuracy and domain portability though annotation of domain-specific areas. Neubig et al. (2011) report that a comparable accuracy to a CRF-based sequential labeling method can be achieved without referring to the estimated labels for unlabeled words. They call this method a pointwise approach. Even with the pointwise assumption, we can estimate labels as accurately as sequential labeling just by referring to the appropriate features. We design a P-A structure analyzer that directly estimates the semantic role labels by referring"
I13-1126,D09-1082,0,0.0288546,"analysis that can be trained from partially annotated corpora. In order to allow partial annotation, this semantic role labeler does not require word dependency information. The advantage of partial annotation is that it allows for smooth domain adaptation of training data and improves the adaptability to a variety of domains. 1 Introduction The predicate-argument (P-A) structure is one of the most fundamental and important representations in linguistics (Fillmore, 1968). Many applications use P-A structure as a component, for example, QA systems (Shen and Lapata, 2007), text mining systems (Wang and Zhang, 2009), and a spoken dialogue systems (Yoshino et al., 2011). P-A structure analysis is regarded as a task of semantic role labeling (SRL). A semantic role represents a meaning of the components in P-A structure (i.e. Propbank (Palmer et al., 2005), FrameNet (Baker et al., 1998), and NAIST Text Corpus (NTC) (Iida et al., 2007b)). Traditional P-A structure analyzers estimate the semantic role labels for an input sentence by referring to a model trained on data annotated with not only semantic role labels but also dependency labels (Surdeanu et al., 2008; Hajiˇc et al., 2009). Most of the previous app"
I13-1126,P10-2018,0,0.279139,", 1998), and NAIST Text Corpus (NTC) (Iida et al., 2007b)). Traditional P-A structure analyzers estimate the semantic role labels for an input sentence by referring to a model trained on data annotated with not only semantic role labels but also dependency labels (Surdeanu et al., 2008; Hajiˇc et al., 2009). Most of the previous approaches to P-A structure analysis assume full annotation for P-A structures and the lower layer labels: word boundaries, parts of speech (POS), and dependencies. Given a corpus fully annotated with them, the structural prediction approach was shown to be effective (Watanabe et al., 2010). However, this pre-annotation incurs high annotation costs which prevent us from adapting the analyzer to new domains. Having training data that are representative of a domain is essential for constructing a robust semantic role labeler (Pradhan et al., 2008) because the important information structures are specific to each domain (R.Grishman, 2003). Fully annotated corpus 2 Predicate argument structure analysis In this section, we give a brief explanation of PA structure and its problems. Then, we describe the typical method of structural prediction for this task based on supervised machine"
I13-1126,W11-2008,1,0.843432,"corpora. In order to allow partial annotation, this semantic role labeler does not require word dependency information. The advantage of partial annotation is that it allows for smooth domain adaptation of training data and improves the adaptability to a variety of domains. 1 Introduction The predicate-argument (P-A) structure is one of the most fundamental and important representations in linguistics (Fillmore, 1968). Many applications use P-A structure as a component, for example, QA systems (Shen and Lapata, 2007), text mining systems (Wang and Zhang, 2009), and a spoken dialogue systems (Yoshino et al., 2011). P-A structure analysis is regarded as a task of semantic role labeling (SRL). A semantic role represents a meaning of the components in P-A structure (i.e. Propbank (Palmer et al., 2005), FrameNet (Baker et al., 1998), and NAIST Text Corpus (NTC) (Iida et al., 2007b)). Traditional P-A structure analyzers estimate the semantic role labels for an input sentence by referring to a model trained on data annotated with not only semantic role labels but also dependency labels (Surdeanu et al., 2008; Hajiˇc et al., 2009). Most of the previous approaches to P-A structure analysis assume full annotati"
I13-1126,C12-1183,1,0.890997,"Missing"
I13-1126,P98-1013,0,0.0247373,"and improves the adaptability to a variety of domains. 1 Introduction The predicate-argument (P-A) structure is one of the most fundamental and important representations in linguistics (Fillmore, 1968). Many applications use P-A structure as a component, for example, QA systems (Shen and Lapata, 2007), text mining systems (Wang and Zhang, 2009), and a spoken dialogue systems (Yoshino et al., 2011). P-A structure analysis is regarded as a task of semantic role labeling (SRL). A semantic role represents a meaning of the components in P-A structure (i.e. Propbank (Palmer et al., 2005), FrameNet (Baker et al., 1998), and NAIST Text Corpus (NTC) (Iida et al., 2007b)). Traditional P-A structure analyzers estimate the semantic role labels for an input sentence by referring to a model trained on data annotated with not only semantic role labels but also dependency labels (Surdeanu et al., 2008; Hajiˇc et al., 2009). Most of the previous approaches to P-A structure analysis assume full annotation for P-A structures and the lower layer labels: word boundaries, parts of speech (POS), and dependencies. Given a corpus fully annotated with them, the structural prediction approach was shown to be effective (Watanab"
I13-1126,W09-1206,0,0.0577077,"Missing"
I13-1126,I11-1087,1,0.84542,"ethod a pointwise approach. Even with the pointwise assumption, we can estimate labels as accurately as sequential labeling just by referring to the appropriate features. We design a P-A structure analyzer that directly estimates the semantic role labels by referring to a model that is trained from a corpus. It includes only partially annotated POS tags but not with dependency information for the following reasons. Automatic estimation of POS tags achieves high accuracy in domain adaptation cases, and the annotation cost is small (Neubig et al., 2011), but the accuracy for dependency parsing (Flannery et al., 2011; Sassano and Kurohashi, 2010) is not sufficiently high. However, handcraft annotation cost of dependency is so high, and it disturbs rapid preparation of annotation data. We show an example of a partially annotated corpus in Figure 2. The annotation of “reach” is incomplete, and the information that can be referred to by an analyzer is the fully annotated word boundaries, POS tags, and partially annotated P-A tags. Word boundaries and POS tags are output by 2.3 Open problems in P-A structure analysis Existing approaches require full annotation of word boundaries, POS tags, and word dependenci"
I13-1126,E09-1026,0,0.0472369,"Missing"
I13-1126,J95-2003,0,0.221772,"a positive example Y, and pairs of “fate” and other candidates are negative examples N. The features used for classification are listed in Table 1. We use simple n-gram features based on words and POS tags. The pairwise features are POS pairs located at positions from -2 to +2, and pairs of the predicate and the argument candidates. The distance between the argument candidate and the predicate is used as a feature. We used the number of predicates between the predicate and the argument candidate as this feature. Binary features (1) and (2) are based on a previous study on “Centering” theory (Grosz et al., 1995). In this theory, subjects are frequently omitted, and the first candidate tends to be a subject. By contrast, objects are not omitted, and the last candidate tends to be an object. To apply the theory to a pointwise approach, we define features that are independent of syntactic structure. Finally, the result of the processing described above is used as a binary feature (3). Table 1: Features of SRL: wp is a predicate, wa is an argument candidate, ti is the POS tag of wi . type word 1-gram word 2-gram word 3-gram POS 1-gram POS 2-gram POS 3-gram pairwise distance binary feature wp−3 ,wp−2 ,wp−"
I13-1126,W09-1201,0,0.0244114,"Missing"
I13-1126,I11-1023,0,0.101367,"ious research. The zero-anaphora problem is caused by the ellipsis of shared words, and it is a gap in a sentence that has an anaphoric function (Iida et al., 2007a). Some semantic relationships exist in which there is no dependency relationship between their arguments and predicates; this is called zero anaphora. The task of P-A structure analysis goes beyond the syntactic problem and comes down to a semantic problem to fill in the words that are semantically omitted. Various special approaches can be applied after SRL to solve this problem (Sasano and Kurohashi, 2009; Iida and Poesio, 2011; Hayashibe et al., 2011). Some approaches adopt a Salience Reference List (Nariyama, 2002) based on the 1-best argument decision model. 3 Partial annotation for P-A structures Partial annotation allows annotators to focus on efficient examples in the target domain document, and to maximize the cost-effectiveness of annotation. For automatic word segmentation and POS tagging, the scheme allows partial annotation of corpus (Tsuboi et al., 2008; Neubig and Mori, 2010; Neubig et al., 2011) and achieves high accuracy and domain portability though annotation of domain-specific areas. Neubig et al. (2011) report that a comp"
I13-1126,P11-1081,0,0.172638,"he SRL task in the previous research. The zero-anaphora problem is caused by the ellipsis of shared words, and it is a gap in a sentence that has an anaphoric function (Iida et al., 2007a). Some semantic relationships exist in which there is no dependency relationship between their arguments and predicates; this is called zero anaphora. The task of P-A structure analysis goes beyond the syntactic problem and comes down to a semantic problem to fill in the words that are semantically omitted. Various special approaches can be applied after SRL to solve this problem (Sasano and Kurohashi, 2009; Iida and Poesio, 2011; Hayashibe et al., 2011). Some approaches adopt a Salience Reference List (Nariyama, 2002) based on the 1-best argument decision model. 3 Partial annotation for P-A structures Partial annotation allows annotators to focus on efficient examples in the target domain document, and to maximize the cost-effectiveness of annotation. For automatic word segmentation and POS tagging, the scheme allows partial annotation of corpus (Tsuboi et al., 2008; Neubig and Mori, 2010; Neubig et al., 2011) and achieves high accuracy and domain portability though annotation of domain-specific areas. Neubig et al."
I13-1126,W07-1522,0,0.250021,"ins. 1 Introduction The predicate-argument (P-A) structure is one of the most fundamental and important representations in linguistics (Fillmore, 1968). Many applications use P-A structure as a component, for example, QA systems (Shen and Lapata, 2007), text mining systems (Wang and Zhang, 2009), and a spoken dialogue systems (Yoshino et al., 2011). P-A structure analysis is regarded as a task of semantic role labeling (SRL). A semantic role represents a meaning of the components in P-A structure (i.e. Propbank (Palmer et al., 2005), FrameNet (Baker et al., 1998), and NAIST Text Corpus (NTC) (Iida et al., 2007b)). Traditional P-A structure analyzers estimate the semantic role labels for an input sentence by referring to a model trained on data annotated with not only semantic role labels but also dependency labels (Surdeanu et al., 2008; Hajiˇc et al., 2009). Most of the previous approaches to P-A structure analysis assume full annotation for P-A structures and the lower layer labels: word boundaries, parts of speech (POS), and dependencies. Given a corpus fully annotated with them, the structural prediction approach was shown to be effective (Watanabe et al., 2010). However, this pre-annotation in"
I13-1126,D08-1008,0,0.0130355,"re analyzer, we need to annotate the entire document. To make it worse, these kinds of annotations are costly and difficult for untrained annotators. This difficulty interferes with efficient language resource preparation and reduces domain portability. However, the accuracy of P-A structure analysis increases in accordance with the data size. This indicates that we can realize an improvement just by easily preparing more training data for the target domain document. 2.2 Typical solution The typical solution divides the P-A structure prediction into two problems: semantic role labeling (SRL) (Johansson and Nugues, 2008; Bj¨orkelund et al., 2009) and zero-anaphora resolution (Iida et al., 2007a; Sasano and Kurohashi, 2009). The typical approach requires three preprocessing steps: word segmentation, POS tagging, and dependency parsing. After the preprocessing, the task of SRL improves assigning semantic role labels to the edges in word dependencies. A semantic role labeler performs two tasks: predicate sense estimation, and SRL. Zeroanaphora resolution is treated as an independent problem from the SRL task in the previous research. The zero-anaphora problem is caused by the ellipsis of shared words, and it is"
I13-1126,N06-1023,0,0.0254209,"es that are clearly annotated. 4.1 Case existence detection The first step in the proposed sequential analysis is case existence estimation. The given semantic cases differ according to the type of the predicate. This predicate and semantic case behavior strongly affects the SRL task. The oracle of the case existence is used for SRL features. For example, the predicate “bet” in Figure 5 contains information indicating that the predicate has two kinds of argument: “subject, zero” and “direct object depend.” We assume that the case existence for each predicate can be estimated with case frames (Kawahara and Kurohashi, 2006). A case frame is a set of a predicate and its potential arguments. It is known that the case frames contribute to the P-A structure analysis performance (Sasano et al., 2008). 5 Evaluations We conducted three experiments to evaluate the proposed method: SRL, corpus size discrimination, and domain adaptation. 4.2 SRL and zero-anaphora resolution The second step is SRL that includes zeroanaphora resolution. We handle the problem with a direct approach for SRL that is redefined as a binary classification problem for the pair of an argument candidate and a predicate. Labeled pairs of argument (ar"
I13-1126,kawahara-etal-2002-construction,0,0.0449111,"Missing"
I13-1126,N07-1070,0,\N,Missing
I13-1126,C98-1013,0,\N,Missing
I13-1126,2002.tmi-papers.15,0,\N,Missing
I17-1071,W09-3949,0,0.0801018,"Missing"
I17-1071,W16-3625,1,0.828238,"boundaries. Accuracy, Macro F1 measure, and Weighted F1 measure are used for evaluation of the recognition task since it is a text classification problem. For the joint task, we use the DA Error Rate (DER) which is the same as the DSER but also considers the DA type for correctness. Table 4 demonstrates the calculation of DSER and DER. For each set of experiments, we also vary the length of history k for the cascading model and the joint training model. 5.1 4 165 1.76 30 8 Data Set We use a one-to-one Japanese chatting corpus collected using a conversational android ERICA (Glas et al., 2016; Inoue et al., 2016). It is annotated with 4 DA tags (i.e. Question, Statement, Response and Other) following standards in (Bunt et al., 2010). Table 3 presents related statistics. 1 2 708 https://www.tensorflow.org/ https://taku910.github.io/crfpp/ Reference Prediction DSER DER EG EG √ √ IS IS IS IS × × ES IS IQ ES IQ IQ × × EQ EQ IS IR ES ER √ × Table 4: An example of DSER and DER metrics. The DSER equals 0.5 (2/4) and the DER equals 0.75 (3/4). 5.5 11.5 In the task of DA recognition, we evaluate the model performances of DA recognition. Therefore, we directly use ground-truth segments as inputs and predict a D"
I17-1071,N16-1037,0,0.0577957,"Missing"
I17-1071,bunt-etal-2010-towards,0,0.0280787,"Missing"
I17-1071,C16-1189,0,0.030755,"Missing"
I17-1071,D13-1061,0,0.0221034,"documents, dialog utterances have much fewer words and it is difficult to extract enough information from simple word co-occurrence features. Secondly, it is of great importance to consider contexts in DA recognition. For instance, a sentence “the weather is quite good today” is regarded as an Answer if 3.1 Sentence Representation A sentence encoder encodes a sequence of words into a fixed-length vector. By training the encoder, it obtains the ability to mine useful task-related information from a word sequence. We choose Bidi705 ing model, and joint training model for accuracy. Zheng et al. (2013) applied a joint coding method to Chinese word segmentation and POS tagging by changing POS labels using a “BIES” tag coding scheme. Peng and Dredze (2016) improved NER by word representation learnt in word segmentation task using a LSTM-CRF model. Yang et al. (2016) proposed a multi-task cross-lingual model for sequence labeling tasks using RNN-CRF structures. These approaches to joint learning mostly attempt to learn shared representation of words and characters from different tasks. rectional Long Short-Term Memory (BiLSTM) - a variant of RNN. LSTM (Hochreiter and Schmidhuber, 1997) can bet"
I17-1071,N16-1062,0,0.0638366,"Missing"
I17-1071,C16-1185,0,0.038943,"Missing"
I17-1071,P16-2025,0,0.0222579,"es. Secondly, it is of great importance to consider contexts in DA recognition. For instance, a sentence “the weather is quite good today” is regarded as an Answer if 3.1 Sentence Representation A sentence encoder encodes a sequence of words into a fixed-length vector. By training the encoder, it obtains the ability to mine useful task-related information from a word sequence. We choose Bidi705 ing model, and joint training model for accuracy. Zheng et al. (2013) applied a joint coding method to Chinese word segmentation and POS tagging by changing POS labels using a “BIES” tag coding scheme. Peng and Dredze (2016) improved NER by word representation learnt in word segmentation task using a LSTM-CRF model. Yang et al. (2016) proposed a multi-task cross-lingual model for sequence labeling tasks using RNN-CRF structures. These approaches to joint learning mostly attempt to learn shared representation of words and characters from different tasks. rectional Long Short-Term Memory (BiLSTM) - a variant of RNN. LSTM (Hochreiter and Schmidhuber, 1997) can better avoid the vanishing gradient problem compared with normal RNNs, thus it is suitable for processing information through many time steps. t Input words w"
lee-etal-2002-continuous,itou-etal-2000-ipa,1,\N,Missing
P03-1033,A00-1014,0,0.0278293,"es have been proposed: confirmation management methods based on confidence measures of speech recognition results (Komatani and Kawahara, 2000; Hazen et al., 2000) and implicit confirmation that includes previous recognition results into system’s prompts (Sturm et al., 1999). In terms of determining what to say to the user, several studies have been done not only to output answers corresponding to user’s questions but also to generate cooperative responses (Sadek, 1999). Furthermore, methods have also been proposed to change the dialogue initiative based on various cues (Litman and Pan, 2000; Chu-Carroll, 2000; Lamel et al., 1999). Nevertheless, whether a particular response is cooperative or not depends on individual user’s characteristics. For example, when a user says nothing, the appropriate response should be different whether he/she is not accustomed to using the spoken dialogue systems or he/she does not know much about the target domain. Unless we detect the cause of the silence, the system may fall into the same situation repeatedly. In order to adapt the system’s behavior to individual users, it is necessary to model the user’s patterns (Kass and Finin, 1988). Most of conventional studies"
P03-1033,J88-3002,0,0.0733606,"rious cues (Litman and Pan, 2000; Chu-Carroll, 2000; Lamel et al., 1999). Nevertheless, whether a particular response is cooperative or not depends on individual user’s characteristics. For example, when a user says nothing, the appropriate response should be different whether he/she is not accustomed to using the spoken dialogue systems or he/she does not know much about the target domain. Unless we detect the cause of the silence, the system may fall into the same situation repeatedly. In order to adapt the system’s behavior to individual users, it is necessary to model the user’s patterns (Kass and Finin, 1988). Most of conventional studies on user models have focused on the knowledge of users. Others tried to infer and utilize user’s goals to generate responses adapted to the user (van Beek, 1987; Paris, 1988). Elzer et al. (2000) proposed a method to generate adaptive suggestions according to users’ preferences. However, these studies depend on knowledge of the target domain greatly, and therefore the user models need to be deliberated manually to be applied to new domains. Moreover, they assumed that the input is text only, which does not contain errors. On the other hand, spoken utterances inclu"
P03-1033,C00-1068,1,0.831103,"o obtain information from various places without any other special apparatuses. However, the speech interface involves two inevitable problems: one is speech recognition errors, and the other is that much information cannot be conveyed at once in speech communications. Therefore, the dialogue strategies, which determine when to make guidance and what the system should tell to the user, are the essential factors. To cope with speech recognition errors, several confirmation strategies have been proposed: confirmation management methods based on confidence measures of speech recognition results (Komatani and Kawahara, 2000; Hazen et al., 2000) and implicit confirmation that includes previous recognition results into system’s prompts (Sturm et al., 1999). In terms of determining what to say to the user, several studies have been done not only to output answers corresponding to user’s questions but also to generate cooperative responses (Sadek, 1999). Furthermore, methods have also been proposed to change the dialogue initiative based on various cues (Litman and Pan, 2000; Chu-Carroll, 2000; Lamel et al., 1999). Nevertheless, whether a particular response is cooperative or not depends on individual user’s charact"
P03-1033,J88-3006,0,0.130482,"ys nothing, the appropriate response should be different whether he/she is not accustomed to using the spoken dialogue systems or he/she does not know much about the target domain. Unless we detect the cause of the silence, the system may fall into the same situation repeatedly. In order to adapt the system’s behavior to individual users, it is necessary to model the user’s patterns (Kass and Finin, 1988). Most of conventional studies on user models have focused on the knowledge of users. Others tried to infer and utilize user’s goals to generate responses adapted to the user (van Beek, 1987; Paris, 1988). Elzer et al. (2000) proposed a method to generate adaptive suggestions according to users’ preferences. However, these studies depend on knowledge of the target domain greatly, and therefore the user models need to be deliberated manually to be applied to new domains. Moreover, they assumed that the input is text only, which does not contain errors. On the other hand, spoken utterances include various information such as the interval between utterances, the presence of barge-in and so on, which can be utilized to judge the user’s character. These features also possess generality in spoken di"
P03-1033,P87-1030,0,0.223327,"Missing"
P03-2027,J94-4001,1,\N,Missing
P03-2027,W03-1108,0,\N,Missing
P03-2027,C02-1166,0,\N,Missing
P03-2027,W02-0902,0,\N,Missing
P03-2027,C02-1084,1,\N,Missing
P06-2042,N01-1025,0,0.0438954,"ed to have no modifiee. In our experiments, we defined their dependencies as follows. ¯ The rightmost bunsetsu in a quotation or an inserted clause depends on the rightmost one in the sentence. ¯ If a sentence boundary is included in a quotation or an inserted clause, the bunsetsu to the immediate left of the boundary depends on the rightmost bunsetsu in the quotation or the inserted clause. ¯ Other bunsetsus that have no modifiee depend on the next one. 3.2 Detection of Quotations and Inserted Clauses We regard the problem of clause boundary detection as a text chunking task. We used YamCha (Kudo and Matsumoto, 2001) as a text chunker, which is based on Support Vector Machine (SVM). We used the chunk labels consisting of three tags which correspond to sentence boundaries, boundaries of quotations, and boundaries of inserted clauses, respectively. The tag for sentence 326 Table 1: Tag categories used for chunking Tag B E I O S Explanation of tag Beginning of a clause End of a clause Interior of a clause (except B and E) Exterior of a clause Clause consisting of one bunsetsu boundaries can be either E (the rightmost bunsetsu in a sentence) or I (the others). The tags for the boundaries of quotations and ins"
P06-2042,maekawa-etal-2000-spontaneous,1,0.746056,"a sentence is represented by dependency relationships between bunsetsus in the CSJ. For example, the sentence “彼は ゆっくり歩いている” (He is walking slowly) can be divided into three bunsetsus, “彼は, kare-wa” (he), “ゆっくり, yukkuri” (slowly), and “歩いて いる, arui-te-iru” (is walking). In this sentence, the first and second bunsetsus depend on the third one. The dependency structure is described as follows. 彼は─────┐ (he) │ ゆっくり─┤ (slowly) 歩いている (is walking) 1 Introduction The “Spontaneous Speech: Corpus and Processing Technology” project sponsored the construction of the Corpus of Spontaneous Japanese (CSJ) (Maekawa et al., 2000). The CSJ is the biggest spontaneous speech corpus in the world, consisting of roughly 7M words with the total speech length of 700 hours, and is a collection of monologues such as academic presentations and simulated public speeches. The CSJ includes transcriptions of the speeches as well as audio recordings of them. Approximately one tenth of the In this paper, we first describe the problems with dependency structure analysis of spontaneous speech. We focus on ambiguous clause boundaries as the biggest problem and present a solution. 2 Problems with Dependency Structure Analysis in Spontaneo"
P06-2042,2000.iwpt-1.43,1,0.73658,"propose a method for improving dependency structure analysis based on automatic detection of quotations and inserted clauses. 3 Dependency Structure Analysis and Detection of Quotations and Inserted Clauses The outline of the proposed processes is shown in Figure 1. Here, we use “clause” to describe a quotation and an inserted clause. Inserted Clauses In spontaneous speech, speakers insert clauses in the middle of other clauses. This occurs when speakers change their speech plans while produc325 3.1 Dependency Structure Analysis In this research, we use the method proposed by Uchimoto et al. (Uchimoto et al., 2000) to analyze dependency structures. This method is a twostep procedure, and the first step is preparation of a dependency matrix in which each element represents the likelihood that one bunsetsu depends on another. The second step of the analysis is finding an optimal set of dependencies for the entire sentence. The likelihood of dependency is represented by a probability, using a dependency probability model. The model in this study (Uchimoto et al., 2000) takes into account not only the relationship between two bunsetsus but also the relationship between the left bunsetsu and all the bunsetsu"
P06-2042,C04-1159,1,0.824005,"en written text and spontaneous speech, and consequently, problems peculiar to spontaneous speech arise in de324 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 324–330, c Sydney, July 2006. 2006 Association for Computational Linguistics pendency structure analysis, such as ambiguous clause boundaries, independent bunsetsus, crossed dependencies, self-corrections, and inversions. In this study, we address the problem of ambiguous clause boundaries in dependency structure analysis in spontaneous speech. We treated the other problems in the same way as Shitaoka et al. (Shitaoka et al., 2004). For example, inversions are represented as dependency relationships going in the direction from right to left in the CSJ, and their direction was changed to that from left to right in our experiments. In this paper, therefore, all the dependency relationships were assumed to go in the direction from left to right (Uchimoto et al., 2006). There are several types of clause boundaries such as sentence boundaries, boundaries of quotations and inserted clauses. In the CSJ, clause boundaries were automatically detected by using surface information (Maruyama et al., 2003), and sentence boundaries w"
P11-1064,N10-1028,0,0.636111,"tributions, and thus the parameters for the Pitman-Yor process will be different for each distribution. Further, as ll and lr must be smaller than l, Pt,l no longer contains itself as a base measure, and is thus not deficient. An example of the actual discount values learned in one of the experiments described in Section 7 is shown in Figure 2. It can be seen that, as expected, the discounts for short phrases are lower than 636 4.2 Implementation Previous research has used a variety of sampling methods to learn Bayesian phrase based alignment models (DeNero et al., 2008; Blunsom et al., 2009; Blunsom and Cohn, 2010). All of these techniques are applicable to the proposed model, but we choose to apply the sentence-based blocked sampling of Blunsom and Cohn (2010), which has desirable convergence properties compared to sampling single alignments. As exhaustive sampling is too slow for practical purpose, we adopt the beam search algorithm of Saers et al. (2009), and use a probability beam, trimming spans where the probability is at least 1010 times smaller than that of the best hypothesis in the bucket. One important implementation detail that is different from previous models is the management of phrase co"
P11-1064,P09-1088,0,0.778629,"nts. However, as DeNero and Klein (2010) note, this two step approach results in word alignments that are not optimal for the final task of generating In this paper, we propose the first unsupervised approach to joint alignment and extraction of phrases at multiple granularities. This is achieved by constructing a generative model that includes phrases at many levels of granularity, from minimal phrases all the way up to full sentences. The model is similar to previously proposed phrase alignment models based on inversion transduction grammars (ITGs) (Cherry and Lin, 2007; Zhang et al., 2008; Blunsom et al., 2009), with one important change: ITG symbols and phrase pairs are generated in the opposite order. In traditional ITG models, the branches of a biparse tree are generated from a nonterminal distribution, and each leaf is generated by a word or phrase pair distribution. As a result, only minimal phrases are directly included in the model, while larger phrases must be generated by heuristic extraction methods. In the proposed model, at each branch in the tree, we first attempt to generate a phrase pair from the phrase pair distribution, falling back to ITG-based divide and conquer strategy to genera"
P11-1064,J93-2003,0,0.0978707,"Missing"
P11-1064,W10-1703,0,0.0131603,"he proposed method on translation tasks from four languages, French, German, Spanish, and Japanese, into English. 638 TM (en) TM (other) LM (en) Tune (en ) Tune (other) Test (en) Test (other) de-en 1.80M 1.85M 52.7M 49.8k 47.2k 65.6k 62.7k es-en 1.62M 1.82M 52.7M 49.8k 52.6k 65.6k 68.1k fr-en 1.35M 1.56M 52.7M 49.8k 55.4k 65.6k 72.6k ja-en 2.38M 2.78M 44.7M 68.9k 80.4k 40.4k 48.7k Table 1: The number of words in each corpus for TM and LM training, tuning, and testing. 7.1 Experimental Setup The data for French, German, and Spanish are from the 2010 Workshop on Statistical Machine Translation (Callison-Burch et al., 2010). We use the news commentary corpus for training the TM, and the news commentary and Europarl corpora for training the LM. For Japanese, we use data from the NTCIR patent translation task (Fujii et al., 2008). We use the first 100k sentences of the parallel corpus for the TM, and the whole parallel corpus for the LM. Details of both corpora can be found in Table 1. Corpora are tokenized, lower-cased, and sentences of over 40 words on either side are removed for TM training. For both tasks, we perform weight tuning and testing on specified development and test sets. We compare the accuracy of o"
P11-1064,W07-0403,0,0.436106,"able that is consistent with these alignments. However, as DeNero and Klein (2010) note, this two step approach results in word alignments that are not optimal for the final task of generating In this paper, we propose the first unsupervised approach to joint alignment and extraction of phrases at multiple granularities. This is achieved by constructing a generative model that includes phrases at many levels of granularity, from minimal phrases all the way up to full sentences. The model is similar to previously proposed phrase alignment models based on inversion transduction grammars (ITGs) (Cherry and Lin, 2007; Zhang et al., 2008; Blunsom et al., 2009), with one important change: ITG symbols and phrase pairs are generated in the opposite order. In traditional ITG models, the branches of a biparse tree are generated from a nonterminal distribution, and each leaf is generated by a word or phrase pair distribution. As a result, only minimal phrases are directly included in the model, while larger phrases must be generated by heuristic extraction methods. In the proposed model, at each branch in the tree, we first attempt to generate a phrase pair from the phrase pair distribution, falling back to ITG-"
P11-1064,J07-2003,0,0.350869,"a fraction of the size of most heuristic extraction methods. Finally, we varied the size of the parallel corpus for the Japanese-English task from 50k to 400k senFor future work, we plan to refine HLEN to use a more appropriate model of phrase length than the uniform distribution, particularly by attempting to bias against phrase pairs where one of the two phrases is much longer than the other. In addition, we will test probabilities learned using the proposed model with an ITG-based decoder. We will also examine the applicability of the proposed model in the context of hierarchical phrases (Chiang, 2007), or in alignment using syntactic structure (Galley et al., 2006). It is also worth examining the plausibility of variational inference as proposed by Cohen et al. (2010) in the alignment context. Acknowledgments This work was performed while the first author was supported by the JSPS Research Fellowship for Young Scientists. References Figure 4: The effect of corpus size on the accuracy (a) and phrase table size (b) for each method (Japanese-English). tences and measured the effect of corpus size on translation accuracy. From the results in Figure 4 (a), it can be seen that at all corpus size"
P11-1064,N10-1081,0,0.293077,"rates from the symbol distribution Px , then from the phrase distribution Pt , while HIER generates directly from Pt , which falls back to divide-and-conquer based on Px when necessary. It can be seen that while Pt in FLAT only generates minimal phrases, Pt in HIER generates (and thus memorizes) phrases at all levels of granularity. 4.1 Length-based Parameter Tuning There are still two problems with HIER, one theoretical, and one practical. Theoretically, HIER contains itself as its base measure, and stochastic process models that include themselves as base measures are deficient, as noted in Cohen et al. (2010). Practically, while the Pitman-Yor process in HIER shares the parameters s and d over all phrase pairs in the model, long phrase pairs are much more sparse those of long phrases. In particular, phrase pairs of length up to six (for example, |e |= 3, |f |= 3) are given discounts of nearly zero while larger phrases are more heavily discounted. We conjecture that this is related to the observation by Koehn et al. (2003) that using phrases where max(|e|, |f |) ≤ 3 cause significant improvements in BLEU score, while using larger phrases results in diminishing returns. Figure 2: Learned discount va"
P11-1064,P05-1066,0,0.0803727,"Missing"
P11-1064,P08-2007,0,0.0326897,"Fi). We decompose this posterior probability using Bayes law into the corpus likelihood and parameter prior probabilities Wong (2002), DeNero et al. (2008), inter alia), and in particular a number of recent works (Cherry and Lin, 2007; Zhang et al., 2008; Blunsom et al., 2009) have used the formalism of inversion transduction grammars (ITGs) (Wu, 1997) to learn phrase alignments. By slightly limit reordering of words, ITGs make it possible to exactly calculate probabilities of phrasal alignments in polynomial time, which is a computationally hard problem when arbitrary reordering is allowed (DeNero and Klein, 2008). The traditional flat ITG generative probability for a particular phrase (or sentence) pair Pf lat (he, f i; θx , θt ) is parameterized by a phrase table θt and a symbol distribution θx . We use the following generative story as a representative of the flat ITG model. 1. Generate symbol x from the multinomial distribution Px (x; θx ). x can take the values TERM, REG , or INV . 2. According to the x take the following actions. (a) If x = TERM, generate a phrase pair from the phrase table Pt (he, f i; θt ). (b) If x = REG, a regular ITG rule, generate phrase pairs he1 , f1 i and he2 , f2 i from"
P11-1064,P10-1147,0,0.261523,"the accuracy of traditional two-step word alignment/phrase extraction approach while reducing the phrase table to a fraction of the original size. 1 Introduction The training of translation models for phrasebased statistical machine translation (SMT) systems (Koehn et al., 2003) takes unaligned bilingual training data as input, and outputs a scored table of phrase pairs. This phrase table is traditionally generated by going through a pipeline of two steps, first generating word (or minimal phrase) alignments, then extracting a phrase table that is consistent with these alignments. However, as DeNero and Klein (2010) note, this two step approach results in word alignments that are not optimal for the final task of generating In this paper, we propose the first unsupervised approach to joint alignment and extraction of phrases at multiple granularities. This is achieved by constructing a generative model that includes phrases at many levels of granularity, from minimal phrases all the way up to full sentences. The model is similar to previously proposed phrase alignment models based on inversion transduction grammars (ITGs) (Cherry and Lin, 2007; Zhang et al., 2008; Blunsom et al., 2009), with one importan"
P11-1064,W06-3105,0,0.0185751,"lso for phrases that, while not directly included in the model, are composed of two high probability child phrases. It should be noted that while for FLAT and HIER Pt can be used directly, as HLEN learns separate models for each length, we must combine these probabilities into a single value. We do this by setting Pt (he, f i) = Pt,l (he, f i)c(l)/ L ∑ c(˜l) ˜ l=1 for every phrase pair, where l = |e |+ |f |and c(l) is the number of phrases of length l in the sample. We call this model-based extraction method MOD. 5.3 Sample Combination As has been noted in previous works, (Koehn et al., 2003; DeNero et al., 2006) exhaustive phrase extraction tends to out-perform approaches that use syntax or generative models to limit phrase boundaries. DeNero et al. (2006) state that this is because generative models choose only a single phrase segmentation, and thus throw away many good phrase pairs that are in conflict with this segmentation. Luckily, in the Bayesian framework it is simple to overcome this problem by combining phrase tables from multiple samples. This is equivalent to approximating the integral over various parameter configurations in Equation (1). In MOD, we do this by taking the average of the jo"
P11-1064,D08-1033,0,0.563293,"Missing"
P11-1064,P06-1121,0,0.17041,"ds. Finally, we varied the size of the parallel corpus for the Japanese-English task from 50k to 400k senFor future work, we plan to refine HLEN to use a more appropriate model of phrase length than the uniform distribution, particularly by attempting to bias against phrase pairs where one of the two phrases is much longer than the other. In addition, we will test probabilities learned using the proposed model with an ITG-based decoder. We will also examine the applicability of the proposed model in the context of hierarchical phrases (Chiang, 2007), or in alignment using syntactic structure (Galley et al., 2006). It is also worth examining the plausibility of variational inference as proposed by Cohen et al. (2010) in the alignment context. Acknowledgments This work was performed while the first author was supported by the JSPS Research Fellowship for Young Scientists. References Figure 4: The effect of corpus size on the accuracy (a) and phrase table size (b) for each method (Japanese-English). tences and measured the effect of corpus size on translation accuracy. From the results in Figure 4 (a), it can be seen that at all corpus sizes, the results from all three methods are comparable, with insign"
P11-1064,D07-1103,0,0.0694819,"mentation. Luckily, in the Bayesian framework it is simple to overcome this problem by combining phrase tables from multiple samples. This is equivalent to approximating the integral over various parameter configurations in Equation (1). In MOD, we do this by taking the average of the joint probability and span probability features, and re-calculating the conditional probabilities from the averaged joint probabilities. 6 Related Work In addition to the previously mentioned phrase alignment techniques, there has also been a significant body of work on phrase extraction (Moore and Quirk (2007), Johnson et al. (2007a), inter alia). DeNero and Klein (2010) presented the first work on joint phrase alignment and extraction at multiple levels. While they take a supervised approach based on discriminative methods, we present a fully unsupervised generative model. A generative probabilistic model where longer units are built through the binary combination of shorter units was proposed by de Marcken (1996) for monolingual word segmentation using the minimum description length (MDL) framework. Our work differs in that it uses Bayesian techniques instead of MDL, and works on two languages, not one. Adaptor gramma"
P11-1064,P07-2045,0,0.00525629,"Missing"
P11-1064,N03-1017,0,0.562956,"not only by terminal, but also non-terminal symbols. This allows for a completely probabilistic model that is able to create a phrase table that achieves competitive accuracy on phrase-based machine translation tasks directly from unaligned sentence pairs. Experiments on several language pairs demonstrate that the proposed model matches the accuracy of traditional two-step word alignment/phrase extraction approach while reducing the phrase table to a fraction of the original size. 1 Introduction The training of translation models for phrasebased statistical machine translation (SMT) systems (Koehn et al., 2003) takes unaligned bilingual training data as input, and outputs a scored table of phrase pairs. This phrase table is traditionally generated by going through a pipeline of two steps, first generating word (or minimal phrase) alignments, then extracting a phrase table that is consistent with these alignments. However, as DeNero and Klein (2010) note, this two step approach results in word alignments that are not optimal for the final task of generating In this paper, we propose the first unsupervised approach to joint alignment and extraction of phrases at multiple granularities. This is achieve"
P11-1064,2005.iwslt-1.8,0,0.00647738,"tokenized, lower-cased, and sentences of over 40 words on either side are removed for TM training. For both tasks, we perform weight tuning and testing on specified development and test sets. We compare the accuracy of our proposed method of joint phrase alignment and extraction using the FLAT, HIER and HLEN models, with a baseline of using word alignments from GIZA ++ and heuristic phrase extraction. Decoding is performed using Moses (Koehn and others, 2007) using the phrase tables learned by each method under consideration, as well as standard bidirectional lexical reordering probabilities (Koehn et al., 2005). Maximum phrase length is limited to 7 in all models, and for the LM we use an interpolated Kneser-Ney 5-gram model. For GIZA ++, we use the standard training regimen up to Model 4, and combine alignments with grow-diag-final-and. For the proposed models, we train for 100 iterations, and use the final sample acquired at the end of the training process for our experiments using a single sample6 . In addition, 6 For most models, while likelihood continued to increase gradually for all 100 iterations, BLEU score gains plateaued after 5-10 iterations, likely due to the strong prior information Al"
P11-1064,N06-1014,0,0.0794575,"f |; λ) 1 M0 (he, f i) =(Pm1 (f |e)Puni (e)Pm1 (e|f )Puni (f )) 2 . Ppois is the Poisson distribution with the average length parameter λ. As long phrases lead to sparsity, we set λ to a relatively small value to allow us to bias against overly long phrases4 . Pm1 is the word-based Model 1 (Brown et al., 1993) probability of one phrase given the other, which incorporates word-based alignment information as prior knowledge in the phrase translation probability. We take the geometric mean5 of the Model 1 probabilities in both directions to encourage alignments that are supported by both models (Liang et al., 2006). It should be noted that while Model 1 probabilities are used, they are only soft constraints, compared with the hard constraint of choosing a single word alignment used in most previous phrase extraction approaches. For Pbu , if g is the non-null phrase in e and f , we calculate the probability as follows: Pbu (he, f i) = Puni (g)Ppois (|g|; λ)/2. Note that Pbu is divided by 2 as the probability is considering null alignments in both directions. 4 Hierarchical ITG Model While in FLAT only minimal phrases were memorized by the model, as DeNero et al. (2008) note We choose 10−2 , 10−3 , or 10−"
P11-1064,W02-1018,0,0.126279,"Missing"
P11-1064,W07-0715,0,0.0636315,"n conflict with this segmentation. Luckily, in the Bayesian framework it is simple to overcome this problem by combining phrase tables from multiple samples. This is equivalent to approximating the integral over various parameter configurations in Equation (1). In MOD, we do this by taking the average of the joint probability and span probability features, and re-calculating the conditional probabilities from the averaged joint probabilities. 6 Related Work In addition to the previously mentioned phrase alignment techniques, there has also been a significant body of work on phrase extraction (Moore and Quirk (2007), Johnson et al. (2007a), inter alia). DeNero and Klein (2010) presented the first work on joint phrase alignment and extraction at multiple levels. While they take a supervised approach based on discriminative methods, we present a fully unsupervised generative model. A generative probabilistic model where longer units are built through the binary combination of shorter units was proposed by de Marcken (1996) for monolingual word segmentation using the minimum description length (MDL) framework. Our work differs in that it uses Bayesian techniques instead of MDL, and works on two languages, n"
P11-1064,W99-0604,0,0.0831392,"on which value gives the best performance on the development set. 5 The probabilities of the geometric mean do not add to one, but we found empirically that even when left unnormalized, this provided much better results than the using the arithmetic mean, which is more theoretically correct. 3 and we confirm in the experiments in Section 7, using only minimal phrases leads to inferior translation results for phrase-based SMT. Because of this, previous research has combined FLAT with heuristic phrase extraction, which exhaustively combines all adjacent phrases permitted by the word alignments (Och et al., 1999). We propose an alternative, fully statistical approach that directly models phrases at multiple granularities, which we will refer to as HIER. By doing so, we are able to do away with heuristic phrase extraction, creating a fully probabilistic model for phrase probabilities that still yields competitive results. Similarly to FLAT, HIER assigns a probability Phier (he, f i; θx , θt ) to phrase pairs, and is parameterized by a phrase table θt and a symbol distribution θx . The main difference from the generative story of the traditional ITG model is that symbols and phrase pairs are generated i"
P11-1064,W09-3804,0,0.435467,"be seen that, as expected, the discounts for short phrases are lower than 636 4.2 Implementation Previous research has used a variety of sampling methods to learn Bayesian phrase based alignment models (DeNero et al., 2008; Blunsom et al., 2009; Blunsom and Cohn, 2010). All of these techniques are applicable to the proposed model, but we choose to apply the sentence-based blocked sampling of Blunsom and Cohn (2010), which has desirable convergence properties compared to sampling single alignments. As exhaustive sampling is too slow for practical purpose, we adopt the beam search algorithm of Saers et al. (2009), and use a probability beam, trimming spans where the probability is at least 1010 times smaller than that of the best hypothesis in the bucket. One important implementation detail that is different from previous models is the management of phrase counts. As a phrase pair ta may have been generated from two smaller component phrases tb and tc , when a sample containing ta is removed from the distribution, it may also be necessary to decrement the counts of tb and tc as well. The Chinese Restaurant Process representation of Pt (Teh, 2006) lends itself to a natural and easily implementable solu"
P11-1064,P06-1124,0,0.832206,"tribution, and each leaf is generated by a word or phrase pair distribution. As a result, only minimal phrases are directly included in the model, while larger phrases must be generated by heuristic extraction methods. In the proposed model, at each branch in the tree, we first attempt to generate a phrase pair from the phrase pair distribution, falling back to ITG-based divide and conquer strategy to generate phrase pairs that do not exist (or are given low probability) in the phrase distribution. We combine this model with the Bayesian nonparametric Pitman-Yor process (Pitman and Yor, 1997; Teh, 2006), realizing ITG-based divide and conquer through a novel formulation where the Pitman-Yor process uses two copies of itself as a 632 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 632–641, c Portland, Oregon, June 19-24, 2011. 2011 Association for Computational Linguistics base measure. As a result of this modeling strategy, phrases of multiple granularities are generated, and thus memorized, by the Pitman-Yor process. This makes it possible to directly use probabilities of the phrase model as a replacement for the phrase table generated by heuri"
P11-1064,J97-3002,0,0.466135,"le values of the hidden parameters: ∫ P (e|f , hE, Fi) = P (e|f , θ)P (θ|hE, Fi). (1) θ If θ takes the form of a scored phrase table, we can use traditional methods for phrase-based SMT to find P (e|f , θ) and concentrate on creating a model for P (θ|hE, Fi). We decompose this posterior probability using Bayes law into the corpus likelihood and parameter prior probabilities Wong (2002), DeNero et al. (2008), inter alia), and in particular a number of recent works (Cherry and Lin, 2007; Zhang et al., 2008; Blunsom et al., 2009) have used the formalism of inversion transduction grammars (ITGs) (Wu, 1997) to learn phrase alignments. By slightly limit reordering of words, ITGs make it possible to exactly calculate probabilities of phrasal alignments in polynomial time, which is a computationally hard problem when arbitrary reordering is allowed (DeNero and Klein, 2008). The traditional flat ITG generative probability for a particular phrase (or sentence) pair Pf lat (he, f i; θx , θt ) is parameterized by a phrase table θt and a symbol distribution θx . We use the following generative story as a representative of the flat ITG model. 1. Generate symbol x from the multinomial distribution Px (x;"
P11-1064,P08-1012,0,0.360881,"t with these alignments. However, as DeNero and Klein (2010) note, this two step approach results in word alignments that are not optimal for the final task of generating In this paper, we propose the first unsupervised approach to joint alignment and extraction of phrases at multiple granularities. This is achieved by constructing a generative model that includes phrases at many levels of granularity, from minimal phrases all the way up to full sentences. The model is similar to previously proposed phrase alignment models based on inversion transduction grammars (ITGs) (Cherry and Lin, 2007; Zhang et al., 2008; Blunsom et al., 2009), with one important change: ITG symbols and phrase pairs are generated in the opposite order. In traditional ITG models, the branches of a biparse tree are generated from a nonterminal distribution, and each leaf is generated by a word or phrase pair distribution. As a result, only minimal phrases are directly included in the model, while larger phrases must be generated by heuristic extraction methods. In the proposed model, at each branch in the tree, we first attempt to generate a phrase pair from the phrase pair distribution, falling back to ITG-based divide and con"
P12-1018,P02-1051,0,0.0205265,"ey et al., 2011). It has also been noted that it is more difficult to translate into morphologically rich languages, and methods for modeling target-side morphology have attracted interest in recent years (Bojar, 2007; Subotin, 2011). Another source of data sparsity that occurs in all languages is proper names, which have been handled by using cognates or transliteration to improve translation (Knight and Graehl, 1998; Kondrak et al., 2003; Finch and Sumita, 2007), and more sophisticated methods for named entity translation that combine translation and transliteration have also been proposed (Al-Onaizan and Knight, 2002). Choosing word units is also essential for creating good translation results for languages that do not explicitly mark word boundaries, such as Chinese, Japanese, and Thai. A number of works have dealt with this word segmentation problem in translation, mainly focusing on Chinese-to-English translation (Bai et al., 2008; Chang et al., 2008; Zhang et al., 2008b; Chung and Gildea, 2009; Nguyen et al., 2010), although these works generally assume that a word segmentation exists in one language (English) and attempt to optimize the word segmentation in the other language (Chinese). We have enumer"
P12-1018,I08-1033,0,0.0173092,"ed by using cognates or transliteration to improve translation (Knight and Graehl, 1998; Kondrak et al., 2003; Finch and Sumita, 2007), and more sophisticated methods for named entity translation that combine translation and transliteration have also been proposed (Al-Onaizan and Knight, 2002). Choosing word units is also essential for creating good translation results for languages that do not explicitly mark word boundaries, such as Chinese, Japanese, and Thai. A number of works have dealt with this word segmentation problem in translation, mainly focusing on Chinese-to-English translation (Bai et al., 2008; Chang et al., 2008; Zhang et al., 2008b; Chung and Gildea, 2009; Nguyen et al., 2010), although these works generally assume that a word segmentation exists in one language (English) and attempt to optimize the word segmentation in the other language (Chinese). We have enumerated these related works to demonstrate the myriad of data sparsity problems and proposed solutions. Character-based translation has the potential to handle all of the phenomena in the previously mentioned research in a single unified framework, requiring no language specific tools such as morphological analyzers or word"
P12-1018,N10-1028,0,0.511558,"r)I(as,S,u,U )I(aS,t,U,v ) s≤S≤t u≤U ≤v + X X Px (inv)I(as,S,U,v )I(aS,t,u,U ) s≤S≤t u≤U ≤v where Px (str) and Px (inv) are the probability of straight and inverted ITG productions. While the exact calculation of these probabilities can be performed in O(n6 ) time, where n is the 2 Pt can be specified according to Bayesian statistics as described by Neubig et al. (2011). 168 length of the sentence, this is impractical for all but the shortest sentences. Thus it is necessary to use methods to reduce the search space such as beamsearch based chart parsing (Saers et al., 2009) or slice sampling (Blunsom and Cohn, 2010).3 In this section we propose the use of a look-ahead probability to increase the efficiency of this chart parsing. Taking the example of Saers et al. (2009), spans are pushed onto a different queue based on their size, and queues are processed in ascending order of size. Agendas can further be trimmed based on a histogram beam (Saers et al., 2009) or probability beam (Neubig et al., 2011) compared to the best hypothesis a ˆ. In other words, we have a queue discipline based on the inside probability, and all spans ak where I(ak ) &lt; cI(ˆ a) are pruned. c is a constant describing the width of th"
P12-1018,P09-1088,0,0.0977356,"normalize or split the sentence into morpheme streams (Corston-Oliver and Gamon, 2004). 167 enough information to allow for effective alignment with its corresponding elements in eI1 . While this is often the case in word-based models, for characterbased models this assumption breaks down, as there is often no clear correspondence between characters. 3.2 Many-to-Many Alignment On the other hand, in recent years, there have been advances in many-to-many alignment techniques that are able to align multi-element chunks on both sides of the translation (Marcu and Wong, 2002; DeNero et al., 2008; Blunsom et al., 2009; Neubig et al., 2011). Many-to-many methods can be expected to achieve superior results on character-based alignment, as the aligner can use information about substrings, which may correspond to letters, morphemes, words, or short phrases. Here, we focus on the model presented by Neubig et al. (2011), which uses Bayesian inference in the phrasal inversion transduction grammar (ITG, Wu (1997)) framework. ITGs are a variety of synchronous context free grammar (SCFG) that allows for many-to-many alignment to be achieved in polynomial time through the process of biparsing, which we explain more i"
P12-1018,W07-0735,0,0.0131682,"is a major problem in agglutinative languages such as Finnish or compounding languages such as German. Previous works have attempted to handle morphology, decompounding and regularization through lemmatization, morphological analysis, or unsupervised techniques (Nießen and Ney, 2000; Brown, 2002; Lee, 2004; Goldwater and McClosky, 2005; Talbot and Osborne, 2006; Mermer and Akın, 2010; Macherey et al., 2011). It has also been noted that it is more difficult to translate into morphologically rich languages, and methods for modeling target-side morphology have attracted interest in recent years (Bojar, 2007; Subotin, 2011). Another source of data sparsity that occurs in all languages is proper names, which have been handled by using cognates or transliteration to improve translation (Knight and Graehl, 1998; Kondrak et al., 2003; Finch and Sumita, 2007), and more sophisticated methods for named entity translation that combine translation and transliteration have also been proposed (Al-Onaizan and Knight, 2002). Choosing word units is also essential for creating good translation results for languages that do not explicitly mark word boundaries, such as Chinese, Japanese, and Thai. A number of wor"
P12-1018,J93-2003,0,0.0971778,"ir. We represent our target and source sentences as eI1 and f J1 . ei and fj represent single elements of the target and source sentences respectively. These may be words in word-based alignment models or single characters in character-based alignment models.1 We define our alignment as aK 1 , where each element is a span ak = hs, t, u, vi indicating that the target string es , . . . , et and source string fu , . . . , fv are aligned to each-other. 3.1 One-to-Many Alignment The most well-known and widely-used models for bitext alignment are for one-to-many alignment, including the IBM models (Brown et al., 1993) and HMM alignment model (Vogel et al., 1996). These models are by nature directional, attempting to find the alignments that maximize the conditional probability of the target sentence P (eI1 |f J1 , aK 1 ). For computational reasons, the IBM models are restricted to aligning each word on the target side to a single word on the source side. In the formalism presented above, this means that each ei must be included in at most one span, and for each span u = v. Traditionally, these models are run in both directions and combined using heuristics to create many-to-many alignments (Koehn et al., 2"
P12-1018,2002.tmi-papers.3,0,0.0215762,"in the form of garbage collection, where uncommon words in one language are incorrectly aligned to large segments of the sentence in the other language (Och and Ney, 2003). Unknown words are also a problem during the translation process, and the default approach is to map them as-is into the target sentence. This is a major problem in agglutinative languages such as Finnish or compounding languages such as German. Previous works have attempted to handle morphology, decompounding and regularization through lemmatization, morphological analysis, or unsupervised techniques (Nießen and Ney, 2000; Brown, 2002; Lee, 2004; Goldwater and McClosky, 2005; Talbot and Osborne, 2006; Mermer and Akın, 2010; Macherey et al., 2011). It has also been noted that it is more difficult to translate into morphologically rich languages, and methods for modeling target-side morphology have attracted interest in recent years (Bojar, 2007; Subotin, 2011). Another source of data sparsity that occurs in all languages is proper names, which have been handled by using cognates or transliteration to improve translation (Knight and Graehl, 1998; Kondrak et al., 2003; Finch and Sumita, 2007), and more sophisticated methods f"
P12-1018,W08-0336,0,0.0274774,"Missing"
P12-1018,D09-1075,0,0.0227118,"ion (Knight and Graehl, 1998; Kondrak et al., 2003; Finch and Sumita, 2007), and more sophisticated methods for named entity translation that combine translation and transliteration have also been proposed (Al-Onaizan and Knight, 2002). Choosing word units is also essential for creating good translation results for languages that do not explicitly mark word boundaries, such as Chinese, Japanese, and Thai. A number of works have dealt with this word segmentation problem in translation, mainly focusing on Chinese-to-English translation (Bai et al., 2008; Chang et al., 2008; Zhang et al., 2008b; Chung and Gildea, 2009; Nguyen et al., 2010), although these works generally assume that a word segmentation exists in one language (English) and attempt to optimize the word segmentation in the other language (Chinese). We have enumerated these related works to demonstrate the myriad of data sparsity problems and proposed solutions. Character-based translation has the potential to handle all of the phenomena in the previously mentioned research in a single unified framework, requiring no language specific tools such as morphological analyzers or word segmenters. However, while the approach is attractive conceptual"
P12-1018,P06-3003,0,0.165382,"ter-based) Model 1 probability, which can be efficiently calculated using the dynamic programming algorithm described by Brown et al. (1993). However, for reasons previously stated in Section 3, these methods are less satisfactory when performing character-based alignment, as the amount of information contained in a character does not allow for proper alignment. 5.2 Substring Co-occurrence Priors Instead, we propose a method for using raw substring co-occurrence statistics to bias alignments towards substrings that often co-occur in the entire training corpus. This is similar to the method of Cromieres (2006), but instead of using these cooccurrence statistics as a heuristic alignment criterion, we incorporate them as a prior probability in a statistical model that can take into account mutual exclusivity of overlapping substrings in a sentence. We define this prior probability using three counts over substrings c(e), c(f ), and c(e, f ). c(e) and c(f ) count the total number of sentences in which the substrings e and f occur respectively. c(e, f ) is a count of the total number of sentences in which the substring e occurs on the target side, and f occurs on the source side. We perform the calcula"
P12-1018,D08-1033,0,0.0307241,"Missing"
P12-1018,W11-2107,0,0.014441,"riments, although it does indicate that we must have access to tokenized data for the development set. 7 171 6.2 Quantitative Evaluation Table 2 presents a quantitative analysis of the translation results for each of the proposed methods. As previous research has shown that it is more difficult to translate into morphologically rich languages than into English (Koehn, 2005), we perform experiments translating in both directions for all language pairs. We evaluate translation quality using BLEU score (Papineni et al., 2002), both on the word and character level (with n = 4), as well as METEOR (Denkowski and Lavie, 2011) on the word level. It can be seen that character-based translation with all of the proposed alignment improvements greatly exceeds character-based translation using one-to-many alignment, confirming that substringbased information is necessary for accurate alignments. When compared with word-based translation, character-based translation achieves better, comparable, or inferior results on character-based BLEU, comparable or inferior results on METEOR, and inferior results on word-based BLEU. The differences between the evaluation metrics are due to the fact that character-based translation of"
P12-1018,H05-1085,0,0.0216227,"ollection, where uncommon words in one language are incorrectly aligned to large segments of the sentence in the other language (Och and Ney, 2003). Unknown words are also a problem during the translation process, and the default approach is to map them as-is into the target sentence. This is a major problem in agglutinative languages such as Finnish or compounding languages such as German. Previous works have attempted to handle morphology, decompounding and regularization through lemmatization, morphological analysis, or unsupervised techniques (Nießen and Ney, 2000; Brown, 2002; Lee, 2004; Goldwater and McClosky, 2005; Talbot and Osborne, 2006; Mermer and Akın, 2010; Macherey et al., 2011). It has also been noted that it is more difficult to translate into morphologically rich languages, and methods for modeling target-side morphology have attracted interest in recent years (Bojar, 2007; Subotin, 2011). Another source of data sparsity that occurs in all languages is proper names, which have been handled by using cognates or transliteration to improve translation (Knight and Graehl, 1998; Kondrak et al., 2003; Finch and Sumita, 2007), and more sophisticated methods for named entity translation that combine"
P12-1018,P09-1104,0,0.122759,"when co-occurrence counts are used. More importantly, they allow for more aggressive beam pruning, increasing sampling speed from 1.3 sent/s to 2.5 sent/s for Finnish, and 6.8 sent/s to 11.6 sent/s for Japanese. 7 Conclusion and Future Directions This paper demonstrated that character-based translation can act as a unified framework for handling difficult problems in translation: morphology, compound words, transliteration, and segmentation. One future challenge includes scaling training up to longer sentences, which can likely be achieved through methods such as the heuristic span pruning of Haghighi et al. (2009) or sentence splitting of Vilar et al. (2007). Monolingual data could also be used to improve estimates of our substring-based prior. In addition, error analysis showed that wordbased translation performed better than characterbased translation on reordering and lexical choice, indicating that improved decoding (or pre-ordering) and language modeling tailored to character-based translation will likely greatly improve accuracy. Finally, we plan to explore the middle ground between word-based and character based translation, allowing for the flexibility of character-based translation, while usin"
P12-1018,N07-1018,0,0.0294521,"ng, 2003), and tic-tac-toe pruning for wordbased ITGs (Zhang and Gildea, 2005). As the calculation of the actual outside probability O(ak ) is just as expensive as parsing itself, it is necessary to approximate this with heuristic function O∗ that can be calculated efficiently. Here we propose a heuristic function that is designed specifically for phrasal ITGs and is computable with worst-case complexity of n2 , compared with the n3 amortized time of the tic-tac-toe pruning 3 Applying beam-search before sampling will sample from an improper distribution, although Metropolis-in-Gibbs sampling (Johnson et al., 2007) can be used to compensate. However, we found that this had no significant effect on results, so we omit the Metropolis-in-Gibbs step for experiments. algorithm described by (Zhang et al., 2008a). During the calculation of the phrase generation probabilities Pt , we save the best inside probability I ∗ for each monolingual span. Ie∗ (s, t) = max If∗ (u, v) = max {˜ a=h˜ s,t˜,˜ u,˜ v i;˜ s=s,t˜=t} Pt (˜ a) {˜ a=h˜ s,t˜,˜ u,˜ v i;˜ u=u,˜ v =v} Pt (˜ a) For each language independently, we calculate forward probabilities α and backward probabilities β. For example, αe (s) is the maximum probabilit"
P12-1018,N03-1016,0,0.0120405,"is unwise to ignore competing hypotheses during beam pruning. Particularly, the alignment “les/1960s” competes with the high-probability alignment “les/the,” so intuitively should be a good candidate for pruning. However its probability is only slightly higher than “ann´ees/1960s,” which has no competing hypotheses and thus should not be trimmed. In order to take into account competing hypotheses, we can use for our queue discipline not only the inside probability I(ak ), but also the outside probability O(ak ), the probability of generating all spans other than ak , as in A* search for CFGs (Klein and Manning, 2003), and tic-tac-toe pruning for wordbased ITGs (Zhang and Gildea, 2005). As the calculation of the actual outside probability O(ak ) is just as expensive as parsing itself, it is necessary to approximate this with heuristic function O∗ that can be calculated efficiently. Here we propose a heuristic function that is designed specifically for phrasal ITGs and is computable with worst-case complexity of n2 , compared with the n3 amortized time of the tic-tac-toe pruning 3 Applying beam-search before sampling will sample from an improper distribution, although Metropolis-in-Gibbs sampling (Johnson e"
P12-1018,N03-1017,0,0.0487988,"n et al., 1993) and HMM alignment model (Vogel et al., 1996). These models are by nature directional, attempting to find the alignments that maximize the conditional probability of the target sentence P (eI1 |f J1 , aK 1 ). For computational reasons, the IBM models are restricted to aligning each word on the target side to a single word on the source side. In the formalism presented above, this means that each ei must be included in at most one span, and for each span u = v. Traditionally, these models are run in both directions and combined using heuristics to create many-to-many alignments (Koehn et al., 2003). However, in order for one-to-many alignment methods to be effective, each fj must contain 1 Some previous work has also performed alignment using morphological analyzers to normalize or split the sentence into morpheme streams (Corston-Oliver and Gamon, 2004). 167 enough information to allow for effective alignment with its corresponding elements in eI1 . While this is often the case in word-based models, for characterbased models this assumption breaks down, as there is often no clear correspondence between characters. 3.2 Many-to-Many Alignment On the other hand, in recent years, there hav"
P12-1018,W04-3250,0,0.0751149,"35.45 en-fi 13.22 / 58.50 / 27.03 13.12 / 59.27 / 27.09 04.58 / 35.09 / 11.76 12.14 / 59.02 / 25.31 en-fr 32.19 / 69.20 / 52.39 31.66 / 69.61 / 51.98 10.31 / 42.84 / 25.06 27.74 / 67.44 / 48.56 en-ja 20.79 / 27.01 / 38.41 20.26 / 28.34 / 38.34 01.48 / 00.72 / 06.67 17.90 / 28.46 / 35.71 Table 2: Translation results in word-based BLEU, character-based BLEU, and METEOR for the GIZA++ and phrasal ITG models for word and character-based translation, with bold numbers indicating a statistically insignificant difference from the best system according to the bootstrap resampling method at p = 0.05 (Koehn, 2004). source and target were 100 characters or less,6 the total size of which is shown in Table 1. In characterbased translation, white spaces between words were treated as any other character and not given any special treatment. Evaluation was performed on tokenized and lower-cased data. For alignment, we use the GIZA++ implementation of one-to-many alignment7 and the pialign implementation of the phrasal ITG models8 modified with the proposed improvements. For GIZA++, we used the default settings for word-based alignment, but used the HMM model for character-based alignment to allow for alignmen"
P12-1018,2005.mtsummit-papers.11,0,0.090289,"ed enhancements to the model. Finally, we perform a qualitative analysis, which finds that character-based translation can handle unsegmented text, conjugation, and proper names in a unified framework with no additional processing. 2 Related Work on Data Sparsity in SMT As traditional SMT systems treat all words as single tokens without considering their internal structure, major problems of data sparsity occur for less frequent tokens. In fact, it has been shown that there is a direct negative correlation between vocabulary 166 size (and thus sparsity) of a language and translation accuracy (Koehn, 2005). Sparsity causes trouble for alignment models, both in the form of incorrectly aligned uncommon words, and in the form of garbage collection, where uncommon words in one language are incorrectly aligned to large segments of the sentence in the other language (Och and Ney, 2003). Unknown words are also a problem during the translation process, and the default approach is to map them as-is into the target sentence. This is a major problem in agglutinative languages such as Finnish or compounding languages such as German. Previous works have attempted to handle morphology, decompounding and regu"
P12-1018,N03-2016,0,0.0319786,"logical analysis, or unsupervised techniques (Nießen and Ney, 2000; Brown, 2002; Lee, 2004; Goldwater and McClosky, 2005; Talbot and Osborne, 2006; Mermer and Akın, 2010; Macherey et al., 2011). It has also been noted that it is more difficult to translate into morphologically rich languages, and methods for modeling target-side morphology have attracted interest in recent years (Bojar, 2007; Subotin, 2011). Another source of data sparsity that occurs in all languages is proper names, which have been handled by using cognates or transliteration to improve translation (Knight and Graehl, 1998; Kondrak et al., 2003; Finch and Sumita, 2007), and more sophisticated methods for named entity translation that combine translation and transliteration have also been proposed (Al-Onaizan and Knight, 2002). Choosing word units is also essential for creating good translation results for languages that do not explicitly mark word boundaries, such as Chinese, Japanese, and Thai. A number of works have dealt with this word segmentation problem in translation, mainly focusing on Chinese-to-English translation (Bai et al., 2008; Chang et al., 2008; Zhang et al., 2008b; Chung and Gildea, 2009; Nguyen et al., 2010), alth"
P12-1018,N04-4015,0,0.0188944,"f garbage collection, where uncommon words in one language are incorrectly aligned to large segments of the sentence in the other language (Och and Ney, 2003). Unknown words are also a problem during the translation process, and the default approach is to map them as-is into the target sentence. This is a major problem in agglutinative languages such as Finnish or compounding languages such as German. Previous works have attempted to handle morphology, decompounding and regularization through lemmatization, morphological analysis, or unsupervised techniques (Nießen and Ney, 2000; Brown, 2002; Lee, 2004; Goldwater and McClosky, 2005; Talbot and Osborne, 2006; Mermer and Akın, 2010; Macherey et al., 2011). It has also been noted that it is more difficult to translate into morphologically rich languages, and methods for modeling target-side morphology have attracted interest in recent years (Bojar, 2007; Subotin, 2011). Another source of data sparsity that occurs in all languages is proper names, which have been handled by using cognates or transliteration to improve translation (Knight and Graehl, 1998; Kondrak et al., 2003; Finch and Sumita, 2007), and more sophisticated methods for named en"
P12-1018,P11-1140,0,0.0221195,"e segments of the sentence in the other language (Och and Ney, 2003). Unknown words are also a problem during the translation process, and the default approach is to map them as-is into the target sentence. This is a major problem in agglutinative languages such as Finnish or compounding languages such as German. Previous works have attempted to handle morphology, decompounding and regularization through lemmatization, morphological analysis, or unsupervised techniques (Nießen and Ney, 2000; Brown, 2002; Lee, 2004; Goldwater and McClosky, 2005; Talbot and Osborne, 2006; Mermer and Akın, 2010; Macherey et al., 2011). It has also been noted that it is more difficult to translate into morphologically rich languages, and methods for modeling target-side morphology have attracted interest in recent years (Bojar, 2007; Subotin, 2011). Another source of data sparsity that occurs in all languages is proper names, which have been handled by using cognates or transliteration to improve translation (Knight and Graehl, 1998; Kondrak et al., 2003; Finch and Sumita, 2007), and more sophisticated methods for named entity translation that combine translation and transliteration have also been proposed (Al-Onaizan and K"
P12-1018,W02-1018,0,0.0382455,"alignment using morphological analyzers to normalize or split the sentence into morpheme streams (Corston-Oliver and Gamon, 2004). 167 enough information to allow for effective alignment with its corresponding elements in eI1 . While this is often the case in word-based models, for characterbased models this assumption breaks down, as there is often no clear correspondence between characters. 3.2 Many-to-Many Alignment On the other hand, in recent years, there have been advances in many-to-many alignment techniques that are able to align multi-element chunks on both sides of the translation (Marcu and Wong, 2002; DeNero et al., 2008; Blunsom et al., 2009; Neubig et al., 2011). Many-to-many methods can be expected to achieve superior results on character-based alignment, as the aligner can use information about substrings, which may correspond to letters, morphemes, words, or short phrases. Here, we focus on the model presented by Neubig et al. (2011), which uses Bayesian inference in the phrasal inversion transduction grammar (ITG, Wu (1997)) framework. ITGs are a variety of synchronous context free grammar (SCFG) that allows for many-to-many alignment to be achieved in polynomial time through the pr"
P12-1018,P11-1090,0,0.014234,"nsduction grammar (ITG, Wu (1997)) framework. ITGs are a variety of synchronous context free grammar (SCFG) that allows for many-to-many alignment to be achieved in polynomial time through the process of biparsing, which we explain more in the following section. Phrasal ITGs are ITGs that allow for non-terminals that can emit phrase pairs with multiple elements on both the source and target sides. It should be noted that there are other many-to-many alignment methods that have been used for simultaneously discovering morphological boundaries over multiple languages (Snyder and Barzilay, 2008; Naradowsky and Toutanova, 2011), but these have generally been applied to single words or short phrases, and it is not immediately clear that they will scale to aligning full sentences. 4 Look-Ahead Biparsing In this work, we experiment with the alignment method of Neubig et al. (2011), which can achieve competitive accuracy with a much smaller phrase table than traditional methods. This is important in the character-based translation context, as we would like to use phrases that contain large numbers of characters without creating a phrase table so large that it cannot be used in actual decoding. In this framework, trainin"
P12-1018,P11-1064,1,0.701097,"of traditional word-based systems using only character strings. We draw upon recent advances in many-to-many alignment, which allows for the automatic choice of the length of units to be aligned. As these units may be at the character, subword, word, or multi-word phrase level, we conjecture that this will allow for better character alignments than one-to-many alignment techniques, and will allow for better translation of uncommon words than traditional word-based models by breaking down words into their component parts. We also propose two improvements to the manyto-many alignment method of Neubig et al. (2011). One barrier to applying many-to-many alignment models to character strings is training cost. In the inversion transduction grammar (ITG) framework (Wu, 1997), which is widely used in many-to-many alignment, search is cumbersome for longer sentences, a problem that is further exacerbated when using characters instead of words as the basic unit. As a step towards overcoming this difficulty, we increase the efficiency of the beam-search technique of Saers et al. (2009) by augmenting it with look-ahead probabilities in the spirit of A* search. Secondly, we describe a method to seed the search pr"
P12-1018,C10-1092,0,0.0075172,"1998; Kondrak et al., 2003; Finch and Sumita, 2007), and more sophisticated methods for named entity translation that combine translation and transliteration have also been proposed (Al-Onaizan and Knight, 2002). Choosing word units is also essential for creating good translation results for languages that do not explicitly mark word boundaries, such as Chinese, Japanese, and Thai. A number of works have dealt with this word segmentation problem in translation, mainly focusing on Chinese-to-English translation (Bai et al., 2008; Chang et al., 2008; Zhang et al., 2008b; Chung and Gildea, 2009; Nguyen et al., 2010), although these works generally assume that a word segmentation exists in one language (English) and attempt to optimize the word segmentation in the other language (Chinese). We have enumerated these related works to demonstrate the myriad of data sparsity problems and proposed solutions. Character-based translation has the potential to handle all of the phenomena in the previously mentioned research in a single unified framework, requiring no language specific tools such as morphological analyzers or word segmenters. However, while the approach is attractive conceptually, previous research"
P12-1018,C00-2162,0,0.113372,"d uncommon words, and in the form of garbage collection, where uncommon words in one language are incorrectly aligned to large segments of the sentence in the other language (Och and Ney, 2003). Unknown words are also a problem during the translation process, and the default approach is to map them as-is into the target sentence. This is a major problem in agglutinative languages such as Finnish or compounding languages such as German. Previous works have attempted to handle morphology, decompounding and regularization through lemmatization, morphological analysis, or unsupervised techniques (Nießen and Ney, 2000; Brown, 2002; Lee, 2004; Goldwater and McClosky, 2005; Talbot and Osborne, 2006; Mermer and Akın, 2010; Macherey et al., 2011). It has also been noted that it is more difficult to translate into morphologically rich languages, and methods for modeling target-side morphology have attracted interest in recent years (Bojar, 2007; Subotin, 2011). Another source of data sparsity that occurs in all languages is proper names, which have been handled by using cognates or transliteration to improve translation (Knight and Graehl, 1998; Kondrak et al., 2003; Finch and Sumita, 2007), and more sophistica"
P12-1018,J03-1002,0,0.00795056,"traditional SMT systems treat all words as single tokens without considering their internal structure, major problems of data sparsity occur for less frequent tokens. In fact, it has been shown that there is a direct negative correlation between vocabulary 166 size (and thus sparsity) of a language and translation accuracy (Koehn, 2005). Sparsity causes trouble for alignment models, both in the form of incorrectly aligned uncommon words, and in the form of garbage collection, where uncommon words in one language are incorrectly aligned to large segments of the sentence in the other language (Och and Ney, 2003). Unknown words are also a problem during the translation process, and the default approach is to map them as-is into the target sentence. This is a major problem in agglutinative languages such as Finnish or compounding languages such as German. Previous works have attempted to handle morphology, decompounding and regularization through lemmatization, morphological analysis, or unsupervised techniques (Nießen and Ney, 2000; Brown, 2002; Lee, 2004; Goldwater and McClosky, 2005; Talbot and Osborne, 2006; Mermer and Akın, 2010; Macherey et al., 2011). It has also been noted that it is more diffi"
P12-1018,P02-1040,0,0.101074,"atmt.org/moses/ 11 We chose this set-up to minimize the effect of tuning criterion on our experiments, although it does indicate that we must have access to tokenized data for the development set. 7 171 6.2 Quantitative Evaluation Table 2 presents a quantitative analysis of the translation results for each of the proposed methods. As previous research has shown that it is more difficult to translate into morphologically rich languages than into English (Koehn, 2005), we perform experiments translating in both directions for all language pairs. We evaluate translation quality using BLEU score (Papineni et al., 2002), both on the word and character level (with n = 4), as well as METEOR (Denkowski and Lavie, 2011) on the word level. It can be seen that character-based translation with all of the proposed alignment improvements greatly exceeds character-based translation using one-to-many alignment, confirming that substringbased information is necessary for accurate alignments. When compared with word-based translation, character-based translation achieves better, comparable, or inferior results on character-based BLEU, comparable or inferior results on METEOR, and inferior results on word-based BLEU. The"
P12-1018,W09-3804,0,0.613151,"els by breaking down words into their component parts. We also propose two improvements to the manyto-many alignment method of Neubig et al. (2011). One barrier to applying many-to-many alignment models to character strings is training cost. In the inversion transduction grammar (ITG) framework (Wu, 1997), which is widely used in many-to-many alignment, search is cumbersome for longer sentences, a problem that is further exacerbated when using characters instead of words as the basic unit. As a step towards overcoming this difficulty, we increase the efficiency of the beam-search technique of Saers et al. (2009) by augmenting it with look-ahead probabilities in the spirit of A* search. Secondly, we describe a method to seed the search process using counts of all substring pairs in the corpus to bias the phrase alignment model. We do this by defining prior probabilities based on these substring counts within the Bayesian phrasal ITG framework. An evaluation on four language pairs with differing morphological properties shows that for distant language pairs, character-based SMT can achieve translation accuracy comparable to word-based systems. In addition, we perform ablation studies, showing that thes"
P12-1018,P08-1084,0,0.0198035,"n the phrasal inversion transduction grammar (ITG, Wu (1997)) framework. ITGs are a variety of synchronous context free grammar (SCFG) that allows for many-to-many alignment to be achieved in polynomial time through the process of biparsing, which we explain more in the following section. Phrasal ITGs are ITGs that allow for non-terminals that can emit phrase pairs with multiple elements on both the source and target sides. It should be noted that there are other many-to-many alignment methods that have been used for simultaneously discovering morphological boundaries over multiple languages (Snyder and Barzilay, 2008; Naradowsky and Toutanova, 2011), but these have generally been applied to single words or short phrases, and it is not immediately clear that they will scale to aligning full sentences. 4 Look-Ahead Biparsing In this work, we experiment with the alignment method of Neubig et al. (2011), which can achieve competitive accuracy with a much smaller phrase table than traditional methods. This is important in the character-based translation context, as we would like to use phrases that contain large numbers of characters without creating a phrase table so large that it cannot be used in actual dec"
P12-1018,P11-1024,0,0.0120071,"oblem in agglutinative languages such as Finnish or compounding languages such as German. Previous works have attempted to handle morphology, decompounding and regularization through lemmatization, morphological analysis, or unsupervised techniques (Nießen and Ney, 2000; Brown, 2002; Lee, 2004; Goldwater and McClosky, 2005; Talbot and Osborne, 2006; Mermer and Akın, 2010; Macherey et al., 2011). It has also been noted that it is more difficult to translate into morphologically rich languages, and methods for modeling target-side morphology have attracted interest in recent years (Bojar, 2007; Subotin, 2011). Another source of data sparsity that occurs in all languages is proper names, which have been handled by using cognates or transliteration to improve translation (Knight and Graehl, 1998; Kondrak et al., 2003; Finch and Sumita, 2007), and more sophisticated methods for named entity translation that combine translation and transliteration have also been proposed (Al-Onaizan and Knight, 2002). Choosing word units is also essential for creating good translation results for languages that do not explicitly mark word boundaries, such as Chinese, Japanese, and Thai. A number of works have dealt wi"
P12-1018,P06-1122,0,0.012896,"s in one language are incorrectly aligned to large segments of the sentence in the other language (Och and Ney, 2003). Unknown words are also a problem during the translation process, and the default approach is to map them as-is into the target sentence. This is a major problem in agglutinative languages such as Finnish or compounding languages such as German. Previous works have attempted to handle morphology, decompounding and regularization through lemmatization, morphological analysis, or unsupervised techniques (Nießen and Ney, 2000; Brown, 2002; Lee, 2004; Goldwater and McClosky, 2005; Talbot and Osborne, 2006; Mermer and Akın, 2010; Macherey et al., 2011). It has also been noted that it is more difficult to translate into morphologically rich languages, and methods for modeling target-side morphology have attracted interest in recent years (Bojar, 2007; Subotin, 2011). Another source of data sparsity that occurs in all languages is proper names, which have been handled by using cognates or transliteration to improve translation (Knight and Graehl, 1998; Kondrak et al., 2003; Finch and Sumita, 2007), and more sophisticated methods for named entity translation that combine translation and transliter"
P12-1018,2009.eamt-1.3,0,0.0804142,"for languages with explicit word The first author is now affiliated with the Nara Institute of Science and Technology. These difficulties occur because we are translating sequences of words as our basic unit. On the other hand, Vilar et al. (2007) examine the possibility of instead treating each sentence as sequences of characters to be translated. This method is attractive, as it is theoretically able to handle all sparsity phenomena in a single unified framework, but has only been shown feasible between similar language pairs such as Spanish-Catalan (Vilar et al., 2007), Swedish-Norwegian (Tiedemann, 2009), and ThaiLao (Sornlertlamvanich et al., 2008), which have a strong co-occurrence between single characters. As Vilar et al. (2007) state and we confirm, accurate translations cannot be achieved when applying traditional translation techniques to character-based translation for less similar language pairs. In this paper, we propose improvements to the alignment process tailored to character-based machine translation, and demonstrate that it is, in fact, possible to achieve translation accuracies that ap165 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics,"
P12-1018,W07-0705,0,0.459683,"d eI1 is assumed to be a word in the source and target languages. However, the definition of a “word” is often problematic. The most obvious example of this lies in languages that do not separate words with white space such as Chinese, Japanese, or Thai, in which the choice of a segmentation standard has a large effect on translation accuracy (Chang et al., 2008). Even for languages with explicit word The first author is now affiliated with the Nara Institute of Science and Technology. These difficulties occur because we are translating sequences of words as our basic unit. On the other hand, Vilar et al. (2007) examine the possibility of instead treating each sentence as sequences of characters to be translated. This method is attractive, as it is theoretically able to handle all sparsity phenomena in a single unified framework, but has only been shown feasible between similar language pairs such as Spanish-Catalan (Vilar et al., 2007), Swedish-Norwegian (Tiedemann, 2009), and ThaiLao (Sornlertlamvanich et al., 2008), which have a strong co-occurrence between single characters. As Vilar et al. (2007) state and we confirm, accurate translations cannot be achieved when applying traditional translation"
P12-1018,C96-2141,0,0.510173,"ces as eI1 and f J1 . ei and fj represent single elements of the target and source sentences respectively. These may be words in word-based alignment models or single characters in character-based alignment models.1 We define our alignment as aK 1 , where each element is a span ak = hs, t, u, vi indicating that the target string es , . . . , et and source string fu , . . . , fv are aligned to each-other. 3.1 One-to-Many Alignment The most well-known and widely-used models for bitext alignment are for one-to-many alignment, including the IBM models (Brown et al., 1993) and HMM alignment model (Vogel et al., 1996). These models are by nature directional, attempting to find the alignments that maximize the conditional probability of the target sentence P (eI1 |f J1 , aK 1 ). For computational reasons, the IBM models are restricted to aligning each word on the target side to a single word on the source side. In the formalism presented above, this means that each ei must be included in at most one span, and for each span u = v. Traditionally, these models are run in both directions and combined using heuristics to create many-to-many alignments (Koehn et al., 2003). However, in order for one-to-many align"
P12-1018,J97-3002,0,0.511044,"th of units to be aligned. As these units may be at the character, subword, word, or multi-word phrase level, we conjecture that this will allow for better character alignments than one-to-many alignment techniques, and will allow for better translation of uncommon words than traditional word-based models by breaking down words into their component parts. We also propose two improvements to the manyto-many alignment method of Neubig et al. (2011). One barrier to applying many-to-many alignment models to character strings is training cost. In the inversion transduction grammar (ITG) framework (Wu, 1997), which is widely used in many-to-many alignment, search is cumbersome for longer sentences, a problem that is further exacerbated when using characters instead of words as the basic unit. As a step towards overcoming this difficulty, we increase the efficiency of the beam-search technique of Saers et al. (2009) by augmenting it with look-ahead probabilities in the spirit of A* search. Secondly, we describe a method to seed the search process using counts of all substring pairs in the corpus to bias the phrase alignment model. We do this by defining prior probabilities based on these substring"
P12-1018,P05-1059,0,0.00986268,"arly, the alignment “les/1960s” competes with the high-probability alignment “les/the,” so intuitively should be a good candidate for pruning. However its probability is only slightly higher than “ann´ees/1960s,” which has no competing hypotheses and thus should not be trimmed. In order to take into account competing hypotheses, we can use for our queue discipline not only the inside probability I(ak ), but also the outside probability O(ak ), the probability of generating all spans other than ak , as in A* search for CFGs (Klein and Manning, 2003), and tic-tac-toe pruning for wordbased ITGs (Zhang and Gildea, 2005). As the calculation of the actual outside probability O(ak ) is just as expensive as parsing itself, it is necessary to approximate this with heuristic function O∗ that can be calculated efficiently. Here we propose a heuristic function that is designed specifically for phrasal ITGs and is computable with worst-case complexity of n2 , compared with the n3 amortized time of the tic-tac-toe pruning 3 Applying beam-search before sampling will sample from an improper distribution, although Metropolis-in-Gibbs sampling (Johnson et al., 2007) can be used to compensate. However, we found that this h"
P12-1018,P08-1012,0,0.710838,"n to improve translation (Knight and Graehl, 1998; Kondrak et al., 2003; Finch and Sumita, 2007), and more sophisticated methods for named entity translation that combine translation and transliteration have also been proposed (Al-Onaizan and Knight, 2002). Choosing word units is also essential for creating good translation results for languages that do not explicitly mark word boundaries, such as Chinese, Japanese, and Thai. A number of works have dealt with this word segmentation problem in translation, mainly focusing on Chinese-to-English translation (Bai et al., 2008; Chang et al., 2008; Zhang et al., 2008b; Chung and Gildea, 2009; Nguyen et al., 2010), although these works generally assume that a word segmentation exists in one language (English) and attempt to optimize the word segmentation in the other language (Chinese). We have enumerated these related works to demonstrate the myriad of data sparsity problems and proposed solutions. Character-based translation has the potential to handle all of the phenomena in the previously mentioned research in a single unified framework, requiring no language specific tools such as morphological analyzers or word segmenters. However, while the approach"
P12-1018,W08-0335,0,0.0813058,"n to improve translation (Knight and Graehl, 1998; Kondrak et al., 2003; Finch and Sumita, 2007), and more sophisticated methods for named entity translation that combine translation and transliteration have also been proposed (Al-Onaizan and Knight, 2002). Choosing word units is also essential for creating good translation results for languages that do not explicitly mark word boundaries, such as Chinese, Japanese, and Thai. A number of works have dealt with this word segmentation problem in translation, mainly focusing on Chinese-to-English translation (Bai et al., 2008; Chang et al., 2008; Zhang et al., 2008b; Chung and Gildea, 2009; Nguyen et al., 2010), although these works generally assume that a word segmentation exists in one language (English) and attempt to optimize the word segmentation in the other language (Chinese). We have enumerated these related works to demonstrate the myriad of data sparsity problems and proposed solutions. Character-based translation has the potential to handle all of the phenomena in the previously mentioned research in a single unified framework, requiring no language specific tools such as morphological analyzers or word segmenters. However, while the approach"
P12-1018,corston-oliver-gamon-2004-normalizing,0,\N,Missing
P12-1018,P10-3006,0,\N,Missing
P12-1018,I08-8003,0,\N,Missing
P12-1018,J98-4003,0,\N,Missing
uchimoto-etal-2006-dependency,E99-1026,1,\N,Missing
uchimoto-etal-2006-dependency,C02-1136,0,\N,Missing
uchimoto-etal-2006-dependency,P98-1083,0,\N,Missing
uchimoto-etal-2006-dependency,C98-1080,0,\N,Missing
uchimoto-etal-2006-dependency,C04-1159,1,\N,Missing
uchimoto-etal-2006-dependency,W98-1511,0,\N,Missing
uchimoto-etal-2006-dependency,maekawa-etal-2000-spontaneous,1,\N,Missing
uchimoto-etal-2006-dependency,W00-1303,0,\N,Missing
W03-2107,A00-1014,0,0.0321568,"ained query results. Another problem to realize user-friendly interaction is how to generate cooperative responses. When we consider the responses generated from the system side, the dialogue strategies, which determine when to make guidance and what the system should tell to the user, are the essential factors in spoken dialogue systems. There are many studies in respect of the dialogue strategy such as confirmation management using confidence measures of speech recognition results (Komatani and Kawahara, 2000; Hazen et al., 2000), dynamic change of dialogue initiative (Litman and Pan, 2000; Chu-Carroll, 2000; Lamel et al., 1999), and addition of cooperative contents to system responses (Sadek, 1999). Nevertheless, whether a particular response is cooperative or not depends on individual user’s characteristic. In order to adapt the system’s behavior to individual users, it is necessary to model the user’s patterns (Kass and Finin, 1988). Most of conventional studies on user models have focused on the knowledge of users. Others tried to infer and utilize user’s goals to generate responses adapted to the user (van Beek, 1987; Paris, 1988). Elzer et al. (2000) proposed a method to generate adaptive s"
W03-2107,J88-3002,0,0.100362,"e systems. There are many studies in respect of the dialogue strategy such as confirmation management using confidence measures of speech recognition results (Komatani and Kawahara, 2000; Hazen et al., 2000), dynamic change of dialogue initiative (Litman and Pan, 2000; Chu-Carroll, 2000; Lamel et al., 1999), and addition of cooperative contents to system responses (Sadek, 1999). Nevertheless, whether a particular response is cooperative or not depends on individual user’s characteristic. In order to adapt the system’s behavior to individual users, it is necessary to model the user’s patterns (Kass and Finin, 1988). Most of conventional studies on user models have focused on the knowledge of users. Others tried to infer and utilize user’s goals to generate responses adapted to the user (van Beek, 1987; Paris, 1988). Elzer et al. (2000) proposed a method to generate adaptive suggestions according to users’ preferences. However, these studies depend on knowledge of the target domain greatly, and therefore the user models need to be deliberated manually to be applied to new domains. Moreover, they assumed that the input is text only, which does not contain errors. We propose more comprehensive user models"
W03-2107,C00-1068,1,0.836629,"L scripts in advance. Furthermore, it enables various behaviors adaptive to the dialogue situations such as obtained query results. Another problem to realize user-friendly interaction is how to generate cooperative responses. When we consider the responses generated from the system side, the dialogue strategies, which determine when to make guidance and what the system should tell to the user, are the essential factors in spoken dialogue systems. There are many studies in respect of the dialogue strategy such as confirmation management using confidence measures of speech recognition results (Komatani and Kawahara, 2000; Hazen et al., 2000), dynamic change of dialogue initiative (Litman and Pan, 2000; Chu-Carroll, 2000; Lamel et al., 1999), and addition of cooperative contents to system responses (Sadek, 1999). Nevertheless, whether a particular response is cooperative or not depends on individual user’s characteristic. In order to adapt the system’s behavior to individual users, it is necessary to model the user’s patterns (Kass and Finin, 1988). Most of conventional studies on user models have focused on the knowledge of users. Others tried to infer and utilize user’s goals to generate responses adapted to"
W03-2107,J88-3006,0,0.120714,"mic change of dialogue initiative (Litman and Pan, 2000; Chu-Carroll, 2000; Lamel et al., 1999), and addition of cooperative contents to system responses (Sadek, 1999). Nevertheless, whether a particular response is cooperative or not depends on individual user’s characteristic. In order to adapt the system’s behavior to individual users, it is necessary to model the user’s patterns (Kass and Finin, 1988). Most of conventional studies on user models have focused on the knowledge of users. Others tried to infer and utilize user’s goals to generate responses adapted to the user (van Beek, 1987; Paris, 1988). Elzer et al. (2000) proposed a method to generate adaptive suggestions according to users’ preferences. However, these studies depend on knowledge of the target domain greatly, and therefore the user models need to be deliberated manually to be applied to new domains. Moreover, they assumed that the input is text only, which does not contain errors. We propose more comprehensive user models to generate user-adapted responses in spoken dialogue systems taking account of information specific to spoken dialogue. Spoken utterances include various information such as the interval between the utte"
W03-2107,P87-1030,0,0.243219,"Missing"
W11-2008,D07-1002,0,0.10912,"Missing"
W11-2008,2009.eamt-1.30,0,0.0218093,"Missing"
W11-2008,P08-1028,0,0.0367914,"Missing"
W11-2008,P98-2127,0,0.00882207,"ts is defined based on the co-occurrence statistics in the corpus. The measure for predicate is defined based on distributional analysis of arguments. 4.2 Relevance measure of arguments The relevance of argument words (=nouns) wi and wj is defined as simarg (wi , wj ) = {C(wi , wj )}2 . C(wi ) × C(wj ) (6) Here, wi is in the original query, and relaxed (ignored) in the partial matching, and wj of the best relevance score is retrieved for response generation. In the example of Fig. 2, wi is “Ichiro” and wj is “Lopez”. 4.3 Relevance measure of predicates Distributional analysis (Z.Harris, 1951; Lin, 1998) has been used to define similarity of words, assuming that similar words have similar contexts. In this paper, we use the distribution of arguments which have a modification relation to predicates (Fig. 3) frequency 28 Ichiro 12 single 20 Lopez 31 homer Agent Object Agent Object frequency 3 Ichiro 1 single 2 Lopez 4 homer hit Agent 1. Exact Matching of P-A templates. 2. Partial Matching using significance measure for query relaxation and relevance score for candidate selection. 3. Back-off to “Bag-of-Words” (BOW) model with significance measure for disambiguation. Object Agent Object Figure 4"
W11-2008,D09-1082,0,0.0528628,"Missing"
W11-2008,P05-1026,0,0.0234721,"s been studied to handle large-scale texts such as web, but most of the conventional systems adopt a “bag-ofwords” model, and naive statistical matching often generates irrelevant responses which have nothing to do with the user’s requests. Our proposed scheme solves this problem by using information extraction based on semantic parsing from web texts, without constructing an RDB. We adopt the predicateargument (P-A) structure generated by a parser as a baseline, but every P-A structure is not useful for information extraction and retrieval(Y.Kiyota et al., 2002; M.O.Dzikovska et al., 2003; S.Harabagiu et al., 2005). In fact, the useful information structure is dependent on domains. Conventionally, the templates for information extraction were hand-crafted (R.Grishman, 2003), but this heuristic process is so costly that it cannot be applied to a variety of domains on the web. In this paper, therefore, we pro59 Proceedings of the SIGDIAL 2011: the 12th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 59–66, c Portland, Oregon, June 17-18, 2011. 2011 Association for Computational Linguistics SYSTEM PROCESS DIALOGUE USER BACK END SYSTEM Ichiro(agent), home-run(object), hit User:"
W11-2008,P10-1097,0,0.0216602,"Missing"
W11-2008,I08-2110,0,0.0658194,"Missing"
W11-2008,C02-1084,0,0.0823079,"Missing"
W11-2008,H94-1010,0,\N,Missing
W11-2008,N06-1023,0,\N,Missing
W11-2008,C98-2122,0,\N,Missing
W11-2008,D09-1098,0,\N,Missing
W12-1601,W09-3933,0,0.211916,"Missing"
W14-4305,C00-1068,1,0.495258,"Missing"
W14-4305,C10-1086,0,0.0203388,"o model and train dialogue managers (Levin et al., 2000; Williams and Young, 2007; Young et al., 2010; Yoshino et al., 2013b). However, the conventional scheme assumes that the task and dialogue goal can be clearly stated and readily encoded in the RL reward function. This is not true in casual conversation or when browsing information. Some previous work has tackled with this problem. In a conversational chatting system (Shibata et al., 2014), users were asked to make evaluation at the end of each dialogue session, to define rewards for reinforcement learning. In a listening dialogue system (Meguro et al., 2010), levels of satisfaction were annotated in logs of dialogue sessions to train a discriminative model. These approaches require costly input from users or developers, who provide labels and evaluative judgments. In this work, we present a framework in which reward is defined for the quality of system actions and also for encouraging long interactions, in contrast to the conventional framework. Moreover, user focus is tracked to make appropriate actions, which are more rewarded. We present a spoken dialogue system for navigating information (such as news articles), and which can engage in small"
W14-4305,H94-1010,0,0.394747,"Missing"
W14-4305,J86-3001,0,0.787852,"ested in the topic, the speaker avoids the details of that topic, and changes the topic. Topics are often taken from current news. In our past work, we have developed a news navigation system (Yoshino et al., 2011) based on this dialogue structure. The system provides topics collected from Web news texts, and the user gets information according to his interests and queries. 2.2 User focus in information navigation “Focus” in discourse is “attentional state (that) contains information about the objects, properties, relations, and discourse intentions that are most salient at any given point.” (Grosz and Sidner, 1986). The user has specific attention to an object if the user utterance contains the focus. In this work, we define the user focus as “the main piece of information of interest to the user.” It makes a central component when making a reply or selecting relevant topics at the current dialogue state. For example, given “Did Ichiro perform bril2.1 System overview An overview of the proposed system is depicted in Figure 2. The system has six modules, each of which implements a class of actions. Each module takes as input a recognized user utterance, an analyzed predicate-argument (P-A) structure and"
W14-4305,W13-4065,0,0.042555,"Missing"
W14-4305,W11-2008,1,0.717929,"e real world. Spoken dialogue applications that interact with a diversity of users are available on smart-phones. However, current applications are based on simple question answering and the system requires a clear query or a definite task goal. Therefore, next-generation dialogue systems should engage in casual interactions with users who do not have a clear intention or a task goal. Such systems include a sightseeing navigation system that uses tour guide books or documents in Wikipedia (Misu and Kawahara, 2010), and a news navigation system that introduces news articles updated day-by-day (Yoshino et al., 2011; Pan et al., 2012). In this paper, we develop an information navigation system that provides information even if the user request is not necessarily clear and there is not a matching document in the knowledge base. The user and the system converse on the current topic and the system provides potentially useful information for the user. Dialogue management of this kind of systems was usually made in a heuristic manner and based 2 Conversational Information Navigation System In natural human-human conversation, participants have topics they plan to talk about, and they progress through the dial"
W14-4305,I13-1127,1,0.890226,"Missing"
W16-3625,W15-4624,0,0.0287919,"onstration, ERICA plays two social roles: a laboratory guide and a counselor. The scenarios assume that the user meets ERICA for the first time where the user might be nervous. The highlight in the current demonstration is ERICA trying to make the user comfortable by doing the following: Introduction Dialogue systems deployed in various devices such as smartphones and robots have been widely used to assist users in daily life. Although they can reply to users for what they are asked, their behaviors are mechanical and the primary objective of dialogue is efficiency (Wilcock and Jokinen, 2015; Skantze and Johansson, 2015). Users need to adapt their behaviors such as their utterance style for the systems, and thus the observed users’ behaviors are different from those in human communication. In the current ERATO project, an autonomous android ERICA with the appearance of human being is developed. Our goal is to make her behave like a human being and naturally interact with human beings by tightly integrating verbal and nonverbal information. For the moment, we make ERICA play a specific social role according to the conversational situation. Figure 1 illustrates some prospective social roles which could be cover"
W16-3625,W15-4623,0,0.0297645,"le performance. In this demonstration, ERICA plays two social roles: a laboratory guide and a counselor. The scenarios assume that the user meets ERICA for the first time where the user might be nervous. The highlight in the current demonstration is ERICA trying to make the user comfortable by doing the following: Introduction Dialogue systems deployed in various devices such as smartphones and robots have been widely used to assist users in daily life. Although they can reply to users for what they are asked, their behaviors are mechanical and the primary objective of dialogue is efficiency (Wilcock and Jokinen, 2015; Skantze and Johansson, 2015). Users need to adapt their behaviors such as their utterance style for the systems, and thus the observed users’ behaviors are different from those in human communication. In the current ERATO project, an autonomous android ERICA with the appearance of human being is developed. Our goal is to make her behave like a human being and naturally interact with human beings by tightly integrating verbal and nonverbal information. For the moment, we make ERICA play a specific social role according to the conversational situation. Figure 1 illustrates some prospective soc"
W16-3625,W15-4652,0,0.0282225,"oder (DAE) to suppress reverberation components and signal distortion. Afterwards, the output speech signal of the DAE is decoded by an acoustic model based on a deep neural network (DNN). The DAE and DNN are trained by using multi-condition speech data so that it is robust against various types of the acoustic environment. It is also necessary for the above processes to be performed in real time. 4.2 Speaker tracking with depth camera To realize smooth interaction, it is essential for the system to correctly identify who talks to whom and if the user is giving his/her attention toward ERICA (Yu et al., 2015). In this demonstration, we track the user’s location and head orientation in the 3D space by using the Kinect v2 sensor. The user localization enables ERICA to spot if there is It is nice weather today. Un. (continuer) It is the best day to play football outside. Un, un. (continuer, stronger than the previous one) 214 Figure 3: System architecture References a person who wants to interact with her. ERICA identifies if the user is speaking to her by the head orientation. This enables ERICA not to respond to the talking between people, for example when a person introduces ERICA to a guest stand"
W17-5516,C10-1097,0,0.420747,"We then send this information to the statement response component which generates a question response “What kind of curry?”. Further details of the technical implementation are described in the Continuous backchannel generation Our goal is to increase rapport (Huang et al., 2011) with the user by showing that the system is interested in the content of the user’s speech. There have been many works on automatic backchannel generation, with most using prosodic features for either rule-based models (Ward and Tsukahara, 2000; Truong et al., 2010) or machine learning methods (Morency et al., 2008; Ozkan et al., 2010; Kawahara et al., 2015). In this work we use a model in which backchanneling behavior occurs continuously during the speaker’s turn, not only at the end of an utterance. We take a machine learning approach by implementing a logistic regression model to predict if a backchannel would occur 500ms into the future. We predict into the future rather than at the current time point, because in the real-time system Erica requires processing time to generate nodding and mouth movements that synchronize with her utterance. We trained the model using a counseling corpus. This corpus consisted of eight o"
W17-5516,N09-1071,0,0.532539,"d take the turn using a decision model. One simple approach is to wait for a fixed duration of silence from the user before starting the speaking turn. However, we have found this is highly user-dependent and very challenging when the user continues talking. The major problem is that if the user has not finished their turn and the system begins speaking, they must then wait for the system’s utterance to finish. This disrupts the flow of the conversation and makes the user frustrated. Solving this problem is not trivial so several works have attempted to develop a robust model for turn-taking (Raux and Eskenazi, 2009; Selfridge and Heeman, 2010; Ward et al., 2010). Figure 3 displays our approach towards turntaking behavior, rather than having to make a binary decision about whether or not to take the turn. When the user has the floor and the system receives an ASR result, our model outputs a likelihood score between 0 and 1 that the system should take the turn. The actual likelihood score determines the system’s response. The system has four possible responses - silence, generate a backchannel, generate a filler or take the turn by speaking. The novelty of our approach is that we do not have to immediatel"
W17-5516,P10-1019,0,0.0216133,"ecision model. One simple approach is to wait for a fixed duration of silence from the user before starting the speaking turn. However, we have found this is highly user-dependent and very challenging when the user continues talking. The major problem is that if the user has not finished their turn and the system begins speaking, they must then wait for the system’s utterance to finish. This disrupts the flow of the conversation and makes the user frustrated. Solving this problem is not trivial so several works have attempted to develop a robust model for turn-taking (Raux and Eskenazi, 2009; Selfridge and Heeman, 2010; Ward et al., 2010). Figure 3 displays our approach towards turntaking behavior, rather than having to make a binary decision about whether or not to take the turn. When the user has the floor and the system receives an ASR result, our model outputs a likelihood score between 0 and 1 that the system should take the turn. The actual likelihood score determines the system’s response. The system has four possible responses - silence, generate a backchannel, generate a filler or take the turn by speaking. The novelty of our approach is that we do not have to immediately take a turn based on a har"
W18-5021,W09-3949,0,0.064563,"Missing"
W18-5021,P05-2014,0,0.112142,"Missing"
W18-5021,N16-1037,0,0.0329277,"tes a probability distribution yseg,1:L over segmentation labels: (1) (5) where WDA and bDA are trainable parameters in the DA tag decoding layer. Figure 1: A unified neural architecture consisting of a word sequence tagger for DA segmentation and a sentence classifier for DA recognition. x1:L = word-embedding(w1:L ), (4) • Model 1 A straightforward method is to separately build a word sequence tagger and a sentence classifier. The model that has no shared layers is called Model 1. Sentence Classifier for DA Recognition Accurate recognition of DA requires understanding of discourse relations (Ji et al., 2016). Therefore, preceding sentences are needed as context in the recognition of the current sentence. Hierarchical neural networks are able to encode intrasentence information and capture inter-sentence • Model 2 Word embedding layers are shared between the sequence tagger and the DA classifier in Model 2. When training the sequence tagger on the segmentation task, gradients 203 &apos;()*+,+-*../0"" 1"" &apos;- &apos;(23*3/4/.3 from top end are back-propagated into the shared word embeddings that are also used by the DA classifier, vice versa. Parameters in the shared word embedding layer are updated by losses fr"
W18-5021,C16-1189,0,0.0295427,"Missing"
W18-5021,N16-1062,0,0.0476113,"Missing"
W18-5021,C16-1185,0,0.0345429,"Missing"
W18-5021,W16-3632,0,0.0229827,"mann, 2009; Quarteroni et al., 2011; Granell et al., 2009). Segmentation labels are combined with DA labels (e.g. “E Statement” denotes the end of a Statement segment), and a sequence labeling model is applied to predict tags for both tasks. This approach has a merit of integration so that recognition helps segmentation and segmentation errors are not propagated to the recognition step. On the other hand, it has a drawback that it can hardly incorporate a history of preceding sentences to predict the DA tag of the current sentence. Another approach is to process the data in a pipeline manner. Manuvinakurike et al. (2016) used a CRF for DA segmentation and a Supported Vector Machine (SVM) for DA recognition given predicted segments. For pipeline methods, downstream task (e.g. DA recognition) is vulnerable to errors from upstream task (e.g. DA segmentation). In this paper we propose a unified architecture based on neural networks for DA segmentation and recognition to solve the aforementioned problems. Our method uses separate models for DA segmentation and recognition but introduces joint learning so that the models can learn from Models and Training The proposed method applies a word sequence tagger for segme"
W18-5021,J00-3003,0,0.370257,"Missing"
