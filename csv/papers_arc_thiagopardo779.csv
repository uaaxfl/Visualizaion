2020.webnlg-1.14,{NILC} at {W}eb{NLG}+: Pretrained Sequence-to-Sequence Models on {RDF}-to-Text Generation,2020,-1,-1,2,1,6269,marco cabezudo,Proceedings of the 3rd International Workshop on Natural Language Generation from the Semantic Web (WebNLG+),0,"This paper describes the submission by the NILC Computational Linguistics research group of the University of S{\~a}o Paulo/Brazil to the RDF-to-Text task for English at the WebNLG+ challenge. The success of the current pretrained models like BERT or GPT-2 in text-to-text generation tasks is well-known, however, its application/success on data-totext generation has not been well-studied and proven. This way, we explore how good a pretrained model, in particular BART, performs on the data-to-text generation task. The results obtained were worse than the baseline and other systems in almost all automatic measures. However, the human evaluation shows better results for our system. Besides, results suggest that BART may generate paraphrases of reference texts."
2020.msr-1.6,{NILC} at {SR}{'}20: Exploring Pre-Trained Models in Surface Realisation,2020,-1,-1,2,1,6269,marco cabezudo,Proceedings of the Third Workshop on Multilingual Surface Realisation,0,"This paper describes the submission by the NILC Computational Linguistics research group of the University of S Ìao Paulo/Brazil to the English Track 2 (closed sub-track) at the Surface Realisation Shared Task 2020. The success of the current pre-trained models like BERT or GPT-2 in several tasks is well-known, however, this is not the case for data-to-text generation tasks and just recently some initiatives focused on it. This way, we explore how a pre-trained model (GPT-2) performs on the UD-to-text generation task. In general, the achieved results were poor, but there are some interesting ideas to explore. Among the learned lessons we may note that it is necessary to study strategies to represent UD inputs and to introduce structural knowledge into these pre-trained models."
2020.lrec-1.176,Measuring the Impact of Readability Features in Fake News Detection,2020,-1,-1,5,0,16974,roney santos,Proceedings of the 12th Language Resources and Evaluation Conference,0,"The proliferation of fake news is a current issue that influences a number of important areas of society, such as politics, economy and health. In the Natural Language Processing area, recent initiatives tried to detect fake news in different ways, ranging from language-based approaches to content-based verification. In such approaches, the choice of the features for the classification of fake and true news is one of the most important parts of the process. This paper presents a study on the impact of readability features to detect fake news for the Brazilian Portuguese language. The results show that such features are relevant to the task (achieving, alone, up to 92{\%} classification accuracy) and may improve previous classification results."
2020.emnlp-main.123,Semantically Inspired {AMR} Alignment for the {P}ortuguese Language,2020,-1,-1,2,1,20169,rafael anchieta,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,"Abstract Meaning Representation (AMR) is a graph-based semantic formalism where the nodes are concepts and edges are relations among them. Most of AMR parsing methods require alignment between the nodes of the graph and the words of the sentence. However, this alignment is not provided by manual annotations and available automatic aligners focus only on the English language, not performing well for other languages. Aiming to fulfill this gap, we developed an alignment method for the Portuguese language based on a more semantically matched word-concept pair. We performed both intrinsic and extrinsic evaluations and showed that our alignment approach outperforms the alignment strategies developed for English, improving AMR parsers, and achieving competitive results with a parser designed for the Portuguese language."
W19-4028,Towards a General {A}bstract {M}eaning {R}epresentation Corpus for {B}razilian {P}ortuguese,2019,-1,-1,2,1,6269,marco cabezudo,Proceedings of the 13th Linguistic Annotation Workshop,0,"Abstract Meaning Representation (AMR) is a recent and prominent semantic representation with good acceptance and several applications in the Natural Language Processing area. For English, there is a large annotated corpus (with approximately 39K sentences) that supports the research with the representation. However, to the best of our knowledge, there is only one restricted corpus for Portuguese, which contains 1,527 sentences. In this context, this paper presents an effort to build a general purpose AMR-annotated corpus for Brazilian Portuguese by translating and adapting AMR English guidelines. Our results show that such approach is feasible, but there are some challenging phenomena to solve. More than this, efforts are necessary to increase the coverage of the corresponding lexical resource that supports the annotation."
P19-2011,"Natural Language Generation: Recently Learned Lessons, Directions for Semantic Representation-based Approaches, and the Case of {B}razilian {P}ortuguese Language",2019,0,0,2,1,6269,marco cabezudo,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop,0,"This paper presents a more recent literature review on Natural Language Generation. In particular, we highlight the efforts for Brazilian Portuguese in order to show the available resources and the existent approaches for this language. We also focus on the approaches for generation from semantic representations (emphasizing the Abstract Meaning Representation formalism) as well as their advantages and limitations, including possible future directions."
D19-6313,Back-Translation as Strategy to Tackle the Lack of Corpus in Natural Language Generation from Semantic Representations,2019,0,0,3,1,6269,marco cabezudo,Proceedings of the 2nd Workshop on Multilingual Surface Realisation (MSR 2019),0,"This paper presents an exploratory study that aims to evaluate the usefulness of back-translation in Natural Language Generation (NLG) from semantic representations for non-English languages. Specifically, Abstract Meaning Representation and Brazilian Portuguese (BP) are chosen as semantic representation and language, respectively. Two methods (focused on Statistical and Neural Machine Translation) are evaluated on two datasets (one automatically generated and another one human-generated) to compare the performance in a real context. Also, several cuts according to quality measures are performed to evaluate the importance (or not) of the data quality in NLG. Results show that there are still many improvements to be made but this is a promising approach."
W18-3608,{NILC}-{SWORNEMO} at the Surface Realization Shared Task: Exploring Syntax-Based Word Ordering using Neural Models,2018,0,0,2,1,6269,marco cabezudo,Proceedings of the First Workshop on Multilingual Surface Realisation,0,"This paper describes the submission by the NILC Computational Linguistics research group of the University of S{\~a}o Paulo/Brazil to the Track 1 of the Surface Realization Shared Task (SRST Track 1). We present a neural-based method that works at the syntactic level to order the words (which we refer by NILC-SWORNEMO, standing for {``}Syntax-based Word ORdering using NEural MOdels{''}). Additionally, we apply a bottom-up approach to build the sentence and, using language-specific lexicons, we produce the proper word form of each lemma in the sentence. The results obtained by our method outperformed the average of the results for English, Portuguese and Spanish in the track."
L18-1157,Towards {AMR}-{BR}: A {S}em{B}ank for {B}razilian {P}ortuguese Language,2018,0,2,2,1,20169,rafael anchieta,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
W17-6605,Improving Opinion Summarization by Assessing Sentence Importance in On-line Reviews,2017,11,0,4,1,20169,rafael anchieta,Proceedings of the 11th {B}razilian Symposium in Information and Human Language Technology,0,"This paper describes an approach for improving a state of the art opinion summarization method, incorporating the assessment of sentence importance in on-line reviews. We compare the enriched method to its original version and show that we significantly outperform it, producing more informative summaries."
W17-6610,Forma{\\c{c}}{\\~a}o de gent{\\'\\i}licos a partir de top{\\^o}nimos: descri{\\c{c}}{\\~a}o lingu{\\'\\i}stica e aprendizado autom{\\'a}tico (Formation of Demonyms from Toponyms: Linguistic Description and Machine Learning)[In {P}ortuguese],2017,-1,-1,2,0,31371,roger antunes,Proceedings of the 11th {B}razilian Symposium in Information and Human Language Technology,0,None
W15-5612,Joint semantic discourse models for automatic multi-document summarization,2015,0,2,2,1,36451,paula cardoso,Proceedings of the 10th {B}razilian Symposium in Information and Human Language Technology,0,None
W15-5618,On Strategies of Human Multi-Document Summarization,2015,-1,-1,3,0,36460,renata camargo,Proceedings of the 10th {B}razilian Symposium in Information and Human Language Technology,0,None
W15-5619,Enriching entity grids and graphs with discourse relations: the impact in local coherence evaluation,2015,7,0,2,0,36462,marcio dias,Proceedings of the 10th {B}razilian Symposium in Information and Human Language Technology,0,"This paper describes how discursive knowledge, given by the discursive theories RST (Rhetorical Structure Theory) and CST (Crossdocument Structure Theory), may improve the automatic evaluation of local coherence in multi-document summaries. Two of the main coherence models from literature were incremented with discursive information and obtained 91.3% of accuracy, with a gain of 53% in relation to the original results."
W15-4608,A Discursive Grid Approach to Model Local Coherence in Multi-document Summaries,2015,23,3,2,0,36462,marcio dias,Proceedings of the 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"Multi-document summarization is a very important area of Natural Language Processing (NLP) nowadays because of the huge amount of data in the web. People want more and more information and this information must be coherently organized and summarized. The main focus of this paper is to deal with the coherence of multi-document summaries. Therefore, a model that uses discursive information to automatically evaluate local coherence in multi-document summaries has been developed. This model obtains 92.69% of accuracy in distinguishing coherent from incoherent summaries, outperforming the state of the art in the area."
W15-1607,A Qualitative Analysis of a Corpus of Opinion Summaries based on Aspects,2015,23,2,2,0,37013,roque lopez,Proceedings of The 9th Linguistic Annotation Workshop,0,"Aspect-based opinion summarization is the task of automatically generating a summary for some aspects of a specific topic from a set of opinions. In most cases, to evaluate the quality of the automatic summaries, it is necessary to have a reference corpus of human summaries to analyze how similar they are. The scarcity of corpora in that task has been a limiting factor for many research works. In this paper, we introduce OpiSums-PT, a corpus of extractive and abstractive summaries of opinions written in Brazilian Portuguese. We use this corpus to analyze how similar human summaries are and how people take into account the issues of aspect coverage and sentiment orientation to generate manual summaries. The results of these analyses show that human summaries are diversified and people generate summaries only for some aspects, keeping the overall sentiment orientation with little variation."
R15-1057,Semi-Supervised Never-Ending Learning in Rhetorical Relation Identification,2015,22,5,3,1,24628,erick maziero,Proceedings of the International Conference Recent Advances in Natural Language Processing,0,"Some languages do not have enough la- beled data to obtain good discourse pars- ing, specially in the relation identification step, and the additional use of unlabeled data is a plausible solution. A workflow is presented that uses a semi-supervised learning approach. Instead of only a pre- defined additional set of unlabeled data, texts obtained from the web are continu- ously added. This obtains near human per- fomance (0.79) in intra sentential rhetori- cal relation identification. An experiment for English also shows improvement using a similar workflow."
W14-0404,Some Issues on the Normalization of a Corpus of Products Reviews in {P}ortuguese,2014,12,9,4,0,30756,magali duran,Proceedings of the 9th Web as Corpus Workshop ({W}a{C}-9),0,"This paper describes the analysis of different kinds of noises in a corpus of products reviews in Brazilian Portuguese. Case folding, punctuation, spelling and the use of internet slang are the major kinds of noise we face. After noting the effect of these noises on the POS tagging task, we propose some procedures to minimize them."
S14-2074,{NILC}{\\_}{USP}: An Improved Hybrid System for Sentiment Analysis in {T}witter Messages,2014,13,7,3,1,37014,pedro filho,Proceedings of the 8th International Workshop on Semantic Evaluation ({S}em{E}val 2014),0,"This paper describes the NILC USP system that participated in SemEval-2014 Task 9: Sentiment Analysis in Twitter, a re-run of the SemEval 2013 task under the same name. Our system is an improved version of the system that participated in the 2013 task. This system adopts a hybrid classification process that uses three classification approaches: rule-based, lexiconbased and machine learning. We suggest a pipeline architecture that extracts the best characteristics from each classifier. In this work, we want to verify how this hybrid approach would improve with better classifiers. The improved system achieved an F-score of 65.39% in the Twitter message-level subtask for 2013 dataset ( 9.08% of improvement) and 63.94% for 2014 dataset."
S14-2075,{NILC}{\\_}{USP}: Aspect Extraction using Semantic Labels,2014,13,0,2,1,37014,pedro filho,Proceedings of the 8th International Workshop on Semantic Evaluation ({S}em{E}val 2014),0,"This paper details the system NILC USP that participated in the Semeval 2014: Aspect Based Sentiment Analysis task. This system uses a Conditional Random Field (CRF) algorithm for extracting the aspects mentioned in the text. Our work added semantic labels into a basic feature set for measuring the efficiency of those for aspect extraction. We used the semantic roles and the highest verb frame as features for the machine learning. Overall, our results demonstrated that the system could not improve with the use of this semantic information, but its precision was increased."
hartmann-etal-2014-large,A Large Corpus of Product Reviews in {P}ortuguese: Tackling Out-Of-Vocabulary Words,2014,19,12,6,0,14003,nathan hartmann,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"Web 2.0 has allowed a never imagined communication boom. With the widespread use of computational and mobile devices, anyone, in practically any language, may post comments in the web. As such, formal language is not necessarily used. In fact, in these communicative situations, language is marked by the absence of more complex syntactic structures and the presence of internet slang, with missing diacritics, repetitions of vowels, and the use of chat-speak style abbreviations, emoticons and colloquial expressions. Such language use poses severe new challenges for Natural Language Processing (NLP) tools and applications, which, so far, have focused on well-written texts. In this work, we report the construction of a large web corpus of product reviews in Brazilian Portuguese and the analysis of its lexical phenomena, which support the development of a lexical normalization tool for, in future work, subsidizing the use of standard NLP products for web opinion mining and summarization purposes."
W13-4806,Subtopic Annotation in a Corpus of News Texts: Steps Towards Automatic Subtopic Segmentation,2013,20,6,3,1,36451,paula cardoso,Proceedings of the 9th {B}razilian Symposium in Information and Human Language Technology,0,"Subtopic segmentation aims at finding the boundaries among text passages that represent different subtopics, which usually develop a main topic in a text. Being capable of automatically detecting subtopics is very useful for several Natural Language Processing applications. This paper describes subtopic annotation in a corpus of news texts written in Brazilian Portuguese. In particular, we focus on answering the main scientific questions regarding corpus annotation, aiming at both discussing and dealing with important annotation decisions and making available a reference corpus for research on subtopic structuring and segmentation. Resumo. Segmentacao topical visa segmentar um texto em passagens que representam subtopicos diferentes, os quais desenvolvem um topico principal de um texto. A identificacao de subtopicos e util para diversas aplicacoes de Processamento de Linguagem Natural. Este artigo descreve a anotacao de subtopicos em um corpus de textos jornalisticos em Portugues do Brasil. Em particular, foca-se em responder as questoes cientificas a respeito da anotacao do corpus, visando discutir e lidar com questoes importantes de anotacao e disponibilizacao de um corpus de referencia para pesquisas sobre estruturacao e segmentacao topical."
W13-4815,Desambigua{\\c{c}}{\\~a}o Lexical de Sentido com uso de Informa{\\c{c}}{\\~a}o Multidocumento por meio de Redes de Co-ocorr{\\^e}ncia (Word Sense Disambiguation with the Use of Multi-document Information with Cooccurrence Nets) [in {P}ortuguese],2013,0,0,2,0,37016,fernando nobrega,Proceedings of the 9th {B}razilian Symposium in Information and Human Language Technology,0,None
W13-4829,An Evaluation of the {B}razilian {P}ortuguese {LIWC} Dictionary for Sentiment Analysis,2013,9,29,2,1,37014,pedro filho,Proceedings of the 9th {B}razilian Symposium in Information and Human Language Technology,0,This work presents an evaluation of the Brazilian Portuguese LIWC dictionary for Sentiment Analysis. This evaluation is conducted by comparison against two other sentiment resources for Portuguese language: Opinion Lexicon and SentiLex. We conducted an intrinsic and an extrinsic evaluations and show how LIWC dictionary could be used in sentiment analysis projects.
W13-4012,On the contribution of discourse structure to topic segmentation,2013,14,8,3,1,36451,paula cardoso,Proceedings of the {SIGDIAL} 2013 Conference,0,"In this paper, we describe novel methods for topic segmentation based on patterns of discourse organization. Using a corpus of news texts, our results show that it is possible to use discourse features (based on Rhetorical Structure Theory) for topic segmentation and that we outperform some well-known methods."
S13-2095,{NILC}{\\_}{USP}: A Hybrid System for Sentiment Analysis in {T}witter Messages,2013,12,10,2,1,37014,pedro filho,"Second Joint Conference on Lexical and Computational Semantics (*{SEM}), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation ({S}em{E}val 2013)",0,"This paper describes the NILC USP system that participated in SemEval-2013 Task 2: Sentiment Analysis in Twitter. Our system adopts a hybrid classification process that uses three classification approaches: rulebased, lexicon-based and machine learning approaches. We suggest a pipeline architecture that extracts the best characteristics from each classifier. Our system achieved an Fscore of 56.31% in the Twitter message-level subtask."
N13-2003,A Machine Learning Approach to Automatic Term Extraction using a Rich Feature Set,2013,23,25,2,0,41581,merley conrado,Proceedings of the 2013 {NAACL} {HLT} Student Research Workshop,0,"In this paper we propose an automatic term extraction approach that uses machine learning incorporating varied and rich features of candidate terms. In our preliminary experiments, we also tested different attribute selection methods to verify which features are more relevant for automatic term extraction. We achieved state of the art results for unigram extraction in Brazilian Portuguese."
W11-4501,Multi-Document Discourse Parsing Using Traditional and Hierarchical Machine Learning,2011,22,3,2,1,24628,erick maziero,Proceedings of the 8th {B}razilian Symposium in Information and Human Language Technology,0,"Multi-document handling is essential today, when many documents on the same topic are produced, especially considering the Web. Both readers and computer applications can benefit from a discourse analysis of this multi- document content, since it demonstrates clearly the relations among portions of these documents. This work aims to identify such relations automatically using machine learning techniques. Particularly, this work focuses on the identification of relations predicted by the Cross-document Structure Theory (CST). The obtained results improve the state of the art."
W11-4514,Um Processo Baseado em Par{\\'a}grafos para a Extra{\\c{c}}{\\~a}o de Tratamentos em Artigos Cient{\\'\\i}ficos do Dom{\\'\\i}nio Biom{\\'e}dico (A Paragraph-based Process to Extraction of Treatments from Biomedical Scientific Papers) [in {P}ortuguese],2011,-1,-1,4,0,44003,juliana duque,Proceedings of the 8th {B}razilian Symposium in Information and Human Language Technology,0,None
W11-4531,A Generative Approach for Multi-Document Summarization using Semantic-Discursive information,2011,6,0,2,0,44026,maria jorge,Proceedings of the 8th {B}razilian Symposium in Information and Human Language Technology,0,"Multi-document summarization is the automatic produ ction of a unique summary from a collection of texts. In this paper, we propose a statistical generative approach for multi-document summarization that combines simple information such as sentence positi on in the text and semantic-discursive information from CST (Cross-Doc ument Structure Theory). In particular, we formulate the multi-docu ment summarization task using a Noisy-Channel model."
R11-1109,Experiments on Term Extraction using Noun Phrase Subclassifications,2011,10,3,6,0,41581,merley conrado,Proceedings of the International Conference Recent Advances in Natural Language Processing 2011,0,"In this paper we describe and compare three approaches for the automatic extraction of medical terms using noun phrases (NPs) previously recognized on medical text corpus in Spanish. In the first approach, as baseline, we extracted all NPs, while for the second and third ones the extraction process is directed to xe2x80x9cspecific NPsxe2x80x9d that are determined on the basis of the syntactic and positional criteria, among others. As contributions (i) we showed that it is possible to extract medical terms using xe2x80x9cspecific NPsxe2x80x9d, (ii) new terms were added in the software dictionary, and (iii) terms that were not in the reference lists were extracted. For the third contribution, we used the SNOMED CT R terms lists, aiming at improving the IULA reference lists."
W10-2312,Experiments with {CST}-Based Multidocument Summarization,2010,18,32,2,0,44026,maria jorge,Proceedings of {T}ext{G}raphs-5 - 2010 Workshop on Graph-based Methods for Natural Language Processing,0,"Recently, with the huge amount of growing information in the web and the little available time to read and process all this information, automatic summaries have become very important resources. In this work, we evaluate deep content selection methods for multidocument summarization based on the CST model (Cross-document Structure Theory). Our methods consider summarization preferences and focus on the overall main problems of multidocument treatment: redundancy, complementarity, and contradiction among different information sources. We also evaluate the impact of the CST model over superficial summarization systems. Our results show that the use of CST model helps to improve informativeness and quality in automatic summaries."
W10-1601,Computational Linguistics in {B}razil: An Overview,2010,2,4,1,1,14083,thiago pardo,Proceedings of the {NAACL} {HLT} 2010 Young Investigators Workshop on Computational Approaches to Languages of the {A}mericas,0,"In this paper we give an overview of Computational Linguistics/Natural Language Processing in Brazil, describing the general research scenario, the main research groups, existing events and journals, and the perceived challenges, among other relevant information. We also identify opportunities for collaboration."
W09-2105,Supporting the Adaptation of Texts for Poor Literacy Readers: a Text Simplification Editor for {B}razilian {P}ortuguese,2009,17,41,5,0,46973,arnaldo candido,Proceedings of the Fourth Workshop on Innovative Use of {NLP} for Building Educational Applications,0,"In this paper we investigate the task of text simplification for Brazilian Portuguese. Our purpose is three-fold: to introduce a simplification tool for such language and its underlying development methodology, to present an on-line authoring system of simplified text based on the previous tool, and finally to discuss the potentialities of such technology for education. The resources and tools we present are new for Portuguese and innovative in many aspects with respect to previous initiatives for other languages."
W07-0203,Extractive Automatic Summarization: Does more Linguistic Knowledge Make a Difference?,2007,20,24,3,0,49074,daniel leite,Proceedings of the Second Workshop on {T}ext{G}raphs: Graph-Based Algorithms for Natural Language Processing,0,"In this article we address the usefulness of linguistic-independent methods in extractive Automatic Summarization, arguing that linguistic knowledge is not only useful, but may be necessary to improve the informativeness of automatic extracts. An assessment of four diverse AS methods on Brazilian Portuguese texts is presented to support our claim. One of them is Mihalceaxe2x80x99s TextRank; other two are modified versions of the former through the inclusion of varied linguistic features. Finally, the fourth method employs machine learning techniques, tackling more profound and language-dependent knowledge."
