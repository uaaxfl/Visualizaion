2021.wnut-1.22,Understanding the Impact of {UGC} Specificities on Translation Quality,2021,-1,-1,3,1,166,jose nunez,Proceedings of the Seventh Workshop on Noisy User-generated Text (W-NUT 2021),0,"This work takes a critical look at the evaluation of user-generated content automatic translation, the well-known specificities of which raise many challenges for MT. Our analyses show that measuring the average-case performance using a standard metric on a UGC test set falls far short of giving a reliable image of the UGC translation quality. That is why we introduce a new data set for the evaluation of UGC translation in which UGC specificities have been manually annotated using a fine-grained typology. Using this data set, we conduct several experiments to measure the impact of different kinds of UGC specificities on translation quality, more precisely than previously possible."
2021.wnut-1.23,Noisy {UGC} Translation at the Character Level: Revisiting Open-Vocabulary Capabilities and Robustness of Char-Based Models,2021,-1,-1,2,1,166,jose nunez,Proceedings of the Seventh Workshop on Noisy User-generated Text (W-NUT 2021),0,"This work explores the capacities of character-based Neural Machine Translation to translate noisy User-Generated Content (UGC) with a strong focus on exploring the limits of such approaches to handle productive UGC phenomena, which almost by definition, cannot be seen at training time. Within a strict zero-shot scenario, we first study the detrimental impact on translation performance of various user-generated content phenomena on a small annotated dataset we developed and then show that such models are indeed incapable of handling unknown letters, which leads to catastrophic translation failure once such characters are encountered. We further confirm this behavior with a simple, yet insightful, copy task experiment and highlight the importance of reducing the vocabulary size hyper-parameter to increase the robustness of character-based models for machine translation."
2021.jeptalnrecital-taln.2,Biais de genre dans un syst{\\`e}me de traduction automatiqueneuronale : une {\\'e}tude pr{\\'e}liminaire (Gender Bias in Neural Translation : a preliminary study ),2021,-1,-1,1,1,168,guillaume wisniewski,Actes de la 28e Conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Volume 1 : conf{\\'e}rence principale,0,"Cet article pr{\'e}sente les premiers r{\'e}sultats d{'}une {\'e}tude en cours sur les biais de genre dans les corpus d{'}entra{\^\i}nements et dans les syst{\`e}mes de traduction neuronale. Nous {\'e}tudions en particulier un corpus minimal et contr{\^o}l{\'e} pour mesurer l{'}intensit{\'e} de ces biais dans les deux directions anglais-fran{\c{c}}ais et fran{\c{c}}ais-anglais ; ce cadre contr{\^o}l{\'e} nous permet {\'e}galement d{'}analyser les repr{\'e}sentations internes manipul{\'e}es par le syst{\`e}me pour r{\'e}aliser ses pr{\'e}dictions lexicales, ainsi que de formuler des hypoth{\`e}ses sur la mani{\`e}re dont ce biais se distribue dans les repr{\'e}sentations du syst{\`e}me."
2021.emnlp-main.377,Are {T}ransformers a Modern Version of {ELIZA}? {O}bservations on {F}rench Object Verb Agreement,2021,-1,-1,2,0,9479,bingzhi li,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"Many recent works have demonstrated that unsupervised sentence representations of neural networks encode syntactic information by observing that neural language models are able to predict the agreement between a verb and its subject. We take a critical look at this line of research by showing that it is possible to achieve high accuracy on this agreement task with simple surface heuristics, indicating a possible flaw in our assessment of neural networks{'} syntactic ability. Our fine-grained analyses of results on the long-range French object-verb agreement show that contrary to LSTMs, Transformers are able to capture a non-trivial amount of grammatical structure."
2021.eacl-main.269,Are Neural Networks Extracting Linguistic Properties or Memorizing Training Data? An Observation with a Multilingual Probe for Predicting Tense,2021,-1,-1,2,0,9479,bingzhi li,Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume,0,"We evaluate the ability of Bert embeddings to represent tense information, taking French and Chinese as a case study. In French, the tense information is expressed by verb morphology and can be captured by simple surface information. On the contrary, tense interpretation in Chinese is driven by abstract, lexical, syntactic and even pragmatic information. We show that while French tenses can easily be predicted from sentence representations, results drop sharply for Chinese, which suggests that Bert is more likely to memorize shallow patterns from the training data rather than uncover abstract properties."
2021.computel-1.7,User-friendly Automatic Transcription of Low-resource Languages: Plugging {ESPnet} into Elpis,2021,-1,-1,3,0.684541,11431,oliver adams,Proceedings of the 4th Workshop on the Use of Computational Methods in the Study of Endangered Languages Volume 1 (Papers),0,None
2021.blackboxnlp-1.24,Screening Gender Transfer in Neural Machine Translation,2021,-1,-1,1,1,168,guillaume wisniewski,Proceedings of the Fourth BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP,0,"This paper aims at identifying the information flow in state-of-the-art machine translation systems, taking as example the transfer of gender when translating from French into English. Using a controlled set of examples, we experiment several ways to investigate how gender information circulates in a encoder-decoder architecture considering both probing techniques as well as interventions on the internal representations used in the MT system. Our results show that gender information can be found in all token representations built by the encoder and the decoder and lead us to conclude that there are multiple pathways for gender transfer."
2020.sltu-1.43,Phonemic Transcription of Low-Resource Languages: To What Extent can Preprocessing be Automated?,2020,0,0,1,1,168,guillaume wisniewski,Proceedings of the 1st Joint Workshop on Spoken Language Technologies for Under-resourced languages (SLTU) and Collaboration and Computing for Under-Resourced Languages (CCURL),0,"Automatic Speech Recognition for low-resource languages has been an active field of research for more than a decade. It holds promise for facilitating the urgent task of documenting the world{'}s dwindling linguistic diversity. Various methodological hurdles are encountered in the course of this exciting development, however. A well-identified difficulty is that data preprocessing is not at all trivial: data collected in classical fieldwork are usually tailored to the needs of the linguist who collects them, and there is baffling diversity in formats and annotation schema, even among fieldworkers who use the same software package (such as ELAN). The tests reported here (on Yongning Na and other languages from the Pangloss Collection, an open archive of endangered languages) explore some possibilities for automating the process of data preprocessing: assessing to what extent it is possible to bypass the involvement of language experts for menial tasks of data preparation for Natural Language Processing (NLP) purposes. What is at stake is the accessibility of language archive data for a range of NLP tasks and beyond."
2020.jeptalnrecital-jep.51,Analyse d{'}erreurs de transcriptions phon{\\'e}miques automatiques d{'}une langue Â« rare Â» : le na (mosuo) (Analyzing errors in automatic phonemic transcriptions of the {N}a ({M}osuo) language ({S}ino{T}ibetan family) Automatic phonemic transcription tools now reach high levels of accuracy on a single speaker with relatively small amounts of training data: on the order two to three hours of transcribed speech),2020,-1,-1,4,0,11437,alexis michaud,"Actes de la 6e conf{\\'e}rence conjointe Journ{\\'e}es d'{\\'E}tudes sur la Parole (JEP, 33e {\\'e}dition), Traitement Automatique des Langues Naturelles (TALN, 27e {\\'e}dition), Rencontre des {\\'E}tudiants Chercheurs en Informatique pour le Traitement Automatique des Langues (R{\\'E}CITAL, 22e {\\'e}dition). Volume 1 : Journ{\\'e}es d'{\\'E}tudes sur la Parole",0,"Les syst{\`e}mes de reconnaissance automatique de la parole atteignent d{\'e}sormais des degr{\'e}s de pr{\'e}cision {\'e}lev{\'e}s sur la base d{'}un corpus d{'}entra{\^\i}nement limit{\'e} {\`a} deux ou trois heures d{'}enregistrements transcrits (pour un syst{\`e}me mono-locuteur). Au-del{\`a} de l{'}int{\'e}r{\^e}t pratique que pr{\'e}sentent ces avanc{\'e}es technologiques pour les t{\^a}ches de documentation de langues rares et en danger, se pose la question de leur apport pour la r{\'e}flexion du phon{\'e}ticien/phonologue. En effet, le mod{\`e}le acoustique prend en entr{\'e}e des transcriptions qui reposent sur un ensemble d{'}hypoth{\`e}ses plus ou moins explicites. Le mod{\`e}le acoustique, d{\'e}calqu{\'e} (par des m{\'e}thodes statistiques) de l{'}{\'e}crit du linguiste, peut-il {\^e}tre interrog{\'e} par ce dernier, en un jeu de miroir ? Notre {\'e}tude s{'}appuie sur des exemples d{'}une langue Â« rare Â» de la famille sino-tib{\'e}taine, le na (mosuo), pour illustrer la fa{\c{c}}on dont l{'}analyse d{'}erreurs permet une confrontation renouvel{\'e}e avec le signal acoustique."
W19-6101,Comparison between {NMT} and {PBSMT} Performance for Translating Noisy User-Generated Content,2019,0,0,3,1,166,jose nunez,Proceedings of the 22nd Nordic Conference on Computational Linguistics,0,"This work compares the performances achieved by Phrase-Based Statistical Machine Translation systems (PB-SMT) and attention-based Neuronal Machine Translation systems (NMT) when translating User Generated Content (UGC), as encountered in social medias, from French to English. We show that, contrary to what could be expected, PBSMT outperforms NMT when translating non-canonical inputs. Our error analysis uncovers the specificities of UGC that are problematic for sequential NMT architectures and suggests new avenue for improving NMT models."
N19-1019,{H}ow {B}ad are {P}o{S} {T}agger in {C}ross-{C}orpora {S}ettings? {E}valuating {A}nnotation {D}ivergence in the {UD} {P}roject.,2019,0,0,1,1,168,guillaume wisniewski,"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",0,"The performance of Part-of-Speech tagging varies significantly across the treebanks of the Universal Dependencies project. This work points out that these variations may result from divergences between the annotation of train and test sets. We show how the annotation variation principle, introduced by Dickinson and Meurers (2003) to automatically detect errors in gold standard, can be used to identify inconsistencies between annotations; we also evaluate their impact on prediction performance."
D19-5553,Phonetic Normalization for Machine Translation of User Generated Content,2019,0,0,3,1,166,jose nunez,Proceedings of the 5th Workshop on Noisy User-generated Text (W-NUT 2019),0,"We present an approach to correct noisy User Generated Content (UGC) in French aiming to produce a pretreatement pipeline to improve Machine Translation for this kind of non-canonical corpora. In order to do so, we have implemented a character-based neural model phonetizer to produce IPA pronunciations of words. In this way, we intend to correct grammar, vocabulary and accentuation errors often present in noisy UGC corpora. Our method leverages on the fact that some errors are due to confusion induced by words with similar pronunciation which can be corrected using a phonetic look-up table to produce normalization candidates. These potential corrections are then encoded in a lattice and ranked using a language model to output the most probable corrected phrase. Compare to using other phonetizers, our method boosts a transformer-based machine translation system on UGC."
2019.jeptalnrecital-court.7,Combien d{'}exemples de tests sont-ils n{\\'e}cessaires {\\`a} une {\\'e}valuation fiable ? Quelques observations sur l{'}{\\'e}valuation de l{'}analyse morphosyntaxique du fran{\\c{c}}ais. (Some observations on the evaluation of {P}o{S} taggers),2019,-1,-1,1,1,168,guillaume wisniewski,Actes de la Conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles (TALN) PFIA 2019. Volume II : Articles courts,0,"L{'}objectif de ce travail est de pr{\'e}senter plusieurs observations, sur l{'}{\'e}valuation des analyseurs morphosyntaxique en fran{\c{c}}ais, visant {\`a} remettre en cause le cadre habituel de l{'}apprentissage statistique dans lequel les ensembles de test et d{'}apprentissage sont fix{\'e}s arbitrairement et ind{\'e}pendemment du mod{\`e}le consid{\'e}r{\'e}. Nous montrons qu{'}il est possible de consid{\'e}rer des ensembles de test plus petits que ceux g{\'e}n{\'e}ralement utilis{\'e}s sans cons{\'e}quences sur la qualit{\'e} de l{'}{\'e}valuation. Les exemples ainsi Â« {\'e}conomis{\'e}s Â» peuvent {\^e}tre utilis{\'e}s en apprentissage pour am{\'e}liorer les performances des syst{\`e}mes notamment dans des t{\^a}ches d{'}adaptation au domaine."
N18-2064,Automatically Selecting the Best Dependency Annotation Design with Dynamic Oracles,2018,0,0,1,1,168,guillaume wisniewski,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)",0,This work introduces a new strategy to compare the numerous conventions that have been proposed over the years for expressing dependency structures and discover the one for which a parser will achieve the highest parsing performance. Instead of associating each sentence in the training set with a single gold reference we propose to consider a set of references encoding alternative syntactic representations. Training a parser with a dynamic oracle will then automatically select among all alternatives the reference that will be predicted with the highest accuracy. Experiments on the UD corpora show the validity of this approach.
N18-2066,Exploiting Dynamic Oracles to Train Projective Dependency Parsers on Non-Projective Trees,2018,0,0,2,1,29360,lauriane aufrant,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)",0,"Because the most common transition systems are projective, training a transition-based dependency parser often implies to either ignore or rewrite the non-projective training examples, which has an adverse impact on accuracy. In this work, we propose a simple modification of dynamic oracles, which enables the use of non-projective data when training projective parsers. Evaluation on 73 treebanks shows that our method achieves significant gains (+2 to +7 UAS for the most non-projective languages) and consistently outperforms traditional projectivization and pseudo-projectivization approaches."
N18-2077,Automated Paraphrase Lattice Creation for {H}y{TER} Machine Translation Evaluation,2018,0,1,2,0,2673,marianna apidianaki,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)",0,"We propose a variant of a well-known machine translation (MT) evaluation metric, HyTER (Dreyer and Marcu, 2012), which exploits reference translations enriched with meaning equivalent expressions. The original HyTER metric relied on hand-crafted paraphrase networks which restricted its applicability to new data. We test, for the first time, HyTER with automatically built paraphrase lattices. We show that although the metric obtains good results on small and carefully curated data with both manually and automatically selected substitutes, it achieves medium performance on much larger and noisier datasets, demonstrating the limits of the metric for tuning and evaluation of current MT systems."
L18-1711,{E}rrator: a Tool to Help Detect Annotation Errors in the {U}niversal {D}ependencies Project,2018,0,1,1,1,168,guillaume wisniewski,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
C18-1270,Quantifying training challenges of dependency parsers,2018,0,0,2,1,29360,lauriane aufrant,Proceedings of the 27th International Conference on Computational Linguistics,0,"Not all dependencies are equal when training a dependency parser: some are straightforward enough to be learned with only a sample of data, others embed more complexity. This work introduces a series of metrics to quantify those differences, and thereby to expose the shortcomings of various parsing algorithms and strategies. Apart from a more thorough comparison of parsing systems, these new tools also prove useful for characterizing the information conveyed by cross-lingual parsers, in a quantitative but still interpretable way."
2018.jeptalnrecital-court.31,Analyse morpho-syntaxique en pr{\\'e}sence d{'}alternance codique ({P}o{S} tagging of Code Switching),2018,-1,-1,2,1,166,jose nunez,"Actes de la Conf{\\'e}rence TALN. Volume 1 - Articles longs, articles courts de TALN",0,"L{'}alternance codique est le ph{\'e}nom{\`e}ne qui consiste {\`a} alterner les langues au cours d{'}une m{\^e}me conversation ou d{'}une m{\^e}me phrase. Avec l{'}augmentation du volume g{\'e}n{\'e}r{\'e} par les utilisateurs, ce ph{\'e}nom{\`e}ne essentiellement oral, se retrouve de plus en plus dans les textes {\'e}crits, n{\'e}cessitant d{'}adapter les t{\^a}ches et mod{\`e}les de traitement automatique de la langue {\`a} ce nouveau type d{'}{\'e}nonc{\'e}s. Ce travail pr{\'e}sente la collecte et l{'}annotation en partie du discours d{'}un corpus d{'}{\'e}nonc{\'e}s comportant des alternances codiques et {\'e}value leur impact sur la t{\^a}che d{'}analyse morpho-syntaxique."
2018.jeptalnrecital-court.41,Divergences entre annotations dans le projet {U}niversal {D}ependencies et leur impact sur l{'}{\\'e}valuation des performance d{'}{\\'e}tiquetage morpho-syntaxique (Evaluating Annotation Divergences in the {UD} Project),2018,-1,-1,1,1,168,guillaume wisniewski,"Actes de la Conf{\\'e}rence TALN. Volume 1 - Articles longs, articles courts de TALN",0,"Ce travail montre que la d{\'e}gradation des performances souvent observ{\'e}e lors de l{'}application d{'}un analyseur morpho-syntaxique {\`a} des donn{\'e}es hors domaine r{\'e}sulte souvent d{'}incoh{\'e}rences entre les annotations des ensembles de test et d{'}apprentissage. Nous montrons comment le principe de variation des annotations, introduit par Dickinson {\&} Meurers (2003) pour identifier automatiquement les erreurs d{'}annotation, peut {\^e}tre utilis{\'e} pour identifier ces incoh{\'e}rences et {\'e}valuer leur impact sur les performances des analyseurs morpho-syntaxiques."
W17-4779,{LIMSI} Submission for {WMT}{'}17 Shared Task on Bandit Learning,2017,4,1,1,1,168,guillaume wisniewski,Proceedings of the Second Conference on Machine Translation,0,None
W17-0419,A Systematic Comparison of Syntactic Representations of Dependency Parsing,2017,11,1,1,1,168,guillaume wisniewski,Proceedings of the {N}o{D}a{L}i{D}a 2017 Workshop on Universal Dependencies ({UDW} 2017),0,None
K17-3017,{LIMSI}@{C}o{NLL}{'}17: {UD} Shared Task,2017,-1,-1,2,1,29360,lauriane aufrant,Proceedings of the {C}o{NLL} 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies,0,"This paper describes LIMSI{'}s submission to the CoNLL 2017 UD Shared Task, which is focused on small treebanks, and how to improve low-resourced parsing only by ad hoc combination of multiple views and resources. We present our approach for low-resourced parsing, together with a detailed analysis of the results for each test treebank. We also report extensive analysis experiments on model selection for the PUD treebanks, and on annotation consistency among UD treebanks."
E17-2051,Don{'}t Stop Me Now! Using Global Dynamic Oracles to Correct Training Biases of Transition-Based Dependency Parsers,2017,16,0,2,1,29360,lauriane aufrant,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 2, Short Papers",0,"This paper formalizes a sound extension of dynamic oracles to global training, in the frame of transition-based dependency parsers. By dispensing with the pre-computation of references, this extension widens the training strategies that can be entertained for such parsers; we show this by revisiting two standard training procedures, early-update and max-violation, to correct some of their search space sampling biases. Experimentally, on the SPMRL treebanks, this improvement increases the similarity between the train and test distributions and yields performance improvements up to 0.7 UAS, without any computation overhead."
2017.jeptalnrecital-court.17,Adaptation au domaine pour l{'}analyse morpho-syntaxique (Domain Adaptation for {P}o{S} tagging),2017,-1,-1,5,0,33245,eleonor bartenlian,Actes des 24{\\`e}me Conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Volume 2 - Articles courts,0,Ce travail cherche {\`a} comprendre pourquoi les performances d{'}un analyseur morpho-syntaxiques chutent fortement lorsque celui-ci est utilis{\'e} sur des donn{\'e}es hors domaine. Nous montrons {\`a} l{'}aide d{'}une exp{\'e}rience jouet que ce comportement peut {\^e}tre d{\^u} {\`a} un ph{\'e}nom{\`e}ne de masquage des caract{\'e}ristiques lexicalis{\'e}es par les caract{\'e}ristiques non lexicalis{\'e}es. Nous proposons plusieurs mod{\`e}les essayant de r{\'e}duire cet effet.
W16-2304,{LIMSI}@{WMT}{'}16: Machine Translation of News,2016,-1,-1,7,0.491381,5598,alexandre allauzen,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,None
W16-1203,Cross-lingual Dependency Transfer : What Matters? Assessing the Impact of Pre- and Post-processing,2016,-1,-1,2,0,2749,ophelie lacroix,Proceedings of the Workshop on Multilingual and Cross-lingual Methods in {NLP},0,None
W16-1205,Cross-lingual alignment transfer: a chicken-and-egg story?,2016,25,0,2,1,29360,lauriane aufrant,Proceedings of the Workshop on Multilingual and Cross-lingual Methods in {NLP},0,None
N16-1121,Frustratingly Easy Cross-Lingual Transfer for Transition-Based Dependency Parsing,2016,20,7,3,0,2749,ophelie lacroix,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"In this paper, we present a straightforward strategy for transferring dependency parsers across languages. The proposed method learns a parser from partially annotated data obtained through the projection of annotations across unambiguous word alignments. It does not rely on any modeling of the reliability of dependency and/or alignment links and is therefore easy to implement and parameter free. Experiments on six languages show that our method is at par with recent algorithmically demanding methods, at a much cheaper computational cost. It can thus serve as a fair baseline for transferring dependencies across languages with the use of parallel corpora."
L16-1241,Cross-lingual and Supervised Models for Morphosyntactic Annotation: a Comparison on {R}omanian,2016,0,1,2,1,29360,lauriane aufrant,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Because of the small size of Romanian corpora, the performance of a PoS tagger or a dependency parser trained with the standard supervised methods fall far short from the performance achieved in most languages. That is why, we apply state-of-the-art methods for cross-lingual transfer on Romanian tagging and parsing, from English and several Romance languages. We compare the performance with monolingual systems trained with sets of different sizes and establish that training on a few sentences in target language yields better results than transferring from large datasets in other languages."
C16-1012,Zero-resource Dependency Parsing: Boosting Delexicalized Cross-lingual Transfer with Linguistic Knowledge,2016,15,9,2,1,29360,lauriane aufrant,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,"This paper studies cross-lingual transfer for dependency parsing, focusing on very low-resource settings where delexicalized transfer is the only fully automatic option. We show how to boost parsing performance by rewriting the source sentences so as to better match the linguistic regularities of the target language. We contrast a data-driven approach with an approach relying on linguistically motivated rules automatically extracted from the World Atlas of Language Structures. Our findings are backed up by experiments involving 40 languages. They show that both approaches greatly outperform the baseline, the knowledge-driven method yielding the best accuracies, with average improvements of +2.9 UAS, and up to +90 UAS (absolute) on some frequent PoS configurations."
2016.jeptalnrecital-poster.23,Investigating gender adaptation for speech translation,2016,-1,-1,2,0,7687,rachel bawden,Actes de la conf{\\'e}rence conjointe JEP-TALN-RECITAL 2016. volume 2 : TALN (Posters),0,"In this paper we investigate the impact of the integration of context into dialogue translation. We present a new contextual parallel corpus of television subtitles and show how taking into account speaker gender can significantly improve machine translation quality in terms of B LEU and M ETEOR scores. We perform a manual analysis, which suggests that these improvements are not necessary related to the morphological consequences of speaker gender, but to more general linguistic divergences."
2016.jeptalnrecital-long.1,Apprentissage d{'}analyseur en d{\\'e}pendances cross-lingue par projection partielle de d{\\'e}pendances (Cross-lingual learning of dependency parsers from partially projected dependencies ),2016,-1,-1,3,0,2749,ophelie lacroix,Actes de la conf{\\'e}rence conjointe JEP-TALN-RECITAL 2016. volume 2 : TALN (Articles longs),0,"Cet article pr{\'e}sente une m{\'e}thode simple de transfert cross-lingue de d{\'e}pendances. Nous montrons tout d{'}abord qu{'}il est possible d{'}apprendre un analyseur en d{\'e}pendances par transition {\`a} partir de donn{\'e}es partiellement annot{\'e}es. Nous proposons ensuite de construire de grands ensembles de donn{\'e}es partiellement annot{\'e}s pour plusieurs langues cibles en projetant les d{\'e}pendances via les liens d{'}alignement les plus s{\^u}rs. En apprenant des analyseurs pour les langues cibles {\`a} partir de ces donn{\'e}es partielles, nous montrons que cette m{\'e}thode simple obtient des performances qui rivalisent avec celles de m{\'e}thodes {\'e}tat-de-l{'}art r{\'e}centes, tout en ayant un co{\^u}t algorithmique moindre."
2016.jeptalnrecital-long.19,Ne nous arr{\\^e}tons pas en si bon chemin : am{\\'e}liorations de l{'}apprentissage global d{'}analyseurs en d{\\'e}pendances par transition (Don{'}t Stop Me Now ! Improved Update Strategies for Global Training of Transition-Based),2016,-1,-1,2,1,29360,lauriane aufrant,Actes de la conf{\\'e}rence conjointe JEP-TALN-RECITAL 2016. volume 2 : TALN (Articles longs),0,"Dans cet article, nous proposons trois am{\'e}liorations simples pour l{'}apprentissage global d{'}analyseurs en d{\'e}pendances par transition de type A RC E AGER : un oracle non d{\'e}terministe, la reprise sur le m{\^e}me exemple apr{\`e}s une mise {\`a} jour et l{'}entra{\^\i}nement en configurations sous-optimales. Leur combinaison apporte un gain moyen de 0,2 UAS sur le corpus SPMRL. Nous introduisons {\'e}galement un cadre g{\'e}n{\'e}ral permettant la comparaison syst{\'e}matique de ces strat{\'e}gies et de la plupart des variantes connues. Nous montrons que la litt{\'e}rature n{'}a {\'e}tudi{\'e} que quelques strat{\'e}gies parmi les nombreuses variations possibles, n{\'e}gligeant ainsi plusieurs pistes d{'}am{\'e}liorations potentielles."
W15-3027,Why Predicting Post-Edition is so Hard? Failure Analysis of {LIMSI} Submission to the {APE} Shared Task,2015,5,4,1,1,168,guillaume wisniewski,Proceedings of the Tenth Workshop on Statistical Machine Translation,0,"This paper describes the two systems submitted by LIMSI to the WMTxe2x80x9915 Shared Task on Automatic Post-Editing. The first one relies on a reformulation of the APE task as a Machine Translation task; the second implements a simple rule-based approach. Neither of these two systems manage to improve the automatic translation. We show, by carefully analyzing the failure of our systems that this counterperformance mainly results from the inconsistency in the annotations."
2015.jeptalnrecital-long.1,Apprentissage par imitation pour l{'}{\\'e}tiquetage de s{\\'e}quences : vers une formalisation des m{\\'e}thodes d{'}{\\'e}tiquetage easy-first,2015,-1,-1,2,0,14735,elena knyazeva,Actes de la 22e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"De nombreuses m{\'e}thodes ont {\'e}t{\'e} propos{\'e}es pour acc{\'e}l{\'e}rer la pr{\'e}diction d{'}objets structur{\'e}s (tels que les arbres ou les s{\'e}quences), ou pour permettre la prise en compte de d{\'e}pendances plus riches afin d{'}am{\'e}liorer les performances de la pr{\'e}diction. Ces m{\'e}thodes reposent g{\'e}n{\'e}ralement sur des techniques d{'}inf{\'e}rence approch{\'e}e et ne b{\'e}n{\'e}ficient d{'}aucune garantie th{\'e}orique aussi bien du point de vue de la qualit{\'e} de la solution trouv{\'e}e que du point de vue de leur crit{\`e}re d{'}apprentissage. Dans ce travail, nous {\'e}tudions une nouvelle formulation de l{'}apprentissage structur{\'e} qui consiste {\`a} voir celui-ci comme un processus incr{\'e}mental au cours duquel la sortie est construite de fa{\c{c}}on progressive. Ce cadre permet de formaliser plusieurs approches de pr{\'e}diction structur{\'e}e existantes. Gr{\^a}ce au lien que nous faisons entre apprentissage structur{\'e} et apprentissage par renforcement, nous sommes en mesure de proposer une m{\'e}thode th{\'e}oriquement bien justifi{\'e}e pour apprendre des m{\'e}thodes d{'}inf{\'e}rence approch{\'e}e. Les exp{\'e}riences que nous r{\'e}alisons sur quatre t{\^a}ches de TAL valident l{'}approche propos{\'e}e."
2015.jeptalnrecital-long.4,"Oublier ce qu{'}on sait, pour mieux apprendre ce qu{'}on ne sait pas : une {\\'e}tude sur les contraintes de type dans les mod{\\`e}les {CRF}",2015,-1,-1,4,0,36855,nicolas pecheux,Actes de la 22e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Quand on dispose de connaissances a priori sur les sorties possibles d{'}un probl{\`e}me d{'}{\'e}tiquetage, il semble souhaitable d{'}inclure cette information lors de l{'}apprentissage pour simplifier la t{\^a}che de mod{\'e}lisation et acc{\'e}l{\'e}rer les traitements. Pourtant, m{\^e}me lorsque ces contraintes sont correctes et utiles au d{\'e}codage, leur utilisation lors de l{'}apprentissage peut d{\'e}grader s{\'e}v{\`e}rement les performances. Dans cet article, nous {\'e}tudions ce paradoxe et montrons que le manque de contraste induit par les connaissances entra{\^\i}ne une forme de sous-apprentissage qu{'}il est cependant possible de limiter."
W14-3344,{LIMSI} Submission for {WMT}{'}14 {QE} Task,2014,16,8,1,1,168,guillaume wisniewski,Proceedings of the Ninth Workshop on Statistical Machine Translation,0,"This paper describes LIMSI participation to the WMTxe2x80x9914 Shared Task on Quality Estimation; we took part to the wordlevel quality estimation task for English to Spanish translations. Our system relies on a random forest classifier, an ensemble method that has been shown to be very competitive for this kind of task, when only a few dense and continuous features are used. Notably, only 16 features are used in our experiments. These features describe, on the one hand, the quality of the association between the source sentence and each target word and, on the other hand, the fluency of the hypothesis. Since the evaluation criterion is the f1 measure, a specific tuning strategy is proposed to select the optimal values for the hyper-parameters. Overall, our system achieves a 0.67 f1 score on a randomly extracted test set."
wisniewski-etal-2014-corpus,A Corpus of Machine Translation Errors Extracted from Translation Students Exercises,2014,8,3,1,1,168,guillaume wisniewski,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"In this paper, we present a freely available corpus of automatic translations accompanied with post-edited versions, annotated with labels identifying the different kinds of errors made by the MT system. These data have been extracted from translation students exercises that have been corrected by a senior professor. This corpus can be useful for training quality estimation tools and for analyzing the types of errors made MT system."
F14-1016,Cross-Lingual {POS} Tagging through Ambiguous Learning: First Experiments (Apprentissage partiellement supervis{\\'e} d{'}un {\\'e}tiqueteur morpho-syntaxique par transfert cross-lingue) [in {F}rench],2014,-1,-1,1,1,168,guillaume wisniewski,Proceedings of TALN 2014 (Volume 1: Long Papers),0,None
D14-1187,Cross-Lingual Part-of-Speech Tagging through Ambiguous Learning,2014,21,16,1,1,168,guillaume wisniewski,Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP}),0,"When Part-of-Speech annotated data is scarce, e.g. for under-resourced languages, one can turn to cross-lingual transfer and crawled dictionaries to collect partially supervised data. We cast this problem in the framework of ambiguous learning and show how to learn an accurate history-based model. Experiments on ten languages show significant improvements over prior state of the art performance."
W13-2250,{LIMSI} Submission for the {WMT}{`}13 Quality Estimation Task: an Experiment with N-Gram Posteriors,2013,18,2,2,0,13740,anil singh,Proceedings of the Eighth Workshop on Statistical Machine Translation,0,This paper describes the machine learning algorithm and the features used by LIMSI for the Quality Estimation Shared Task. Our submission mainly aims at evaluating the usefulness for quality estimation of ngram posterior probabilities that quantify the probability for a given n-gram to be part of the system output.
P13-2025,On the Predictability of Human Assessment: when Matrix Completion Meets {NLP} Evaluation,2013,15,0,1,1,168,guillaume wisniewski,Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"This paper tackles the problem of collecting reliable human assessments. We show that knowing multiple scores for each example instead of a single score results in a more reliable estimation of a system quality. To reduce the cost of collecting these multiple ratings, we propose to use matrix completion techniques to predict some scores knowing only scores of other judges and some common ratings. Even if prediction performance is pretty low, decisions made using the predicted score proved to be more reliable than decision based on a single rating of each example."
F13-2028,A corpus of post-edited translations (Un corpus d{'}erreurs de traduction) [in {F}rench],2013,-1,-1,1,1,168,guillaume wisniewski,Proceedings of TALN 2013 (Volume 2: Short Papers),0,None
2013.mtsummit-papers.15,"Design and Analysis of a Large Corpus of Post-Edited Translations: Quality Estimation, Failure Analysis and the Variability of Post-Edition",2013,-1,-1,1,1,168,guillaume wisniewski,Proceedings of Machine Translation Summit XIV: Papers,0,None
W12-4201,{WSD} for n-best reranking and local language modeling in {SMT},2012,22,6,2,0,2673,marianna apidianaki,"Proceedings of the Sixth Workshop on Syntax, Semantics and Structure in Statistical Translation",0,"We integrate semantic information at two stages of the translation process of a state-of-the-art SMT system. A Word Sense Disambiguation (WSD) classifier produces a probability distribution over the translation candidates of source words which is exploited in two ways. First, the probabilities serve to rerank a list of n-best translations produced by the system. Second, the WSD predictions are used to build a supplementary language model for each sentence, aimed to favor translations that seem more adequate in this specific sentential context. Both approaches lead to significant improvements in translation performance, highlighting the usefulness of source side disambiguation for SMT."
W12-3120,Non-Linear Models for Confidence Estimation,2012,14,4,2,0,42247,yong zhuang,Proceedings of the Seventh Workshop on Statistical Machine Translation,0,"This paper describes our work with the data distributed for the WMT'12 Confidence Estimation shared task. Our contribution is twofold: i) we first present an analysis of the data which highlights the difficulty of the task and motivates our approach; ii) we show that using non-linear models, namely random forests, with a simple and limited feature set, succeeds in modeling the complex decisions required to assess translation quality and achieves results that are on a par with the second best results of the shared task."
W12-3141,{LIMSI} @ {WMT}12,2012,23,1,8,1,40944,haison le,Proceedings of the Seventh Workshop on Statistical Machine Translation,0,"This paper describes LIMSI's submissions to the shared translation task. We report results for French-English and German-English in both directions. Our submissions use n-code, an open source system based on bilingual n-grams. In this approach, both the translation and target language models are estimated as conventional smoothed n-gram models; an approach we extend here by estimating the translation probabilities in a continuous space using neural networks. Experimental results show a significant and consistent BLEU improvement of approximately 1 point for all conditions. We also report preliminary experiments using an on-the-fly translation model."
E12-1013,Computing Lattice {BLEU} Oracle Scores for Machine Translation,2012,19,9,2,0,7089,artem sokolov,Proceedings of the 13th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"The search space of Phrase-Based Statistical Machine Translation (PBSMT) systems can be represented under the form of a directed acyclic graph (lattice). The quality of this search space can thus be evaluated by computing the best achievable hypothesis in the lattice, the so-called oracle hypothesis. For common SMT metrics, this problem is however NP-hard and can only be solved using heuristics. In this work, we present two new methods for efficiently computing BLEU oracles on lattices: the first one is based on a linear approximation of the corpus BLEU score and is solved using the FST formalism; the second one relies on integer linear programming formulation and is solved directly and using the Lagrangian relaxation framework. These new decoders are positively evaluated and compared with several alternatives from the literature for three language pairs, using lattices produced by two PBSMT systems."
2012.amta-papers.17,Non-linear n-best List Reranking with Few Features,2012,-1,-1,2,0,7089,artem sokolov,Proceedings of the 10th Conference of the Association for Machine Translation in the Americas: Research Papers,0,"In Machine Translation, it is customary to compute the model score of a predicted hypothesis as a linear combination of multiple features, where each feature assesses a particular facet of the hypothesis. The choice of a linear combination is usually justified by the possibility of efficient inference (decoding); yet, the appropriateness of this simple combination scheme to the task at hand is rarely questioned. In this paper, we propose an approach that replaces the linear scoring function with a non-linear scoring function. To investigate the applicability of this approach, we rescore n-best lists generated with a conventional machine translation engine (using a linear scoring function for generating its hypotheses) with a non-linear scoring function learned using the learning-to-rank framework. Moderate, though consistent, gains in BLEU are demonstrated on the WMT{'}10, WMT{'}11 and WMT{'}12 test sets."
W11-2135,{LIMSI} @ {WMT}11,2011,19,17,5,0.769231,5598,alexandre allauzen,Proceedings of the Sixth Workshop on Statistical Machine Translation,0,"This paper describes LIMSI's submissions to the Sixth Workshop on Statistical Machine Translation. We report results for the French-English and German-English shared translation tasks in both directions. Our systems use n-code, an open source Statistical Machine Translation system based on bilingual n-grams. For the French-English task, we focussed on finding efficient ways to take advantage of the large and heterogeneous training parallel data. In particular, using a simple filtering strategy helped to improve both processing time and translation quality. To translate from English to French and German, we also investigated the use of the SOUL language model in Machine Translation and showed significant improvements with a 10-gram SOUL model. We also briefly report experiments with several alternatives to the standard n-best MERT procedure, leading to a significant speed-up."
max-wisniewski-2010-mining,Mining Naturally-occurring Corrections and Paraphrases from {W}ikipedia{'}s Revision History,2010,10,40,2,0,28247,aurelien max,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"Naturally-occurring instances of linguistic phenomena are important both for training and for evaluating automatic text processing. When available in large quantities, they also prove interesting material for linguistic studies. In this article, we present WiCoPaCo (Wikipedia Correction and Paraphrase Corpus), a new freely-available resource built by automatically mining WikipediaÂs revision history. The WiCoPaCo corpus focuses on local modifications made by human revisors and include various types of corrections (such as spelling error or typographical corrections) and rewritings, which can be categorized broadly into meaning-preserving and meaning-altering revisions. We present an initial hand-built typology of these revisions, but the resource allows for any possible annotation scheme. We discuss the main motivations for building such a resource and describe the main technical details guiding its construction. We also present applications and data analysis on French and report initial results on spelling error correction and morphosyntactic rewriting. The WiCoPaCo corpus can be freely downloaded from http://wicopaco.limsi.fr."
D10-1076,Training Continuous Space Language Models: Some Practical Issues,2010,23,31,3,0,42291,hai le,Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,0,"Using multi-layer neural networks to estimate the probabilities of word sequences is a promising research area in statistical language modeling, with applications in speech recognition and statistical machine translation. However, training such models for large vocabulary tasks is computationally challenging which does not scale easily to the huge corpora that are nowadays available. In this work, we study the performance and behavior of two neural statistical language models so as to highlight some important caveats of the classical training algorithms. The induced word embeddings for extreme cases are also analysed, thus providing insight into the convergence issues. A new initialization scheme and new training techniques are then introduced. These methods are shown to greatly reduce the training time and to significantly improve performance, both in terms of perplexity and on a large-scale translation task."
D10-1091,Assessing Phrase-Based Translation Models with Oracle Decoding,2010,30,13,1,1,168,guillaume wisniewski,Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,0,"Extant Statistical Machine Translation (SMT) systems are very complex softwares, which embed multiple layers of heuristics and embark very large numbers of numerical parameters. As a result, it is difficult to analyze output translations and there is a real need for tools that could help developers to better understand the various causes of errors.n n In this study, we make a step in that direction and present an attempt to evaluate the quality of the phrase-based translation model. In order to identify those translation errors that stem from deficiencies in the phrase table (PT), we propose to compute the oracle BLEU-4 score, that is the best score that a system based on this PT can achieve on a reference corpus. By casting the computation of the oracle BLEU-1 as an Integer Linear Programming (ILP) problem, we show that it is possible to efficiently compute accurate lower-bounds of this score, and report measures performed on several standard benchmarks. Various other applications of these oracle decoding techniques are also reported and discussed."
2010.jeptalnrecital-long.13,Recueil et analyse d{'}un corpus {\\'e}cologique de corrections orthographiques extrait des r{\\'e}visions de Wikip{\\'e}dia,2010,-1,-1,1,1,168,guillaume wisniewski,Actes de la 17e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Dans cet article, nous introduisons une m{\'e}thode {\`a} base de r{\`e}gles permettant d{'}extraire automatiquement de l{'}historique des {\'e}ditions de l{'}encyclop{\'e}die collaborative Wikip{\'e}dia des corrections orthographiques. Cette m{\'e}thode nous a permis de construire un corpus d{'}erreurs compos{\'e} de 72 483 erreurs lexicales (non-word errors) et 74 100 erreurs grammaticales (real-word errors). Il n{'}existe pas, {\`a} notre connaissance, de plus gros corpus d{'}erreurs {\'e}cologiques librement disponible. En outre, les techniques mises en oeuvre peuvent {\^e}tre facilement transpos{\'e}es {\`a} de nombreuses autres langues. La collecte de ce corpus ouvre de nouvelles perspectives pour l{'}{\'e}tude des erreurs fr{\'e}quentes ainsi que l{'}apprentissage et l{'}{\'e}valuation des correcteurs orthographiques automatiques. Plusieurs exp{\'e}riences illustrant son int{\'e}r{\^e}t sont propos{\'e}es."
2010.iwslt-evaluation.13,{LIMSI} @ {IWSLT} 2010,2010,30,0,5,0,5598,alexandre allauzen,Proceedings of the 7th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This paper describes LIMSI{'}s Statistical Machine Translation systems (SMT) for the IWSLT evaluation, where we participated in two tasks (Talk for English to French and BTEC for Turkish to English). For the Talk task, we studied an extension of our in-house n-code SMT system (the integration of a bilingual reordering model over generalized translation units), as well as the use of training data extracted from Wikipedia in order to adapt the target language model. For the BTEC task, we concentrated on pre-processing schemes on the Turkish side in order to reduce the morphological discrepancies with the English side. We also evaluated the use of two different continuous space language models for such a small size of training data."
2010.amta-papers.18,Refining Word Alignment with Discriminative Training,2010,-1,-1,4,0,21324,nadi tomeh,Proceedings of the 9th Conference of the Association for Machine Translation in the Americas: Research Papers,0,"The quality of statistical machine translation systems depends on the quality of the word alignments that are computed during the translation model training phase. IBM alignment models, as implemented in the GIZA++ toolkit, constitute the de facto standard for performing these computations. The resulting alignments and translation models are however very noisy, and several authors have tried to improve them. In this work, we propose a simple and effective approach, which considers alignment as a series of independent binary classification problems in the alignment matrix. Through extensive feature engineering and the use of stacking techniques, we were able to obtain alignments much closer to manually defined references than those obtained by the IBM models. These alignments also yield better translation models, delivering improved performance in a large scale Arabic to English translation task."
